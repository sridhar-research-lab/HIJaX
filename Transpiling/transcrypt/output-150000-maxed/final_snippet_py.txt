sorted(l, key=lambda x: (-int(x[1]), x[0]))
[int(x) for x in str(num)]
np.array(x._data).reshape(x.size[::-1]).T
itertools.combinations
pygame.display.flip()
print([l[i:i + n] for i in range(len(l)) for n in range(1, len(l) - i + 1)])
max(min(my_value, max_value), min_value)
pd.get_dummies(df)
[x[1] for x in elements]
root.mainloop()
[i for i, e in enumerate(a) if e != 0]
max(a_list, key=operator.itemgetter(1))
[item for item in a if item[0] == 1]
[a[i] for i in (1, 2, 5)]
sum(len(v) for v in food_colors.values())
plt.show()
plt.show()
plt.show()
[[[4, 4, 4], [4, 4, 4], [4, 4, 4]], [[4], [4], [4]]]
sorted(list(myDict.items()), key=lambda e: e[1][2])
sorted(list(tag_weight.items()), key=lambda x: int(x[1]), reverse=True)
max(flatlist, key=lambda x: x[1])
df.sort(axis=1, ascending=False)
[i for i, j in zip(a, b) if i == j]
conn.commit()
sorted(list_of_tuples, key=lambda tup: tup[1])
datetime.datetime.now() - datetime.timedelta(days=1)
{k: v for d in L for k, v in list(d.items())}
a.sort(key=lambda x: b.index(x[0]))
instance.__class__.__name__
sorted(list(data.items()), key=lambda x: x[1])
f.close()
datetime.datetime.now().date()
numpy.array([[0, 1, 0], [0, 0, 0], [0, 0, 0]])
[i[0] for i in a]
sorted(list(data.items()), key=lambda x: x[1][0])
sorted(a, key=foo)
ax.plot_trisurf(XS, YS, ZS)
map(dict, zip(*[[(k, v) for v in value] for k, value in list(d.items())]))
datetime.datetime.fromtimestamp(ms / 1000.0)
SomeModel.objects.filter(id=id).delete()
print(random.choice(words))
a.sort(key=lambda x_y: b.index(x_y[0]))
zipped.sort(key=lambda t: t[1])
np.where(a == 1)
f.close()
list(itertools.product(*a))
[input[i:i + n] for i in range(0, len(input), n)]
logging.getLogger().setLevel(logging.DEBUG)
sorted(enumerate(a), key=lambda x: x[1])
array([[True, True], [False, False], [False, False], [True, True]], dtype=bool)
random.sample(list(range(100)), 10)
max(abs(x - y) for x, y in zip(values[1:], values[:-1]))
A = [[[0, 0, 0], [0, 0, 0], [0, 0, 0]], [[0], [0], [0]]]
df.unstack()
[dict(y) for y in set(tuple(x.items()) for x in d)]
sum(d.values())
decimal.Decimal(random.randrange(10000)) / 100
root.destroy()
pandas.concat([df1, df2], axis=1)
[(x, y) for x, y in a if x == 1]
sorted(iter(dict_.items()), key=lambda x: x[1])
xs.sort(key=lambda s: len(s))
len(set(mylist)) == 1
plt.show()
plt.show()
__init__.py
[len(x) for x in s.split()]
[(i // 2) for i in range(10)]
sorted(iter(result.items()), key=lambda key_value: key_value[0])
ax.scartter(XS, YS, ZS)
df.sort(df.columns, axis=1, ascending=False)
[(k, v) for k, v in a.items()]
list(range(9))
L.sort(key=operator.itemgetter(1))
plt.show()
dict((k, v) for k, v in parent_dict.items() if 2 < k < 4)
os.path.dirname(os.path.abspath(existGDBPath))
dict([(e[0], int(e[1])) for e in lst])
df.groupby(level=[0, 1]).median()
plt.show()
my_list[-10:]
all(isinstance(x, int) for x in lst)
[[X[i, j] for i in range(X.shape[0])] for j in range(x.shape[1])]
fh1.seek(2)
(i + 1, j), (i - 1, j), (i, j - 1), (i, j + 1), (i + 1, j - 1), (i + 1, j + 1)
[[X[i, j] for j in range(X.shape[1])] for i in range(x.shape[0])]
[(0, 4), (7, 9), (11, 11)]
[x for y, x in sorted(zip(Y, X))]
myFunc(lambda a, b: iadd(a, b))
plt.gca().invert_yaxis()
numpy.where(mask)
sorted(list(dictionary.items()), key=lambda x: x[1])
numpy.array([(x in a) for x in b])
p.stdin.flush()
dict([(k, v) for k, v in zip(keys, values)])
plt.show()
np.outer(a, b)
[x[0] for x in G]
X_train = scaler.fit(X_train).transform(X_train)
os.kill(process.pid, signal.SIGKILL)
dict((k, v) for k, v in zip(keys, values))
[set(item) for item in set(frozenset(item) for item in L)]
x[(np.arange(x.shape[0]) != 1), :, :]
plt.show()
(i + 1, j), (i - 1, j), (i, j - 1), (i, j + 1), (i - 1, j - 1), (i + 1, j - 1)
[(i, sum(j) / len(j)) for i, j in list(d.items())]
dogtail.rawinput.click(100, 100)
sorted(d, key=lambda k: d[k][1])
[item for item in a if 1 in item]
session.query(Entry).join(Entry.tags).filter(Tag.id == 1).count()
list(d.values())
[x[1] for x in L]
df.div(df.sum(axis=1), axis=0)
sum(your_list)
x, y = np.random.randint(20, size=(2, 100)) + np.random.rand(2, 100)
[sum([x[1] for x in i]) for i in data]
[k for k, v in i.items() if v == 0]
dataList.sort(key=lambda x: x[1])
plt.show()
sum(x * y for x, y in list(zip(a, b)))
p = subprocess.Popen(cmd, stdout=sys.stdout, stderr=sys.stderr)
HttpResponse(status=204)
df.apply(lambda x: x.tolist(), axis=1)
list.sort()
df.apply(lambda row: label_race(row), axis=1)
sorted(list_of_tuples, key=lambda tup: tup[::-1])
plt.show()
[x for x in items if x[2] == 0]
os.path.split(os.path.abspath(existGDBPath))
l.sort(key=alphanum_key)
C = [(a - b) for a, b in zip(A, B)]
[x for x in l if x[1] == 1]
df[~df.index.duplicated()]
b = {a[i]: a[i + 1] for i in range(0, len(a), 2)}
print([key for key, value in list(d.items()) if value == 1])
[i for i in y if y[i] == 1]
bar.sort(key=lambda x: (x.attrb1, x.attrb2), reverse=True)
print(soup.get_text())
sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
[j for i in zip(a, b) for j in i]
df.groupby(df.index).sum()
plt.gca().invert_xaxis()
s.groupby(grouper).sum()
[4, 5, 5, 6, 6, 6]
self.request.url
logging.basicConfig()
[y for x in list(dict.items()) for y in x]
sorted(lst, reverse=True)
[x for x in a if x != [1, 1]]
print(bool(a))
os.path.dirname(os.path.abspath(__file__))
sorted(a, key=lambda x: (len(x), [confrom[card[0]] for card in x]))
df.sort_values(by=1, ascending=False, axis=1)
list(itertools.islice(it, 0, n, 1))
sys.stdout.flush()
plt.show()
array([[1, 2], [2, 0]])
next(iter(list(dict.values())))
{x[1]: x for x in lol}
plt.show()
a[:] = [x for x in a if x != [1, 1]]
sorted(mylist, key=lambda x: order.index(x[1]))
cv2.destroyAllWindows()
matplotlib.pyplot.show()
sum(map(lambda x: x * x, l))
sorted(lst, key=lambda x: (sum(x[1:]), x[0]), reverse=True)
unittest.main()
sorted(item, key=lambda x: x.id)
np.cumsum(x[::-1])[::-1]
pd.concat([df1, df2], axis=1)
plot([0, 0.5], [0.5, 0.5], [0.5, 0.5], [0.5, 1], [0.5, 1], [1, 1])
keys.sort(key=lambda k: (k[0], int(k[1:])))
sorted(lst, key=lambda x: (x < 0, x))
[(v, k) for k, v in a.items()]
map(sum, zip(*l))
df[(df.iloc[:, -12:] == -1).any(axis=1)]
fig.add_subplot(1, 1, 1)
print(any(x in a for x in b))
print([key for key, value in d.items() if value == 1])
[i for i in y if y[i] > 1]
getattr(your_obj, x)
new_list = [(x + 1) for x in my_list]
np.sum(a)
sorted(unsorted, key=lambda element: (element[1], element[2]))
f.close()
vectorizer.get_feature_names()
pygame.display.update()
your_list.sort(key=lambda x: x.anniversary_score)
time.sleep(1)
[(lst[i], lst2[i]) for i in range(len(lst))]
[x[0] for x in os.walk(directory)]
all(i < j for i, j in zip(a, b))
df = df.reset_index()
sorted(lst, key=lambda x: (sum(x[1:]), x[0]))
[sorted(item) for item in data]
print(browser.current_url)
db.session.commit()
sum(j ** i for i, j in enumerate(l, 1))
pygame.display.update()
b = dict(zip(a[0::2], a[1::2]))
pd.concat([df, res], axis=1)
any(np.equal(a, [1, 2]).all(1))
datetime.datetime.now().date()
dict(x[1:] for x in reversed(myListOfTuples))
{key: val for key, val in list(myDict.items()) if val != 42}
[k for k, v in d.items() if v == desired_value]
[[sum([x[1] for x in i])] for i in data]
np.mean(np.array([old_set, new_set]), axis=0)
plt.subplots_adjust(top=0.5)
sorted(list_of_medals, key=lambda x: (-x[1], x[0]))
plt.show()
self.pushButton.clicked.connect(self.showDial)
dict(x[i:i + 2] for i in range(0, len(x), 2))
df.index.values.tolist()
[[int(x) for x in sublist] for sublist in lst]
np.diff(arr[:, (1)])
func(*args)
data[:, ([1, 9])]
lambda a, b: a + b
df.index.get_level_values(0).unique()
plt.show()
map(int, str(num))
[[[x[0]] for x in y] for y in listD]
all(isinstance(x, int) for x in lst)
pd.DataFrame(df.columns[np.argsort(df.values)], df.index, np.unique(df.values))
df.groupby(df.columns, axis=1).sum()
ax.set_xticks([])
arr[:, (1)]
array([True, False, False, True], dtype=bool)
sorted(list(a_dict.items()), key=lambda item: item[1][1])
dict((k, v) for d in dicts for k, v in list(d.items()))
db.commit()
[x for x in my_list if not any(c.isdigit() for c in x)]
arr[arr != 0].min()
os.chdir(os.path.dirname(__file__))
df.head()
pd.concat([students, pd.DataFrame(marks)], axis=1)
dict(zip(list(range(1, 5)), list(range(7, 11))))
threading.Thread(target=SudsMove).start()
zip(*list_of_tuples)
sum(d.values())
root.mainloop()
plt.show()
myList = [i for i in range(10)]
plt.show()
deletemy_list[2:6]
sys.stdout.flush()
urlfetch.fetch(url, deadline=10 * 60)
plt.show()
sys.exit(app.exec_())
PROJECT_ROOT = os.path.abspath(os.path.dirname(__file__))
plt.show()
root.destroy()
plt.show()
l1.sort(key=lambda x: int(x[0]))
my_list.sort(key=lambda x: x[1])
br.select_form(nr=0)
plt.show()
thisRDD = sc.parallelize(range(10), 2).cache()
time.sleep(5)
plt.show()
pygame.display.set_mode((0, 0), pygame.FULLSCREEN)
[list(d.keys()) for d in LoD]
df.value.astype(str).apply(list).apply(pd.Series).astype(int)
isinstance(s, str)
a[tuple(b)]
plt.show()
[[[x[0]] for x in listD[i]] for i in range(len(listD))]
[row[0] for row in a]
x, y = np.random.rand(2, 100) * 20
y = str(int(x, 16))
s.sort(key=operator.itemgetter(1, 2))
driver = webdriver.Firefox()
root.mainloop()
instancelist = [MyClass() for i in range(29)]
df.head()
any([True, False, False])
np.delete(1, 1)
ax.xaxis.set_major_locator(MaxNLocator(integer=True))
[float(i) for i in lst]
[(x * x) for x in range(10)]
x = numpy.delete(x, 0, axis=0)
[x[0] for x in a]
plt.show()
max(enumerate(a), key=lambda x: x[1])[0]
a = [(sum(x) / len(x)) for x in zip(*a)]
msglist = [hextotal[i:i + 4096] for i in range(0, len(hextotal), 4096)]
driver.set_window_size(1400, 1000)
os.path.realpath(os.path.join(root, name))
list(set(frozenset(item) for item in L))
myList = [i for i in range(10) if i % 2 == 0]
vol.extend((volumeA, volumeB, volumeC))
response = requests.put(url, data=json.dumps(data), headers=headers)
df2 = df.reset_index()
pylab.ylim([0, 1000])
d.stack().groupby(level=0).apply(pd.Series.value_counts).unstack().fillna(0)
plt.show()
any(item[2] == 0 for item in items)
dict((v, k) for k, v in map.items())
plt.show()
[l[i:i + n] for i in range(0, len(l), n)]
Book.objects.filter(author__id=1).filter(author__id=2)
{k: v for d in dicts for k, v in list(d.items())}
[item for item in my_list if 1 <= item <= 5]
pd.DataFrame(d)
sum(my_counter.values())
sorted(list(data.items()), key=lambda x: x[1])
[[X[i][j] for j in range(len(X[i]))] for i in range(len(X))]
dict((k, v) for k, v in hand.items() if v)
sorted(data.values())
__init__.py
getattr(test, a_string)
len(dict_test) + sum(len(v) for v in dict_test.values())
[o.my_attr for o in my_list]
plt.show()
f.close()
[i for i in x if i in y]
plt.show()
gca().get_lines()[n].get_xydata()
df.loc[(df.loc[:, (df.dtypes != object)] != 0).any(1)]
dict((i, i * 2) for i in range(10))
[(x + tuple(y)) for x, y in zip(zip(a, b), c)]
{i: (i * 2) for i in range(10)}
time.mktime(dt.timetuple()) + dt.microsecond / 1000000.0
binascii.a2b_hex(s)
s[::2], s[1::2]
plt.show()
[(x1 - x2) for x1, x2 in zip(List1, List2)]
sorted(unsorted_list, key=lambda x: order.get(x, -1))
myDict = {key: val for key, val in list(myDict.items()) if val != 42}
[l[i:i + n] for i in range(0, len(l), n)]
plt.show()
1j * np.arange(5)
plt.show()
sorted(trial_list, key=lambda x: trial_dict[x])
pd.concat(d, ignore_index=True)
d = {k: v for k, v in list(d.items()) if v > 0}
sys.stdout.flush()
plt.show()
file.close()
self.process.terminate()
plt.show()
np.all(np.all(test, axis=2), axis=1)
numpy.ma.array(strided, mask=mask)
plt.show()
df.mean(axis=1)
zip(*np.where(a == 1))
random.sample(range(1, 50), 6)
os.path.abspath(__file__)
plt.show()
a, b = map(int, input().split())
dbb.commit()
sys.exit()
fig.subplots_adjust(wspace=0, hspace=0)
setattr(self, attr, group)
np.array([1j])
df.index
session.query(Shots).filter_by(event_id=event_id).count()
requests.post(url, headers=headers, files=files, data=data)
requests.get(url, verify=True)
sum(list_of_nums)
split_list = [the_list[i:i + n] for i in range(0, len(the_list), n)]
plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))
[i for i in range(len(a)) if a[i] > 2]
sum(len(x) for x in list(food_colors.values()))
session.query(Shots).filter_by(event_id=event_id)
numpy.delete(a, index)
plt.show()
plt.show()
x = numpy.delete(x, 2, axis=1)
[row[1] for row in A]
sorted(lst, key=lambda x: (-sum(x[1:]), x[0]))
np.where(np.diff(arr[:, (1)]))[0] + 1
win.show()
[(x, y) for x, y in zip(myList, myList[1:]) if y == 9]
sum(sum(x) for x in lists)
sorted(a, key=dict.values, reverse=True)
plt.show()
list(range(10, 0, -1))
np.any(np.in1d(a1, a2))
groupby(tags, key=operator.itemgetter(0))
a = sorted(a, key=lambda x: x.modified, reverse=True)
plt.show()
self.axes = self.figure.add_axes([0, 0, 1, 1])
subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
sum(d * 10 ** i for i, d in enumerate(x[::-1]))
data = [line[i:i + 12] for i in range(0, len(line), 12)]
conn.commit()
quadmesh.set_clim(vmin=0, vmax=15)
A(1) + A(2)
somelist.sort(key=lambda x: x.resultType)
mylist.sort()
numpy.concatenate([a, b])
datetime.datetime.now() + datetime.timedelta(seconds=10)
dict((k, v) for k, v in parent_dict.items() if k > 2 and k < 4)
requests.post(url, headers=headers, data=data, files=files)
a[[[0, 0], [0, 0]], [[0, 0], [0, 0]], [[0, 0], [0, 0]]]
cv2.destroyAllWindows()
unique_data = [list(x) for x in set(tuple(x) for x in testdata)]
unittest.main()
os.walk(directory)
pd.DataFrame(df.values - df2.values, columns=df.columns)
d = dict((k, v) for k, v in d.items() if v > 0)
writer.writerows(A)
pd.concat([df_slcd, signs], axis=1)
df.apply(lambda x: x.fillna(x.mean()), axis=0)
root.destroy()
time.sleep(1)
np.nonzero(np.any(a, axis=0))[0]
[x[0] for x in l1 if any(x[0] == y[0] for y in l2)]
sum(d.values())
a = [0] * 10000
admin.site.register(Blog, BlogAdmin)
plt.show()
sorted(s, key=float)
gtk.main()
ax.set_ylim((-10, 80.0))
np.delete(a, list(range(0, a.shape[1], 8)), axis=1)
plt.show()
plt.show()
df.groupby(df.index.year).sum().head()
a[np.argsort(a[:, (1)])]
itertools.permutations([0, 0, 0, 0, 1, 1, 1, 1])
plt.show()
l = [int(x) for x in s.split()]
plt.show()
plt.show()
desired_array = [int(numeric_string) for numeric_string in current_array]
plt.show()
print(x[0], x[1])
lst.append(map(int, z))
app.run()
jsonify(my_list_of_eqtls)
[x for y, x in sorted(zip(Y, X))]
f.write(g.read())
zip(*sorted(enumerate(a), key=operator.itemgetter(1)))[0][-2:]
np.array([fnan, pinf, ninf]) < 0
print(arr[1, 1])
sorted_dict = collections.OrderedDict(sorted(d.items()))
sorted(zipped, key=lambda x: x[1])
ax2.legend(loc=0)
[elem.tag for elem in a.iter() if elem is not a]
plt.show()
plt.show()
dict((v, k) for k, v in my_dict.items())
dict(zip(keys, zip(*data)))
deletemylist[:]
list(df.index)
db.close()
root.mainloop()
plt.show()
root.mainloop()
root = tk.Tk()
f = lambda x, y: x + y
[sum(x) for x in zip(*l)]
print([key for key in d if d[key] == 1])
app.run()
photo.put()
plt.show()
x = x[~numpy.isnan(x)]
np.sqrt(((A - B) ** 2).sum(-1))
app.run()
plt.show()
platform.system()
[(a, b, c) for a, (b, c) in l]
a.index(max(a))
plt.show()
list(set(listA) & set(listB))
[i for i in a if i.isdigit()]
os.system(command)
plt.show()
[tup[0] for tup in A]
plt.show()
plt.show()
list(itertools.combinations(a, 2))
ax.xaxis.tick_top()
json.dumps(your_data, ensure_ascii=False)
bigram_measures = nltk.collocations.BigramAssocMeasures()
plt.show()
writer.writerow(A)
d.apply(pd.Series.value_counts, axis=1).fillna(0)
sparse.coo_matrix(([6], ([5], [7])), shape=(10, 10))
B = np.reshape(A, (-1, 2))
writer.writerow([item[0], item[1], item[2]])
root.lift()
numpy.where(x == x.min())
plt.show()
values = np.array([i for i in range(100)], dtype=np.float64)
plt.show()
list(zip(a, b))
mercury(1, 1, 2)
cleaned_list = [x for x in some_list if x is not thing]
list(itertools.product(*arrays))
np.dot(np.atleast_2d(a).T, np.atleast_2d(b))
[dict(t) for t in set([tuple(d.items()) for d in l])]
df.values.tolist()
cur.execute(sql, list(d.values()))
sum([True, True, False, False, False, True])
plt.show()
plt.show()
plt.show()
[[0, -1, -2], [1, 0, -1], [2, 1, 0]]
np.sqrt(tangent[:, (0)] * tangent[:, (0)] + tangent[:, (1)] * tangent[:, (1)])
pd.to_datetime(pd.Series(date_stngs))
sorted(list(y.items()), key=lambda x: (x[1], x[0]), reverse=True)
[list(i) for i in set(tuple(i) for i in testdata)]
plt.show()
numpy.array([[key, val] for key, val in result.items()], dtype)
window.destroy()
matplotlib.pyplot.show()
driver = webdriver.PhantomJS()
df.values.flatten()
multiprocessing.Process(target=foo, args=(x,)).start()
dict((k, v) for k, v in parent_dict.items() if 2 < k < 4)
sum(df.apply(lambda x: sum(x.isnull().values), axis=1) > 0)
numpy.array([(key, val) for key, val in result.items()], dtype)
plt.show()
datetime.date(2010, 6, 16).isocalendar()[1]
df.isnull().values.any()
pd.concat([x] * 5)
sorted(a, key=lambda i: list(i.values())[0], reverse=True)
print(func.__name__)
[x for x in lst if fn(x) != 0]
list(itertools.chain(*a))
Book.objects.create(**d)
x = [int(i) for i in x.split()]
pd.concat([distancesDF, datesDF.dates], axis=1)
img.show()
ax.set_ylim(0, 5)
mypred = myplsda.predict(Xdata)
plt.show()
pd.concat([pd.DataFrame(l) for l in my_list], axis=1).T
[map(int, sublist) for sublist in lst]
plt.show()
print(list(itertools.chain.from_iterable(a)))
[list(x) for x in zip(*sorted(zip(list1, list2), key=lambda pair: pair[0]))]
sorted(unsorted_list, key=presorted_list.index)
M.sum(axis=0).sum(axis=0)
sorted(list(range(len(a))), key=lambda i: a[i], reverse=True)[:2]
[value for pair in zip(a, b[::-1]) for value in pair]
app.run()
grouped.filter(lambda x: len(x) > 1)
[(lambda x: x * x)(x) for x in range(10)]
app.run()
sorted(list(d.items()), key=lambda k_v: k_v[1])
yourdatetime.date() == datetime.today().date()
df.groupby(df.index.map(lambda t: t.minute))
plt.show()
self.showMaximized()
[(i, j) for i, j in zip(lst, lst2)]
result = [x for x in list_a if x[0] in list_b]
conn.commit()
np.where(out.ravel())[0]
df.round()
a[np.all(a != 0, axis=1)]
[(x + y) for x in l2 for y in l1]
A[(np.random.randint(A.shape[0], size=2)), :]
plt.show()
pd.concat([a, b], ignore_index=True)
table.sort(key=lambda t: t.points)
df.iloc[:, (np.r_[1:10, (15), (17), 50:100])]
foo()
[item[0] for item in queryresult]
plt.show()
[(a * b) for a, b in zip(lista, listb)]
array([[0, 0], [1, 1], [2, 2]])
server.serve_forever()
numpy.nonzero(m.mask)
n = int(input())
Motifs.append(Motif)
range(10, 0, -1)
res_list = [x[0] for x in rows]
plt.show()
plt.show()
[max(len(a), len(b)) for a, b in zip(*x)]
zip(list(range(10)), list(range(10, 0, -1)))
df.groupby(level=0, axis=1).mean()
time.sleep(5)
{k: v for k, v in list(hand.items()) if v}
duck.quack()
next((idx, x, y) for idx, (x, y) in enumerate(zip(list1, list2)) if x != y)
pd.concat([x] * 5, ignore_index=True)
my_string.splitlines()[0]
dfts.groupby(lambda x: x.month).mean()
(a.T * b).T
[key for item in lst for key, value in list(my_dict.items()) if item in value]
pd.read_json(elevations)
plt.show()
hash(pformat(a)) == hash(pformat(b))
np.all(a == a[(0), :], axis=0)
plt.show()
plt.show()
df2 = pd.DataFrame(index=df1.index)
listofzeros = [0] * n
[s for s in (square(x) for x in range(12)) if s > 50]
sys.exit(0)
plt.show()
[max(abs(x) for x in arr[i:i + 4]) for i in range(0, len(arr), 4)]
sys.exit()
plt.show()
plt.show()
s = sorted(s, key=lambda x: (x[1], x[2]))
df = df.reset_index()
plt.show()
[sum(map(int, s)) for s in example.split()]
plt.show()
response = requests.get(url, headers=HEADERS)
any(e in lestring for e in lelist)
plt.show()
Blog.objects.filter(pk__in=[1, 4, 7])
self.canvas.create_image(0, 0, image=image1, anchor=NW)
plt.show()
root.mainloop()
last = len(s) - s[::-1].index(x) - 1
items = [item for item in container if item.attribute == value]
pd.concat(map(pd.DataFrame, iter(d.values())), keys=list(d.keys())).stack().unstack(0)
df.sort_index(ascending=False)
datetime.timedelta(-1, 86100).total_seconds()
sorted(list(d.items()), key=lambda k_v: k_v[1], reverse=True)
fig.add_subplot(111)
plt.show()
[(y - x) for x, y in zip(L, L[1:])]
[a for c in Cards for b in c for a in b]
plt.show()
rows = session.query(Congress).count()
[j for i in zip(a, b) for j in i]
pd.concat((df1, df2), axis=1).mean(axis=1)
new_dict = {k: v for k, v in zip(keys, values)}
map(lambda x: max(x, key=lambda y: y[1]), lists)
list_.sort(key=lambda x: [x[0], len(x[1]), x[1]])
next((key, value) for key, value in list(c.items()) if value > 1)
df.loc[(df.index < start_remove) | (df.index > end_remove)]
sorted(s, key=str.lower)
np.linalg.solve(np.dot(a.T, a), np.dot(a.T, b))
os.chdir(path)
[int(x) for x in regex.findall(filename)]
zip(*l)
A[:, -2:]
plt.show()
dict((k, float(d2[k]) / d1[k]) for k in d2)
a.append(b).reset_index(drop=True)
print(np.array(list(mystr), dtype=int))
ax.get_yaxis().set_ticklabels([])
plt.show()
dict(zip(l[::2], l[1::2]))
dfts.groupby(lambda x: x.year).std()
root.destroy()
[(v, k) for k, v in d.items()]
[f(x) for x in list]
plt.show()
plt.show()
dict((key, sum(d[key] for d in dictList)) for key in dictList[0])
plt.show()
plt.show()
plt.show()
x = x[numpy.logical_not(numpy.isnan(x))]
plt.show()
cv2.destroyAllWindows()
any(isinstance(el, list) for el in input_list)
json_data = json.loads(json_string)
t = sorted(list(a.items()), key=lambda x: x[1])
func(*args, **kwargs)
csvwriter.writerow(row)
l = [[x for x in range(5)] for y in range(4)]
[[y for x, y in sublist] for sublist in l]
cb.ax.xaxis.set_major_formatter(plt.FuncFormatter(myfmt))
list(range(11, 17))
numpy.in1d(b, a)
list(range(1, 11))
plt.show()
plt.show()
plt.show()
my_dict = {x[0]: x[1:] for x in my_list}
plt.show()
db.commit()
sum(x[1] for x in structure)
result = min(max_value, max(min_value, result))
func(*args)
os.kill(pid, signal.SIGUSR1)
parser = argparse.ArgumentParser(allow_abbrev=False)
[list(group) for key, group in itertools.groupby(data, operator.itemgetter(1))]
all(value == 0 for value in list(your_dict.values()))
plt.show()
sorted(map(list, list(totals.items())))
pylab.setp(_self.ax.get_yticklabels(), fontsize=8)
numpy.dstack((your_input_array, numpy.zeros((25, 54))))
plt.show()
__init__.py
new_list = [x.split()[-1] for x in Original_List]
min([x for x in num_list if x > 2])
pd.concat([good, new], axis=0, ignore_index=True)
plt.show()
print(hex(new_int)[2:])
max_item = max(a_list, key=operator.itemgetter(1))
print(proc.communicate()[0])
a[a != 0]
dict(my_object)
plt.show()
theset = set(k.lower() for k in thedict)
hex(sum(b << i for i, b in enumerate(reversed(walls))))
my_list == list(range(my_list[0], my_list[-1] + 1))
Book.objects.filter(pk=pk).update(**d)
print(urllib.request.urlopen(request).read())
[[Foo() for x in range(10)] for y in range(10)]
yourdatetime.date() < datetime.today().date()
np.concatenate(input_list).ravel().tolist()
km.fit(x.reshape(-1, 1))
plt.show()
max(alkaline_earth_values, key=lambda x: x[1])
sorted(subjects, operator.itemgetter(0), reverse=True)
plt.figure(figsize=(1, 1))
[(x + y) for x, y in zip(first, second)]
Gtk.main()
numpy.array(b).reshape(5, 5)
plt.show()
dic.setdefault(key, []).append(value)
df = pd.DataFrame(np.random.random((1000, 100)))
plt.show()
result = [sum(b) for b in a]
print([word for word in words if word[0].isupper()])
df.loc[:, ((df != 0).any(axis=0))]
plt.show()
today = datetime.datetime.utcnow().date()
s[0].upper() + s[1:]
[y[1] for y in sorted([(myDict[x][2], x) for x in list(myDict.keys())])]
p1.communicate()[0]
cherrypy.quickstart()
People.objects.all().order_by()
list_of_lists = [list(k) for k in list_of_tuples]
dict(pair for d in L for pair in list(d.items()))
json.dumps({str(k): v for k, v in data.items()})
sheet.write(1, 1, 2)
alist.sort(key=lambda x: x.foo)
all(a_list)
plt.show()
plt.show()
plt.show()
unittest.main()
map(list, zip(*main_list))
plt.show()
plt.show()
plt.show()
B[np.argsort(A)] = np.sort(B)
np.random.uniform(0, cutoffs[-1])
[f.name for f in br.forms()]
conn.commit()
sorted_by_length = sorted(list_, key=lambda x: (x[0], len(x[1]), float(x[1])))
self.request.get_all()
np.savez(tmp, *[getarray[0], getarray[1], getarray[8]])
[k for k, v in sorted(list(mydict.items()), key=lambda k_v: k_v[1][1])]
sess.run(tf.initialize_all_variables())
list(i[0] == i[1] for i in zip(list1, list2))
plt.show()
lambda x, y: x + y
print(all(word[0].isupper() for word in words))
sorted(li, key=operator.itemgetter(1), reverse=True)
sys.exit(main())
plt.show()
time.sleep(0.1)
plt.show()
print([y for x in list(dict.items()) for y in x])
[x for x in list_of_nums if x != 2]
pygame.display.flip()
new_list = [x[:] for x in old_list]
plt.scatter(*zip(*li))
ax.scatter(XS, YS, ZS)
numpy.dot(numpy.dot(a, m), a)
randomList = [random.random() for _ in range(10)]
[(a + i.reshape(2, 2)) for i in np.identity(4)]
plt.show()
plt.show()
plt.show()
self.sock.connect(self.url, header=self.header)
urllib.request.urlopen(url).read()
Activity.objects.filter(list__topic__user=my_user)
mylist.sort(key=str.lower)
plt.show()
[(i, max(j)) for i, j in list(d.items())]
sum(i * j for i, j in zip(a, b))
ax.contour(x, y, z, levels, cmap=cmap, norm=norm, antialiased=True)
os.path.join(*x.split(os.path.sep)[2:])
time.sleep(1)
[(x / y) for x, y in zip(a, b)]
plt.show()
get_client_ip(request)
sorted(list(d.items()), key=lambda x: (x[1], x[0]))
sum(isinstance(x, int) for x in a)
list(zip(a, b, zip(c[0::2], c[1::2]), d))
df = df.reset_index(drop=True)
plt.show()
result = {k: d2.get(v) for k, v in list(d1.items())}
ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
plt.cla()
set(d.keys())
args[-1] + mySum(args[:-1])
[False, False, True]
plt.show()
threading.Timer(delay, self.update).start()
df.columns = df.columns.get_level_values(0)
archive.write(pdffile, os.path.basename(pdffile))
plt.show()
t = tuple(x[0] for x in s)
root.mainloop()
plt.show()
{{car.date_of_manufacture | datetime}}
list_of_tuples = [tuple(k) for k in list_of_lists]
x[::-1]
sorted(list(u.items()), key=lambda v: v[1])
len(set(a)) == len(a)
np.dot([1, 0, 0, 1, 0, 0], [[0, 1], [1, 1], [1, 0], [1, 0], [1, 1], [0, 1]])
sys.exit()
a = np.array(a)
print(re.findall(pattern, x))
df.sub(df.mean(axis=1), axis=0)
[j for i in x for j in i]
plt.show()
self.assertEqual(response.status_code, 200)
next(iter(dictionary.values()))
os.read(f.fileno(), 50)
np.split(a, [-1])
plt.subplots_adjust(wspace=0, hspace=0)
[i for s in [list(d.keys()) for d in LoD] for i in s]
self.myList.extend([0] * (4 - len(self.myList)))
[[i, i * 10] for i in range(5)]
sorted(list(range(len(a))), key=lambda i: a[i])[-2:]
random.randint(100000000000, 999999999999)
[(c / t) for c, t in zip(conversions, trials)]
np.sqrt(np.square(df).sum(axis=1))
link.click()
[(x[i] == y[i]) for i in range(len(x))]
[list(t) for t in zip(*list_of_tuples)]
string[0].isdigit()
[[0, 0, 0], [1, 1, 1], [0, 0, 0]]
np.array([0.0, pinf, ninf]) < 0
{(x ** 2) for x in range(100)}
connection.commit()
numpy.dstack(numpy.meshgrid(x, y)).reshape(-1, 2)
numpy.array(your_list)
[x[0] for x in rows]
plt.figure(figsize=(8, 8))
array([True, True, True, True, True, True, True, True, True, True], dtype=bool)
file.close()
np.apply_along_axis(mahalanobis_sqdist, 1, d1, mean1, Sig1)
my_array = numpy.array(list(gimme()))
sum(ord(c) for c in string)
sorted(a, key=lambda x: x[1])
logging.disable(logging.CRITICAL)
np.cumsum(a[::-1])[::-1] - np.cumsum(a)
sum(i * i for i in l)
[dict(zip(k, x)) for x in v]
df.drop_duplicates()
urllib.parse.unquote(string)
lista_elegir[np.random.choice(len(lista_elegir), 1, p=probabilit)]
x[[0, 1, -2, -1]]
screen.blit(img, (0, 0))
random_choice = random.choice(choices)
(now - datetime.datetime(1970, 1, 1)).total_seconds()
plt.show()
plt.show()
c[np.logical_or(a, b)]
my_new_list = zip(my_list[0::2], my_list[1::2])
[(x, lst2[i]) for i, x in enumerate(lst)]
plt.show()
plt.show()
ax.yaxis.set_visible(False)
data[i][j][k]
reverse(str1[1:] + str1[0])
z = [(i == j) for i, j in zip(x, y)]
a[-1:] + a[:-1]
plt.show()
self.show()
np.where(np.in1d(A, B))[0]
Group.objects.get(id=1).members.all()[0]
plt.show()
driver.current_url
AtB.loc[:2, :2]
plt.show()
pd.get_dummies(s.apply(pd.Series).stack()).sum(level=0)
itertools.product([False, True], repeat=5)
[x for x in a if x not in b]
gtk.main()
np.count_nonzero(~np.isnan(data))
length = sum(len(s) for s in strings)
df.iloc[:, ([2, 5, 6, 7, 8])]
merged.reset_index()
f.write(makeGrayPNG([[0, 255, 0], [255, 255, 255], [0, 255, 0]]))
A = np.array(sorted(A, key=tuple))
os.stat(filename).st_mtime
plt.show()
[func(a, b) for a, b in zip(arrA, arrB)]
np.diag(np.rot90(array))
lambda a, b: (a, b)
set(a).intersection(b)
datetime.datetime.combine(my_date, datetime.time.min)
plt.show()
[(v, k) for k, v in list(d.items())]
[int(i) for i in str_list]
sorted(l, key=asum)
df[df.columns[df.max() > 0]]
[([0] * width) for y in range(height)]
ax.legend()
root.mainloop()
fig.canvas.draw()
the_list.sort(key=lambda item: (-len(item), item))
time.sleep(0.5)
T = [L[i] for i in Idx]
float(math.factorial(171))
len(set(list1).intersection(list2)) > 0
df.index.to_series().diff()
sorted(matrix, key=itemgetter(1))
threading.Thread(target=play2).start()
birthdays.sort(key=lambda d: (d.month, d.day))
len(set(lst)) == len(lst)
len(list(dictionary.values())) == len(set(dictionary.values()))
plt.show()
[x.lower() for x in words]
df.groupby(key_columns).size()
dict(zip(x, y))
str = etree.tostring(root, pretty_print=True)
print(sum(map(int, x[num - n:num])))
f.close()
plt.show()
A[np.ix_([0, 2], [0, 1], [1, 2])]
np.column_stack(np.where(b))
list(accumulate(list(range(10))))
plt.show()
Group.objects.filter(member__in=[1, 2])
entity.key.id()
plt.show()
sorted(list_of_dct, key=lambda x: order.index(list(x.values())[0]))
df = df.ix[:, 0:2]
regex.findall(string)
[y for y in a if y not in b]
a = a[:n] + k + a[n:]
y = [i[0] for i in x]
int(Decimal(s))
plt.scatter(x, y, color=color)
plt.show()
df.isnull().sum()
name[0].firstChild.nodeValue
list(permutations(list(range(9)), 2))
list(range(10))
slice = [arr[i][0:2] for i in range(0, 2)]
print(repr(data))
{k: (d2[k] / d1[k]) for k in list(d1.keys()) & d2}
numpy.sort(arr, axis=0)
cb.ax.yaxis.set_major_formatter(plt.FuncFormatter(myfmt))
plt.show()
print(response.read())
plt.show()
a = [mynamedtuple(*el) for el in a]
element.click()
{{json.key1}}
list(itertools.product(list(range(-x, y)), repeat=dim))
redis_conn = redis.Redis(connection_pool=redis_pool)
do_something()
a = sorted(a, key=lambda x: float(x))
numpy.concatenate(LIST, axis=0)
any(substring in string for substring in substring_list)
np.in1d(b, a).nonzero()[0]
len(myArray)
data[:, ([1, 2, 4, 5, 7, 8])]
sorted(iter(cityPopulation.items()), key=lambda k_v: k_v[1][2], reverse=True)
[item for innerlist in outerlist for item in innerlist]
plt.show()
a[i] += 1
pygame.display.set_mode(size, FULLSCREEN)
cleaned = [x for x in your_list if x]
User.objects.filter(userprofile__level__gte=0)
list_of_lists = [[try_int(x) for x in lst] for lst in list_of_lists]
app = Flask(__name__)
ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=45)
sorted(t, key=lambda i: (i[1], -i[2]))
app.run(debug=True)
logger = logging.getLogger(__name__)
pyplot.show()
nodes = [[Node() for j in range(cols)] for i in range(rows)]
sys.stdout.flush()
plt.show()
plt.show()
plt.show()
print([u for v in [[i, i] for i in range(5)] for u in v])
sys.stdout.flush()
sorted(itertools.chain(args), cmp)
plt.legend(frameon=False)
cv2.waitKey(0)
min(myList, key=lambda x: abs(x - myNumber))
i, j = np.where(a == value)
cookies = driver.get_cookies()
pd.DataFrame(d)
A[[0, 1], [0, 1]]
sorted(yourdata, reverse=True)
pd.DataFrame(df.values * df2.values, columns=df.columns, index=df.index)
list(itertools.combinations(L, 2))
[item for item in my_list if any(x in item for x in bad)]
list(x * y for x, y in list(zip(a, b)))
b = np.concatenate((a, a), axis=0)
[[int(x)] for y in list_of_lists for x in y]
gtk.main()
result = sys.stdin.read()
res = list(sorted(theDict, key=theDict.__getitem__, reverse=True))
c = [b[i] for i in index]
pickle.loads(s)
figure(figsize=(11.69, 8.27))
[list(v) for k, v in itertools.groupby(mylist, key=lambda x: x[:5])]
str1.split()
legend(numpoints=1)
root.mainloop()
any(x in string for x in search)
df1.groupby([df1.index.year, df1.index.hour]).mean()
len(max(i, key=len))
sorted(iter(d.items()), key=lambda x: x[1])
plt.show()
y = map(operator.itemgetter(0), x)
dict((x, set(y) & set(d1.get(x, ()))) for x, y in d2.items())
vobj.adr
np.equal.reduce([1, 0, 0, 1])
i = np.array([[0], [1]])
plt.show()
xs.sort(lambda x, y: cmp(len(x), len(y)))
df_result.apply(get_col_name, axis=1)
uinfo.save()
arr[[0, 1, 1], [1, 0, 2]]
set([i for s in [list(d.keys()) for d in LoD] for i in s])
[x for b in a for x in b]
sorted(a.items()) == sorted(b.items())
plt.grid(True)
[int(d) for d in str(bin(x))[2:]]
Reporter.objects.all().delete()
df.groupby(level=[0, 1]).quantile()
{{value | safe}}
{k: int(v) for k, v in d.items()}
df[[1]]
[max(len(str(x)) for x in line) for line in zip(*foo)]
a.fromlist([int(val) for val in stdin.read().split()])
session.query(Tag).distinct(Tag.name).group_by(Tag.name).count()
c = [[(i + j) for i, j in zip(e, b)] for e in a]
plt.show()
np.corrcoef(x)
[sublist[::-1] for sublist in to_reverse[::-1]]
[str(wi) for wi in wordids]
keys, values = zip(*list(d.items()))
os.chmod(path, stat.S_IRUSR | stat.S_IRGRP | stat.S_IROTH)
[[] for _ in range(n)]
win.show_all()
cursor.execute(sql, list(myDict.values()))
len(s.split())
pd.concat([df, df.dictionary.apply(str2dict).apply(pd.Series)], axis=1)
plt.colorbar(im, ax=ax)
df.reset_index(inplace=True)
print([obj.attr for obj in my_list_of_objs])
dates_dict.setdefault(key, []).append(date)
[[-1, 2, 0], [0, 0, 0], [0, 2, -1], [-1, -2, 0], [0, -2, 2], [0, 1, 0]]
next(iter(dict.values()))
sorted(zip(a, b))
max(len(word) for word in i)
df.to_pickle(file_name)
sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
isinstance(a, dict)
aapl.groupby((aapl.sign.diff() != 0).cumsum()).size()
self.view.header().setModel(model)
np.where((vals == (0, 1)).all(axis=1))
pd.concat([A, B], axis=1)
root.quit()
sum(map(ord, string))
l = (int(x) for x in s.split())
time.sleep(1)
root.mainloop()
datetime.now() - datetime.now()
connection.close()
msglist = [hextotal[i:i + 4096] for i in range(0, len(hextotal), 4096)]
text.config(state=DISABLED)
new_list = my_list[-10:]
array([[-1, -1], [0, 0], [1, 1]])
y = [row[:] for row in x]
datetime.datetime.combine(dateobject, datetime.time())
mylist.sort(key=lambda x: x.lower())
plt.show()
sum(1 for i, j in zip(a, b) if i != j)
sorted(set(my_list))
p.properties()[s].get_value_for_datastore(p)
np.random.randn(5) * 10
db.session.commit()
df.ix[:-1]
Toy.objects.filter(toy_owners__parents=parent)
curry = lambda f, a: lambda x: f(a, x)
A.ravel()[A.shape[1] * i:A.shape[1] * (i + A.shape[1]):A.shape[1] + 1]
plt.show()
plt.show()
ax.axes.get_yaxis().set_visible(False)
df.stack().groupby(level=0).first()
sck.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
sorted(sorted(s), key=str.upper)
[line.split() for line in f]
weekly = [sum(visitors[x:x + 7]) for x in range(0, len(daily), 7)]
plt.show()
plt.show()
print(zip(my_list[0::2], my_list[1::2]))
file.close()
json.dumps([dict(list(row.items())) for row in rs])
[k for k, v in User._fields.items() if v.required]
d = {t[0]: t[1:] for t in l}
ax2.set_ylim([0, 5])
sys.exit(0)
browser.submit()
sorted(Profile.objects.all(), key=lambda p: p.reputation)
writer.writerows(zip(*[d[key] for key in keys]))
sum(len(y) for y in x if len(y) > 1)
b = np.delete(a, -1, 1)
some_func(*params)
app.run()
((25 < a) & (a < 100)).sum()
sum(x * y for x, y in zip(a, b))
[k for d in list(foo.values()) for k in d]
self.assertEqual(response.status_code, 200)
float(a) / float(b)
itertools.product(list(range(2)), repeat=4)
time.sleep(1)
{k: v for k, v in enumerate(range(10)) if v % 2 == 0}
b.update(d)
[s[:5] for s in buckets]
a[np.in1d(a, b)]
[x for x in j if x >= 5]
d = pd.DataFrame(0, index=np.arange(len(data)), columns=feature_list)
sorted(d, key=d.get)
[m.group(1) for l in lines for m in [regex.search(l)] if m]
sorted(iter(mydict.items()), key=itemgetter(1), reverse=True)
no_integers = [x for x in mylist if not isinstance(x, int)]
plt.plot(x, y)
plt.show()
df.iloc[:, ([2, 5, 6, 7, 8])].mean(axis=1)
plt.show()
plt.draw()
tuple(sorted(a.items()))
plt.show()
time.sleep(5)
A[(np.random.choice(A.shape[0], 2, replace=False)), :]
lst.sort(key=lambda x: x[2], reverse=True)
output.append(max(flatlist, key=lambda x: x[1]))
y = sorted(set(x), key=lambda s: s.lower())
list(itertools.product(*a))
str(n) == str(n)[::-1]
changed_list = [(int(f) if f.isdigit() else f) for f in original_list]
db.session.commit()
np.arange(len(df.columns)) // 2
root.mainloop()
[(lambda x: x * x) for x in range(10)]
[1, 1, 1, 10, 10, 5, 5, 5, 5, 5, 5]
window.set_position(Gtk.WindowPosition.CENTER)
df.iloc[:, ([2, 5, 6, 7, 8])].mean(axis=0)
np.array(arr[:, (1)], dtype=np.float)
mynewlist = list(myset)
time.sleep(10)
reactor.run()
np.array(arr[:, (1)])
plt.show()
plt.show()
random.choice([k for k in d for x in d[k]])
session.commit()
zip(*main_list)
(e == np.array([1, 2])).all(-1)
plt.show()
logger.setLevel(logging.DEBUG)
random.sample(range(1, 50), 6)
ssh.close()
a = a[-1:] + a[:-1]
df.columns[df.max() > 0]
df.info()
globals().update(vars(args))
list_of_tuples[0][0] = 7
done = [(el, x) for el in [a, b, c, d]]
plt.show()
print([[l[:i], l[i:]] for i in range(1, len(l))])
{k for d in LoD for k in list(d.keys())}
sorted(lst, key=lambda x: (-1 * c[x], lst.index(x)))
networkx.draw_networkx_labels(G, pos, labels)
x = [i[0] for i in x]
p.terminate()
b = np.where(np.isnan(a), 0, a)
plt.show()
cv2.destroyAllWindows()
webbrowser.open_new(url)
db.session.delete(page)
pixmap = QtGui.QPixmap(path)
df[df.applymap(isnumber)]
sum(1 for x in list(d.values()) if some_condition(x))
root.mainloop()
app.exec_()
plt.show()
Group.objects.get(id=1).members.all()[0]
m[~m.mask]
matrix = [([0] * 5) for i in range(5)]
[item for item in a if sum(item) > 10]
sorted(list(dictionary.items()), key=operator.itemgetter(1))
[(x, f(x)) for x in iterable if f(x)]
app.run(debug=True)
glfw.Terminate()
print(select([my_table, func.current_date()]).execute())
element.click()
plt.show()
names = list(map(lambda x: x[0], cursor.description))
process.stdin.close()
session.commit()
a = np.concatenate((a, [0]))
app.run(threaded=True)
pd.concat([df.head(1), df.tail(1)])
app.debug = True
model.predict(X_test)
time.sleep(1)
np.flatnonzero(x).mean()
print(template.render())
np.array(list(arr[:, (1)]), dtype=np.float)
map(sum, zip(*lists))
CustomPK._meta.pk.name
[next(it) for _ in range(n)]
cursor.close()
driver.implicitly_wait(60)
[1, 1, 0, 0, 1, 0]
df.T.apply(tuple).apply(list)
root.mainloop()
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
reverse_d = {value: key for key, values in list(d.items()) for value in values}
plt.show()
os.remove(filename)
plt.show()
df.reindex_axis(df.mean().sort_values().index, axis=1)
print(sorted(xs, key=len))
pdb.set_trace()
df.groupby(by=df.columns, axis=1).mean()
plt.show()
numpy.apply_along_axis(numpy.linalg.norm, 1, a)
myList[:] = [(x / myInt) for x in myList]
plt.show()
str_list = list([_f for _f in str_list if _f])
df = df.reset_index()
my_list[:]
my_list = [[x for x in sublist if x not in to_del] for sublist in my_list]
d.setdefault(x, []).append(foo)
obj.save()
driver.page_source
list(chain.from_iterable(a))
ForkedPdb().set_trace()
sum(v for v in list(d.values()) if v > 0)
writer.writeheader()
print(max(x, key=sum))
levels = [{}, {}, {}]
plt.show()
plt.show()
list_dict = {t[0]: t for t in tuple_list}
dict((k, v * dict2[k]) for k, v in list(dict1.items()) if k in dict2)
math.cos(math.radians(1))
sentence = [word.lower() for word in sentence]
logger.setLevel(logging.DEBUG)
zip(it, it, it)
{_key: _value(_key) for _key in _container}
[list(x) for x in list(results.values())]
cv2.waitKey()
np.where((a[0] == 2) & (a[1] == 5))
data = [[0, 0], [0, 0], [0, 0]]
fig.set_size_inches(w, h, forward=True)
df.groupby(level=0, as_index=False).nth(0)
df.iloc[2, 0]
self.buttonBox.button(QtGui.QDialogButtonBox.Reset).clicked.connect(foo)
s.reset_index(0).reset_index(drop=True)
user2 = forms.ModelChoiceField(queryset=User.objects.all())
con.commit()
plt.show()
GRAVITY = 9.8
plt.show()
app.run(debug=True)
args = parser.parse_args()
sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
db.close()
pygame.display.flip()
[i for i, v in enumerate(a) if v > 4]
cv2.waitKey()
[(i, j) for i, j in zip(a, x)]
plt.show()
files.sort(key=file_number)
sortedlist = [(k, a[k]) for k in sorted(a)]
df[pd.isnull(df).any(axis=1)]
conn.commit()
plt.show()
a[1::2] = -1
print(pattern.search(url).group(1))
self.SetSizerAndFit(bsizer)
print(sorted(student_tuples, key=lambda t: (-t[2], t[0])))
sum(x == chosen_value for x in list(d.values()))
plt.show()
sum(l) / float(len(l))
process.start()
plt.show()
arr[arr[:, (2)].argsort()]
grouped.reset_index(level=0).reset_index(level=0)
isinstance(s, str)
plt.show()
arr[-2:2]
signal.signal(signal.SIGCHLD, signal.SIG_IGN)
datetime.utcnow() + timedelta(minutes=5)
[elem.tag for elem in a.iter()]
[(x, y) for x, y in zip(myList, myList[1:]) if y == 9]
app.mainloop()
tst2 = str(tst)
self.root.destroy()
[0, 2, 4, 5]
c[np.logical_and(a, b)]
json_string = json.dumps([ob.__dict__ for ob in list_name])
numpy.append(a, a[0])
win.setWindowFlags(QtCore.Qt.WindowMinimizeButtonHint)
[element for i, element in enumerate(centroids) if i not in index]
np.isnan(np.array([np.nan, 0], dtype=np.float64))
os.system(my_cmd)
app.run()
new_list = [d[key] for key in string_list]
root.mainloop()
os.path.join(root, name)
plt.show()
[{key: dict(value)} for key, value in B.items()]
plt.show()
pprint(dict(list(o.items())))
print((a, b, c, d))
plt.show()
pd.concat([d1, df1], axis=1)
(set(x) for x in d.values())
unittest.main()
datetime.datetime(2010, 7, 26, 0, 0)
plt.show()
pygame.display.flip()
pd.concat([df2, df1], axis=1)
sorted(s, key=str.upper)
[item for item in my_list if some_condition()]
my_list.pop(2)
ordered = OrderedDict(sorted(list(mydict.items()), key=lambda t: t[0]))
datetime.utcnow()
pd.concat([df[:start_remove], df[end_remove:]])
lines.sort()
df.applymap(lambda x: isinstance(x, (int, float)))
server.serve_forever()
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
e = next(iter(s))
sort()
(e == np.array([1, 2])).all(-1).shape
app.run(debug=True)
all(item in list(superset.items()) for item in list(subset.items()))
plt.show()
plt.clf()
deletemy_list[index]
[(myList[i - 1], myList[i]) for i in range(len(myList)) if myList[i] == 9]
sum([(i * j) for i, j in list(itertools.combinations(l, 2))])
plt.figure()
logging.getLogger().setLevel(logging.DEBUG)
new_index = max(0, min(new_index, len(mylist) - 1))
sys.hash_info
text_file.close()
plt.show()
numpy.in1d(b, a).all()
array([True, False, False, True, True, False], dtype=bool)
[key for key, value in list(my_dict.items()) if set(value).intersection(lst)]
sys.stdout.flush()
plt.show()
Book.objects.filter(id=id).update()
zip(*a)
ax.yaxis.set_label_coords(0.5, 0.5)
country, capital = random.choice(list(d.items()))
unittest.main()
int(math.ceil(x)) - 1
[dict(d, count=n) for d, n in zip(l1, l2)]
uniques = collections.defaultdict(set)
C / C.astype(np.float).sum(axis=1)
cv2.waitKey()
r = [(1) for i in range(n)]
sys.exit(0)
{{grains.fqdn_ip}}
sorted(data, key=data.get)
fig, ax = plt.subplots(10, 10)
scipy.spatial.distance.euclidean(A, B)
subseqs = (seq[:i] for i in range(1, len(seq) + 1))
proc.terminate()
plt.show()
plt.show()
d = {(a.lower(), b): v for (a, b), v in list(d.items())}
s.split()
[np.unravel_index(np.argmin(a), (2, 2)) for a in A2]
a.insert(0, k)
list(map(list, set(map(lambda i: tuple(i), testdata))))
plt.show()
plt.show()
plt.show()
max(list(MyCount.keys()), key=int)
numpy.fft.fft([1, 2, 1, 0, 1, 2, 1, 0])
x = map(int, x.split())
plt.show()
{k: (float(d2[k]) / d1[k]) for k in d2}
woduplicates = list(set(lseperatedOrblist))
a.contains(b)
results = Model.objects.filter(x=5).exclude(a=true)
dt = pytz.utc.localize(dt)
print(my_string[0:100])
[lambda x: (x * x for x in range(10))]
array([0, 1, 4, 5, 6, 1, 7, 8, 8, 1])
a[np.in1d(a[:, (1)], b)]
arr[mask] = arr[np.nonzero(mask)[0], idx[mask]]
root.mainloop()
alpha = img.split()[-1]
df.sort(inplace=True)
timestamp = (dt - datetime(1970, 1, 1)).total_seconds()
plt.show()
df.stack()
print_tree(shame)
tuple(zip(*t))
datetime.datetime.fromtimestamp(calendar.timegm(d.timetuple()))
print(response.geturl())
plt.show()
locals()[x]
f.read()
next((i for i, j in enumerate(lst) if j == 2), 42)
dict(d)
driver.current_window_handle
f.close()
df.unstack(level=1)
np.concatenate((np.sort(a[~np.isnan(a)])[::-1], [np.nan] * np.isnan(a).sum()))
a.where(~np.isnan(a), other=b, inplace=True)
f.write(chr(i))
50 - list1[0][0] + list1[0][1] - list1[0][2]
[x for t in zip(list_a, list_b) for x in t]
sorted(list(d.items()), key=lambda x: x[::-1])
plt.show()
plt.show()
plt.show()
df.iloc[:, (0)]
random.choice(list(d.keys()))
list(set(a).union(b))
last_index = len(list1) - 1
z = zip(x, y)
locals()[x]
a = list(a)
A = [i for i in A if i not in B]
unittest.main()
plt.show()
my_list = [item for item in my_list if item.isalpha()]
plt.show()
len(re.findall(pattern, string_to_search))
driver.close()
a[0:0] = k
{k: [lookup[n] for n in v] for k, v in list(my_dict.items())}
df.loc[:, (cols)] / df.loc[ii, cols].values
np.amin(V, axis=0)
b.append(c)
setattr(test, attr_name, 10)
pg.mixer.init()
zip(*a)
f(*((1, 4), (2, 5)))
np.array(list(itertools.product([0, 1], repeat=n ** 2))).reshape(-1, n, n)
plt.show()
print(etree.tostring(root, pretty_print=True))
l.sort(key=alphanum_key)
plt.show()
tuple_of_tuples = tuple(tuple(x) for x in list_of_lists)
sorted(timestamp, reverse=True)
lst = [[] for _ in range(a)]
l[-1:] + l[:-1]
str.isdigit()
unittest.main()
df.apply(pd.Series.nunique, axis=1)
MyClass().mymethod()
list(joined_dataset.values())
plt.show()
MyModel.objects.get(id=1).my_field
model.fit(X_train, y_train)
df.to_pickle(file_name)
ax1.xaxis.get_major_formatter().set_powerlimits((0, 1))
sum(1 for i in range(1, len(a)) if a[i - 1] * a[i] < 0)
plt.show()
plt.show()
plt.show()
getattr(foo, bar)(*params)
{k: list(v) for k, v in groupby(sorted(d.items()), key=itemgetter(0))}
a[np.in1d(a[:, (2)], list(b))]
settime = time.mktime(ftime.timetuple())
print(max(list(d.keys()), key=lambda x: d[x]))
deriv_poly = [(poly[i] * i) for i in range(1, len(poly))]
ab = [(a[i] * b[i]) for i in range(len(a))]
y = str(int(x, 16))
[(i + j) for i, j in zip(x[::2], x[1::2])]
y = np.cumsum(x)
print(max(d, key=d.get))
multiprocessing.Process.__init__(self)
root.mainloop()
self.submenu2.menuAction().setVisible(False)
y[:, (cols)].sum()
[(item for sublist in list_of_lists) for item in sublist]
[i for i in d for j in range(d[i])]
writer.writerows(zip(*list(d.values())))
sorted(L, key=itemgetter(1), reverse=True)
b = a[:, :-1, :]
sum(v[1] for d in myList for v in d.values())
f, axs = plt.subplots(2, 2, figsize=(15, 15))
len(s)
print(df.to_string(index=False))
plt.draw()
ax.scatter(xs, ys, zs, c=cs, marker=m)
sorted(a, key=lambda x: x[1], reverse=True)
[y for sublist in l for x, y in sublist]
plt.show()
res.drop_duplicates()
numpy.prod(a)
urlfetch.set_default_fetch_deadline(60)
session.commit()
db.commit()
output = [[word, len(word), word.upper()] for word in sent]
dist = sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)
np.dot(x, y)
[[j for j in families[i] if i != j] for i in range(len(families))]
row = [x.strip() for x in row]
[i[0] for i in e]
array([[1, 0, 1, 1], [0, 0, 0, 0], [1, 1, 1, 0]])
file.close()
print(soup.prettify())
self.est.fit(X, y)
a = [[(0) for y in range(8)] for x in range(8)]
numpy.apply_along_axis(numpy.linalg.norm, 1, dist)
getpass.getuser()
d.update((k, frozenset(v)) for k, v in d.items())
plt.show()
q = B.select().join(A).group_by(A).having(fn.Max(B.date) == B.date)
plt.show()
np.vstack(a)
dict(map(lambda a: [a[1], a[0]], iter(d.items())))
plt.show()
cleanlist = [(0.0 if math.isnan(x) else x) for x in oldlist]
deletedct[key]
ctypes.addressof(bufstr)
app.run()
a_send = dict((k[0], v) for k, v in list(a.items()))
plt.show()
(df.notnull().cumsum(axis=1) == 4).idxmax(axis=1)
entry_list.extend([entry.title.text for entry in feed.entry])
plt.show()
plt.legend()
app = Flask(__name__)
df = df.loc[:, ((df != 0).any(axis=0))]
x_image = tf.reshape(tf_in, [-1, 2, 4, 1])
[line[2:] for line in lines]
list([a for a in A if a not in B])
[max(len(b) for b in a) for a in zip(*x)]
app.exec_()
next((i for i, v in enumerate(L) if v != x), -1)
zip(*l)
result = [{k: (d1[k] + d2[k]) for k in d1} for d1, d2 in zip(var1, var2)]
df.stack().groupby(level=0).first().reindex(df.index)
pd.concat([s1, s2], axis=1).reset_index()
app.MainLoop()
app.run(debug=True)
map(float, i.split()[:2])
plt.figure().canvas.draw()
[item for pair in zip(a, b) for item in pair]
logging.getLogger().setLevel(logging.DEBUG)
p.start()
y = [s for s in x if len(s) == 2]
top_n.sort(key=lambda t: (-t[1], t[0]))
deletemylist[:n]
int(str1.split()[0])
Employee.objects.select_related()
b[a].shape
print(json.dumps(data))
test_rec[(test_rec.age == 1) & (test_rec.sex == 1)]
match.group(1)
list({(x[0], x[1]): x for x in L}.values())
sys.stdout.isatty()
btn.grid(column=x, row=y, sticky=N + S + E + W)
plt.show()
my_dict2 = dict((y, x) for x, y in my_dict.items())
root.mainloop()
f.read()
pd.concat([df, df.sum(axis=1)], axis=1)
np.searchsorted(A, np.intersect1d(A, B))
session.commit()
np.resize([1, -1], 10)
plt.show()
plt.show()
equal([1, 2], a).all(axis=1)
fig.subplots_adjust(wspace=0, hspace=0)
print(sorted(d.keys()))
plt.show()
new_list = copy.deepcopy(old_list)
np.linspace(0, 5, 10, endpoint=False)
somelist.sort(key=lambda x: x.resultType)
f.close()
array[itemindex[0][0]][itemindex[1][0]]
type(ham).__name__
tuple([(10 * x) for x in img.size])
plt.show()
root.mainloop()
root.mainloop()
plt.show()
[(x, y) for x, y in zip(myList, myList[1:]) if y == 9]
print(os.path.abspath(__file__))
urllib.request.install_opener(opener)
scipy.stats.hypergeom.pmf(k, M, n, N)
btn.clicked.connect(self.close)
plt.show()
cv2.destroyAllWindows()
np.array([a, a, a])
a[:, :2]
[item for sublist in list_of_lists for item in sublist]
main.mainloop()
plt.show()
pd.value_counts(d.values.ravel())
np.tensordot(ind, dist, axes=[1, 1])[0].T
plt.show()
my_tuple = tuple([my_string] + my_list)
[4957, 4957, 1945]
plt.show()
[2, 4, 6, 8]
plt.show()
n = int(input())
good_data = np.array([x for x in data[(0), :] if x == 1.0])
sorted(my_tuple, key=lambda tup: tup[1])
ftp.quit()
plt.show()
xs.sort(key=len)
mylist.sort()
[sum(x, []) for x in zip(L1, L2)]
all_keys = set().union(*(list(d.keys()) for d in mylist))
lst.sort(reverse=True)
workbook.close()
list(sorted(iter))[-10]
i = 5 + Tup()[0]
numpy.concatenate((a, b))
driver.quit()
list(dict.items())
lst = [[] for _ in range(a)]
[(1, 4), (4, 8), (8, 10)]
li = [x for x in li if condition(x)]
zip(*heapq.nlargest(2, enumerate(a), key=operator.itemgetter(1)))[0]
[mystr[i:i + 8] for i in range(0, len(mystr), 8)]
sorted_list_of_values = [item[1] for item in sorted_list_of_keyvalues]
logging.Logger.__init__(self, name, logging.DEBUG)
StreetCat._meta.get_parent_list()
plt.show()
plt.show()
list(dict(((x[0], x[1]), x) for x in L).values())
numpy.nonzero(numpy.in1d(a2, a1))[0]
list(zip(s[::2], s[1::2]))
contour = cv2.convexHull(contour)
sys.stdout.flush()
l = [(x * 2) for x in l]
list(your_iterator)
new_dict = dict(zip(keys, values))
d2 = dict((k, f(v)) for k, v in list(d1.items()))
[dict(zip(r.dtype.names, x)) for x in r]
[x for x in L if x >= 0]
plt.show()
[0, 1, 0, 1, 0, 0, 1, 0]
time.sleep(2)
app.mainloop()
random.shuffle(a)
isinstance(s, str)
plt.show()
data[(np.where(masks)[1]), :]
next((x for x in range(10) if x > 5))
YourApp().run()
a = datetime.datetime.now().year
[row[2:5] for row in LoL[1:4]]
cursor.close()
rates.sub(treas.iloc[:, (0)], axis=0).dropna()
values = [d[k] for k in a]
csv_file.close()
d2 = {k: f(v) for k, v in list(d1.items())}
sorted(list(mydict.values()), reverse=True)
plt.show()
mylist[0][0]
multi_db = True
lst.sort(key=lambda x: (-x[2], x[0]))
Gtk.main()
f.close()
logging.disable(logging.NOTSET)
plt.show()
[len(x) for x in a[0]]
ax.auto_scale_xyz([0, 500], [0, 500], [0, 0.15])
plt.show()
print(etree.tostring(f, pretty_print=True))
[item for sublist in [[i[1:], [i[0]]] for i in l] for item in sublist]
l = [(ord(a) ^ ord(b)) for a, b in zip(s1, s2)]
client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
df.set_index(s.index).sort()
plt.show()
circles = cv2.HoughCircles(gray, cv.CV_HOUGH_GRADIENT)
pd.Series(np.concatenate([a, b]))
df.to_csv()
C = [i for i in A if i not in B]
sum(map(sum, a))
list(range(max(x[0], y[0]), min(x[-1], y[-1]) + 1))
sorted(((v, k) for k, v in d.items()), reverse=True)
transaction.commit()
proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
np.resize([1, -1], 11)
plt.show()
df.plot(x=df.index.astype(str))
[(x - y) for x, y in zip(a[1:], a)]
mylist = list(range(10))
plt.show()
list(zip(keys, values))
plt.colorbar()
set([1, 2, 2]).issubset([1, 2])
plt.show()
list(itertools.chain(*[item.split() for item in lst]))
pygame.display.flip()
np.isnan(a).any(1)
models.PositiveSmallIntegerField(default=0)
set(a).intersection(b, c)
plt.show()
al_arrays = [[l[i:i + 2] for i in range(0, len(l.strip()), 2)] for l in In_f]
sorted(dct, key=dct.get)
x, y = zip(*[(i, -1 * j) for i, j in enumerate(range(10))])
np.where(np.any(a == 2, axis=0) & np.any(a == 5, axis=0))
ax.set_ylim([0, 5])
gpb = float(eval(input()))
splitlists[-1].append(splitlists[0][0])
plt.show()
a = [a[i] for i in range(1, len(a)) if a[i][1] > a[i - 1][1]]
wb.save(file)
[i for i, (a, b) in enumerate(zip(vec1, vec2)) if a == b]
driver = webdriver.Firefox()
list(SomeModel.objects.filter(id=instance.id).values())[0]
y = list(x)
np.where(np.triu(np.ones(A.shape[0], dtype=bool), 1), A.T, A)
f.close()
list(dict.keys())[0]
random.choice(string.ascii_letters[0:4])
df.groupby(df.columns, axis=1).agg(numpy.max)
numpy.array([v for v in vals if len(set(v)) == len(v)])
np.where(~a.any(axis=1))
listOfLists = [[] for i in range(N)]
plt.show()
df = pd.read_pickle(file_name)
workbook.close()
plt.show()
[1, 1, 2, 2]
sorted(trial_list, key=lambda x: trial_dict[x])
app.run()
plt.hist(x, bins=list(range(-4, 5)))
np.array([j for i in arr for j in np.arange(i - 0.2, i + 0.25, 0.1)])
CB.lines[0].set_linewidth(10)
sum(map(sum, my_list))
handler.setLevel(logging.DEBUG)
print(np.split(a, b, axis=0))
app.run(debug=True)
np.diag(np.fliplr(array))
[x[0] for x, y in zip(l1, l2) if x[0] == y[0]]
ax.yaxis.set_major_formatter(formatter)
logger = logging.getLogger(__name__)
plt.show()
tuple(l)
writer.writerows([val])
json.dump(data, f)
a[i:j] = sorted(a[i:j])
len(set(new_words))
df = pd.concat([df1, df2], ignore_index=True)
fig.legend(lines, labels, loc=(0.5, 0), ncol=5)
[i for i in a if i not in b]
f.close()
[row for row in listOfLists if row[x].isdigit()]
plt.show()
set(data1).intersection(data2)
time.sleep(1)
__init__.py
df.values.max()
(f(x) for x in list)
df.drop(grouped.get_group(group_name).index)
ax.xaxis.set_major_formatter(plt.NullFormatter())
sys.stdout.write(msg)
workbook.close()
np.kron(np.eye(n), a)
df[0].values.tolist()
plt.show()
[(index, row.index(val)) for index, row in enumerate(mymatrix) if val in row]
plt.show()
np.take(a, idx, axis=1)
foo(n - 1) + [1]
zip(*data)
ssh.close()
df1.apply(lambda x: x.asof(df2.index))
c = dict(list(a.items()) + list(b.items()))
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
numpy.array([v for v in vals if len(numpy.unique(v)) == len(v)])
[(0, 0), (0, 1), (1, 0), (1, 1)]
[key for key, values in list(rev_multidict.items()) if len(values) > 1]
cv2.waitKey()
plt.show()
reversed(x)
count = sum(len(v) for v in d.values())
print(list(set(chain(*array))))
plt.show()
s1.dropna(inplace=True)
plt.show()
a, b = (int(x) for x in s.split())
listener.close()
plt.show()
sys.exit()
matplotlib.pyplot.scatter(x, y)
rows_list.sort(key=operator.itemgetter(0, 1, 2))
round(1.679, 2)
ax = plt.gca()
my_logger.setLevel(logging.DEBUG)
[name for name in starring if name.strip()]
now = datetime.datetime.now()
{i: np.where(arr == i)[0] for i in np.unique(arr)}
func(*r)
plt.show()
plt.show()
plt.show()
df.head(10)
len(my_list)
isinstance()
root.mainloop()
S2[:len(S1)] == S1
Counter(v for sublist in list(d.values()) for v in sublist)
Hsub = H[1:-1, 1:-1]
server.serve_forever()
set([a, b, c, a])
np.where(x == 5)
map(ord, hex_data)
time.sleep(1)
[y for y in x for x in data]
tornado.ioloop.IOLoop.instance().start()
plt.show()
[list(zip(a, p)) for p in permutations(b)]
print([y for x in l for y in (x, x + 1)])
print(dict(zip(keys, [list(i) for i in zip(*data)])))
any(i.isdigit() for i in s)
list(range(1, 6)) + list(range(15, 20))
a = [0] * 10
bucket.copy_key(new_key, source_bucket, source_key)
window.destroy()
root.mainloop()
print([x[0] for x in data])
clf.fit(X, y)
c[:] = b
pdb.set_trace()
a.argmax(axis=0)
list = [[6, 5, 4], [4, 5, 6]]
plt.show()
df[self.target].str.contains(t).any()
User.objects.filter(userprofile__level__lte=0)
ma.array(np.resize(b, a.shape[0]), mask=[False, False, True])
len(set(a))
a = list(set(a))
list(itertools.product(*s))
set(d1.items()).issubset(set(d2.items()))
db.session.query(Printer).all()
plt.draw()
plt.show()
p.wait()
cols = list(df.columns.values)
plt.show()
firstpart, secondpart = string[:len(string) / 2], string[len(string) / 2:]
os.rename(file, new_name)
my_model.save()
match.group(1)
img.save()
plt.show()
dict((m.get(k, k), v) for k, v in list(d.items()))
lst.sort()
[x[0] for x in listD[2]]
value.isdigit()
[tuple(l) for l in nested_lst]
my_array[:, ([0, 1])] = my_array[:, ([1, 0])]
s.reset_index().drop(1, axis=1)
new_array = [x for x in main_array if x not in second_array]
x = all((a, b, c, d, e, f))
python - -version
cursor.commit()
random.seed()
[(a + b) for a, b in zip(s[::2], s[1::2])]
test[numpy.apply_along_axis(lambda x: x[1] in wanted, 1, test)]
numpy.apply_along_axis(sum, 1, X)
max_index = my_list.index(max_value)
v.dot(np.rollaxis(a, 2, 1))
print(sys.path)
pygame.display.flip()
x = [i for i in x if len(i) == 2]
[word for word in words if any(not char.isdigit() for char in word)]
plt.show()
[(x + y) for x, y in zip(L1, L2)]
out = p.communicate()
[(e in lestring) for e in lelist if e in lestring]
plt.figure(figsize=(6, 6))
plt.draw()
datetime.datetime.fromtimestamp(1284286794)
k, v = next(iter(list(d.items())))
plt.legend(numpoints=1)
nested_list = [[s.upper() for s in xs] for xs in nested_list]
o.save()
print({word: word_list.count(word) for word in word_list})
pdf.close()
print(Event.objects.filter(date__lt=datetime.datetime.now()).delete())
[elem for x in list for elem in (x, 0)][:-1]
list(itertools.product(*list(mydict.values())))
{key: list(set(a[key]).difference(b.get(key, []))) for key in a}
sys.exit(1)
pd.to_datetime(pd.Series(date_stngs))
list(next(it) for _ in range(n))
plt.show()
plt.show()
result.extend(item)
ii = np.where(a == 4)
timestamp = (dt - datetime(1970, 1, 1)) / timedelta(seconds=1)
plt.show()
array[itemindex[0][1]][itemindex[1][1]]
plt.show()
Person.objects.filter(**kwargs)
line = f.readline()
myfile.write(c_uncompData_p[:c_uncompSize])
df[df.index.map(lambda x: x[0] in stk_list)]
plt.show()
[(2, 1, 1), (1, 2, 1), (1, 1, 2)]
isinstance(s, str)
set(L[:4])
plt.show()
f.close()
ind[np.argsort(a[ind])]
df1.reset_index()
os.path.dirname(sys.executable)
plt.draw()
transmission_array.extend(zero_array)
all(x == mylist[0] for x in mylist)
plt.show()
a[:] = [x for x in a if x <= 2]
json.dumps(list)
plt.show()
myList = sorted(set(myList))
a[0:1][0][0] = 5
df.A.apply(lambda x: pd.Series(1, x)).fillna(0).astype(int)
zip(a, b, c)
plt.scatter(list(range(len(y))), y, c=z, cmap=cm.hot)
app.run(debug=True)
df.loc[ii, cols]
plt.show()
np.exp(-x)
print(json.dumps(foo))
{k: (v() if callable(v) else v) for k, v in a.items()}
df.drop(x[x].index)
hehe()
Book.objects.create(**d)
plt.show()
dist = math.hypot(x2 - x1, y2 - y1)
1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0
sorted([-5, 2, 1, -8], key=abs)
out = np.concatenate(input_list).ravel().tolist()
[(i, j) for i, j in zip(a, x) if i >= 4]
ax1.set_xticks([int(j) for j in range(-4, 5)])
datetime.datetime(d.year, d.month, d.day)
s = s[:pos] + s[pos + 1:]
sorted(d, key=d.get)
np.cumsum(a, axis=1, out=a)
sorted(a, key=len)
pd.concat((df1, df2), axis=1)
len(d[obj]) == 2 and isinstance(d[obj][0], int) and isinstance(d[obj][1], int)
inspect.getfile(C.__class__)
sorted(x) == sorted(y)
from_date = from_date.replace(hour=0, minute=0, second=0, microsecond=0)
perm = sorted(range(len(foo)), key=lambda x: foo[x])
print(os.path.dirname(os.path.abspath(sys.argv[0])))
pd.concat(series_list, axis=1)
sum([x for x in list if isinstance(x, (int, float))])
numpy.where(a <= 2, a, 2)
pd.DataFrame(s).T
[[4], [5, 5], [6, 6, 6]]
i = np.indices(B.shape)[0]
a[-2:] + a[:-2]
re.findall(pat, s)
d = dict([(y, x) for x, y in enumerate(t)])
x = Dish.query.filter(Dish.restaurants.any(name=name)).all()
driver.implicitly_wait(10)
dict((d1[key], value) for key, value in list(d.items()))
np.tile(b, (2, 2, 2))
result = [d[key] for key in d if key.startswith(query)]
zip(*it)
y = numpy.unique(x)
set(x[0] for x in zip(a, a[1:]) if x[0] == x[1])
sys.exit(0)
root.mainloop()
bigdata = pd.concat([data1, data2], ignore_index=True)
posting_date = models.DateTimeField(auto_now_add=True)
d = dict((m.get(k, k), v) for k, v in list(d.items()))
app.run()
np.kron(a, np.ones((B, B), a.dtype))
a = zip(list(range(10)), list(range(10)))
plt.show()
f.write(bytes((i,)))
server.serve_forever()
plt.show()
random.choice(mylist)
a[i:j].sort()
some_action.triggered.connect(functools.partial(some_callback, param1, param2))
json.dump([], f)
self.assertTrue(issubclass(QuizForm, forms.Form))
session.query(Shots).filter_by(event_id=event_id).order_by(asc(Shots.user_id))
f.write(hex(i))
decimal.Decimal(str(random.random()))
next(g)
OrderedDict(sorted(list(d.items()), key=d.get))
plt.show()
sorted(a, key=lambda x: b.index(x[0]))
plt.show()
plt.show()
db.commit()
plt.xlim([0, bins.size])
A.sum(axis=0, skipna=True)
df.groupby(df.index).mean()
numpy.argwhere(numpy.in1d(a, b))
plt.show()
datetime.datetime.utcfromtimestamp(1284286794)
a.nonzero()
bool(value)
plt.show()
time.sleep(1)
set(a).intersection(b)
urllib.request.install_opener(opener)
plt.show()
[[word, len(word), word.upper()] for word in sent]
logger.setLevel(logging.DEBUG)
pdb.set_trace()
np.array([[int(i[0], 2)] for i in a])
plt.show()
[str(item[0]) for item in x if item and item[0]]
df = df.reset_index()
products = Product.objects.filter(categories__pk=1).select_related()
{k: v for k, v in list(points.items()) if v[0] < 5 and v[1] < 5}
f.close()
json.dumps(c, default=lambda o: o.__dict__)
sck.setproxy()
list(range(N, -1, -1)) is better
print(tuple(my_list))
set(aa.items()).intersection(set(bb.items()))
rows = [i for i in range(0, len(a)) if a[i][0] == value]
HttpResponse(status=500)
plt.show()
plt.show()
[(x + i * y) for i in range(1, 10)]
len(df.columns)
np.savez(tmp, *getarray[:10])
sys.stdin.read(1)
np.hstack([np.arange(i, j) for i, j in zip(start, stop)])
app.run(threaded=True)
n = int(input())
A.ravel()[:A.shape[1] ** 2:A.shape[1] + 1]
[(x + y) for x in l2 for y in l1]
plt.show()
time.sleep(spacing)
plt.show()
np.fromiter(a, dtype=np.float)
~np.isnan(a).any(1)
matplotlib.pyplot.show()
dict(set.intersection(*(set(d.items()) for d in dicts)))
s * (a + b) == s * a + s * b
some_func(**mydict)
my_list = sorted(list(dict.items()), key=lambda x: x[1])
c = a.flatten()
any(i in a for i in b)
log.start()
sum(x * y for x, y in zip(a, b))
[0, 1, 0, 1, 2, 5, 6, 7, 8, 9]
round(random.uniform(min_time, max_time), 1)
A.ravel()[i:max(0, A.shape[1] - i) * A.shape[1]:A.shape[1] + 1]
app.run()
print([i for i in range(5)])
df
plt.show()
logging.basicConfig(level=logging.WARNING)
plt.show()
plt.show()
itertools.repeat(0, 10)
ax.set_xlim([0, 100])
{k: (float(d2[k]) / d1[k]) for k in d1.keys() & d2}
dct[key].append(some_value)
[([k] + [(sum(x) / float(len(x))) for x in zip(*v)]) for k, v in list(d.items())]
[ord(c) for c in s]
os.makedirs(newpath)
results.sort(key=lambda r: r.person.birthdate)
response = urllib.request.urlopen(req, json.dumps(data))
screen_height = root.winfo_screenheight()
a, b = np.sin(x), np.cos(x)
form.save()
b = a[:-1] + (a[-1] * 2,)
plt.show()
a = [str(wi) for wi in wordids]
print(np.unravel_index(result.argmax(), result.shape))
fcntl.ioctl(s.fileno(), SIOCSIFFLAGS, ifr)
dir()
auth.set_access_token(access_token, access_token_secret)
zip(*[[5, 7], [6, 9], [7, 4]])
df2 = df.astype(float)
img.save()
root.mainloop()
d[i[0]] = int(i[1])
foo[:, (1)]
datetime.combine(date.today(), time()) + timedelta(hours=2)
root.mainloop()
a = np.array(a, dtype=np.float128)
[[random.random() for i in range(N)] for j in range(N)]
c = [(x | y) for x, y in zip(a, b)]
input()
print(list(enumerate(words)))
pdb.set_trace()
cnxn.commit()
print(os.path.join(dirpath, filename))
cursor.execute(query, data)
root.quit()
encoded_string = base64.b64encode(image_file.read())
[(i, j) for i in range(10) for j in range(i)]
browser = webdriver.Safari(quiet=True)
results = [t[1] for t in mylist if t[0] == 10]
driver.quit()
zip(iter(x.items()), iter(y.items()))
heapq.nlargest(6, your_list, key=itemgetter(1))
plt.show()
os.path.relpath(subdir2, subdir1)
[[], [], [], [], [], [], [], [], [], []]
sys.stdout.flush()
df.ix[idx]
setattr(self, key, value)
[l[i::5] for i in range(5)]
operator.itemgetter(*b)(a)
[(m.start(0), m.end(0)) for m in re.finditer(pattern, string)]
any(map(eval, my_list))
df.values.T.tolist()
[i for i in range(len(s1)) if s1[i] != s2[i]]
[list(e) for e in zip(*[fl[i::2] for i in range(2)])]
plt.show()
l[1:]
y[argrelmax(y)[0]]
root.mainloop()
cv2.waitKey()
plt.show()
my_list.sort()
a[~(a == 5).any(1)]
dict([(m.get(k, k), v) for k, v in list(d.items())])
forminstance.is_valid()
plt.show()
socket.gethostname()
np.repeat(a, [2, 2, 1], axis=0)
done = [(i, x) for i in [a, b, c, d]]
plt.setp(axs[1].xaxis.get_majorticklabels(), rotation=70)
array([0, 100, 100, 100, 4, 5, 100, 100, 100, 9])
plt.show()
unique_a = np.unique(b).view(a.dtype).reshape(-1, a.shape[1])
[i for i, x in enumerate(testlist) if x == 1]
dict((key_from_value(value), value) for value in values)
p.start()
self.submenu2.setVisible(False)
array([0, 0, 2, 1, 0, 1])
np.vstack((np.cos(theta), np.sin(theta))).T
pdb.set_trace()
equal([1, 2], a).all(axis=1).any()
[v for k, v in self.items() if v == value]
g = df.groupby(df.index // 2)
len(set(d.values())) == 1
min(L, key=lambda theta: angular_distance(theta, 1))
img.seek(1)
l = [(x * x) for x in range(0, 10)]
plt.show()
plt.show()
dictionary = dict([(List[i], List[i + 1]) for i in range(0, len(List), 2)])
plt.show()
df.applymap(time.isoformat).apply(pd.to_timedelta)
df.groupby(by=df.columns, axis=1).apply(gf)
l = map(lambda x: x * 2, l)
new_list = [seq[0] for seq in yourlist]
my_dictionary = {k: f(v) for k, v in list(my_dictionary.items())}
app.run(port=port)
map(lambda x: x + 1, L)
sys.stdout.flush()
df_col_merged = pd.concat([df_a, df_b], axis=1)
s[::-1]
ip.iptype()
a[list(np.ogrid[[slice(x) for x in a.shape]][:-1]) + [i]]
plt.show()
self.layout.addWidget(self.button)
img.save(sys.argv[2])
db.session.commit()
list(chain.from_iterable(zip(list_a, list_b)))
{i: j for i, j in zip(list(range(1, 5)), list(range(7, 11)))}
series = pd.Series(list(range(20)), dtype=float)
plt.show()
results = cursor.fetchall()
m[m.mask]
x[np.where(x == 5)]
int(time.mktime(dt.timetuple()))
plt.show()
weekdays = models.PositiveIntegerField(choices=WEEKDAYS)
clsmembers = inspect.getmembers(sys.modules[__name__], inspect.isclass)
{k: v for k, v in list(mydict.items()) if k >= 6}
plt.show()
plt.show()
app.run()
[(x * 2 if x % 2 == 0 else x) for x in a_list]
browser.close()
[(x * 1.0 / y) for x, y in zip(a, b)]
pygame.display.update()
root.mainloop()
root.mainloop()
x = [x for x in b.split() if x in a.split()]
wx.Frame.__init__(self, parent)
multiprocessing.cpu_count()
plt.show()
map(self.queryQ.put, self.getQueries())
sorted(s, key=lambda x: int(x[-1]))
func(1, *args, **kwargs)
float(a)
list(globals().keys())[2]
d = dict.fromkeys(string.ascii_lowercase, 0)
root.mainloop()
plt.show()
cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
plt.show()
result = [(x + dx, y + dy) for x, y in points for dx, dy in offsets]
array([[True, True], [True, True]], dtype=bool)
gca().xaxis.set_major_formatter(FuncFormatter(formatter))
list(d.keys())
min([x[::-1] for x in a])[::-1]
plt.show()
x = (x + y) % 48
[ord(x) for x in letters]
plt.show()
zip((1, 2), (40, 2), (9, 80))
r = dict((v, k) for k, v in d.items())
self._bar()
plt.show()
plt.show()
longest_strings = [s for s in stringlist if len(s) == maxlength]
print([(x[0], x[-1]) for x in l])
time.sleep(1)
tables = cursor.fetchall()
df.loc[(df == 1).any(axis=1)]
newsampledata.reindex(newsampledata.index.repeat(n)).reset_index(drop=True)
plt.show()
time.sleep(1)
a.sort(key=Counter(a).get, reverse=True)
len(os.walk(path).next()[2])
df.dtypes
results = sorted(list(results.items()), key=lambda x: x[1], reverse=True)
first, rest = l[0], l[1:]
sorted((sorted(item) for item in data), key=lambda x: (len(x), x))
sorted(os.listdir(whatever_directory))
[i for i in x if 60 < i < 70]
lst.sort()
[(x[i] + x[i + 1]) for i in range(0, len(x), 2)]
plt.show()
self.grid_rowconfigure(1, weight=1)
plt.show()
sys.exit(app.exec_())
json.loads(s)
driver.quit()
plt.show()
[v[0] for v in sorted(iter(d.items()), key=lambda k_v: (-k_v[1], k_v[0]))]
fu_list = [(k, fus_d.get(k), fus_s.get(k)) for k in fus_d.keys() | fus_s]
functools.reduce(np.logical_or, (x, y, z))
d = {int(k): [int(i) for i in v] for k, v in list(d.items())}
cursor.execute(sql)
singleitem = next(iter(mylist))
sys.exit()
[[(k, x[k], y[k]) for k in x if x[k] != y[k]] for x, y in pairs if x != y]
linalg.svd(a[:, :, (1)])
print(dict(new_dict))
[int(s) for s in str.split() if s.isdigit()]
np.moveaxis(np.indices((4, 5)), 0, -1)
list({e.id: e for e in somelist}.values())
plt.show()
time.sleep(0.1)
max(A, key=A.get)
a[i, j] = x
app.run()
model.fit([X])
plt.show()
[dict(zip(keys, a)) for a in zip(values[::2], values[1::2])]
[item for sublist in l for item in sublist]
[item for sublist in list_of_lists for item in sublist if valid(item)]
plt.show()
df.index
plt.show()
f.write(doc.render())
plt.show()
shutil.copyfileobj(from_file, to_file)
main()
df.apply(lambda x: sum(x.isnull().values), axis=1)
{k: v for k, v in points.items() if v[0] < 5 and v[1] < 5}
myFunc(lambda a, b: iadd(a, b))
pl.show()
main()
s.getsockname()[0]
array([4, 5, 5, 6, 6, 6])
os.killpg(self.process.pid, signal.SIGTERM)
fh.close()
list(range(0, 100, 5))
[x for x in foo]
plt.show()
[x for x, y, z in G]
b = np.delete(a, i, axis=0)
root.mainloop()
my_list = [col for row in matrix for col in row]
list(set(dict_a.values()) & set(dict_b.values()))
a = datetime.date.today().year
map(list, list(totals.items()))
np.argmax(np.max(x, axis=1))
cursor.close()
my_list = list(set(my_list))
plt.show()
f.close()
Student.objects.filter(studentgroup__level__pk=1)
self.window.keypad(1)
a.flatten()
files.sort(key=lambda x: os.path.getmtime(x))
df[df.columns[2:5]]
Farm.objects.filter(tree__in=TreeQuerySet)
t.start()
plt.show()
df.replace(0, np.nan).bfill(1).iloc[:, (0)]
root.mainloop()
cherrypy.quickstart(Root())
p.terminate()
set([1])
plt.draw()
sys.stdout.flush()
print(calendar.monthrange(now.year, now.month)[1])
client.transport.write(message)
cell.value = statN
[row[i] for row in matrix]
[(a - int(a)) for a in l]
cbar.ax.tick_params(labelsize=10)
vulnerability = models.ForeignKey(Vuln)
[[[(0) for _ in range(n)] for _ in range(n)] for _ in range(n)]
plt.show()
A = np.squeeze(np.asarray(M))
root.mainloop()
pd.Series([np.array(e)[~np.isnan(e)] for e in x.values])
curses.endwin()
User.objects.filter(Q(income__gte=5000) | Q(income__isnull=True))
random.choice(string.letters)
[dict(zip(keys, values[i:i + n])) for i in range(0, len(values), n)]
(local_dt - datetime.datetime.utcfromtimestamp(timestamp)).seconds
res = np.zeros((arr.shape[0], m), arr.dtype)
np.where(np.in1d(values, searchvals))
logger.setLevel(logging.DEBUG)
dictionary = dict(zip(List[0::2], List[1::2]))
data = {tuple(sorted(item)) for item in lst}
list1 = [i for i in range(n)]
df.apply(lambda x: np.all(x == 0))
{v[0]: data[v[0]] for v in list(by_ip.values())}
sys.stdout.flush()
Kid.objects.filter(id__in=toy_owners)
os.stat(path).st_birthtime
data = [[int(v) for v in line.split()] for line in lines]
[list(l[0]) for l in mylist]
mySet = set(itertools.product(list(range(1, 51)), repeat=2))
json.dumps(s)
sum(v[0] for v in list(d.values())) / float(len(d))
datetime.datetime.combine(dateobject, datetime.time.min)
numpy.array(list(c))
hash(frozenset(list(my_dict.items())))
gems = pygame.sprite.Group()
original[::-1]
root.mainloop()
sum([(x * y) for x, y in zip(*lists)])
result = np.zeros(b.shape)
c = [tuple(x + b[i] for i, x in enumerate(y)) for y in a]
keys, values = zip(*list(dictionary.items()))
db.commit()
dict([i for i in iter(d.items()) if i[0] in validkeys])
plt.colorbar()
bin(10)
s.split()
z = dict(list(x.items()) + list(y.items()))
plt.show()
plt.show()
print(sys.path)
sys.stdout.flush()
somelist = [x for x in somelist if not determine(x)]
plt.show()
df2.reset_index()
len(df.index)
plt.show()
cursor = cnx.cursor(buffered=True)
obj = json.loads(string)
np.corrcoef(x[0:len(x) - 1], x[1:])[0][1]
rows.sort(key=itemgetter(1), reverse=True)
sorted(lst, key=lambda x: (c[x], x), reverse=True)
pd.DataFrame(s).T
[i for i in range(10) if i % 2 == 0]
__init__.py
t.start()
plt.gca().xaxis.set_major_formatter(FixedFormatter(ll))
thread.exit()
d = {k: frozenset(v) for k, v in list(d.items())}
root.mainloop()
sorted(data, key=itemgetter(1))
print(json.dumps(data, indent=2, sort_keys=True))
reactor.run()
L = [L[i] for i in ndx]
yourdate = dateutil.parser.parse(datestring)
[1, 2]
cv2.waitKey(0)
x = np.maximum(x, y)
list(flatten(elements))
time.sleep(1)
f.close()
self._socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
word[1:]
my_handler = logging.StreamHandler(sys.stdout)
print(date.today().year + 1)
df.apply(lambda x: np.sqrt(x.dot(x)), axis=1)
print(str(2) + str(1))
designs = Design.objects.filter(author__user__profile__screenname__icontains=w)
d = dict((y, x) for x, y in enumerate(t))
zip(*s)[0]
list(chain.from_iterable(list_of_lists))
MyApp().run()
server.serve_forever()
np.concatenate((a, val))
map(partial(f, x), y) == map(f, [x] * len(y), y)
handles, labels = ax.get_legend_handles_labels()
a, b, c = (int(i) for i in line.split())
Y = X - X.mean(axis=1).reshape(-1, 1)
f.close()
sys.path.insert(1, os.path.dirname(os.path.realpath(__file__)))
map(list, zip(charlist, numlist))
time.sleep(5)
np.hstack(b)
test[numpy.logical_or.reduce([(test[:, (1)] == x) for x in wanted])]
results = [s for s in strings if any(m in s for m in matchers)]
s.sendmail(FROMADDR, TOADDR + CCADDR, msg.as_string())
ndb.StringProperty(repeated=True)
reverse_lst = lst[::-1]
ax1.set_xticklabels([])
deletelist[-n:]
arr = [[], []]
np.where(np.in1d(a, b))
dict(zip(*([iter(l)] * 2)))
L[:] = new_list
strg[n:] + strg[:n]
df[~df.applymap(np.isreal).all(1)]
b = [int(i != 0) for i in a]
driver = webdriver.Firefox()
print(proc.communicate()[0])
names = [description[0] for description in cursor.description]
plt.show()
plt.show()
plt.show()
dict((k, v) for k, v in list(points.items()) if all(x < 5 for x in v))
inlinkDict[docid] = adoc[1:]
(x * x for x in range(10))
main()
singleitem = mylist[-1]
len(dict[key])
array.append([int(x) for x in line.split()])
[[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]
pd.DataFrame(df.to_records())
verts = [[(0) for x in range(100)] for y in range(10)]
{k: v for k, v in zip(range(1, 5), count(7))}
cursor.execute(sql)
main(sys.argv[1:])
date = models.DateTimeField(default=datetime.now, blank=True)
sys.exit(app.exec_())
A = [[(0) for i in range(n)] for j in range(2 ** n)]
x = float(x)
sorted(test, key=lambda x: isinstance(x, list) and len(x) or 1)
root.mainloop()
fig.show()
((a[:, (np.newaxis), :] - v) ** 2).sum(axis=-1).shape
plt.show()
print(datetime.datetime.now(EST()))
(array_2d == row).all(-1).sum()
sorted([True, False, False])
random.sample(range(len(mylist)), sample_size)
array([[0, 1, 0], [1, 1, 1], [0, 1, 0]])
np.argmax(np.max(x, axis=0))
plt.show()
df[df.index.levels[0].isin([int(i) for i in stk_list])]
df.show()
process.stdin.flush()
np.vstack(counts_array)
ax.xaxis.set_major_locator(ticker.LogLocator(numticks=6))
datetime.datetime(2012, 4, 1, 0, 0).timestamp()
[list(x) for x in zip(*sorted(zip(list1, list2), key=itemgetter(0)))]
date_time_secs = time.mktime(datetimeobj.timetuple())
os.makedirs(path_directory)
m[:, (0)].reshape(5, 1).shape
ax.set_axis_off()
words = line.split()
queryset.filter(created_at__gte=datetime.date.today())
os.getpid()
next((i for i, v in enumerate(l) if is_odd(v)))
smtp.sendmail(send_from, send_to, msg.as_string())
print(list(sk.d.items()))
plt.scatter(x, y, color=c)
settings.py
print(pd.Series(df.values.tolist(), index=df.index))
[[random.random() for x in range(N)] for y in range(N)]
set(alllists).difference(set(subscriptionlists))
plt.show()
[values for key, values in list(rev_multidict.items()) if len(values) > 1]
start_delta = datetime.timedelta(days=weekday, weeks=1)
plt.tight_layout()
pd.concat([df_current, df_future]).sort_index()
bin(_)
a = a.reshape((m, n)).T
result = [list(someListOfElements) for _ in range(x)]
x = list(set(x))
plt.show()
print(all(lst[i].lower() < lst[i + 1].lower() for i in range(len(lst) - 1)))
max(l, key=lambda x: (x[1], random.random()))
dict(zip(it, it))
data.apply(lambda r: sorted(r), axis=1).drop_duplicates()
sum(int(c) for c in strs if c.isdigit())
arr[np.maximum.accumulate(np.isnan(arr), axis=1)] = np.nan
writer.writerow([val])
cursor.execute(sql_and_params[0], sql_and_params[1:])
df.sort_index(inplace=True)
print(df.head())
print(os.path.basename(sys.argv[0]))
plt.show()
self.somevalue = somevalue
plt.show()
[x for i in range(len(l)) for x in l[i]]
np.vstack(dat_list)
max(l, key=lambda x: x[1] + random.random())
self.date = d.replace(tzinfo=pytz.utc)
a.insert(0, a.pop())
new = np.reshape(a, (-1, ncols))
min(list(range(len(values))), key=lambda i: (values[i], -i))
timestamp = dt.replace(tzinfo=timezone.utc).timestamp()
print([x for x in A if all(y in x for y in B)])
plt.show()
ax.set_xticklabels(xlbls)
type(iter(d.values()))
df = df / df.max().astype(np.float64)
conn.commit()
plt.show()
[(lambda x: x * i) for i in range(4)]
df = pd.read_sql(sql, cnxn)
test.__name__
plt.show()
os.isatty(sys.stdin.fileno())
wordcount = len(s.split())
scipy.optimize.leastsq(residuals, p_guess, args=(x, y))
print(decrement())
df.corr().mask(np.equal.outer(df.index.values, df.columns.values))
random.choice(mylist)
tuple_list = [(a, some_process(b)) for a, b in tuple_list]
{{OBJNAME.get_FIELDNAME_display}}
p.stdin.close()
f.write(s)
test = sorted(test, key=lambda x: len(x) if type(x) == list else 1)
text_file.close()
sys.setrecursionlimit()
root.mainloop()
holes = [(table[i][1] + 1, table[i + 1][0] - 1) for i in range(len(table) - 1)]
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj))
time = timeit.timeit(lambda : module.expensive_func(data))
{k: (v * dict2[k]) for k, v in list(dict1.items()) if k in dict2}
json.dumps(fu)
map.put(key, new_value)
root.mainloop()
dic = dict((y, x) for x, y in enumerate(al, 1))
plt.show()
arr[[1, 4, 5]]
logger = logging.getLogger(__name__)
fig.tight_layout()
cherrypy.engine.start()
root.mainloop()
df.columns = pd.MultiIndex.from_tuples(df.columns.to_series())
somelist[:] = [x for x in somelist if not determine(x)]
{x[0]: len(list(x[1])) for x in itertools.groupby(sorted(mylist))}
(lambda x, f: list(y[1] for y in f(x)))(lst, lambda x: (sorted(y) for y in x))
connection.commit()
sum(a)
pdb.set_trace()
np.split(a, np.nonzero(np.diff(a))[0] + 1)
self.button.clicked.connect(self.calluser)
blog.comment_set.all()
cap = cv2.VideoCapture(0)
[array([0]), array([47, 48, 49, 50]), array([97, 98, 99])]
ax.set_xticklabels(x)
ma.array(a, mask=np.isnan(a)).mean(axis=0)
pd.crosstab(df.A, df.B).apply(lambda r: r / len(df), axis=1)
pd.DataFrame([record_1])
app.run(debug=True)
scipy.stats.hypergeom.cdf(k, M, n, N)
[np.nonzero(np.in1d(x, c))[0] for x in [a, b, d, c]]
pd.DataFrame(np.where(df, 1, 0), df.index, df.columns)
f = lambda x, y: x + y
data = json.load(f)
tuple(tup[0] for tup in A)
datetime.fromtimestamp(1268816500)
plt.show()
len(set(a)) == len(a)
np.isnan(a)
np.cov(x)
np.linalg.norm(x, ord=1)
[1, 4, 5, 6, 7]
inspect.getmembers(my_module, inspect.isclass)
s.map(lambda x: x[:2])
ioloop.IOLoop.instance().start()
[list(g) for k, g in itertools.groupby(iterable)]
np.equal.reduce([False, 0, 1])
f.write(json.dumps(data, ensure_ascii=False))
Counter(map(tuple, list1))
os.path.dirname(fullpath)
list(range(len(strs) - 1, -1, -1))
csv_file.writerows(the_list)
python - -version
np.cumsum(np.concatenate(([0], np.bincount(v))))[v]
[k for k, g in groupby(sorted(chain.from_iterable(iter(content.values()))))]
np.asarray([func(i) for i in arr])
numpy.in1d(a, b).nonzero()
df.fillna(0)
ax.set_yticks([])
current_module = sys.modules[__name__]
server.starttls()
np.hstack([X, Y])
plt.figure()
sys.exit(1)
env.skip_bad_hosts = True
not any(my_list)
map(max, zip(*alist))
Book.objects.filter(Q(author__id=1) & Q(author__id=2))
Thread(target=cherrypy.quickstart, args=[Root()]).start()
app.mainloop()
f = os.path.join(path, f)
df[last_row.argsort()]
dict(zip(l[::2], l[1::2]))
[(i ** 2) for i in list]
numpy.where(mask, 1, numpy.where(numpy_array == 0, 0, 2))
QApplication.desktop()
plt.show()
sys.exit()
server.serve_forever()
mydict = dict((rows[0], rows[1]) for rows in reader)
numpy.empty((10, 4, 100))
{k: v for k, v in list(dict.items()) if v > something}
admin.site.register(User, UserAdmin)
fig.autofmt_xdate()
plt.show()
[k for k, count in list(Counter(L).items()) if count > 1]
entry = [str(x) for x in cols.findAll(text=True)]
plt.show()
etree.tostring(e, pretty_print=True)
admin.site.register(Person, PersonAdmin)
pygame.display.set_mode((1, 1))
sorted(iter(cityPopulation.items()), key=lambda k_v: k_v[1][2], reverse=True)
y.astype(int)
print(m.group(1))
data = numpy.genfromtxt(yourFileName, skiprows=n)
localtime(now()).replace(hour=0, minute=0, second=0, microsecond=0)
df2.reindex(df.index)
plt.show()
plt.show()
np.random.random((N, N))
app = Flask(__name__)
setattr(i, x, f(getattr(i, x)))
max(x, key=x.get)
plt.show()
zip(*sorted(zip(x, y), key=ig0))
all_challenges = session.query(Challenge).join(Challenge.attempts).all()
[dictio for dictio in dictlist if dictio[key] in valuelist]
sum(abs(x - y) for x, y in zip(sorted(xs), sorted(ys)))
[[int(y) for y in x] for x in values]
[OrderedDict((k, d[k](v)) for k, v in l.items()) for l in L]
l = np.array([list(method().values()) for _ in range(1, 11)])
ax.xaxis.set_major_locator(locator)
sys.stdout.flush()
outfile.write(infile.read())
os.path.dirname(sys.argv[0])
button.clicked.connect(self.commander(command))
__init__.py
input_str = sys.stdin.read()
print(re.findall(pattern, x))
[i for i, item in enumerate(a) if item in b]
[tuple(l) for l in nested_lst]
[transform(x) for x in results if condition(x)]
min(x for x in lst if isinstance(x, str))
server.serve_forever()
os.path.abspath(math.__file__)
sum(map(int, l))
im = Image.fromarray(my_array)
list_.sort(key=lambda x: x[0])
do_something()
[[(i * j) for i, j in zip(*row)] for row in zip(matrix1, matrix2)]
result = sorted(iter(promotion_items.items()), key=lambda pair: list(pair[1].items()))
sys.exit(app.exec_())
print(getpass.getuser())
getattr(model, fieldtoget)
output.close()
sorted(list(d.items()), key=operator.itemgetter(1, 0))
foo()
[int(i) for i in str(number)]
plt.show()
os.system(cmd)
pd.DataFrame(a, df.index, df.columns)
(a1[:, (numpy.newaxis)] == a2).all(axis=2).astype(int)
gtk.main()
s1.reset_index(drop=True) * s2.reset_index(drop=True)
df.applymap(np.isreal)
[(i * y + x) for i in range(10)]
df.reindex_axis(sorted(df.columns), axis=1)
l = list(set(l))
p = subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE)
logging.basicConfig(level=logging.WARN)
logging.Formatter.__init__(self, msg)
plt.show()
datetime.utcfromtimestamp(float(self.timestamp))
curses.doupdate()
pixmap4 = pixmap.scaled(64, 64, QtCore.Qt.KeepAspectRatio)
A = A - A.multiply(B)
plt.show()
sys.exit(0)
revdict = dict((v, k) for k, v in list(ref.items()))
zip(*lists)
plt.show()
plt.show()
dict((k, 2) for k in a)
a[:, ::2] + a[:, 1::2]
np.array(list(g))
win.show_all()
plt.show()
list1.sort(key=convert)
[a for a in s if s.count(a) == 1][0]
numpy.nonzero(numpy.in1d(a, b))
browser.quit()
plt.subplots_adjust(top=0.75)
session.commit()
dict([(t.__name__, t) for t in fun_list])
sorted(temp, key=itemgetter(1), reverse=True)
l = [x for x in l if x.strip()]
a[np.arange(np.shape(a)[0])[:, (np.newaxis)], np.argsort(a)]
root.mainloop()
b.sort(key=lambda x: a.index(x))
np.put(arr, np.where(~np.in1d(arr, valid))[0], 0)
b[a[1, 1]]
z = arr[:, (5)].sum()
ftp.quit()
ast.literal_eval(reclist)
sorted(d, key=lambda x: (-x[1], x[0]))
df.append(new_df, ignore_index=True)
df.sort_index(inplace=True)
set(x[0] for x in list1).intersection(y[0] for y in list2)
print(etree.tostring(root, pretty_print=True))
root.mainloop()
sys.stdin.isatty()
os.kill(pid, signal.SIGTERM)
os.path.join(directory, filename)
RotatingFileHandler(filename, maxBytes=10 * 1024 * 1024, backupCount=5)
plt.legend()
a[-1] * (a[-1] + a[0]) / 2 - sum(a)
your_list = [int(i) for i in f.read().split()]
sympy.sstr(_)
plt.show()
[x for d in thedict.values() for alist in d.values() for x in alist]
pd.concat([data, ts]).sort_index().interpolate().reindex(ts.index)
print(repr(the_string))
list({len(s): s for s in jones}.values())
np.tile(np.arange(y), x)
print(list(itertools.combinations(a, i)))
newprefix = list(prefix)
ax.set_ylim(0, 1)
python - mserver
sum(jdcal.gcal2jd(dt.year, dt.month, dt.day))
User.query.join(User.person).filter(Person.id.in_(p.id for p in people)).all()
Project.objects.filter(action__person=person)
menu = gtk.Menu()
x = min(float(s) for s in l)
threading.Thread.__init__(self)
sorted(list(c.items()), key=itemgetter(0))
np.polyfit(x, y, 4)
sorted(a, key=lambda v: (v, random.random()))
[i for i, x in enumerate(lst) if x < a or x > b]
plt.show()
np.count_nonzero(boolarr)
y = (i[0] for i in x)
plt.show()
queryset.filter(created_at__range=(start_date, end_date))
QtCore.Qt.ItemIsEnabled
time.sleep(10)
datetime.datetime(1970, 1, 1) + datetime.timedelta(seconds=-2082816000)
data = numpy.loadtxt(yourFileName, skiprows=n)
a.transpose(2, 0, 1)
df.to_dict()
b = np.fill_diagonal(np.zeros_like(a), value)
python - pip
f(tup1[0], tup1[1], tup2[0], tup2[1])
print(bytes.decode(encoding))
sys.stdout.flush()
plt.show()
plt.show()
plt.setp([ax.get_xticklines(), ax.get_yticklines()], color=color)
z = merge_two_dicts(x, y)
f(*args)
cursor.close()
a.index(max(a))
p.wait()
ma.vstack([a, ma.array(np.resize(b, a.shape[0]), mask=[False, False, True])])
__init__.py
G[i, j] = C_abs[i, j] + C_abs[j, i]
{x: (0) for x in string.printable}
tuple(s[i:i + 2] for i in range(0, len(s), 2))
[map(int, x) for x in values]
aList, bList = [[x for x in a if x[0] == i] for i in (0, 1)]
pool = Pool(4, initializer, ())
app.mainloop()
browser = webdriver.Safari()
print(math.ceil(4.2))
tf.sqrt(tf.reduce_mean(tf.square(tf.sub(targets, outputs))))
ones = [(x, y) for x, y in l if y == 1]
gtk.main()
[(s + mystring) for s in mylist]
ser.readline()
result = sum(x for x in range(1, 401, 4))
doctest.testmod()
os.chmod(path, mode)
[[0.4, 0.6, 0.0, 0.0], [0.2, 0.4, 0.4, 0.0], [0.0, 0.0, 0.4, 0.6]]
df.corr().iloc[:-1, (-1)]
[0] * 4
sorted(l, key=lambda i: hypot(i[0] - pt[0], i[1] - pt[1]))
session = Session.get_by_id(sid)
ar = [r[0] for r in cur.fetchall()]
frozenset(list(a.items()))
norm.ppf(norm.cdf(1.96))
plt.show()
root = tree.getroot()
sorted(set().union(*input_list))
plt.gca().set_position([0, 0, 1, 1])
d = {k: [] for k in keys}
f.close()
forms.ModelForm.__init__(self, *args, **kwargs)
socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
file.read(1)
f.seek(0)
print(nat.index(nat.Germany))
plt.show()
plt.subplots_adjust(bottom=0.2)
random.choice(string.ascii_letters + string.digits)
form = MyModelForm(request.POST, instance=my_record)
a = [map(int, row.split()) for row in stdin]
list(itertools.accumulate(lst, lambda a, b: tuple(map(sum, zip(a, b)))))
plt.show()
main()
simplelist.append(x)
[word for line in f for word in line.split()]
print(arr[[1, 4, 5]])
integers = [(int(i) - 1) for i in line.split()]
plt.show()
p = ax.scatter(xs, ys, zs, c=cs, marker=m)
list(itertools.chain.from_iterable(list(d.values())))
collections.Counter(a)
self.show()
[numbers[i % len(numbers)] for i in range(start, start + len(numbers))]
plt.show()
json.dumps([dict(mpn=pn) for pn in lst])
plt.imshow(cv2.cvtColor(cube, cv2.COLOR_BGR2RGB))
print(list_end_counter([1, 2, 1, 1, 1, 1, 1, 1]))
map(itemgetter(1), elements)
root.deiconify()
test.reshape((4, 4))[:, :2].reshape((2, 4))
dt = tz.localize(naive, is_dst=True)
print(json.dumps(result))
print(applejuice.__name__)
sys.path.append(module_path)
d += datetime.timedelta(1)
subprocess.call(cmd, stdin=f)
map(lambda y: [np.mean(y[i:i + length]) for i in range(0, len(y), length)], a)
testarray = ast.literal_eval(teststr)
bool(random.getrandbits(1))
(arr == arr[0]).all()
[(0, 0, 1, 1), (0, 1, 0, 1)]
test.__defaults__
sys.exit(main(sys.argv[1], sys.argv[2]))
A = np.delete(A, 50, 1)
print(json.dumps(result))
my_dictionary = dict(map(lambda k_v: (k_v[0], f(k_v[1])), iter(my_dictionary.items())))
zipfile.ZipFile(path)
[sum(zip(*x)[1]) for x in data]
data.groupby(level=[0, 1]).sum()
plt.show()
sys.exit(1)
img = Image.open(file)
res_list = [i[0] for i in rows]
sys.exit(1)
plt.show()
plt.show()
np.polyfit(X, Y, 1)
score = sum([(x * y) for x, y in zip(a, b)])
frame = pd.read_csv(path, names=columns)
b = [i for sub in a for i in sub]
os.close(fh2)
plt.show()
cursor.commit()
[[y for y in x if y not in to_del] for x in my_list]
print(sum(map(ord, my_string)))
a[key].append(1)
c.most_common(1)
sum(d.values())
[(int(i) if i.isdigit() else float(i)) for i in s]
plt.show()
plt.minorticks_off()
output.close()
ax.get_xaxis().get_major_formatter().set_scientific(False)
app = Flask(__name__)
tree.delete(*tree.get_children())
[n for i, n in enumerate(xs) if i == 0 or n != xs[i - 1]]
plt.show()
r = np.ptp(a, axis=1)
d.update((b, a[:, (i)]) for i, b in enumerate(a))
cbar.set_ticklabels([mn, md, mx])
next((i for i, val in enumerate(lst) if np.all(val == array)), -1)
reactor.run()
root.mainloop()
df.groupby(df.index.year // 10 * 10).sum()
x = [[foo for i in range(10)] for j in range(10)]
self.response.out.write(self.request.body)
plt.show()
Category.objects.filter(category__isnull=True)
ax.w_yaxis.set_ticklabels([])
[len(x) for x in a[0]]
plt.show()
os.path.join(mydir, myfile)
plt.show()
plt.show()
driver.quit()
list1[0][2]
dummy = np.array([[1, 1, 0, 0], [0, 0, 1, 1]]).T
[v for i, v in enumerate(myList) if i not in toRemove]
(df == 1).sum()
asyncio.get_event_loop().run_forever()
np.flatnonzero(x[:-1] != x[1:]).mean() + 0.5
datetime(date.year, date.month, date.day)
plt.show()
map(lambda f: f(*args), funcs)
numpy.zeros((i, j, k))
y = [i[0] for i in x]
plt.show()
df.ix[:5, :10]
[x for x in a if x <= 1 or x >= 4]
proc.communicate()
f(*args, **kwargs)
c = [item for pair in zip(a, b) for item in pair]
ax.lines.pop(0)
sorted(Thing.objects.all(), key=lambda t: t.name)
ssh.close()
sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
root.mainloop()
a[:, (0)][mask]
plt.plot(x[i:i + 2], y[i:i + 2])
l = [i.split() for i in l]
reactor.run()
ax.set_yticklabels([])
self.searchqueryset.filter(group__isnull=True)
some_list.remove(thing)
datetime.datetime(1, 1, 1) + datetime.timedelta(microseconds=ticks / 10)
[x for x in l if x % 2 == 0]
logger.setLevel(logging.DEBUG)
np.cross(a, b, axis=0)
c = dict(list(a.items()) | list(b.items()))
self.canvas.pack()
root.mainloop()
plt.show()
[1, 1, 1] < [1, 1, 2]
df.iloc[i]
M = list(set(L))
df[df.apply(lambda x: min(x) == max(x), 1)]
app.run(debug=True)
logger = logging.getLogger(__name__)
my_list.sort(key=nonesorter)
FieldSet = dict((k, v) for k, v in FieldSet.items() if len(v) != 1)
__init__.py
assertTrue(math.isnan(nan_value))
sum(v for k, v in c.items() if v > 1)
s.send(my_bytes)
pylab.show()
np.place(a, np.isnan(a), 0)
writer.writerows(cursor.fetchall())
array([[0, 1, 2], [0, 2, 0], [0, 1, 2], [1, 2, 0], [2, 1, 2]])
y.mean(axis=1).mean(axis=-1)
ZipFile.write(a, compress_type=zipfile.ZIP_DEFLATED)
sys.stdout.flush()
pylab.show()
setattr(self, k, v)
x.reshape(2, 2, 5).transpose(1, 0, 2).reshape(4, 5)
l = [item.lower() for item in l]
[item for item in my_list if some_condition()]
session.query(q).limit(10)
tuple([tuple(row) for row in myarray])
help(my_func)
p1.start()
Post.objects.filter(createdAt__lte=datetime.now() - timedelta(days=plan.days))
coord = tuple(sum(x) for x in zip(coord, change))
sorted(lst, key=lambda L: (L.lower(), L))
plt.show()
time.mktime(time.gmtime(0))
plt.show()
getattr(foo_obj, command)()
df = pd.DataFrame.from_dict(data)
print(result.group(0))
time.sleep(1)
form = MyModelForm(instance=someinst)
self.Bind(wx.EVT_PAINT, self.OnPaint)
{l[1]: l for l in lol}
any(k in s for k in keywords)
len(a) == len(b) and all(a.count(i) == b.count(i) for i in a)
a[a == 2] = 10
sorted(lst, key=operator.itemgetter(1), reverse=True)
cols = list(df.columns.values)
ax.legend()
Gtk.main()
myscript.py
nx.draw(G)
signal.signal(signal.SIGINT, signal_handler)
root.mainloop()
df = df.append(pd.read_sql(querystring, cnxn, params=[i]))
n = sum([(len(v) + 1) for k, v in list(dict_test.items())])
[random.choice(list_of_lists) for _ in range(sample_size)]
mySet = set((x, y) for x in range(1, 51) for y in range(1, 51))
bool_list = [False] * len(bool_list)
numpy.intersect1d(a, b)
A[np.ix_([0, 2], [0, 1], [1, 2])]
spDF.rdd.first()
[i for i, (a, b) in enumerate(zip(vec1, vec2)) if a == b]
root = Tk()
json.loads(s)
dict(j for i in L for j in list(i.items()))
ax.set_xticks([])
outfile.write(line)
df = pd.DataFrame(data=matrix.toarray(), columns=names, index=raw)
plt.show()
print([s[i] for i in index])
print((i, [round(255 * x) for x in rgb]))
[-2, -2, -2, -2, -8, -8, -8, -8, -8, -8]
ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
plt.show()
cv2.waitKey(0)
list(range(11, 17))
Thread(target=fct).start()
[len(x) for x in s.split()]
[y for y in a if y not in b]
df.insert(idx, col_name, value)
[(x + 1) for x in y]
defaultdict(lambda : defaultdict(dict))
db.session.add(query)
Group.objects.get(id=1).members.filter(is_main_user=True)[0]
sqs.filter(has_been_sent=True)
plt.show()
plt.show()
df.sort_index()
np.linspace(0, 5, 10)
numpy.transpose([numpy.tile(x, len(y)), numpy.repeat(y, len(x))])
np.array(x).reshape(2, 2, 4)
admin.site.unregister(Site)
plt.figure(figsize=(5, 6))
{i: (0) for i in range(0, 10)}
os.setsid()
drawPropagation(1.0, 1.0, numpy.linspace(-2, 2, 10))
[item for sublist in (list_of_lists for item in sublist)]
[a for a in A.objects.all() if a.b_set.count() < 2]
z = merge_dicts(a, b, c, d, e, f, g)
logging.basicConfig(level=logging.DEBUG)
int(s[1:], 2) / 2.0 ** (len(s) - 1)
os.path.splitext(os.path.basename(f))
[x[0] for x in a]
plt.show()
list(my_dict.items())
plt.show()
array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])
plt.show()
numpy.argwhere(a.max() == a)
lines.sort()
np.random.seed(1)
plt.show()
filtered_dict = {k: v for k, v in my_dict.items() if not st.isdisjoint(v)}
simplelist = [SimpleClass(count) for count in range(4)]
(lambda x, y: x + y)(1, 2)
plt.show()
array([0, 0, 1, 0, 0, 1, 0])
ax.set_xticks([])
doctest.testmod()
max(enumerate(props), key=lambda tup: len(tup[1]))
(M == 0).T.nonzero()
a[np.lexsort(a[:, ::-1].T)]
plt.plot(x, y)
numpy.mean(gp2)
a[key].append(2)
my_dict2 = {y: x for x, y in my_dict.items()}
func(*args, **kwargs)
df.iloc[:, ([0])]
sum([True, True, True, False, False])
[key for key, val in list(dct.items()) if val]
root.mainloop()
a = [(b + 4 if b < 0 else b) for b in a]
b = a[:]
assert rdd.squares().collect() == rdd.map(lambda x: x * x).collect()
L.append([7, 8, 9])
zipfile.ZipFile(zipbytes)
random_key = os.urandom(16)
np.allclose(a, b)
fig = plt.figure()
any(np.array_equal(np.array([[0, 0], [0, 0]]), x) for x in my_list)
[(x, y) for x, y in numpy.ndindex(a.shape)]
admin.site.register(User, UserAdmin)
l = ast.literal_eval(s)
plt.draw()
self.process.terminate()
soup = BeautifulSoup(html)
sorted(chain(a, b), key=lambda x: x.name)
pd.DataFrame(s.groupby(level=0).apply(list).to_dict())
name = sys.argv[1]
Gtk.main()
admin.site.register(YourModel, YourModelAdmin)
a[i, j] = 5
sum(1 for row in rows for i in row if i)
c.bin[2:]
gtk.main()
[0] * 10000
locals().update(my_dict)
plt.show()
{k: sum(v) for k, v in list(trimmed.items())}
time.sleep(1)
print(getattr(somemodule, class_name))
plt.show()
time.sleep(1500)
print(pdf_file.read())
(dist ** 2).sum(axis=1) ** 0.5
df_row_merged = pd.concat([df_a, df_b], ignore_index=True)
print(sys.stdin.read())
p.wait()
sheet.write(1, 0, 1)
lst = [os.path.splitext(x)[0] for x in accounts]
odeint(func, y0, t, a, b, c)
np.dot(I, np.ones((7,), int))
fig.colorbar(p)
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
df.to_csv(f, index=False, header=False)
bids.append(int(bid))
connection.close()
Some_Model.objects.filter(id__in=ids_list).delete()
platform.architecture()
plt.show()
my_list2, my_list1 = map(list, zip(*my_list))
sum(1 for c in string if c.islower())
[a[i // 2] for i in range(len(a) * 2)]
[1505]
pickle.dumps(threading.Lock())
open(f.name).read()
ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.jet)
df.loc[(df.isnull().any(axis=1)), :] = np.nan
df.toPandas()
int(sum(jdcal.gcal2jd(dt.year, dt.month, dt.day)))
a_lower = dict((k.lower(), v) for k, v in list(a.items()))
{tuple(x) for x in l1}.intersection(map(tuple, l2))
print(celery.current_task.task_id)
starf = [int(i) for i in starf]
sum(zip(*structure)[1])
x.reshape(2, 2, 5).transpose(1, 0, 2)
locals()[4]
S1.intersection(S2)
plt.gca().invert_yaxis()
[list(itertools.chain(*x)) for x in zip(L1, L2)]
s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
plt.show()
{k: [(a + b) for a, b in zip(*v)] for k, v in list(d.items())}
text = str(combobox1.currentText())
datetime.datetime.combine(birthdate, datetime.time())
A * B[:, (np.newaxis)]
np.dot(np.dot(I, np.ones((7,), int)), mat)
z = int(str(x) + str(y))
np.mgrid[0:5, 0:5].transpose(1, 2, 0).reshape(-1, 2)
list(dict.keys())
plt.show()
cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)
[(2 * x) for x in some_list if x > 2]
Toy.objects.filter(owner__parent__id=1)
random.uniform(-1, 1)
plt.show()
B = numpy.array([A[0, 0, 1], A[2, 1, 2]])
json.dump(data, outfile, ensure_ascii=False)
data = [[int(i) for i in line.split()] for line in original]
subsampled = df.ix[(choice(x) for x in list(grouped.groups.values()))]
plt.show()
self.response.out.write(key)
plt.show()
print(os.path.join(subdir, file))
greet_selves()
plt.show()
[next(iter(s)) for _ in range(10)]
cidrs = netaddr.ip_range_to_cidrs(ip_start, ip_end)
response = requests.post(url, data=data)
ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
[os.path.split(r)[-1] for r, d, f in os.walk(tree) if not d]
pprint([OrderedDict(zip(names, subl)) for subl in list_of_lists])
(df != 0).any(axis=0)
plt.show()
tornado.ioloop.IOLoop.instance().start()
plt.show()
re.findall(rx, st, re.VERBOSE)
max(a, key=sum)
plt.show()
root.mainloop()
plt.show()
a[([i for i in range(a.shape[0]) if i != 1]), :, :]
myfile.close()
f.subs(x, 1)
[(x, y) for x in a for y in b]
sys.stdout.buffer.write(pdf_file.read())
webbrowser.open(filename)
print(requests.get(url, data=data, cookies=cookies).text)
datetime.datetime(ddd.year, ddd.month, ddd.day)
sorted(list(range(len(s))), key=lambda k: s[k])
plt.show()
reactor.run()
foo()
sys.stdout = sys.__stdout__
[str(n) for n in range(10)]
print(os.path.join(directory, file))
plt.show()
filtered_dict = {k: v for k, v in list(d.items()) if filter_string in k}
set(dic1.keys()) == set(dic2.keys())
MyMIDI.addNote(track, channel, pitch, time, duration, volume)
root.mainloop()
int(float(s))
msg.attach(MIMEText(text))
reactor.run()
print(doctree.toprettyxml())
combined = list(itertools.chain.from_iterable(lists))
file_contents = f.read()
print(line.rstrip())
np.random.multivariate_normal(mean, cov, 10000)
list(l) == [0] * len(l)
dict(mylist)
np.concatenate((A[::-1, :], A), axis=0)
mylist[0][:1]
fig.autofmt_xdate()
[random.random() for _ in range(0, 10)]
print(numpy.array([X()], dtype=object))
plt.show()
plt.show()
plt.show()
map(truediv, a, b)
a = np.frombuffer(Data)
df[(df <= 2).all(axis=1)]
np.allclose(ans1, ans2)
f.write(e8)
[i for i in range(len(word)) if word[i] == letter]
print(soup.prettify())
d = collections.defaultdict(lambda : [0, []])
thing.save()
plt.show()
app.run()
max(PlayerList, key=lambda p: max(p[1:]))[0]
set(a) & set(b)
sys.exit(0)
plt.show()
db.session.commit()
np.linalg.norm(A - B, axis=-1)
[0, 16, 17, 18]
random.shuffle(array)
json.dumps({str(k): v for k, v in list(data.items())})
sorted(d, key=d.get, reverse=True)
c = [(i, 0) for i in a]
Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
np.isnan(np.array([np.nan, 0], dtype=object))
MyList = [inst1, inst2]
result = (list_[0][0] + list_[1][0]) * (list_[0][1] + list_[1][1])
zip(*elements)[1]
print(df.applymap(lambda x: str(x).isdigit()))
q = Model.objects.filter(Q(field1=f1) | Q(field2=f2)).distinct()
sum(sum(1 for i in row if i) for row in rows)
zip(keys, values)
repr(s)
plt.show()
json1_data = json.loads(json1_str)[0]
rdd = sc.parallelize([(1, 2)])
ax.legend()
sum([v[0] for v in list(d.values())]) / float(len(d))
time.sleep(1)
time.sleep(0.1)
smaller_array = np.delete(array, index)
sys.stdout.flush()
total = sum(int(r[1]) for r in csv.reader(fin))
ax.set_xlim(0, 7)
plt.hist(b, bins)
[(m.get(k, k), v) for k, v in list(d.items())]
[(mylist[i:] + [newelement] + mylist[:i]) for i in range(len(mylist), -1, -1)]
x.pop(random.randrange(len(x)))
df = df / df.loc[df.abs().idxmax()].astype(np.float64)
plt.show()
df.reset_index(level=0, inplace=True)
plt.show()
sorted(lst, reverse=True, key=operator.itemgetter(0))
print([tryeval(x) for x in L])
python - mplatform
[(m + str(n)) for m, n in zip(b, a)]
sum(int(n) for n in str(2 ** 1000))
new_list.append(fruit)
random.choice(words)
time.sleep(1)
myfunc(*args)
time.sleep(1)
foo()
s.dropna()
br.set_handle_robots(False)
plt.show()
[int(s) for s in I.split() if s.isdigit()]
random.shuffle(l)
df_example.iloc[([1, 4]), :-1].T.corr()
max(d, key=d.get)
print(first_list + list(set(second_list) - set(first_list)))
ax.legend()
lambda i: i[0]
np.concatenate((A[::-1, :], A[1:, :]), axis=0)
np.mean(a, axis=1)
array([True, True, True, False, False, False, False], dtype=bool)
app.run()
do_something_with(line)
r = requests.post(url, data=json.dumps(data), headers=headers)
existing = db.session.query(Task).filter_by(challenge_slug=slug)
[x[0] for x in tuple_list]
new_list = [(a, new_b) for a, b in tuple_list]
A = np.random.randn(1000, 1000)
ax.set_xlim([0, 1])
sorted(list(a.items()), key=itemgetter(1), reverse=True)
time.sleep(1)
fig.show()
plt.show()
sorted(l, key=lambda s: (s.isdigit(), s))
ax.plot_wireframe(T, z, abs(U), cstride=1000)
root.mainloop()
max(x, key=lambda i: x[i])
arr = np.append(arr, np.array([[4, 5, 6]]), axis=0)
[list(map(int, x)) for x in values]
r = requests.post(url, files=files)
code.interact(local=locals())
_w()
pdb.set_trace()
matplotlib.pyplot.show()
schema = models.TextField(default=get_default_json)
np.isclose([10000000000.0, 1e-07], [10000100000.0, 1e-08])
int(x) / int(y) == math.floor(float(x) / float(y))
_cxn.commit()
gtk.main()
set.intersection(*(set(x) for x in d.values()))
sum(i for i in a)
pygame.display.set_mode(size)
df.sub(df.a, axis=0)
dict((k, mydict[k]) for k in keys_to_select if k in mydict)
str(1).zfill(2)
print(line.rstrip())
out = [a, b, c, d, e, f]
reactor.run()
list1.sort(key=int)
plt.show()
ax.plot(x, y)
sorted(lst, key=lambda x: (-counts[x], firstidx[x]))
sys.stdout.write(chr(x))
sorted(lst, key=str.lower)
set(zip(*[lst[i:] for i in range(n)]))
A = [(A[i + 1] + A[i]) for i in range(len(A) - 1)]
[numbers[i] for i in range(len(numbers)) if i not in indices]
print(os.path.join(path, filename))
[i for e in bad for i in my_list if e in i]
(s * 5).tolist()
myDict[item[1]] += item[2]
scipy.sparse.csr_matrix(df.values)
bin(0)
new_data = np.vectorize(boolstr_to_floatstr)(data).astype(float)
time.sleep(1)
plt.show()
db.rollback()
np.any(my_array[:, (0)] == value)
os.getpid()
rand_smpl = [mylist[i] for i in sorted(random.sample(range(len(mylist)), 4))]
list([x for x in l if x not in f])
lst = [int(i) for i in str(num)]
obj.save()
res = list(set(a) ^ set(b))
sys.stdout.write(str(x))
l.sort(key=sum_nested)
np.fill_diagonal(df.values, 0)
__init__.py
cherrypy.quickstart(HelloWorld())
[i for i, j in enumerate(a) if j == m]
mySet = set([myString])
self.matches = [s for s in self.options if s and s.startswith(text)]
MyModel.objects.all()
plt.show()
length = len(list(clusterList))
norm = [(float(i) / sum(raw)) for i in raw]
data.append(json.loads(line))
sorted(zipped, key=operator.itemgetter(1))
c = sum(1 for word in words if word[0] == word[-1])
cnx.commit()
np.eye(foo.shape[1]) * foo[:, (np.newaxis)]
app.run()
plt.show()
[map(dict.get, list(range(1, 6))) for _ in range(10)]
author = models.ForeignKey(User, null=True, blank=True)
corrs = df.corr()
re.sub(reg, rep, text)
Py_Finalize()
conn.commit()
self.cdr = cdr
x = np.array([(1, 0), (0, 1)])
plt.show()
gtk.main_iteration()
new = [int(i) for i in old]
hismgr = get_ipython().history_manager
any(x in set(b) for x in a)
print(settings.BASE_DIR)
requests.get(url, params=query)
A[B == x].sum()
ax.set_xticklabels([])
sys.stdin.isatty()
ax.xaxis.set_major_formatter(xfmt)
sys.stdout.flush()
np.where(np.eye(A.shape[0], dtype=bool), A, A.T + A)
self.Bind(wx.EVT_LEFT_DCLICK, self.OnDoubleClick)
datetime.datetime.now() - datetime.timedelta(minutes=15)
sys.stdout.flush()
app.exec_()
ma.array(a, mask=np.isnan(a))
[(j - i) for i, j in zip(t[:-1], t[1:])]
writer.writerow(row)
all(b >= a for a, b in zip(the_list, it))
zip(*A)
plt.show()
plt.show()
[word for word in l if word.isalnum()]
c = [x for x in b if x in _auxset]
[list(x[1]) for x in itertools.groupby(data, lambda x: x == 0) if not x[0]]
list(itertools.chain(*[([k] * v) for k, v in list(d.items())]))
self.save()
print(time.mktime(d.timetuple()))
np.roll(a, 1)
round(number * 2) / 2.0
pprint(sys.path)
A[i, j]
print(doc.toprettyxml())
parts = [your_string[i:i + n] for i in range(0, len(your_string), n)]
app.logger.setLevel(logging.DEBUG)
random.shuffle(lst)
data_slices.sort(key=lambda s: s[-1].start)
reactor.run()
sorted(mydict, key=lambda key: mydict[key])
plt.show()
results = list(map(int, results))
df.where((df > df.shift(1)).values & DataFrame(df.D == 1).values)
user.put()
cv.WaitKey(0)
dfrm.drop(dfrm.index[len(dfrm) - 1])
df.stack().reset_index(level=[0, 1], drop=True)
img.show()
t1start <= t2start <= t1end or t2start <= t1start <= t2end
df.iloc[indexers]
plt.legend(loc=4)
Cordi1 = [[int(i) for i in line.split()] for line in data]
Foo.foo()
json_string = json.dumps(list_name, default=obj_dict)
[x for b in a for x in b]
unittest.main()
plt.show()
br.select_form(nr=1)
ax.xaxis.set_visible(False)
image = gtk.image_new_from_pixbuf(pixbuf)
plt.show()
{key: val for key, val in parent_dict.items() if 2 < key < 4}
cursor = db.cursor(dictionary=True)
numpy.in1d(a, b)
plt.show()
sorted(mylist, key=cmp_to_key(locale.strcoll))
np.array([(arr + i) for i in np.arange(-0.2, 0.25, 0.1)]).T.ravel()
tf.constant(1) + tf.constant(2)
min([t for t in l if not math.isnan(t[1])], key=itemgetter(1))
sorted(l1 + l2)
zeros = [([0] * M) for _ in range(N)]
driver.switch_to_alert().accept()
sys.exit()
dict([k_v for k_v in list(d1.items()) if k_v[0] in d2 and d2[k_v[0]] == k_v[1]])
random.sample(list(range(1, 10)), 5)
Series([str(x) for x in htmldata])
print([(lst[i], lst[i + 1]) for i in range(0, len(lst), 2)])
session.commit()
ftp.quit()
a.transpose(2, 1, 0)
lst.append(os.path.splitext(x)[0])
re.split(seperator, f.read())
myTextCtrl.SetFont(font1)
a == a[(0), :]
plt.show()
zip(l, l[1:])
print([(s, s in st1) for s in re.findall(pat, st2)])
df.idxmax(axis=1)
plt.show()
[x for y in l for x in y]
list(range(x1, x2 + 1))
root.mainloop()
method()
writer.writerow([])
pd.concat([df_a, df_b], axis=1)
time.sleep(0.1)
{tuple(key): value for key, value in zip(bins, count)}
p.start()
[10, 9, 8, 4, 7]
calendar.timegm(time.gmtime())
conn.commit()
{key: list(set.difference(set(a[key]), b.get(key, []))) for key in a}
print(file_contents)
print(list(chain.from_iterable((x, x + 1) for x in l)))
nx.draw_spring(G)
df.index
[[[x, y] for x in list1] for y in list2]
ssh.connect(IP[0], username=user[0], pkey=mykey)
df[(df.iloc[:, -12:] == -1).all(axis=1)]
a.__init__(*args, **kwargs)
a[~np.isnan(a).any(1)]
plt.show()
list(StreetCat._meta.parents.keys())[-1]
print(f.read())
sorted(a) == sorted(b)
set(data1) & set(data2)
pl.show()
ax.get_xticklines()[i].set_visible(False)
time.sleep(0.5)
df.dot(weight)
chr(128512)
array[(i[0]), (i[1]), (i[2]), ..., (i[n - 1])]
plt.show()
[6, 7, 8, 9]
A2, B2 = zip(*sorted(zip(A, B), key=lambda x: x[1]))
len([x for x in frequencies if x > 0])
x[:, 1::2]
df[0].apply(lambda x: (0, 0) if x is np.nan else x)
plt.show()
app.run()
inlinkDict[docid] = adoc[1:] if adoc[1:] else 0
the_regex = re.compile(re.escape(the_value))
myArray = np.zeros((6, 6))
C = np.hstack((A, B[:, 1:]))
sys.exit(1)
print(date(today.year + 1, today.month, today.day))
sum(Decimal(n) * Decimal(10) ** Decimal(i) for i, n in zip(count(0, -1), a))
plt.show()
MyClass.__dict__
x1 = sorted(x, key=lambda t: t[2], reverse=True)
df = pd.DataFrame([df.sum()] * len(df))
pd.crosstab(df.saleid, df.upc)
plt.show()
print(data.reshape(-1, 2).mean(axis=1))
screen = pygame.display.set_mode((1600, 900))
max(n for n in range(1000) if str(n) == str(n)[::-1] and is_prime(n))
clf.fit(X_train, y_train)
np.random.seed(1)
rect = picture.get_rect()
main()
datetime.time()
test.f(0)
df.stack().between(2, 10, inclusive=False).unstack()
y = [j for i in x for j in i]
hex(x)[2:]
im = Image.open(image_file)
session.delete(instance)
result.append(b[index])
server.starttls()
np.concatenate(counts_array).reshape(len(counts_array), -1)
plt.show()
name = sys.argv[1:]
plt.show()
itemindex = numpy.where(array == item)
s.groupby(level=0).apply(list)
df.convert_objects(convert_numeric=True)
pobj.stdin.flush()
plt.show()
plt.show()
foo()
multiprocessing.Process.__init__(self)
[sum(x) for x in zip(*lists_of_lists)]
u = User.objects.filter(userjob__job=a).filter(userjob__job=c)
pd.concat([pd.Series(initial_value), cum_growth]).reset_index(drop=True)
np.concatenate(input_list).ravel()
a[0]
app.run()
mp.Process(target=foo, args=(x,)).start()
sys.stdout.write(line)
df.drop(df.columns[i], axis=1)
plt.show()
ax.xaxis.set_major_locator(locator)
A.ravel()[np.in1d(A, B)] = 0
my_list.sort(key=my_key)
cv2.waitKey(0)
os.path.expanduser(path)
time.sleep(1)
plt.show()
df.ix[:5, :10]
a.ravel()
ax.set_xticklabels(nonRepetitive_x)
deletepkt[TCP].chksum
[x for i, x in enumerate(numbers) if i not in indices]
A[0][0:4]
conn.rollback()
a[[0, 1], [1, 2], [2, 2]]
set.intersection(*map(set, d))
df.columns.droplevel(1)
[2, 6, 8, 7, 9, 6, 5, 4, 2]
[[]] * 10
time.sleep(0.1)
print(r.dtype)
ax.axes.get_xaxis().set_visible(False)
str.isalpha()
sys.exit(app.exec_())
{i: functools.reduce(dict.__getitem__, keys, d[i]) for i in d}
os.chown(path, uid, gid)
set(map(tuple, listB)) <= set(map(tuple, listA))
(x for x in List)
print(sum(num for num in numbers if num % 2 == 1))
dict(zip(i, i))
np.array([a, a]).shape
[[], [], []]
myplsda = PLSRegression().fit(X=Xdata, Y=dummy)
instance.__class__.__name__
json.dump(data, outfile)
time.sleep(60)
print(max(group, key=lambda k: len(list(k[1]))))
f.close()
some_func(*params)
column_names = [item[0] for item in cursor.description]
numpy.clip(x, 0, 255)
x.reshape(2, 2, 5)
lines.sort(key=itemgetter(2), reverse=True)
sorted({x for v in content.values() for x in v})
set(tuple(i) for i in l)
console = logging.StreamHandler()
set([1, 2])
self.ham = dict()
certificat = signers[0]
unravel_index(a.argmax(), a.shape)
[e for i, e in enumerate(main_list) if i in indexes]
cv2.rectangle(image, (x, y), (x + w, y + h), (255, 255, 0), 5)
self.ui.closeButton.clicked.connect(self.closeIt)
sum(int(x) for x in digit if x.isdigit())
app.run()
AtB = A.stack(0).dot(twos).unstack()
r = requests.post(url, files=files, data=data, headers=headers)
plt.plot(x, y)
root.mainloop()
[k for k, v in colour.items() if v == min_val]
plt.show()
[y for y in a if y not in b]
np.fft.fft(xfiltered)
root.mainloop()
matplotlib.pyplot.plot(raw_audio_data)
root.grid_rowconfigure(1, weight=1)
palette.append((0, 0, 0))
today + datetime.timedelta(days=1)
newNums = [i for i, x in enumerate(nums) if x == 12]
[peaks([x, y]) for x, y in zip(xscat, yscat)]
print(json.dumps(dict(table_data)))
sorted(li1, key=k)
list(range(0, 6, 2))
admin.site.register(Foo, FooAdmin)
plt.axvline(x=2.20589566)
df.column_A.apply(to_binary)
df.max()
plt.show()
yacc.yacc(debug=0, write_tables=0)
nx.draw_networkx_edges(G, pos, edgelist=black_edges, arrows=False)
sys.exit()
good_data = [data[(n), :][flag == 1].tolist() for n in range(data.shape[0])]
img[:, :, (0)] = 0
self.SetSizer(sizer)
sum(x > 0 for x in frequencies)
json.dumps(geodata)
print(A.reshape(-1, k)[np.arange(n * m), B.ravel()])
np.in1d(A, B).any()
plt.show()
y = set(x.flatten())
date.today() > self.date
pygame.init()
plt.show()
canvas.create_image(0, 0, anchor=NW, image=displayPlantImage)
age = models.IntegerField(blank=True, null=True)
root.mainloop()
[(key, len(list(it))) for key, it in itertools.groupby(list_one)]
df.isnull()
df1.apply(lambda s: df2.corrwith(s))
self.response.out.write(html)
plt.plot(list(range(10)))
[int(x) for line in data for x in line.split()]
ax.plot(x, y, color=uniqueish_color())
QtGui.QMainWindow.__init__(self, parent)
print(etree.tostring(root, pretty_print=True))
sdb.close()
np.mgrid[[slice(row[0], row[1], n * 1j) for row, n in zip(bounds, n_bins)]]
results = [r for k in keywords for r in re.findall(k, message.lower())]
getattr(this_prize, choice)
root.mainloop()
time.sleep(0.2)
int(bin(n)[:1:-1], 2)
plt.show()
requests.post(url, data=body, headers=headers)
print([hex(x) for x in numbers])
zip(string, string[1:], string[2:])
win.show_all()
sum(Decimal(i) for i in a)
np.split(x.reshape(x.shape[0], -1), 9, axis=1)
conn.close()
G = nx.balanced_tree(10, 10)
process.terminate()
f.close()
xxxxx.yyyyy.zzzzz
d = os.path.dirname(os.getcwd())
list2 == sorted(list2, key=lambda c: list1.index(c))
dict((y, x) for x, y in t)
myothermodule.py
print(repr(s))
plt.show()
print(list(range(n, (m + 1) * n, n)))
type(theobject).__name__ in dir(__builtins__)
root.mainloop()
func()
[[cell for cell in row] for row in X]
s[::-1]
text_file.close()
print([[x for x in a if len(x) == i] for i in set(len(k) for k in a)])
y = x.astype(int)
plt.show()
root.mainloop()
signal.signal(signal.SIGINT, quit_gracefully)
self.request.user
Mainscreen()
ax.xaxis.set_major_formatter(myFmt)
ax.set_yticklabels([])
sys.stdout.flush()
self.assertEqual(my_patch_method, patch_my_lib().target_method.__func__)
logging.getLogger().setLevel(logging.INFO)
current_time = (datetime.now() - timedelta(seconds=10)).time()
pgdb.paramstyle
time.sleep(5)
[L[i] for i in [2, 1, 0]]
fig.tight_layout()
plt.show()
plt.show()
self.f.close()
x[1::2, 1::2]
arr[arr > 0].min()
etree.tostring(div)
painter.restore()
zlib.decompress(data)
plt.show()
array([[0], [7], [1], [0], [4], [0], [0], [0], [0], [1], [0], [0], [0]])
out = mat[0] * (len(ixs) - len(nzidx)) + mat[ixs[nzidx]].sum(axis=0)
[str[start:start + num] for start in range(0, len(str), num)]
np.asarray(V).min(0)
base = df.index.get_loc(18)
[[0, 0], [1, 1]]
ax2.set_xlim([0, 5])
plt.show()
MY_SORTED_TUPLE = tuple(sorted(MY_TUPLE, key=lambda item: item[1]))
x = dict(zip(list(range(0, 10)), itertools.repeat(0)))
list(item[1] for item in pkgutil.iter_modules())
datetime.datetime.date(2011, 1, 1)
i, = np.where(a == value)
cv2.destroyAllWindows()
b = numpy.append(a, numpy.zeros([len(a), 1]), 1)
A[np.random.choice(A.shape[0], num_rows_2_sample)]
fig, ax = plt.subplots(figsize=(6, 1))
pil_im.show()
mlab.show()
ax.set_yticks([])
pd.concat([s1, s2], axis=1)
file.write(str(m))
sys.stdout.flush()
Activity.objects.filter(list__topic=my_topic)
app.exec_()
np.logical_or.reduce((x, y, z))
writer.writerow([item])
print(rawstr(test7))
{{settings.MY_SETTING_NAME}}
[s.strip() for s in data_string.splitlines()]
fo.write(fp.read())
sess.run(assign_op)
ts.reindex(pd.date_range(min(date_index), max(date_index)))
bbox_data = ax.transData.inverted().transform(bbox)
print(alphs[:i] + alphs[i::-1])
plt.show()
[dict(zip(d, v)) for v in product(*list(d.values()))]
self.text.pack()
a = numpy.frombuffer(buffer, float)
mylist = list(set(mylist))
print(sorted(list(a.items()), key=lambda t: get_key(t[0])))
np.in1d(a, b).reshape(a.shape).any(axis=1)
self.assertEqual(my_patch_method, patch_my_lib().target_method.__func__)
deletemy_dict[k]
plt.show()
squared = [(x ** 2) for x in lst]
threading.Thread(target=play1).start()
x = np.random.rand(5, 1)
plt.show()
os.path.sep
csv_writer.writerows(cursor)
app.run()
df2.reset_index(drop=True)
print(lxml.etree.tostring(order, pretty_print=True))
globals()
print(max(result, key=lambda a: a[1]))
all_data.append(data)
matplotlib.pylab.show()
input_file.close()
self.setWindowFlags(PyQt4.QtCore.Qt.WindowStaysOnTopHint)
deleteL[index]
print(f.read())
d = dict((v[0], v[1:]) for v in arr)
print(lxml.etree.tostring(tree))
pygame.init()
list(d.values())
[item for item in lis if item[1] not in seen and not seen.add(item[1])]
any(([1, 2] == x).all() for x in a)
[(x + b[i]) for i, x in enumerate(a)]
[(tuple[a], tuple[a + 1]) for a in range(0, len(tuple), 2)]
df.index.values
[((i // 2) ** 2 if i % 2 else i // 2) for i in range(2, 20)]
zip(*([iter(l)] * 2))
os.kill(os.getppid(), signal.SIGHUP)
len(sum4) - np.count_nonzero(sum4)
gtk.gdk.pixbuf_new_from_array(arr, gtk.gdk.COLORSPACE_RGB, 8)
print(etree.tostring(e, pretty_print=True))
print(equations((x, y)))
ham.__class__.__name__
os.kill(12765, 0)
calendar.timegm(dt.utctimetuple())
sum(int(i) for i in data)
pdb.set_trace()
[[[flatten[int(i * 2)]]] for i in range(int(len(flatten) / 2))]
plt.show()
results = [int(i) for i in results]
func(*args, **kwargs)
[m.group(1) for m in (re.search(regex, l) for l in lines) if m]
print(sum(sum(map(int, r.findall(line))) for line in data))
[x[1] for x in L]
plt.tight_layout()
df.genres.apply(pd.Series).stack().drop_duplicates().tolist()
nms.dropna(thresh=2)
admin.site.register(Person, PersonAdmin)
ax1.set_xticklabels([])
result = copy.deepcopy(source_dict)
soup = BeautifulSoup.BeautifulSoup(urllib.request.urlopen(url).read())
[([0.0] * 10) for _ in range(10)]
a[1, 1]
eliminated.append(x)
print(etree.tostring(x, pretty_print=True))
emp.delete()
[myDictionary.get(key) for key in keys]
urllib.parse.unquote(url)
max((t for t in yourlist if t[2] >= 100), key=itemgetter(1))
urllib.parse.unquote(urllib.parse.unquote(s))
app.exec_()
list(sys.modules.keys())
code.interact()
range(N, -1, -1)
ws.cell(row=i + 2, column=1).value = statN
plt.show()
isinstance(variable, States)
a = a.reshape((a.shape[0], -1, n))
procs.append(multiprocessing.Process(target=worker))
setattr(current_module, new_name, func)
print(f.read())
groupby(a, [0, 1])
list(metadata.tables.keys())
webbrowser.open_new_tab(url)
plt.show()
s.reset_index(drop=True, inplace=True)
reactor.run()
dict((item[0], (item[1], z[item[0]])) for item in l)
pd.crosstab(df.A, df.B).apply(lambda r: r / r.sum(), axis=1)
process.terminate()
soup.body.insert(len(soup.body.contents), yourelement)
json.loads(_)
x.do_something()
total = sum([int(i) for i in cost])
writer.writerows(all)
random.shuffle(lst)
n ^= (1 << upper) - 1 & ~((1 << lower) - 1)
my_series.sort()
time.sleep(1)
deletemyList[i]
session.commit()
max(x, key=sum)
[(x ** 2) for x in range(10)]
sum(a * b for a, b in zip(it, it))
df.a = df.a / 2
example2()
time.sleep(1)
[(float(c) / t) for c, t in zip(conversions, trials)]
self.assertEqual(4, 2 + 2)
user.save()
window.after(1, lambda : window.focus_force())
time.sleep(1)
[list(t) for t in set(tuple(element) for element in xx)]
print(et.tostring(tree, pretty_print=True, xml_declaration=True))
root.mainloop()
log = logging.getLogger(__name__)
sys.stdout.flush()
np.cos(-1.5)
time.time() * 1000
df.ix[pd.to_datetime(df.Date).order().index]
sorted(l, key=lambda x: (x[:-1], x[-1].isdigit()))
result = array[:, (idx)]
print(os.path.join(root, name))
sys.exit(0)
sum(map(int, str(n)))
q.T.reshape(-1, k, n).swapaxes(1, 2).reshape(-1, k)
sys.exit(0)
cols_to_use = df2.columns.difference(df.columns)
round(math.degrees(math.asin(0.5)), 2)
min(enumerate(a), key=itemgetter(1))[0]
print(list(sampleDict.values())[0].keys()[0])
initgstreamer()
time.sleep(4)
test_df.where(~(test_df < 4))
l = list(map(lambda x: 2 * x, l))
plt.show()
im.show()
app.run()
myShelvedDict.update(myDict)
{v: (v ** 2) for v in l}
im = Image.open(tempimg)
plt.show()
app.run()
Lmerge = [(i1 + i2) for i1, i2 in zip(L1, L2)]
[[try_int(x) for x in lst] for lst in list_of_lists]
subprocess.Popen(executable, creationflags=DETACHED_PROCESS, close_fds=True)
app.run()
np.array(my_list, dtype=np.float)
{{request.session.foo}}
driver.quit()
plt.show()
n.index(min(n))
t.start()
x = [(0) for i in range(10)]
file_handle.close()
a.__setitem__(slice(0, 1), [1])
[data[i:i + n] for i in range(0, len(data), n)]
server.serve_forever()
a.take(np.arange(start, end), axis=axis)
vet = [random.randint(1, 10) for _ in range(100000)]
plt.xticks(ticks, labels)
sum(map(float, s.split()))
print(ET.tostring(newdom, pretty_print=True))
array([0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0])
f.set_size_inches(11.69, 8.27)
x1, y1, a1, b1, x2, y2 = (int(eval(input())) for _ in range(6))
df._get_numeric_data()
circle1.set_visible(False)
ast.literal_eval(a)
logging.getLogger().handlers[0].setLevel(logging.DEBUG)
pyplot.draw()
df.iloc[:, (your_col_index)]
coautorshipDictionary = {int(k): int(v) for k, v in json.load(json_data)}
plt.show()
items = [some(a.split(), d, n) for a, d, n in (list(m.values()) for m in dl)]
isinstance(now, datetime.datetime)
ax.set_xticklabels([])
server.serve_forever()
np.repeat(np.arange(x), y)
df1.ix[0, 1]
plt.show()
a_lower = {k.lower(): v for k, v in list(a.items())}
your_list = map(int, your_string)
plt.show()
[list(g) for k, g in itertools.groupby(sorted(iterable))]
sys.stdout.flush()
cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
User.objects.filter(active=True)
[key for key, val in list(dct.items()) if val == True]
data = np.concatenate((im, indices), axis=-1)
mimetypes.init()
cv2.destroyAllWindows()
random.randrange(1, 10)
numpy.histogram(a, bins=(25, 100))
my_list = my_list[:8] + new_array
dictionary[key] = value
app.run()
print(list(range(0, (m + 1) * n, n))[1:])
df.columns = [strip_non_ascii(x) for x in df.columns]
a_order, a_sorted = zip(*sorted(enumerate(a), key=lambda item: item[1]))
L.grid(row=6, column=0)
all_descendants = list(elem.iter())
cv2.waitKey(0)
mc = MyClass()
sorted(A, key=operator.itemgetter(2, 0, 1))
df = pd.concat([df, s1, s2], axis=1).reset_index(drop=True)
[[int(j) for j in i] for i in a]
[0, 0, 0, 0, 0, 0, 0, 0, 0],
myRoundedList = [round(elem, 2) for elem in myList]
db.commit()
madata.mean(axis=1)
a = np.array([[1, 2], [10, 20], [100, 200]])
set(list1).intersection(list2)
np.bincount(accmap, weights=a)
isinstance(d[obj], list)
time.sleep(1)
self.canvas.pack(fill=BOTH, expand=YES)
plt.show()
plt.scatter(x, y)
verts = [(0) for x in range(1000)]
[(1) for _ in range(6)]
np.linalg.norm(x)
connection.connect()
time.sleep(100)
[(1, 2, 2), (5,), (1, 1, 1, 1, 1), (1, 1, 1, 2)]
sorted(Author.objects.all(), key=lambda a: a.full_name)
jsonify(eqtls=[e.serialize() for e in my_list_of_eqtls])
sum(len(i) for i in x if len(i) > 1)
[[k for k in x if x[k] != y[k]] for x, y in pairs if x != y]
admin.site.register(Product, ProductAdmin)
norm = [(float(i) / max(raw)) for i in raw]
df.iloc[[2, 4]]
next(s for s in list_of_string if s)
Gtk.main()
[x for x in mylist if x in pattern]
fcntl.flock(fd, fcntl.LOCK_EX)
plt.show()
[x[:] for x in [[foo] * 10] * 10]
root = tk.Tk()
arr = arr[:, :, 0::2]
df[(df.A == 0) & (df.B == 2) & (df.C == 6) & (df.D == 0)]
[set(i) for i in OrderedDict.fromkeys(frozenset(item) for item in L)]
MyModel2.mymodel1.through.objects.all()
_.sum()
df.groupby(df.index.year)
[i for i in range(4) if i <= 1 or i >= 4]
plt.show()
time.sleep(10)
df.mean(axis=1)
sorted(a, key=lambda x: aux.index(x[0]))
np.where(a == a.max())
hasattr(Dynamo, key) and callable(getattr(Dynamo, key))
[math.log10(i) for i in x]
do_something()
np.where(condition(zeta), func1(zeta), func2(zeta))
numpy.array(list(result.items()), dtype)
a.mean(axis=-1).mean(axis=-1)
pdb.set_trace()
sys.modules
plt.show()
np.argwhere(arr)
im = Image.open(BytesIO(base64.b64decode(data)))
print(json.dumps(json_output, indent=4))
print(a.pop(0))
data = np.atleast_2d(np.loadtxt(filename))
Employee.objects.active()
[(not x) for x in some_list]
print(hex(int(string, base=16)))
df.dropna(thresh=len(df) - 7)
session.query(Location, func.count(Work.id)).outerjoin(Work).group_by(Location)
indices = [i for i, x in enumerate(myList) if re.search(pattern, x)]
cursor.execute(sql, args)
plt.show()
plt.hist(x, bins=n, range=(a, b))
plt.show()
plt.show()
[(x + 1 if x >= 45 else x + 5) for x in l]
reactor.run()
ret = pycb()
list(chain(*(i if isinstance(i, tuple) else (i,) for i in l)))
print(chr(1081))
print(cursor.fetchall())
crypthash.hexdigest()
[func(x, y) for x, y in zip(xs, ys)]
pygame.mixer.music.play()
[filterList(numbers, ranges[i], ranges[i + 1]) for i in range(len(ranges) - 1)]
index, value = max(enumerate(my_list), key=operator.itemgetter(1))
f.close()
int(value or 0)
MyModel.objects.filter(name__exact=models.F(title)).exists()
{{my_num | intcomma}}
map(set, list(d.values()))
list(df.index.values)
plt.show()
plt.draw()
[k for k, v in numbers.items() if v == max(numbers.values())]
f.write(os.linesep.join(data))
dictionary[new_key] = dictionary.pop(old_key)
root.mainloop()
[i for i, (m, n) in enumerate(zip(bool_array[:-1], bool_array[1:])) if m != n]
fh.close()
sys.stdout.flush()
plt.figure()
print((key, value))
sys.modules
lst[0] in lst[1:]
the_list.sort(key=len, reverse=True)
filtered_dict = {k: v for k, v in d.items() if filter_string in k}
plt.show()
str(chr(97))
myList.append(i)
globals()[name] = 10
Model.__table__.create(session.bind)
time.sleep(1)
df.index = list(range(len(df)))
giant = max(nx.connected_component_subgraphs(G), key=len)
conn.commit()
[list(group) for k, group in groupby(l, bool) if k]
good_data = [data[(n), :][flag == 1] for n in range(data.shape[0])]
input()
np.cumsum(a)
datetime.datetime.now() + datetime.timedelta(days=1)
[l for l in a if l in b]
df1.loc[(df1 > s).any(axis=1) == True].index.tolist()
list([a for a in x if a != 2])
instance = ClassObject()
plt.show()
ar.reshape(ar.shape[0], -1)
[random.uniform(lbound, rbound) for i in range(n)]
sys.path.append(root)
list(double([1, 2]))
any(key.startswith(mystr) for key in mydict)
Py_Finalize()
{{form.as_table}}
plt.show()
webdriver.Firefox(firefox_profile=fp)
[1, 0, 1, 1]
server.serve_forever()
[int(digit) for digit in bin(n)[2:]]
D = np.vstack((np.hstack((A, B)), np.hstack((B.T, C))))
a = a + [0] * (maxLen - len(a))
list(d.keys())
signal.signal(signal.SIGCHLD, signal.SIG_IGN)
plt.show()
[True] * 5000
d.sort(key=itemgetter(1), reverse=True)
sorted(items, key=cmp_to_key(comparer))
self.setupUi(self)
br.select_form(nr=0)
np.asarray(map(func, arr))
x, y = -y, x
print((cities[0][1], cities[1][1]))
plt.show()
conset = set(map(lambda x: tuple(sorted(x)), consarray))
coords = np.c_[xx.ravel(), yy.ravel()]
a, b, c
f(*((1, 4),))
__init__.py
Achievement.objects.get(name=str(b))
np.ma.array(np.tile(arr, (cond.shape[0], 1)), mask=~cond).argmax(axis=1)
plt.imshow(lena, cmap=plt.cm.gray)
server.serve_forever()
iqr = q75 - q25
array2[:, :, :, :] = array1.copy()
gtk.main()
df.T
[item for item in my_list if item not in to_be_removed]
df.loc[(df != 0).any(axis=1)]
f.close()
requests.get(url, auth=auth)
browser.quit()
cherrypy.request.params.get(key_name)
((a == b) | numpy.isnan(a) & numpy.isnan(b)).all()
plt.show()
np.random.permutation(arr)
conPG.commit()
[item for item in my_list if 1 <= item <= 5]
print([next(c) for _ in range(10)])
ax.set_xlim([0, len(df)])
kOUT = np.zeros((N + 1, N + 1))
app.MainLoop()
plt.show()
ax.yaxis.set_visible(False)
not set(list1).isdisjoint(list2)
time.sleep(60)
shutil.copy(filename, dest_dir)
_(a + b * c)
f.close()
csv_output.writerows(zip(*rows))
my_list.sort(key=lambda x: order.index(x[0]))
np.sin(-1.5)
__init__.py
list(string.ascii_lowercase)
simulation.someloop()
conn.close()
arr[arr < 0] = 0
plt.show()
sys.stderr.write(str(e))
session.query(RssFeed).all()
server.serve_forever()
buffer1[:] = buffer2
A = np.array([C[:, (B == i)].sum(axis=1) for i in range(M)])
plt.show()
math.hypot(p2[0] - p1[0], p2[1] - p1[1])
plt.show()
dic = {x: i for i, x in enumerate(al, 1)}
m = {k: (float(d) / len(cs)) for k, d in sum(cs).items()}
f.close()
np.where(a == a.max(axis=1, keepdims=True), a, 0)
mlab.show()
self.est.fit(X, y)
os.makedirs(dirname)
self.Bind(wx.EVT_LEFT_DOWN, self._onMouseDown)
tar.close()
plt.show()
pygame.display.update()
__init__.py
tuple(l)
ax.scatter(x, y, z, depthshade=0)
plt.show()
unittest.main()
timediff.total_seconds()
[abs(a - b) for a, b in zip(l, l[1:] + l[:-1])]
self.d.setdefault(index, []).append(value)
plt.show()
df.mean().sort_values()
pygame.display.update()
[-2, -1, 0, 1, 2]
sorted(li, key=operator.itemgetter(1))
random.choice(string.ascii_lowercase)
window.mainloop()
plt.close()
[(k, list(g)) for k, g in groups]
app.exec_()
sum(my_list)
{{model.datetime | time}}
tuple(map(tuple, arr))
tuples_filtered = [tup for tup in tuples if tup[0] in filter_set]
plt.show()
list(itertools.combinations(list(range(6)), 2))
plt.show()
s.sort(key=operator.itemgetter(1, 2))
roundrobin(my_list, my_list)
root.mainloop()
sys.exit()
today = date.today()
json.dumps(result)
pyplot.close()
plt.show()
br.submit()
log.start()
list(map(len, s.split()))
print(item.strip())
plt.show()
sys.stdout = sys.stdout.detach()
[(items[:i] + items[i + 1:]) for i in range(len(items))]
np.arange(a.shape[0])[~np.in1d(a, b)].tolist()
df.apply(lambda x: x.value_counts()).T.stack()
app.run()
np.argwhere(M == 0)
out_file.close()
x = dict((i, set()) for i in range(10))
reactor.run()
s = s[0].lower() + s[1:]
picturetags.py
map(list, df.values)
jsonData = json.dumps(data)
dframe = pd.concat([dframe, to_be_appended], axis=1)
list(set(list1 + list2))
plt.step(x, y)
C = np.dot(A, B)[:, :, (0), :]
sorted(iter(adict.items()), key=itemgetter(1), reverse=True)
func(*args, **kwargs)
driver.close()
(df == 0).sum(axis=1)
s.isnull().sum()
[item for item in my_list if any(x in item for x in bad)]
output.append([items[0], int(items[1]), int(items[2])])
ax.annotate(str(j), xy=(i, j + 0.5))
word in wordList[:4]
pprint.pprint(filtered)
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
forms.ModelForm.__init__(self, *args, **kwargs)
es.refresh()
conn.rollback()
np.insert(a, 1, np.array((1, 1)), 1)
df.apply(np.prod, axis=1)
p.pattern
df.T.drop_duplicates().T
self.thread.start()
p.stdout.close()
self.figure.canvas.draw()
[key for key, group in groupby(li) if all(i == 0 for i, j in enumerate(group))]
matrix.append([0] * columns)
a[:] = []
os.path.dirname(sys.argv[0])
ax.set_ylim([-0.5, 0.5])
print(os.getcwd())
transaction.commit()
lst.append(z)
a[0:1] = [[5]]
sorted(counter.items())
[0, 0, 0, 0, 1, 0, 0, 0, 0],
df_with_x7.show()
datetime.timestamp()
a[2:10] = []
driver.quit()
map(str.upper, letters)
plt.show()
pkg_resources.get_distribution(name).activate()
sum(map(lambda x, y: bool(x - y), [1, 2], [1]))
zip(t[::2], t[1::2])
time.sleep(1)
parts = [s[indices[i]:indices[i + 1]] for i in range(len(indices) - 1)]
[4, 5, 5, 6, 6, 6]
list(chain.from_iterable((i, i ** 2) for i in range(1, 6)))
hash_dict = dict(itertools.groupby(list(dic.values()), key=hash))
{{add(a, b)}}
time.sleep(1)
a.sort(axis=1)
plt.show()
newD = {k: round(v) for k, v in list(d.items())}
f.close()
masked_a = numpy.ma.array(a, mask=numpy.repeat(a[:, (0)] == 1, a.shape[1]))
f.close()
hash(frozenset(iter(self.__dict__.items())))
len(a[0])
data2 = np.asarray(data2, dtype=np.int16)
plt.show()
cv2.bitwise_and(gray, gray, mask=mask)
fig, ax = plt.subplots()
plt.show()
np.hstack((a, b, c)).ravel()
x_ = tf.reshape(x, [-1, 1, 10, 1])
plt.show()
lowest_dirs.append(os.path.split(root)[-1])
print(soup.get_text().strip())
ax.set_xlim(-5, 5)
time.sleep(1)
data = OrderedDict(sorted(list(data.items()), key=lambda x: x[1][0]))
tf.initialize_all_variables().run()
foo = foo.upper()
time.sleep(1)
db.close()
min(max_val, max(min_val, val))
item = gtk.MenuItem()
{key_for_value(value): value for value in values}
tuple(list(x[0]) + [x[1]])
np.take(A, np.arange(ncols) % A.shape[1], axis=1)
my_list2, my_list1 = zip(*my_list)
Gtk.main()
all(key in dict_obj for key in properties_to_check_for)
Clock.schedule_once(partial(self.update, message), 0)
random.uniform(1.5, 1.9)
datetime.timedelta(seconds=10) + datetime.timedelta(hours=5)
np.equal.reduce([True, 1])
[[x, y] for x in list1 for y in list2]
[x for x in lelist if lestring.count(x)]
termios.tcsetattr(fd, termios.TCSAFLUSH, old_settings)
L = [bytes_obj[i:i + 1] for i in range(len(bytes_obj))]
a.transpose(0, 2, 1).ravel()
pickle.loads(pickle.dumps(PickalableC()))
random.shuffle(thelist)
print(a if b else 0)
self.appExeCB.addItems(list(self.items.keys()))
plt.xticks(xvalues, xlabels)
[(x * 0.1) for x in range(0, 10)]
np.argwhere(np.all(e - array([1, 2]) == 0, axis=2))
help(my_list)
strip_list = [item.strip() for item in lines]
[int_or_float(el) for el in lst]
shutil.copy2(file, dest_dir)
filtered_list = [i for i, v in zip(list_a, filter) if v]
self.Center()
moneyx = float(money.read())
print(sys.argv)
plt.show()
cv2.imwrite(name, imagem)
toolz.unique(obj_list, key=lambda x: x.my_attr)
operator.itemgetter(1)(row)
a[np.argsort(ma[:, (1)])]
my_array = numpy.array(my_list, dtype=numpy.float64)
app.run(port=port, debug=False)
x[:] = [value for value in x if len(value) == 2]
os.startfile(filename)
plt.show()
sys.argv[2]
not any(dict.values())
[(item, value) for item, value in config.items(section)]
np.hstack(a.flat)
my_list.sort(key=operator.itemgetter(1))
array = [[int(x) for x in line.split()] for line in f]
globals()
sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
self.thread.start()
app.run()
json.load(request.body)
{c: s.count(c) for c in chars}
tk.mainloop()
pdb.set_trace()
B_p.to_csv(sys.stdout, index=False)
{str(k): convert_value(v) for k, v in list(d.items())}
QtCore.Qt.ItemIsEnabled
data = [map(int, line.split()) for line in f]
urllib.parse.urlencode(f)
d = dict(zip([o.name for o in object_list], object_list))
writer.writerows(lines)
keys = [i for i, v in scores.items() if v == max_value]
[i[0] for i in x]
plt.show()
session.commit()
map(lambda frame: frame.query(expr), [df, df2])
berlin_now = datetime.now(tz)
prod(list(range(1, 5)))
keys.update(list(d.keys()))
(df != 0).dot(df.columns)
print(object.__repr__())
thread.start()
self.x += STEP
plt.show()
plt.show()
all_the_ways = [(2, 1, 2), (2, 2, 1)]
int(b, 2)
f = figure(figsize=(5, 1))
ssh.close()
fp.close()
list({x.tag: x for x in myList}.values())
p.delete()
all(i.count(1) == n for i in l)
df.reset_index()
result = np.arange(20, dtype=np.float).reshape((2, 10))
datetime.datetime.fromtimestamp(0) + datetime.timedelta(seconds=2147570047)
pd.crosstab(df.A > 0, df.B > 0)
self.get()
plt.show()
app.exec_()
ContactForm.get_reason_display()
len(x) >= 4
my_list = [json.loads(line) for line in f]
session.query(func.count(User.id)).scalar()
l.append(elt2)
all(v == 0 for v in values)
plt.show()
result.wait()
ssh.close()
zip(*([iter(L)] * 2))
img = Image.open(file)
df2.show()
(dict(zip(dicts, x)) for x in itertools.product(*list(dicts.values())))
[x for x in strings if x]
sum(v) == sum(v + [n])
df.eq(df.iloc[:, (0)], axis=0).all(1)
list(d.values())
module1.Relay()
print(arg, getattr(args, arg))
[word for word in words if not word.isdigit()]
plt.show()
data2 = sorted(data, key=operator.itemgetter(1))
plt.show()
plt.show()
ax.set_xticklabels(labels)
print(etree.tostring(root))
df = pd.DataFrame(data[1:], columns=data[0])
mod = sys.modules[__module__]
im2.putdata(list_of_pixels)
np.sqrt(s.multiply(s).sum(1))
np.tile(data, 5)
[0, 0, 1, 1, 1, 1, 1, 0, 0],
plt.show()
w.writerow(my_dict)
pdb.set_trace()
QtGui.QMainWindow.__init__(self, parent)
print(output.stdout.read())
show()
print(tuple(itertools.chain.from_iterable(product)))
l.sort(key=key)
df.groupby([df.a.apply(tuple)])
c.save()
plt.show()
d = dict(zip((o.name for o in object_list), object_list))
plt.show()
np.repeat(data, 5)
pd.concat([df[col].apply(pd.Series) for col in cols], axis=1, keys=cols)
pprint.pprint(a, width=1)
sum((Counter(d) for d in list(data.values())), Counter())
test.__kwdefaults__
print(sum(1 for x in arr if x is False))
cherrypy.engine.start()
plt.show()
db.session.add(product_obj)
df.iloc[-6:-1, (2)]
extmodule.dontoverride()
sum([[False, False, True], [True, False, True]])
np.linalg.lstsq(A.T, y)
value_at_index = list(dic.values())[index]
[0, 0, 0, 1, 1, 1, 0, 0, 0],
plt.show()
random.shuffle(temp)
buckets = [0] * 100
d2 = dict((k, f(v)) for k, v in list(d.items()))
np.putmask(elevation, elevation > 0, np.nan)
plt.draw()
sorted(vec, key=itemgetter(1), reverse=True)[:5]
gtk.main()
func(*args, **kwargs)
[name for name, age in list(mydict.items()) if age == search_age]
somelist.sort(key=predefined_list.index)
df = df.apply(myfillna)
signal.signal(signal.SIGINT, signal.SIG_DFL)
pyplot.show()
func.__code__.co_code
cursor.execute(sql)
self.canvas.draw()
deletemyList[-2:], myList[:2]
print(np.allclose(sola, solb))
zip(*l)
df.iloc[:5, :5]
set(a) & set(b) & set(c)
datetime.datetime(2010, 9, 29, 11, 15)
gevent.monkey.patch_all(httplib=True)
plt.show()
cursor.execute(query, l)
self.actionthread.start()
instance.instance_method()
dict((x, i) for i, x in enumerate(t))
pygame.init()
ranges = [(n, min(n + step, stop)) for n in range(start, stop, step)]
app.register_blueprint(someappmod)
sum(int(x) for x in s if x.isdigit())
sys.stdout.flush()
[x for y in collection for x in y]
frame.grid(row=0, column=0)
os.path.dirname(sys.argv[0])
outfile.close()
[(i, [j for j in L if j != i]) for i in L]
remote_file.close()
np.sum(my_list)
[int(i) for i in str(bin(x))[2:]]
list(itertools.chain(*list(d.values())))
moo.py
d = dict((x.key, x) for x in object_list)
((x, y) for x in a for y in b)
select(L, [2, 5])
transposed_l.sort(key=lambda x: x[1], reverse=True)
nonVarargMethod(args[0], args[1], args[2])
f(*list(range(5000)))
print(line)
(dict(zip(dicts, x)) for x in product(*iter(dicts.values())))
plt.show()
shutil.copy(full_file_name, dest)
random.seed([x])
array([1.05206154, 1.96929465, 0.94590444]), 1
plt.show()
plt.show()
server.stop()
ax.yaxis.set_visible(False)
{f(k): v for k, v in d.items()}
a = [t[1] for t in enumerate(a[1:]) if t[1][1] > a[t[0] - 1][1]]
doctest.testmod()
[[2, 4, 6], [8, 10, 12], [6, 8, 12]]
session.rollback()
[i for i, d in enumerate(lod) if 2 in d]
OrderedDict(sorted(list(d.items()), key=lambda t: t[0]))
file.write(str(formatted))
plt.show()
DataFrame(values, columns=columns)
file = service.files().insert(body=body, media_body=media_body).execute()
os.chdir(path)
ax.plot_surface(X, Y, Z, facecolors=cm.Oranges(V))
sorted(qs, key=lambda x: x.id == id)
self.assertEqual(5, self.testme)
float(math.factorial(170))
hand = dict((k, v) for k, v in hand.items() if v != 0)
pdb.set_trace()
[item for sub_list in a[1:] for item in sub_list].count(1)
kethread.start()
json.loads(s)
df1.reset_index()
B = A[[0, 2], [0, 1], [1, 2]]
writer.writerow(row)
edges.append((m.group(1), m.group(2)))
set.intersection(*map(set, p))
print(repr(line))
sys.exit()
[main_list[x] for x in indexes]
df.apply(func, axis=1)
sys.exit()
f.newmethod()
os.remove(filename)
print(top[0][1])
{k: v for k, v in list(d.items()) if k.startswith(s)}
root.mainloop()
conn.commit()
s = sum(a * b for a, b in zip(list_1, list_2))
list(range(10, 0, -1))
l1.sort()
plt.show()
nans, x = np.isnan(y), lambda z: z.nonzero()[0]
df.drop_duplicates()
db.session.commit()
main()
list(my_dataframe.columns.values)
a[:, :, ::-1, ::-1]
C = np.sum(A[:, :, :, (np.newaxis)] * B[:, (np.newaxis), :, :], axis=2)
ax1.set_xticklabels([])
b = [x[:] for x in a]
datetime.utcfromtimestamp(timestamp1)
plt.show()
self.button.clicked.connect(self.handleButton)
np.repeat(np.repeat(a, 2, axis=0), 2, axis=1)
a_b = list(set(a) - set(b))
new_list.append(f(x))
plt.show()
plt.show()
QtGui.QFrame.__init__(self)
pycurl_connect.perform()
((s.iloc[::2].values + s.iloc[1::2]) / 2).reset_index(drop=True)
list(g)
plt.show()
(vals == (0, 1)).all(axis=1)
np.unravel_index(np.argmax(corr_img), corr_img.shape)
element.click()
plt.show()
writer.writerow(map(quote, row))
time.sleep(0.25)
deletemy_dict[x]
Entry.objects.filter(weekdays=HasBit(WEEKDAYS.fri))
any(a_list)
ftp.set_pasv(False)
d = dict(zip(l, t))
__init__.py
{i[0]: i[1:] for i in list1}
foo(*t)
array = np.fromiter(iter(result.items()), dtype=dtype, count=len(result))
dict(my_list)
ea.Reload()
sorted(items, cmp=comparer)
plt.show()
pd.value_counts(d.values.ravel())
int(list(filter(str.isdigit, str1)))
[(x, y) for x, y in pairs if x != y]
q = Model.objects.filter(Q(field1=f1) | Q(field2=f2))
result[k].append(v)
process.terminate()
print(sys.argv[1])
plt.plot(dat0[:, (0)], dat0[:, (1)])
aapl.index.to_series().diff().median() / (60 * 60 * 10 ** 9)
bids = [int(bid) for bid in bids]
output = [value for value, count in list(counts.items()) if count > 1]
app.exec_()
plt.figure()
time.sleep(1)
A[0] is A[0]
singleitem = mylist.pop()
data = np.loadtxt(filename, ndmin=2)
min(timeit.repeat(lambda : dict((k, v) for d in (x, y) for k, v in list(d.items()))))
now_aware = unaware.replace(tzinfo=pytz.UTC)
writer.writerows(data)
brr[:] = brr[::-1]
ax.set_xlim(0, 10)
list2b == sorted(list2b, key=lambda c: list1.index(c))
print(sys.argv[1].lower())
A[:, (2)]
plt.show()
ctypes.addressof(bufstr)
sys.stdout.write(RESET)
q = Queue(maxsize=0)
np.concatenate([a[a == i][:2] for i in np.unique(a)])
root.mainloop()
unittest.TextTestRunner().run(suite)
nodebox.__version__
[(x + y) for x, y in l]
urllib.parse.quote(item.url)
new_dict = dict((k, v) for k, v in list(old_dict.items()) if v in allowed_values)
ax.yaxis.tick_left()
func(that, session, *args, **kwargs)
reactor.run()
sum(letterGoodness.get(c, 0) for c in yourstring.upper())
all_ingredients = Ingredient.objects.filter(recipe__book=my_book)
lock = threading.Lock()
canvas_obj = self.canvas.create_image(250, 250, image=tkimage)
self.button.grid(row=2, column=2, sticky=W)
cs.collections[0].get_paths()
np.any(a == 2, axis=0) & np.any(a == 5, axis=0)
q, bins = pd.qcut(a, 2, retbins=True)
f.pack_propagate(0)
Matrix = [[(0) for x in range(w)] for y in range(h)]
n * factorial(n - 1)
{k: v for k, v in list(metadata.items()) if v}
self.axes = self.figure.add_subplot(111)
s.groupby(s.notnull()[::-1].cumsum()[::-1]).transform(lambda g: g[-1] / g.size)
k, v = list(d.items())[0]
session.query(JT.aID).filter(not_(JT.bID.in_(ids))).all()
datetime.datetime.today().replace(hour=0, minute=0, second=0, microsecond=0)
plt.show()
arr.sum(axis=0, keepdims=True)
print((date_string, dt.date()))
[sum(l) for l in l_o_l]
np.average(list(map(float, meanNumbers.split())))
fig.canvas.draw()
result = set(d[0]).intersection(*d)
plt.show()
self.after(100, self.periodiccall)
df.fillna(0, inplace=True)
[(sum(x) / len(x)) for x in zip(*a)]
instance.__class__.__name__
plt.show()
threading.Thread.__init__(self)
A.shape
d = dict(zip(keys, values))
client.close()
np.repeat(data, data[:, (-1)], axis=0)
comport = sys.argv[2]
print(now.year, now.month, now.day, now.hour, now.minute, now.second)
plt.show()
l = [(2 * x) for x in l]
all_data = np.concatenate((my_data, new_col), 1)
outfile.write(line)
connection.commit()
line = ser.readline()
self.setLayout(self.layout)
plt.tight_layout()
ax.set_xlim(0, 1)
len(your_list) != len(set(your_list))
ax2.set_zorder(-1)
foo = [{} for _ in range(n)]
list(s)
dict((k, [v[1] for v in itr]) for k, itr in grob)
lambda x: np.dot(A, x) - b
getattr(foo, bar)(*params, **keyword_params)
Html_file.close()
(a > 1) & (a < 5)
f(*args, **kwargs)
ax1.set_xlim(-4, 4)
list(accumu([4, 6, 12]))
plt.show()
np.multiply(a, b[:, (np.newaxis)])
app.run(debug=True)
dev.leds()
df = pd.concat(list_of_dataframes)
y = [int(val) for val in x]
plt.plot(x, y)
np.where(np.any(a == 2, axis=0) & np.any(a == 5, axis=0))
my_list = list(range(1, 1001))
new_list_of_lists = map(list, map(intify, list_of_lists))
sorted(L, key=operator.itemgetter(1))
threading.Timer(2, interrupt).start()
list(itertools.chain(*lst))
np.arange(new[0]) % old[0]
app.run()
driver.quit()
print(len(path) - 1)
print(b[0])
[(2, 5), (12, 17)]
print(df.loc[i].reset_index())
B = np.reshape(A, (-1, ncols))
ip = self.request.remote_addr
writer.writerows(a)
df = df.drop_duplicates()
mylist.insert(0, mylist.pop(5))
f = lambda x: x * 2
f.close()
ax.plot(x, y)
plt.show()
answer.extend(map(str, list(range(int(start), int(end) + 1))))
make_adder(5)
pyplot.show()
list(filter(func, data))
plt.show()
df = pd.DataFrame(data)
{k: d1[k] for k in set(d1).intersection(l1)}
nx.topological_sort(G)
x = x.split()
sys.stdout.close()
idx = np.where(xvalues == xvalues[-2])
f.close()
[(x, y) for x in L for y in L]
contents = f.readlines()
c = random.choice(a)
d = datetime.today() - timedelta(days=days_to_subtract)
L.sort()
time.sleep(60)
driver.quit()
plt.show()
print(ZipFile(path).namelist())
assertTrue(text in self.driver.page_source)
np.in1d(a[:, (2)], list(b))
df.loc[mask]
{k: v for k, v in list(d1.items()) if k in l1}
help(bar)
setattr(self, key, kwargs[key])
L[i:i + 2] = reversed(L[i:i + 2])
user.save()
pylab.text(max_x, max_y, str((max_x, max_y)))
df_with_no_strings = df[~rows_with_strings]
deletefoo.fields[-1]
df = pd.read_csv(filename, error_bad_lines=False)
results.setdefault(i, []).append(benchmark(i))
pivoted.cumsum()
plt.show()
list(str(n) for n in range(10))
pool = mp.Pool(processes=1)
A[B == 1.0].sum()
print(s[1:])
br.set_handle_referer(True)
plt.show()
l = [dict(zip([1], [x])) for x in range(1, 100)]
cv2.destroyAllWindows()
sys.exit(app.exec_())
pkl_file.close()
list(gen_items())
any(map(lambda v: v in list2, list1))
print(some_object.__repr__())
np.where((A > 2) & (A < 8))
print(et.tostring(tree))
HttpResponse(json.dumps(data))
sys.exit(0)
app.debug = True
s.getvalue()
ax.set_yticks(ax.get_yticks()[:-1])
pool.terminate()
a, b, c = func()
[(1, 2)]
numpy.logical_not(array)
json.dumps(dict(foo=42))
print(sorted([Card(c[0], c[1]) for e in a for c in e]))
print(json.dumps(data, indent=4))
myf.close()
plt.scatter(x, y, color=next(colors))
root.mainloop()
len(s) - len(s.lstrip())
map(s.__setitem__, a, m)
plt.show()
f([1, 1, 2], [1, 1])
cls.dosomethingelse()
ax.set_ylim(ylim)
WSGIApplicationGroup % {GLOBAL}
yourmodule.py
info = json.loads(json.loads(get_info()))
plt.show()
unittest.main()
fig.subplots_adjust(hspace=0.5)
output.write(new_line)
a = numpy.array(b)
painter.restore()
globals()
driver.switch_to_window(window_after)
f.close()
ax2.set_rlim([0, 1])
ax.xaxis.set_major_formatter(formatter)
st = st[:-1]
total = sum(int(v) for name, v in table)
plt.show()
sys.exit(0)
np.hstack(np.meshgrid(*L)).swapaxes(0, 1).reshape(ndims, -1).T
[(sum(group) / size) for group in zip(*(data[x::size] for x in range(size)))]
print(os.lseek(fd, 0, os.SEEK_CUR))
plt.show()
list(product([a, b, c, d], [x]))
a.sum(1) / (a != 0).sum(1)
webdriver.Firefox(firefox_profile=fp)
sum(1 for x in l if x)
plt.show()
print(chr(4))
sys.stdout.flush()
pd.concat([data, ts]).sort_index().interpolate()[ts.index]
math.sqrt(x)
lambda x, y: (x + y, x - y)
json.dump(data, fp, sort_keys=True, indent=4)
ax.xaxis.set_minor_locator(mdates.MonthLocator())
print((lbl.winfo_width(), lbl.winfo_height()))
a[np.mod(np.arange(a.size), 4) != 0]
np.where(np.isclose(a, val, tol))
ax.plot(x, y)
do_stuff()
root.mainloop()
print(p.communicate(answer)[0])
session.commit()
widget.show()
plt.show()
[p for p in process_list if all(e not in p for e in exclude_list)]
bad = [x for x in mylist if x not in goodvals]
plt.show()
num_list[-9:]
map(f, my_list)
plt.tight_layout()
self.redirect(newurl)
np.vstack([np.array(u) for u in set([tuple(p) for p in points])])
d = dict((m.get(k, k), v) for k, v in list(d.items()))
[rex.split(i) for i in sequence_list]
D[(idx), :]
db.session.commit()
hash(repr(d))
unittest.main()
{d[0]: d[1:] for d in data}
np.delete(a, list(range(0, a.shape[0], 8)), axis=0)
list(reversed(sorted(a.keys())))
dict((v, v ** 2) for v in l)
age_list = [int(a[0]) for a in ages_iterator]
potion_names = [p.name for p in list_of_potions]
ax.xaxis.set_minor_locator(minor_locator)
print(today.replace(year=today.year + 1))
pd.concat([s, pd.rolling_mean(s, window=4, min_periods=1)], axis=1)
self.button[i].grid(sticky=W + E + N + S, row=row, column=col, padx=1, pady=1)
time.sleep(5)
np.tensordot(a, b, axes=1)
(df - 0.2).round()
print(etree.tostring(root))
plt.show()
im = Image.open(f)
df.mask(np.random.choice([True, False], size=df.shape, p=[0.2, 0.8]))
[x for x in l1 if tuple(x) in intersection]
a, b = 5, 8
subprocess.Popen(cmd, shell=True, stdout=f, stderr=f)
ct.reindex_axis(a_x_b, axis=1).fillna(0)
print(a[1][1])
sum(1 + count(i) for i in l if isinstance(i, list))
print(func(*args))
np.random.shuffle(dataset)
map(dict, list(dict(sorted(map(sorted, map(dict.items, s)))).items()))
plt.show()
df.fillna(df.mean())
app.run(threaded=True)
a.split()
plt.show()
sys.exit(1)
print(m.group())
max(index for index, value in data if value == max_value)
mylist.sort(key=lambda val: SORT_ORDER[val[1]])
row.append(row[0])
[name for name in names if any([(p in name) for p in pattern])]
count = np.all(listScore == np.array([2, 0]), axis=1).sum()
plt.show()
list(filter(func, data))
arr = np.arange(10).reshape(5, 2)
random.shuffle(data)
plt.show()
f.seek(0)
max(s, key=lambda x: x.arity())
writer.writerow(row + [row[0]])
f.__code__.co_freevars[0] in creator.__code__.co_cellvars
x = np.fromfile(f, dtype=np.int)
sys.stdout = old_stdout
pd.to_timedelta(df)
sys.exit(1)
np.all(a == b)
a.take(np.arange(1, 2), axis=1)
f.close()
dict((x, a.get(x, 0) + b.get(x, 0)) for x in set(a) | set(b))
base64.urlsafe_b64decode(uenc)
my_func.__doc__
WD = os.path.dirname(os.path.realpath(sys.argv[0]))
DELTAFETCH_ENABLED = True
b.widget().deleteLater()
dis.dis(withlocals)
np.isclose(a, b)
cleaned_list = [_f for _f in some_list if _f]
ymin, ymax = axes.get_ylim()
self.matches = [s for s in self.options if text in s]
pylab.show()
lst = [float(x) for x in lst]
[tuple(g[1]) for g in itertools.groupby(enumerate(l), lambda i_x: i_x[0] - i_x[1])]
wr.writerows(RESULTS)
ax.set_ylim([-10, 10])
np.hstack((test, test[:, ([0])]))
sps_data = sps_data[np.argsort(label_idx)]
cursor.execute(sql, args)
result = list([_f for _f in orig if _f])
self.root.after(1, self.openfile)
functools.partial(self, obj)
matrix[0].pop()
foo()
sorted_docs_info = collections.OrderedDict(sorted(docs_info.items()))
plt.show()
file.close()
deleteL[:]
next(g)
[(a + b) for a, b in zip(A, B)]
time.sleep(0.1)
time.sleep(interval)
time.sleep(1)
buckets = [[(0) for col in range(5)] for row in range(10)]
load_source(module_name, path_to_file)
1, 0, 0, 1, 0, 0, 1, 0, 0
set(map(frozenset, lst))
print(list(csv.reader(f)))
dx, dy = -dy, dx
bin(8)
plt.show()
g0.plot()
a[:1000] = [0] * 1000
items.sort()
s1.combine_first(s2)
A[tuple(rc1)], A[tuple(rc2)] = A[tuple(rc2)], A[tuple(rc1)]
plt.legend()
[list(g) for _, g in groupby(bool_array)]
df = df.divide(df.sum(axis=1), axis=0)
sys.stdout.flush()
[word for word in l if word.isalpha()]
np.array([np.where(np.in1d(array, matched))[0] for array in arrays])
print(len(set(map(len, my_lists))) <= 1)
sys.stdout.flush()
dict(d)
process.close()
list = [(str(a[i]) + str(b[i])) for i in range(len(a))]
longest = s1 if len(s1) > len(s2) else s2
deleted[max(d, key=d.get)]
ax.margins(0.1, 0.1)
[i for i, (l1, l2) in enumerate(zip(list1, list2)) if l1 >= 1 and l2 == 0]
db.session.commit()
plt.show()
{k: list(g) for k, g in groupby(sorted(l, key=len), len)}
x[np.isnan(x)] = 0
fig.subplots_adjust(wspace=0)
ax2.set_xticklabels([])
df.drop_duplicates()
a[[[0] * 5, [1] * 5], index]
button.click()
smile = [[255], [129], [165], [129], [165], [189], [129], [255]]
ax.set_ylim((valmin, valmax))
np.delete(a, [2, 4, 5])
im.show()
cv.CvtColor(img, gray, cv.CV_BGR2GRAY)
x[2:6] = []
driver = webdriver.Chrome(chrome_options=chromeOptions)
sys.exit(main(sys.argv))
self.assertEqual(json.loads(call_args[0]), expected)
plt.show()
a[numpy.nonzero(numpy.in1d(a, b))]
int_list = [int(i) for i in line]
the_sum = sum(a[k] * b[k] for k in keys)
pickle.dumps(data, 0)
self.Bind(wx.EVT_LEFT_DOWN, self.OnLeftDown)
exit(0)
any(c.isalpha() for c in string_2)
sum(map(int, zip(*table)[-1]))
self.legend.figure.canvas.draw()
[[] for _ in range(2)]
{k: mylist.count(k) for k in set(mylist)}
sum(val for val in l1 if isinstance(val, numbers.Number))
sum(counter_list, Counter())
plt.show()
x.astype(int)
sys.executable
sys.stdout.flush()
con.commit()
logging.Handler.__init__(self)
tom = [a, b, c]
pdb.set_trace()
ax.xaxis.set_major_locator(ScaledLocator(dx=6))
result = sum(timedeltas, datetime.timedelta())
ts[datetime(2011, 1, 8):][0]
(CENTROIDS - x.mean()) / x.std()
cv.CvtColor(cv_img, cv_img, cv.CV_RGB2BGR)
sys.stdout.flush()
print([((a + b) / 2) for a, b in zip(data[::2], data[1::2])])
session.commit()
cv2.destroyAllWindows()
[a for a, b in zip(nums, nums[1:] + [not nums[-1]]) if a != b]
django.setup()
ax.bar(list(range(len(dates))), values)
plt.show()
sys.exit(0)
ax2 = ax.twinx()
bool(list(someDict.keys()) & set(someSet))
dist = math.hypot(x2 - x1, y2 - y1)
rdd1.cartesian(rdd2)
someclassname.ask()
rbs = np.array([ish[4] for ish in realbooks])
plt.show()
a.sort(key=lambda x: x[0])
[e for e in lelist if e in lestring]
pygame.draw.circle(screen, (0, 0, 0), (100, 100), 15, 1)
np.where(np.all(np.all(win_img == pattern, axis=-1), axis=-1))
MyModel.objects.filter(pk=instance.id).update(**data)
log.setLevel(logging.DEBUG)
d = dict(zip([o.name for o in object_list], object_list))
f.read()
time.sleep(10)
subprocess.call(args, stdout=FNULL, stderr=FNULL, shell=False)
[t for t in enumerate(l)]
plt.xlim(-2 * np.pi, 2 * np.pi)
[np.ma.array(arr, mask=~c).argmax() for c in cond]
a = [1, 2]
print(cls.__name__)
lst.sort()
dict((k, v) for k, v in dictionary.items() if begin <= k <= end)
FO.close()
print(args)
[y for y in x for x in data]
y = [x for x in list(dict.keys()) if dict[x] > 0.0]
print(a[key])
qs.distinct()
b = [a.ix[i] for i in a.index if sorted1[i] >= sorted2[i]]
bids.sort(key=int, reverse=True)
[v for k, v in enumerate(mylist) if k % 2 == 0]
unp = msgpack.unpackb(f.read())
mydict[new_key] = mydict.pop(old_key)
setattr(self, key, value)
a = dict.fromkeys(list(range(n)))
plt.show()
np.in1d(data, np.hstack(test)).reshape(data.shape)
(len(word) for word in wordslist)
self.data += self.ser.read()
main()
ws.add_image(img)
df.reset_index(level=1, drop=True, inplace=True)
df.stack()[df.stack().values == 1].reset_index()
urllib.parse.quote_plus(a)
any(char.isdigit() for char in s)
ax.yaxis.set_ticks([0, 2, 4, 8])
bttn_0.grid(row=5, column=0, pady=5, columnspan=2)
driver = webdriver.Firefox(firefox_profile=profile)
d = dict((str(n), list(range(20))) for n in range(1000000))
df.T.drop_duplicates().T
pylab.show()
lines.sort(key=lambda x: int(x.split()[0]))
[0] + [(i + 1) for i in [4, 9, 12, 14, 18]] + [len(bool_array)]
datetime.datetime.combine(tdate, datetime.time())
subprocess.call(my_cmd, stdout=outfile)
x = np.random.randint(0, 20, 1000000)
pd.isnull(df).any(1).nonzero()[0]
plt.plot(x, y)
print(pix[x, y])
app.debug = True
os.path.abspath(checkIP.__file__)
pprint.pprint(obj)
client.set_option(new_url)
A[0:4][1]
re.sub(pattern, replacement, text)
master.grid_columnconfigure(0, weight=1)
root.mainloop()
plt.show()
ast.literal_eval(some_string)
a.__getitem__(slice(0, 1)).__setitem__(0, 5)
bids.append(bid)
os.path.dirname(os.path.dirname(file))
Thread(target=p.start).start()
list(foo)
os.remove(f)
((m.get(k, k), v) for k, v in list(d.items()))
ax.xaxis.set_major_formatter(tkr.FuncFormatter(formatter))
y = x.subs({a: b, b: a}, simultaneous=True)
writer.writerow(row)
OrderedDict((k, queue[key]) for k in key_order)
my_model.save()
[{y: x[y].lower()} for x in messages for y in x]
integer.setParseAction(lambda t: int(t[0]))
[list(x) for x in a_strpadded]
print(np.where(a == a.min()))
[item for item in l for repetitions in range(2)]
[x for x in matrix if x[2] == 1.0]
[min(j) for i, j in itertools.groupby(A, key=lambda x: x[:7])]
RGB_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
urllib.request.urlretrieve(stream_url, target_path)
d.update((k, v * 0.5) for k, v in list(d.items()))
plt.show()
res = os.system(sys.argv[1], sys.argv[2])
cursor.execute(query_string, varlist)
signal.signal(signal.SIGINT, signal_handler)
self.Bind(wx.EVT_PAINT, self._onPaint)
fcntl.flock(g, fcntl.LOCK_UN)
print(json.dumps(json.loads(json_string)))
[listofLines[i] for i in sortedIndex]
plt.show()
numpy.zeros((10, 4, 100))
br.set_response(resp)
[b.append(item) for item in a if item not in b]
time.mktime(d.timetuple())
(n + 1) ** 2 == n ** 2 + (2 * n + 1)
sys._getframe().__code__.co_argcount
gems.add(gem)
dict(zip(keys, values))
session.close()
sys.exit(app.exec_())
split_str.groupby([0, 1])[2].apply(fnc)
sys.stdout.flush()
myfile.write(buffer(c_uncompData_p.raw, 0, c_uncompSize))
np.asarray(t)
pd.DataFrame(series_data, columns=series_name)
plt.show()
sys.getsizeof(x)
myl[:] = [(x if x != 4 else 44) for x in myl]
df.mycolumn.map(func)
nested_lst_of_tuples = [tuple(l) for l in nested_lst]
appcfg.py
app.MainLoop()
cmap(np.linspace(0.2, 0.8, 100))
self._driver.quit()
len(a) - len(a.lstrip())
plt.show()
self.append(x)
sorted(l) == list(range(min(l), max(l) + 1))
file_obj.seek(0)
print(get_ip())
plt.show()
grouped.apply(wavg)
results = cursor.fetchone()
s.lower()
map(ord, s)
app.run(port=0, debug=True)
plt.show()
a[:, (b)]
sorted(L, key=operator.itemgetter(1))
len(mylist) - mylist[::-1].index(myvalue) - 1
len(s)
plt.show()
self.grid_columnconfigure(0, weight=1)
n = str(input())
map(sum, l) == [n] * len(l)
f.write(content)
mratings.mean(axis=1)
plt.show()
plt.show()
fu_list = [(k, fus_d.get(k), fus_s.get(k)) for k in s]
np.sum(c[:, 1:] == c[:, :-1], axis=1)
sum(n * (n - 1) // 2 for n in list(index2count.values()))
p[0], p[1]
MyClass.Property1
a = [int(x) for x in input().split()]
all_strings = [s for string_list in list(my_dict.values()) for s in string_list]
vsampled = numpy.interp(numpy.arange(t[0], t[-1]), t, v)
population = list(itertools.chain(fhd, fhet, fhr))
p.getfitness()
worst = sorted(Player(v, k) for k, v in list(d.items()))
[6, 5, 1]
json.dumps(list)
f(*args, **kwargs)
df_test.iloc[0]
pdb.set_trace()
cv2.drawContours(image, [ctr], 0, (255, 255, 255), 1)
np.random.seed(0)
df.head()
sorted(iter(d.items()), key=operator.itemgetter(1))
list(range(0, 100 + 1, 5))
sorted(a, key=lambda x: order_dict[x[0]])
plt.show()
plt.draw()
plt.show()
p.terminate()
iter_length = len(list(iterable))
root.config(menu=menu)
np.argwhere(np.isnan(x))
assert response.status_code == 200
[ks[i] for i in range(len(ks)) if i == 0 or ks[i] != ks[i - 1]]
print(df.applymap(lambda x: str(x).isdigit()).T)
re.findall(p, test_str)
sum(x ** 2) * (x[1] - x[0])
json.dump(data, jsonFile)
(x * 2 for x in [2, 2])
a = [i[0] for i in sorted(zip(a, ind), key=lambda x: x[1])]
plt.show()
json.dumps(cls=MyEncoder)
do_stuff()
print(a[:, (0)])
template.render(context)
workbook.close()
arr[np.argsort(arr[:, (1)])]
result = datetime.datetime.now() - datetime.timedelta(seconds=X)
list.__setitem__(index, value)
test_df.where(test_df >= 4)
zip([a, b, c, d], repeat(x))
session.query(RssFeed).get(1)
new_list
ivd = {v: k for k, v in list(d.items())}
plt.show()
sorted(set(mylist), key=lambda x: mylist.index(x))
random.shuffle(x)
os.system(cmd)
lasts.append(bpos)
df.agg(*[count(c).alias(c) for c in df.columns]).show()
array([0, 2, 1], dtype=int64)
m.group(1)
logging.getLoggerClass().root.handlers[0].baseFilename
np.digitize([1.5], a, right=True)[0]
math.sqrt((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2)
result = max(iter(your_dict.items()), key=operator.itemgetter(1))[0]
items = sorted(list(ipCount.items()), key=lambda item: socket.inet_aton(item[0]))
myA[(myA > val).nonzero()[0][:2]] = 0
intbids = [int(bid) for bid in bids]
isinstance(a, Test1)
server.quit()
dict((k, mydict[k]) for k in keys_to_select)
[((index % 8 + 2) * item) for index, item in enumerate(range(1, 21))]
df.convert_objects(convert_numeric=True)
(lambda a, b: a(a, b))(lambda a, b: b * a(a, b - 1) if b > 0 else 1, num)
sys.getsizeof(s)
list(itertools.chain.from_iterable(a))
df1 = df[(df.a != -1) & (df.b != -1)]
df
app.mainloop()
writer.writerows([[item] for item in new_text_list])
list(set(dict_a.values()).intersection(list(dict_b.values())))
[my_tuple[isinstance(x, str)].append(x) for x in a_list]
[[f for f in family if f != i] for i, family in enumerate(families)]
print(f())
ax.yaxis.set_major_locator(yloc)
os.path.dirname(str(__file__, encoding))
best = sorted([Player(v, k) for k, v in list(d.items())], reverse=True)
plt.show()
print(p.communicate()[0])
numpy.dstack((A, B)).transpose(0, 2, 1).reshape(A.shape[0] * 2, A.shape[1])
{{request.META.HTTP_NAME}}
all(x == mylist[0] for x in mylist)
ax.xaxis.set_major_locator(ticker.LogLocator(base=1000.0))
Counter(elem[0] for elem in list1)
time.sleep(1)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
slice = arr[0:2, 0:2]
a.reshape(-1, m / k, k).swapaxes(0, 1).reshape(-1, k)
df.append(row, ignore_index=True)
result = sum(some_list[1:])
res = [(i if i < 4 else 0) for i in range(1, 6)]
print(ET.tostring(root))
averages = [((x + y) / 2.0) for x, y in zip(my_list[:-1], my_list[1:])]
json_object = json.load(raw)
plt.show()
indices = np.where(np.in1d(x, y))[0]
get_keyring()
print([x for x in a if x in b])
new_dict.setdefault(v, []).append(k)
newList = [[ch, len(ch), ch.upper()] for ch in sent]
np.sum(boolarr)
form = UserForm(user=request.user)
file.close()
ROOT_DIR = os.path.dirname(os.path.abspath(__file__))
my_dataframe.columns.values.tolist()
[k for k in seq if counts[k] == 1]
result = [r for r in x if not any(z in r for z in y)]
sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq)
df.applymap(np.isreal).all(1)
self.Bind(wx.EVT_SIZE, self.OnSize)
print(f.readlines())
db.CommitTrans()
list(im.getdata())
plt.show()
[(x + y) for x, y in zip(string, string[i:])]
np.array(a)
cherrypy.session.regenerate()
list_of_lists = [[] for _ in columns]
print(recursive_dict_eval(my_dict))
plt.tight_layout()
list(conn.execute(query).keys())
nf.write(str(random.randint(0, 1000)))
plt.show()
set(itertools.permutations(lst))
pipe.close()
datetime.timedelta(0, 540)
t.start()
f = lambda x, y: x[0] + x[1] + (y[0] + y[1])
list_1, list_2 = zip(*((x, y) for x, y in zip(list_1, list_2) if f(x)))
os.path.abspath
df = pd.concat(dfs)
ax.set_xticks(xticks)
path = os.path.dirname(os.path.realpath(__file__))
db.session.commit()
numpy.array([sub_array for sub_array in counts_array])
mysocket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
self.Bind(wx.EVT_CHAR_HOOK, self.onKey)
t = s.reshape(-1, 2)
{{(news.description | truncatewords): 50}}
sum(map(sum, input))
plt.show()
list(range(2, 2))
list1.sort(key=int)
sys.stdout.flush()
cluster.fit(X)
print(et.tostring(tree, pretty_print=True))
print({k: v for k, v in mime_types.items()})
fig.tight_layout()
QtWidgets.QMainWindow.__init__(self, parent)
list(filter(os.path.isdir, [os.path.join(d, f) for f in os.listdir(d)]))
date_list = [(base - datetime.timedelta(days=x)) for x in range(0, numdays)]
print(np.array(list(mystr)))
conn.close()
print(json.dumps(info))
print(list(range(n, (m + 1) * n, n)))
set(mylist)
plt.colorbar()
pyplot.show()
print(is_cardano_triplet(2, 1, 5))
btn.grid(column=x, row=y, sticky=N + S + E + W)
raw_img_data = img.tostring()
a.__class__.print_x(b)
model.fit(X, y)
keep.update(yoursequenceofvalues)
df.groupby(lambda x: x, axis=1).sum()
ax.xaxis.set_major_formatter(mdates.AutoDateFormatter(locator))
image.save(image_out_path)
main()
res = pd.DataFrame(json.loads(out))
l = list(gen_items())
mymodel.objects.get(pk=a[i])
[int(t) for t in (True, True, False)]
config.write(configfile)
frame.pack()
logger.setLevel(logging.DEBUG)
df[df.columns[2]]
documents = [sub_list[0] for sub_list in documents]
sorted(x) == sorted(y)
plt.show()
logging.getLogger().addHandler(logging.StreamHandler())
time.sleep(1)
data = [([0] * cols) for i in range(rows)]
s.start()
urllib.request.urlopen(req)
frw.close()
plt.show()
pool.apply_async(test, (t,), dict(arg2=5))
profile.save()
np.logical_or(np.logical_or(x, y), z)
df = df.astype(str)
good_data = data[:, (data[0] == 1)]
(x.count(item) for item in set(x))
[_f for _f in lis if _f]
df = pd.read_sql(query.statement, query.session.bind)
w.pack()
con.commit()
subList = [theList[n:n + N] for n in range(0, len(theList), N)]
root.mainloop()
result_dict = [u.__dict__ for u in my_query.all()]
list(OrderedDict.fromkeys(my_list))
arr[np.isnan(arr).cumsum(1) > 0] = np.nan
y = numpy.r_[0, x[:-1]]
[item for item in full_list if all(x not in omit for x in item)]
df = df[df.line_race.notnull()]
self.thread.start()
time.sleep(1)
isinstance(s, str)
img[..., ::-1]
app.mainloop()
(x * sin(y)).subs([(x, y), (y, x)], simultaneous=True)
df.append(duplicates).sort_index()
set(second_list).difference(map(f, first_list))
df.drop(remove, axis=1, inplace=True)
f.apply(clean, axis=1)
max((v, i) for i, v in enumerate(a))[1]
self.a, self.b = a, b
self.grid_columnconfigure(1, weight=1)
conn.commit()
print(datetime.now())
np.sum(np.abs(x) ** 2, axis=-1) ** (1.0 / 2)
pylab.show()
logging.getLogger().addHandler(handler)
cnxn.commit()
datetime.date(2015, 8, 9).isocalendar()[1]
br.set_handle_equiv(True)
combs.extend(els)
DateR = re.compile(Date)
ax.set_ylim(0, 1)
datetime.datetime.now() - datetime.timedelta(minutes=15)
my_randoms = random.sample(range(1, 101), 10)
np.random.uniform(-10, 10, size=(1, 5, 1))
dict((key, getattr(self, key)) for key in keys)
new_list_of_dict = [new_dict(d) for d in list_of_dict]
df = pd.concat([pd.read_sql_query(q, connection) for q in queries])
np.array([x for x in set(tuple(x) for x in A) & set(tuple(x) for x in B)])
{{d.content}}
np.array([[0], [1]])
bytearray(100)
[0, 1, 0, 1, 0, 1, 0, 1, 0, 1],
conn.commit()
results = [int(match.group(1)) for match in matches]
root.mainloop()
os.uname()[1]
f.write(etree.tostring(root, pretty_print=True))
[val for i, val in enumerate(values) if i not in indices]
[some_string[i:i + 2] for i in range(0, len(some_string), 2)]
termios.tcsetattr(sys.stdin, termios.TCSADRAIN, old_settings)
ds.to_netcdf(new_file)
cython.uchar
plt.show()
zf.close()
a[:, :, ([5])].shape
tuple(x for sublist in base_lists for x in sublist)
expense.save()
urllib.parse.unquote(url)
pygame.display.flip()
plt.show()
conn.commit()
pd.DataFrame([data])
admin.site.register(User, UserProfileAdmin)
list(groupings.values())
np.argmin(df.applymap(np.isreal).all(1))
list(flatten(a))
df.max() > 0
plt.show()
print(et.tostring(tree, pretty_print=True))
max(array.flatten())
df.append([df_try] * 5, ignore_index=True)
result = [i for k, g in groupby(lst, bool) for i in ((sum(g),) if k else g)]
plt.show()
my_process.kill()
print(linalg.solve(A, x))
[s[i:i + 2] for i in range(0, len(s), 2)]
data = request.stream.read()
sum(delta_list, timedelta()) / len(delta_list)
data = (float(row[1]) for row in incsv)
[1, 2, 1, 1, 2, 1, 2, 2, 1, 2]
time.sleep(0.001)
db.session.commit()
val, idx = min((val, idx) for idx, val in enumerate(my_list))
sys.exit(app.exec_())
ax2.yaxis.set_major_locator(matplotlib.ticker.LinearLocator(nticks))
plt.show()
sys.stdout.write(line)
time.sleep(0.1)
print(new_func.__name__)
plt.show()
lambda x, i=i: x % i == 0
obj = result.json()
root.mainloop()
exit()
self.view.setModel(model)
conn.commit()
np.dot(a, b)
print(json.loads(json_string))
a[np.arange(a.shape[0])[:, (np.newaxis)], i]
pyplot.plot([point[0], point2[0]], [point[1], point2[1]])
MyApp().run()
c = b[1:]
pool = multiprocessing.Pool(2)
ax1.set_yticklabels([])
subprocess.call(cmd)
set(pd.DataFrame(df.genres.tolist()).stack().tolist())
array([0, 7, 1, 0, 4, 0, 0, 0, 0, 1, 0, 0, 0])
np.ravel_multi_index(X.T, dims)
[x for t in zip(*lists) for x in t]
df.index.get_loc(ds)
[entry for tag in tags for entry in entries if tag in entry]
outputfile.close()
pd.concat([s1, s2], axis=1)
cipher.decrypt(base64.b64decode(text))
len(set(map(len, (a, b, c)))) == 1
self.Bind(wx.EVT_ENTER_WINDOW, self._onMouseEnter)
sorted(top_n, key=lambda t: (-t[1], t[0]))
setattr(self, key, initial_data[key])
b.__class__.__class__
soup = BeautifulSoup.BeautifulSoup(html_string)
[item for item in l for _ in range(r)]
yaml.dump(dataMap, f, default_flow_style=False)
rdd = df.rdd.map(list)
d += dt.timedelta(days=1)
root.destroy()
[1, 0, 1, 0, 1, 0, 1, 0, 1, 0],
ax6.set_yticks(np.linspace(0, 1, 7))
request = urllib.request.Request(url)
print(df.to_html())
permissions = Permission.objects.filter(user=user)
[(n - 9 * int((n - 1) / 9)) for n in list1]
requests.post(url, params=params, data=json.dumps(data), headers=headers)
c = dict(a, **b)
array([[[4, 5], [12, 14], [24, 27]], [[0, 0], [6, 7], [-8, -9]]])
plt.show()
df[(df.a > 0) & df.index.isin([0, 2, 4])]
f.close()
plt.show()
sort(data, key=datekey, reverse=True)
time.sleep(1)
profile.save()
plt.show()
sys.stdout = self._stdout
session.commit()
c = [x[0] for x in A]
json.dumps(o)
sorted(unsorted_list, key=order.__getitem__)
self.lc.Bind(wx.EVT_LIST_BEGIN_DRAG, self.onDrag)
[(A[x], B[x % len(B)]) for x in range(len(A))]
value = list(d.values())[index]
plt.show()
pattern.match(string)
g.add_nodes_from(l)
np.log(df / df.shift())
br.set_cookiejar(cj)
plt.show()
files = sorted((f for f in files if firstFile <= int(f) < lastFile), key=int)
sess.run(tf.initialize_all_variables())
time.sleep(2)
l[len(l):-len(l) - 1:-1]
sum(1 for _ in iterable)
df = pd.DataFrame(list_of_series, columns=cols)
d = {k: (lambda s, k=k: s * A[k]) for k in range(n)}
ax1.set_xlim([0, 5])
signchange[0] = 0
[(p[0], sum(p[1:]) / 2.0) for p in PlayerList]
plt.show()
set(a).intersection(b)
summary_dict = {c: [] for c in new.columns[1:]}
df.merge(s.to_frame(), left_index=True, right_index=True)
[[i for i in sublist if counts[i] == 1] for sublist in mylist]
np.matmul(a, b)
buckets = [[0] * 100] * 100
ax.set_ylim(-5, 5)
next((a for a in s if s.count(a) == 1))
bigList.sort(key=operator.itemgetter(*args))
print(sum(1 for elem in list1 if elem[0] == entry[0]))
map(tuple, map(flatten, zip(a, b, c)))
print(etree.tostring(root, pretty_print=True))
finder.score_ngrams(bigram_measures.pmi)
print(np.nanmean(arr, axis=0))
ivd = dict((v, k) for k, v in list(d.items()))
a[np.arange(np.shape(a)[0])[:, (np.newaxis)], np.argsort(a)]
keys = set(l1).intersection(d1)
df = pd.concat([df, dummy_df], axis=1)
doc.toxml()
isinstance(fn, collections.Callable)
df.reindex(prev_dates.union(df.index))
foo.save()
len(words)
MainWindow.show()
map(centroids.__delitem__, sorted(index, reverse=True))
a = [0, 1]
testDf.iloc[:, 1:].stack().groupby(level=0).nunique()
np.where(np.all(a == b, axis=1))
s = set(lst)
plt.show()
print([item for item, count in list(collections.Counter(a).items()) if count > 1])
outfile.writelines(lines)
iqr = np.subtract(*np.percentile(x, [75, 25]))
product([[1, 2], [4, 5]])
print({k: round(v) for k, v in x.items()})
array([[1, 0, 1], [2, 0, 1]])
Foo.allocate_ids(max=26740080011050)
sys.exit(test())
x_pieces = [x[i:i + step] for i in range(0, len(x), step)]
hex(random.randint(0, 16777215))[2:].upper()
numpy.vstack((a, b, c)).T
server.serve_forever()
B = list(A[0])
b = [x for x in a if x not in itemsToRemove]
plt.show()
df = pd.DataFrame(df_dict)
intersect = {key: [o, spec2[key]] for key, o in list(spec1.items()) if key in spec2}
root.mainloop()
fruits = {k: [] for k in names}
args = parser.parse_args()
plt.show()
d.setdefault(x, []).append(y)
json.JSONEncoder.default(self, obj)
(x - y for x, y in it.izip(a[1:], a))
c = a[(np.searchsorted(a[:, (0)], b)), :]
np.concatenate([[88], a, [77]])
plt.show()
plt.show()
pylab.show()
time.sleep(0.01)
plt.show()
r.setdefault(key, []).append(lst2dct(val))
admin.site.register(Email, EmailAdmin)
len(arr)
size = fields.IntegerRangeField(min_value=1, max_value=50)
print(element.tag, element.text, element.tail)
app.exec_()
reactor.run()
help(assign2)
d = dict([(k, v) for k, v in zip(l[::2], l[1::2])])
np.array([[d[str(i)], d[str(j)]] for i, j in A])
self.response.out.write(simplejson.dumps(data))
tst.save()
list(range(0, 10, 2))
df[(df[[0, 1]] > 0).all(1)]
cnxn.commit()
df.where(~outliers_low, down_quantiles, axis=1)
datetime.datetime(*d.timetuple()[:6])
GC.remove_edge(clique[0], clique[1])
ax1.set_ylim(0, 1)
gca().xaxis.set_major_formatter(xfmt)
myMethod(myVariable, *myTuple)
print(np.unravel_index(result.argmax(), result.shape))
ipdb.set_trace()
plt.show()
cursor = conn.cursor(MySQLdb.cursors.DictCursor)
np.fill_diagonal(out, np.diag(A))
big = np.random.randint(-10, 10, size=10000000)
b = [list(x) for x in b_set]
ax.plot(x, y)
json.dumps(o)
x ** 2 + 1
ax.yaxis.set_major_formatter(mpl.ticker.FuncFormatter(mjrFormatter))
msg.send()
print(somefake.readlines())
C = [[(0) for row in range(len(A))] for col in range(len(B[0]))]
db.Close()
ax.get_xaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())
pd.DataFrame(data, tid1, ucat)
file = forms.FileField(required=False)
logging.getLogger(__name__).setLevel(logging.WARNING)
my_dict = {k: [] for k in keys}
input_seq[ix1], input_seq[ix2] = input_seq[ix2], input_seq[ix1]
math.sqrt((p0[0] - p1[0]) ** 2 + (p0[1] - p1[1]) ** 2)
app.mainloop()
ax.scatter(x, y)
d = {c: i for i, c in enumerate(ascii_lowercase, 1)}
conn.commit()
self.assertTrue(issubclass(QuizForm, forms.Form))
cursor.execute(sql, args)
conn.execute(sql, list)
dict_compare(dict_a, dict_b)
np.arange(new[1]) % old[1]
root.mainloop()
aapl.index.to_series().diff().mean() / (60 * 60 * 10 ** 9)
shapesMatch([(0, 0), (1, 0), (1, 1), (2, 1), (2, 2), (0, 2)], l_shape)
(my_array[:, (np.newaxis)] == my_array).all(axis=2).sum(axis=1)
[d[k] for k in lst]
[i for i, x in enumerate(t) if x]
traceback.print_stack()
time.sleep(1)
Entry.objects.bulk_create([Entry(id=x) for x in list])
jsonify(json_list=qryresult.all())
dict(a)
print(soup.prettify())
{{myexample}}
b = dict(zip(i, i))
self.transport.write(self.message.encode())
np.sort(m)[:, -N:]
array([[4, 5], [1, 4]])
foo.__class__.__class__
set(listA) & set(listB)
dict(list(x.items()) | list(y.items()))
[e for l in lst for e in l]
[y for y in listOfLists if y[x].isdigit()]
result.append(os.path.join(root, name))
setattr(self, pointer, group)
plt.ylim(-6, 6)
a[[0, 1], [1, 2], 2]
raise NotImplementedError()
sum(1 for _ in takewhile(lambda x: x == a[0], a))
i = int(math.floor(x) - 1)
[(x, y) for x, y, label in data_one]
jdf = df._jdf
pprint(dict(grouped_by_soundex))
portalocker.lock(file, flags)
print(m.group(1))
hand = {k: v for k, v in hand.items() if v != 0}
ftp.quit()
red, green, blue, alpha = img.split()
nx.draw_networkx(G)
pl.show()
f = open(os.path.join(sub_dir, file))
[[copy.deepcopy(foo) for x in range(10)] for y in range(10)]
dict((x1, (x0, x2)) for x0, x1, x2 in zip(x[:-2], x[1:-1], x[2:]))
df.div(df.sum(1), axis=0)
image = cv2.cvtColor(image, cv2.cv.CV_BGR2RGB)
dill.pickles(f)
m = sqrt(a ** 2 + b ** 2)
plt.show()
sys.stdout.close()
df.reindex(df.index.drop(1))
x[index] if len(x) > index else default
self.show()
cursor.execute(query_insert, data * 2)
canvas.config(scrollregion=canvas.bbox(ALL))
list(itertools.chain(*list(foo.values())))
plt.show()
logging.handlers.pop()
result = [numbers[i] for i in indices]
Hsub = H[1:H.shape[0] - 1, 1:H.shape[1] - 1]
logging.config.stopListening()
ax.plot(list(range(10)), list(range(10)))
[0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]
app.run(debug=True)
random.seed(SEED)
plt.show()
print(proc.stdout.readline())
pd.DataFrame(L)
plt.show()
cursor.execute(sql, (val1, val2))
random.choice(string.ascii_letters)
User.query.filter_by(**kwargs)
array([0, 1, 0, 0])
df.drop(df.columns[[1, 69]], axis=1, inplace=True)
a = np.delete(a, zero_row, 0)
file_writer.writerow([x[i] for x in lol])
g.filter(lambda x: len(x) > 1)
df.T.groupby(level=0).first().T
sorted_df = df.sort_values(df.last_valid_index(), axis=1)
[[0, 1, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 0]]
tornado.ioloop.IOLoop.instance().start()
[sympy.diff(sum(m * m.T), i) for i in m]
programs = tapjoy - game1, tapjoy - game2
arr[[2, 1]]
t.start()
np.in1d(fake, [0, 2, 6, 8]).reshape(fake.shape)
thread.start_new_thread(interrupt_user, ())
requests.post(url, data=data)
sys.stdout.flush()
5.55 % 1
json_string = json.dumps(row)
s.flush()
sys.stdout.flush()
plt.show()
len(os.listdir(directory))
print(socket.gethostbyname_ex(socket.gethostname())[2])
cgi.parse_qs(qs)
all(0 < n < 50 for n in thetuple)
list_of_nums[:] = [x for x in list_of_nums if x != 2]
lambda m: replacement_dict.get(m.group(), m.group())
sum([i for i in l1 if isinstance(i, int)])
[[k, len(list(g))] for k, g in groupby(strs)]
ax1.set_yticks([int(j) for j in range(0, 4)])
plt.subplot(122), plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
im = cv2.imread(path, -1)
zip(xnew[1:], ynew[1:])
f = lambda x, a=a: x ** a
pygame.mixer.music.play()
django.setup()
datetime.date.today()
zip(*filterer(list1, list2))
max(l1, l2, key=len)
numpy.sqrt(numpy.sum((A - B) ** 2))
ax.plot(x, y, z)
__init__.py
np.argsort(K)[-5:]
getattr(module_a, mod)()
c[a & b]
lol = lambda lst, sz: [lst[i:i + sz] for i in range(0, len(lst), sz)]
output_file.close()
GPIO.output(4, False)
[2, 5, 7, 8, 9, 12]
min(alist, key=itemgetter(1))[1], max(alist, key=itemgetter(1))[1]
main()
setattr(self, k, v)
a[~np.isnan(a).any(axis=1)]
scipy.signal.ltisys.lti
dfUnstacked2.columns
meta.Session.commit()
self.layout.addWidget(self.button)
np.tensordot(A, B, axes=[[0, 1], [0, 2]])
root.mainloop()
result = set(d[0]).intersection(*d[:1])
self.root.mainloop()
gevent.wait()
sess.run(y, feed_dict={i: d for i, d in zip(inputs, data)})
c = list(chain(*zip(a, b)))
response = requests.post(url, data=json.dumps(payload), headers=headers)
math.isnan(x)
logger.setLevel(logging.INFO)
255, 255, 255
{k: v for k, v in d.items() if k.startswith(s)}
plt.show()
(dict(x=x[ii], y=y[ii], z=z[ii]) for ii in range(10))
time.sleep(1000)
new_module = __import__(modulename)
driver.quit()
print(my_list)
result = json.dumps(response[1])
s = map(sum, zip(*([s] * 2)))
max_index = max(max_index, index)
print(repr(input()))
timeit(lambda : list(test(12, 5)), number=1)
root.mainloop()
striped = [l.split() for l in [c.strip() for c in file_desc.readlines()] if l]
test.dosomethingelse()
time.sleep(1)
plt.show()
np.exp(2j * np.pi * np.random.rand(n, 1)).view(dtype=np.float64)
setattr(self, k, kwargs[k])
d.setdefault(k, []).append(v)
b2[np.in1d(b1, a)]
[x for t in a for x in t]
root.mainloop()
f.close()
temp = lambda x, i=i: x + i
s * a == s * a + s * 0
plt.plot(*zip(*a))
dict.fromkeys(my_list)
plt.show()
ax.axes.get_yaxis().set_visible(False)
object = object.__iadd__(value)
myList[:] = [x for x in myList if x not in totoss]
time.sleep(60)
dict(lst)
a = a[0:100]
parser.parse_args()
workbook.close()
__init__.py
numpy.random.seed(42)
canvas.pack(side=LEFT, expand=True, fill=BOTH)
self.write(jsonp)
conn.commit()
self.grid_rowconfigure(0, weight=1)
Foobar.objects.filter(Q(blah=1) ^ Q(bar=2))
deletemylist[-2:]
plt.show()
time.sleep(5)
s = [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]
plt.show()
worker.start()
plt.figure()
child.kill()
[item for item in yourlist if item % 2]
[int(i in locs) for i in range(size)]
time.sleep(2)
s.groupby(s.index.weekday).transform(lambda x: pd.rolling_mean(x, window=n))
plt.show()
[x for x in matrix if x[2] == 0.0]
ax.xaxis.set_major_formatter(ScaledFormatter(dx=6))
s.quit()
doc = lxml.html.fromstring(res.content)
time.time()
set(a[i] for i in range(1, len(a)) if a[i] == a[i - 1])
A[np.isnan(A)] = 0.0
new_list = [dict((transform[k], v) for k, v in list(d.items())) for d in old_list]
sys.path.append(root)
plt.show()
max(t, key=lambda e: (-e[1], e[2]))
regex.findall(s)
result_list = list(map(list, deduped))
f.seek(0)
display.sendstop()
input.close()
counter_list = [item for item in counter_list if item]
driver.implicitly_wait(secs)
data.groupby([lambda x: x.year, lambda x: x.time])
plt.show()
plt.xticks(list(range(10)), labels)
res = service.cse().list(q=search_term, cx=my_cse_id).execute()
os.rmdir(temp_dir)
plt.show()
subprocess.call(cmd, shell=True)
cur.execute(query, (sortname, limit1, limit2))
print([d.isoformat() for d in get_week(datetime.datetime.now().date())])
root.mainloop()
bisect.bisect_left(mylist, compareValue)
spam_list = [spam_list[i] for i in spam_order]
ax.set_xlim([0, N])
fh4.close()
plot(x, y)
np.vstack({tuple(row) for row in a})
ser.read(5)
random.sample(list(range(1, 10)), 10 - 1)
l = L[1::2]
plt.show()
b = a[:, :, ::-1]
parser.parse_args()
[(a % 1) for a in l]
se2.commit()
[j for i in x for j in i]
print(np.allclose(cols, cols2))
data.sort(key=lambda entry: entry[1], reverse=True)
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
db.session.commit()
time.sleep(1)
l[::-1]
rolling_corr.iloc[-200:].mean(axis=0)
list(itertools.permutations(set([1, 1, 2, 2])))
[t for t in mylist if t[0] == 10]
df.isnull().values.ravel().sum()
unittest.main()
a[a < 0] += 1
new_list = [foo for foo in foos if foo.location == 2]
a.reshape(-1, m / k, k).transpose(1, 0, 2).reshape(-1, k)
socket.setdefaulttimeout(15)
print(list(chain.from_iterable(A)))
[hex(ord(c)) for c in chars]
HttpResponse(response.content)
os.startfile(file)
Gtk.main_iteration()
A = [operation(A[i], A[i + 1]) for i in range(len(A) - 1)]
print(etree.tostring(builder, pretty_print=True))
root.mainloop()
4 * scipy.integrate.nquad(f, [[0, 1], [0, 1]])[0] / 12.565472446489999
sys.stdout.flush()
array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]])
plt.show()
a = set()
print(etree.tostring(new_root, pretty_print=True))
a = list(set(a))
A.sort(key=lambda x: B.count(x))
my_dict = {x[0]: {k: v for k, v in zip(my_headers, x[1:])} for x in my_list}
end_date = date_1 + datetime.timedelta(days=10)
random.sample(the_list, 50)
a, b, c, d = [x[i:i + step] for i in range(0, len(x), step)]
ax.hist(mydata, weights=np.zeros_like(data) + 1.0 / data.size)
x, y = y, x
wx.Frame.__init__(self, parent, ID, title, pos, size, style)
grayimg = cv2.cvtColor(image, cv2.cv.CV_BGR2GRAY)
df_new.head()
min(li, key=lambda x: x.number)
datetime.fromtimestamp(timestamp2)
df.ix[idx]
cursor.executemany(sql, rows)
a.append(s)
df.replace(d)
unique_a.view(a.dtype).reshape((unique_a.shape[0], a.shape[1]))
f.close()
self.Bind(wx.EVT_LEAVE_WINDOW, self._onMouseLeave)
plt.show()
set(range(1, 101)) - s
list1.sort(key=natural_sort_key)
sns.kdeplot(x, shade=True)
set(list2).issubset(list1)
local_file.close()
json_string = json.dumps(foo.__dict__)
self.queue.pop()
list = map(str.strip, list)
session.flush()
[list(t) for t in zip(*l)]
res_list = [x for x, _ in rows]
x[5:]
plt.show()
shutil.rmtree(name)
np.flipud(your_array)
p.wait()
df.apply(lambda row: row[1] if row[0] > 0 else row[2], 1)
vbar.pack(side=RIGHT, fill=Y)
set(a[i] for i in range(1, len(a)) if a[i] == a[i - 1])
np.multiply(np.arange(1, 5), np.cumprod([1, 2, 2, 2])[np.newaxis].T)
timestamps.sort()
QtCore.QObject.__init__(self)
list(k for k, g in itertools.groupby(x for x in numbers if x != 0))
fvtool(Hd1, Hd2)
[int(i) for i in x[num - n:num]]
res = cv2.matchTemplate(img, template, cv2.TM_CCORR_NORMED)
y = x.reshape(x.shape[0] / 2, 2, x.shape[1], 2)
a = datetime.datetime.today().year
con = MySQLdb.connect()
newList = [(x / myInt) for x in myList]
self.setWindowState(QtCore.Qt.WindowMinimized)
cv2.destroyAllWindows()
datetime.datetime(1890, 1, 1, 0, 0)
pd.read_csv(Reader(gen()))
plt.show()
session.query(MyTable.col1).count()
array([[18, 6], [19, 5], [17, 9], [10, 5]]),
df.iloc[:, ([1])]
val0 = f(list[0])
plt.show()
signal.signal(signal.SIGQUIT, handler)
self.top_frame.grid_columnconfigure(1, weight=1)
sorted((i, j) for i, j in zip(x, y))
args = parser.parse_args()
plt.show()
lambda x, y: x + y
open(location, mode).write(content)
db.commit()
time.mktime(dt.timetuple()) + dt.microsecond / 1000000.0
((0, 1),) * 5
[False] * 10
clusters = [X[labels == i] for i in range(n_clusters_)]
x2[:, (0)] = np.roll(x2[:, (0)], -2)
plt.show()
self.root.mainloop()
ax1.plot(x[i:i + 2], y[i:i + 2])
f(*args, **kw)
datetime.datetime.today().weekday()
os.path.dirname(file)
stream.close()
added.sort(key=lambda x: os.stat(os.path.join(path_to_watch, x)).st_mtime)
f.close()
my_model.save()
c.ravel()
ctx.Process(target=foo, args=(x,)).start()
obj.refresh_from_db()
[i for i in my_list if my_counter[i] > 1]
infile.close()
client.images.data(img)
np.random.seed(1977)
df.iloc[df.index.get_indexer([2, 7])]
df.stack()
numpy.array(list(c))
self.frame.pack()
G.remove_nodes_from(to_remove)
reactor.run()
print(line)
df.apply(lambda f: to_number(f[0]), axis=1).sum()
plt.xlim(0, 10000)
matplotlib.pyplot.plot_date(dates, values)
wx.Frame.__init__(self, *args, **kwargs)
arr = arr[:, :, ::2]
df = pd.DataFrame.from_dict(map(dict, df_list))
func(*args, **kwargs)
self.checkqueue()
print(rdd.collect())
np.all(a == 0)
process_file(sys.argv[1])
dirname2 = os.path.split(dir)[1]
ax1.yaxis.set_visible(False)
time.time()
plt.show()
NOT_DONE_YET
inspect.signature(datetime.datetime.now)
print(np.allclose(rows, rows2))
time.sleep(0.5)
f()
{t[0]: t[1:] for t in s}
con.commit()
df1.ix[:, (1)]
admin.site.register(Session, SessionAdmin)
new_lst.sort()
print([v for v in simplex.vertices])
os.kill(cpid, signal.SIGKILL)
tiffiles.sort(key=getint)
arr.argsort()[:n]
random.shuffle(lst)
my_array.pop()
fliplr(m.swapaxes(0, 1))
dict(map(lambda l: l.split(), s.splitlines()))
df.index = pd.to_datetime(df.index)
[sum(e) for e in zip(*data)]
time.sleep(10)
plt.show()
doc = lxml.html.parse(url)
pd.DataFrame(list(d.items()))
C = [[(0) for col in range(len(B[0]))] for row in range(len(A))]
pd.value_counts(list(concat(df.categories.values.tolist())))
fh.close()
random.shuffle(x)
result = sorted(mylist, key=lambda x: d[x[0]])
list_of_hets.append(hets)
np.unravel_index([0, 18, 26], a.shape)
urllib.request.urlopen(url).geturl()
np.where((a >= 6) & (a <= 10))
print(a.dtype)
df[df.isnull().any(axis=1)]
index = numpy.clip(index, 0, len(my_list) - 1)
[i for i in range(10) if i == 9]
input()
plt.subplot(212, sharex=ax1, sharey=ax1)
list(s)[0]
glOrtho(self.left, self.right, self.bottom, self.top, 1, -1)
time += datetime.timedelta(hours=1)
main()
[random.random() for _ in range(100000)]
driver = webdriver.Chrome(chrome_options=chrome_options)
getpass.getuser()
f.close()
stokes_list = np.vstack((stokes_list, stokes_line))
app.mainloop()
ax.plot(x, y)
plt.show()
df.stack().apply(pd.Series).unstack().swaplevel(0, 1, 1).sort_index(1)
offset = dt.astimezone(cet).utcoffset()
plt.show()
out_file.write(replace_all(text, spelling_dict))
ax1.set_ylim([0, 5])
f.close()
top5 = itertools.islice(my_list, 5)
list_2 = [i for i in list_1 if isinstance(i, (int, float))]
plt.show()
reverse_dict = {value: keypath for keypath, value in keypaths(example_dict)}
G = nx.DiGraph()
out = np.linalg.norm(row.data)
contains_non_string = s[s.apply(type) != str].any()
np.array(_)
self.listbox.selection_set(first=0)
np.fromiter((row[index] for row, index in zip(X, Y)), dtype=int)
sorted(l, key=lambda x: (x[:-1], x[-1].isdigit()))
help(func)
np.subtract.outer(a, b)
min(a, key=lambda t: t[1])
self.check_object_permissions(self.request, obj)
plt.show()
list(tuple(mydata.transpose()))
tuples = list(genreDictionary.items())
a[..., (numpy.newaxis)] * b[(numpy.newaxis), ...]
self.lock.acquire()
self.value = value
theproc.communicate()
[item for item in theList if item in theDict]
user.save()
df1.count()
setattr(self, k, v)
print(sorted(set(my_list)))
s = pd.Series([1, 5, 20, -1])
self.Bind(wx.EVT_MOTION, self.OnMouseMove)
user.save()
do_it_lots()
np.where((vals[:, (0)] == 0) & (vals[:, (1)] == 1))[0]
numpy.array([[elem for elem in x_row] for x_row in X])
lst.extend(data)
request.remote_addr
round(1.5145, 2)
print([m.start(1) for m in matches])
time.sleep(0.5)
ax.set_xlim([datetime.date(2014, 1, 26), datetime.date(2014, 2, 1)])
some_class(*os.path.split(somefile))
set(word_list).intersection(a_string.split())
plt.pause(1)
self.baseDict[key]
getattr(CallMe, variable)()
cl.getlevel(2)
ordered = OrderedDict((k, mydict[k]) for k in myorder)
np.MAXDIMS
time.sleep(0.2)
zip(s, s[1:], s[2:])
__init__.py
plt.show()
decimal.Decimal(1.1)
uni = [k for k, v in a.items() if countMap[v] == 1]
lowercase = [c for c in s if c.islower()]
self.__dict__.update(*args, **kwargs)
x = x[:50]
z = dict(list(x.items()) + list(y.items()))
ax.margins(0.05)
[a[i:i + 2] for i in range(0, len(a), 2)]
sys.exit(0)
logging.basicConfig()
plt.show()
[_f for _f in lst if _f]
sys.exit(1)
[y for x in list(d.values()) for y in x]
sorted([(0, 0, 0, int(random.getrandbits(4))) for x in range(10)])
min(a, b) / max(a, b)
self.client.post(url, data=post_data)
d = {t[0]: t[1:] for t in arr}
plt.show()
admin.autodiscover()
x, y, z = (v + 2 for v in l)
min(list(d.items()), key=lambda x: x[1])
print(pix[x, y])
curses.endwin()
words_list.extend(contents[i].split())
plt.show()
os.path.normpath(os.path.join(os.getcwd(), os.path.dirname(__file__)))
f.close()
d = pd.concat([d, temp])
quantiles = df.quantile([0.01, 0.25, 0.5, 0.75, 0.99])
rows = session.query(func.count(Congress.id)).scalar()
self.label.pack()
file = models.FileField(blank=True, null=True)
text_area.pack()
plt.plot(list(range(5)))
[tuple(zip(*x)) for x in lst]
root.mainloop()
plt.show()
print(Foo.bar)
[a.index(item) for item in b]
writer.writerow(list(d.keys()))
sock.bind((MCAST_GRP, MCAST_PORT))
shutil.copy(file, dest_dir)
map(lambda x: x ** 2, list)
update_fitness()
new_list = [f(x) for x in it.takewhile(lambda x: condition(x), l)]
tk.Tk.__init__(self, *args, **kwargs)
plt.show()
[i[0] for i in list(zip(listOfTuples, bools)) if i[1] == True]
os.path.dirname(__file__)
ax.plot_surface(X, Y, Z)
cv2.waitKey(0)
arbiter.run()
__init__.py
screen.fill((255, 255, 255))
data.append([int(v) for v in line.split()])
pygame.display.flip()
list(map(fs.format, sum(map(str.split, l), [])))
plt.xticks([])
plt.show()
sys.exit(1)
[b for a in ((x, -x) for x in range(1, 10 + 1)) for b in a]
print(soup.get_text())
list(r.keys())
plt.show()
df.reset_index(inplace=True)
[item for item in my_list if any(x in item for x in bad)]
[[10, 6, 45, 18, 49], [5, 6, 45, 6, 14]]
time.sleep(1)
skipsdist = BOOL
csv_writer.writerow([x for x in line])
mars.circle(228, 1)
print([len(x) for x in partition(list(range(105)), 10)])
[4, 4, 2, 1, 2]
plt.ylim([-4, 2])
foo.__getitem__(slice(a, b, c))
output_list = list(set(itertools.chain(first_list, second_list)))
plt.show()
plt.show()
plt.contour(xi, yi, zi, 20, linewidths=1)
math.modf(x)
pfile.seek(0)
USE_TZ = False
time.sleep(5)
f = np.vectorize(f, otypes=[np.float])
func(*args, **kwargs)
new_list = sorted_set(my_list)
base64.b64decode(coded_string)
a[(a != 5).all(1)]
plt.figure()
[(i, sublist.index(item)) for i, sublist in enumerate(list)]
[v for k, v in d.items() if k not in (2, 5)]
filtered_list = list([x for x in input_list if x % 2 == 0])
server.serve_forever()
data = np.array([float(f) for f in file(filename).read().split()])
main()
result = [r for r in x if all(z not in r for z in y)]
any(kidname == row[ct] for row in csv.reader(file))
plt.show()
newd = dict.fromkeys(origdict)
--honour - stdin
[[int(i) for i in line.split()] for line in data]
logger = logging.getLogger(__name__)
sum(1 for _ in itertools.takewhile(str.isspace, a))
con.commit()
w.show_all()
JsonResponse(list(data), safe=False)
[(k, v)] = list(d.items())
driver.refresh()
{}
time.sleep(1)
result.stack()
app.run()
plt.show()
type(d.copy())
grouped.boxplot()
tuple(sum(z) for z in zip(a, b))
ax.add_patch(circ)
[[True, False], [False, True]]
plt.imshow(rotate_lena, cmap=plt.cm.gray)
aa = dict([(k, d[k]) for k in f])
sum(strat(line) for line in f)
[[10, 6, 45, 18, 49], [5, 6, 45, 6, 14]]
print(pd.concat([d1, df], axis=1))
cv2.waitKey(0)
nx.draw(G, pos)
float_to_hex(17.5)
number = list(filter(str.isdigit, filename))
[x[0] for x in listD[1]]
print(sorted(list(d.items()), key=lambda x: x[1], reverse=True)[0])
result = [a for a in A if a not in subset_of_A]
main()
a, b = map(int, sys.stdin.readline().split())
content = text.selection_get()
[(x * y) for x, y in zip(lis[0], cyc)]
app.run()
ext_id = db.Column(db.Integer, primary_key=True, autoincrement=False)
Toy.objects.filter(owner__parent=parent)
np.in1d(arr1, arr2)
plt.figure()
sock.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)
json.dump(feeds, feedsjson)
data[:, (set_col)] = val
time.sleep(1)
Mailbox.quit()
background = pygame.transform.scale(background, (1200, 800))
all(word[i + 1] >= word[i] for i in range(len(word) - 1))
plt.show()
list(sum(list(dict.items()), ()))
parser = argparse.ArgumentParser()
sorted(l, key=alphanum_key)
list.focus_set()
df.values[:] = df.sum()
[m.group(0) for m in matches]
os.makedirs(dir_path)
newstr = oldstr[:4] + oldst[5:]
logging.basicConfig(level=your_level)
locale.setlocale(locale.LC_ALL, saved)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
newData = np.array([d[:4] for d in data])
A.a.__get__(a, A)
vf(numpy.outer(phases, numpy.arange(1, 4)))
print(date.isoformat())
plt.show()
df.a.value_counts()
fib = lambda n: reduce(lambda x, n: [x[1], x[0] + x[1]], list(range(n)), [0, 1])[0]
mydict = default.copy()
Y[:, (1)]
df = df.loc[:, (~df.columns.duplicated())]
np.where(idx)
plt.show()
array([0, 0, 0, 0])
logger.setLevel(logging.DEBUG)
session.commit()
[[w for w in L if len(w) == num] for num in set(len(i) for i in L)]
links = [rel.get_accessor_name() for rel in a._meta.get_all_related_objects()]
hex(291)
setattr(c, key, value)
result_list = [elements[i] for i in indices]
dictget = lambda d, *k: [d[i] for i in k]
os.kill(pid, signal.SIGTERM)
plt.show()
A[np.arange(A.shape[0]), (A != 0).cumsum(1).argmax(1)] = 0
sys.exit(0)
SomeModel.objects.filter(id__in=ids_list).delete()
plt.show()
con.commit()
{{a.name}}
cygstart / cygdrive / c / Python27 / python.exe
y = [0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0]
unittest.main()
print(response.content)
L4 = [item for item in L1 if item not in unwanted]
p1 = Process(target=f, args=(d,))
np.dot(a, b)
gtk.main()
plt.show()
sum(x > i for i in x)
draw = ImageDraw.Draw(im)
map(itemgetter(0), G)
print(getattr(test, a_string))
plt.figure(figsize=(4, 4))
{i: words.count(i) for i in set(words)}
sys.setrecursionlimit(10000)
res = df - df.shift()
df = df.reset_index()
sum((doSomething(x) for x in originalList), [])
[([0] * cols) for x in range(rows)]
[pair for pair in itertools.combinations(li, 2) if sum(pair) == 10]
print(max(max(x) if isinstance(x, list) else x for x in my_list))
root.update_idletasks()
(s.iloc[::2].values + s.iloc[1::2]) / 2
shuffle(x)
plt.show()
plt.show()
Reporter.objects.all().delete()
conn.commit()
ax = fig.add_subplot(111)
d = {k: [] for k in keys}
stack[-1]
some_list.append(dic)
blogpost.tags[:] = []
plt.show()
result[np.lexsort((result[:, (0)], result[:, (0)]))]
[i for i in range(10) if i not in digits]
root.mainloop()
loop.run_forever()
print(json.dumps(data))
dateutil.parser.parse(date_string)
plt.show()
new_string, np.tensordot(tensor1, tensor2, axes)
last = df.index[-1]
writer.writerow([latlon])
parser = parse_args(sys.argv[1:])
output = proc.communicate()[0]
args = parser.parse_args()
itertools.chain(*lists)
fout.writelines(data[1:])
noise = np.random.normal(0, 1, 100)
root.mainloop()
ax.xaxis.set_major_locator(mdates.YearLocator())
time.sleep(1)
sys.stdout.flush()
contained = [x for x in d if x in paid[j]]
self.send(data)
pygame.display.flip()
zeroMatrix = [([0] * Np) for i in range(Np)]
plt.show()
[i for i in zip(narrative, subject, activity, filer)]
self.progressbar.pack(padx=10, pady=10)
chain.from_iterable(combinations(s, r) for r in range(len(s) + 1))
print(f.read())
OrderedDict(itertools.islice(iter(d.items()), 500))
sheet.merge(top_row, bottom_row, left_column, right_column)
seq_iter = x if isinstance(x, dict) else range(len(x))
resultlist.append(M[:])
outfile.write(line)
df1.date = pd.to_datetime(df1.date)
figure(1, figsize=(6, 6))
self.timer.cancel()
writer.writerow([val])
print(matrix.data)
os.remove(filename)
a[np.argpartition(-a, np.arange((~np.isnan(a)).sum()))]
ws0.write(row, col, value, style)
print(line.strip())
unittest.main()
x, y = map(list, zip(*[(e, -e) for e in range(10)]))
writer.writerow([word])
ax.legend(handles, labels)
session.query(SomeClass).all()
[p[0] for p in datapoints[0:5]]
admin.site.unregister(User)
threading.Thread.__init__(self)
np.sum(M, axis=(0, 1))
bool(np.where(np.array([0, 0])))
print(Temperature.value)
ROOT_PATH = os.path.split(os.path.abspath(__file__))[0]
result = [x for x in orig if x]
istr.close()
scipy.stats.chi2_contingency(data)
[True, True, False].count(True)
df.loc[df.Col4.isin(target_array)].index
list(chain.from_iterable(zip_longest(d, reversed(e))))
deletemydict[key]
print(cls.__base__)
root.mainloop()
sys.stdout.flush()
list_1, list_2 = list(list_1), list(list_2)
my_dictionary = dict(line.split() for line in f)
objs.append(MyClass())
ans = [i for i in xy if i[1] > 0]
[len(max(i, key=len)) for i in tableData]
msg.attach(html_text)
smtp.sendmail(send_from, send_to, msg.as_string())
[int(s[x[1]:x[2]]) for x in parser.parse(s)[1]]
setattr(self, attr, val)
np.arange(1000000).dtype
f.seek(0)
label.destroy()
out = [(1 if num & 1 << 7 - n else 0) for n in range(8)]
np.pi
n.append(float(row[8]))
my_list.remove(item)
file.close()
a[:5, :5]
time.sleep(1)
sys.exit(app.exec_())
time.sleep(0.1)
df[(df <= 2).any(axis=1)]
Counter(words).most_common(10)
list(wrapper(raisinggenfunc()))
plt.show()
nine_hours_from_now = datetime.now() + timedelta(hours=9)
ax1.set_xlim(0, 1)
root.mainloop()
do_something()
root.mainloop()
urllib.request.build_opener(HTTPCookieProcessor).open(url)
df2.reset_index(drop=True, inplace=True)
plt.show()
sys.exit(app.exec_())
row.save()
list_of_tuples
logging.basicConfig(level=logging.INFO)
print(self.request.body)
plt.colorbar(im, cax=cax)
shutil.copy(str(my_file), str(to_file))
plt.show()
print(d[key])
response = urllib.request.urlopen(req)
buffer.append(np.ndarray((len(my_buf),), buffer=my_buf, dtype=datatype))
func1(1, 2)
[(i ** 2) for i in l]
myDict[x] += 1
pylab.show()
s.sendmail(me, to, msg.as_string())
users_list = [int(x) for x in users_list]
ax.set_yticks([])
base_dir = os.path.dirname(os.path.realpath(__file__))
p = [(i + 1) for i, (x, y) in enumerate(zip(a, a[1:])) if x > y]
plt.show()
c = (a + b)[:len(b)]
mask = numpy.repeat(a[:, (0)] == 1, a.shape[1])
plt.colorbar()
time.sleep(1)
json.dumps(new_D)
printx2()
tf.initialize_all_variables().run()
sys.exit(0)
num = int(your_str, 8)
map(list, list_of_tuples)
delta.total_seconds()
list(k for k, _ in itertools.groupby(k))
str(dec)
top.mainloop()
MyModel.filter(id__in=ids)
df.loc[~(df == 0).all(axis=1)]
img.putalpha(alpha)
plt.show()
self.__class__(os.path.expanduser(str(self)))
plt.show()
plt.subplots_adjust(left=0.2, top=0.8)
QtCore.Qt.ItemIsEditable | QtCore.Qt.ItemIsEnabled
pd.DataFrame(df.values.reshape(-1, 2, df.shape[1]).mean(1))
doc_df = pd.DataFrame(list(iter_docs(etree)))
sys.path.append(submod_path)
wM.reset()
A.stack(0).dot(twos).unstack()
print(parser.parse_args())
now.replace(hour=0, minute=0, second=0, microsecond=0)
print(df.sort_index(axis=1))
file.write(content)
a, b, c, d, e = my_string.split()[:5]
dir(__builtins__)
forms.ModelForm.__init__(self, *args, **kwargs)
unique_filename = uuid.uuid4()
connection.close()
window.show_all()
word[1:]
sys.exit(app.exec_())
root.mainloop()
model.objects.filter(id=i[1]).update(order=i[0])
x.ravel().tolist()[0]
diff = set(dictb.keys()) - set(dicta.keys())
socket.getfqdn()
rows = csv.reader(f1, delimiter=dialect.delimiter)
A[np.arange(A.shape[0]), A.shape[1] - 1 - (A[:, ::-1] != 0).argmax(1)] = 0
pd.DataFrame(zip(a, b), columns=[a.name, b.name])
db.commit()
p1 = Process(target=func1)
content = urlopen(url).read()
main()
imshow(data)
pylab.plot(x, y)
[x for x in collection]
browser.implicitly_wait(10)
canvas.save()
logging.getLogger().handlers[0].setFormatter(formatter)
root.mainloop()
bit_array.setall(0)
app.run(debug=False)
2 ** np.arange(m)
matched = np.array(list(set(arrays[0]).intersection(*arrays[1:])))
map(sum, data)
cursor.execute(query)
x[0][0].append(value1)
A[:, (np.arange(ncols) % A.shape[1])]
screen.blit(transsurface, (0, 0))
sum(1 for x in frequencies if x > 0)
con.close()
plt.figure()
len([_f for _f in a_list if _f]) > 0
os.unlink(filename)
transmission_array.append(1)
sorted(lst, key=lambda L: (L.lower(), L))
yvalues[idx]
print((k, v))
print(os.path.dirname(os.path.realpath(sys.argv[0])))
magnitudes = np.sqrt((vectors ** 2).sum(-1))[..., (np.newaxis)]
sid = session.key().id()
yticks[-1].set_visible(False)
x = np.delete(a, zero_row, 0)
User.objects.create_user(**data)
b = [(n >> i & 1) for i in range(7, -1, -1)]
element = ET.parse(fp)
logger.setLevel(logging.INFO)
ax.invert_yaxis()
locals()
OrderedDict(sorted(list(d.items()), key=lambda t: len(t[0])))
B = [i for i in A]
sys.stdout.flush()
logging.basicConfig(stream=sys.stdout, level=logging.INFO)
{x: 1, y: 2}
data[i][0] = math.sin(data[i][0])
signal.pause()
os.path.join(*choices[:-1])
a[:, (np.newaxis), :] - v
[tuple(y for y in x if y) for x in a]
print(max(flatten(l)))
tf.initialize_all_variables().run()
functools.reduce(operator.add, map(collections.Counter, dict1))
setattr(A, the_name, classmethod(func))
max([l1, l2], key=len)
f.seek(0)
cv2.destroyAllWindows()
random.shuffle(shufflethis)
ax.xaxis.set_major_formatter(ticks)
somedict = {x: (1) for x in somelist}
next(i for i, j in enumerate(lst) if j)
pd.concat([total, xtabs], axis=1)
list(set(tuple(sorted(s)) for s in all_the_ways))
np.sum(arr, axis=0)
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
id = models.CharField(max_length=10)
values, vectors = scipy.sparse.linalg.eigs(P, k=1, sigma=1)
[x for i, x in enumerate(myList) if i not in toRemove]
solve(eqs, [x, y])
np.intersect1d(A, B)
sys.path.append(os.path.abspath(path))
admin.site.register(Item, ItemAdmin)
conv.ravel()
ax1.imshow([[0, 1], [2, 0]])
e[np.all(e - np.array([1, 2]) == 0, axis=2)]
sc.parallelize(List(line)).collect()
time.timetuple()
s.multiply(sparse.csr_matrix(1 / np.sqrt(s.multiply(s).sum(1))))
A[:] = [1, 2]
print(sum(i == 1 for i in flatten_list(x)))
obj.save()
print(str(socket.gethostbyname(socket.getfqdn())))
np.std(sample)
os.path.abspath(os.path.dirname(__file__))
plt.show()
np.isnan(y), lambda z: z.nonzero()[0]
b = np.array([list(word) for word in a])
help(parrot.Norwegian)
(lambda a, b: a(a, b))(X, b)
plt.grid()
A[0:2, 0:2]
round(2606.89579999999, 2)
model.fit(S)
output.write(bytearray(int(i, 16) for i in yoursequence))
thumb = base64.b64encode(im.tostring())
np.take(a, b, axis=1)
matches = [m.span() for m in re.finditer(pattern, text)]
data.sort(key=lambda x: sorted(tally[i] for i in x))
cursor.close()
pipeline.fit_transform(data)
ax.plot_surface(X, Y, Z)
lambda i: isinstance(i, (int, float))
{x: (x + 6) for x in range(1, 5)}
np.concatenate([[0.2], linspace(1, 60, 60), [60.8]])
print(sys.argv[0])
a.shape = a = a.reshape((a.shape[0], -1, n))
all(x > limit for x in my_list)
a[1:] -= a[:-1]
ax.plot_trisurf(triang, z_refi, cmap=cm.jet, lw=0.0)
process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
plt.show()
_cache.clear()
plt.show()
all(getattr(self, key) == val for key, val in list(kwargs.items()))
a[:, ::2] + a[:, 1::2]
{k: v}
s.close()
pdb.set_trace()
df.apply(lambda x: x.argmax(), axis=1)
a = [[], [], [], []]
posts = Post.objects.filter(likes__21__exists=True)
sys.stdout.flush()
list(starmap(add, zip(lst, lst[1:])))
b = [(n >> i & 1) for i in range(0, n.bit_length() - 1)]
plt.show()
resp = requests.post(url, data=values, allow_redirects=True)
{tuple(x) for x in l1} & {tuple(x) for x in l2}
time.sleep(0.5)
plt.pcolormesh(x, y, z, cmap=mpl.cm.Reds)
label.pack(fill=BOTH, expand=1)
np.isnan([nan, nan]).any()
list(y)
cb.ax.xaxis.set_ticks(minorticks, minor=True)
result = requests.get(LOGIN_URL, auth=(USERNAME, PASSWORD))
plt.show()
self.canvas.pack()
alist = [row for row in alist if 2 not in row]
one, two, three = list(range(1, 4))
root.mainloop()
MPI_Finalize()
posts = Post.objects.filter(tags__in=tags)
cursor.execute(sql)
file.close()
form.save()
plt.plot(x_list, y_list)
first_element = myList[i][0]
sorted(zip(listofTimes, listofLines))
set(list1 + list2)
A = np.array(A)
session.commit()
df2.T.drop_duplicates().T
plt.show()
pipe.stdin.close()
(a[n:n + 1] + [default])[0]
pprint.pprint(obj, compact=True)
A.sum(axis=0)
ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())
ts[datetime(2011, 1, 8):]
b = numpy.vstack((numpy.zeros(a.shape, int), a))
print(list(map(lambda x, y: x + [y], A, list(range(1, len(A) + 1)))))
conn.commit()
pylab.show()
sum(functools.reduce(operator.mul, data) for data in zip(*lists))
sys.exit(1)
print(s.seconds / 60)
[(i, lst.count(i)) for i in set(lst)]
line[5:]
sorted(a, key=my_key)
arr = np.array(list_of_arrays)
print(match.group(2))
session.commit()
sum(i for i in range(a, b + 1) if i % 2 == 0)
nx.draw_networkx_labels(G, pos_higher, labels)
conn.escape_string()
os.path.dirname(f)
random.shuffle(migrant)
numpy.setxor1d(a, b)
df.cumsum()
plt.show()
arr.sum(axis=(0, 1)).shape
[x for x in x if x[id] == 20]
plt.show()
repr(a)
f.seek(0)
sort(arr, arr.size)
ordered_dictionary = [OrderedDict(zip(names, subl)) for subl in list_of_lists]
plt.show()
element = ET.parse(fp).getroot()
df.drop(df.columns[11:], axis=1)
2 ** 2 ** numpy.arange(5)
pl.show()
a.insert(0, a.pop())
root.mainloop()
r.mainloop()
app.run()
print(MyClass())
self.show()
data = numpy.array(f.read().split(), dtype=float).reshape(7000, 8)
df.mean(axis=1)
new_dict[key].extend(value)
print(get_lists_with_sum(11, 8))
session.expunge_all()
xx, yy = np.mgrid[:5, :5]
A[::-1, :]
ax = fig.add_subplot(1, 1, 1)
itertools.chain.from_iterable(lists)
np.mean(t, axis=1)
root.mainloop()
session.query(WhateverClass).filter(WhateverClass._containerClassId == 5).all()
driver.quit()
h.setLevel(logging.DEBUG)
np.cos(np.pi * x) * np.sin(np.pi * y)
self.clickcursor.execute(query)
pd.value_counts(list(chain(*df.categories.values.tolist())))
plt.show()
type(variable_name)
A[A == NDV] = numpy.nan
print(any(l[i:i + len(pat)] == pat for i in range(len(l) - len(pat) + 1)))
pygame.init()
x[np.r_[0:2, -2:0]]
print(s.tell())
time.sleep(5)
dest = dict(list(orig.items()) + list(extra.items()))
print(my_new_list)
df.loc[row, key] = data[key]
pipeline.steps[1][1]
dir(request.body)
df[(df > 16) & mask]
xvfb.wait()
print(new_string)
files = [f for f in os.listdir(dirToScreens) if path.isfile(f)]
[random.randrange(1, 10) for _ in range(0, 4)]
root.mainloop()
sys.stdout.flush()
plt.show()
sum(1 for i in x if i)
x = (x + y) % 48
isascii = lambda s: len(s) == len(s.encode())
users = models.ManyToManyField(Users)
[l[i:i + n] for i in range(0, len(l), n)]
pprint.pprint(obj, depth=1)
req.close()
hash(self.__key__())
a.__getitem__(slice(0, 1)).__getitem__(0).__setitem__(0, 5)
app = create_app()
len(set(a)) == len(a) == max(a) and min(a) == 1
time.sleep(1)
print(etree.tostring(page, pretty_print=True))
sess.run(train_op)
label.pack()
site.delete(os.path.join(path, ftpfile.name))
(dt - datetime(1970, 1, 1)).total_seconds()
ax1.set_zorder(1)
np.any((0 < x) & (x < 1))
gtk.main()
[a for a, b in zip(aa, bb) if a == b]
issubclass(C, A)
fig.tight_layout()
df = pd.concat([df, pd.DataFrame(new_data)])
matplotlib.get_backend()
conn.commit()
[s[i:i + 2] for i in range(0, len(s), 2)]
os.path.basename(f.name)
p.start()
any(x[1:] == x[:-1] for x in zip(*arr))
df.stack().reset_index(1)
self.assertEqual(0, os.getpid())
my_array[:, (0)], my_array[:, (1)] = my_array[:, (1)], my_array[:, (0)].copy()
df.shape[1]
len(df)
utc_dt = datetime(1970, 1, 1) + timedelta(seconds=timestamp)
cts.minute == 0 and cts.second == 0
[0] * 10
pyplot.show()
fragments
locations = sorted(list(range(len(A))), key=A.__getitem__)
sys.stdout.flush()
root = tree.getroot()
ax.xaxis.set_major_locator(myLocator)
print(min(Mylist, key=lambda x: x[1]))
tup[0] = tup[0].__iadd__((4, 5, 6))
Gtk.main()
python - devel
ax.set_xlim(1, 11)
plt.draw()
{i: a[i] for i in np.nonzero(a)[0]}
[i.strip() for i in txt.split(default_sep)]
p.wait()
tmp[:, :-1] += a[:, 1:]
plt.show()
l2 = zip(l1[0::2], l1[1::2])
plt.show()
newD = dict(zip(list(d.keys()), [round(v) for v in list(d.values())]))
self.save()
gtk.main_quit()
A[((0,), (1,)), B]
int(t[0], 2) + int(t[1], 2) / 2.0 ** len(t[1])
print([(int(i) + 1) for i in s.split()])
df.apply(calculateC2, axis=1)
window.show()
pdb.set_trace()
str = str[:1].upper() + str[1:]
collections.OrderedDict(sorted(result.items()))
(10)()
f.close()
plt.show()
x = (x + y) % 48
df_with_x5.show()
array2 = [i for i in array2 if i not in array1]
t2c.main()
sorted(get, key=sortkey)
plt.show()
sys.exit(app.exec_())
requests.get(url)
os.remove(filename)
watchout()
skycake()
plt.show()
func(self, *args, **kwargs)
show()
foo.update(list(range(2, 6)))
pg.mixer.set_num_channels(50)
df.mask(np.arange(df.shape[0]) >= np.arange(df.shape[1])[:, (np.newaxis)])
[os.path.join(root, *choices[:i + 1]) for i in range(len(choices))]
print(iter2(A.copy(), rc1, rc2))
df.loc[target_index]
b = a[0:2]
dsp.close()
root.mainloop()
np.nanmean(data, axis=0)
Counter(test.split()).most_common()
print(df.sum().sum())
isinstance(dates, pd.DatetimeIndex)
df.columns = [str(i) for i in df.columns.values.tolist()]
canvas.pack()
(my_array[:-1] * my_array[1:] < 0).sum()
reactor.run()
isdeployed.strip()
print(a[0][0])
list(set(a) & set(b))
ws.write(rowi, coli, converters[coli](value))
array([[-1, -2, -1, 2], [1, 0, 1, 4]])
plt.show()
sys.exit()
do_something()
x[::2, 1::2]
[a[i] for i in np.argsort(a)[-2:]]
plt.show()
np.allclose(r1, r2)
emp.save()
f.seek(0)
os.makedirs(dir)
os.makedirs(mypath)
list1, list2 = f()
pygame.joystick.init()
plt.gcf().canvas.get_supported_filetypes_grouped()
df.reindex(stk_list, level=0)
deletec[0]
plt.show()
os.remove(i)
plt.show()
func()
print(etree.tostring(root, pretty_print=True))
d = dict(map(str.split, list1))
np.array([arr[([0, n]), :], arr[:, ([0, n])].T]).ravel()
random.choice([True, False])
[x for x, _ in lst]
(abs(x) + x) / 2
cgi.parse_qsl(qs)
dict1.update([(key, dict2[key]) for key in list(dict2.keys())])
pd.read_csv(StringIO(s), parse_dates=[0], date_parser=parser)
blogpost.tags[:] = new_tags
redirect(request.path)
sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))
csvdata_old = csvdata.copy()
losses = tf.reshape(tf.concat(1, losses), [-1, size])
root.mainloop()
dict(zip(range(1, 5), count(7)))
plt.show()
x, y = zip(*[l.split() for l in f])
len(set(map(tuple, M))) == len(M)
Superlist.__init__
plt.show()
admin.site.register(Product, padmin)
test()
plt.show()
s = sorted(s, key=operator.itemgetter(1, 2))
y[(1 < x) & (x < 5)]
pg.init()
first_elements, second_elements = map(list, zip(*data))
key_precedence = dict((x, n) for n, x in enumerate(string_list))
ax.set_zlim(-10, 0)
writer.writerow(row)
result.extend(list(t))
logger.setLevel(logging.DEBUG)
time.sleep(1)
plt.show()
[tuple(x) for x in data_set.to_records(index=False)]
plt.show()
plt.show()
fts = ustyle.create_featuretypestyle()
a.add([1, 2])
os.path.join(os.path.dirname(parent), template)
time.mktime(datetime_object.timetuple())
employee.license_set.all()
inspect.getargspec(g)
cherrypy.quickstart(Root())
conn.close()
ax = fig.add_subplot(111)
os.close(f)
[j for i in sequence_list for j in rex.split(i)]
result[:a.shape[0], :a.shape[1]] = a
func()
widget2.grid(row=0, column=1)
numpy.linalg.norm(A - B, numpy.inf)
f.seek(0, 0)
nx.draw(G)
QtNetwork.QSslSocket.supportsSsl()
p = subprocess.Popen(cmd, stdout=subprocess.PIPE, shell=True)
plt.show()
set(map(itemgetter(0), l1)) & set(map(itemgetter(0), l2))
etree.fromstring(s, parser=utf8_parser)
request.user_agent
pckl_file.close()
shutil.rmtree(sub_folder)
[(my_array + [i]) for i in input_elements]
pygame.font.init()
sympy.solve(l - r, c)
np.random.seed(0)
self.worker.start()
a = [[(0) for _ in range(ROWS)] for _ in range(COLUMNS)]
print(sys._getframe().f_code.co_name)
[(x ** 2) for x in range(10) if x < 7]
thingy1.f()
self.panel = wx.Panel(self)
f = anotherdecorator(lambda x: x * 2)
np.ma.array(a, mask=mask)
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
json.dump(data, sys.stdout, indent=2)
[x for x in lst if float(x.split()[-1]) not in s]
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
StringIO()
ax2.set_ylim([0, 1])
r.destroy()
str1.replace(str2, str2.upper())
self.transport.write(data.encode())
np.array(lists)
[(y if y not in b else other_value) for y in a]
array([[100, 200], [255, 255]], dtype=uint16)
np.in1d(a, [14, 16, 18])
t.start()
parser.parse_args(read_my_file(sys.argv[1:]))
l1 = np.array([a1, b1])
root.mainloop()
plt.show()
browser.get(url)
measure.grid(row=0, column=0)
root.mainloop()
session.commit()
os.close(fh2)
value = next(v for i, v in enumerate(d.values()) if i == index)
m[:, :1].shape
pl.show()
{x[0] for x in list1} & {y[0] for y in list2}
out_im.putpalette((0, 0, 0, 255, 0, 0, 0, 255, 0, 255, 255, 0))
tmp[:, 1:] += a[:, :-1]
os.path.abspath(os.path.expanduser(path))
fwrite.close()
f = lambda X, model, **kw: cost(X, model, sparse=np.random.rand(10, 10), **kw)
e = next(iter(S))
plt.show()
sorted(L, key=lambda x: x[0] / (x[1] * 1.0))
self.main()
(df * weight[0]).sum(1)
pygame.draw.rect(screen, black, (0, 0, width, height), 0)
int(n)
test()
dest = dict(chain.from_iterable(map(dict.items, list_of_dicts)))
self.__dict__.update(b)
pickle.load(f)
df[df.apply(pd.Series.nunique, axis=1) == 1]
sorted(l1)
driver = webdriver.Firefox(capabilities=caps, firefox_profile=profile)
msg.send()
plt.hist(a, bins)
p.poll()
logger.setLevel(logging.DEBUG)
f.close()
f.close()
x = Example()
file.write(port.read())
pygame.quit()
210.184175597721, 210.184175597721, 210.184175597721, 210.184175597721
print(test())
QtGui.QWidget.__init__(self)
time.sleep(5)
metadata.reflect(engine)
map(lambda x: f(x, fixed), srclist)
f.close()
br.set_handle_refresh(mechanize._http.HTTPRefreshProcessor(), max_time=1)
os.path.getsize(path)
plt.show()
f.close()
os.unlink(path)
ax.add_patch(circle1)
df.columns = col_list
gtk.main()
QTcpSocket.__init__(self)
A = dot(A, R.T)
[(x + y) for x, y in grouper(2, q)]
ssh.close()
{(x, y) for x in r for y in r if x + 2 == y}
date = models.DateTimeField()
wx.Icon(sys.argv[0], wx.BITMAP_TYPE_ICO)
[([0] * 8) for x in range(8)]
unittest.main(argv=[sys.argv[0]])
array2 = [int(x == 4) for x in array1]
plt.show()
root.mainloop()
html.escape(string)
max(item[1] for item in alkaline_earth_values)
sorted(list(d.items()), lambda a, b: b[1] - a[1] or a[0] - b[0])
numbers = [n for n in numbers if n >= 20]
[(next(z) if i < 0 else i) for i in y]
proc.wait()
arr.tolist()
print(Model.objects.get(pk=1).ranking)
equation1(**dict_of_parameters)
n = np.apply_along_axis(np.linalg.norm, 1, a)
[(x, y) for x, y in zip(it, it1)]
my_list.insert(index, item)
set([(4, 5), (2, 2, 5), (1, 20), (2, 10)])
f2.close()
writer.writerow(row)
self.assertEqual(2, 0)
f1.writelines(lines)
A.extend(B)
connection.close()
root.deiconify()
cv2.rectangle(eroded, (0, 0), (x, y), (255, 255, 255), 1)
df = pandas.concat([df1, df2], axis=1)
X_test = scaler.transform(X_test)
a[a.argsort()[-10:]]
QtGui.QTableView.__init__(self, *args, **kwargs)
[[4, 2, 6], [8, 10, 12], [6, 8, 6]]
list(x)
test[1].index + pd.DateOffset(hours=16)
[((x + (x - 1)) / 2) for x in list_of_nums]
print(input[indices[(0 <= indices) & (indices < 5)]])
f.close()
d.pop(your_key)
plt.show()
result = (M[:, :9] * N[:9, :].T).sum(1)
queue.Queue(maxsize=0)
(lambda i: lambda x: x % i)(i)
session.query(inc_type_md_col).filter(cnt_col > 0)
zip(itertools.repeat(ls[0]), ls[1:])
plt.colorbar()
window.show_all()
ax.set_ylim([0, 5])
self.process.start()
result = [key for key, value in dict.items() if value == min_value]
dict.fromkeys(list(range(2)), object())
plt.plot(x, y1)
main()
f.flush()
plt.show()
[v[0] for v in sorted(list(dict.items()), key=lambda k_v: (-k_v[1], k_v[0]))]
print(template.render())
print(json.dumps(jsonobj))
string.ascii_uppercase + string.digits
any((myrow1 == x).all() for x in myarray)
pandas.read_csv(s)
x, y = y, x + y
y = [i[j] for i in x for j in range(len(i))]
my_list = list(my_set)
first_type if all(type(x) is first_type for x in iseq) else False
time.sleep(5)
any(t.isupper() for t in month[1:])
random.choice(string.ascii_letters + string.digits)
list([x for x in mylist if x in pattern])
sum(i * j for i, j in zip(v1, v2))
sum(map(lambda x, y: bool(x - y), a, b))
tfactory = TTransport.TBufferedTransportFactory()
print(list(Counter(l).items()))
s = sum(b for a, b in zip(list_1, list_2) if a)
sys.exit(1)
model.objects.all()
data = np.random.randint(0, 10, size=(100000, 2))
print(sys.version)
a.append((1, 2, 4))
df = df.reindex(columns=cols)
exp.evalf(subs={a: 6, b: 5, c: 2})
tup = tuple((element.foo, element.bar) for element in alist)
settings.__dict__
A.data = np.array([10, 6])
master.mainloop()
params = {arg: self.request.get_all(arg) for arg in self.request.arguments()}
dict(list(i.items())[0] for i in L)
A = P * D.sum(axis=1) - D.dot(P)
plt.hist(x, bins=20)
subprocess.Popen(cmd).communicate()
test()
map(max, arr)
mail.Send()
data = np.arange(-50, 50, 10)
df.eq(df.iloc[:, (0)], axis=0)
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
plt.show()
stdout, stderr = process.communicate()
sorted(d, key=lambda i: int(d[i]))
self._droplock()
new_foo.append(item)
e = [x[0] for x in eagles]
[key for key, group in groupby(li) if len(tuple(group)) == 1]
np.unravel_index(match_indices, result.shape)
pd.DataFrame(res)
session.commit()
[(val, np.sum(A[B == val])) for val in np.unique(B)]
plt.show()
plt.show()
itertools.product(list(C.items()), repeat=2)
instance.save()
hey()
hist(b.ravel().astype(np.uint8), bins=255, range=(0, 255))
{k: v for k, v in list(dictionary.items()) if begin <= k <= end}
first = l.pop(0)
tkmc.close()
cleaned = [i for i in (word.strip() for word in words) if i]
f.close()
G.data = np.ones(G.nnz)
time.sleep(1)
ax = fig.add_subplot(111)
lambda a, b: b * a(a, b - 1) if b > 0 else 1, b
sys.getsizeof(s)
[list(s) for s in sets]
ser.close()
clf.fit(X, y)
plt.subplots_adjust(bottom=0.17)
bool(my_list)
os._exit(1)
__init__.py
[(x + 1 if x >= 45 else x + 5) for x in l]
tornado.ioloop.IOLoop.instance().start()
print(list(mydict.keys())[list(mydict.values()).index(16)])
plt.show()
sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
id(copy_my_list[0]) == id(my_list[0])
x.append(i)
df1.sort(axis=1) == df2.sort(axis=1)
my_list = list(my_set)
solve(my_func, 16)
int(a)
df.groupby(df.columns.tolist(), as_index=False).size()
frame.show()
__init__.py
setattr(self, name, number)
a = db.ReferenceProperty(A)
d + datetime.timedelta(hours=8)
sys.path.pop(0)
b.remove(i)
print([x for x in words if len(x) > average])
sorted(text, key=lambda x: (str.lower(x), x))
plt.show()
distance[0][1][2]
fig.set_size_inches(18.5, 10.5, forward=True)
{k: v for k, v in zip(list(range(1, 5)), list(range(7, 11)))}
p.start()
self.setWindowFlags(QtCore.Qt.Tool)
print([x for x in a if counts[x] >= 2])
sys.stderr = sys.__stderr__
__init__.py
QMainWindow.__init__(self, parent)
x2[:, (4)] = np.roll(x2[:, (4)], 2)
print(is_list_of_strings(i))
time.sleep(5)
e / e.sum(axis=1, keepdims=True)
subprocess.Popen(cmd)
plt.show()
x = x[:-1]
__builtins__.set
ax = fig.add_subplot(111)
not set(a).isdisjoint(b)
br.submit()
print(w.readline().strip())
l.sort(key=lambda x: x[1])
ax2.set_ylim(0, 10)
platform.system()
setattr(obj, prop_list[0], something)
centroids.append((x, y))
plt.show()
random.sample(list(enumerate(a)), 5)
dtwithoutseconds = dt.replace(second=0, microsecond=0)
plt.show()
sys.version
received_json_data = json.loads(request.body)
soup = BeautifulSoup(page)
line = line[2:]
main.run()
p.start()
lst[:] = [v for v in lst if pred(v)]
[x for x in L if not any(set(x) <= set(y) for y in L if x is not y)]
plt.subplots_adjust(wspace=0.001)
n[:] = [[(b - 1) for b in a] for a in n]
data_file = models.FileField(upload_to=content_path)
urllib.request.urlopen(request).read()
self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
logger.setLevel(logging.DEBUG)
np.random.uniform(5, 10)
key = next(iter(d))
plt.show()
clf.fit(X)
reactor.run()
unittest.main()
df = df.loc[mask]
plt.show()
main()
df.head()
j2 = [i for i in j if i >= 5]
time.sleep(0.5)
rf.merge_arrays((arr, x), flatten=True)
set(x) == set(y)
X_test = sc.transform(X_test)
json.dumps(d)
form = MyForm(questions=your_list_of_questions)
print(Matrix[x][y])
ser.close()
isinstance(b, Test2)
normal_dist.set_shape([input_data.get_shape()[1], labels.get_shape()[1]])
sys.stdout.write(REVERSE + CYAN)
a = np.array([d])
IOLoop.instance().start()
married = models.CharField(max_length=1, choices=MAYBECHOICE)
print([obj.name for obj in gc.get_objects() if isinstance(obj, potions)])
QtCore.Qt.ItemIsEditable | QtCore.Qt.ItemIsEnabled
csv_writer.writerow([i[0] for i in cursor.description])
values = [max(x, 0) for x in values]
HttpResponse(simplejson.dumps(data_dict))
list(csv.reader(s, skipinitialspace=True))
[x[0] for x in listD[0]]
workbook.close()
print(hex(new_int))
df
mylist[:] = [(not x) for x in mylist]
ax.set_axis_bgcolor((1, 0, 0))
c = [item for t in zip(a, b) for item in t]
ax.margins(0.2)
setup.py
ssh.connect(server, username=username, password=password)
ordered = [item for item in ordered if item in unordered]
[OrderedDict(row) for i, row in df.iterrows()]
c = dict.fromkeys(s, 0)
print(datetime.utcfromtimestamp(tai_timestamp))
a[:, (0), (0)], b[:, (0), (0)] = b[:, (0), (0)], a[:, (0), (0)].copy()
fout.close()
data.reset_index(drop=True)
vals = numpy.delete(vals, numpy.where(a), axis=0)
[sum(int(c) for c in str(num)) for num in list1]
list(map(hash, list(range(1, 6))))
nx.has_path(G, 1, 5)
user.save()
date = models.DateTimeField(default=datetime.now, blank=True)
df1.combine_first(df2)
s.tolist()
wx.Frame.__init__(self, parent, id, title)
plt.show()
A - mean.reshape(mean.shape[0], 1)
app.run()
plt.show()
plt.show()
len(alist) - alist[-1::-1].index(value) - 1
file.write(unicode_text)
root.mainloop()
regr.fit(Xtrain, ytrain)
plt.show()
df.rolling(window=10).mean().applymap(round).shift()
os.kill(process.pid, signal.SIGINT)
circular()
final_l = []
[i for i in range(len(bv)) if bv[i]]
plt.draw()
f.write(line)
query = session.query(TestUser).filter(TestUser.numbers.any(25)).all()
self.process.terminate()
sorted(A, key=A.get)
df = pd.DataFrame(data, columns=columns)
plt.figure(figsize=[6, 6])
driver = webdriver.Chrome(chrome_options=options)
hist(b.ravel().astype(np.uint8), bins=255)
my_list = list(the_tuple)
ax1.xaxis.set_visible(False)
self.root.mainloop()
login(request, user)
result = re.sub(regex, subst, file_contents)
Foo._bar()
[random.shuffle(x) for x in workList]
plt.show()
pi = (a + b) ** 2 / (4 * t)
l = l[0] + (l[1],)
plt.show()
df.to_excel(ew)
a[..., ([1, 1])]
[(s[i], i) for i in indices]
d = dict(list(row.items()))
rgb = np.dstack((r, g, b))
ax.xaxis.set_ticks(x)
a - a.min(axis=0)
infloop()
sys.exit(app.exec_())
root.mainloop()
np.minimum(arr, 255, out=arr)
sorted(list(range(len(K))), key=lambda x: K[x])[-5:]
plt.xlim(-1, 1)
tf.multiply(x, y).eval()
elements.append(table)
primes = list(range(2, 20))
found = any(word in line.split() for line in file)
pdb.set_trace()
app.MainLoop()
form = CModelForm(UPOST(request.POST, c_instance), instance=c_instance)
time.sleep(1)
df.a / df.b.replace({(0): np.nan})
zip(np.nonzero(starts)[0], np.nonzero(ends)[0])
print(pandas.concat([s1, s2], axis=1).min(axis=1))
my_dict.clear()
xlbook.close()
[seq[i:i + n] for i in range(len(seq) - n + 1)]
h = {k: v for k, v in l}
[len(list(group)) for key, group in groupby(a)]
do_something()
1 - residual / sum((y - y.mean()) ** 2)
ax.set_xlim(ts.index.min(), ts.index.min() + 24)
df.fillna(0, inplace=True)
all(x <= y for x, y in zip(L, L[1:]))
time.sleep(1)
plt.show()
y = int(x, 16)
layout.setContentsMargins(20, 0, 20, 0)
[8, 5, 6]
root.mainloop()
os.rename(tmpFile, myFile)
lst.sort(key=itemgetter(1), reverse=True)
admin.site.register(TestModel, TestModelAdmin)
print(etree.tostring(tag, pretty_print=True))
root = Tk()
plt.tight_layout()
os.killpg(os.getpgid(p.pid), signal.SIGTERM)
sys.exit(app.exec_())
((a[:, (np.newaxis), :] - v) ** 2).sum(axis=-1).min(axis=0).sum()
time.sleep(x)
[index[start:end] for start, end in zip(slices[::2], slices[1::2])]
uniq_animal_groups = [list(t) for t in set(map(tuple, animal_groups))]
df.append(dm2)
df = df.reset_index()
(1 for i in x if 60 < i < 70)
plt.plot(x, y)
a, b, c = do_something()
bane.astype(np.float).view(np.complex64)
self.configure(width=width, height=height)
plt.clabel(cs, inline=1, fontsize=9)
keys.sort(lambda x, y: cmp(dict[x], dict[y]))
[0, 1, 2, 4]
time.sleep(1)
random.sample(zip(xs, ys), 1000)
app.MainLoop()
[j() for j in [(lambda i=i: i) for i in range(10)]]
line = sys.stdin.readline()
time.sleep(1)
split = pd.concat([df, TScolumns], axis=1)
logger.setLevel(logging.DEBUG)
plt.show()
lst = []
[y for x in data for y in x]
a[0].append(1)
obj = PageModel.get_by_id(page_id)
M = np.column_stack((x ** 2, x, np.ones_like(x)))
solve(eqs2, [x, y])
[item for item in mylist if item[0][0] == letter]
plt.show()
fh.close()
ax.set_yticklabels([])
df.append(data)
print(Foo.bar.__get__(f, Foo))
all(e == a[0] for e in a)
next(x for x in (f(y) for f in hundreds) if x)
self.process.wait()
pygame.joystick.quit()
worksheet.save()
row0 = ynew[0].toarray()
d[i[i < d.shape[0]]]
self._socket.bind((self._host, self._port))
f.write(text)
print(str(n)[::-1])
b = [(n >> i & 1) for i in range(n.bit_length() - 1, -1, -1)]
[sorted(item, key=priority.get) for item in my_lists]
test[n:]
sys.stdout.flush()
zip(*[(lst[i:] + lst[:i]) for i in range(n)])
print([(x - i) for i, x in enumerate(a)])
lists[0].append(1)
Image.fromarray(result).save(sys.argv[2])
dict(zip(l[::2], l[1::2]))
sess.close()
result = [r[0] for r in result]
plt.show()
plt.show()
any([(x[1:] == x[:-1]) for x in zip(*arr)])
dsub = df1.reset_index(drop=True).sub(df2.reset_index(drop=True))
doctest.testmod()
logging.getLogger().getEffectiveLevel()
df
MyThread().start()
round(2.607, 2)
[k for k, n in Counter(seq).items() if n == 1]
root.mainloop()
indices = [i for i, x in enumerate(myList) if re.search(regex, x)]
np.abs(A[:, (np.newaxis)] - B)
self.timer.stop()
username = request.user.username
pd.read_csv(f, **kwargs)
soup = BeautifulSoup.BeautifulSoup(html)
sys.path.append(path)
deletemy_list[1]
foo((noniterable,))
app.root.mainloop()
print(sorted(iter(counter.items()), key=lambda x: x[::-1]))
vectors /= np.sqrt((vectors ** 2).sum(-1))[..., (np.newaxis)]
s.find_longest_match(0, len(a), 0, len(b))
{k: v for k, v in list(dict.items()) if v > something}
db.session.commit()
results = sorted(list(results.items()), cmp=lambda a, b: b[1] - a[1])
[k for k, g in groupby(data)]
my_func(*arr.T)
sys.exit(app.exec_())
sum(map(len, [s for s in x if len(s) > 1]))
test_rec[indices]
Color(*Color2.as_list())
xbook.close()
plt.colorbar()
combined = [item for sublist in lists for item in sublist]
deletec[:]
root.mainloop()
ws.cell(row=index, column=2).value = x1
datetime(1970, 1, 1)
my_dict = json.load(f)
dot(x, y)
print(match.groups())
Y = X - X.mean(axis=1, keepdims=True)
df.where(df.eq(df.max(1), 0), -1)
f_out.close()
plt.show()
maxlen = len(max(a, key=len))
data = pickle.load(f)
Response(serializer.data, status=status.HTTP_201_CREATED)
plot_data = [[]] * len(positions)
application = django.core.handlers.wsgi.WSGIHandler()
sum(map(r, v)) == -n
np.cross(c, d).reshape(5, 4)
e = Example(size=10)
result.append(x[:2].tolist())
method()
self.ProgressBar.SetValue(0)
func(*args, **kwargs)
df.loc[df.index.tolist() + missing]
result[:-1]
df.loc[set(df.index) - set(blacklist)]
time.sleep(1)
np.where(a == a.max())
[f(a) for f in funcs for a in args]
current_module = sys.modules[__name__]
response = mechanize.urlopen(request, data=data)
sys.path.append(path)
print(f.stdout.readline())
tup = tuple([(element.foo, element.bar) for element in alist])
sys.exit(app.exec_())
print(c.most_common()[0])
plt.show()
main()
df.iloc[np.argmin(np.abs(df.index.to_pydatetime() - dtObj))]
a[:] = [s.strip() for s in a]
p[s] == np.arange(n)
random.shuffle(newcolors)
t + np.roll(t, -1)
l.sort(operator.itemgetter(0), reverse=True)
al[0], al[1] = float(strs[0]), float(strs[1])
str(random.random())[2:]
r = requests.post(URL, data=payload)
list(set().union(a, b, c))
main()
self.graph = self.ax.hexbin(self.xData, self.yData)
csvwriter.writerow(row)
c.setopt(c.HEADERFUNCTION, storage.write)
admin.site.unregister(Group)
sys.stderr = sys.__stderr__
R = np.array(mean_data)[:, (0)]
numpy.invert(array)
sum(1 for x in gen)
print(a[x][y])
a[1].append(2)
np.log(df.col1 / df.col1.shift())
addrport = ADDRPORT(addrbytes, portshort)
L = [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]]
make_adder(5)(10)
cbar.set_ticks([mn, md, mx])
mag = np.sqrt(x.dot(x))
np.random.seed(1977)
lol = [list(range(10)), list(range(2, 12)), list(range(5, 15))]
split_curve(np.array([0, 1]), np.array([0, 1]), 2)
sys.stderr.close()
print(my_new_list)
Base.metadata.create_all(engine)
window.show_all()
a.append(str(wi))
plt.show()
logging.Handler.__init__(self)
ax7.yaxis.set_label_coords(-0.2, 0.5)
ax2.set_xlim(0, 10)
t.date()
len(set(perms))
np.random.choice(array1, 5, replace=False)
getattr(module, class_name)
plt.imshow(crop_lena, cmap=plt.cm.gray)
plt.show()
con.close()
df = pd.DataFrame(data)
big_df = pd.concat(df_list)
data = [tuple(line) for line in csv.reader(f)]
wx.Panel.__init__(self, parent)
a[-9:]
ax.grid(True)
plt.show()
df.reindex(s.index)
a.repeat(2, axis=0).repeat(2, axis=1)
signal.signal(signal.SIGALRM, signal_handler)
a[np.arange(len(a)), [1, 0, 2]]
sys.exit()
Project.objects.all()
isinstance(f, float)
plt.plot(x, y2)
form = MyForm(request.user)
print(df.astype(float).sum().astype(int).astype(str))
entry.focus_set()
[myfunc(a, b) for a, b in zip(data[::2], data[1::2])]
plt.show()
pd.DataFrame(a.reshape(A.shape[0], -1), A.index)
name = next(name for name, value in list(vars(Status).items()) if value == 1)
mask = np.in1d(a[:, (0)], b)
time.sleep(0)
y[y.nonzero()]
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6
driver = webdriver.Firefox()
print(list(f()))
list(Blog.objects.values())
ax.xaxis.set_major_formatter(dates.AutoDateFormatter(locator))
tornado.ioloop.IOLoop.instance().start()
print(cmod.greet(a))
im_data = output.getvalue()
print(random.choice(a))
writer.writerows(new_data)
np.array_split(a, 2, axis=1)
f.write(leds[0])
(vals[:, (0)] == 0) & (vals[:, (1)] == 1)
{key: data[key] for key in one_by_ip}
ax.xaxis.set_major_locator(mdates.YearLocator())
tk.mainloop()
item_labels.sort(key=lambda t: c[t[1]])
br.title()
list(set(theList).intersection(theDict))
Decimal(1) / Decimal(7)
heapq.nsmallest(l, 2)
max(i[0] for i in oceans[regcode - 1])
sorted(a, key=lambda x: (x[0].isdigit(), x))
plt.show()
a.dot(v)
set([x for x in l if l.count(x) > 1])
f.seek(0, 2)
root = Tk()
admin.site.register(User, UserAdmin)
logging.basicConfig(level=logging.DEBUG)
orcl.close()
root.grid_columnconfigure(0, weight=1)
df.apply(lambda s: s.value_counts().get(0, 0), axis=1)
first2pairs = {k: mydict[k] for k in sorted(mydict.keys())[:2]}
plt.colorbar()
ax.set_xticklabels(x_labels)
dict(form=form)
plt.xlim(0, data.shape[0])
df = df[df.line_race != 0]
plt.contourf(xi, yi, zi, v, cmap=plt.cm.jet)
zip(*data)
print(row[0].read())
L.append(l)
any(i.isdigit() for i in string)
f.seek(-len(line), os.SEEK_CUR)
QtGui.QWidget.__init__(self)
sum(s[i:].startswith(subs) for i in range(len(s)))
logging.getLogger().addFilter(Aggregator)
len([x for x in myList if x in myDict]) > 0
print(date.isoformat())
table.create()
HttpResponse(status=500)
sys.exit(0)
my_dict[key].append(value)
df.drop(drops, inplace=True)
writer.writerow(dict(zip(fieldnames, row)))
print({k: [d[k] for d in dd if k in d] for k in all_keys})
sys.stdout.flush()
layout.addWidget(btn)
sorted(a.keys())
A[np.lexsort((A[:, (0)], A[:, (1)]))]
session.commit()
plt.hist(np.clip(values_A, bins[0], bins[-1]), bins=bins)
plt.show()
time.sleep(0.1)
lst[:] = [word for words in lst for word in words.split()]
requests.delete(url, data=json.dumps(data))
earth.speed(0)
mars.speed(0)
df.stack().value_counts()
b.sort(key=float)
autoreconf - i
hdf5.close()
reactor.run()
dict(i=i, j=j, k=k)
sorted(lst, key=lambda x: (counts[x], -firstidx[x]), reverse=True)
changewriter.writerow([productcode, amountentered] + changecoins)
os.system(cmd)
plt.gcf().canvas.get_supported_filetypes()
plt.show()
threading.Thread.__init__(self)
answer = [0, 1, 1, 1, 1, 0]
s.setsockopt(socket.SOL_SOCKET, socket.SO_LINGER, linger_struct)
main()
w, h = draw.textsize(text, font)
sys.stdout.write(line)
x[y.nonzero()] = y[y.nonzero()]
self.assertEqual(response.status_code, 200)
vars(funkytown)
pd.concat([pd.DataFrame(out, df.index, a), df], axis=1)
urllib.request.urlopen(req)
self.__getitem__(slice(start, stop))
itertools.chain(*([i] * i for i in range(1, 5)))
[range(2, 5), range(12, 17), 20]
time.sleep(1)
mySet = {x[0] for x in TUPLES}
print(os.listdir(path))
cursor.execute(sql, args)
extra_logger.setLevel(logging.INFO)
pylab.show()
v = int(float(s)) if int(float(s)) == float(s) else float(s)
id_map = {k: v for v, k in enumerate(df.phone_no.unique(), 1)}
deletefoo.fields[index]
fig.canvas.draw()
print((char, char.isalpha()))
plt.show()
plt.draw()
distances = np.sqrt((x - x0) ** 2 + (y - y0) ** 2 + (z - z0) ** 2)
getattr(someobject, foostring)
np.append(a, z, axis=1)
map(str.strip, my_list)
list(ordered_dict.values())[2]
np.concatenate((arr[([0, n]), :].ravel(), arr[1:-1, ([0, n])].ravel()))
np.random.seed(1)
f.close()
list(set(a))
[int(i) for i in bin(x)[2:]]
HttpResponse(line)
br.set_cookiejar(cj)
plot_data = [[] for _ in positions]
a = np.array([np.array(list()) for _ in y])
(np.abs(a - val) <= tol).argmax()
plt.show()
__init__.py
[seen[c] for c in list]
QApplication.restoreOverrideCursor()
plt.show()
sys.stdout.flush()
QtGui.QWidget.__init__(self)
widget.destroy()
pd.concat([df.iloc[:, :1], df.shift(1), df.shift(2).iloc[:, 4:]], axis=1)
transmission_array.append(0)
app = Flask(__name__)
np.insert(B, np.arange(len(A)), A)
plt.show()
df
ax.set_ylim((0, 10))
mylist.append(item)
inverse = numpy.linalg.inv(x)
df.show()
button1.config(height=WHATEVER, width=WHATEVER2)
a[-1]
[x for x in ls if ls.count(x) == 1]
ones = [x for x in l if x[1] == 1]
main()
f.close()
fout.close()
json_data = json.loads(response.text)
self.fig.canvas.draw()
termios.tcsetattr(sys.stdin, termios.TCSADRAIN, old_settings)
reverse_dict.setdefault(value, []).append(keypath)
mlab.show()
list(itertools.chain(*l2))
new_list.append(item[1])
out = [l for l in out if l]
json.loads(text)
nltk.tokenize.sent_tokenize(text)
widget_set = {tuple(sorted(widget.items()))}
self.response.out.write(photo.imageblob)
time.sleep(2)
(x[i:j] for i, j in itertools.combinations(range(len(x) + 1), 2))
[i for i, j in zip(x, y) if i == j]
driver.switch_to_window(driver.window_handles[0])
ts.ix[ts.index.indexer_between_time(datetime.time(9), datetime.time(18))]
max(max(p[1:]) for p in PlayerList)
print(os.walk(DIR_PATH).next()[1])
pool = Pool(processes=4)
plt.show()
print(aslocaltimestr(datetime.utcnow()))
plt.show()
ser.read(bytesToRead)
aa = [d[k] for k in f]
np.transpose(arr, [2, 0, 1]).reshape(5, -1)
f(lambda x, y: x + y, 1, 2)
print(etree.tostring(bar, pretty_print=False, with_tail=True))
results[i].append(benchmark(i))
unique_list.append(sorted(item))
plt.show()
newdict = {k: olddict[k] for k in goodkeys}
db.close()
plt.gca().add_artist(myline)
plt.show()
plt.show()
isinstance(n, int)
img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)
extractedData = data[:, ([1, 9])]
pylab.show()
[x[0] for x in G]
result = [y for y in (expensive(x) for x in mylist) if y]
self.connection.commit()
np.concatenate([a[(np.newaxis), :], b[(np.newaxis), :]], axis=0)
objects = ndb.get_multi([ndb.Key(Model, k) for k in ids])
filtered = [i for i in full if not regex.search(i)]
avgs = [((a + b) / 2) for a, b in zip(*([iter(data)] * 2))]
tekstboks2.pack()
plt.subplot(211)
list(permutations(list_of_tuples))
self.ax.set_xlim(0, R + pR)
deleted[k]
httpd.serve_forever()
x.shape
ts1.corr(ts2)
pkgutil - -pkgs
res.reset_index()
z = [x] + (y if isinstance(y, list) else [y])
formatdate(time.mktime(dt.timetuple()))
np.array_equiv(A, B)
relative_paths = [os.path.relpath(path, common_prefix) for path in paths]
myArray[1][1] == 2.71828
deque_slice = collections.deque(itertools.islice(my_deque, 10, 20))
fro.close()
zip(*([s] * 2))
list(itertools.chain.from_iterable(L))
clf = linear_model.LinearRegression()
x = str(something)
print((value, count))
[(len(list(g)), k) for k, g in itertools.groupby(l)]
test.append(pd.Series(200, index=[101]))
[1] * 5
str(int(value))
Dataset.objects.filter(i_end_int__gte=x, i_begin_int__lte=x)
zip(a, x)
plt.plot(x, y)
next(gen)
print(first.lower() <= second.lower() <= third.lower())
list(chain.from_iterable(a))
[(x * (2 - x % 2)) for x in a_list]
ax.plot(x, y)
instance.save()
random.shuffle(array)
X_train, y_train, X_val, y_val, X_val, y_val
p.wait()
list1 = [_f for _f in list1 if _f]
print(len(unique_values))
ax.set_xticks(np.arange(data.shape[1]) + 0.5, minor=False)
self.__init__(*args, **kwargs)
Response(status=204)
rec = lambda x: sum(map(rec, x)) if isinstance(x, list) else x
plt.figure(figsize=plt.figaspect(1))
sys.stdout.flush()
plt.draw()
print(self.bar)
nlargest(5, vector, key=itemgetter(1))
random.shuffle(s)
new_re_df = [s.iloc[np.where(ts.astype(int) == int(i))] for i in ts]
bin(10)
list(product(x, chain.from_iterable(y)))
msg.attach(MIMEText(text))
maxLPFt = max(lpfData, key=operator.itemgetter(1))[1]
BillboardTracker.objects.filter(expiry_date__le=datetime.now())
func2(**locals())
bsizer.Add(yourTxtCtrl, 1, wx.EXPAND)
sum(n for _, n in structure)
ssh.close()
do_something()
a[index] += 1
matplotlib.pyplot.show()
handler.setLevel(logging.DEBUG)
json.dumps(data, ensure_ascii=False)
a.add(2)
zip(s, s)
x[np.isnan(x)] = something_not_nan
uncompressedData = bz2.BZ2File(zipFile).read()
self.grid_columnconfigure(2, weight=1)
B = np.linalg.inv(A.T).T
nums = [int(n) for n in text.split()]
[(sum(e) / len(e)) for e in zip(*data)]
df1[df1 == 1].count()
os.getlogin()
process.wait()
sys.exit(1)
words = f.read().split()
cursor.close()
body = body.replace(block.text, hilited)
b += int(a)
br.add_handler(PrettifyHandler())
reactor.run()
writer.writerow(csvdata)
a = np.hstack(([0.2], np.linspace(1, 60, 60), [60.8]))
current_command()
pylab.hist([random_triangular(1, 6, 5) for t in range(10000)])
moving_average(a, n=4)
tf.py_func(func, inp, Tout, stateful=stateful, name=name)
result = set(x for l in array for x in l)
plt.show()
timeit([x for x in a if x in b])
ax = fig.add_subplot(111)
plt.show()
QtGui.QMainWindow.__init__(self)
d = dict((k, v) for k, v in list(d.items()) if k)
sys.exit(app.exec_())
print(soup.prettify())
fh.close()
plt.show()
df.apply(lambda x: x.apply(lambda x: [] if math.isnan(x) else x))
app.run(server=server)
arr.sum(axis=1).shape
r = [[] for i in range(4)]
df.append(df.sum(numeric_only=True), ignore_index=True)
a.get() + b.get()
lst.append(lambda x: f(x, i))
app.root.mainloop()
[x for x in L if x >= 0]
print(key, value)
setattr(module, name, value)
print(df.applymap(lambda x: x > 1))
[x[1] for x in sorted(random.sample(enumerate(myList), K))]
logging.set_up_done = True
np.hstack(results)
(a == b).sum()
newsampledata.sample(n, replace=True).reset_index(drop=True)
[sum(map(f, x)) for x in data]
sns.heatmap(data, ax=ax)
tornado.ioloop.IOLoop.instance().start()
time.sleep(0.1)
list(dict((tuple(x[:2]), x) for x in L).values())
[wordList[i] for i in indexList]
print(s.recv(1024))
sum(a[i] != b[i] for i in range(len(a)))
do_something_with(lines)
window.Minimize()
fig.canvas.draw()
fig.canvas.draw_idle()
dict.__init__(self, *args, **kwargs)
self.table.setColumnCount(5)
foundItems = (key for key, vals in list(mydict.items()) if item in vals)
root.destroy()
signal.signal(signal.SIGINT, signal.SIG_DFL)
ax.pcolormesh(x, y, z, cmap=mpl.cm.Reds)
unittest.main(*args, **kwargs)
result = map(sum, a)
pd.concat([pd.DataFrame(a), pd.DataFrame(b)], axis=1)
lst.extend([5, 6, 7])
col.find_one()
numbers = iter(list(range(100)))
my_queue.put(x)
len({s[i:i + n] for i in range(len(s) - n + 1)})
shutil.copyfileobj(buf, fd)
ftp.cwd(path)
[x for item in l for x in repeat(item, 2)]
dict(zip(headers, zip(*sdata)))
pattern.format(s)
random.shuffle(x)
virtualenv
pd.isnull(df).any()
tasklist.append(newtask)
[x for x in lst if x.lower() not in seen and not seen.add(x.lower())]
sess.run(tf.initialize_all_variables())
array([[1, 0, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0]])
log = logging.getLogger(__name__)
app.run()
html = urllib.request.urlopen(url).read()
sys.exit(0)
list(takewhile(lambda x: x < 5, list(range(5))))
p.kill()
np.array_equal(A, B)
plt.show()
Base.metadata.create_all(engine)
new_array = np.array(df.index.to_pydatetime(), dtype=numpy.datetime64)
output.close()
grid = QtGui.QGridLayout()
nodes.CallBlock([call], [], [], [])
requests.post(url, data=data, headers=headers)
grades = [x.strip() for x in files.readlines()]
lambda i: isinstance(i, int)
any(isinstance(e, list) for e in my_list)
time.sleep(5)
ssh_client = paramiko.SSHClient()
elapsed_time = time.time() - start_time
{{value | unlocalize}}
test[(1), :]
df[0].to_json()
s.getvalue()
t = tuple(lst)
math.ceil(x / 500.0) * 500.0
print(ET.tostring(graph, pretty_print=True))
zip(*[s, s])
im = Image.open(StringIO.StringIO(buffer))
test[:, (0)]
c = list(itertools.chain.from_iterable(zip(a, b)))
[item for item, flag in zip(s, b) if flag == 1]
reactor.run()
_draw_point(renderer, position, j, i)
os.path.dirname(sys.executable)
print(min(strings, key=len))
ax.set_xlim(0.5, 5)
[(x + (y,)) for x, y in zip(a, h)]
self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
sorted(mydict.items())
self.log.setLevel(logging.INFO)
[0, 1, 2]
plot(x, y, color=color)
sorted_by_medals = sorted(list_of_medals, key=lambda tup: (-tup[1], tup[0]))
Image.open(file).verify()
[x for pair in zip(l, l) for x in pair]
func(*args, **kwargs)
reactor.run()
{randint(0, 9): (v + 1) for v in list(mydict.values())}
R = np.array(mean_data[:, (0)])
layout.addWidget(QtGui.QLineEdit(self))
fcntl.flock(self.__lock_file.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
sys.exit(0)
r.grid(sticky=(N, E, S, W))
cv2.destroyAllWindows()
plt.show()
matches.append(os.path.join(root, filename))
regex.findall(filename)
a + b
print((m.span(), m.group(0)))
list(s)
[a for a, b in list(params.items())]
cur.close()
datetime.datetime.combine(tdate, datetime.time.min)
c = tuple(x - y for x, y in zip(a, b))
plt.show()
[e for sub in a for e in sub]
pygame.quit()
p.start()
dall.update(d)
X - np.dot(A, B)
Blender.Redraw()
im.wcs[::2, ::2]
min_keys = [k for k, x in list(d.items()) if not any(y < x for y in list(d.values()))]
server_socket.close()
print([key for key, group in groupby(x) if len(list(group)) > 1])
app.run(debug=True)
func()
requests.get(url, verify=path_to_bundle)
all(x[i] - x[i - 1] == x[i + 1] - x[i] for i in range(1, len(x) - 1))
app.run()
s.seek(0, os.SEEK_END)
pd.__version__
mainwin.mainloop()
plt.show()
map(tuple, np.array(list(combinations(list(range(N - 1, -1, -1)), M)))[::-1])
print(f.read())
plt.bar(x, y)
widget.deleteLater()
sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
df.columns = df.columns.str.lower()
size = fields.IntegerRangeField(min_value=-100, max_value=100)
pd.concat([df, dict_col.apply(pd.Series)], axis=1)
main()
app.run()
ax2.xaxis.set_visible(False)
now = datetime.datetime.now()
app.MainLoop()
os.remove(os.path.join(dir, f))
(dt - datetime.datetime.utcfromtimestamp(0)).total_seconds()
func(that, session=session, *args, **kwargs)
date = datetime.datetime.fromtimestamp(your_timestamp / 1000.0)
print(np.mgrid[:5, :5])
sys.stdout.flush()
root.mainloop()
numpy.random.seed(0)
window.mainloop()
pprint(stiff)
AB = [(A[i] + B[i]) for i in range(len(A))]
wx.Frame.__init__(self, *args, **kwargs)
plt.subplot(2, 1, 2)
sys.exit(app.exec_())
plt.legend(loc=0)
f_in.close()
print(a[s])
[[y for y in x if y not in to_del] for x in my_list]
time.sleep(0.05)
[t for t in tuples if all(f(t) for f in filters)]
json.loads(json.loads(b))
plt.show()
[(1, 5), (8, 11), (200, 202)]
my_dict = {k: (v if len(v) > 1 else v[0]) for k, v in list(tmp.values())}
dict1.update((k, dict2[k]) for k in keys)
list(itertools.combinations(items, 2))
pid, stdin, stdout, stderr
MyDiccoSorted = sorted(list(MyDicco.items()), key=lambda x: x[1][0])
time.mktime(datetime.datetime.now().timetuple()) * 1000
ax.collections
data = [float(fractions.Fraction(x)) for x in data]
doc = lxml.etree.parse(xml)
(s[i:j] for i in range(length) for j in range(i + 1, length + 1))
my_list.remove(4)
scipy.array(x).ravel().tolist()
name = models.CharField(max_length=255)
itertools.chain.from_iterable([i] * i for i in range(1, 5))
l.append(x[:len(x) - k])
b = a[0][:]
data = p.stdout.readline()
plt.show()
[element for tupl in tupleOfTuples for element in tupl]
GC.remove_edge(clique[0], clique[1])
new_list = [{transform[k]: v for k, v in list(d.items())} for d in old_list]
pylab.show()
np.place(arr, ~np.in1d(arr, valid), 0)
conn.send(stranza)
pil_im = Image.open(strio)
fig.canvas.draw()
plt.show()
(A == B).all()
startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
date += datetime.timedelta(days=1)
cbar.set_clim(newimg.min(), newimg.max())
writer.writerows(sheet.row_values(row) for row in range(sheet.nrows))
f = (lambda a, b, c: lambda x: a + b * c - x)(a, b, c)
[a for a in x if a != 2]
s1[s1.isin(s2)]
pygame.event.poll()
data = json.loads(resp.text)
sorted(lst)[-20:]
pptable(x_axis, y_axis, a.tolist())
rescaled = np.uint8(b)
exec(open(filename).read())
s.reset_index()
list(set([(a, l.count(a)) for a in l]))
b = np.fill_diagonal(np.zeros((N, N)), value)
QtCore.QThread.__init__(self)
session = request.session
numpy.matrix(numpy.identity(n), copy=False)
list(itertools.product(*arrays))
bytearray(random.getrandbits(8) for _ in range(size))
fig.subplots_adjust(bottom=0.2)
a.A * ~mask.A
sorted(array, key=lambda x: x[:24])
print(mirror([mirror(sublist) for sublist in inputs]))
deletemydict[k]
object_list.sort(key=lambda x: string_list.index(x.key))
list(itertools.zip_longest(fillvalue=0, *lists))
driver.find_element_by_id(tc.value).click()
cherrypy.engine.block()
pixbuf = pixbuf.scale_simple(width, height, gtk.gdk.INTERP_BILINEAR)
plt.draw()
pprint({k: getattr(f.__code__, k) for k in dir(f.__code__)})
[x for x in lst if x % 2]
plt.scatter(x, y, c=t, cmap=cm.jet)
deletemy_dict[key[-1]]
time.sleep(0.1)
print(uuid.uuid4())
A[~np.isnan(A)].mean()
P[np.arange(n), x, y]
form = ContactForm()
numbers.append(random.randint(a, b))
client.close()
s.index(t.lower())
pygame.mouse.get_pos()
t = s.reshape(-1, k)
random.shuffle(l, random.random)
temp.iloc[[0, 1, 4]].index.tolist()
urlfetch.set_default_fetch_deadline(60)
print([(x - empty) for x in test])
sys.exit(0)
float(s)
time.sleep(1)
plot(x, sin(x) * cos(x))
[x for x in range(m) for y in range(n)]
request = client.read_holding_registers(0, 4, unit=1)
zlib.decompress(data)
print(line.rstrip())
sorted(list(counts.items()), reverse=True, key=lambda tup: tup[1])[:top]
df.stack(0).reset_index(1)
app.exec_()
datetime.now()
time.sleep(1)
log.start()
out = (m[1:] > m[:-1]).sum() + m[0]
plt.show()
list(filter(os.path.isdir, os.listdir(os.getcwd())))
df.columns[df.isnull().any()].tolist()
ax.scatter(x, y, zflat)
mean, sigma = a.mean(), a.std()
tk.Text.__init__(self, *args, **kwargs)
df.groupby(df.index).max()
a = np.arange(10)
d = ast.literal_eval(some_string)
dict(list(dict1.items()) + list(dict2.items()))
plt.show()
obj = session.query(ObjectRes).order_by(ObjectRes.id.desc()).first()
plt.ylim([-0.5, 1.5])
indices = [i for i, x in enumerate(myList) if re.match(regex, x)]
Series(df.values.ravel()).unique()
plt.ylim(-1, 1)
driver.close()
pyodbc.connect(connect_string, autocommit=True)
self.widget_name.deleteLater()
len(set(len(x) for x in l)) <= 1
val = img.getpixel((x, y))
a = [a]
filename = str(uuid.uuid4())
D()
foo = decorator(foo)
time.sleep(2)
a = [0] * 10000000
df.reindex(columns=cols)
tags = json.loads(s, object_pairs_hook=collections.OrderedDict)
A = map(lambda t: list(t), A)
img = client.images.get(IMAGE_ID)
text.splitlines()[0]
self.response.out.write(template.render(path, template_values))
raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), filename)
file.close()
time.sleep(0.01)
print(getglobals(f))
max(set(lst), key=lst.count)
ExampleApp().run()
author = models.CharField(max_length=60)
sys.stdout.flush()
plt.axis([min(x_arr), max(x_arr), max(y_arr), 0])
[myfunc(x, y) for x, y in myiter(data)]
all(bb[k] == v for k, v in aa.items() if k in bb)
plt.show()
datetime.date.fromordinal(datetime.date.today().toordinal() - 1)
plt.plot(x, y)
root.destroy()
set(x)
x[:, (i)] = np.roll(x[:, (i)], i)
p1.stdout.close()
print(cmp(list1, list2))
self.main.show()
plt.show()
Gtk.main()
dict(zip(unique, counts))
sorted(lst, key=str.lower, reverse=True)
sorted(myList, key=itemgetter(1))
p.wait()
results = dict.fromkeys(inputs, [])
[indexes[x] for x in l]
f = x ** 2 + 1
self.list_of_strings.append(str_to_add)
words[word[0] + word[-1]].append(word)
s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
self.a = a, self.b = b
sock.setsockopt(socket.IPPROTO_TCP, TCP_KEEPALIVE, interval_sec)
plt.show()
plt.show()
(i * i for i in range(5))
call([command, parameter])
pyplot.show()
d[key][0] = x
(dt.replace(month=dt.month % 12 + 1, day=1) - timedelta(days=1)).day
plt.close()
dtyp = np.dtype(list(zip(X.dtypes.index, X.dtypes)))
driver = webdriver.PhantomJS()
print(match.group(0))
time.sleep(float(sys.argv[1]))
np.where(~a.any(axis=1))[0]
[z0] * len(seconds)
a[-1] * (a[-1] + 1) / 2 - sum(a)
50 - List1[0][0] + List[0][1] - List[0][2]
ax.plot(x, y)
shutil.copy2(src, dst)
client.disconnect()
df = df.loc[mask]
m.save()
[i for i, _ in itertools.groupby(ks)]
entity.key().id_or_name()
ax.set_ylim([-1, 10])
np.reshape(data, newshape=(len(data) / 5, 5))
self.Bind(wx.EVT_ERASE_BACKGROUND, self._onEraseBackground)
1, 0, 1, 0, 0, 0, 0, 0, 1, 0
plt.show()
pd.rolling_mean(aapl, 200).plot()
counts = Counter(sentence.lower().split())
df[~pd.isnull(df[list_of_cols]).all(axis=1)]
df.apply(lambda x: x.apply(lambda x: [] if isnan(x) else x))
min(t, key=lambda i: (i[1], -i[2]))
ax.autoscale()
response = br.submit()
string_list.sort(key=lambda s: len(s), reverse=True)
plt.show()
next((i, d) for i, d in enumerate(lod) if 1 in d)
sorted(l, key=lambda name_score: int(name_score[1]), reverse=True)
rows = table.tbody.find_all(True, recursive=False)
time.sleep(0.1)
replace(my_dict)
json.dumps(c.__dict__)
response = urllib.request.urlopen(req).read()
np.random.shuffle(arr)
f.write(data)
foo = Foo()
first2vals = [mydict[k] for k in sorted(mydict.keys())[:2]]
root.mainloop()
next([i for i in userInput if i in wordsTask])
QtGui.QDialog.__init__(self, parent)
numpy.linalg.lstsq(a, b)
browser.submit()
[(entry if tag in entry else []) for tag in tags for entry in entries]
plt.show()
element.clear()
conn.commit()
A.test()
QMainWindow.__init__(self)
s.sendmail(sender, recipients, msg.as_string())
map(id, a)
proc.stdin.close()
y *= np.hanning(len(y))
a.shape
np.where(np.triu(np.ones(A.shape[0], dtype=bool), 1), A.T, A)
np.reshape(self.data, newshape=(self.data.shape[0] / 5, 5))
print(sum(iter(lambda : len(sys.stdin.read(4096)), 0)))
contents = self.view.substr(sublime.Region(0, self.view.size()))
sorted(new_lst, reverse=True)
gevent.sleep(5)
print(expr.evalf(subs=dict(a=2, b=4, n=5)))
np.where(arr == arr.min())
a.__getitem__(slice(0, 1)).__setitem__(0, 1)
lst_gen = sum([(i, i * i) for i in range(1, 10)], ())
os.lseek(fd, 0, os.SEEK_SET)
logging.getLogger().setLevel(logging.DEBUG)
parser = argparse.ArgumentParser()
dict.fromkeys(my_list, 0)
plt.show()
pool.join()
bin(int(binascii.hexlify(st), 16))
np.sqrt(((A - B) ** 2).sum(-1))
print(json.dumps(out))
plt.show()
list({t[1]: t for t in reversed(l)}.values())
ax.add_artist(rect)
web.HTTPError.__init__(self, status, headers, data)
ax.set_xticks(list(range(0, 11)))
img = cv2.imdecode(nparr, cv2.CV_LOAD_IMAGE_COLOR)
value.Increament()
it = heapq.nlargest(20, allrows, key=lambda x: x[2])
df1.merge(df2)
[(((x - 1) % 8 + 2) * x) for x in range(1, 21)]
pyl.draw()
converted_text = pattern.sub(lambda m: format_term(m.group(0)), text)
ax[1].autoscale(True)
time.sleep(1)
Z = Y.transpose(1, 2, 0)
{k: d1[k] for k in d1.keys() & l1}
plt.show()
x.loc[(x.B >= 111.0) & (x.B <= 500.0)]
dict(y, **x)
list_.sort(key=lambda x: len(x[1]))
server.login(user, password)
array([[1, 2], [0, 2]])
Note.objects.filter(created__year=years.year)
np.nonzero(starts)[0], np.nonzero(ends)[0]
plt.show()
print(p.stdout.read())
print(handle.read())
[el for el in lst if isinstance(el, collections.Iterable) and st in el]
random.shuffle(keys)
print(test[numpy.in1d(test[:, (1)], wanted)])
int(numberA), int(numberB)
np.linalg.lstsq(a, b)
somelist.sort(cmp=lambda x, y: cmp(x.resultType, y.resultType))
common_keys = list(dict_a.keys() & dict_b.keys())
set(df.Col1).union(set(df.Col2))
s.decode(encoding)
[c for c in words if not c.isalpha() and not c.isdigit() and not c.isspace()]
[d[x] for x in a]
float(1.001).is_integer()
foo()
self.user.get_full_name()
self.Bind(wx.EVT_CHAR_HOOK, self.hotkey)
arr[1, -2]
image[idx] = chex[idx]
print([tuple(t[1] for t in v) for k, v in groupby(myList, key=itemgetter(0))])
p.kill()
ax1.legend(loc=2)
match = re.search(re.escape(string), text)
f.close()
list(my_dataframe)
finalPath = os.path.abspath(os.path.join(p.netloc, p.path))
root.mainloop()
[k for k, v in list(my_counter.items()) if v > 1]
df = pd.concat(list_of_series, axis=1).transpose()
driver.switch_to_window(driver.window_handles[1])
sys.stdout.write(chr(c + 48))
equation1(*list_of_parameters)
bool(set(a) & set(b))
os.kill(pid, 0)
self.create_socket(socket.AF_INET, socket.SOCK_STREAM)
print(line)
Player.objects.filter(Q(games1__pk=self.pk) | Q(games2__pk=self.pk))
values = json.loads(data)
np.triu(A.T, 1) + A
x = rnorm(n=100, mean=0, sd=1)
l.append((4, 5))
ax.set_xlim([-1, 10])
[[j.span() for j in rex.finditer(i)] for i in sequence_list]
browser.set_window_size(1400, 1000)
map(math.log10, x)
sorted(tuples, key=lambda x: (x[0], x[2]))
A[np.isnan(A)] = 0
froms[p[0]].append(p)
result = np.array([list(g) for _, g in groupby(a)])
BeautifulSoup(r.content).title.text
out = np.concatenate(input_list).ravel()
(area_width - string_width) / 2
urlparse.urljoin(url, urlparse.urlparse(url).path)
mrg.drop(drops, axis=1)
list(compress(seq, criteria))
x = 256 * ord(pS[0]) + ord(pS[1])
xvfb.terminate()
(e.T / e.sum(axis=1)).T
pylab.show()
[0, 1, 0, 9, 0, 25, 0, 49, 0, 81]
quit_gracefully()
a += b[idx].sum(0)
d = np.array(dataPoints.tolist())
posts = TodaysObject.objects.filter(datafilter)
first2vals = [v for v in list(mydict.values())[:2]]
np.random.shuffle(A)
plt.legend()
data[0]
s.close()
cls.objects.get(pk=self.pk)
d2 = dict((k, v) for k, v in list(d1.items()) if v > 0)
[1, 1]
z = dict(itertools.chain(iter(x.items()), iter(y.items())))
np.median([2, 0, 1, 0, 0])
B[X.ravel()] = A.ravel()
print([k for k, v in d.items() if v == 1])
draw()
runserver.py
plt.plot(x, f(x), zorder=1)
redirect(client.authorize_url)
urllib.request.urlopen(url, postData)
plt.show()
df[df.ix[:, 2:].abs().lt(1).all(1)]
k.set_contents_from_string(data_file.readlines())
df.reindex(idx)
subprocess.Popen([name], stdout=devnull, stderr=devnull).communicate()
reactor.run()
gtk.main()
print(dt.year, dt.month, dt.day)
assert Implementation().frobnicate()
timedelta(hours=6) / 2
self.modules = []
df1.merge(df2)
setattr(self, k, v)
os.unlink(path)
plt.show()
sys.exit(app.exec_())
l[i].append(j)
ax.plot(list(range(10)))
np.argwhere(M.T == 0).squeeze()
df_html = df.to_html()
print(list(set(tuple(i) for i in a)))
browser.get(url)
x.reshape(2, 2, 2, 2).swapaxes(1, 2).reshape(4, -1)
mpl_plt.show()
con.close()
locals().update(parm)
result = DataFrame(result).reset_index(drop=True)
type(b) is Test1
map(list, set(map(tuple, k)))
d = {t.key: t for t in [t0, t1, t2]}
b.shape
any(x in someDict for x in someList)
dists /= dists.max(axis=(0, 1))
d = dict((k, tuple(v)) for k, v in d1.items())
time.sleep(0.5)
plt.show()
array1.reshape(array2.shape)
l.pop(0)
b = map(lambda x: x[:9], g)
os.path.join(path, format)
app.mainloop()
plt.clf()
np.random.choice(np.flatnonzero(b == b.max()))
instance.save()
print(np.allclose(r[1], b))
list(d.keys())
parse_freebase_quadruple_tsv_file(file_name)
first2pairs = {k: mydict[k] for k in list(mydict.keys())[:2]}
writer.close()
[(i, z) for i in [1, 2] for z in zs_i]
((x, y) for x in range(width) for y in range(height))
pylab.show()
ax.set_yticks([])
cursor.execute(sql, args)
d[cols[0]] = dict((headers[idx], v) for idx, v in enumerate(cols[1:]))
sys.exit(app.exec_())
group[group.apply(lambda x: len(x) > 1)]
root.mainloop()
random.shuffle(itrange)
winfile.close()
self.exec_()
result[i].append(j)
avgs[np.where(binplace == 1)]
self.user_set.all()
sys.exit()
sess.run(train_op)
random.randint(1, 6)
server.mainloop()
tree = soupparser.parse(StringIO(text))
a = numpy.nan_to_num(a)
my_file.copy(to_file)
Py_Finalize()
find_eulerian_tour(cg4)
df[-mask.any(axis=1)]
capture = cv.CaptureFromCAM(-1)
deletetest[2]
b += [c]
plt.gcf().axes[0].xaxis.set_major_formatter(formatter)
rdd = df.rdd
plt.show()
print(doc.toxml())
plt.plot(xs, density(xs))
numpy.column_stack((a, b, c))
A - mean[:, (np.newaxis)]
grid[[a[second_mask] for a in np.where(mask)]] = 100
func()
fcntl.ioctl(s.fileno(), SIOCGIFFLAGS, ifr)
auth_login(request, user)
a[0, 1, 2]
print((key, values))
frame.axes.get_xaxis().set_ticks([])
ax2.contour(theta_edges[:-1], r_edges[:-1], H)
BASE_DIR = os.path.dirname(os.path.dirname(__file__))
print(t.total_seconds())
map(len, s.split())
max(set(list), key=list.count)
ax1.yaxis.tick_left()
foo = _log_error(logger)(partial(bar, someparam))
input_list = [int(a) for a in input_list]
urllib.request.install_opener(opener)
self.box.grid(column=0, row=0)
sys.exit(0)
request.session.set_expiry(request.session.get_expiry_age())
dict([(an_object.name, an_object) for an_object in object_list])
sys.exit()
render_to_response(your_custom_template, ctx)
df.ix[0]
draw.text((10, 0), txt, (0, 0, 0), font=font)
layout.addWidget(self.lineedit)
ax.add_patch(polygon1)
a.split()
[9.444064187694842, 1.2256912728995506]
{{jsonData | safe}}
not seen.add(x)
f.close()
{x: (x * x) for x in range(10)}
bydiscra = sorted(promotion_items, key=bydra)
sys.stdout.write(data)
plot(X, Y)
wx.Dialog.__init__(self, *args, **kwds)
datetime.timedelta(hours=-5)
time.mktime(now.timetuple())
table = [row for row in data]
time.sleep(10)
tuple(l.T)
mngr.window.setGeometry(newX, newY, dx, dy)
isinstance(b, Test1)
my_file.seek(0, os.SEEK_END)
[s[i:j] for i, j in zip_longest(start, end)]
np.random.shuffle(b)
writer.writerows(new_rows)
print(list(matdata.keys()))
con.close()
reverse(str1[1:]) + str1[0]
fig.canvas.draw()
print(simplejson.loads(json_string))
__init__.py
self.canvas.draw()
{{form.certification()}}
[ComVisible(true)]
df = pd.concat(list(pd.read_csv(Reader(gen()), chunksize=10000)), axis=1)
len(haystack) - len(parts[-1]) - len(needle)
sorted(l, key=lambda x: (x[:-1], x[-1].isdigit(), x))
dict(widget_set.pop())
plt.show()
s.group(0)
list(q)[0]
print(lilfoo.baaz)
sorted(l, key=lambda x: float(x[1]))
self.button.pack()
print(regex.search(data).groups())
sys.exit()
diag = [mat[i][i] for i in range(len(mat))]
ax.plot_surface(X, Y, Z)
matching_lines = [line for line in string_list if filter_func(line)]
plt.show()
print([n for n in (x.giveMyNum() for x in q) if n > 1])
L2.sort(key=lambda x: L.index(x))
int(log10(x)) + 1
mySet = set(x[0] for x in TUPLES)
suspect = {}
os.kill(9999999999999, 0)
user.profile.save()
Foo.__init__.__self__.__class__
print(track.permalink_url)
a, b = int(a), a - int(a)
plt.show()
newlist.append(i)
np.frombuffer(test)
dict([(k, v) for k, v in list(mydict.items()) if k >= 6])
l[:1] + [b for a, b in zip(l, l[1:]) if a != b]
left.remove(left[0])
local_file.write(f.read())
[seq for seq in my_list if [item for item in seq if some_condition()]]
server.serve_forever()
print(key, d[key])
model_to_dict(instance, fields=[field.name for field in instance._meta.fields])
sys.exit(0)
{k: min(h1.get(k) or h2[k], h2.get(k) or h1[k]) for k in list(h1.keys()) + list(h2.keys())}
platform.system()
sorted(A, key=A.get, reverse=True)[:5]
stdout, stderr = p.communicate()
[age] = [t[1] for t in mylist if t[0] == 10]
comb = list(comb)
Publication.objects.all().delete()
[(a, b) for a in A for b in B if a in b]
number = random.randint(5, 20)
some_queue.get()
re.findall(s, text)
np.min(np.nonzero(np.hstack((B, 1))))
m = coo_matrix((v, (l - 1, c - 1)), shape=(l.max(), c.max()))
uppers = [l for l in letters if l.isupper()]
func(func, *args, **kwargs)
pygame.display.flip()
reactor.run()
c.setopt(pycurl.WRITEFUNCTION, lambda bytes: len(bytes))
unsure_rows[key].append(row[key])
(item for sublist in list_of_lists)
numpy.digitize(b, a)
cleaned = [_f for _f in map(str.strip, words) if _f]
ax.set_xlim(-10, 10)
app.MainLoop()
p = sparse.dia_matrix(1.0 / np.array(x), shape=(len(x), len(x)))
numpy.array([0.24])[0] == 0.24
type(list(d.values()))
X = 1
self.assertEqual(content, expected_content)
s = pd.Series([0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1])
glob.glob(name)[0]
result_dict = [u.__dict__ for u in my_query.fetchall()]
curses.endwin()
time.sleep(1)
getattr(filters, method)(**options)
driver.switch_to_window(driver.window_handles[-1])
{k: map(sum, zip(*v)) for k, v in list(d.items())}
a[:, (1)]
reactor.run()
newNums = [i for i, x in enumerate(nums) if x == 12]
os.close(fh1)
fig = plt.figure(figsize=(6, 6))
now = datetime.now()
s.play()
werte[1:-1][(diff(werte)[:-1] > 0) * (diff(werte)[1:] < 0)]
numpy.unravel_index(A.argmin(), A.shape)
f.__dict__.update(b)
sys.stdout.buffer.write(pdf_file.read())
ax.xaxis.set_minor_locator(MultipleLocator(0.2))
df = df[df.columns[:11]]
[True, True, False, True, True]
f = lambda *x: sum(x) - 1
print(dir(__builtins__))
contents = urllib.request.urlopen(request).read()
print(args)
ax.yaxis.set_ticks([16, 8, 4, 2, 1, 0])
numpy.reshape(array, array.shape + (1,))
min(timeit.repeat(lambda : dict((k, v) for k, v in zip(keys, values))))
user = models.ForeignKey(User)
deletex[i + 1:]
self.setWindowFlags(Qt.FramelessWindowHint)
list[0].pop(0)
req.close()
[x[0] for x in sorted(data, key=lambda x: x[1], reverse=True)[0:6]]
pdb.set_trace()
degs = degrees(rads)
[elem[:12] for elem in g]
plt.show()
setattr(module_obj, method_name, func)
self.clickcnx.close()
dict1 = {x: dict1[x] for x in keys}
df.reindex(approach1(df.A.values, df.B.values))
re.findall(pattern, s)
pd.tslib.repr_timedelta64
app.run(debug=True)
next((x for x in lst if x % 2 == 0))
self.assertDictEqual(a, b)
problem = importlib.import_module(sys.argv[1])
b.insert(bisect(b, a), a)
union([(10, 12), (9, 16)])
f.write(line)
build_stylus()
br.set_response(response)
contours, _ = cv2.findContours(img, cv2.RETR_LIST, cv2.cv.CV_CHAIN_APPROX_NONE)
[k for k, v in list(mydict.items()) if list(mydict.values()).count(v) > 1]
pygame.init()
dev.leds(verbose=True)
[sum(sublist) for sublist in zip(*myListOfLists)]
last_row = df.ix[df.last_valid_index()]
pygame.init()
ax = fig.add_subplot(111)
res = cv2.bitwise_and(closex, closey)
print(__file__)
plt.show()
eval(x)
cv2.destroyAllWindows()
c = [[(x + b[i]) for i, x in enumerate(y)] for y in a]
funkytown._asdict()
my_string = my_string.replace(k, v)
fig, ax = plt.subplots()
print(read_records(data))
Foo().bar()
glUniform1i(self.tex2D, 0)
list.__getitem__(self, index)
print(parser.parse(treebank.sents()[0]))
numpy.vstack((x, y))
[[], []]
ax.set_xticks(xticks)
button.clicked.connect(lambda : self.commander(command))
l[0][0] += 1
height = img.get_height()
tree.removeItemWidget(i, 0)
fig.canvas.draw()
sys.getsizeof(i)
print(fibonacci(int(eval(input()))))
birth_years = dict(zip(name, year))
ax = fig.add_subplot(1, 1, 1)
d = {b: a[:, (i)] for i, b in enumerate(a)}
tk.mainloop()
f.write(content)
TextCtrlInstance.GetValue()
np.flatnonzero(~a[:-2] & a[1:-1] & a[2:])
asdf.save()
plt.ylim(10, 40)
libdl.dlclose(handle)
Z = func(X, Y)
plt.show()
ax.set_yticklabels(y_label, fontsize=20)
cursor.execute(qry, list(myDict.keys()) + list(myDict.values()))
os._exit(0)
random.shuffle(r)
my_treeview.setEditTriggers(QAbstractItemView.NoEditTriggers)
total = value[c1 - 1] + value[c2 - 1]
plt.show()
df.groupby(level=0, sort=False).transform(lambda x: sorted(x, key=pd.isnull))
print(lxml.etree.tostring(doc))
m.mask = np.repeat(i == j, k.size, axis=2)
subversion.search(s).group()
raise AssertionError(expression2)
frames.append(pandas.DataFrame(row))
np.sqrt((a * a).sum(axis=1))
QtGui.QWidget.__init__(self)
print(os.path.abspath(my_module.__file__))
plt.show()
self.view.setModel(self.model)
random.shuffle(word)
img_as_np = np.asarray(img.getdata()).reshape(img.size[1], img.size[0], -1)
data.setdefault(k, []).append(v)
self.func(*args, **self.kwargs)
print(y.max())
df.apply(OrderedDict)
print(list(date_range(5, 2)))
QMainWindow.__init__(self, *args)
phrase.strip().capitalize()
min_keys = [k for k in d if d[k] == min_value]
list(choice(json_obj[k]).values())[0]
df.head()
df.plot(subplots=True)
[tuple(d.values()) for d in l]
time.sleep(1)
sys.path.insert(0, p)
plt.show()
sys.stdout.write(next(spinner))
new_lst.append(x)
sys.stdout.flush()
curses.endwin()
PyErr_Clear()
np.asarray(np.bmat([[A, Z], [Z, B]]))
ax.add_patch(polygon2)
sock.bind((UDP_IP, UDP_PORT))
nodeenv - -python - virtualenv
p.wait()
[(sum(group) / size) for group in zip(*([iter(data)] * size))]
list(itertools.product(*l))
helloworld.helloworld()
plt.show()
pd.to_numeric(s)
sum(x > 7 for x in a)
abs(n)
df = pd.read_csv(io.StringIO(string), delim_whitespace=True)
ax = pylab.gca()
p.stdin.close()
file.close()
threading.Timer(60, f).start()
plt.show()
self.create_socket(socket.AF_INET, socket.SOCK_STREAM)
x[0].append([])
l = list(t)
obj.func1()
list_of_nums = [x for x in list_of_nums if x != 2]
HttpResponse(html)
sys.stdout.flush()
sum(bool(x) for x in l)
c = np.in1d(a, b)
diag = [row[i] for i, row in enumerate(mat)]
[0, 0, 0, 0, 1, 1],
pygame.quit()
self.sections.clear()
all(a % i for i in range(2, a))
sys.stderr = logger
sys.exit(100)
time.sleep(10)
[[item for item in seq if some_condition] for seq in my_list]
list(range(start, end, step))
conn.close()
proc.wait()
plt.plot()
plt.show()
PyObject_HEAD_INIT(NULL)
age = models.IntegerField()
print(response.status_code)
main()
sorted(iter(cityPopulation.items()), key=lambda k_v: k_v[1][0], reverse=True)
f.write(bytes(bin_array))
sum([i for i in l1 if isinstance(i, int)])
np.meshgrid(x, x, sparse=True)
df.iloc[0:2, :]
logging.getLogger().addHandler(console_handler)
app.MainLoop()
max([x for x in ls if x < 0])
data = numpy.arange(5 * 4).reshape(5, 4)
all(x * y > 0 for x, y in zip(l1, l2))
app.MainLoop()
f = lambda x: x[0] * x[0] * x[0] + x[1] * x[1]
datetime.datetime.date(2011, 1, 1)
self.grid_columnconfigure(0, weight=1)
sleep(1)
plt.xlim(0, 125)
min_unfairness = min(num[i + k - 1] - num[i] for i in range(n - k + 1))
logger = logging.getLogger(__name__)
print([int(x) for x in T1])
A[~np.in1d(A.dot(cumdims), B.dot(cumdims))]
[x for x, y in groupby(L) if len(list(y)) < 2]
plt.scatter(x, y)
TimeModel.objects.create(time=td.total_seconds())
__init__.py
df.columns[pd.isnull(df).any()].tolist()
a = [([0] * 8) for _ in range(8)]
print(binascii.hexlify(content))
now.replace(minute=0, hour=0, second=0, microsecond=0)
p.wait()
plt.show()
sys.exit()
writer.writerows(rows)
time.sleep(5)
lines = set(f.readlines())
float(x)
sys.path.append(dirname(__file__))
all(x == L[0] for x in L)
[a for a in s if s.count(a) == 1]
fig, ax = plt.subplots()
np.multiply(a, b)
result = [separator.join(map(str, x)) for x in product(*lists)]
[name for name in data1 if name in data2]
reversed_arr = np.swapaxes(np.swapaxes(arr, 0, k)[::-1], 0, k)
df.drop_duplicates()
server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
writer.close()
print(imap_conn.list())
plt.show()
os.path.dirname(sys.argv[0])
json.dumps(data)
[[random.random() for i in range(N)] for j in range(M)]
src.close()
gtk.main()
len(a) / np.sum(1.0 / a)
datetime.date.fromtimestamp(ts).month
df.divide(df.ix[0] / 100)
df.apply(lambda x: sum(x.isnull().values), axis=0)
print(json.dumps(e, cls=new_alchemy_encoder(), check_circular=False))
print(d.get(frozenset((2, 1))))
time.sleep(5)
l = [d for d in days if d.weekday() in [1, 2]]
barbar.py
[x for i, x in enumerate(y) if i != 1]
s.lstrip(punctuation)
data = urllib.request.urlopen(url).read()
wav_file.close()
ax.legend()
x()
os.rename(os.path.join(base, old_name), os.path.join(base, new_name))
plt.show()
ax.scatter(x, y, c=c, cmap=cmap)
chain.from_iterable(combinations(s, r) for r in range(1, len(s) + 1))
np.vstack(a)
ftpc.close()
fig.tight_layout()
ax.set_ylim(0, 10)
Response(serializer.data)
ax.set_xlim(0, 20)
plt.legend()
kNN1.fit(data, class_labels)
df.index
reg = conn.fetchall()
a = a[(a >= -100) & (a <= 100)]
datetime.datetime.fromtimestamp(1004256400)
p2 = Process(target=f, args=(d,))
self.finish()
p.terminate()
a.reshape(-1, np.prod(a.shape[-2:]))[:, ::-1].reshape(a.shape)
df.max(1)
matches.append([os.path.join(root, filename), error])
sock.connect((address, port))
func()
__init__.py
fig.close()
time.sleep(5)
R2a.__init__(self)
map(int, sum(map(lambda x: list(str(x)), lst), []))
plt.plot(x, x)
app.mainloop()
Series(df.Letter.values, index=df.Position).to_dict()
df.prod(axis=1)
l.sort()
dicts.flatMap(lambda x: list(x.items()))
sorted(li, key=lambda x: x[1])
[myfunc(a, b) for a, b in zip(idata, idata)]
sum(data[x::size] for x in range(size)) / size
root.overrideredirect(True)
[np.max(arr) for arr in np.split(v, np.where(mask)[0] + 1)]
r = client.post(URL, data=login_data, headers=dict(Referer=URL))
setattr(self, name, value)
print(top[0][1][2])
random.seed(1)
np.histogramdd(data, bins=(2, 2, 2))[0]
numpy.count_nonzero((25 < a) & (a < 100))
a += numpy.histogram(b, numpy.arange(len(a) + 1))[0]
surface = pygame.Surface((100, 100))
sorted(arr[ind])
response = view(request)
a[np.isfinite(a)]
ax.xaxis.set_major_locator(MultipleLocator(20))
np.eye(d.shape[1]) * d[:, :, (np.newaxis)]
time.sleep(1)
plt.show()
imageblob = db.BlobProperty()
dict(d1, **d2)
clf.fit(X_train, y_train)
local_dt = datetime.datetime.fromtimestamp(timestamp)
[(0) for _ in range(10000)]
string.format_map({k: Pluralizer(v) for k, v in list(data.items())})
[c for c in df]
ax.set_navigate(False)
data = json.loads(response.body)
dict((c, string.count(c)) for c in string)
sys.path.insert(0, p)
self.stdout.write(data)
dropped_copies = [[x[i] for x in copies[i]] for i in range(2)]
temp[::-1].sort()
[peaks([x, y]) for x, y in zip(xscat, yscat)]
[1, 4, 7]
fig.tight_layout()
[(arr[i], arr[-i - 1]) for i in range(len(arr) // 2)]
sys.exit(app.exec_())
df.loc[df.A.isin(a)]
list(_)
print(output[0])
[[1, 5], [6, 11]]
time.sleep(5)
print(argparse._sys.argv[0])
pd.DataFrame(data)
suite = unittest.TestSuite()
root.mainloop()
driver.manage().timeouts().pageLoadTimeout(15, TimeUnit.SECONDS)
matches.extend(isbn.findall(line))
y[:, ::2]
OrderedDict(items)
beginnings = numpy.where(diffs == 1)
time.sleep(0.1)
a = np.array(a)
application = wsgi.WSGIHandler()
a = a.clip(min=0)
threading.Thread.__init__(self)
lambda x, y: set([x]) == (y if b else lambda x, y: x in y)
main()
plt.show()
random.randrange(100, 20001, 100)
plt.figure(figsize=(10, 7))
print(m.group(1))
cv2.waitKey(0)
pos = nx.spring_layout(G, k=0.15, iterations=20)
f.close()
results.append((url, urlopen(url).read()))
ax2.set_xlim([0, repeat_length])
root.mainloop()
array = list(range(numCase))
list(solve(4))
plt.show()
convertfile.write(line)
match.start(1)
plt.show()
np.put(a, np.ravel_multi_index(idx.T, a.shape), 5)
stackless.run()
np.argmax(np.random.multinomial(1, a, 1))
lin.split()
print(dict(zip(keys, zip(*data))))
result = [dishes[key] for key in list(crucial.keys()) & list(dishes.keys())]
df
A.dot(B).dot(C)
sorted(points)
1 / 2
solution.sort_index()
df.isnull().any()
data = data.groupby(data.index).sum()
memory2.clear()
numpy.hstack((x, y))
sums = [sum(subseq) for subseq in subseqs]
[datetime.date(2010, 2, 27), datetime.date(2010, 2, 28)]
f2.write(lines[i + 2])
print(os.walk(DIR_PATH).next()[2])
sys.stdout.write(os.read(stdout.fileno(), 1024))
[line[i:i + n] for i in range(0, len(line), n)]
PROJECT_PATH = os.path.dirname(os.path.abspath(__file__))
Point(x, y)
ax = fig.add_subplot(211)
queryset = MyModel.objects.all()
my_python_object = my_qvariant.toPyObject()
db.session.add(new_provider)
threading.Thread(target=play_audio).start()
Counter(words).most_common(10)
np.where(np.array([0, 1]))
[100, 10, 20]
cur.execute(query, args)
df = df.sort()
max(l_one + l_two)
gnuplot.stdin.flush()
ppf(q, loc=0, scale=1)
to_file.write(replacement_line)
ax.yaxis.set_major_locator(MultipleLocator(0.5))
pylab.show()
hatch_path_stroke.width(1.0)
__init__.py
s.apply(pd.to_datetime, dayfirst=True)
locals()[string1 + string2]()
print ()
popt, pcov = scipy.optimize.curve_fit(func, x, ynoisy)
np.mean(gp)
df[df.groupby(level=0).transform(np.size).gt(1).values]
combo.focus_set()
ws.write(rowi, coli, float_if_possible(value))
sys.exit(app.exec_())
fig.canvas.draw()
df.sort_index(inplace=True)
np.count_nonzero(a[:2, :2])
df[cols] = np.where(df[cols] < 0, np.nan, df[cols])
remove_extras_and_sort(my_list)
signal.signal(signal.SIGINT, signal_handler)
d[len(lst)] += 1
sets = [(myList[i - 1], j) for i, j in enumerate(myList) if j == 9]
time.sleep(10)
game = models.ForeignKey(Game)
new_instance.save()
br.set_handle_redirect(True)
p[i:j] = list(sorted(p[i:j]))
text_classifier.fit(X_vectorized, y_train)
salesdata.Outlet_Size.dropna().unique()
l.extend(map(int, (w for w in line.split() if w.isdigit())))
{{person.get_gender_display}}
instance.save()
files.extend(glob(os.path.join(dir, pattern)))
[os.path.splitext(os.path.basename(fn))[0] for fn in a]
ppp_data.rename(columns=dict(zip(columns[2:], names)), inplace=True)
lines = random.sample(f.readlines(), 5)
f.write(text)
sumlog([5, 4, 1, 0, 2]) < sumlog([5, 1, 4, 0.0001, 1])
LOGNORM.DIST(x, Ln(mean), standard_dev, FALSE)
LOGNORM.DIST(x, Ln(mean), standard_dev, TRUE)
self.attr2 = attr2
bottle.run()
a.any(axis=1)
array([2, 2, 2, 2, 1, 2, 1, 2])
print(file(path).read())
nx.draw(G, pos=pos, with_labels=True)
expit(0.458)
time.sleep(1)
letter2, letter1, letter4, letter5
cur.close()
os.path.split(s)
ax.add_patch(rect1)
sys.path.append(path)
time.sleep(1)
any(char.isdigit() for char in inputString)
t1 = set(frozenset(i) for i in t)
Py_Finalize()
out_file.write(line)
print(xls.sheet_names())
list(itertools.product(*l))
bool(np.array([0, 0]))
pickle.loads(pickle.dumps(C()))
list(itertools.chain.from_iterable(a))
DBSession.close()
output_stream.close()
sorted_li = sorted(li, key=lambda x: (-x[1], x[0]))
plt.show()
cherrypy.engine.exit()
tmp_file = os.path.join(settings.MEDIA_ROOT, path)
os.execl(sys.executable, sys.executable, *sys.argv)
queryset.filter(mycolname__len__gte=10)
file_out[-1] = file_out[-1][:-1]
A[(0, 1, 2), (0, 1, 0)]
reactor.run()
list_.sort(key=lambda x: float(x[1]))
[0.0, 0.0, 0.0, 0.4, 0.6]
print(match.group(), match.start(), match.end())
e = Example()
ipshell()
values[np.where((coo == [1, 2]).all(1))].mean()
list(adjacent_tuples(list(range(8)), 4))
self.Bind(wx.EVT_LEFT_UP, self.OnLeftUp)
app.run()
base = df.index.get_indexer_for(df[df.A == 2].index)
self._tree = (lambda f: f(f))(lambda t: defaultdict(lambda : t(t)))
print(json.dumps(data, ensure_ascii=False))
doctest.testmod()
oceans = [[], [], [], [], []]
logging.basicConfig(level=logging.DEBUG)
(m[1:] > m[:-1]).sum() + m[0]
cords_set.add((x, y))
print(list(message.keys()))
t = dt.time(0, 0, 0)
df.tail(1).index
syncdict.update([(key, 0)])
plt.show()
f.close()
self.window2.show()
(s + mystring for s in mylist)
other_list.remove(other_list[index])
(a[n:] + [default])[0]
maxlen = max(len(sublist) for sublist in a)
x, y = zip(*lst)
distribution = scipy.stats.gengamma(100, 70, loc=50, scale=10)
run()
str(dt)
[(x - 1) for x in perm_index[i][1:]]
s.sendmail(from_email, emails, msg.as_string())
self.entry.pack()
sub_dict = dict([(key, round(a[key] - b.get(key, 0), 1)) for key in a])
True
sent_detector.tokenize(your_text)
tuples = [tuple(x) for x in subset.values]
list_of_groups = zip(*((iter(the_list),) * group_size))
o = urlparse.urlparse(self.request.url)
app.exec_()
time.sleep(1)
layout.addWidget(grview)
A[0:4, (1)]
module.workflow_set.filter(trigger_roles__in=[self.role], allowed=True)
do_something_with(wrapper[0])
[([0] * len(row) if 0 in row else row) for row in matrix]
plt.show()
matchingVals = [x for x in a if x > 2]
datetime.time(0)
r = requests.delete(URL_delete, params=mydata)
app.register_blueprint(heysyni)
print(os.getcwd())
plt.subplots_adjust(right=0.75)
any(sublst == lst[i:i + n] for i in range(len(lst) - n + 1))
out.remove(x)
winsound.Beep(Freq, Dur)
print(sorted(inputWords, key=lambda word: [alphabet.index(c) for c in word]))
urllib.parse.unquote(s)
testit()
task.cancel()
bothlists[x[0]].append(x)
request.data
dgtsv = lapack.dgtsv_
requests.delete(url, **kwargs)
ax.autoscale()
new_list = map(operator.itemgetter(1), old_list)
glVertex2i(10, 10)
zip(*lis)
df.ix[:, ((df == 0).all())]
cv2.destroyAllWindows()
print(np.where(~mask)[0])
ax.legend()
plt.imshow(im2, cmap=plt.cm.gray)
p = Process(target=fn)
popen.wait()
self.periodiccall()
plt.ylim([-400, 400])
[Teaser(Context(result)) for result in self.post.results]
mp.Process(target=run, args=(_QUEUE, cb, func, args, kwargs)).start()
print((dt.datetime.combine(dt.date(1, 1, 1), t) + delta).time())
len([_f for _f in a_list if _f]) == len(a_list)
plt.show(block=True)
s.multiply(1 / np.sqrt(s.multiply(s).sum(1)))
sys.stdout.flush()
os.path.exists(my_path)
ax.set_ylim([-2, 2])
mp.Process.__init__(self)
m[:, ([0])].shape
filepath = os.path.abspath(filepath)
self.button.clicked.connect(self.testMethod)
topdirs = [os.path.split(x)[0] for x in dirs]
print((m.group(1), m.group(2)))
a.reshape(2, 2, 2, 2).sum(axis=1).sum(axis=2)
x.reshape(4, 2, 2)
raise ValueError
sorted(s1, key=prefixed_digits())
plt.show()
df.index = pd.DatetimeIndex(df.index)
list(range(1, 6)) + list(range(15, 20))
df.index.level_map
br.select_form(nr=0)
pd.rolling_apply(df, 12, lambda x: np.prod(1 + x) - 1)
temp.append(sub_list[0])
admin.site.register(Employee, EmployeeAdmin)
i += 1
print(np.sqrt(np.sum((p[:, (np.newaxis)] - p[(np.newaxis), :]) ** 2, axis=-1)))
set(x for x, count in common if count == common[0][1])
cat_sorted = zip(*sorted(zip(*cat), key=itemgetter(2)))
print(my_list)
signal.signal(signal.SIGALRM, handler)
plt.show()
pd.DataFrame(MM, dtype=int, columns=Col)
conn = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
db.session.add(region2)
time.sleep(2)
print_matrix(spiral(5, 5))
map(list, list(result.items()))
mylist = [(w[0] + w[1]) for w in words]
img.fill(255)
random.randrange(5, 10)
__mycode = True
max(iter(stats.items()), key=operator.itemgetter(1))[0]
args = parser.parse_args()
print(line)
some_module.py
list(obj.children)
print(map(str, young_fellas))
do_something()
sorted(list(the_dict.items()), key=lambda x: x[1], reverse=True)[:10]
a = [two for one, two in zip(a, a[1:]) if two[1] > one[1]]
f.close()
df = df[dupemask]
cursor = db.cursor()
plt.xlim(x.min(), x.max())
os.remove(temp_file)
app.MainLoop()
pd.concat([df, df1], axis=0, ignore_index=True)
ax.grid()
tuple.__new__(cls, (x, y))
sessions.append(sessionmaker(bind=engine)())
f.geturl()
v, b, n = j[4:7][::-1]
np.array([[x] for x in a1])
log.start()
print(test2())
form.save()
plt.subplots_adjust(bottom=0.1)
df
app.run(debug=True)
rnd = np.random.rand(n)
sometuple + (someitem,)
x[x.columns[0]]
driver.quit()
id = Column(Integer, primary_key=True)
app.MainLoop()
knapp.pack(pady=10)
views / __init__.py
ssh = paramiko.SSHClient()
QMainWindow.__init__(self, parent)
func(*args)
int(n ** 0.5) + 1
main()
list(chain.from_iterable((i, i * i) for i in range(1, 10)))
bar = foo(bar)
L += [4] * 10
ufunc.reduceat(mat.data, mat.indptr[:-1])
pygame.init()
response.set_data(json.dumps(d))
df[col_values] = df[col_values].astype(float)
f.write(text)
df.to_json()
print(time.mktime(new.timetuple()))
session.add(obj)
plt.show()
termios.tcsetattr(sys.stdin, termios.TCSADRAIN, new_settings)
self.entry.focus()
k.reshape(k.shape + (1,))
reactor.run()
a, b, c
result = first_date + np.arange(24) * datetime.timedelta(hours=1)
dictionary[next(iter(dictionary))]
powd = DataFrame(data2)
deletec[:2]
input()
print(int(date[:4]) + 1)
__main__()
QtGui.QMainWindow.__init__(self)
df.mean()
print(sys.path)
t = threading.Thread(target=task, args=(data,))
pd.DataFrame.from_dict(d)
yx.sort()
color = ebar[0].get_color()
window.show_all()
f.close()
browser.quit()
filtered_list = [x for x in input_list if x % 2 == 0]
newdf.head()
d = datetime.date.today()
d = dict((t.key, t) for t in [t0, t1, t2])
print(list(tb_notes.select().execute()))
writer.writerow(row)
result.append(([key] * len(values), values))
plt.axis([0, 10, 0, 1])
pickle.load(f)
p.communicate()
all_potion_names = list(all_potions.keys())
wkt = dane[0][0].read()
sys.path.append(os.path.dirname(__file__))
[(lower + x * (upper - lower) / length) for x in range(length)]
time.sleep(1)
get_object_or_404(Book, pk=id)
inspect.stack()[2]
fig.canvas.draw()
dists.shape
plt.xlim(0, 20)
list(_)
time.mktime(dt.timetuple())
plt.draw()
print(txtrecord.to_text())
HttpResponse(status=410)
ax.set_xlim(0, 6)
name[0][0][-1][-1]
pool.append(Process(target=pool_func, args=(q,)))
sys.stdout.writelines(sorted_lines)
p.terminate()
thestring[:-len(ending)]
output_list = [x for x in input_list if isinstance(x, list)]
dftmtx(2)
img = pygame.image.load(filename)
socket.close()
last_lines.append(line)
X.dot(A.T)
foo()
blob.delete()
zeros = [([0] * N) for _ in range(M)]
list(chain.from_iterable(ls[:1] + ls[2:]))
root.mainloop()
[item for item in sequence if item < value]
sys.exit(0)
lock.acquire()
v.setdefault(value, []).append(key)
dict_setitem(self, key, value)
[1][0][0]
res = requests.post(url, files=files, data=data, headers=headers)
items = SomeModel.objects.all()
b_t = np.vstack((b, np.ones_like(b)))
user.save()
plt.tight_layout()
pylab.xlim([-2.5, 2.5])
plt.show()
dict([(k, v) for k, v in d.items() if k >= begin and k <= end])
Dataset.objects.filter(i_begin_int__lte=170, i_end_int__gte=170)
data.append(sheet1.cell(i, 1).value)
time.mktime(then.timetuple()) * 1000.0 + then.microsecond / 1000.0
not sum([(not i in A) for i in B]) if len(A) == len(B) else False
plt.show()
ax = fig.add_subplot(1, 1, 1)
df.reset_index(inplace=True)
[a.join(b) for a, b in zip(df.a[10:20], df.b[10:20])]
plt.ylim(0, 5)
print(sys.argv[0])
newMyList = [(v, k) for v, k in myList if not k in myDict]
top.mainloop()
[[i for i, n in enumerate(li) if n == x] for x in sorted(set(li))]
print(k, d2.get(k, 0))
f.__code__.co_name in creator.__code__.co_varnames
reactor.run()
limit = int(limit)
sheet.set_portrait(False)
simplejson.JSONEncoder.default(self, obj)
plt.pcolor(data, vmin=0.01, vmax=0.99, cmap=my_cmap)
df.Group.value_counts()
foo()
df.a.sort_values()
Number(randint(1, 100))
result = [makedict(elem) for elem in yourlist]
plt.show()
server.serve_forever()
regex.findall(s)
any((a[:] == [1, 20]).all(1))
plt.gcf().show()
iter(self.books.values())
listbox.pack()
probas_ = clf.predict_proba(Kt)
ax.add_patch(rect2)
json_obj = json.dumps(a_dict, ensure_ascii=False)
tuple(map(operator.add, a, b))
allow_unicode = True
s.replace(d)
pd.DataFrame(stdf.tolist())
print([element for element, count in Counter(list1).most_common()])
plt.gcf().autofmt_xdate()
[(next(car) if item else next(a)) for item in lyst]
pd.concat(g for i, g in grouped if len(g) > 2)
proc.stdin.close()
alist = [arr[(0), :], arr[1:, (-1)], arr[(-1), :-1], arr[1:-1, (0)]]
main()
app.mainloop()
cherrypy.engine.start()
extra_logger.setLevel(logging.DEBUG)
[match for match in matches]
s[::-1]
toarchive.filter(date__gt=interval).delete()
root = tk.Tk()
plt.show()
data.pop()
fig = plt.figure()
df_c = pd.concat([df_a.reset_index(drop=True), df_b], axis=1)
[(x + 1) for x in L]
sum(i for i in range(a, b + 1) if not i % 2)
z = dict(x, **y)
np.sum(a), np.nonzero(np.any(a, axis=0))[0]
conn.close()
eliminated = eliminated.append(x)
rect.set_visible(True)
[vali[i] for i, vali in enumerate(f(*vals))]
pd.melt(piv)
urllib.request.install_opener(my_opener)
obj = json.loads(json_string)
s = s.lower()
globals()[module_name] = __import__(module_name)
sys.stdout.flush()
results.extend(re.findall(key, message, re.IGNORECASE))
print([list(v) for k, v in groupby(sorted_list, key=move)])
print(dumps(a.__dict__))
angle = atan2(a.x * b.y - a.y * b.x, a.x * b.x + a.y * b.y)
api = falcon.API()
plt.show()
weekly.append(sum(visitors[x:x + 7]))
randomvalue = myRandom.randint(0, 10)
df[column_list].iloc[row_index_list].mean(axis=0)
func()
L4 = [n for n in L1 if n not in tmpset]
shutil.copyfile(path, os.path.join(*path_rel))
counter_list = [item for item in counter_list if len(item) != 0]
{{f.following_set.count()}}
stripped_list = [j.strip() for j in initial_list]
plt.show()
np.isclose([10000000000.0, 0], [1.00001e-10, 0])
workbook.close()
print(df2.set_index([0, 1]))
df
ax.imshow(pawprint)
g.plot()
df[(df != 0).all(1)]
list.remove(item_to_be_removed)
set(x[0] for x in zip(a, a[1:]) if x[0] == x[1])
print(os.path.getmtime(os.path.join(SOME_DIR, filename)))
win = gtk.Window()
plt.show()
ctypes.cast(x, ctypes.POINTER(ctypes.c_ulong))
now_epoch = (datetime.utcnow() - datetime(1970, 1, 1)).total_seconds()
vec.fit_transform(measurements).toarray()
map(bool, a).index(True)
l[0][1]
print(a[:-10:-1])
l = list(zip_longest(x, x, fillvalue=[]))
draw.ellipse((x - r, y - r, x + r, y + r), fill=(255, 0, 0, 0))
__init__.py
[(A[k], B[k]) for k in A if k in B]
RNA_integers = [RNA_dictionary[i] for i in RNA_list if i in RNA_dictionary]
p.stdout.close()
min(items, key=lambda item: p1.compute_distance_to(item.loc))
arr = numpy.random.randint(2, size=(n,))
list(chain.from_iterable(l))
round(random.random() * (m_time - min_time) + min_time, 1)
plt.show()
cv2.destroyAllWindows()
np.allclose(C0, C2)
ax.plot(data)
mydog.findall(s)[0]
uniq_animal_groups = set(map(tuple, animal_groups))
ax.set_xticklabels([])
QtCore.Qt.ItemIsEnabled
writer.writerow(the_list)
string = float(string) if string.isdigit() else string
logger.setLevel(logging.DEBUG)
a / (a - 1)
A[1], A[0], A[1] = A[0], A[1], A[1]
next(e in lestring for e in lelist if e in lestring)
print(np.all(norm1 == norm2))
canvas.pack()
django.setup()
print(df2.reindex(df.index[df.index.isin(df2.index)]))
ii = np.nonzero(a == 4)
subprocess.Popen(command, stdout=subprocess.PIPE).communicate()[0]
json.loads(data, object_hook=_json_object_hook)
sys.stdout.flush()
a[::2] = 1
value = my_dic.get(100, 0)
fig = plt.figure()
numpy.isnan(myarray).any()
b = a[:]
do_something_with(result)
ax.set_yticks([0.5, 1.0])
cnx.sendInitPresence()
np.average(a, axis=-1).repeat(a.shape[-1]).reshape(a.shape)
classifier.fit(X, y)
log.setLevel(logging.DEBUG)
print(trks.name())
plt.draw()
a.setdefault(key, [])
axcut.set_visible(False)
array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0]])
reactor.run()
pd.isnull(df).any(axis=1)
win.run()
urlsIwant = [x for x in allurls if any(w in x for w in words)]
new_list.extend(i)
text_file.close()
np.exp(-4 * np.log(2) * ((x - x0) ** 2 + (y - y0) ** 2) / fwhm ** 2)
A.objects.filter(id=some_a.id).update(hidden=True)
s.apply(lambda x: Series(1, index=x)).fillna(0)
self.SetSizerAndFit(sizer)
pkl_file.close()
print(m.group(1))
resp.text, resp.status_code, list(resp.headers.items())
self.tcp_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
X_train = scaler.fit_transform(X_train)
f.close()
request.user.get_profile().token
session.commit()
self.frame.pack(fill=BOTH, expand=YES)
count = sum(1 for line in myfile)
fig = plt.figure()
time.sleep(10)
random.choice(list(range(100, 20100, 100)))
[f(aItem, bItem) for aItem, bItem in zip(a, b)]
G = nx.Graph()
s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
match.group(0)
print(sum(map(lambda x: x * x, l)))
normalizedscores = {u: (float(l) / maxscore) for u, l in list(linkscores.items())}
resp = urllib.request.urlopen(req)
all_data = []
a.extend(a, b)
dict((k, sum(d[k] for d in dict1)) for k in dict1[0])
urllib.request.urlopen(url).read()
datetime.timedelta(0)
M = scipy.sparse.csr_matrix(M)
runserver.py
dict(itertools.islice(iter(dictionary.items()), begin, end + 1))
main1()
[a for a, a in list(params.items())]
tk.Tk.__init__(self, *args, **kwargs)
{{(user | hash): item}}
len(set(sum(sl) for sl in L)) == 1
[id(x) for x in test]
[x for x in L if x not in delitems]
sum(i != j for i, j in zip(a, b))
a.reshape(-1, R)
random.shuffle(myList)
conn.commit()
self.thisptr.clone()
np.average(df.y - df.x, weights=df.index.asi8)
[line for time, line in sorted(zip(listofTimes, listofLines))]
VVg = np.sum(np.dot(GinvVV[:, :-1], GRZVV.T), axis=-1) * VV
frame.axes.get_yaxis().set_ticks([])
e.pack()
self.window1.show()
foo()
resp.peercert
df.iloc[0]
cursor.execute(insert_query, data)
pygame.display.flip()
spherical_dist(locations_1, locations_2[:-1])
plt.show()
G = nx.Graph()
print(repr(line))
sock.connect((host, port))
possibles.update(locals())
que = multiprocessing.Manager().Queue()
fh.write(base64.decodestring(imgData))
fig = plt.figure()
re.compile(regex).groups
[(v * v) for v in vals]
MyApp().run()
print(self.time)
[char for char in yourstring]
sum(1 for item in arr if item == 0 and type(item) is type(0))
time.sleep(1)
np.stack(np.nonzero(df.values)).T
user.user_trips.all()
list(map(lambda f, a: f(a), *zip(*itertools.product(funcs, args))))
print(result.group(1))
app = wx.App(False)
browser.select_form(nr=0)
print(r.data())
print(sorted(a, key=Counter(a).get, reverse=True))
pandas.DataFrame.from_records([s.to_dict() for s in signals])
df.groupby(level=0, as_index=False).nth(2)
proc.stdin.flush()
dictionary = json.loads(cur.fetchone()[0])
proc.wait()
c = (len(a) * a - sum(a)) / b
ax.set_title(title)
[0][0][0]
field.setAlignment(QtCore.Qt.AlignCenter)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
__init__.py
a.func(**kwargs)
bool(number % 2)
A[np.lexsort(A.T)]
sample(10, [2, 4, 8, 16])
sum(a, b)
len(np.atleast_1d(a))
df = pd.DataFrame(data.tolist(), columns=data.dtype.names)
tornado.ioloop.IOLoop.instance().start()
os.makedirs(dst)
list(map(len, s.split()))
user.put()
a = sorted(list(a.items()), key=lambda x: x[1])
plt.xlim(X[0] - day, X[-1] + day)
plt.plot(list(range(10)))
a = numpy.tile([1, -1], 15)
server.quit()
plt.show()
plt.show()
mylist = [mylist[i] for i in myorder]
name = models.CharField(max_length=100)
p1.join()
new_array = map(list, old_array)
infile.close()
Base.metadata.bind = engine
list_of_lines = [next(f) for _ in range(chunk_len)]
plt.show()
print(key, sum(r[2] for r in rows))
content = content_file.read()
ax.set_ylim(0, 10)
conda - -version
Page.query.get(page_id).query.delete()
field_names = [i[0] for i in cursor.description]
np.allclose(result_data, result_data2)
time.sleep(1800)
project_root = os.path.dirname(os.path.abspath(__file__))
c.fetchall()
print(len(unicode_string))
pl.plot(X, Cosine)
plt.show()
hex(15)
[0, 1, 1, 0, 0, 0],
Peak()
agent_list = [list(ast.literal_eval(line)) for line in f]
app.MainLoop()
ax = fig.add_subplot(111)
cnxn = pyodbc.connect(connectString)
plt.subplot(122)
mylist.count(mylist[0]) == len(mylist)
p.join()
r = requests.post(url, files=files, headers=headers)
scrapyd
new_dict[v].append(k)
avg.append(sum(d[key]) / len(d[key]))
list(merge(list1, list2))
urllib.request.install_opener(opener)
{{form.content()}}
s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
df.dropna(thresh=df.shape[1] - 7)
lines.sort(key=extract_time, reverse=True)
fig, ax = plt.subplots()
sleep(1)
plt.show()
a = np.array(df.C)
plt.show()
lambda name: (name[0], -len(name), name)
print(nodes[0].firstChild.nodeValue)
__init__.py
sorted(list(d.items()), key=foo)
session.run(tf.initialize_all_variables())
bytearray(hex_data)
final_data[cnames[i]] = np.zeros((nalpha, nmach, nbeta, nalt))
hello.helloworld()
Motifs.insert(x, Motif)
main()
tree = ET.fromstring(msg)
list(zip(foo, bar))
[x for x in range(LOW, HIGH) if len(set(str(x))) == len(str(x))]
db.session.commit()
self._file.close()
request.user
categories = {k: (sum(v) / len(v)) for k, v in list(categories.items())}
logging.setLoggerClass(ColoredLogger)
d > timedelta(minutes=1)
print(json.dumps(obj, indent=2))
time.sleep(5)
np.allclose(omega, slicing_summing(a, b, c))
Popen(cmd, shell=True, cwd=newpath)
rdd.collect()
window.show()
[a for b, b in list(params.items())]
hex(int(time.time()))
response = requests.get(url, headers=headers)
mlab.show()
type(a)(b)
ax.plot(x, y)
dicts = [dict(zip(fields, d)) for d in data]
plt.plot(x, y)
print(bcrypt.hashpw(password, bcrypt.gensalt()))
print(team.__dict__ == team2.__dict__)
std_2 = numpy.std(list_size_2, axis=1)
w.pack()
sum(len(word) for word in wordslist)
ax.plot(x, y)
df.TIMESTAMP.dt.hour
ax.margins(0.1)
time.sleep(1)
PyArray_ENABLEFLAGS(arr, NPY_ARRAY_OWNDATA)
sum(num for num in numbers if num % 2 == 1)
np.append(xs, arr[i])
s = numpy.fromstring(s, numpy.int16) / 10 * 5
start_time = start_time.replace(minute=ceil_to, second=0, microsecond=0)
dict_with_ints = dict((k, int(v)) for k, v in dict_with_strs.items())
layout.addWidget(self.button)
[k for k, v in list(self.__class__.__dict__.items()) if type(v) is property]
distance = skfmm.distance(m)
urllib.request.urlopen(url)
counts.sort(key=operator.itemgetter(1))
transaction.commit()
ax.set_yticks([1, 2, 8])
my_array = my_array.reshape((50, 50))
test.pop()
int(x)
p.close()
plt.xlim([-400, 400])
print(my_list[1::2])
ax2.yaxis.set_visible(False)
len(x) >= 4
process.stdin.flush()
app.ActiveWorkbook.ActiveSheet.Cells(r, c).Formula
[(0 if i < 0 else i) for i in a]
subprocess.check_call(cmd, startupinfo=startupinfo)
smagnoni
d.setdefault(year, []).append(value)
[0, 0, 0, 0, 0],
plt.show()
[child for child in soup.td.children if isinstance(child, str)]
dg.Items.Add(value)
ax.get_xaxis().set_ticklabels([])
s.save()
app.register_blueprint(mod)
divtd(datetime.timedelta(hours=12), datetime.timedelta(hours=2))
df_out = pd.concat([df, df_v], 1)
time.sleep(1)
sum(map(operator.mul, vector1, vector2))
[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]
df.T.squeeze()
dict((x, data.count(x)) for x in data)
fileMenu = Menu(menubar, tearoff=False)
B in (A[i:i + len(B)] for i in range(len(A)))
buf.seek(0)
sum(itertools.starmap(operator.mul, itertools.combinations(l, 2)))
my_shelf.close()
strat2.execute()
main()
msg = MIMEText(fp.read())
yourProcess.terminate()
x2 = sorted(x1, key=lambda t: t[1])
conn.close()
s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
np.diagonal(np.dot(b, a)).T
plt.subplots_adjust(top=0.85)
pygame.display.flip()
writer.UpdatePipeline()
A[([0, 2]), :, 1:]
plt.show()
ax1.plot(X, Y)
do_something()
data.columns = [x.lower() for x in data.columns]
mlab.show()
[doSomethingWith(ch) for ch in s]
df.values.tolist()
s.sum()
plt.draw()
page = urllib.request.urlopen(url)
matplotlib.pylab.show(block=False)
xcode - select - -install
img.putdata(data)
max([a for a in yourlist if a[2] >= 100], key=itemgetter(1))
(df == 1).any(axis=1)
args = main_parser.parse_args()
plt.close()
ax.set_yticks(np.arange(data.shape[0]) + 0.5, minor=False)
eval(input())
bar()
df = DataFrame(data)
random.shuffle(list(range(n)))[:k]
time.sleep(20)
pdb.set_trace()
mat = hstack([mat[:, 0:i], mat[:, i + 1:]])
self.response.out.write(zipstream.getvalue())
parse_qs(urlparse(url).query)
set([1, 2]) in {1, 2, frozenset([1, 2])}
gtk.gdk.notify_startup_complete()
numpy.where(your_array_name != 0, 1, 0).sum()
setattr(self, property, getattr(self, property) + amount)
self.cursor.execute(query)
random.choice(states.split())
pyplot.show()
random.sample(list(D.items()), K)
active_id = hex(ewmh.EWMH().getActiveWindow().id)
self.foo.kill()
results = [[1, 0, 1], [0, 1, 0], [1, 1, 0]]
classifier.classify(test_sent_features)
scipy.signal.filtfilt
p.stdout.close()
results = map(int, results)
cursor.close()
a = forms.CharField(max_length=20)
sum(p) * (c[1] - c[0])
self.process.stdin.flush()
pipeline.fit(X, y)
f.write(response.content)
im.save(newpathname)
Counter(chain.from_iterable(map(set, listOfLists)))
temp_list = [i for i in squares()]
window.SetFocus()
mask1 &= ~mask2
self.grid_columnconfigure(0, weight=1)
evt.Skip()
(idx[1::2] - idx[::2]).max()
inv.fill((255, 255, 255, 255))
print(collections.Counter(words))
uniq = [x for x in a if x not in seen and not seen.add(x)]
pd.concat([T, df])
getattr(obj, name)
session.commit()
line = line.rstrip()
someMethod.__code__.co_argcount
sorted(li, key=itemgetter(1))
plt.clf()
serve_pil_image(img)
cursor = db.test.find(timeout=False)
solution.loc[df.index]
foo[i], foo[j] = foo[j], foo[i]
plt.show()
find_majority([1, 1, 1, 1, -1, -1, -1, 0])
clf.fit(X, y)
driver.manage().window().maximize()
matches = [x for x in a if x in str]
sorted(templist, key=int, reverse=True)
unittest.main()
d = defaultdict(lambda : defaultdict(lambda : defaultdict(list)))
cursor.close()
plt.draw()
graph = facebook.GraphAPI(oauth_access_token)
y[:][::2]
logger.setLevel(logging.DEBUG)
commands[com](*args)
file.flush()
np.add.reduceat(X[:, (idx0)], cut_idx, axis=1)
logger.setLevel(logging.DEBUG)
dict(zip(tokens[0::2], tokens[1::2]))
len(set(items)) == 1
setattr(self, name, value)
pd.DataFrame([s1, s2]).min()
time.sleep(0.1)
cnxn.close()
args = parser.parse_args()
plt.show()
df.astype(int)
ax.legend()
kana = a + k + g + s + z + t + d + n + h + b + p + m + y + n
l1.append([4, 5, 6])
time.sleep((future - t).seconds)
signal.signal(signal.SIGALRM, original_handler)
x, y = a[0:2]
print(response.text)
min(items, key=lambda x: abs(x - pivot))
time.sleep(1)
root.mainloop()
print(f.getvalue())
numpy.all(product1 == product2)
User.query.get(id)
plt.draw()
values = [d[k] for k in keys]
df.where(df.a.isNull()).count()
a.symmetric_difference(b)
{v: k for k, vs in list(extension_to_type_mapping.items()) for v in vs}
cv2.waitKey(0)
self.request.query_string
new = str[:1] + new + str[6:]
print(sys.exit.__doc__)
im.show()
print(f(4))
json.dumps(data)
header = input.readline()
plt.show()
x[(list(range(0, i)) + list(range(i + 1, x.shape[0]))), :, :]
main()
proc.stdin.close()
out, err = p.communicate()
pygame.sprite.Sprite.__init__(self)
testdataframe2.plot(style=styles2, ax=ax)
np.log(absd, absd)
plt.contour(data)
ax.patch.set_visible(False)
server.login(username, password)
map = [[a, b] for a, b in map if a > 0 and b > 0]
print(Digit[i])
{{car.date_of_manufacture | strftime}}
df.iloc[:, (n)]
ax.get_xaxis().set_ticks([2, 4, 6, 8])
xprt.excel()
run()
data.append(ruamel.yaml.load(open(file_name)))
~a.any(axis=1)
subprocess.Popen(cmd_str, shell=True)
pool.terminate()
process.terminate()
Test.__init__()
con.set_option(ldap.OPT_X_TLS_REQUIRE_CERT, ldap.OPT_X_TLS_NEVER)
print(line)
result = self.cur.executemany(sql, data)
plt.figure()
np.argwhere((Ax == Bx.min()) & (Ay == By.min()))
s.stack().reset_index(level=1, drop=True)
plt.show()
plt.ylim(0, 20)
cv2.destroyAllWindows()
print(datetime.fromtimestamp(timestamp))
obj.save()
time.sleep(wtime)
ax = fig.add_subplot(111)
plt.show()
plt.ylim(-1, 1)
d = [(0.25 * math.sin(math.radians(i))) for i in range(0, 1024)]
os.path.join(dir_name, base_filename + suffix)
sizer.Add(buttons, 0, wx.EXPAND | wx.ALL, 5)
plt.figure()
m = re.search(reg, s)
cherrypy.tree.mount(root)
print(hash.hexdigest()[:10])
smtp.starttls()
pd.to_datetime(dte.stack()).unstack()
msg.attach(body)
cax.get_xaxis().set_visible(False)
plt.xticks([])
a = [x for x in names if any(pat in x for pat in pattern)]
sys.exit(0)
indices = tf.where(where)
print(link.text)
plt.show()
plt.show()
arr.T.reshape(5, -1)
ax.set_xlim(0, 24)
print(x[np.unique(a)])
errf.close()
proc.terminate()
ax.set_ylim(-40, 40)
abort(404)
print((a, b, c))
connection.commit()
df = df2.transpose()
c.py
bmp.Bind(wx.EVT_ENTER_WINDOW, onWindow)
[(not i) for i in mylist]
pdfkit.from_string(html_text, output_filename)
issubclass(A, A)
abs(b - c) < abs(b) / 1000000000000
u = Union(a, b)
pygame.display.update()
s += str(n)
df.rename(index=lambda x: tup)
seaborn.voilinplot(ax=ax, data=df, **violin_options)
ax.set_xlim([-0.5, 4.5])
[x for y in zip(list, list) for x in y]
df1.corr()
initpyxmod()
plt.show()
dat1 = pd.concat([dat1, dat2], axis=1)
map(f, list(range(10)))
line = line.rstrip()
self.assertEqual([attr, val], [attr, getattr(self.nu, val)])
filename = sys.argv[-1]
Base.metadata.create_all(engine)
fig.savefig(os.path.join(my_path, my_file))
instance.__dict__
sum(tuples, ())
df
sys.argv[1:]
k = lambda x: x[1]
list(k for k, g in itertools.groupby(numbers))
ax.set_xlim((0, 10))
ax.yaxis.set_major_locator(ticker.MultipleLocator(1))
object.__getattribute__(self, name)
cmp(x.lower(), y.lower())
print ()
fps = cap.get(cv2.cv.CV_CAP_PROP_FPS)
logger.addHandler(handler)
dict(zip_longest(x, y))
df.apply(update_vals, axis=1)
cleared, dominated
fill_between(x.values, y.min(), y.values, alpha=0.5)
plt.show()
print(name.lower())
sys.stdout.write(line)
b.doSomething()
sock.connect((host, port))
bulk.execute()
gevent.wait()
libxslt - devel
(OrderedDict(row) for i, row in df.iterrows())
mylist[:]
menu.remove(i)
logger.setLevel(logging.INFO)
globals()[n] = 1
new_array = list(set(main_array) - set(second_array))
np.corrcoef(df1.s1, df1.s2)
row.delete()
[[ix.upper() for ix in x] for x in nested_list]
array2 = np.tile(array1, (20, 20, 1, 1))
cv2.destroyAllWindows()
req.close()
s[-1].isdigit()
print(arr[idx])
pd.Series(*zip(*((b, a) for a, b in data)))
ind = np.flatnonzero(mask)
conn.close()
df.iloc[:5, :4]
tangent = np.array([1 / ds_dt] * 2).transpose() * velocity
app.run(threaded=True)
l.sort(key=asum)
width, height = img.size
print(etree.tostring(document, xml_declaration=True))
print(unicode_text.encode(sys.getfilesystemencoding()))
root.overrideredirect(True)
sys.exit(1)
{key: list(set(a[key]) - set(b.get(key, []))) for key in a}
epoch_time = int(time.time())
time.sleep(0.01)
time.sleep(5)
np.reshape(self.data, newshape=(len(self.data) / 5, 5))
[flatten[int(i * 2)] for i in range(int(len(flatten) / 2))]
Fraction(*(0.25).as_integer_ratio())
signal.signal(signal.SIGINT, self.handler)
np.may_share_memory(a, a[:, 1::2])
o = numpy.delete(n, deletions, axis=0)
sum(r(i)) == -n
foo.bar()
unittest.main()
np.linspace(x[0], x[-1], 10)
B[:, :, (2)] = 0
df.values
s1[s1.index.isin(s2.index) & s1.isin(s2)]
nobj.__dict__ = oobj.__dict__.copy()
sys.exit(0)
(a > 2).sum()
df.ix[d1:d2]
print(oct(9))
norm.ppf(0.95, loc=10, scale=2)
[(s % x) for x in itertools.product(l1, l2)]
r.json()
print(re.search(find, l).group(0))
max(self.left.depth(), self.right.depth()) + 1
print(os.name)
cv2.FONT_HERSHEY_SIMPLEX
self.root.mainloop()
qdict.update(dict)
df.stack(level=1).reset_index(level=1, drop=True).reset_index()
writer.writerow(row)
outFile = sys.argv[2]
root = Tk()
server = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
print(s.group())
root.mainloop()
etree_to_dict(tree.getroot())
np.repeat(np.arange(4), 4)
img_io.seek(0)
data.columns = map(str.lower, data.columns)
df.groupby(diff_to_previous.cumsum())
print(ElementTree.tostring(xmlET))
button.pack()
parser.feed(data)
new_list
ax2.yaxis.get_major_ticks()[0].label1.set_visible(False)
{data[k].append(v) for k, v in list(line_dict.items())}
[s[i:j] for i in range(length) for j in range(i + 1, length + 1)]
list(split_on_members(l, s))
serializer = PhotoSerializer(data=request.DATA, files=request.FILES)
sorted(the_list, key=splitter)
music.play()
db.session.commit()
my_func(*my_list)
a[idx[:, (0)], idx[:, (1)], idx[:, (2)]] = 5
classifier.fit(X, Y, sample_weight=weights)
indices = np.arange(len(arr))
r = requests.post(url, data=json.dumps(payload))
plt.show()
add_matrices(c, d)
sns.set()
data.reshape(2, -1).mean(0)
random.shuffle(x)
d[tup[0]][tup[1]] = [tup[2]]
np.dot(a, b) == np.tensordot(a, b, axes=([-1], [2]))
lcmm(*list(range(1, 21)))
len(list(d.items())[0][1])
y.do_something()
QtGui.QWidget.__init__(self, parent)
df.values is df.values
ax.set_yticks([0.2, 0.55, 0.76])
print(evil_vals[0] in list(dict_with_evil_keys.keys()))
woduplicates = set(lseparatedOrblist)
df[(df == pd.Series(conditions)).all(axis=1)]
ax.legend()
self.clslength()
e2 = np.array([0, 1, 0])
Books.objects.exclude(authors__in=bad_authors)
thread.start()
round(2.615, 2)
admin.site.register(Game, MyModelAdmin)
self.proc.wait()
reactor.run()
output = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)
self.linenumbers.config(state=DISABLED)
matrix = [list(line.strip()) for line in matrixfile]
zlib.decompress(decrypt(data))
shapely.ops.unary_union(list(shapely.ops.polygonize(lines)))
print(df.values.tolist())
print(list(d.values()))
[x for x in library if terms.issubset(x)]
out = proc.communicate()[0]
counter += 1
plt.show()
assert expression1, expression2
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
todb.commit()
args = parser.parse_args()
fig, ax = plt.subplots()
db.session.remove()
sleep(1)
Gtk.Entry.__init__(self)
sys.stdout.flush()
print([type(x) for x in htmldata])
model.fit(X)
pl.pop()
process.wait()
workbook.close()
print(sys.version)
x.total_seconds()
os.path.dirname(sys.executable)
(dict(zip(keys, row)) for row in zip(nums, chars))
im.shape
any(1 in x for x in d)
multiprocessing.Process.__init__(self)
plt.show()
data = numpy.asarray(im)
df.columns = columns
map(len, s.split())
sorted(s)
checkbox.Click()
pdb.Pdb.interaction(self, *args, **kwargs)
decompressedString = zlib.decompress(compressedString)
data = json.loads(mtext)
self.func(*args, **kwargs)
print(buffalo)
time.ctime()
zip(it, it)
model.fit(X_train, y_train)
do_something()
bytes(10)
msg.attach(attachment)
redirect(redirect_url())
list(itertools.chain(*[([k] * v) for k, v in sorted(d.items())]))
lki.sort(key=itemgetter(1))
cur = db.cursor()
app = Flask(__name__)
name = models.CharField(max_length=100)
x[~np.any(np.isnan(x), axis=1)]
min(itertools.product(*lists), key=distance)
df.AC = df.AC.astype(float)
result = json.dumps(d, ensure_ascii=False)
df.plot(subplots=True, layout=(1, 2))
print(match.groups())
df2 = df.stack().reset_index(1)
[0, 1, 1, 1, 1],
print(df.groupby(df.A // 2).A.apply(pd.Series.sample, n=2))
User.objects.count()
json.dump(LoL, myfile)
cleantext = BeautifulSoup(raw_html).text
groups_no_a = [group for group in groups if a.isdisjoint(group)]
random.sample(deq, 10)
print(dt - datetime.fromtimestamp(s))
CHOICES = [(i, i) for i in range(11)]
imRes = cv2.resize(im, maxsize, interpolation=cv2.CV_INTER_AREA)
q, bins = pd.qcut(a, 2, retbins=True)
ax.set_xlim(-40, 40)
app.url_map
ax1.set_ylim(0, 1.2)
ax.xaxis.set_visible(False)
sys.exit(0)
deletel[100:]
self.response.out.write(simplejson.dumps([p.to_dict() for p in photos]))
array.tolist()
a.flat[np.abs(a - a0).argmin()]
object.__getattribute__(self, attr)
plt.show()
session.commit()
df.reset_index(drop=True).T
final_image = cv2.warpPerspective(image, H, (2150, 2800))
fig.subplots_adjust(wspace=0.5)
self.transport.write(data)
out = [(1 if num & 1 << bits - 1 - n else 0) for n in range(bits)]
mainloop()
tuple(A[:, (0)])
ssh.close()
print(connection.getresponse().read())
is_cardano_triplet(2, 1, 5)
random.shuffle(new_lst)
FFnetlayer0 = FFnetlayer0.reshape(-1, 2)
max(i + 1 for i in range(20) if n % (2 << i) == 0)
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
new_data = [float(n) for n in data]
L[-1:], L[:-1] = L[:1], L[1:]
request.resolver_match.app_name
[6, 7, 8]
df.columns = df.columns.str.strip()
pylab.show()
plt.pause(0.05)
image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)
fig.canvas.draw()
property_asel = [property_a[i] for i in good_indices]
linregress(X, Y)
image = tk.PhotoImage(data=b64_data)
np.fill_diagonal(corrs.values, -2)
f.close()
a.remove(x)
ax.plot(x, y)
sess.run(init_op)
print(channel.recv(1024))
r = requests.post(url, data=json.dumps(payload), headers=headers)
numpy.count_nonzero(boolarr)
np.random.shuffle(x)
print(etree.tostring(root, pretty_print=True))
p.stdin.close()
[a for b, a in list(params.items())]
rowmax = df.max(axis=1)
module = importlib.import_module(var1)
time.sleep(2)
Y == np.array([6, 7, 8, 9])
MM().__dict__
l1.extend([4, 5, 6])
self.assertEqual(a, b)
logger.addHandler(mh)
shutil.copyfileobj(source_file, target_file)
input()
user.save()
lookup.setdefault(key(item), []).append(item)
f.close()
skrift2.pack(pady=10)
writer.save()
df.col2.replace(-1, np.nan).interpolate().astype(int)
isinstance(a, Test2)
session2.add(obj1)
dff.drop(c, axis=1, inplace=True)
array([8.0, 5.5])
m.groups()[0]
do_something()
wr.writerow([item])
product(list(range(2)), repeat=k)
x + ((0, 0),)
[chr(ord(uc)) for uc in udata]
np.take(mat, ixs, axis=0).sum(axis=0)
int_arr[-2, -2] + int_arr[0, 0] - int_arr[-2, 0] - int_arr[0, -2]
self.socket.close()
conn.set_timeout(self.timeout)
result = func()
main()
print(round(a, 2))
sys.getsizeof(10 ** 10 ** 7)
all(x == items[0] for x in items)
df2 = df.transpose()
label.mainloop()
proc.wait()
csum = np.cumsum(b)
ax.set_xticklabels(dates, rotation=90)
plt.plot(x, y)
self.response.out.write(row)
y.astype(int)
db.collection.find().limit(1).skip(Math.floor(Math.random() * N))
dlg.ShowModal()
main()
signal.signal(signal.SIGALRM, handler)
rnd = np.random.rand(n) / np.sqrt(2.0 * np.pi)
datetime.date(2011, 1, 1)
my_instance = my_class()
fig.subplots_adjust(bottom=0.2)
abs(A[0] - B[0]) + abs(A[1] - B[1])
np.any((x, y, z), axis=0)
set_trace()
form.populate_obj(user)
app.run()
os.path.dirname(filepath)
max(map(len, tup))
plt.axvline(x=0.22058956)
a.f4(1)
set([1])
rs = (grequests.get(u) for u in urls)
ax.add_patch(patch)
sum(1 for _ in assignments(12, 5))
time.sleep(10)
print(OpenSSL.crypto.dump_certificate(OpenSSL.crypto.FILETYPE_TEXT, x509))
QtGui.QFrame.__init__(self)
sys.path.insert(0, self.install_lib)
setup()
np.median(x, axis=0)
np.where(cond, arr, -inf).argmax(axis=1)
newstr = oldstr[:midlen] + oldstr[midlen + 1:]
db.close()
print((a, b, c, d))
sorteditems = sorted(iter(mydict.items()), key=itemgetter(1))
set_contents_from_string(data_file.read())
decorator_to_enhance(func, *args, **kwargs)
plt.show()
np.random.seed(seed)
df.show()
A.view(dtype=np.complex64)
l.sort()
x.pop(0)
self.__dict__.update(d)
d.setdefault(k, []).append(v)
frame.pack()
A[:, (np.mod(np.arange(ncols), A.shape[1]))]
print([x for x in p.findall(s) if x])
plt.close()
data = json.loads(input_str)
self.assertEqual(callresult, [xargs, yargs])
list(metadata.tables.keys())
print(datetime.datetime.utcfromtimestamp(dt))
mlab.show()
print(clf.coef_)
fopen.close()
setattr(someobject, name, user)
label_indices = [(labels == i).nonzero() for i in range(1, numL + 1)]
op.worksheet.Worksheet.iter_rows()
docvec = model.docvecs[99]
set([2, 1]) in list
CATSDllApiProto = ctypes.WINFUNCTYPE(ctypes.c_uint8, ctypes.c_double)
db.close()
urllib.request.install_opener(opener)
(list(g) for k, g in grouped)
res = np.array(sorted(a, key=lambda x: -x[0]))
plt.figure(figsize=(5.15, 5.15))
d.copy()
self.thread.start()
ax.set_ylim([177, 196])
c = numpy.linalg.lstsq(b.T, a.T)[0].T
QtGui.QWidget.__init__(self)
plt.show()
hasproperty = np.all(C)
result = dict(setup1)
g.add_edge(a[0], a[1])
signal.signal(signal.SIGINT, signal_handler)
os.setsid()
self.response.out.write(str(datetime.datetime.now() - starttime))
isinstance(obj, ModuleType)
[(x * x) for x in range(10)]
[x for x in ls if c[x] == 1]
y = dict((k.lower(), v) for k, v in x.items())
os.isatty(sys.stdout.fileno())
img_resized = image.resize((188, 45), Image.ANTIALIAS)
np.isnan(np.nan)
config.write(configfile)
d = eval(some_string)
display.flush()
min(s.find(i) for i in a if i in s)
round(x / 500.0) * 500.0
f(a, b)
images.reshape((images.shape[0], -1))
self.assertEqual(len(result), 2)
javasphinx - apidoc - -help
self.response.out.write(row)
self.d = self.d + 1
formset.save()
np.random.seed(1977)
keys = [k for k, v in list(dict.items()) if v == maxval]
lines = tuple(lines)
map(tuple, (N - 1 - np.array(list(combinations(list(range(N)), M))))[::-1])
os.path.relpath(filename, blog_images)
batch.execute(http=http)
bin(1)
d.dot(d.T)
setattr(namespace, dest, value)
ax.set_ylim([0, 2])
pd.Series(dict(col1=a, col2=b))
data = np.array(data)
plt.show()
y = r * np.sin(t)
print(any(x in regx.split(string) for x in search))
ent2.grid(row=1, column=1)
[tuple(chain.from_iterable(prod)) for prod in product(*lists)]
{{mywidget.script()}}
{{item}}
dateutil.parser.parse(date_string)
app.run()
print(etree.tostring(elem))
[0, 1, 1, 0, 0, 1],
ax.get_yticklabels()[i].set_visible(False)
sys.modules[__name__] = Foo()
l.append([])
app.run(debug=True)
plt.close()
backup.close()
t5.start()
fro.readline()
view_func(request, *args, **kwargs)
lines = sorted(shopping.readlines())
a = dict((key, value) for key, value in a.items() if key not in exclusion)
s[0].lower() + s[1:]
csum = np.cumsum(a[:, (1)])
pkgutil.iter_modules()
pattern = re.compile(pattern_string)
ax.set_yticks(np.linspace(0, 200, 11))
Tablename.objects.filter(fieldname__lt=value)
map(list, my_array)
float(x)
print(data.split())
set(d[0]).intersection(*d[1:])
np.full((200, 20, 10, 20), 0)
plt.setp(ax.get_xticklabels()[-1], visible=False)
str(0.1)
setattr(self, key, dictionary[key])
plt.subplots_adjust(hspace=0.001)
dict(zip(headers, sdata))
termios.tcsetattr(fd, termios.TCSADRAIN, old)
func(*parameters)
plt.tight_layout()
parser = argparse.ArgumentParser()
Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec = values
PrintLn(Abs(vf))
image.show()
os.remove(path)
print(urlparse.urlunparse(url_parts))
list(chain(*x))
np.array(list(itertools.zip_longest(fillvalue=np.nan, *ll))).T
logging.getLogger().addHandler(handler)
root.mainloop()
a[len(a) - 1:-len(a) - 1:-1]
foo(*t)
numpy.random.shuffle(ids)
my_list.append(int(i))
df.loc[~df.index.isin(t)]
ax.set_xticklabels(x_labels)
set(my_list) - {i for e in bad for i in my_list if e in i}
list(x[x > 0].stack().index)
dll.add.restype = c_double
numpy.where(M == 0)
[(x + 1) for x in mylist]
assert not os.path.exists(f.name)
pprint([(my_array + [i]) for i in input_elements])
mydict[key].append(line.strip())
server.serve_forever()
x[x & x - 1 == 0]
shallow_copy_of_set = old_set.copy()
random.choice(files)
deletesys.path[0]
model4.py
scipy.signal.lfilter
Department._objects.filter(group__exact=self.group)
next(i for i, j in list(enumerate(s))[::-1] if j == x)
result = json.loads(result)
server.close()
driver.close()
outer_list.sort(key=MyOrdering)
plt.plot(y)
fig = plt.figure(figsize=(5, 5))
reactor.run()
r = random.choice(numbers)
logging.disable(logging.CRITICAL)
ax2.imshow([[0, 1], [2, 0]])
time.sleep(5)
the_sum += A[k] * B[k]
type(a.tolist()[0])
[(slice(*map(int, a)) if len(a) > 1 else int(a[0])) for a in ranges]
np.random.seed(seed)
ftp.login()
[(x < 0 and x + 4 or x) for x in [1, -2, 2]]
maze_dict[r, c] = [(r - 1, c), (r, c + 1)]
e.update()
sys.stdout.flush()
simplejson.JSONEncoder.default(self, obj)
mylist.sort(key=lambda v: v.x ** 2 + v.y ** 2)
ax.imshow(data)
figure(figsize=(4, 4))
time.time()
asin(2).evalf()
f.close()
xDate = sys.argv[1]
plt.plot(x, y)
fxn()
dict(zip(x, map(x.count, x)))
session.commit()
painter.setPen(Qt.QColor(100, 100, 100))
self.assertEqual(1, 0)
connection.close()
wx.Yield()
[i for i, j in c.most_common()]
plt.clf()
print(json.load(json_file))
os.remove(os.path.join(parent, fn))
l = list(t)
np.dot(a, a)
r = requests.post(url, files=files, data=values)
threading.Thread.__init__(self)
model = sm.Logit(y, x.astype(float)).fit()
array([[24, 20, 21], [4, 0, 1], [9, 5, 6]])
os.remove(os.path.join(dirpath, file))
fib = lambda n: n if n < 2 else fib(n - 1) + fib(n - 2)
root.columnconfigure(0, weight=1)
Image.open(path)
dx, dy = 1, 0
gluLookAt(eX, eY, eZ, cX, cY, cZ, 0, 1, 0)
set([])
np.diagonal(np.dot(np.rollaxis(a, 2), a), 0, 2).T
res = [([x] * len(y), y) for x, y in d.items()]
func(*posargs, **fkwargs)
print(rawstr(test4))
b[x, y] = z
self.sftp.putfo(fileobj, path)
[n.name for n in tf.get_default_graph().as_graph_def().node]
im.show()
inset.set_ylim(axis.get_ylim())
screen.blit(background, (0, 0))
dict.__setitem__(self, key, value)
Hn = np.fft.fft(Moisture_mean_x[0])
print(str(names)[1:-1])
ssh.close()
res.cluster.value_counts()
list(itertools.chain(pat.split(line) for line in data))
[(i * j) for i, j in combinations(array, 2)]
my_objects.append(MyClass(i))
plt.draw()
[[0.4, 0.6, 0.0, 0.0], [0.2, 0.4, 0.4, 0.0], [0.0, 0.0, 0.4, 0.6]]
self.setLayout(self.layout)
a.writerows(data)
df.values - df2.values
json.dump(data, f, ensure_ascii=False)
theano.printing.debugprint(f)
fig, ax = plt.subplots()
ax.lines.remove(lines[0])
test.py
smtp.sendmail(from_addr, to_addr, m.as_string())
ch.setLevel(logging.DEBUG)
mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)
db.create_all()
ax = fig.add_subplot(111)
help(dir)
plt.show()
button.pack()
T = map(lambda i: L[i], Idx)
f = lambda x, y: x if x > 100 and y < 50 else y
line[len(prefix):]
proc.stdin.flush()
{{a}}
self.create_socket(socket.AF_INET, socket.SOCK_STREAM)
print(s, s[-1].isdigit())
t.pack()
self.Layout()
app.logger.handlers[:] = []
data.split()
today.day
dVal.apply(lambda series: series / dX)
plt.show()
abc = dict((c, string.count(c)) for c in string)
do_something()
diag_T = np.ravel(T.diagonal().copy())
result[key] += int(row[0])
ax.xaxis.set_visible(False)
names = pd.concat(names, frame, ignore_index=True)
print(my_list)
scores.close()
Response(serializer.data)
writer.writerow(row)
threading.Timer(1, greeting, (oh_hi,)).start()
[row[s] for row in LoL[r]]
np.random.choice(np.squeeze(a))
list(dict1.items()) ^ list(dict2.items())
blowfish()
np.in1d(a, b)
(k, v), = list(d.items())
output.append(float(row[4]))
log = logging.getLogger(__name__)
sys.argv[i]
a.remove(set([2]))
self.table.setRowCount(5)
array([1, 1, 1, 1, 0])
y = np.hsplit(x, np.arange(10, 129, 10))
self.queue.add(item)
print(list(a[b]))
print(b.__class__.__name__)
int(n) == n
x[::2]
plt.plot(data)
{{form.as_div}}
files = list(filter(path.isfile, os.listdir(dirToScreens)))
pd.to_datetime(df.Date).order().index
func(func, *args, **kwargs)
{str(key): value for key, value in zip(bins, count)}
m.put()
skrift1.pack(pady=5)
tekstboks.pack(pady=5)
t.start()
plt.show()
time.sleep(5)
os.system(cmd)
plt.show()
self.add(record)
subprocess.call(args)
f.close()
right.remove(right[0])
time.sleep(1)
main()
admin.site.register(ItemPending, ItemAdminPending)
out.extend(map(str, list(range(a, b + 1))))
pygame.init()
ax.invert_yaxis()
a.xaxis.set_major_formatter(ticker.NullFormatter())
foo.__class__
id = models.AutoField(primary_key=True)
threading.Thread(target=play_audio).start()
sum(isinstance(i, int) for i in a)
print(map(lambda x, y: x + [y], A, list(range(1, len(A) + 1))))
sys.stdout.write(message)
pylab.plot(x, y)
proc = subprocess.Popen(command, startupinfo=startupinfo)
print(conn.notices[-1])
self.method()
df.index.values
bmp.Bind(wx.EVT_LEAVE_WINDOW, onWindow)
data = np.loadtxt(f)
order_array = np.array(rows_list)
screen = pygame.display.set_mode(size)
instance.save()
ax.plot(xx, yy)
sum(map(pow, l, count(1)))
ts = time.mktime(dtt)
print(map(hex, a))
abs_path = os.path.abspath(file.name)
logging.basicConfig(level=logging.INFO)
res = urllib.request.urlopen(req)
(myset - (myset - set([b]))).pop() is a
app.MainLoop()
app.logger.addHandler(stream_handler)
kwargs.update(dict(zip(myfunc.__code__.co_varnames, args)))
f.read()
self.root.after(1000, self.update_clock)
min(s.find(i) for i in a)
session.query(Foo).filter(tuple_(Foo.a, Foo.b, Foo.c).in_(items))
data = f.readframes(chunk)
QtCore.QVariant()
[2, 5, 6, 7, 8, 10]
zipped = zip(mylist[0::2], mylist[1::2])
time.sleep(1)
print(pd.concat([df, df1]))
sys.exit(2)
plt.show()
board[i].append(0)
f(*args, **kwargs)
print(datetime.timedelta(days=1))
[item for item in my_list if item not in to_be_removed]
items = sorted(list(d.items()), key=keyfunc)
plt.scatter(x, y, c=z, s=20)
query_set.filter(deleted_at__isnull=True)
plot(data)
a = set(a)
self.bottom_frame.grid_columnconfigure(0, weight=1)
y = np.arange(10, 20)
settings.py
mech.set_handle_robots(False)
df = df.sortlevel(level=1, axis=1)
file.seek(-len(line), 1)
[k for k in x if type(k) == str]
list1.sort()
app.root.mainloop()
a = [row for row in a if all(row[j] <= 0 for j in range(0, len(row), 2))]
loop.run()
exit(0)
cv2.waitKey()
zip(list_a, list_b)
print(dss)
ax.set_xticks([])
rank = models.IntegerField()
plt.show()
string[0].isdigit()
application = django.core.handlers.wsgi.WSGIHandler()
data = response.json()
sys.stdout = FlushFile(sys.__stdout__)
d = {x: y for x, y in zip(m[::2], m[1::2])}
app.exec_()
app = QtGui.QApplication([])
x[np.ix_(np.arange(x.shape[0]), x_range, y_range)]
cygstart / cygdrive / c / Python27 / Scripts / ipython.exe
a = np.where(np.eye(7), np.nan, 1)
opener = urllib.request.build_opener()
areas.apply(multiply_by_demand).unstack(0)
btn.pack()
df[(df.values > 1.5).any(1)]
[([k] * v) for k, v in list(Counter(L).items())]
os.listdir(base)
yourcode()
indices = np.where(a >= 1.5)
window.show()
x = list(x)
plt.subplot(122)
content = urllib.request.urlopen(req).read()
unittest.main()
sift = cv2.xfeatures2d.SIFT_create()
np.where(np.isnan(a), ma.array(a, mask=np.isnan(a)).mean(axis=0), a)
{k: v for k, v in somedict.items() if key_criteria_func(k)}
print(df)
np.roll(a, -1)
[(new_element if i in indices else e) for i, e in enumerate(lst)]
plt.show()
map(int, list(bin(YOUR_NUMBER)[2:]))
d = {name: int(value) for name, value in splitstrs}
plot(x, y)
plt.ylim(1, 0)
print(np.may_share_memory(a, b))
plt.show()
pd.DataFrame(d)
print(datetime.datetime.fromtimestamp(dt))
gevent.joinall([job1, job2])
plt.show()
shutil.rmtree(self.name)
b.shape
elementwiseApply(add, [[0, 0, 0], [0, 0], 0], [[4, 4, 4], [4, 4], 4])
[x for x in list_1 if isinstance(x, numbers.Number)]
datetime.datetime.utcfromtimestamp(x.tolist() / 1000000000.0)
f.write(mytext)
set([0, 9, 4, 6, 7])
apps.get_models()
print(match.group(0))
time.sleep(1)
ax.scatter(x, y, z)
list(set(q) & set(w))
user.save()
response
cbar = fig.colorbar(result)
self.frame.Show()
prettyHTML = soup.prettify()
root.mainloop()
plt.show()
np.count_nonzero(np.bitwise_xor(a, b) & r != 0)
list[:10]
run_cmd()
file.writelines(data)
self.show()
sys.stdout.flush()
example1()
assertDictEqual(dict1, dict2)
df.sort(axis=1, inplace=True)
Eat = 0
text = sys.stdin.read()
min(max(num, start), end)
extension = os.path.splitext(filename)[1][1:]
index_list.append([(i + temp) for i in range(items)])
plt.show()
df.Cat1 = np.where(df.Cat1.isnull(), df.Cat2, df.Cat1)
unique_longest_strings = list(set(longest_strings))
df = pd.DataFrame.from_records(data)
Tkinter.Frame.__init__(self, root)
logger = logging.getLogger(__name__)
(lambda : 1)() == (lambda : 1)()
app.jinja_env.filters.update(my_filters)
stopword_pattern = re.compile(stopstring)
startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
data.append(row)
[LoL[i][s] for i in range(len(LoL))[r]]
df[df.index.levels[0].isin(stk_list)]
DBSession = scoped_session(sessionmaker(bind=engine))
plt.pause(0.5)
print(time.mktime(datetime.datetime.now().timetuple()))
getattr(parent, collection).append(child)
result.append(b[index - 1])
row = [item[0] for item in cursor.fetchall()]
plt.show()
B, C = A[::2], A[1::2]
proc.communicate()
np.arange(1, a.shape[1], 2)
plt.show()
ax.lines = []
df1.ix[0,]
x = all(list_of_bools)
print([(k, len(index[k])) for k in sorted(index.keys())])
my_model.duration = datetime.timedelta(days=20, hours=10)
np.argwhere(np.in1d(a, np.intersect1d(a, b)) == False).flatten().tolist()
print((len(s), len(data), data))
sorted(qs, key=lambda n: (n[0], int(n[1:])))
dict(enumerate(google_price_data, start=1))
json.load(f)
print(decoded.strip())
[k for k, v in list(d1.items()) if v == max(d1.values())][0]
print(row.get_text())
process.exit()
sys.stdout.flush()
gtk.main()
[x for x in seq if x not in seen and not seen.add(x)]
p.start()
print(socket.gethostname())
driver.close()
anyTrue = any(somePredicate(elem) for elem in someIterable)
loop.close()
weekdays[datetime.now().weekday()]
data_json = simplejson.dumps(data_dict)
getattr(obj, name)
np.unique(a.round(decimals=4))
set(x * x for x in range(10))
sys.exit(1)
d.setdefault(item[0], []).append(item[1:])
plt.show()
[dict(zip(keys, row)) for row in zip(nums, chars)]
f.seek(old_file_position, os.SEEK_SET)
mylist.pop(0)
new_d = pd.Series(d)
df = df.applymap(str)
df = pd.DataFrame([])
fig.autofmt_xdate()
a.append(1)
q = {(i, j): (0) for i in range(5) for j in range(4)}
print(request.get_message().request_body.flatten().data)
models.py
func()
plt.plot(x, g(x), zorder=1)
set(d2.items()).issubset(set(d1.items()))
session.query(BlogPost).filter_by(visible=True)
Gtk.main_quit()
twrv.start()
tasks[sys.argv[1]]()
users = db.session.query(User).all()
random.shuffle(items)
f.close()
self.show()
subprocess.call(row, shell=True)
print([columns[0] for column in cursor.fetchall()])
np.minimum.accumulate(a)
interleaveHelper(lst[:len(lst) / 2], lst[len(lst) / 2:])
int(input(msg))
print(json.dumps(somedict))
time.sleep(1)
pl.show()
sys.exit(0)
name.__class__.__class__
session.query(ZKUser).filter(ZKGroup.id.in_([1, 2])).all()
len([char for char in unistr if unicodedata.combining(char) == 0])
x.as_matrix()
[elem for elem in some_iterable]
imshow(gray1, cmap=cm.gray, alpha=0.5)
dict(dict_list)
c.flatten()
plt.show()
matched[0]
zipDocment.extractall()
np.sort(reference)
v = data[row][col]
list_2 = [num for num in list_1 if isinstance(num, (int, float))]
sys.stdout.write(alphabet[bisect.bisect(f_list, random.random()) - 1])
session.rollback()
map(numpy.random.shuffle, a)
[item for item in x if not y.intersection(item)]
nextmonth = datetime.date.today() + relativedelta.relativedelta(months=1)
x[index] if -len(l) <= index < len(l) else default
result = [r for r, in result]
app.MainLoop()
list_of_tuples = [(x, y) for x, y, label in data_one]
bisect.bisect(grid, value)
print(Matrix[0][0])
frame.grid(row=0, column=0, sticky=N + S + E + W)
print(sys.argv[0])
a.deiconify()
self.conn.send(msg)
print(calendar.timegm(d.timetuple()))
keys = set().union(*all_dicts)
Py_Finalize()
x ** 2
ax.grid()
shutil.move(name, dst)
text = dlg.ui.lineEdit.text()
plt.show()
sys.exit(app.exec_())
app.logger.setLevel(logging.DEBUG)
start_server()
np.random.shuffle(a.flat)
shutil.copytree(from_path, to_path)
cogrouped.mapValues(lambda x: (list(x[0]), list(x[1]))).collect()
curses.endwin()
l.sort(key=itemgetter(1), reverse=True)
pd.DataFrame(data)
[10, 40, 60, 90, 100]
np.random.choice(array1, 5)
{k: (p[k] - m[k] ** 2) for k in m}
f = open(fpath)
t.start()
plt.figure()
object.__setattr__(self, name, value)
[[m[row][col] for col in range(0, width)] for row in range(0, height)]
json_data.close()
self.setSizePolicy(QtGui.QSizePolicy.Expanding, QtGui.QSizePolicy.Fixed)
os.isatty(sys.stdout.fileno())
list(b)
logging.Handler.__init__(self)
os.killpg(process.pid, signal.SIGKILL)
scaling = np.array([dx, dy, dz])
complete_path = os.path.join(root_path, sanitised_path)
print(f())
Photo.objects.filter(tags=t1).filter(tags=t2)
data = [[eval(x) for x in y] for y in data]
list(s)
writes.writerows(mygen(reader))
QtCore.Qt.ItemIsEnabled
plt.pcolormesh(X, Y, Z)
assert f([[0, 100], [0, 10], [10, 20], [15, 40]]) == [[0, 10], [15, 40]]
ser.close()
primes = {x for x in range(2, 101) if all(x % y for y in range(2, min(x, 11)))}
dups = [x for x in list_a if list_a.count(x) > 1]
email.send()
print(r.url)
list(chain.from_iterable(sorted(sub) if len(sub) > 1 else sub for sub in G))
row.remove(row.getchildren()[1])
Py_Finalize()
x = np.linspace(-np.pi, np.pi, 100)
print(model.summary())
result = sorted(iter(dictionary.items()), key=lambda k_v: (k_v[0].field, k_v[1]))
ax.set_xticks(np.arange(0, 6, 1))
math.isnan(b)
df2.plot(ax=axes[0, 1])
json.dumps(a, default=encode_b)
pd.end_time = pandas.to_datetime(pd.end_time)
x = tf.Variable(tf.constant(0, shape=[2, 2]))
int((value - epoch).total_seconds())
ax.xaxis.set_visible(False)
a = dict.fromkeys(a, 0)
self.root.destroy()
self.Acceuil.show()
lst.append(st[i:i + 10])
current_module.new_name = func
self.configure(image=self.image)
animals.sort(key=lambda name: (name[0], -len(name), name))
HttpResponse(status=204)
array([1]), array([0])
print(datetime.now() - datetime.combine(bday, time()))
[k for k, v in sorted(iter(d.items()), key=lambda k_v: (-k_v[1], k_v[0]))]
plt.show()
np.where(a > 0)
isinstance(y, float)
zip(*a)
classifier.fit(X_train, y_train)
ax.set_xlim([-2, 2])
sys.exit(0)
np.split(data, np.where(np.diff(data) != stepsize)[0] + 1)
conn.commit()
[self[n] for n in range(start, stop)]
parser = argparse.ArgumentParser()
sys.argv[1]
d = make_defaultdict(2, list)
print((x, y))
sum(dict[i] for i in range(1, 5))
subprocess.call(cmd, shell=True)
arr.sum(axis=(0, 1))
wordset = set(wordlist)
shutil.copy(src, dst)
b.remove(e)
dict(MyClass(5, 6, 7))
new_file.close()
raw_bytes = (ctypes.c_ubyte * 20).from_buffer_copy(str_bytes)
dict(itertools.chain.from_iterable(list(dct.items()) for dct in dicts))
plt.show()
A[i, j] = D[i, j]
self._body
self.setLayout(layout)
[k for k in itertools.chain(*(list(d.keys()) for d in list(foo.values())))]
pyplot.show()
serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
s = pd.Series(np.random.randn(5))
main()
array([[1.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 1.0], [0.0, 0.0, 1.0, 1.0]])
form = waypointForm(user)
app.MainLoop()
sys.stdout.write(mystdout.get_text())
l.index(d)
filtered_numbers = [n for n in numbers if len(repr(n)) == len(set(repr(n)))]
modernthingy = zopethingy.asdatetime()
[list(x) for x in dt.T.itertuples()]
df.apply(func, axis=1)
print([x for x in range(2, 100) if not [t for t in range(2, x) if not x % t]])
soup = BeautifulSoup(f)
A[1:1] = B
new_df = pd.concat([new_df, extract_df], ignore_index=True)
np.diff(m.tocsr().indptr)
db.session.commit()
foo()
self.ax.axis([-10, 10, -10, 10])
[j() for j in [create_lambda(i) for i in range(10)]]
print(list_end_counter([1, 2, 1, 1, 1]))
df = pd.DataFrame(data[1:], columns=data[0])
ax.get_yticklines()[i].set_visible(False)
unittest.main()
Clock.schedule_interval(self.update, 2)
foo = d.get(x, bar)
plot_df.plot(subplots=True)
plt.draw()
[(ix, iy) for ix, row in enumerate(a) for iy, i in enumerate(row) if i == 0]
self.set_tab_reorderable(tab.child, True)
df.apply(pd.value_counts)
self.origstream.write(self.escape_char)
notlast = lambda lst: itertools.islice(lst, 0, len(lst) - 1)
p1.start()
s = set(A() for i in range(1000000))
images[idx].reshape(90, 90)
cv2.destroyAllWindows()
writer.writerow(row)
dict((key, value) for key, value in a.items() if key == 1)
ran_floats = [random.uniform(low, high) for _ in range(size)]
results = map(lambda x: (x[0], x[1:]), reader)
session.commit()
axis.set_major_formatter(ScalarFormatter())
response = serializers.BooleanField(required=True)
df = df.iloc[:, ([j for j, c in enumerate(df.columns) if j != i])]
date = models.DateTimeField(default=datetime.now, blank=True)
x, y = (val - delta for val, delta in zip((x, y), (1, 2)))
[np.argmin(a) for a in A2]
df
query = query % conn.escape(args)
setattr(Foo, v, 0)
process.start()
np.abs(a - b) < atol + rtol * np.abs(b)
map(list.__add__, L1, L2)
cnxn.commit()
list(range(x1, x2 + 1))
np.delete(arr, 2, axis=1)
plt.scatter(X, Y)
everyone = [friendlies + enemies]
cls(a, b)
jsonFile.close()
ax.set_xticklabels(alphab)
__init__.py
scipy.linalg.cython_blas
admin.site.register(Contest, ContestAdmin)
files_list.sort(key=operator.itemgetter(1))
l2 = [l1.index(x) for x in sorted(l1)]
plt.show()
print(list(db.keys()))
lowess(y, x)
print(time.time())
y = tuple([(z * 10) for z in img.size])
mydict = {x[0]: x[1]}
pumpedThread.start()
Fraction(0.185).limit_denominator()
c.update(line.split())
b = cosfromsin(x, a)
map(str, numbers)
lbl7.grid(row=1, column=0)
np.where(cond, arr, -100).argmax(1)
threading.Thread.__init__(self)
app.run(processes=2)
time.sleep(0.1)
send_file(tempcreator.somePath)
grequests.map(rs)
print(neigh.predict_proba([[0.9]]))
directory_list.append(os.path.join(root, name))
foo(a[:, :, (np.newaxis)] - b[:, (np.newaxis)])
tree.write(filename, pretty_print=True)
timestamp = (utc_naive - datetime(1970, 1, 1)).total_seconds()
i += 1
abc = dict((c, string.count(c)) for c in set(string))
timestamp = dt.timestamp()
tree = html.fromstring(page)
plt.show()
__init__.py
axe.set_xticklabels(df.index, rotation=0)
self._dynprop
dict[array[i][0]] = array[i][1]
subprocess.call(command.split(), shell=False)
print(_[0][0].decode(_[0][1]))
[c for c in col_names if not any(f in c for f in filter_array)]
b = word in wordList[:1] + wordList[2:]
scatter([(a, b) for a, b in zip(x, y) if a > 0 and a < 10])
ZipFile.write(os.path.basename(a), compress_type=zipfile.ZIP_DEFLATED)
mydict = dict.fromkeys(string.printable, 0)
int(math.log(n, 2))
print([a[i], a[i + 1]])
v.split()
json.dumps(pyDict)
self.Bind(wx.EVT_LEFT_UP, self._onMouseUp)
fig.autofmt_xdate()
results = cur.fetchall()
MyApp().run()
self.assertEqual(response.status_code, 200)
A[(0, 2), :, 1:]
[a[row, col] for row, col in enumerate(col_index)]
popt, pcov = curve_fit(goal, xdata, ydata, p0=[1] * 5)
metadata.create_all(engine)
plt.show()
self.setupUi(self)
print((name, val))
[hex(ord(c)) for c in data]
[2, 1, 0]
sm[(np.random.sample(sm.shape[0], K, replace=False)), :]
ax = fig.add_subplot(1, 1, 1)
time.sleep(60)
list(filterer(list1, list2))
data = {tuple(item) for item in map(sorted, lst)}
con.close()
sorted(gen)
my_handler.setLevel(logging.INFO)
plt.close()
session2.commit()
np.fill_diagonal(a, 0)
[item for t in tuples for item in t]
qs.filter(name__startswith=self.kwargs.name)
(foo().bar() if condition else foo()).baz()
hscrollbar.grid(row=1, column=0, sticky=E + W)
time.sleep(2)
pd.concat([df.T[x] for x in df.T], ignore_index=True)
round(0, 4)
cor.loc[:, :] = np.tril(cor.values, k=-1)
logging.getLogger(my_module.__name__).setLevel(logging.DEBUG)
print(df.groupby(ind).head())
np.where(a == a.max())
print(map(joiner, sixgrams))
time.mktime(time.strptime(time1, format))
a[(0), :, :], a[(1), :, :], a[(2), :, :]
plt.show()
f.close()
asyncio.get_event_loop().run_until_complete(hello())
ax.yaxis.set_minor_locator(MultipleLocator(0.2))
[(i in fruit_dict2) for i in fruits]
workbook.close()
plt.show()
print(my_list[-1])
html = driver.page_source
fig = PLT.figure()
fruitdict[i] = locals()[i]
plt.show()
ax = fig.add_subplot(1, 1, 1)
your_method()
np.sum(arr[1:-1, 1:-1])
plt.colorbar()
print(flatten_count(x, 1))
np.getbufsize()
self.decorator(func)
item_set[category].append(item)
plt.xticks()
list(zip(lst[:-2], lst[1:-1], lst[2:]))
ax = fig.add_subplot(111)
result = [(x * P) for x in S]
bar[a:b:c].foo()
json.JSONEncoder.default(self, obj)
pl.clf()
data = [(line[0], line[1:]) for line in csv.reader(f)]
writer.writerow(row)
print(cv2.__version__)
[log(y, 10) for y in x]
df
[x for i, x in enumerate(unculledlist) if i % 6 % 2 == 0 if i % 5 % 2 == 0]
time.sleep(delay)
startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
[x for x in lst if x % 2 == 0]
new_df.iloc[0, 0] = 1
s.setsockopt(SOL_SOCKET, SO_BROADCAST, 1)
min(l1, l2)
os.remove(file_list.pop())
self.crawler.engine.unpause()
ax2.set_yticklabels(y_label2, fontsize=20)
self.driver.quit()
ax.legend(numpoints=1)
con.commit()
soup = BeautifulSoup(html)
threading.Thread.__init__(self)
string[start:end]
tuple(d[k] for k in keys)
etree.fromstring(xml_response)
conn.close()
subprocess.call(cmd, stdin=subprocess.PIPE)
{k: d1[k] for k in list(d1.keys()) & l1}
json_docs = [json.dumps(doc, default=json_util.default) for doc in cursor]
plt.show()
df.columns[np.argsort(df.values)]
df.groupby(level=0, group_keys=False).apply(first_last)
plt.show()
g.sum()
[[400, 200]]
df1.loc[df2.index[0]] = df2.iloc[0]
get_color(1)
fig.set_figwidth(24)
[a[x:x + seg_length] for x in range(0, len(a), seg_length)]
ax = fig.add_subplot(111)
print([zip(A, item) for item in product(B, repeat=len(A))])
print(sys.stdin.readline())
random.shuffle(data)
self.layout().addWidget(self.child)
logger.setLevel(logging.DEBUG)
np.count_nonzero(df.isnull())
start_time = time.time()
intbids.append(int(bid))
[dict(template, **{k: value}) for value in add]
print(time.mktime(d.timetuple()))
[Request(self.start_url, callback=self.parse_listings, follow=True)]
time.sleep(20)
ws.cell(row=1, column=1).style.border.top.border_style = borders.BORDER_MEDIUM
[(x + y) for x, y in zip_longest(reversed(P), reversed(Q), fillvalue=0)][::-1]
unittest.main()
x[mask] = np.nan
table.append(row)
len()
workbook.close()
nsolve([x * y - 1, 4 * x ** 2 + y ** 2 - 5], [x, y], [1, 1])
reactor.run()
print(math.ceil(v * 100) / 100)
example[4:1]
out = [np.sum(data[c]) for c in contribs]
plt.show()
conn.rollback()
next(x for x in list_of_tuples if value in x)
screen.blit(image, (0, 0))
arr.resize((arr.shape[0] * 2, arr.shape[1]))
b.close()
a[tuple(idx.T)] = 5
fig = plt.figure()
libc.cprogram(wts, res, kks, byref(n), ex)
c = np.concatenate((a, b))
time.sleep(1)
df.reindex([2, 0, 1])
np.array(map(str, a))
buff += sys.stdin.read(1)
lst.sort()
{{a.some_other_field}}
mydic = {}
datetime.datetime(2001, 12, 11, 0, 0)
ax.set_aspect(2)
[len(list(group)) for value, group in itertools.groupby(b_List) if value]
output = stdout.read()
db_col_data = json.dumps(latest_data)
do_stuff()
sum(len(v) for v in d.values())
print(new_list)
result.append((btoa[k], k))
admin.site.unregister(User)
[0, 1, 1, 1, 0],
self.assertEqual(response.status_code, 200)
pixels.append(((x, y), pixel[:-1]))
dist = numpy.linalg.norm(a - b)
x.reshape(-1, np.prod(x.shape[-2:])).shape
newshapeA = A.shape + (1,) * (N + 1 - A.ndim)
predictions = [t.predict(testData) for t in trees]
data.append(json.loads(line))
List_name = df_name.values.tolist()
json_output = json.dumps(my_query)
y = set(x.flat)
[sum(int(i) for i in num) for num in list]
time.sleep(1)
print(np.allclose(coeffs1, coeffs2))
np.random.seed(seed)
kOUT = np.zeros(N + 1, dtype=object)
cython.ushort
cython.longlong
cython.ulonglong
[(i - 1) for i in l]
plt.show()
urllib.request.install_opener(opener)
browser._update_state(response)
OrderedDict(lla[::-1])
trainer = BackpropTrainer(n, dataset=ds, learningrate=0.1, verbose=True)
self.close()
image.close()
df[~df.index.isin(df_a.index + df_b.index)]
ent.grid(row=0, column=1)
i.setGridIntersection(i.pos())
main()
coords.reshape(-1, 2)
result = my_func(**vars(args))
cv2.waitKey(0)
hsz = wx.BoxSizer(wx.HORIZONTAL)
df.groupby(dr5minute.asof).agg(ohlcsum)
sum(1 for _ in iter)
self.ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
seen.add(i)
plt.imshow(rotate_lena_noreshape, cmap=plt.cm.gray)
s.send(data)
VVg1 = np.sum(np.multiply(EVV1[:n, :], VV[:, (np.newaxis)]), axis=0)
[tuple(sequence[i:i + n]) for i in range(count)]
c = copy.deepcopy(a)
print(sys.path)
list(d.items())
urllib.parse.quote(a)
[dict(template, z=value) for value in add]
wrapped()
sorted(lst, key=lambda x: x[1], reverse=True)
df.iloc[:, 2:] = a
print(int(Nationality.PL))
as_strided(a, shape=(2, 2, 2, 2), strides=(2 * s, 0, s, 0)).reshape(4, 4)
f.read()
root.destroy()
map(min, zip(*alist))
dict(lst)
main()
print(ET.tostring(tree))
driver = webdriver.Chrome(chrome_options=options)
filtered_d = dict((k, d[k]) for k in keys if k in d)
[token for token in text.split() if token.isdigit()]
print(np.fft.fft(x))
d[k].append(v)
main()
a_unique_max[np.argsort(perm[last])]
lst.sort(key=lambda x: x[1])
ax.scatter(x, y, z)
print((cities[0][0], cities[1][0]))
p.Start()
dict(zip(keys, values))
max_value = max(my_list)
user = models.ForeignKey(User)
listings = list(get_listings())
reversed(sorted(a.keys()))
signal.signal(signal.SIGALRM, _handle_timeout)
[1, 1, 0, 1, 0, 1]
ax = fig.add_subplot(1, 1, 1)
cv2.waitKey(0)
self._s.get(k.lower())
lst[1::2]
lots_list.sort(mycmp)
variable = sys.stdin.read()
f1.write(line)
self.socket.close()
mobile = models.CharField(max_length=16)
len(df.columns)
print(get_drives())
res = [s[i - 2:i + 1] for i in range(2, len(s)) if s[i] == s[i - 2]]
str(float(your_string_goes_here))
df[~df.field.isin(ban_field)]
slices = diagonal.reshape(-1, 2)
__init__.py
gtk.main()
test()
self.send_response(200)
pl.figure(1)
result = cursor.fetchall()
np.concatenate((a1, b1))
my_list2 = [i[0] for i in my_list]
[1][0][1]
vectors / norms.reshape(1, -1)
settings_dir = os.path.dirname(__file__)
print(line)
m.create_all()
lines.append(ax.plot(np.arange(1000) / 2.0))
sys.exit(1)
self.button.clicked.connect(self.handleButton)
result.update((k, dol1[k] + dol2[k]) for k in set(dol1).intersection(dol2))
sys.stdout.flush()
response = requests.delete(url, data=json.dumps(payload), headers=headers)
a[0:1][0] = 1
df = pd.DataFrame([series])
print(nplats[index], nplons[index])
print([tuple(x for x in y if x) for y in a])
history.append(next(sequence))
zip(t[::2], t[1::2])
print(max(foo))
sys.modules[__name__].__file__
test()
itertools.zip_longest(fillvalue=fillvalue, *args)
Z[(raw[:, 0:2] - minimum(raw[:, 0:2], axis=0)).T.tolist()] = raw[:, (2)]
sns.kdeplot(x, shade=True)
c.save()
plt.close()
Counter(words).most_common(10)
df.plot()
app.mainloop()
celery.config_from_object(celeryconfig)
time.sleep(random.random())
dic.setdefault(key, []).append(item[-1])
list(itertools.product((0, 1), repeat=4))
print(find_nearest(array, value))
logfile.close()
plt.legend()
pygame.sprite.Sprite.__init__(self, self.groups)
print(len(someList))
d[pair[0]] = int(pair[1])
items = sorted(list(ipCount.items()), key=my_key)
page = html.fromstring(urllib.request.urlopen(url).read())
list = x.split()
nic.EnableDHCP()
map(id, a[1:])
logging.basicConfig(level=logging.ERROR)
lst.count(1) > 1
msg.send()
sorted(adict, key=adict.get, reverse=True)
convert_file(sys.argv[1], sys.argv[2])
wb.save(filename=dest_filename)
sorted(l1, key=lambda id_and_name: id_and_name[0])
[0, 0, 0, 0, 0, 0, 1, 1],
beat(app=app).run()
new_dic.setdefault(1, {})[2] = 5
matrix.append([0] * ncols)
print(f(2))
random.shuffle(values)
splitlists = [mylist[i:i + n] for i in range(0, len(mylist), n - 1)]
pd.DataFrame(dfN, columns=wordlist).fillna(0)
print(line)
next(key for key, value in d.items() if value == my_value)
data = File.read(16 * 1024 * 1024)
plt.show()
time.sleep(sleep_time)
dict(((a, b, c), 1) for a in A for b in B for c in C)
pygame.display.set_mode((infoObject.current_w, infoObject.current_h))
os.path.dirname(foo.__file__)
plt.contour(r * np.cos(t), r * np.sin(t), z)
nx.draw_networkx(G, pos)
plot(b[:, (0)], b[:, (1)])
label.pack()
len(gc.get_referrers(my_obj))
data.get(num, data[min(list(data.keys()), key=lambda k: abs(k - num))])
np.random.seed(0)
json.dumps(row)
print(line)
make_list = ArrayField(models.CharField(max_length=200), blank=True)
mod == __import__(module_name)
self.assertEqual(res, 7)
file1.close()
subset = df2.columns[-k:]
A = (B == np.arange(M)[:, (np.newaxis)]).dot(C.T)
lst.attr.get(idx, default_value)
screen.fill((0, 0, 0))
df = df.merge(df.apply(calculate, axis=1), left_index=True, right_index=True)
[(1, 4), (6, 8), (10, 10)]
lbl6.grid(row=0, column=0)
np.empty((M, N, L))
sorted(lst)
Route.objects.filter(stops_forwards__contains=[285])
plt.show()
random.shuffle(random_order)
sess.run(train_op)
items.sort()
writer.writerow([test_data[0][1]])
signal.signal(signal.SIGINT, self.old_handler)
dir(settings)
python - V
print(etree.tostring(root, pretty_print=True))
pprint.pprint(list(cursor))
QtGui.QWidget.__init__(self, parent)
df.stack().dropna().reset_index(drop=True)
pygame.display.list_modes()
list(chain(repeat(0, a.count(0)), compress(a, a)))
file_date_tuple_list.sort(key=lambda x: x[1], reverse=True)
plt.gcf().canvas.draw()
sum(totals.values())
data = json.loads(result.text, object_pairs_hook=OrderedDict)
myscript.py | xclip
np.random.seed(0)
pg.display.flip()
[[next(b) for _ in range(x)] for x in l]
webbrowser.open(url)
simplejson.JSONEncoder.default(self, obj)
start_date = local_tz.localize(start_date)
dict.__init__(self, *args, **kwargs)
sum(n * (n - 1) // 2 for n in list(index2count.values()))
print(match.group(1))
d.save()
ax.legend()
csv.writer(f, quoting=csv.QUOTE_NONE).writerows(cursor)
self.driver.implicitly_wait(20)
writer.writerows(data)
all_words = set(gen_words(txt))
df.join(s)
s[s == 12].index
all(x != y for x, y in itertools.combinations(objs, 2))
test_f()
ax.patch.set_visible(False)
fh.write(h.hexdigest())
ax[1].plot(np.arange(2) / p, c=c)
time.sleep(1)
writer.writerows(zip_list)
sys.path
bar.sort(reverse=True)
app.mainloop()
a.reshape(-1, R).mean(axis=1)
np.where(np.logical_and(a >= 6, a <= 10))
pool = Pool(processes=5)
{{my_json | safe}}
root.grid_rowconfigure(0, weight=1)
writer.writerow(reorderfunc(row))
allsum = mask.sum()
print(my_file.read())
fib(n - 1) + fib(n - 2)
platform.architecture()
min(x, key=lambda t: (t[1], -t[0]))
ax.plot(list(range(10)))
[x for x in A if x not in subset_of_A]
subprocess.Popen(cmd)
greeter.greet()
sys.maxsize + 1
self._handle.close()
output, err = process.communicate()
base64.b64encode(chr(255))
list(ordered_dict.keys())[2]
np.diag(A.dot(B.T))
pylab.show()
keys.add(parts[1])
myreportscode.py
plt.xlim(0, 4)
main()
buff.seek(0)
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
time.sleep(0.5)
any(first == c for c in letter)
vectors.T / norms.reshape(-1, 1)
wx.Frame.__init__(self, wx.GetApp().TopWindow, title=self.title)
sorted(list(some_dict.items()), key=operator.itemgetter(1), reverse=True)[:10]
array([[11.4, 4.0], [12.0, 5.0]]),
self.text.focus()
[e.value for e in Color]
path, file = os.path.split(path_and_file)
writer.writerow(row)
cb = plt.colorbar(sc, ax=ax1, aspect=10)
f.write(file_str)
copy.copy()
load_documentation()
{{toctree(collapse=False)}}
g[:] = (elem[:12] for elem in g)
print((i, p))
df = pd.DataFrame({i: list(range(1000)) for i in range(100)})
fig = plt.figure()
sum(1 for i in set(list_of_purple_items) if i not in main_set)
users = User.objects.filter(event__in=events)
int(utc_mktime(dt.timetuple()))
scroll = Gtk.ScrolledWindow(hexpand=True, vexpand=True)
f2.close()
datetime.timedelta(2.5)
ax = fig.add_subplot(1, 1, 1)
norm.cdf(norm.ppf(0.95))
not float(your_number).is_integer()
arr.append([0, 0, 0, 0])
df.as_matrix(columns=df.columns[1:])
self.setdefault(key, self.default_factory(key))
array([[1, 1], [2, 2]])
common_keys = [k for k in dict1 if k in dict2]
l.last_index()
rule_list = [cls() for cls in Rule.__subclasses__()]
collections.Counter(dictionary).most_common(2)
[0, 0, 0, 1, 1, 1, 0, 0],
set(tuple(element) for element in xx)
f.close()
time.sleep(2)
ax1.plot(list(range(2)), list(range(2)), linewidth=2)
c[tuple(list1[0])]
tornado.ioloop.IOLoop.instance().start()
all(item1 == item2 for item1, item2 in zip(list1, list2))
sorted_rows[i[0]].append((i[1], i[2]))
sc = plt.scatter([1, 1], [data.min(), data.max()])
Response(serializer.data, status=status.HTTP_200_OK)
AC_SUBST([PYTHON_CFLAGS])
some_list.append(some_list)
imagedata.put()
a[~b] = np.nan
conn.commit()
pool = Pool(processes=1)
p = numpy.vstack([p, q])
transaction.commit()
np.random.seed(seed)
ax.xaxis.set_major_formatter(hfmt)
deletemylist[:]
pyplot.show()
p.start()
os.path.join(expanded, filename)
opener = urllib.request.build_opener(MyHTTPHandler)
win.set_app_paintable(True)
app.exec_()
IOLoop.instance().start()
l = [y for x, y in sorted(zip([key(i) for i in l], l))]
all_my_models = MyModel.objects.all()
sm = plt.cm.ScalarMappable(cmap=my_cmap)
fsock.close()
QtGui.QWidget.__init__(self, parent)
plt.draw()
[(x + y) for x, y in zip_longest(P, Q, fillvalue=0)]
MPI_Finalize()
s.close()
print(x.apply(lambda a: list([v for v in a if v == v])))
ax.add_patch(rect)
array([[0], [0], [0], [1], [1], [0]])
sorted(trial_list, key=trial_dict.get)
inspect.getouterframes(inspect.currentframe())[1][1:4][2]
set(a_list).intersection(a_string.split())
cv2.waitKey(0)
app.run(debug=True)
sys.stdout.flush()
print(soup.prettify())
object.__getattribute__(self, name)
pfile.close()
zin.close()
x == y and type(x) == type(y)
print(hashlib.sha1(json.dumps(b, sort_keys=True)).hexdigest())
print(line)
[(4 if x == 1 else x) for x in a]
sys.stdout.flush()
list(chain(*zip_longest(d, e[::-1])))
colorbar()
p.terminate()
new_list
float.hex(8.25)
layout.addWidget(self.button)
np.hstack([np.repeat(a, len(a), 0), np.tile(b, (len(b), 1))])
server.quit()
a.sort()
json.dumps(dict)
self.layout.addWidget(self.button)
a[slice(*b)]
reactor.run()
s[start:end]
sys.exit(app.exec_())
rank = models.IntegerField(default=0)
xax.setTicks(ticks)
indata = fp.read()
pd.stats.moments.rolling_std(timeseries, periods, ddof=0)
sorted(list(a_dict.items()), key=lambda k_v1_v2: k_v1_v2[1][1])
df.T.apply(lambda x: x.nunique(), axis=1)
print(cls.__name__)
print(request.LANGUAGE_CODE)
self.cls.instances[key]
q = Queue.Queue()
self.save_m2m()
self.show()
[random.random() for i in range(N)]
requests.get(url, cookies=load_cookies(filename))
id = db.Column(db.Integer, primary_key=True)
[(i[0] + j[0], i[1] + j[1]) for i, j in zip(a, b)]
[i for i in L1 if i in L2]
admin.site.register(User, UserAdmin)
os.path.basename(fullpath)
main()
a[1:4].sort()
np.where(detected_minima)
sorted(s1, key=trailing_digits)
ssc.awaitTermination()
ax = fig.add_subplot(111)
ax.w_xaxis.set_major_formatter(ticker.FuncFormatter(format_date))
myFunction()
response = subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT)
text = text.translate(replace_punctuation)
print(now - dateutil.relativedelta.relativedelta(months=1))
main()
root.clear()
Article.objects.all().delete()
sqlContext.createDataFrame(rdd)
screen_width = root.winfo_screenwidth()
dupl = np.where(mask)[1]
self.lc.Bind(wx.EVT_MOTION, self.OnMouseMotion)
a = [x[:] for x in [[0] * cols] * rows]
[f(x) for x in l if f(x)]
result = child.communicate()[0]
test.myfun(f)
args = parser.parse_args()
mylogger.setLevel(logging.INFO)
foo.mymethod(1, 2)
df.loc[df.loc[:, (columns)].eq(value).all(axis=1)]
data.groupby(data.date.dt.year)
dir()
df.groupby([times.hour, times.minute]).value_col.sum()
df = DataFrame(np.random.randn(1000, 2))
plt.show()
app.run()
[dict(items) for items in product(*flat)]
print(sum(1 for _ in f))
r = np.hypot(x, y)
print(cts.minute == 0)
reactor.run()
mydict = {rows[0]: rows[1] for rows in reader}
pprint(d, width=40)
binary_string = binascii.unhexlify(hex_string)
dict(a)
d = d.replace(tzinfo=tz)
a.sum(axis=0)
proc.kill()
p = Process(target=f, args=(arr,))
main()
plt.show()
random.uniform(0, numpy.nextafter(0, 1))
[e for e in lelist if e in lestring]
ax.grid(True)
plt.show()
print(iorf.fup(2))
x.pop()
random.shuffle(idx)
ax0.yaxis.set_ticks(np.arange(70000, 80000, 2500))
response = requests.post(url, files=files)
plt.show()
source.close()
curses.endwin()
mpmath.besselk(0, 1714)
int(1 / 2)
self.a, self.b = a, b
name = models.CharField(max_length=64)
deleteglobals()[name]
plt.figure()
df.subtract(df2, fill_value=0).reindex_like(df).astype(int)
[x for x in lst if x % 2 == 0]
print(z[k.astype(int)])
bigfloat.exp(5000, bigfloat.precision(100))
con.commit()
[(), (0,), (1,), (2,), (0, 1), (0, 2), (1, 2), (0, 1, 2)]
xarr, yarr = array[(0), :], array[(1), :]
ax.add_patch(polygon)
plt.imshow(np.array(img.tolist()))
sys.exit(start_ipython())
time.sleep(timeout)
set.union(*lis)
__init__.py
sorted(a, key=a.count, reverse=True)
driver.add_cookie(cookie)
{{count}}
sys.exit()
itertools.chain(*itertools.zip_longest(*iters))
[i for i, j in mylist]
strata = np.array(strata)
self.show()
ax = fig.add_subplot(111)
mylist.sort(key=sort_func)
client.close()
self.__dict__[key]
ax1 = fig.add_subplot(111)
thread.start()
requests.post(url, params=params, json=data)
d[k].append(v)
os.chdir(os.path.dirname(__file__))
grid.cbar_axes[1].colorbar(im1)
main()
main()
root.withdraw()
plt.plot(y)
np.split(indices, np.where(np.diff(args))[0] + 1)
tree.xpath(xpathselector)
Bar.objects.filter(pk=foo.id).update(a=bar.id)
simplejson.loads(_)
q.queue.clear()
msg = email.message_from_string(msgtxt)
{{a.some_field}}
gc.collect()
f.write(g)
[tup[0] for tup in mylist]
df = pandas.read_csv(filename, skiprows=skip)
session2.commit()
app.mainloop()
l = nx.topological_sort(g)
np.insert(a, 1, np.array((1, 1)), 0)
len(zdumps(z))
dir(MyClass)
list(dict((len(i), i) for i in l).values())
calendar.day_name[1]
time.sleep(0.1)
main()
HttpResponseRedirect(user.redirect_to())
df.dictionary.apply(str2dict).apply(pd.Series)
f.save()
[woman for woman in list(graph.keys()) if woman not in list(match.keys())]
stream.close()
time.sleep(0.5)
g = myfunct()
text = str(combobox1.currentText())
timeout.cancel()
plt.gcf().autofmt_xdate()
a[[0, 1], [1, 1], [2, 2]]
a = [[]] * 2
plt.show()
outfile.close()
time.sleep(0.02)
w.start()
myfile.write(template.format(**context))
sec_since_epoch = (date_obj.date() - date(1970, 1, 1)).total_seconds()
self.foo.wait()
arr = np.empty((N, M))
print(list(mydict.keys())[list(mydict.values()).index(16)])
foo(a=1, b=2)
items = [item.time for item in objects]
{k: v for k, v in list(d.items()) if k.startswith(s)}
words.add(line.strip())
ax.add_line(Line2D([-50, 0, 50], [-50, 0, 0], linewidth=80))
print(i, repr(binify(i)))
screen.blit(picture, rect)
server.sendmail(FROM, TO, message)
entryFrame.grid(row=0, column=1)
[l[:1], l[1:]]
curses.endwin()
output.close()
time.sleep(1)
range(-20, 0, -1)
tree = etree.HTML(result.read(), etree.HTMLParser())
window.show_all()
plt.plot(x, y)
plt.clf()
X.argmin(axis=1)
nf.write(str(random.randint(0, 1000)))
isinstance(x, collections.Iterable)
reduce(lambda d, key: d[key], path, aDict).update(aSecondDict)
plt.show()
locale.currency(188518982.18, grouping=True)
os.unlink(self.dest)
func(*args, **kwargs)
int(round(2606.89579999999, 2) * 100)
x.append(1)
x.astype(int)
inspect.getmembers(MyClass, lambda a: not inspect.isroutine(a))
output.close()
lpr.stdin.write(your_data_here)
plt.show()
print({key: a[key] for key in a if key not in keys})
invite_reason = models.CharField(max_length=64)
sys.exit(app.exec_())
ModelA.objects.filter(Q(instance_of=ModelB))
profile.save()
map(dict.fromkeys, l)
call_with_dict(some_func, my_dict)
self.SetSize((self.Size[0], self.figurecanvas.Size[1]))
{c.name: getattr(self, c.name) for c in self.__table__.columns}
out = np.vstack((lats, lons, vals))
ax.axis([0, 10, 0, 10])
s[0].astype(int)
json.dumps(recursive_asdict(data))
root.mainloop()
f()
tuple([x[0] for x in G])
print(requests.post(target_url, data=xml, headers=headers).text)
(a * 67108864.0 + b) / 9007199254740992.0
RichIPythonWidget.__init__(self, *args, **kw)
((a + a[:0:-1]) * len(a))[::len(a)][:len(a)]
print(document.text_content())
self.newargument = myarg
first_element = myList[i[0]]
title = models.CharField(max_length=60)
f.flush()
[[m[row][col] for row in range(0, height)] for col in range(0, width)]
series.dt.date.astype(str).to_json()
plt.colorbar()
mask[::4] = 0
a.append(2)
x = {k: v for k, v in spec1.items() if k in spec2 and spec2[k] == v}
[entry for tag in tags for entry in entries if tag in entry]
p.Start()
plt.subplot(121)
urllib.request.install_opener(opener)
screen.blit(surf1, (100, 100, 100, 100))
print(urlparse.parse_qs(qs))
combo.pack()
path = path.to.module.__file__
a = numpy.array([Register() for _ in range(4)])
sorted(list(mydict.items()), key=itemgetter(1))
[0][1][0]
bar = dict(foo)
reverse(text[1:]) + text[0]
DELTAFETCH_ENABLED = True
Py_Finalize()
ws.cell(row=2, column=2).value = 2
df.rename(columns=lambda x: int(x) if type(x) == float else x)
sys.exit(app.exec_())
timediff = datetime.datetime.now() - self.pub_date
rgb_uint8 = (np.dstack((r, g, b)) * 255.999).astype(np.uint8)
link.click()
entry.pack()
np.allclose(C0, C1)
sys.stdout.flush()
plt.plot(x, density(x))
f.write(bin_array)
ax.yaxis.set_major_formatter(mpl.ticker.ScalarFormatter())
plt.hist(data, bins=bins, alpha=0.5)
ax.get_xaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())
urlfetch.set_default_fetch_deadline(60)
ax2.get_position()
any([(i in fruit_dict2) for i in fruits])
os.chdir(path_dir)
derefrenced_spams = prefetch_refprops(Spams, models.Spam.eggs)
dt = datetime.fromtimestamp(mktime(struct))
plt.show()
a = sps.csr_matrix((a.data, a.indices, a.indptr), shape=(10000, 10020))
tk.Tk.__init__(self)
set(itertools.combinations(S, m))
self.grid_columnconfigure(1, weight=1)
xs.intersection(y)
my_file.seek(0, 0)
time.sleep(remain)
value = cache.get(key) or cache.setdefault(cache, func(key))
{k: mylist.count(k) for k in set(mylist)}
obj.foo42()
proc.wait()
a, b, c = [(lambda n=n: n * n) for n in l]
min_x, max_x, min_y, max_y = temp[0][0], temp[0][-1], temp[1][0], temp[1][-1]
x.__add__(x)
np.frombuffer(ftdi.read(RXcount), dtype=np.uint8)
self.ax = self.fig.add_subplot(111)
plt.close()
setattr(someobject, key, value)
plt.axvline(x=xc)
zip(*args)
frame.values[0][0]
itertools.cycle(list(range(2, 10)))
conn.close()
time.sleep(1)
print({v[0]: v[1:] for v in list(d.values())})
indices = np.where(a == a.max())
d = np.diag(a[:, (0)])
time.sleep(1)
plt.colorbar()
s.reset_index().groupby(s.index.names).first()
ax.add_collection(coll)
self.__class__.__name__
[(v + 1 if i % 2 != 0 else v) for i, v in enumerate(list1)]
k, v = list(d.items())[0]
uuid.UUID(int=rd.getrandbits(128))
deletethe_dict[key]
df.groupby(by=[df.index.year, df.index.month]).sum().transpose()
__init__.py
[x for x in lst if [(x[A], x[C]) not in seen, seen.add((x[A], x[C]))][0]]
A[(2), (2), :, :]
cvuint8.dtype
self.__dict__.update(s)
admin.site.register(TwitterUser, TwitterUserAdmin)
new_list
do_something_with_frame(frame)
[0, 0, 0, 1, 0, 1, 0, 0],
my_type = field.get_internal_type()
data = json.loads(contactFile.read())
ciao.ciao()
server.starttls()
pprint(sorted(flatten(THIS)))
r = size ** (1 / (n - 1))
signal.alarm(0)
numpy.apply_along_axis(lambda row: numpy.linalg.norm(row, ord=1), 1, a)
numpy.where(numpy.all(a_view == may_b, axis=1))[0]
[x for x in a if x not in b]
next(x for x in lst if matchCondition(x))
queryset.filter(id__in=articles)
modernthingy = datetime.datetime.fromtimestamp(zopethingy.timeTime())
session.query(Page.url).filter(tuple_(Page.url_crc, Page.url).in_(keys))
f.write(str(x))
solve([5, 10], [1, 4])
main_sizer = wx.BoxSizer(wx.VERTICAL)
list(chain(*a))
pd.DataFrame(x.T).T.drop_duplicates(keep=False).as_matrix()
lines = lines[:-1]
transaction.rollback()
lst.sort(key=lambda c: POS[c])
fin = cv2.warpPerspective(img, h, (back.shape[1], back.shape[0]))
ax.xaxis.set_major_locator(locator)
C = np.dot(A, B)
ip_list
time.sleep(1)
ax.w_xaxis.set_major_locator(ticker.FixedLocator(some_dates))
root.mainloop()
[sum(x) for x in zip(*lis)]
time.sleep(1)
result = json.load(urllib.request.urlopen(url))
name = models.CharField(max_length=100)
-r72 - g595x842
plt.figure()
pd.options.display.max_colwidth
ax.set_rmax(1)
[1][1][0]
np.random.seed(5)
result = {k: (v / len(list_of_dicts)) for k, v in list(summed.items())}
next(iter(q))
libxml2 - devel
file_2.write(file_1.read())
[x for y in z if sum(y) > 10 for x in y if x < 10]
locale.setlocale(locale.LC_ALL, saved)
tuple(itertools.chain.from_iterable(t))
[hex(i) for i in data]
ax.plot_surface(x, y, z, rstride=4, cstride=4, facecolors=bm)
plt.show()
modules[module] = sys.modules[module]
sys.getsizeof(string_drawer)
doc = yaml.load(f)
plt.subplot(121)
df = df[(df.one > 0) | (df.two > 0) | (df.three > 0) & (df.four < 1)]
max(im.getcolors(im.size[0] * im.size[1]))
root.mainloop()
pd.Series(a, a._fields)
l = [max(g, key=lambda x: x[1])[0] for _, g in groups]
True
__init__.py
chain.delay()
x.reshape((x.shape[0], -1)).mean(axis=1)
list(dd.values())
ax.plot(x)
logging.basicConfig(filename=settings.log_file, level=logging.DEBUG)
app = application(urls, globals())
deletex[:N]
fh.seek(0)
etree.fromstring(goodxml)
newdict = {x: [] for x in range(10)}
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
app.run(debug=True)
xl.Quit()
urllib.request.install_opener(opener)
a.func(b=b, c=c)
window.show()
print(Outputstring)
self.y += STEP
np.random.seed(1)
{i: [] for i in x}
diag = [row[-i - 1] for i, row in enumerate(mat)]
os.makedirs(savedir)
maxLPFt = max(lpfData, key=operator.itemgetter(1))
data = np.random.rand(10, 15, 5)
type(f).__str__ is not object.__str__
(-avgDists).argsort()[:n]
lambda x, i=i: x % i == 0
~pd.isnull(df[list_of_cols]).all(axis=1)
text.collocations(num=20)
plt.show()
s += timedelta(minutes=minutes, seconds=seconds * 100)
L.append([])
setattr(self, varargs, remaining_args)
tqdm_notebook().pandas(*args, **kwargs)
np.array([[int(i) for i in line.split()] for line in data])
ax.clear()
basemodule.dontoverride()
pdb.set_trace()
[zip(x, main2) for x in itertools.combinations(main1, len(main2))]
my_failing_task()
unixtime = time.mktime(d.timetuple())
ax1.imshow(source, cmap=plt.cm.gray)
key in self.__dict__
pool.close()
complete_path = os.path.join(root_path, sanitised_filename)
type(plain_string), type(unicode_string)
self.rect.set_xy((self.x0, self.y0))
[(x[0], len(x[1]), x[1][0][0]) for x in l]
browser.close()
m.dot(m.T)
[0][0][1]
Decimal(math.factorial(171))
Base.metadata.create_all()
fliplr(matrix)
tornado.ioloop.IOLoop.instance().start()
matrix[0][1]
app.run()
toppings = models.ManyToManyField(Topping)
berlin.delete()
ax.plot(xp, yp, zs=zp)
UserProfile.objects.create(user=instance)
dict((c, string.count(c)) for c in set(string))
plt.imshow(data, vmin=-10, vmax=10)
pd.concat([price, vol], axis=1)
all([(xdiff[0] == xdiff[n]) for n in range(1, len(xdiff))])
print(len(japanese))
master.mainloop()
s[::-1].replace(old[::-1], new[::-1], count)[::-1]
print(im.size)
plusone.append(int(value))
DialApp().run()
a_b = [e for e in a if not e in b]
print(sys.exc_info()[0])
extension = os.path.splitext(filename)[1]
df.rename(columns, inplace=True)
l[1::2] = [(x * 2) for x in l[1::2]]
plt.show()
ts.index.freq
np.nonzero(np.all((lower_bound < m2D) & (higher_bound > m2D), axis=1))[0][0]
file.seek(0)
self.data.columnconfigure(0, weight=1)
d = ordereddict(dic, relax=True)
plt.plot(x, y)
p.start()
[len(t) for t in tuples]
file.write(line)
self.window.unfullscreen()
df1.to_sparse().info()
self.capture = cv.CaptureFromCAM(0)
print(zed())
layout.setSpacing(10)
func(parameters[0], parameters[1], parameters[2])
sheet1.write(i, 0, n, fmt)
dic[keys[-1]] = value
cbar = fig.colorbar(im)
count.most_common()[:10]
plt.subplots_adjust(bottom=0.2)
random.shuffle(l)
conn = pyodbc.connect(odbc_conn_str)
heapq.nsmallest(1, ((k, i) for i, k in enumerate(s)))
models.py
answer = [v for v in itertools.product(*ranges) if sum(v) == 100]
s = c.connect()
fig = plt.figure()
[i for i, v in enumerate(list1) if v >= 1 and list2[i] == 0]
print([(num if num > 0 else z.pop(0)) for num in y])
print([i for i in results])
print(np.argmax(counts))
data[:5]
index1 = np.array([[0, 0], [1, 1]])
print(rsp.content)
[id(x) for x in l2]
sys.modules[module_name]
moduleA.py
ScrolledText(root).pack()
content = f.read()
pygame.display.flip()
len(max(sum(tableData, []), key=len))
list_of_lists
counter.save()
f.close()
sys.exit()
my_list.remove(new_dict)
complete_path = os.path.join(root_path, sanitised_path, sanitised_filename)
b = copy.deepcopy(a)
self.queue.pop()
list(df.T.to_dict().values())
show()
window.show_all()
print(line)
root.mainloop()
zip(*(x[i:] for i in range(n)))
flask.jsonify(**course_list)
[1] * 6
ax.set_xticklabels(final_labels)
print(list(map(int, chain.from_iterable(line.split() for line in f))))
json_data = json.dumps(data)
x.reshape(x.shape[:-2] + (-1,)).shape
response.render()
not any(el == 0 for sublist in maze for el in sublist)
button.pack()
{{message | safe}}
min(s, key=lambda c: (-s.count(c), s.index(c)))
False
libfoo.dylib
SCRIPT_DIR = os.path.abspath(os.path.dirname(__file__))
t.grid(sticky=(N, E, S, W))
ax.set_xticklabels(label_text)
os.remove(os.path.join(dir, file))
ax.imshow(im, *args, **kwargs)
fp.close()
random.shuffle(temp)
p.stdin.write(cmd)
data = urllib.request.urlopen(req).read()
[]
category = models.ForeignKey(Category)
ofimg[0].getHomography()
main.show()
t.start()
self.write(response.content)
txt_frm.grid_columnconfigure(0, weight=1)
df.sort_index(inplace=True)
answer = msvcrt.getch()
x, y = zip(*xy)
soup.contents[0]
httpd.serve_forever()
n.show()
print(instance.name)
figure.canvas.draw()
httpd.serve_forever()
Thread.__init__(self)
p.stdin.flush()
json_object = json.loads(json_raw[0])
df.append(s)
sys.exit()
writer.writerow([date, value])
ax.set_axis_off()
threading.Thread(target=run_all).start()
(2 - N) % 7
PYTHONUNBUFFERED = TRUE
df.A.apply(pd.value_counts).fillna(0).astype(int)
print(sys.exc_info())
d = [a, b, c]
num1, num2 = int(num1), int(num2)
rmfield = lambda a, *f: a[[n for n in a.dtype.names if n not in f]]
self.__dict__.update(adict)
np.allclose(D0, D2)
df_b.combine_first(df_a)
tmp = proc.stdout.read()
print(sum([i[list(i.keys())[0]][1] for i in myList]))
fig = plt.figure()
[item for item in full_list if not omit & set(item)]
datetime.datetime(now.date(), datetime.time(tzinfo=now.tzinfo))
plt.figure(figsize=(5, 5))
self.canvas.configure(yscrollcommand=self.vsb.set)
result.write(new_text)
p = subprocess.Popen([cmd_list], shell=False)
print(list_of_hets)
print(df.to_string())
A.T[B == 1].T
foo = (x ** 2 for x in count())
execution.history()
x[x].index
Row(**row_dict)
root.mainloop()
TotSize[:] = map(sum, data)
print(parse_qsl(urlparse(url)[4]))
print(list(d.values()))
max(values[i + 1] - values[i] for i in range(0, len(values) - 1))
random.shuffle(l)
result = [split_result[0], split_result[1], [i for i in split_result[2:] if i]]
print(list_end_counter([1, 2, 1, 1]))
plt.show()
deletex[index]
print(parse_python_source(os.path.join(d, f)))
hello(sys.argv[1], sys.argv[2])
object_list.sort(key=lambda x: key_precedence[x.key])
ax = fig.add_subplot(111)
i = max(i - 1, 0)
file.close()
map(sum, zip(*([iter(q)] * 2)))
list(set(A).intersection(B))
pl.show()
np.where(x == np.max(x))
ax.set_ylim(y_min, y_max)
print([attr.get(idx, default_value) for attr in attrs])
self.y = math.sin(a) * original_x + math.cos(a) * original_y
subprocess.Popen([file], shell=True)
sys.setrecursionlimit(10000)
my_array[:, (1)] = temp
sorted(l, key=lambda *args: random.random())
[[[0] * n] * n] * n
fig = plt.figure(figsize=(4, 4))
response = DeviceView.as_view()(request, pk=1)
path = os.path.abspath(args.file.name)
pyplot.show()
fig.canvas.draw()
root_id = hex(ewmh.EWMH().root.id)
S.pop()
a = set([1])
len(list(flatten(mylist[0:1])))
ax.add_patch(angle_plot)
__init__.py
plt.xlim((-1, 4))
invite_reason = models.CharField(max_length=64)
time.mktime(time.localtime(calendar.timegm(utc_time)))
sys.stdout = sys.__stdout__
app.mainloop()
s.listen(1)
pylab.show()
B.sendall(A.recv(4096))
br.set_cookiejar(cookiejar)
y = np.array([2, 1, 5, 2])
conn.autocommit = True
priors = df[datetime.datetime.now() - df.placed_at >= timedelta(90)]
plt.plot(z, t)
time.sleep(1)
set(dict1.items()).symmetric_difference(list(dict2.items()))
pygame.init()
os.dup2(si.fileno(), sys.stdin.fileno())
print((item, value))
tree = etree.parse(filename, parser)
datetime.now(timezone.utc).isoformat()
plt.show()
rdd.zipWithIndex().filter(lambda tup: tup[1] > 0).map(lambda tup: tup[0])
tuple(lines[0])
serializer.save()
map(lambda x: x.title(), s)
int(ceil(adjusted_dom / 7.0))
{{post.tags}}
time.sleep(5)
time.sleep(0.01)
df.drop(df[df.amount == 0].sample(frac=0.5).index)
fileContent = file.read()
print(l[x][y])
words = sorted(set(stream.read().split()))
YourModel.objects.filter(query)
arr[[1, 1]]
f.close()
etree.XMLParser(recover=True)
f(x=100)
insert_ids.append(cur.lastrowid)
result = np.concatenate((a, val))
datetime.datetime.strptime(dt, fmt)
myRoundedList.sum()
ax.add_patch(rectangle)
pygame.init()
tuple.__new__(*args, **kwargs)
A[A == pinf] = 0.0
imagem = cv2.bitwise_not(imagem)
dict((k, D[k] - v) for v, k in enumerate(albums_today))
z = np.ones((5, 1, 1))
(b - b[0] == 0).all()
help(foo.__name__)
print([_ for _ in range(5)])
a[slice(1, 2)]
fig.canvas.draw()
plt.show()
print(sp.communicate()[0].split())
QtGui.QWidget.__init__(self)
driver = webdriver.Firefox(firefox_profile=firefoxProfile)
DataFrame(dict([(k, Series(v)) for k, v in d.items()]))
print(line)
plt.imshow(img, cmap=plt.cm.gray)
np.split(np.asarray(quaternion0), 4, -1)
os.remove(path)
con.commit()
json.loads(json.dumps(my_dict))
d[k].setdefault(kk, 0)
df = pd.concat(pool.map(process, links), ignore_index=True)
threading.Thread(target=post_request, args=(q,)).start()
param = np.apply_along_axis(func1d, axis=2, arr=data)
ax2.xaxis.set_visible(False)
button.configure(bg=colour)
result = np.sum(product, axis=1)
a.extend(memoryview(b)[14:20])
ds = xr.open_dataset(path_file)
plt.show()
a = a.ravel().view((np.str, a.itemsize * a.shape[1]))
np.hstack((x, np.prod(x, axis=1, keepdims=True)))
sum(dct.get(k, 0) for k in lst)
print(json.dumps(dict(r.headers)))
pd.DataFrame(data=[l])
app.run()
c = list(map(operator.or_, a, b))
B = np.random.rand(2, 4)
server.starttls()
tk.mainloop()
ob_list = data.objects.filter(name__in=my_list)
unittest.main()
results.sort(key=lambda x: x[0], reverse=True)
getattr(obj, name)
os.sysconf(2)
pygame.quit()
data = pd.DataFrame(list(data.items()))
self.progbar.pack()
self.Bind(wx.EVT_CLOSE, self._on_close)
self.Bind(wx.EVT_TEXT, self.OnFiltr, self.filtr)
pylab.show()
button.clicked.connect(myFunction)
user = models.ForeignKey(User, unique=True)
session.sendmail(sender, recipients, message)
b / (b - 1)
{k: list(map(add_element, v)) for k, v in list(dicty.items())}
df = pd.DataFrame.from_dict(d)
cur.close()
signal.signal(signal.SIGINT, signal.SIG_DFL)
t.start()
print(type(Foo.__dict__))
__init__.py
plt.colorbar(im, cax=cax)
self.log = logging.getLogger(self.__class__.__name__)
browser = webdriver.Firefox()
df_Quota = pd.DataFrame()
index_sets = [np.argwhere(i == a) for i in np.unique(a)]
canvas.pack()
output = process.stdout.read()
result = np.minimum(arr, 255)
x = x or y
plt.bar(idx, c[0], color=hexencode(c[1]), edgecolor=hexencode(c[1]))
f(a, b)
numpy.linalg.norm(a - b, ord=1)
plt.show
out = a[np.sort(sidx[np.searchsorted(a, b, sorter=sidx)])]
[1, 1, 0, 1]
file.write(html)
print(int(s))
df = df.append(data)
ax1.scatter(X, Y, Z)
p.start()
main()
os.kill(8861, 0)
list(zip(*itertools.zip_longest(*ll)))
curses.endwin()
list(set(a) & set(b))
s.diff().fillna(0)
[(row if all(row) else [0] * len(row)) for row in matrix]
widget.setWindowFlags(QtCore.Qt.Window)
update_list(l, [4, 5, 6])
traceback.print_stack()
args[0].__disown__()
LOCALIZED = True
not any(data)
match(a, b)
print(whisper())
plt.show()
time.sleep(120)
Response(serializer.data)
cnx.commit()
t + np.r_[t[1:], t[0]]
request.add_data(edata)
userProfile.save()
[a for a in alphastartgen(8)]
{i[0]: map(int, j) for i, j in p}
lines = f.readlines()
self.fig.canvas.draw()
cursor.fetchall()
dockerpty.PseudoTerminal(client, container).start()
canvas.grid()
pyflakes - -version
root.mainloop()
json.dumps(arrays)
peoples = Person.objects.all()
plt.show()
fun()
plt.show()
datetime.datetime.strptime(date_string, format1).strftime(format2)
json.dumps(my_dict)
dict(zip(freq[1::2], freq[0::2]))
[(l[i], l[(i + 1) % n]) for i in range(n)]
plt.colorbar(sm)
self.autocomplete()
my_list
numbers[start:] + numbers[:start]
__init__.py
plt.show()
last_row.argsort()
C = 1 - np.prod(D, axis=1)
fp.close()
simplejson.dumps(d, ignore_nan=True)
app.MainLoop()
w.show()
o.write(line)
fox.quit()
plt.show()
A = coo_matrix((values, coords.T))
person.put()
Base.metadata.create_all()
module.main()
sys.stdin.readline()
name = db.StringProperty()
display(w)
sys.path.append(path)
sys.stdout.close()
foo.bar
view_func(request, *args, **kwargs)
plt.legend()
self._build_data()
parser.print_help()
from_file.readline()
HttpResponse(escape(repr(request)))
plt.show()
ax.get_yaxis().set_label_coords(-0.1, 0.5)
list(chain(*a))
print(cursor.lastrowid)
all(not X for X in dict.values())
transmission_array.extend([1] * 400 * slot_duration)
plt.setp(cg.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)
result = bytes.fromhex(some_hex_string)
app.mainloop()
print(sorted(sub_strings, key=lambda x: levenshtein_distance(x, s))[0])
f.close()
input_file.close()
PLT.show()
self.sock.bind((self.host, self.port))
path = os.path.realpath(path)
merged_df = pd.concat(dfs, axis=1)
deserialized_object.save()
app.logger.setLevel(logging.ERROR)
logger.setLevel(logging.DEBUG)
Counter(list(d.values()))
a[0] = 5
my_tuple = tuple(my_list)
[(v1 * list1[j]) for i, v1 in enumerate(list1) for j in range(i)]
fact = lambda x: 1 if x == 0 else x * fact(x - 1)
random.randint(10 ** (x - 1), 10 ** x - 1)
writer.writerows(out_data)
client.connect()
plt.show()
df[df.a < df.a.quantile(0.95)]
list_of_lists
new_list = list(set([date for date in dates if dates.count(date) > 1]))
time.mktime(dt_obj.timetuple())
len(buf.read())
print(np.abs(s[0] - s[1]) / std)
df[0:2]
df.mean()
func()
print((lambda x: chr(ord(x) + 1))(i))
tkinter.deletefilehandler(file)
time.sleep(random.randint(1, 4))
unittest.main()
client.load_system_host_keys()
app = QtGui.QApplication([])
(index for index, value in enumerate(obj))
imgc = cv2.imread(file, 0)
vbox.setContentsMargins(0, 0, 0, 0)
df = np.dot(df, p_value)
pool.apply_async(test2, (t,), [dict(arg2=5)])
type(b)(a)
Session.objects.filter(pk__in=user_sessions)
object.save()
print(rawstr(test6))
[sum(g) for b, g in itertools.groupby(bits) if b]
sys.exit(app.exec_())
print(subg.edges())
[it for it in l for _ in range(2)]
a = df.iloc[:, 2:].values
pickle.dump(data1, output)
server.quit()
plt.show()
len(tested) == len(input)
pool = mp.Pool(processes=4)
plt.gcf().set_size_inches(10, 10)
pygame.draw.circle(surf1, (0, 0, 200, 100), (100, 100), 100)
print([b(5, 8) for b in bases])
cv.Remap(image, remapped, mapX, mapY, cv.CV_INTER_LINEAR)
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
print(df.loc[mask])
im.show()
a[tuple(idx)] = 5
df_output_lines = [s.split() for s in fixed_df_output.splitlines()]
centroids = [prefs[random.choice(users)] for i in range(k)]
root.grid_columnconfigure(0, weight=1)
info = collection.find_one(obj_id)
a = np.array([[1, 1], [2, 2], [4, 4]])
plt.show()
logger.removeHandler(hdl)
euclid(nums[1], gcd(nums[:2]))
fig = plt.figure()
df[(df.foo == 222) | (df.bar == 444)]
sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
plt.clabel(CS, inline=1, fontsize=10)
plt.ylim(plt.ylim()[0], 1.0)
plt.show()
br.submit()
plt.show()
sys.stdout.write(os.read(fd, 1024))
sys.exit(1)
df = pd.concat([df, market], axis=1)
func(*args, **kwargs)
all(v in value for v in input_list)
gc.garbage
numpy.kron(a, [[1, 1], [1, 1]])
print(d[k])
self.top.destroy()
plt.show()
plt.show()
print(list(range(len(words))))
cf.insert(uuid.uuid4(), [{k: str(v) for k, v in d.items()} for d in x])
np.isfinite(b)
json.dumps(object())
time.sleep(1)
pickle.dumps(defdict)
a[b[:, (0)], b[:, (1)]]
isinstance(v, type(LAMBDA)) and v.__name__ == LAMBDA.__name__
layout.addWidget(self.browser)
ax.set_yticklabels([])
message = sys.stdin.readlines()
persons = Person.objects.all().order_by(now, anniversary)
s.fill((255, 255, 255))
(dist ** 2).sum(axis=2) ** 0.5
myNames = [line.strip() for line in f]
l1.extend([7, 8, 9])
g2 = [elem[:12] for elem in g]
any(isinstance(e, list) for e in my_list)
solve(eqn, Rsense)
t.start()
a.execute(sql)
self.label.pack()
trimmed_text = text.strip()
f.close()
any(thelist.count(x) > 1 for x in thelist)
help(list)
self.add_tag(tag)
listening_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
j2 = [x for x in j if x >= 5]
np.reshape(x, (-1, 1))
[i for i, letter in enumerate(s) if letter == ch]
self.worker.start()
df.stack()
sum(map(mul, a, b))
[datetime.datetime(2012, 1, 5, 0, 0)]
app = Flask(__name__)
ent6.grid(row=1, column=1)
admin.site.register(Group, GroupAdmin)
self.send_response(200)
plt.show()
scipy.optimize
df.to_csv(f, header=False, index=False)
print(hex(-1 & 4294967295))
deletel[0]
win.show_all()
print((i, line))
this_array[indices[0]:indices[-1] + 1].fill(new_v)
plt.show()
dropped_copies = [(lambda i: (x[i] for x in copies[i]))(i) for i in range(2)]
df_subset.apply(lambda x: x.C * x.E, axis=1).sum()
os.kill(pid, 0)
os.isatty(0)
print(re.findall(p, test_str))
res = cv2.bitwise_and(img, img, mask=mask)
result = p.communicate()[0]
cursor.fetchall()
serializer = CommentSerializer(comment, data=request.data, partial=True)
[entry for tag in tags for entry in entries if tag in entry]
shelf.close()
graph = facebook.GraphAPI(access_token)
self.ax.set_ylim(0, R + pR)
s.connect((HOST, PORT))
a[(0), :, :]
cdf1.update(cdf2, overwrite=False)
print(os.path.abspath(__file__))
sys.stdout.flush()
self.pack(fill=BOTH, expand=1, padx=5, pady=5)
pts = [(1, 1), (10, 1), (10, 10), (1, 10)]
print(br.response().read())
characters += sum(len(word) for word in wordslist)
print(df.loc[:, (~mask)])
radioValue = butRadio.value_selected
datetime.now(timezone.utc).astimezone().isoformat()
splitted = [i.strip() for i in re.split(pattern, s) if i.strip()]
any(np.allclose(row, x) for x in myarray)
f.seek(0)
Companies.objects.filter(q)
print(s.getvalue())
ind[np.where(np.diff(ind) == 0)]
server.sendmail(self.EMAIL_FROM, self.EMAIL_TO, msg.as_string())
p.stdout.close()
l.extend(map(int, r.findall(line)))
dict.__setitem__(self, keys[-1], value)
app.run(debug=True)
a[0]
sum([i for i in l1 if isinstance(i, numbers.Number)])
t.start()
{k: min(i for i in (h1.get(k), h2.get(k)) if i) for k in list(h1.keys()) | h2}
lst.sort(key=operater.itemgetter(2), reverse=True)
col = A.getcol(colindex)
app = QtGui.QApplication([])
result = [sum(el) for el in itertools.zip_longest(fillvalue=0, *lists)]
unittest.main()
d = {r[0]: tuple(r[1:-1]) for r in reader}
self.instance.status
signal.signal(signal.SIGINT, signal_handler)
plt.show()
virtualenv - -help
f = lambda r: r * (sp.j0(r) + sp.jn(2, r))
pygame.display.init()
a = np.loadtxt(stdin, dtype=np.int)
random.shuffle(lis)
x[0] + x[-1]
a = k + a
sizer.Add(text, 0, wx.ALL, 5)
sys.exit(app.exec_())
people_list.append(person)
ax = fig.add_subplot(111)
plot(tmp.max(axis=0))
mat = sparse.coo_matrix(points, (I, J))
im.show()
admin.site.register(LocationCode, LocationAdmin)
config.write()
self.initUI()
siympify(y)
A[i, j] = C[j, B == i].sum()
ax.xaxis.set_major_locator(mdates.AutoDateLocator())
logging.Handler.__init__(self)
text.pack()
print(table.ascii_table(data, has_header=True))
jsonify(json_list=[i.serialize for i in qryresult.all()])
self.schedule.run()
plt.colorbar()
plt.draw()
max(0, min(a[1], b[1]) - max(a[0], b[0]))
json.dumps(o)
df.head()
element_counts = collections.Counter(itertools.chain.from_iterable(allsets))
{(x, x + 2) for x in r if x + 2 in r}
cherrypy.quickstart(HelloWorld())
calendar.timegm(dt.utctimetuple())
turtle.circle(circumfrence / 2)
temp_list = (x * x for x in range(0, 10))
X_train_array = X_train.toarray()
cv.WaitKey(0)
sc.addFile(some_path)
print(len(a) - a.index(min(a)) - 1)
PyMem_DEL(self)
sys.path.insert(0, lib_path)
tk.Label(frame, text=t).grid(row=row, column=1)
any(v > 0 for v in pairs.values())
help(pyudt)
self.pack()
data = pd.DataFrame(json.loads(line) for line in f)
print(line, file=file)
[1, 1, 1],
trainer.trainEpochs(1000)
g.filter(lambda x: len(x) >= 10)
self.grid_rowconfigure(0, weight=1)
list(range(len(sent)))
link.click()
print(v, type(v))
webbrowser.open(whatever)
[0, 0, 0, 1, 0, 1]
np.arange(x[0], x[0] + 60, 10)
np.allclose(a, b)
plt.ion()
ax.imshow(im)
model1.objects.all()
print(json.dumps(df.T.as_matrix().tolist(), indent=4))
getattr(module, name)
os.chdir(currdir)
self._autosave()
QAbstractTableModel.__init__(self, parent)
print(template.render())
plt.figure()
self.factories.append(factory)
mpl.pyplot.legend(**dict(list(defaults.items()) + list(kwargs.items())))
plt.savefig(file_path, dpi=80)
httpd.serve_forever()
(numpy.diff(numpy.sign(a)) != 0) * 1
thread.start()
max(knapsack(i - 1, W), values[i] + knapsack(i - 1, W - weights[i]))
timedelta(hours=6)
ax.set_ylim([-2, 2])
pil_img = PIL.Image.open(filename)
numpy.transpose(matrix7, axes=(1, 0, 2)).tolist()
plt.draw()
b = a[..., ::-1]
paramdata.columns
setattr(self, key, value)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
sum(v[1][1] for v in itertools.chain(*[list(d.items()) for d in myList]))
browser.close()
f.close()
all([])
max(b, key=inverse)
setpath(d.setdefault(p[0], {}), p[1:], k)
df.groupby(date).mean()
val, _ = funky_func()
wrpcap(OUTFILE, paks)
ax1 = fig.add_subplot(2, 1, 1)
ax.yaxis.set_major_locator(mtick.LinearLocator(5))
f.write(bin_data)
set(tuple(sorted(elt)) for elt in example)
b = [dict(a)]
plt.plot(x, y)
fact = lambda x: 1 if x == 0 else x * fact(x - 1)
main()
string_key = entity.key().urlsafe()
conn.request()
cax.get_yaxis().set_visible(False)
a[:len(bbins)] += bbins
f()
Entry.objects.filter(created__range=(start_date, end_date))
y = x.astype(np.float)
np.hstack(x).shape
plt.show()
cursor.execute(sql, [id])
data = [(item + 256 if item < 0 else item) for item in data]
x[0] + x[-1]
MyDiccoSorted = sorted(list(MyDicco.items()), key=lambda s: s[1][2])
time.sleep(5)
self.label.setAlignment(QtCore.Qt.AlignCenter)
sorted(sentence, reverse=True)[0]
list(list(zip(r, p)) for r, p in zip(repeat(a), permutations(b)))
self.transport.write(line)
np.array_equal(np.asarray(foo_cv), foo_np_view)
self.timer.join()
plt.show()
sys.exit(0)
screen.blit(surf, (100, 100))
print(list(iter(root.children[1])))
np.hstack((vector1.reshape(-1, 1), matrix2))
out_file.write(line)
unittest.main()
books_array = numpy.array(list_of_lists)
root.mainloop()
self.post(*args, **kwargs)
ax2 = fig.add_subplot(2, 1, 2)
imshow(np.asarray(pil_im))
circle.grid(row=1, column=1)
Fraction.from_float(0.25)
max(sum(1 for i in g) for k, g in groupby(L))
pyl.show()
self.stream.close()
array ^= numpy.random.rand(len(array)) < prob
plt.show()
shutil.copyfileobj(f_in, f_out)
f()
plt.show()
self.__dict__.update(state)
matplotlib.pyplot.show()
time.sleep(2)
df.groupby[di.month].Category.apply(pd.value_counts)
[next(gen) for _ in range(6)]
plt.show()
print(sorted(list(globalHotItems.items()), key=lambda x: x[1])[-4:])
abs(x=5)
plt.subplots_adjust(right=0.85)
biggest = [x[0] for x in d.most_common(6)]
float(s)
main()
list(IT.izip_longest(*readers))
myChoice = random.choice(answer)
letters = [choice(ascii_lowercase) for _ in range(5)]
self.foo()
dot(A, x)
webapp2.RequestHandler.dispatch(self)
s.listen(1)
a.max(axis=1)
seq[::2], seq[1::2]
sys.exit(app.exec_())
print([r.lower() for r in row])
df.apply(print_row, axis=1)
pyplot.show()
r = np.sqrt(x * x + y * y)
queryset = queryset.filter(full_name__icontains=string)
plt.subplots_adjust(top=0.9)
document.close()
plt.show()
element.clear()
server.serve_forever()
Thread.__init__(self)
ax.xaxis.set_major_locator(MultipleLocator(1.0))
now_plus_10m = now + datetime.timedelta(minutes=10)
s == s[::-1]
ax.plot_surface(x_surf, y_surf, z_surf, cmap=theCM)
reactor.run()
A = np.array(mean_data).mean(axis=0)
new_rows.append([str(elt).expandtabs() for elt in row])
even = [n for n in numbers[:numbers.index(412)] if not n % 2]
s = requests.Session()
t.start()
Image.fromarray(imarray)
the_dict = json.loads(JSON_Datalist)
[(i, sum(j)) for i, j in list(d.items())]
sys.stdout.flush()
item = singlet_list[0] if len(singlet_list) == 1 else False
figure(figsize=(5, 10))
self.Bind(wx.EVT_PAINT, self.OnPaint)
cbgen(int(x), base, iexps), cbgen(x - int(x), base, fexps)
root.mainloop()
shutil.rmtree(temp_dir)
dataframe.iloc[:, ([0, 1, 4])]
curses.curs_set(0)
QtCore.QVariant()
b = a * (a > 0)
os.nice(1)
result.drop(0, axis=1, inplace=True)
dot_product = sum(dict_1[key] * dict_2.get(key, 0) for key in dict_1)
sorted(dictionary, key=dictionary.get, reverse=True)[:10]
response = requests.get(url)
self.show_all()
blobs = BlobInfo.all().run()
[x.time for x in list_of_objects]
pd.MultiIndex.from_tuples(list(product(*categories)), names=names)
Acut[np.isnan(Acut)] = np.nanmean(Acut)
total += float(current_number)
s[~s.isnull()]
[0, 0, 0, 0]
changes.setdefault(k, []).append(v)
pd.read_excel(filename)
[0] * (len(a) - len(c)) + c
logger.addHandler(handler)
plt.figure(1, figsize=(size_x, size_y), dpi=98)
aobj.__class__
django.contrib.auth.middleware.AuthenticationMiddleware
b.swapaxes(0, 1)
res = [((s[i] + s[i + 1]) / 2) for i in range(0, len(s) - 1, 2)]
doublepp = np.ctypeslib.ndpointer(dtype=np.uintp)
serializer.save()
themod.__dict__.update(thedict)
logger.setLevel(logging.DEBUG)
np.searchsorted(np.sort(x), x)
plt.axvline(x_position)
mylist.insert(0, mylist.pop(mylist.index(targetvalue)))
ax.plot_surface(X, Y, F)
Done
min(map(lambda x: string.index(x) if x in string else len(string), specials))
random.shuffle(all)
now = datetime.datetime.utcnow().replace(tzinfo=utc)
subprocess.Popen(cmd).wait()
threading.Thread.__init__(self)
plt.scatter(x, y, c=t, cmap=cm.cmap_name)
driver = webdriver.PhantomJS()
filter_func(parent_dict, lambda x: 2 < x < 4)
response
[1][0][2]
last_wednesday = today - timedelta(days=offset)
sorted(A, key=lambda e: e not in B)
sys.path.append(os.path.abspath(scriptpath))
tuple(numpy.subtract((10, 10), (4, 4)))
image.image.save(file_name, files.File(lf))
seq2str(img.getdata())
b.sort()
threading.Thread.__init__(self)
list(compress(list_a, fil))
moduleA.py
moduleB.py
ar = [[str(item) for item in results] for results in cur.fetchall()]
plt.show()
x = EqM_list(someiter)
data = [x for x in data if type(x) == float]
sorted(set(a_list))
service.files().delete(fileId=dir_id).execute()
gtk.main()
f.close()
plt.show()
f.close()
str1.split()
ax.set_xlim(-0.5, 1.5)
print(mystring[2:4])
[i for i in l for r in range(2)]
x = f.readlines()
tree = etree.parse(StringIO(your_xml_string), magical_parser)
map(f, tuple_list)
bare_argspec = inspect.getargspec(func)
pixels = list(im.getdata())
[(x - y) for x, y in it.izip(a[1:], a)]
b = word in (w for i, w in enumerate(wordList) if i != 1)
self.assertEqual(actual, expected)
ax2.set_ylim(0, 1.2)
print(map(itemgetter(0), next(bykey)[1]))
subA.tick_params(labelsize=6)
queryset = User.objects.all()
fun(**{b.decode(): v for b, v in list(dic.items())})
x = EqM_list(iter(d.keys()))
app.run()
sympy.solve([sympy.Eq(b - a ** 2.552 - c), sympy.Eq(b, 2)], rational=False)
globals().update({name: module_dict[name] for name in to_import})
np.random.seed(seed=0)
zip(*(s[i:] for i in range(n)))
print(r.status_code)
new_list.append(temp_list)
object.__new__(cls, *args, **kwargs)
A = (A - mean(A, axis=0)) / std(A, axis=0)
list(itertools.product(a, b))
[0.00148820116, 0.000295700572, 0.00441516179],
df.iloc[:, (0)]
getattr(self, name)
ax1 = fig.add_subplot(1, 2, 1)
print(ruamel.yaml.dump(d, Dumper=ruamel.yaml.RoundTripDumper))
ax.yaxis.set_major_locator(MultipleLocator(1.0))
b, g, r = img[:, :, (0)].copy(), img[:, :, (1)].copy(), img[:, :, (2)].copy()
smtp.sendmail(from_addr, to_addr, message.as_string())
lst.sort(key=lambda x: x[2], reversed=True)
process.kill()
views.py
conn.send(data)
hist([(t.hour + t.minute / 60.0) for t in ts], bins=24 * 60 / 15)
session.add(p)
c.append(quad(f, -1, 1, args=list(range(1, n + 1)))[0])
content = some_file.read()
print([result.get(timeout=10) for result in results])
print(lxml.html.tostring(doc))
df = df.append(df)
[11, 11, 11, 1, 18, 14, 14, 9, 9]
logging.getLogger().addHandler(setupcon.ColoredHandler())
arr[indices[:, (0)], indices[:, (1)]]
users.create()
ws = wb.worksheets[0]
getpass.getuser()
parrot(**d)
ax = fig1.gca()
app.mainloop()
self.pack()
itertools.count(1000000000000)
sum(a)
time.sleep(2)
os._exit(0)
print(sess.run([x, y]))
self.queries.append(a[1])
json.dumps([str(nparray.dtype), base64.b64encode(nparray), nparray.shape])
ax.set_zticks(np.arange(0, 9, 0.5))
print(list(itertools.chain(*kana)))
sys.stdout.flush()
img = np.empty((100, 100, 1), dtype=np.uint16)
k.append(j)
client.send(message)
newobjs._register(obj)
p.kill()
math.exp(-np.logaddexp(0, -x))
ax.boxplot(data)
win.show_all()
args = parser.parse_args(get_xyz_cmd_line(sys.argv[1:]))
reactor.run()
json.dumps()
master.mainloop()
cropped = pygame.Surface((80, 80))
pandas.merge(df.stack(0).reset_index(1), id, left_index=True, right_index=True)
Ainv = np.array(map(np.linalg.inv, A))
milestones_list = milestones_df.index.tolist()
time.sleep(1)
plt.gcf().show()
os.symlink(linkto, dst)
print(yaml.dump(data, Dumper=yaml.RoundTripDumper, indent=4))
mainloop()
numpy.array([network.activate(x) for x, _ in train])
print(os.path.join(path, file))
Thread.__init__(self)
np.dstack(np.nonzero(df.values))[0]
hash(str(d))
print(response.read())
QtGui.QTabWidget.addTab(self, widget, title)
result_list = list(result.values())
print(cls.__name__)
X, Y = np.meshgrid(XB, YB)
print(icon_info.get_filename())
self._var1 = 1
pylab.draw()
print(celery.AsyncResult.task_id)
a.argsort()[-10:]
window.activateWindow()
print(f.read())
content_sizer = wx.BoxSizer(wx.HORIZONTAL)
deleteL[::2]
arr[1, -1]
print(sum(a))
np.argsort(b)[c]
time.sleep(0.5)
[(x * 2) for x in [2, 2]]
console.setFormatter(color_formatter)
ax = fig.add_subplot(111)
signal.signal(signal.SIGINT, old_action)
silhouette_score(iris.data, iris.target, sample_size=50)
print(fout.read())
plt.ylim([0, 1])
sys.exit()
map(lambda x: group(x, a), sum_vals)
[(stuff + stuff[:n / 2 - 1])[i:i + n / 2] for i in range(n)]
math.acos(dotproduct(v1, v2) / (length(v1) * length(v2)))
reactor.run()
rest = (n - last_digit) / 10
x = math.ceil(x * 100.0) / 100.0
root.mainloop()
view.configure_traits()
M.reshape(-1, 2, 2).sum(axis=0)
a = np.random.randint(0, 9, 10)
tuple(l)
admin.site.register(Session, SessionAdmin)
row[0, col.argsort()]
ax.add_artist(circle)
wb.Close()
self.text_ent.grid(row=1, column=0)
5 + np.random.sample(10) * 5
ax.xaxis.set_major_formatter(formatter)
math.radians(45.0)
max(depth(self.left), depth(self.right)) + 1
flask.request.user_agent.string
print(list(reader))
next(iter(list(c.items())))
sorted(2 * list(range(5)))
session.query(Action).filter_by(name=name).one()
ShowAppsView.as_view()(self.request)
df.to_excel(writer)
name = models.CharField(max_length=64)
df.loc[cond1 | cond2]
ax.legend(loc=0)
print(list_end_counter([1, 1, 2, 2, 2, 2]))
os.chown(path, uid, gid)
app.exec_()
[(int(lst[x]) if x in indices else lst[x]) for x in range(len(lst))]
my_dictionary_list
x.__enter__()
a % b
i = [int(x) for x in s.split()]
dict(zip(x, y))
webbrowser.open(url, new=0, autoraise=True)
ax.set_xlim(-10, 10)
show()
df.apply(fillnull)
[k for k in list(mydict.keys()) if k >= 6]
show(p)
rows = [[field[k][i] for k in list(field.keys())] for i in range(2)]
window.show()
clientsocket.send(p)
process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
a + b
print(os.path.join(dir, file))
datetime.datetime.utcfromtimestamp(seconds)
self.y = 0
e.toxml()
[ast.literal_eval(el) for el in lst]
next(y)
book = Workbook()
fullpower = quad(f, 1e-09, np.inf)[0]
Thread.__init__(self)
plt.draw()
plt.plot(x)
req.get_method()
t.start()
time.sleep(1)
print([abs(v - l[(i + 1) % len(l)]) for i, v in enumerate(l)])
print(df)
[(k, adict[k]) for k in sorted(adict, key=adict.get, reverse=True)]
s.replace(0, np.nan).dropna().astype(s.dtype)
sp.wait()
test.ix[i::4]
sock.settimeout(5)
cj = cookielib.CookieJar()
pd.DataFrame(data, df.index, u)
file.seek(0, os.SEEK_END)
parser.parse(open(filename))
a[0][0]
str(f)
sizer.Add(input, 1, wx.EXPAND | wx.ALL, 5)
ax.plot_surface(Rnew * np.cos(Tnew), Rnew * np.sin(Tnew), Znew)
result = np.average(_array[::][1:], axis=1)
imgc = cv2.imread(file)
plt.legend()
any(map(my_dict.__contains__, my_list))
mpl.rcParams.update(manager._rcparams)
list(_)
np.dot(W, B)
[[z[i] for z in foo] for i in (0, 1)]
ax.plot(list(range(10)))
plt.show()
B = A[::2, :, 1:2]
os.chdir(path)
board4 = [[1, 0, 0, 1], [0, 1, 1, 0], [0, 0, 1, 0], [0, 1, 0, 0]]
ab[x].sort()
arr[20:] = [0] * (len(arr) - 20)
S2.startswith(S1)
self.initialized = True
np.clip(arr, 0, 255, arr)
{{forloop.counter0}}, {{j}}
new_column.index
{t: [next(it) for _ in range(next(it))] for t in it}
app.mainloop()
br.set_handle_gzip(True)
plt.show()
df.apply(lambda x: x.between(2, 10, inclusive=False))
s.setsockopt(socket.IPPROTO_IP, socket.IP_HDRINCL, 1)
n, bins, patches = plt.hist(x, histedges_equalA(x, nbin), normed=False)
plt.subplot(111)
time.sleep(2)
all(item[2] == 0 for item in items)
self._background_task()
circ = np.linspace(0, 2 * pi)
ax.set_xticks(numpy.arange(0, 1, 0.1))
c.showPage()
theproc.communicate()
hottest_cakes = Cake.objects.filter(id__in=hottest_cake_ids)
plt.subplots_adjust(left=0.25, bottom=0.25)
myApp.setWindowFlags(QtCore.Qt.Tool)
driver = webdriver.Firefox(firefox_profile=profile)
s.bind((HOST, PORT))
H = nx.DiGraph()
main()
df.rename(columns=lambda x: x[1:], inplace=True)
print(html.tostring(table, pretty_print=True))
sys.excepthook = info
results = [t.age for t in mylist if t.person_id == 10]
mat.data -= numpy.repeat(vec.toarray()[0], numpy.diff(mat.indptr))
i = int(round(float(s)))
subprocess.Popen.communicate()
sys.modules.pop(module_name)
[x for i, x in enumerate(y) if i != 0 and x != 6]
d.execute()
print(todayDate.replace(day=1))
f.close()
socket.setdefaulttimeout(60)
[t for t in my_set if my_list.count(t) > 1]
bar()
A = numpy.array([[2, -1, 0], [-1, 2, -1], [0, -1, 2]], numpy.float)
{{value.name}}
child_process.kill()
L1.sort(key=lambda x: L.index(x))
func(*args, **kwargs)
list(filter(f, list(range(2, 25))))
iv = bytes([random.randint(0, 255) for i in range(16)])
map(operator.add, a, b)
self.create_socket(socket.AF_INET, socket.SOCK_STREAM)
main()
layout.addWidget(self.de)
print(r.content)
[(seen.add(obj.id) or obj) for obj in mylist if obj.id not in seen]
multiprocessing.cpu_count()
plt.boxplot(boxes, vert=0)
self.setGridIntersection(self.pos())
self.layout.addWidget(self.view)
delta = datetime.datetime.now() - previousTime
Entry.objects.bulk_create(aList)
[a.join(b) for a, b in zip(df.a, df.b)]
show()
s.close()
C = map(sub, A, B)
func()
sys.stdout.flush()
np.maximum.reduceat(v, idx)
window.show()
my_list = [dict(out[v]) for v in sorted(out)]
[k for k, g in groupby(a) if len(list(g)) >= 2]
output.close()
print(cur.fetchall()[0])
tree = ET.ElementTree(ET.fromstring(xmlstring))
type.__new__(cls, name, bases, dct)
time.sleep(0.11)
sorted(list(x.items()), key=lambda kv: kv[1])
ctypes.c_ulong(-1)
result = [line.upper() for line in lines]
f.axes[0].set_position([0.05, 0.05, 0.4, 0.4])
t = [x for x in q if x in w]
list2b = [c for c in list2 if c in list1]
print(match.group(1))
self.set.remove(d)
the_list.sort()
names = [row[0] for row in curs.fetchall()]
time.sleep(1)
python - -version
Py_Finalize()
1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0
w.writerow(row)
rfecv.fit(X_train, y_train)
df[~((df.A == 0) & (df.B == 2) & (df.C == 6) & (df.D == 0))]
[df.loc[list(p)] for p in permutations(age.get_group(21).index)]
print(sess.run(Z))
label.pack()
self.__dict__.update(kwargs)
db.close()
ssh.close()
fatal.setLevel(logging.FATAL)
process.stdin.write(data)
gtk.main_iteration(block=False)
solve(do_something(something))
clf = pickle.load(f)
weights = np.array([[1, 1, 1], [1, 0, 1], [1, 1, 1]]),
a = MyClass()
reactor.run()
wb = openpyxl.load_workbook(file)
df[sheet] = pd.read_csv(csv)
df[df.duplicated(keep=False)]
pyplot.show()
data = json.loads(elevations)
deletelist1[:]
vars(obj).setdefault(name, value)
data.sort(key=keyfunc)
array([[1, 0], [1, 2]])
x.shape
s = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_IP)
print(im.format, im.size, im.mode)
br.set_handle_robots(False)
wx.Panel.__init__(self, parent)
sys.exit(app.exec_())
root.mainloop()
model = get_object_or_404(Customer, id=id, user=1)
Py_Initialize()
ax.xaxis_date()
print(f(a))
A = np.zeros((6, 6))
s.logout()
race = models.CharField(choices=RACES, max_length=5)
set(range(1, 101)) - s
list_one.append(list_two)
classroom.py
(l[i:i + n] for i in range(0, len(l), n))
o = [(l[i], l[i + 1]) for i in range(0, len(l), 2)]
rreverse(s[1:]) + s[0]
os.waitpid(p.pid, 0)
FI.close()
session.commit()
frame.groupby([pd.DatetimeIndex([x.date() for x in frame.index])]).sum()
count_nan = len(df) - df.count()
max_validation = lambda x, y, z: x < y < z
q.filter(or_(*conditions))
query = Session.query(Table).filter(clauses)
zip(range(1, 7, 2), range(2, 8, 2))
response = urllib.request.urlopen(req)
any(np.array_equal(np.array([a, a]), x) for x in my_list)
uuid.UUID(value)
[1, 2, 2]
f = Foo()
res.append(lst[i])
json.dumps(self.json)
time.sleep(0.5)
any(len(set(x)) == 1 for x in zip(*arr))
struct.pack(new_format, *args)
server.set_debuglevel(1)
plt.show()
[[0], [1], [2], [42], [4]]
(u + x) * (a + d + g) + (v + y) * (b + e + h) + (w + z) * (c + f + i)
print(cur.fetchall())
np.vstack(j).T
zcat.wait()
time.sleep(0.25)
df[df.Phrase.str.len() != 0]
f.close()
sys.exit(app.exec_())
print(my_list)
sys.getsizeof(a)
pos = numpy.random.multivariate_normal(mean, C, size=Nwalkers)
f2.close()
plt.draw()
self.canvas.pack()
signal.signal(signal.SIGINT, signal.SIG_IGN)
sys.getsizeof(n.__dict__)
out.extend(map(str, list(range(r[0], r[-1] + 1))))
QtCore.QAbstractItemModel.__init__(self)
gtk.main_quit()
GL = [list(v) for k, v in it.groupby(sorted(L, key=sorter), key=sorter)]
numpy.atleast_2d(x[x[:, (2)] == 1])
sum(int(x) for x in s if x.isdecimal())
__init__.py
plt.xticks(rotation=70)
cur.connection.close()
test.myfun(test.f)
self.assertEqual(r, a)
cur.execute(sql, list(values.values()))
pygame.display.flip()
[prod(x) for i in range(2, len(lst) + 1) for x in combinations(lst, i)]
order = models.PositiveIntegerField(default=0)
instance.save()
rdd.mapPartitions(f).collect()
q = Queue.Queue()
{b.pop(0): {b.pop(0) for _ in range(1)} for _ in range(1)}
a[::-2]
test_handler()
print(in_nested_list(x, [1, 2]))
id = Column(Integer, primary_key=True)
root.quit()
data[abs(data - np.mean(data)) < m * np.std(data)]
pip2 - -version
print(A[idx])
zip(a, b, c)
result.append([list[index][0], list[index + 1][1]])
plt.scatter(x, y, c=t)
list(Counter(words).values())
ax.set_axis_off()
xDate = sys.argv[1]
caketaste()
timedelta(seconds=_diff.total_seconds())
ctx.set_font_size(font_size)
admin.site.unregister(User)
Foo.allocate_ids(max=26740080011040)
fig.canvas.draw()
max((len(v), k) for k, v in flows.items())
set(a).intersection(b)
ax.spines[direction].set_visible(True)
sys.exit(exit_code)
len(self.children) == 0
sorted(_, key=lambda x: sum(x))
[([x] * i) for i, x in zip(A, B)]
plt.figure()
sys.path
plt.imshow(Z)
sliced = [list(islice(it, 0, i)) for i in seclist]
sys.exit(0)
PyInit_gstreamer()
[bar() for i in range(10)]
foo(1, 2)
app.run(extra_files=extra_files)
sys.stdout.flush()
t, z, y, x = np.indices(temp.shape)
file(filename).read()
np.where((abcd <= data2a) & (abcd >= data2b), 1, 0).sum()
print(len(letters) > len(no_rep))
print([[x for x in a if len(x) == i + 1] for i in range(m)])
ax.set_aspect(1)
i += 1
ax.set_xlim(0, 10)
print([A[p][i] for i, p in enumerate(P)])
filtered_list = list(filter_list(full_list, excludes))
json.JSONEncoder.__init__(self, *args, **kwargs)
sys.exit(app.exec_())
list_of_lists = [list(elem) for elem in list_of_tuples]
s = random.randint(0, 2 ** 10000 - 1)
pd.concat(pd.read_html(url), ignore_index=False)
urllib.parse.urlencode(a)
np.array(__, dtype=float)
curses.echo()
urllib.parse.urlencode(url_dict, True)
conn.close()
s1.reset_index(drop=True)
f.close()
inpaint_mask = cv.CreateImage(cv.GetSize(im), 8, 1)
time.sleep(1)
dW = masked.sum(axis=1)
loop.close()
np.where(a[:, (1)] == 2)
tokenize.sent_tokenize(p)
ordering = {word: i for i, word in enumerate(predefined_list)}
colnames = df.columns.tolist()
print(f(1))
login()
keys = set(chain.from_iterable(dicts))
plt.show()
min(iList, key=lambda i: i.number)
tk.Label(self.frame, text=t).grid(row=row, column=1)
QtWidgets.QGraphicsScene.mouseMoveEvent(self, event)
zip((x.count(item) for item in set(x)), set(x))
print(f.read())
start_date + relativedelta(months=2)
csv_reader = csv.reader(f)
pygame.quit()
response.close()
first, rest = seq[0], seq[1:]
root.mainloop()
print(repr(f.readline()[:1]))
QtCore.QVariant()
msg = msg.rstrip()
list(map(itemgetter(0), G))
results = sorted(list(results_dict.items()), key=lambda x: abs(x[0]))
logger.setLevel(logging.DEBUG)
[list(islice(b, x)) for x in l]
pprint.pprint(row)
connect.commit()
self.Bind(wx.EVT_KEY_DOWN, self.OnKey)
pickle.dump(a, f)
items = [[1, 2, 0], [1, 2, 1], [1, 2, 0]]
time.sleep(2)
pprint(sys.path)
retdict = json.loads(content)
list(itertools.dropwhile(math.isnan, reversed(r)))[::-1]
isinstance(obj, int)
print(select([func.count()]).select_from(table))
time.sleep(1)
a + b
ax.set_xlim(0, 25)
plt.show()
deletex[2]
fig = plt.figure()
srcList = list(set(srcText.split()))
a = b
result.setdefault(column, []).append(value)
next(x for x in range(10) if x == 7)
str(tdo)
bisect.bisect_left(l, 4)
list(df.T.to_dict().values())
clen = ctypes.c_ulonglong(0)
signal.signal(signal.SIGTERM, signal_handler)
o5.method()
self.crawler.start()
[np.insert(j, 0, i) for i, j in product(a, np.array((b, c)).T)]
df.groupby(df.index)
date -= timedelta(days=5)
result = [el.text_content() for el in result]
selfref_list.append(selfref_list)
plt.figure(figsize=(7.15, 5.15))
var1, var2 = [int(var1), int(var2)]
os.path.split(fullpath)
celery.control.revoke(uuid, terminate=True)
{{42.55 | round}}
print(user.username, user.get_full_name(), user.email)
cls(*args, **kwargs)
[(x ** 2) for x in range(5)]
res4 = inner1d(U.transpose(0, 2, 1), V.T)
yourThread.daemon = True
print(pattern.search(text).group(1))
label.pack()
plot.show()
sys.stdout = sys.__stdout__
df.ix[row.name]
numpy.array(strings, dtype=float)
my_dict[key] += 1
writer.writerow(keys)
deleteall[max(current - 2, 0):current]
value = int(value)
print(num)
f.read()
wb = load_workbook(filename=BytesIO(input_excel.read()))
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
a[[ind]]
list(enumerate(reversed(test)))
pdb.set_trace()
any(c.isalpha() for c in string_1)
neurons.append(neuron)
all_ranges = list(gen_range(100000000, 600000000, 100))
f.close()
print([tuple((a, b + 1) for a, b in group) for group in t])
event_full_datetime = models.DateTimeField()
print(numpy.argmax(a_by_a, axis=1))
do_something(my_object)
G_ij = K(X_i, Y_j)
controller1.py
np.dot(a, weights)
tar.close()
deletea[k]
plt.show()
script = os.path.abspath(sys.argv[0])
print(np.where(mask)[0])
zdf2 = bcolz.ctable.fromdataframe(df2)
d2 = copy.deepcopy(d)
deletesys.argv[1]
len([x for x in str_.split() if x in list(dict_1.values())])
cur.close()
r = urllib.request.urlopen(req)
logging.getLogger()
media_frame.stack().map(m).unstack()
DataFrame.mode()[0]
d = dict(l)
app.test_request_context().push()
np.split(index[sort_idx], np.cumsum(cnt[:-1]))
df
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
mylist.pop()
c = b[index]
[do_stuff(a, b) for a, b in itertools.permutations(A, 2)]
sys.exit(app.exec_())
a = numpy.arange(25).reshape(5, 5)
self.figurecanvas.draw()
df = pd.read_csv(StringIO(text), parse_dates=[0])
followers_df.reset_index()
timestamps, elements = zip(*sorted(zip(timestamps, elements)))
urls = sys.argv[2:]
print(sys.version)
set(yourString) & set(badChars)
plt.yticks(np.arange(y.min(), y.max(), 0.005))
arr = np.empty(dims, dtype=kerneldt)
[e for e, g in groupby(sorted(my_list))]
heapq.heappush(heap, (-prod, n, n))
unittest.main()
foo(*values)
self.__dict__.update(cls.__dict__)
matched[1] += 1
bucket.delete()
sys.stderr.write(str(prompt))
plt.subplots_adjust(bottom=0.2)
writer.writerow(item)
pdb.Pdb.__init__(self)
df.CITY
self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
foo()
print(json.dumps(OrderedDict(table_data)))
plt.show()
d = {key: value for key, value in zip(keys, values)}
fig.clf()
id = Column(Integer, primary_key=True)
root = tk.Tk()
result = op_func(a, b)
sns.kdeplot(np.array(data), bw=0.5)
sum(delta_list, timedelta()) / len(delta_list)
deletedictionary[old_key]
plt.show()
parser.parse_args(f.read().split(), namespace)
Thread(target=run, args=(args.arg1, args.arg2))
newList
pkt[TCP].payload = send_hdr
termios.tcsetattr(fd, termios.TCSAFLUSH, new_settings)
threading.Thread.__init__(self)
socket.connect((HOST, PORT))
myList.index([x for x in myList if x != 0][0])
loop.run_forever()
print(msg.as_string())
lambda partition: target == sum(map(int, partition))
classifier.classify(featurized_test_sentence)
setattr(self, Properties_Pointers[i], group)
sorted(lst, key=lambda x: -x[1])
tuples_list = list(tuples2)
plt.scatter(list(range(len(y))), y, s=60, c=z, cmap=cm.hot)
plt.gca().add_artist(circle)
help(uuid.UUID.__init__)
fly.set_data([fdata[0][0], fdata[0][-1]], [fdata[1][0], fdata[1][-1]])
numbers_float = map(float, line.split())
fig.show()
pandas.DataFrame(data).groupby(0).mean()
self.id = self.get_next_id()
_to.update(_from)
print(difflib.get_close_matches(target_word, list_of_possibles))
[(x + y) for x, y in zip(*([iter(q)] * 2))]
do_something()
s = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
custom_API()
np.delete(x, indx)
QtWidgets.QListView.__init__(self, parent)
[(1 if p < 0.5 else 2) for p in classifications]
result = map(lambda x: x * P, S)
a = a[:]
print(os.read(f.fileno(), 50))
len(mylist)
p.terminate()
f.close()
abs((10 ** 0.5) ** 2 - 10) < 1e-10
vals[idx].tolist()
[np.argmin(a) for a in A1]
logger.setLevel(logging.WARNING)
oname.text
stations = OrderedDict((el, idx) for idx, el in enumerate(lines))
signal.signal(signal.SIGUSR1, handler)
np.sum(np.dot(xdiff, L_inv.T) ** 2, axis=1)
plt.subplot(212)
my_string.split()[:5]
ax.xaxis_date()
time.sleep(0.5)
fig.autofmt_xdate()
MyClass.__init__(a)
cursor.execute(sql, data)
threading.Thread.__init__(self)
thread.start()
main()
geoms.append(p)
threads.setdefault(row[2], []).append(row)
array([[11], [12]])
plt.pause(1)
pd.rolling_mean(data, window=5, center=True)
main()
[x for x in tokenize(txt)]
print(d[key])
soup.prettify()
df.drop(idx)
termios.tcsetattr(fd, termios.TCSADRAIN, new)
b = (x ** 2 for x in a)
x = x[:50]
lst.sort(key=itemgetter(1))
5 // 2
results[i].append(benchmark(i))
f.close()
yourlist.append(yourdict.copy())
self.socket.connect((server_ip, server_port))
threading.Thread(target=listen_to_audio).start()
merge(DataFrame(tmp, index=[0]), data)
zip(*lst)[0]
tick_params(labeltop=True, labelright=True)
parser = argparse.ArgumentParser()
client.load_system_host_keys()
np.vstack([get_col(col) for col in cols]).T
time.sleep(0.5)
a = np.array([0, 0, 0, 0, 0, 0])
bbins = np.bincount(b)
sorted(set(val for row in content.values() for val in row))
msg.attach(part)
xi, yi = np.meshgrid(xi, yi)
r = redis.Redis(connection_pool=pool)
pl.xlim(0, df2.shape[1])
QWidget.__init__(self)
plt.show()
data = list(datareader)
form = UserForm(request.POST, user=request.user)
sum(dict(structure).values())
driver.set_window_position(0, 0)
sheet = book.sheet_by_index(0)
np.unpackbits(b)[:n].reshape(shape).view(np.bool)
copy.deepcopy()
l.sort(key=itemgetter(0))
id = Column(Integer, primary_key=True)
os.startfile(d)
pg.QtGui.QApplication.exec_()
f.write(doc.toxml())
ax1.yaxis.set_major_locator(matplotlib.ticker.LinearLocator(nticks))
plt.show()
python - config - -cflags
python - config - -ldflags
main()
br.select_form(nr=0)
min_keys = [k for k in d if all(d[m] >= d[k] for m in d)]
print(sysconfig.get_config_vars())
print(zip(*p))
itertools.product(universe, repeat=2)
ax = fig.add_subplot(1, 1, 1)
sys.path.append(os.path.basename(os.path.dirname(__file__)))
list(zip_longest(*([iter(chain([0], *liPos))] * 2)))
plt.figure(1)
f.seek(0)
df = pd.read_csv(yourdata, dtype=dtype_dic)
plt.show()
ax = fig.add_subplot(1, 1, 1)
gen.__code__.co_name
df.columns = df.iloc[1]
sys.stdout.flush()
session.add_all([a, b])
Foo.__str__ is not object.__str__
QtGui.QWidget.__init__(self)
app.logger.setLevel(logging.INFO)
signal.signal(signal.SIGUSR1, debug)
HttpResponseRedirect(url)
fig = plt.figure()
l = [0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1]
list(product(*iterables))
parser.parse(some_file)
print(max(path.nodes, key=lambda item: item.y))
requests.get(url, cookies=load_cookies_from_lwp(filename))
time.sleep(60)
tf.matmul(x, tf.transpose(y))
writer = csv.writer(fout)
self.someSignal.connect(self.someSlot)
a2.ravel()[:] = m.reshape(2, -1).T.tolist()
np.where(binplace == 1)
pprint.pprint(value)
print([list(g[1]) for g in groupby(sorted(l, key=len), len)])
instance = form.save(commit=False)
fig, ax = plt.subplots()
fig, ax = plt.subplots()
Books.objects.filter(q)
random_number = random.random() * 2 - 1
datetime.time(0, 0, 0)
sys.path.append(lib_path)
print(my_list)
ax.set_aspect(1)
input.close()
p.terminate()
print(numpy.linalg.norm(x))
plt.close()
myfunc(*mylist)
fig.show()
fig.autofmt_xdate()
f = sys.stdin
input()
Znew = griddata(Xmesh.flatten(), Ymesh.flatten(), Z.flatten(), Xnew, Ynew)
signed_angle = atan2(b.y, b.x) - atan2(a.y, a.x)
dis.dis(lambda : i)
root.mainloop()
blobs = BlobInfo.all().fetch(500)
first_elements, second_elements = zip(*data)
sorted([i for i in lst if i > 0]) + sorted([i for i in lst if i < 0])
y = math.cos(1 * math.pi / 180)
s = math.sqrt(max(radius * radius - i * i, 0.0))
print(urllib.request.urlopen(ipcheck_url).read())
c.execute(query)
xml_etree = ET.parse(xml_filename, parser=parser)
cs.send(c + 1)
timestamp.sort(reverse=True)
fig = plt.figure()
base64.b64encode(stream.getvalue()).decode()
out_file.write(indata)
print([num for num in a if counts[num] > 1])
QtGui.QWidget.__init__(self, parent)
[np.where((B == x).sum(axis=1))[0] for x in A]
file.write(line)
d.update([a, b, c])
selected_array = my_array[mask]
results = Orchard.objects.filter(**options)
plt.show()
(v1 == v2).all()
self.timer.start(10)
reactor.run()
[c for c in col_names if all([(f not in c) for f in filter_array])]
f.axes[5].set_position([0.95, 0.05, 0.05, 0.4])
df2 = df[df.Group.isin(groups)]
out.shape
clp.CloseClipboard()
self.crawler.install()
np.count_nonzero(A == B)
pipe.communicate()
plt.imshow(data.T)
ax.plot_wireframe(X, -Y, Z, rstride=1, cstride=1)
df.shape[0] - df.dropna().shape[0]
str(self.person)
fstools.py
entry_list = [entry.title.text for entry in feed.entry]
args = parser.parse_args()
f(*args, **kwargs)
ax.set_ylim(bot, top)
f = lambda x: 2 * x
os.waitpid(cpid)
SumLine.extend(ast.literal_eval(x))
print(list(Counter(L).items()))
x[np.lexsort((x[:, (0)], x[:, (1)]))]
ax.set_xlim(x_min, x_max)
print(cert.get_issuer().as_text())
p.terminate()
plt.show()
Base.metadata.create_all(engine)
root.destroy()
self.f(*args, **kwargs)
infile.close()
self.graph, = self.ax.hexbin(self.xData, self.yData)
i += 1
array([[0, 0, 1, 1], [0, 1, 1, 0]])
result.append(myDict)
plt.draw()
time.sleep(0.01)
sys.stdout.write(out)
zip(a[0], a[1])
globals().update(test.__dict__)
log.start()
foo()
np.ma.median(y, axis=0).filled(0)
dict_of_lists = merge_with(list, *csv.DictReader(open(f)))
[0, 1, 0, 2, 1, 1, 1, 0],
object.__new__(cls, x)
sandboxed()
inspect.getargspec(func)
np.where(np.in1d(a, b))[0]
max(depth(d[k], level + 1) for k in d)
result = [_f for _f in map(expensive, mylist) if _f]
sys.stdout.flush()
results = cursor.fetchall()
print(r.cookies)
x.append(y)
node_count = len(db.nodes)
list(itertools.chain(*a))
socket.close()
estimated_mu, estimated_sigma = stats.norm.fit(logdata)
time.sleep(5)
created_date = Column(DateTime, default=datetime.datetime.utcnow)
options, args = parser.parse_args()
f.close()
print([(dotted[n][:-1] + (i,)) for s in signs for n, i in enumerate(s)])
n, bins, patches = plt.hist(x, histedges_equalN(x, 10), normed=True)
signal.signal(signal.SIGINT, signal.SIG_DFL)
next(g)
repr(self.contained)
web.show()
hasattr(obj, name) and type(getattr(obj, name)) == types.MethodType
time.sleep(1)
pool.terminate()
time.sleep(self.interval)
ftp.close()
fig = plt.figure()
plt.tight_layout(rect=[0.05, 0.15, 0.95, 0.95])
hex(x)[2:]
matplotlib.get_backend()
plt.draw()
unittest.TextTestRunner().run(suite)
p = Pool(5)
layout.addWidget(self.button)
pygame.mixer.init()
bytearray(os.urandom(1000000))
objs = [MyClass() for i in range(10)]
chain.from_iterable(combinations(s, r) for r in range(1, len(s) + 1))
wrapper_object.blink()
rsa = M2Crypto.RSA.load_pub_key(pk)
self.progress.pack()
self.output.append(data)
lst[0].append(1)
print([(k, len(d[k])) for k in sorted(d.keys())])
print(x.apply(lambda y: list(filter(np.isfinite, y))))
repeated_items = [list(row[1] * row[2]) for row in df.itertuples()]
sorted(list(dct.items()), key=lambda p: p[1], reverse=True)
os.dup2(cat.stdin.fileno(), sys.stderr.fileno())
plt.colorbar()
min(data, key=lambda t: t[1])
print(tuple([k] + [v for d in L for v in list(d.values())]))
f.write(bytes(int(x, 0) for x in L))
my_tuple[isinstance(x, str)].append(x)
ax = fig.add_subplot(1, 1, 1)
self.window.set_default_size(self.width, self.height)
a[len(a)]
df[~df.isnull().all(axis=1)]
event_box.set_events(gtk.gdk.BUTTON_PRESS_MASK)
list2 = [dict2[k] for k in commons]
smtpObj.sendmail(sender, receivers, message)
f.read()
top.mainloop()
browser = webdriver.Firefox()
tt = t.reshape(-1)
stats = df.describe()
main()
img = Image.open(BytesIO(response.content))
[int(elem) for elem in testList]
[functools.reduce(dict.__getitem__, keys, d[i]) for i in d]
plt.show()
datetime.time
diags.sum(axis=1)
MySQLdb.connect(server, username, password, database, local_infile=1)
m.groups()[0].strip()
input_file.close()
plt.show()
[myFunc(p, additionalArgument) for p in pages]
inspect.ismethod(d.__setitem__)
plt.show()
a = np.arange(100).reshape(2, 50)
d = json.loads(s)
x_new = x[np.sum(x, axis=1) > 0.5]
results_df = pd.concat(results)
sys.exit(1)
a, b = divmod(a, 1)
p.terminate()
doctest.testmod()
lists[1].append(url)
np.random.shuffle(a)
pdb.set_trace()
Job.fetch(job_id, connection=conn)
HttpResponse(status=500)
print(s, len(s))
self.SetClientSize((self.bmp.GetWidth(), self.bmp.GetHeight()))
foo.wait()
plt.show()
id = models.CharField(max_length=255, default=create_id)
x = np.linspace(0, 1, 20)
main()
QtGui.QMainWindow.__init__(self)
array_proxy()
os.kill(int(pid), signal.SIGTERM)
sess.run(tf.initialize_variables(set(tf.all_variables()) - temp))
print(ET.tostring(dom))
main()
signal.signal(signal.SIGUSR2, lambda sig, frame: code.interact())
f(*args, **kwargs)
ax.scatter(X[:, (0)], X[:, (1)], s=s)
plt.show()
self.a = a
[np.bincount(xs, minlength=10) for xs in itertools.combinations(list(range(10)), 2)]
numpy.linalg.norm(A - B)
plt.subplots_adjust(0, 0, 1, 1, 0, 0)
self.driver.close()
max(lengths(l))
x = {i: set() for i in range(10)}
print(line)
args[-1] + mySum(*args[:-1])
myDict[name]
len(s)
arr = numpy.array([(base + datetime.timedelta(hours=i)) for i in range(24)])
fig = plt.figure(1)
df.replace(to_remove, np.nan, inplace=True)
data.sort()
255, 255, 255
ax2.set_xlim(ax1.get_xlim())
self.calendar.pack()
some_list[:target_len] + [0] * (target_len - len(some_list))
ax2.plot(x2, x2, alpha=0)
a = str(datetime.now())
time.sleep(1)
object.__repr__(self)
max(len(str1), len(str2))
t.start()
print(func_name)
plt.contour(xi, yi, zi, con_levels, linewidths=1)
cv2.circle(cimg, (i[0], i[1]), i[2], (0, 255, 0), 2)
df.sort_index(inplace=True)
[var_1]
result = map(f, [x, y, z])
utc_dt = local_dt.astimezone(pytz.utc)
df = pd.concat([df1, df2], ignore_index=True)
axcut.set_visible(True)
mydriver = webdriver.Firefox()
np.random.seed(0)
file_out.write(line)
json.loads(page_detail_string)
sys.__stdin__ = dummyStream()
ax.clear()
nan in np.array([nan])
list1.append(i)
self.data.append(data)
set(b.items()) ^ set(a.items())
print(response.status, response.reason)
s.dt.to_pydatetime()
dictionary[round(a, 4)]
meta.create_all()
app.exec_()
data[data[data[:, (0)] == 0, 1] == 0]
f.close()
df2.fillna(0, inplace=True)
dill.pickles(f)
list(set(a) - set(b))
rdd = df.rdd.map(tuple)
all([(len(i) == len(set(i))) for i in zipt])
stock_vals[stock_name][day_index]
myDict = dict(list(element.attributes.items()))
appname = get_application_id()
cs = m.contourf(x, y, nc_new, numpy.arange(0.0, 1.0, 0.1), cmap=plt.cm.RdBu)
np.hstack([R, phase])
{{test | tojson | safe}}
out = ohc.fit_transform(X)
print(repr(a))
zip(a, b)
0j
expand = [(a * int(b) if len(b) > 0 else a) for a, b in test]
blog_post = models.ForeignKey(BlogPost)
x[nonzeros].dot(mat[nonzeros])
pygame.init()
found = any(word == line.strip() for line in file)
A[:, (0)]
self.file.close()
ContentType.objects.get_for_model(obj)
np.bmat([[A, D], [C, B]]).A
self.panel.SetSizer(main_sizer)
os.chdir(curdir)
fig, ax = plt.subplots(1, 1, figsize=(12, 5))
array([1, 2])
p4in.close()
pp.sort(key=lambda p: math.atan2(p[1] - cent[1], p[0] - cent[0]))
Py_DECREF(v)
l[:] = [(x * 5) for x in l]
l1.append([7, 8, 9])
min(dictionary.values())
[elem for i, elem in enumerate(inputlist) if i not in excluded_indices]
Bar.objects.foo_active()
df.index + pd.offsets.MonthEnd(0)
print(list(locals().keys()))
server.quit()
plt.xticks(x)
list(replaceiniter(range(11), lambda x: x % 2))
np.any(a == 5, axis=0)
[list(g) for k, g in groupby(a, lambda x: x != 0) if k]
cursor.execute(*sql_and_params)
session.query(User, User.entries_count(Entry.date > start_date))
root.mainloop()
k += 1
a.shape
plt.show()
d = {m.get(key, key): value for key, value in list(d.items())}
utc_now = datetime.datetime.utcnow
pool = Pool(processes=2)
map(dictionary.__delitem__, lst)
reduce(dict.get, path, aDict).update(aSecondDict)
n * n
LOGGER.setLevel(logging.WARNING)
self.root.mainloop()
cookiejar.set_cookie(cookie)
np.power(df, 2)
GC.remove_edge(*clique[0:2])
a[::-1]
random.shuffle(b)
plt.show()
time.sleep(1)
save_as = True
sum(map(lambda x, y: x * y, l1, l2))
print(thingy.attrib)
min(a, key=itemgetter(1))
ax = fig.add_subplot(111)
vscrollbar.grid(row=0, column=1, sticky=N + S)
time.sleep(1)
print(np.loadtxt(io.BytesIO(trace.text)))
os.nice(20)
df = pd.read_csv(filename, skiprows=lines2skip)
array([nan + 0j, nan + nanj, nan + nanj, nan + nanj, nan + nanj])
dis.dis(f)
sys.excepthook = handle_exception
f.close()
dis.dis(lambda x: x)
logging.Handler.close(self)
ax.set_yticks(list(range(0, 90, 10)))
main()
found = re.findall(regex, my_txt)
print(f.decorator)
df.matches.sum()
print(numpy.sum(c * a))
plt.show()
plt.pcolormesh(X[i - 2:i], Y[i - 2:i], C[i - 2:i])
sys.path.insert(0, self.path)
random.shuffle(thelist)
module1.Relay(1, 1)
User.objects.filter(id=self.request.user.id)
time.sleep(5)
template.render(**vars)
[list(i) for i in set([tuple(sorted(i)) for i in a])]
lbl8.grid(row=2, column=0)
ao[:, :-1] += ai[:, 1:]
fpid.close()
f(1, 2)
print(sys.path)
print(np.allclose(a2, a))
sorted(templist, key=int)
tt = np.linspace(0, 19, 20)
ord(chars[0])
func(arg)
print(a[:, (1)])
(d1.year - d2.year) * 12 + d1.month - d2.month
self.children = {}
queryset = Model.objects.all()
show()
input.close()
unitary = [linalg.expm(-(1j) * t * h) for t in t_list]
plt.draw()
user.save()
parser = argparse.ArgumentParser()
my_func()
show()
result = bool_indices.apply(lambda x: df.loc[x, col_values].sum())
cv2.cv.CreateMat(500, 500, template.dtype)
time.mktime(t.timetuple()) + t.microsecond / 1000000.0
conn.close()
df.loc[lhs, column] = rhs
callback(self)
plt.clf()
response
np.vstack((a, a, a))
height = img.shape[0]
zip(list(range(len(a))), a)
os.path.join(root, file)
output.close()
print(self.__name__)
canvas.grid(row=1, column=1, sticky=Tkconstants.NSEW)
hosts = sorted(celery.current_app.control.inspect().ping().keys())
obj.save()
decorator
x = [(bah * 2) for bah in buh]
self._socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
s.connect((ip_addr, port))
a.py
list(results.values())
X_imputed_df = pd.DataFrame(X_imputed, columns=X_train.columns)
Counter(A.flat).most_common(1)
scores.append(clf.score(X[outer_test], Z[outer_test]))
plt.show()
jsonFile.seek(0)
sorted(lst, key=lambda x: (x < 0, x))
lis.append(lambda i=i: i)
(get_comments.s(url) | render_template.s()).apply_async()
a = numpy.empty([210, 8])
communication_set.save()
self.setWindowFlags(QtCore.Qt.FramelessWindowHint | QtCore.Qt.Popup)
words = sorted(wordset)
plt.gca().yaxis.set_major_locator(MaxNLocator(nbins=6))
pivoted.cumsum() + (pivoted == -1)
pd.isnull(np.array([np.nan, 0], dtype=object))
C = A * B
time.sleep(1)
ax = fig.add_subplot(111, frameon=False, xticks=[], yticks=[])
pygame.display.quit()
file.flush()
print(Y.transpose())
root.mainloop()
self.create(request, *args, **kwargs)
type(li)(map(double, li))
plt.legend()
p = subprocess.Popen(cmd, shell=False, stdout=subprocess.PIPE)
category = forms.ChoiceField(choices=CATEGORIES, required=True)
pygame.display.set_mode()
arr[arr > 255] = x
cursor.execute(sql)
test_moduleB.py
main.py
plt.gca().add_artist(leg2)
plt.gca().add_artist(leg4)
plt.gca().add_artist(leg6)
[1][1][1]
x.pattern
zip([iter(l)] * 2)
len(set(hashlib.sha256(str(i)).hexdigest()[:5] for i in range(0, 2000)))
name = models.CharField(max_length=200)
print(time.time())
Counter(list(c.values()))
results = pbex.run()
data = json.load(f)
ax = fig.add_subplot(1, 1, 1)
ax.set_xlim(0, m.shape[1])
numpy.random.rand(count)
result = next(x for x in my_list if works(x))
ts = pd.Series([2, 1, 2, 1, 5], index=date_index)
np.savetxt(s, x)
s.close()
t = datetime.datetime(2009, 4, 1)
ax2.xaxis.set_visible(False)
Gtk.main()
root.mainloop()
img.write(pdf_path)
self.entry.focus_set()
print(result.groups())
worker.send(msg, zmq.NOBLOCK)
{{(request.user.username | multiply): 5}}
AB = np.matmul(A, B)
list(itertools.product(list(range(5)), list(range(5))))
rendered_output = template.render(context)
my_date = datetime.date.today()
a.insert(len(a), 5)
data_dict = defaultdict(list)
self.stateChanged.connect(self.handleStateChanged)
temp = tuple(map(sorted, zip(*alist)))
print(x[0], len(list(x[1])))
somelist.sort(key=ordering.get)
assert text in self.driver.page_source == True
isinstance(value, list)
population = [a for n, a in zip(pops, alleles) for _ in range(n)]
__import__(module)
etree.tostring(tree)
a[:2, (2)] = 0
app.run(debug=True, use_reloader=False)
lista = [x for x in db]
indices_zero = numpy.arange(len(array))[bindices_zero]
[(1.0 * conversions[n] / trials[n]) for n in range(len(trials))]
self._dealer = dealer
func(*args, **kwargs)
shutil.copyfileobj(key, rsObject.stream())
tk.Tk.__init__(self, *args, **kwargs)
--Commentasfkjaskfj
fig, ax = plt.subplots(1, 1)
resultqueue.join()
np.isnan(a[2]).nonzero()
cells = [n for n in B.nodes() if n[0] not in nodes]
setattr(obj.a, p, value)
add_something(l)
plt.show()
res = (list(range(s, s + step + 1, step)) for s in range(start, stop, step))
app.MainLoop()
type(())
L.sort()
print(contruct.__version__)
print(m.group())
array([[100, 200], [255, 255]], dtype=uint16)
print(json.dumps(parsed, indent=4, sort_keys=True))
Av = np.hstack(A)
ent7.grid(row=2, column=1)
list(zip(*(d[k][n] for k in keys for n in d[k])))
MyObject.objects.bulk_create(my_objects)
value = models.CharField(max_length=240, db_index=True)
np.mean([0, 1, 2])
theclass.run()
signal.signal(signal.SIGINT, s)
u = np.random.random(100)
[(key, list(val)) for key, val in itertools.groupby(lst, lambda x: x[0:5])]
self.x.pack(side=LEFT)
find_majority([-1, -1, 0, 0, 0])
print(dom.toxml())
sorted(xs, key=len)
[func(elem) for elem in lst]
ax.add_patch(polA)
ax.add_patch(polB)
out.close()
df.head(5)
df.iloc[:, (0)]
pylab.show()
my_category.category.all()
window.unfullscreen()
ax.xaxis.set_ticks_position(direction)
plt.figure()
lxml.html.tostring(root)
os.unlink(f.name)
excel.Quit()
(A + B).min(axis=1)
connection.close()
task.AsyncResult(task.request.id).state
numbers = list(map(int, s.split()))
df
model.fit_transform(X, y)
list(range(0, n + 1, 2))
main()
time.sleep(1)
results.sort(key=lambda x: x[1])
listmatrixMap(lambda val, r, c: ((r, c), val), a, indices=True)
yaml.dump(self.__dict__)
parser = argparse.ArgumentParser()
app.run()
ax.set_yticklabels(row_labels, minor=False)
diff_file.write(difftext)
diff(unwrap(phase(hilbert(filtered_data))))
data.depth * len(data.getbands())
t.start()
ntxt.write(rline)
server.quit()
QtGui.QApplication.sendEvent(clipboard, event)
pd.groupby(b, by=[b.index.month, b.index.year])
some_file.seek(0)
ssh_client.connect(host, username=user, password=password)
df[~df.index.isin(dropThis)]
token.save(force_insert=True)
browser.close()
strange_sandwich()
[lst[indices[i]:indices[i + 1]] for i in range(n)]
idx = np.argsort(a[1])
MyClass = funkyDecorator(MyClass)
pygame.display.flip()
self.f.make_a_doo()
b = copy.deepcopy(a)
df.round()
self._rooms = dict()
itertools.chain(*zip(*iters))
sizer.Add(notebook, 1, wx.EXPAND)
list()
s = urllib.request.urlopen(form_url)
os.getpid()
set([4, 5, 6])
output.append(acids[0])
np.diff(m.tocsc().indptr)
yacc.errok()
print(locals())
print(repr(tokzr_SENT(inp1)))
plt.xlim(np.log10(ilim))
print(ET.tostring(f))
f.write(ip)
main()
func(*parameters)
main()
app.run()
label.pack()
[a for i in items if C]
fo.close()
plt.show()
encodedWindow = base64.b64encode(s.getvalue())
session.add(stud)
data = json.loads(response.get_data(as_text=True))
logger.setLevel(logging.DEBUG)
print(item)
foo(*params)
df.sort_index(inplace=True)
logger.setLevel(level)
p.start()
globals[key] = value
df[~df.field.isin(ban_field)]
plt.show()
QApplication.restoreOverrideCursor()
ax2 = fig.add_subplot(1, 2, 2)
items.remove(item)
db.session.commit()
installer.uninstall()
plt.show()
dict(heapq.nlargest(5, list(names_dict.items()), key=itemgetter(1)))
arr[idx[:, (0)], idx[:, (1)]]
df.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))
main()
self.data[column].add(row)
df.isnull().sum()
GL.glOrtho(-1.0, 1.0, -1.0, 1.0, -1.0, 1.0)
service = __create_service()
widget.show()
print(A.T)
b.swapaxes(0, -1)
stream.Close()
escaped = re.escape(a_string)
C.objects.create(a=a1, b=b)
inputElement.submit()
os.unlink(tmpfile_name)
sorted_files = sorted(all_files, key=os.path.getsize)
print(G.nodes())
S = [5, 5]
data = re.findall(pattern, line)
root.mainloop()
parser = etree.XMLParser(remove_blank_text=True, strip_cdata=False)
datetime.datetime.fromtimestamp(0) + datetime.timedelta(seconds=2047570047)
func.__code__.co_freevars
ax = fig.add_subplot(111)
print(df)
self.filelist.append(zinfo)
mlab.axes()
gtk.main()
self.setCentralWidget(self.button)
type(a)
xs = dict((i, []) for i in range(2))
newprefix = prefix[:]
lstbox.grid(column=0, row=0, columnspan=2)
map(lambda *x: sum(x), list(range(10)), list(range(10, 0, -1)), list(range(0, 20, 2)))
wx.Button.__init__(self, *a, **k)
matrix = np.random.randint(2, size=(row, col))
development.py
p.wait()
low_bit_list = [(byte & 1) for byte in bytearray(fh.read())]
rev_sorted = sorted(paired, reverse=True, key=lambda x: x[1])
f.write(line)
pool.close()
ax = fig.add_subplot(111)
sum(map(doSomething, originalList), [])
result.append(func(e))
self.Bind(wx.EVT_BUTTON, self.OnClick, b)
exit(0)
[False, False, False, False, False],
queue = deque([])
tk.Tk.__init__(self, *args, **kwargs)
__init__.py
self.buttonStart.clicked.connect(self.worker.run)
Base.metadata.create_all(bind=db.engine)
foo(n - 1) + [1]
connection.start()
webdriver.ActionChains(driver).move_to_element(el).click(el).perform()
app.run()
m1 = np.zeros((50, 50))
driver.quit()
year = datetime.datetime.today().year
f.writelines(file_lines)
np.where(self == value)
root.mainloop()
session.commit()
y[0] = 0
print(response.read())
time.sleep(10)
t0 = math.pow(math.tan(phi1), 2)
searchfile.close()
[add_number(xi) for xi in my_list]
ax.add_line(line_2)
sys.path
plt.gca().add_patch(rect)
f.close()
A, = np.array(M.T)
sys.path.pop(0)
stream = sys.argv[1:] and open(sys.argv[1]) or sys.stdin
int(bin(n)[:1:-1], 2)
doc = etree.parse(url)
optimize.fmin(func, x0=[y_estimate, z_estimate], args=data)
elm = driver.find_element_by_xpath(expression)
result = (x.sum() ** 2 - x.dot(x)) / 2
assert diff_month(datetime(2010, 10, 1), datetime(2009, 8, 1)) == 14
session.query(Workflow).get(id)
filtered_output.write(line)
psutil.cpu_times()
msglist.append(hextotal[start:start + 4096])
data.write(c + n)
b1.insert(END, item)
x.append((i, j))
dict(zip(fields, row))
True
test[:, ([0])]
y = np.array([-1, 1, 1, 1, -1, 1])
controller2.py
controllerapi.py
utilities.py
extfoo.py
array = np.ones((n, n))
words = {line.strip() for line in file_a}
Cmd.cmd.__func__()
Base.metadata.create_all(engine)
data = pd.concat([data, stock_data], axis=1)
self.window.fullscreen()
data = cursor.fetchone()[0]
math.degrees(math.atan(1.18))
Category.objects.get(pk=2).get_descendants(include_self=True)
client.close()
self.root.mainloop()
cv.SetCaptureProperty(video2, cv.CV_CAP_PROP_FRAME_WIDTH, 800)
print(open(my_module.__file__).read())
L.pop(i)
self.image.show()
text = Tkinter.Text()
fin.close()
df.loc[g.groups[1]]
[(x[0:index] + x[index + 1:]) for x in L]
s.groupby(s.index).first()
[x for x in seq if not (x in seen or seen_add(x))]
dt.replace(microsecond=int(parts[1]))
plt.gca().add_artist(mynewline)
sys.maxunicode
new_list = [foo for foo in foos if foo.location == 2]
fig, ax = plt.subplots(figsize=(8, 8))
f.seek(0, 0)
dict_of_lists[key].append(val)
[next(generator) for _ in range(n)]
ax.set_xticks(np.linspace(0, 2 * np.pi, 5))
ax1.xaxis.set_major_locator(xloc)
x.append(sublist[0])
L4 = list(item for item in L1 if item not in unwanted)
time.sleep(duration)
foo.module_method()
os.path.normpath(path1) in (os.path.normpath(p) for p in list_of_paths)
list(chain.from_iterable(zip(a, reversed(a))))[:len(a)]
self.variable_evidence.arrays.append(self.basic_in)
np.finfo(np.float).eps
self.finish()
arr[(arr[:, (0)] >= xmin) & (arr[:, (0)] <= xmax)]
Thaidump(text)
plt.show()
a[0] = np.nan
data = [(b[1], p, b[0], b[2]) for p, b in list(rays_starters.items())]
is_main_user = models.BooleanField(default=False)
plt.show()
image.show()
print(term.move(term.height - 1, 0))
a[i1, i2, i]
msvcrt.get_osfhandle(a.fileno())
pd.Series(np.nanmean(val.reshape(-1, k), axis=1))
msg.send()
os.makedirs(final_path)
time.sleep(0.01)
math.factorial(n)
[(i - set.union(*[j for j in allsets if j != i])) for i in allsets]
text.pack()
dict((k.lower(), v) for k, v in d.items())
df.reset_index(inplace=True)
s.groupby(idx).mean()
module.myif.__init__(self)
cur.execute(query, parameters)
set(tuple1).issubset(tuple2)
sum(itervalues(d))
instance = YourModel(name=value, image=self.get_image_file())
value = np.ctypeslib.as_array(value).tolist()
r.json()
fifth_period_slope = np.diff(y[::5]) / np.diff(x[::5])
tree = scipy.spatial.cKDTree(array_of_coordinates)
abs(a - b) <= max(rel_tol * max(abs(a), abs(b)), abs_tol)
dict(d2, **d1)
df2 = pd.DataFrame(index=df1.index.copy())
image = Image.open(file)
df = df[df.line_race != 0]
np.unravel_index(np.ravel_multi_index((10, 1, 2), arr1.shape), arr2.shape)
time.sleep(10)
all(not element for element in data)
min([s for s in lst if isinstance(s, str)])
list_of_pixels = list(im.getdata())
root = tk.Tk()
id = Column(Integer, primary_key=True)
plt.show()
arr = np.array(arr_ip, dtype=dtyp)
[[[1]][[2]]]
logger.setLevel(logging.DEBUG)
sys.exit(app.exec_())
df.sum()
signal.signal(signal.SIGINT, handler)
a = np.empty((15,))
mymodel.objects.filter(pk=a[i]).update(attr=i)
[i for i, v in enumerate(a) if v in b_set]
print(name.title())
df_both.swaplevel(0, 1).sort_index().swaplevel(0, 1)
x = list(y)
self.pot.temperatureRaisedSignal.connect(self.temperatureWarning)
plt.show()
{{post.text | markdown}}
self.user.username
self.get_solr_results()
df
widget.setWindowFlags(QtCore.Qt.Widget)
print(et.tostring(tree))
plt.show()
button.show()
a2.append(float(s))
[0][0][2]
repo.push()
lexobj.writetab(lextab, outputdir)
client = paramiko.SSHClient()
(lst[i] for i in indices)
resolve(request.path).app_name
b[a] = 10
f.close()
len([x for x in a_list if x[0] == 1]) > 0
fig.subplots_adjust(bottom=0.2)
ax2.set_xticklabels(new_labels)
plt.imshow(Z)
datetime.utcfromtimestamp(timestamp1)
plt.show()
args = parser.parse_args(sys.argv[1:])
(lambda : 1) == (lambda : 1)
g = nx.Graph()
foo.x
print(sum(i * i for i in l))
print(max(b - a for a, b in pairwise(values)))
plt.legend()
w.show_all()
pcap_lookupnet(dev, ctypes.byref(mask), ctypes.byref(net), errbuf)
server.serve_forever()
setattr(cls, attr_name, prop)
list(nx.weakly_connected_component_subgraphs(G))
ax0b.plot(x, y)
ax0c.plot(x, y)
mysignal.connect_via(app)(print_howdy)
fig = plt.figure()
app.run()
root = Tk()
logging.Handler.__init__(self)
serializer = NewModelSerializer(data=request.data, context=context)
win.show_all()
zip(*elements)
any(1 in d for d in lod)
urlparse(request.url).query
{(1, 1): something}
post_save.connect(create_user_profile, sender=User)
process.kill()
print(y.shape)
raise TypeError(node)
func(*args, **kw)
print(aiff_file.nframes / float(aiff_file.samplerate))
m.toarray()
d.setdefault(y, []).append(x)
pd.DataFrame({n: c.apply(lambda x: x.get(n, 0)) for n in wordlist})
session = requests.Session()
fid.close()
[0] * A + [1] * B
binascii.hexlify(bytearray(array_alpha))
wavf.write(out_wav, fs, out_data)
print(p.stdout.read())
[(car.pop(0) if item else a.pop(0)) for item in lyst]
dic[g][y] = df[(df[Gender] == g) & (df[Year] == y)]
validate(yaml.load(bad_instance), yaml.load(schema))
new_list = [v for v in a if v not in b]
dict_out = {unq[i]: iterID for i, iterID in enumerate(indices)}
app.start()
form = PostForm(obj=post)
sizer.Add(self.canvas, 1, wx.EXPAND)
np.put(out, np.ravel_multi_index(idx.T, dims), vals)
cb = plt.colorbar(sc, ax=ax1, aspect=10, format=Myfmt())
gs1.update(wspace=0.025, hspace=0.05)
yylex()
admin.site.register(User, UserProfileAdmin)
row = cursor.fetchmany(10)
root.mainloop()
sorted(a) == sorted(b)
math.floor(math.log(n, 2)) + 1
f.write(sio.getvalue())
num_fatals += 1
server.run()
func = yad(list_of_decorators)(func)
blogpost.tags[:] = new_tags
writer.writerow(row)
isinstance(amodule, __builtins__.__class__)
HTMLParser.HTMLParser.__init__(self)
ax = fig.add_subplot(111, polar=True)
scatter = ax.scatter(np.random.randn(100), np.random.randn(100))
QtGui.QFrame.__init__(self, parent)
print(m.group(1).rstrip())
one, four, ten = [lst[i] for i in [1, 4, 10]]
gtk.main()
print(hashlib.sha512(password).hexdigest())
cv2.__version__
qs.filter(map(operators.or_, [Q(k=v) for k, v in list(request.GET.items())]))
L[idx].append(item)
cashflow[-1] += 100
ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())
runner.run()
np.mean([0, 0, 1])
file.seek(0)
urllib.request.urlretrieve(url, filename)
print((word, count))
s1.reset_index()
b = a[:]
list(unique_everseen(lst, key=len))
isinstance(obj, collections.Callable)
df.columns = new_cols
time.sleep(1)
time.sleep(1000)
self.send_response(200)
oath_access_token = utils.get_application_access_token(app_id, app_secret)
root.columnconfigure((0, 2), weight=1)
element = max(myset)
[x for x in myTuple if foo(1, x, 4)]
[(elem + func()) for elem in myList]
d[k].append(v)
results = sorted(list(results_dict.items()), key=lambda x: x[1])
db.session.add(post)
self.y = [self.x for i in range(1)]
ax.plot_surface(X, Y, Z)
nodes = [node() for _ in range(100)]
popt, pcov = curve_fit(lambda x, a: func(x, a, b), x1, x2)
User.objects.get(id=uid)
plt.gcf().subplots_adjust(hspace=0.5, wspace=0.5)
plt.show()
msvcrt.setmode(sys.stdin.fileno(), os.O_BINARY)
COMPRESS_ENABLED = True
cmp(A[adiff], b[bdiff])
network.draw()
np.sqrt((w * q * q).sum())
np.allclose(np.dot(A, B), A * sparse_B)
threading.Thread.__init__(self)
[[df.columns[j] for i, j in grp] for k, grp in groups]
foo(*x, **y)
time.sleep(1)
session.commit()
gs1 = gridspec.GridSpec(4, 4)
FOUT.close()
root.mainloop()
ax1 = fig.add_subplot(111)
ax.minorticks_off()
df1.index & df2.index
print(x.apply(lambda y: [a for a in y if pd.notnull(a)]))
[(sum([(i * i) for i in vec]) ** 0.5) for vec in x]
proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, env=initial)
(value for key, value in sorted(dictobj.items()))
isodd = lambda x: x % 2 != 0
list.__setitem__(self, index, value)
d.sort(key=itemgetter(0))
pd.DataFrame({n: c.apply(lambda x: x[n]) for n in wordlist})
n = n + 1 / 10 ** (len(repr(n)) - 2)
hist = History.objects.get(pk=1)
[x for x, y in groupby(L) if sum(1 for i in y) < 2]
b[1:] = b[1:] - b[:-1]
driver = webdriver.Chrome(chrome_options=opts)
df
ax.xaxis.set_visible(False)
np.delete(x, 1, 1)
conn.close()
pylab.show()
driver.get(url)
a = np.hstack((a, b))
d = {k: list(v) for k, v in groupby(tags, key=lambda x: x[0])}
-tox
fsizer.Add(self.filtr, 1, wx.EXPAND)
tfile.seek(0)
print(chr(i))
li2 = list(itertools.chain(*li))
parser = argparse.ArgumentParser()
avg_rating = db.FloatProperty()
os.dup2(w, sys.stderr.fileno())
[numpy.all(-2), numpy.all(-1), numpy.all(0), numpy.all(1), numpy.all(2)]
date_parser = pd.datetools.to_datetime()
sorted(population, key=keyfun)
td_series.astype(pd.Timedelta).apply(lambda l: l.days)
GPIO.output(4, True)
formset.save_m2m()
soup = BeautifulSoup(page)
pattern = re.compile(re.escape(motif))
id(df._data.blocks[0].values)
writer.writerow(row)
df.loc[df.isin([1, 2]).any(1)]
os.path.join(base_path, relative_path)
array[mask] = 255
sftp.close()
print(temp_df.apply(lambda x: x - temp_arr[x.index], axis=1))
[k for k, v in list(d1.items()) if v == m][0]
cmds.ls(sl=1, fl=1)
pygame.draw.circle(surf2, (200, 0, 0, 100), (100, 100), 100)
writer = csv.writer(f)
exit()
ax1 = fig.add_subplot(111)
s = s[117:]
b.extend(map(ord, s))
text = nltk.Text(tokens)
run()
subprocess.call([PLAYERPATH, FILEPATH])
yaml.add_representer(OrderedDict, represent_ordereddict)
ax.imshow(im)
[(float(p[1] + p[2]) / 2) for p in PlayerList]
main()
print(br.response().read())
self.create(request, *args, **kwargs)
all(starmap(lt, zip(a, b)))
signal.pause()
y = list(x)
print([(y - x) for x, y in l])
df = df[colnames]
results = [do_smth(slurp_file(f)) for f in filenames]
print((k, v))
plt.colorbar(pc, cax=axes)
math.isnan(a)
df.iloc[sort_slice]
Base.metadata.create_all(engine, checkfirst=True)
plt.plot([0, 1])
sys.stdout.close()
print(zip(*(zip(itertools.repeat(ls[0]), ls[1:]) for ls in data)))
ax.scatter(xs, ys, zs)
self.response.out.write(xml)
print(list(d.keys()))
formset.save()
neuron.draw()
new_im_vec = im.swapaxes(0, 2).swapaxes(1, 2).flatten()
self.textEdit.setPlainText(mytext)
image = Image.open(io.BytesIO(bytes))
df.rdd.map(lambda r: r.zip_code).collect()
server.quit()
time.sleep(1)
tf.div(x, y)
print([data[id == i].max() for i, _ in groupby(id)])
fh.close()
sys.path.append(path)
df.iloc[:, 1:]
f.write(line)
a.sort(key=len)
soup = BeautifulSoup(data)
time = datetime.strptime(time, DATETIME_FORMAT)
self.ax.figure.canvas.draw()
f.close()
window.add(vbox)
s = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_IP)
plt.pause(0.001)
dict2 = {key: value for key, value in list(dict1.items()) if key in required_fields}
func(*args, **kwargs)
df.comments.dropna()
img = f.read()
groups.sortlevel([0, 2], sort_remaining=False)
pool = Pool(processes=2)
warnings.resetwarnings()
imshow(skeleton, cmap=cm.Greys_r)
q = Post.query.options(db.joinedload(Post.tags)).all()
yacc.errok()
float(sum(lst[len(lst) / 2 - 1:len(lst) / 2 + 1])) / 2.0
s[s.index.dayofweek < 5]
df.applymap(lambda x: (0, 0) if x is np.nan else x)
self.mthread.start()
print(zip(*lists))
browser.get(url)
print(soup.html.string)
cursor = conn.cursor()
timestamp = (aware - datetime(1970, 1, 1, tzinfo=pytz.utc)).total_seconds()
plt.tight_layout()
time.sleep(1)
eyear1.grid(row=1, column=1)
layout.removeWidget(self.widget_name)
mc.__dict__
draw = ImageDraw.Draw(im)
ax.patch.set_alpha(0.5)
self.__getattribute__(name)
df
df2
plt.figure()
print(list(words))
[1][2][0]
plt.show()
a = numpy.array(a)
time_t = time.mktime(my_date.timetuple())
pylab.show()
bin(int(my_hexdata, scale))[2:].zfill(num_of_bits)
print(repr(data))
s = chr(i)
plt.ylim((-5, 5))
random_day = date.fromordinal(random.randint(start_date, end_date))
func(*args, **kwargs)
df.tail(1).T.assign(passes=lambda x: x.iloc[:, (0)] > 1)
f()
locale.setlocale(locale.LC_ALL, lang)
(counts == 1).all(axis=1)
fig.autofmt_xdate()
df = pd.DataFrame.from_dict(data)
f()
plt.show()
ax.set_ylim(0, m.shape[0])
a.shape
session.add(inst)
Representative.objects.create(**dict(zip(fields, row)))
turtle.forward(100)
a.tolist()
self.sprockets.add(spr)
print(ord(s[0]))
data.get(num) or data[min(list(data.keys()), key=lambda k: abs(k - num))]
model.fit(X, y)
table.cols.key.createIndex()
p.terminate()
print(char, char.isalpha())
printRecurrence()
ax.axis((x1, x2, y1 - 1, y2 + 1))
square(double(Maybe(5)))
driver = webdriver.Firefox(firefox_binary=binary)
ax.yaxis.set_major_formatter(formatter)
dict(enumerate(grouper(numbers), 1))
x = [[] for i in range(4)]
f = open(fd, closefd=True)
bar.name
[id(v) for v in list(d.values())]
problems
[1][1][2]
[0][1][1]
mydict[index] += 1
moobar()
print(json.dumps(data, indent=4))
df[g.cumcount() == n - 1]
dict((k, dict(v)) for k, v in list(r.items()))
plt.show()
[word for words in lst for word in words.split()]
ax.set_rlim([0, 5])
session.add(feed)
User.name.property.columns[0].type.length
r = requests.get(url, params=payload_str)
i += 1
list(filter(my_filter, my_iterable))
image.save(savepath)
print(pd.concat([df, pd.DataFrame(D, index=df.index)], axis=1))
np.random.rand(5) < 0.8
a.tolist()
hash = hashlittle(hashstr, 0)
chain.apply_async()
fd.close()
print(f.getvalue())
t.start()
ent5.grid(row=4, column=1)
data = {}
1.0 - scipy.stats.hypergeom.pmf(0, N, M, Q)
print(r.json())
[(i, mylist.count(i)) for i in set(mylist)]
__init__.py
print(func())
lst[:] = (v for v in lst if pred(v))
time.sleep(0.5)
x = list(itertools.islice(list(d.items()), 0, 4))
proc.stdout.close()
unittest.main()
image[(mask[:] == 0), ...] = chex[(mask[:] == 0), ...]
wr.writerow(list1)
[subword for word in list for subword in word.split()]
self.thisptr.myBMethod(dereference(a.thisptr), getAMethod())
data_line = (data_line[i] for i in good_cols)
m.group(1)
n = np.clip(n, minN, maxN)
ax.set_xticklabels(column_labels, minor=False)
gp1 = [2, 6, 9]
spherical_dist(locations_1[0], locations_2[0])
raise NotImplementedError
f2.write(lines[i + 1])
plt.scatter(_x, _y, marker=_s, c=c)
L[1][:]
inset.xaxis.set_tick_params(labelsize=INSET_TICK_FONTSIZE)
tuple(x + y for x, y in zip(xs, ys))
(value[i:i + n] for i in range(0, len(value), n))
[i for v, i in sorted((v, i) for i, v in enumerate(x))]
ws = base.add_sheet(k.upper())
mycanvas.pack(fill=BOTH, expand=YES)
mylist.remove(min(mylist))
img.size
np.broadcast(x, y, z).shape
cols_to_use = df2.columns - df.columns
find_majority([1, 1, -1, -1, 0])
[ord(uc) for uc in udata]
plt.legend(handles, labels)
twitterDataFile.close()
self.panel.SetSizer(sizer)
np.concatenate([a[:k] for k in x])
time_list[np.arange(5, 7)]
lst.append(4)
image_data_blue = image_data[:, :, (2)]
b = a.copy()
print(line)
pprint(a)
get_proc_name()
l = list(map(lambda x: f(indices=x), itertools.product(x, y, z)))
print(checktype(i))
(x for x in full_list if x not in s)
sorted(l, key=lambda x_y: (-x_y[1], x_y[0]))
ax.set_ylim(0, 5)
answer[pk].append({sk: L[i][1]})
row = dict(zip(list(row.keys()), row))
[2, 0, 1, 0, 1, 0]
index_list.append(last_index)
csv_file.writerows(mylist)
dec_num = int(oct_string, 8)
self._reverse_mocks()
self.Bind(wx.EVT_RIGHT_UP, self.OnExit)
module_name.__file__
np.array(avgDists).argsort()[::-1][:n]
sys.stdout.write(line)
fig = plt.figure()
name_in_module()
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
jmag = np.array(jmah)
merged_dict = {k: [d.get(k, np.nan) for d in dicts] for k in keys}
Gtk.main()
self.ax.clear()
hxs = HtmlXPathSelector(response)
{k: (D[k] - v) for v, k in enumerate(albums_today)}
itertools.combinations()
max((len(v), v, k) for k, v in flows.items())[1:]
tz.fromutc(utc_time)
transaction.commit()
result.append(message)
fig, ax = plt.subplots()
print(hex_to_datetime(s), dt)
array[i:i + size] + array[:max(0, i + size - len(array))]
fcntl.flock(g, fcntl.LOCK_EX)
h.encode()
t = threading.Thread(target=get_url, args=(q, u))
self.send_response(200)
data = line.split()
print(2 * math.asin(1))
letter_count = dict.fromkeys(string.ascii_lowercase, 0)
pak.show2()
value = a_lower[key.lower()]
digits = int(math.log10(n)) + 1
signal.signal(signal.SIGINT, signal.SIG_DFL)
os.chdir(directory)
np.repeat(arr, rep.flat).reshape(2, -1)
data = {foo: foo_value, bar: bar_value}
[alist[i:i + sublen] for i in range(0, len(alist), sublen)]
self.name = name
print(frame.f_lineno)
dtt = d.timetuple()
sys.exit(1)
point.x, point.y
obj = MyModel.objects.create(val=1)
print(url)
print(m[0])
self.ShowModal()
list(data.keys())
process_url(a)
jsonFile.write(json.dumps(data))
board2 = [[1, 0, 1], [1, 0, 1], [0, 1, 0]]
self.assertEqual(yargs[0], yexpected)
my_list = list(my_set)
[8, 8, 8, 8, 8, 8, 8, 8, 8, 8]
self.main_app(environ, start_response)
pl.plot(X, Sine)
reactor.run()
ax1.plot(s1.index, s1)
p.communicate()
print(sys.builtin_module_names)
cur.execute(query, (limit1, limit2))
collatz(10)
data = sys.stdin.read()
self.assertEqual(xargs[0], xexpected)
plot.colorbar(im, cax=ax2)
ax.set_ylim(-0.5, 1.5)
driver.set_window_size(1120, 550)
app.logger.addHandler(file_handler)
jsonify(d)
self.redis = Redis()
L.sort()
isinstance({}, dict)
sin(x) * cos(x)
s.rstrip(punctuation)
plt.show()
sys.stdout.flush()
{{request.user.pretty_username}}
plt.show()
sp.sourceslist.save()
pd.DataFrame(X, columns=v.get_feature_names(), index=grouped.index)
fig = plt.figure()
os.system(mycommand)
worker.start()
cmp(x, y)
os.chmod(path, 511)
a[:] = [(x, mapping[x]) for x in b]
soup = BeautifulSoup(html)
map(list, a)
signal.signal(signal.SIGINT, signal_handler)
sys.exit(12)
min(filtered, key=lambda x: x.last - x.first)
[i for i, x in enumerate(a) if x in list_duplicates(a)]
tk.Tk.__init__(self, *args, **kwargs)
zip(MONTHS, MONTHS)
x = X.objects.get(id=x.id)
bisect.bisect_left(list_, item)
np.log(sample_df).diff()
some_list == sorted(some_list)
QApp().run()
e1.pack()
res = func(*args, **kwargs)
n = clamp(n, 7, 42)
ostream = StringIO(istream.read())
print(random.choice(data))
os.chdir(random.choice([d for d in os.listdir(os.curdir) if os.path.isdir(d)]))
json.dumps(doc, sort_keys=True, indent=4, default=json_util.default)
subprocess.Popen(smart_cmd)
plt.xlim((-5, 5))
os.kill(2405, 0)
some_object = klass()
b[indices] = a[indices]
end = datetime.time(1, 0, 0)
layout.addWidget(self.button)
print(map(lambda x, y: abs(x - y), l[1:] + l[:1], l))
plt.figure(figsize=(12, 8))
self.after(1000, self.countdown)
reshaped2.show()
my_list.sort()
app = Flask(__name__)
data = json.load(json_data)
screen.blit(temp_surf, (0, 0))
df.groupby(np.arange(len(df)) // 10)
self.app(environ, custom_start_response)
print(list(get_week(datetime.datetime.now().date())))
plt.setp(ax.get_xticklabels(), visible=False)
__init__.py
last_inner_append(x[-1], y)
self.driver.quit()
driver.get(url)
ax.xaxis.grid(True)
signal.signal(signal.SIGALRM, signal_handler)
L = [(x + [0]) for x in L]
colorbar()
time.sleep(0.1)
[2.0, 2.0017]
app.debug = True
client.put_file(dropbox_path, f)
sorted([(i, j) for j in range(10) for i in range(10) if j > i])
df.xs(1)
print(f.bar)
cursor = conn.cursor()
board1 = [[1, 0, 1], [1, 0, 1], [0, 0, 1]]
temp.append(data.tolist())
app.MainLoop()
func_to_call()
pylab.show()
list(filter(bool, l))
dt.microsecond
print(json.dumps(t, cls=MyEncoder))
self._numberButtons[i].clicked.connect(partial(self._number, i))
df2.apply(lambda x: df2.loc[~x.isin(df1[x.name]), x.name])
df = df.sort_index(axis=1)
False
logger.setLevel(logging.DEBUG)
plt.ylim(0, 8)
BabyDataSet = zip(names, births)
btn5.grid(row=4, column=0)
[r for r in x if not any(s in r for s in y)]
client.set_options(wsse=security)
user.get_all_permissions()
counterpart.sendall(data)
print(Photo.objects.filter(tags=t1).filter(tags=t2).query)
reactor.run()
plt.show()
(x - 1) // 10 if x > 0 else 0
event.wait()
A - A.multiply(BisBigger) + B.multiply(BisBigger)
id = Column(Integer, primary_key=True)
browser.quit()
{k1: d2[d1[k1]] for k1 in d1 if d1[k1] in d2}
db.session.commit()
[arr[max(0, idx - 1):idx + 2] for idx in range(0, len(arr), 2)]
np.where(x & x - 1 == 0)
local_dt.replace(microsecond=utc_dt.microsecond)
newgrid.append([x[i] for x in grid])
ax.set_yticks([])
enemy1 -= punch
func(*args, **kwargs)
date = datetuil.parser.parse(string, tzinfos=tzd).astimezone(pytz.utc)
sess.run([init_op])
engine.execute(createview)
ax0b.set_xticklabels([])
seen.add(item.lower())
float_array.fromstring(input_file.read())
app.MainLoop()
self.grid_rowconfigure(1, weight=1)
pubkey = rsa.PublicKey(n, e)
timer.timeout.connect(self.move_towards)
fig = plt.figure()
print(response.content)
df.columns = list(resoverall.keys())
reactor.run()
print(df2[[15, 16, 17, 18, 19, 8]])
texts[0].set_fontsize(4)
fig = plt.figure(figsize=(xinch, yinch))
ws.cell(row=i, column=j)
sys.exit(0)
ax.set_zlim(0, 5)
main()
[0, 0, 0, 0, 1, 1, 1]
p.wait()
client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
df[col] = df[col].sum()
ng.run()
lambda : [func() for _ in range(n)]
pattern = re.compile(pattern_string)
fout.close()
best_authors = Author.objects.filter(books__bestseller=True).distinct()
df[~df.From.str.contains(ignorere)]
sstd.on_changed(update)
__builtins__.set
plt.legend()
e.shape
random.choice(my_list)()
alist.append(string[i:j + 1])
all((x > 0) == (y > 0) for x, y in zip(l1, l2))
print(response.text)
log2int_faster = int(x).bit_length() - 1
ax = fig.add_subplot(111)
ax.xaxis.set_minor_locator(MultipleLocator(5))
dict.__setitem__(self, x, value)
ax.figure.show()
Tkinter.mainloop()
dir = os.path.dirname(__file__)
s.between(0, 1).any()
self.data[attr]
inList = any(a in sublist for sublist in mylist)
np.random.shuffle(arr[:, (i)])
X, Y = np.meshgrid(X, Y)
print(len(s), len(data), repr(data))
print(img.shape)
r.read()
pylab.ylim([0, 1000])
plt.plot(c[0], c[1], c[2])
list(intermix([1, 0, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2]))
proc.wait()
np.fill_diagonal(out, 1)
redirect(login_url)
frame = cv.QueryFrame(self.capture)
print(s.read())
msg = MIMEMultipart()
D = np.r_[np.c_[A, B], np.c_[B.T, C]]
print(list(itertools.islice(arith(10, 2), 100)))
bool(_digits.search(d))
L[item][0]
manual_wcwidth(data)
a = np.append(a, i)
response = json.loads(jsonResponse)
final_l.append((p[0], visit(p)))
tmp.append([X[i, j] for i in X])
sys.exit(app.exec_())
BabyDataSet = list(zip(names, births))
d = int(s[0:7], 2) + int(s[8]) / 2.0
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
foo()
pool = multiprocessing.Pool()
print(df.iloc[:, (0)].tolist())
ax.set_zlim(-100, 100)
ax = plt.gca()
a[i, j]
self.clip.disconnect(self.signal_id)
server.ehlo()
deleterow[1]
np.cov(data, rowvar=False)
axes.set_ylim([ymin, ymax])
Y[(1), :]
time.sleep(0.1)
do_stuff()
x = x[1:]
quit()
time.sleep(1)
cur.execute(sql, params)
plt.show()
fig, ax = plt.subplots()
sw.pack(fill=tk.BOTH, expand=1)
l.extend(t + t2)
print(token.access_token)
dict((k, bigdict[k]) for k in wanted_keys if k in bigdict)
NameRank.sort(key=lambda x: int(x.split()[1]))
set(x) == set(y)
print(save_data.get())
{{i}}, {{j}}
cls.__new__()
list(OrderedDict.fromkeys(t).keys())
a, b = b, a + b
plt.show()
self.setCentralWidget(self.window)
random.choice(list(dictionary.values()))
lbl5.grid(row=4, column=0)
n * factorial(n - 1)
[_ for _ in itertools.compress(d, map(lambda x: x >= 4, a))]
df.stack().map(m).unstack()
d += timedelta(days=7)
conn.send(data)
a, b = 1, 1
c.mymethod2()
str(User.query.filter_by(role_id=user_role))
view.show()
ax.set_ylim(0, 10)
df.iloc[np.sort(np.concatenate([idx[~iszero], keep_these]))]
new_pressures.append(0)
x = ast.literal_eval(x)
ser.write(str(d))
application_path = os.path.dirname(os.path.abspath(__file__))
table[1][2]
plt.xticks(list(range(len(x))), x)
func()
pairs = dict(zip(second_split[::2], second_split[1::2]))
(myarray[i] for i in myindex)
collections.deque(itertools.islice(iterator, n), maxlen=0)
fig = plt.figure()
driver.set_window_size(1024, 768)
A.shape
[o.specific_attr for o in objects]
x = list(someiter)
[(a if a else b) for a in sequence]
df.reindex(ind & ind2)
test[2] = new_value
o4.method()
cardValue = int(card[0])
X.__setitem__(0, 2)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
plt.show()
dict((k, int(v)) for k, v in d.items())
names = self.__class__.__dict__
Ainv = np.zeros_like(A)
func(*args, **kwargs)
df2.apply(lambda x: df2.loc[~x.isin(df1.values.ravel()), x.name])
df
fig.set_size_inches(11.7, 8.27)
math.hypot(y[0] - x[0], y[1] - x[1])
next(decfa)
decimal.Decimal(1) / decimal.Decimal(7)
arr = (ctypes.c_int * len(pyarr))(*pyarr)
os.kill(self.pid, signal.SIGKILL)
superstrings = [stset_string[s] for s in superstsets]
dfs = [df0, df1, df2, dfN]
Response(token, status=200)
plot_df.plot()
ftp.quit()
print([(k, v) for k, v in list(dupl.items()) if len(v) > 1])
json.dump(row, outfile)
f.seek(0)
j2 = sorted(i for i in j if i >= 5)
suffix_array.sort(key=lambda a: buffer(content, a))
sess = tf.InteractiveSession()
Py_Finalize()
sys.stdout.flush()
ao[:, 1:] += ai[:, :-1]
self.predictions_.append(classifier.predict_proba(X))
driver.switch_to.window(driver.window_handles[1])
print(list_of_dict)
result = [tuple([ai, bi] + ci) for ai, bi, ci in zip(a, b, c)]
main()
subprocess.call(command, shell=True)
ancestors_descendents.add(descendent)
par2.xaxis.set_ticklabels([i[0] for i in data])
proc.wait()
index_list = [int(i) for i in index_list]
sys.exit(app.exec_())
ax.clear()
print([list(g) for g in group([], lambda x: x % 5 == 0)])
mark_safe(simplejson.dumps(data))
vars(ns)
loader.load_module()
map(lambda x, y: x + y, itertools.repeat(x), y)
print([w for w in txt.split() if not w in s])
test.py
list(d.items())
literal_eval(s)
random.shuffle(items)
trace.main()
pylab.show()
xl.Workbooks.Close
df = df.T.stack().reset_index()
pd.concat([d1, df], axis=1)
attr = (o.attr for o in objsm)
Py_INCREF(interned)
df.dtypes
IOLoop.instance().start()
fig = plt.figure(figsize=(4, 10))
print(sys.argv)
time = time - datetime.timedelta(microseconds=time.microseconds)
[indicies[elements == i] for i in range(1, N)]
print(re.findall(p, test_str))
Sample.objects.filter(date__range=[startdate, enddate])
L[i] = sorted(L[i], key=operator.itemgetter(1, 2))
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
(sum(a) ** 2 - sum([(x ** 2) for x in a])) / 2
examplemod.do_stuff()
os.unlink(filename)
d = collections.defaultdict(dict)
session_list.delete()
[right for left, right in pairwise(a) if right[1] > left[1]]
resultwords = [word for word in querywords if word.lower() not in stopwords]
fig = plt.figure()
plt.show()
parts2 = urlparse.urlparse(fake_url)
db.session.add(c)
do_stuff()
line.set_ydata(r[:, (1)])
form = ExcludedDateForm(user=request.user)
globals()[funcname](**argsdict)
driver = webdriver.Firefox(p)
f.close()
my_list
(i for i, j in zip(seq, shift) if (i, j) != (x, x))
app.exec_()
User = settings.AUTH_USER_MODEL
a, b = b, a + b
sum(value for _, value in list(a.items()) if value > 0)
foo()
data = json.dumps(myobject.__dict__)
print(powercheck([1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1]))
ax.set_position(pos2)
id(lines[0]), id(ax.lines[0])
draw.ellipse((x1, y1, x2, y2), fill=background_color)
hasattr(obj, method_name) and callable(getattr(obj, method_name))
foo(2)
cursor = collection.find(spec={}, snapshot=True)
sorted(d, key=sorting)
df[new_columns]
data = myfile.read()
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj))
d.setdefault(t[0], {})[t[1]] = t[2]
handle.close()
writer = csv.writer(f)
out = np.asarray(np.bmat([[A, Z], [Z, B]]))
x[0] = x[0] + 1
run()
adder(10)
plt.show()
curses.noecho()
print(soup.prettify())
np.array(result)[::-1]
client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
sys.maxunicode
master.grid_rowconfigure(0, weight=0)
b.foo()
include(GenerateExportHeader)
db.session.commit()
[(arg + 1) for arg in args]
d = [list(map(int, x)) for x in DATA]
hi()
mylist.sort(key=lambda x: x[1])
TaskBase.__call__(self, *args, **kwargs)
self.assertTrue(mock.called)
t.start()
foo.name
func(*args, **kwargs)
admin.site.register(User, CustomUserAdmin)
parser = argparse.ArgumentParser()
[lst[i::n] for i in range(n)]
admin.site.register(CherryTomato, TomatoAdmin)
self.session.execute(count_query).scalar()
duplicates = [x for x in mylist if mylist.count(x) > 1]
user2 = forms.ChoiceField(choices=choices)
ActionChains(driver).move_to_element(element).perform()
json.dumps(convert(d))
sys.exit()
writer.writerow(row)
message.save()
self.grid_rowconfigure(0, weight=1)
i, j = np.indices(a.shape)
time.sleep(0.5)
fig = plt.figure()
{k: add_element(v) for k, v in list(dicty.items())}
json.loads(x)
self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file)
time.sleep(1)
globals()
func.__code__.co_consts
rgbs = [((x & 16711680) >> 16, (x & 65280) >> 8, x & 255) for x in values]
float(element)
x.isoformat()
y.compute()
tt = np.linspace(0, 20, 201)
sys.exit(1)
fout.close()
foo = set(range(0, 4))
__init__.py
product = functools.reduce(operator.mul, iterable, 1)
belly_name = models.CharField(max_length=50)
[x[0] for x in G]
list(s) == sorted(s)
sum(ord(c) << i * 8 for i, c in enumerate(mystr))
avg = float(sum(mylist)) / len(mylist)
list(roundrobin(l1, l2))
a, b = b, a + b
res = urllib.request.urlopen(req)
ax.add_line(line_1)
spstereo.scatter(x, y)
n11.add(n111)
datetime.timedelta(seconds=seconds)
str(a)
x = x + a + b + c
im.show()
cov = np.array([[u20, u11], [u11, u02]])
s1.reset_index(inplace=True, drop=True)
self.canvas.update_idletasks()
os.remove(filename)
print(me.toJSON())
loggerCent.setLevel(logging.DEBUG)
key_to_delete = max(d, key=lambda k: d[k])
new_list = [(a + b) for a, b in zip(a_list, b_list)]
type([])
all(c in gram.lower() for c in string.ascii_lowercase)
module.workflow_set.filter(trigger_roles__in=[self.role.id], allowed=True)
form.rate.queryset = Rate.objects.filter(company_id=the_company.id)
pool = multiprocessing.Pool(4)
sys.exit(1)
cls.recalc_mro()
os.kill(os.getppid(), 0)
desired_cols = (tuple(row[col] for col in columns) for row in reader)
(data.T / vector).T
{w: counts[w] for w in word_list}
new = map(int, old)
d2 = {k: (v * 0.5) for k, v in list(d.items())}
(A.stack(0) << np.arange(10)).sum(1).unstack()
plt.show()
print({k: (x.get(k, 0) + y.get(k, 0)) for k in set(x) | set(y)})
ax.figure.canvas.draw()
key[:2].upper() + key[2:]
deletelist[index]
cur.execute(query, (b,))
self.button.pack(padx=10, pady=10)
m = re.search(pat, t)
persons = Person.objects.all().order_by(birthday, anniversary)
r.status_code
a.index(4)
dff[[c for c in dff if dff[c].isnull().sum() < 2]]
dropped_copies = [(lambda j: (x[j] for x in copies[j]))(i) for i in range(2)]
print([value for value in x if not math.isnan(value)])
otest.sort(key=lambda x: int(x))
df.tail(5)
print(text[i])
s == len(s) * s[0]
sys.getsizeof(Bar.__dict__)
plt.show()
plt.plot(data.index, data.amount)
[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
fig.subplots_adjust(left=0.25, bottom=0.25)
json.loads(obj)
query = users.select().order_by(-users.c.id.desc()).limit(5)
bucket.configure_lifecycle(lifecycle_config)
arrback = numpy.array(json.loads(s))
x.digits(10, 0, -1, 1)
np.array_equal(a, b)
self.temperatureRaisedSignal.emit()
raise web.notfound()
df.head()
self._task.cancel()
a[:, (idx)]
logger.addHandler(file_handler)
out = [x for x in a if x in b and x in c]
newdf = df.join(newcols)
plt.xlim([0, len(data)])
dropped_copies = [make_gen(i) for i in range(2)]
main()
f(**{str(k): v for k, v in list(kwargs.items())})
ax.plot_surface(grid_x, grid_y, grid_z, cmap=plt.cm.Spectral)
reactor.run()
print(files[0])
ch = logging.StreamHandler()
print(json.dumps(output, indent=4))
main()
req.read()
df.loc[:, (msk)]
[y for x in data for y in x]
logger.setFormatter(logFormatter)
plt.subplot(1, 2, 2)
np.ma.array([[1, 0, 0, 1], [1, 0, 1, 0]], mask=[[0, 0, 0, 1], [1, 1, 0, 1]])
RGB_tuples = map(lambda x: colorsys.hsv_to_rgb(*x), HSV_tuples)
enumerate(list(range(2000, 2005)), 1)
json_dict = json.dumps(values)
self.transport.write(data)
s.update(list(fus_s.keys()))
Entry(root, textvariable=mystring).grid(row=0, column=1, sticky=E)
browser = webdriver.Firefox()
print(cmp(memoryview(test1), memoryview(test2)))
signal.signal(signal.SIGQUIT, dumpstacks)
print([(100 * (b - a) / a) for a, b in zip(prices[::1], prices[1::1])])
output = urllib.request.urlopen(url).read()
__metaclass__ = Proxier
[mm_fib(i) for i in range(20)]
fig.canvas.draw_idle()
anumlist = [int(x) for x in alist if x.isdigit()]
data.append([w.getparams(), w.readframes(w.getnframes())])
app = flask.Flask(__name__)
request.user.get_myuser().pretty_username()
[i for n, i in enumerate(d) if i not in d[n + 1:]]
new_dict = {k: v for k, v in my_dict.items() if v >= threshold_value}
ax.scatter(a.real, a.imag)
self.previewImage.show()
print(arr_list)
df = pd.DataFrame()
array([1, 2, 4, 5, 6, 7, 8])
regr.fit(chntrain, austrain)
print(response.read())
tk.Tk.__init__(self)
p.start()
container.grid_columnconfigure(0, weight=1)
ax.set_xticks(np.arange(len(df.columns)) + 0.5)
print(df)
fig, axes = plt.subplots(nrows=2, sharex=True)
df.fillna(1, inplace=1)
list(product())
imshow(gray2, cmap=cm.gray, alpha=0.5)
imshow(gray2b, cmap=cm.gray, alpha=0.5)
db.init_app(app)
app = Bottle()
string1.join(string2)
fileObj.close()
lists = [[] for i in range(num_lists)]
train_perplexity = math.pow(2, train_loss)
loader.construct_yaml_str(node)
decorator
foo(params[0], params[1])
fileinput.close()
sys.stdin.close()
background_label.place(x=0, y=0, relwidth=1, relheight=1)
layout.addWidget(self.label)
boundaries = [1, 6, 10, 21, 40, 51]
[0, 1, 0, 2, 1, 0]
print((i, os.path.join(dir, file)))
python - -version
plt.figure()
sys.exit(2)
deletesys.modules[name]
a = [a]
worksheetObject.portrait = False
d = dict(t for t in zip(m[::2], m[1::2]))
{c.name}
app.mainloop()
meets = Counter(chain.from_iterable(combinations(line, 2) for line in lines))
plt.plot(signal)
s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
plt.scatter(R, P, s=150, color=c, zorder=2)
l2.append([x[1] for x in zip(pattern, facs) if not x[0]])
print(key[index].reshape(a.shape))
args = parser.parse_args()
myData.dtype.names
socket.close()
list_regexs = [re.compile(x) for x in list_patterns]
MyModel.objects.all().delete()
regressions = regressions.reshape(A.shape)
data = [[([0] * h) for _ in range(w)] for _ in range(d)]
traceback.print_exc()
min(timeit.repeat(lambda : {k: v for d in (x, y) for k, v in list(d.items())}))
mainloop()
deleteself.__dict__[key]
max(max(l_one), max(l_two))
any(child.contains(other_node) for child in self.children)
regressor.fit(X, y)
print(x)
querset = MyModel.objects.filter(id__in=custom_list)
plt.show()
__init__.py
do_your_thing_with(item)
self.close()
thread.start()
im.show()
map(join, zip(s, drop(s, 1)))
newlist += mylist[i:i + 22]
[i for i in userInput if i in wordsTask]
f.close()
print(d[1] + f.split(d)[1])
instance.__init__(cls, *args, **kw)
pd.concat([df, df.shift(-1)], axis=1, keys=[0, 1]).dropna()
subs = [l[i:i + n] for i in range(len(l)) if len(l[i:i + n]) == n]
admin.site.register(Example, MyAdmin)
list(itertools.product(l1, l2))
x[np.argmin(abs(f2 - f1))]
json_data = json.load(StringIO(json_str))
a = map(float_or_string, mylist)
data = dict((key, request.form.getlist(key)) for key in list(request.form.keys()))
f.close()
fig.show()
((1 + sqrt(5)) ** n - (1 - sqrt(5)) ** n) / (2 ** n * sqrt(5))
[(next(it), next(it1)) for _ in range(10)]
os.makedirs(expanded)
print(key, value)
str(d)
browser.get(googleURL)
self.app.run()
out.close()
help(parrot)
sys.stderr.close()
ax.axis([-1, 10, -1, 10])
ax.transData.transform([(0, 1), (1, 0)]) - ax.transData.transform((0, 0))
zf.close()
setup.py
num2words(10000000000000000000000000)
time.sleep(10)
root.mainloop()
self.__dict__.update(dictionary)
print(Board([1, 2]))
tf.initialize_variables(lstm_variables)
fig, ax = plt.subplots()
pyglet.app.run()
cache.update()
print(instance.Variable)
root = tree.getroot()
print(root.winfo_height())
tree = ET.fromstring(xmlstr)
m / m.norm(1, axis=1).reshape((m.shape[0], 1))
l.extend(list(range(1, n + 1)))
reactor.run()
print(list(roundrobin(*l)))
smtp.close()
timestamp.sort(reverse=True)
print(find_eulerian_tour(graph))
df1 = df1.fillna(0)
time.sleep(1)
[list(g) for k, g in groupby(inp, key=lambda i, j=count(): i - next(j))]
plt.show()
reactor.run()
myTreeView.setEditTriggers(QAbstractItemView.NoEditTriggers)
plt.show()
base.rhyme()
do_something_special()
array([1, 1])
workbook.close()
webdriver.ActionChains(driver).move_to_element(el).click(el).perform()
outputfile.close()
[k for k, v in list(mydict.items()) if c[v] > 1]
layout.addWidget(self.connectButton)
str1_list.sort()
selenium_logger.setLevel(logging.WARNING)
plt.hold(True)
a[ainb]
df.isnull().sum().sum()
print(time.time() - start)
offset += datetime.timedelta(days=1)
pygame.draw.circle(screen, (0, 0, 0), (250, 250), 125)
i / int(pow(10, l - m)) % int(pow(10, m - n + 1))
rs = urllib.request.urlopen(req.to_url())
[x[start:end] for start, end in slices if end - start > 1]
td.findAll(text=True)
r = requests.delete(URL_delete, data=json.dumps(mydata))
print(bool([]))
list(intermix([1, 0, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 2]))
sys.stdin.close()
t[0][0]
seventh_value = next(f(i) for i in range(1, 10) if i == 7)
any(i in array2 for i in array1)
fig, ax = plt.subplots()
traceback.print_exc(file=sys.stdout)
self.openBtn.clicked.connect(self.openClicked)
[x[1] for x in Counter(n).most_common() if x[0] > 1]
y = arr[29].sum()
df[1].plot(ax=axes[0, 1])
listbox.config(width=0)
TestApp().run()
y[(1), :, (2), :]
simplejson.load(f)
sess.run(tf.initialize_all_variables())
list_of_pairs = [(p1, p2) for p1 in people for p2 in people]
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(jar))
pylab.show()
axborder.set_xlim(0, binimg.shape[1] - 1)
any(np.array_equal(b, x) for x in my_list)
ax.set_ylim(-20, 100)
admin.site.register(CMSMediaDocument)
cj = cookielib.LWPCookieJar()
sys.exit(0)
pygame.image.save(Surface, filename)
__rmul__ = __mul__
plt.pause(0.0001)
lst = [x for x, in mysql_rows]
do_something()
self.text.configure(yscrollcommand=self.vsb.set)
sm.OLS(df[ycol], df[xcols]).fit().predict()
response = urllib.request.urlopen(url).read()
time.sleep(0.1)
OrderedDict.__setitem__(self, key, value)
u.save()
any(e[1] == search for e in data)
F(n - 1) + F(n - 2)
[day for day in range(len(day_list)) if day_list[day] == inp][0]
Py_DECREF(arr)
logging.StreamHandler.__init__(self)
unique[maxsort], counts[maxsort]
df_out = pd.DataFrame(out, index=df_index)
list(itertools.dropwhile(lambda x: x == r[-1], reversed(r)))[::-1] + r[-1:]
somelist = [i for j, i in enumerate(somelist) if j not in remove_indices]
writer.close()
self.server.serve_forever()
fig.subplots_adjust(hspace=0.5, wspace=0.001)
plt.show()
cPickle.loads(_)
l.append((floar(row[0]), float(row[1])))
main()
sorted_list == list(range(sorted_list[0], sorted_list[-1] + 1))
y = [0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0]
dict(a)
app = Flask(__name__)
d = collections.defaultdict(int)
net.build()
first_line = f.readline()
plt.scatter(x, y)
nmf_model.fit(A)
plt.tight_layout()
browser.set_handle_robots(False)
libc.cprogram(wts, res, kks, pointer(n), ex)
print([(a, b, z[a]) for a, b in l])
server.listen(5)
res.append(copy.deepcopy(l))
gb.apply(lambda x: dict(zip(*x))).unstack()
[97, 98, 114, 97, 107, 97]
pylab.show()
tf = tempfile.NamedTemporaryFile(delete=False)
f.close()
lst.append(lambda x, z=i: f(x, z))
plt.show()
print(list(chain(*listOfTuples)))
print((x, y))
[ord(b) for b in bytestr]
s.set_xticklabels(group_labels)
{i: str(i) for i in range(5)}
unittest.main()
self.emitter.start()
followers_df.index = list(range(20))
blocklist.append(line)
plt.scatter(t, x, c=y)
upper = tuple(x + 1 for x in upper)
Record.objects.select_related().filter(id=variable_that_stores_id)
root.mainloop()
var1, var2 = [int(x) for x in [var1, var2]]
writer = csv.writer(out_file)
layout.addWidget(self.label)
reversed_arr = arr[::-1]
pizza = models.ForeignKey(Customer)
simplejson.dumps(object())
QObject.__init__(self)
hist = np.histogram(img.flatten(), 256, [0, 256])[0]
self.left.extend(self.right[0:x])
print(list(d))
count.most_common(2)
p1.join()
process = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True)
sorted(iter(x), key=lambda k: random.random())
glTranslatef(100, 100)
legobj.set_linewidth(2.0)
self.response.set_status(401)
items.append(self.listWidget.item(index))
plt.show()
threading.Thread.__init__(self)
response = requests.get(url, auth=(username, password), verify=False)
out4 = a[i[0] + 1:i[2]]
signal.signal(signum, sighandler)
df[0][0]
PyMODINIT_FUNC
numpy.where(a != 0, 1, 0).sum()
x.sort()
arr = numpy.array(((2, 2), (2, -2)))
f()
next(x for x in range(10) if x == 11)
print(repr(object))
sorted(list(mydict.items()), key=itemgetter(1, 0))
res.fillna(0)
np.diff(a)
output = defaultdict(lambda : defaultdict(int))
print(bar.__name__)
image.set_from_pixbuf(pixbuf)
self.img.set_from_file(fname)
app.setStyleSheet(stylesheet)
server.NOT_DONE_YET
b = [(sl + [0] * (len(max(a, key=len)) - len(sl))) for sl in a]
[t[i:i + n] for i in range(0, len(t), n)]
json.dump(data, f)
unittest.main(verbosity=2)
df.C.plot(ax=plt.gca())
db = SQLAlchemy(app)
print(line)
submodule2.py
np.linspace(0, 1, 10, endpoint=False)
size = fields.IntegerRangeField(list(range(1, 50)))
map(ord, os.urandom(10))
logger = logging.getLogger()
do_something_with(name)
x.sort()
urllib.request.install_opener(opener)
pd.read_csv(io.StringIO(t), header=False)
print(list(iterable))
widget.lift()
user.save()
((x - a) / (b - a)).clip(0, 1)
self.fitness = 2 * self.i
plt.gcf().add_subplot(422)
ytest = regr.predict(Xtest)
self.render_to_response(self.get_context_data(form=form))
stdin.flush()
ax.bar(x, y, width=10)
form = ContactForm(request.POST)
myscript.py
popen = subprocess.Popen(args, stdout=subprocess.PIPE)
tornado.ioloop.IOLoop.instance().start()
time.tzset()
float(output_string)
list_2 = [item for item in list_2 if f(item)]
x = pickle.load(f)
x = foo[index]
a = np.arange(729).reshape((9, 9, 9))
province = models.ForeignKey(Province)
browserify()
A[i, j] += C[j, k]
hash.update(line)
dists = np.vstack(([x_dists.T], [y_dists.T])).T
par1.set_ylim(0, 4)
sorted(l1)
[day for day in range(len(day_list)) if day_list[day] == inp][0]
stats.weibull_min.fit(data, floc=0)
sorted((k, ordered(v)) for k, v in list(obj.items()))
float(value)
self.matplotlibWidget.canvas.draw()
os._exit(1)
cv2.destroyAllWindows()
jsonString = json.dumps(data)
sys.exit(1)
msg.attach(part1)
f.tell() == os.fstat(f.fileno()).st_size
[item[0] for item in tl]
p.start()
app.run()
data = np.random.uniform(-1, 1, 44100)
plt.show()
print(value[:min(len(value), size)].ljust(size))
list(remove_reversed_duplicates(a))
self.ui_web_view.installEventFilter(self)
p.join()
time.sleep(0.1)
clf.fit(X, y)
a.setLevel(logging.DEBUG)
server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
deletearray[0]
pd.get_dummies(df.apply(tuple, 1)).groupby(level=0).sum()
learner = milk.defaultclassifier()
app.run()
gtk.main_quit()
self.finish()
main()
{{mydocimage.property.date_added}}
plt.plot(x2, my_curve2)
foo.bar()
a()
all(x > y for x, y in zip(L, L[1:]))
QtGui.QWidget.__init__(self, parent)
percentages.append(temp)
pyplot.show()
l.append(i)
self.mainframe.columnconfigure(0, weight=1)
QtGui.QDialog.__init__(self)
fig.subplots_adjust(wspace=0)
self.socket.bind((server_ip, server_port))
self.common1()
results[i].append(benchmark(i))
h.append({k: d.get(k) for k in get_keys})
sorter[np.searchsorted(b, a, sorter=sorter)]
grid_1.AddMany(wx.StaticText(self.panel, label=str(i)) for i in range(24))
x[row_idx.reshape(-1, 1), col_idx]
sys.stdout.flush()
f(Foo(1))
creatures = defaultdict(lambda : defaultdict(lambda : defaultdict(int)))
print(next(zip(*s)))
print(row.column_name)
l.append([x, y])
a = A()
df.loc[all_days]
dates.sort()
self.filelist.append(zinfo)
np.equal(a, tgt).all(1).any()
length = sum(1 for x in clusterList)
ax.set_xticklabels(df.columns, rotation=90, size=15)
d = tf.constant([[1.0, 1.0], [0.0, 1.0]])
self.rect.set_width(self.x1 - self.x0)
lines = [line for line in infile][:N]
bananaxxxxxxxxxgestrawberryxxxxxxxar
df.hist(layout=(1, 2))
df = pd.concat([df.ix[:, :5], x], axis=1)
rconsole.spawn_server()
pycurl_connect.setopt(pycurl.URL, your_url)
cv2.waitKey()
item.setCheckState(QtCore.Qt.Unchecked)
f.seek(0)
ax.set_axis_off()
print(df.loc[:, (mask)])
time.sleep(1)
scored.sort()
d = dict(urlparse.parse_qsl(qs))
print(word)
gtk.main()
sorted(set(chain.from_iterable(iter(content.values()))))
__str__ = lambda self: str(self._name)
s = ax.scatter(X, Y, c=C)
self.button.clicked.connect(self.createTab)
process.wait()
print((k, v))
np.where(x < 0, -x / x.min(axis=0), x / x.max(axis=0))
tuple([x for sublist in base_lists for x in sublist])
print(widget.GetName())
label.pack()
sum(range(a[0], a[-1] + 1)) - sum(a)
b = [ord(x) for x in s]
driver = webdriver.Chrome()
[group for group in groups if a.isdisjoint(group)]
print(json.dumps([1, a, b]))
a = csc_matrix([[1, 0, 0, 0], [0, 0, 10, 11], [0, 0, 0, 99]])
t = tuple(s)
os.system(cmd)
numpy.linalg.norm(a - b, ord=1)
process.kill()
os.makedirs(directory_name)
[idx for idx, el in enumerate(foo) if np.array_equal(el, arr)]
sys.exit(1)
ax = plt.gca()
dict(c)
p.stdin.flush()
main()
[False] * 20
app = QtGui.QApplication(sys.argv)
time.gmtime(0)
self.Bind(wx.EVT_PAINT, self.on_paint)
thread.start()
x.g(2)
wx.Frame.__init__(self, parent, title=title, size=(200, 100))
m.drawcoastlines()
i += 1
print(objectify.dump(root))
browser.back()
points = [(i // sy, i % sy) for i in random.sample(range(sx * sy), n)]
map(lambda x: 0.4 if 7 <= x <= 22 else 0.2, hourOfDay)
json.dumps(object())
zip(A, B + B)
ax.set_xticks(np.arange(25))
scene = QtGui.QGraphicsScene()
sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPCNT, max_fails)
[id(x) for x in list(dic.values())]
w.readline()
str2_list.sort()
n += 1
fig = plt.figure()
time.sleep(10)
print(a.get())
print(np.percentile(map(int, i), 95))
foo(a, b)
((i, o) for i in l)
p.plot()
result.append(item)
plt.draw()
f(2)
lists.append(pickle.load(infile))
a * b
plt.show()
reader = csv.reader(f)
etree.LXML_VERSION
item.lower()
print(doc.text_content())
pd.concat(dfs, ignore_index=True)
proc.terminate()
codeErr.close()
r = sum(compress(list_2, list_1))
self[key].add(value)
np.allclose([np.nan], [np.nan])
yy = np.concatenate((y, [0] * 10 * len(y)))
arr[:, (col)] /= abs(arr[:, (col)]).max()
lines.append(line)
writer.writeheader()
positionsList.sort(key=lambda p: howCentric(p, boardLength))
p.terminate()
main()
sorted(zip(unique_rows, counts), key=lambda x: x[1], reverse=True)
fixed.write(line)
log.setLevel(logging.INFO)
cv.SetCaptureProperty(video2, cv.CV_CAP_PROP_FRAME_HEIGHT, 600)
app.exec_()
sys.stdout.buffer.write(TestText2)
server.serve_forever()
sample_df.apply(np.log).diff()
[a, b, c, d]
xx, yy, zz = np.mgrid[:5, :5, :5]
print(re.findall(pattern, string))
my_method()
print(browser.title)
img = cv2.imread(sys.argv[1])
fig = plt.figure()
r.reset_index()
proc.start()
br.set_handle_equiv(False)
a.foo = new_foo.__get__(a, type(a))
test_file.close()
add_column(engine, table_name, column)
d2 = [k for k, v in sorted(d.items()) for _ in range(v)]
foo()
nums = map(lambda x: x * 2, nums)
divtd(datetime.timedelta(hours=12), 2)
element.click()
root.withdraw()
d[row[0]].append(row[1:])
email = models.EmailField(max_length=255)
print(sorted(list(mydict.items()), key=lambda k_v: ordering[k_v[0]]))
settings.name
sum(x[1] for x in divs)
csv2.close()
print(res[1])
my_foo.echo_bar()
f.seek(0, 2)
input = list(input)
wx.ListCtrl.__init__(self, *args, **kwargs)
QWidget().setLayout(self.layout())
imobj.set_data(np.zeros((100, 100)))
np.piecewise(a, [a > 80, (40 < a) & (a <= 80), a <= 40], [funcA, funcB, funcC])
Funny.dynprop
self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
yaml.dump(data, ff, allow_unicode=True)
time.sleep(1)
X, Y = np.meshgrid(np.linspace(xmin, xmax, 100), np.linspace(ymin, ymax, 200))
{e: str1.count(e) for e in set(str1)}
time.mktime(ts)
clips.Run()
fig = plt.figure()
print(dom.toprettyxml())
m = m.multiply(m >= 10)
[1, 1, 1, 1, 1, 1, 1, 1],
w.show()
pd.DataFrame.from_records(records_from_json(fh))
y = np.hsplit(x, [((i + 1) * 10) for i in range((129 - 1) // 10)])
mydict = dict((k, v) for k, v in mydict.items() if k != val)
sys.getsizeof(sys.getsizeof)
temp = temp.reshape(-1, 1)
pygame.quit()
id = Column(Integer, primary_key=True)
ax.xaxis.set_label_position(direction)
main()
tuple(zip(*ii))
ptdiff = lambda p1_p2: (p1_p2[0][0] - p1_p2[1][0], p1_p2[0][1] - p1_p2[1][1])
unittest.main()
print(regex.group(1))
ax2.yaxis.set_major_locator(mtick.LinearLocator(5))
prettyp([1] * 100)
print((x.eval(), y.eval(), tf.gradients(y, [x])[0].eval()))
new_dict = nested_dict(2, float)
l = [(x * (2 if i % 2 == 1 else 1)) for i, x in enumerate(l)]
plt.xlim(xmin, xmax)
QWebView.__init__(self)
frame.Show(True)
df.shape
new_points = [do_something_with(x, y, z) for x, y, z in surface.points]
legend.draggable(state=True)
urllib.request.Request.__init__(self, *args, **kwargs)
burger.save()
wilma.save()
myList[:] = [(a, b) for a, b in myList if myDict.get(a, sentinel) != b]
regex.findall(string)
df = pd.read_sql_query(query.statement, engine)
random.shuffle(tmp)
f = interpolate.UnivariateSpline(x, y)
text = tk.Text()
print(my_list_of_objs)
ax.plot_wireframe(xp, yp, zp)
map(sum, a)
br = mechanize.Browser()
json.dumps(data)
df2.fillna(0, inplace=True)
help(func)
clamp = lambda n, minn, maxn: max(min(maxn, n), minn)
t.start()
plt.show()
print(CreateTable(Model.__table__).compile(engine))
queue = Queue()
sys.getsizeof(bitArray.tobytes()) / float(len(sequence))
eigvals, eigvecs = np.linalg.eigh(cov)
Af.reshape(A.shape)
file_handler.setLevel(logging.INFO)
self.setLevel(logging.INFO)
sys.__stdout__.write(s)
df.iloc[:, (np.lexsort(v.T[::-1]))]
[a for v, a in sorted((x[a], a) for a in y)]
df1.reindex(index)
[m.group(1) for m in matches if m]
self.my_list.extend(repeat(0, 4 - len(self.my_list)))
pprint.pprint(l)
plt.figure()
os.setsid()
name = models.CharField(max_length=50)
id = Column(Integer, primary_key=True)
iter_10 = (i for i in range(10))
[(i, z) for i in [1, 2] for z in zs_i]
s.quit()
compressed_table.append((istart, i, table[i]))
fig2 = plt.figure()
print(subprocess.list2cmdline(sys.argv[1:]))
ax.clear()
df.groupby(1)
root = Tk()
b = [a, a]
plt.show()
sys.stdout
print(data.splitlines())
sum_yearly_data(*list(data.values()))
axes.set_xlim([xmin, xmax])
dict.get(self, key)
pdb.set_trace()
output.close()
numcount[num] += 1
next(g, default_value)
axm.xaxis.set_visible(False)
print(etree.tostring(root, xml_declaration=True))
tuples = [(1, 1), (0, 1), (1, 0), (0, 0), (2, 1)]
datetime.datetime(*eut.parsedate(text)[:6])
print((1, 2, get_nesting_level()))
layout.addWidget(self.buttons)
gp5 = [1, 4, 7, 9]
year = datetime.date.today().year
signal.signal(signal.SIGINT, on_interrupt)
ax.invert_yaxis()
shm_test()
driver = webdriver.Firefox(firefox_profile=profile)
os.close(fd)
time_d_float = time_d.total_seconds()
self.builder.get_name(widget)
math.sin(2 * math.pi / LIMIT * x) + 0.001 * random.random()
l.sort(key=int)
SESSION_COOKIE_AGE = 600
myModule.printX()
db.put(models)
[0, 1, 1, 2, 2, 2, 1, 0],
argparse.ArgumentParser.__init__(self, *args, **kwargs)
sorted(list(range(len(K))), key=lambda x: K[x])
X, Y = np.meshgrid(x, y)
tar.close()
df = pd.DataFrame(d)
[subl for subl in _itersplit(l, splitters) if subl]
p.wait()
show_windows()
x[0] + np.arange(0, 60, 10)
all_genic_snps = pd.concat(all_dfs)
do_sth()
x = Bunch(d)
sio.seek(0)
paramdata.index
lst.sort(key=POS.get)
int(p.stdout.read())
mcastsock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
sk = Sink()
[(x * y) for x, y in zip(list(range(1, 21)), cycle(list(range(2, 10))))]
print(repr(tokzr_QA(inp1)))
numpy.full((2, 2), True, dtype=bool)
s.map(Timestamp.date)
data.groupby([a, b]).count()
np.split(b.indices, b.indptr[1:-1])
print(str(item[0:])[1:-1])
show()
np.fromiter(a, dtype=np.float)
numpy.median(numpy.array(lst))
list(d.keys())
any(b == a[i:i + len(b)] for i in range(len(a) - len(b) + 1))
button.clicked.connect(self.make_calluser(name))
lst.sort(key=lambda x: x[0])
plt.tight_layout()
result = json.loads(line)
con.close()
b.append(i + 1)
1 in set([l[0] for l in a_list])
data = cur.fetchone()[0]
[_f for _f in sequence if _f]
pygame.draw.rect(x, y, width, length)
sys.stdout = sys.__stdout__
clf.fit(Xs, ys)
countvec.fit_transform(df.title)
do_stuff()
other_list.append(obj)
min(list(range(len(L))), key=L.__getitem__)
pickle.dump(my_list, f)
writer.writerow([i[0] for i in cursor.description])
print(repr(arr))
ffit = np.polyval(coefs[::-1], x_new)
result = [convert(i, j) for i, j in enumerate(tlist)]
print(list(map(replace, a)))
x, y
foo()
seq = difflib.SequenceMatcher(a, b)
[dishes[x] for x in crucial if x in dishes]
time.sleep(10)
os.dup2(copied.fileno(), stdout_fd)
response = br.submit()
writer.close()
setattr(self, name, val)
df2 = df[(df.a != -1) | (df.b != -1)]
items = [[1, 2, 0], [1, 2, 0], [1, 2, 0]]
app.run()
print(first.lower() <= second.lower() <= third.lower())
np.unique(struct)
print(cur.fetchone())
unittest.TextTestRunner().run(suite)
admin.site.register(Group, GroupAdmin)
self.dg.Items.Add(self.value)
xl.ActiveWorkbook.ActiveSheet.Columns(1).AutoFilter(1)
p.start()
print(list(value.keys())[0])
axclust.imshow(clustimg)
print(df[c].value_counts())
tags = Tag.objects.all()
anims.append(f)
root.setLevel(logging.DEBUG)
db.close()
fout.close()
axr.yaxis.set_major_locator(yrloc)
dict_x.setdefault(key, []).append(value)
exit(0)
plt.show()
[remove_cruft(s) for s in sites]
context
app = QtWidgets.QApplication(sys.argv)
salt = b62encode(os.urandom(16))
f.write(value)
b.save()
sess = tf.Session()
data = pd.DataFrame(list(collection.find()))
ret[line.strip()] = parse_message_to_tree_helper(buf, index)
app = Flask(__name__)
matplotlib.pyplot.show()
screen.blit(pygame.transform.scale(pic, (500, 500)), (0, 0))
name = models.CharField(max_length=100)
deleted[key_to_delete]
floor_float(10.8976540981, 8)
numpy.median(d, axis=0)
self.SetSizer(sizer)
self.logentry.append(line)
os.path.dirname(str(sys.executable, encoding))
map(list, iter(c.items()))
df.sub(df2, fill_value=0)
gtk.main()
dosomething()
self.layout = QtGui.QHBoxLayout()
print(df[df.Name.isin(val)].reset_index(drop=True))
func2(**locals())
ax = fig.add_subplot(2, 1, 1)
np.isclose(arr_f, a, atol=0.01).any()
numpy.prod(a)
([next(it) for _ in _range(s)] for s in count(1))
sys.stdout.flush()
1 in [len(set(i)) for i in zip(*arr)]
my_strings.sort(key=last_part)
print([sum(daily[x:x + 7]) for x in range(0, len(daily), 7)])
[x for x in lst if x % 2 == 0][0]
main()
print(args)
MyApp().main(sys.argv[1:])
print(a.sum())
plt.xticks(list(range(len(D))), list(D.keys()))
args = parser.parse_args()
print((key, value))
df[(df.a < df.b) & (df.b < df.c)]
print(random.random())
form = ContactForm(request.POST)
{{django_version}}
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
arr.sum(axis=0)
[s for n in range(12) for s in [square(n)] if s > 50]
f.seek(0, 2)
pygame.init()
print(df.iloc[:, (0)].values.tolist())
output.writelines(data)
m * c[:, (np.newaxis)]
time.sleep(5)
proc.kill()
tuple(totuple(i) for i in a)
sorted([15, 8])
self.grid_columnconfigure(2, weight=1)
frame.Show()
self.assertEqual(cm.exception.code, 1)
img = Image.open(image_path)
app = Flask(__name__)
np.vstack(a) - b
cv2.waitKey(0)
[0][2][0]
print(get_authoritative_nameserver(sys.argv[1], log))
a = np.arange(5)
isinstance(s, string_types)
list(islice(rows, 0, len(rows), int(1 / proportion)))
q = multiprocessing.Queue()
func_to_cache()
f.close()
ax1 = fig.add_subplot(111)
file = models.FileField(upload_to=content_file_name)
np.maximum(X.A, Y.A)
[x for x in l if x is not 0] + [x for x in l if x is 0]
avg = sum(mylist) / len(mylist)
shutil.copy2(os.path.join(dirpath, file), dstdir)
t.date.dt.to_pydatetime()
L.append(L[-1][:] + [L[-1][-1] + 1])
list(itertools.zip_longest(*ll))
plt.hist(val, weights=weight)
con.commit()
nx.draw(G, node_size=1000)
id(a[0:2])
L[:start] + L[start + n:i] + L[start:start + n] + L[i:]
c = MyClass()
id = Column(Integer, primary_key=True)
{0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1}
cv2.waitKey(0)
do_something()
Response(serializer.data, status=status.HTTP_201_CREATED)
lines[-n:]
s.fill((255, 255, 255, 128))
pl.show()
sum(j << i for i, j in enumerate(reversed(l)))
b.T
dfile.close()
s = json.dumps(foo.__dict__)
df.loc[idx]
print(np.cross(a, b))
root.winfo_children()
s = s[::-1]
x[:5]
scipy.misc.imshow(im_out)
list({len(x): x for x in reversed(lst)}.values())
print(a[i, j])
fig = plt.figure(figsize=(15, 10))
python - -version
0, 1, 1, 0, 0, 0, 0, 1, 0
self.frame.destroy()
printx()
show()
item in self.queue
l + [pad] * (n - len(l))
s.close()
next(f)
a = np.arange(27)
os.unlink(file_path)
[2, 0, 1, 0, 1, 0]
signal.signal(signal.SIGINT, handler)
list(chain(*zip(list(range(1, 7)), list(range(-7, 0))[::-1])))
widget.show()
cv.CvtColor(vis0, vis2, cv.CV_GRAY2BGR)
Globals = GLOBALS()
dict.__setitem__(self, keys, value)
obj.save()
columns.setdefault(column, []).append(row)
l += [sum(v) / len(v)]
soup = BeautifulSoup(html_text)
grouped.JobNos.sum().order(ascending=False)
proxies = {}
btn.grid(row=0, column=tabslen, sticky=W + E)
b.shape
f.close()
myarr0 = array([1, 0])
ax.set_yticklabels(df.index)
matches = (x for x in lst if x > 6)
session1.add(item)
color = models.CharField(max_length=2)
setattr(self.obj, self.attr, val)
con.commit()
inactive_user_count = IntegerField(default=0)
parsedData = feedparser.parse(data.content)
plt.clf()
not set(a).isdisjoint(b)
inner(myList, [])
tornado.ioloop.IOLoop.instance().start()
isinstance(x, tuple) and isinstance(x.__dict__, collections.abc.Mapping)
b = np.lib.stride_tricks.as_strided(a, (1000, a.size), (0, a.itemsize))
df = pd.DataFrame(rows_list)
s.value_counts().index[2:]
reactor.run()
session.commit()
obj if isinstance(obj, dict) else range(len(obj))
outf.flush()
apsched.start()
bit[::-1]
ax.set_yticks(y_tick * np.pi)
self.mc.Play()
list(filter(pattern.search, strings))
conn.sendmail(sender, destination, msg.as_string())
_.view(data.dtype)
self.handle_request()
[(a + b) for a, b in x]
expander.py
shell.interact()
not bool
ax = fig.add_subplot(111)
intercepts = y_log[:-1] - slopes * x_log[:-1]
MyClass.call_me()
new_d = dict((val, d[val]) for val in reverse_d.values())
first_column = [x[0] for x in mysql_rows]
func()
studying / VBG
numpy.sum(boolarr)
cls._instances[cls].__init__(*args, **kwargs)
fox = webdriver.Firefox()
reactor.run()
requests.status_codes._codes[200]
myList[:] = [x for x in myList if myDict.get(x[0], sentinel) != x[1]]
[0, 0, 0, 0, 0, 0, 0, 0],
im.set_clim(vmin, vmax)
final.append(compound[x])
np.linalg.lstsq(A.T.dot(A) + lamb * np.identity(n_col), A.T.dot(y))
Employee.__init__(self, name, salary)
plt.show(block=True)
im = Image.open(imgfile)
s.bind((host, 8080))
list(range(min((a, b)), max((a, b)) + 1))
conn.send(filepath)
arr.dtype.names
print(doCombine(target, x, len(target), 0, 0))
tk.Canvas.__init__(self, *args, **kwargs)
x[np.logical_and(x > -2, x < 2)]
args = parser.parse_args()
sys.exit(0)
plt.show()
[x for x in lst if x % 2 == 0][:1]
a + b == c or a + c == b or b + c == a
admin.site.unregister(User)
a[slice(*b)]
time.ctime()
set([zip(perm[::2], perm[1::2]) for perm in permutations(list(range(9)))])
any(np.array_equal(a, x) for x in my_list)
fig.autofmt_xdate()
np.random.choice(keys, size=n, replace=True, p=prob)
f_out.write(i)
self.panel.SetSizerAndFit(self.sizer)
plt.plot(data)
print([d.__name__ for d in foo.bar._decorators])
subject = db.StringField(max_length=255, required=True)
[v for v in x if v == v]
sys.exit(app.exec_())
thread.start()
show_firm_url.allow_tags = True
print(list_end_counter([1, 1, 2]))
ax.bar(arange(len(grosses)), grosses)
data = json.loads(json_string)
get_max(dicts)
b = np.array([[5, 6], [7, 8]])
raise ValueError
print(solve([2, 0, 1]))
version.search(s).group()
dir(module)
os.waitpid(-pid)
self.assertTrue(settings.DEBUG)
myObject2 = MyObject(foo, bar)
child.widget().deleteLater()
plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)
fp.close()
ax.set_xlim(0, len(changes) + 1)
items = list(yourdict.items())
PLT.show()
my_dict[len(data)].append(id)
r = requests.get(url, cookies=cd)
obj = MyClass()
sys.getrecursionlimit()
fig.autofmt_xdate()
b = map(bool, a)
soup.find_all(text=is_comment)
reg_data = np.ones((int(1000.0), int(100000.0)))
result.append(x)
plt.show()
datetime.datetime.strptime(date_txt, DATE_FORMAT)
fig.show()
format_timedelta(timedelta(minutes=-5))
self.graphicsView.setScene(scene)
datetime.fromtimestamp(0)
current_size = f.tell()
test[start:end]
self.socket.listen(1)
plt.plot(x, 2 * x)
browser.get(url)
all(val == testval for val in list(d.values()))
contact_form.save()
acc.setdefault(key, []).append(value)
sbtn.click()
myList.sort(key=extractNum)
df.columns = [c_name.strip() for c_name in df.columns.values.tolist()]
image = Image.open(buffer)
__init__.py
listener = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
Foo.class_method()
mat[ixs].sum(axis=0)
tuple(map(sum, zip(a, b)))
plt.draw()
pool.join()
idx = numpy.argmin(numpy.abs(A - target))
cursor.execute(sql)
self.assertTrue(users.is_current_user_admin())
print(myString[len(myString) - 1])
self.save()
id = Column(Integer, primary_key=True)
s[len(start):-len(end)]
match.groups()
app.run()
print(repr(b))
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
runserver.py
print(soup)
writer = csv.writer(outfile)
print(line)
plt.setp(list(ax.spines.values()), color=color)
bins = np.array([0, 1, 10, 60, 60 * 10, 60 * 60, 24 * 60 * 60])
turtle.forward(size)
host.close()
self.board[y][x]
sys.path.append(PYSOLR_PATH)
d = dateutil.parser.parse(s)
[False, False, True, False, False],
print(os.path.join(root, name))
s[4]
pd.concat([c.series for c in [France, Germany]], axis=1)
os.remove(os.path.join(root, file))
ax.set(xticks=np.arange(dates.size), xticklabels=datelabels)
dialog.setLayout(some_layout)
ax.set_xlim(0, 5)
time.sleep(1)
img.putdata(data)
fig = plt.figure()
a = numpy.empty_like(b)
ws.cell(row=r, column=1).value = statN
print(soup.li.findAll(text=True, recursive=False))
xl.Application.Quit()
ser.setDTR(False)
sum(b[i] << i * 8 for i in range(4))
np.meshgrid(x, x)
os.unlink(path)
np.subtract.at(dW, np.s_[:, (y)], masked.sum(axis=2))
len(tup)
ax1.set_xlim([0.1, 10])
commands[command](*sys.argv[1:])
s.commit()
plt.hlines([0], -10, 20)
QtDBus.QDBusConnection.sessionBus().send(msg2)
map(lambda a_b: a_b[1] - a_b[0], pairwise(L))
result = dict(result)
sets = [set(i + j) for i in g for j in g if i != j and set(i) & set(j)]
collections.deque.__getitem__(self, index)
draw = ImageDraw.Draw(img)
set(bell).issubset(printset)
frame.columnconfigure(1, weight=1)
self.a[-1]
plt.xticks(rotation=25)
plt.contourf(X, Y, Z)
pi = square(a + b) / (4 * t)
setattr(object, name, value)
my_dict[item] = a[index + 1]
print(max(len(s) for s in row))
datetime.datetime(2012, 11, 16, 0, 0)
print(output)
random.shuffle(x)
all(map(lambda x: x == items[0], items))
k = np.arange(n)
sys.path.append(SYS_PATH)
main()
sys.maxsize
random.shuffle(thelist)
s.get_text()
backend.setsockopt(zmq.XPUB_VERBOSE, True)
row_ind = [k for k, v in list(d.items()) for _ in range(len(v))]
logger.setLevel(logging.ERROR)
logging.shutdown()
np.array(zip(*(A[i:] for i in range(n))))
time.sleep(1)
pd.concat([i for _, i in df.items()]).dropna().reset_index(drop=True)
[_f for _f in map(func, x) if _f]
ax = fig.add_subplot(111)
li2 = [y for x in li for y in x]
root.mainloop()
plt.xlim(0, 4)
br.select_form(nr=0)
cursor = db.cursor()
len(x)
self.verticalLayout.addWidget(self.label)
df = pd.concat([df1, df2])
MY_SORTED_TUPLE = tuple(sorted(MY_TUPLE, key=itemgetter(1)))
root = Tk()
print(g.reset_index(drop=True))
data_dict[regNumber].append(details)
plt.figure()
raise KeyError(request.POST)
__init__.py
print(find_nearest(x))
output.sort()
df.loc[mask.any(axis=1)]
pd.__version__
os.makedirs(dir)
[int(any(full.endswith(last) for last in B)) for full in A]
self.est.predict_proba(X)[:, (1)][:, (numpy.newaxis)]
date = models.DateTimeField(auto_now_add=True, blank=True)
locals().update({col: df[col]})
django.setup()
[item for item in my_iterable if my_filter(item)]
re.findall(p, test_str)
client.send(msg)
str(b)
plt.annotate(labls[i], xy=(x[i, 2], y[i, 2]), rotation=rotn[i, 2])
jsonFile.close()
do_many_amazing_things(a, b)
math.isnan(x)
plt.show()
sys.exit(1)
X, Y = np.mgrid[:bignum, :bignum]
df[col].replace(to_remove, np.nan, inplace=True)
channel.basic_consume(callback_func, queue, no_ack=True)
df.ix[df.index.indexer_between_time(datetime.time(10), datetime.time(14))]
mratings.mean(axis=0)
store.put(key, value, table=True, append=False)
tk.Tk.__init__(self)
plt.yticks(np.arange(y.max() + 1), labels)
outfile.write(file2.read())
do_something()
area1 + area2
type(a[0])
sum(map(len, primes))
main()
[(x % 2 == 0) for x in t_f_list]
a.childNodes[0].nodeValue
[val for val in a for _ in (0, 1)]
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
test[:, (0)]
sys.stdout.write(RED)
template.render()
gevent.killall([obj for obj in gc.get_objects() if isinstance(obj, greenlet)])
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
getdict(x)
list(range(1, 11))
printArray([str(x) for x in row])
self.send_blob(blob_info, save_as=True)
x.sort(key=str.lower)
output.close()
a[:0] = b
os.symlink(linkto, dstname)
im.file.save(img_filename, File(img_temp))
print(repr(t[1]))
p[np.argsort(p)]
int(b[::-1], 2)
root.mainloop()
app.run()
setHatchThickness(1.0)
self.queue.add(item)
[(item + (z[item[0]],)) for item in l]
sess = tf.Session()
time.sleep(5)
y.mean()
datetime.fromtimestamp(time.mktime(time_tuple))
np.sin(2 * np.pi * freq * t)
s.replace(d, regex=True)
sound.play()
df
pprint(dict_to_etree(d))
YourModel.objects.filter(some_datetime__date=some_date)
[item for item, count in Counter(a).items() if count > 1]
ax.scatter(a, b, c, c=[use_colours[x[0]] for x in d], s=50)
suite.addTest(unittest.TestLoader().loadTestsFromModule(module))
ax.set_xlim(xlim)
a.itemset((i, j), x)
df.loc[[(df.iloc[(i), 1:].duplicated().sum() == 0) for i in df.index]]
path = sys.modules[self.__module__].__file__
app.register_blueprint(post_blueprint)
df[k] = df[k].astype(v)
type(json.loads(data))
[k[1] for k in d]
button.grid(row=1, column=4)
str(165).zfill(4)
img = Image.open(stream)
np.linalg.norm(A[1:] - A[:-1], axis=1)
locals().update(d)
fobj.close()
{{page.get_title}}
sum(np.array(a) > 7)
time.sleep(4)
Py_Finalize()
Table.query.filter(Table.name == con.name).first()
array2[:] = [e for e in array2 if e not in set1]
lucky.append(L[0])
r = np.exp(np.sqrt(x * x + y * y))
[1, 2] in a.tolist()
self.mainloop()
reduced_basi = [[[0, 0]], [[1, 0], [0, 1]], [[2, 0], [1, 1], [0, 2]]]
args = parser.parse_args()
args = parser.parse_args()
ax.plot([1, 1, 1])
str(self.as_date())
min_positions = [i for i, x in enumerate(a) if x == mymin]
print(len(list(group)), key)
int(True)
table.sort(functools.cmp_to_key(team_cmp))
G.add_edge(prereq, target)
driver = webdriver.PhantomJS(desired_capabilities=dcap)
obj.save()
con.close()
QtGui.QWidget.__init__(self, parent)
df.loc[:, ((df != df.ix[0]).any())]
iter(self._data)
cv2.waitKey(0)
my_list = [False for i in range(n)]
[s for s in perms if valid(s)]
main()
canvas.pack()
plt.show()
plt.subplot(154)
numpy.random.seed(x)
fig = plt.figure()
painter.rotate(90)
plt.ion()
fh.close()
values[i] = struct.unpack(endian, f.read(bytes))[0]
os.chdir(whatever)
totalist, forselection = itertools.tee(totalist, 2)
f.close()
df = df.sample(frac=1).reset_index(drop=True)
driver = webdriver.Firefox(firefox_binary=binary)
time.sleep(0.1)
sorted_B = sorted(B)
[s.index(x) for x in lst]
sys.getrefcount(object)
plt.show()
bar = foo.copy()
print(line)
module.run_pool()
sum(A, [])
ast[([0, 1, 2]), ([0, 1, 0]), ([0, 2, 2]), (0), :2, :2]
same_structure(a[0], b[0]) and same_structure(a[1:], b[1:])
a * x ** 2 + b + c * np.sin(x)
indices = np.split(sidx, np.flatnonzero(np.diff(arr[sidx]) > 0) + 1)
list(s)
dict((k, dol1.get(k, no) + dol2.get(k, no)) for k in keys)
M.A.diagonal(2)
Py_Finalize()
time.sleep(0.5)
A[:, (1)].sum()
wx.StaticBitmap(panel, -1, jpg, (10, pos), (jpg.GetWidth(), jpg.GetHeight()))
map(complex, row)
mypoly = Point(0, 0)
thisFile = __file__
dllname = os.path.dirname(__file__)
nid = Column(Integer, primary_key=True)
[(item, the_list.count(item)) for item in sorted(set(the_list))]
fulldate = fulldate + datetime.timedelta(milliseconds=500)
s.splitlines()
master.grid_rowconfigure(1, weight=1)
[(x + 1) for x in l]
zip(a[::2], a[1::2])
[val for sublist in mylist for val in sublist]
df.set_index(df.merged_ix, inplace=True)
a[np.ix_(*[list(range(0, i, 2)) for i in a.shape])]
fig = plt.figure()
time.sleep(0.1)
ax.plot(x, y)
y.shape
sorted(listofLines, key=extract_time)
np.random.uniform(-10, 10)
deletemydict[k]
store.close()
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
deleterecursive_dict[key]
X.T
fp.seek(0)
lines.sort(key=second_column)
print(ame_to_bre(text))
b = [i for i in a]
func(*args, **kwargs)
imresize(np.ones((1000, 1000)), 50).shape
wx.Frame.__init__(self, parent, id, title, size=(600, 600))
root.mainloop()
any([(sorted(sub) in range(min(l), max(l) + 1)) for sub in subs])
ldap.set_option(ldap.OPT_DEBUG_LEVEL, 0)
k, _, _, _ = np.linalg.lstsq(M, y)
dta.co2.interpolate(inplace=True)
a[i:j]
connlisten_thread.start()
print(foo.bar())
self.yet = True
A[np.arange(m), idx]
print(line.strip())
np.dot(X, np.dot(M, X.T)).trace()
ax.set_xlim([x[0], x[1]])
(220922000, 2428),
(220922001, 2429),
(220922564, 2992),
(220922566, 2994),
(220924161, 4589),
lines = ax.plot(list(range(10)), np.random.randn(10), list(range(10)), np.random.randn(10))
xml_tree = etree.parse(xml_file)
print(is_shifted_copy([1, 1, 1], [1, 1, 1]))
HttpResponse(status=400)
text.pack()
[audio[i // 2] for i in range(0, len(audio) * 2)]
df = pd.concat(series, axis=1)
pipeline.fit(X[:, (np.newaxis)], y)
time.sleep(0.05)
y = np.array([0, 0, 1, 1])
plt.plot(x, y)
process_names = [proc.name() for proc in psutil.process_iter()]
a.repeat(2, axis=1)
True
b = tuple(a)
obj.save()
sess.query(Tag.name).distinct()
im.save(sys.argv[2])
bool([1, 2])
plt.plot(x, y)
self.Bind(wx.EVT_MOTION, self.on_motion)
y_pred = model.predict(X_test)
pub_dict[p.key].append(p)
print(data)
[j for j in range(2, n) if isprime(n)]
c = itertools.chain(a, b)
df1.plot(ax=axes[0, 0])
final_dict = {key: t[key] for key in t if key not in [key1, key2]}
tar.close()
dict(re.findall(pattern, json_string))
df.ix[df.Col1.isin(search_list)]
self.app = app.app.test_client()
lock = threading.Lock()
ax2.get_yaxis().set_animated(True)
[cube(i) for i in range(1, 11)]
int(1.0 / -2)
ax1.yaxis.set_major_locator(y1loc)
ipython = get_ipython()
func(a)
img.save(filename=output_destination)
prettyp(CrazyClass())
myfunc(a, b, c, d, e, f)
next((x for x in seq if predicate(x)))
ftp.cwd(path)
self.multlineCommands = Forward()
fig = plt.figure()
execlist[i][4] = mydelay
x, y = zip(*points)
x.append([])
Z[xidx, yidx] = raw[:, (2)]
temp = temp[1:]
self.model.objects.filter(active=True)
df.iloc[2:6]
print(map(itemgetter(1), g))
print((r.status_code, r.reason))
xi, ti = np.meshgrid(xi, ti)
chain.from_iterable(combinations(xs, n) for n in range(len(xs) + 1))
np.diagonal(np.rollaxis(np.tensordot(a, a, (1, 1)), 1), 0, 2).T
Gtk.main()
f.close()
dict(d1, **d2)
window = collections.deque(sorted(window), maxlen=WINDOW_SIZE)
signal.pause()
[(k, len(list(g))) for k, g in groupby(s)]
serverSocket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
Counter(item for lst in listOfLists for item in set(lst))
self.canvas.after(50, self.check_queue)
str(numpy.array([0.24])[0])
self.assertEqual(resp.status_code, 200)
[0][1][2]
print(recursive_lambda(lambda a, b: b * a(a, b - 1) if b > 0 else 1)(6))
list(set(a) & set(b))
cursor.execute(query)
root.mainloop()
sys.getsizeof(b)
data.append(item)
np.moveaxis(np.indices(dims), 0, -1)
a = dict.fromkeys(list(range(4000000)))
ax1 = fig.add_subplot(111)
b = [6, 7, 8, 9, 0]
soup = BeautifulSoup(browser.page_source)
m.close()
self.httpd.stop()
{x for x in a if x == x}
dictionary = dict(zip(keys, values))
process.stdout.close()
list(itertools.chain.from_iterable([l[x] for x in lslice]))
sys.stdout.write(s)
print(json.dumps(foo))
os.startfile(filename)
QtCore.Qt.ItemIsEnabled | QtCore.Qt.ItemIsSelectable | QtCore.Qt.ItemIsEditable
cv2.waitKey(0)
cv2.destroyAllWindows()
(x + 1 for x in l)
numpy.ndarray((5, 5))
user = models.OneToOneField(User)
pyglet.app.run()
self._stack.pop()
time.sleep(1)
b.py
webtail
list(range(m, (count + 1) * m, m))
main()
func(x)
print(sys.exc_info()[2].tb_next.tb_frame.f_locals)
datetime(2015, 12, 2, 0, 0), datetime.datetime(2015, 12, 8, 0, 0)
f.write(text)
d.update(locals())
Notify.uninit()
celery.config_from_object(app.config)
len(a)
a.append(row)
print(df.attr.iloc[i])
data = np.random.random((int(1000.0), int(100000.0)))
any((a[:] == [1, 2]).all(1))
np.vstack((a, a, a))
doctest.testmod()
plt.setp(plt.xticks()[1], rotation=90)
cursor.execute(qSQL)
print(json.dumps(data, default=date_handler))
frame1.axes.get_yaxis().set_ticks([])
arr.append(list(df.iloc[i]))
threading.Thread.__init__(self)
[map(counter.__getitem__, all_features) for counter in counters]
file.close()
~pd.isnull(df[list_of_cols])
2 * frexp(n)[0]
gdata.gauth.AeLoad(users.get_current_user().user_id())
G = nx.MultiGraph()
count_array = [int(i.count) for i in mvv_list.collect()]
df.stack()
sock.close()
np.vstack([np.diag(c[:, (i), (i)]) for i in range(A.shape[0])]).T
f = open(filename)
AuthorFormSet = modelformset_factory(Author, extra=2, form=AuthorForm)
qs.filter(user=request.user)
screen.mainloop()
QtCore.Qt.ItemIsEnabled
MyApp().run()
result[numpy.argsort(A)] = numpy.sort(B)
time.sleep(10)
print(getpass.getuser())
print(queue.method.message_count)
item.set_fontsize(20)
cal_window.show_all()
test_moduleA.py
mpl.ticker.MaxNLocator.__init__(self, nbins=9, steps=[1, 2, 5, 10])
main()
dict((k, json.dumps(v)) for k, v in list(json.loads(val).items()))
signal.signal(signal.SIGALRM, old_handler)
(m.T * c).T
df.iloc[idx]
new_list = list(range(1, 6)) + list(range(15, 20))
app.MainLoop()
fig = plt.figure()
os.chdir(storetodir)
axborder.set_ylim(binimg.shape[0], -1)
print(codeproc.stdout.read())
image = Image.open(f)
dset1.apply(func, axis=1)
layout.addWidget(self.label)
repeat(lambda : bar(42))
first_num, first_arr, second_num, second_arr = generate_arrangements(data)
nhb = random.choice(range(0, len(A)))
connection.commit()
elapsed2s.append(elapsed2)
elapsed1s.append(elapsed1)
d[key].append(row[1:])
subsampled = df.ix[(choice(x) for x in grouped.groups.values())]
p.map(process_file, listdir(inputDir))
locale.resetlocale()
b.foo()
python - mfoo.bar
vars(args)
thread.start()
img.size
User.insert_many(row_dicts).execute()
df.Group.map(df.Group.value_counts())
plt.draw()
pdf_text_object.textOut(text)
imp.load_dynamic(__name__, __file__)
form.save()
main()
df = df.sort()
mock.assert_called_with(42)
listOfStuff = [doSomethingWith(v) for v in range(n // 2, -1, -1)]
fig.subplots_adjust(wspace=0.4)
print(df[(df.Symbol1 == df.Symbol2) & (df.BB == df.CC)])
wx.StaticBitmap(panel, -1, bmp, (10, pos), (bmp.GetWidth(), bmp.GetHeight()))
other_app.other_view(request, **kwargs)
print(map(float_or_str, line.split()))
myArray = np.vstack(myArray)
process_data(line)
moduleZ.py
plt.plot(X, Y, lw=0)
do_some_other_stuff()
dict_lol = dict((item[1], item) for item in lol)
legline.set_color(color)
df_out
json.dumps(result, default=json_util.default)
fig, ax = plt.subplots()
self.__class__(data)
kwargs_new = {str(k): v for k, v in list(d.items())}
t.start()
f(*args, **kwargs)
print(tag.nextSibling.nextSibling.__class__)
[(a if C else b) for i in items]
uniq_animal_groups = map(list, set(map(tuple, animal_groups)))
im1 = ndimage.grey_erosion(im, size=(15, 15))
fig, ax = plt.subplots()
x + 1
root.withdraw()
pool = multiprocessing.Pool(multiprocessing.cpu_count())
r = requests.get(URL, cookies=jar)
foo()
conn.close()
greetings.hello()
numpy.zeros((2, 2), dtype=bool)
r.findall(s)
output, err = p.communicate()
a = a.reshape(-1)
d += timedelta(days=6 - d.weekday())
largest_names = [x[0] for x in heapq.nlargest(6, your_list, key=itemgetter(1))]
print(yaml.load(f))
jsonify(result=wordlist)
print([filters.get(word) for word in sentence.split() if word in filters])
proc.terminate()
[[2], [0], [1], [0], [1], [0]]
np.dot(Zij, G)
tuple(x[0] for x in G)
print(t.timeit(5))
fig, ax = plt.subplots()
ax2.set_xticks([100, 80, 50])
df
a.remove(i)
hex((val + (1 << nbits)) % (1 << nbits))
pyglet.app.run()
distinct()
result = response.read()
hashlib.md5(img.tostring()).hexdigest()
button.pack()
MyClass in MyClass.__mro__
self.listTools.add(self.addButton)
a.append((1, 2, 4))
xml.close()
sorted([B, C, A, D, X], key=lambda cls: len(cls.mro()))
hash(self.PersonID)
str_list = [item for item in str_list if item]
next(hex_list)
OrderedDict(sorted(list(d.items()), key=lambda t: t[1]))
X[:, (i)] = x
platform.system()
print(newcorpus.sents())
len(set(it_copy)) == 1
DISABLE_SIMULATION = _DISABLE_SIMULATION
a.flatten()
random.shuffle(array)
pprint(data)
assert len(A) == len(B)
uniq_animal_groups = map(list, set(map(tuple, map(set, animal_groups))))
all(x == 0 for x in list(d.values()))
b.setdefault(j, []).append(i)
os.remove(os.path.join(my_dir, fname))
self.name = name
form.save()
newImage = myImage.copy()
B[A[1], cat_index] = A[2]
shutil.rmtree(tmpdir)
f.flush()
seq[n:] + seq[:n]
df
select_indices = np.where(np.logical_and(x > 1, x < 5))
logger.addHandler(fileHandler)
b = np.array([0] * 4)
result = [sum(data) for data in zip(*args)]
dot_data = StringIO()
fig = plt.figure()
new_list.append(x)
unique_a.view(a.dtype).reshape((unique_a.shape[0], a.shape[1]))
plt.gcf().tight_layout()
assert np.allclose(result, expected)
Thread.__init__(self)
arity.__class__.arity = arity
numpy.histogram(my_values, bins=numpy.r_[-numpy.inf, my_bins, numpy.inf])
p.start()
df.clip(upper=4400).plot.hist(stacked=True, bins=bins, normed=True)
naive_dt = datetime.now()
df = pd.DataFrame([[1, 0, 0, 0], [0, 0, 1, 0]])
self._server.shutdown()
ax.set_autoscale_on(False)
traceback.print_exc()
help(hehe)
arr[([1, 1]), :]
[x for x in mylist if not any(c.isdigit() for c in x)]
traceback.print_exc()
self._list[x]
b[i] = 1
itertools.islice(mygenerator(), 10)
l = json.loads(s)
afield = forms.ChoiceField(choices=my_choices)
a, b = 1, 2
fig = plt.figure()
func()
Py_Finalize()
dialog.setAttribute(QtCore.Qt.WA_DeleteOnClose)
stack[-1].append([])
mask1 = (arange(10) > 5) & (arange(10) <= 8)
self.sock.connect((host, port))
list(map(chr, list(range(ord(s[0]), ord(s[-1]) + 1))))
a.reshape((2, 2, 2))
logger = logging.getLogger(__name__)
a, result = a[:-1], a[-1]
top.sort(key=lambda a: a[1])
b = tuple(b)
print(delta.days * 24 * 60 * 60 + delta.seconds + delta.microseconds / 1000000.0)
vars(args)
tf.contrib.layers.embedding_column(workclass, dimension=8)
GEN_SUSPENDED
x.view((float, len(x.dtype.names)))
setattr(self, k, d[k])
arraymean = sum([int(i[0]) for i in array]) / len(array)
result.append(list[-1])
output.append(float(row[4]))
words = [x for x in words if x not in bad_words]
attrList = map(lambda x: x.attr, objectList)
list(set([x for x in l if l.count(x) > 1]))
[[6, 2], [7, 5], [8, 7], [9, 9], [0, 4]]
print(x)
do_something_dangerous()
fig.autofmt_xdate()
AB = [(a + b) for a, b in itertools.zip_longest(A, B, fillvalue=0)]
unittest.main()
sys.exit(1)
ax2 = ax.twinx()
foo()
any(some_func(x) for x in some_list if x > 5)
r.json()
EMAIL_USE_TLS = True
time.sleep(1)
from_date = from_date - datetime.timedelta(days=1)
df.dtypes
out.close()
some_value
xml = xml.dom.minidom.parse(xml_fname)
uuid.uuid1(random.randint(0, 281474976710655))
unittest.main(failfast=True)
nonzero(r_[1, diff(t)[:-1]])
bar.foobar()
dev / tests / test_file.py
print(textelem.text)
x = json.loads(x)
np.vstack([topbottom, xvalues])[:, (mask)].T
ax.xaxis.set_major_formatter(major_formatter)
fig = plt.figure()
s.add(get_my_new_random_number())
hmag = np.array(hmag)
self.label.pack()
ispower(1, 1)
print(json.JSONEncoder().encode(response))
df.loc[:, (df.dtypes == object)]
random.shuffle(ans)
args = parser.parse_args()
norm.cdf(1.96)
self.fileobj.seek(-8, 1)
Base.metadata.create_all(engine)
views.py
foo.f()
element.clear()
[1426802400, 1429218000]
firstvalue = mvv_list[0].mvv
cursor.commit()
self.scrollbar.grid(column=2, sticky=N + S)
ax2.set_ylim([np.amin(image[:, (5), (5)]), np.amax(image[:, (5), (5)])])
print(p.stderr.read())
plt.show()
QtCore.QAbstractListModel.__init__(self)
canvas.configure(yscrollcommand=vsb.set)
soup.prettify()
print(Foo.instance_count)
conn, addr = s.accept()
zip(*lol)
ax.yaxis.set_visible(False)
tableWidget.show()
json_data.close()
bool(urlparse.urlparse(url).netloc)
hash(obj)
print(request.headers)
subList = [tempList[n:n + N] for n in range(0, len(theList), N)]
feeder_lock_object.lock()
f.columnconfigure(0, weight=1)
parser.parse(string)
ax.clear()
anims = [f for f in files if f[2].lower() not in IMAGE_TYPES]
seen_add(element)
a[b]
self.window.show()
batch.execute(http=http)
layout = QVBoxLayout()
soup = BeautifulSoup(html)
do_the_stuff(my_list)
zip(*r)
plt.subplots_adjust(top=0.55)
df.stack().loc[first:last].min()
run(reloader=True)
str(self.__dict__)
cursor.execute(CQLString)
x.pop()
np.testing.assert_almost_equal((x, x, x), (y, y, y), 5)
bar()
c.save()
fnan == fnan
zip(words[1:], words[:-1])
outsock.close()
sorted(list(range(len(a))), key=a.__getitem__)
PLT.show()
sns.regplot(x, y, lowess=True)
a[a < 0] = 0
cmp(x[1], y[1])
main()
event.SetEventObject(self)
option.click()
datetime.datetime(year=year, month=month, day=day, hour=hour)
[(i + j) for i, j in zip(list_of_urls, string.lowercase[:14])]
contents = fh.read()
print(db_data.count(with_limit_and_skip=True))
outputStream.close()
plt.show()
np.arange(lllon, urlon, 2.0),
print(a, b, c)
self.widget.click.connect(self.onWidgetClick)
xlim(0, 0.8)
print(A[0], B[0])
print(2 * math.acos(0))
max(a, key=itemgetter(1))[0]
out.close()
np.sum(np.linalg.solve(L, xdiff.T) ** 2, axis=0)
globals()[name] = value
syncdict.update([(key, syncdict.get(key) + inc)])
ax2.imshow(template, cmap=plt.cm.gray)
print(list1[-5:])
sys.exit(app.exec_())
gc.get_objects()
ASTVisitor.__init__(self)
logger = logging.getLogger(COMPANY_LOGGER)
m[:, :, ::-1]
server.terminate()
APP_ROOT = os.path.dirname(os.path.abspath(__file__))
C.__init__(self)
[(y1 - x1, y2 - x2) for (x1, x2), (y1, y2) in combinations(myList, 2)]
col_1 = M[:, (1)]
ax = fig.add_subplot(1, 1, 1)
(b - a).total_seconds()
writer.writerow(row)
int(round(170, -2))
self.view.header().resizeSection(column, width)
test()
tdelta.total_seconds()
root.mainloop()
self.assertAlmostEqual(em(1, 2), 0.1481, 4)
print(len(request.headers))
[(x * next(cyc)) for x in lis[0]]
i = int(float(s))
ax.xaxis.set_major_formatter(mpl.ticker.FuncFormatter(myFormatter))
tested = [i for i in input if i > 2]
pprint(od, width=40)
args = parser.parse_args()
flat = itertools.chain.from_iterable(pairs)
HttpResponse(status=204)
mylib.mySub.argtypes = [POINTER(c_double), c_int, POINTER(c_double)]
ax.yaxis.set_major_formatter(y_formatter)
user = User.objects.get(pk=uid)
a_to_as = np.argsort(a)
even = list(next(iter(())) if n == 412 else n for n in numbers if 0 == n % 2)
ttk.Radiobutton(self.mainframe, value=0).grid(column=1, row=2)
print(ArrayAddition([2, 95, 96, 97, 98, 99, 100]))
map(func, *sequences)
print(float(x))
[ips_data[ip] for ip in sorted_ips]
nDigits = int(ceil(log(nmb, base)))
plt.show()
reactor.run()
self.assertEqual(expected, self.nums.marshal())
self.fcall(*args)
signal.signal(signal.SIGTERM, sigterm_handler)
admin.site.register(LocationGroup)
container.grid_columnconfigure(0, weight=1)
numpy.fromiter((your_func(row) for row in X), dtype=bool, count=len(X))
time.sleep(1)
zip(*data)
self.frame.pack()
f.close()
ainb = np.array([(x in b) for x in a[:, (2)]])
name = CharField()
f.read()
plt.ylim(-1, 2)
[str[i:i + chunk_size] for i in range(0, len(str), chunk_size)]
l[t[0]][t[1]] = something
unq_out = np.any(np.diff(sorted_Ar, axis=0), 1).sum() + 1
sorted(li, key=lambda x: x.anniversary_score)
sys.exit(-1)
sess.run(init_new_vars_op)
np.roots([a, b, c])
main()
title = models.CharField()
plt.show()
MyInterpreter().cmdloop()
x = np.linspace(0, 2 * np.pi)
np.issubdtype(np.complex64, np.integer)
sizer.Add(widget, proportion=0, style=wx.ALL, border=5)
csv_out.close()
self.fp.flush()
print([v for v in values if len(v[1]) > 1])
str1_list == str2_list
int(s)
pprint(list(iter_rows(ws)))
ax.plot(data1)
tunnel.start()
plt.plot(x, y)
xbook.close()
pd.Series(test).where(lambda x: x != 1).dropna()
f(*args)
process.poll()
lines = [line for line in f if line.strip()]
info[2][1] == 6
Text.__init__(self, *args, **kwargs)
a, b = given_str[:len(given_str) / 2], given_str[len(given_str) / 2:]
s.reset_index()
df.reindex(all_days)
get_value(dic, 0)
mdd, start, end
td = timedelta(seconds=TimeModel.objects.get(id=1).time)
fig.canvas.draw()
[a, b, c]
subprocess.call([path_to_notepad, path_to_file])
data = [(x if x.isalpha() else float(x)) for x in line.split()]
np.array([0, 1]).any()
data = self.request.recv(1024)
config = configparser.ConfigParser()
file = os.path.join(os.getcwd(), os.listdir(os.getcwd())[0])
plot(x, y)
dict([(elem, 0) for elem in s])
out[1:, :] += tmp[:-1, :]
ax.xaxis.set_major_locator(ticker.MultipleLocator(20))
ssh.load_system_host_keys()
keys = [k for k, v in Arr]
plt.show()
requests.get(url, stream=True)
aw2.show()
do_something(i)
out = []
q.put(urllib.request.urlopen(url).read())
print(type(parsed))
A = alpha * x * y + beta * x ** 2 + gamma * y ** 2
foo(**{key: 1, foo: 2})
json.dumps(datetime.datetime.now(), default=date_handler)
found = m.group(1)
print(response.read())
os.close(fh1)
a.reshape((-1, 5))[:, 1:4] = 100
vfunc(*np.ix_(xv, yv, zv))
email = forms.EmailField(required=True)
fib(n - 1) + fib(n - 2)
p.wait()
[push(D, k, K) for K, D in list(c.items())]
signal.signal(signal.SIGINT, signal_handler)
mask = numpy.random.choice([False, True], len(data_arr), p=[0.75, 0.25])
list(ordered_dict.values())[2]
words[0] == words[-1] == check_str
plt.ylim([0, 5])
winfile.close()
df.A.append(df.B).dropna().reset_index(drop=True)
time.sleep(2)
print([arr[i][i][i] for i in range(len(arr))])
uwsgi - H / path / to / your / virtualenv
urllib.request.urlopen(r)
print(my_queryset.query)
self.mfcChanged.emit()
deletemydict[key]
logger = get_task_logger(__name__)
a[(0, 2), :, :]
self.rect.left += self.xvel
pipe.wait()
[k for k, v in groupby(sorted(a))]
a + _(b * c)
c = [(x + [y]) for x, y in zip(a, b)]
data = numpy.fromfile(my_file, dtype=numpy.uint8).reshape(-1, N)
print([name for name in dir(B) if isbuiltin(getattr(B, name))])
sample_object.save()
print(tree.getpath(e))
os.makedirs(dest_dir)
time.sleep(5)
list(range(*args))
r, g, b = wfloat.transpose((2, 0, 1))
d = {k: v for dct in l for k, v in list(dct.items())}
f.write(urllib.request.urlopen(url).read())
numpy.random.randint(0, 1000, count) * 0.001
s.sort()
ax.plot(x, y * 2)
zip_longest(fillvalue=fillvalue, *args)
[0, 1, 1, 1, 1, 1, 1, 0],
l = [cond(i) for i in range(1, n)]
base64.urlsafe_b64encode(encoded_string)
ax.plot(x, y)
c.execute(query)
print(lxml.etree.tostring(the_doc, pretty_print=True))
screen.blit(surf2, (200, 200, 100, 100))
plt.figure(figsize=(7, 7))
sizer.Add(fsizer, 0, wx.EXPAND)
tf.matmul(tf.transpose(x), y)
logging.info(line)
main()
tree.add(2)
plt.show()
avg_sum.append(A.sum(axis=1).mean())
(self.players1.all() | self.players2.all()).distinct()
result = process.communicate()[0]
signal.signal(signal.SIGINT, signal_handler)
Gtk.main()
options = webdriver.ChromeOptions()
int(math.ceil(x / 100.0)) * 100
[i for i in a if i != [0]]
[solution for solution in solve(4)]
time.sleep(0.5)
image.astype(np.uint8)
map(lambda d: abs(d - date), dates)
sys.setrecursionlimit(100000)
cols.append(str(col))
s.cookies.clear()
dates_dict[key].append(date)
np.maximum.accumulate(Q, axis=1)
self.own_id = current_socket.getsockname()[1]
ax.yaxis.set_major_locator(ticker.MultipleLocator(20))
ax.plot(x, y)
random.shuffle(l)
stream = sys.argv[1] if len(sys.argv) > 1 else sys.stdin
obj.save()
wx.Panel.__init__(self, parent)
x = int(x)
i += 1
plt.show()
plt.setp(ax2.get_yticklabels(), visible=False)
json.dump(my_dict, f)
a.split()
sum(map(my_condition, l))
ax.add_patch(patch)
start = str(cols[1].find(text=True))
df.loc[(df[0] == k[0]) & (df[1] == k[1])] = [[v[0], v[1]]]
food = [random.choice(i) for i in list(my_dict.values())]
deletex[k]
indices = zip(*sp_matrix.nonzero())
X[np.ix_(idx, idx)]
mail.starttls()
[z0] * len(seconds)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
p.start()
x = numpy.arange(data.shape[1])
out.value_counts(sort=False).plot.bar()
test.pop(5)
add(*l)
plt.show()
writer.writerows(clean_list)
a = fig.add_subplot(1, 2, 1)
[0, 0, 0, 0, 1, 0, 0, 0],
signal.signal(signal.SIGALRM, _handle_timeout)
array.sort(key=lambda k: (k[0] - point[0]) ** 2 + (k[1] - point[1]) ** 2)
os.open(os.devnull, os.O_RDWR)
self.setCentralWidget(self.view)
conn.rollback()
y = numpy.arange(data.shape[0])
print(dict(d))
[i for i, (a1, a2) in enumerate(zip(s1, s2)) if a1 != a2]
leg = plt.legend()
f_new.close()
df.as_matrix(columns=[df[1:]])
self.axes.set_title(title)
num_words += len(line.split())
new_x = np.ma.masked_where(np.ma.getmask(m), x)
image = np.zeros((max_x, max_y))
index = np.array([0, 1, 2])
new.append(l[i:i + 5])
main(sys.argv[1])
ax1.plot(list(range(0, 10)))
print(r.content)
df.to_excel(writer, index=False)
line = line.strip()
heapq.heappush(heap, (-prod2, x, y - 1))
plt.setp(g.ax_heatmap.get_xticklabels(), rotation=90)
ttypager(text)
self.add_widget(Label(text=str(data)))
type(c)(a)
A.f.__func__(b)
sys.path.append(somepath)
A = (A - mean(A)) / std(A)
buffer += ser.read(ser.inWaiting())
p = np.poly1d(np.polyfit(t, data, 2))
l.extend(t)
fig = plt.figure()
soup = BeautifulSoup.BeautifulSoup(data)
ax1.set_color_cycle([cm(1.0 * i / (NPOINTS - 1)) for i in range(NPOINTS - 1)])
new_list.append([some_tuple])
pir(df)
self.figure.canvas.draw()
ax.imshow(X, cmap=cm.jet)
f.write(image_response.read())
ax.set_xlim(-1, 7)
df.merge(melted_items, left_index=True, right_index=True)
[x for x in data if func(x)]
recur(n - 1, count + 1)
self.response.write(name)
document.append(line)
[x for x in range(len(self.states)) if self.states[x]]
plt.show()
series.hist(bins=division)
driver = webdriver.Chrome()
plt.plot(list(range(10)))
not any(d.values())
plt.show()
dict((x, duplicates(List, x)) for x in set(List) if List.count(x) > 1)
print(r[i:i + n])
print(new_dic)
self.assertAlmostEqual(em(1, 1), 0.6407, 4)
a.sort(key=key, reverse=True)
print(year_fraction(datetime.datetime.today()))
print(counter.most_common())
numpy.nextafter(1, 0)
element.clear()
df.ix[yesterday.strftime(fmt):now.strftime(fmt)]
fig.canvas.draw()
print((f.__name__, f.__hash__))
plt.setp(ax2, xticks=[], yticks=[])
win.set_keep_above(False)
child.interact()
plt.xlim([0, 1])
ax1.set_color_cycle([colormap(i) for i in np.linspace(0, 1, number_of_plots)])
a.remove(10)
fig.autofmt_xdate()
df.join(pd.concat([pd.DataFrame(s).T] * len(df), ignore_index=True))
0, 1, 0, 1
signal.alarm(0)
urllib.request.install_opener(opener)
(a1[:, (numpy.newaxis)] == a2).all(axis=2)
OrderedDict(sorted(list(d.items()), key=lambda t: t[0]))
collections.Counter(lst)
ax.fill_between(np.arange(1, 10), 1, 2, zorder=-1, **kwargs)
id = Column(Integer, primary_key=True)
frame.Show()
df.columns = zip(*col_names)[1]
float(x) / float(x)
my_app = MyApp()
print(url_without_query_string)
img.putdata(my_list)
urllib.request.install_opener(opener)
self.canvas = tk.Canvas(self, width=100, height=100)
data = json.loads(json_input)
reactor.run()
B = np.array([2, 4, 6, 8])
nocapture = 1
[x for x in l1 if not any(fnmatch(x, p) for p in l2)]
f.close()
self.video_out.release()
uniq_animal_groups = set(map(tuple, animal_groups))
fig, ax = plt.subplots(2, 1)
outfile.close()
db.session.commit()
conset = set(map(frozenset, consarray))
a[::-1]
print(message.get_payload())
astar(formation, heuristic, solution, getneighbors)
sanitised_path = sanitise_filesystem_path(path)
zip_longest(fillvalue=fillvalue, *args)
sum(masked, axis=1)
sparse_out = coo_matrix((data, (np.arange(N), a.ravel() - 1)), shape=(N, L))
a.tolist()
set(df.Col1) | set(df.Col2)
data = [str(float(fractions.Fraction(x))) for x in data]
self.driver.close()
[1][2][2]
admin.site.register(FooProxy, FooAdmin2)
(datetime.datetime.min + value).time()
jsonpath.jsonpath(data, path)
new_dict = dict(list)
naive_utc_dt = datetime.utcnow()
a = np.arange(100)
max_idx, max_val = max(enumerate(l), key=operator.itemgetter(1))
time.sleep(0.1)
reader = io.open(sys.stdin.fileno())
PLT.show()
np.random.seed(0)
series[10] = np.nan
matplotlib.pyplot.close()
np.nanargmax(a, axis=1)
file = zipfile.ZipFile(BytesIO(request.content))
msglist = list(chunkify(hextotal, 4096))
ax.xaxis.set_minor_locator(MultipleLocator(0.2))
django.setup()
shutil.copyfileobj(infile, outfile)
celery.start()
x.reshape(x.shape[0], -1).shape
Response(UserSerializer(request.user).data)
[Factorial(x) for x in it]
f()
np.roll(a, -2)
fp.close()
gca().get_xaxis().get_major_formatter().set_useOffset(False)
myfunc()
res.cumsum().applymap(lambda x: np.unique(list(x)))
plt.show()
p.start()
pd.DataFrame(v[i0:i1], df.loc[df.name].index[i0:i1], df.columns)
new_string
connection.disconnect()
type(a).__call__(a)
f.write(chunk)
b.sort(key=order.get)
self.setWindowFlags(Qt.FramelessWindowHint)
print(f.read())
ax.plot_surface(x, y, 10, rstride=5, cstride=5, facecolors=img)
im = img.load()
self.__class__.__name__
print(df.reset_index())
[1, 2]
[list(g) for k, g in groupby(a)]
self.start.connect(self.run)
plt.bar(J2 - 0.5 * width, z(J2), width=width)
csv_fileh.seek(0)
User.objects.get(pk=user_id)
ee.save()
max(n for n in a if n < 0.7)
{{raw | unquote_raw}}
inspect.getargvalues(traceback.tb_frame)
dict.__delitem__(self, key)
p.start()
a if b else c
instance.save()
df
l = np.array([[0, 0], [0, 1], [1, 1]])
args, unknownargs = parser.parse_known_args()
[1][2][1]
r = requests.post(url, files=files, data=values)
pprint({key: getattr(f, key) for key in dir(f)})
self.fig = mplfig.Figure(figsize=(5, 4), dpi=100)
frec(word)
keys = set()
ax.bar(list(range(len(dates))), values, width=width)
module1.f()
s.run()
app = QtGui.QApplication(sys.argv)
nums.sort(key=functools.cmp_to_key(lambda x, y: cmp(y + x, x + y)))
plt.legend(handles=legend_patches)
ssh_client = paramiko.SSHClient()
print({i: f.lower() for i in nums for f in fruit})
request.finish()
print(cursor.fetchall())
df.reindex(ind - ind2).join(df2.reindex(ind - ind2))
type(varname)
inithello()
base64.b64decode(a)
ax.scatter(x, y)
np.shape(result)
reader = csv.reader(f)
plt.show()
df.index.get_level_values(0)
p.plot(x, y)
fig, axes = plt.subplots((2, 2))
time.sleep(0.1)
plt.pcolormesh(X[0:1], Y[0:1], C[0:1])
newList = [word for word, mask in zip(s, b) if mask]
mask[y:y + h, x:x + w] = img[y:y + h, x:x + w]
zip(*([iter(l)] * 2))
server.sendmail(FROMADDR, TOADDRS, msg)
out.close()
db.put(1)
df.loc[i] = [float(d) for d in data]
len([i for i in x if 60 < i < 70])
(df == 0).astype(int).sum(axis=1)
b = a[m]
board.append([])
destination.close()
y = x[1:] - x[:-1]
c.coords(x)
plot(x, sin(x))
instance._meta.app_label
subprocess.Popen(SCRIPT % filename, shell=True)
python - V
plt.ion()
next(p)
x.astype(int)
sys.stdout = old_stdout
[x for x in l if x not in f]
[x for i, x in enumerate(a) if i in indices]
list(intermix([1, 0, 1, 1, 2, 1, 0, 1, 1, 1, 2]))
a()
picture = pygame.transform.scale(picture, (1280, 720))
Silly(0)
ax.yaxis.set_visible(False)
[id(i) for i in x]
plt.figure(1)
double([1, 2])
cont, = ax.contourf([], [], [], 500)
fig.canvas.draw()
int(s)
app.MainLoop()
isinstance(x, int)
sorted(array, key=lambda x: x is 0)
c.append(l)
main_sizer.Add(content_sizer, 1, wx.EXPAND)
a = A(10)
file.seek(0, os.SEEK_END)
print(url)
ax.set_ylim(0, max_height)
a[i] = d.get(a[i], a[i])
surround.py
result.append(item)
self.show()
xl.ActiveWorkbook.Close(SaveChanges=1)
driver.switch_to_default_content()
areas_pos = abs(z[:-1] + z[1:]) * 0.5 * dx
out, err = proc.communicate()
fig = plt.figure(figsize=(10, 5))
shout.start()
list(f([9, 8], [2, 1]))
map(int, testList)
img.show()
print((a, b))
wrapper(fn(*args, **kw))
[ulist.append(x) for x in l if x not in ulist]
print(a, b, c, d)
dict_you_want = {your_key: old_dict[your_key] for your_key in your_keys}
plt.show()
sys.stdout.write(line)
user().key().id()
list_comprehension = [i for i in range(4) if i > 0]
unbroadcast(y).shape
plt.show()
z, x, y = d.nonzero()
text = str(encoded_string, the_encoding)
arr[:] = [a, b]
a1[mask.A] = 0
ax2.yaxis.get_offset_text().set_color(plot_ax2.get_color())
[item for item in mylist if item.isalpha()]
thread.start_new_thread(loop0, ())
[n]
plt.show()
ax.set_theta_direction(-1)
graph.tree().pprint()
latest_subdir = max(all_subdirs, key=os.path.getmtime)
np.where(binplace == 2)
self._numberButtons[i].clicked.connect(lambda i=i: self._number(i))
self.listbox.pack(padx=10, pady=10)
setattr(self, key, value)
do_post_install_stuff()
print(k, a[k])
data = s.recv(4096)
app.exec_()
print(Foo.bar.__get__)
uniques[col].update(chunk[col].unique())
ax.yaxis.set_ticks([])
sys.exit(1)
f.write(s)
print(df1[[0, 7]])
l = [s.name for s in sections]
self.transport.loseConnection()
self.suggestions.append(a[1])
p.map(g, list(range(10)))
self.name
time.sleep(1)
print(user_result)
subprocess.call(cmd, stdin=fd)
df.drop(df.index.get_duplicates())
[0, 0, 1, 1, 1, 1, 1, 0],
self.selenium.start()
od = OrderedDict(sorted(list(d.items()), key=lambda x: x[1], reverse=True))
os.kill(int(pid), 0)
app.exec_()
(x & -x).bit_length() - 1
show()
print([[(each - x) for x in l] for each in l])
dir()
lesser = qsort([x for x in inlist[1:] if x < pivot])
writer = csv.writer(f)
a = 1 if x < 1 else 10 if x > 10 else x
B = A[0]
conv1d_on_image = Reshape((dim_x, output_channels))(conv1d_on_image)
yourdate = dateutil.parser.parse(datestring)
plt.show()
student = Student.objects.get(user=id)
a[:, :, :, (0)].flatten()
ax.yaxis.labelpad = 20
json.dumps(_data, indent=4)
plt.show()
descendents_ancestors.add(descendent)
min(dates, key=lambda d: abs(d - date))
plt.show()
mask.reshape(-1, 20).sum(1)
sleep(1)
df.loc[mask]
logger.setLevel(logging.INFO)
api.update_status(status=single_tweet)
print(nat.Poland)
output.writeframes(data[0][1])
self.thread = threading.Thread(target=self.run, args=())
print(df.to_csv(index=False, header=False))
ax.set_ylim(-40, 40)
pd.concat(vals, axis=1, keys=keys, **kwargs)
obj.save()
root = Tk()
plt.show()
process.poll()
categories = Category.filter(animals__in=animals).all()
s.sendmail(me, you, msg.as_string())
l.extend([pad] * (n - len(l)))
b = list(a)
df.plot()
map(list, zip(*lis))
size = sum(1 for _ in bucket.objects.all())
x, y = np.ogrid[:shape[0], :shape[1]]
html_source = driver.page_source
ax.set_axis_off()
start.mainloop()
set(chain.from_iterable(df.genres))
db = client.get_default_database()
df.idxmax()
sys.exit()
[row.tostring() for row in data]
csv_writer = csv.writer(csv_file)
np.vstack(np.hsplit(a, m / k))
plt.show()
Z[np.where(Z == 0)] = np.nan
cv2.CV_FONT_HERSHEY_SIMPLEX
self.SetIcon(icon)
context.pop()
x += tuple(y)
audio.save()
plt.plot(xvalues, yvalues)
setattr(self, attr, getattr(student, attr))
pts = [(10, 10), (10, 11), (20, 11), (20, 10), (10, 10)]
ii = (s1 ** 2 + s2 ** 2 < 1).sum()
GL.glVertexAttribPointer(self.loc, 1, GL.GL_FLOAT, GL.GL_FALSE, 0, 0)
p2.stdout.close()
pg.draw.rect(surf, STIMCOL, (10, 20, 40, 50))
lst[i:] + lst[:i]
json.dump(pickle.load(fpick), fjson)
inF.close()
x_new = sparse.lil_matrix(sparse.csr_matrix(x)[:, (col_list)])
print((f, b))
scipy.stats.linregr(X, Y)
{k: (v() if callable(v) else v) for k, v in a.items()}
repo = user.create_repo(full_name)
plt.show()
pd.get_dummies(s1[s1.notnull()])
time.sleep(1)
blue_count = len(set(list_of_blue_items).difference(list_of_all_items))
toppings = forms.ModelMultipleChoiceField(queryset=Topping.objects.all())
df_norm.max() - df_norm.min()
topten = sorted(list(mydict.items()), key=itemgetter(1), reverse=True)[0:10]
browser = webdriver.Chrome(chrome_options=co)
self.send(response.toXml())
print(count.most_common(16))
[(a, b, c) for a in range(x + 1) for b in range(y + 1) for c in range(z + 1)]
f.seek(0, os.SEEK_END)
plt.show()
traceback.print_exc()
app.MainLoop()
forwarder.write(serial_out)
root = Tk()
GpsPoint(self.x + other, self.y + other, self.z + other)
tuples.remove((entry[1], entry[0]))
plt.scatter(latt, lont, c=uniqueish_color(len(latt)))
f.write(data)
ax.set_yticklabels(map(str, list(range(90, 0, -10))))
data.most_common(1)
response = urllib.request.urlopen(req)
ax.yaxis.set_visible(False)
logger.addHandler(handler)
set_keyring(PlaintextKeyring())
map(int, temps)
stdoutdata, stderrdata = process.communicate()
self.button.pack()
print(args.bar)
window.show_all()
np.random.seed(seed)
l = math.floor(math.log10(i)) + 1
list(collection.questions)
entry_list.extend(x.title.text for x in feed.entry)
a.sort(key=operator.itemgetter(1))
random.random() < probability
bin(100)
df2.reindex(ix)
[multiply(*pair) for pair in zip(iterA, iterB)]
plt.plot(x_fit, y_fit)
min(data, key=operator.itemgetter(1))
y = np.linspace(0, 1, 20)
serializer.save()
groups.append(list(g))
print(dishes[key])
self.SetTitle(str(event.GetSize()))
x, y = zip(*li)
[(x[0] * x[1]) for x in result]
c[a | b]
admin.site.register(ModelMock)
list(np.array(a) - np.array(b))
sys.stdout.write(next(spinner))
curses.endwin()
obj.__dict__[prop]
theclass
any(lst[i:i + ln] == sub for i in range(len(sub) - ln + 1))
str(str(self))
sys.modules[__name__] = ModuleClass()
n * (n - 1) * 2
[node() for _ in range(100)]
title = CharField()
proc.stdin.write(text)
firstpost = db.DateTimeProperty()
current_time = time.time()
plt.ylim([0, 1])
[(y - x) for x, y in it.combinations(a, 2)]
df.buyer_id = df.apply(make_buyer_id, axis=1)
np.linalg.inv(a)
lst = ast.literal_eval(strab)
Session = sessionmaker(bind=engine, autocommit=True)
app = Flask(__name__)
max(MyCount, key=int)
ax = fig.add_subplot(111)
sp.Matrix(np.diag(d - 4) + 4)
print(random.triangular(0, 1, 0.7))
print([(i, sum(j)) for i, j in list(d.items())])
p.stdin.close()
urllib.request.install_opener(opener)
r = int(s)
lines.pop(0).remove()
plt.hold(True)
platform.version()
[1, 0, 1, 1, 0, 0, 0, 1],
print(eventdata)
logger.setLevel(logging.INFO)
pos = nx.spring_layout(G)
content = browser.page_source
wb.save(stream)
time.sleep(1)
shutil.rmtree(TEST_OBJECTS_DIR, onerror=on_rm_error)
a.update(1)
a.bit_length()
print(match.groups())
i = s.index(t.lower())
serializer.is_valid()
self.connection.close()
db.session.commit()
[datetime.datetime(2012, 1, 1, 0, 0), datetime.datetime(2012, 1, 1, 1, 0)]
df.apply(lambda row: get_nth(row, n), axis=1)
result.extend(list(range(a, b + 1)))
data_cluster.fit(data_numeric)
x.dtype
index_list(l)
docvec = model.docvecs[99]
self.save()
time.sleep(1)
list2 = [[item[i] for item in list if len(item) > i] for i in range(0, 100)]
client.close()
(1, 2) in d
print(list(kwargs.items()))
result = DataFrame(list(cursor), columns=tweet_fields)
draw.ellipse((0, 0) + size, fill=255)
print(__file__)
list(itertools.product(a, b))
form = forms.ChapterForm(request.POST, request.FILES, instance=chapter)
(df[self.target] == t).any()
cfloats[i] = pyfloats[i]
np.argmin(myList)
[list(zip(a, p)) for p in permutations(b)]
print(type(im))
signal.signal(signal.SIGINT, signal.SIG_IGN)
br.set_handle_refresh(mechanize._http.HTTPRefreshProcessor(), max_time=1)
print(info.get_content_maintype())
self.lock.acquire()
aDict[name].append((startTime, endTime))
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
pool = multiprocessing.Pool()
list.pop(self, *args, **kwargs)
urllib.request.install_opener(opener)
browser.show()
out.append(l[new_i].pop(random.randint(0, len(l[new_i]) - 1)))
print(sqrt(2))
dest_file.close()
set().union(*lis)
values = list(dictionary.values())
matrix = [line.rstrip() for line in infile]
a.astype(numpy.int64)
skel = mh.thin(im)
mylist = [p for i, p in enumerate(mylist) if i not in remove]
int(s)
fullname = os.path.join(thispath, filename)
plt.show()
main()
unittest.main()
filename = input()
sleep(1)
duggars = db.session.query(Parent).filter(Parent.child_count > 17)
f.write(file_data)
sess = tf.Session()
x_2, y_2
sys.stdout.write(line)
ax.set_xticks(np.arange(len(dates)) + width / 2)
min_val, max_val = min(x, y), max(x, y)
resource = urllib.request.urlopen(url)
serializer = UserSerializer(user, data=request.DATA, partial=True)
format_to_year_to_value_dict.setdefault(format_str, {})[year] = value
x = array([0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1], dtype=np.bool)
subprocess.Popen(shlex.split(command))
print(f.__self__)
session.add(another_obj)
argvb = list(map(os.fsencode, sys.argv))
[1, 0, 0, 0, 0, 1, 0, 1],
print(np.array([i, j], dtype=np.int64))
iter(self.__dict__)
decimal.Decimal(x.seconds)
_(1, 4)
reactor.run()
logging.getLogger().setLevel(logging.INFO)
form = CustomQueryConstraintForm(initial=request.POST)
process.kill()
self.fig.canvas.draw()
sorter = np.argsort(colkeys)
match = re.search(pat, s)
new_df = pandas.DataFrame.from_dict(a_dict)
b = np.array([1.0, 0.9, 0.8, 0.7, 0.6])
ax.scatter(theta, r)
response = requests.get(bl_url, headers=headers)
script_dir = os.path.dirname(__file__)
print(polygon(4, 2, math.pi / 4, [10, 10]))
self.canvas.after(10, self.move)
p.wait()
list(hex_list)
self._handler.close()
self.show()
-np.linalg.det(self.state)
ax.imshow(data)
print(r.content)
data.remove(row)
[0, 0, 0, 0, 0]
session = requests.session()
[(x == y) for x, y in zip(s, t)]
current_milli_time()
self.lock.release()
random.shuffle(c)
((int(x), int(y)) for x, y in split)
getpass()
{{form.as_p}}
sys.exit(1)
print(make_hash(Foo.__dict__))
print(test._tests)
self.rect.top += self.yvel
print(list(get_names(func)))
main()
cv_image = cv_image[:, :, ::-1]
a.remove(b)
inithello()
sys.exit(main())
printFoo()
{{analytics_code}}
v = fbx.FbxVector4(x, y, z)
newdict.update(mydict)
grequests.map(rs)
TaskBase.__call__(self, *args, **kwargs)
main()
random.shuffle(row)
sys.getwindowsversion()[0] >= 6
d[k].add(v)
map(flat_tuple, a, b, c)
OrderedDict.__getitem__(self, key)
l = [0] * 10000
b[0].append(1)
sorted(lst)
dtsegs = zip(dtg0, dtg1)
area += (p1[0] - p0[0]) * ((p1[1] + p0[1]) / 2 if trapezoid else p0[1])
show()
time.sleep(5)
sys.stderr.close()
setattr(self, name, kwargs[name])
img.resize((width, height), Image.ANTIALIAS)
pdb.set_trace()
print(intersects(a, b))
print(dict(customers))
canvas.pack()
k, v = random.choice(list(d.items()))
data = f.read()
rgb_values.pop(-1)
{k: (v / len(list_of_dicts)) for k, v in list(summed.items())}
MyModel.objects.filter(created__isoyear=year, created__week=week)
getattr(hello, m)()
string.ascii_lowercase[:14:2]
scipy.optimize.fsolve(g, 0.0)
client.connect(HOST, username=USER, password=PASSWORD)
list(params.items())
items = list(dictionary.items())
nltk.clean_html(html)
do_something_useful()
someList.sort(key=key2, reverse=True)
soup = BeautifulSoup.BeautifulSoup(doc)
print(dateparser.parse(date_string).date())
os.path.join(path, fname)
ax.get_xticklabels()[i].set_visible(False)
service.files().copy(fileId=originalId, body=newfile).execute()
self.run.grid(row=4, column=0, sticky=EW)
dataPadded = numpy.concatenate((data, padding), axis=1)
df_new
json.dump(sample, fp)
f(1)
self.Show()
(b - a).seconds
len(self.__dict__)
sys.stdout.flush()
browser.submit()
ax = plt.subplot(111)
loader.construct_yaml_map(node)
inspect.getmembers(a, predicate=inspect.ismethod)
df.isnull().any(axis=1)
myClass.__subclasses__()
print(L[i])
infile.close()
frame1.axes.get_yaxis().set_visible(False)
fig.autofmt_xdate()
{k: c[k] for k in li}
output.append(sublist[0])
ws.append(l)
elem.clear()
[zip(x, list2) for x in itertools.permutations(list1, len(list2))]
numcols = len(input[0])
ax2.set_xlim([0, repeat_length])
plt.figure()
ax.set_xlim(-40, 40)
self.finish()
time.sleep(1)
imshow(Z1, cmap=cm.hsv, alpha=0.6, extent=extent)
unittest.main()
time.sleep(5)
last_modified_date = datetime.fromtimestamp(mtime)
result = pattern.sub(lambda x: d[x.group()], s)
sleep(1)
all(x >= y for x, y in zip(L, L[1:]))
[v for v in x2 if v[1] == optimal[0] and v[2] == optimal[1]]
today = datetime.datetime.today()
df[1].apply(pd.Series)
s.get_data()
app.run()
ssh_client = paramiko.SSHClient()
data = json.loads(file)
mystr.replace(k, v)
getattr(self._i, n)
result = sorted(iter(promotion_items.items()), key=item_value)
print(x.task_id)
sorted(s, lambda x, y: cmp(x.lower(), y.lower()) or cmp(x, y))
plt.xlim(0, variability.shape[1])
value = next(iter(some_collection))
self.__dict__.update(_dict)
my_list
time.sleep(10)
self.builder.add_from_file(self.glade_file)
math.isnan(math.nan)
a[np.arange(a.shape[0]), entries_of_interest]
d = math.floor(sdl2.SDL_ALPHA_OPAQUE * (math.ceil(s) - s) + 0.5)
time.sleep(1)
[list(comb) for i in range(1, n + 1) for comb in itertools.combinations(x, i)]
startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
shlex.split(raw_args, posix=False)
A = numpy.vstack([A, newrow])
logging.Formatter.converter = time.gmtime
bar.baz[a:b:c].foo()
mainFrame.grid()
object_list = [c for c in Content.objects.all() if random.random() < fraction]
writer.writerows(worksheet.get_all_values())
number += 1
sys.stdout.flush()
logging.getLogger(className)
len(set(sum(a, [])) & set(b) & set(c).is_empty()) > 0
MySuperClass.__init__(self)
t.start()
QtGui.QWidget.__init__(self, parent)
A.remove(i)
plt.legend(numpoints=1)
out.read()
list(y)
clf.fit(X, y)
print(root.winfo_width())
a = np.arange(10)
logger.setLevel(logging.DEBUG)
httpd.serve_forever()
person.delete()
client = requests.session()
my_list.pop()
self._getlock()
df[[iscomedy(l) for l in df.genre.values.tolist()]]
element = min(myset)
some_object = klass()
form.save()
app.start()
ax.add_patch(rect)
list.append(run(*i))
conn.commit()
min(max(start, num), end)
group in user.groups.all()
pkgpath = os.path.dirname(testpkg.__file__)
y = odeint(func, 0, t)
np.delete(arr, index, 0)
np.vstack([A[i:i - width] for i in range(width)]).T
message.save()
t.isoformat()
[word.strip(string.punctuation) for word in text.split()]
f.write(response.body)
timestamp = (dt - datetime(1970, 1, 1)).total_seconds()
f_out.write(data)
ax.xaxis.set_major_locator(ticker.FixedLocator(x))
ax1.plot(pd.Series(np.random.uniform(0, 1, size=10)))
plt.show()
seq.sort()
print(map(itemgetter(1), g))
[i for i, elem in enumerate(lst) if condition(elem)]
time.sleep(0)
a = list(range(10))
any(i) and not any(i)
result = np.array(list(ranges(intersect(a, b))))
main.py
image_data = np.asarray(image)
list(grpname.keys())
list(subgrpname.keys())
print(df)
pylab.show()
ax.add_patch(unmanhattan_patch)
ax = fig.add_subplot(111)
EmailThread(subject, html_content, recipient_list).start()
pd.rolling_mean(aapl, 50).plot()
arr[mask != 5] = 0
writer.writeheader()
self.root.quit()
set(b1).intersection(b2)
fig, ax = plt.subplots()
current_frame = inspect.currentframe()
a.sort(key=lambda v: v != 0)
a[mask] = 888
print(Child.getId())
plt.plot(x, y, color=(r, g, b))
A().test()
[mapping[value] for value in a1 if value in mapping]
mask = pd.Index(base).union(pd.Index(base - 1)).union(pd.Index(base + 1))
JsonResponse(posts_serialized, safe=False)
a = np.array(t)
send_thread.daemon = True
bigdata = data1.append(data2, ignore_index=True)
result = collections.defaultdict(lambda : collections.defaultdict(list))
time.mktime(utc_tuple) - time.mktime((1970, 1, 1, 0, 0, 0, 0, 0, 0))
calendar.timegm(time.gmtime(0))
b = A[(2), :].copy()
key = sum(map(itemgetter(play)))
win.show()
app.register_blueprint(auth_blueprint)
libtest2d.print_2d_list(arr2d.shape[0], arr2d.shape[1], arr2d)
parm[var_name] = int(eval(input()))
result += [[x, y, z]]
np.linalg.inv(b)
testclassb().testmethod2()
self.response.out.write(filename)
raise tornado.web.HTTPError(404)
writer.writerow(header)
lst = [maybe_int(s) for s in lst]
np.arange(100, 1, -1)
[x for x in a if x not in b]
thread.start()
op(x, y)
self._stdout = sys.stdout
ax.set_xticks(np.arange(AUC.shape[1]) + 0.5, minor=False)
objc.__version__
list(IT.izip_longest(readers[0], readers[1], readers[2]))
dt_sec = map(datetime.timedelta.total_seconds, dt)
plt.draw()
print(data[:, :, :, (1)])
im = Image.open(filename)
session2.add(new_item)
c = np.hstack((a[a_inds], b[b_inds]))
f.close()
dict[firstname] = dict.get(firstname, 0) + 1
create_engine(db_connect_string, connect_args=ssl_args)
deletelst[len(lst) - n:]
f1(localvariable=localvariable, *args)
stringaxis.setTicks([list(xdict.items())])
b = zip(*a)
time.sleep(1)
b.__class__
imshow(X, norm=norm)
Counter(protein[i:i + 6] for i in range(len(protein) - 5))
iter(f)
models.ForeignKey(EntryAdmin)
a, b, c, d = map(float, line.split())
timeit.timeit(lambda : timeit.timeit(f), number=100)
data.dtype.names
col_dict = {x: col for x, col in enumerate(df.columns)}
nlistnew = [([a] + row) for row in nlist]
pyplot.plot(x, y)
time.sleep(1)
args = parser.parse_args()
ax.legend()
app.exec_()
canvas.pack()
sess.run(tf.initialize_all_variables())
created_at = db.DateTimeField(default=datetime.now)
ax.set_xlim(0, 2 * np.pi)
driver = webdriver.Firefox(profile)
per_column = zip(*per_row)
hex(ord(chars[0]))
x = x + 1
c = pygame.time.Clock()
s.send_message(msg)
df.reset_index(inplace=True)
x.append([])
audio_data, pyaudio.paContinue
z = np.sqrt(x ** 2 + y ** 2) + np.sin(x ** 2 + y ** 2)
ax.set_ylim(min(y), max(y))
format_elements(reduce_list(some_list))
self.progbar.start()
tk.Toplevel.__init__(self, *args, **kwargs)
label.pack(padx=4, pady=4)
self.app = Flask(__name__)
shutil.copyfileobj(src, dest)
plt.show()
temp.sort()
joint = [[sum(x) for x in zip(a, b)] for a, b in zip(incoming, outgoing)]
db.put(groups)
print(sum(sum(map(int, r.findall(line))) for line in data))
self.window.set_border_width(8)
server.serve_forever()
device.dispose()
max(hand, key=lambda c: rank_cards.index(c[0]))
a = [[0] * ROWS] * COLUMNS
self.out.write(bytearray([self.accumulator]))
A = np.empty((15, 15))
client_sock.close()
app = QtGui.QApplication(sys.argv)
ax1.set_ylim([0.1, 10])
offset = datetime.fromtimestamp(0) - datetime.utcfromtimestamp(0)
fig = plt.figure()
analysed.add(color)
[(a if tC else b) for i in items if fC]
result.predict(np.vander(x_new, degree + 1))
max(elements, key=lambda e: int(e[0]))
[e for sub in tgt if isinstance(sub, (list, tuple)) for e in sub][-5:]
print(sum(a * b for a, b in combinations(xList, 2)))
x = np.array([0, -1, -1, 0, 1, 1])
itertools.product(list(range(2)), repeat=n)
print([dict(zip(keys, items)) for items in res])
plt.matshow(M, cmap=plt.cm.Blues)
all_challenges = session.query(Challenge).all()
all_pixels.append(luma)
print(soup.prettify())
[(key, other) for key in keys for other in prefixes[key[1:]]]
sys.exit(1)
plt.rcParams.update(params)
foo.__defaults__
a = np.fromiter(Data, dtype=np.float, count=DataLength.value)
np.random.shuffle(indices)
result.update(d)
fluidsynth.play_Note(64, 0, 100)
d1 = np.random.random((25, 4))
screen.blit(surface, (0, 0))
issubclass(test, object)
parser.parse_args([])
some_list[start:stop:step]
df[:5]
doctest.testmod()
client = Client(url, transport=ntlm)
new_a = a[(a == a).all(1)]
maxValue = curs.fetchone()[0]
win.add(vbox)
x = [False, True, True, False]
id = Column(Integer, primary_key=True)
np.fromiter(a, dtype=np.float, count=100000)
a.exec_loop()
server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
ax = fig.add_subplot(111)
pprint.pprint(output)
plt.show()
{a: 1, b: 2}
cppcode.init()
print(json.dumps(data, indent=4))
time_waited = time.time() - then
sys.exit(app.exec_())
d + timedelta(weeks=week - 1, days=-d.weekday())
base64.b64encode(bytes([foo]))
self.lineedit.setFocus()
pd.concat(df_list, ignore_index=True)
app_log.addHandler(file_handler)
self.belltimer.Start(1000)
ax.set_zlim((0, 50))
filename = tkFileDialog.askopenfilename(filetypes=FILE_DIALOG_FILETYPES)
app = Flask(__name__)
ax.plot(x, y * 10)
self._shape = self._shape[0] - 1, self.shape[1]
m.group(1), int(m.group(2))
my_list.sort(key=lambda elem: [my_alphabet.index(c) for c in elem[0]])
pd.DataFrame(zip(X.columns, np.transpose(model.coef_)))
test.py
dict((k, sum(map(itemgetter(k), dict1))) for k in dict1[0])
ws = wb.active
args = parser.parse_args()
f.close()
out = np.add.reduceat(X[:, (idx0)], cut_idx, axis=1)
len(set(str_.split()) & set(dict_1.values()))
maxu2().sum()
subprocess.list2cmdline(args)
m[list(zip(*map(range, m.shape)))] = 0
db.commit()
HTML_with_style(df.head())
self.SetSizer(self.sizer)
print(df.sum(1).to_frame())
pprint.pprint(yourDict)
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
new_matrix.append(matrix[i])
self.children = weakref.WeakValueDictionary()
sys.path.append(path_to_parent)
a, b = zip(*my_list)
os.chdir(default_path)
ax = fig.add_subplot(111)
df.reset_index(drop=True)
cin = ast.literal_eval(cin)
json.dumps(rh)
deleteL[len(L) % 2::2]
Tkinter.mainloop()
bSizer.Add(button6, 0, wx.ALL, 5)
bSizer.Add(button7, 0, wx.ALL, 5)
bSizer.Add(button8, 0, wx.ALL, 5)
new_list = [foo for foo in foos if foo.location == 2]
plt.xlim([0, bin.size])
objs[0].do_sth()
ast.literal_eval(s)
frame.focus_set()
out[-1]
axborder.set_axis_off()
print(le.tostring(doc))
handler = logging.StreamHandler()
file.close()
assert len(name) < len(input_given)
file.close()
cursor.execute(sql)
self.assertOK(response)
thread.start_new_thread(updateCounter, ())
list(range(0, 1)) == list(range(0, 1))
(a - a[0] == 0).all()
print(datetime.now() - start)
a = models.ForeignKey(Foo, default=lambda : Foo.objects.get(id=1))
print(add.addtwo_(byref(a), byref(b)))
plt.show()
reactor.run()
groups.append(list(g))
{{form.title}}
C / C.astype(np.float).sum(axis=0)
writer.writerow(row)
os.listdir(short_unc)
c = a[2:]
mean = A.mean(axis=1)
r = requests.post(post_url, data=json.dumps(payload), headers=headers)
pygame.display.flip()
tm += datetime.timedelta(minutes=10)
bool(b)
datetime.datetime(*map(int, values))
argv.pop(0)
plt.figure()
unique_edges = set(map(normalize, edges))
timer.start()
time.sleep(10)
self.cmdloop()
timedelta(seconds=_diff.total_seconds()) - timedelta(wek)
json.dumps(message)
cvtColor(src, gray, COLOR_BGR2GRAY)
print(f.readlines()[1:15])
lists = [[]] * 5
array_double = np.array(a, dtype=np.double)
testsite_array = my_file.readlines()
s.send(data_string)
ax.cla()
[x for x in s.lower() if x in string.ascii_lowercase]
all_pairs.sort(key=lambda p: distance(p[0][0], p[1][0]))
zfile.close()
time.sleep(random.random())
b.save()
keys = list(test)
gtk.main_quit()
day_list.index(inp)
print(x, categorize(x))
np.sum(np.log(np.arange(1, n + 1)))
s.ioctl(socket.SIO_RCVALL, socket.RCVALL_OFF)
plt.plot(np.arange(10), 4 * np.arange(10))
out_file.write(line)
plt.plot(y)
time = models.FloatField()
cooler()
circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT)
v.toPyObject()[0]
Page.objects.published()
df.iloc[:10, :5]
[map(second, row) for row in data]
list(filter(str.isdigit, text))
n = re.findall(pattern, string)
ax.set_xticks(indeces)
self._fd.close()
a * np.exp(-c * x) + d
root = Tk()
dict(counts)
area = area1 + area2
C.f(2)
self.stop()
main(sys.argv)
output = p2.communicate()[0]
threading.Thread(target=cli).start()
ax.xaxis.set_major_formatter(formatter)
sys.exit(0)
r._meta.id
np.array(mp.arange(600))
repo.pull()
plt.xlim([0, n])
task.react(main_task)
[value for value in the_list if value != val]
result.append(c)
post_body = self.rfile.read(content_len)
driver.set_window_size(1024, 768)
lis.sort(key=itemgetter(1))
self.request.route_url(name, id=self.id, **kw)
self.target(*args, **kwargs)
obj.save()
wb.Close()
lambda x: f(g(x))
time.sleep(1)
plt.subplots_adjust(left=0.2, bottom=0.2)
k_keys_sorted_by_values = heapq.nlargest(k, dictionary, key=dictionary.get)
q.open()
list(unique_everseen(a, key=frozenset))
codecs.BOM_UTF8
chi2_contingency(data)
datetime.strptime(text, fmt)
response.status_code
canvas.place(x=5, y=height + 10)
unittest.main()
model.setData(index, newValue, QtCore.Qt.EditRole)
[5, 6, 7, 8, 9]
ndimage.gaussian_filter1d(np.float_([0, 0, 0, 0, 1, 0, 0, 0, 0]), 1)
total = sum(total)
print(mystring[:1])
data[k].append(fitem(v))
Thread(target=serve_on_port, args=[1111]).start()
sum(1 for i in x if 60 < i < 70)
list(chain.from_iterable(result))
print(p.url)
axarr[0].set_xticklabels(map(str, axarr[0].get_xticks()))
p.start()
writer.writerow(d)
c.__getattribute__
print(Decimal(2) ** Decimal(2))
c.add(1).cumprod()
__metaclass__ = Singleton
text = pattern.sub(lambda m: rep[re.escape(m.group(0))], text)
print(df.groupby(lambda x: x.month).agg([min, max, np.mean]))
mlab.show()
xl.Quit()
Counter(data).most_common()
p1.wait()
social.set_extra_data(extra_data)
main()
print(paths(p)[0])
f.__code__.co_varnames
elapsed_time = time.time() - start_time
print(np.sort(x)[-10:])
my_randoms = random.sample(range(100), 10)
grid.cbar_axes[2].colorbar(im2)
l = [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 2, 2, 2]
process.wait()
runInParallel(func1, func2)
mainloop()
[Link(url, text) for url, text in urlstext]
driver = webdriver.PhantomJS()
HttpResponseRedirect(settings.LOGIN_URL)
stdout, stderr = p.communicate(in_string)
self.timeout.cancel()
self.name = name
ax.set_xticks([])
response.read()
Base.metadata.create_all(engine)
filter_func(parent_dict, func)
f.seek(0, 0)
t.date()
print(cur.fetchall())
s = pd.Series([2], index=[2])
result.append(x)
tuple(int(i * 255) for i in colorsys.hsv_to_rgb(h, s, v))
process.wait()
[a[i] for i in b]
asyncore.loop()
wd.config(height=500, width=500)
plot.rcParams.update(params)
print(list(chain(*A)))
funs = list(get_petters())
quit()
self.label.pack()
lines = infile.readlines()
A.__init__(self, n)
rows, cols = X.nonzero()
root.mainloop()
print(ndimage.zoom(data, (1, 2, 2)))
df = df.stack().sample(frac=0.8).unstack()
cur.execute(sql, macs, host)
dict2 = dict1.copy()
[0, 0, 0, 0, 0, 0, 0, 0, 0, 164],
my_list.extend([int(i) for i in row if i.isdigit()])
print(Dummy())
[[4, 2, 6], [8, 10, 12], [6, 4, 6]]
{{user.username | e}}
Model.objects.filter(filters_for_query)
req = urllib.request.Request(site, data, headers)
table[0][1]
r = s.post(url, data=data)
[2, 5]
[1, 1, 1, 0, 1, 0, 0, 1],
list(gen())
m = np.log10(np.abs(x))
print(hex(res))
date = datetime(year=int(s[0:4]), month=int(s[4:6]), day=int(s[6:8]))
[lst[i::n] for i in range(n)]
exif_data = img._getexif()
ax.xaxis.set_major_formatter(date_format)
role = models.CharField()
self.__addL__[self.number][x]
container.grid_rowconfigure(0, weight=1)
issubclass(B, A)
self.response.out.write(json.dumps(response))
s.add(item)
max(depth(self.left), depth(self.right)) + 1
myprocess.kill()
sys.stdout.write(sio.getvalue())
self.parent.x
datetime.now() + relativedelta(weekday=FR(-1))
plt.show()
manager.start()
sys.executable
f(x)
graph = facebook.GraphAPI(oauth_access_token)
console_handler.setLevel(logging.DEBUG)
match = next((x for x in a if x in str), False)
[0, 0, 1, 1, 0, 1, 1, 0],
plt.plot(x, y)
zip(x, y, z)
id9, Wood, moreinfo9
show()
print(etree.tostring(elem, pretty_print=True))
x[0][0][1] = 111
cv2.waitKey(0)
gimpfu.main()
form.save()
PREPEND_WWW = True
doc = etree.fromstring(xml)
array([np.linalg.solve(x, identity) for x in A])
self.append(x)
[x for x in a if x.size > 0]
AllItems = [QComboBoxName.itemText(i) for i in range(QComboBoxName.count())]
q.interruptable_get()
np.random.choice(elements, 10, p=probabilities)
plt.plot(xdata, ydata)
all(is_okay(s) for s in some_array)
rect.set_height(h)
dict(urlparse.parse_qsl(urlparse.urlsplit(url).query))
screen = pygame.display.set_mode((500, 500))
name = module.name
soup = BeautifulSoup(html)
np.nanargmax(a, axis=0)
imobj.set_data(img)
dict((k, [v[1] for v in vs]) for k, vs in itertools.groupby(l, lambda x: x[0]))
fig = plt.figure()
ax = plt.gca()
plt.fill([0, 0, 1, 1], [0, 1, 1, 0])
Image.objects.all().large().portraits()
response
np.dot(a, b)
ax.scatter(x, y, z)
ax.set_zlim(z_min, z_max)
f.close()
a = np.random.rand(10, 10)
df1.reset_index(inplace=True)
port = s.getsockname()[1]
my_list = [tuple(i) for i in my_list]
print(df.sum().to_frame())
sum(letterGoodness[c] for c in yourstring)
bool(array)
p = (b - a) * p + a * p.ceil()
pl.show()
draw()
Column(id_column_name, UUID(), primary_key=True, default=uuid.uuid4)
main()
writes.writerow(x)
f.writelines(mylist)
checkbutton.grid(row=1, column=0)
im.show()
isinstance(gen, types.GeneratorType)
print(twenty.data[958])
max_product = max(mul(*l[:2]), mul(*l[-2:]))
df = pandas.DataFrame(data)
logger.addHandler(dh)
conn.send(data)
logger.addHandler(handler)
board[x, y]
win = tk.Toplevel(root)
list(zip(*G))[0]
size = win.window.get_size()
layout.addWidget(self.edit)
df.replace([np.inf, -np.inf], np.nan)
plt.figure(1)
np.min(np.nonzero(np.hstack((A, 1))))
y = [a for a in x]
db = MySQLdb.connect(self.server, self.user, self.passwd, self.schema)
soup = BeautifulSoup(driver.page_source)
np.unique1d(np.floor(10000000.0 * x) / 10000000.0)
b[0].append(1)
l1.remove(x)
lambda s: int(s) if s.isdigit() else 0
[mean(cluster) for cluster in cl.getlevel(2)]
GST_VERSION_MAJOR,
df2 = df[df.dte < lastyear].head(depth)
[iter(l)] * 2
site.addsitedir(self.install_lib)
self.ui.PoseBtn_GridLayout.addWidget(self.button, 0, 0, 1, 1)
ax2.yaxis.set_major_locator(MaxNLocator(nbins=len(ax1.get_yticks())))
a = np.arange(100).reshape(10, 10)
q.close()
sum(args)
ax = fig.add_subplot(111)
max(dict_depth(v, depth + 1) for k, v in d.items())
browser.get(url)
a = np.random.randint(0, 2, (10, 8))
set(a) == set(c)
compat.register()
os.close(f)
x[1::2]
df.divide(df.sum(axis=1), axis=0)
mylist = mylist[2:-2]
b[b > 0]
trimmed.setdefault((k[0], k[-1]), []).append(v)
plt.xlim(bins[0], bins[-1])
file.seek(0, os.SEEK_END)
f.apply(clean, axis=1).reindex(f.index)
fct()
list(theDict.keys() & theList)
source_file.readline()
dct = defaultdict(list)
street = models.CharField(max_length=100)
print(os.getegid())
B = A[([0, 2]), :, :][:, :, ([1, 2])]
temp_file.close()
time.sleep(1)
df_a.merge(df_b, left_index=True, right_index=True)
w.menuBar().addMenu(menu)
a[a < 0] = 0
ax = fig.add_subplot(111)
dosomethingelse
sorted(list(scores.items()), key=itemgetter(1), reverse=True)
mapping[frozenset(list(d.keys()))](**d)
aaa()
t_points = t_image[[t_pos[:, (1)], t_pos[:, (0)]]]
random.shuffle(charlst)
stdin.close()
plt.legend(scatterpoints=1)
ax = fig.add_subplot(1, 1, 1)
list(set(seq))
print(calendar.month(tgtdate.year, tgtdate.month))
ip = models.CharField(max_length=200, blank=True, db_index=True)
plt.gca().get_xaxis().get_major_formatter().set_useOffset(False)
s.seek(0)
(df * weights).sum(1)
logger.addHandler(logging.StreamHandler())
len(set(in_list)) == len(in_list)
[(L1[i] + L2[i]) for i in range(min(len(L1), len(L2)))]
self.connection.commit()
sub_df.iloc[0]
zip(*([it] * 2))
foo()
__init__.py
frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
answer.append((key, len(list(iter))))
(4, 5, 6) > (1, 1, 1, 9)
os.setsid()
seen = set()
ax2 = fig.add_subplot(2, 2, 2)
Simulation.mocked_method
plt.show()
combs = [i for j in range(1, len(atom) + 1) for i in combinations(atom, j)]
select_indices = np.where(np.logical_or(x < 1, x > 5))
print(line)
draw.ellipse((x - r, y - r, x + r, y + r), fill=(255, 0, 0, 0))
f.write(new_text)
x.subs([(y, z), (x, y)])
inset.set_xlim(inset_xlimit[0], inset_xlimit[1], auto=False)
float(p[1] - b[1]) / float(p[0] - b[0]), p[0] < b[0]
startupinfo.dwFlags |= _subprocess.STARTF_USESHOWWINDOW
f.write(s)
now.timetuple().tm_isdst
set(a) == set(b)
list(product(x, flatten(y)))
list(set(array2))
MyList = [inst1.i, inst2.i]
self.send_result
app = wx.PySimpleApp()
RNA_integers = [RNA_dictionary[i] for i in RNA_list if i in RNA_dictionary]
print(twenty.data[0])
tgt.close()
dict((k, json.dumps(v)) for k, v in list(json.loads(val).items()))
x1, y1, x2, y2 = itertools.repeat(0, 4)
res.append(count)
ssh = paramiko.SSHClient()
print(os.path.join(root, f))
pprint.pprint(dataDict)
reactor.stop()
array([[14, 22], [46, 54]])
app = wx.App(redirect=True)
(2, 2, 10, 10), (12, 8, 2, 10)
fxn()
screen.update()
print(list(go(iter(lst))))
self.foo.kill()
x = np.arange(100)
sess.run([sparse_update])
A[c1b, r1b], A[c2b, r2b] = A[c2b, r2b], A[c1b, r1b]
t.selection_get()
tornado.ioloop.IOLoop.instance().start()
fig = plt.figure()
sys.stdout.write(session.recv(4096))
[[next(a_iter) for _ in range(n)] for n in b]
a[np.ix_(index, index)]
sum(range(start, start + n))
0, 0, 0, 0 | 0, 1, 0, 1, 1, 0
newdf.iloc[:10, :5]
p.kill()
print(func.__name__, args, kwargs)
data[:size]
f.write(r.content)
plt.show()
plt.show()
set(a)
print(a.data.nbytes + a.indptr.nbytes + a.indices.nbytes)
pygame.quit()
print(json.dumps(tree, indent=4))
h.setdefault(x, []).append(y)
time.sleep(1)
np.intersect1d(b1, a)
print([dict[i] for i in dict if dict[i] >= x])
screen.exitonclick()
name = models.CharField(max_length=150)
print(match.groups())
x1 = y1 = x2 = y2 = 0
print(t.timeit(number=1))
self.emitter.append(e)
self.platforms.append(e)
ax.set_xlim(xbnds)
s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
df.to_csv(s)
a.sort(key=lambda d: list(d.values())[0], reversed=True)
result_dict.setdefault(x.key, []).append(x.value)
self.button.clicked.connect(self.handleButton)
dic[i].append(j)
time.sleep(1)
eval(command)
cmap = mcolors.ListedColormap([(0, 0, 1), (0, 1, 0), (1, 0, 0)])
connection.close()
plt.clf()
x = [[i] for i in range(10)]
[len(set(i)) for i in data.reshape(data.shape[0], -1)]
print(repr(html_to_text(html)))
setup.py
list.append(run(i[0], i[1], i[2]))
platform.system()
self.Raise()
min(timeit.repeat(lambda : dict([(k, v) for k, v in zip(keys, values)])))
plt.xlim(0, 9)
str(self.i)
reversed(lines)
map(functools.partial(f, y=fixed), srclist)
stdout_thread.start()
a.reshape(a.shape[0] // n, n, a.shape[1]).sum(1)
self.button.Bind(wx.EVT_BUTTON, self.OnButton)
the_frame = pd.read_sql_table(name_of_table, engine)
pickle.dump(data, fp)
ax.set_yticks(numpy.arange(0, 1.0, 0.1))
grouped.sort(key=itemgetter(1), reverse=True)
a.close()
heapq.heappush(heap, (-prod1, x - 1, y))
fruit = [df.columns[row.astype(bool)].tolist() for row in df.values]
args = parser.parse_args()
self.canvas.scale(ALL, x, y, self.scale, self.scale)
limit = int(limit)
window = gtk.Window()
chris.userprofile.followed_by.all()
renormalize = true
keys = [k for k in scores if scores[k] == scores[key]]
cursor.execute(sql)
[{k: d[k]} for k in sorted(d)]
driver = webdriver.PhantomJS()
(lambda j: lambda x: x == j or x % j != 0)(i)
z = a[0] * b[1] - a[1] * b[0]
main.py
d = dict(matches)
subprocess.call(cmd)
[dic[k] for k in sorted(dic)]
plt.imshow(img)
self._id = uuid1().urn
termios.tcsetattr(sys.stdin, termios.TCSADRAIN, orig_settings)
dbQueryModel.itemData(treeView.selectedIndexes()[0])
bp.stdout.readline()
frame.grid()
iter(self.books.values())
min(zip(Lat, Lon), key=operator.itemgetter(1))[0]
ax.set_xticks(np.arange(-0.5, width, 1), minor=True)
print(sys.argv[0])
pivots = np.zeros((m, n), intc)
GF4(self.__addL__[self.number][x])
list(groups.values())
plt.figure()
time.sleep(0.5)
ax.autoscale()
cap.release()
[5, 5, 5, 4]
print(np.arange(100).nbytes)
print(df.head())
y.reshape(2, 1) - x
self.urls_seen.add(request.url)
self.send_blob(blobstore.BlobInfo.get(blob_key), save_as=True)
TRUE = 1
setattr(fundamentalconstants, name, value)
plt.scatter(X, Y)
do_something_with(x)
sns.distplot(a, bins=list(range(1, 110, 10)), ax=ax, kde=False)
QMainWindow.__init__(self, parent)
np.allclose(df_norm.values.dot(coef), pca.fit_transform(df_norm.values))
my_dict[k].append(dict1[k])
[i for i in mysites if i not in list(sites.keys())]
chr(65)
pyplot.plot(x, y)
[index_dict[x] for x in b]
p.get_open_files()
logger.addHandler(handler2)
x = np.asarray(x)
all(c in string.hexdigits for c in s)
m = coo_matrix((values, (row, col)), shape=(nrows, ncols), dtype=float)
QtGui.QMainWindow.eventFilter(self, widget, event)
fig, ax = plt.subplots(ncols=2)
print(G.edges())
plt.plot(x, y)
x.append(l)
models.ForeignKey.__init__(self, User, null=True, **kwargs)
zip(a, b)
main.config.from_object(config)
cPickle.load(f)
s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
plt.plot(freqs[idx], ps[idx])
ax2.set_ylim(0, 2)
print(info.get_content_type())
sum(scipy.stats.hypergeom.pmf(k, N, M, Q) for k in range(1, Q + 1))
db.model_to_protobuf(your_entity)
list(combinations(x, 2))
zip(l, combinations(reversed(l), len(l) - 1))
self.send(message)
plt.show()
fig = plt.figure()
x.split()
client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
new_array = new_array.reshape(old_array.shape)
data = data[~np.isnan(data).any(axis=1)]
child.sendline(mypassword)
print(int(x))
pygame.draw.rect(game_display, (0, 0, 0), rect_old)
DEBUG = True
np.argmin(abs(f2 - f1))
regex.findall(string)
ax.plot(x, x)
chmod + x / home / randy / lib / python / gbmx.py
L1 = [[0, 50], [7.75, 120], [10.25, 70], [17, 100], [20, 60]]
mat_array = cv.fromarray(numpy_array)
round(2.675, 2)
s = p.sub(process_match, s)
sum(range(a + a % 2, b + 1, 2))
pd.DataFrame(d)
dict_.update((prefix, value) for prefix in prefixes)
rotn = np.degrees(np.arctan2(y[:, 1:] - y[:, :-1], x[:, 1:] - x[:, :-1]))
gui.root.mainloop()
Foo()
numpy.arange(11, 17, 0.5)
list.append([])
myarray[x.group(1)] = [x.group(2)]
driver.set_script_timeout(10)
app.MainLoop()
do_something(f.result())
app = QtGui.QApplication(sys.argv)
lambda _: f()
image = Image.open(data)
limitx = random.choice([0, 1])
list(range(string.ascii_lowercase))
b = np.identity(A.shape[2], dtype=A.dtype)
q = mp.Queue()
ax = fig.add_subplot(111)
nx.traversal.dfs_successors(G)
sys.stdout.write(out)
db, host, user, password = user_list[0]
self.sizer.Add(self.canvas, 1, wx.LEFT | wx.TOP | wx.GROW)
{k: v for k, v in list(d.items()) if k not in excluded_keys}
max(len(i[j]) for i in x)
df.index[(df == window_stop_row).all(axis=1)]
result[-1].append(thetext)
[max(min(x, 255), 0) for x in oldList]
QtWebKit.QWebView.__init__(self)
ssl.OPENSSL_VERSION
root.mainloop()
[self[i] for i in index]
plot_date(a, 2)
df.columns
bar()
passer()
merged[k].append(d2[k])
print(d[2])
start_response(status, headers)
now = datetime.datetime.now()
form
print(a)
wordslist = line.split()
palette.set_bad(alpha=0.0)
display(fig)
c_mat1 = np.tensordot(Q, a1, axes=([-1], [0]))
start_time = time.time()
p.join()
traceback.print_exc()
data[0, 0] = [1, 2]
area = cv2.contourArea(contour)
numpy.random.seed(1)
df
locale.currency(float(cents) / 100.0)
plt.show()
dict(d)
profile = webdriver.FirefoxProfile()
bar(ind, num, width, color=colors)
ax.xaxis.set_major_formatter(daysFmt)
app.run(debug=True)
subprocess.call(cmd, shell=True)
plt.show()
print(tailq.get_nowait())
ws.cell(row=1, column=1).hyperlink = link
Response(status=204)
self.origstream = sys.stdout
Entry.objects.bulk_create([Entry(name=x) for x in a])
list(product(*map(lambda x: list(range(x[0], x[1] + 1)), args)))
Row(**OrderedDict(sorted(row_dict.items())))
plot.append(axE)
plot.append(axPA)
writer = csv.writer(output)
cast(a, POINTER(c_int))
lst[-1:] + reverse(lst[:-1])
p.start()
tk.Tk.__init__(self, *args, **kwargs)
main(sys.argv)
Qt.QFrame.paintEvent(self, event)
IOLoop.current().run_sync(runner)
print(m.group(1))
app = Flask(__name__)
plt.plot(X, Y)
print(OrderedDict.fromkeys(s))
os.close(sys.stderr.fileno())
self.figure.set_facecolor((1, 1, 1))
win.mainloop()
writer.writerow(out)
x = np.linspace(0, 2 * np.pi, 100)
1j * numpy.inf
area = img.crop(box)
time.sleep(1)
f2.write(line)
grid.grid(sticky=N + S + E + W, column=0, row=7, columnspan=2)
f128 = numpy.frombuffer(file.read(16), dtype=numpy.float128)
ssh.connect(host, username=username, password=password)
self.est.predict_proba(X)[:, (1)]
np.tile(v, (1, 2))
[dict(zip(columns, row)) for row in cursor]
np.cumsum(a, out=a)
id = db.Column(db.Integer, primary_key=True)
session.query(QuerySchema).filter(QuerySchema.way.ST_Within(bbox))
MyObject = MyClass()
listbox.pack()
self.set.add(d)
fib(n - 1) + fib(n - 2)
new_dict = dict(zip(keys, values))
Counter(chain.from_iterable(map(str.split, f)))
a, b = map(int, input().split())
o.writerow(line.split())
map(lambda x: int(255 * x), (r, g, b))
np.arange(0, 1, 0.1)
list(it1)
reduced_list = [x for x in full_list if not omit.intersection(x)]
app.register_blueprint(child2.child2)
someList.sort(key=key1)
line = line.strip()
abs(numpy.array([0.24])[0] - 0.24) < numpy.finfo(float).eps
plt.show()
print(newcorpus.sents(newcorpus.fileids()[0]))
self.root.destroy()
random.shuffle(x)
wtr.writerow(r)
os.chdir(prev_cwd)
EMAIL_USE_TLS = False
process.stderr.close()
cursor.close()
df1[ind].append(df2[ind])
KillerApp().run()
print(hashlib.sha1(json.dumps(a, sort_keys=True)).hexdigest())
driver = webdriver.Remote(desired_capabilities=options.to_capabilities())
b[0].append(1)
k[np.in1d(list(map(np.ndarray.dumps, k)), list(map(np.ndarray.dumps, k2)))]
new_x = itertools.chain(y, x)
print(np.array_equal(A, C))
list(d.values())
imshow(img, zorder=0, extent=[left, right, bottom, top])
sys.exit(0)
app.mainloop()
p.wait()
time.sleep(1)
args = parser.parse_args()
t.start()
blobstore.delete(key)
emonth1.grid(row=1, column=2)
re.findall(str_in_doublequotes, text)
plt.colorbar()
[a, b] = [1, 2]
[x for x in individual(nest)]
numpy.random.seed(29)
conn.response()
pyplot.show()
np.savetxt(myfile, sample_array)
ax2.set_yticks(y_tick * np.pi)
ax.set_xlim(-5, 100)
main_menu.display()
content = fp.read()
axr.set_ylim(altitude.min(), altitude.max())
full_df = pd.concat(dfs)
path = os.getcwd()
tree = etree.ElementTree(root)
df2.boxplot()
tf.mul(scale, x)
gc.collect()
list([val for val in range(10) if val & 1])
deletetup[0]
my_file.close()
setattr(obj, name, value)
str(self)
reactor.run()
self.handler = logging.StreamHandler(self.stream)
print(dict(re.findall(r, z)))
root.mainloop()
sort(data, key=key, reverse=rev)
response.set_data(soup.prettify())
emailer.send(messages)
list2 = [int(y) for y in list(itertools.chain(*[str(x) for x in list1]))]
a[i].append(int(value))
print(sum(chain(n, o, p)))
axes[0].legend(bbox_to_anchor=(0, 0.5))
plt.show()
ax.set_ylim(-1, 7)
[(2, 5), (12, 17), (22, 22), (25, 26), (28, 28), (51, 52), (57, 57)]
pixels = [pixels[i * width:(i + 1) * width] for i in range(height)]
events = list(groupify(lines))
plt.subplot(111)
list(repeat(100, foo))
s2[s2.isin(s1)]
plt.xlim([0, 6])
self.write(self.request.uri)
ldap.set_option(ldap.OPT_X_TLS_REQUIRE_CERT, ldap.OPT_X_TLS_NEVER)
df_out
random.seed()
ax1 = fig.add_subplot(2, 2, 1)
myArray.append(np.array([i, i + 1, i + 2]))
self.category.name
game.init()
root.mainloop()
mlab.show()
print(m.cancel())
np.savetxt(outfile, slice_2d)
counts = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
myDict.setdefault(newKey, []).append(value)
channels = cv2.split(img)
plt.show()
contours, _ = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)
parent_map = dict((c, p) for p in tree.getiterator() for c in p)
l[1::2]
set(map(tuple, map(sorted, pairs)))
ax.xaxis.set_major_formatter(fmt)
self.log.close()
self.config_from_object(app.config)
app.run(debug=True, threaded=False)
union([(10, 12), (14, 16), (15, 22)])
print(PixelAt(int(sys.argv[1]), int(sys.argv[2])))
id = db.Column(db.Integer, primary_key=True)
event.widget.pack_forget()
a = fig.add_subplot(1, 2, 2)
np.intersect1d(amem, bmem).size
scores.ffill().sum(axis=1)
proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
s.close()
m.save()
wb = openpyxl.load_workbook(filename=file)
outarr[x1to:x2to, y1to:y2to] = inarr[x1fr:x2fr, y1fr:y2fr]
np.where(M == 0)
a2.ravel()[:] = [tuple(l) for l in m.reshape(2, -1).T]
ttk.Radiobutton(self.mainframe, value=1).grid(column=2, row=2)
filtered_list = [x for x in your_list if all(f(x) for f in filters)]
Base.metadata.create_all(engine)
domain = str(line.strip())
x.a = 2
{file: find_mime_with_file(file) for file in files}
rx.findall(allsorts)
lines = f.readlines()
ax.set_xlim(0.5, ly + 0.5)
pool.map(lambda x: preprocess(x), real_preds)
assert response.status_code == 200
dest = dict(chain(list(orig.items()), list(extra.items())))
Toplevel.__init__(self, parent)
lines.append([(x, lastY), (x, y)])
foo(x, y)
plt.show()
print(np.all(A[a_to_b] == B))
draw.rectangle(bbox, outline=(0, 255, 0))
repr(tst2)
s.set_missing_host_key_policy(paramiko.AutoAddPolicy())
[0, 1, 0, 0, 1, 0, 1, 0],
f.close()
opener = urllib.request.build_opener()
df[df.one.isin(checkList) | df.two.isin(checkList)]
datetime.date(datetime.now()).isocalendar()[1]
d = defaultdict(int, zip(list(range(1, 10)), list(range(50, 61))))
B().a()
term_appearance = Counter(chain.from_iterable(texts_list))
layout.addWidget(self.canvas)
l = [item for sublist in list for item in sublist]
data = data.reshape(data.size / 2, 2)
func.__code__.co_varnames
PyErr_Print()
conn2 = psycopg2.connect(dsn2)
x.argsort().argsort()
is_active = True
plt.clf()
self.sock.close()
signal.signal(signal.SIGINT, handle)
os.symlink(pythonapp, newpython)
file = models.FileField(upload_to=get_random_filename)
kmeans.fit(p_df)
bin(a ^ b)
pos = emcee.utils.sample_ball(mean, np.sqrt(np.diag(C)), size=Nwalkers)
driver = webdriver.Firefox(firefox_profile=profile)
os.system.__module__
pd.crosstab(df.gender, df.doctor)
urllib.request.install_opener(opener)
all(x < y for x, y in zip(L, L[1:]))
paired_sorted = sorted(rev_sorted, key=lambda x: x[0])
q.T.reshape(-1, 2, 2).swapaxes(1, 2).reshape(-1, 2)
cache._cache.flush_all()
ax.plot(data2)
cv.create_rectangle(10, 10, 50, 50)
df[df.genre.map(iscomedy)]
sum(sys.getsizeof(x) for x in s)
connection.close()
kurt = kurt.T
profile = request.user.get_profile()
zusers = bcolz.ctable.fromdataframe(users)
my_num = int(f.read(1))
MyApp().run()
Done
next(it1)
print(np.linalg.det(A))
json_data_rdd.flatMap(lambda j: processDataLine(j, arg1, arg2))
p.stdin.close()
zip(*[L[i::4] for i in range(4)])
result_df = json_normalize(my_list).T
list(accumulate(example_list, add))
ax = self.figure.add_subplot(111)
person = models.ForeignKey(Person)
s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
list_a = [1, 2, 4, 6]
b = a.transpose()
__init__()
plt.show()
v.append(n)
np.take(arr, inds)
now_plus_10 = now + datetime.timedelta(minutes=10)
a = datetime.datetime.now()
G.add_nodes_from([1, 2])
__init__.py
writer = csv.writer(f)
print(df.loc[mask])
f(x, y, z)
j_obj = json.load(j)
pylab.figure(figsize=(20, 9))
{{nhl_form.league}}
dict(alist[i:i + 2] for i in range(0, len(alist), 2))
f()
pygame.display.update()
profile.user.save()
df.loc[df.name].tail(2)
Node.objects.get_queryset_descendants(my_queryset, include_self=False)
self.panel.Bind(wx.EVT_CHAR, self.OnKeyDown)
t.start()
df
thread.start()
plt.setp(xticklabels, visible=False)
list(t)
tobin(x / 2) + [x % 2] if x > 1 else [x]
subprocess.call(args, stderr=subprocess.STDOUT, stdout=f)
logger.setLevel(logging.INFO)
self.table.setItem(1, 0, QtGui.QTableWidgetItem(self.led.text()))
someClass.doSomething()
df.columns = df.columns.astype(str)
pylab.gca().add_patch(arr)
print(etree.tostring(tree))
regex.match(string)
a.result() + b.result()
tk.Frame.__init__(self, root)
f.write(s.getvalue())
f.seek(0, 2)
self.out_file.close()
a.print_x.__func__(b)
print(s[:])
f = np.array([(df * n if n < N / 2 else df * (n - N)) for n in range(N)])
my_dict = {x: (x ** 2) for x in range(10)}
print(json.dumps(doc.reprJSON(), cls=ComplexEncoder))
g.username = user.name
file.close()
p.stdout.close()
[os.path.join(*choices[:i + 1]) for i in range(len(choices))]
print(row[0])
fig = plt.figure()
{c: counter.get(c, 0) for c in chars}
sys.path
do_stuff()
client_name = models.CharField(max_length=400)
laplace_k = make_kernel([[0.5, 1.0, 0.5], [1.0, -6.0, 1.0], [0.5, 1.0, 0.5]])
list(it.product(x, mit.collapse(y)))
fun(*args, **kwargs)
type(s)
m_action2.perform()
ax = self.figure.add_subplot(111)
process.kill()
timezone.localtime(timezone.now())
mz = np.indices(IRtest.shape)[0]
width, height = img.size
c.append(a[index])
df.ix[idx]
config.write(configfile)
main()
cur.close()
gp1.iloc[0].values
fig = plt.figure()
fsizer.Add(self.stext, 0, wx.ALL)
pickle.dump(selfref_list, output, -1)
start_response(status, response_headers)
auser = self.auth.get_user_by_session()
print(list(takewhile(lambda x: bool(x.strip()), v)))
np.dot(J, mat)
df = pd.DataFrame(list(BlogPost.objects.all().values()))
response = urllib.request.urlopen(url)
all_pairs += [((nA, 0), (nC, 2)) for nA, nC in itertools.product(listA, listC)]
result[nI] = v2[nI]
smtp.quit()
os.dup2(savout, 1)
a = a & b
{{(user | hash): item}}
print(tmp)
pd.concat((df1, df2), axis=1)
mydict_as_string = cPickle.dumps(mydict)
print(str(mytuple)[1:-1])
queryset = Profile.objects.filter(condition)
fig, ax = plt.subplots(1, 1)
plt.subplot(122)
print(yaml.dump(a, default_flow_style=False))
parameters(my_get_params)
get_lineage(dt, df.columns)
my_list = [item for item in range(10)]
strided(a, shape=((a.size + n - 1) // n, n), strides=(n * s, s))[:, 1:]
self._app(environ, log_response)
f.seek(2)
len(a)
time.sleep(1)
plt.rcParams.update(params)
QtCore.QAbstractTableModel.__init__(self, parent)
plt.hexbin(x, y)
self.right.extend(self.left[0:x])
shallow_copy_of_set = set(old_set)
clf.fit(K, y)
ax.xaxis.set_major_locator(dates.MinuteLocator())
fig, ax = plt.subplots()
image_file_size = img_file.tell()
QtCore.Qt.ItemIsEnabled | QtCore.Qt.ItemIsSelectable | QtCore.Qt.ItemIsDragEnabled | QtCore.Qt.ItemIsDropEnabled
pri()
self._decks = []
object_list.append(new_element)
sleep(10)
Feed.objects.update_one(push__posts=post)
s.ix[x:y].asfreq(BDay()).count()
print(arr[[1, 2], [0, 1]])
user = models.ForeignKey(User, unique=True)
image.show()
os.symlink(src, dst)
txt_frm.grid_rowconfigure(0, weight=1)
np.sum(a == b)
result.extend(flatten_to_strings(i))
sl = slice(0, 4)
self._display.sync()
[datetime.datetime(2012, 1, 2, 0, 0)],
frozenset(itertools.chain.from_iterable(args))
next(i for i, string in enumerate(strings) if substring in string)
other_work()
func(*args, **kwargs)
curses.wrapper(MyApp)
self.name = name
convert_A_to_B(sys.stdin, sys.stdout)
time.mktime(utc_dt.timetuple())
infile.seek(0)
self.process.run()
output.append((num, val))
datetime.date(int(a[:4]), int(a[5:7]), int(a[8:10]))
result = [x for k, v in list(d.items()) for x in k * v]
print(cursor.bindnames())
{{(value | currency): request.session.currency_type}}
execute(sys.argv[1])
fh.readlines()
allmodules = [sys.modules[name] for name in modulenames]
t.to_datetime()
fact2 = dd0 * dd0 / 2
c.append(int(digit))
somelist = [i for j, i in enumerate(somelist) if j not in indices]
[fac(n) for n in nums]
app
index_file.write(template.render(index_variables))
numpy.float64(1.0) / 0.0
f.close()
np.issubdtype(np.bool, np.integer)
a[ind]
{{test | safe}}
tuple(f())
self.data = data
flipbf(m).swapaxes(1, 2)
times = [match.group(1) for match in pattern.finditer(ifile.read())]
states.split()
func()
np.argmax(np.mean(complete_matrix, axis=1))
sys.exit(app.exec_())
df_test = df_test.apply(sizes, axis=1)
a = [0, 1, 0, 1, 0, 0, 0, 0]
ax.grid(True)
shutil.copyfile(source_path + file_name, dest_path + file_name)
app = Flask(__name__)
p.stdout.flush()
self.__name__
conn.send(msg)
print((k, v))
np.rollaxis(result, 0, result.ndim)
ok = models.BooleanField(null=False, default=True)
print(sys.maxunicode)
Py_Finalize()
plt.clf()
data_mean = pd.rolling_mean(data, window=5).shift(-2)
print(bar.x)
elevation[elevation > 0] = numpy.NAN
list(range(start, stop + 1, step))
print(add_number(A))
cube = numpy.array(list(itertools.product((0, 1), (0, 1), (0, 1))))
args = parser.parse_args()
locale.setlocale(locale.LC_COLLATE, newone)
a * b[:, (np.newaxis)]
handles, labels = ax.get_legend_handles_labels()
dir(nltk.corpus)
plt.gca().add_artist(scalebar)
s.connect((host, port))
self.stop.grid(row=4, column=1, sticky=EW)
Str = random.randomint(1, 18)
print(df1.to_string())
c = np.array([[1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 1, 0]])
G = np.array([[0, 0, 0, 0], [1, 0, 0, 0], [1, 1, 0, 0], [1, 1, 1, 0]])
manager.connect()
plt.show()
print(rf.predict([testdataset[-1]]))
django.setup()
[i for i in x]
Food._meta.get_all_related_objects()[0].model
[list(range(2, 6)), list(range(12, 18))]
ax.pcolormesh(theta, r, Z)
hb2 = plt.hexbin(x2, y2, norm=norm)
[Factorial(x) for x in arg]
response
f.write(template)
print(link.text.strip()[5:])
ax = fig.add_subplot(111)
PyEval_SaveThread()
numbers = map(int, s.split())
signed_number = ctypes.c_long(number).value
text.set_rotation(90)
joe(joe(joe({}, myTupleList[0]), myTupleList[1]), myTupleList[2])
setp(ax1.get_xticklabels(), fontsize=6)
time.sleep(1)
myNames = f.readlines()
logger.addHandler(fh)
o.a = 2
app.SetTopWindow(frame)
plt.show()
B = matrix(expm(A))
print(f(1))
x[1]
stdscr.getch()
2 * a + b
vbox1.addWidget(self.edit2)
progbar.pack()
main()
result_dict[str(len(word))].append(word)
logging.root.setLevel(logging.DEBUG)
data = request.GET
between1(b[0], p[0], q[0]) and between1(b[1], p[1], q[1])
myDict[key] += val
flt = np.array([x for x in lrg if x == 0])
print(s[i:])
im2, = ax2.plot(image[0:time, (5), (5)])
Obj2.grid_forget()
result = list(DBProcessor().get_listings())
res += [os.path.join(root, d) for d in dirs]
cap = cv2.VideoCapture(0)
dict.fromkeys(s, 0)
app.register_blueprint(mod)
cur.close()
sys.exit(app.exec_())
x = np.arange(len(df.columns))
min(map(lambda x: s.index(x) if x in s else len(s), a))
{{message}}
df
plt.show()
e.save()
find_indices(a, lambda e: e > 2)
nodes[2] = 1
print(regex.group(2))
obj.refresh_from_db()
self.visit_typeA(dataobj)
a = np.array([1, 2, 2, 1]).reshape(2, 2)
user.Setinfo()
html = gzipper.read()
gmpy.divm(1, 4, 9)
dict(dd)
a = str(tag.getArtist())
df.to_excel(writer, sheet_name=sheetname)
main()
app = QtGui.QApplication([])
nlargest(2, tags, key=lambda e: e[1])
response
simplejson.loads(json)
oldest = max(people, key=lambda p: p[1])
sys.exit(EMERGENCY)
result.append([])
opt, args = parser.parse_args()
axes.legend(handles, labels)
unicode_string = byte_string.decode(encoding)
img = Image.open(StringIO(response.content))
app.cgirun()
image = Image.open(picture)
groupby(a, [1])
[groups[k] for k in sorted(groups.keys())]
sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPINTVL, interval_sec)
signal.signal(signal.SIGTERM, self.exit_gracefully)
res = urllib.request.urlopen(req)
setattr(obj, self.name, float(val))
plt.figure()
q = DBSession.query(model.Name).distinct(model.Name.value)
obj.post_set.count()
draw(2, 4, 5)
plt.locator_params(nbins=10)
print(hex(id(x)))
print(dll.get_buf())
p = figure(x_range=(-1, 1), y_range=(-1, 1))
words.flatMap(set).distinct().count()
a = defaultdict(lambda : 1)
sys.exit(0)
print(key, dict[key])
zippend((one_array, two_array), two_outputs())
l[:n]
numpy.set_printoptions(threshold=numpy.nan)
self.label.setMouseTracking(True)
flann = cv2.flann_Index(desc2, flann_params)
m = merge_a_b(a, b)
print([sum(x) for x in itertools.zip_longest(fillvalue=0, *lists)])
sys.exit()
writer = csv.writer(self.response.out)
s = requests.Session()
int_list = [int(x) for x in line.split()]
plt.set_cmap(viridis)
documents = [doc[0] for doc in documents]
print([b(5) for b in bases])
(dt - epoch).total_seconds()
Py_DECREF(result)
sigmoid(W1 * x1 + W2 * x2 + B)
not any(data)
list(zip(A, B * 2))
options, args = parser.parse_args()
{1}.pop()
my_list = [b, a]
cv.SetCaptureProperty(camcapture, cv.CV_CAP_PROP_FRAME_WIDTH, 1280)
(np.diff(sdata) > 0).sum(axis=1) + 1
list(chain.from_iterable(a))
data.append(map(str.strip, row))
id = Column(Integer, primary_key=True)
category = models.ForeignKey(Category)
mail.quit()
pylab.show()
unittest.main()
myDF = pd.DataFrame(data)
self._shape = self._shape[0], self._shape[1] - 1
app
[sum(i) for i in zip_longest(fillvalue=0, *l)]
cursor.close()
listD.append(listC[num])
canvas.grid(row=0, column=0, sticky=N + S + E + W)
x = np.clip(x, 0, 1)
list(itertools.combinations(enumerate(a), 2))
result = np.vectorize(my_dict.get)(a)
type(counts)
coeff, r, rank, s = np.linalg.lstsq(A, B)
admin.site.register(Department, DepartmentAdmin)
c.close()
cleaned = [i for i in map(str.strip, words) if i]
print([element for element in lst])
app = Flask(__name__)
Counter(map(tuple, a))
text = pipe.communicate()[0]
filename = models.CharField(max_length=128)
sock.close()
random.shuffle(l2)
parser.parse_args()
a2D = np.lib.stride_tricks.as_strided(a, shape=(nrows, N), strides=(n, n))
a = [1, 1, 1, 1, 1]
bin_n = bin(int(n))
fig, ax = plt.subplots()
diff(x)
map(a.__getitem__, b)
[0, 2, 6, 7]
matrix[:] = [([0] * len(row) if 0 in row else row) for row in matrix]
pickle.dump(abe, f)
qs_sorted.append(qs.get(id=id))
solution = pd.concat(frames)
myparent = models.ForeignKey(Parent)
sys.path.insert(0, parent_dir)
child.sendline(password)
collections.deque(iterator, maxlen=0)
root.rowconfigure((0, 1), weight=1)
print(x.group(1))
zip(*list_of_values[i:i + len(pattern)])
[item for item in items if item.col2 == 2006]
asyncore.dispatcher.__init__(self)
DataFrame([row for i in range(1000)])
kwargs = {}
isinstance(dict(), collections.MutableMapping)
plt.show()
wr.writerow(mylist)
template = cv2.imread(template_path, cv2.IMREAD_UNCHANGED)
[x[i:i + chunk_size] for i in range(0, chunks, chunk_size)]
plt.colorbar()
mech = mechanize.Browser()
pd.DataFrame(r, i, u)
sys.path
new_list2 = [list2[i] for i in indicies]
output += item[0].upper() + item[1:]
df.join(x)
fib(n - 1) + fib(n - 2)
date_parser = pd.datetools.to_datetime
pylab.show()
func()
pprint(result)
win = gtk.Window(gtk.WINDOW_TOPLEVEL)
list.__setitem__(self, index, value)
suite.sort()
list[i].append(random.randint(0, 9))
print(df.reset_index())
df.loc[[0, 2, 4]]
writer.writerows(zip(*test_data[1:]))
user.put()
4.0 * scipy.integrate.nquad(f, [[0, inf], [0, inf]])[0]
print(dict.setdefault.__doc__)
print(json_data[entry])
main()
[[[1][2]]]
print(e.subs([(a, d), (b, f)]))
fig.clf()
time.sleep(1)
s.bind((TCP_IP, TCP_PORT))
scipy.misc.factorial(6)
db.init_app(app)
gc.collect()
image.paste(ic, box)
groups_no_a = [i for i in groups if a not in i]
QWebView.page().setNetworkAccessManager(myNetworkAccessManager)
print(moneyx)
django.setup()
{{request.user.get_myuser.pretty_username}}
clear()
n = gmpy2.next_prime(n)
plt.scatter(x, y, zorder=1)
max_by_group.collect()
print(next(next(mp.parse_sents([sent, sent2]))))
print(list(myDict.keys()))
self.rect.set_height(self.y1 - self.y0)
wordlist = openedfile.read().split()
do_something(column)
tuple([x for x in map(itemgetter(0), G)])
n.addConnection(bias_to_hidden)
reversed_dict[value].append(key)
plt.figure(1)
manylinux1_compatible = False
os.listdir(long_unc)
cv2.destroyAllWindows()
do_something()
ax.set_xlim(x.min(), x.max())
math.pow(x, y)
B = np.hstack((splits[0], splits[2]))
[x for x in filename if x.isdigit()]
os.path.split(x)[-1]
cursor = cnx.cursor(dictionary=True)
commom = [item for item in list(dict_b.values()) if item in list(dict_a.values())]
print(G.__code__.co_freevars)
unittest.main()
self.show_popup()
print(fin.read())
c.connect((hostn, 80))
df.index = df.index + 1
a / (math.sqrt(2) * erfinv(P))
test.py
plt.step(x, y)
print(cookie)
itertools.zip_longest(fillvalue=fillvalue, *args)
tuple_foo(tuple(a))
os.makedirs(path)
df[:-1]
CoverageACol = array(list(range(10)), dtype=str).reshape(2, 5)
df
plt.show()
ax.plot(x, y)
test = np.array([0, 1, 2, 5, 0])
args = parser.parse_args(sys.argv[1:])
Response(serializer.data)
image.save(output)
np.set_printoptions(suppress=True)
pyhk.addHotkey(SomeHotkey, SomeFunction)
df
[list(range(s, s + step + 1, step)) for s in range(start, stop, step)]
fn(*args, **kwargs)
pygame.quit()
conn.close()
p.start()
nx.draw(G)
walk, walk2 = itertools.tee(walk)
do_code()
out, err = p.communicate()
nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)
do_stuff()
app = QApplication(sys.argv)
curses.endwin()
bar = models.CharField()
data = json.load(f)
sum(int(c) for c in s if c.isdigit())
ws = wb.worksheets[0]
print(columns[0])
Gtk.ContainerClass.list_child_properties(parent)
signal.signal(signal.SIGINT, handler)
ax2.plot(list(range(100)), np.ones(100))
df.loc[df2.index, df2.columns] = df2
print([(k, out[k]) for k in sorted(out.keys())])
self.columnconfigure(10, weight=1)
axclust.set_xticks([])
axcltwo.set_xticks([])
ax.autoscale(False)
self.window.refresh()
curses.initscr()
{{field.errors}}
out.append([])
list(itertools.combinations(keys, 2))
mqtt.client.loop_start()
run_loop_with_timeout()
self.fig.canvas.draw()
most_expensive_cars.append(list(company.cars_by_price.all())[0])
time.sleep(0.1)
yests += [yest]
fileout.close()
[x for x in seq if x not in seen and not seen.add(x)]
str.__init__(self, *args)
print(list(zip(A, i)))
[e] * n
bool(s.intersection(list(someDict.keys())))
sys.exit(1)
{file: check_image_with_pil(file) for file in files}
result.setdefault(v, []).append(k)
self.func()
plt.xlim([0, len(sub_data)])
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
btn.Bind(wx.EVT_BUTTON, self.onDialog)
df
simplejson.JSONEncoder.default(self, obj)
sys.stdout.write(char)
sys.stderr.flush()
int(f) if f.is_integer() else f
cursor.execute(sql)
server.start()
plt.show()
print([eq1] == [eq2])
f.write(contents)
q = B.select().join(A).where(B.date == last_entry_date)
[0.66666667 - 0.66666667]
__DBNAME__[0] = name
dict.__setitem__(self, frozenset((idx,)), value)
items = sorted(list(dct.items()), key=lambda kv: kv[0])
list(zip(a, b, zip(*gr), d))
self.x == p.x and self.y == p.y
df = pd.DataFrame(np.random.randn(10, 6), columns=cols)
p = subprocess.Popen(cmdline, stdout=sys.stdout, stderr=sys.stderr)
parent.config(menu=menubar)
edge_dict[e[0]][e[-1]] += 1
lambda s, *args, **kw: not v(s, *args, **kw)
im = Image.open(filename)
result = list(filter_value(a, 1))
float(x)
gray = img[:, :, (0)]
thread.start()
print(s.query(myTable))
min_obj_set.append(obj)
sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))
app = QtGui.QApplication(sys.argv)
plt.figure(1)
con.commit()
z.close()
y.std()
cert = crypto.dump_certificate(crypto.FILETYPE_PEM, k)
frame2 = cv.QueryFrame(video2)
id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
reader = csv.reader(f)
result[a][b] = n[a][b] - 1
now = datetime.datetime.utcnow()
x
out, err = p.communicate()
evaluate(lambda x: x < 5 and x > -5)
self.y / self.x
random.shuffle(arr)
numpy.std(rolling_window(observations, n), 1)
zip(np.ravel(ix0), np.ravel(ix1), np.ravel(v2))
handle_last_line(last_line)
wm.add_watch(watched_dir, pyinotify.IN_CLOSE_WRITE, proc_fun=MyProcessEvent())
shutil.rmtree(dir)
print((r.status_code, r.reason))
x += y.todense()
ax.figure.canvas.draw()
np.random.shuffle(coordinates)
func(*args, **kwds)
yvalues = line2d[0].get_ydata()
model4.py
print((find_interval(tlist, item) for item in newlist))
sheet.write(0, index, value)
soup = BeautifulSoup(html_object)
np.array([row[:num_cols] for row in arr])
x += datetime.timedelta(1)
print(int(round(random.randint(100, 200001), -2)))
session.add(s)
list(takewhile(lambda i, j=iter(list2): i == next(j), list1))
p.close()
df = pd.concat((ser1, ser2), axis=1)
urllib.parse.unquote_plus(t)
fig = plt.figure()
driver = webdriver.Firefox(firefox_profile=firefox_profile)
array.append([0] * 8)
sys.stdout.write(prompt)
idx = np.argsort(a, axis=1)
proc.wait()
k = [(ord(x) - 96) for x in l]
model.setData(index, editor.currentIndex())
httpd.serve_forever()
[(8, 9), (4, 9), (7, 9)]
drive, path_and_file = os.path.splitdrive(path)
f.write(data)
max(MyCount, key=int)
first_index = match.start()
QtGui.QMainWindow.eventFilter(self, source, event)
ax.set_axis_off()
QtGui.QWidget.__init__(self)
HttpResponse(response, content_type=mimetype[0])
False
plt.plot()
driver.set_window_size(1280, 1024)
{i: (IDsums[itr], value_sums[itr]) for itr, i in enumerate(unqID)}
s = int(s)
json.dump(parse(sys.stdin), sys.stdout, indent=2)
ax.plot([0, normp[0]], [0, normp[1]], zs=[0, normp[2]])
boolarr = np.array([[0, 0, 1], [1, 0, 1], [1, 0, 1]], dtype=np.bool)
app = Flask(__name__)
child.kill()
matrix.data[row].append(column)
to_call(*args, **kwargs)
any(x in mystr for x in ls)
lists = [[] for _ in range(n)]
self.Show()
results = sorted(query.fetch(FETCHED), key=_func)
Counter(data[1]).most_common()
idx[mask].argsort()[unqID]
new_list = [g(f(x)) for x in old_list]
nt = lambda a, b: S[a].intersection(S[b])
db.session.add(provider)
set_column(first_col, last_col, width, cell_format, options)
fin.seek(0)
resp = session.post(url, headers=headers, data=form)
my_data = [[int(val) for val in line.split()] for line in lines_list[1:]]
hand.sort(key=lambda c: rank_cards.index(c[0]), reverse=True)
[hex(c) for c in chars]
wx.ListCtrl.__init__(self, parent, ID, pos, size, style)
df = concat([reader(f) for f in files], keys=files)
img = Image.open(input_path)
dirs = list(set([os.path.dirname(x) for x in z.namelist()]))
pickle.dump(d, afile)
cause
feedback.save()
a = [[0, 0], [0, 0]]
sig1, sig2 = abs(sig1), abs(sig2)
setattr(object, attrname, value)
writer = csv.writer(output, quoting=csv.QUOTE_NONNUMERIC)
element.close()
raise AttributeError()
child.destroy()
pairs = list(my_dict.items())
random.choice([p for p in itertools.product(x, repeat=2)])
deserialized = Data.deserialize(json.loads(json_string))
signal.signal(signal.SIGINT, signal.SIG_IGN)
plt.legend()
auth.set_access_token(access_token, access_token_secret)
df1.add(df2, fill_value=0)
np.random.seed(1)
plt.scatter(x, y)
group.plot(ax=ax[ix], title=i)
setup.py
self.root.mainloop()
{file: mimetypes.guess_type(file) for file in files}
opts = parser.parse_args()
urllib.request.install_opener(opener)
foo.bar()
getattr(self.ham, func)(*args, **kwargs)
[list_a for list_a in list_a if list_a[0] in list_b]
array([[1.0, 0.1, 0.1], [0.09, 1.0, 0.1], [0.2, 0.1, 1.0]])
df = pandas.DataFrame.from_records(data_records)
number = random.randrange(1, 10)
d.setdefault(key, [])
lines.append(line)
w.show()
y_actu = [2, 0, 2, 2, 0, 1, 1, 2, 2, 0, 1, 2]
assert np.allclose(results[0], results[1])
print(set_list_intersection(set_list))
self.save()
soup = BeautifulSoup(html)
plt.scatter(x, y, c=c)
ax.set_ylim(0, 16000)
entry.grid(row=0, column=0)
random.shuffle(a)
g = f()
print(len(locals()))
els = list(d.items())
model.add(Dropout(0.5))
deleteseq[i]
groups.mean().b
writer.writerow(values)
v = myDict[k]
DISPATCH()
ax.add_patch(circle)
hbar.pack(side=BOTTOM, fill=X)
self.get_next_probe(new_list, probes, unit_length)
test()
img = ndi.gaussian_filter(img, (10, 10))
img.show()
fig, ax = plt.subplots()
HTML(df.to_html(escape=False))
Serial.println(a)
df = df.dot(p_value)
X[[[0], [1]], [0, 1]]
browser.set_handle_equiv(True)
m.group(1)
list(islice((x for x in a if x not in bset), 100))
plt.show()
t.start()
np.array([1.0, 1.0]).astype(int)
print(list(request.headers.keys()))
[5, 6, 9]
x + y + z
self.get_type_display()
self.greet()
fp.close()
g.write(base64.decodestring(newjpgtxt))
loads(dumps(input_ordered_dict))
df.end_time = pd.to_datetime(df.end_time)
ax.xaxis.set_minor_locator(FixedLocator(x_da))
fig, axes = plt.subplots(nrows=2, ncols=2)
curs.execute(query, args_tuple)
[(x, y) for x in nums for y in nums]
now = datetime.now()
data = {a: int(float(sum(b)) / float(len(b))) for a, b in list(data.items())}
rates.sub(treas.squeeze(), axis=0).dropna()
list(zip_longest(*a))
app = Flask(__name__)
time.sleep(0.5)
assert len(set(a)) == len(a)
print(hdict_from_dict(data))
s.getsockname()
print(repr(value))
slice = arr[:2, :2]
globals()[lib] = __import__(lib)
print(sock.recv(10240))
raise SystemExit(1)
r.content
print((x.subs(sol[0]), y.subs(sol[0])))
sum(dice) - min(dice)
t.start()
age.__class__.__class__
cur_date += relativedelta(months=1)
datetime.datetime(*time.gmtime()[:6])
response
df.isnull()
myapp.db.session.commit()
print(driver.page_source)
your_list = f.read().split()
self.config(width=self.width, height=self.height)
x = EqM_list(bah * 2 for bah in buh)
reversed_arr = np.fliplr([arr1d])[0]
children.append(node.starargs)
id = Column(Integer, primary_key=True)
dummy_df[cols[cols].index]
[list_[v:indices[k + 1]] for k, v in enumerate(indices[:-1])]
popt, pcov = curve_fit(func, x1, x2)
print([(x, text.count(x)) for x in set(text)])
ax.plot(x, y)
res = {k: coords[nzvals == k] for k in range(1, num_labels + 1)}
pprint(d)
b_any(word in x for x in lst)
stack.append((y0, w0))
list(combinations(list(range(len(sent))), n - 1))
self.root.update()
ao[1:, 1:] += ai[:-1, :-1]
print((b[2][0] == b[2][0]).all())
raise KeyboardInterrupt
new_button.pack()
print(datetime.date.today() - datetime.timedelta(1))
[o for o in gc.get_objects() if isinstance(o, Foo)]
test_trisolve2.test_trisolve()
pool.join()
plot_selected.xaxis.set_ticks(np.arange(0.2, 1.1, 0.2))
req = Request(environ, shallow=True)
f.axes[1].set_position([0.05, 0.45, 0.4, 0.05])
np.random.permutation(indices)
queryset = SomeObject.objects.filter(owner=request.user)
tk.Tk.__init__(self, *args, **kwargs)
first_name, last_name
x, y, z = scipy.sparse.find(a)
permu(l)
plt.yticks(visible=False)
my_handler.setLevel(logging.DEBUG)
fnew = np.empty((Nj, Nk))
worksheet.write(row, col, key)
[bool(x) for x in [[], {}, np.array([])]]
np.interp(np.linspace(0, npt, nbin + 1), np.arange(npt), np.sort(x))
listbox.insert(tk.END, key)
time.time() - time
list(itertools.chain.from_iterable(line.split() for line in f))
str(int(match.group(0)) - 1)
wi.fooi(7)
plt.show()
pdb.set_trace()
app = Flask(__name__)
now = datetime.datetime.now()
df = pd.DataFrame(data)
plt.clf()
np.maximum(a, 0, a)
self.listofrecords.append(record)
Category.objects.filter(child__isnull=True)
f.close()
df = pd.concat([df[:], tags[:]], axis=1)
table = Table(data, colWidths=270, rowHeights=79)
wx.Frame.__init__(self, parent)
models.OneToOneField(EntryAdmin)
result = [i for s in S for i, row in enumerate(X) if (s == row).all()]
Response(serializer.data)
n = sorted([minN, n, maxN])[1]
y = [0.0, 0.5, 1.0, 1.5, 2.0, 2.5]
[1, 0, 0, 0, 0]
dlg.ShowModal()
print(list(flatten_group(b)))
np.broadcast_arrays(*output)
stdscr.refresh()
self.SetTopWindow(mainDlg)
grid = np.zeros((10, 10))
sum(dct[k] for k in lst if k in dct)
main()
self.finish()
location = models.CharField(max_length=25, choices=SHOP1_CHOICES)
[x for x in s if x in printable]
deletearray[0]
B = np.array([[1], [2]])
ax.zaxis.set_major_locator(LinearLocator(10))
new_list
np.alltrue((a == b).compressed())
pretty_xml_as_string = xml.toprettyxml()
fig = plt.figure()
[min(y, max(x, z)) for x, y, z in zip(a, b, c)]
df.eq(df.max(1), 0).astype(int)
[list(v) for k, v in groupby(a, np.isfinite) if k]
pixbuf = gtk.gdk.Pixbuf(gtk.gdk.COLORSPACE_RGB, False, 8, width, height)
pstree - p - a
root.mainloop()
q.write(w)
tree = ET.ElementTree(root)
np.ma.masked_array(np.interp(value, x, y))
sys.path.insert(0, os.getcwd())
outfile.write(json.dumps(output, indent=4))
[a, b, c, d, e]
ts_clip = ts.reindex(idx)
soup = BeautifulSoup(html)
req = urllib.request.Request(url)
map(str, x)
app.mainloop()
browser.set_handle_referer(True)
Process.__init__(self)
self(*args, **kwargs) + other(*args, **kwargs)
distances = numpy.linalg.norm(np_cell[1] - srcPos, ord=1, axis=1)
A = np.arange(600)
stdout_copy = os.fdopen(os.dup(sys.stdout.fileno()), sys.stdout.mode)
thread.start()
random.shuffle(tmp)
x[~np.isnan(x)]
A[:, (j)] = (C[j] * mask).sum(axis=-1)
ynew = np.linspace(0, 1, Newy)
f = open(str(path, encoding))
f.seek(0)
ax.xaxis.set_major_locator(ticker.FixedLocator(pos_list))
print(file.read())
f.write(file_str)
setattr(modelclass, collection_name, (cls, self))
best_index = np.argmin(sq)
calling_func(*args, **kw)
x = defaultdict(int)
process = subprocess.Popen(cmd, stdout=subprocess.PIPE)
cpoints = np.unique(cpoints)
print(name.lower())
print(request.json)
code.interact(local=locals())
output_file.write(line)
hashlib.sha1(bn.T).hexdigest()
img.show()
a[0].append(8)
xs[1::4]
all_data = np.hstack((my_data, new_col))
abacus[index] = abacus[index] + 1
p = Popen(cmd, stdin=PIPE, stdout=PIPE, stderr=PIPE)
p1.wait()
app_log.setLevel(logging.INFO)
numpy.std(arr, axis=0)
hex(x)
sys.exit(0)
main()
glOrtho(0, 1, 0, 1, -1, 1)
the_integers[a:b:c].foo()
time.sleep(10)
new_list_of_dict = map(new_dict, list_of_dict)
sess = tf.InteractiveSession()
time_d.total_seconds()
im = np.asarray(x)
t.start()
f = {x: make_func(x) for x in range(10)}
write(n, 0, 0, 0)
np.arange(n) >= arr[:, (np.newaxis)]
result()
ax1.yaxis.get_offset_text().set_color(plot_ax1.get_color())
A[i], A[j], A[k] = A[j], A[k], A[i]
w.writerow([key, val])
line
data = response.json()
module_b.py
self.Bind(wx.EVT_SIZE, self.on_size)
browser.set_handle_redirect(False)
tcpCliSock.close()
d.tzname()
child.kill()
p_values = scipy.stats.norm.sf(abs(z_scores)) * 2
print(np.asarray((unique, counts)).T)
f.write(bytearray(b))
model.fit(X, Y, nb_epoch=5, batch_size=100, verbose=1)
print(np.flatnonzero(npi.contains([[0, 1]], vals)))
print(pd.get_dummies(values))
print(type(data))
app.run(debug=True)
self.canvas.delete(self.last_img)
plt.subplot(6, 1, 1)
my_dict = obj.__dict__
example.examplemod.do_stuff()
np.random.seed(1)
np.all(a == b, axis=1)
Sensor.__init__(self, *args, **kwargs)
plt.xticks(x, my_xticks)
s = [(e + d) for e in line.split(d) if e]
a.do_something()
test2 = array([[1, 0, 1, 0, 1]])
pygame.mixer.init()
f.close()
get_template(self.template_name)
self._lock.__exit__(*args, **kwargs)
p.start()
subprocess.Popen([command] + args, startupinfo=startupinfo).wait()
[(4 - x, x) for x in range(5)]
sizer.Add(button, 0, wx.ALIGN_CENTER)
unpickler.load()
image_output.seek(0)
setattr(target, attr, value)
self.w.show()
ast.literal_eval(s)
self.setCentralWidget(self.form_widget)
row.append(0)
outfile.close()
print([i for r in ranges for i in range(int(r[0]), int(r[-1]) + 1)])
any(sublst == lst[i:i + n] for i in range(len(lst) - n + 1))
module_object = importlib.import_module(module_name)
assert (np_data == new_data).all()
output = f.read()
co.co_firstlineno, co.co_lnotab, co.co_freevars
f()
totaldict = dict(totaldict)
print(f.read(line_len).decode())
reader = csv.DictReader(csvfile, fieldnames)
pool.terminate()
int(x) if x else 0
idx = np.array([[0, 0, 0], [1, 1, 0], [0, 1, 2]])
head, tail = seq[0], seq[1:]
time.sleep(delay)
print(df)
ss.chisquare(FRQ)
matches = list(compress(totalist, selectors))
pool.map_async(f, args)
app.run()
ECD.close()
True
entries = Entry.objects.select_for_update().filter(author=request.user)
print(sign.getvalue())
B.append(A[0])
plt.contour(X, Y, scalar_field)
raw_xml = etree.tostring(div)
net.params
L[:1], L[1:] = L[-1:], L[:-1]
ax = fig.add_subplot(111)
tf.set_random_seed(1)
print(json.loads(jsonstring, object_hook=hinted_tuple_hook))
db.session.add(query)
s.commit()
results.div(weights, axis=0)
os.path.isdir(path)
s.group(0)
data_file.close()
[d[i] for i in k]
factarr * cplxarr.real + 1j * cplxarr.imag
df.iloc[0, 2] = np.nan
f(*args, **kwargs)
print(filename[0])
print(row[0], binascii.b2a_hex(row[1]))
x[1][0][2]
nx.draw(G, pos, with_labels=False, arrows=False)
plt.xticks(rotation=15)
now = datetime.datetime.now()
msg.attach(img)
y_pred = [0, 1, 0, 1, 2, 2, 1]
plt.axis([-2, 2, -12, 12])
cell = sheet.cell(6, 0)
setattr(self, name, value)
sum((y_pred - y_true) ** 2, axis=-1)
wx.PyControl.__init__(self, parent, id, **kwargs)
self.d.callback(self.buffer)
[99.0, 99.0, 99.0, 99.0, 99.0, 99.0],
aware = naive.replace(tzinfo=utc)
server_ssl.close()
[1, 2]
{y: x for x, y in t}
fliplr(m).swapaxes(0, 1)
stdin, stdout, stderr
window.show()
do_stuff()
f.close()
l.sort()
C = scipy.delete(C, 1, 1)
r = dict(list(a.items()) + list(b.items()) + [(k, a[k] + b[k]) for k in set(b) & set(a)])
shop1()
self.byid[row[0]] = item
input.sort(key=sortkeyfn)
betas.iloc[:5, :5]
print(list(row))
Silly(1)
df.columns = pd.to_datetime(df.columns)
a * b
plt.plot(list(range(10, 20)))
root = tk.Tk()
print([item for items, c in Counter(a).most_common() for item in [items] * c])
writer.writeheader()
r.text
b = map(list, zip(*a))
ax.scatter(x, y, c=z, cmap=cm, norm=norm)
r = proc.stdout.readline()
True
result.append(item)
myarray = np.asarray(mylist)
newList = map(lambda y: max(0, min(255, y)), oldList)
plt.colorbar()
driver.implicitly_wait(20)
print(pool.map(square, range(1000)))
y = np.sin(x)
main()
inspect.isclass(X)
len(self.left) + len(self.right)
res.append(f(v))
out[:-1, :] += tmp[1:, :]
genn(igap, igap + 2)
func2(gen2)
result = []
print(resp.status_code)
plt.show()
ax2.xaxis.set_major_formatter(copy.copy(Formatter))
time.sleep(10)
b = datetime.datetime.now()
id = Column(Integer, primary_key=True)
str(self)
scipy.stats.norm(100, 12).cdf(100)
print(repr(text))
err = p.communicate()[1]
imshow(data)
fcntl.flock(f.fileno(), fcntl.LOCK_EX)
print(a.intersection(b))
df.columns[(df == 0).all()]
grid.cbar_axes[0].colorbar(im0)
app = Flask(__name__)
print(trk.name())
dists.value
imgdata = base64.b64decode(imgstring)
file1.close()
myfile.write(S)
smallerThanN([1, 4, 10, 2, 7], 5)
top.mainloop()
z = {(s[x:] + s[:x]) for x in range(len(s))}
print(f.read())
f.close()
pdf.add_page()
__init__.py
np.concatenate((M, new_face), dim)
sys.exit()
width = img.shape[1]
Py_Finalize()
NULL
seq[-a:] + seq[:-a]
name = models.CharField()
self.harmstat = harmstat
current_child.save()
foo[0][0][0] is foo
getattr(self._ref2, name)
s.connect((HOST, PORT))
cursor.execute(query, param)
time.sleep(1.0)
button1_window = canvas1.create_window(10, 10, anchor=NW, window=button1)
arr = [[] for _ in range(5)]
b = json.loads(a)
myList.sort(cmp_dict)
signal.signal(signal.SIGINT, signal_handler)
print((c, p(c)))
PyObject_HEAD_INIT(NULL)
np.arange(n)
whisper
x = a << 1 & 4294967295
print(paramdata.values)
data = urllib.request.urlopen(url).read()
np.dstack((a1, a1.T)).reshape(-1, 2)
window.fullscreen()
print(sys.argv[1])
f.pack(padx=100, pady=100)
pdf.savefig()
print(re.findall(r, s))
print(my_list)
ax.plot(list(range(10)), color=color)
x = df.reset_index()
pat.findall(text)
conn.close()
plt.xticks(rotation=90)
list_list = [[] for Null in range(2)]
f.write(e)
yappi.start()
print((x, y))
matches = [string for string in l if re.match(regex, string)]
bool(collections.Counter([1]))
i = np.array([[0, 0], [1, 1]])
df.sort_index(inplace=True)
sys.getsizeof(a)
excel.Quit()
plt.tight_layout()
self.canvas.scan_mark(event.x, event.y)
y = tf.slice(x, [i], [1])
wx.BeginBusyCursor()
[math.sqrt(sum([(i * i) for i in vec])) for vec in x]
myproject / myapp / middleware / globalrequestmiddleware.py
s.sendmail(me, family, msg.as_string())
self.mainframe.grid(column=0, row=0, sticky=(N, W, E, S))
my = np.matrix(y)
self.canvas.configure(scrollregion=(0, 0, 1000, 1000))
glfw.WindowHint(glfw.OPENGL_FORWARD_COMPAT, GL_TRUE)
print(channel.recv(1024))
print(trimmed_text)
Listsuper.__init__
random.shuffle(shuffled)
htmlentitydefs.entitydefs[x[1:-1]]
fig, ax = plt.subplots()
shutil.move(tempname, zipfname)
start_time = time.time()
arr_ip = [tuple(i) for i in X.as_matrix()]
sys.stdout.flush()
db.commit()
turtle.mainloop()
Counter(myletters)
df
writer.writerow(fields)
new_file.write(new_line)
datetime.date(2011, 1, 1)
list(df)
QObjectCleanupHandler().add(self.layout())
D = np.diff(np.sort(product.T, axis=0), axis=0) == 0
Notification.objects.exclude(pk__in=list(notes)).delete()
A[(idx), :]
my_list.Skip(1).Concat(my_list.Take(1))
print(data.text)
x = np.linspace(0, 10, 50)
x, y, z = v
deletex[key]
orig_image = Image.open(original_file)
a = np.frombuffer(array_pointer.contents)
ax = fig.add_subplot(111)
print(paragraph.text)
new_a = np.delete(a, index)
self.fileobj.fileno()
c = matplotlib.pyplot.contour(x, y, f(x, y))
c = [tuple([(i + j) for i, j in zip(e, b)]) for e in a]
assert np.allclose(np.dot(P, vec), val * vec)
self.num = 1
df = pd.DataFrame(data)
Py_Initialize()
self.sock.listen(5)
tree.add(0)
server.listen(5)
fig = plt.figure()
df1.index.get_loc(t)
M(**vars(args))
inner1()
data = s.recv(2048)
main()
l.pack()
model.fit(X)
created_at = models.DateTimeField()
output.close()
flipbf(m).swapaxes(0, 2)
root = Tk()
shutdownJVM()
instance.save()
d + (date(d.year + years, 1, 1) - date(d.year, 1, 1))
newList = [elem for elem in oldlist]
dct = dict(zip(l2, lens))
yaml_file.write(yaml.dump(data, default_flow_style=False))
id = Column(Integer, primary_key=True, nullable=False)
sys.stdout.write(format % args)
ax.set_xlim(-0.5, 4.5)
self.assertEqual(first, second, msg)
child.start()
list(incremental_range(0, 20, 1, 1))
np.array_split(a, [1], axis=1)
df.index = pd.to_datetime(df.index)
freq = db.StringProperty()
QtCore.QThread.__init__(self)
print([int(ch) for i in list1 for ch in str(i)])
print((k, list(g)))
print(my_object)
plt.scatter(i, y)
foofunc()
ax.set_ylim(6, 24)
b.append((begin, end))
functest()
os.fsync(f.fileno())
threading.Thread.__init__(self)
(w for w in wordlist if is_neighbors(word, w))
plt.show()
pandas_df_to_markdown_table(infodf)
d[key].append(list(value))
build_cscript()
{{(img.height | div): 2}}
d.update({1})
plt.show()
sizer = wx.BoxSizer(wx.VERTICAL)
dev.ledstates(verbose=True)
arr = input().split()
http_request = get_request()
loss_or_grads = loss_or_grads.mean()
dicC.update(dicB)
x = np.linspace(0, 1, N)
foo()
httpd.serve_forever()
list(self).index(obj)
foo = np.array([[0, 1], [1, 1]])
instance = klass()
pygame.camera.quit()
string_input = input()
env = Environment()
print_foo()
c_uint.__init__(self, value)
crl_url.strip()
ax2 = fig.add_subplot(122)
process.start()
main()
w = Button(root)
fig.canvas.draw()
self.scat.set_offsets(data[:2, :])
_draw_point(renderer, position, i, j + 1)
app.exec_()
df = pd.concat([df[df.columns[:5]], a], axis=1)
np.index_exp[10:4, ::-1, ...]
sys.exit()
content = resp.read()
print(dtd.error_log.filter_from_errors())
contourf(x, y, H1, levels1, cmap=cmap_lin1)
plt.gca().add_collection(lc)
plt.show()
now = time.time()
mask = x == 0
browser = webdriver.Firefox(fp)
fig.subplots_adjust(wspace=0, hspace=0)
fp.close()
pygame.draw.rect(game_display, (255, 0, 0), rect_one)
app.debug = True
inner1d(U.transpose(0, 2, 1), V.T)
test.main()
G = nx.Graph()
plt.show()
abs(x), angle(x)
self.scat = self.ax.scatter(x, y, c=c, s=s, animated=True)
False
plt.plot(np.sin(np.linspace(0, 10, 100)))
TScolumns = pd.DataFrame(df.TimeStamp.tolist())
locale.setlocale(locale.LC_ALL, loc)
G.add_node(1)
a[:i] + MIDCHAR
next(self.iterator)
f.close()
time.sleep(10)
name = models.CharField(max_length=64)
heap_sort()
print(list(range(maxend - maxrun + 1, maxend + 1)))
np.random.seed(1977)
fig, ax = plt.subplots()
reuests.post(url, files=files)
pdb.set_trace()
de[i].extend(j)
sphinx - apidoc - -help
print(functools.reduce(lambda x, y: x & y, [a, b, c]))
f(*args, **kwds)
opener = urllib.request.build_opener()
gc.collect()
np.random.choice(choices, 5, p=counts / len(a), replace=False)
print(hashlib.sha1(bencode.bencode(info)).hexdigest())
do_something(line)
self.stdin.flush()
os.unlink(filename)
pl.show()
plt.xlim([min(data) - 5, max(data) + 5])
admin.site.register(Person, PersonAdmin)
main(sys.argv)
time.sleep(1)
a[0] += 1
list2 = [1, 1, 0, 0, 1]
conn = pymongo.MongoClient()
len(nearbystrikes) > 0
server.starttls()
apos += alo
a, b
pd.read_json(json.dumps(r)).unstack()
u.delete()
transport = ssh_client.get_transport()
id = Column(Integer, primary_key=True)
time.mktime(date.timetuple())
suite = unittest.TestSuite()
self.table.item(1, 0).setBackground(QtGui.QColor(125, 125, 125))
tk.Frame.__init__(self, *args, **kwargs)
setp(ax2.get_xticklabels(), visible=False)
d.apply(pd.value_counts)
{k: (v[0] if len(v) == 1 else v) for k, v in qdict.lists()}
np.where(y == 0, 0, x / y)
deletelist_2[int(i)]
help(window.set_position)
[5] * 4
simulations_to_run.join()
s.connect((TCP_IP, TCP_PORT))
print(df.head())
df = pd.DataFrame()
iren.Start()
s.starttls()
self.driver = webdriver.Firefox()
d1.update(d2)
ranges.append((1, 10))
4.0 * scipy.integrate.nquad(f, ([0, d / 2], [0, d / 2]))[0]
myDictionary.get(key)
[1, 2, 5, 6, 7, 10]
json.JSONEncoder.default(self, obj)
p = pyaudio.PyAudio()
ax.set_xlim([-2, 2])
t.start()
app = QtGui.QApplication(sys.argv)
cheese = args.three
np.argsort(x)
os.setsid()
query_set.filter(deleted_at__isnull=True)
getattr(c, m)()
seen.add(x)
f = x.decl()
numpy.random.bytes(length)
label.pack()
a *= a > 0
tree = lxml.etree.fromstring(doc)
loop.run_forever()
print(len(lines))
kmdistance = float(kmdistance)
bitmap = gtk.gdk.Pixmap(win.window, size[0], size[1], 1)
pyplot.plot(x, y)
dir = os.path.dirname(os.path.dirname(file))
self.transport.loseConnection()
connection.close()
mail.sendmail(EMAIL_FROM, EMAIL_TO, msg.as_string())
ax.plot(x, y)
DF.cumsum()
thirdpartymodule_b.dosomething()
list(le.inverse_transform([2, 2, 1]))
self.root.mainloop()
roc_curve(y_true, y_score)
print(ascii_num[::-1])
MDD_start, MDD_end, MDD_duration, drawdown, UW_dt, UW_duration
print([(r / s) for s in [psum(raw)] for r in raw])
layout.addWidget(self.toolbar)
p = subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
zip(cv.get_feature_names(), np.asarray(X.sum(axis=0)).ravel())
{x: (0) for x in alphabet}
id = db.Column(db.Integer, primary_key=True)
data = np.random.normal(size=1000)
df = pd.read_csv(io.StringIO(data))
n_grams = CountVectorizer(min_n=1, max_n=5)
dfcopy.a.ix[0] = 2
subprocess.call(args)
round(2.605, 2)
round(2.067, 2)
file.seek(lastKnownSizeOfFile)
Base2.bar()
res.read()
member = getattr(module, membername)
print(list(filter(len, a)))
s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
plt.bar(x2, y)
print([(2 ** ((N - abs(N - k)) % N)) for k in range(2 * N + 1)])
srf = pygame.display.set_mode((640, 480))
decompressed_data = zlib.decompress(f.read(), 16 + zlib.MAX_WBITS)
ax2.plot(list(range(10, 20)))
print(PATTERN.split(data)[1::2])
X[::-1, ::-1, ::-1]
fout.write(regex.sub(replfunc, line))
print(tuple(l))
df1.join(df2)
object_id = models.PositiveIntegerField()
X = X.reindex(np.roll(X.index, 1))
x = a if b else 0
img = plt.imread(filename)
ax.legend()
sorted(y, key=x.__getitem__)
fig = plt.figure()
root = Tk()
c.setopt(c.URL, url)
df = df.loc[(df[col].isin(counts[counts > threshold].index)), :]
s = f.read()
y = np.arange(Y)
print(i, j, k)
table.sort(reverse=True, key=Team.getPoints)
result.append(list(g))
unittest.main()
logger.removeFilter(dup_filter)
print(get_image_info(data))
plt.ylim(0, 40000)
thread = threading.Thread(target=server.serve_forever)
print(soup.prettify())
print(resp.url)
fig, ax = plt.subplots()
conn = boto.connect_dynamodb()
s[0]
QApplication.__init__(self, *args)
module = imp.new_module(name)
print(key, value)
df = pd.DataFrame(a.T)
ax.set_yticks([])
ax = fig.add_subplot(121)
rand_stocks = np.random.randint(0, len(data), size=batch_size)
self.assertEqual(404, response.status_code)
plt.draw()
self.myParent.grid_columnconfigure(0, weight=1)
tuples = list(d.values())
m.mymethod()
Cal2 = sum(n for n in domain if n % 2 == 0)
harmonic_number = lambda n: sum(Fraction(1, d) for d in range(1, n + 1))
stdscr.refresh()
[1, 2][::-1]
zip_longest(fillvalue=fillvalue, *args)
list(OrderedDict.fromkeys(items))
list_words = [fs.format(a) for x in l for a in x.split()]
random.seed(42)
list_of_pairs = [(p1, p2) for p1 in people for p2 in people if p1 != p2]
time.sleep(5)
li = [id_s[c] for c in list]
Y_modified = np.where(variance > 0.5 * np.max(variance), Y, 0)
plt.bar(df.index.to_pydatetime(), df.Val, width=0.4)
pad.refresh(top, 0, 0, 0, curses.LINES - 1, curses.COLS - 1)
app = Flask(__name__)
dict.__setitem__(self, key, value)
os.makedirs(directory_name)
new_a = a[(a <= 100).all(1)]
ax.set_ylim(0, 5)
[str(v) for v in obj.attrs.all()]
c = copy.deepcopy(a)
namestr(a, globals())
df[df.a < np.percentile(df.a, 95)]
func(b)
np.linalg.norm(coef, axis=0)
open_file.close()
pprint.pprint(arr)
z.update({key: value})
all_pairs += [((nB, 1), (nC, 2)) for nB, nC in itertools.product(listB, listC)]
(data[index] for index in indices[field][key])
result._fields
df = pandas.DataFrame(data)
print(np.corrcoef(x_tag[0:len(x_tag) - 1], x_tag[1:])[0][1])
df.apply(make_plot)
(i.bit_length() + 7) // 8
ordered = list(list_dict[val] for val in ordering_list)
print(df5.groupby(level=0).apply(process))
self.show()
np.argwhere(np.in1d(a, np.intersect1d(a, b)) == False)
scopes = set()
get_max(my_list)
plt.gcf().gca().add_artist(circle1)
cursor.execute(query, [id])
newlist = old_list.copy()
imshow(A)
ax1.set_xlim(0, 1000.0)
matrix[~mask] = 0
ax.w_zaxis.set_major_locator(LinearLocator(10))
self.SetSizer(self.sizer)
zfile.close()
[(id(x) == id(y)) for x, y in zip(lis, new_lis1)]
plt.ylim(ymin, ymax)
s += etree.tostring(sub_element)
writer.writerows(row[:1] + [0.0] + row[1:] for row in reader)
ax.grid()
plt.show()
print(soup.p)
new_list.append(l1[index] + l2[index])
cursor.execute(sql)
dilation.process(tree.clone(), tree)
f(1)
aList.sort(key=lambda x: (x[idx] for idx in args))
Counter(string)
numpy.vectorize(complex)(Data[..., (0)], Data[..., (1)])
port = int(port)
type(data)
plt.draw()
root = ET.fromstring(xmlstr)
cfs = floating_bond.cashflows()
random.sample(list(enumerate(l)), 5)
print(df)
stupidtrick()
parser = argparse.ArgumentParser()
1 / (1 + math.exp(-x))
db.create_tables([ModelA, ModelB, ModelC])
imshow(cm.hsv(Z1), alpha=0.6, extent=extent)
model = Sequential()
c_dict = {k: pd.DataFrame(v) for k, v in groups.groups.items()}
myDB.connect()
writer.writerow(row)
all([0, 1])
[s[5 * i:5 * i + 5] for i in range(0, math.ceil(len(s) / 5))]
x = [n.strip() for n in x]
a.A()
axins1.set_xlim(x1, x2)
socket.setdefaulttimeout()
audio /= np.max(np.abs(audio), axis=0)
map(str, lst)
plt.subplots_adjust(bottom=0.15)
result = sum(range(1, 401, 4))
text_entry.pack()
A[:] = somedata[:]
created_by = models.ForeignKey(profile)
results.append((a[first][0], a[second][0], a[third][0]))
self.builds = builds
print(lines[:100])
cost_obj.save()
UserModel.save(using=db, force_insert=True)
ip = socket.gethostbyname(socket.gethostname())
self._result.addFailure(self, sys.exc_info())
matplotlib_fig.show()
g.__code__.co_name
color_img = cv2.cvtColor(gray_img, cv.CV_GRAY2RGB)
nlargest(n, your2DList, key=lambda x: x[-1])
df = pd.concat([df] * 100000).reset_index(drop=True)
plt.show()
ax.plot(list(range(10)))
sys.stdout.flush()
root2.minsize(root2.winfo_reqwidth(), root2.winfo_reqheight())
webbrowser.open_new(url)
a[-1].shape
e.pack()
plt.plot(np.cos(np.linspace(0, 10, 100)))
d.bar()
normedA = array(norm(v) for v in A)
handles, labels = plt.gca().get_legend_handles_labels()
a.add(x)
foofoo.py
os.kill(int(sys.argv[1]), 0)
strat1.execute()
nil
dictionary[len(i)] += 1
response = urllib.request.urlopen(url)
sorted(l, key=alphanum_key)
datetime.datetime.now()
help(raw_input)
matmult(x, y)
g.index = g.index.swaplevel(1, 2)
creatures = dict()
meds.sort(ascending=False)
canvas.pack(side=LEFT, fill=BOTH, expand=TRUE)
print(self.parent.__name__)
time.sleep(0.1)
fig, ax = plt.subplots()
next(combs2)
app.run(debug=True)
print(type(data))
__init__.py
row, col = numpy.where(M == 0)
self.setupUi(self)
plt.plot(x, 4 * x)
pnt.ewkt
__init__.py
ax.set_xlim(0, 10)
arg[::-1]
plt.scatter(a[0], a[1], s=50, c=colormap[categories])
ax = plt.gca()
size = models.IntegerField(blank=True, null=True)
dct = dict(zip(ascii_uppercase, lens))
self.model = QtGui.QStandardItemModel()
sublist.sort()
saved = locale.setlocale(locale.LC_ALL)
len([letter for letter in word if letter not in BAD_LETTERS])
plt.figure(2)
shutil.copyfileobj(r, f)
len(response.content)
plt.show()
a.append(a.pop(0))
print(f.info())
os.unlink(targetLink)
b_result.append(b)
pd.read_csv(s, parse_dates=[0], dayfirst=True)
tuple(l)
objs.append(pickle.load(f))
df
response
pl.hist(data, bins=np.logspace(0.1, 1.0, 50))
x = copy.deepcopy(y)
print(sys.executable)
self.process.communicate()
print(utc_dt.astimezone(get_localzone()))
len(set(list_)) == len(list_)
httpd.serve_forever()
print(self.__class__.__dict__)
final_ensemble.estimators_ += ensemble.estimators_
ns = np.arange(-5, 5 + 1)
s = requests.Session()
print(abs(x) % 1000)
logger.removeHandler(logger.handlers[0])
self.foo.start()
[1695.86408654, 2140.0, 6969.0],
msg = MIMEMultipart()
s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
print(key)
f.seek(999999)
l = list(filter(str.strip, l))
form = ContactForm(request.POST)
root.mainloop()
result = [myFunc(p, additionalArgument) for p in pages]
b()
end_date[-1] = end_date[-1][:4]
Counter(map(tuple, a.T))
pylab.show()
kpt_data.reshape(h_r.shape[:2] + (-1,))
x.upper()
gobject.threads_init()
tt = matplotlib.delaunay.triangulate.Triangulation(x, y)
time.sleep(0.01)
time.sleep(0.1)
R1.__init__(self)
print(types[bisect.bisect(points, Point(0.1, 0.1)) - 1])
time.sleep(seconds / 1000000.0)
root.mainloop()
wtr.writerows(in_iter)
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
s[1]
list(chain.from_iterable(zip(data, tweets)))
ords = (ord(c) for c in s)
lines = (line.rstrip() for line in f)
s.set_debuglevel(1)
stdoutdata, stderrdata = proc.communicate()
open_workbook(excel_file_full_path, formatting_info=True)
df.university.apply(extract_city)
sys.exit(app.exec_())
self._exit()
arr2d.sum(1)
HypotheticalBranch(0, 1, 1)
shutil.copyfileobj(zf, f)
Parent.__init__(self, *args, **kwargs)
df.reset_index()
ax = plt.gca()
file.seek(-1024 * 1024, os.SEEK_END)
a = numpy.empty(n, dtype=object)
np.array(sorted(set(a) | set(b)))
self.button.clicked.connect(self.plot)
writer = csv.writer(f)
plt.axis([-1, 6, 0, 6])
ftp.close()
pygame.draw.circle(screen, COLOR, POS, RADIUS, WIDTH)
pprint.pprint(w.config())
float(num) / float(denom)
result
alist2 = [item[:] for item in alist]
path = urllib.request.url2pathname(path)
md5.digest()
logger.setLevel(logging.ERROR)
cmyk.append(cmyk_im[i].load())
loop.close()
print(C.x.__doc__)
newImage.paste(srcImage, (x1, y1, x1 + oldWidth, y1 + oldHeight))
f.close()
[hash(tpl[0]) for tpl in stackframe[1:]]
timediff.total_seconds()
loop.run_forever()
itertools.zip_longest(fillvalue=fillvalue, *args)
ax.plot(VecStart_x + VecEnd_x, VecStart_y + VecEnd_y, VecStart_z + VecEnd_z)
{k: v for k, v in list(d.items())}
foo()
xml.write(m.group(1))
joint = [[(x + y) for x, y in zip(*row)] for row in zip(outgoing, incoming)]
l.pack()
frozenset().union(*l)
np.array(test)
list(a.keys())
self.val = 0
list(accumulative_product(A, B, C))
server_socket.bind((HOST, PORT))
gevent.joinall(greenlets)
tree_dict = {key: tree_dict}
hex_int = int(hex_str, 16)
print(myzip.namelist())
pool = multiprocessing.Pool(processes=cpus)
df.drop(df.columns[1:], axis=1)
urllib.request.HTTPSHandler.__init__(self)
plt.hold(True)
plt.boxplot(x)
layout.addWidget(self.button)
regex = re.compile(ptn % re.escape(punc))
a.reshape((-1, 5))
lines.append([(lastX, lastY), (lastX + 1, lastY)])
Planet.MERCURY
print(soup)
out, err = proc.communicate()
engine.block()
p.start()
root.mainloop()
out = abs(z[..., (np.newaxis)] - z)
_nextkey += 1
myset = set(filter(test, myset))
hash(foo)
cv2.drawContours(drawing, [cnt], 0, (255, 255, 255), 2)
self.platforms.append(p)
app.MainLoop()
list(gen())
df = pd.read_excel(path + filename)
pd.infer_freq(ts.index)
c.execute(sql, tup)
f.close()
temp_list.append(item)
panel = tk.Label(root, image=img)
{{(floatvalue | floatformat): 2 | intcomma}}
data = data.reshape(shape)
float_color = color / 255.0
[0, 2, 4, 10, 12, 14, 20, 22, 24]
gamma + log(n) + 0.5 / n - 1.0 / (12 * n ** 2) + 1.0 / (120 * n ** 4)
print(m.start(), m.group())
pygame.display.update()
imp.find_module(imported)
list(filter(pattern.match, strings))
sorted(lst, reverse=True)
print(arr.reshape(2, 2, 2, 2).swapaxes(1, 2).reshape(2, 2, 4).max(axis=-1))
my_list = list(my_iterable)
form.field(disabled=True)
data.append(group_data)
spsd.euclidean(nparray1, nparray2)
self.ax.add_patch(self.rect)
list(enumerate([4, 5, 6, 7]))
setattr(cls, membername, lockedmethod)
pd.concat([Out[24], Out[25]], axis=1)
chain.from_iterable(listOfLists)
range_prod(1, n)
print(driver.page_source)
System.out.println(id.getClass().getName())
random.choice([4, 5, 6])
im = Image.open(StringIO.StringIO(f.read()))
a[y[:-1]] -= x[:-1]
foosparse[key1, key2] = value
browser.driver.set_page_load_timeout(10)
soup = BeautifulSoup(urllib.request.urlopen(url).read())
fitness_landscape.shape
func(*args, **kw)
[list(g) for _, g in groupby(sorted(flat, key=len), key=len)]
sys.exit(app.exec_())
a, b, c = [list(g) for k, g in it.groupby(mylist, keyfunc)]
axes.hist(x, bins=binedges, weights=weights, *args, **kwargs)
args = parser.parse_args()
canvas.setStrokeColorRGB(0, 0, 0)
self.opt.stdin.write(string)
type(a)
data = np.zeros((200, 200), dtype=np.float)
cursor.fetchall()
list[list.index(target) - 1]
pl.ylim(0, ymax)
print(sorted(a, key=to_minutes))
array.sort(key=lambda item: item is 0)
iv = Random.new().read(16)
[remove_bad_substrings(s) for s in sites]
net.addModule(hidden1)
zelib.multiplier.argtypes = [ctypes.c_float, ctypes.c_float]
ax.xaxis.set_major_locator(ticker.MultipleLocator(1))
word[-1:-len(word) - 1:-1]
path = os.path.join(os.path.dirname(__file__), template_file)
traceback.print_stack(file=sys.stdout)
etree.tostring(fragment)
sleep(10)
list(result[0][1].keys())
response = urllib.request.urlopen(req)
[convert_value(item) for item in lst]
df.update(df2)
r = np.linspace(1, 5, n)
n, bins, patches = plt.hist([x, y])
same_structure(a[1:], b[1:])
plot(c(0, 1), c(0, 1))
fig.tight_layout()
np.resize(a, 10).reshape(5, 2)
plt.clf()
len(df)
print(drives)
np.allclose(OP(cords, atoms, atom_proj), project_atom(cords, atoms, atom_proj))
screen.keypad(0)
list(test)[0]
print(ast.literal_eval(input()))
fp = webdriver.FirefoxProfile()
array([True, True, False], dtype=bool)
app.exec_()
xs = np.array([[0, 1, 0], [0, 0, 1], [0, 1, 1]]) * 1.0
df.set_index(keys=[df.index.year, df.index.month]).transpose()
set(MyList).intersection(MyDict)
parent_parser = argparse.ArgumentParser(add_help=False)
functools.reduce(op.mul, (sum(x) for x in zip(*list_)))
ax.set_ylim(ybnds)
PROJECT_ROOT = os.path.realpath(os.path.dirname(__file__))
plot(x, y1)
pdb.set_trace()
arr = numpy.array(data)
self.apple_button.Bind(wx.EVT_BUTTON, self.apple_button_click)
fig.autofmt_xdate()
slice_list(x, 7)
br.select_form(nr=0)
draw.ellipse((0, 0) + size, fill=0)
timedelta(hours=2)
d[x].append(y)
plt.gca().add_artist(leg1)
plt.gca().add_artist(leg5)
window.show()
np.set_printoptions(suppress=True)
repr(s)
[0.0, 0.0] / sum([0.0, 0.0])
arr.sum(axis=0).shape
content = file.read()
[list(g) for k, g in groupby(l, bool) if k]
data = json.dumps(data, cls=DjangoJSONEncoder)
frame = pd.read_csv(path, names=columns)
xlim(0, 1)
draw()
group = Group.objects.get(pk=1)
plt.show()
p = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.IGNORE)
server.close()
array([0, 2, 4], dtype=int64)
Py_Initialize()
email.send()
d = {}
print(df1.groupby(df1.columns, axis=1).sum())
self.close()
df = pd.DataFrame(m.toarray())
parent.kill()
sys.stderr.close()
B = np.array(A)
Qapp.exec_()
ax = fig.add_subplot(111)
_draw_point(renderer, position, i, j)
cluster_count = len(set(map(representative, representatives)))
all = all[:max(current - 2, 0)] + all[current:]
print(lol[1:4, 2:5])
self.listofrecords[listnum][record] = value
True
sqllogger.addHandler(sqlhandler)
session.quit()
indices = np.searchsorted(u, arr.flat)
False
self.a + self.b
hxs = HtmlXPathSelector(response)
plot(x, cos(x))
pprint(ddiff)
time.sleep(0.1)
example_df.iloc[(1), :].corr(example_df.iloc[(2), :])
print(zlib.decompress(b))
[x for xs in a for x in xs]
merged = map(list, zip(listone, listtwo))
connection.close()
self.__class__.bar(self)
server.sendmail(FROM, TO, message)
ax.scatter(x, y, z)
time.sleep(1)
results = [do_smth(file.read()) for file in files]
ar.sort()
inputs = list(map(int, input().split()))
data = np.random.normal(0, 20, 1000)
threading.Thread.__init__(self)
x = np.array(x, copy=False, ndmin=1)
handler404 = Custom404.as_view()
s = pd.Series(np.random.randn(n).cumsum())
plt.plot(X[i])
out = [float(f_interp(*p)) for p in zip(X, Y)]
fig = plt.figure()
self.delete(0, Tkinter.END)
a[0] = [1, 2]
print(isinstance(MyClass, MyClass()))
plt.scatter(X, Y)
pool.join()
main()
l = []
print(dtd.validate(root))
True
ax.set_xticklabels(labels, minor=False)
[given[i:i + len(sublist)] for i in range(0, len(given) - len(sublist))]
out = data[np.in1d(data[:, (1)], goodIDs)]
df.mean()
admin.site.register(Foo, FooAdmin1)
[seq[i:i + k] for i in range(0, len(seq), k)]
plt.ylim(-0.1, 1.1)
np.vstack(np.unravel_index(indices, arr.shape)).T
unwrap_method(get_func) is unwrap_method(Client.get)
Permission.objects.all()
setattr(something, k, v)
pygame.display.flip()
ts.ix[ts.index.indexer_between_time(datetime.time(10), datetime.time(14))]
main()
list(set(x[0]).union(*x[1:]))
List.append(Item)
fig = plt.figure()
kde.integrate_box_1d(1, 2)
password = getpass.getpass()
sys.stdout.write(out)
bstr[0]
A[(1), (1), :]
print([str(x) for x in l])
set.intersection(*lis)
[[0, 1][name.split()[-1] in set(B)] for name in A]
self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
browser.back()
True in set(map(lambda x: x[0] == 1, a_list))
output.addPage(page)
regex = re.compile(pattern, re.MULTILINE | re.DOTALL)
sck = socks.socksocket()
print(solution(list(range(1, 2000))))
s = requests.session()
__path__ = pkgutil.extend_path(__path__, __name__)
hsv_to_rgb = np.vectorize(colorsys.hsv_to_rgb)
self.setCursor(QtCore.Qt.SplitHCursor)
self.log.addHandler(self.handler)
chardet.detect(elems[0].getText())
path = os.path.dirname(os.path.abspath(filename))
sys.getwindowsversion()[0] >= 6
app.exec_()
print(LH.tostring(doc, pretty_print=True))
start_time = time.time()
self.forms[self.initial_form_count():]
fig = plt.figure()
p = Pool(1)
keys[-1] in lastplace
result = cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)
ax.set_ylim(bottom=0)
df = xl.parse(0, converters={i: str for i in range(ncols)})
dict_lol = {item[1]: item for item in lol}
re.findall(regex, statements, re.I)
sys.stdout.write(line)
csvfile.seek(0)
player_list.append(player)
admin.autodiscover()
main()
ax.set_rmax(1.25)
cur.execute(sat)
b.shape
foo
a + b * c
arr.resize((k, M))
print(b[0])
y = 2 * np.sin(x)
f.close()
print(match.group(1))
object.__setattr__(self, name, value)
func()
counts[item] += 1
pipeline.fit(X, Y)
im.resize(size, Image.BILINEAR)
env.use_ssh_config = True
polB.set_transform(tB)
clipboard.store()
np.all([i for i in range(10)])
sess.run(init_op)
mylist.append(first_el)
idx = list(range(len(S)))
obj.__class__._default_manager.get(pk=obj.pk)
dict(page=context)
d[i].append(int(j))
[list(islice(it, i)) for i in b]
db.connections.close_all()
plot(list_of_dates, counts)
fs.noteoff(0, 60)
z = [int(i == j) for i, j in zip(x, y)]
print([joiner(words) for words in sixgrams])
ctx.set_source_rgb(1, 0, 0)
print(message.get_body_encoded())
zipped = zip(*l)
A[:, ([1, 2])]
plt.scatter(x, y)
str({})
doSomething()
y = x.reshape(x.shape[0] / 2, 2, x.shape[1] / 2, 2)
array_to_filter[np.in1d(array_to_filter, equal_array)]
s = list(filter(str.isalnum, s))
tar.close()
self._socket.recv(buffersize, flags)
send_mail(subject, message, settings.DEFAULT_FROM_EMAIL, [self.user.email])
lst.insert(randrange(len(lst) + 1), item)
bin(10)
os.dup2(se.fileno(), sys.stderr.fileno())
self.fc2.draw()
[getrange(x) for x in newlist]
self.navigate(1)
j = index - d * (d - 1) / 2 + (d - i) * (d - i - 1) / 2 + i + 1
username = db.Column(db.String(80), unique=True)
np.allclose(old, new)
root.update()
print(p.pattern)
NULL
list(set(x[-1]).union(*x[1:]))
b = np.dot(a, c)
time.sleep(1)
app = Flask(__name__)
client.set_options(soapheaders=ssn)
QtGui.QLabel.__init__(self)
setattr(modadd, camel_name, f)
df2 = df2.reset_index()
driver.switch_to_default_content()
func(obj, *args, **kw)
image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
Bar.py
Html_file.write(html_str)
python - i
main(sys.argv[1])
array([10, 4, 1], dtype=int64)
ET.fromstring(t)
len(new_strs.split())
log.setLevel(logging.INFO)
foundwords.extend(words[1:])
QtGui.QMainWindow.__init__(self)
results = sorted(results, key=getaccountingdate, reverse=True)
deletealist[i]
t.start()
wf.close()
logger.info(parsed_item_info)
tag.save()
cursor.execute(sql)
self.image.set_from_pixbuf(loader.get_pixbuf())
url
foo()
webapp2.RequestHandler.dispatch(self)
br = mechanize.Browser()
self.wfile.flush()
ax = plt.subplot(111)
time.sleep(0.5)
CE, BF, BC, BD, BE
do_stuff()
perf_func(root.getroot(), print_level)
x if f else random.choice(good)
today = datetime.datetime.today()
curs.fetchone()
fd.close()
nearby_strikes = other_strikes.loc[ind[0]:ind[1] - 1].copy()
ssh_stdin, ssh_stdout, ssh_stderr = ssh.exec_command(cmd_to_execute)
self.results.append(result)
List.append(Item)
sys.getsizeof((1, 2))
a[0:1] = [1]
ax1.semilogx(data[:, (1)], data[:, (2)])
results = pool.map(solve1, args)
fig = plt.figure(figsize=(10, 8))
os.close(fd)
[func(mylist) for func in map(globals().get, fxnOfInterest)]
os.path.join(path, filename)
print(p.communicate()[0])
a, b = b, a + b
type(d)
print(finfo.dtype, finfo.nexp, finfo.nmant)
list_of_hets = []
sympy.evalf(f, subs=dict(zip(fvars, b)))
threading.Thread(target=thread_job).start()
window.show()
xl.Workbooks.Close()
pool = multiprocessing.Pool()
deleteL[-n:]
np.testing.assert_allclose([np.nan], [np.nan])
app = QtGui.QApplication(sys.argv)
w.show()
f.close()
root.rowconfigure(1, weight=1)
q = A.select(A, B).join(B).where(B.date == last_entry_date)
r.close()
tornado.ioloop.IOLoop.instance().start()
index = d * (d - 1) / 2 - (d - i) * (d - i - 1) / 2 + j - i - 1
dict.__setitem__(self, key, val)
g.Category.apply(pd.value_counts).unstack(-1).fillna(0)
a[i]
df
value.__format__(format_spec)
random.shuffle(s)
a.upper() == b.upper()
pool.join()
MySuperClass.__init__(self)
self.Change(self.variable)
conn.perform()
d = datetime.datetime.now()
g.add_edge(1, 2)
db.session.remove()
df.to_records().dtype
a = [([k] + [x[1] for x in g]) for k, g in groupby(r, key=lambda row: row[0])]
dumps(a.__dict__, default=encode_b)
logging.getLogger().setLevel(logging.DEBUG)
do_stuff(A[i], A[j])
C = np.empty((A.shape[0] + B.shape[0], A.shape[1]))
root = Tk()
script = os.path.abspath(sys.argv[0])
print(sys.executable)
self.setCentralWidget(page)
[distance(*pair) for pair in zip(repeat(pts[0]), pts[1:])]
your_module.get_logger().log_to_file(filename)
print(set(n1).difference(set(n2)))
res.fillna(0).squeeze().dt.days
ax.set_ylim(ylim)
ax1 = fig.add_subplot(121)
conn.commit()
ex2.show()
QtCore.QSize(150, 75)
print(tuple(pad_strings(x)))
14.078685
ax.scatter(x, y, c=colors, s=50, cmap=mpl.cm.Reds)
plt.figure()
process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)
outfile.close()
fig, ax = plt.subplots()
print((i, l))
print(pool.map(f, list(range(10))))
B = A[[col1, col2]].iloc[idx]
plt.legend(handles=[select], scatterpoints=1)
browser.submit()
df
f(*args, **kwds)
older_books = [b.title for b in BSI if b.year < 2000]
globals().update(var=value)
stack.append(stack[-1][-1])
zf.write(os.path.join(dirname, filename))
self._children = []
contents.sort(key=itemgetter(1))
df = df.reset_index()
plt.style.use(style_name)
DISPATCH()
canvas.rect(i, 0, 2, 100)
df.apply(lambda x: x.astype(object).replace(1, x.name))
np.split(df1.index[c], np.flatnonzero(r[1:] > r[:-1]) + 1)
traceback.print_stack()
help(myFunc.__code__)
self.panel.Bind(wx.EVT_KEY_DOWN, self.OnKeyDown)
grid = np.random.random((10, 10))
new_dic[1][2] = 5
x.astype(int)
print(sum([float(x) for x in re.findall(p, test_str)]))
x * 2
sorted(files)
tar.add(source_dir, arcname=os.path.basename(source_dir))
biglist2.sort(key=(operator.itemgetter(2), operator.itemgetter(0)))
dict((k, v) for k, v in list(mydict.items()) if k >= 6)
plt.plot([pt[0], pt[0]], [0, pt[1]])
tk.Canvas.__init__(self, *args, **kwargs)
raise ValueError((a, b))
True
name = models.CharField(max_length=100)
data = np.array([1, 4, 5, 5, 6, 8, 8, 9])
str(datetime.strptime(value, FORMAT_STRING))
do_something()
handle.close()
plt.show()
ao[1:, :-1] += ai[:-1, 1:]
df2 = pd.read_csv(StringIO(df2_text), delim_whitespace=True)
float(Mixed(1, 1, 2))
isinstance(x, list)
em = trained.emission
plot(a[:, (0)], a[:, (1)])
ax.plot(theta, r)
print(len(set(probes)))
data = dd.from_pandas(df, npartitions=2)
frame.append(1)
localtime(now()).date()
x[x]
models.py
y = np.array([1, 2, -1, 1, 1])
g.axes[0][0].legend(loc=1)
cnx.close()
self.canvas.clear()
spam.ham
plt.imshow(np.random.random(100, 100))
print(k, v)
server.quit()
[staging]
print(str_to_type(v))
doSomething()
reader = csv.reader(f)
traceback.print_stack()
writer = csv.writer(f)
dictname = pickle.load(f)
seclist = [2, 4, 6, 8]
print(img.shape)
p = argparse.ArgumentParser()
print(file.read())
image.set_from_stock(gtk.STOCK_CLOSE, gtk.ICON_SIZE_MENU)
re = [y for x, y, z in zip(tmp[2:], tmp[1:-1], tmp[:-2]) if y != x and y != z]
plt.yticks(pos, labels.sort_index())
output, error = process.communicate()
0.2775516299989249
plt.show()
math.degrees(math.atan(1))
a[0:1] = [1]
np.random.seed(10)
f.write(site.read())
user = User.objects.get(pk=request.user.id)
__main__.py
db.delete(item)
words = {}
parser = argparse.ArgumentParser()
os.path.join(path, filename)
[x for xs in a for x in xs]
print(response.content)
True
i += 1
self.assertEqual(fn(i), output[i])
ordereddict.py
any(c in yourString for c in badChars)
locals().update(vars(args))
{{(img.height | add): 1}}
self.request.send(self.data.upper())
setattr(self, key.lower(), val)
intified_list = list(intify(lst))
glDrawArrays(GL_TRIANGLE_STRIP, 0, 4)
[iplocation]
c = sorted(set(a).intersection(b))
print(in_nested_list(x, []))
sys.exit(1)
listofLines.sort(key=extract_time)
print(df.values.flatten())
setattr(self, name, callable)
print(map(lambda x: not B_set - set(x), A))
main()
reactor.connectTCP(host, port, factory)
ps.wait()
thisprogramdoesntexist
jsonFile.truncate()
1 / 2
Response(serializer.data, status=status.HTTP_201_CREATED)
fig, ax = plt.subplots()
f.write(line)
data = json.load(contactFile)
pprint(sorted(list(results.items()), key=lambda x: x[1]))
l[:n] + [0] * (n - len(l))
obj_list[0].do_somthing()
tuple(y)
b = np.random.rand(10, 10)
method(*args, **kwargs)
instance.topping_set.add(topping)
time.sleep(2)
main()
os.mkfifo(thefifo)
ax = fig.add_subplot(111)
data[data < threshold] = 0
B[:, (col)] = np.prod(np.delete(A, col, 1), 1)
last_name = models.CharField(max_length=50)
d.replace(hour=0, minute=0, second=0, microsecond=0)
time.sleep(2)
random.shuffle(rects)
edge_list = [tuple(map(int, line.split())) for line in data]
print(hashlib.sha512(password + salt).hexdigest())
powerpoint.Quit()
main_window.show()
f()
dom = minidom.parseString(xml_text)
print(list(itertools.chain(*list(parser_config.keys()))))
a = np.array([1e-09])
A.columns = pd.MultiIndex.from_product([list(range(A.shape[1] / 10)), list(range(10))])
z.set_zorder(-1)
pool = multiprocessing.Pool(4)
conn.close()
np.where(abs(arr_f - a) < t)[0].any()
a = np.arange(8)
f_new.write(line)
do_something(item)
print(df.sum(1).to_frame().dot(df.sum().to_frame().T).div(df.sum().sum()))
json.loads(json1)
Py_Finalize()
self._connect()
df = df.reset_index()
print(requests.post(endpoint, data=data, headers=headers).json())
lib.get_strings(c_array, len(list_to_send))
conn.sendmail(sender, destination, msg.as_string())
mat - vec[:, ([0, 0, 0])]
A.reshape(h // ph, ph, w // pw, pw, -1).swapaxes(1, 2).shape
reactor.run()
self.driver.close()
(m.transpose() - v).transpose()
collections.Counter(x) == collections.Counter(y)
logging.getLogger().setLevel(logging.DEBUG)
self.window.show_all()
list(chain(ls[:idx], replace_with, ls[idx + 1:]))
print(np.corrcoef(x[0:len(x) - 1], x[1:])[0][1])
s.commit()
f.writelines(lines)
alsonow = now.astimezone(yourtz)
decorated_argspec = inspect.getargspec(func2)
os.chmod(full_path, stat.S_IWRITE)
data = numpy.fromfile(f, dt)
pd.io.json.dumps(summary, double_precision=2)
revlist(lst[1:]) + [lst[0]]
frq = frq[list(range(n / 2))]
foo = Foo()
[5, 7, 9, 11]
ShapedFrame().Show()
stack[-1].append(x)
file.close()
id = Column(Integer, primary_key=True)
main()
pool = Pool(processes=4)
plt.plot(sorted, yvals)
bid = int(bid)
plt.show()
df.set_index([0, 1], inplace=True)
connection.close()
b = Matrix([[0, 0], [0, 0]])
files.sort(key=os.path.getmtime)
mainloop()
lst[:] = whatever
newlist = [[y[0] for y in list if y[1] == x] for x in values]
d.setdefault(word[0].lower(), []).append(word)
a[:, (0)]
urllib.request.Request.__init__(*args, **kwargs)
myslice = array[tuple(idx)]
type(dates[0]) == pd.tslib.Timestamp
entry_list = [x.title.text for x in feed.entry]
foo()
self.driver = webdriver.Firefox()
output.close()
result_dict = dict((n, res_list[i]) for i, n in enumerate(header))
ax.annotate(str(j), xy=(i, j))
s.listen(1)
print(m.group())
clf.fit(X, y)
game_display = pygame.display.set_mode((800, 800))
smtp.close()
fig = plt.figure()
rtc.Newline()
output = check_output(cmd, stdin=file)
entry.pack()
print([0] * i)
file_writer.writerow([x[i] for x in lol])
print(type(result))
d = dict(zip(list(adict.values()), list(adict.keys())))
plt.show()
plt.colorbar()
tk.Frame.__init__(self, parent)
ax.annotate(str(y), xy=(x, y))
str(list(self.__iter__()))
data = f(data)
self.figure.set_canvas(self.figurecanvas)
self.ui.main_plot.figure.subplots_adjust(bottom=0.4)
screen.fill((0, 0, 0))
coords.reshape(-1, N)
self.ax.cla()
child.kill()
p = subprocess.Popen(your_command, preexec_fn=os.setsid)
self.g.get(key)
test.py
b = a.T
self.update({element.tag: element.text})
root.mainloop()
print(sum(a))
Process(target=do_something).start()
print(sum(ord(char) - base for char in mystring))
line_count += 1
print(sum1(-1, 0, 6, 10))
ax = fig.add_subplot(gs[1])
pygame.display.update()
func()
__init__.py
res = urllib.request.urlopen(req)
ax = fig.add_subplot(111)
random.shuffle(Order)
draw.line((0, im.size[1], im.size[0], 0), fill=128)
new = numpy.zeros_like(arr)
s.join()
fig, ax = plt.subplots()
sc._conf.getAll()
ax0.imshow(img, cmap=plt.cm.gray)
A.reshape(h // ph, ph, w // pw, pw, -1).swapaxes(1, 2)
self.label.configure(text=now)
o = object()
print((d1 + datetime.timedelta(i)).isoformat())
print(workdaycount(date(2011, 8, 15), date(2011, 8, 22), 1))
np.concatenate(alist)
self.SetTopWindow(frame)
l.sort(key=f)
list(intermix([1, 1, 1, 1, 1, 2, 2, 2, 2, 2]))
os.kill(pid, 0)
l.pop()
a + b
a = [1000 + 1, 1000 + 1, 1000 + 1]
cbar0 = plt.colorbar(cf0)
dict[key] = val
test.my_redifinable()
httpd.serve_forever()
print(traceback.format_exc())
plt.ylim([40, 110])
node_schema.load(json_data, instance=Node().query.get(node_id), partial=True)
x = np.arange(10)
self.setupUi(self)
timeit(stmt4, setup4, number=100)
p.start()
ax.yaxis.grid(True)
print(dirname(dirname(__file__)))
np.cov(data.T)
any(e in s for e in b)
file.close()
ax.set_xlim([-1, 0.5])
d[k].extend(v)
func(self, *args, **kwargs)
time.sleep(1)
r.json()
site.set_debuglevel(1)
quadV = [-0.5, -0.5, 0.0, 0.5, -0.5, 0.0, -0.5, 0.5, 0.0, 0.5, 0.5, 0.0]
sheet.set_clip(pygame.Rect(SPRT_RECT_X, SPRT_RECT_Y, LEN_SPRT_X, LEN_SPRT_Y))
data = cursor.fetchall()
YB = np.linspace(-1, 1, 20)
print(pd.concat([df, pd.concat([dm] * df.shape[1], axis=1, keys=df.columns)]))
print(sys.argv)
tips.reset_index(inplace=True)
self.assertTrue(result)
l = [i for sub in l for i in sub]
__path__ = extend_path(__path__, __name__)
help(string)
np.allclose(tmp, tmp2)
print(int(number) - int(number[::-1]))
print(dis.disco(f.f_code, i))
text, xoff = line_data[k][-1]
sys.exit(0)
print(m.hexdigest())
time.sleep(1)
print(repr(a))
numpy.zeros((5, 5))
sys.stdout.flush()
ctx.set_source_rgb(0.47, 0.47, 0.47)
data.append(0.25 * math.sin(math.radians(i)))
y = np.array([1, 2, 0, 1, 1, 2])
print(sys.path)
a[0]
[[1][2]]
data_tuple = Item(**dict(zip(fields, raw_data)))
label.grid(row=0, column=0)
subprocess.Popen(subprocess)
X[np.ix_([0, 1], [0, 1])]
print(fpp[1])
np.datetime64(datetime.utcnow()).astype(datetime)
df
ax.yaxis.set_minor_locator(MultipleLocator(0.2))
your_code.run()
minutes_diff = (datetime_end - datetime_start).total_seconds() / 60.0
df.query(qry)
model.objects.filter(id=id).update(order=order.index(id))
start()
transsurface.fill((255, 0, 255))
print(s.__dict__)
id(b[0]), id(b[1])
thread.start()
matrix[0]
somethingThread.join()
x.ix[random.sample(x.index, n)]
self.post(request, *args, **kwargs)
b_set = set(tuple(x) for x in a)
rs = json.dumps(dict(lst))
s == s[::-1]
df.describe().transpose()
root.deiconify()
_ = plt.setp(p.get_xticklabels(), rotation=90)
lines = f.readlines()
result.append(list(set1.union(set2)))
formset.save()
m.eliminate_zeros()
A = np.array(ss.zscore(A))
frame.axes.get_yaxis().set_ticks([])
print(repr(n))
Response(content)
ax.clear()
pd.options.display.max_columns = 50
plt.figure()
ax = plt.subplot(111)
[[2, 2, 2, 2], [2, 2, 2, 2], [2, 2, 2, 2]],
sys.exit(main(sys.argv))
self.fp.write(buf)
h = [[1, 0, 0][0, 0, 0][0, 0, -1]]
fig = plt.figure()
fig = plt.figure()
[1, 1, 1, 1, 1, 1]
list(set(l1) & set(l2))
numpairs = [nums[i:i + 2] for i in range(0, len(nums), 2)]
next(iter(list(self.items())))
[(a + b) for a, b in zip(l, l[1:])[::2]]
print(monotonic_time())
print(f.read())
conn.rollback()
ax.set_ylim([-1, 1.5])
entry1.grid(row=0, column=0)
new = dict(old)
ax.yaxis.set_minor_locator(MultipleLocator(0.1))
logger.addHandler(ch)
self.fp.write(zinfo.FileHeader(zip64))
key = line.strip()[1:]
func(1, 2)
foo = models.IntegerField()
out = np.column_stack((sortedA[(start_unqA), :-1], np.nanmax(grpA, axis=1)))
newarray = np.dstack(mylist)
inspect.getargspec(someMethod)
self.assertForbidden(response)
print(type(f.__self__))
loop.run_until_complete(main())
reduce(lambda d, k: d.setdefault(k, {}), keys, dict_nested)[newkey] = newvalue
Y.mean(axis=1)
print((k, v))
{{r.report_desc}}
print(df[df.columns[2:5]])
plt.subplot(122)
handler = logging.StreamHandler()
value[-2:]
d += timedelta(days=7)
pylab.show()
str(value)
pid.wait()
print(sys.argv)
show(p)
df
[row[colidx] for row in self._getrow(rowidx)]
print(requests.get(url, auth=(username, password)).content)
oceans[regcode - 1].append((temp, fecha))
print(b.decode())
job = dict(zip(keys, values))
my_randoms = [random.randrange(1, 101, 1) for _ in range(10)]
self.x -= STEP
im = Image.open(BytesIO(base64.b64decode(data)))
print(str(l)[1:-1])
conn = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
isinstance(y, X)
print(counter.most_common(10))
G = nx.Graph()
letter_count = dict(zip(string.lowercase, itertools.repeat(0)))
map(lambda s: s.split(), a)
file_1.write(line)
fig, ax = plt.subplots()
pool.close()
o.many2many.all()
{data[k].append(v) for line_dict in dr for k, v in list(line_dict.items())}
get_value(dic, 4)
r.findall(url)
plt.figure(figsize=(12.5, 2.5))
query_model.save()
input.seek(0, 2)
a = [i for i in range(2, 10)]
QApplication.setOverrideCursor(Qt.WaitCursor)
False
matches = {x for x in a if x in str}
plt.plot([0, 2], [2, 4])
data = [tryconvert(x, int, float) for x in line.split()]
mean = sum_x / n
test()
os._exit(EMERGENCY)
plt.show()
subplot(2, 1, 1)
mask = x ** 2 + y ** 2 + z ** 2 < radius ** 2
obj.__dict__
fig.colorbar(im)
tasks.remove(t)
random.shuffle(data)
random.shuffle(random_list)
ax.set_xlim(-50, 50)
root = Tk()
sock = socket.socket()
df_norm.mean()
pool = multiprocessing.Pool(processes=4)
self.init()
bins = np.arange(-100, 100, 5)
p.wait()
STATUS_ERR_INVALID_PARAMETER = 2
out, err = ssh_process.communicate()
handler.setLevel(logging.DEBUG)
time.sleep(0.05)
helloset.issubset(printset)
manager.run()
self.makeList(aNode.lChild) + [aNode.data] + self.makeList(aNode.rChild)
plt.show()
self.initUI()
plt.contour(xgrid, ygrid, zgrid)
comment = models.TextField()
unittest.TestCase.__init__(self, test_name)
msg.attach(msg_image)
k, len(v)
result.append(el)
sys.maxunicode
AMOServer.Disconnect()
pyplot.show()
driver.quit()
window = Tk()
d = pd.DataFrame(np.zeros((N_rows, N_cols)))
QtGui.QFileDialog.__init__(self, *args)
help(file.read)
ppc = run_ppc(trace, model=model, samples=200)
excel.ActiveSheet.Columns.AutoFit()
C = MyReallyBigClassNameWhichIHateToType
self.Layout()
self.func(self.parent_obj, *args, **kwargs)
f.write(chunk)
process(data)
print(fcount(path))
a[0, 1, 1] = [0, 1, 0]
print(df1[df1.B.isin(df2.B)])
logger.addHandler(ch)
max(allfuncs)
object.__getattribute__(self, name)
college = models.CharField(max_length=40)
root = tk.Tk()
df.gdp = df.gdp.shift(-1)
choice.things.all()
x[np.where([c != 2])[1]]
pygame.display.flip()
plt.ion()
np.sin(y * x)
audio.save()
cbar = fig.colorbar(cax, ticks=[0, 5, 10])
session.execute(sql_string).fetchall()
timer = pygame.time.Clock()
d += timedelta(days=6 - d.weekday())
print(df_Quota)
propnames = [name for name, value in inspect.getmembers(SomeClass, isprop)]
app.run()
B = A[:]
fig = plt.figure()
print(s.find(s2))
min(darr)
window.show()
self.hlayout.addWidget(self.b)
Encoders.encode_base64(eml_atch)
my_dict[1]
dialog.exec_()
self.foo.wait()
ax.set_xticklabels(categories)
ij = np.random.multivariate_normal((100, 100), cov, int(100000.0))
zip_longest(fillvalue=fillvalue, *args)
curses.echo()
show()
print(next(a))
df.drop_duplicates(inplace=True)
find_matches(list(a), list(b))
layout = QtGui.QVBoxLayout(self)
plt.figure(2)
numpydata = np.fromstring(data, dtype=np.int16)
response = br.submit()
window.Maximize()
threading.Timer(1, greeting, args=(oh_hi,)).start()
matches.extend([os.path.join(root, fn) for fn in filenames])
np.linspace(0, 1, 11)
self.data.grid(row=0, column=0, rowspan=4, columnspan=2, sticky=N + E + S + W)
objs = map(get_object, random.sample(list(range(length)), 0.001 * length))
json_docs.append(json_doc)
admin.site.unregister(User)
plt.subplot(2, 1, 1)
ax.get_xaxis().set_visible(False)
theclass.run
y = data[:, (0)]
tasks.join()
f.writelines(lines)
u[np.argmax(np.bincount(indices))]
ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
ax = fig.add_subplot(111)
driver = webdriver.Firefox(proxy=proxy_config, firefox_profile=prof)
print(out.upper())
cs = a, b, c, d
keys, values = list(dict.keys()), list(dict.values())
mydriver.maximize_window()
cursor.execute(query)
termf.pack(fill=BOTH, expand=YES)
str(self)
window_after = driver.window_handles[1]
i += 1
foo.stop()
center = (max(x) + min(x)) / 2.0, (max(y) + min(y)) / 2.0
root = tk.Tk()
sns.set_palette(flatui)
assert diff_month(datetime(2010, 10, 1), datetime(2010, 9, 1)) == 1
ContestResults.objects.filter(contest=instance).delete()
foo = Foo()
ax1 = plt.subplot(gs1[i])
driver = webdriver.Firefox()
lambda v: tryconvert(v, 0, int)
db.session.commit()
soup = BeautifulSoup(html)
new_list.append(data[index][current_index])
driver.close()
zf.seek(0)
df[df.ge(0)].fillna(-9999)
soup = BeautifulSoup(html)
ax.xaxis.set_major_locator(days)
{{narratives.narrative_text}}
axclust.set_yticks([])
axcltwo.set_yticks([])
f.close()
frame.columnconfigure(1, weight=1)
urllib.request.install_opener(opener)
map(lambda row: map(int, row), inputVals)
pl.figure()
a + list(repeat(0, 6))
plt.imshow(a, cmap=plt.gray())
cv2.destroyAllWindows()
arr[0, 0]
names.remove(name)
print(map(str, rr[::2]))
ax = fig.add_subplot(111)
result[k] += myDict[k]
ax = fig.add_subplot(gs[0])
HTMLParser.__init__(self)
result = {k: d1[k] for k in keys}
plt.imshow(img_a)
OrderedDict.__init__(self, *args, **kwds)
globals()[key] = value
sys.exit(app.exec_())
sess = tf.Session()
ax.set_yticklabels(names)
worksheet4 = workbook.add_worksheet()
table.reset_index()
y = x[:]
print(prev.tb_frame.f_locals)
self.cursor.commit()
ax1 = fig.add_subplot(111)
sys._getframe(number)
fd.write(data)
setattr(self, key, value)
b = a + b
pprint(Matrix([[1 / (4 * pi), 1], [1, f(x)]]))
A.todense()
pd.concat(subs)
self.canvas.configure(yscrollcommand=self.ysb.set, xscrollcommand=self.xsb.set)
opener = urllib.request.build_opener(urllib.request.HTTPHandler, handler)
setting2 = config2
set([5, 6])
ax = fig.add_subplot(111)
plt.show()
p.start()
self.name = name
gtk.main()
db.backup.insert(list(cursor))
django.setup()
my_logger.setLevel(logging.DEBUG)
main.py
print(df.head())
km = KMeans()
time.sleep(1)
screen = pygame.display.set_mode((640, 480))
[a, b]
index = np.array([0, 1])
client.options.transport.last_headers
sys.exit(rc)
date = datetime.datetime.fromtimestamp(timestamp)
pd.merge(df1, df2, left_index=True, right_index=True)
plt.draw()
parser = etree.XMLParser(recover=True)
PROJECT_ROOT = os.path.dirname(__file__)
today = date.today()
o.subscribe(my_callback_func)
print([x for x in range(1, 1000) if pred(x)])
raise SystemExit(1)
plt.show()
conn.close()
df = pd.DataFrame()
model_to_dict(instance, fields=[field.name for field in instance._meta.fields])
os.chdir(path_dir)
np.corrcoef(signal[:-1], signal[1:])[0][1]
print(dt - datetime.fromtimestamp(s * factor))
Decimal((0, a, -len(a) + 1))
df = df[df.end_date.notnull()]
metadata.create_all()
sys.stdout.flush()
total_loss = tf.add_n(losses)
gzip_file_handle = gzip.GzipFile(fileobj=url_file_handle)
ax = fig.add_subplot(1, 1, 1)
textfile.write(artigo)
whos
django.utils.simplejson.loads(someJson)
df.columns
self.show_progress(100)
response = view(request)
print(zdd1.join(zdd2).collect())
p[i] += 1
p2 = Process(target=func2)
Class.method(instance, argument)
pyximport.install()
gen1, gen2
np.add.outer(a, a)
r = requests.post(url, data=form_data, headers=user_agent)
hash(tuple())
mlab.start()
urllib.parse.quote(s)
DataFrame(foo, index=df.index)
process(line)
np.array([x for x in aset & bset])
self.__dict__ == other.__dict__
frames.append(df)
pd.to_datetime(s)
c.setopt(c.WRITEFUNCTION, retrieved_body.store)
s.connect((ip, port))
id = db.Column(db.Integer, primary_key=True)
m.bluemarble()
draw = ImageDraw.Draw(mask)
app.register_blueprint(filters.blueprint)
b[:len(a)] == a or is_sublist(a, b[1:])
wx.NO_BORDER ^ wx.SYSTEM_MENU ^ wx.MINIMIZE_BOX ^ wx.MAXIMIZE_BOX ^ wx.CLOSE_BOX
pd.read_csv(s, index_col=0, parse_dates=True, dayfirst=True)
self.navigate(-1)
main()
self.last_name = last_name
a = np.array([[5, 7], [12, 18], [20, 29]])
AaBbCcDdEeFfGgHhIiJjKkLlMNOPQRSTUVWXYZ
print(p.groupby(p.ne(p.shift()).cumsum()).cumcount())
df
main()
np.random.seed(0)
fig, ax = plt.subplots(figsize=a4_dims)
blurred = gaussian_filter(a, sigma=7)
d = dict(zip(m[::2], m[1::2]))
bot.polling()
sys.stdout = sys.__stdout__
d = dict(map(tabsplit, list1))
Obj1.grid_forget()
window.show()
fig, ax = plt.subplots()
process.stdin.close()
plt.setp(ax.get_xticklines()[-2:], visible=False)
Thread.__init__(self)
f.write(line)
map(convert, a)
print(d.foo())
urllib.request.urlopen(URL).read()
print(my_hex)
numpy.isfinite(myarray).all()
self._sock.sendall(data)
paramdata.to_csv(sys.stdout)
ser.readline()
p1.stdout.close()
df[df.apply(lambda x: x.A in x.B, axis=1)]
sum(x is 0 for x in arr)
file_bytes.seek(0, 0)
main()
self.client = paramiko.SSHClient()
x = numpy.array([0, 1, 1, 2, 2, 2])
np.random.shuffle(curr_data)
self.layout.addWidget(self.button1)
second = [y for x, y in data]
conn.commit()
buf.seek(0)
complete_path = os.path.abspath(complete_path)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
os.play()
lowcut = 500.0
run()
result = a[np.argsort(a)[:k]]
app.exec_()
PWD = os.path.dirname(os.path.realpath(__file__))
sizes = [display.GetGeometry().GetSize() for display in displays]
test.py
[0, 1, 2]
self.value = self.left.value + self.right.value
lines.append(text)
time_start = time.time()
func()
chapter = form.save()
f, axarr = plt.subplots(2, 1)
datetime.datetime(d.year, d.month, d.day)
len(np.unique(arr)) == 1
print([x for x in a if x not in b] + [x for x in b if x not in a])
s.set_debuglevel(0)
parser.parse(f)
A = np.empty((len(x), 2))
col_idx = np.array([0, 2])
x = np.arange(1000)
sum(list(dict.items()), ())
func(**r._asdict())
arr.reshape(k, 2, k, 2).swapaxes(1, 2).reshape(k, k, 4).max(axis=-1)
session.add(foo)
pairs = tuple(combinations(list(range(len(A[0]))), 2))
heapq.heappush(heap, (a + b, a, b))
plt.clf()
plot(x, y2s)
scipy.stats.poisson.cdf([4, 17], 10)
print(slept)
fig.canvas.draw()
pl = pl[:5]
root = Tk()
np.diff(array1) - lens[:-1] + 1
x.append(np.nonzero(np.in1d(a, c))[0])
key = lambda x: x[1][0]
a[:, (1)].toarray()
data = sys.stdin.read()
print(new_list)
SudsObject.__init__(self)
task.revoke(terminate=True)
label_Image.setPixmap(QtGui.QPixmap.fromImage(image_profile))
data.reshape(2, -1)
ResultSerializer(results, many=True).data
QWidget.__init__(self, parent)
plt.show()
thread.start()
np.random.seed(2015)
QApplication.setOverrideCursor(QCursor(QtCore.Qt.WaitCursor))
print(sys._getframe().f_code.co_name)
pygame.init()
print(link.url, link.text)
out, err = proc.communicate()
main2()
wait = WebDriverWait(driver, 10)
help(module)
my_list = [int(i) for line in f for i in line.split() if i.isdigit()]
answer.append((alo, blo))
x = numpy.zeros((i, j, k))
profiler.start()
new_arr = arr.reshape(-1, arr.shape[-1])
pdb.set_trace()
sys.exit(app.exec_())
ax1.bar(x, y)
length = len(string)
os._exit(0)
int(hashlib.sha1(s).hexdigest(), 16) % 10 ** 8
self.set_text(new_text)
server.start()
assert hash(a) == hash(b)
window.show()
list1_indices = {item: i for i, item in enumerate(list1)}
print(x[:10])
clf.fit(X, y)
n if n - 1 < x <= n else n + 1
sys.stdout.write(line)
print(data)
HttpResponse()
a * np.exp(-b * x) + offset
datastream.seek(0)
l[:x] + l[-y:]
time.sleep(duration)
quote.save()
do_something_based_on_the_request_endpoint(request)
app = web.application(urls, globals())
x, y = foo(50)
app.config.from_object(__name__)
p.terminate()
print(repr(a))
plt.show()
locale.setlocale(locale.LC_COLLATE, old_locale)
print(requests.get(url, proxies=proxies).text)
foo.__code__.co_consts[1].co_consts[2].co_cellvars
numpy.isnan(a).any()
os.kill(os.getpid(), signal.SIGUSR1)
time.sleep(2)
elapsed = time.time() - t
total += int(row[1])
results = query.all()
ax.legend()
dfrand = pd.DataFrame(data=np.random.randn(data.shape[0], data.shape[1]))
app.exec_()
os.system(bashCommand)
[tuple(getattr(obj, field) for field in fields) for obj in listobj]
a[np.abs(a) < eps] = 0
main()
plt.xlim([-0.5, len(values) - 0.5])
ax = plt.gca()
plt.show(block=False)
stations = []
dist(site1[0], site1[1], site2[0], site2[1])
float_to_str(4.2e+17)
print(arreq_in_list(myarr1, mylistarr))
round(float(x) / 500) * 500
p.start()
ao[:-1, :-1] += ai[1:, 1:]
self.button.append(Button(frame, text=name, command=callback))
plt.plot(z, f(z, tval))
time.sleep(120.0)
f.__class__
fig = plt.figure()
print(dt + datetime.timedelta(days=d + 1))
e = 0.081819191
s.listen(1)
replace = [(y, z + 1), (x, y + z), (z, a)]
f.writelines(lines)
ax.add_collection(collection, autolim=True)
ax.imshow(img, extent=[min(xi), max(xi), min(yi), max(yi)])
t.start()
setattr(self, method, wrapped_method)
print(stdout.read())
all(x != y for x, y in zip(s[:-1], s[1:]))
next(reader)
mydict.setdefault(mykey, myfunc())
a[np.lexsort(np.transpose(a)[::-1])]
out = mat[0] * (len(ixs) - np.count_nonzero(nzmask)) + nzsum
do_something()
response = request.execute()
Thread(target=callback).start()
_trace(args[0])
fig, ax = plt.subplots()
newID = db.insert_id()
driver = webdriver.Firefox()
element.remove(subelement)
conn.close()
fig.tight_layout()
a.sort(key=len, reverse=True)
test.py
sys.stdout.write(line)
signal.signal(signal.SIGTERM, lambda signum, stack_frame: sys.exit(1))
c = np.tile(a, (b.shape[0], 1))
A.__init__(self)
pythoncom.PumpMessages()
int(x * 10 ** (1 + a) + y)
label = np.random.random((100, 100))
plt.bar([1, 2], [5, 4])
print([(c.rate(), c.accrualPeriod()) for c in coupons])
db.create_all()
fileHandler.setLevel(logging.DEBUG)
writer.writerow(codecs.BOM_UTF16_LE)
result = np.average(_array, axis=1)
signal.signal(signal.SIGINT, my_signal_handler)
lesser + [pivot] + greater
list(a)
print ()
print((11 + 7) % 12)
conn.setopt(pycurl.FOLLOWLOCATION, True)
soup = BeautifulSoup(html)
list(Project.__table__.columns.keys())
channel.start_consuming()
mylist.pop(0)
unittest.main(failfast=True)
item.active = not item.active
df[(df > 0).all(1)]
assert rdd.squares().collect() == [1, 4, 9]
tuple(list(zip(*G))[0])
result.setdefault(widget_type, []).append(app)
plt.subplots_adjust(hspace=0.0)
ext = os.path.splitext(path)[1]
v = np.array([0, 1, 2])
[id(x) for x in a]
TLabels = np.array([-1, 1, 1, 1, 1, -1, -1, 1, -1, -1])
self.__class__.num += 1
FlaskApplication().run()
json.JSONEncoder.default(self, o)
list_of_tuples = [(1, 2), (4, 5)]
False
app.run(debug=True)
g.user = current_user.username
plt.gca().yaxis.set_minor_locator(mpl.ticker.NullLocator())
app.MainLoop()
val = rtpinterpolator(xyz2rtp(x, y, z))
sorted(my_set, key=natural_sortkey)
sum(args) == 1
g = nx.Graph()
db.session.add(p)
aic.append(x)
comments = soup.findAll(text=lambda text: isinstance(text, Comment))
g = a + b + np.sqrt(d * d + e * e + f * f)
self.list[key]
func()
app = Flask(__name__)
col_names = sorted(list(col_dict.items()), key=lambda x: x[0])
deleted[key]
print(do_something())
window.show()
interleave(lst[:len(lst) / 2], lst[len(lst) / 2:])
time.sleep(1)
x = np.arange(100).reshape(10, 10)
dest.close()
np.kron(a.reshape(-1, 2), np.ones((2, 2), dtype=int))
my_array = np.clip(my_array, minN, maxN)
fig.canvas.draw()
ax = fig.add_subplot(111)
graph = GraphAPI(oauth_access_token)
fg.canvas.draw()
print(df)
root.after(0, add_letter)
sa, sb, sc = [str(e) for e in [a, b, c]]
sc.parallelize([], n).count()
self.rebuild_index()
br = mechanize.Browser()
globals()[string1 + string2]()
plt.plot(data)
s.write(line)
logging.basicConfig(level=logging.DEBUG, format=FORMAT)
a.sum(axis=1)
l.pop()
result = []
items.sort(key=lambda obj: (obj.firstname, [(-ord(c) for c in obj.lastname)]))
setp(ax.get_yticklabels(), fontsize=8)
json.loads(json.dumps([dict1, dict2]))
decorator
help(foo)
list_list.append(list1)
self.ProgressBar.SetValue(event.count)
self.thread.start()
-min((x, -i) for i, x in enumerate(values))[1]
plt.subplot(6, 1, 2)
self.setCentralWidget(widget)
plt.show()
name = models.CharField(max_length=255)
print(row.rstrip())
str(int(match.group(0)) - 1)
ax = fig.add_subplot(1, 1, 1)
file.close()
obj_list = [x.obj for x in set(HashMyAttr(obj) for obj in obj_list)]
self.fd.close()
m.fit(X, y)
fig, ax = plt.subplots()
s.between(0, 1)
e2.pack()
betterdata = numpy.concatenate((maybeinliers, alsoinliers))
dict((f, getattr(self, f)) for f, _ in self._fields_)
os.unlink(file)
result_dict[k] = v
wjoykhsapcmvjmar
reader.SetFileName(filename)
self.num += 1
print(line)
reactor.run()
dir(__builtin__)
time.time() - start
flatten_to_strings(list_of_menuitems)
os.killpg(p.pid, signal.SIGKILL)
print([(x, y) for x in range(5) for y in [f(x)] if y != 2])
setattr(cls, name, new_value)
ys = lowess(y, x)[:, (1)]
P = expm(A)
a.append({mykeys[n]: values[n] for n in range(0, len(mykeys))})
r = func(*args, **kwargs)
self.transport.write(self.name, (self.host, self.port))
m.put(k, m.get(k) + 1)
writer.writerow(row)
window = QtGui.QMainWindow()
print((letter, count[letter]))
self.setSceneRect(0, 0, width, height)
datetime.time(*values)
FooModel.objects.get(pk=1).children.all()
test = array([[0, 1, 2], [1, 1, 6], [2, 0, 4]])
background.paste(top, (0, 0))
testRust()
[x for x, y in pairwise(xs) if x != y]
self.ax.set_xlim(self.min_x, self.max_x)
self.file.flush()
df[df.line_race != 0]
PyQt4.QtCore.QPoint(1867, 416)
picture.putpixel((x, y), new_color)
list(mkimap())
gradients
cvs = df.columns.values
NUMBER_OF_EXCEPTIONS += 1
copy + copy_to_depth(item, depth - 1)
z = [int(i == j) for i, j in zip(x, y)]
fig, ax = plt.subplots()
cursor.execute(query)
all_labels.sort()
self.assertEqual(self.seq, list(range(10)))
f.write(bitbufstr)
list(compress(listOfTuples, bool_array))
print(f.read())
img_gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
(values.cumsum() - ALLOWANCE).clip_lower(0).diff().fillna(0)
zin.close()
gray2b = cv2.warpAffine(gray2, Minv, shape(gray2.T))
HttpResponse(escape(some_string))
self.newargument = myarg
myfile2.write(text)
plt.show()
graceful = argparse.ArgumentParser(add_help=False)
print(s)
a = concat(a, b)
time.sleep(1)
map(itemgetter(1), rows)
ax1 = fig.add_subplot(111)
bisect.bisect == bisect.bisect_left
func(*args, **kwargs)
plt.title(title)
now.replace(minute=now.minute - now.minute % 15, second=0, microsecond=0)
floored_data = data.apply(np.floor)
Script1.py
A.objects.filter(id=some_a.id).update(hidden=False)
print(sys.stdin.read())
script = os.path.abspath(sys.argv[1])
pairs = tuple(combinations(list(range(len(A[0]))), n))
df.loc[new_index] = pd.Series([99], df.columns)
plt.figure()
good = [x for x in mylist if x in goodvals]
id(Point(1, 2)) == id(Point(1, 2))
loop.run_until_complete(asyncio.wait_for(asyncio.sleep(60), 5))
print(html2text.html2text(html))
link.click()
clientsocket.send(r.encode())
image.show()
root = etree.fromstring(xml)
server.ehlo()
output_file.write(ablob[0])
warning.setLevel(logging.WARNING)
print(args.file.readlines())
module
sorted(set(a).intersection(xyz))
fixedser.dropna().plot(ax=axes[1])
newser.dropna().plot(ax=axes[1])
figure.canvas.draw()
app.MainLoop()
func_a(s)
driver.get(url)
nzsum = np.take(mat, ixs[nzmask], axis=0).sum(axis=0)
sys.exit(app.exec_())
l.append(x[:k])
list(pairs(board))
now = datetime.datetime.now()
m.close()
numpy.set_printoptions(precision=15)
answerlist.extend(templist[:lengthmodified])
se = pd.Series(mylist)
_finditem(v, key)
workList.sort(key=len, reverse=True)
foo.x = 0
main()
[(double(x) if isinstance(x, list) else x * 2) for x in numberlist]
fig = pyplot.figure()
ax.set_xticks(bins)
cookies = browser.get_cookies()
pg.draw.rect(surf, STIMCOL, (60, 70, 80, 90))
time.sleep(5)
jsonify(username=g.user.username, email=g.user.email, id=g.user.id)
image = Image.open(image_in_path)
x if x < y else y
something()
fig = plt.figure()
new_list.append(tmp_list)
fig = plt.figure(figsize=(5, 10))
list(dill.detect.badtypes(f, depth=1).keys())
admin.site.register(User, UserAdmin)
text = models.TextField()
pool = Pool()
pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)
scipy.linalg.solve(X, Y)
insert_sort(descend_list, i, lambda x, y: x[1:] < y[1:])
display(fig)
self.Refresh()
pd.DataFrame(list(ds1.difference(ds2)))
df
df
test(1, 2)
s.connect((host, port))
[1, 0, 1],
resp = urllib.request.urlopen(request)
self.driver = webdriver.Firefox()
ax = fig.add_subplot(111, polar=True)
print(map(lambda x: dict(zip(reader[0], x)), reader))
print(os.getpid())
resp.set_data(soup.prettify())
fig.multi_line(y_err_x, y_err_y, color=color, **error_kwargs)
c += initval2
np.array(b)
permutate(n, k) // permutate(k, k)
other_file.py
sys.exit(app.exec_())
sorted(list(y.items()), cmp=reverse_comparison)
print(word[1], word[0])
output, output_err = p.communicate(myfile.read())
all(c in string.printable for c in bell)
parser.print_help()
sum(ele[1] == 1 for ele in a)
ax.set_position([0.1, 0.1, 0.5, 0.8])
list(skip(list(range(10)), at_start=2, at_end=2))
f1.close()
WSGIScriptAlias / myapp / code / wsgi / wsgi.py
test.postmodel_set.all()
print(max(node.y for node in path.nodes))
self.setCentralWidget(self.view)
math.ceil(float(177) / 10)
np.random.seed(0)
d1.x1 - d2.x2.values
numpy.array([Register() for i in range(4)])
application = QtGui.QApplication(sys.argv)
print(i, list(csv.reader(source)))
setattr(e, key, val)
result = np.empty_like(zeta)
chars.append(c)
n = random.randint(1, 1000)
b = [indicies[elements == i] for i in range(1, N)]
do_something_else(array[-1])
p.stdin.write(answer)
self.setStrokeColorRGB(0, 0, 0)
set(a).intersection(b)
Image.open(filepath)
s[-1]
0.0, -64.0, 208.0, 0.0, -90.0, 0.0, -80.0, 0.0, 0.0, -80.0, -48.0
plot([4, 5, 6])
time.sleep(0.1)
main()
b = OrderedDict(sorted(a.items()))
np.set_printoptions(**original)
h = [[0, 0, 1][0, 0, 0][-1, 0, 0]]
serializer = UserSerializer(data=request.DATA)
neurons.append(neuron)
b = numpy.arange(5)
sat = im.cumsum(1).cumsum(0)
plt.show()
main()
self.toolbar.update()
hash({})
strat0.execute()
msg.attach(attachment)
latex_float(1000000000.0)
bisect.bisect(l, 55)
print(socket.gethostname())
A[np.where(~np.isnan(A))[0][0]:]
df.stack().str.split().str[-1].unstack()
server.serve_forever()
sys.stderr = os.devnull
Path(__file__).parent.parent
collections.OrderedDict()
plt.show()
print(get_last_non_zero_index([]))
Response(serializer.data)
ax.set_xticks(xticks[1:-1])
val = hex(val)
indices_nonzero = numpy.arange(len(array))[~bindices_zero]
theta_edges, r_edges = CartesianToPolar(xedges[:-1], yedges[:-1])
history.append(item)
app.mainloop()
response_doc = etree.fromstring(body, parser)
chardet_detector.close()
now = utc.localize(datetime.datetime.utcnow())
numbers.append(map(int, line.split()))
dt + datetime.timedelta(seconds=delta)
pickle.dump(requests.utils.dict_from_cookiejar(session.cookies), f)
list1 = [1, 1, 1, 0, 0]
merged = list(joinz(0, zusers.iter(), 0, zratings.iter()))
f(1, np.pi)
Z = itp(X, Y, grid=False)
soup = BeautifulSoup(totstring)
images = [image for seq in images for image in seq]
mod.__file__
self.stopped = True
points.append((x, y))
plt.scatter(data1, data2, c=colors, cmap=my_cmap)
data = conn.recv(4096)
self.setWindowFlags(self.windowFlags() | QtCore.Qt.FramelessWindowHint)
ser = pd.Series(np.random.normal(size=100))
pix = im.load()
options[0]
plt.yticks(rotation=0)
colors = hsv(np.linspace(0, 1.0, len(kinds)))
norm.ppf(0.5)
sine_list.append(math.sin(2 * math.pi * freq * (x / frate)))
print(child.tag, child.attrib, child.text)
a.func()
x = lst.pop()
print(ridge.coef_)
[a for a in s if len(a) > 0]
app.exec_()
d.update(dict(d))
hbar.config(command=canvas.xview)
B_p.to_csv(sys.stdout)
M.iloc[index][col]
Signal.send_robust(sender, **kwargs)
self.response.out.write(output.getvalue())
shapesMatch([(0, 0), (1, 1), (0, 2), (-1, 1)], l_shape)
X, Y = np.meshgrid(X, Y)
sorted(randlist2(2000000000, 10000000, 1900000000))
plt.show()
unplugged()
pid = proc.pid
entretien_send_email.send_mail(self.id)
printout()
time.sleep(1)
signal.signal(signal.SIGINT, lambda number, frame: sys.exit())
pprint.pprint(tup, depth=6)
c, b
db.init_app(current_app)
list(zip(lst[:-1], lst[1:]))
name = models.CharField(max_length=100)
tree = ElementTree.parse(StringIO.StringIO(output))
hl, = plt.plot([], [])
{{formset}}
plt.axis([xmin, xmax, ymin, ymax])
p = Process(target=f, args=(arr,))
__init__.py
a, b, c
fig.tight_layout()
print(df.to_latex())
app = Flask(__name__)
dill.pickles(Foo.x)
oneone
s.fillna(0).plot()
all(a == b for a, b in zip_longest(gen_1, gen_2, fillvalue=sentinel))
ax.add_artist(ell)
flt = float(random.randint(0, 100))
case(re.search(pattern, st))
idx = np.arange(n)
out.close()
python / Users / luca / Documents / python / gameover.py
a[indices]
averaged = {k: (v / len(folds)) for k, v in list(summed.items())}
db.test.remove(doc_id)
send_email()
game.update()
(rollingcor.sum(skipna=0).sum(skipna=0) - n) / 2 / n
pickle.dump(dict2, fp)
my_objects = []
set(l1) | set(l2)
im.set_clip_path(clip_path)
print(line)
(0 < x) & (x < 1)
constr = []
self._points = []
local_tz = tzlocal.get_localzone()
raise KeyError(key)
fh.setLevel(logging.DEBUG)
newlist.append(d)
trainer = deepbelief.DeepBeliefTrainer(net, dataset=ds)
ax = fig.add_subplot(111)
root = tk.Tk()
pickle.dump(score, file)
df.ix[:, (2)]
image.save(self.get_thumbnail_path())
f.write(something)
ax.set_xlim(0, X)
sum(i == word for word in str1.split())
imresize(np.ones((1000, 1000)), (100, 100)).shape
len1 = math.hypot(x1, y1)
a.set_xlim(0, 4 * pi)
[x[i:i + step] for i in range(0, len(x), step)]
print([list(b) for b in zip(l, inner)])
ax.yaxis.set_major_formatter(ticker.FuncFormatter(myLogFormat))
tpool = ThreadPool(processes=4)
df.info()
self.crawler.engine.crawl(self.create_request(), spider)
smtp.sendmail(send_from, send_to, msg.as_string())
httplib.HTTPConnection.connect(self)
sorted(numbers)[-2]
plt.figure(figsize=(4.5, 2.5))
print(D.x.value)
themsg.attach(msg)
item
chain.from_iterable(combinations(s, r) for r in range(len(s) + 1))
ax1 = fig.add_subplot(111)
urllib.request.urlopen(request)
func(*args, **kwargs)
step = datetime.timedelta(days=1)
p.start()
start_date = start_date.replace(tzinfo=local_tz)
pylab.show()
os.remove(path)
img = np.uint8(np.random.random((720, 1280)) * 256)
win.set_decorated(False)
browser = webdriver.Firefox()
matches = regex.findall(my_str)
sess.run(apply_transform_op)
itertools.chain(iter(self.items.values()), iter(self.people.values()))
ax.plot(list(range(10)))
arr = np.vstack((arr, np.array([4, 5, 6])))
G = nx.Graph()
soup = BeautifulSoup(html_page)
sum(1 if int(line) % k == 0 else 0 for line in sys.stdin)
pythoncom.CoInitialize()
all_data.shape
root.withdraw()
plt.plot(y)
ax = plt.subplot(gs[i, j])
db.delete(q.fetch(200))
print(np.allclose(res1, res2))
fig.canvas.draw()
getattr(self.cp, attr)
alltests = unittest.TestSuite([fast, slow])
engines.append(engine)
self.finish()
self.tk.config(menu=self.menu)
new_list = copy.copy(old_list)
print(firstMatch.group())
s.setsockopt(socket.IPPROTO_IP, socket.IP_HDRINCL, 1)
csvout.close()
fig, ax = plt.subplots()
type(s)
a.max(axis=0)
self.setCentralWidget(self.web_view)
writer.writeheader()
sess.run(tf.initialize_all_variables())
fig.subplots_adjust(wspace=0.05)
fs.noteoff(0, 67)
x = 2
plt.show()
myQuery.Availability
tar.extractall(path, get_members(tar, args[1]))
assert len(yields1) == len(list_of_yields)
A[:] = (sub for sub in A if st.issubset(sub))
reader = csv.reader(f)
velcro.right(180)
do_something(val)
word_list.sort(key=lambda i: i[0].lower())
lowdiag = [0.5] * (n - 1) + [0] * 2
odeint(func, y0, t, *list1)
print(Second_row_first_column.strip() + Second_row_second_column.strip())
l = sorted(list(d.items()), key=lambda x: x[1], reverse=True)
p.start()
df
ax.xaxis_date()
np.sin(y * x) + z
points = np.random.randint(0, 5, (10, 2))
list(chain.from_iterable(pattern.split(w) for w in input_list))
print(f.text)
s.setsockopt(SOL_SOCKET, SO_BROADCAST, 1)
curs = conn.cursor()
pygame.event.pump()
s[~s.index.duplicated()]
plt.axis([0, 10, 0, 10])
compressor.close()
n = a.shape[0]
[(k1[0], k1[1], k2) for k1, k2 in zip(chain.from_iterable(dge), nde)]
cv.Rectangle(color_image, pt1, pt2, cv.CV_RGB(255, 0, 0), 1)
sys.exit(0)
max(zip((x.count(item) for item in set(x)), set(x)))
list(range(int(toks[0]), int(toks[1]) + 1))
f.close()
app.MainLoop()
print(parser.parse_args())
print(name, value)
self._worker_handler.start()
vbox.add(label)
lambda a, b: (a + 1, b * 1)
demangled[:-1]
model.train_on_batch(state_action_vector, target)
ax1.set_xlim(0, 60)
self.assertEqual(a, b)
numpy.finfo(numpy.longdouble)
screen = pygame.display.set_mode((500, 500))
int(round(5678, -1))
print(df.eq(df.iloc[0]))
sorted(set(range(start, end + 1)).difference(L))
print(combinedRDD.collect())
data += proc.stdout.read()
server.start()
plt.tight_layout()
surfc = ax.plot_trisurf(Xc, Yc, Zc, cmap=cm.jet, linewidth=0.2)
html = urlopen(url).read()
keys.insert(i, k)
np.floor(series)
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
[[l[x] for l in lists] for x in range(len(lists[0]))]
mainloop()
tst.main(globals())
{k: [da.get(k, []), db.get(k, [])] for k in set(listanum + listbnum)}
s.setsockopt(socket.SOL_TCP, socket.TCP_KEEPCNT, 5)
print(re.findall(pattern, line))
pbar.finish()
image.swapaxes(0, 1), out
print(nums.mean(axis=1))
get_value(d[l[0]], l[1:])
y = np.random.rand(m, n)
out.close()
logger.addHandler(handler)
print(new_pressures)
print(f())
nosetests - v
remove_even([4, 5, 4, 7, 9, 11])
response = urllib.request.urlopen(req)
Label.__init__(self, master, image=self.frames[0])
d[a].append(b)
x[0::2]
self.n += 1
wr.writerows([k] + v for k, v in list(od.items()))
window.show_all()
df.mean()
final_list = sorted(pos_list) + sorted(neg_list)
pickle.dump(saved_data, outfile, protocol=pickle.HIGHEST_PROTOCOL)
datetime.datetime(*dtuple[:6])
s.compute()
list_1 = [i for n, i in enumerate(list_1) if n not in index_list]
your_csv_file.close()
book = xlwt.Workbook()
df.groupby(np.arange(len(df)) // 2).mean()
ax.add_line(line)
var_1 = type(var_2)()
data.sum()
d[key] = value
button.pack()
p = Pool(5)
testdataframe1.plot(style=styles1, ax=ax)
list(set(a) - set(b))[:100]
plt.figure()
density = scipy.stats.gaussian_kde(scatterpoints)
ax.set_ylim(-0.5, 4.5)
b[:, ([True, True, True, False, False])]
pd.concat([df[col].apply(pd.Series) for col in cols], axis=1, keys=cols)
writer.writerow(row)
list_2 = [i for n, i in enumerate(list_2) if n not in index_list]
events.append([])
e.findall(data)
add_patch(axes[0], alpha=0.2, rasterized=False)
zk.start()
ax.add_patch(polygon)
df = pd.read_csv(StringIO(text), parse_dates=[0])
id = Column(Integer, primary_key=True)
results.append(pool.apply_async(foo, args=(words[i], numbers[i])))
list(range(item.start or 0, item.stop or len(self), item.step or 1))
window.show()
string.ascii_letters[:random.randint(1, 50)].title()
{{instance.key().name()}}
app.mainloop()
time.sleep(0.25)
Base.metadata.create_all()
processed_images = tf.map_fn(process_fn, images)
sorted(results)
df = df.unstack()
Tkinter.Label(root, image=imgtk).pack()
self.show()
res.extend([entry[1:], entry[:1]])
np.array(a) - np.array(b)
user.save()
np.isnan(np.nan)
plot_selected.yaxis.set_ticks(np.arange(0, 1.1, 0.2))
self.wb.save(self.dest)
proc.join()
ax1 = fig.add_subplot(111)
fig.subplots_adjust(right=0.75)
set(perms)
int(round(5678, -2))
x = numpy.random.uniform(1.5)
self.Bind(wx.EVT_LEFT_UP, self.OnClick)
orig_stdout = sys.stdout
points = np.random.randint(0, 5, (N, 2))
self.thisptr.calculate()
self.spinbox.valueChanged.connect(self.worker.update_value)
d = dict((an_object.name, an_object) for an_object in object_list)
autosummary_gerenerate = True
filename = sys.argv[1]
f.close()
[(1 if any(full.endswith(last) for last in B) else 0) for full in A]
np.allclose([np.where(a <= x)[0][0] for x in b], np.digitize(b, a))
ax.set_xlim(0, 1)
n = n % len(strg)
out = np.where(mask, np.nan, a)
print(i, chr(i))
session.commit()
gzip_obj.read()
result = timedelta1 + timedelta2
first_name = models.CharField(max_length=50)
x[index]
sys.exit()
QGraphicsTextItem.mouseMoveEvent(self, event)
user.groups.add(group)
t.start()
x ** 2 + y ** 2 + z ** 2 < radius ** 2
R_mean1.append(R)
s = s.lower()
output = np.array([1, 1, 5])
output.writeframes(data[1][1])
time.sleep(0.1)
ax = plt.subplot(gs[:, :])
plt.subplot(121)
app = Flask(__name__)
ax.tick_params(labelsize=8)
print(x)
object.__getattribute__(self, name)
wx.version()
c = f.read(1)
print(fig.axes[0])
self.__dict__.update(d)
self.q.join()
print(foo[1:5, (1), (2)])
self.wsgi_app(environ, start_response)
sub_cmd.cmdloop()
test()
df[idx]
nosetests - -all - modules
res = dict([(t, nt(*t)) for t in pairs])
data.sort(key=get_score, reverse=True)
sys.exit(app.exec_())
df[df.b.isnull()]
[int(line) for line in f]
im2.set_xdata(np.arange(n))
dynamic(name, bases, attrs)
Value2 = Baz
query = query.filter(and_(*filter_group))
fulldict = {i: i for i in range(1000)}
indices[field][key].add(i)
plt.show()
new.setdefault(i, []).extend(j)
print(list([x for x in words if len(x) > average]))
self.write(data)
outeropt = outer_result.get()
time.sleep(1.0 - elapsed)
self.mainframe.rowconfigure(1, weight=1)
all_pairs += [((nA, 0), (nB, 1)) for nA, nB in itertools.product(listA, listB)]
df.columns = ts_clip.iloc[:len(df.columns)].index.time
value
item, value
text.pack(expand=1, fill=BOTH)
print(settings.BASE_DIR)
layout.itemAt(i).widget().deleteLater()
areas.apply(foo)
sum(l) + 0.529964086141668
averaged = {k: (sum(d[k] for d in folds) / len(folds)) for k in folds[0]}
scipy.misc.factorial(temp)
plt.bar(indexes, values, width)
lambda a, b: (a + 1, b * 1)
app.exec_()
w.GetWindowText(w.GetForegroundWindow())
sys.exit(-1)
plt.show()
0.0054 is 0.0054
self.output(0.1, Op.setlinewidth)
pd.get_dummies(df.Knownvalue // 10)
dd.min(axis=1)
foo.sort()
parser = argparse.ArgumentParser()
im = A2.shape[1] - 1 - np.argmax(A2[:, ::-1] < 0, axis=1)
resp.raise_for_status()
preincrement(i)
self.setLayout(self.layout)
1j * numpy.inf * 1
intersection = queryset1 & queryset2
user_input = user_input.strip().lower()
ax0b.get_yaxis().get_offset_text().set_size(10)
ax0c.get_yaxis().get_offset_text().set_size(10)
df = pd.DataFrame(data)
potential(abs(b[np.triu_indices_from(b, 1)])).sum()
linesamples.add(int(4 * i + 1))
s.bind((HOST, PORT))
link.allow_tags = True
my_array = my_array.reshape(nrows, ncols)
root = tk.Tk()
w.close()
isinstance(d, dict)
dic[mygroup].append(entry)
conj = rdflib.ConjunctiveGraph()
r = s.post(url, data=data)
HypotheticalBranch(0, 0, 0)
time.sleep(0.01)
pool = Pool()
pdb.set_trace()
cv2.waitKey()
G = nx.Graph()
[u for u in self.custom_fields if self.cleaned_data[str(u.id)]]
row.insert(0, a)
G.add_node(1)
[x for y in l if len(y) < 4 for x in y if isinstance(x, int)]
random.shuffle(order)
widget.show()
obj.__class__ = cls
frame.set_linewidth(0)
dir(obj)
(-np.array(avgDists)).argsort()[:n]
toc2()
print(repr(s))
print(df1.columns.unique())
a, b, c, d, e, f = flatten(v)
i.close()
line = file.readline()
pp(list(map(list, zip(*grid))))
main()
this_row.append(s.cell_value(row, col))
plt.ylim(-20, 60)
your_csv_file.close()
df
self.set_positions((xs[0], ys[0]), (xs[1], ys[1]))
list(intersect(*postings))
x = np.array(x)
Base.Foo(self)
db.session.add(entry)
html_use_index = True
x = np.array([0.1, 0.2, np.nan, 0.4, 0.5])
ax1.plot(np.array([1, 5]) * i, label=i)
ynew = csc_matrix((data, (rows, cols)), shape=(N, M), dtype=dtype)
pdb.set_trace()
q, r = divmod(x, y)
s.connect((HOST, PORT))
matplotlib.pyplot.close(f)
sc = SparkContext()
allkey = set().union(*alldict)
[int(c) for c in s if c.isdigit()]
screen = pygame.display.set_mode((640, 480))
os.mkfifo(path)
self.lock.acquire()
ax1.plot(x, y)
d = {x: i for i, x in enumerate(lis)}
foo.py
print(len(list1))
data = np.genfromtxt(urllib.request.urlopen(url), skip_header=1, skip_footer=4)
(i * i for i in range(5))
asyncio.get_event_loop().run_until_complete(start_server)
app = QtGui.QApplication(sys.argv)
x = tab.query()
y_pred = pipe_lrSVC.predict(X_test)
np.maximum.accumulate(idx, axis=1, out=idx)
celery.start()
np.array(tmp).reshape((len(longlist), len(longlist[0])))
QtGui.QItemDelegate.__init__(self, parent)
m2[np.asarray(m2[:, (1)] > 10).flatten()]
strncpy(addr.sun_path, UD_SOCKET_PATH, sizeof(addr.sun_path) - 1)
soup = BeautifulSoup(data)
mylist.remove(max(mylist))
p.parse_args([])
reader = csv.DictReader(f)
pprint.pprint(combs)
add_cols(*x.T)
painter.rotate(-angle)
list(d.items())[1]
self.canvas.config(scrollregion=self.canvas.bbox(ALL))
ax.xaxis.get_minorticklines()
modinv(exp, (p - 1) * (q - 1))
df5 = pn5.to_frame()
csv_row = line.split()
response = urllib.request.urlopen(url, data, headers)
sns.kdeplot(x, ax=ax2)
f.seek(-len(os.linesep), os.SEEK_END)
self.changeLayout(QtCore.Qt.Vertical)
list(set(x) & set(y))
print(format_float(1500000.0))
A = A[np.ix_(L)]
self.assertTrue(mock_bar.called)
p.start()
wav_file.close()
sum(is_monotonic(num, reverse) for num in range(start, end))
len(set(a) - set(b))
random.sample(a, len(a) + 1)
l.append(row[i])
pyplot.show()
thread.start()
Book.create_table()
print((a, b, c, d))
app = QtGui.QApplication(sys.argv)
normX = np.sqrt(ssX)
sess.run(init_op)
logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)
cursor = connection.cursor()
df.sum()
my_module.__file__
pdb.set_trace()
file.save()
self._thread.start()
button.pack()
[int(line) for line in f]
df
iter(List)
channel.queueDeclarePassive(queueName).getMessageCount()
ssh = paramiko.SSHClient()
ax.set_yticks([0, 0.5, 1])
data.append(fileData)
threading.Thread.__init__(self)
data = np.random.uniform(-1, 1, fs)
print(browser.title)
max(-15, 0)
blank_image.paste(image64, (0, 0))
int(time.mktime(d.timetuple()))
p.start()
soup = BeautifulSoup.BeautifulSoup(your_data)
foo.start()
yaml.load(s)
[5, 6, 10]
vc.release()
text = open(filename).read()
plt.plot(list(range(10)))
sys.stdout.flush()
np.array([float(sym.subs(all_dict)) for sym in syms])
some_fun()
meta.py
section_sums = mask.reshape(-1, 20).sum(1)
cursor = db.cursor()
find_chamber_discard2(locals())
dict(const1=const1, const2=const2)
users = User.objects.all()
writer.writerow(next(reader))
self.ui.gridLayout.update()
readFileObject.close()
bin(-4)
print(sum(s) / len(s))
set(l1).intersection(l2)
a_string.encode(encoding)
ranges.append((4, 10))
dot(Phi, R)
[sublist for sublist in list_ if sublist[1] != 1]
my_data.append(line)
file.seek(0)
pygame.sprite.spritecollide(hook, fish, False, pygame.sprite.collide_circle)
time.sleep(1)
d += timedelta(days=inc)
thread.start()
self.ax.set_autoscaley_on(True)
app.exec_()
print(msg.get_payload())
a, b = [], []
np.vstack([a, b])
a[0:1][0] = 4
tuples = [(freq, word) for word, freq in D.items()]
x + 1
a[:, (1)] = -1
print(numpy.array_equal(new_data, output))
client.connect(server, port, user, password)
canvas.itemconfigure(cwid, width=wi, height=hi)
self.button.grid(row=1, column=0, sticky=W)
sys.stdin = sys.__stdin__
rdd.groupByKey().mapValues(lambda x: sum(x) / len(x)).collect()
print(scipy.optimize.brentq(f, 0.0, 100.0, args=(77.0 / 27.0, 1.0, 1.0, 10.0)))
a, b = int(a), int(b)
df = pd.DataFrame(delimit)
t = datetime.timedelta(seconds=1)
queens = [(i, random.randint(1, 8)) for i in range(1, 9)]
cv.SetCaptureProperty(camcapture, cv.CV_CAP_PROP_FRAME_HEIGHT, 720)
a.newMethod = newMethod.__get__(a, A)
thread.start()
file.readline()
df.iat[0, 0]
widget.setLayout(layout)
Thread(target=recv).start()
()
func()
len(max(tup, key=len))
logger.setLevel(level)
df.plot(ax=axs, alpha=0.7)
next_num = cur.fetchone()[0]
session_id = hismgr.get_last_session_id()
main(**vars(args))
data = cursor.fetchone()
[gu(i) for i in range(len(uo))]
template.render(context)
a = numpy.load(memfile)
dir(__builtins__)
result.extend(literal_eval(line.strip()))
sample.save()
divisibleBySeven = [num for num in inputList if meetsCondition(num)]
print(d[keyList[i - 1]])
fooarray = numpy.zeros((N, M))
deletep_list[idx]
line = proc.stdout.readline()
zlib.decompress(inf, 16 + zlib.MAX_WBITS)
ecb()
df.iloc[last - 2:last + 1]
ax = plt.subplot(111)
print(fmax, pinf, ninf, fnan)
fout.write(f.getvalue())
chromosome2 = [1, 1, 2, 1, 0]
f[i] += 1
l[1] = 5
G.add_nodes_from(L4)
my_new_list = list(my_set)
m2[:, (1)] > 10
data = np.vstack((data, (np.ones(data.shape[0]) * num).reshape(-1, 1)))
df_two.show()
main()
foo.save()
hops.insert(0, response.geturl())
pygame.mixer.music.load(soundfile)
driver = webdriver.Chrome()
print(binascii.hexlify(x))
user.save()
list_one.insert(2, list_two)
sizer.Add(self.grid, 1, wx.EXPAND)
no_vow(seq, index + 1)
image = cv2.imread(imagepath)
dirname1 = os.path.basename(dir)
writer.commit()
unittest.TextTestRunner(verbosity=2).run(suite)
points[index]
os.fdopen(fd, *args, **kwargs)
[x for x in pattern.split(s) if x]
plt.show()
df = pd.DataFrame(list(cursor))
sizer = wx.BoxSizer(wx.VERTICAL)
hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
self.root.after(1000, self.circle)
sorted_d = OrderedDict(zip(sorted_keys, [d[k] for k in sorted_keys]))
obj._meta.concrete_model._meta.model_name
mask = np.isnan(arr)
zip_longest(fillvalue=fillvalue, *args)
z.close()
window.setGeometry(0, 0, 400, 200)
print(min((f(i, j), i, j) for i in l for j in l))
df1.info()
b.append([begin, end])
server.shutdown()
sys.exit(app.exec_())
act.triggered.connect(self.on_triggered)
ax.plot_surface(x_surf, y_surf, z_surf, cmap=cm.hot, alpha=0.2)
L.sort(lambda x, y: cmp(x.name, y.name) or -cmp(x.year, y.year))
arrows(0, 0, 1, 1)
lines = (line for line in f if line.strip())
[y for x in lst for y in (x if isinstance(x, tuple) else (x,))]
sys.exit()
dt = datetime.fromtimestamp(ts, tz)
ax.set_xticks(list(range(len(g))))
process.terminate()
shutil.copyfile(src, dest)
datetime.timedelta(seconds=seconds)
data[np.isnan(data)] = dfrand[np.isnan(data)]
c.sort(axis=1)
func2(innerfunc)
parts = splitparts.split(match.group(2))
socket.inet_pton(socket.AF_INET, address)
p[pair[1]] += 1
y.shape.eval()
handles, labels = ax1.get_legend_handles_labels()
self.setLayout(hbox)
df1.values / df2[df1.columns].values
ax.plot([2, 2, 2])
log.setLevel(logging.INFO)
column(A, 1)
X = np.zeros((100, 100, 100))
setup2 = dict(setup1, param1=val10, param2=val20)
a2.ravel()[:] = np.array(ll)
show_svg()
lines = f.readlines()
sizer.Add(self.ultimateList, 1, flag=wx.EXPAND)
fig, ax = plt.subplots()
[n] = set(sum(sl) for sl in L)
heapq.heappush(heap, (-prod, n, n))
ax1 = fig.add_subplot(211)
time.sleep(1.0)
Decimal(0.5)
print(x.name, x.hometown.name, x.hometown.id)
sys.getdefaultencoding()
sum(f(x) for f in funcs)
self.modules
a[a < 0] += 1
hist, bin_edges = np.histogram(a, bins=bins)
timeit(hugeequal1, hugeequal2, 10000)
output = p.communicate(input)[0]
b[i] = a[i]
solve(M * x + N * y, x)
deletemylist[:2]
plt.show()
csv_writer = csv.DictWriter(csv_file, headers)
soup = BeautifulSoup(urllib.request.urlopen(url).read())
pprint.pprint(result)
df.min(1)
resp = br.open(url)
pw = getpass.getpass()
root.rowconfigure(0, weight=1)
s.connect((HOST, PORT))
doctest.testmod()
inspect.getgeneratorstate(gen)
locals().update(mydict)
avg = tot / ((data.shape[0] - 1) * data.shape[0] / 2.0)
np.dot(b, a)
df.drop(cols, inplace=True, axis=1)
text.split(a)[-1].split(b)[0]
pool.join()
[(s, s1.index(s), s2.index(s)) for s in maximal]
[p for p in itertools.product(x, repeat=2)]
pdb.Pdb.__init__(self, nosigint=True)
p2.communicate()
list = [i for i in stuff]
sys.exit(app.exec_())
newlst.append(int(i))
fmt.format(**d)
list_one.extend(list_two)
ds_dt = np.sqrt(dx_dt * dx_dt + dy_dt * dy_dt)
earth.circle(150, 2)
sys.stdout.write(line)
os.symlink(os.path.realpath(sys.argv[0]), exe_install_path)
output[0]
self._list[i][1]
self.set_picture(picture)
data = bytearray(f.read())
type.__init__(cls, name, bases, d)
sys.stdout.flush()
nums = list(range(1000000))
image = image.resize((width_new, height_new))
result = [item for sublist in l for item in sublist]
new_dict = defaultdict(dict)
b = tf.add(a, a).eval()
ax.set_ylim([-2, 2])
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w, h), 1, (w, h))
scipy.stats.hypergeom.sf(0, N, M, Q)
s.prompt()
info.setLevel(logging.INFO)
btn.grid(column=1, row=1)
func()
fake_datetime = flexmock(now=lambda : datetime(year=2012, month=12, day=12))
f.seek(55)
found = word in file.read().split()
isinstance(x, X)
plt.figure(i)
root.mainloop()
timer2.start()
main()
fig = plt.figure()
print(root.winfo_geometry())
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
ax.set_extent([4, 16, 47, 56], ccrs.PlateCarree())
self[key].append(value)
draw.text((10, 10), unicode_text, font=unicode_font, fill=font_color)
os.kill(int(processId), signal.SIGTERM)
df
tmp.append(chr(d))
xedges, yedges = np.meshgrid(xedges[:-1], yedges[:-1])
mylist[:] = []
Person.query().filter(Person.guilds == self.key)
[(s[0], s[1]) for s in (s.split() for s in strings)]
path_list[0] = path_list[0][0]
print(i, j, k, v)
np.ma.MaskedArray(x, mask)
plt.plot(x, y)
[i.value for i in d]
fig = plt.figure()
b = do_something(a, b)
x = [True, True, True, True]
self.window.clear()
sys.exit(app.exec_())
print(root, dirs, files)
self.f.writeframes(output)
logging.getLogger().addHandler(handler)
print(key, sum(d[key]) / len(d[key]))
process.start()
zip_safe = False
mean(arr[k + 1:n - k])
hax2.set_position([0.1, 0.1, 0.8, 0.8])
plt.legend()
a = np.array([1.0, 2, 6, 2, 1, 7])
do_the_stuff(key, value)
sheet1.write(i, 1, e)
f.seek(-4, 2)
os.setsid()
model = model.fit(X_train, y_train)
logger.addHandler(handler)
br.load(url)
min(allowedList, key=sortedList.index)
tekstboks = tk.Entry(root, textvariable=ordinn)
tekstboks2 = tk.Entry(root, textvariable=bokstinn)
fig, axes = plt.subplots(nrows=4, sharex=True)
m = re.match(regex, line)
s.bind((host, port))
ax1 = plt.subplot2grid((1, 1), (0, 0))
data = []
worksheet.write(row, col + 1, item)
my_date = date.today() - timedelta(days=days_to_substract)
datetime.datetime(t.year, t.month, t.day)
soup = bs4.BeautifulSoup(YOUR_CONTENT)
fig, ax = plt.subplots()
time.sleep(1)
host.set_xlim(0, 2)
plt.setp(labels, rotation=0)
self.root.mainloop()
foo = bar(foo)
browser = mechanize.Browser()
gb1.assign_to_a([1, 2])
plt.close(fig)
df2 = pd.concat([df] * 10000)
df.groupby(level=0).cumcount()
print(os.ttyname(sys.stdin.fileno()))
bins.append(int(df.val1.max() + 1))
y = np.concatenate((firstvals, y, lastvals))
output, err = p.communicate()
plt.quiver(X, Y, Z2, width=0.01, linewidth=1)
v.iloc[-1]
parser = etree.XMLParser(schema=oaischema)
plot_events(x, y)
sys.exit()
b = a.tolist()
mytext = self.textEdit.toPlainText()
info[0][0] == 1
log.setLevel(logging.ERROR)
sessionmaker(bind=self.engine, autocommit=True)
all(recursively_empty(c) for c in e.getchildren())
df = pd.concat([df] * 1000, axis=1)
form = MyModelForm(instance=my_record)
assert np.all(a == b)
req = urllib.request.Request(url, data)
(data.T - vector).T
ax = fig.add_subplot(1, 1, 1)
np.random.seed(0)
ts = pd.Series(zip(*my_list))
h.funcB()
h.funcC()
distance[0][0][0] = 1
df[2].plot(ax=axes[1, 0])
comp = np.dstack(complist).sum(-1)
data = self.request.recv()
print(my_string.format(**d))
matched = [c for c in cmds if c.startswith(s)]
np.unravel_index(np.ravel_multi_index((10, 52), arr2.shape), arr1.shape)
print(hb.norm.vmin, hb.norm.vmax)
np.split(lst, np.cumsum(sec))
self.get_user_from_cookie()
time.sleep(0.01)
ranges.append((2, 10))
r = requests.get(url)
array1 = itertools.chain(array1[:-1], array2)
r.json()
pool = Pool()
self.num = self.num + 1
lines = f.readlines()
django.setup()
finalimage = ImageChops.lighter(finalimage, currentimage)
[(5, 0), (8, 2)]
plt.show()
plt.subplot(2, 1, 2)
df_test.reindex(idx)
list(itertools.islice(fib(), 10))
print(np.trapz(counts, bins))
gtk.main()
plt.show()
[k for k, v in sorted(list(dct.items()), key=lambda p: p[1], reverse=True)]
pd.read_json(jsonfile, lines=True)
main()
self.socket.sendall(image_data)
print(np.allclose(r[0], k))
print(a[i:j])
HttpResponse(something)
Doc.docimage_set.all()
df.columns = pd.to_datetime(df.columns)
r = float(s)
sheet = book.sheet_by_index(index)
np.split(a, [int(0.8 * len(a)), int(0.9 * len(a))])
index2 = np.array([[0, 1], [0, 1]])
h5file.close()
socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
newcols = df.apply(lambdafunc, axis=1)
array_of_list_of_tuples = array(list_of_tuples)
self.update_clock()
np.where(a < b * 10, a * 2, -a)
csv_df = csv_df.groupby(csv_df.columns, axis=1).mean()
module = sys.modules[func.__module__]
self.parent_model.objects.get(pk=resolved.args[0])
imgplot = plt.pcolormesh(lum_img, cmap=cmaps.viridis)
a = create_matrix(8, 8)
pygame.mixer.music.play()
h.Do()
file.write(line)
a.mainloop()
args = parser.parse_args()
mydict.update(myitem)
np.tensordot(gggg, T, axes)
Py_INCREF(v)
send_file(file_name, as_attachment=True)
f.__defaults__
result = np.clip(arr, 0, 255)
True
ax.axis([-0.2, 1.2, -0.2, 1.2])
render_to_response(template, context)
my_anim = animation.ArtistAnimation(fig, myimages, interval=100)
ctypes.string_at(self._buffer, self.size)
-autobus
query.filter(Cls.field.in_(terms))
print(response.url)
ax.scatter(xflat, y, z)
z = np.array([complex(c.m_x, c.m_y) for c in cells])
arr[1, 0]
s.groupby(s.shift().notnull().cumsum()).transform(lambda g: g[-1] / g.size)
logging.debug(line)
urllib.request.install_opener(opener)
pprint(ddiff, indent=2)
PLT.show()
df.query(qry)
np.random.shuffle(ones)
df.index.values
self.hide()
foo[1, 2]
fig = plt.figure(figsize=(4, 4))
a = a[::-1]
round_down(10, 10)
[j for i in lst for j in (replace_with if i == to_replace else [i])]
plt.gca().add_artist(leg2)
self.fig.canvas.draw()
print(response.url)
root = tk.Tk()
a[..., (0)].flatten()
(a + 1) % 2
df = pd.read_sql(querystring, cnxn, params=orders)
print(time.localtime())
print(tostring(root))
fig = plt.figure()
self.glade.connect_signals(self)
np.linalg.norm(x - y) < np.linalg.norm(sx + sy)
ax1.plot(t, s)
a = df.iloc[:, 1:]
ax = plt.subplot(111, polar=True)
data = render_template(path, **context)
wordcount = Counter(file.read().split())
transport = ssh.get_transport()
s.get(url)
writer.save()
print([l[0].strip() for l in re_data_fields.findall(line)])
retcode = p.wait()
ZipFile.namelist()
sys.stdout = sys.__stdout__
x = [0, 1, 0, 1, 0, 0, 0, 0]
A = csr_matrix((data, (row, col)))
self._socket.sendto(message, self._dest)
print(child.tag, child.text)
self.render_template([template], **context)
TestApp().run()
im.crop((0, 0, width, l_start_y + 2)).save(sys.argv[1])
assert isinstance(variable, type)
my_method_name()
msg.attach(img)
main()
Base.metadata.create_all(engine)
self.submitButton.grid()
im2.show()
dummy = list(map(int, map(set(data).__contains__, variables)))
temp()
xvals = np.arange(beginx, endx + 1)
yvals = np.arange(beginy, endy + 1)
a = numpy.random.rand(N)
foo(a)
logger.setLevel(logging.DEBUG)
MyModel2.mymodel1
xmin, xmax = min([i.min() for i in xs]), max([i.max() for i in xs])
l = sorted(d.keys())
self.showMaximized()
plt.show()
parser = argparse.ArgumentParser()
root.lift()
index = MyModel.objects.filter(sortField__lt=myObject.sortField).count()
l.remove(i)
self.put()
people.groupby(mapping).sum()
data = json.loads(response_data)
row = cursor.fetchone()
print(x)
finder1.score_ngrams(bigram_measures.pmi)
Thread.__init__(self)
book = xlrd.open_workbook(filename)
ranges.append((5, 10))
ax.scatter(xs, ys, zs)
frame.pack()
unicode_list = [chr(i) for i in range(sys.maxunicode)]
dsn = cx_Oracle.makedsn(ip, port, SID)
print(user.columns.name.type.length)
print(numbers, sum(numbers))
df.columns.tolist()
sns.pairplot(df)
decimal.Decimal(x).to_eng_string()
json.dumps(d.isoformat())
aw2.redraw_plot()
numpy.__version__
aapl_200ma.plot(legend=True)
site.close()
print(resp.read())
fp = webdriver.FirefoxProfile()
pd.isnull(np.array([np.nan, 0], dtype=float))
dlg.Destroy()
zip_longest(fillvalue=fillvalue, *args)
i, j = np.meshgrid(np.arange(N), np.arange(N))
accum0.append(cc0)
num = np.sum(np.abs(diffs) < some_value)
print(pd.DataFrame(result, df.index, df.columns))
odds.append(i)
np.kron(a, np.ones((blockSize, blockSize)))[:rows, :cols]
time.sleep(random.randint(1, 4))
letter_count = dict(zip(string.ascii_lowercase, [0] * 26))
s.diff()
render_template(template_name, var1=var2, var2=var2)
server.close()
data = np.random.randint(25, size=(4, 4))
a[:, (i)]
calendar.setdefault(date, []).append(event)
im = numpy.array(img)
print(find_supersets(strings))
f.seek(0, 0)
__import__(module)
plt.set_cmap(cmaps.viridis)
my_dict[k].append(dict2[k])
A()
pool = multithreading.Pool(1)
plt.gca().add_patch(cir)
SettableRLSD = TRUE
MKTYPE2(Stitcher)
sys.stdout.write(char)
df
enc.transform([[0, 1, 1]]).toarray()
newNums = (i for i, x in enumerate(nums) if x == 12)
ssh = paramiko.SSHClient()
screen.blit(newGameButton, (button_x, button_y))
data = f.read()
head, tail = (lambda x: (x[0], x[1:]))(my_func())
datetime.datetime.fromtimestamp(1004260000)
res.append(l)
s.cookies.set_policy(BlockAll())
t.timeit(5)
gibberish(10)
np.mean(self.predictions_, axis=0)
nk -= 1
zipped_file.seek(0)
output[-1].append(item)
m.group()
print(result)
os.kill(-self.proc.pid, signal.SIGKILL)
a = list(range(10000, 20000))
print(sys.path)
the_file.close()
x.argmin(axis=1)
False
result = solve((x + I * y) ** 2 - z, (x, y))
d.update(makedict(elem))
fig = pylab.figure()
sum(v[idx] for k, v in stats.items() if k[ikey] == keyv)
mu = np.mean(array)
ax = fig.add_subplot(211)
pipeB.send(20)
sp.coo_matrix((C, coords), (a.shape[0], b.shape[1]))
redis.StrictRedis(connection_pool=connection_pool)
self.results = pandas.concat(frames)
ax.set_xlim(0, n_pts)
c_float_p = ctypes.POINTER(ctypes.c_float)
ax.set_xlim(0, 255)
plt.contourf(X, Y, Z)
[1, 2, 0, 0, 0]
engine.start()
sns.despine()
pkt = Ether() / IP() / TCP() / payload
self.lock.acquire()
print(df)
sys.stdin = Peeker(sys.stdin)
Clock.schedule_once(self.create_webview, 0)
m, n = map(int, input().split())
db.session.add(region)
data.seek(0)
pygame.quit()
float(str)
a[i] += 1
server.starttls()
os.kill(-self.proc.pid, signal.SIGTERM)
ssh.close()
time.sleep(4)
df_c.ix[df_b.index] = df_b
ax[0].legend()
self.render_to_response(context)
assert not self.broken
w = csv.DictWriter(f, list(my_dict.keys()))
now_epoch = time.time()
coo = [(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2), (2, 0)]
notifier.loop()
ax = fig.add_subplot(111)
ids_list = [item[0] for item in cursor.fetchall()]
points.append((x, y))
print(set(chain(*array)))
numbers = zip(*data)
w.show()
a = [a.ix[i] for i in a.index if sorted1[i] < sorted2[i]]
z2[i, list(range(z2.shape[1]))]
sorted(map(sorted, sets), key=lambda x: (len(x), x))
o.close()
smtp.quit()
self.grid()
data.rename(columns=str.lower)
self.hello()
time.sleep(1)
stream.flush()
my_list.append(map(int, ints))
csv_out.writerow(row)
setattr(user, key, value)
np.where(np.array([0, 0]))
A[[0, 1]].shape
response = urllib.request.urlopen(url)
p.start()
np.arange(N).reshape(shp).transpose(np.arange(len(shp))[::-1]).ravel()
print(most_common_words)
ax.clabel(terr, fontsize=9, inline=1)
d1 - d2.values
context.driver.switch_to.alert.accept()
sys.stdout = sys.__stdout__
earth.circle(150, 1)
assert np.allclose(results[1], results[2])
ax.set_xticks(ind + width)
self.fileobj.close()
db.commit()
my_list = pickle.load(f)
[x for x in the_list if the_list.count(x) == 1]
df
QDialog.__init__(parent)
self.Show()
res = t.render(items=items)
df.replace(replacements, regex=True, inplace=True)
plt.figure()
frame.grid(row=0, column=0, sticky=N + S + E + W)
defaultdict.__init__(self, list)
writer.save()
chr(int(match.group(1), 16))
self.children.append(obj)
tar.getmembers()
cherrypy.config.update(server_config)
pygame.mixer.music.play()
sum(atuple)
parent.kill()
datetime.date(2016, 6, 9),
map(int, list(bin(n)[2:]))
obj.update(add_obj)
okay_items = [x for x in all_items if not regex.match(x)]
print(text_re)
logging.basicConfig(format=FORMAT, level=logging.INFO)
self.__add__(-other)
admin.site.register(question, QuestionAdmin)
Potato(**validated_data)
print(json.dumps(d, indent=4))
t1 = threading.Thread(target=foo)
[([_] + list(itertools.takewhile(lambda x: x != 2, a))) for _ in a]
fig.subplots_adjust(right=0.55)
plt.show()
process.kill()
print(foofile.read())
root.config(menu=menubar)
plt.ylim(max(y) + 0.5, min(y) - 0.5)
type(1)
m_date = datetime.datetime(Yr, Mo, Day)
s.count(s[0]) == len(s)
move_to_root_folder(root_path, os.path.join(cur_path, filename))
callee()
app.logger.addHandler(handler)
writer.writerows(data)
count_2.most_common(2)
plt.show()
element = ElementTree.fromstring(line)
user_id = Column(Integer, ForeignKey(User.id), primary_key=True)
df[df.User_ID.isin(counts[counts > 1].index)]
sns.plt.show()
ax1.xaxis.set_major_locator(mticker.MaxNLocator(10))
print(neighbors(A, 1, 0))
text.set_transform(fig.transFigure)
payload.set_verdict(nfqueue.NF_DROP)
answer.append((apos, bpos))
logging.Handler.__init__(self)
dt + timedelta(days=7 - dt.weekday())
sympy.sympify(r)
[max(islice(map(abs, array), i, i + 4)) for i in range(0, len(array), 4)]
self._on_change()
np.where(a == a.max())
plt.xlim((1e-12, 1))
list(it.starmap(op.sub, it.izip(a[1:], a)))
len(pytz.all_timezones)
handler.setLevel(logging.DEBUG)
self[key]
(dt - epoch).total_seconds() * 1000.0
myadd = lambda xs, ys: tuple(x + y for x, y in zip(xs, ys))
narr
name = os.path.realpath(os.path.join(root, name))
d = lisp(d[0])
print((first_num, first_arrangement))
self.ax.grid()
x.append(y)
self.ssh.close()
current_time = datetime.datetime.now()
f(a, b)
df.apply(lambda S: S.append(dm))
train_op = tf.train.GradientDescentOptimizer(0.01).minimize(cost)
self.comboBox_2.addItem(QIcon(pixmap), text)
cursorclass = MySQLdb.cursors.DictCursor
server.starttls()
result = list(set(s for s in stringlist if len(s) == ml))
view_func(request, *args, **kwargs)
key.get_contents_to_file(f, headers)
print(rf.predict(testdataset[-1:]))
newdate = datetime.datetime(*values)
f(f, *args, **kwds)
pprinttable([data, data])
[dict(zip(list_of_keys, row)) for row in spamreader]
array.pop(0)
print(paramiko.__version__)
self.conn.commit()
print(df_concat.median())
print(soup)
file.writelines(input_lines)
my_copy = copy.deepcopy(my_dict)
assert f([[0, 100], [9, 10], [12, 90]]) == [[9, 10], [12, 90]]
self.mplvl.setLayout(self.vLayout)
pl.show()
x = conn.cursor()
borderseg, X, labels, Xslice
time.sleep(1)
row_result.append(row_separator)
sys.exit(e)
logging.Handler.__init__(self)
np.transpose(arr, [2, 0, 1]).shape
-47.5, -10.4, 19.1, 25.9, 18.9, -10.4, -2.1, -47.6, 41.8, -12.1, -15.7, 12.1, -11.0, -0.6
window.show()
func(*args, **kwargs)
(df == 0).all()
loop.run_until_complete(task)
a[:, (0)].max()
os.chdir(folder)
L.grid(row=i, column=j)
np.sqrt((q * q.T).sum())
words = l.split()
str(theint)
[i for i, j in takewhile(lambda i_j: i_j[0] == i_j[1], zip(list1, list2))]
window._master = tk.Frame(window)
s.add(val)
os.dup2(so.fileno(), sys.stdout.fileno())
print(driver.title)
x[2:].sort()
ch = logging.StreamHandler()
next(reader)
plt.colorbar(heatmap)
c.writerow(sh.row_values(r))
plt.show()
json.dump(jsonData, outfile, sort_keys=True, indent=4, ensure_ascii=False)
model1.py
now = datetime.datetime.now()
plt.clf()
fd.close()
urlobj = urllib.request.urlopen(url)
A.__init__(self, *a, **k)
res.append(value)
window = pygame.display.set_mode((WIDTH, HEIGHT))
session.add(marten)
session.add(shrew)
session.add(loris)
Newlist.append(x)
d.setdefault(k, []).append(v)
base64.urlsafe_b64decode(enc)
a, b
mock_boo_obj = mock.Mock()
np.ones(10, dtype=bool)
print(as_list)
np.random.seed(42)
value_sums = np.bincount(idx, value.ravel())
yaml.load(s)
random.choice([left, right]), random.choice([top, bottom])
f.quit()
layout.addWidget(self.list)
plt.tight_layout()
pd.Series(date_rng.format())
z = pd.read_csv(io.StringIO(x))
obj.__class__ = newclass
ax.set_yticks(list(range(1, 5)))
self.panel.SetFocus()
sock.close()
nax.set_yticks(tcks)
{(1): 2, (2): 1}
func(*args, **kwargs)
df.POINTS = (df.POINTS * (df.POINTS == df.DATA)).fillna(0)
tree = et.fromstring(xml)
username = db.Column(db.String(20), unique=True)
print(sys.path)
fig, ax = plt.subplots()
np.where(np.isnan(a), ma.array(a, mask=np.isnan(a)).mean(axis=1), a)
do_something()
self.generator.__len__()
json.dump(row, jsonfile)
plt.ion()
sum(l)
dest.close()
fig = pl.figure(figsize=(6, 6))
hist2d(xval, yval, bins=1000, range=np.array([(-6, 6), (-4.5, 4.5)]))
next(i for i in range(100000) if i == 1000)
self.command()
evens = (i for i in range(limit) if i % 2 == 0)
text_widget.index(Tkinter.INSERT)
nbrs.kneighbors(X)
print(tensor[0].eval())
self.frame.focus_set()
set([l[0] for l in a_list])
im.seek(im.tell() + 1)
my_input.ask()
p.stdout.close()
inverted_image = PIL.ImageOps.invert(image)
writer.writerow(row)
np.tile(a, (6, 1))
merged_dict = {k: [d.get(k, np.nan) for d in all_dicts] for k in keys}
list(takewhile(lambda i_j: i_j[0] == i_j[1], zip(list1, list2)))
raise argparse.ArgumentTypeError(msg)
X_train, X_test, y_train, y_test = ttsplit(X, y, test_size=0.1, random_state=0)
out = np.dot(arr_one, arr_two.T)
msg.attach(img)
txttime = os.path.getmtime(os.path.join(root, txt))
f[::-1]
urllib.request.install_opener(opener)
ioloop.IOLoop.instance().run_sync(main)
_ranks.append({})
print(list(dedupe_adjacent(data)))
deletex
print(argparse.__dict__)
ax = fig.add_subplot(111)
plt.subplot(121)
somethingThread.start()
item.set_rotation(45)
Client(*sys.argv[1:]).run()
b = np.array([2, 4, 6])
bodytext = body.text
Session.remove()
screen = pygame.display.set_mode((800, 800))
print(str(a[1]))
book_author.save()
session.add(stoat)
startupinfo = subprocess.STARTUPINFO()
df.shift(2).iloc[:, 4:]
dt = datetime.datetime.strptime(s, fmt)
a.shape
s = SomeClass(bar=1, foo=0)
people = Person.objects.filter(employee__in=employee_query)
func(*args, **kwargs)
list(filter(pred, A))
print(f.readlines())
self.itemSelectionChanged.connect(self.print_row)
a, b = test()
token.get_access_token(code)
tmp.append(float(line))
df
re.predict_proba(X_test)
new_list = [fruit for fruit in a if fruit not in b]
log = logging.getLogger(__name__)
a = np.array([[1, 2], [1, 2]])
df.eq(0).apply(lambda x: list(df.columns[x]), 1)
m.groups(1)
y = random.randrange(0, maxy)
setattr(self.obj, self.property_names[item], value)
os.path.abspath(sys.modules[LocationArtifact.__module__].__file__)
p.x, p.y, p[0], p[1]
c.nonzero()
xs.append(x)
(-4) ** 2
ax.yaxis.set_ticks(np.arange(0, 100, 10))
-rtest - requirements.txt
mylist.sort(key=itemgetter(1))
self.button.clicked.connect(self.dialog.show)
smax.on_changed(update)
ax.set_xticklabels(xlabels)
love_ctx.add((alice, loves, charlie))
ax.set_yticks(np.arange(len(df.index)) + 0.5)
sleep(1)
x = x - int(x)
myset.add(item)
b = p.map(func, a)
globals()
pprint({x: list(range(x)) for x in range(10)})
time.sleep(0.001)
a.add_child(b)
print(ToSI(d))
x.bar()
sys.path.append(os.getcwd())
elevations = json.dumps(data)
plt.show()
fig.colorbar(cf, cax=cax)
print(dpkt.ethernet.Ethernet(packet))
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj))
l.append(s[i:i + 10])
ax2.set_xticklabels(X2tick_location)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
a2 = np.array([[4, 5, 6], [7, 8, 9], [1, 1, 1]])
y = x.dot(w)
do_something_useful()
X_max = np.max(X[idx])
df = df.swaplevel(0, 1, 1)
dfile.write(sfile.read())
admin.site.unregister(User)
hermes.__loader__
self.frame.pack()
{k: map_nested_dicts(v, func) for k, v in ob.items()}
list_of_ints = [int(i) for i in str(ISBN)]
solve(fprime, x)
app.mainloop()
imarray = numpy.array(im)
time.sleep(0.25)
random.shuffle(count_list)
multiprocessing.Process.__init__(self)
self.onThread(self._doSomething)
threading.Timer(10, foo).start()
cur.execute(query)
plt.show()
i_take_strings(*s.split())
max_idx = l.index(max_val)
ax1.legend(bbox_to_anchor=(1.2, 1))
colormap_r = ListedColormap(colormap.colors[::-1])
name = models.CharField(max_length=50)
self.setCentralWidget(self.central)
[([x] + p) for x in seqs[0] for p in [[]]]
sys.stdout.write(str(result))
dict.__setitem__(self, key, value)
sys.exit(main(sys.argv[1:]))
to_search = {x[0]: x for x in input}
r = requests.get(url, stream=True)
print(m.groups())
fcntl.fcntl(thePipe, fcntl.F_SETFL, os.O_NONBLOCK)
self.data = np.array([])
smtpserver.starttls()
draw = ImageDraw.Draw(im)
parsed = rdd.map(json.loads)
c.add(o)
json.dump(data, fp)
rdd = sc.parallelize(np.random.randint(1000000, size=700000))
name = models.CharField(max_length=10)
sys.exit(0)
Foo.bar()
time.sleep(0.5)
args = parser.parse_args()
len(np.unique(array)) > 1
select.select([A], [], [])
connection = redis.Connection(**kwargs)
_location.gsm_location()
root = lxml.etree.fromstring(xmlstr)
ax.ticklabel_format(useOffset=False)
intvals[i - 1:i + 1]
fh.seek(offset)
get_indices(a, b)
True
c.set_dashes([(0, (2.0, 2.0))])
sorted(dictionary.values())[0]
(df == 0).astype(int)
get_key(d, 22)
np.bincount(A, B)
result = random.sample(coo, 2)
legend = DraggableLegend(ax.legend())
fig = plt.figure()
service = get_vision_service()
print(df[column])
process.crawl(MySpider)
self.x1 += self.speed * math.cos(self.bearing)
dict.__setitem__(d, new_key, v)
print(timedelta(minutes=6 * 60))
l = l[:1] + x + l[2:]
pool.terminate()
f.seek(0, whence=2)
list2.append(dict2.get(key))
soup = BeautifulSoup(urllib.request.urlopen(url).read())
np.bincount(ixs, minlength=mat.shape[0]).dot(mat)
min(k for k in d if k > key)
draw()
self.add_node(destination)
list(grouper(2, my_list))
arcpy.RefreshTOC()
gb1.copy_to_a([1, 2])
add.apply_async((1, 4), task_id=i)
grid_sizer_1.Add(self.window_1, 1, wx.EXPAND, 0)
list(iterateFinitely(lambda x: [x / 2] if x else [], 20))
raise NotImplementedError
p.start()
yz = NNN.mean(axis=0)
sys.exit(0)
print(audio.info.length)
app = QtGui.QApplication([])
ao[1:, :] += ai[:-1, :]
DataFrame(dict(s1=s1, s2=s2)).reset_index()
numbers.append(i)
[(5,), (2, 2, 1), (2, 1, 1, 1), (1, 1, 1, 1, 1)]
logging.basicConfig(level=logging.INFO)
form.save()
fullname = os.path.join(path, filename)
myline = random.choice(lines)
[seq[i:i + n] for i in range(0, len(seq), n)]
sum(1 for _ in it)
kwargs_new = {k: v for k, v in list(d.items()) if isinstance(k, str)}
print([[item.p1, item.p2] for item in uniq])
im2 = ax2.plot(image[0:time, (5), (5)])
mx = pow(2, 24) - 1
map(id, b)
result.extend(changecoins)
t.cancel()
sum(p[0] for p in datapoints[0:5]) / 5.0
abort(405)
mainwin.show_all()
self._base.all()[0]
id(x) == foo(x)
{{a}}
tseries.order()
math.sqrt(point[0] ** 2 + point[1] ** 2)
f = a ** 2 + x * b ** 2 + y * a * b * np.cos(c) + z * a * b * np.sin(c)
out.save(output_path)
L[:4]
b = Matrix([[2, 2], [2, 2]])
x = pd.DataFrame(np.random.randn(20, 5))
axes.plot(xs, ys)
view_func(request, *args, **kwargs)
plt.scatter(x, y, c=x, s=100, cmap=reds)
set(l1) & set(l2)
nsmallest(4, list(range(len(values))), key=lambda i: values[i])
container.grid_rowconfigure(0, weight=1)
dis.dis(func)
print(os.path.join(root, pathname))
file_count = len(files)
current_app.login_manager.unauthorized()
new_list = []
print(node.text)
a = input()
root = objectify.fromstring(xml_string)
years = [x.year for x in your_list]
self.configure(width=imagesize[0], height=imagesize[1])
HttpResponse(status=200)
ax = plt.gca()
df_final = pd.concat(pieces, ignore_index=True)
print((datetime.date(year, month, day) - datetime.timedelta(1)).isoformat())
ssh = paramiko.SSHClient()
df
print(file_content)
{10}.issubset(chain.from_iterable(x))
self.worker.beep.connect(self.update)
self.clients.append(client)
np.put(arr, list(range(len(arr) + num, len(arr))), np.nan)
A = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]])
result.fillna(df1, inplace=True)
fig, ax = plt.subplots(nrows=1, ncols=1)
bytes([1, 65, 2, 255])
conn, addr = s.accept()
self.SetSizer(sizer)
f.close()
id = Column(Integer, primary_key=True)
B = copy.deepcopy(A[0])
ax = fig.add_subplot(111)
e.pack()
widget.show()
time.sleep(2.0)
print(p.stdout.read())
df.loc[df[:-1][df.index.month[:-1] != df.index.month[1:]].index]
print(zap)
plt.show()
np.random.shuffle(a.flat)
show()
listbox = Listbox(master, selectmode=tk.SINGLE)
blit_text(screen, text, (20, 20), font)
ani = animation.FuncAnimation(fig, animate, frames=10)
d = np.repeat(b, a.shape[0], axis=0)
proc.communicate()
print(os.getcwd())
cal_window.set_type_hint(gtk.gdk.WINDOW_TYPE_HINT_DOCK)
print(response.content)
bits = [int(x) for x in bits[::-1]]
entries = dict([(x, y) for x, y in zip(out[::2], out[1::2])])
a.wut
rdd1.join(rdd2)
fn(*args, **kwargs)
msg.attach(MIMEText(message))
wx.App.__init__(self, False)
result.extend(pat.findall(text))
maxLen = max(len(p) for p in props)
np.array([1, 2]).size
self.setLayout(layout)
sys.exit(subprocess.call(sys.argv[i:]))
htmlDoc.close()
plt.show()
f.close()
con.close()
identity = lambda x: [[int(i == j) for i in range(x)] for j in range(x)]
[p[0] for p in deck]
print(a.headlines.all())
sorted(list(kwargs.items()), key=lambda i: i[0])
figure(1, figsize=(6, 6))
self.appExeCB.addItems(list(self.items.keys()))
b_thread.start()
{(x * x) for x in range(10)}
punto.wkt
count = sum(1 for _ in emoticons)
groups.append([x[1] for x in g])
res = cv2.bitwise_and(img, img, mask=mask)
{{post}}
func(*args, **kwargs)
new_items = [item for item in items if not item.isdigit()]
deletedic[k]
d = defaultdict(lambda : 1)
app.run()
result[key] += 1
np.datetime64(dt.isoformat())
sys.stdout.write(str(tuple[0]))
plt.scatter(*zip(*new_points))
headers.setContextMenuPolicy(Qt.CustomContextMenu)
network.draw()
zk.stop()
df
print(not not r.search(s))
a = defaultdict(dict)
f()
plt.figure(figsize=(8, 6))
zip(l, l[1:], l[2:])
draw = ImageDraw.Draw(image)
time.sleep(0.05)
self.header = header
ax.patch.set_visible(False)
pd.concat(df.xs(d, axis=1) for d in dupes).groupby(level=0, axis=1).mean()
C[k] = np.dot(A[k], B[k])
self.canvas.scan_dragto(event.x, event.y, gain=1)
stream.write(data)
np.fromiter(test, dtype=np.int)
id(lines), id(ax.lines)
facebook_graph = facebook.GraphAPI(oauth_access_token)
print(x, y)
f.seek(0)
False
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
data.columns = data.iloc[0]
soup = BeautifulSoup(page)
PY_MAJOR, PY_MINOR = sys.version_info[0:2]
cv2.drawContours(mask, [largest_area], 0, (255, 255, 255, 255), -1)
time.sleep(0.1)
pythoncom.PumpWaitingMessages()
sys.exit(2)
show()
print(index, key, value)
file.close()
df
random.randint(0, int((stop - start) / step)) * step + start
self.x0 += self.speed * math.cos(self.bearing)
smtpserver.starttls()
sys.stdout.write(s)
(np.arange(n) >= m).astype(int)
cause = e.args[0]
pd.show_versions(as_json=False)
np.dot(copy, onevec)
assert list(a.keys()) == list(b.keys())
self.panel.Bind(wx.EVT_KEY_UP, self.OnKeyDown)
len(list(flatten(mylist)))
pdb.Pdb(stdout=sys.__stdout__).set_trace()
data = response.read()
a.add(1)
data = line.split()
print(cardsdiscarded)
a + [a < 0]
sock.close()
iph.show2()
QObject.__init__(self, parent)
frame.append(4)
contest = models.ForeignKey(Contest)
sign * 2.0 ** (expo - 25) * prec
print(tupl.a, tupl.b)
pprint(d)
table.resizeColumnsToContents()
df.loc[start:end]
numbers = [random.randint(1, 1000) for x in range(SOMEVERYLARGENUMBER)]
x = Counter([-1, -1, -1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0])
resulting_list.extend(x for x in second_list if x not in resulting_list)
[sorted(sub) for sub in result]
x = np.arange(X)
ax2 = fig.add_subplot(212)
print(unanimous(list(dd.values())))
model.save([spark_context], [file_path])
root = tk.Tk()
app = QtGui.QApplication(sys.argv)
db = SQLAlchemy()
urlfetch.set_default_fetch_deadline(10)
f.close()
eventLoopThread.start()
seen_models = connection.introspection.installed_models(tables)
print(df)
myList.append(myList)
test.py
r = requests.get(url, stream=True)
label.grid_remove()
print(lines[i])
cb.ax.yaxis.set_tick_params(pad=45)
do_something()
a in (b + c, b - c, c - b)
set(tuple2).issuperset(tuple1)
arr = np.array([nbLamps, nbDays], dtype=np.bool)
items = [(-value, key) for key, value in list(the_dict.items())]
__init__.py
print(time.ctime(cdate), os.path.basename(path))
models.py
B = csr_matrix((data, indices, indptr))
EMAIL_USE_SSL = True
print(fdist1.most_common(10))
opa = pd.concat([pirmas_m, antras_m, trecias_m, ketvirtas_m], axis=1)
engine = cherrypy.engine
plt.plot(x_new, ffit)
ax1 = fig.add_subplot(2, 1, 1)
print(p.match(s).groups())
input_date.astimezone(current_tz)
attr = {}
[datetime.datetime(2012, 1, 2, 0, 0)]
getattr(o, name)()
pad = curses.newpad(PAD_LENGTH, curses.COLS - 1)
sys.path
[(5 * n) for n in range(1, 10 + 1)]
d = {}
A = [(A[i] + (0 if i % 2 == 0 else 0.1)) for i in range(len(A))]
itertools.chain(iter(self.items.items()), iter(self.people.items()))
print(json.dumps(mydata, indent=4))
f.flush()
map(int, numbers.strip().split())
df = pd.read_csv(csv_file)
result = df.a.sort_values().apply(lambda x: sorted(x))
print(thisRDD.toDebugString())
subprocess.Popen(winCMD, stdout=subprocess.PIPE, shell=True)
assert f([[0, 100], [0, 10], [11, 20], [15, 40]]) == [[0, 10], [11, 20]]
desired_list = map(lambda x__: x__[0], tuple_list)
result.append(line)
cell_value = int(cell_value)
lst2.append([x[0] for x in lst])
browser.close()
s.close()
min(foo, key=float)
deletedf.index.name
bokeh.io.show(page)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
fig = plt.figure()
client.get(URL)
driver = webdriver.Firefox()
fig = plt.figure(figsize=(10, 8))
f.close()
np.tensordot(A, Combinations, [2, 1]).transpose(2, 0, 1)
f.axes[2].set_position([0.45, 0.05, 0.05, 0.4])
appended_data = pd.concat(appended_data, axis=1)
connection = urllib.request.urlopen(url)
Session.commit()
np.put(arr, list(range(len(arr) + num, len(arr))), np.nan)
initcaller()
rdd_malformed.flatMap(lambda x: seq_try(json.loads, x)).collect()
dict_writer.writerows(toCSV)
self.end_headers()
app.config.from_object(config_obj)
out, err = proc.communicate(open(fn).read())
plt.imshow(np.random.randn(10, 10))
ax.add_patch(circ)
print(data)
document.update(**conv_dict_to_update(data))
df.index = df.index.droplevel(1)
Maemo4Spec()
fig = plt.figure(figsize=(8, 4))
table.sort(reverse=True, key=Team.getName)
prob = clf.predict_proba(X_test)[:, (1)]
time.sleep(5)
r, g, b = map(lambda x: x / 255.0, [r, g, b])
average_timedelta = sum(timedeltas, datetime.timedelta(0)) / len(timedeltas)
imarray.shape
writer = csv.writer(f)
target.update(request, *args, **kwargs)
cv2.rectangle(img, top_left, bottom_right, 255, 5)
screen.blit(my_image, another_position)
[(x + y) for x, y in zip(a, b)]
lines = f.readlines()
br.show()
processes.append(Popen(command, stdout=pipe, close_fds=True))
ax2 = fig.add_subplot(2, 1, 2)
logger.setLevel(logging.NOTSET)
a = np.random.rand(size)
self.layoutChanged.emit()
path.path(mypath).splitall()[0]
b in l[l.index(a) + 1:]
a[i1, i2]
layout.addWidget(self.table)
chunk = np.genfromtxt(f, max_rows=chunksize, *args, **kwargs)
deletedict_[key]
server.bind(sockfile)
fig = plt.figure()
list(map(add, [2, 2]))
cls.method_two()
fs.noteoff(0, 76)
p.stdin.close()
s = requests.Session()
ax1.plot([x1, x2], [y1, y2])
x = np.linspace(0, 20, 1000)
setup.py
print(str(a[2]))
now = datetime.datetime.now()
print(df)
x, y
np.where(a > b * 10, a * 2, -a)
rec.array([[40.0, 140.0], [50.0, 150.0], [60.0, 160.0]], dtype=float64)
gca().get_lines()[n].get_xydata()
app = QtGui.QApplication(sys.argv)
df
f.flush()
cb = fig.colorbar(im, ticks=LogLocator(subs=list(range(10))))
my_svr.fit(x_training, y_trainr)
msg.get_payload()
plt.show()
print(ET.tostring(newroot))
root.columnconfigure(1, weight=1)
file.close()
print(bool(pattern.search(byte)))
sps.coo_matrix((data, (rows, cols)), shape=(x.shape[0], theta.shape[0]))
ax1.set_xlim(1, 6)
mail.starttls()
df.idxmin(1)
good_html = tree.prettify()
str(unichar)
result = [[k, da[k] + db[k]] for k in set(da.keys()).intersection(list(db.keys()))]
result.append(key)
self.panel_sizer.Add(self.tin2, 0, wx.EXPAND)
threading.Thread.__init__()
frame.append(2)
griddata.addSample([X.ravel()[i], Y.ravel()[i]], [0])
arr = np.array([5, 4, -2, 1, -2, 0, 4, 4, -6, -1])
h, w = img.shape
settings.py
root.resizable(width=False, height=False)
time = datetime.now()
[i for i in B if i in A] + [i for i in A if i not in B]
baz2()
[d[item] for item in a]
pickle.dump(dict1, fp)
str(d)
plot.append(axF)
data = urllib.parse.urlencode(values)
arr = np.array(list(it))
list2 = [foo(i) for i in list1]
im.putalpha(256)
line = line.strip()
p.pattern
QGraphicsTextItem.__init__(self)
splitmaptime / parsetime
summaptime / parsetime
strp / parsetime
plt.show()
sum(a * b for a, b in zip(A, B))
print(get_last_non_zero_index([-2, -2, 0, 0, 0, 0, 0]))
max(b)
print(random_with_N_digits(4))
IOLoop.instance().start()
int(self.opt.stdout.readline().strip())
5 < [1, 2]
plt.show()
msg.attach(part1)
plt.show()
self.panel.Bind(wx.EVT_LEFT_DOWN, self.OnMouseDown)
print([(k, v) for k, v in list(self.items())])
pickle.dump(parameters, out_file)
ax.autoscale_view()
[random.randrange(10000) for _ in range(length)]
fill_node(root)
m = urllib.request.urlopen(url)
time.sleep(60)
oct_num = oct(dec_num)
Br = [x, x, x, x, 0, y]
new_t = t + np.hstack((t[1:], [t[0]]))
min(collection, key=lambda x: abs(x - num))
fig, ax = plt.subplots()
today = datetime.datetime.now()
vobject.contents
np.where(a == a.min())
datetime.strptime(s, f)
file.seek(0, 2)
w.setPalette(p)
plt.plot(t, s)
d2 = [k for k, v in list(d.items()) for _ in range(v)]
trimmed[k[0], k[-1]] += v
len(x)
password = db.StringProperty()
tmpdata = {}
list(range(10))
sys.path.insert(1, parent_dir)
l.set_option(ldap.OPT_X_TLS, ldap.OPT_X_TLS_DEMAND)
print([(sum(nums[:count]) / count) for count in range(1, len(nums) + 1)])
D0 = np.array([(A[i] * B[(i), :]) for i in range(len(A))])
self.append(item)
fig, ax = plt.subplots()
driver = webdriver.Chrome(chrome_options=chrome_options)
xticks(list(range(1, 6)))
gca().yaxis.set_major_locator(NullLocator())
numpy.exp(numpy.sum(numpy.log(a)))
combination[r - 1] += 1
f1.write(line)
text = json.loads(jsonurl.read())
print([val[1] for val in enumerate(a) if val[0] != i])
y1 = (x - x0) * sin(theta) + (h - y - y0) * cos(theta)
shallow_copy_of_x = type(x)(x)
poly = Polygon([(0, 0), (0, 2), (2, 2), (2, 0)])
np.dot(X, A)
img = ImageTk.PhotoImage(Image.open(path))
s.bind((HOST, PORT))
self.log.write(message)
do_some_stuff(i)
pool.join()
[0, 0, 0]
settings.development.py
a, b, c, d
Test().run()
a, b
b.sort()
pyplot.show()
e.pack()
lfilter(b, a, data)
json.loads(json_repr, object_hook=_decode_dict)
list.append(values[i])
connection = opener.open(request)
hl.set_ydata(numpy.append(hl.get_ydata(), new_data))
weed.save()
felix.save()
fixedser.plot(ax=axes[0])
pickle.dumps(test)
self.b = a
clean = [x for x in usertext if x not in stop_words]
driver = webdriver.Firefox()
lastDigit = x[-1]
np.fmin(np.digitize(A, hist[1]), bin_count)
[gu(i) for i in range(len(uo))]
True
print(mystring[-1])
p.start()
menu_item.show()
plt.show()
XB = np.linspace(-1, 1, 20)
ax.set_ylim(0, Y)
(a != b).nonzero()
self.socket.write(self.request)
psutil.virtual_memory()
a_game.run()
second_list.append(ls[1])
self.Show()
root = et.fromstring(text)
x.Bar()
(a * prior_reci + (1 - a) * prior_reci / 10).sum(axis=1)
app = QtGui.QApplication(sys.argv)
np.vstack(np.triu_indices_from(a, k=1)).T
bcut.label.set_visible(False)
self.s.lower() == other.s.lower()
subplot(2, 2, 4)
s, loc, scale = stats.lognorm.fit(data, floc=0)
z = dict(list(x.items()) + list(y.items()))
cnt1 = np.concatenate(([0], np.cumsum(cnt)[:-1]))
plt.ylim(0, 2.5)
print(list(result))
wx.Frame.__init__(self, parent, -1, title, size=(600, 400))
aList.append([element.strip() for element in row])
points.intersects(poly.unary_union)
ax1 = fig.add_subplot(111)
frame.pack()
self.connection.close()
list_2_sorted = [x[1] for x in sorted_together]
sum_chunk(a, 2, axis=0)
print(lines[0][0].shape)
confusion_matrix(y_actu, y_pred)
x = x.set_value(i, i ** 2)
id = Column(Integer, primary_key=True, nullable=False)
result.append(list_to_html(item))
math.sqrt(2)
signal.signal(signal.SIGPIPE, signal.SIG_DFL)
sort_indices = numpy.argsort(a, axis=0)
cherrypy.tree.mount(Root())
frozenset(chain.from_iterable(L))
numpy.__version__
data = [line.strip().split() for line in f.readlines()]
df.T
print(tmpl.render(v=Myobj()))
copyofL = remove_column(L, 1)
parent.mainloop()
print(list(traverse(data)))
conn.commit()
dcounts = Counter(d[0] for d in defectdetails)
create_user_profile(user)
np.all(A == B)
pool = Pool(processes=4)
item.append(item[0])
d = json.loads(json_acceptable_string)
[i for i in range(100000) if i == 1000][0]
print((current_item, next_item))
f.close()
a.f()
pdf = pyPdf.PdfFileReader(f)
g.mean()
print(ax.lines[0])
raise KeyboardInterrupt
os.dup2(oldstdout_fno, 1)
int(random.randrange(0, 255))
MyButton1.grid(row=0, column=0)
ax.lines[-1].set_linewidth(8)
shlex.split(teststring)
user = User.objects.get(pk=1)
z = [[y for y in row if y] for row in x.T]
help(subprocess.list2cmdline)
ax = fig.add_subplot(111)
time.sleep(5)
f(x, y)
my_dict[key] = 1
jsonify(d)
decorator(method)
both = np.hstack((img1, img2))
sys.stdout = old_target
console_handler = logging.StreamHandler()
result.append(item)
print(formatter.format(fmt, **data))
f.write(df.to_html())
subplot(4, 1, 1)
self.update_status()
print(df)
eval(x)
result = []
[0] + list(accumulate(sum(1 for _ in g) for _, g in groupby(bool_array)))
wrapper
my_field = models.CharField(max_length=100)
now = time.time()
regex.sub(_replacer, string)
session.run(tf.initialize_variables(uninitialized_variables))
assertion_raiser()
res = np.array(sorted(a, key=lambda x: (-x).tolist()))
self.comboBox_2.addItems(list1)
unicode_somedir = somedir.decode(encoding)
time.sleep(0.001)
dask.set_options(get=dask.multiprocessing.get)
last_name = forms.CharField(max_length=256)
writer = csv.writer(csvfile)
deleteL[idel:]
np.matrix(m)
plt.draw()
soup = bs4.BeautifulSoup(thehtml)
arr = arr.flatten()
s.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)
hxs = HtmlXPathSelector(response)
self._timer.cancel()
driver = ChromeDriver(options)
print([x for x in pattern.split(string) if x])
ax.add_artist(ab)
foo.read()
set(d[0]).intersection(*d)
unittest.main()
(np.random.rand(40, 40, 9, 1, 9, 1, 8) + np.random.rand(1, 9, 1, 9, 8)).shape
upload.save(file_path)
r = requests.get(url, stream=True)
df.Mathscore.map(d)
foo(noniterable, isiterable=False)
arr = numpy.zeros((50, 100, 25))
sd.SetSecurityDescriptorDacl(1, dacl, 0)
f.close()
tree = ElementTree.parse(StringIO(text))
x / y
start_date + timedelta(days=days_in_month)
app = QtGui.QApplication([])
np.cumsum(v)
id = Column(Integer, primary_key=True)
x.close()
x += c
moving_average(a)
cf.body[0].names[0].name
collection.insert(data)
views.py
greet()
l = [sublist[:] for sublist in l]
mytest.start()
pd.Timestamp(0)
min(S)
value = sheet.cell(row, col).value
query = query.filter(~table_a.id.in_(subquery))
tuple({name: score} for name, score in max_scores.items())
main()
ent.put()
dis.dis(test)
num_overlap = sum(map(all, zip(list1, list2)))
print(Kerma())
p = subprocess.Popen(inputcommand, stdout=subprocess.PIPE, shell=True)
dy = RK4(lambda t, y: t * sqrt(y))
qstring = webapp2.request.query_string
ax2.plot(list(range(10)))
point_buffer = np.array(point_list)
user_id = db.Column(db.Integer, primary_key=True)
print(list(range(math.floor(min(y)), math.ceil(max(y)) + 1)))
df
print(map(lambda x: x[:-1], test))
ax.get_yaxis().set_visible(False)
dict.__setitem__(self, key, value)
g[1].nunique()
q = mp.Queue()
HttpResponseRedirect(request.path)
df1 = df.ix[:, 0:12]
True
os.fstat(f.fileno()).st_nlink
logger.addHandler(handler)
thumb = ImageOps.fit(image, size, Image.ANTIALIAS)
set(frozenset(ts) for ts in x)
[(a, b, c) for a in range(10) for b in range(a, 10) for c in range(b, 10)]
f.close()
print(my_list)
json.dumps(lst)
print((filename, oct(mode)))
df.index = df.index.values + df.RecordID.map(str)
main()
root.remove(child)
btn_1.focus_set()
ordered = sorted(Foo.objects.all(), key=lambda n: (n[0], int(n[1:])))
a[a > 2]
float(str(x)[:i])
plt.figure(2)
msgunfmt[path_to_file.mo] > [path_to_file.po]
extruded = np.zeros((N, 10, 10))
cv2.convertScaleAbs(image, result, alpha, beta)
self.retrieve(request, *args, **kwargs)
ax.quiver(X, Y, Z, U, V, W)
luckynumbers.append(item)
print(unicode_row)
y = [p[1] for p in points]
root.update()
t.close()
fig = plt.figure(figsize=(8, 8))
print(map(str, rr))
yourFile.write(raw_data)
(a[1], b[1]),
f(2)
user = models.OneToOneField(User)
array[0],
print(xyz.__doc__)
plt.colorbar(pc, ax=axes)
plt.xticks(x, labels)
d.setdefault(a, []).append(b)
clf.tree_.apply(np.asfortranarray(X.astype(sklearn.tree._tree.DTYPE)))
pythoncom.CoInitialize()
form.category.data = post.category.id if page.category else 0
np.diff(np.array(s))
np.allclose(a.indices, b.indices)
a = np.arange(10)
self.conn.close()
bp.output_notebook()
imgplot = plt.pcolormesh(lum_img)
proc.append(p)
a = np.arange(10)
ax.bar(dates, values, width=100)
ui.WebDriverWait(browser, 10).until(waiter)
df.to_records()
show()
contestant = models.ForeignKey(Contestant)
print(solve(eqn))
collection.find({}, limit=10).sort(sort)
win.setWindowFlags(win.windowFlags() & ~QtCore.Qt.WindowMaximizeButtonHint)
init_new_vars_op = tf.initialize_variables(uninitialized_vars)
os.makedirs(myTemp)
opener = urllib.request.build_opener(authhandler)
print(list(Squares(20, 90)))
self.ax.autoscale_view()
time.sleep(1)
a = [1, 2, 7]
y = tf.slice(x, i, [1])
authorization = authorization.Authorization()
ax.legend(handles, labels, loc=2, ncol=4)
inset.yaxis.set_tick_params(labelsize=INSET_TICK_FONTSIZE)
print(s.strip(punctuation))
P = multiprocessing.Pool()
self.draw_grid()
pygame.init()
divide(2, 7, 1000)
plt.imshow(im, cmap=cm.gray)
run_thread.start()
sess = tf.Session(config=config)
all(x == s[0] for x in s)
np.count_nonzero(df.isnull().values)
fig = plt.figure()
np.array(sorted(a, cmp=lambda x, y: list(x).index(1) - list(y).index(1)))
zip(zip(*a), zip(*b))[0]
wx.Menu.__init__(self)
value = test[2]
b = copy.deepcopy(a)
c.append(list(el))
globals()[tupleofnames[i]] = data[i]
f()
date += datetime.timedelta(days=2)
message.send()
Py_DECREF(name)
rows.append(row)
print(w.cget(item))
file_list.append((os.stat(filename)[stat.ST_MTIME], filename))
self.driver.get(response.url)
self.pot.Boil()
ax.update_datalim(np.column_stack([x, y]))
print(icon_info.get_filename())
my_rhs = [1.0, 1.0, 0.0, 0.0, 0.0, -1.0, -1.0, -1.0, 0.0, 0.0, 0.0]
content = urllib.request.urlopen(some_url).read()
window.activateWindow()
sys.stdout = stdout
round(2.99999999999)
qmgr.connectTCPClient(queue_manager, pymqi.cd(), channel, conn_info)
assert np.allclose(results[2], results[0])
np.count_nonzero((abcd <= data2a) & (abcd >= data2b))
response.read()
Response(body, status=status, headers=headers)
f.readline()
datetime.now() - datetime.combine(bday, time())
cv.fit(X, y)
Index = next(i for i, _ in enumerate(a) if np.isclose(_, val, tol))
np.random.seed(1977)
ser.sum()
plt.close(fig)
max(a, b)
print([x for x in groups if a not in x])
elements.append(q.get_nowait())
{{field}}
msg = email.message_from_string(data[0][1])
p.stdin.write(input)
app = Flask(__name__)
ctx.pop()
print(b[:, :, (2)])
a = a.__iand__(b)
df.A.combine_first(df.B)
df.loc[df[1:][df.index.month[:-1] != df.index.month[1:]].index]
np.argsort(p)
stream_handler.setFormatter(formatter)
words = input_string.split()
df.apply(lambda x: len(set(x)) == 1, axis=1)
seq.sort(key=itemgetter(1))
response = requests.get(url, data=data)
False
json_data_string = simplejson.dumps(your_data)
GEN_CLOSED
_async_raise(self._get_my_tid(), exctype)
Base.metadata.create_all(engine)
pd.isnull(df).sum() > 0
os.chdir(cwd_path[0])
fig = plt.figure()
fillmylist(l, 5)
frame.Show()
self.admin_model_path = self.model.__name__.lower()
self.video_cap.release()
result_dict = {k: list(g) for k, g in it.groupby(mylist, keyfunc)}
dict([x for x in list(data.items()) if x[0] > 5])
print(f(2))
aapl.sign.iloc[(aapl.sign.diff() != 0).cumsum().drop_duplicates().index]
args = parser.parse_args()
d[x].append(foo)
f.close()
myarray[0][-1]
self.pack()
ax.set_ylim(0, np.pi)
setattr(self, field.attname, getattr(db_instance, field.attname))
d = defaultdict(list)
plt.plot(list(range(10)))
np.cov(np.nan_to_num(data.T))
self.filter(id__in=ids)
ridx = sorted(range(len(U)), key=idx.__getitem__)
d = pd.DataFrame()
current_time = start_time = time.time()
f.close()
fig, ax = plt.subplots()
canvas.draw()
[rect.set_visible(False) for rect in rects]
irc = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
time.sleep(5)
a[0], a[1] = [4, 5]
plt.colorbar(cax=cax)
datetime.datetime(2001, 11, 12, 0, 0)
signal.pause()
numpy.zeros((2, 20))
print(self.myVar)
in_file.close()
inithello()
print(data)
windowSurface.blit(s, (0, 0))
GST_VERSION_MINOR,
self._data[key]
result = np.cumsum(np.random.uniform(size=100))
[memoized(x) for x in l if memoized(x)]
self.d[key] = max(self.d[key], n)
ax.set_rasterization_zorder(0)
result = eval(myString)
len(set(str_.split()).intersection(list(dict_1.values())))
today = datetime.datetime.now()
m.click(x, y, 1)
date = dateutil.parser.parse(text)
dc.SetBackground(wx.Brush(wx.Colour(255, 0, 255)))
myapp.db.create_all()
[0, 0, 0, 0, 1, 0, 0, 0, 0],
bar = p[0]
data = np.random.randint(0, 100, (400000.0, 206))
b.grab_set()
layout.addWidget(self.view)
frame.a.str.contains(pattern)
time.sleep(2)
df.applymap(atof)
n = a.shape[1]
info[0][1] == 2
ax1.patch.set_alpha(0.0)
db.add_son_manipulator(Transform())
form.jobs[0].company.choices = company_list
cameraL.SetFocalPoint(0, 0, 0)
ax.set_ylim(-0.5, 1.7)
print(res.cluster.value_counts())
print(t.astimezone(EST))
dir(settings)
A.view(dtype=np.complex128)
fig = plt.figure()
dt_start = dt_start + datetime.timedelta(days=21)
doc = ET.fromstring(content)
[(x, sum(map(itemgetter(1), y))) for x, y in groupby(L, itemgetter(0))]
df.dtypes
browser = webdriver.Firefox(firefox_binary=binary)
help(modulename)
np.issubdtype(np.uint8, np.integer)
app
element.remove(subelement)
a[1:][::2]
bytes = bitarray(bin(my_long)).tostring()
q.all()
print((group.id, group.last_response))
vals = redis.zrange(key, 0, -1)
screen_width = root.winfo_screenwidth()
print(sess.run(tf.shape(parsed), feed_dict={raw: my_data}))
items = [dicttolatex(dic) for dic in items_to_clean]
print([x for x in list(globals().keys()) if isinstance(globals()[x], FunctionType)])
sys.stdout.write(line)
local_namespace.clear()
arr[97][99][99]
d = dict(zip((o.name for o in object_list), object_list))
s = socket.socket()
grouped.size().idxmax()
zipfile = ZipFile(StringIO(result.read()))
[i for i in np.argsort(a[:, (0)]) if a[i, 1] == -1][0]
list(merged.values())
parser.add_argument(*option, **config)
foo()
random.choice(list(i))
t_points = t_image[t_pos[:, (1)], t_pos[:, (0)]]
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
output_signal = scipy.signal.filtfilt(b, a, input_signal)
pg.AxisItem.__init__(self, *args, **kwargs)
os.system(command)
eiffel_tower_5k = Location.objects.nearby(48.8582, 2.2945, 5)
filename = os.path.abspath(os.path.realpath(filename))
list(flatten(remove(l, 1)))
sys.stdout = sys.__stdout__
print(br.title())
print(m.group(1))
dom = xml.dom.minidom.parseString(document)
main()
D.ix[idx]
print(Decimal(x))
pythoncom.PumpWaitingMessages()
dateForm.set_index(pd.DatetimeIndex(poorList), inplace=True)
set_trace()
df
[1, 17, 1, 0, 2, 0]
browser.select_form(nr=0)
chain.from_iterable([x] if isinstance(x, str) else x for x in lst)
plt.show()
fileconcord.close()
b = [(sl + [0] * (maxlen - len(sl))) for sl in a]
(bad, good)[x in goodvals].append(x)
arg2value
connection.put_record(stream_name, data, partition_key)
[sum(q[i:i + 2]) for i in range(0, len(q), 2)]
v1 = max(0, A)
webdriver.Firefox(firefox_profile=fp)
stats.normaltest(x)
seen_add(k)
self.on_finish()
_test()
admin.site.register(model)
_quicksort(array, left, stop)
writer.writeheader()
sys.stdin.readline()
t.start()
root.mainloop()
window.set_icon(windowicon)
print(curve_fit(func, (x, y), z, p0))
sorted(mydict)
plt.subplot(121)
4, (0, 5, 0, 0)
self.textLayout.addWidget(text)
csv_writer.writerows(mylist)
print(my_dict)
types = [elem[1] for elem in res.cursor.description]
assert isinstance(o.someattribute, str)
print(foo(**d))
print(pool.map(f, list(range(10))))
a[i].append(x)
val = val[:-1]
self.gzfile.close()
db.Column(*args, **kwargs)
config = configparser.ConfigParser(defaults=myDefaults)
dst = cv2.cv.CreateMat(height, width, cv2.IMREAD_COLOR)
total = sum(marks.values())
sys.getsizeof(10 ** 10 ** 6)
soup = BeautifulSoup(html)
browser.set_handle_redirect(True)
msgBox.exec_()
app = Flask(__name__)
max(set(words), key=words.count)
s = [0] + [i for i in range(1, len(x)) if x[i] != x[i - 1] + 1] + [len(x)]
ax.plot(dataX, dataY, linewidth=0.5)
response = urllib.request.urlopen(req2)
f.write(header)
draw()
ax.set_ylim(ax.get_ylim()[::-1])
{{day}}
p.stdout.read().strip()
draw.text((5, 5), char, (0, 0, 0), font=font)
tuple(map(itemgetter(0), G))
Process.__init__(self)
transsurface = pygame.display.set_mode(screen.get_size())
libfoo.dll
val = ast.literal_eval(val)
p.join()
s = pd.Series([10, 10, 10, 14, 10, 10, 10, 14, 100, 14, 10])
http.HttpResponseRedirect(url_with_get)
subplot(1, 2, 1)
db.session.add(entry)
add(*arg)
s = input()
print(self._applecount)
[n for d, n in sorted((abs(x - myNumber), x) for x in myList)[:k]]
result.append(a)
[dct for dct in listA if dct.items() >= dictA.items()]
p.start()
gunicorn_django - c / path / to / website_gunicorn.conf.py
self.values.add(item[1])
np.split(a - b, np.cumsum(y))
max(zip(map(sum, a), a))[1]
{(x + 1) for x in l}
print(foo)
Parallel(n_jobs=2)(delayed(foo)(parameters) for x in range(i, j))
uuid.uuid4().hex
yaml.dump(data, outfile, default_flow_style=False)
self.pack()
d.cards.remove(Card(1, 1))
tree.xpath(expr, namespaces=nsmap)
form.save()
print(line)
do_something_else()
logger = logging.getLogger(name)
soup = BeautifulSoup.BeautifulSoup(htmldoc)
self.filter(id__in=ids)
df.combine_first(s.T)
sys.getsizeof(t1)
result = [list(map(player, group)) for level, group in groups]
x.digest()
out = [(x, y, z, c) for (x, y, z), c in zip(a, h)]
velocity = np.array([[dx_dt[i], dy_dt[i]] for i in range(dx_dt.size)])
my_logger.setLevel(logging.DEBUG)
args = sys.argv[2:]
vv.plot(x, y, z, lw=10)
df = pd.DataFrame(np.random.randint(10, size=(10, 10)))
t.daemon = True
demand.ix[series.name].apply(lambda x: x * series).stack()
d = defaultdict(list)
tag.insert(1, subtag2)
plt.scatter(x2, y2, label=str(pointset2))
reader = csv.reader(csvinput)
new_func_name()
name[0][0][-1]
data = json.load(jsonFile)
a = [x[:] for x in repeat([0] * cols, rows)]
lis = []
Profile.objects.filter(full_name__iregex=regex)
df.astype(float).sum().astype(int).astype(str)
num_df[num_df[data_columns].notnull().all(axis=1)]
conn.close()
print(g.user_set.all())
pic = QtGui.QPixmap(imagePath)
f.close()
ax.get_children()
[vector.index(x) for x in sorted(list(range(n)), key=vector.__getitem__)]
print(list(od.values()))
ax = fig.add_subplot(111)
a.remove(item)
y.sort(key=sort_key)
bucket.configure_lifecycle(lifecycle)
map(cls.my_func, items)
instance.save()
key = bytearray.fromhex(hexs)
ax.xaxis.set_major_formatter(ticker.NullFormatter())
pb = gtk.gdk.Pixbuf(gtk.gdk.COLORSPACE_RGB, False, 8, sz[0], sz[1])
movie_tuples = [tuple(map(d.get, fields)) for d in movie_dicts]
[0, 0, 0, 0, 0, 1, 0, 0, 0],
clocknumber = models.CharField(max_length=16)
L = [np.arange(start[i], stop[i]) for i in range(ndims)]
app.debug = True
print(file.readline())
res = [f.name for f in message.DESCRIPTOR.fields]
[x for x in iter if is_even(x)]
result.get()
print(isinstance(obj, BaseClass))
ax.plot(x, y)
queryset.filter(created_at__range=(first_date, last_date))
arr[1, 1]
win = gtk.Window()
background_label = tk.Label(parent, image=background_image)
a.reshape(sh).mean(-1).mean(1)
plt.plot(list(range(10, 20)))
signal.signal(signal.SIGALRM, nothing)
print(float(2))
full_time = timedelta(seconds=multiplier * passed_time.total_seconds())
index = np.ogrid[:z2.shape[0], :z2.shape[1], :z2.shape[2]]
func(*args)
root = tk.Tk()
l.sort(cmp=lcmp)
cherrypy.quickstart(CServer(), config=conf)
self.audio.terminate()
cb = plt.colorbar()
tree.predict(iris.data)
str(self.client_address[0])
reactor.run()
output.append([item])
df.values
y[np.isnan(y) | np.isinf(y)] = 0
log_file
srcs = [src[2] for src in list_of_all]
writer = csv.writer(out)
map(mydict.get, [k for k in list(mydict.keys()) if k >= 6])
(x - x.min()) * (b - a) / (x.max() - x.min()) + a
fig.subplots_adjust()
x(os.path.join(dirpath, f))
self.y -= STEP
scipy.sparse.coo_matrix((data, ij), shape=(nrows, ncols))
curs.execute(sql)
mutate_dict(lambda x: x + 1, my_dictionary)
assert np.allclose(s, [r.sum() for r in results])
maxlength = max(len(s) for s in stringlist)
textobj.set_text(wrapped_text)
pool = multiprocessing.Pool()
max(list(d1.items()), key=operator.itemgetter(1))[0]
numsum = sum(numbers)
result_dict = OrderedDict()
matplotlib.hatch._hatch_types.append(CustomHorizontalHatch)
plt.show()
plt.ion()
p.start()
data[s < m]
result[i] = func1d(x, y)
textwrap.fill(s, width=10)
sorted(list(range(len(a))), key=lambda i: positions[i])
[[(e - d) for d in l] for e in l]
ax.xaxis.set_major_formatter(ticker.FixedFormatter(name_list))
list(d.items())
[0, 0, 0, 0, 0, 0, 1, 0, 0],
docx.write(os.path.join(tmp_dir, filename), filename)
wx.EndBusyCursor()
gtk.main()
mod = importlib.import_module(name)
d.add(2)
print(etree.tostring(doc, pretty_print=True))
Tup()[0]
n = collatz(int(n))
print(sum(1 for x in range(1000000) if my_condition(x)))
ctypes.memmove(self._buffer, value, size)
zbar.version()
df.iloc[[p] + [i for i in range(len(df)) if i != p]]
{{b}}
lst = [(word[0].upper() + word[1:]) for word in s.split()]
HypotheticalBranch(1, 2, 1)
self.label = QtGui.QLabel(self)
print(hex(id(b)))
plt.setp(labels, rotation=90)
date_paris.astimezone(pytz.utc)
df.dot(s)
parser = argparse.ArgumentParser()
user = request.user
data.sort(key=lambda data: [alphabet.index(c) for c in data[0]])
res = [x for x in res if x.size > 1]
na_values = []
double_to_hex(17.5)
r = requests.get(url)
ax1.axis([xmin, xmax, ymin, ymax])
plt.grid()
array([16, 6, 8])
self._timer.start()
A = np.arange(16).reshape((4, 4))
print(maskborder.shape[:2])
f.write(xml)
np.set_printoptions(threshold=np.inf, linewidth=np.inf)
writer.close()
ax.grid()
print(b.dtype, b[0].dtype, b[1].dtype)
scat = plt.scatter(x, y, c=c, s=100)
result = db.engine.execute(sql)
a = np.array([sum(row * weights) for row in values])
z = z.reshape(x.shape)
cj = cookielib.CookieJar()
time.sleep(60)
np.random.seed(1145)
p.stdout.close()
data = response.read()
self.tws.connect()
print(concatenate((tone2, tone1), axis=1))
self.assertEqual(resp.status_code, 200)
self.output = []
basemetaclasses.append(metacls)
source.camlp4.ocaml
fd.close()
fig.figimage(np.random.random((xpixels, ypixels)))
python - -version
TRUE
max(i[j] for i in l)
sess = tf.Session()
timestamp = calendar.timegm(d.utctimetuple())
to_remove = [i for i, val in enumerate(x) if len(val) == 2]
cursor = connection.cursor()
pyplot.ioff()
mcurr = location_re.search(currline)
set(dic1) == set(dic2)
self.assertDictEqual(input_dict, expected)
c.writerow([cell.value for cell in r])
count += 1
new.setdefault(k, []).append(v)
[(a - b) for a, b in zip(dividers + [total], [0] + dividers)]
files_grabbed.extend(glob.glob(files))
ax.set_xticks(np.arange(0.5, 10.5, 1))
ax2.plot(x, y)
{{saved_setting}}
random.shuffle(indices)
makesymbexp(makesymbtree(T, L))
print(response.getvalue())
list1 = [int(x) for x in list1]
f.seek(0)
EllShape = Affine2D(numpy.array(sqrtm(inv(A)), dtype=np.float64))
print(a)
{k: min(i for i in (h1.get(k), h2.get(k)) if i) for k in h1.keys() | h2}
do_something()
self.clear_button.pack()
self.func(*(args + self.args), **kwargs)
zip(assignment, *grades)
int_docs_info = {int(k): v for k, v in list(docss_info.items())}
pylab.imshow(image)
self._data = {}
pool.close()
id = models.CharField(max_length=255, default=create_id)
plt.tight_layout()
len(bitArray.tobytes()) / float(len(sequence))
ax.legend()
theFile.close()
words = line.split()
sum(chain(*my_list))
array = [myNumber]
not int(a)
fig = plt.figure()
print(__main__.__file__)
f1 = Foo.objects.get(pk=f1.id)
msg.attach(text)
np.argwhere(A > 50)
Department.objects.filter(group__exact=self.group)
[_f for _f in map(f, string) if _f]
self.root = tk.Tk()
s = sparse.csr_matrix(a)
df.iloc[indexers]
data.append(value)
app = wx.PySimpleApp()
print(best2)
__getitem__
neurons.append(neuron)
my_array.clip(0, 255)
result = list(create(10))
cosetCoding.cosetCoding(10, 11, 8, ctypes.byref(arr), 0)
mpp.start()
callback(myargument)
np.random.seed(100)
a = next((i for i in userInput if i in wordsTask), 42)
lxml.html.etree.tostring(a)
foo(20, 5)
G = nx.gnp_random_graph(n, p)
AB = [(a + b) for a, b in zip(A, B)]
[a, b, c, d, e, f]
self.stream.stop_stream()
update_document(person, data)
os.path.normpath(os.getcwd() + os.sep + os.pardir)
output.append(lst)
plt.plot(datenums, values)
pdb.set_trace()
camera_handle = ctypes.c_ulong(0)
a + b
assert np.allclose(xRemainder, 0)
parser = argparse.ArgumentParser()
result = dict(defaults, **request)
[]
setattr(obj, key, value)
app.exec_()
worksheet.column_dimensions[get_column_letter(i + 1)].width = column_width
my_server = redis.Redis(connection_pool=POOL)
sess.run(init_op)
isinstance(obj.method, types.MethodType)
np.add(a, b, out=c)
reader = csv.reader(f)
df
random.shuffle(a)
df
[list(g) for _, g in groupby(numbers, lambda x: x // 10)]
gethandler
time.sleep(0.1)
result = regex.match(str)
nbrs.fit(X)
self.setLayout(layout)
client = suds.client.Client(sys.argv[1])
map(tuple, pairs)
f.close()
output.write(resp.content)
time.sleep(x)
binascii.unhexlify(line)
indices = np.split(sidx, cut_idx)[1:]
__init__.py
fh.write(dh.read())
plt.hold(False)
plt.figure()
tags = ManyToManyField(Tag)
z = np.arange(Z)
pilImage.close()
tuple(it.chain(*base_lists))
d = dict.fromkeys(a, 0)
process(line)
{{my_dollars | currency}}
axins1.set_ylim(y1, y2)
sorted([[x, y] for x, y in list(distances.items())], key=lambda x: x[0])
feature_names = vectorizer.get_feature_names()
plt.xticks(visible=False)
_test_model()
print(r[0] + r[1])
print(value)
socket.gethostname()
[(a[i] - a[i + 1]) for i in range(len(a) - 1)]
lgd = ax.legend(loc=9, bbox_to_anchor=(0.5, 0))
print(hex(i)[2:].zfill(2).upper())
res.append(x)
s.apply(partial(map, lambda x: x * 2))
assert np.allclose(std, data.std())
d[parts[0]] += parts[1:]
Decimal(2).sqrt()
r = requests.get(file_url)
foo = decorator_with_args(arg)(foo)
importlib.import_module(name)
server.close()
print(letters[:i] + letters[i::-1])
sudokupossibilities = [[[1] * 9] * 9] * 9
d.mean(axis=tuple(range(1, d.ndim)))
plt.clf()
soup = BeautifulSoup(text)
a.func()
MyUser.friends.append(Friend(MyUser.id, MyFriend.id))
df * df2.values
list(map(lambda m, n: m - n, a, b))
np.random.seed(10)
ns = np.linspace(-5, 5, 1000)
print(extract_text(htmlDom))
id = Column(Integer, primary_key=True)
logging.error(e)
sockobj = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
t = np.copy(a[:, (0), (0)])
tz.localize(parser.parse(a_datetime))
json.dumps(my_data)
mw.dockWdg2.setWidget(mw.content2)
log.addHandler(fileh)
output.close()
root.config(menu=menubar)
raise Exception()
f.axes[4].set_position([0.55, 0.45, 0.4, 0.05])
reader = csv.reader(input, **options)
fig, ax = plt.subplots()
pool = Pool(processes=4)
handler()
[x for x, y, z in G]
print(line.rstrip()[::-1])
np.npv(0.01, cashflow)
urllib.request.install_opener(opener)
list2 = list(total_and_item(list1))
digits = int(math.log10(-n)) + 2
doSomethingWith(match.group(0))
zip(l, itertools.repeat(o))
app.debug = True
Ainv[i] = np.linalg.inv(A[i])
ast.literal_eval(s)
s.listen(1)
divisibleBySeven = [num for num in inputList if num != 0 and num % 7 == 0]
time.sleep(1)
id = Column(Integer, primary_key=True)
fig = plt.figure()
instance.save()
observer.start()
self.response.out.write(os.stat(path).st_mtime)
print(numpy.__version__)
c.most_common()[0]
result.get()
u.close()
subplot(4, 1, 2)
C4.foo()
C5.foo()
c_array[:] = chain(p for p in points)
writer.save()
df.drop(df.columns[cols], axis=1, inplace=True)
print(p.groupby(p.diff().cumsum()).cumcount())
pprint(dict(grouped))
app.listen(8888)
parser = argparse.ArgumentParser(add_help=False)
nopreds.add(u)
np.maximum.reduceat(given_sort, first_idx)
tree = etree.parse(StringIO(data), magical_parser)
im.set_clim([frame.min(), frame.max()])
app = QtGui.QApplication(sys.argv)
image /= image.max() / 255.0
w.tk.mainloop()
int(s)
process(0)
plt.scatter(xs[i], ys[i], marker=m[i])
signal.signal(signal.SIGALRM, self.handle_timeout)
fig = plt.figure()
print(is_perfect_cube(2146689000))
screen = pygame.display.set_mode(DISPLAY, FLAGS, DEPTH)
alphabetDict = {char: (0) for char in alphabet}
print(x)
fig.autofmt_xdate()
keyName = myMember.key().name()
int(time.mktime(value.timetuple()))
self.Bind(wx.EVT_LEFT_DOWN, self.on_left_down)
m2 = np.zeros((50, 50))
sum(map(lambda x: map(lambda f: f(x), ListArg), listFunc), [])
sys.getsizeof(Bar())
self.out, self.err = self.proc.communicate()
math.ceil(f / 2.0) * 2
print(json.dumps(categories, indent=4))
m = [[(row - col) for row in l] for col in l]
abs(1)
url_get = self.request.GET
f.bar(1, 2)
subprocess.call(subprocess_cmd)
transpose.sort(key=itemgetter(0))
hash(round(6.75, 1))
p.stdin.close()
pool = multiprocessing.Pool()
loop.run_until_complete(main())
df2[cols]
dict.__setitem__(self, frozenset(idx), value)
x + y
text[(value + step) % len(text)]
gevent.joinall(jobs)
print(requests.get(url).text)
outfile.write(self.archive.getmember(name).read())
ax.set_xticklabels(mons)
f.close()
n % 2 == 0
t.join()
{k: {k_: v[k_] for k_ in common_keys} for k, v in d.items()}
sys.exit(0)
mylist.append(item)
list(dict.keys())[0]
tn.close()
tree = ET.parse(StringIO(text), parser)
dict_writer.writerows(rows)
MyModel.objects.filter(complexQuery)
ax = fig.add_subplot(111)
df.ix[start:end]
o.call()
url = Column(String)
np.random.shuffle(zeros)
a2[:, (1)] > 10
a = bitarray(2 ** 20)
pool.join()
[del_zeros(L, i) for i in range(5)]
nll
result.add(elements[0])
df
rconsole.spawn_server()
f(**locals())
XXX
func(*args, **kwargs)
now - timedelta(seconds=15)
os.chdir(os.path.dirname(os.path.realpath(__file__)))
reload_urlconf()
x = int(str(x)[::-1])
pylab.draw()
b = np.matrix(np.array(a))
a[0] * b[1] - a[1] * b[0]
writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
wx.Frame.__init__(self, parent, id, title, pos, size, style, name)
__main__.py
doctest.testmod()
print(list(igroups([0, 0, 0])))
ax = fig.add_subplot(111)
r = boxplot(data)
nx.draw(G, pos)
groups.apply(existedBefore)
a = np.delete(a, b, 0)
numpy.ma.masked
socket.setdefaulttimeout(10)
print(list(unzipped[0]))
pyplot.show()
parent.remove(elem)
Package - 2 / namespace / module2 / __init__.py
ax = fig.add_subplot(111)
entryFrame.columnconfigure(0, weight=10)
func_name = sys._getframe().f_code.co_name
d[k] = tuple(d[k] for d in ds)
p.join()
plt.hist2d(a, b, (50, 50), cmap=plt.cm.jet)
b = word in (w for i, w in enumerate(wordList) if i not in ignore)
obj.load_from_filename(filename)
PROJECT_DIR = os.path.dirname(os.path.abspath(__file__))
all(isinstance(i, int) for i in l)
foo_vars = {id(instance): instance.foo for instance in A.instances}
fig, ax = plt.subplots(1, 1)
g.set(xticklabels=[])
t = np.linspace(0, T, nsamples, endpoint=False)
ax.scatter(x, y)
ast = np.lib.stride_tricks.as_strided(a, a.shape * 2, a.strides * 2)
random.seed(1)
name = models.CharField(max_length=100)
raise OSError(p.stderr.read().rstrip())
print(response.read())
add_keys(d[l[0]], l[1:], c)
df.groupby(df.columns, axis=1).apply(lambda x: x.info())
self.common1()
root.tag
setattr(self, key, [company])
merged = list(joinz(1, zdf1.iter(), 0, zdf2.iter()))
bitmap = np.array(bitmap, np.uint8)
time.sleep(2)
pd.concat([group for _, group in grouped if len(group) > 1])
plt.draw()
print(match.groupdict())
print(string)
df = pd.concat([df] * 1000).reset_index(drop=True)
toggle_btn.pack(pady=5)
write.writeheader()
t, dt = np.linspace(0, 1, num_t, endpoint=False, retstep=True)
self.__dict__ = self._dict
a = [1, 2, 1, 4, 1, 1, 1, 1]
ln.set_xdata(list(range(len(data))))
x.reshape(-1, x.shape[-1]).shape
signal.signal(signal.SIGINT, _forward_to_django_shutdown_signal)
pixmap5 = pixmap.scaled(64, 64)
self.Bind(wx.EVT_WINDOW_CREATE, self.SetWindowShape)
np.isfinite(b_0).all()
int(string[::2], 2)
xscroll.grid(row=1, column=0, sticky=E + W)
ax.set_xticks(x_labels_pos)
roster.append(dayroster)
tableWidget.setItem(i, j, item)
tic2()
f = lambda x: x * np.cos(x - 4)
flags = np.arange(1, n + 1).reshape(1, -1)
cursor = cnxn.cursor()
accumulationList.extend(doSomething(x))
{{item_forms.empty_form}}
_stack.append(self.kwargs)
[[f(v) for v, f in zip(x, funcs)] for x in a]
mod = __import__(module_name)
os.path.join(*choices)
unicodedata.category(character)
code_country.append([key, countries[key]])
self.window.set_default_size(100, gtk.gdk.screen_height())
w = Gtk.Window()
collections.defaultdict(recursive_dict)
ttk.Frame.__init__(self, *args, **kwargs)
parse(data)
data = json.loads(json_content)
result = my_range[:-1]
self.exit(0)
max(sentence)
self(other(*args, **kwargs))
w.writerow(list(somedict.values()))
time.sleep(1)
DEVNULL.close()
self.session.get(url)
ax.set_zlim(-100, 100)
textdata.set_index(mergecols, inplace=True, drop=False)
User._default_manager.get(username__iexact=username)
form = UploadForm(request.POST, request.FILES)
canvas.grid(row=1, column=1, sticky=Tkconstants.NSEW)
(x + y) / 2
assert a.average() == 10
list(map(sub, a, b))
[x for x in b for b in a]
Base.metadata.reflect(bind=engine)
idx = np.arange(A.shape[0])
list(product([]))
fig, ax = plt.subplots()
list(totals.items())
ax = fig.add_subplot(111)
my_list = json.load(f)
test = defaultdict(defaultdict(list))
list(set(chain(*x)))
fig = plt.figure()
d.update(extra)
f.close()
result.append(list(range(last, last + v)))
app.register_blueprint(simple_page)
[0, 0, 0, 0, 0, 8, 0, 0, 0, 8, 0, 0, 0],
results = Queue.Queue()
chi2.ppf(0.8, df=2)
path = os.path.realpath(path)
inner(x)
print(avg(arr))
print(df.iloc[:, (0)].values.flatten())
C5.bar()
r = requests.post(finalURL, data=payload)
unittest.TextTestRunner(verbosity=1).run(testsuite)
f.readline()
os.system(image)
len([(1) for _ in takewhile(lambda x: x == a[0], a)])
output_file.writelines(merge(*files))
deletenew_list[0][0], new_list[1][0]
fn = lambda x: x if True else lambda x: x * x
db.session.commit()
socket.bind((HOST, PORT))
ax.set_xlim([-0.1, 1.1])
True
buf = lines[-1]
foo.foo()
parser.print_help()
now_date.replace(day=1)
all(x == first for x in it)
m = cv2.moments(c)
self.level(sys.stderr)
s.ioctl(socket.SIO_RCVALL, socket.RCVALL_OFF)
reader = csv.reader(csvfile)
a = np.array([0, 0, 0, 0, 0, 0])
ax = fig.add_subplot(111)
self.response.out.write(template.render(template_values))
solve(z ** 2 + (1 + I) * z + (6 + 18 * I), (x, y))
hist([t.hour for t in ts], bins=24)
any(s in l for l in lines2 for s in search_strings)
family.remove(i)
suffixes = set(s[-5:] for s in x)
model.feature_importances_
print(pool.map(f, list(range(10))))
f.close()
main()
sort_idx = np.argsort(a)
wx.Frame.__init__(self, parent, title=title, size=(200, 100))
leadingzerocounts[i] += 4
pylab.show()
lst = json.loads(string)
np.split(np.concatenate((a, np.zeros(padding))), n)
round(number * 20) / 20
tar.close()
obj.save()
ser.close()
browser = webdriver.Firefox()
signal.signal(signal.SIGINT, self._signal_handler)
max(a)
b = Finalizable()
np.all(np.linalg.eigvals(x) > 0)
cv2.circle(img, (x, y), 4, (0, 255, 0), -1)
foo.baz()
key = lambda x: x[0]
result
df[:-1]
self.frame.SetFocus()
np.sum(np.where(m, 1.0 / p, 0.1 / p), axis=1)
res[(i), (j), :] = [C, X, 0]
shutil.rmtree(path)
df[idx]
df
self.device.open()
math.factorial(10)
application = django.core.handlers.wsgi.WSGIHandler()
getattr(obj, self.attr)
[x for x in a_list if x[0] == 1]
print(list(multilpy_string(l)))
panel.to_frame().unstack().T.groupby(level=0)
data = requests.get(url).json
json.loads(json_data)
time.sleep(0.05)
zip(l, l[1:])[::2]
self.conditions[:] = [helper(c, type, params) for c in self.conditions]
print(mystring[:100])
psutil.pid_exists(os.getpid())
x = list(d.keys())
cmat2 = scipy.sparse.csc_matrix(mat2)
print(proc.communicate())
print(repr(test), repr(is_valid_name(test)))
os.chmod(path, stat.S_IWRITE)
[parser.parse(x) for x in _split(s)]
ax.plot(xs, ys, *args, **kwargs)
y[:]
fig = plt.figure()
array([27, 27, 27, 26, 26, 26, 26, 26, 26, 26])
pandas.set_printoptions(max_colwidth=100)
palindromes = [(x + x[::-1]) for x in permutations(digits, k // 2)]
doing_fd.seek(0)
{{value}}
abs(x) % abs(y) * (1 if x > 0 else -1)
config.readfp(buf)
plt.tight_layout()
dict.__init__(self, *args, **kwargs)
app.exec_()
print(interestingelts[0])
[dict(pairs) for pairs in unique]
data_entry.save()
print(url_string)
self.panel.Bind(wx.EVT_PAINT, self.OnPaint)
writer.writerows(changes)
frame.Show()
d[l[0]]
serve_on_port(2222)
plt.close()
cov = np.array([[200, 100], [100, 200]])
time.tzset()
plt.contourf(Yi, Xi, Z, alpha=0.7, cmap=plt.cm.jet)
lambda x: int(float(x))
INSTDIR = os.path.dirname(os.path.realpath(__file__))
ax = plt.subplot(111)
2 * np.arcsin(np.minimum(1, np.sqrt(a))) * radius
do_something()
mlb.focus_set()
plt.subplot(211)
form.is_valid()
auth_login(request, user)
DO_SOMETHING()
log()
inverse_dict[v].append(k)
br.set_cookiejar(cj)
ax.axis([0, 10, 0, 255])
t.colname == getattr(t, Table.colname.property.key)
ax.axis([0, max_dim, 0, max_dim])
map(joiner, sixgrams)
plt.stem(x, y)
settings.py
print(newList)
self.frames.append(ImageTk.PhotoImage(frame))
print((a, b, c))
plt.show()
frame.axes.get_xaxis().set_ticks([])
app = web.application(urls, globals())
G.add_edge(1, 2)
time.sleep(random.random() * 5)
random.seed(0)
arrow.utcnow().isoformat()
os.read(sys.stdin.fileno(), 4096)
len(line) == 9 and sum(line) == sum(set(line))
m = re.search(pattern, text)
useful = l[match[0] + 4:match[0] + 8]
local_p.kill()
saveglobals(savepath)
print(response.info())
print(type(my_date))
self.instream.close()
a = [[i] for i in range(5)]
os.chdir(directorypath)
df.index[:-1].union([df.index[-1] + pd.offsets.MonthEnd(0)])
ax.autoscale()
foo[index] = foo[index][0], new_value
setattr(c, a, getattr(cls, a))
print(value[0])
print(row)
do_something_with_i(i)
mock_output.reset_mock
br = mechanize.Browser()
str(self.num)
hashed_password = hashlib.sha512(password + salt).hexdigest()
_style.fill.start_color.index
[(b - a) for a, b in pairwise(L)]
obj.some_method()
ax.invert_yaxis()
img = cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)
s = match.group(0)
System.out.println(str.toString())
self.x == other.x
df = df.append(data)
self.mock_requests.get.assert_called_with(url)
p.i, p.fitness
d[number].append(line)
screen.show()
new_dict
str(value)
instance.delete()
aDict = dict(zip(string.ascii_lowercase, list(range(1, 27))))
HttpResponse(folders)
[random.randint(low, high) for _ in range(count)]
print(my_func.__doc__)
QGraphicsTextItem.mouseReleaseEvent(self, event)
ind = [i[0] for i in sorted(enumerate(b), key=lambda x: x[1])]
suspect[k] = v
db.delete(d)
req.send(data)
deactivate
print(r.url)
filelike.seek(0)
my_book = Book.objects.get(pk=1)
new_im_vec = ravel(rollaxis(im, 2))
self._handle(*args, **options)
print(get_max_count(l=l, num=7))
list.activites.all()
a[::2] = [-1, -2]
[list(filter(str.isalpha, word)) for word in s.lower().split() if word[0].isalpha()]
[double(x) for x in li]
sys.exit(app.exec_())
print(f(2))
contourf(x, y, H, levels, cmap=cmap_lin)
contourf(x, y, H, levels, cmap=cmap_nonlin)
body = urllib.parse.urlencode(post_data)
Response(post_serializer.data)
lock.acquire()
t[0].__sizeof__()
self.connectToMUC()
Br = [x, x, x, x, x, 0]
urlparse(url).query
im.show()
t5 = threading.Thread(target=task5)
json_string = json.dumps(d)
T2()
parser = argparse.ArgumentParser()
p.wait()
deleteself.d[k]
plt.imshow(normalized)
c = a[::2]
chain.from_iterable(combinations(s, r) for r in range(len(s) + 1))
pool = ThreadPool(processes=1)
compare(mylist[i], mylist[j])
sp = subprocess.Popen(command, shell=True, stdin=sys.stdin)
fig = plt.figure()
[0.0, 0.4, 0.6, 0.0, 0.0]
sys.stdout.flush()
FALSE
main()
np.inner(a, b)
print(permutenew(l))
print(cv2.__version__)
fin.close()
u = np.unique(arr)
time.localtime().tm_isdst > 0
list(it.product(x, mit.flatten(y)))
set(x for x in hello if hello.count(x) == m)
plt.gca().cla()
session.commit()
ssh = paramiko.SSHClient()
func2()
p.start()
toss2 = toss.copy()
datetime.utcfromtimestamp(dt64.astype(int))
sleep(1)
db.create_all()
ax = fig.add_subplot(221)
df.ix[:, (df.columns.isin(col_list))]
self._lines.append(d)
a = np.arange(11)
plt.figure()
binimg = np.zeros((rgbimg.shape[0], rgbimg.shape[1]))
{{item.date | localtime}}
o5.method
plt.show()
time.sleep(0.5)
path, tail = os.path.split(path)
ax = fig.add_subplot(111)
raise NotImplementedError
list.__init__(self)
f1()
re.findall(p, test_str)
list(set(result))
soup = BeautifulSoup(html)
Counter((type(x), x) for x in arr)
wkt.dumps(point)
sample = [[1, [1, 0]], [1, 1]]
math.floor(numpy.nextafter(x, -numpy.inf))
print(error.__class__.__name__, error)
plt.scatter(x[i], y[i], marker=mapping[m[i]])
b = {name: a[name] for name in a.dtype.names}
signal.signal(signal.SIGINT, signal_handler)
np.random.shuffle(lst)
ret = urllib.request.urlopen(req).read()
msg.attach(part)
print(pd.get_dummies(values[mask]))
surface.write_to_png(ofile)
cbar = plt.colorbar(CF, ticks=lvls, format=l_f)
match.group(0)
1 << np.arange(m)
sum(alist)
checkBox = QtGui.QCheckBox()
cax = fig.add_subplot(122)
df1.iloc[1:5, 2:4]
new_df.index.set_levels(group_names, level=0, inplace=True)
photoImg = ImageTk.PhotoImage(img)
n = [x for x in n if x in string.whitespace or x not in string.printable]
[]
send_from_directory(cache_timeout=0)
key, value = dict.popitem()
preprocessed, _ = p.communicate()
log_file.close()
dfm_summary = pd.concat(dfs, axis=1)
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj))
B = np.split(A, np.argwhere(A[:, (0)] == 0.0).flatten()[1:])
slice_coords_by_x(arr, xmin=1, xmax=5)
[counts[w] for w in word_list]
unittest.main()
popen.wait()
f(*args)
AC_SUBST([PYTHON_LIBS])
[6.49, 48.9995]
sorted(matches, key=len, reverse=True)[0]
print(line)
gtk.main()
table[table.column_name == some_value]
graph = nx.Graph()
Test(somevalue)
os.chdir(curdir)
[e for e in l if e % 2 == 0]
pool = multiprocessing.Pool(processes)
valves = CheckValve.objects.all()
myusers = db.session.query(User).all()
WINEVENT_OUTOFCONTEXT = 0
href_tags = soup.find_all(href=True)
img.show()
img.execute_transforms(output_encoding=images.JPEG, quality=1)
Clojure
Response()
s.bind((ADDR, PORT))
print(G.neighbors(1))
print(sess.run(output))
[x for x, y in list(collections.Counter(l).items()) if y > 1]
func(**literal_eval(params))
possibles = globals().copy()
d = dirname(dirname(abspath(__file__)))
any([(i in fruit_dict1) for i in fruits])
output = [(x, y) for x, y, label in L]
psycopg2.connect(database=database_name)
os.chdir(WORKDIR)
sys.getsizeof(x)
df
print(r.read())
print(deco2.__name__)
model = Sequential()
lst = lst[0].split()
s = pygame.Surface((1000, 750))
print(time.mktime(t1))
fill_between(x, 0, l[0], color=colors[0], alpha=alpha)
parser = argparse.ArgumentParser()
[(item * 2) for item in x]
fig = plt.figure()
self.queue.pop()
self.log_window.Show()
im.show()
f.seek(0)
list(od.values())
pprint.pprint(recur_dictify(df))
help(x)
map(sum, zip(a, b, c, d, e))
print(ord(sys.stdin.read(1)))
result
sorted(set().union(*list(results[env].values())), key=str.lower)
f.seek(0)
self.queue.put(item, block=True)
df = df.reindex(pd.DatetimeIndex(df.index), fill_value=NaN)
print(e.message)
user = User.objects.get(pk=1)
data = json.loads(response.read())
print(mechanize.urlopen(form.click()).read())
self.assertEqual(obj.val, 2)
im.seek(im.tell() + 1)
abc = lambda *args, **kwargs: myFunction(*args, **kwargs)
plt.show()
parallelismPool.close()
ax.cla()
big_np_array = np.array(big_array)
ax1 = fig1.add_subplot(111)
writer.writerow(record)
-javascript
pl.ylim(0.0, 1.0)
cp / usr / bin / pdb / path / to / virtual / env / bin
print(sys.path)
pool = multiprocessing.Pool()
src_dt = src_tz.localize(dt)
b.extend([i, i])
mask = np.in1d(A, B)
cv2.circle(mask, (i[0], i[1]), i[2], (255, 255, 255), -1)
img.ConvertToBitmap()
line = f.stdout.readline()
print(bisect(b, a))
fb.append(str(n))
os.write(1, a.tostring())
model = Sequential()
plot_confusion_matrix(df_conf_norm)
new_list.index(to_find.lower())
pcap_lookupnet(dev, ctypes.byref(net), ctypes.byref(mask), errbuf)
new2 = np.array([block.T for block in blocks]).T
button.pack()
type(a)
r = sqrt(2 * random.uniform(0, 1) / A + r_min * r_min)
type(img_str)
signal.signal(signal.SIGALRM, old_handler)
worksheet.write(row, col, text)
s = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_IP)
print(settings.SIMPLE_CONF)
print(x)
gen_move(list(range(10))[::-1])
assert np.allclose(expected, result)
d = {}
self.sizer.Add(self.inner_sizer, 1, wx.ALL | wx.EXPAND, 20)
browser = webdriver.Firefox()
im.show()
time.sleep(10)
label.set_fontproperties(ticks_font)
g.kill()
mapping = dict(zip(a, b))
data = ctypes.POINTER(ctypes.c_char)()
save_file.write(str(tweet))
nil
ii = df[pd.notnull(df.C)].index
self.timeout = timeout
np.setdiff1d(a1_rows, a2_rows).view(a1.dtype).reshape(-1, a1.shape[1])
pos = f.tell()
time.sleep(1)
res = next(idx for idx, (x, y) in coupled_idx if x != y)
parentdir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
y_pred = [0, 0, 2, 1, 0, 2, 1, 0, 2, 0, 2, 2]
sum2 = sum((row1 * row2.T).data)
fork()
file2.close()
plt.show()
test()
plt.plot(x, y)
ax.plot(dates, data)
f(u(n - 1))
new_stdout.seek(0)
logging.getLoggerClass().root.handlers[0].baseFilename
cols = df.columns.values.tolist()
vals = [g(i) for i in range(100)]
a.index(a.lstrip()[0])
string[i:i + len(keyword) + 5 + 1]
ax.pbaspect = [2.0, 0.6, 0.25]
c.setopt(c.HEADERFUNCTION, retrieved_headers.store)
app = flask.Flask(__name__)
ssh = paramiko.SSHClient()
both.reset_index(inplace=True)
output.close()
d.setdefault(a, {}).setdefault(b, {}).setdefault(c, []).append(value)
self.response.set_status(404)
print(var_name)
vt[:, (0)]
hey()
group.save()
ds.addSample((1, 1), (0,))
np.linalg.solve(a, b)
result = collections.defaultdict(list)
total = sum(c.values())
threading.Thread(target=listen_to_audio).start()
console = logging.StreamHandler()
plt.plot(list(range(10)), rasterized=True)
numbers = [aux[x] for x in row]
plt.yticks(positions, labels)
ax.xaxis.set_minor_locator(hours)
substrings.sort(key=len)
python - i
qPlg.append(QPointF(*p))
today = datetime.date.today()
np.asarray(0 for i in range(10))
plt.subplots_adjust(hspace=0.5, wspace=0.001)
a[-1].append(5)
print(df)
out.write(largedata)
round(VALUE * 2.0, 1) / 2.0
os.close(wpipe)
main()
t.start()
deleteself.__dict__[key]
conn.close()
s = a.sum(axis=(0, 1, 2))
msg.attach(part)
[[i for i in sublist if i < n][:5] for sublist in ls]
fig = plt.figure()
numpy.sin(x)
df = df.astype(object)
window.show_all()
app = wx.PySimpleApp()
scipy.sparse.linalg.spsolve(coeff_mat, np.ones(2 * (n - 1)) * n)
dictonary[k].append(file)
f = lambda x: 2 * x
s.add(x)
substrings.sort(key=lambda s: len(s))
first_record = next(all_records)
sh.write(n, 1, v)
d[a][b] = c
contents.sort(key=itemgetter(2))
date = datetime.datetime.fromtimestamp(seconds + sub_seconds)
func(cpy)
handler.setFormatter(formatter)
f.write(imgdata)
fig, ax = plt.subplots()
len(df[~pd.to_datetime(df.index).isin(dropThis)])
pylab.plot(t)
peasant.badly_hurt()
ax.plot(list1)
serializer = UserSerializer(request.user)
deleteordered_dict[k]
BASE_DIR = os.path.dirname(os.path.dirname(__file__))
[c.__name__ for c in cls.__subclasses__()]
raise Exception()
print(a[:10])
zip(a, b)
d[i] = np.sum(a[(i), b[i]:c[i]])
sys.exit(0)
glVertex2i(10, 110)
result.append(list[index])
max(result, key=len)
list(map(ord, list(L)))
sorted(s) == sorted(t)
mlab.pipeline.iso_surface(src, contours=[s.max() - 0.1 * s.ptp()])
plot(x, y)
tk.Frame.__init__(self, parent, *args, **kwargs)
gevent.sleep(r)
wrapper1
x += a * np.cos(2 * np.pi * f0 * t + 0.11)
img = img.resize((160, 240), Image.ANTIALIAS)
conn.accept()
pprint({k: getattr(creator.__code__, k) for k in dir(creator.__code__)})
counter.save()
(d[i] for i in k)
download_ftp_tree(ftp, remote_dir, local_dir)
shutil.rmtree(target)
df = df.append(r)
os.unlink(f_path)
list(map(pow, list(range(10)), repeat(2)))
mylist[n // 10].append(n)
df.convert_objects(convert_numeric=True)
df = pd.Panel.from_dict(d).to_frame()
cv.Circle(color_image, center_point, 20, cv.CV_RGB(255, 255, 255), 1)
print(countOccurencesAtTheEndOfTheList([1, 2, 1, 1, 1, 1, 1, 1]))
plt.clf()
auth.login(request, user)
lda = gensim.models.ldamodel.LdaModel(corpus=mm, num_topics=100)
{{form.as_p}}
project.some_func()
[x for t in zip(a, reversed(a)) for x in t][:len(a)]
event.Skip()
OrderedDict.__init__(self, *a, **kw)
df.iloc[7:9, (5)] = np.nan
chardet_detector = UniversalDetector()
lines = ax.plot(np.arange(1000))
session.commit()
chardet_detector.reset()
set.intersection(*sets)
np.where(x ** 2 + y ** 2 > 1e-10, x * y / (x ** 2 + y ** 2), 0.5)
sys.path.append(egg_path)
hzfile.printdir()
print(words == sorted(words, key=str.lower))
dict(CharCounter(text))
(Convert(i, base) for i in range(start, end, step))
assert type(session.query(Foo).first()) is ReadonlyFoo
Doc.save()
help(cherrypy.engine.exit)
picture.getpixel((x, y))
stoppool.start()
mpmath.besseli(0, 1714)
self.traceback = traceback.extract_stack()[-2]
os.remove(str(filename))
insert_sort(ascend_list, i, lambda x, y: x[1:] >= y[1:])
rpy2.robjects.numpy2ri.activate()
df = pd.concat([s1, s2], axis=1).ffill().dropna()
self.value += 1
out[:, :, (mask)] = B[:, :, :, ::-1][:, :, (mask[:, ::-1])]
dict((k, v[v < 0].to_dict()) for k, v in compat.iteritems(data))
Frame.__init__(self, master)
self._window.show()
f(1, 2)
parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
panel.SetSizer(sizer)
time.sleep(1)
print(etree.tostring(child))
run(reloader=True)
f = urllib.request.urlopen(req)
cbar.set_clim(-2.0, 2.0)
current.append(item)
print(f.split(d)[0] + d[0])
print(stealth_check[key])
s.close()
form.save()
df
horoscope.check_all()
figure()
show()
cursor = db.execute(sql % params)
q.write(str)
session.rollback()
ax.imshow(field1, cmap=plt.cm.YlGn, vmin=_min, vmax=_max)
fields = list(addresses_table.columns.keys())
words = string1.split()
print(submission.url)
nsmallest(4, list(range(len(values))), key=values.__getitem__)
0.08400000000000002, 0.9999999882280098
shapesMatch([(0, 0), (1, 1), (0, 2), (-1, 1)], rectangle)
unittest.main()
self.session.run(self.init_vars)
ged.close()
r = requests.get(my_url, cookies=cookies)
ax1 = fig.add_subplot(111)
out = np.mod(c, 2)
cursor = db.cursor()
getattr(self.base, name)
newList = np.clip(oldList, 0, 255)
sys.stdout.write(c)
exit.__str__()
gy, gx = np.gradient(Z, 0.05, 0.05)
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
DD = datetime.timedelta(days=90)
self.edges.setdefault(n2, []).append((n1, w))
a[numpy.where(a > 2)]
s.unique()
a = np.array([0, 0.1, 0.5, 1])
d = defaultdict(list)
r = Ribbon(root)
myOjbect.doStuf().doMoreStuf().goRed().goBlue().die()
plt.grid()
np.diag(d - 4) + 4
response
mapping = map(chr, list(range(256)))
[[x0, y0] for x0 in x for y0 in y]
forms = [f for f in br.forms()]
isinstance([], (tuple, list, set))
evensList = [x for x in myList if x % 2 == 0]
fig.canvas.mpl_disconnect(cid)
plt.figure(figsize=(20, 8))
ax.add_artist(bbox_image)
time.sleep(1)
foo.bar()
CTS, DSR, XXX, YYY, ZZZ = list(range(5))
text(x, y, s, fontsize=12)
s.close()
queries &= Q(**{key: options[key]})
G2.add_nodes_from(nodes)
self.paths = []
distances = numpy.linalg.norm(np_cell[1] - srcPos)
[]
compiler = msvc
metadata.create_all()
string.ascii_lowercase
list(filter(os.path.isfile, os.listdir(os.curdir)))
dis.dis(myfunc)
ax = plt.gca()
f(*args, **kwargs)
print(sum(len(mystr) for mystr in strings))
list(d.keys())
ax.figure.canvas.draw()
fh.seek(0)
ll = list(itertools.chain.from_iterable((e, e) for e in l))
screen = pygame.display.set_mode((500, 500), HWSURFACE | DOUBLEBUF | RESIZABLE)
queryset = Town.objects.all()
y = myodeint(lambda y, t: func(y, t, alpha), [1, 0, 0], t)
title = models.CharField(max_length=100)
ax[1].add_collection(collection)
randint(100, 999)
dictpsl[key].append(pslrc)
li = list(filter(condition, li))
my_array = list(filter(lambda x: x != value_to_remove, my_array))
matrix[0][2]
initial_array += increments[::-1].cumsum()[::-1]
s2.reset_index(inplace=True, drop=True)
t = np.linspace(0, 1, 6)
entry_list = [entry.title.text for entry in feed.entry]
print([1, 0] in chain(*sample))
module.workflow_set.filter(trigger_roles__id__exact=self.role.id, allowed=True)
df
sorted(data) == sorted(data2)
self.lbl.after(1000, self.updateGUI)
sorted(list(range(len(vals))), key=vals.__getitem__)
self.values.append(value)
session.put()
fig = plt.figure(1)
eval(strab)
simplejson.load(f)
item, = singlet_list
self.rfile.close()
[[11, 12], [21, 21]]
things.filter(category=category)
plt.imshow(x, cmap=mpl.cm.bone)
s.remove(1)
win.idlok(True)
win.leaveok(True)
app.run()
output, err = process.communicate()
a = 1
reactor.connectTCP(host, port, factory)
pdf.getNumPages()
plt.draw()
termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)
item.save()
cur = conn.cursor()
print(np.random.dirichlet(np.ones(10) * 1000.0, size=1))
ax = fig.add_subplot(111)
symmetric_dec(body, session_key)
print(df.head())
screen.refresh()
random.shuffle(tmp)
child1()
child2()
sess.run(outputs, feed_dict=feed)
Y = Y + Z[::-1] - Z[-1]
self.crawler.stop()
np.roll(a, 2)
sorted(list(totals))
g = (i for i in a + b)
new_df
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
my_array[i] = el
self.glade.add_from_file(self.gladefile)
list(10 ** pos * val for pos, val in enumerate(reversed(test)))
app = Flask(__name__)
new_file.write(line.replace(pattern, subst))
app.yaml
part.get_payload()
result.append(row)
Wire.write(number)
ax.figure.canvas.draw()
tree.delete(i)
pl.xlim(0.0, 100.0)
print(form.is_valid())
feeder_lock_object.release()
ao[:-1, 1:] += ai[1:, :-1]
self.dictset = {}
(A != 0).cumsum(1).argmax(1)
list(results)
print(s.query(A).filter(A.boolean).all())
self._callfunc(self, *args, **kwargs)
print(ET.tostring(dict_to_etree(d)))
slice1.append(a, b)
ws = wb.active
outdict[k.lower()] = v.lower()
g.add_edge(2, 4)
np.in1d(test, states)
list(res)
wordCount = Counter(words)
ax = plt.gca()
lgd = ax.legend(loc=9, bbox_to_anchor=(0.5, -0.02))
tty.tcsetattr(stdin_fileno, tty.TCSANOW, old_ttyattr)
test.main()
C.reshape([4, 2, 2])
qjup
self.popitem(last=False)
setattr(cls, name, decorator(fn))
print(r.json())
signal.alarm(0)
d = {k: [] for k in range(10)}
result.append(L.pop())
a.remove(e)
plt.show(f)
ax.add_artist(p)
proc.join()
ts = (dt_with_tz - datetime(1970, 1, 1, tzinfo=pytz.utc)).total_seconds()
self.columnconfigure(0, weight=1)
ShowAppsView.as_view()(self.request)
random.shuffle(keysShuffled)
chr(97)
list1.append(word)
print(distutils.sysconfig.get_config_vars())
os.getcwd()
unconverged = np.ones(shape=arr.shape, dtype=bool)
self.data[k]
log.setLevel(logging.DEBUG)
A = A[0]
c = {v: k for k, v in list(a.items())}
console.setLevel(logging.INFO)
all(k in dic2 for k in dic1) and all(k in dic1 for k in dic2)
type(f)
df = df.mul(df.columns.to_series(), axis=1)
self.finished.emit()
plt.figure(figsize=(width, height))
print(fib(i))
time.sleep(poll_seconds)
df = pd.DataFrame(array, columns=columns)
nums.append((item, n - item))
line_list = [line for line in filtered_soup]
i += 1
df[subset[subset.isin(myList)].stack().duplicated().unstack().any(1)]
platform.release()
test.main()
print(res.queryString())
[d[:4] for d in MyArray]
json.loads(page_detail_string)
{a[d]: todict([x for x in X if x[d] == a[d]], d + 1) for a in lst}
print(self.recv(8192))
sorted(s, key=lambda c: (-s.count(c), s.index(c)))[0]
request.FILES.update(files)
surf2 = pygame.Surface((200, 200))
xticks[-1].label1.set_visible(False)
list(pkgutil.iter_modules())
groups = itertools.groupby(a, key=lambda x: x[1])
S[int(line[0]), int(line[1])] = True
df.B.plot(ax=plt.gca())
fig = plt.figure()
sys.exit(1)
imgfile.close()
fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(12, 5))
db.session.add(g)
now = datetime.now()
ssh.connect(hostname, username=username, password=password)
time.sleep(0.2)
m = scipy.sparse.coo_matrix((data, (r, c)), shape=(100000, 40000))
fig, ax = plt.subplots()
sys.path.insert(0, root_path)
server.ping()
test_maybe_recursive()
fl.close()
pilImage = Image.open(StringIO(rawImage))
sorted_data = sorted(list(data.items()), key=operator.itemgetter(1))
os.getcwd()
fig = plt.figure()
[c for c in foo if c not in temp and (temp.add(c) or True)]
sys.stdout.write(line)
out.putpixel((x, y), color)
INSTALLED_APPS = ()
numpy.array(imc)
print(resp.status_code, resp.text, resp.headers)
response = requests.get(url)
sys.path.insert(0, virtual_site)
polycube = numpy.transpose(polycube, (1, 2, 0))
instance.save()
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj))
sys.exit(9009)
pylab.scatter([p[0] for p in pp], [p[1] for p in pp])
time.sleep(1)
np.histogram(sampling, bins=np.arange(len(A) + 1))[0]
ao[:-1, :] += ai[1:, :]
server_sock.listen(1)
float(MyClass())
p.kill()
print(json.dumps(doc.identity.addr.reprJSON(), cls=ComplexEncoder))
flat_index = coo[:, (0)] * np.max(coo[:, (1)]) + coo[:, (1)]
triplets = [set(x) for x in triplets]
npi.group_by(a[:, :2]).split(a)
temp.sort()
print(np.ma.masked_invalid(a))
time.sleep(1)
Z = np.array(mean_data)[:, (2)]
e1 = np.array([1, 0, 0])
assert get_current_session()
Z = f(np.dstack(np.meshgrid(x, y)))
print(e.gmm())
x = np.random.rand(10)
flatten(Cards)
self.edges.setdefault(n1, []).append((n2, w))
content = browser.page_source
gca().set_autoscale_on(False)
[i for i, ltr in enumerate(s) if ltr == ch]
ax.add_patch(patches.Rectangle(pos, w, h, color=c))
b.grab_release()
opencvImage = cv2.cvtColor(numpy.array(pil_image), cv2.COLOR_RGB2BGR)
dict(MyDict.lists())
conn.close()
sys.getsizeof(b)
writer = csv.writer(output)
(abs(arr_f - a) < t).any()
sum_over_n[(-1) ** n * x ** (2 * n) / math.factorial(2 * n)]
dataFrame.pow(timeSeries, axis=0)
args = parser.parse_args()
writer = csv.writer(outfile)
show(0)
f = urllib.request.urlopen(req)
turtle.Screen().exitonclick()
Resources.objects.filter(user=self.request.user.username)
self.finished.emit()
sys.exit()
data = np.array(imc)
deletea[:]
reactor.run()
dc.SetFont(self.GetFont())
signal.signal(signal.SIGINT, self.exit_gracefully)
com.convert_robj(rdf)
InitializeComponent()
max(groups, key=_auxfun)[0]
df = pd.DataFrame(data_as_2d_ndarray)
block_reduce(arr * area_cell, block_size=(2, 2), func=np.ma.mean)
t = np.random.randint(0, 50, 500)
rel_path.split(os.path.sep)
print(match)
a = Finalizable()
[x for x in s if not x in rm]
a[subset_a] += 1
print(delta.total_seconds())
ei = np.where(em.flat)[0]
wx.Panel.__init__(self, parent)
plt.close()
raise NotImplementedError
random.shuffle(keys)
env.forward_agent = True
os.path.splitext(f)
plt.close()
checkIP.__file__
df.sort_index()
hash((self.i, self.k, self.j))
self.cardsdiscarded += 1
--nologcapture
leg.set_zorder(1)
img = Image.open(file)
outfile.write(text)
df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in list(sample.items())]))
setattr(s, name, value)
plt.xticks(list(xMap.values()), list(xMap.keys()))
df = df1.append(df2)
[[my_sum]]
split_list = [listo[i:i + n] for i in range(0, len(listo), n)]
t.start()
example.split()
layout = QtGui.QHBoxLayout()
assert isinstance(d, dict) and len(d) == 1
stream_index = numpy.array(stream_index).repeat(repeat_count)
app.run(True, False)
print(df.loc[name])
data
foo()
print(matchobj.group(1))
button.Bind(wx.EVT_BUTTON, on_button)
l.setLevel(logging.INFO)
numpy.linalg.matrix_rank(A)
np.random.seed()
mythread = threading.Thread(target=get_user_input, args=(user_input,))
line = f.readline()
id = Column(Integer, primary_key=True)
my_subprocess = subprocess.Popen(args)
B = np.array([2, 4, 6, 8])
list(range(0, len(list1), 2))
areas.apply(multiply_by_demand)
curses.echo()
con.close()
tk.Frame.__init__(self, master)
decorator
df.Stake[i] = 2 * df.Stake[i - 1]
X.sum(axis=1).sum(axis=0)
repr(test.make_fptr())
self.assertEqual(1, 1)
ax = fig.add_subplot(111)
word[0].isupper()
func()
layout2.addWidget(frame2)
final_ensemble.estimators_ = []
plt.scatter(a, b)
args = parser.parse_args()
plt.show()
map(list, combinations(A, 2))
socket.inet_pton(socket.AF_INET6, address)
x_normed = (x - x.min(0)) / x.ptp(0)
root = tkinter.Tk()
photo.close()
id = Column(Integer, primary_key=True)
min(min(l_one), min(l_two))
self.fail(msg)
lines.append(inf.readline())
main()
dict()
np.ones(4, dtype=int)
handler.setFormatter(formatter)
c.most_common()
sol[0][0] + sol[0][1] * I
print(np.all(insample == insample_mp))
tagger = nltk.tag.UnigramTagger(model=model, backoff=default_tagger)
print(sum(takewhile(lambda x: x < p90, a)))
ax.yaxis.set_major_formatter(matplotlib.ticker.FormatStrFormatter(format))
matches.extend(os.path.join(dirpath, x) for x in dirnames + filenames)
x = sum(similarity(i, j) for i in a for j in b)
df = df.apply(lambda x: np.random.shuffle(x) or x, axis=1)
l.extend(t2)
A = np.array([[0, 1, 0, 0, 1], [0, 0, 1, 1, 1], [1, 1, 0, 1, 0]])
self.lock.acquire()
len(list_of_ids)
pool.join()
list(flatten(lis))
s = s.lower()
a = array(your_list)
[]
queryset = MyModel.objects.all()
ax.add_artist(a)
list(zip(a, b, grouper(c, 2), d))
startfile(os.getcwd())
print(url)
form = ContactForm()
fig = plt.figure()
text = file.read()
math.sqrt((self.x - x) ** 2 + (self.y - y) ** 2 + (self.z - z) ** 2)
np.flatnonzero(goal)
rollaxis(im, 2)
np.fill_diagonal(coocc.values, 0)
print((subject.text, subject.head.text, numbers[0].text))
self.raise_()
Bar.objects.filter(pk=foo.id).update(a_id=bar.id)
set(second_list) - set(x[0] for x in first_list)
map(ord, letters)
time.time() - startTime
list(set(x) - set(y))
execlist[index][4] = mydelay
mlen = ctypes.c_ulonglong(len(message))
10 * np.cos(np.hypot(x, y) / np.sqrt(2) * 2 * np.pi * cycle)
[e] * 4
np.rot90(m, 1)
model.add(Dropout(0.2, input_shape=(60,)))
a = [list(item) for item in a]
array[:] = t
self.agg_log.setLevel(logging.DEBUG)
self.setPixmap(image)
xl.Visible = True
ax.set_xlim(xlim)
G = nx.MultiGraph()
p.some_method()
p = subprocess.Popen(my_cmd, shell=True)
self._stop.set()
pat.findall(s)
sizer.Add(self.panel, 1, wx.EXPAND)
len(x) * (len(x) - 1) * 2
time.sleep(0.2)
new_list = []
time.sleep(2)
mock_sgc_obj = mock.Mock()
time.sleep(interval)
my_lib.py
y = [1, 2, 0, 1, 1, 2]
print(paths[min_index], path_distances[min_index])
is_linear(eq1, [a, c])
self.__setattr__(attr, value)
psutil.cpu_count()
parser.print_help()
type(Foo.__init__)
ax.xaxis_date()
fig.show()
pool.terminate()
intvals[bisect.bisect(intvals, 42000)]
parser.parse_args([])
array([[0.0, 1.206, 1.58]])
print(xy_to_index(x, y))
length = len(list(g))
browser = webdriver.Firefox()
aware_utc_dt = utc_dt.replace(tzinfo=pytz.utc)
path_names = [os.path.basename(path) for path in paths]
np.array([row[:num_cols] for row in arr[:num_rows]])
ssh_client.connect(host)
user.save()
new_class._ordered_items.sort(key=lambda item: item[1].creation_counter)
br.select_form(nr=0)
plt.figure(1)
f1.close()
any(t in k for k in df[self.target])
root = tk.Tk()
map(str.lower, l)
a[0] + a[1] + a[2]
self.show()
ContentType.objects.get_for_model(obj)
np.shape(x)
settings.py
bubble_sort_2nd_value(tuples_list)
print(hash(frozenset(lines)))
YS = np.asarray(YS)
ZS = np.asarray(ZS)
min(mywords, key=len)
new_list = []
json.load(f)
numpy.set_printoptions(precision=16)
app = QtGui.QApplication(sys.argv)
print(0.0 <= x <= 0.5)
array([[106, 140], [178, 220]])
elem.clear()
tag.attrs.append((attr, val))
a2.append(decimal.Decimal(s))
s.close()
print((a, b, c, d, e))
outF.close()
suite = unittest.TestSuite()
conn = psycopg2.connect(conn_string)
xml = ET.fromstring(xmlData)
r = [(a, b) for a, b in zip(l, l[1:] + l[:1])]
any(x is False for x in [a, b, c, d])
newSingle.getHeader().setField(fix.SendingTime(1))
map(lambda a: a[0], takewhile(len, iterate(lambda y: f(y[0]), [x])))
self.redraw(event.x, event.y)
all(isinstance(e, int) and e > 0 for e in [1, 0, 1])
ax2.xaxis.set_major_locator(MultipleLocator(2))
dicts = [{k: v.lower() for k, v in list(d.items())} for d in messages]
{k: sum(d[k] for d in dict1) for k in dict1[0]}
print(args.benchmark)
ax2.set_xticks(new_tick_locations)
bla = globals()[name]
a.append(k)
file_name = file_name + 1
sys.path.append(plugin_path)
deletea[100:99999]
scipy.stats.norm(0, 1).cdf(0)
plt.show()
aView = np.ascontiguousarray(arr).flatten().view(mydtype)
regex = re.compile(pat)
print(df.groupby(df.index).applyParallel(tmpFunc))
print([([k] + v) for k, v in list(dic.items())])
args = parser.parse_args()
print(map(f, [100, 50, 1000, 150]))
ax.set_xticklabels(())
new_d.append(x)
zratings = bcolz.ctable.fromdataframe(ratings)
app = Flask(__name__)
foo_list.append(lambda : bar.func1(100))
a[[0, 1], 1, 2]
x.__exit__()
print(zip(rlist1, rlist2))
{{adminform.form.non_field_errors}}
f(*args, **kargs)
print(str(q.statement.compile(dialect=postgresql.dialect())))
keyname = int(keyname)
print(np.random.rand())
f.close()
w.writeheader()
result.append(a)
dates_dict = collections.defaultdict(list)
A().my_dir()
os.path.isdir(d)
l.set_option(ldap.OPT_REFERRALS, 0)
MyKlass().func1()
instance = form.save(commit=False)
db.session.add(user)
today = date.today()
self.context.leave()
print(sum(li[:i + 1]))
x[-1:0:-1]
print(s.recvfrom(65565))
code.interact()
req = urllib.request.Request(url, urllib.parse.urlencode(params), http_header)
d = OrderedDict(sorted(list(data.items()), key=itemgetter(1)))
bytes = (ord(b) for b in f.read())
raise KeyError(key)
x = df.ix[:, 5:].sort_values(by=0, ascending=False, axis=1)
frame = pd.concat(list_)
print(list(grp))
ax1.xaxis.set_major_formatter(xticks)
print(loc_dt.strftime(fmt))
array = numpy.array(((2, 2), (2, -2)))
1 / sqrt(2 * pi) * exp(-x ** 2 / 2)
pool.close()
plt.plot(x, y)
print(next(second_it))
inner_func
df.isin([1, 2])
zip(*([iter(iterable)] * n))
obj.foo.__func__
[(scores, sum(scores)) for scores in combos]
print(doc.getvalue())
print(bookmark.text)
Aggregator._output()
content_type = models.ForeignKey(ContentType)
d[k].append(v)
user.save()
ax = fig.add_subplot(1, 1, 1)
print(dur.total_seconds())
round(number / roundto) * roundto
n > 1 and all(n % i for i in islice(count(2), int(sqrt(n) - 1)))
arrays = [item[1:] for item in arrays if len(item) > 1]
local_tz.normalize(local_dt)
Py_DECREF(n_ptr)
glutInitDisplayMode(GLUT_RGBA | GLUT_DOUBLE)
print(hello())
fig = plt.figure()
np.nextafter(0, 1)
f_set = f[f.year.between(2002, 2009)]
print([mylist[i:i + 4] for i in range(0, len(mylist), 4)])
print(CAT.number_of_legs)
r, g, b = colorsys.hsv_to_rgb(hue, 1, 1)
markdown_below()
cls.__new__(cls)
log.setLevel(logging.INFO)
print((day_of_year, julian_day))
dict_x[key].append(value)
self.saved = sys.stdin, sys.stderr, sys.stdout
[(i * j * k) for i, j, k in product(a, b, c)]
df
conn.close()
os.abort()
logging.disable(logging.CRITICAL)
utc_offset = datetime.fromtimestamp(ts) - datetime.utcfromtimestamp(ts)
b2.insert(END, item)
datetime.fromtimestamp(unix_timestamp)
s.bind((host, port))
[development]
(item for pair in zip_longest(x, y, default) for item in pair)
root = ET.fromstring(xml_string)
cv.SetData(foo_cv, foo_np_view.data, foo_np_view.strides[0])
Person.__init__(self, name, phone)
writer = csv.writer(out_file)
[distance(*combo) for combo in combinations(list_of_coords, 2)]
duration = models.DurationField()
b = np.zeros_like(a)
layout = QtGui.QVBoxLayout(self)
IOLoop.instance().run_sync(test_it)
Foo()[:42]
threading.Thread.__init__(self)
imgStr = base64.b64encode(jpeg_image_buffer.getvalue())
model.add(Reshape((6, 2)))
index[count][1].append(url)
self.cl.autosetmode()
con.close()
value.append([x for x in getdatas])
artifact = Artifact.objects.select_related().get(pk=pk)
df
output.write(resp.content)
self._s = dict((k.lower(), k) for k in d)
suba = a[indeces]
x = [1, 2]
aux = copy.deepcopy(matriz)
result = lengths.nonzero()[0][0] + 1
someList.sort(key=mixed_order)
y = np.zeros((10, 10))
C0 = np.array([(A[i] * B[(i), :, :]) for i in range(len(A))])
self.file.write(msg)
dict(word.split(value_sep, maxsplit=1) for word in lexer)
a.repeat(2).reshape(2, 2 * len(a[0]))
fig, axes = plt.subplots(nrows=2, ncols=2)
conn.close()
APIResponse(status=status.HTTP_200_OK, data=data)
a_id = Column(Integer, primary_key=True)
s.isdigit()
answer.append([(each - x) for x in l])
print(in_nested_list(x, 2))
print(a)
print(response.status_code, response.url)
property_asel = list(itertools.compress(good_objects, property_a))
final_vector = (start_matrix.T * weights).sum(axis=1)
print(len(args) + len(kwargs))
df.c_contofficeID.str[-4:]
axes[0, 0].legend(bbox_to_anchor=(0, 0.5))
plt.show()
fpid.write(str(pid))
datetime.datetime(2012, 1, 1, 1, 0, 0),
c = a[b[np.searchsorted(b, a[:, (0)]) - len(b)] == a[:, (0)]]
a[numpy.lexsort(a.T)]
self.x + other.x
np.random.shuffle(indices)
json.JSONEncoder.default(self, o)
table.insert(chunksize)
result = [(x + y) for x, y in product(mylist, mysuffixes)]
a.shape[0] == a.shape[1] and np.linalg.matrix_rank(a) == a.shape[0]
deleteelem.getparent()[0]
x.tobytes()
i += 1
sleep(0.05)
Js = np.random.randint(0, n - 1, 4)
indptr = np.where(mask.ravel())[0]
self.Show()
pylab.show()
int(x, 0)
r = requests.get(url % params_json)
self.n
subprocess.Popen([command] + args, startupinfo=startupinfo).wait()
fig, ax = plt.subplots()
engine = create_engine(dsn, listeners=[SearchPathSetter()])
p.run()
sortedLetters = sorted(iter(d.items()), key=lambda k_v: (k_v[1], k_v[0]))
np.hstack([a, lookup[(a[:, (0)] - 1), :]])
ax.grid(True)
ax.set_yticks(np.arange(AUC.shape[0]) + 0.5, minor=False)
numpy.linspace(10, 20, 5)
screen_height = root.winfo_screenheight()
riak_bucket.delete(key)
type(d)
list(filter(f, list(range(2, 25))))
a[4].append(10)
width += (len(string) - 1) * charspace
jvm = sc._jvm
json.dumps(data)
BaseDocTemplate.__init__(self, *args, **kwargs)
alt.close()
upgrade(obj)
sys.exit(0)
list(self.__dict__.items())
print(delta.seconds)
parser = argparse.ArgumentParser()
self.device.close()
main.quit()
tree.add(4)
self.assertEqual(self.nums, self.nu_nums)
sys.exit(app.exec_())
gb.get_group(your_key)
raise error
data = json.load(contactFile)
list(itertools.chain(*[list_[s[0]:s[1]] for s in slices]))
self._choices.append((index, val))
[[int(x == y) for x in range(0, n)] for y in range(0, n)]
print(key, value)
fig = plt.figure()
probability = quad(lambda x: np.exp(kd.score_samples(x)), start, end)[0]
tup[0] = x
np.random.seed(2)
print(unit.objects.all())
df
print(locals())
virEventLoopNativeStart()
valid = set(valid_char_sequence).issuperset(myfilename)
np.reshape(df.values, (1, df.shape[0] * df.shape[1]))
pairs = IT.combinations(idx, 2)
b = np.array([[5, 6], [7, 8]])
instance.save()
self.stdin_sock.close()
main()
moduleY.py
p.close()
out[mask] = A[mask]
plt.show()
print(collections.Counter(y for x in listOfLists for y in set(x)))
b = map(list, b_set)
self.delete(self.position, Tkinter.END)
[OrderedDict(zip(list_of_keys, row)) for row in spamreader]
hash(frozenset(iter(self.items())))
random.choice(tuple(bigset))
deletesys.modules[mtr]
build_tree_recursive(tree[child.name], child, nodes)
[[(0) for _ in range(length)]]
a[1:2]
cv2.waitKey(0)
name = models.CharField(max_length=50)
server.login(gmail_user, gmail_pwd)
idx = np.argsort(a[1])
np.sqrt(sqrDiff.sum(axis=1))
locale.getdefaultlocale()
app = create_app()
b_logits = tf.Variable(tf.zeros([2]))
X, Y = np.meshgrid(X, Y)
df = df[(df.date >= df.beg_date) & (df.date <= df.end_date)]
result.append((a, b))
modList.append(len(self._myList))
dict1 = {x.split()[0]: x.split()[1] for x in list1}
diff(sin(x(t)), t, 2).subs(f, sin(x(t)))
sys.exit(p.wait())
ET.tostring(root)
process.join()
fig, ax = plt.subplots()
B[0, 0, 0]
pylab.plot(data)
print(re.match(regex, line).groups())
plt.setp(ax1.get_yticklines()[1::2], visible=False)
task()
dict2 = dict((item[0], item[1:]) for item in table2)
psycopg2.__version__
nodes = [node() for _ in range(100)]
decorator_maker
rows = np.random.random((100000, 8))
print(etree.tostring(tree, xml_declaration=True, encoding=docinfo.encoding))
_trace
print(a[:, :, (np.newaxis)].shape)
worksheet.set_column(0, len(data), 15, formater)
plt.colorbar()
end_date = date.today().toordinal()
s[-7]
do_sth()
sample_object.users.add(1, 2)
users = db.session.query(User).filter(User.numLogins == max_logins).all()
in_file.seek(0, os.SEEK_END)
args = parser.parse_args()
enc.transform([[0, 1, 1]]).toarray()
match.group(1).lower()
find_max(d)
req.add_data(urllib.parse.urlencode(data))
sum(x for x, c in list(Counter(args).items()) if c == 1)
d = dict((k, v) for k, v in list(d.items()) if v >= 10)
l.sort(key=lambda t: t[0])
html = urllib.request.urlopen(url).read()
me.save()
sorted_arr2 = arr2[arr1inds[::-1]]
x[1][2]
process.start()
print([key] + map(sum, zip(*value)[1:]))
p.start()
ban_status = models.BooleanField(default=False)
user.set_password(password)
t.close()
x = dict([(k, list(l)) for k in range(1000)])
ax = plt.gca()
len(l)
s = socket.socket()
list1.pop(2)
im.thumbnail(size)
plot(ar)
metadata = MetaData()
f(1)
plt.xlim([start - width, end + width])
handler.setFormatter(fmt)
OrderedDict()
p_regression = my_svr.predict(x_test)
l[1]
s = s[:-1]
x[:5] + x[5:].strip()
fig.subplots_adjust(bottom=0.1 * df.index.nlevels)
imshow(wally)
reader = csv.DictReader(f, fieldnames=h)
2 * x + 6
counts = collections.Counter(l[1] for l in a)
str(self.__dict__)
set(second_list) - set(map(f, first_list))
p1 = np.power(np.power(np.pi * 2, k), -0.5)
sum(some_counter.values())
xor_(b.begin(), b.end(), a.begin(), b.begin())
main()
foolist.hml
xml = ET.fromstring(xmlData)
print([r.match(string).groups() for string in strings])
2 * A * sin(distance / (2 * B))
self.canvas.delete(self.img_id)
axes = plt.gca()
im = Image.open(file_path)
orm.YourModel.objects.update(field_name=DEFAULT_VALUE)
Category.query.all()
plot_selected.yaxis.set_ticks(np.arange(0.2, 1.1, 0.2))
ax.set_xlim([0, 2])
p.start()
worker.start()
groups.union_set(a, b)
setattr(self, key, value)
os.chdir(cd)
a_test.__class__
now = datetime.datetime.utcnow().replace(tzinfo=utc)
x = numpy.arange(0, 2 * numpy.pi, numpy.pi / 1000)
matplotlib.__version__
foo()
df.ix[rows]
n += 1
d[k].append(v)
round(x, -int(floor(log10(abs(x)))))
app.MainLoop()
solve([5, 10], [1, 5])
main(list(range(1, 10)))
app = Flask(__name__)
d += datetime.timedelta(days=1)
pi.source_image.save(image_name, ContentFile(image_file.read()))
main()
new_nums.append(nums[-1])
itertools.dropwhile(it, makepred(5))
min(alist)[0], max(alist)[0]
print(solve(eqs, x, y, dict=True))
plt.subplot(121)
result = img.copy()
plt.show()
get_color(0)
pygame.init()
sys.stdout = flushfile(sys.stdout)
a[np.arange(a.shape[0]), I]
min(l_one + l_two)
test.print_array(a)
[date for date in dates if dates.count(date) > 1]
_st += timedelta(days=7)
friday = today + datetime.timedelta((4 - today.weekday()) % 7)
zip(a, a)
[(np.bincount(i) > 0).sum() for i in data]
x_sorted, y_sorted = zip(*sorted(zip(x, y), key=lambda a: a[0]))
sys.stdout.flush()
hash(self.normalized)
x, y
res.append((toktype, tokval))
print([max(v) for _, v in itertools.groupby(l, lambda x: x[0])])
w.setWindowFlags(QtCore.Qt.FramelessWindowHint)
flag.groupby(level=[0, 1]).max().reset_index()
print(df.join(s))
datfiles[0].seek(0)
canvas = numpy.zeros((n, n), dtype=int)
plt.show()
mock_last_transaction.assert_called_once_with()
ImageDraw.Draw(blurred_halo).text(position, text, font=font, fill=col)
self.__dict[name]
plt.show()
d.f()
sess.commit()
find_intersection(lst)
new_list.append(my_array + [e])
lmn = long_module_name
newR.mean()
doc = xml.dom.minidom.Document()
self.assertEqual(mocked_handler.call_count, 1)
response = urllib.request.urlopen(req)
[(x + L2[i]) for i, x in enumerate(L1)]
users = Users.objects.filter(pk__in=[1, 2])
a = k + a
print([item for sublist in out for item in sublist])
func()
socket.setdefaulttimeout(0.5)
print(request.headers)
gtk.CellRendererPixbuf.__init__(self)
filename, size = read_gzip_info(gzipfileobj)
ax.add_patch(circle)
list_of_arrays = map(lambda x: x * np.ones(M), list(range(k)))
axcltwo.set_xlim(0, binimg.shape[1] - 1)
df2 = df.iloc[[0, -1]]
tuple(x for sublist in base_lists for x in sublist)
Atomic.register(str)
soup = BeautifulSoup(test_html)
traceback.print_tb(tb)
{{form.content()}}
[([item] if not isinstance(item, list) else item) for item in l]
my_dict = request.query.decode()
print((k + 1) * lcm)
root.withdraw()
listener.setsockopt(SOL_SOCKET, SO_REUSEADDR, 1)
arr[2, 1] == arr[2, 1]
sess = tf.Session(config=config)
window.add(entry)
mask = np.concatenate(([False], np.isnan(a), [False]))
tar.extractall()
np.random.seed(seed)
arr = np.arange(729)
zip_longest(fillvalue=fillvalue, *args)
logger.setLevel(logging.DEBUG)
any(is_subset(d, d1) for d1 in my_list if d1 != d)
result.get()
builder.connect_signals(self)
self.stdout, self.stderr = p.communicate()
driver = webdriver.Firefox()
self._global_wealth
session.commit()
c = pycurl.Curl()
{{your_python_data}}
self.logger.removeHandler(ch)
l[:n]
app = flask.Flask(__name__)
isinstance(result, collections.Iterable)
cv.pack()
widget1.grid(row=0, column=0)
df = pd.read_csv(path, skiprows=rest)
pygame.init()
english_words = set(word.strip().lower() for word in word_file)
client.service.method(string_array)
print((current_item, next_item))
0.5 * ceil(2.0 * x)
out.clear()
fig.canvas.draw()
epoll.register(p.stdout.fileno(), select.EPOLLHUP)
data2 = data2.groupby(data2.index).sum()
now.astimezone(tz).dst() != timedelta(0)
ax.add_patch(rect)
PROJECT_ROOT = os.path.abspath(os.path.dirname(settings_dir))
followers_df.reindex(index=list(range(0, 20)))
connection.send_command(command, *args)
callable_method(user=user, **{option_name: user_defaults[option_name]})
list[0:10]
json.dump(lst, f)
self._applecount += 1
writer.writerow(row)
buffer(self)[:]
network.draw()
t1.start()
self.worker.moveToThread(self.mthread)
List.append(Item)
f.write(pat.sub(jojo, content))
print(tempfile.gettempdir())
groups = np.array([0, 0, 1, 2, 2, 1])
line = next(f)
users.get_current_user()
all_data = np.append(my_data, new_col, 1)
a = 2
p.wait()
print(ip)
app = QtGui.QApplication(sys.argv)
etree.tostring(nodes[0])
self.connectButton.clicked.connect(self.connectToServer)
xfiltered = np.interp(xi, xi[mask], x[mask])
contents = f.read()
app = QtGui.QApplication(sys.argv)
plt.scatter(X, Y)
ax.hold(True)
name = models.CharField(max_length=20)
[comment.extract() for comment in comments]
np.issubdtype(float, np.inexact)
new_dict = {k: d1[k] for k in list(d1.keys()) & wanted_keys}
[v for k, v in list(mydict.items()) if k >= 6]
plt.plot(list1)
self.root.overrideredirect(1)
m = re.search(regex, text)
plt.gca().xaxis.set_major_locator(dates.HourLocator())
x = [0] * 10
plt.show()
m = matrix([[1, 1], [1, 2]])
cv2.waitKey()
Y_pred = model.predict_on_batch(X_test)
smtp.starttls()
dt = datetime.datetime.now()
ax.set_xticks([])
df
print([str(b) for b in repo.heads])
self.NEWTAGS.append(tag)
a[1:, 1:]
s = socket(AF_NETLINK, SOCK_DGRAM)
fig = plt.figure()
repo = Repo(repo_dir)
list(dic1.keys()) == list(dic2.keys())
X_train, y_train, X_val, y_val
chr(97)
object_list = Content.objects.filter(subset__lte=no_of_subsets)
os.dup2(self._oldstdout_fno, 1)
print ()
list(itertools.chain(*lst))
pylab.plot(abs(fft))
dbkind[db_type](rest)
last = len(s) - i - 1
a[a == 1] += -epsilon
a[np.where(~a[:, (-1)].astype(bool))]
dfrand = pd.DataFrame(data=np.random.randn(rows, cols))
[a[l[0] + 1:l[1] + 1] for l in zip(e, e[1:])]
time.tzset()
foo(**d)
threading.Timer(1.25, lambda : webbrowser.open(url)).start()
self.hide()
im.show()
y = flatten(x)
user = authenticate(username=username, password=password)
m2[m2[:, (1)] > 10]
min(n for n in a if n > 0.7)
hfile.seek(0, os.SEEK_END)
X[:, (n)] += np.dot(A, colb)
rand_var_2 = tf.Variable(rand_t)
sc.close()
myDict = dict().reduceto(lambda t: t[1], lambda o, t: o + t, myTupleList, 0)
max([a for a in yourlist if a[2] >= 100], key=itemgetter(1))
points = np.array(list(product(x_p, y_p, z_p)))
self[key].extend(value)
nn.activate([1, 1])
Spam().foo()
max(min(maxn, n), minn)
df = pd.DataFrame()
client.server_info()
object.__new__(cls)
a, b = b, a
columns = dict([(x[0], x[1:]) for x in zip(*allrows)])
python - virtualenv
count += 1
print(self.cursor.fetchall())
result = yaml.load(fin.read())
np.array([A2[i, slices[j]] for i, j in zip([0, 1, 2], [0, 1, 0])])
sorted(somelist, key=key)
len(result[0])
t.start()
Password = db.Column(db.String(40))
toolbox = base.Toolbox()
g.add_edge(4, 5)
w.setLayout(lay)
doc = BeautifulSoup(xml)
r.cookies.get_dict()
label = tk.Label(image=image)
frames.append(numpy.fromstring(data, dtype=numpy.int16))
np.max(x, axis=axis) - np.min(x, axis=axis)
min(_, key=lambda pair: pair[0] / pair[1])
new_list
main()
[unique.append(item) for item in sequence if item not in unique]
server.ehlo()
pd.DataFrame(df.values[a], df.index.values[a], df.columns)
sandwich()
print(a.base)
lambda x: x == i or x % i != 0
heapq._siftdown(h, 0, i)
ixs = np.array([2, 1, 1])
draw.line(((x1, y1), (x2, y2)), fill=color, width=1)
df
z = np.array([1, 2])
plt.show()
pd.DataFrame(d)
fig = PLT.figure()
r[numpy.isreal(r)]
newcmap = matplotlib.colors.LinearSegmentedColormap(name, cdict)
print(json.dumps(dict(rh)))
cherrypy.config.update(config)
self.assertEqual(r.status_code, 200)
hello.ff(x, y)
self.process = subprocess.Popen(args, shell=True)
unittest.main()
addition.extend(array)
func(*a, **kwargs)
fig = plt.figure()
device.close()
dict((k, rank_a[k] - i) for i, k in rank_b)
nx.draw(G, pos)
CV_rfc.fit(X, y)
exitstatus = (status & 65280) >> 8
x.reset_index()
fig.colorbar(surf, shrink=0.5, aspect=5)
a[-4:]
init = tf.initialize_all_variables()
newPic.save()
unittest.main()
[(a if c else b) for item in list]
sys.exit(0)
file.seek(4)
ftp.cwd(directory)
self.data.append(item)
list.__getitem__(self, index % len(self))
soup = BeautifulSoup(html)
res.ready()
button.clicked.connect(self.onStart)
sys.exit(app.exec_())
neuron.draw()
ax1.plot(list(range(10)))
hash(1)
w.writerows(list(somedict.items()))
sc.stop()
print(row[0], row[1])
print(metrics.accuracy_score(y[100:], clf.predict(X[100:])))
db.session.add_all(users)
__init__.py
data = urllib.request.urlopen(url).read()
pow2(a, out=a, num_threads=4)
datetime.timedelta(seconds=result)
b[:, :-1] = a
norm = mpl.colors.Normalize(vmin=0, vmax=1)
matrix([[0.0, -1.0, -1.0, 0.0], [0.0, 0.0, 1.0, 1.0]])
do_stuff()
self.buf.write(contents)
df.iloc[np.random.permutation(len(df))]
plt.figure()
[1, 1, 0, 0, 0, 0, 0]
keys_to_delete = [k for k, v in d.items() if v == val_to_delete]
count += 1
self.socket.shutdown(SHUT_WR)
order = models.PositiveIntegerField(blank=True, null=True)
process(line)
myFunction(*args, **kwargs)
help(bytes)
any(c in badChars for c in yourString)
field.get_attname_column()
reason = json.loads(e.content).reason
soup = BeautifulSoup(urllib.request.urlopen(address).read())
type(_)
entry1.grid(row=1, column=1)
DirectClass.__init__(self)
x = [[int(float(j)) for j in i] for i in x]
isinstance(d, (dict, collections.MutableMapping))
list(set(newIntersections))
print(sys.path)
writer.writerow([subject, itemID, bias1Answer])
sh = wb.sheet_by_index(0)
now = datetime.utcnow()
list(islice(iter(preresult.items()), 100))[-10:]
conn.send(data)
file_handler.setLevel(logging.DEBUG)
self.frame.pack()
cherrypy.config.update(config)
print(C[np.searchsorted(C[:, (0)], I)])
t.daemon = True
map(functools.partial(myFunc, some_arg=additionalArgument), pages)
supersets.append(s)
plt.figure()
seq[::2], seq[1::2]
os.remove(thefifo)
self.redraw()
json.dumps(fb._asdict())
pool.close()
nx.draw(G, edgelist=edges, edge_color=colors, width=10)
train_op = tf.group(train_op1, train_op2)
self.redraw()
timeit.Timer(timewrapper)
process.start()
setattr(A, name, _method)
c.max()
frame.ix[frame.index[i]]
dt = datetime.datetime.now()
df.columns = pd.MultiIndex.from_tuples(df.columns)
self.assertEqual(auth_result, attempted_auth_result)
soup = BeautifulSoup(html)
self.tree.pack()
shutil.rmtree(dir)
s = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_IP)
protocol = TBinaryProtocol.TBinaryProtocol(transport)
ser.hist(cumulative=True, normed=1, bins=100)
df = pd.DataFrame(df, columns=sorted(custom_dict, key=custom_dict.get))
print(res.json())
clf.fit(np_training, np_labels)
file_content = gzf.read()
pool = multiprocessing.Pool(4, maxtasksperchild=1)
wave_file.writeframes(frame_data)
root.update_idletasks()
print([list(words) for key, words in itertools.groupby(data, init)])
print(response.body)
f = lambda : i
sizer.Add(hsizer, 0, wx.EXPAND)
self.crawler.engine.crawl(self.create_request(), self)
datetime.combine(d, datetime.min.time())
some_func(*params)
str(lst[0]), lst[1:]
my_dictionary.len()
app = QtGui.QApplication(sys.argv)
{{label}}
h2.setLevel(logging.WARNING)
print([item for sublist in [(rep * [i]) for i in a] for item in sublist])
test = set(numpy.random.randint(0, 10, 5))
m.start()
delfile.seek(0)
deletestr
author = models.ForeignKey(User)
HypotheticalBranch(1, 4, 2)
bop.pack(side=tk.LEFT)
[tuple(x for y in i for x in y) for i in list(d.items())]
ax.set_xticklabels([])
l.append(i)
app = Flask(__name__)
data = urllib.parse.urlencode(params)
workbook.close()
b = df.iloc[:, 1:].values
next(value)
s.readline()
K[np.ix_(np.arange(K.shape[0]), train, train)]
container.grid_columnconfigure(0, weight=1)
y_interp = scipy.interpolate.interp1d(x, y)
_myql.__version__
logging.basicConfig(filename=log_name)
stdout.flush()
B.IMC = IMC
isBlank = all(band.getextrema() == (255, 255) for band in bands)
ax.set_xticks([0.15, 0.68, 0.97])
sys.setrecursionlimit(10000)
gp2.append(float(i))
soup = BeautifulSoup(response.text)
print([d.b[i] for i in range(5)])
PLT.show()
i + 1
lambda num: num % 2 != 0
els[-1]
author = models.ForeignKey(Author)
avg_array = (data_array[::2] + data_array[1::2]) / 2
print((ss.name(), ss.lemma_names()))
sns.regplot(x, y, ax=ax1)
axes.set_yticks([])
scatter = ax.scatter(np.random.randn(100), np.random.randn(100))
not sum([(not i in A) for i in C])
self.updater.start()
np.mean(arr.reshape(-1, stride), axis=1)
ziph.write(os.path.join(root, file))
PATH = os.path.abspath(os.path.dirname(__file__))
db.delete(results)
h5file.close()
new_strs.split()
classifier.fit(X_train, Y)
df
__init__.py
somecell.fill.start_color.index
screen.refresh()
time.sleep(0.1)
setattr(self, name, attr)
A = scipy.sparse.csc_matrix((size, size))
m.p
self.Bind(wx.EVT_LEFT_DCLICK, self.on_left_dclick)
win1.destroy()
parser = etree.XMLParser(schema=schema)
plt.draw()
d = set()
main()
id = db.Column(db.Integer, primary_key=True)
b.shape
list.__init__(self, *args, **kwargs)
button.pack()
image_data = im.load()
html.title.text
data[(data > upper_threshold) | (data < lower_threshold)] = default_value
text.set_color(line.get_color())
time.sleep(10)
data = urlfetch.fetch(feedUrl)
plt.close(fig)
msg.set_payload(zf.read())
print([name for _, name, _ in pkgutil.iter_modules([pkgpath])])
sum(l[-n:]) / float(observations)
cursor = conn.cursor()
inv = pygame.Surface(img.get_rect().size, pygame.SRCALPHA)
print(d[7])
profs = session.query(UserProfile).all()
a += b
df.convert_objects(convert_numeric=True).dtypes
dict()
legline.set_linewidth(10)
is_staff = True
fig = plt.figure()
self.connect()
args = parser.parse_args()
sel_cur.close()
root.wait_window()
os.write(fd, data)
d = dict()
desks = Desk.objects.filter(room__in=rooms)
widget2.grid(row=1)
audio = models.FileField(upload_to=aud_get_file_path)
curl.perform()
print(pd.factorize(pd.lib.fast_zip([df.x, df.y]))[0])
print(tag.name)
date = parser.parse(ds)
parser = argparse.ArgumentParser()
2, 0, 0, 0, 0, 0, 1, 1, 20160224, 20160226
df = df.join(split_names)
a = [0] * K
self.client.close()
nbsumeq(A, B)
plot_data[0].append(1)
driver.quit()
cv.Circle(color_image, center_point, 40, cv.CV_RGB(255, 255, 255), 1)
self.stream.close()
self.count += 1
H = sps.coo_matrix((data, (rows, cols)), shape=(num, num)).tolil()
self.setCentralWidget(_widget)
mask = np.isfinite(x)
conn.send(data)
list(set(theList).intersection(set(theDict.keys())))
f = np.poly1d([1, 0, 0, -1])
session.close()
p.start()
module
hex(buffer.rd(1))
rows = (a != 0).sum(1)
lines = [l.split() for l in f.readlines()]
names = names.append(frame, ignore_index=True)
np.set_printoptions(precision=5)
path = path.strip()
nowdt = datetime.datetime.now()
combs = [[x for i, x in enumerate(data) if mask[i]] for mask in masks]
self.application.exec_()
plt.plot(dates, values)
gtk_dlls.append(os.path.join(include_dll_path, dll))
df = df.set_index(cols).apply(f, axis=1).reset_index()
second_largest([1, 1, 1, 1, 1, 1])
self.matrix.append([0] * len(list(adjacencyList.keys())))
points = [random() for _ in range(1000 * 2)]
set_trace()
cv2.waitKey(5)
[x for x in lst if x % 2 == 0][0]
np.apply_along_axis(v.dot, 2, A)
df.ix[df.var4.isnull()]
server_sock.listen(1)
cv2.drawContours(filledI, cs, i, color=255, thickness=-1)
os.close(fd)
pylab.legend()
pool.join()
time.sleep(1)
systemtest_n.py
reduce(dict.__getitem__, path, aDict).update(aSecondDict)
id = Column(Integer, primary_key=True)
QWidget.__init__(self, *args, **kwargs)
user = Session.query(User).first()
browser = webdriver.Firefox()
print(np.sum(data, axis=0))
Quota = celltext(columns[1])
arr[rs:re, cs:ce] = np.rot90(np.copy(arr[rs:re, cs:ce]))
ccb()
self.panel = wx.Panel(self)
writer.writerows(zip(bins, frequencies))
data[row][set_col] = val
r.close()
unittest.main()
new_df = old_df.loc[:, (list_of_columns_names)]
s[4:10]
fd = sys.stdin.fileno()
list(items.keys())
print((key, value))
out = a[sidx[idx]]
timezone.localize(localdt).astimezone(utc)
dialog.ui.setupUi(dialog)
sqlContext.sql(query)
one, four, ten = lst[1], lst[4], lst[10]
print(repr(vocab))
plt.yticks(np.arange(0))
add(**x)
zip(*A)
crawler.crawl(spider)
df2 = pd.DataFrame(np.random.rand(4, 2))
self.opn[op](op1, op2)
obj.__dict__[attr]
a = np.array([0, 0, 15, 17, 16, 17, 16, 12, 18, 18])
print(html2text(html))
dir(modulename)
Base.prepare(engine)
G.edges(data=True, keys=True)
do_stuff()
server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
w.start()
cov = np.zeros((num_vars, num_vars), dtype=float)
cur = conn.cursor()
self.instance.olddrivers = instance.drivers.all()
ax.xaxis.set_minor_formatter(ticker.FuncFormatter(ticks_format))
humansize(58812)
humansize(68819826)
df.index[1]
listx = [item[0] for item in data]
do_foo(obj)
print(list[i][j])
[elem[0] for elem in most_common]
time.sleep(0.1)
os.rename(pathAndFilename, os.path.join(dir, titlePattern % title + ext))
hist, xedges, yedges = np.histogram2d(x, y, bins=4)
fig.tight_layout()
merged[item[key]].update(item)
any(match(str1, str2) for str1 in set1 for str2 in set2)
print(next(first_it))
data.sort(key=getitems)
totaldict[tuple(x[:2])].append(x)
con.close()
ax.legend(loc=1)
print(match.group(0))
password = models.CharField(max_length=50)
process = multiprocessing.Process(target=do_expat, args=(q,))
p.join()
series1 = [float(i) for i in range(10)]
self.assertEqual(target.str(), b62)
ax.xaxis.set_major_formatter(copy.copy(Formatter))
self.flush()
np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))
np.allclose(m[slc], target)
int(b[:-1]) + unicodedata.numeric(b[-1])
pythons_tasklist.append(p)
1 / 0
myset.add(x)
df.ix[List]
M[:, (colnumber)] *= scalar
self.scrollbar.pack(side=RIGHT, fill=Y)
self._stack = []
heapq.heappush(heap, Neg(item))
plt.draw()
ax.get_xaxis().set_major_formatter(mf)
urllib.request.urlopen(r)
s.send(q)
os.fstat(f.fileno()).st_size
cv2.destroyAllWindows()
visited = {p: False for p in l}
df = pd.DataFrame([])
nodes.mlab_source.dataset.point_data.scalars = np.random.random((5000,))
self.layout.addWidget(self.button2)
print(the_table.properties())
h, s, v = hsv[:, :, (0)], hsv[:, :, (1)], hsv[:, :, (2)]
app = Flask(__name__)
print(str(name).lower())
sess = tf.Session()
ax.grid()
A = np.diag(1.0 / np.arange(1, 10000))
self._stream.write(text)
r.join(df)
os.path.normpath(path1)
d2 = {key: value for i, (key, value) in enumerate(d.items()) if i % 2 == 1}
dest.blit(tmp, destpos, dest.get_rect().clip(maskrect))
t1.start()
arr = np.array([4, 4, 1, np.nan, np.nan, np.nan, -5, -4])
entry.set_text(new_text)
caketaste()
set(box(df.genres.tolist()).ravel().tolist())
self.result.SetLabel(self.editname.GetValue())
{{title}}
main()
get_type_hints(Starship)
record2.put()
PETSc.Mat().createAIJ(size=(nrows, ncols), csr=(ai, aj, aa))
l.append(float(t))
document_first_row = [doc[0] for doc in documents]
s.apply(enumerate)
print(coc.x)
print(json.dumps(test_json, cls=MyEncoder))
fcntl.fcntl(fd, fcntl.F_SETFL, fl | os.O_NONBLOCK)
main()
[0, 0, 0, 0],
np.dot(np.array(L1).sum(0), np.array(L2).sum(0))
t.join()
pickle.dumps(self._cookies)
form = MyModelForm(hide_condition=True)
opener = urllib.request.build_opener()
zf.close()
model.train(sentences)
columns = [column[0] for column in cursor.description]
G = bipartite.projected_graph(B, inmates)
[a[i + 1:j] for i, j in zip(zeros, zeros[1:]) if len(a[i + 1:j]) > 0]
timer_thread.start()
pool = multiprocessing.Pool()
ax.figure.show()
datetime.datetime(2012, 1, 1, 0, 0, 0),
ax1.set_xticks(numpy.arange(x1 - 1, x2 + 1, 0.5))
id = Column(Integer, primary_key=True)
l2 = list(zip(*l1))
output_rs = tf.transpose(output, [1, 0, 2])
WebDriverWait(self, timeout).until(staleness_of(old_page))
x.append([4, 5])
my_list[i] = item
time.sleep(refreshrate)
self.mthread.finished.connect(self.worker.deleteLater)
f.write(fileobj.read())
QtCore.QObject.__init__(self)
logging.set_up_done = False
[i for j in (list(range(10)), list(range(15, 20))) for i in j]
self.goButton.clicked.connect(self.simulThread.start)
s = s[:begin] + s[end + 1:]
this_module = sys.modules[__name__]
app.MainLoop()
time.sleep(1)
out = np.zeros_like(array)
os.uname()
stdin.flush()
plt.xlim(-20, 60)
length = len(data)
traceback.print_stack()
new_rows.append(new_row)
plt.ion()
rows = input.filter(lambda line: line != header)
data = cursor.fetchall()
corpus = nltk.Text(corpus0.words())
int(revbin, 2)
polA.set_transform(tA)
index_of_maximum = scipy.argmax(R.getrow(i).data)
coo_matrix((vals, (i, j)), shape=(m, n)).asformat(format)
hi()
self.release()
f.close()
fcntl.ioctl(sock, SIOCSIFADDR, ifreq)
fig, ax = plt.subplots()
[seq[0]] + noVow(seq[1:])
print(tz_to_timedelta(tz))
clf2.fit(X, y)
ax.xaxis.tick_top()
print(list(product(list(range(2)), repeat=k)))
getattr(self.wrapee, attr)
dist = numpy.sqrt(numpy.dot(temp, temp))
np.linalg.inv(a)
print(testmodule.__doc__)
total = sum(int(i) for i in line)
f2(**d)
newstr = str[-4:]
plt.plot(t, s)
ax.xaxis_date()
set(a.items()) - set(b.items())
br.set_cookiejar(cj)
dep_list.append(opcodes[i])
layout = QtGui.QVBoxLayout(self)
print(map(str, EmployeeList))
lambda d=d: self.root.change_directory(d)
print(fn(10))
d = datetime.date(year=1940, month=1, day=1)
a[:2, :2]
print(i.text)
getattr(foo, string1 + string2)()
list(get_stuff(d))
not any(i in seen or seen.add(i) for i in x)
request = requests.get(image_url, stream=True)
print(solve(array1, 1, 5))
ax = plt.subplot(111)
p.search(s).group(1)
any(map(eval, my_list))
atexit.register(report)
ld.append({l[0]: int(l[col]) for l in ll})
stopwaitsecs = 10
x.wrong
request.user.pretty_username()
lists.append([])
childobject.parprint()
print(titlenode[0].firstChild.nodeValue)
[x for _, x in zip(list(range(n)), generator)]
print(line)
ax.set_aspect(1)
id = Column(Integer, primary_key=True)
fn(*args, **kwargs)
console_handler.setLevel(logging.DEBUG)
a, b = c.imag, c.real
startupinfo = subprocess.STARTUPINFO()
first_mask[first_mask] = second_mask
backward = lambda t: t[-1] + backward(t[:-1]) if t else t
courses = {}
self.archive = py7zlib.Archive7z(fp)
xticks[0].label1.set_visible(False)
conn.close()
parser = argparse.ArgumentParser()
calendar.timegm(d.timetuple())
irn += repr(num)
client = paramiko.SSHClient()
fig.set_size_inches(10, 15)
plt.tight_layout()
[2, 4]
ax.xaxis_date()
screen.refresh()
c[5:6, (7)]
print(stdout.read())
ax.add_patch(polygon)
print(model.predict(np.array([[1, 0]])))
serializer_class = TownSerializer
_quicksort(array, 0, len(array) - 1)
x = np.linspace(-1, 1, 201)
c = Counter([values[1] for values in d.values()])
a1.destroyCallback.add(b)
pygame.mixer.music.play()
tk.Frame.__init__(self, master)
X, Y = np.meshgrid(x, y)
print(ops[op](True, False))
time.sleep(timeout)
f.__code__.co_name
add(**arg)
print(traceback.format_exception_only(e.__class__, e))
G.add_edge(1, 2)
dice = [random.randint(1, 6) for x in range(4)]
np.digitize(date_bins_i8, date_bins_i8)
print(tcpdump)
stateB()
stateC()
days = (a - b).days
sum([x] * 10)
pl.plot(pl.randn(100))
Foo.bar.__func__ is foo
np.concatenate((x[:, (i), (i)], x[:, (i), (j)]), axis=1)
canv = Canvas(root, width=100, height=100)
urllib.request.install_opener(opener)
self.extracting(random.uniform(0, self.weight))
self.sampling(random.uniform(0, self.weight))
bm = b.reshape((10, 10, 2))
matches.append(item)
X, Y = numpy.meshgrid(x, y)
df.groupby(group_hours).apply(insert_missing_hours).reset_index(drop=1)
phone = models.CharField(max_length=250, blank=True, null=True)
A.shape
admin.site.register(Log, LogAdmin)
pdf = df.toPandas()
spinbox.grid(row=2, column=0)
[42, 1] in a.tolist()
df = df.dropna().reset_index(drop=True)
f.read()
ax.plot(plotlist[tracenum])
set(q).intersection(w)
assert max_product([-5]) == 1
os.makedirs(target_path)
sock.sendto(dns.pack(), (MCAST_GRP, UDP_PORT))
traceback.print_exc()
data = data.ix[data[cols] > 0]
my_dict = json.loads(input)
stats.norm.interval(0.68, loc=mu, scale=sigma)
self.browser.quit()
self.transport.loseConnection()
new_a = a.reshape(new_shape)
s.issuperset(t)
root = tk.Tk()
ax = plt.gca()
msg.attach(att)
diff = difflib.ndiff(file1.readlines(), file2.readlines())
compressed_table.append((istart, iend, table[i - 1]))
sample = lognorm.rvs(sigma, 0, scale, size=1000000)
type = models.CharField(max_length=5, choices=MEDIA_TYPES)
l = np.asarray(l)
d = array([0, 1])
p()
__init__.py
random.shuffle(list_of_questions)
plt.imshow(image, extent=[x.min(), x.max(), y.min(), y.max()])
id = Column(Integer, primary_key=True)
self.window.setLayout(self.layout)
colorbar.set_ticks(np.linspace(0, ncolors, ncolors))
Process(target=worker, args=(task_queue, done_queue)).start()
[True, True, False, True, True, False, True],
mycounter = Counter(txt.split())
cv2.waitKey(1)
m.save()
ingredients = IngredientSerializer(many=True)
cythonize(*args, **kwargs)
response = urllib.request.urlopen(req)
value = myVariant.toString()
cmp(len(a), len(b))
xvalues = np.tile(np.arange(im.shape[1]), (1, 2))
prev.append(line)
subject = forms.CharField(max_length=100, required=True)
temp[mask2] = 2
l.sort(key=lambda t: t[1], reverse=True)
equals = [(x[1:] == x[:-1]) for x in transposed]
print(a[np.sort(idx)])
w.set_linewidth(2)
df2 = pd.DataFrame(df1)
main()
t.start()
data.plot()
logging.getLogger(__name__).setFormatter(log_format)
sess.run(embedding_init, feed_dict={embedding_placeholder: embedding})
layout = QVBoxLayout()
sum(conf_matrix[i][i] for i in range(len(conf_matrix))) / t
print(a[1, 5])
Data[..., (0)] + 1j * Data[..., (1)]
print(4 * math.atan(1))
index = [(i + 1) for i in range(10)]
array([1, 1, 1, 1])
self._stop = threading.Event()
pool = multiprocessing.Pool()
predicted = classifier.predict(X_test)
students = Students.objects.get.all()
in_memory_file = file.read()
f = input()
sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq)
x = 0.1 * np.sin(2 * np.pi * 1.2 * np.sqrt(t))
ax = fig.add_subplot(111)
np.mean(arr, axis=1)
plt.xticks(new_xticks, new_xticks)
print(soup.title.string)
urllib.parse.urlencode(params)
s = pxssh.pxssh()
lis[0]()
set(item) - set(z)
p.join()
y.append(sublist[1])
input = sys.stdin.readline()
frame.grid(column=0, row=0, sticky=(N, S, E, W))
0, 42, -1, 0, 45, 1
fig = plt.figure()
app = QApplication(sys.argv)
do_something_6()
jmag = np.array(jmah)
np.interp(np.linspace(0, npt, nbin + 1), np.arange(npt), np.sort(x))
sys.stdout.write(term.BOL + term.CLEAR_EOL)
count += 1
os.utime(path_to_file, (access_time, modification_time))
np.vstack((a, b, c)).T
df
y = np.random.rand(n)
print(Counter(n1) - Counter(n2))
plt.legend()
print(response.headers)
ax0b.get_yaxis().get_offset_text().set_x(-0.075)
ax0c.get_yaxis().get_offset_text().set_x(-0.075)
a = np.arange(100)
ax = plt.gca()
self.__add__(other)
repr(s)
numpy.where(a > 2)
batch.add(service.farmers().list(), callback=list_farmers)
delta = timedelta(hours=t.hour, minutes=t.minute, seconds=t.second)
self.assertAlmostEqual(tr(2, 1), 0.0718, 4)
A = (C * mask).sum(axis=-1)
plt.ion()
reader = csv.reader(fin)
self.view.setColumnWidth(0, 800)
a[[[0], [1]], i]
x += (0, 0),
len(net.params)
ser.dropna().plot(ax=axes[1])
[0, 0, 0, 0]
plt.xlim(0, 10)
display.popen.terminate()
print(df.iloc[new_index])
print(sline)
n += 1
app.run(port=7080, **kwargs)
d2 = {k: f(v) for k, v in list(d.items())}
tuple(zip(MONTHS, MONTHS))
plt.show()
parity([perm0[i] for i in perm1])
sys.stdout = progA.stdin
df.loc[g.groups.get(2, [])]
time.sleep(5)
plt.tight_layout()
mylist.sort()
page = urllib.request.urlopen(req).read()
s.set_debuglevel(1)
urllib.request.Request(url, data, header)
json.dumps(your_variable)
console.setLevel(logging.INFO)
f.close()
new_list = [dd for dd in my_list if not dd is new_dict]
print(k, Dictionary[k])
ax.scatter(x, yflat, z)
img_temp.write(opener.open(url).read())
[i for i in l1 if not any(j in i for j in l2)]
ax = plt.axes()
line = f.readlines()[7]
self.result_queue.put(answer)
np.take(arr, inds)
t = np.arctan2(y, x)
current_line += 1
name, age
self.__dict__.update(locals())
ax.add_patch(patch)
soup = BeautifulSoup.BeautifulSoup(html)
res.get()
print(model.predict(np.array([[0, 0]])))
data = client.get_spot_price()
[(i + i * weight) for i in v] + [n]
im.wcs[::1 / 128, ::1 / 128]
hasattr(self, name)
self.listbox.select_set(0)
ax = fig.add_axes([0, 0, 1, 1], frameon=False)
ip.close()
d.setdefault(i, set()).add(j)
a.save()
response.close()
decorator2(f)
s = sys.stdin.read()
response = request.get_response(main.app)
plt.show()
[os.getpid(param) for param in params]
self.SetSizer(s)
self._window.destroy()
cdict = {c.name: c.value for c in cj}
func(*args, **kwargs)
parser = argparse.ArgumentParser()
a == a
worksheet.set_column(i, i, width)
d = dict(d)
root = Tk()
L[i] = L[i][::-1]
time.gmtime(ts / 1000)
f = pd.DataFrame(dict(year=list(range(2000, 2011)), A=np.random.rand(11)))
out = str2num.dot(de2bi_convarr)
print(not any(dict2.values()))
writer.writerows(grouped)
print(df[df.Name.isin(val)])
my_thread.start()
self.layout.addWidget(self.statusBar)
df1.update(df2)
thread.start()
proxy.ProxyClient.__init__(self, *args, **kwargs)
elem_list.append(i)
fig = plt.figure(figsize=(10, 5))
ast.literal_eval(raw)
print(a[-9:])
fig.subplots_adjust(left=0, right=1, top=1, bottom=0, hspace=0, wspace=0)
db.engine.execute(schema)
r.destroy()
CORBA.__file__
d.setdefault(j, []).append(i)
group(5, list(range(5)))
int(round(n[0]))
len(s)
plt.show()
M.diagonal()
root.quit()
a = np.arange(24).reshape((4, 6))
ax2 = ax1.twinx()
os.setpgrp()
start = time.time()
layout.addWidget(self.table)
wait = WebDriverWait(driver, 5)
pylab.figure()
response
X[np.ix_(a, b)]
tk.Frame.__init__(self, master)
print(avg)
tqdm_pandas(tqdm_notebook, *args, **kwargs)
b = dict(zip(i, i))
zip(s, s[1:])
self.pic = QtGui.QPixmap(imagePath)
data = output.getvalue()[14:]
changecolor(rect)
instance = ModelClass.objects.create(**validated_data)
matches.append(m.group(0))
a, b = select_choice()
a[::2]
reader = csv.reader(fin)
array = np.random.random(10)
dict.__setitem__(self, key, value)
self._result_handler.start()
count += 1
plt.ylim(0 - 0.5, data.shape[0] - 0.5)
lst.sort(key=lambda x: x[1])
int(base * round(float(x) / base))
ax1.yaxis.tick_left()
main()
A = numpy.concatenate((A, newrow))
g.user.is_authenticated()
app = wx.PySimpleApp()
plt.hold(True)
self.expunge(record)
print(df.sub(a, axis=0))
signal.signal(signal.SIGUSR1, signal_handler)
kernel = np.ones((10, 10), np.uint8)
ax.set_ylim(0, 255)
br = mechanize.Browser()
np.putmask(a, a >= m, m - 1)
g_list = list(filter(not_subtle_condition, g_list))
doc.appendChild(el)
time.sleep(5)
name = models.CharField(max_length=128)
client.close()
os.makedirs(os.path.dirname(dst))
window2.destroy()
timer2.stop()
serializer = VenueSerializer(venues, many=True)
gleason.setParseAction(diceGleasonParseAction)
numpy.dot(c, a)
end = string.index(end_marker, start + 1)
tex_data[tex_data == 0] = np.nan
hxs = HtmlXPathSelector(response)
os.write(fh, zf.read(name))
e = {v: k for k, v in a.items()}
reversed(it.islice(it.chain.from_iterable(reversed(a)), 5))
dict.update({item[0]: item[1]})
random.shuffle(l)
cv.Circle(color_image, center_point, 10, cv.CV_RGB(255, 100, 0), 1)
result = db.table.filter(db.table.column.ilike(looking_for))
e.extract()
dict(zip(l2, map(len, list(list(g[1]) for g in groups))))
dayDict = {d: [] for d in weekList}
current_date += datetime.timedelta(days=1)
classifier.fit(train_features, train_labels)
k.sort()
client.create_video(**kwargs)
assert np.allclose(expected, result2)
[1, 1, 1, 2, 2, 2],
ax.set_yticks([])
Serial.println(number)
self.build_response_from_file(request)
bytes(key)
time.sleep(1)
mymatrix = [[1, 2, 9], [4, 9, 6], [7, 8, 9]]
do_stuff()
urlopen(req).read()
exit()
p.terminate()
hash(frozenset(self.__dict__.items()))
theother()
N += 1
writer.writerow(line)
driver.get(url)
logging.root.addHandler(file_handler)
excel.Application.Quit()
next(b)
app = Flask(__name__)
seconds = int(cur.fetchone()[0])
a.insert(0, x)
workbook.close()
matplotlib.pyplot.scatter(n.predict(nfeatures).tolist(), targets.tolist())
numpy.bincount(x, weights=w)
id = Column(Integer, primary_key=True)
sum(c.values())
b.comments[0].content
draw_networkx_edges(G, pos)
painter.setBrush(QBrush(Qt.white))
pdb.set_trace()
os.rename(infilename, newname)
[1, 1, 1, 1]
fig, ax1 = plt.subplots()
sys._getframe().f_back.f_code.co_name
text = msg.as_string()
df.iloc[pd.np.r_[10:12, 25:28]]
session.add(model)
ax4.set_ylim(0, 1.2)
self.clear_canvas()
new_dict[length] = {mykey: name_num[mykey]}
self.Show()
dir = os.path.join(root, i)
main()
lst.sort(key=lambda x: x[0])
merged[k].add(d2[k])
binary_search([1, 5, 8, 10], 15)
f = lambda r: r * (sp.j1(r) / r) ** 2
l = [(0, 1, 0), (1, 1, 0)]
reader = csv.reader(f)
self.add_node(origin)
pylab.show()
self.layout.addWidget(self.spinBox)
subset[subset.isin(myList)].stack().duplicated().unstack().any(1)
print(str(a[0]))
lbl.pack()
assert len(a) == len(b)
[m.start() for m in pattern.finditer(sentence)]
print(my_list)
ax = fig.add_subplot(111)
any(map(lambda c: c.isdigit(), value))
print(mylist)
traceback.print_exception(type_, value, tb)
df.applymap(onlynumbers)
app = flask.Flask(__name__)
df_array = np.array(list(upsample(person)))
print(CreateTable(Model.__table__))
parser = argparse.ArgumentParser()
ebar = plt.errorbar(x, y, yerr=err)
pylab.plot(data[:, (0)], data[:, (1)], label=label)
minheap.add(maxheap.poll())
plt.autoscale()
list(itertools.chain(*list_))
painter.save()
plt.plot(x, y, fmt, label=label)
result.append([k, ms[k] + mb[k]])
ax.plot()
main()
plt.show()
plt.subplot(2, 2, n + 1)
row = {name_map[name]: val for name, val in list(row.items())}
bounds = np.repeat([(0, 1)], D, axis=0)
yolk
xs, ys = [], []
[iterable[i:i + length] for i in range(len(iterable) - length + 1)]
sys.exit(1)
json.JSONEncoder.default(self, obj)
app = Flask(__name__)
[i for i in range(1, len(x)) if x[i] != x[i - 1]]
B = np.interp(xx, x, A)
s = df.ix[:, (0)]
b.a.filter(a=a1)
[0, 1, 0, 0, 1, 29]
frame.grid(column=1, row=1, sticky=Tkconstants.NSEW)
polycube = numpy.rot90(polycube)
time.sleep(0.5)
cursor = connection.cursor()
((0 < x) & (x < 1)).any()
mywidget.pack()
a = np.array(literal_eval(a))
sum(map(len, list(d.values())))
d[v].append(i)
image.save(b.image.path, quality=20, optimize=True)
inds = np.cumsum(tmp_range[1:][::-1] + 1)
stream_handler.setLevel(logging.INFO)
act.pyqtConfigure(triggered=self.on_triggered)
calendar.day_name[dayoftheweek]
MyUser.objects.filter(tags__in=id_list)
sys.exit(0)
browser = webdriver.Firefox()
df = DataFrame(data)
self.assertAlmostEqual(tr(2, 2), 0.865, 4)
print(info.group(1))
sys.exit(unittest.main())
is_separately_linear(eq1, [a, c])
new_df = old_df[list_of_columns_names].copy()
sc = ax.scatter(x, y, z)
self.fcall = fcall
w.writerow([row[0], colname, colval])
print(soup)
print([pos for pos, char in enumerate(s) if char == c])
unique_id = models.ForeignKey(MyUUIDModel, unique=True)
np.random.uniform(0, 1, (500, 2000))
print(y.round(2))
self._compile_rules()
MySQLdb.escape_string(SQL)
self.result.append(word[:-1])
o.A(1)
plt.show()
idx = np.where(~mask, np.arange(mask.shape[1]), 0)
[x for b in a for x in b]
fig = plt.figure()
print(m.group(2))
f1.close()
top_line, bottom_line = top.get_line(), bottom.get_line()
time.sleep(1)
self.timer = Timer(self.timeout, self.handler)
copy_a -= copy_a[0].copy()
self.__dict__.update(**attrs)
file.close()
f.write(etree.tostring(root, pretty_print=True))
print(pd.concat([df.iloc[(0), :], df.iloc[(-1), :]], axis=1))
os.rename(outfilename, in_filename)
f.seek(0)
platform.system()
mail.ehlo()
urllib.request.install_opener(opener)
pickle.dumps(value)
data = sys.stdin.readline()
self.crawler.start()
result.insert(1, row_separator)
dt = datetime.datetime.now()
app.mainloop()
enemies = []
cj = cookielib.CookieJar()
pd.options.display.max_colwidth
somelist[:] = [tup for tup in somelist if determine(tup)]
time.sleep(0.5)
plt.plot([pc[i][0], pc[i + 1][0]], [pc[i][1], pc[i + 1][1]], color=c)
page = resp.read()
data = sin(2 * pi * 1000 * t)
app = Flask(__name__)
event.set()
plt.show()
circular.append(p)
p4.readarray(x)
self.lb2.yview(*args)
TrueXor(True, False, False)
solve(a * x ** 2 + b * x + c, x)
[max(s.index(max(s)) - s.index(min(s)), 0) for s in lst]
merged[k].append(d1[k])
out = sys.stdout.getvalue()
print(ET.tostring(root))
f = plt.figure(figsize=(10, 6))
getattr(self.myobj, attr)
np.vstack(l)
func.__code__.co_argcount
deletes[i]
urllib.request.HTTPSHandler.__init__(self)
plt.show()
self.entry.pack(pady=4)
print((a, b))
random.choice(my_list)()
p = np.array([(0, 0), (1, 0), (0, 1), (1, 1), (2, 2)], dtype=np.float)
fig = plt.figure()
main()
plt.ylim(-1.1, 1.1)
fh.close()
print(random.choice(value), key)
p2.start()
br.set_handle_robots(False)
print(data)
ch = logging.StreamHandler()
soup.prettify()
df2 = df2.reset_index()
labels = ax.get_xticklabels()
plt.setp(ax2.get_yticklabels(), visible=False)
cDC.DeleteDC()
cur.fetchone()
self.mainframe.columnconfigure(0, weight=1)
do_something_with(obj)
hist(date2num(list_of_dates), cumulative=True)
a * exp(-(x - x0) ** 2 / (2 * sigma ** 2))
reader = csv.DictReader(fp)
sys.exit(main())
sys.exit(application.exec_())
logging.basicConfig(level=logging.DEBUG)
pw = rps()
df.set_index(date_col_name, drop=True, inplace=True)
pygame.init()
self.task.cancel()
main()
print(pd.merge(df_subset, df).equals(df_subset))
math.sqrt(-1) / 0
list(solve(5))
my_list.append(item)
json.dumps(obj, default=method_name)
s.getvalue()
self.data = np.zeros((100,))
ax = fig.gca()
app = QApplication(sys.argv)
sys.modules[name] = mod
win.set_size_request(100, 100)
ax.clear()
cv2.circle(img, corner, 7, (255, 255, 0), -1)
old_stdout = sys.stdout
numpy.finfo(float).max
kurt
image = Image.open(image_string)
seed2 = df[~msk].mean()
self.panel.SetSizer(sizer)
queryset = Workout.objects.none()
plt.figure(figsize=(10, 10))
raise StopIteration()
reply = socket.recv()
response = requests.get(url, stream=True)
do_something_in_mechanize()
my_logger.addHandler(handler)
pylab.plot(list(range(11)), list(range(11)))
reader = csv.reader(open(filename))
print(myhtml.text_content())
print(json.dumps(test_json, default=json_debug_handler))
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
sys.exit(1)
driver.close()
sieve.primerange(a, b)
axes.append(ax.twinx())
main()
df = pd.concat([df] * 1000).reset_index(drop=True)
len(line)
color = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]
oFid.close()
sys.stdout = stdout
comp += numpy.min(first + second, axis=2)
print(i, j)
plt.plot(Time, signal)
mywidget.update_idletasks()
logger.setLevel(logging.DEBUG)
self.sizer.Add(self.list, proportion=1, flag=wx.EXPAND | wx.ALL, border=5)
QtGui.QWidget.__init__(self, *args, **kwargs)
payload = msg.get_payload()
zdf1 = bcolz.ctable.fromdataframe(df1)
s.close()
addopts = --pylint
np.count_nonzero(a & r != b & r)
np.array([d[x] for x in u])[inv].reshape(a.shape)
current_file = os.path.abspath(os.path.dirname(__file__))
result = [s for s in data if len(s) == maxlen]
process(line)
self._stream.flush()
r = requests.post(url, data=values)
result.append((int(k), c))
curses.noecho()
cols = df.columns.tolist()
ax4.plot(data, data, data, data ** 2 / 10, data, np.sin(data))
[A[b] for b in range(9, -1, -1)]
beta2 = np.linalg.solve(a, b.T)
print(df)
[(B.pop(0) if x else A.pop(0)) for x in selector]
C = np.swapaxes(B, 1, 2)
all.append(row)
self.write(login_response)
r.reduceByKey(lambda x, y: x + y).collect()
x = list(sum(list(dict.items()), ()))
shutil.copy2(path, temp_path)
lst[i] = lst[i] * 2
add_patch(axes[1], alpha=0.2, rasterized=True)
axcltwo.set_ylim(binimg.shape[0], -1)
self.seek(0, 2)
f.seek(findex[n] + 1)
print(max(len(i[j]) for i in x))
fig = pyplot.figure()
func()
fp.close()
user.user_permissions.add(perm)
{NULL, NULL, 0, NULL}
sio.getvalue()
pipe_lrSVC.fit(X_train, y_train)
indices = sp_matrix.nonzero()
res2 = pd.Series(res_arr, index=express_df.index)
p = sns.regplot(x=dat.x, y=ydat, data=dat, ax=ax)
form = UserprofileForm(request.POST)
pygame.quit()
o4 = O4()
o5 = O5()
Child().on_start()
plt.show()
user = models.ForeignKey(User)
raise WindowsError()
A01 = A[:, 0:2].astype(int)
self.Show(True)
plt.show()
ax.set_xticklabels(columns_my_order)
Fraction(0.185)
peaker(Y)
print(BASE_DIR)
logits = faultnet.inference(images)
X[:, (0)] - a
time.sleep(2)
x, chopped = int(x), x - int(x)
df
ax.w_xaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))
print(cur.fetchone())
l.append(v)
print(line)
fig, ax = plt.subplots()
re.compile(RE, re.UNICODE)
sum(1 for i in a.flat if i)
plt.plot(list(range(10)), [math.sin(x) for x in range(10)])
multiples.update(list(range(i * i, n + 1, i)))
date.replace(tzinfo=timezone.utc)
print(x)
fapp(request.environ, self.start_response)
list(islice(gen(), n))
ax.patch.set_visible(False)
mean = all.mean(axis=-1)
print(df.TIMESTAMP.dt.hour)
button.pack()
plt.plot(x, y)
print(np.unravel_index(np.argmax(x), x.shape))
array([[NaN, NaN, NaN, NaN], [NaN, NaN, NaN, NaN], [NaN, NaN, NaN, NaN]])
ax = fig.add_subplot(111)
newdate = datetime.datetime(*map(int, values))
index, value = max(data, key=lambda item: item[1])
df2 = pd.DataFrame(columns=cols, index=list(range(2)))
map.drawcoastlines()
f.readline()
ast = compiler.parse(eq)
outfile.close()
annotation(name, value)
deletesublist[index]
System.out.println(answer.toString())
numpy.dstack((x, y))
mydict = {key: value for key, value in zip(x, y)}
width, height = win.get_size()
pd.concat([df.iloc[-shift:], df.iloc[:-shift]])
models.Model.save(self, force_insert, force_update)
print((a, b, c))
app.mainloop()
map(np.random.shuffle, arr2d)
df.pivot(index=0, columns=1, values=2)
self.saver = tf.train.Saver(self.variables)
print(float(line))
d = dict(zip(list(range(1, 10)), list(range(50, 61))))
print([(x if x else y) for x, y in p.findall(s)])
[0.001, 0.25, 0.5, 0.75, 0.99, 0.999]
f = foo()
app = Flask(__name__)
hets = []
canvas.Canvas.__init__(self, *args, **kwargs)
b_id = Column(Integer, primary_key=True)
conn = urllib.request.urlopen(url)
json.dumps(recursive_asdict(data))
os.path.join(os.path.normpath(directory), filename)
f.__closure__[0].cell_contents
file_list.sort(key=lambda a: a[0])
wordorder = dict(zip(list2, list(range(len(list2)))))
s = pd.Series(l)
print((x, next(it)))
x[1, 2]
np.random.shuffle(arr)
float_arr = np.vstack(arr[:, (1)]).astype(np.float)
sys.path.append(vendor_dir)
df.col = df.col.dropna().apply(lambda x: str(int(x)))
os.chmod(path, current_permissions & NO_WRITING)
score = sum(i * w(i) for i in x if i in y) / sum(i * w(i) for i in x)
answer1[i] += 1
self.meth()
print(matches[1])
dict.__init__(self, *args, **kwargs)
mtime = os.path.getmtime(file_name)
key = parts[-1]
self.obtainingparams(df, tau_1, tau_2, residuals).called
categories.setdefault(i[1], []).append(i[0])
dc = wx.PaintDC(self)
L = [OrderedDict((k, d[k](v)) for k, v in l.items()) for l in L]
column_header.set_focus_on_click(False)
[([x] + p) for x in seqs[0] for p in product(*seqs[1:])]
min(x)
megawarc.main()
Grandparent.my_method(self)
zip(*ntup)
soup = BeautifulSoup(html)
print(a, b)
a.show()
server_socket.listen(10)
self.frame.Show(True)
ax = fig.add_subplot(gs[n])
print(r.url)
im.seek(i)
thread.start()
key, value = min(list(dict.items()), key=lambda __v: abs(__v[1] - target))
f.save()
NP.insert(T, 2, r, axis=0)
directory = os.path.realpath(directory)
i += 1
b.sort(reverse=True)
dir = os.path.dirname(__file__)
main()
r, g, b = im.getpixel((0, 0))
s.close()
{k: [v for _, v in g] for k, g in groupby(arr, lambda x: x[0])}
make_unicorns_from(f)
a_pet.say()
d1 = datetime.datetime.now()
zip_longest(fillvalue=fillvalue, *args)
form.fieldname.choices = choice_list
p2 = subprocess.Popen(args, stdout=subprocess.PIPE)
server = Process(target=app.run)
c = sys.stdin.read(1)
itertools.product(*([list(C.items())] * 2))
logging.exception(e)
print(x)
main()
ax = fig.add_subplot(111)
sys.exit()
sys.exit(0)
np.random.shuffle(arr)
print(prettyformat(obj))
frw.seek(seekpoint, 0)
df.columns = [col_dict.get(x, x) for x in df.columns]
q = Queue.Queue(maxsize=0)
list.remove(s)
self.text.config(yscrollcommand=self.scroller.set)
maxrep = reduce(f, l, (0, 0, 0))[2]
df.append(df2)
definitions.py
main()
open_cv_image = open_cv_image[:, :, ::-1].copy()
print(ElementTree.tostring(tree))
l.set_option(ldap.OPT_REFERRALS, 0)
is_palindrome(letters)
df.stack().values
new_contact.save()
ax1.yaxis.label.set_color(plot_ax1.get_color())
a = A()
logging.Formatter.format(self, record)
br.set_handle_redirect(True)
soup = BeautifulSoup(xml_string)
B = A
fig, ax = plt.subplots(1, 1)
np.dot(rot_matrices, p)
pycharm[path_to_your_file]
f2.write(data)
logging.root.addHandler(console_handler)
print(sys.version)
my_django_file = ContentFile(f.read())
orig(repo, remote, *args, **kwargs)
names = list(a.dtype.names)
ind.append(arr.index(list(df.iloc[i])))
totuple(array)
app = Flask(__name__)
print(format(tree))
logging.error(e, exc_info=True)
a[0](1)
main()
list()
p.join()
msg.attach(MIMEText(text))
lst.sort()
form = EditEventForm(instance=event)
min((angular_distance(theta, L[i], mod), i, L[i]) for i in [i1, i2])
results.sort(key=lambda x: (int(x[0]), x[1]), reverse=True)
data = urllib.request.urlopen(url).read()
data_list = [([key] + value) for key, value in list(data.items())]
pickle.dump(data1, output)
l.set_option(ldap.OPT_X_TLS_DEMAND, True)
setup()
f(*args)
Guild.query().filter(Guild.members == self.key)
ax.set_xlim(-51, 51)
results_list = pool_results.get()
sorted(sentence)[-1]
print(np.allclose(dets(M), dets_fast(M.copy())))
block_start = np.concatenate(([0], np.cumsum(block_count)[:-1]))
data += np.random.normal(size=data.shape) * 0.4
sys.exit(app.exec_())
MyClass(arg1, arg2)
bitmap = wx.Bitmap(path)
setattr(self, attr, value)
item = row[1:]
plt.axvline(x=0.2)
obj = memcache_client.gets(key)
d[l[0]] = l[1]
do_another_thing(object_list[-1])
l.extend(v)
opt.add_argument(*args, **kwargs)
groups.setdefault(y, []).append(x)
temp = pd.concat([temp, temp2], axis=1)
d[key] = value
df.apply(LabelEncoder().fit_transform)
print(l2set)
fig = plt.figure()
print(i, is_square(i))
admin.site.register(Class, ClassAdmin)
browser.add_cookie(cookie)
print(x.date())
l.append(elt)
f.read()
on = models.ForeignKey(Member, blank=True)
time.sleep(0.0)
X = sc.transform(X)
[c, d, e, f]
ax2 = plt.subplot(212)
comments = soup.find_all(string=lambda text: isinstance(text, Comment))
parser = argparse.ArgumentParser()
here = os.path.dirname(os.path.abspath(__file__))
line = line.rstrip()
ax.add_patch(circ)
print(int(math.sqrt(5)))
im.getbbox()
fig.tight_layout()
p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
sleep(snooziness)
parser.parse_args()
print(foo.bar._decorators)
os._exit(1)
[string[i:i + k] for i in range(length - k + 1)]
a[ind]
process.wait()
list(range(0, len(given) - len(sublist) + 1))
window.add(widget)
l[i + 1], l[i] = l[i], l[i + 1]
dftot = pd.concat((df1, df2))
timestamp = (utc_dt - datetime(1970, 1, 1)).total_seconds()
print(foo)
B = numpy.split(A, split_at)
f()
app = Flask(__name__)
not any(i in seen or seen.append(i) for i in x)
(np.corrcoef(M) == 1).sum() == M.shape[0]
num_words = sum(len(sentence.split()) for sentence in text)
ipshell()
ax = fig.add_subplot(111)
earth += 100000.0
time.sleep(1)
response
s += A[k] * B[k]
time.sleep(0.2)
sys.path.append(str(top))
lst = [1, 2]
scaled_data = [scaler(x) for x in data_list]
make_square(2)
local.py
ax.plot_surface(X, Y, Z)
split_list = lambda lst: (lst[0], lst[1:])
root = tk.Tk()
print(mimetypes.guess_type(url))
self.loop.run_forever()
setattr(model, name, request.get(name))
time.sleep(0)
fig.canvas.draw()
a = [1, 2]
links[1].click()
p = multiprocessing.Pool(processes=1)
a = list(range(10))
[1, 2]
response.write(p.body)
foo_list.append(lambda : bar.func2([7, 7, 7, 9]))
p = Pool(processes=10)
sum(x ** 2)
patcher.start()
ax.xaxis.set_visible(False)
print(len(itemlist))
root.after(500, add_letter)
foo()
new_bs = BeautifulSoup(target_html)
self.deauthorize()
Story.append(table)
session1.commit()
datetime.datetime.now()
dir(f)
print(image.shape)
server2.handle_request()
photo = ImageTk.PhotoImage(image)
self.pubsub = self.client.pubsub()
getattr(object, attrname)
str([])
self.my_text.splitlines()
self.comboBox_2.clear()
pysvn.__file__
ax1.legend(loc=2)
shuffle(word)
self.name = name
pool.map(processMdb, mdblist)
print(formatdate(timestamp, True))
self.client.connect()
pylab.figure()
ax.xaxis.set_minor_formatter(FixedFormatter(bin_labels))
time.tzset()
seen.add(line)
print(difft2(time(20, 40, 0), time(18, 41, 0)))
wb.close()
extend_array(data, 10)
len2 = lambda l: sum([len(x) for x in l])
root = Tk()
df[~bad_df]
print(k, v)
np.array(rdd.collect()).nbytes
start += 1
id = Column(Integer, primary_key=True)
list(chain.from_iterable(islice(theList, *t) for t in [(4, 7), (12, 18)]))
parser = argparse.ArgumentParser()
__init__.py
os.fdopen(fd, access)
ax1.set_xlim(*np.log10(olim))
G.edges(data=True)
ipdb.runcall(foo, 1, 2)
print(num.contents[0])
print(np.all(B[b_to_a] == A))
p.map(Copier(target_dir), file_list)
file = forms.FileField()
map(lambda x_y: x_y[0] + x_y[1], zip(repeat(x), y))
a[:] = [((x,) + mapping[x]) for x in b]
ab = np.hstack((a, b))
nums = [int(n) for n in x.split()]
c.__bases__
(options + [False])[current_option == options[0]]
window.set_border_width(10)
ax.set_yticks(z)
self.y2 += self.speed * math.sin(self.bearing)
list.append(i)
out = np.where(~a_extm[1:-1] & mask[1:-1], np.nan, a)
df.iloc[approach1(df.A.values, df.B.values)]
count += 1
self.bar()
print(set(regx.split(string)) & set(search))
scons
stdscr.refresh()
b.load()
train_x, train_y = train_set
ax.set_xticks([])
sb.plt.show()
p.map(mp_worker, (task1, task2))
print(repr(str(row[0])))
X = vectorizer.fit_transform(documents)
deletel[n:]
f.write(buffer(array))
[convert(element) for element in input]
func(*args, **kwargs)
self.webview.pauseTimers()
mock_stuff_obj = mock.Mock()
5 * f(f, 4)
[((x >> shifter) % 2) for x in range(2 ** (K * N))]
zip(fields, row)
ax1 = fig.add_subplot(111)
say_boo_twice()
rows.append(row)
unittest.main(failfast=True, testRunner=unittest.TextTestRunner)
ax1 = fig.add_subplot(1, 1, 1)
print(sys.getsizeof(myint))
num = int(s)
df.groupby(df.date.dt.month).apply(f)
dsp.write(data)
myTurtle.left(90)
base = datetime.datetime.today()
data_tuple = Item(*raw_data)
ax1.bar(x, y, 0.2)
os.mkdir(self.cache_location)
f = etree.fromstring(data)
86400.0 * self.days + self.seconds + 1e-06 * self.microseconds
blog.save()
data.shape
print(soup.prettify())
assert bare_argspec == decorated_argspec
paw_number[1:] += 1
main()
print(a, b)
list(self.items())[-1]
print(func())
sinks.append(sys.stderr)
main()
window.wm_withdraw()
fig, ax = plt.subplots()
sys.stdout.write(line)
console.interact()
Base.metadata.create_all(engine)
[(p[:i] + [l[0]] + p[i:]) for p in perm(l[1:]) for i in range(sz)]
raise web.notfound()
f.seek(0)
venus.speed(0)
numpy.array(list(range(25))).reshape((5, 5))
self.button.pack(side=TOP)
q = Question.objects.filter(criterion1 & criterion2)
max_arity = max(s, key=lambda i: i.arity())
main()
os.kill(p.pid, signal.SIGKILL)
self.y = []
grouped.cumcount()
plt.show()
[a[S] for S in s if a[S] > 0]
[t.get() for t in tasks]
list(range(100))[:10]
show()
print(value_set[1:-1])
print((x, y))
adic[i] += 1
br.submit()
indcs = [i for i in range(len(items)) if items[i] == item]
fsum([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])
print((x[idx], y[idx]))
q = q.with_entities(User.id)
b.grid()
target.close()
logger = logging.getLogger(__name__)
setup_mock()
int(math.pow(10, int(math.log(b, 10)) + 1) * a + b)
result = Model.objects.filter(id__in=object_ids)
end_date = datetime.datetime(pub.year, pub.month, pub.day)
main()
collections.Counter(window(x))
ui.syn()
print(soup.prettify())
co.co_nlocals, co.co_stacksize, co.co_flags
axes[1].legend().set_visible(False)
to_delete.append((corpus.index(match), len(match)))
[(lambda splt: (splt[0], splt[1]))(s.split()) for s in input]
ax.w_zaxis.set_major_formatter(niceMathTextForm)
df = pd.DataFrame()
d1 = {(1): 1, (2): 2}
g.add_edge(1, 7)
x = Decimal(2606.895)
id = Column(Integer, primary_key=True)
a = 1
obj.save()
self.ax.imshow(im)
l.sort(key=lambda t: (t[0], -ord(t[1])))
results = Orchard.objects.filter(**options)
d[x][y] = z
time.sleep(0.25)
self.listofrecords[listnum][record]
nil
do_something_with_results(resuls)
soup = BeautifulSoup.BeautifulSoup(txt)
sys.stdout.flush()
gtk.main_quit()
db.init_app(app)
random.shuffle(lst)
fh.seek(0)
[[d.get(str(y)) for y in x] for x in A]
newmethod(obj, node, **kwargs)
current_date += datetime.timedelta(days=1)
set(b.items()) - set(a.items())
a = [(item + 1) for item in a]
set(word_list).intersection(a_string.split())
time_list[np.arange(5, 6)]
Surname = Dinh
dataf = dataf.append(new_row, ignore_index=True)
table = Orange.data.Table(df.as_matrix())
form = StopAdminForm
paralell_notifications(new_rss)
[0, 0, 1, 1, 0, 0, 0]
np.percentile(S, np.array([0, 100]))
followers_df.index = list(range(len(followers_df)))
items[pos], items[index] = items[index], items[pos]
print(g(1))
print(now.year)
ax = fig.add_subplot(111)
print(list(seach_replace(message, codes)))
a, b = b, a + b
plt.show(block=False)
raw_img = urllib.request.urlopen(req).read()
zf = zipfile.ZipFile(src)
sftp.get(log_file, local_name)
fig.canvas.draw()
np.zeros_like(x, dtype=bool) | initial
sheet1 = book.sheet_by_index(0)
request.json
bpfilename = sys.argv[0]
e = Example(10)
out_file.close()
print(set(better_d))
shutil.copy2(pathname, dstdir)
ln.set_ydata(data)
a, b, c, d, e = a
next.click()
strings = {s[:5]: s[5:] for s in x}
driver = webdriver.Firefox()
grayimg = cv2.equalizeHist(grayimg)
sqrt(res)
f()
mvv_count = [int(i._count) for i in mvv_list.collect()]
sum(count[letter] for letter in valid_letters)
nextelem = li[(idx + 1) % len(li)]
a = np.array([[0, 1, 1, 0], [1, 1, 1, 1], [1, 1, 1, 1], [0, 1, 1, 0]])
fib(n - 1) + fib(n - 2)
ndx = numpy.searchsorted(xs, ys)
self.file.write(data)
value_index = my_list.index(value)
wood = next(itertools.count())
finfo = np.finfo(f)
sys.exit(a.exec_())
v[0] += 1
plt.show()
indices_to_add = np.array([2, 0])
set([1, 2]) in a
plt.figure(1)
plt.show()
sess = tf.Session()
burroughs_wheeler.test(10000)
pickle.dump({(1): 2}, f)
print(cls.foo_string)
gc.get_referrers(obj)
print(yaml.dump(doc, indent=4))
self.__getitem__(key)
nxn = np.arange(n ** 2).reshape(n, -1)
print(line)
app.exec_()
time.sleep(1.0)
plt.xticks(list(range(len(D))), list(D.keys()))
s.close()
pickle.dump(foo, f)
yourmodel.objects.filter(location__dwithin=(geom, 0.02))
all(c == s0 for c in s[1:])
temp_array = np.arange(10, 129, 10)
hov.perform()
print(getpass.getuser())
open(fname.lower())
next(alternator)
json_str = json.dumps(status._json)
scipy.misc.imshow(img)
(x + y) * z
print(map(sum, zip(flattend1, flattend2)))
d.stack().groupby(arange(4))
np.may_share_memory(get_sliding_window(df, 2), df.values)
a = b
thread.start()
ax1.plot(list(range(10)))
self.city_set.filter(is_capital=True)
datetime.datetime.combine(dt.date(), midnight)
x = mungesomedict(dict(adict, **anotherdict))
a.name
Xs = numpy.vstack((Xs, EMOV_n))
counter_list[:] = (c for c in counter_list if c)
print(query.explain())
df.index = df.index.map(str)
items.append(values)
ax = plt.subplot(111)
plt.plot(x, x)
print(Duck().speak())
replacer_regex.sub(lambda m: dict[m.group(1)], regex)
self._data_unoccupied.wait(5)
datetime.date(2016, 8, 26),
max(frequencies, key=counts.get())
reader = csv.reader(f, skipinitialspace=True)
parser.feed(data)
f.write(c)
pool = mp.Pool(8)
r.content
a, b, c = [int(i) for i in line.split()]
next(d for i, d in enumerate(lod) if 1 in d)
log.append((name, attr))
fig, ax = plt.subplots()
dt = datetime.now()
model.docvecs[1]
p = multiprocessing.Process(target=worker, args=(q, nameStr))
run - the - app
ax = fig.add_subplot(111)
print(args)
info[2][0] == 5
[li[i:j] for i, j in zip(inds, inds[1:])]
self.stdout_sock.close()
data[int(i), int(j)] += 1
print(tree.text_content().strip())
temp.iloc[[0, 1, 4]].index
self.window.add(self.box)
A = [6, 7, 8, 9, 10, 11, 12]
gx = np.zeros_like(f)
linearmodel(X, Y, Z)
True
app
test()
w = QtGui.QMainWindow()
_quicksort(array, begin, end)
np.random.seed(seed)
requests_log.setLevel(logging.DEBUG)
d2 = datetime.datetime.now()
sortedList = [dictFromList[i] for i in b]
Gallery.objects.filter(pk__in=valid_ids)
label.master.overrideredirect(True)
foo.__name__
set(A) - set(B)
result = collections.defaultdict(list)
zip(*([iter(iterable)] * n))
my_array[pos]
id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
array([[1.0, 1.0], [1.0, 1.0], [1.0, 1.0]])
print(Foo().bar.arity())
actor.save()
df = pd.DataFrame(data=np.random.randn(1, 8))
sys.exit(app.exec_())
dir = os.path.dirname(module.__file__)
profile.save()
fig = plt.figure()
a = numpy.array([10, 7, 2, 0])
mylist.append(x)
C()
list(unique)
tk.Frame.__init__(self, parent, *args, **kwargs)
x_y_coords = zip(indices[0], indices[1])
len(df)
users = [userA, userB, userC]
THETA = np.random.random(15) * 2 * np.pi
m = a.shape[0]
plot.plot(x, y)
self.canvas.draw()
setattr(self, name, value)
reverse_m2ms = my_model._meta.get_all_related_many_to_many_objects()
np.dot(ZCAMatrix, inputs)
self.Bind(wx.EVT_BUTTON, self.OnOkayCanButton, okayButton)
content_type = models.ForeignKey(ContentType)
sorted_arr1 = arr1[arr1inds[::-1]]
app = Flask(__name__)
l[get_index(l, find_min(l))]
print(x)
ax.set_yticks(list(range(nb_names)))
sys.stdout.write(data)
file.readline()
open_file.write(upload.file.read())
[intify(i) for i in maybeLst]
NULL
[gb.get_group(x) for x in gb.groups]
zip(l, l[1:])
r.json()
list(chain(repeat(0, len(a) - len(c)), c))
lst[0].pop(0)
irenR.Start()
loop.close()
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
string.ascii_uppercase[5]
tempDF[mask]
[f for f in User._meta.get_fields() if f.auto_created and not f.concrete]
find_lyrics()
searchB.pack()
x.sort()
smtpserver.quit()
hour_ago = datetime.datetime.now() - datetime.timedelta(hours=1)
p.start()
apsched.add_interval_job(checkThirdAPI, seconds=5)
start = cols[1].get_text()
conn.commit()
process.stdout.readline()
draw.rectangle((rect_start, rect_end), outline=color)
print((np.average(b), np.mean(b), np.ma.average(b), np.ma.mean(b)))
f.tell()
plt.show()
c.decompose()
xlApp.Workbooks.Add()
print(parmap(lambda x: x ** x, list(range(1, 5))))
br.set_cookiejar(cj)
locations = Locations.objects.filter(**params)
random.seed(4555)
credentials = tools.run_flow(flow, storage, flags)
arr = np.arange(10).reshape(5, 2)
win.run()
print(Base.getSubclasses())
True
globals()[name] = val
B.__init__(self, 4)
self.hack_mro()
np.where(k, 2, 5)
np.random.seed(0)
plt.contourf(np.random.randn(10, 10))
elevate()
setattr(obj, self.func.__name__, value)
print(a)
bpp = mode_to_bpp[data.mode]
matplotlib.pyplot.close()
conn.endheaders()
wordlist = [ch for ch in s]
select.select([process.stdout, process.stderr], [], [])
count = sum(1 for i in l if my_condition(i))
x += 1
zip(*df.values)
self.currentStack.pop()
zip(*lis)
print(postcodes)
self.datadex[x] + 1
self.stream.write(data)
t.start()
rndseries = pd.Series(np.random.randn(len(rndrange)), index=rndrange)
f = plt.figure(figsize=(size, size))
random.shuffle(x)
dlg.exec_()
plot(x, y)
d[j].append(i)
[x for i, x in enumerate(y) if i != 0 and i != 1]
(-17.5).hex()
print(sorted(list(globalHotItems.items()), key=lambda x: x[1])[-1])
shutil.rmtree(tdir)
df
output = [(x, y) for x, y, label in L if x > 10]
ax.set_yticks(y_pos)
print(scipy.ndimage.zoom(x, 2, order=0))
tree = ET.parse(filename)
xmldoc = minidom.parseString(document)
time.sleep(0.1)
sys.stderr.write(line)
ax1.set_color_cycle([cm(1.0 * i / (NPOINTS - 1)) for i in range(NPOINTS - 1)])
fig, ax = plt.subplots()
dict1 = dict2[key]
grouped.loc[1, 2]
plt.bar(bins[:-1][i], n_x[i], width=10)
self.levelno = levelno
time.sleep(1.1)
app.run()
defaultdict(lambda : nested_dict(n - 1, type))
tuple(sorted(x))
hash1.update(text1)
plt.hexbin(x, y, gridsize=20, cmap=cmaps.pop(), mincnt=1)
main.mainloop()
ancestors_descendents = set()
self.__init__()
pd.DatetimeIndex(df.date) + pd.offsets.Hour(1)
b = a
print(GetWindowText(GetForegroundWindow()))
newk.append(i)
p.x, p.y
json.loads(s)
cmp(len(A), len(B))
models.DateTimeField(null=True)
copy.deepcopy(d)
name = models.CharField(max_length=255)
b = numpy.vstack((a, a))
pool = Pool()
client = s.getsockname()[0]
stream.write(chunkout)
np.random.seed(1010)
f.write(doc.toxml())
time.sleep(0.1)
df.head()
self.close()
parser = argparse.ArgumentParser()
new = a + (b,)
jar = cookielib.CookieJar()
df.tail(1).T.assign(passes=lambda x: x.gt(1))
time.sleep(delay)
ax = pl.subplot(111, polar=True)
plt.colorbar()
target_time = time.clock() + 0.025
stringbuilder.py
process = subprocess.Popen(your_command, stdout=subprocess.PIPE)
setattr(self, d[name], value)
itemgetter(2, 5)(L)
print(floor(log(1000, 10)))
sort_indices = np.argsort(brr)[::-1]
m[:, (0)].shape
ax.set_xticklabels(a)
self.set_val(self.valinit)
[x for x in lst if x % 2 == 0][:1]
np.array(xlist, dtype=dt)
self.insert(len(self._list), val)
app = wx.PySimpleApp()
instance = SomeModel.objects.get(id=id)
_start = time.time()
text.strip()
client.close()
fig = plt.figure()
a[:] = b
float(value)
pickle.dump(clf, f)
b = 1
destination.close()
d[k]
time.sleep(10)
self.button.clicked.connect(self.start_download)
functools.partial(func, p)
a.remove(10)
eroded = cv2.erode(img, kern, 1)
NULL, NULL
query_result = DBSession.query(Article).order_by(Article.created).all()
df
stdout.close()
pi = square(a + b) / 4 * t
bitarray.bitarray(l).tostring()
conn.login(usernm, passwd)
writer.save()
b[:, ([1, 2, 0])] * c[:, ([2, 0, 1])] - b[:, ([2, 0, 1])] * c[:, ([1, 2, 0])]
chain.from_iterable(permutations(xs, n) for n in range(len(xs) + 1))
self.altitude *= -1
len(s)
coc.x.append(2)
sys.exit()
deleteself.__dict__[field.get_cache_name()]
draw.ellipse(bbox, fill=128)
print((self.x, self.y, self.z))
statemap = {(1, 0): (0, 1), (0, 1): (-1, 0), (-1, 0): (0, -1), (0, -1): (1, 0)}
A.__init__(self)
exp = (a + b) * 40 - (c - a) / 0.5
print(convert(1692))
plt.ion()
print(bisect.bisect_left(L, (2,)))
map(sum, zip(a, b, c))
new_im.paste(im)
models.signals.post_save.connect(create_api_key, sender=User)
[sum(starmap(mul, zip(first, col))) for col in zip(*second)]
X.copy()
print(scipy.ndimage.zoom(x, 2, order=1))
result[-1].append(temp)
self.socket = socket(AF_INET, SOCK_STREAM)
r = s.post(url, data)
mydog.findall(s)
mngr.window.setGeometry(50, 100, 640, 545)
obj.isoformat()
tmp.append(map(int, line.split()[:w]))
self.stop()
a = list(a)
module2.py
call_fn(*args, **kwargs)
node_schema.load(json_data, instance=Node().quey.get(node_id))
x, y, z, w = map(int, input().split())
vis2 = cv2.cvtColor(vis, cv2.COLOR_GRAY2BGR)
tup[0] += 4, 5, 6
kernel = np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]])
word_list = sentence.split()
np.linalg.norm(xs)
form = MyForm(request.POST)
print(urllib.request.urlopen(request).read())
par2.set_ylim(1, 65)
assert np.allclose(result, ans)
dt = datetime.datetime.now()
self.write_cell(sheet_name, cell, existing_value, updated_format)
subprocess.call(cmd, shell=False)
G.add_edges_from(tuples)
deleteyour_dict[unwanted_key]
get_supported_types()
print(local_tz.localize(datetime(2000, 6, 15)))
list(chain(a))
mem.Blit(0, 0, size[0], size[1], screen, 0, 0)
app.listen(8888)
temp_file.write(bytes)
do_something()
tree = et.fromstring(data)
self.edit2 = QLineEdit()
conn.login(user, password)
app = create_app()
widget.Bind(wx.EVT_COMBOBOX, self.onSelect)
pprint(table)
end += datetime.timedelta(1)
w = np.fft.fft(x)
fo.write(content)
setattr(obj.a, p, value)
print(etree.tostring(element))
markov(arr)
Base.metadata.create_all()
[l for l in list_dirs if os.path.basename(l) not in unwanted_files]
df.mul(vector, axis=0)
wx.Frame.__init__(self, *args, **kwargs)
ith_diag.eliminate_zeros()
test[:, ([0, 2])]
gui.root.mainloop()
ax.quiver(x, y, u, v)
audio.add_tags()
self._treeView.get_cursor()[0][0]
db = SQLAlchemy(app)
writer.writerows([object2list(obj, attr_list) for obj in list_of_objects])
a[0], a[2] = a[2], a[0]
lambda seq: [(lambda : el) for el in seq]
-r72
df.dtypes
loop.run_forever()
strcpy(buffer, path)
text = [x for x in text.lower() if x in string.letters]
plt.show()
csX.n = X.shape[1]
pool.join()
outf.write(ser.read())
list(d.items())
versioned_session(session)
w = distanceM()
print_hello_world()
cv2.namedWindow(winName, cv2.CV_WINDOW_AUTOSIZE)
NULL
sorted(set(li), reverse=True)[n]
app.mainloop()
GPIO.setmode(GPIO.BOARD)
ax2.plot([x1, x2], [y1, y2])
f.close()
updated_at = models.DateTimeField(auto_now=True)
app = Flask(__name__)
print(combs(sampleip2))
res[k].append(v)
df_r.show()
data.insert(bslindex, newcol)
tk.Frame.__init__(self, master, height=42, width=42)
a.sort(axis=1)
print(tuple(list(a)))
[i for i in range(1, n) if n % i == 0]
os.uname()
list(tokenize(stream))
s.sendmail(me, you, msg.as_string())
X -= X.mean()
json.dump(json.load(ifile), ofile, indent=4, ensure_ascii=False)
cursor.execute(*sql_and_params)
form = ContactForm(request.POST)
json_obj = json.load(metros_file)
plt.cm.coolwarm(t)
plt.show()
print(repr(Fraction(f)), Fraction(f))
print(m.shape)
foo = np.array([1, 2])
Base.objects.instance_of(ModelX) | Base.objects.instance_of(ModelY)
raise AssertionError
self._logger.setLevel(logging.INFO)
p.relative_to(*p.parts[:2])
indices.sort(key=lol[1].__getitem__)
draw()
user.save()
print(match.group(2))
o.x += 5
print(line)
time.mktime(datetime.date(year, 1, 1).timetuple())
a = list(range(1, size + 1))
eval(strs)
embed()
result.sort(key=lambda x: -x[1])
f(*args, **kargs)
print(my_new_list)
gs.fit(X, y)
pool = mp.Pool()
result = v.cumsum()
any(some_func(x) and False for x in some_list if x > 5)
cb = plt.colorbar()
br = mechanize.Browser()
User.query.all()
file.write(old_lines)
print(list(myDict.values())[i][j])
logging.basicConfig(format=format, level=logging.INFO)
tuple(map(operator.add, a, b))
print(line)
collections.Counter(lst)
Session.query(FooClass).filter(FooClass.somevalue == 8).all()
x.transpose(1, 2, 0).reshape(2, 4)
plt.figure()
axis.plot(x_data, y_data)
fig.subplots_adjust(hspace=0.5, wspace=0.001)
[fact(a) for a in args]
list(gb.keys())
random_state = random.choice(states.split())
sys.path.append(PATH)
transaction.rollback()
views.py
list(B.intersection(A)) + list(set(A) - B)
all(isinstance(s, str) for s in obj)
print(dir(foo))
out = np.zeros([n, len(arrays)], dtype=dtype)
x = x[(0), :, :]
c = list(itertools.product(a, b))
parser = argparse.ArgumentParser()
a.insert(randint(0, len(a)), x)
c = [i for i in a if i in b]
my_string.split()[:4]
d = dict(input().split() for _ in range(n))
ax = fig.add_subplot(111)
df
_stack.pop()
sys.path.append(here)
fig = plt.figure()
doctest.testmod()
print(np.array(result))
opener.open(req)
b, a = sorted((a, b), key=len)
Response(status=200, data=data)
self.__dict__.update(kwargs)
data = json.load(data_file)
len(list(filter(str.islower, string)))
dayDict = dict.fromkeys(weekList, 0)
output += np.sum(integrand(a), axis=1)
login(request, user)
label_idx = np.searchsorted(all_labels, labels)
(1 - 1 / Decimal(7000000)).ln()
win.update_idletasks()
obj.__class__.__dict__[1]
session1.commit()
qW = np.convolve(sPSF, sQ)
all(y - x >= 2 for x, y in zip(locs, locs[1:]))
b = db.ReferenceProperty()
{{name}}
saved.append(element)
args = parser.parse_args()
data = data[keep_mask]
Base.metadata.create_all(engine)
[list(g) for k, g in groupby(nums, key=lambda n, c=count(): n - next(c))]
post2.delete()
request.session = {}
p.stdin.close()
x = np.arange(-10.0, 10.0, 0.1)
type(s)
self.assertEqual(reference, test)
main()
os.setsid()
x[1]
nx.draw_networkx(G, pos=pos)
np.dot(arr_pairs, xy)
dline = dline.strip()
list(range(x, x + 10 * y, y))
ax = fig.add_subplot(111)
DF.dtypes
dedup = [k[i] for i in range(len(k)) if i == 0 or k[i] != k[i - 1]]
plt.xticks(xx, ll)
count += 1
fig.show()
dt = tz.localize(dt)
myiterator = iter(mylist)
book.save(filename)
date = models.DateField()
temp.flush()
sum(p * q for p, q in zip(vector1, vector2))
d = defaultdict(int)
p.wait()
zipstream.seek(0)
df
do_something()
sys.path.insert(0, PROJECT_ROOT)
models.CharField(null=True)
writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
self.fig, self.ax = plt.subplots()
json.dump(jsonDict, f, indent=4)
a.writerows(data)
jez(df1)
ret = func(*args, **kwargs)
print(list(result))
k = k[..., (np.newaxis)]
user = models.ForeignKey(User)
ax = plt.subplot(111)
seq.append(line)
add_chain.apply_async()
b = sum(a)
np.hsplit(a, 2)
img = Image.open(image_path)
render(request, template, context)
substrings = data.read().split()
cur = conn.cursor()
dbapi_conn.commit()
print(etree.tostring(cityModel, pretty_print=True))
fig, ax = plt.subplots()
df.apply(zscore)
first_name = forms.CharField(max_length=256)
pickle.dump(data, output)
plt.subplot(211)
self.handler.close()
z.append(y)
math.factorial(10)
os.path.exists(destination)
key2 = models.IntegerField()
self.master.columnconfigure(5, weight=1)
self.buffer.seek(0)
print(a_list)
a2.set_xticks([])
print(df)
MyMacro(indirect)
print(str(delta))
sum(map(lambda i: bool(i and i.pop(0) and i) + len(i), x))
MyButton2.grid(row=1, column=0)
list_of_dict.append(mydict)
s = np.sum(a)
output.close()
sum = foo()
test = df.head(1)
inst1.i = 4
float_to_str(5e-08)
Py_Finalize()
f(*a)
f2.write(Lines[i + 1])
cursor = cnx.cursor()
plt.figure(figsize=(12, 6))
x += 1
time.sleep(1)
a = 1 if b else 0
randprime(a, b)
wsgi_handler.run(wsgi_app)
print(a[i] - a[i - 1])
dict((x, x * x) for x in range(10))
rule_list.append(value())
__authentication_required
plt.show()
tfidf_matrix = tfidf.fit_transform(corpus)
doc_topic_distrib = lda.transform(tf)
list(set().union(*x))
print(is_arr_in_list(mylistarr[2], mylistarr))
S = [fnx() for c in range(5)]
self.Show(True)
ax.set_xlim([0, x.max() + 1])
ob.stackoverflow()
plt.plot([1, 2, 6, 4])
a180[0, 0, 0]
[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]
y = np.array([2, 1, 5, 2])
urllib.parse.urlencode(query_pairs)
out.write(f.read())
t = list(set(q) & set(w))
print(exit)
self._socket.close()
s = pygame.Surface((16, 16), flags=pygame.SRCALPHA)
G.remove_edges_from(G.selfloop_edges())
timetup = time.gmtime()
self.var1 = self.var1 + self.var2
gray = cv2.imread(image_path, cv2.CV_LOAD_IMAGE_GRAYSCALE)
print(interleave(a, b))
stdin.flush()
pyplot.locator_params(nticks=4)
L = [1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, -1, 1, -1]
date.replace(tzinfo=pytz.utc)
now = datetime.datetime.now()
self.window.add(self.image)
float(value)
mtransforms.Transform.__init__(self)
newlist.append(v + str(count + 1) if totalcount > 1 else v)
apply_labels(h, labels)
df2 = pd.read_csv(StringIO(txt2))
plt.imshow(flip_ud_lena, cmap=plt.cm.gray)
show()
canvas.Canvas.__init__(self, *args, **kwargs)
print(dog.lemma_names())
foo.save()
tk.Canvas.move(self, *args, **kwargs)
c = b
print(s.groupby([s.index.weekday_name, s.index.hour]).sum())
fig, axes = plt.subplots(nrows=2)
datetime.strptime(value, format)
print(parser.parse_args())
urllib.request.install_opener(urllib.request.build_opener(LowLevelHTTPHandler))
client_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
yshape = list(data.shape)
list(x * x for x in range(10))
oldperson.hello()
func(one=1, two=2)
a = np.arange(1, 7)
diffs = dict((k, ranks2[k] - ranks1[k]) for k in dict1)
kernel = np.uint8([[1, 1, 1], [1, 10, 1], [1, 1, 1]])
numpy.atleast_2d(x[x[:, (2)] == 0])
indices = np.empty((m * n, 8), dtype=int)
heapq.heapify(h)
json.loads(dictString)
fp.write(part.get_payload(decode=True))
open(filename, *args, **kwargs)
e.click()
decoded_text = cipher_suite.decrypt(encoded_text)
ax.get_xaxis().get_major_formatter().set_useOffset(False)
dict((j, locals()) for _ in range(i))
G = nx.DiGraph()
print((a, b, c, d))
s.readline()
increments.append(onediff[i])
msg.attach(part1)
math.sqrt(dotproduct(v, v))
ax.yaxis.set_major_formatter(matplotlib.ticker.ScalarFormatter())
ssh = paramiko.SSHClient()
r.status_code
data = np.random.uniform(-1, 1, 44100)
combo.set_active(0)
C4.bar()
a.sort(key=w.__getitem__)
abort(404)
canvas.tag_lower(secondRect)
c.f()
self.figure.subplots_adjust(right=0.9)
obj_list.append(obj)
lst = ast.literal_eval(strab)
np.zeros(s)
w.show()
cur = con.cursor()
HELLO
__repr__ = __str__
Bbins = np.linspace(B.min(), B.max(), 10)
event.save()
view(request, *args, **kwargs)
pygame.display.flip()
browser.show()
response = urllib.request.urlopen(url)
cache.commit()
plt.plot(x, y)
np.all(i for i in range(10))
column_widths += [len(cell)]
(items + (item,) for items in product(*args[:-1]) for item in args[-1])
quat_multiply(a1[1, 2], b1[1, 2])
f = os.path.join(path, filename)
np.median([0, 2, 6, 5, 4])
clean_data = pd.concat([x, y], 1).dropna(0)
self.x1 = self.x0 + self.width / 2
wb = excel.Workbooks.Open(fname)
df.drop(rows)
y[x.argsort()] = np.arange(x.size)
[randint(1, 9999) for _ in range(randint(50, 200))]
print(Counter(zip(words, words[1:])))
fig, ax = plt.subplots()
optionmenu.configure(width=yourwidthhere)
fig, ax = plt.subplots()
n, bins, patches = plt.hist(x, histedges_equalN(x, 10))
app = Flask(__name__)
[i for i, x in enumerate(lst) if x == item]
sess = tf.Session()
self.assertEqual(expresults, results)
plt.show()
cursor = conn.cursor()
name, email, phone_numbers = record[0], record[1], record[2:]
df = pd.DataFrame(np.random.random((N, M)), index=dates)
ax.set_yticks([-1.25, -0.75, -0.25, 0.24, 0.75, 1.25], minor=True)
id = Column(Integer, primary_key=True)
print(repr(ordliste))
main()
ax.set_ylim(ymax=100)
B = [0, 0, 1, 1, 1, 1]
print(sorted(words) == words)
writer.writerow(row)
G.nodes()
self.treeview.set_search_column(0)
ax1 = fig1.add_subplot(111)
number += 1
foo()
s.play()
sys.modules[__name__].__dict__.clear()
fig.canvas.draw()
x * (x > 0)
loop.run_until_complete(do_work(q))
linesamples.add(int(4 * i + 2))
fig = plt.figure()
df = df.reset_index(level=[0, 1])
my_RDD_dictionaries = my_RDD_strings.map(json.loads)
fig = plt.figure()
print(os.path.join(root, file))
print(args)
print(match.groups())
self.setLayout(layout)
c.py
endDate = models.DateField()
A.ravel()[np.random.choice(A.size, c, replace=False)] = np.nan
myFunction = lambda x, y: x * y
_ = list(map(lambda x: result.extend(x), res))
b in l[l.index(a):]
text = models.CharField(max_length=200)
b = a[:]
signal.signal(signal.SIGCLD, signal.SIG_DFL)
days = (roundedA - roundedB).days
list(product(*([0, x] for x in stuff)))
client.connect(myhostname, theport, myuser, thepass)
print(boop)
func.argtypes = [ctypes.c_char_p, ctypes.c_char_p]
logger.addHandler(fh)
ax = fig.add_subplot(111)
min(i for i in range(len(L)) if L[i:i + len(key)] == key)
Py_Finalize()
file.write(capitalised)
print(b.most_common(1))
print(demo.multiply(2.0, 4.0))
axes[1].plot(x, i * np.cos(x))
datetime.combine(d, datetime.min.time())
palette.append((255, 255, 255))
ax.bar(theta, counts, width=np.pi / 6, color=colors, alpha=0.5)
25.4 / 10 * (1 / 2.54)
t = threading.Thread(target=worker, args=[data])
print(sort_dict_by_list(a, b))
np.random.seed(42)
conf.py
ax.set_yticklabels(people)
web.load(QUrl(url))
y = random.randint(0, walnut.size[1] - 1)
weekly = map(sum, grouper(7, visitors, 0))
cardsdiscarded += 1
id = db.Column(db.Integer, primary_key=True)
{b.pop(0): {b.pop(0) for _ in range(1)}}
driver = webdriver.Firefox()
app.MainLoop()
signal.signal(signal.SIGINT, signal.SIG_DFL)
form = cgi.FieldStorage()
app.logger.addHandler(handler)
my_screenmanager.add_widget(screen2)
print(xcoord)
new_df[df.isnull()] = np.NaN
lxml.etree.Comment
time.sleep(poll_period)
a = dict((hash_counting_int(x), []) for x in range(10))
results.append(make_comp_func(i, j))
array([False, True, True, True, True, True, False], dtype=bool)
conn.connect()
do_something_with_a_and_b
pyglet.app.run()
main()
ax1 = fig.add_subplot(111)
resolved_url = resolve_url(login_url or settings.LOGIN_URL)
a.withdraw()
s.quit()
498, 410
sys.exit(app.exec_())
iter = (i for i in range(50))
httpd.serve_forever()
numpy.linspace(10, 20, 5, endpoint=False)
views.py
zip_longest(fillvalue=fillvalue, *args)
s.get_data()
httpd.shutdown()
result = []
match.group(1)
HttpAuthenticated.__init__(self, *args, **kwargs)
self.get_paginated_response(serializer.data)
a.a().method()
ipixel = im.getpixel((x, y))
x = collections.deque(5 * [0], 5)
Following.objects.filter(follows=self).count()
print(a, b, c, d, e, f)
waitress.serve(demo_app)
root = Tkinter.Tk()
plt.show()
pool.close()
textbuffer.select_range(match_start, match_end)
G.add_node(1)
self.process = subprocess.Popen(self.cmd, shell=True, preexec_fn=os.setsid)
entry.clear()
fs.start()
assert set(a) == set(b)
result = json.loads(output)
result_dict[x.key].append(x.value)
xi = np.arange(len(x))
print(s1, len(s1))
wx.EvtHandler.__init__(self)
keep.add(onemorevalue)
smtp.sendmail(sender, recipients, themsg)
df.apply(outer_product)
node.update(value)
result.appendlist(key, value)
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cookie_jar))
tornado.ioloop.IOLoop.instance().start()
df.dtypes
processHeader(f.readline())
now = dt.datetime.now()
X /= X.std()
ax.xaxis.set_major_formatter(FuncFormatter(lambda tick, _: get_day(tick)))
b = np.array([2, 1, 1, 1, 1])
print(img.size)
print(repr(line))
b[:, :, (some_mask == 1)]
file.write(part.get_payload(decode=True))
job = Job.objects.get(pk=1)
driver = webdriver.Chrome()
conn.perform()
sizer = wx.BoxSizer(wx.VERTICAL)
df.index[0], v.iloc[-1]
driver = webdriver.Firefox(firefox_profile)
__init__.py
[(5, 6), (6, 7)]
soup = BeautifulSoup(html)
np.array(x.tolist())
self.l.append({})
dateutil.parser.parse(node.value)
self.f = args[0]
logging.Logger.__init__(self, name)
p = Process(target=f, args=(q,))
self.sizer = wx.BoxSizer(wx.VERTICAL)
QtCore.QModelIndex()
df.dtypes
pool = Pool(5)
plt.plot(A, B)
app.run()
__main__.py
a = np.random.rand(n, m)
entity1_id = Column(Integer, primary_key=True)
diff_as_html = ghdiff.diff(md1, md2)
p(i - 1) / 2 + p(i + 2) / 2
help(module)
Pdb().set_trace()
time.sleep(2)
tex.pack(side=tk.RIGHT)
cettime.isoformat()
content = response.content
self._is_running = False
mask = cv2.bitwise_or(mask1, mask2)
http_server.listen(8080)
len(data) == 0
turtle.forward(size)
new.setdefault(key, []).append(temp)
do_something()
data, addr = sock.recv(1024)
item = list[2][2]
True
contains_vectorized(geo_polygons, geo_points[:, (np.newaxis)])
func(x, y, z, a, b, c)
print(list(keep_n_dupes(lst, 2)))
myobj[5] = 1
values = np.array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4])
myParent.__init__(self)
G.add_edge(1, 2)
im.update()
s.read()
ans = math.factorial(N)
ssh.close()
lines = [line.strip() for line in file]
Py_Initialize()
db = mongo.db
show()
queue.append(clientsocket.recv(1024))
test_writer = tf.train.SummaryWriter(this_test)
main()
plt.imshow(frames[k], cmap=plt.cm.gray)
a_cursor.execute(sql, (val1, val2))
ti, xi = np.meshgrid(ti, xi)
f.close()
sleep(20)
self.stack.append(len(self.get_item()) - 1)
type(a.tolist())
print(str(uuid.uuid4())[:8])
results.append(a_dict[id])
bin((1 << 7) - 1)
psutil.get_pid_list()
HTMLParser.__init__(self)
print(para_group_demo.sum(df.a, df.b))
DateR = date.compile()
np.random.shuffle(idx)
fig = pyplot.figure()
{k: dict_[k] for k in keys}
self.entry.pack()
imscatter(x, y, image_path, zoom=0.1, ax=ax)
plot(tmp.min(axis=0))
ucontent = str(content, encoding)
val = int(input, 16)
f_out_intkeys.write(line)
f_out_quot.write(line)
f_out_frb.write(line)
f_out_dtwrld.write(line)
driver = webdriver.Chrome()
foo()
print(sum(map(d.get, itertools.takewhile(lambda key: key != 5, d))))
s = sys.stdout.getvalue()
X, Y = np.meshgrid(x, y)
signal.alarm(seconds)
do_stuff_with_two_lines(previous_line, current_line)
print(json.dumps(doc, default=ComplexHandler))
x = x + c
dict_setitem(dct, key, value)
z.update(y)
self.listbox.insert(0, option)
next(itertools.islice(cpy, index, index + 1))
sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)
values = np.random.rand(len(indices))
self.ProgressBar.SetRange(event.total)
plt.xlim(0, 1)
ui.show()
X_plot = np.linspace(0, 1, 100)
main()
img_io = StringIO()
{{form.errors}}
sns.set(**kwargs)
output.write(line)
[s[i:i + width] for i in range(len(s) - width + 1)]
plt.clf()
logger.addHandler(progress)
self.result_queue.put(result)
logging.Handler.__init__(self)
out = process.stdout.read(1)
plt.tight_layout()
b = int(a)
sys.path.append(YOUR_PATH)
browser.load(QtCore.QUrl(url))
row = np.random.randn(100)
tuple_list[i] = a, new_b
object_id = models.PositiveIntegerField()
data2 = np.asarray(data2)
isinstance(os, types.ModuleType)
df = pd.DataFrame(d)
word[len(word):-len(word) - 1:-1]
box.focus_set()
plt.show()
sum(map(int, item))
len(x)
print(string[i:j])
tree = ElementTree.fromstring(xml, parser)
dt_aware = localtz.localize(dt_unware)
background_label.image = background_image
print(every6(example_string))
Goodbye
do_stuff()
plt.axhline(i, color=color)
self.nout += 1
widget2.update_idletasks()
print(cv.GetCaptureProperty(stream, cv.CV_CAP_PROP_FRAME_COUNT))
self.update(dict(*args, **kwargs))
Pool()
a = np.vstack((a, np.array([[1, 1, 0, 0, 0, 0, 0, 1]])))
ssh = paramiko.SSHClient()
a + b
driver = webdriver.Firefox()
cur.close()
ax.set_xlim(0, 1.4)
srcname = os.path.join(src, name)
x = random.randint(0, walnut.size[0] - 1)
bar.buzz()
xl.Quit()
list_size_2 = numpy.array(list_size_2)
response
fd = sys.stdin.fileno()
l.set_option(ldap.OPT_X_TLS_DEMAND, True)
fig = plt.figure()
dict.clear()
events[-1].append(line)
exec(open(filename).read())
sorted(x, key=functools.cmp_to_key(customsort))
plt.show()
draw.line((x1, y1, x2, y2), fill=col, width=1)
testsite_array.append(line)
isinstance(bar, types.UnboundMethodType)
new_list = list(generate_items)
time.sleep(5)
a - b
print(form.instance.id)
print(f2.readline())
print(count_rec(0, 0))
auth.set_access_token(access_key, access_secret)
text = row[1]
python - mfoo.bar
self.thread.start()
form.fileName.file.save(file_path)
handle.flush()
np.repeat(uniques, np.clip(count, 0, 2))
sys.stderr = sys.__stderr__
1 / 0
wx.StaticBitmap(panel, -1, png, (10, pos), (png.GetWidth(), png.GetHeight()))
ax.set_axis_off()
values(np.arange(len(A)))
[(j + i) for i in strings for j in listSubstrings if i.find(j) > -1]
layout.addWidget(self.splitter)
do_something(line)
parser = argparse.ArgumentParser()
df.mask(np.triu(np.ones(df.shape)).astype(np.bool))
objectA.delete()
sys.modules[name] = module
json.loads(list_dump)
b = bytes([x])
id = Column(Integer, primary_key=True)
brr.sort()
defaults.update(kwargs)
datetime.combine(date.today(), exit) - datetime.combine(date.today(), enter)
app = Flask(__name__)
s = map(str, numList)
app = QtGui.QApplication(sys.argv)
deleteL[::L[0]]
a = numpy.ones((2, 4))
df.gdp.drop(df.gdp.shape[0] - 1, inplace=True)
[myList[i] for i in sorted(indices)]
self.SetDiagram(self.diagram)
turtle.right(angle)
fh.write(output_from_parsed_template)
dict.__init__(self, *args, **kwargs)
str(1056) is str(1056)
t.start()
plt.legend()
a[arange(2), 0, 0], b[arange(2), 0, 0] = b[arange(2), 0, 0], a[arange(2), 0, 0]
ws.close()
pprint(sorted_dict)
buffer1[pos:pos + len(buffer2)] = buffer2
self.data[key]
np.any(a == 2, axis=0)
self.layout = QtGui.QHBoxLayout()
A.shape
ax.set_theta_offset(np.radians(90))
app.register_blueprint(bp)
conacatData = [(x[0] + x[1]) for x in testdata]
web.load(QUrl(url))
self.write(figdata.getvalue())
pool = mp.Pool(processes=1)
options, args = parser.parse_args()
logger.addHandler(file_handler)
[b, c, d, e, f]
print(instance.ip_address)
[1, 0, 1, 1, 0]
cls(wfd, bfd, wildfd, tfd, ffd)
p.start()
it = iter(the_list)
f(6)
t.render(c)
[2, 2, 5, 7, 7]
plt.plot(x_new, ffit(x_new))
im.size
msg.attach(part1)
setattr(cls, key, wrapper(value))
myList = []
print(df)
admin.site.unregister(User)
self.testButton.clicked.connect(self.change_text)
drand48()
s = socket.socket()
time.sleep(1)
list = list + [(0) for _ in range(4 - len(list))]
list_of_unique_dicts = list(np.unique(np.array(list_of_dicts)))
self.view.setEditTriggers(QtGui.QAbstractItemView.NoEditTriggers)
mlab.show()
image = image.astype(np.uint8)
print(my_list[0])
help(foo.bar)
response = urllib.request.urlopen(url)
heapq.heappush(heap, (row[1], row))
urllib.request.install_opener(opener)
x = list(range(1, 10))
self.assertEqual(forty_two, 42)
ser.close()
ax.errorbar(theta, r, yerr=1, xerr=0.1, capsize=0)
suite.addTest(unittest.defaultTestLoader.loadTestsFromName(t))
df
s.strip()
table.horizontalHeader().setStretchLastSection(True)
self.master.destroy()
a.foo = 2
os.write(fd, data)
idx = where(abs(A[:, (newaxis), :] - B).sum(axis=2) == 0)
screen = pygame.display.set_mode((100, 100))
start_date = timezone.now().date()
x1, x2 = np.nonzero((diffs < tol).all(2))
[random.choice(xs) for _ in range(sample_size)]
second_column = [row[1] for row in a]
serializer.save(user_id=15)
Response(serializer.data)
list(self.__dict__.keys())
result = np.empty_like(arr)
(A != 0).cumsum(1)
models.DateTimeField.to_python(self, value)
dialect = csv.Sniffer().sniff(f1.read())
self.variable_evidence.arrays.append(lambda : self.basic_in)
print(regx.findall(content))
self.frame.pack_propagate(False)
a = numpy.array(list(range(10)))
A_from_python()
id = Column(Integer, primary_key=True)
fp.close()
self._socket.send(bytes)
np.allclose(a.data, b.data)
print(str(x))
c.save()
self.log_message(format, *args)
len(obj)
InfoDF = pd.concat([InfoDF, tempDF])
line = proc.stderr.readline()
rgb = np.empty_like(hsv)
self.cj = cookielib.CookieJar()
img2 = img.copy()
ngrams(string1, n) & ngrams(string2, n)
offset = cet.utcoffset(dt, is_dst=True)
[mylist[cumlist[i]:cumlist[i + 1]] for i in range(len(cumlist) - 1)]
streams = [data[:, (stream_index == i)].ravel() for i in range(k)]
len(L) == len(E)
app.db = db
app.processEvents()
self.get()
[1, 2]
dt = datetime.datetime(2012, 1, 1, 0, 0)
ax1 = fig.add_subplot(111)
pprint(data, indent=4)
sum(array[mask])
x + 1
extension = guess_extension(guess_type(url)[0])
data = data[tuple(ind)]
parser.feed(your_html_string)
print(now + dateutil.relativedelta.relativedelta(months=-1))
ax.set_xticklabels(xlabels)
nanargmax(a)
data = f.read()
[i for i in l if re.search(s, i)]
num * X(X, b - 1) if num > 0 else 1
INF = _Infinity()
print(kmeans.cluster_centers_)
print({k for k, v in list(counts.items()) if v >= 2})
msg.attach(plain_text)
driver = webdriver.PhantomJS()
print(my_string)
main()
Response(serializer.data)
row.pop()
time.sleep(2)
img = c.getImage()
string.printable
operator.itemgetter(*b)(a)
os.makedirs(whatever)
img.write(artwork)
data[key]
widget = widget.get_parent()
picture.putpixel((x, y), new_color)
file.seek(0, 2)
result = [foo(p1, p2) for p1 in people for p2 in people]
np.transpose(np.nonzero(b))
factor.P()
whos
print({k: (x.get(k, 0) + y.get(k, 0)) for k in set(x) & set(y)})
my_variable,
app = Eve(auth=globalauth.TokenAuth)
time.sleep(1)
y = tuple(x)
array([[1.0, 1.0], [1.0, 1.0]])
getattr(obj, name)
plt.plot([1, 2])
engine = innodb
app.logger.addHandler(file_handler)
proc = subprocess.call(command, stderr=subprocess.OUTPUT)
ax.set_xticks(ind + width / 2)
f()
lines.append(line)
dates.year
widget.show()
len(bin(10)) - 2
plt.yticks(list(range(y.max() + 1)), labels)
list(self.keys())
r = requests.post(url, data=json.dumps(payload), headers=headers)
response = requests.get(url, params=query)
tree = tree.getroottree()
app = Flask(__name__)
os.rename(original, output)
orderdict = dict((y, x) for x, y in enumerate(wantedorder))
a = np.random.random(20).reshape(4, 5)
d.setdefault(key, []).append(val)
pool.join()
{{tag}}
NULL
t.total_seconds()
int()
QtCore.QCoreApplication.instance().quit()
mask = np.ones(len(data), np.bool)
slices = [sli for sli in (list(islice(it, 0, i)) for i in seclist) if sli]
print({k: (x.get(k, 0) + y.get(k, 0)) for k in set(x)})
(string_to_expand * (length / len(string_to_expand) + 1))[:length]
my_string = my_string.lower().split()
s = s[::-1]
df1.columns = pd.MultiIndex.from_tuples(new_cols)
Base.metadata.create_all(e)
client.Resolver.__init__(self, servers=servers)
print(is_summer_time(aware))
b = sorted(sorted(a, key=lambda x: x[0]), key=lambda x: x[1], reverse=True)
t.cancel()
map(add, a, itertools.repeat(2, len(a)))
finder1.apply_freq_filter(2)
data = np.arange(100, dtype=np.int)
diff = set(zip(df2.Buyer, df2.Quantity)) - set(zip(df1.Buyer, df1.Quantity))
datesDF = pd.DataFrame(dates)
threading.Timer(1, foo).start()
n[1]
print(kwlist)
a.name()
sleep(1)
p.stdout.readline()
Parent.__init__(self, x)
list(d.items())
subtraction = int(start_big) - int(start_small)
pcolor(my_array, cmap=cmap, norm=NoNorm())
r.clipboard_clear()
b = [1, 2, 5]
x = np.lib.stride_tricks.as_strided(y, shape=(A, B), strides=(n, n))
os.makedirs(f)
plt.bar(x[i], y[i], color=cm.jet(1.0 * i / len(x)))
dict((v, k) for k, v in d1.items())[55]
button.setVisible(False)
print(tailq.get())
app = Flask(__name__)
ordered = list([x for x in ordered if x not in unordered])
next(c)
app = Flask(__name__)
self.assertEqual(e.args[0], 42)
result = pool.map_async(task, [(x, q) for x in range(10)])
some_queryset[:length] if length else some_queryset[:]
listmatrixMap(add, a, b)
session = requests.session(cookies=cookies)
new_list.append(v)
list(calendar.day_abbr)
compare_lists(a[1:], b[1:])
msvcrt.getch()
(5)()
f.close()
cleaned_list = list(filter(is_not_thing, some_list))
pylab.xlim(xmin=0)
fh.close()
help(f)
money = Column(Integer, default=100)
sp.stdin.close()
p.communicate(input=str)
print(x)
df.iloc[idx]
MyClass.call_me()
some_value
imgtk = ImageTk.PhotoImage(image=im)
zeroMatrix = [zeroArray[:] for i in range(Np)]
utc_dt + timedelta(hours=longitude / math.pi * 12)
np.sqrt(val / 2.0 / a.shape[0])
transaction.commit()
self._fp.close()
re.sub(r, replacer, string)
bundle.obj == bundle.request.user
soup = BeautifulSoup(html_doc)
ax.yaxis.set_major_formatter(matplotlib.ticker.ScalarFormatter())
lock.release()
a = np.array([1, 2, 1, 1, 2])
wait()
self.pressed.connect(self.update)
df.index = pd.MultiIndex.from_tuples(df.index)
print(spectra_list[0])
assert np.allclose(expected, result)
print(t.timeit(5))
fig = plt.figure(figsize=(10, 8))
imp.get_suffixes()
self.seek(0)
views.py
plt.draw()
[i for i in range(2, 25) if f(i)]
print(numpy.array([n.activate(x) for x, _ in d]))
b = ma.masked_array([0, 1, 2, 4], [True, True, False, False])
letterGoodness = dict(zip(string.ascii_uppercase, letterGoodness))
dict(d)
np.add.reduceat(a, w[:-1]).astype(float) / np.diff(w)
a.symmetric_difference(b)
atexit.register(whatever)
enternum.pack()
config = ConfigParser.ConfigParser()
map(lambda x: x[0] == 1, a_list)
closest_date = min(later, key=lambda d: get_datetime(d[0]))
process(line)
time.sleep(SPINUP_WAIT_TIME)
self.master.destroy()
session.commit()
self.button.setContextMenuPolicy(QtCore.Qt.CustomContextMenu)
print(sum((a - i) ** 2, 1).argmin())
print(mywrap(s, 10))
sorted(versions, key=LooseVersion)
a[0] * b[0] + a[1] * b[1] + a[2] * b[2]
c.setopt(c.WRITEFUNCTION, storage.write)
extension = guess_extension(guess_type(url))
show(layout)
temp = temp.reshape(1, -1)
np.delete(myarray, np.r_[tuple(mylist)])
sockOutfile.write(readRequest)
pd.DataFrame((d2 - sums2 / n) / stds2 / n, df.columns, df.columns[k:l])
time.sleep(5)
sys.exit(1)
fig, ax = plt.subplots()
self.setFixedSize(pic.size())
screen = win.get_screen()
print((i[0] + 1, i[1]))
_epoch + timedelta(days=ordinal - 1)
print(a[150001, 2])
A.__init__(self, *args, **kwargs)
data = cur.fetchone()[0]
1, 1, 1, 1, 1, 1, 0, 0, 20160224, 20160226
datetime.datetime.fromordinal(t.toordinal())
D = np.random.random_integers(0, 1, (5, 5))
combs.append((x, y))
print(soup)
{2, 4, 10}.issubset(chain.from_iterable(x))
result.append(s)
a = np.arange(10)
mylist = []
sys.__repr__()
photo = models.ImageField(upload_to=photo_path, blank=True)
print(new_data.shape)
img_file.save(new_image_name)
text.set_text(s)
out[idx, idx] = A[idx, idx]
n_grams = CountVectorizer(ngram_range=(1, 5))
QWebPage.__init__(self)
[0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1]
ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])
[(word[:i] + word[i + 1:]) for i in indexes]
locale.currency(188518982.18)
print(sys.executable)
lambda x: sum(f(x) for f in terms)
sys.__stdout__.write(data)
points = [(i, j) for i, j in zip(x, y)]
inprogress.append(taskindex)
icon_theme = gtk.icon_theme_get_default()
ax.set_yticks(majorticks, minor=False)
ssc.start()
datetime.date(year, month, day)
print([cls.__name__ for cls in X.mro()])
blah = models.IntegerField(choices=BLAH_CHOICES)
sanitised_filename = sanitise_filesystem_name(filename)
X = [i[0] for i in Counter(df.X).most_common()]
data = [[float(x) for x in y] for y in data]
print(flatten(list))
fronts = np.empty(len(M), int)
name = models.CharField(max_length=128)
sio.readlines()
plt.loglog(list(range(100)))
ax.xaxis.set_tick_params(size=0)
out = idx[mask].argsort()[unqID]
token = token_handler.create_token(request, self.refresh_token)
time.sleep(0.1)
print(sys.path)
heapq.heappush(self.heap, (pri, d))
print(strings.group(0))
views.py
t.to_pydatetime()
fcntl.fcntl(fd, fcntl.F_SETFL, fcntl.fcntl(fd, fcntl.F_GETFL) | os.O_NONBLOCK)
a[idx]
locals() is globals()
window = NSApp.mainWindow()
tuples = [(x, y) for x in L1 for y in L1 if x != y]
emissions = [[float(x) for x in nextline().split()] for i in range(n)]
ImageDraw.Draw(halo).text(position, text, font=font, fill=halo_col)
bit_array[25] = 1
self.fd.seek(offset)
foo = Foo()
self.html_file.close()
widget.show()
abs(g(a + b * f(c)) + g(a - b * f(c)) - 1) < 1e-10
min(s[max(0, i - 1):i + 2], key=lambda t: abs(ts - t))
crustFrame.Show()
asyncore.dispatcher.__init__(self)
[x_y_z for x_y_z in a if x_y_z[0] + x_y_z[1] + x_y_z[2] > 6]
statement.parseString(text)
A = np.arange(10)
layout = QtGui.QVBoxLayout()
firsttwo = words[:2]
f1.close()
a = np.array(ulysses.split())
self.model.fetchMore()
demandimport.__file__
a = numpy.random.randn(100, 200)
df[df < 1] = 0
cookies = cookielib.LWPCookieJar()
__init__.py
text = models.TextField()
User[1] == {}
r = requests.get(url)
self.assertAlmostEqual(em(1, 2), 0.2188, 4)
b = tf.square(tf.matrix_determinant(a))
counts = np.bincount(id[mask1] - 1)
b.has_usable_password()
wjdata = json.loads(wjson)
elem.clear()
root = tree.getroot()
widget.deleteLater()
parent.remove(elem)
img.resize(width=scaled_width, height=scaled_hight)
id = Column(Integer, primary_key=True)
print(x)
new = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
setp(a, xticks=[], yticks=[])
f.name
data.setdefault(k, [])
ssh.connect(server, username=username, password=password)
print(type((1,)))
copy.deepcopy(self)
self.window.addstr(1 + index, 1, msg, mode)
list.sort()
psutil.virtual_memory()
partials.append([])
BlogComment.save()
url = opener.open(request)
int(self)
new_foo = filter_divisible_by_three(foo)
instance.new()
args = parser.parse_args()
ecef_cities = [geodetic2ecef(lat, lon) for lat, lon in cities]
new_pressures[-1] += p[index]
script.extract()
accum &= np.abs(a[:, (i)] - b[:, (i)].ravel()) < tol[i]
handler.setLevel(logging.CRITICAL)
df
u in G.neighbors(v)
cvtColor(im, imgrey, CV_RGB2GRAY)
self.cam.release()
words.append(random.sample(novel, 100))
{key: tuple(d[key] for d in dicts) for key in common_keys}
{key: obj.__dict__}
output_set = set(itertools.chain(first_list, second_list))
a == b
hist(x)
si.imgdata = im.tostring()
{{(game.description | safe | truncatewords): 65}}
(date(2015, 10, 7) - date(1, 1, 1)).days
time.sleep(self.delay)
print(daily_prices[2])
print(resp.status_code)
parser = etree.XMLParser(remove_blank_text=True)
plt.colorbar(im, fraction=0.046, pad=0.04)
osa.communicate(ascript)[0]
velcro.right(90)
print(len(S1), len(S2))
x = json2obj(data)
out[idx[:, (0)], idx[:, (1)]] = vals
QtGui.QWidget.eventFilter(self, source, event)
sys.path.insert(0, os.path.abspath(os.path.dirname(__file__)))
list(self.__graph_dict.keys())
values = np.sum(weights * features + bias)
frame.pack()
f_output.write(file_bytes.read())
A[:, (1)] *= 5.2
unittest.main()
fig = plt.figure()
pd.rolling_mean(pivot, 90, center=True, min_periods=1)
np.vstack((dst[idx], rows[idx], cols[idx])).T
session.add(h)
audio_array = audio_array.reshape((len(audio_array) / 2, 2))
self.data.config(yscrollcommand=self.scrollbar.set)
ax = plt.gca()
plt.colorbar(sm)
script = sys.argv[0]
values = [is_prime(x) for x in PRIMES]
print(df)
distance = [[[(0) for k in range(n)] for j in range(n)] for i in range(n)]
callable(fn)
sys.exit(0)
browser = webdriver.Firefox()
func(*args)
pprint.pprint(list(collection.aggregate(pipeline=pipeline)))
list(x)
print(readline.get_history_item(i + 1))
self.frame.Show(True)
self.queue.append(data)
print(a, b)
chars.extend(line)
file = jpgs[-1]
sleep(1)
column_label.show()
res0.remove(element)
x = session.query(Foo).all()
Employee.__init__(self, name, salary)
list(filter(filterfunc, l1))
recursion(0, 0)
dict(zip(student_names, average_of_all_assignments))
t.start()
args = parser.parse_args()
sum([True, True, False], False)
705.0, 690.0, 705.0, 680.0, 715.0, 705.0, 670.0, 705.0, 705.0, 650.0
afield = forms.ChoiceField(choices=INITIAL_CHOICES)
screen.fill((255, 0, 0), (self.x, self.y, 10, 10))
draw = ImageDraw.Draw(image)
list(reversed([i[0] for i in l[1:-1]]))
f(a, b).A
list.append(map(itemgetter(1), g))
self.label.pack(padx=10, pady=10)
cursor.execute(SQL)
print(df.reindex(idx))
np.allclose(B.todense(), B2.T)
response
deleteelem.getparent()[0]
[list(i) for i in zip(*theArray)]
fig = pl.figure()
G.add_path([0, 2, 5])
plt.show()
dt = datetime.datetime.fromtimestamp(float(datestring))
func(xy[0], xy[1], data)
print(str(i))
module_name = inspect.getmodule(s[1][0]).__name__
sorted_files.append(f)
json.loads(value)
c, d = np.meshgrid(a, b)
collections.defaultdict(nested_dict)
args = parser.parse_args()
leg = ax.legend()
hash_md5.update(chunk)
pyplot.ylim(ymin=0)
pool.join()
response = urllib.request.urlopen(req)
server.set_debuglevel(1)
self.fn(*args, **kwargs)
x.loc[(x.A >= 2.0) & (x.A <= 4.0)]
np.all(a == a.T)
-1 if not a or a.isspace() else a.index(a.lstrip()[0])
count[letter] = 1
ax = fig.add_subplot(111)
opener = urllib.request.build_opener(handler)
cursor = db.cursor()
foo[somestuff]
dict1.items() ^ dict2.items()
stdv.reset()
key = models.PositiveIntegerField()
grey_image = cv.CreateImage(cv.GetSize(frame), cv.IPL_DEPTH_8U, 1)
shutil.rmtree(dir)
utc_seconds = time.mktime(t.timetuple())
lst[(len(lst) + 1) / 2 - 1]
plt.figure()
a[x] + a[y]
self.cleaned_data
parser.parse_args(args)
df.describe()
integrate.quad(func, a, b, args=(y,))[0]
fig = plt.gcf()
a + (b - a) * self.random()
df
ax.scatter(xs, ys, zs, c=c, marker=m)
m = ctypes.c_int(x.shape[0])
plt.show()
self.window.add(self.image)
ioctl(fd, USBDEVFS_RESET, 0)
zipf.close()
np.random.choice(make_sampling_arr(n_k), m)
s.send(tmsg)
a[20:] = zip(*zip(a[20:], itertools.repeat(0)))[1]
instance.topping_set.clear()
ww.writeframes(new_frames)
ET.dump(root)
[c, d, f]
{{mywidget.css()}}
form_data = urllib.parse.urlencode(form_fields, doseq=True)
ConstantFunction(constant)
sum(b << k * 8 for k, b in enumerate(bytes))
plt.clf()
x.append(Foo())
app = QtGui.QApplication(sys.argv)
app.listen(8888)
suffix_array.sort(key=lambda a: content[a:])
Maybe(val)
matrix = matrix[0:100, 0:80]
print(new_url)
found_extensions.add(os.path.splitext(f)[-1])
a = numpy.linspace(-1, 1, 20)
u = np.sin(np.pi * x) * np.cos(np.pi * y) * np.cos(np.pi * z)
chart.Copy()
x = theano.shared(numpy.arange(10))
now += timedelta(minutes=1)
ranges.append((last_start, offset - 1, current_set))
my_dict[key] = indices
xmlOutput += self.dirToXML(os.path.join(root, subdir))
ax = pl.subplot(111)
self.__dict__.update(name_value_dict)
win.setWindowFlags(win.windowFlags() | QtCore.Qt.CustomizeWindowHint)
ndata = np.frombuffer(data, np.int8)
type(int(s))
[0, 0, 0, 17, 0, 0, 0, 40, 0, 0, 0, 0, 0],
__init__.py
app = QtGui.QApplication(sys.argv)
listWidget.setItemWidget(item, w)
result.update(dictionary)
corpus.sort(cmp=locale.strcoll)
info[1][1] == 4
np.random.seed(22)
df1 = df.iloc[:, :-1]
session.expunge(item)
list(unique_everseen(a, key=set))
hash(dumps(data))
self.__dict__.update(kwds)
[tmp.setdefault(name, len(tmp)) for name in names]
new_points = list(do_something_with(x, y, z) for x, y, z in surface.points)
self.assertAlmostEqual(em(2, 2), 0.4251, 4)
list(b)
z.append(matchobj.group(1))
[foo() for x in range(10)]
time.sleep(4)
plt.bar(list(range(0, 100)), x)
fig = pylab.figure(figsize=(12, 9))
mask = np.ones(len(a), dtype=bool)
lst = [(int(s) if s.isdigit() else s) for s in lst]
sys.stdout = sys.__stdout__
print(numpy.__path__)
random.shuffle(some_list_of_stuff)
type(n) is int
arr = np.dstack((r, g, b, a))
x.update([i])
numpy.arange(a.shape[0])[numpy.in1d(a, b)]
sock.bind((HOST, PORT))
tck = scipy.interpolate.splrep(x, y)
datenow = datenow.replace(hour=16, minute=0, second=0, microsecond=0)
data = pickle.load(fp)
axes[0].legend().set_visible(False)
playlists = [i[1] for i in list(radio.items())]
0.5 * (1 + tsr.erf((x - mu) / (sd * tsr.sqrt(2))))
a.extend(map(add, lst))
print([set(x) for x in bodylist])
-__init__.py
new_db.executescript(query)
b = a[:]
zip_longest(fillvalue=fillvalue, *args)
a[(labels.view(np.ndarray).ravel() == 1), :]
print(sys._getframe().f_code.co_name)
soup = BeautifulSoup(data)
p.wait()
MyObj2 = MyModel.objects.all()[index2]
plt.plot(X, Y1, lw=0)
samp_rate, data = scipy.io.wavfile.read(filename)
test_module2.py
plt.pause(1e-09)
draw = ImageDraw.Draw(circle)
timeit(lambda : list(assignments(12, 5)), number=1)
serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
file_handler.setLevel(logging.DEBUG)
foo(nonsene=True, blather=False)
byweekday = byweekday, byhour = byhour, byminute = byminute, bysecond
ax.set_xlim(0, 5)
os.path.splitext(fn)[1] != ext
a[i, j]
dfs = pd.concat(df_list)
np.random.seed(0)
user = User.objects.get(pk=uid)
cv2.waitKey(1000)
delete_keys_from_dict(v, lst_keys)
tk.Tk.__init__(self)
statuses = [a.wait(), b.wait()]
search = np.array([1, 2], dtype=e.dtype).view(dt)
[y for y in x.split() if len(y) > 2]
args = vars(parser.parse_args())
time.sleep(1)
a.take((1,), axis=1)
os.startfile(filepath)
self._tunnel()
writer = csv.writer(f)
BeautifulSoup(badString, markupMassage=myNewMassage)
result.append(elem)
fig = plt.figure()
print(p.match(input).groups())
dummy_event.wait()
datetime.datetime(2012, 1, 2, 0, 0, 0),
zeroMatrix = numpy.zeros((Np, Np))
points.append((x, y))
pickle.loads(encoded)
jsonify(x.serialize())
rd = dateutil.relativedelta.relativedelta(dt2, dt1)
Widget.__init__(self, parent)
s = set(fus_d.keys())
torfile.set_priv(torinfo.priv())
b = [(1 if i else 0) for i in a]
print(sum(1 for _ in takewhile(lambda x: x == l[0], l)))
q = multiprocessing.Queue()
df /= df.max()
form.show()
tk.Tk.__init__(self, *args, **kwargs)
[sum(combination, []) for combination in itertools.product(*outer)]
node
article.author = self.request.user
article.headline_set.all()
data[tuple(ind)]
isinteger(1)
itertools.combinations(items, 2)
dfasamplefive = dfa.sample(n=5)
server()
L[-1]
np.array([np.bincount(ii, r) for r in a.T]).T
result_queue = multiprocessing.Queue()
L[:] = [x for x in L if d[x] == 1]
years_dict[line[0]] = [line[1]]
w = Gtk.Window()
thiselem, nextelem = nextelem, next(licycle)
os.play()
print(form.username)
req = urllib.request.Request(url)
B = numpy.array(A)
Time.insert(0, time)
print(y, len(y))
print(conn.sock.getpeercert())
type(d)
s.seek(0)
pylab.plot(x)
self.d[index] = [value]
d + datetime.timedelta(days_ahead)
id = models.IntegerField(primary_key=True)
max_value = np.iinfo(im.dtype).max
self.close()
f = open(filename)
d.setdefault(m, []).append(k)
m.getch()
max(L[0], 0)
opener = urllib.request.build_opener(urllib.request.HTTPRedirectHandler)
vars()
print((lambda b: Y)(num))
t = xml.fromstring(s)
np.ma.array(x, mask=~bool_arr).argmax()
ax.add_patch(patch)
print(tavnit % tuple(columns))
show()
shape = np.array(a.shape)
(alist[i:j] for i, j in pairs)
pathqueue.join()
PyMODINIT_FUNC
root = tree.getroot()
request = requests.get(url, stream=True)
set(c).issubset(set(a))
numbers = [int(w) for line in lines for w in line.split()]
stdout, stderr = p.communicate()
new_col = sc.parallelize(np.array([20, 20, 20, 20]), n).map(int)
pythoncom.CoInitialize()
archive_path = os.path.abspath(sys.argv[0])
painter.rotate(90)
frozenset(some_item for some_set in some_sets for some_item in some_set)
myDict[key] = 20
seen.add(item)
print(values[:, (1)].sum())
self.handle_request()
width = win.winfo_width()
option.NPV()
key_name = lipis.key().name()
l2 = [0, 2, 5, 6, 8, 9]
print(statlib.__version__)
cs = axs[1].contourf(X, Y, zdata, levels=[-1, 0, 1])
divmod(c.days * 86400 + c.seconds, 60)
QApplication.restoreOverrideCursor()
myarray[x.group(1)] = [x.group(2)]
do_case0()
self.socket.sendall(length)
peewee.create_model_tables(models)
queue.start()
yi, zi = np.zeros_like(xi), np.zeros_like(xi)
help(CM)
ynew
superstrings.add(s)
((key, mydict[key]) for key in mydict)
profile.options.filter(id=option_id).count()
stack.pop()
np.choose(m, p_vec).sum(axis=1)
transsurface.set_colorkey((255, 0, 255))
B[:, :] = v.dot(A)
a = A[:, (j)]
smtp.login(username, password)
plt.tight_layout()
not bool(condition)
pl.show()
ax.set_yticks([-0.5, 0.5])
cur = con.cursor()
req.add_data(urllib.parse.urlencode(kwargs))
0 if len(cn) > 1 and cn[0][1] == cn[1][1] else next(iter(cn), [0])[0]
list1[:]
a1Note.play()
array[np.abs(array) < eps] = 0
False
d.get_state()
root.mainloop()
ax = fig.add_subplot(111)
file_handler.setLevel(logging.DEBUG)
thrs.append(threading.Thread(target=targ))
new_v = (this_array[indices[0] - 1] + this_array[indices[-1] + 1]) / 2
row_ind = [k for k, v in d.items() for _ in range(len(v))]
self.values.remove(item[1])
print(file_type(filename))
workers = [ageName(row[0], row[1]) for row in reader]
tty.setraw(sys.stdin.fileno())
User.__unicode__ = User.get_full_name()
self.blocks.clear()
pool.apply_async(func, callback=callback)
vars(your_object)
main()
frame.Show()
table = list(itertools.product([False, True], repeat=n))
out = pcorr[np.nanargmax(np.abs(pcorr), axis=0), np.arange(pcorr.shape[1])]
process.start()
len(l)
sys.exit(0)
source.yaml
out[:, (mask)] = B[:, :, ::-1][:, (mask[:, ::-1])]
root.focus_force()
bool(urlparse(url).netloc)
self.wfile.write(f.read())
Py_Finalize()
id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
platform.version()
data = f.read()
print(binascii.b2a_hex(os.urandom(15)))
fn_globals.update(globals())
f()
pycallgraph.start_trace(filter_func=filtercalls)
uniques = npi.intersection(x, y)
print(s[:117])
ifr.ifr_flags |= IFF_PROMISC
pickle.dump(_object, self.transport)
im = cv2.imread(sample)
email = db.Column(db.String(45), unique=True)
len(y[b])
len(result.index.names) > 1
njit(simulator)
box.show()
os.setsid()
end_time = time.time()
cursor = collection.find({})
make_xml().write(sys.stdout)
{{form.name()}}
s = input()
socket.listen(1)
do_something()
show(p)
id = Column(Integer, primary_key=True)
np.where(np.eye(A.shape[0], dtype=bool), A, A.T + A)
[0, 0, 0, 0, 0, 0, 0, 17, 0, 0, 0, 17, 0],
window.show()
lst[out.sum(axis=1) == 1]
res2 = numpy.array(list(zip_longest(fillvalue=0, *a))).transpose()
arr.reshape(-1, la)
sys.exit(-1)
df = pd.concat([df] * 10000).reset_index(drop=True)
print(e.message)
self.__dict__ = self
editAdForm = AdForm(obj=ad)
l = numpy.array(l, dtype=int) * 2
self._is_owned()
a.extend(list(range(0, 1000000)))
obj.do_something()
app = QtGui.QApplication([])
process(f)
np.linalg.det(individual.reshape(self.N, self.N)),
title = models.CharField(max_length=128, blank=True)
print(len(line))
int(value)
sns.barplot(x=data.index, y=data, palette=np.array(pal[::-1])[rank])
np.ascontiguousarray(c)
myFunc()
client.login(user, passwd)
dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)
yests = []
MyModel.BLAH_GOO_GOO_GAA_GAA
thread = threading.Thread(target=target)
self._server.show()
range_start + int(drand48() * range_size)
text_file.write(contents)
g.__code__ is f.__code__ is creator.__code__.co_consts[1]
len(net.layers[1].blobs)
plt.figure()
current_milli_time = lambda : int(round(time.time() * 1000))
button.grid(row=1, column=4)
shutil.copyfileobj(source, target)
print(arr[10])
self.user.delete()
datetime.datetime(2010, 5, 17, 0, 0)
xticks = ax.xaxis.get_major_ticks()
max(string.rfind(s) for s in findees)
self.panel.SetFocus()
print(list(map(tuple, list(od.values()))))
self.features = {k: v for k, v in list(kwargs.items())}
values = np.array([1, 1, 1, 1, 1])
pd.DataFrame(df.values[slc], df.index[slc])
id = Column(Integer, primary_key=True)
self.name = name
stdout, stderr = proc.communicate()
df.ix[0, 0]
dict((k, v.dropna().to_dict()) for k, v in compat.iteritems(data))
(a > 1).all() and (a < 5).all()
print(get_last_non_zero_index([0, 0, 0]))
tk.Tk.__init__(self, *args, **kwargs)
list(set(a).difference(b))[:100]
array([[0, 2, 6], [9, 4, 8], [7, 5, 1]])
print(s.to_string(index=False))
print(score_sum_py(pd.factorize(df.page_id)[0], df.score))
buffer += ser.read(1)
f(*args, **kwargs)
Base.prepare()
f.write(tempfile.read())
plt.show()
a = TestC()
os.rename(renamee, pre + new_extension)
max_index = max_sub[0]
raise ValidationError(self.errors)
setup.py
lst.append(x)
[True, False]
t.show()
ax.set_yticks(np.arange(nba_sort.shape[0]) + 0.5, minor=False)
f.readinto(data)
root = Tkinter.Tk()
[x[0] for x in groupby(L)]
obj.__dict__
fig = plt.figure(figsize=(1, 1), dpi=400)
module_a.py
topbottom = np.empty((1, 2 * im.shape[1]), dtype=np.uint16)
fake_restaurant.delete()
user = request.user
mpl.rcParams.update(saved_state)
process = subprocess.Popen(cmd, shell=True)
self.b.pack()
sum(map(str.islower, string))
p.cpu_percent(interval=1)
np.bincount(diag_idx.ravel(), weights=a.ravel())
plt.clf()
data = [str(round(float(fractions.Fraction(x)), 2)) for x in data]
bokeh.io.show(p)
my_string = my_string.translate(trans)
d = {}
Potion.all_potions.append(self)
plt.subplot(122)
sum(data) / n
result = list(chain.from_iterable(pattern.split(w) for w in input_list))
Py_Finalize()
fig, ax = plt.subplots()
np.full((10, 5), list(vals))
[x for x in k if x in kDash]
cv2.waitKey(0)
temp = temp[1:]
print(os.__file__)
print(np.squeeze(a))
print(s.format(*x))
np.random.shuffle(ages)
file.close()
plt.ylim(0.5, 4)
candlestick(plt.gca(), quotes)
grid.flat[np.flatnonzero(mask)[second_mask]] = 100
leadingzerocounts[0] += 4
new_df = old_df[list_of_columns_names]
data = data.astype(dt)
rdd2 = sc.parallelize([4, 5, 6])
oldstdout = sys.stdout
response.url
x = np.arange(10)
gender = models.BooleanField(choices=BOOL_CHOICES)
server.start()
self.obj = obj
int(Decimal(2))
print((f.__name__, timeit.timeit(f, number=1000)))
k[v.index(max(v))]
assert datetime.datetime.now() == datetime.datetime(2012, 1, 14)
x = [k] * len(v)
ax = fig.add_subplot(2, 1, 1)
f.truncate()
msg.attach(part2)
shutil.copyfileobj(source, target)
time.localtime(time.time())[2]
web.input(**my_args)
id = db.Column(db.Integer, primary_key=True)
html_decoded_string = parser.unescape(html_encoded_string)
print(response.read())
[1, 2] == sorted([2, 1])
f(0, 1, 0)
print(current_credentials.access_key)
getattr(mod, class_name)
line(res, vertices[0][0], vertices[1][0], color, 5)
Y[X == X.max(axis=0)].reshape(X.max(axis=0).shape)
pdb.set_trace()
[2.29, 47.77]
[2.01, 57.28]
[2.61, 66.82]
[2.49, 85.85]
[2.55, 104.9]
[2.65, 114.47]
sess = tf.Session()
QtGui.QMainWindow.__init__(self, parent)
df = pd.read_csv(data, delim_whitespace=True)
root.mainloop()
rand_numbers = np.random.random(5)
not bool
ch.flush()
encapsulated()
deletemylist[:n]
sys.stdout = capturer
procs[-1].start()
p.stdout.close()
np.testing.assert_allclose(res1, res2)
print(i, d[i])
ax.autoscale(False)
self.statusitem.setHighlightMode_(1)
self.table = QtGui.QTableView(self)
os.path.join(directory, filename)
A = np.delete(A, 2, 1)
os._exit(1)
rivers = np.ma.masked_where(rivers == 0, rivers)
event.Skip()
self.func = func
assert add(a, b) == a + b
new_index = random.randrange(0, len(data))
socketIO.wait(seconds=1)
ssh = paramiko.SSHClient()
ax1 = fig.add_subplot(121)
self.client.connect(self.host, self.port)
Py_DECREF(mylist)
HiddenFormMixin.__init__(self, *args, **kwargs)
self._request = urllib.request.urlopen(url)
plt.show()
student.courses[c.title] = form[c.title].data
proc.kill()
mylist.append((pair[0], pair[1]))
print(start.date())
r.wait()
pd.DataFrame(a).fillna(0)
print(varname(spam))
d[key] = value / 2
self.__dict__.update(*args, **kwargs)
print(repr(p.value))
min(min(p[1:]) for p in PlayerList)
solve([sigma * (y - x), x * (rho - z) - y, x * y - beta * z], [x, y, z])
td2 = datetime.timedelta(hours=t.hour, minutes=t.minute, seconds=t.second)
b = [(i + 1) for i, (x, y) in enumerate(zip(s, s[1:])) if y > x + 2]
subplot(4, 1, 4)
f.seek(max(fsize - 1024, 0), 0)
tile_frame.pack()
time.sleep(0.5)
time.sleep(1)
print(type(img_ipl))
x += 1
repr(self.dictify())
print(json.dumps(data, sort_keys=True, indent=4))
a.seek(0)
a = [1, 2]
itemgetter(*wanted_keys)(my_dict)
np.random.seed(0)
print(map(itemgetter(1), g))
get_key(d, 2)
do_something_else()
print(p.stdout.read())
x[1:4:2, 1:4:2]
self.show()
st.norm.cdf(1.64)
ax.set_xticks(np.arange(n) - 0.5)
map(itemgetter(0), sorted(list(dct.items()), key=itemgetter(1), reverse=True))
pprint(combine(l))
opener = urllib.request.build_opener(urllib.request.HTTPHandler)
s = fp.read()
client.server_receive_file(binary_data)
func(**args)
result = db.engine.execute(sql)
r.raw.read(10)
self.items = set(items)
L = [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 2, 2, 2]
definition = CharField(max_length=100)
biglist1.sort(key=(operator.itemgetter(2), operator.itemgetter(0)))
all(x == items[0] for x in items)
np.where(A > 50)
ax.cla()
pl.show()
s.listen(5)
self.dialog.setFocusPolicy(QtCore.Qt.StrongFocus)
graph = facebook.GraphAPI(ACCESS_TOKEN)
dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)
outputStream.close()
response = requests.get(url, stream=True)
time.sleep(0.1)
time.sleep(1)
hashlib.sha1(s).hexdigest()
biglist[:] = newlist
c.f(2)
plt.xticks([0.4, 0.14, 0.2, 0.2], fontsize=50)
proc.communicate()
treeview = gtk.TreeView()
{i: l[sum(ind[:i - 1]):sum(ind[:i - 1]) + i] for i in ind}
c.bin
[tag for tag in BeautifulSoup(doc, parseOnlyThese=links)]
self.typename = typename
assert not s.cookies
time.sleep(0.05)
print(url)
loop2()
fig.colorbar(surf, shrink=0.5, aspect=5)
plt.imshow(np.dstack([im, im, im]))
sys.stdout.flush()
new_extpost.save()
self.__dict__[key] = value
Lv = np.array(Lv)
fig = pyplot.figure()
a.tostring()
self.i = 1
L.sort(key=lambda x: map(lower_if_possible, x))
time.sleep(5)
turtle.getscreen()._root.mainloop()
wdiplay(img)
your_dict[x]
goodrows.append(row)
int(time.mktime(d.timetuple())) * 1000
parser.add_option_group(group)
uniq.view(data.dtype).reshape(-1, data.shape[1])
sys.exit(0)
self.get_full_name()
logger = logging.getLogger(__name__)
some_module.classinstance = MyClass()
run()
self.client.disconnect()
self._x = value
int_list = [int(i) for i in line.split()]
print(filecmp(sys.argv[1], sys.argv[2]))
self.particles.extend(next(f))
str(lst[0]), lst[1:]
auth.set_access_token(access_token, access_secret)
t.ix[0], t.ix[1] = t.ix[1], t.ix[0]
cj = cookielib.LWPCookieJar()
log(msg, x=5, y=6)
d[k] = v
tfidf[0:1]
ax4.xaxis.set_visible(False)
logging.basicConfig(level=log_level)
[np.mean(model.trace(t).gettrace()) for t in timesteps]
list[i] += 2
show_log_button.Bind(wx.EVT_BUTTON, self._show_log)
conn.close()
plt.yticks(x, x)
xs = np.arange(512)
inner_lst.append(item)
app = web.application(urls, globals())
dc.DrawBitmap(self.bmp, 0, 0, True)
print(line_intersection((A, B), (C, D)))
dill.dumps(lambdified_expr)
print([(val + [i]) for i, val in enumerate(A, 1)])
INTP = ctypes.POINTER(ctypes.c_int)
clf.fit(X[outer_train], Z[outer_train])
listy[2].append(1)
ifaces
root = Tk()
doSomething(x)
data = f.read()
out.writelines(lines)
self._thread.close()
timestamp1 = calendar.timegm(d.timetuple())
driver = webdriver.Firefox(firefox_profile=profile)
sys.path.insert(0, basePath)
listNew.extend([element, element])
list(set(neighbors))
newarr = [splitfirst(a) for a in arr]
f2 = np.exp(-copper[:, (1)] * 0.08128 * 8.96)
self.filter(is_vegetarian=True)
L = [([0] * 10) for i in range(10)]
student.save()
autorestart = true
client = paramiko.SSHClient()
app = QtGui.QApplication(sys.argv)
np.piecewise(x, conds, funcs)
plt.figure(2)
print(pop_list(nodes, 5, node_list))
sorted(list(s2))
print(list(d.values()))
raise UnwindStack(lambda : _addup(n))
os.stat(path)
self.response.write(template.render())
df[df.columns[5:][ridx]]
os.rename(oldname, newname)
tree = et.fromstring(sxml)
data = [(1, 2), (40, 2), (9, 80)]
cv2.circle(mask, (100, 70), 25, 0, -1)
writer = csv.writer(fout)
correct_prediction = tf.equal(tf.round(tf.nn.sigmoid(pred)), tf.round(y_))
f.close()
sum(zip(a, a[::-1]), ())[:len(a)]
raise MyCustomException(str(e))
time.sleep(10)
aDict[key] = value
list(map(func, itertools.zip_longest(*sequences)))
print(b.shape)
newList.append((oldList[i + 1][0], oldList[i][1]))
self.table.setModel(model)
[x.count for x in list(a.keys())]
connection = pika.BlockingConnection()
[(x * 2) for x in L]
hex(chars[0])
np.abs(a - b) <= atol + rtol * np.abs(b)
logger.setLevel(logging.DEBUG)
time.sleep(1)
fig = plt.figure()
l.save()
u1 = (random.uniform(0, phi1) for _ in range(len(part)))
itertools.chain(do_something(), do_something_else())
mlab.show()
canvas.PrepareDC(dc)
form.save()
self.allClasses.append(instance)
p.stdin.close()
data = sys.stdin.readlines()
v[value].append(key)
platform.release()
data = infile.read()
list[idx] = item
assert isinstance(evaled_value, dict)
[0, 0, 0, 17, 0, 0, 0, 0, 0, 0, 0, 40, 0],
sum(map(operator.mul, topo[:-1], topo[1:]))
os.remove(small)
mask = (data_with_zeros.a == 0) & (data_with_zeros.b == 0)
ids = list(itertools.islice(unique_sequence, 1000))
self.orange_button.Bind(wx.EVT_BUTTON, self.orange_button_click)
notNan = sliding_window(np.logical_not(np.isnan(a)), (2, 2))
soup = BeautifulSoup(html_to_parse)
plot_graph1()
lst[-1] += st[:left]
dstname = os.path.join(dst, name)
line = p.stdout.readline()
print(mystring[0])
myVariable = testVariable or myVariable
db = SQLAlchemy(app)
n * s + m * s == (n + m) * s
new_cols = list(zip(df1.columns.get_level_values(0)))
id(a[0]), id(a[1])
set(sample_generator(10000)) ^ set(range(10000))
np.array(map(lambda x: round(x) - 1, result), dtype=np.uint64)
result = [[(a * b) for a, b in zip(i, j)] for i, j in zip(list1, list2)]
self.numbers.append(self)
thrd2.start()
nx.draw(G)
zip_ref.close()
result = base64.b64decode(body)
expense.tags.add(*self.tags.all())
len(l)
sys.stdin.readline()
a, b = result
scipy.__version__
dict((k.lower(), lower_keys(v)) for k, v in x.items())
df.where(m, n, axis=1)
a = np.arange(1, 100000.0, dtype=float)
fig = plt.figure(figsize=plt.figaspect(1))
im2.set_data([], [])
new_list.append(x + y)
G.add_edges_from([(x, y) for x in L1 for y in L2])
os.makedirs(tmp)
f()
win.show_all()
df = df[cols]
fig, ax = plt.subplots()
ax.plot(list(range(1024)))
soda = a + b
t.start()
pprint(data)
soup = BeautifulSoup(text)
fh.close()
response.close()
lst[i:i + 2] = [nxt, cur]
k = [(ord(x.upper()) - 64) for x in l]
outfile.write(line)
key = models.CharField(max_length=240, db_index=True)
im = np.array(first_subreg * 255, dtype=np.uint8)
usleep(100)
(y != y.shift()).cumsum()
list(int_filter(items))
ax1.set_ylim(*np.log10(olim))
img.show()
csv_f = csv.reader(f)
PLT.axis([x.min(), x.max(), y.min(), y.max()])
t.seek(0)
self.frame.Show(True)
menu.show_all()
a + b[i:]
self.image = ImageTk.PhotoImage(self.photo)
new_list.append(intermediate_dict[i])
count = len(total) - np.count_nonzero(sum)
os.remove(filename4)
lengths = [len(x) for x in lst]
f.seek(0)
shutil.rmtree(tmpdir)
dist = np.abs(X[:, (np.newaxis)] - Y)
print([int(x) for x in a[1:]])
data = cgi.FieldStorage()
results = cursor.fetchone()
d = datetime.date(year=1940, month=1, day=1).year
a2b_hex()
self.assertAlmostEqual(em(1, 1), 0.6765, 4)
x = df.reset_index()
foo[1:2]
print(tokenize.untokenize([(toktype, tokval)]))
axes.set_xticks([])
show()
bob4.save()
bob5.save()
bob6.save()
{{(object | getattribute): field}}
words = line.split()
p.start()
plt.subplot(2, 1, 1)
c.save()
A = array([[0, 1, 2], [0, 2, 0]])
ax0a.plot(x, y)
{{record.c}}, {{record.e}}
s = random.randint(0, n - 1) + 1
get()
decorated.sort(key=lambda v: (v[1], -v[2]))
s.order()
X_train = np.random.randn(6, 2, 2)
x = np.cumsum(np.random.random(1000) - 0.5)
dict((k, vs[x]) for k, vs in self.O.items())
pool = Pool()
readfile.close()
nzsum = mat[ixs[nzmask]].sum(axis=0)
self.gzfile = gzip.open(filename)
datetime.strptime(time1, format)
ax.autoscale_view()
parser.close()
f.close()
df[col] = X[:, (i)]
scipy.stats.norm(0, 1)
psycopg2.extensions.register_type(psycopg2.extensions.UNICODEARRAY)
print(x[:n])
instance = getattr(modul, class_name)()
[1, 20] in a.tolist()
lst.append(arg)
np.random.seed(1977)
cur.execute(query)
ans.append(list(cur_set))
msg.attach(body)
[[[2, 4, 6], [1, 4, 7]]]
param_one = self.one_of_the_vars
unique_list = list(map(itemgetter(0), groupby(yourList)))
cursor.execute(query, data)
out.reshape(np.asarray(shp) * N)
screen.fill(pygame.Color(255, 255, 255))
type(_)
[2.0, 2.0017]
self.view.setModel(self.model)
out_queue.put(test)
root.columnconfigure(0, weight=1)
dff.dropna(thresh=len(dff) - 2, axis=1)
set(a).intersection(b)
pd.Series(a1).isin(a2).any()
output.write(line)
raise Exception()
pp(list(zip(*grid)))
days = (start + timedelta(days=i) for i in range((end - start).days + 1))
time.sleep(10)
value.update((key, 0) for key in all_second_keys if key not in value)
self.text = tk.Text(self)
indices[i] += 1
ax2.imshow(field2, cmap=plt.cm.YlGn, vmin=_min, vmax=_max)
sys.settrace(self.oldtrace)
my_struct = np.array([(1, 2)], dtype=my_struct_type)
ax.set_ylim([-0.1, 1.1])
allnames().visit(t)
{b.pop(0): b.pop(0) for _ in range(1)}
string[:idx if idx != -1 else len(string)]
pylab.show()
stopButton.pack()
output.setparams(data[0][0])
df
fig, ax = plt.subplots()
[sum(x) for x in zip(*myTuples)]
YarnLogger.setup_logger()
plt.plot(X, Y, lw=0)
print(a, b, c, d)
s.listen(1)
np.column_stack((unq_x, avg_y, std_y))
df.iloc[df.index.get_loc(window_stop_row.name)]
c = np.ones((2, 6))
sorted(set(a))[-2]
list(range(5)) + list(range(10, 20))
contourf(x, y, H1, levels1, cmap=cmap_nonlin1)
new_dict_deepcopy = deepcopy(my_dict)
grad * C * tf.transpose(Ainv)
plt.colorbar()
print(x)
resp = requests.get(url=url, params=params)
results = pbex.run()
df = pd.concat(valid(chunks))
model = models.Progress
1.0 * sum(i * w[i] for i in xx & yy) / sum(i * w[i] for i in x)
od.setdefault(a, []).append(b)
urlParams = urlparse.parse_qs(urlparse.urlparse(url).query)
object() == object()
cv2.imwrite(face_file_name, sub_face)
ip_list = []
x + 2
array = [LoL[i][j] for i, j in product(list(range(*r)), list(range(*s)))]
datalisten_thread.start()
abs((d2 - d1).days)
os.makedirs(dir)
self._value
tk.Tk.__init__(self)
patch_jedi()
source._get_numeric_data()
list(map(lambda x: False if x == 0 or x == 1 else True, map(int, lst)))
s = socket.socket()
b = [(ctr[frozenset(x)] == 1) for x in a]
dt.fit(df.ix[:, :2], df.dv)
x.g(2)
B[:, :, (1)] = 1
{file: any(file.endswith(ext) for ext in extensions) for file in files}
token.get_access_token(uri.query)
plt.suptitle(date)
raise_exception()
pool = multiprocessing.Pool(processes=count)
print(dict(d))
plt.cm.RdYlGn._segmentdata
out = np.split(sidx, np.nonzero(sorted_ids[1:] > sorted_ids[:-1])[0] + 1)
myseries_one.iloc[0:2]
fig = plt.figure()
delta = datetime.timedelta(days=1)
yaml.dump(data, stream, OrderedDumper, **kwds)
list(range(*args))
resp = client.service.Execute(req)
wav_file.close()
p.communicate()
mask = mahotas.dilate(mask, np.ones((48, 24)))
abs_file_path = os.path.join(script_dir, rel_path)
sleep(1)
hmag = np.array(hmag)
python - v
os.remove(path)
sys.path.remove(rundir)
conn.sendall(error)
df1.fillna(1).sort(axis=1).eq(df2.fillna(1).sort(axis=1)).all().all()
fig.colorbar(coll)
[snip]
print(x[y][i][z])
n.getme()
fastest = ranked[0][1]
uo_fclose(hFile)
x = [6, 7, 8, 9, 10, 11, 12]
float(n) / (1 << int(log(n, 2)))
pylab.ylim(ymin=0)
time.sleep(1.0)
x = np.array([0, 0, 1, 1, 2, 2])
print(settings.myList[0])
tk.Tk.__init__(self)
f()
ax2.set_ylim([np.amin(image[:, (5), (5)]), np.amax(image[:, (5), (5)])])
plt.imshow(skel)
len(get_file_contents(filename))
True
list(chain(*zip(l, map(partial(add, 1), l))))
data.__dict__.update(json.parse(data))
cursor.close()
f(a, b)
G.add_path([2, 4, 0, 5])
attr(*args, **kwargs)
new_data = new_data.reshape((4, 5, 10))
test()
msg.send()
ax.set_xticklabels(lab)
series = series.astype(float)
print(X[0], Y[0], calc_fast(X[0], Y[0]))
self.transitions = transitions
tornado.ioloop.IOLoop.instance().add_callback(self.loop)
sys.stdout.flush()
l[0], l[-1]
fig.autofmt_xdate()
ax = plt.gca()
buildings = get_hospital_buildings(hospital_obj)
out = scipy.spatial.cKDTree(variable).query_pairs(r=0.1, p=np.infinity)
finished = cv2.warpPerspective(img, transform, img.shape[1::-1])
df.iloc[:, 1:].idxmax(axis=1)
fig, ax = plt.subplots()
str_list = list(filter(len, str_list))
print(objfunc([1.0, 0.0]))
df = pd.DataFrame(data=d)
bool({}) == False
a, b = b, a + b
raise unittest.SkipTest(message)
platform.python_compiler()
ax4 = fig.add_subplot(2, 2, 4)
numpy.linalg.norm(a - b)
print((len(al), al.get_alignment_length()))
getattr(obj, self.name)
main()
zip(list(range(len(l) - 1, -1, -1)), l)
f(*args, **kwargs)
print(ruamel.yaml.dump(data, allow_unicode=True))
sleep(1)
aList.append([xc, yc])
True
plt.plot(t, f(t))
output = PdfFileWriter()
r = random.sample(list(range(len(x))), 10)
X_train_1 = X_train[y_train != 0]
msg.attach(image)
self._list.append(o)
sys.stdout.flush()
sherr.pop(0)
_api_client.ExecuteBatch(batch_request, cells.GetBatchLink().href)
step4.communicate()[0]
{GOOGLE_APP_ENGINE} / dev_appserver.py
print(is_true(x) or is_false(x))
session = Session(key=seshKey)
result = [dict(zip(fields, row)) for row in cursor.fetchall()]
[f(x, fixed) for x in srclist]
print(link.text)
df.columns
fig = plt.figure()
[(x + Ly[i]) for i, x in enumerate(Lx)]
stuff()
n = n + 1
pInt = POINTER(c_int)()
atexit.register(__terminate)
self.browserHandle = webdriver.Firefox(firefoxProfile)
pylab.show()
sys.exit(not result.wasSuccessful())
binascii.unhexlify(x)
image_pixels = image.load()
id = Column(Integer, primary_key=True)
nodes.CallBlock(call, [], [], [])
resultcode = proc.wait()
output.append(char)
df.sample(frac=1)
x1 = np.linspace(0, 0.4, 100)
shutil.copyfile(source, destination)
word in wordList
fig = plt.figure()
self.ax.relim()
y[0]
elem.clear()
s.login(login, password)
app.exec_()
d = a[1::2]
df1 = pd.DataFrame([dict(x) for x in df.word_prob_pair])
app.register_blueprint(feed)
print(type(element))
s.loc[~np.isfinite(s) & s.notnull()] = np.nan
myFunc(False, False, True)
assert diff_month(datetime(2010, 10, 1), datetime(2009, 10, 1)) == 12
canvas.setPageSize(width, height)
chimpchat.shutdown()
ssh_client = paramiko.SSHClient()
print((i, key, value))
session.flush()
app = Flask(__name__)
{k: v for d in dicts for k, v in list(d.items())}
layout = QtGui.QVBoxLayout()
fun(ctypes.byref(indata), 5, 6, ctypes.byref(outdata))
self.picture = QtGui.QPixmap(imagePath)
s = pd.Series(np.arange(4) ** 2, index=np.arange(4))
tree = Tree()
fig, axes = plt.subplots(nrows=4, ncols=4)
list(itertools.accumulate(nums))
data.append([c.text for c in row.getchildren()])
child.show()
print(calendar.timegm(utc_dt.timetuple()))
self.panel = wx.Panel(self, wx.ID_ANY)
user = models.OneToOneField(User)
first_list.append(ls[0])
app = Flask(__name__)
print([myround(x) for x in list_num])
pool.join()
scipy.nanmean(b_padded.reshape(-1, R), axis=1)
text = in_file.read()
cnxn.close()
print(Bar().x)
classifier.fit(X_train, y_train)
new_list = []
type(dates[0]) == pandas.tslib.Timestamp
df = df.append(new_rows).sort_index().reset_index(drop=True)
window.show()
a = Counter(your_list)
axs[0].xaxis.set_major_locator(x_major_lct)
line(src, Q4, Q1, Scalar(0, 0, 255), 1, CV_AA, 0)
wn.synsets(word)
reader = csv.DictReader(fh, fieldnames=header)
bar()
os.symlink(target, link_name)
queryset = Simple.objects.all()
fig = plt.figure(figsize=(10, 10))
print(sys.path)
self.data = numpy.delete(self.data, i, 0)
Process(target=loop_b).start()
np.testing.assert_allclose([1], [[1]])
data += np.random.normal(size=data.shape)
call_quack()
a = np.frombuffer(ArrayType.from_address(addr))
print(outer.__code__.co_cellvars)
df = df.dropna()
browswer_proc = subprocess.Popen(cmd, shell=True)
dist = np.sqrt(dist)
np.median([0, 1, np.inf])
vdisplay.start()
myqserver.delete_current()
frame = cv2.flip(frame, 0)
leng(s)
multiprocessing.freeze_support()
[i - 1, i + 1]
G = nx.Graph()
plt.register_cmap(cmap=newcmap)
b = fig2.add_subplot(2, 2, i)
int_list = models.CommaSeparatedIntegerField(max_length=200)
Py_DECREF(newobj)
sum(100.0 * (x[1:] - x[:-1] ** 2.0) ** 2.0 + (1 - x[:-1]) ** 2.0)
tornado.ioloop.IOLoop.instance().start()
parser = argparse.ArgumentParser()
plt.plot(x, y)
print(df)
output_notebook()
models.IntegerField.__init__(self, verbose_name, name, **kwargs)
print(tab[i])
permutations(string_copy, step + 1)
self.delta = wx.Point(0, 0)
Matrix.map(lambda a, b, **kw: a - b, self, other)
app.config.from_pyfile(config, silent=True)
self.username
np.triu(out)
os.makedirs(dir)
draw = ImageDraw.Draw(image)
glLoadIdentity()
1 / 2
ax2 = ax1.twinx()
result[i] = func1d(x)
df = pd.Dataframe(dict)
self.mthread = QThread()
self.get(timeout=1000)
cursor.execute(sql, [this_year])
reactor.run()
time.sleep(1)
fig = plt.figure()
max(lo, min(hi, x))
list(grpname.values())
foo()
self.file.close()
allkey.append(key)
l.append(hash((x, y)))
hash(self.a) ^ hash(self.b)
print(myForm.__dict__)
fig.canvas.blit(ax.bbox)
other_data = data[mask]
wb.Save()
temp = [(t.count(str(i)) / len(x)) for i in range(1, 5)]
df = pd.DataFrame(np.random.randn(10, 6))
app.register_blueprint(mod)
html_content = urllib.request.urlopen(req).read()
response
fig, ax1 = plt.subplots()
a = np.random.rand(size, size)
d += timedelta(weeks=4)
isinstance(True, int)
root.mainloop()
array(ranked)
transport.accept()
print(df1.head())
df[1][df[1] == 4]
ax.plot(data1)
any(x in sb for x in a)
self._lock.__enter__()
f()
plt.xlim((0, AUC.shape[1]))
list(vars.keys())
ax2.set_xticks(numpy.arange(x1 - 1, x2 + 1, 0.5))
deleted[id]
df = pd.DataFrame(dict(A=np.arange(70)), tidx)
ax = plt.axes(xlim=(0, 2), ylim=(-2, 2))
smtp.starttls()
lexobj
r = requests.post(url, files=files)
do_something()
foo()
t.render(form=MyForm())
l.append(element)
ax.set_axis_off()
the_string = input()
register = models.DateField(auto_now_add=True)
squared = lambda li: map(lambda x: x * x, li)
diff = [(v[0] - v[1]) for v in zip(a[0:-1], a[1:])]
m.group(2)
test(100, 500, 11)
df.describe()
worker.work()
p.start()
parser.parse_args()
f(*args, **kwargs)
sys.exit(1)
platform()
f.close()
NULL
pool.join()
c.showPage()
sheet1.cell(row=row, column=col).value = sheet.cell_value(row, col)
a.transpose(0, 2, 1)
self.driver.get(response.url)
print(indent(text, 4))
avg = avg.replace(microsecond=0)
os.remove(fl)
self.axes.clear()
l = literal_eval(s)
[1, 1, 0, 0]
np.hstack(np.where(a == a.max()))
time.sleep(1)
worksheet1.set_column(1, 1, 25)
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
a.bar
data = np.fromfile(file, dtype=dt)
list(league.items())[0]
raise SystemExit(0)
QtCore.QAbstractTableModel.__init__(self, parent)
str(bar)
time.sleep(0.1)
logging.Formatter.converter = time.localtime
print(firstLine[0], firstline[1], sum(int(x[2]) for x in lines))
print([dict(zip(reader[0], x)) for x in reader])
self.lock.release()
df.ix[dates]
form.populate_obj(student_courses)
plt.show()
result.append(line.upper())
y = np.zeros((yt, xt))
x = np.random.random((100, 100, 100))
np.array([[array2 for _ in row] for row in array1.tolist()])
targetFile.write(contents)
time.sleep(5)
fib(n - 2) + fib(n - 1)
plt.subplot(212)
bool(6)
plt.clabel(CS, inline=1, fontsize=10, manual=manual_locations)
max_idx, max_val = max(enumerate(l), key=operator.itemgetter(1))
plt.show()
float_in[0:16] = list(arr_in[0:16])
plt.show()
b[-1]
mp.scatter(xvals[i], yvals[i], s=rvals[i])
plt.xlim(xmin, xmax)
writer.writerow(row)
s.indices(0)
__init__.py
print((i, el))
self.run()
dosomething()
d = defaultdict(list)
HttpResponseRedirect(redirect_to)
barycoords = barycoords[:, (np.all(barycoords >= 0, axis=0))]
f.__qualname__
stats.f_oneway(a, b)
root.mainloop()
op.outputs[0] * tf.transpose(tf.matrix_inverse(op.inputs[0]))
mail.quit()
print(d[p])
a.set_xticklabels([])
self.e.pack()
screen.keypad(1)
cv2.drawContours(imgBWcopy, contours, idx, (0, 0, 0), -1)
db.close()
f(v, w)
friendlies = []
driver.maximize_window()
plt.show()
groups[tuple(row[c] for c in key_columns)].append(i)
dbx.files_upload(f.read(), file_to)
print((repr(group[0]), len(group)))
df.columns[pd.isnull(df).sum() > 0].tolist()
foo()
dict_writer.writeheader()
r = tk.Tk()
sys.exit(app.exec_())
pl.hist(h, normed=True)
np.cumsum(cols, out=cols)
numpy.zeros(height, width)
listb = [x for x in listb if x[2] != 0]
any(c.isdigit() for c in value)
logger = logging.getLogger(__name__)
pygame.display.update()
print(MyClass.bar)
os.makedirs(mydir)
(p0[0] - p1[0]) ** 2 + (p0[1] - p1[1]) ** 2
newData.append((255, 255, 255, 0))
1, 1, 1
link_model = models.ForeignKey(settings.LINK_MODEL)
new_list.append(obj)
print(repr(tokzr_WORD(inp1)))
links.append((url, rule.endpoint))
print(delta.days)
(x for x in data if func(x))
name = models.CharField(max_length=50)
sample_object.save()
lines = random.sample(all_lines, 40)
[(2 ** i) for i in range(n)]
result = client.service.methodName(Inputs)
True
print(df)
ax.set_ylim(50, 0)
os.path.walk(your_dir, print_it, 0)
y = np.zeros(data.shape[1:], data.dtype)
b = np.array([1, 1])
unmanhattan_patch = descartes.PolygonPatch(unmanhattan)
plt.show(block=True)
ax2.set_xbound(ax1.get_xbound())
ax2 = plt.subplot2grid((6, 1), (1, 0))
pool.close()
np.argwhere(np.diff(bool_array)).squeeze()
urllib.request.install_opener(opener)
setup(ext_modules=[module])
numpy.roots([2, -6])
atexit.register(interrupt)
b = np.in1d(np.arange(n), np.random.randint(0, n, n))
plt.plot(t, y[0])
sns.set(font_scale=5)
response.iter_lines(chunk_size=1)
time.sleep(self.interval)
a.shape
print(app_info.get_name(), app_info.get_executable(), app_info.get_icon())
sys.exit(11)
d[sku] = price[0]
redirect(rp[:-1])
(x + y) % 12
dynmodule.load(module_code)
[r.pop(1) for r in L]
next(i for i, d in enumerate(lod) if 1 in d)
fig, ax = plt.subplots()
plt.figure()
{e for l in lst for e in l}
ax.imshow(gray_data, cmap=cm.gray)
self._foo
unq_idx = np.split(sort_idx, np.cumsum(unq_count[:-1]))
attrs.update({(1): 1})
[k for item in map(lambda x: [g(x) for g in listFunc], ListArg) for k in item]
b2.pack()
help(property)
print(os.getcwd())
(s - np.mean(s)) / np.std(s)
already_inserted = all(bitfield[i] for i in indexes)
m.drawcoastlines()
[(a, b) for a in res for b in B if a.search(b)]
dis.dis(method2)
user = models.ForeignKey(User)
sub_df.columns = list(range(12))
-(x + a) + b / (1 + np.exp(-(x + c)))
writer.writerow(headers)
isinstance(object, type)
s = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
A[~np.isnan(A)]
Py_Initialize()
gtk.Entry.do_key_press_event(self, event)
fd.close()
second_largest([1, 1, 1, 1, 1, 2])
s.plot(ax=ax)
app = QApplication(sys.argv)
self.setGeometry(800, 400, 250, 80)
(t for t in tuples if all(f(t) for f in filters))
ax2 = plt.subplot(gs[1])
main()
df.stack().idxmax()
b[:, (0), (0)] = t
print(pd.DataFrame(com.convert_robj(r_DF)))
df.C = a
out[mask] = B[:, ::-1][mask[:, ::-1]]
main()
df.mask(outliers_low, down_quantiles, axis=1)
obj.__class__.__dict__[2]
r = requests.get(url, cookies=cookies)
[NOSE_XUNIT_FILE]
np.isnan(a[2])
d1 + timedelta(days=-1)
NULL
s.update(list(fus_s.keys()))
newList = list(convert(oldList))
l1.append([x[1] for x in zip(pattern, facs) if x[0]])
jobs.apply_async()
11
self.edit1 = QLineEdit()
date(year, month, day)
testFunc()
monkey.patch_all()
data = {k.strip(): [fitem(v)] for k, v in list(reader.next().items())}
m = np.ones(len(a), dtype=bool)
ax = plt.gca()
out_queue = mp.Queue()
pygame.init()
objects.sort(key=getScore)
observer.start()
start_urls = [url.strip() for url in f.readlines()]
print(cell.text_content())
app.debug = True
sorted(student_tuples, key=student_key)
self.panel.SetBackgroundColour(wx.Colour(250, 250, 250))
log = logging.getLogger()
auth.load_session()
np.matlib.identity(n)
df
s.iloc[s.first_valid_index():]
VAR1
byrempcs = sorted(promotion_items, key=bypcs)
quicksort(array, i + 1, end)
char = chr(ord(char) + 1)
print(m.group(0))
result.append(int(item))
name = models.CharField(max_length=1024, blank=True)
b = list(a)
IGNORE_TESTS = ()
cj = cookielib.CookieJar()
[syndication]
ax2.yaxis.set_major_formatter(ticks_y)
oldout, olderr = sys.stdout, sys.stderr
turtle.forward(200)
output = popen.stdout.read()
t = datetime.datetime.now()
shutil.get_terminal_size((80, 20))
f.close()
df.dtypes
driver.set_page_load_timeout(10)
ax = pylab.gca()
self.init_vars = tf.initialize_variables(self.variables)
zip.extractall()
self.SetSizer(grid_sizer_1)
app.MainLoop()
[item for item in full_list if not omit & set(item)]
f()
a.__dict__
pprint.pprint(data)
product = models.ForeignKey(Product)
my_list = list(range(10))
urllib.request.install_opener(opener)
found = any(matched(line) for line in file)
reader = csv.reader(in_file)
sys.stdout = sys.__stdout__
sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPIDLE, after_idle_sec)
__init__.py
signals.pre_save.connect(User.pre_save, sender=User)
c[:len(b)] += b
[mylist.__setitem__(i, thing) for i, thing in enumerate(mylist)]
args = parser.parse_args()
PyArray_ENABLEFLAGS(arr, np.NPY_OWNDATA)
self.layout.addWidget(self.progressBar)
out = np.empty(len(a), dtype=object)
XXXX
df = pd.concat([df.iloc[:, :4], df.iloc[:, 4:]]).reset_index()
ax.set_ylim(-2, 2)
run.py
content = pdf.getPage(1).extractText()
func(*args, **kwargs)
self.tk.config(menu=self.blank_menu)
b = a.ravel()
print(df.columns[2:5])
time.sleep(1)
args._get_kwargs()
L[i:i + 2] = L[i + 1:i - 1:-1]
frame.Show()
fig1 = plt.figure(figsize=(8, 5))
p.wait()
print(item)
(match.group(0) for match in sentence.finditer(text))
data = [rndseries, rndseries, rndseries, rndseries, rndseries, rndseries]
main()
termios.tcsetattr(fd, termios.TCSANOW, attrs)
sq_sum.append((A ** 2).sum(axis=1).mean())
print(line)
np.random.shuffle(arr)
[x for x in string_list if x.isdigit()]
a = np.ones(2)
self.new_names[name] = value
p.get_lines()[0].get_ydata()
parent = psutil.Process(pid)
print(u.__dict__)
b = array([1, 4, 5])
list(range(0, 0.4, 0.1))
data = np.fromfile(f, dtype=dtype)
Parent.__init__(self, x, y, z)
set(itertools.chain(l1, l2))
str_object2 = zlib.decompress(str_object1)
entry.focus()
result
Thread(target=receiving, args=(ser,)).start()
f.seek(-pos, 2)
db.session.commit()
cur.execute(query, my_dict)
self.things.append(0)
client.set_options(headers=headers)
sorted(set(xyz).difference(a))
graph.set_xticks(x)
app = Flask(__name__)
self.columnconfigure(1, weight=0)
plt.plot(np.sin(theta), np.cos(theta))
xmlstring = re.sub(pattern, lambda m: substitutions[m.group(1)], xmlstring)
tk.Tk.__init__(self)
f.write(data)
a = [[0, 0], [0, 0]]
genre_count.sort(ascending=False)
raise ValueError(ret)
processes.append((p, f))
print(ipath[i])
plt.plot(x, i * x + 5 * i)
df.delta.apply(lambda x: x.microseconds)
plot(f, p)
ax2.xaxis.set_major_formatter(ticks_x)
datareader = csv.reader(io.TextIOWrapper(webpage))
model.add(Dropout(0.5))
m = re.search(pat, t)
im.putpalette(mypalette)
self.sleep(1)
count += 1
sys.stderr = sys.stdout
self.functor(*args, **kwargs)
view_pyc_file(sys.argv[1])
ax4.plot(np.linspace(0, len(xp), len(xp)), xp)
os.path.basename(f)
x = dict.fromkeys(list(range(0, 10)), 0)
do_stuff()
math.cos(_ / 2)
my_array[:, (0)] = my_array[:, (1)]
conn.close()
s = s.strip()
root.grid_rowconfigure(1, weight=1)
raise Exception()
list({frozenset(list(Counter(tup).items())): tup for tup in data}.values())
bisect.bisect_left(dates, datetime.datetime(2007, 1, 6))
print(row)
days, hours, minutes, seconds
set(list1) & set(compSet)
logger.addHandler(fileHandler)
manager.start()
file_path = os.path.join(root, filename)
total += 1
ax.set_yticks(np.arange(-0.5, height, 1), minor=True)
self.append([])
gray = cv2.cvtColor(image_src, cv2.COLOR_BGR2GRAY)
print(line_count)
combine([9, 8], [2, 1])
myLists.append([122284.8, 111161.8, 106581.1, 141419.9])
self.Show()
pfile.truncate()
req = urllib.request.Request(url, data)
s.sort()
sock.close()
cursor.execute(qry)
self.timeout = timeout
interpreter.process_page(page)
tf.logging.set_verbosity(tf.logging.ERROR)
sum(c, [])
array([0, 1, 1, 2])
self.ax = self.fig.add_subplot(111)
fh.write(text)
f()
self.origstream.flush()
float(2 ** _random_decimal(min_exp, max_exp, 64))
dict(Counter(A).most_common(5))
s = requests.Session()
print(request.error_message)
a_n82_remember_4ever()
len(self._data)
b = random.choice(range(0, a))
body = resp.read()
context_for_rendering_inclusion_tag
bre.close()
c = pymongo.MongoClient()
remote.close()
timestamp2 = time.mktime(d.timetuple())
QtCore.QThread.__init__(self, parent)
datetime.datetime(*t.timetuple()[:-4])
print(hex(i)[2:].zfill(2))
os.path.dirname(os.path.abspath(file))
tf.reduce_sum(x) < 100
collections.deque(itertools.islice(iterator, n))
zipDocument = zipfile.ZipFile(StringIO.StringIO(response.content))
turtle.left(90)
(recursive_map(f, x) if isinstance(x, tuple) else f(x) for x in it)
cur.execute(sql, (lite.Binary(data),))
tuple(int(entry) for entry in s)
print(G.edge[0][1])
(first_num, first_arr), (second_num, second_arr) = generate_arrangements(data)
os.dup2(0, 2)
dict.__getitem__(self, keys)
type(f)
datetime.datetime(2012, 1, 5, 0, 0, 0),
stats.norm.interval(0.68, loc=mu, scale=sigma / sqrt(N))
stats.normaltest(y)
PyArray_ENABLEFLAGS(arr, np.NPY_OWNDATA)
tf.nn.relu(x + c)
per_column = zip(*per_row)
anotherfunc()
self.left = FibTree(n - 1)
np.array_equal(org_approach(data, reference), vect_approach(data, reference))
fig, axs = plt.subplots(1, 2)
b = collections.OrderedDict(sorted(list(a.items()), key=lambda t: get_key(t[0])))
s.update(list(fus_s.keys()))
sum((a - b) ** 2 for a, b in zip(a, b))
df
func2()
np.column_stack((slope, intercept))
plt.subplot(212)
draw = ImageDraw.Draw(img)
lst.extend(list(range(11, 14)))
ws.run_forever()
sys.exit(0)
token = token_handler.create_token(request, refresh_token=False)
ui.syn()
json.dumps(o)
self.log.removeHandler(self.handler)
self.successors.append(other)
help(math.sin)
root.update()
events.sort(key=lambda x: x[0])
froms = collections.defaultdict(list)
next(key for key, values in list(d.items()) if search_value in values)
self.wrapee = wrapee
rows = iter(csv.reader(file))
np.array(list_).sum(0).prod()
False
f1.close()
driver.switch_to.window(handle)
G.add_edge(1, 2)
listening_socket.listen(backlog)
author = models.CharField(max_length=20)
makeArchive(dirEntries(folder, True), zipname, folder)
print(b.shape)
[x[i:i + chunk_size] for i in range(0, chunks, chunk_size)]
show()
foo.__setitem__(something, bar)
result.reset_index()
data = get_data()
print(df.col.str.split(expand=True))
server.sendmail(fromaddr, toaddrs, message)
lognorm.cdf(x, sigma, 0, mean)
[list(row) for row in zip(*mat)]
print(foo[0:5])
content = f.read()
df
self.auth.username
cluster.setdefault(label, []).append(word)
self.search_list(request, *args, **kwargs)
c = initval
key = lambda x: customlist.index(x)
idx = npi.indices(b, a)
crawler.start()
sys.stdout.write(inp_data)
self.tweet_list.append(json.loads(data))
app.MainLoop()
key = np.array([0, 10])
client.add_credentials(instaaccount, instapassword)
pygame.init()
G = nx.Graph()
df = pd.concat([df1, df2])
print(i)
data = list(image.getdata())
cym.year, cym.month
print(F.__code__.co_stacksize)
print(F.__code__.co_cellvars)
print(F.__code__.co_freevars)
column_widget.show()
print(arr[np.ix_(rows, cols)])
print(matplotlib.colors.rgb2hex(rgb))
KERNEL[1, 1] = 0
app.exec_()
parser = argparse.ArgumentParser()
ax.quiver(x, y, z, u, v, w, length=0.1)
self.b2.pack()
signal.signal(signal.SIGINT, signal.SIG_IGN)
y_train_1 = y_train[y_train != 0]
df = pd.DataFrame()
root = tk.Tk()
slug = defaultfilters.slugify(unidecode(input_text))
fig = plt.figure(figsize=(8, 2))
self.assertAlmostEqual(em(2, 1), 0.0584, 4)
c.update(d)
ndata.append([(start + end) / 2.0, np.mean(np.array(within))])
byvalue[x].append(i)
m.indices = (indices - 1) % m.shape[1]
print(filename)
python / path / to / script.py
print(df)
np.issubdtype(float, np.floating)
interleaved = pd.concat([s1, s2]).sort_index()
plt.ylim(variability.shape[0], 0)
logger = logging.getLogger(__name__)
time.sleep(0.001)
b = np.array([[4], [5], [6]])
data.append(row)
label_group_bar(ax, data)
r = requests.get(QUERY_URL)
qs = self.get_query_set().filter(*args, **kwargs)
wb = load_workbook(StringIO.StringIO(xlsx))
line = process.stdout.readline()
df = df[df[c].isin(df[c].value_counts()[df[c].value_counts() > m].index)]
c[1, 2]
self.sizer.Add(self.log, 1, wx.EXPAND)
print(func.locals)
regex_compiled.pattern
reducefn(dic1)
pprint(l)
plt.show()
self.file.close()
next_line = lines[i + 1]
params = urllib.parse.urlencode(params)
Baz().foo()
l.append(float(rec[col]))
ax.set_xticks(np.arange(nba_sort.shape[1]) + 0.5, minor=False)
p = argparse.ArgumentParser()
b = a + b
{{thing}}
Decimal(1.5).quantize(0, ROUND_HALF_UP)
int(toks[0])
friend_id = Column(Integer, ForeignKey(User.id), primary_key=True)
start = urllib.request.urlopen(image_url).read(24)
[0.0, -1.0]
result = a or b or c or default
line = line.strip()
plt.colorbar(p)
list(l)
pylab.hist(A[~np.isnan(A)])
print(p.stdout.read())
soup = BeautifulSoup(urllib.open(url).read())
pool = Pool(processes=4)
plt.show()
[s.split()[:2] for s in strings]
dict.__setitem__(self, key, value)
x = random.random()
pInt[0]
tuple(lst)
f.readline()
x = np.empty((), dtype=object)
name = models.CharField(max_length=200)
app
c.setopt(c.NOBODY, 1)
s.loc[:] = [7, 8]
list(individual(nest))
-24.784805 - 0.927448
print(result.read())
np.cumsum(hist)
output.write(line)
ax = fig.add_subplot(111)
ax.add_patch(arc)
p.join()
[dct for dct in listA if dictA.items() <= dct.items()]
B = np.random.randint(0, 1000, 10000)
print(G.__code__.co_names)
fig = plt.figure()
fig = plt.figure()
f = open(mkstemp()[0])
print([b(5) for b in bases])
cursor.execute(query, params)
df[df.Group.map(df.Group.value_counts().ge(4))]
fig.canvas.draw()
sys.stdout.write(str(time))
sys.stdin.read(1)
[self[i] for i in index]
s.send(query)
print(response.read())
self.d[index].append(value)
float(c[a]) / len(x)
func()
sys.exit(2)
print(indented)
sock.send(data)
s.setDTR(True)
self.ham = dict()
raise ArgumentError(action, msg)
root.overrideredirect(True)
a = [[0, 1], [0, 1]]
print(sys.exc_info()[0])
fig = plt.figure()
fig1 = plt.figure()
result = list(join_unescaped(list_1))
[tuple(y for y in x if y != False) for x in df.to_records()]
nums.insert(index, mean(nums[index - 1], nums[index]))
ax = fig.add_subplot(111)
print(i, line)
conn = listener.accept()
fuse(x, y)
get_nested_list(a[0])
article.save()
grid = [[a, b, c], [d, e, f], [g, h, i]]
painter.drawText(QtCore.QPoint(0, -pen.width()), QtCore.QString(hw[i]))
os.chdir(sys.argv[1])
roi = gray[y1:y2, x1:x2]
array = []
pd.Series(c, u)
pl.plot(x, y)
choice = forms.ChoiceField(widget=RadioSelect, choices=choices)
print(guyGenerator([2, 2, 2, 2, 2], [1, 1, 1, 1, 1]))
y[REPLACE_EVERY_Nth - 1::REPLACE_EVERY_Nth] = REPLACE_WITH
[d[x] for x in a]
signal.alarm(0)
decorator
count[letter] += 1
periodic_task.save()
[dishes[x] for x in crucial if x in dishes]
[random.uniform(low, high) for _ in range(size)]
mylist1.sort(key=sort_order.index)
l = [1, 5, 7]
output.close()
self.cb = self.figure.colorbar(hb)
G = nx.Graph()
l.append(Test(0))
index_list = []
app.add_url_rule(url, view_func=view)
p.stdin.write(data)
gc.get_objects()
print(line)
numpy.set_printoptions(linewidth=160)
self.queue.clear()
sys.exit(ret)
app.exec_()
vect = CountVectorizer(ngram_range=(1, 4))
1, 0, 1, 0, 0, 0, 0, 0, 1
cursor.close()
self.connect((host, 80))
self.start()
t0 = time.time()
x = 4
print((x, y, z))
urllib.request.urlretrieve(link, file_name)
intercepting_func
c = cv2.VideoCapture(0)
ru = {}
[_f for _f in l if _f]
c = pycurl.Curl()
StoppableThread.__init__(self)
layout.addWidget(self.button)
np.add(*np.indices((nrow, ncol)))
print(df)
(datetime.date.today() - date_cand).days
fig, ax = plt.subplots()
DEBUG = False
pylot.draw()
newImage = Image.new(mode, (newWidth, newHeight))
wr.writerow(sheet.row_values(0))
data_y = [5, 6, 15, 20, 21, 22, 26, 42, 45, 60, 55, 58, 55, 50, 49]
os.unlink(fname)
print(find_eulerian_tour(graph))
w.writerow(a)
server.NOT_DONE_YET
map(list1.__setitem__, indices, list2)
img_bgr = cv2.merge([b, g, r])
os.remove(f)
compare(a, b)
tag.update()
row_dict[col] = row[i]
df.show()
self.browser.quit()
X.mean(axis=1)
print(repr(object))
print(xml2json.xml2json(s))
hiddenimports = [],
print(line)
f(x, (a[x], a[y])), f(y, a[x][0]), f(x, a[x][1])
top_names = dict(heapq.nlargest(5, list(names_dict.items()), key=itemgetter(1)))
print(fpp[0])
self.lineedit.selectAll()
script1.py
shout.start()
iso8601(datetime.timedelta(0, 18, 179651))
dumper.represent_dict(iter(data.items()))
getitem_rlist = lambda s, i: getitem_rlist(s[1:][0], i - 1) if i > 0 else s[0]
b = [[7, 9], [1, 2], [2, 9]]
uchar * uimg
pdb.set_trace()
head[0][0:]
c = Counter(a)
dict(enumerate(df.five.cat.categories))
debuild - us - uc
main()
ts = pd.Series(np.random.randn(6), index=dates)
accuracy = (true_pos + true_neg) / float(len(gold)) if gold else 0
math.factorial(170)
Category.add(row[1])
next(a)
result = []
ax = f.add_subplot(111, polar=True)
ax.set_xlim(min(x), max(x))
outfile.write(filedata.file.read())
string.ascii_uppercase
mercury.speed(0)
subprocess.popen(command, shell=True)
selected = dict(zip(selected, selected))
vbdref1 = session.xenapi.VBD.create(vbdconnectcd)
df.index = list(range(1, n)) + [0] + list(range(n, df.index[-1] + 1))
py.test
parser.parse_args()
self.realnames[name]
NULL
d1.update(b1)
self.line.set_color(self.get_color())
True
sq = [(np.subtract.outer(item, item) ** 2).sum() for item in items]
c()
b[..., ([2, 2])]
ax = df.plot()
unittest.TextTestRunner(verbosity=2).run(fullSuite)
ts = time.time()
m.fit(X / np.std(X, 0), y)
plt.figure()
sample_weight = np.array([(5 if i == 0 else 1) for i in y])
self.coconut = coconut
sum(islice(count(1, step=4), 101, 200))
print(d[4])
plt.xlim(0, 20 + i)
dc.SetPen(wx.Pen(self.GetForegroundColour()))
layout.addWidget(self.listview)
x = np.random.random((5000, 5000)) - 0.5
(datetime.date.today() - date_cand.date()).days
process.join()
g.add_edge(6, 7)
self.move(global_point - QtCore.QPoint(self.width(), 0))
pos = pygame.mouse.get_pos()
a = np.zeros((5, 10))
P.figure()
curses.setsyx(-1, -1)
plt.ylim(0, 1)
a1 = np.arange(1, 11)
res.update({k: v for k, v in list(b.items()) if k not in a})
plt.tricontourf(x, y, T.triangles, v)
new_string = str(string, enc)
self.lc = wx.ListCtrl(self, style=wx.LC_REPORT)
now = datetime.now(mytz)
fh.seek(0, os.SEEK_END)
start = end + 1
print(n)
[processed(x) for x in input_array]
base.py
lrg = np.arange(2).reshape((2, -1)).repeat(1000000, -1).flatten()
logmod.fit(x, y)
doms = doms.split()
add(*x)
df
mylist = [True, True, False]
print(df)
B.__init__(self)
plot_bars(x_bar, y_bar, angle, ax)
fig1 = plt.figure()
conn.execute(penguin)
abort(401)
word = word[:index] + char + word[index + 1:]
sys.stdout = self.stdout
ab[s][np.concatenate(([True], t[1:] != t[:-1]))]
ax = fig.add_subplot(111)
self.strategies = strategies
User.objects.bulk_create(iter(users_iterator()))
doctest.testmod()
y = np.cumsum(x, dtype=np.intp)
np.sin(n * np.pi * x) * g(x)
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
plt.subplot(2, 1, 2)
self.y2 += mh
self.parser.parse_args(namespace=self)
print(xmlFile.toprettyxml())
logger = logging.getLogger(__name__)
proc.wait()
s.mean(level=1)
email.send()
Tup()[1]
itemDict.append(r)
startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
log.close()
print(nltk.tokenize.WordPunctTokenizer().tokenize(german))
win.add(notebook)
orig.update(extra)
result = np.reshape(result, (frames_per_buffer, 2))
now = datetime.now()
[{next(cyc): y for y in x} for x in v]
df.applymap(list).sum(1).apply(set)
conn = boto.connect_ec2()
face_cascade = cv2.CascadeClassifier()
serializer = AvatarSerializer(data=request.DATA, files=request.FILES)
{{form.as_p}}
pandas2ri.activate()
spawn()
someClass.start()
ss.expon.fit(data, floc=0)
m = np.zeros(size, dtype=np.uint8)
min(timeit.repeat(lambda : {k: v for k, v in zip(keys, values)}))
doubles[x] = x * 2
latest_date = B.select(B.date).order_by(B.date.desc()).limit(1).scalar()
df.reindex(np.roll(df.index, shift))
Counter.objects.get_or_create(name=name)
p.join()
plt.figure()
IM20010809, IM75550511, CL0700100U
out = vec.cumsum()
plt.gcf().autofmt_xdate()
listbox.insert(0, option)
app = QtGui.QApplication(sys.argv)
raise ValueError
plt.plot(list(range(10)))
plt.imshow(frames[k], cmap=plt.cm.gray)
str(a)
fig, ax = plt.subplots(1, 1)
print(list(itertools.product(*combs)))
chambersinreactor, cardsdiscarded
(a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))
cmd.wait()
len(f.readlines())
fig = plt.figure()
dirname = os.path.splitext(f)[0]
xnew = np.linspace(0, 1, Newx)
new_dataset.sort(key=lambda item: item[group_by_key])
x * x
main()
asarray(all_data)
writer.save()
post = db.session.query(Post).get(1)
parser = argparse.ArgumentParser()
np.dot(np.array(n0), np.array(p) - np.array(p0))
a = dict.fromkeys(iter(a.keys()), 0)
test_list += [([0] + list(x)) for x in itertools.product(*args)]
print(newcorpus.words(newcorpus.fileids()[0]))
{{form.id}}
c.mymethod1()
session1.close()
matrix = sparse.lil_matrix((rows, columns))
list(set(raises))
out.write(b)
sample_object.users.through.objects.create(user_id=2, sample_id=sample_id)
app = QtGui.QApplication(sys.argv)
f.seek(pos)
sys.exit(2)
table.rename(index=str).index[0]
language = form.language.data
workbook.add_format(dict(list(new_dict.items()) + list(dict_of_properties.items())))
skel_coords.append((r, c))
print(status._json)
my_file.write(a)
init_p = numpy.array(init_a)
assert diff_month(datetime(2010, 10, 1), datetime(2009, 11, 1)) == 11
b = dict(a)
a = json.loads(s, object_hook=registry.object_hook)
path[:-len(ext)], path[-len(ext):]
print(Timetable([random_row(50) for _ in range(15)]))
file_handler.setLevel(logging.INFO)
module.stuff()
row = next(reader)
[dishes[x] for x in set(crucial) & set(dishes)]
result.append(current.pop())
content = f.read()
self.w.setGeometry(QRect(100, 100, 400, 200))
print(regexp.search(s).group(1))
ax.xaxis.set_ticks([0, tick_limit])
mlab.axes(extent=(0, 1, 0, 1, 0, 1))
(item for item in my_iterable if my_filter(item))
A = [0, 0, 0, 1, 0, 1]
[1.0, 0.0, 1.0, 0.0, 1.0],
results = dict([(i, []) for i in inputs])
lastHourDateTime = datetime.today() - timedelta(hours=1)
db.session.add(p)
xy[-2]
list(df)
using_clump(x)
draw = ImageDraw.Draw(image1)
y.append(row[1])
parser = argparse.ArgumentParser()
self.fc1.draw()
rows.nonzero()
cnt == cnt.max()
bokeh.io.show(layout)
[tuple(map(sum, zip(x, y))) for x, y in zip(a, b)]
print(last_lines.pop(0))
form.fields[DELETION_FIELD_NAME].widget = forms.HiddenInput()
q = np.frombuffer(r, dtype=np.float64)
sorted(a, key=a.count)
numStreak = ([(a[0] == n) for n in a] + [False]).index(False)
array([1, 1, -1, 0, 0, -1, 1, 0, -1, -1])
all(c <= indices[i + 1] for i, c in enumerate(indices[:-1]))
t.print_exc()
scipy.stats.poisson(9.2 * 25).cdf(254 - 50)
Foo().ham
ii = np.where(values == searchval)[0]
hypot(x2 - x1, y2 - y1)
self.wfile.write(chunk)
object.__setattr__(self, name, value)
k.lower() in self._s
run.py
soup = BeautifulSoup.BeautifulSoup(html)
lines.reverse()
ax.legend(handles, labels)
func(**filter_dict(kwargs, get_input_names(func)))
list(map(deep_reverse, to_reverse[::-1]))
file_size = file_size + len(buf)
app = Flask(__name__)
BOMLEN = len(codecs.BOM_UTF8)
t = pd.to_datetime(t)
end = min(len(list1), len(list2))
master.minsize(width=666, height=666)
ranges[-1].append(oldidx)
listening_socket.close()
nzsum = np.bincount(ixs[nzmask] - 1, minlength=mat.shape[0] - 1).dot(mat[1:])
total += int(string[:j]) + sum_string(string[j:])
setup.py
timeit(lambda : list(fulldict.keys()))
self.log.write(data)
x = np.random.rand(n)
plt.fill(x, y)
a = [1, 1, 5, 1, 1]
myseries_two.iloc[0:2]
pkg_resources.require(dependencies)
flat = [x for sublist in nested for x in sublist]
random_array = np.random.randint(0, 16, (4, 4))
pdb.Pdb.postloop(self)
Z = np.random.normal(size=N)
my_df.reset_index(inplace=True)
b = pd.Series(data=[4, 5, 6])
pencil.py
value = sa.Column(sa.String, nullable=False)
eventLoopThread.setDaemon(True)
not any(bool(a) ^ bool(b) for a, b in zip(it1, it2))
browser = mechanize.Browser()
remove_if_not_substring(l1, l2)
print(extmodule.makeBalls(1, 2))
parser = argparse.ArgumentParser()
soup = BeautifulSoup(html)
list(range(1, n + 1))
b.append(item)
a[i < 0]
self.nodes.append(node)
any(i in L1 for i in L2)
firstNlines = myfile.readlines()[0:5]
show(p)
df = pd.concat([ars, che], axis=1)
soup = BeautifulSoup(html)
rows.append(row)
sys.stdout = StringIO()
stdout, stderr = proc.communicate()
ax.set_zticks([])
toss = pd.Series(toss)
sum(asum(x) for x in a)
id = Column(Integer, primary_key=True)
raise TimeoutError()
zip(l[::2], l[1::2])
checksum = hashlib.md5(open(path).read())
(1000000 * delta.seconds + delta.microseconds) / 1000000.0
print(format_float(1.5e-06))
keyword2func[word]()
testclass().testmethod()
image = Image.open(image)
assert hash(42) == 42
f.close()
start_date = date.today().replace(day=1, month=1).toordinal()
li.append(x + y)
print(k, od[k])
scores = []
fig.tight_layout()
print(ndimage.zoom(data, (1, 2, 2)))
send_file(io.BytesIO(image_binary))
ax = plt.axes([0.0, 0.0, 1.0, 1.0], frameon=False, xticks=[], yticks=[])
my_list.insert(index, insert_string)
tree = ET.ElementTree(root)
d[key][k] = v
combined_meta_data._add_table(table_name, table.schema, table)
r[~numpy.iscomplex(r)]
b[1, 1] = 100
fig = plt.figure()
time = datetime.strftime(time, DATETIME_FORMAT)
self.factories = []
self.platforms = []
self.emitter = []
print(foo())
[(1, 2), (2, 4)]
new_list = sorted(mylist, key=lambda x: x[1])
sys.stderr.write(msg)
cimage = Image.open(cimage)
print(bigmat[:, (x), (y)])
results = self.clickcursor.fetchall()
Test(**fields)
df_crawls.dtypes
send_from_directory(MEDIA_FOLDER, filename, as_attachment=True)
print(type(df.iloc[0, 0]))
angleInDegrees = arctan(deltaY / deltaX) * 180 / PI
id = Column(Integer, primary_key=True)
c = a + b
reactor.listenUDP(Protocol(timeout))
startButton.pack()
self.Bind(wx.EVT_CHAR_HOOK, self.OnKeyUP)
sys.exit(main())
Dbins = np.linspace(D.min(), D.max(), 24)
plt.bar(ind, data[0], color=colors[0])
dict[entry[0]] = entry[1:]
zip(*a)
flags = tools.argparser.parse_args(args=[])
timestamp = (utc_date - date(1970, 1, 1)).days * DAY
[x for x in ls if isinstance(x, dict)]
all(a + b == c)
blist = [0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0]
self.addItem(item)
mydict[s[0:1]] + s[1:]
mmc.serial.close()
self.bottom = 0
print(repr(a))
pd.read_csv(io.StringIO(df.to_csv()))
sys.exit(0)
b = numpy.random.rand(N)
conn.close()
Image.open(buff)
math.atan2(0.0, -0.0) == math.atan2(-0.0, -0.0)
print(k, v)
{{encoded}}
os.chdir(search_dir)
subprocess.call
m = re.search(self.BASE_RE, elem.text)
print(d[key])
False
root = Tk()
result = [list(t) for t in l]
df
buffer[:] = bytearray(size)
hfile.seek(0, os.SEEK_SET)
my_list.extend(sorted(my_dict.get(k)))
pos = nx.spring_layout(G)
assert True
bar()
df2.mul(np.log(df2)).sum(1)
remove_from[:index + 1] + remove_from[endIndex:]
send_file(image_file)
ax = fig.add_subplot(2, 1, 1)
f.close()
threading.Thread(target=foo).start()
dall.update(d1)
h5file.close()
b = np.array([99999, 99997, 99999])
contour_info.append((c, cv2.isContourConvex(c), cv2.contourArea(c)))
STACKADJ(-oparg)
list1[:next(compress(count(), map(ne, list1, list2)), 0)]
fig = plt.figure()
CS = plt.contour(X, Y, Z)
digits.extend([0] * (sigfig - len(digits)))
insert_into_homefeed.delay(photo_id, user_id, range_limit + 1)
m = __import__(module_name, globals(), locals(), func_names, -1)
json_data[key] = value.strip()
list(filter(partial(foo, 1, c=4), myTuple))
ax.set_xticks([0.5, 1.5, 2.5])
brlxusd.split()[0]
graph[a].append(b)
print(is_arr_in_list(myarr0, mylistarr))
im = Image.fromstdin()
fig = plt.figure()
name = models.CharField(max_length=100)
zip(*rows)
sys.stderr = f
line_split = list(line.split()[0])
b = np.array([1, 760])
[1]
time.mktime(obj.updated_at.timetuple()) * 1000
np.dot(A.T, B)
d87f7e0c
d2d10e28
print(min(resolutions, key=keyfunc))
final.append(s[x:i + 1])
np.in1d(a, b, assume_unique)
result.extend([int(b) for b in bits])
__init__.py
str(int(matchObject.group()) + 10)
ftp.connect(host, port)
fig, ax = plt.subplots(figsize=(11, 4))
first = [x for x, y in data]
td.total_seconds()
window.stick()
self.page()
run_wsgi_app(application)
time.sleep(waittime)
json.loads(urllib.request.urlopen(req).read())
df.T.apply(lambda x: x.dropna()[n - 1:].index[0])
w.set_foreground()
root = tree.getroot()
x + y * z
s.index = pd.MultiIndex.from_tuples(s.index)
plt.legend()
p.wait()
bv[i] = 1
self.fn(*args)
parser = argparse.ArgumentParser()
rdd = list(sc.wholeTextFiles(input_dir).values())
process.start()
all(ord(l[i + 1]) - ord(l[i]) == 1 for i in range(len(l) - 1))
s.decode(encoding)
time.time(), int(in_bytes), int(out_bytes)
turtle.begin_fill()
pickle.load(f)
print(canvas.find_closest(x, y))
myList = map(gen_rand, myList)
xs.min(axis=0)
do_case1()
do_case2()
httplib.HTTPConnection.__init__(self, *args, **kwargs)
deltas[(deltas < 0) | (deltas > 100)] = 0
f = lambda x, y: x + y
output = data[2] + data[2]
np.where(m.any(1), idx0, np.nan)
zf.close()
lines = tuple(l.rstrip() for l in text_file.readlines())
fig = plt.figure()
print(dict(regex.findall(r, z)))
ax.plot(new_series, your_pandas_dataframe)
fig = plt.figure()
print(tag.string)
os.kill(2405, 15)
c = [True, True, False]
(0.0, [0.0, 0.0, 0.0], [0.0, 0.0]),
zerolistmaker(15)
ax.plot(x1, np.sin(x1))
dev.off()
0, 1, 0, 1, 0, 1, 0, 0, 0
image.thumbnail(size, Image.ANTIALIAS)
pathqueue.put(path)
im = Image.open(image_path)
all(v > 0 for v in pairs.values())
tokens = nltk.word_tokenize(sentence)
print([x for x, c in list(Counter(chain(*lists)).items()) if c != len(lists)])
vals = np.array(list(d.values()))
gain = (1 - R ** 2) * sqrt(1 - c ** 2)
data = os.read(self.pipe_out, 1)
pandas2ri.activate()
time.sleep(1)
(self.i, self.k, self.j) == (other.i, other.k, other.j)
x = np.arange(5)
soup.b.contents[0]
channel.basic_consume(on_message, queue_name)
select.select([], [], [])
print(np.all(A[idx_a] == B[idx_b]))
os.fsync(file.fileno())
c.append(random.choice(tmp).pop(0))
re.findall(re1, text)
size += os.path.getsize(os.path.join(path, f))
hxs = HtmlXPathSelector(response)
image.file.seek(0)
img = numpy.zeros_like(img, dtype=numpy.uint8)
new_col.shape
sys.stdout.close()
print(in_nested_list(x, 5))
t = np.arange(0, 0.001, dt)
time.sleep(2)
main()
np.interp(np.linspace(0, tmp.max(), nbin + 1), tmp, np.sort(x))
self.running = True
x, y = Point(0, 1)
print(sum(odd))
my_list
json = urllib.request.urlopen(url).read()
method(**options)
_grow
name = Column(String(20), primary_key=True)
opt.text.clear()
D[key].update(item)
today = datetime.datetime.today()
doc = tree.getroot()
wr.writerow([py_date] + sheet.row_values(rownum)[1:])
print([hex(ord(byte)) for byte in bytes])
turtle.fillcolor(color)
self.stream.start_stream()
file.write(file_data)
print(dict(parse_key_value_list(text)))
pprint(etree_to_dict(e))
print(dishes[key])
self._callbacks.append(callback_ref)
self.create_socket(socket.AF_INET, socket.SOCK_STREAM)
settings.MY_SETTING
id = Column(Integer, primary_key=True)
logger.addHandler(my_handler)
out.append((a, b))
handler = logging.StreamHandler()
random.random() * 6 + 1
arr[offs_x:offs_x + shape[0], offs_y:offs_y + shape[1]]
df.ix[[0, -1]]
to = models.EmailField(null=False, blank=False)
csv_output = csv.writer(f_output)
ax.yaxis.tick_right()
print(winner.flatten().tolist())
libvirt.virEventRegisterDefaultImpl()
python / path / to / filename.py
t = threading.Thread(target=run_one, args=(source,))
d.append(line)
_g = globals()
a = numpy.zeros((6, 6), dtype=numpy.int)
self.user_id == other.user_id
ax = fig.add_subplot(1, 1, 1)
result1.add(j + 1)
outputStream.close()
print(df)
process = Popen(command, stdout=PIPE, stderr=PIPE, bufsize=1)
rank = dict.get(key, 1.0)
c = list(itertools.product(a, b))
log = logging.getLogger()
exec(code, module.__dict__)
hbox.addWidget(self.view)
f.seek(0)
requests.post(url, data=data, headers=json.loads(headers))
df = DataFrame(flattened_records)
d.set_state(gst.STATE_NULL)
subprocess.call(shlex.split(command))
ax = fig.add_subplot(1, 1, 1, polar=True)
x = np.random.rand(25, 4)
output = {k: v for k, v in list(input.items()) if key_satifies_condition(k)}
fn(*args, **kwargs)
X = np.arange(100).reshape(10, 10).astype(float)
plt.colorbar(sc)
data = urllib.parse.urlencode(data)
visited_nodes.update(path)
axicon.set_yticks([])
np.delete(p_a_colors, indices, axis=0)
v[0] = 10
plt.show()
n > 1 and all(n % i for i in range(2, n))
turtle.left(90)
self.__dict__ = self
print((name, add, num))
nosetests
word[len(word):-(len(word) + 1):-1]
print(x)
QSize(200, 200)
c_long_p = ctypes.POINTER(ctypes.c_long)
print_decimal(b, prec)
counter = db.IntegerProperty(default=0)
f.read(1024)
self.func(*args, **kwargs)
self.openBtn.clicked.disconnect()
bytes([255])
df2.index = pd.MultiIndex.from_arrays(df1.values.T)
self.parse_request()
self.user = current_user()
user = models.OneToOneField(User)
self.hbox.pack_start(self.poles, False, False, 0)
plt.figure()
target.add_edge(1, 2)
result = zip(a, b, c)
driver.get(url)
accept.start()
foo(lcl)
app = QtGui.QApplication(sys.argv)
l1 = [(x, y) for x in range(n) for y in range(n)]
User.objects.filter(active=False)
print(repr(e))
s.close()
index += 1
reader = csv.DictReader(f)
sum(results) / len(results)
metadata.create_all(engine)
fff(train_set_x[index:index + 1])
func()
file = cStringIO.StringIO(urllib.request.urlopen(URL).read())
res = argparse.ArgumentParser.parse_args(self, *args, **kw)
str(lst[0])
nll
assert np.all(m[:, (i), :] == m_swapped[..., (i)])
send(packet1)
d = dict((v, k) for k, v in list(adict.items()))
user = models.OneToOneField(User)
draw.line([0, center, width, center], green)
Py_Finalize()
fig = plt.figure()
map(float, mystr.split()[:2])
request.session[SESSION_KEY] = user.id
self._printTree(self.root)
b.insert(index, a)
dict_writer.writerows(groupdata)
print((d.get(20), d.get(60), d.get(200)))
Super.__init__
f.seek(0)
curses.noecho()
d = dict(regex.findall(r))
lines = text_file.readlines()
D.update([1, 2])
title = models.CharField(max_length=100, unique=True)
self.wrong_values.clear()
main_dir = os.path.dirname(os.path.realpath(sys.argv[0]))
canvas.pack()
logging.root.setLevel(logging.DEBUG)
cv.Flip(frame, flipMode=-1)
new.show()
random.shuffle(l)
d1 = datetime.date.today()
plt.show()
sys.exit(1)
subprocess.Popen(command)
sys.stdout.flush()
os.urandom(10)
im.point(lut * im.layers)
cr = func(*args, **kwargs)
raise IOError
session.expunge(obj1)
ax = plt.axes([0.0, 0.0, 1.0, 0.8], frameon=False, xticks=[], yticks=[])
cursor = conn.cursor(MySQLdb.cursors.DictCursor)
[[-4, -4, -4, -4], [-7, 2, 2, 2], [-1, -1, -1, -1, -1]]
print(child.tag, child.text)
title = models.CharFiled(max_length=1000, blank=True)
str(thing)
inst = session.query(Model).first()
result.append(new_t)
df.sort_index(inplace=True)
M = np.random.random((5, 8))
thread.start_new_thread(self.Run, ())
zip(a, b)
t2 = [(a + b) for a, b in zip_longest(t, t[1:], fillvalue=t[0])]
plt.show()
self._s.close()
data = data[:75]
b.append(str(z))
process[-1].start()
f.write(chunk)
matches = [mapping[value] for value in a1 if value in mapping]
plt.show()
key = Column(Integer, primary_key=True)
ax.imshow(data.sum(axis=2).T)
sys.exit(1)
plt.show()
fig, ax = plt.subplots(1)
df[df.columns.intersection(col_list)]
float(item)
object.__getattribute__(self, x)
pcap_lookupnet(dev, ctypes.pointer(net), ctypes.pointer(mask), errbuf)
[list(x) for x in {tuple(e) for e in a}]
timestamp = (aware_dt - datetime(1970, 1, 1, tzinfo=pytz.utc)).total_seconds()
ax = fig.add_subplot(111)
time.sleep(0.25)
ws = root.winfo_screenwidth()
X, Y = np.meshgrid(np.arange(N), np.arange(N))
print(df2)
row = cursor.fetchone()
print(L[i])
b.append(c)
ranges = np.vstack((a, b))
self.mylist[i]
cur = conn.cursor()
http_server = tornado.httpserver.HTTPServer(application)
a.remove(item)
l = [_f for _f in l if _f]
type(z[0])
print([format_string.format(v, i) for i, v in enumerate(a)])
assert User.objects.count() == 0
self.right[i - len(self.left)]
print(counts[1])
numpy.nextafter(0, 1)
groups = Group.objects.filter(member=p1).filter(member=p2)
filename = socket.recv(1024)
{{p.first_name}}
arr = numpy.empty([0, 1], dtype=type1)
self.setContentsMargins(0, 0, 0, 0)
texts = list(chain.from_iterable(x[1] for x in posts))
list(data)
result.append(i)
urllib.request.install_opener(opener)
B = np.array([2, 4, 6])
set(fruits).intersection(fruit_dict1)
time.sleep(1)
print((df.Symbol1 == df.Symbol2) & (df.BB == df.CC))
browser = mechanize.Browser()
json.load(io)
c.extend(combinations(x, i + 1))
indices[i] += 1
sons.append(son)
urllib.request.urlretrieve(dirpath + file, localfilelocation)
a = np.ma.array(a, mask=False)
print([y for y in (x.giveMyNum() for x in q) if y > 1])
os.kill(os.getpid(), signal.SIGTERM)
admin.add_view(PaidOrderView(Order, db.session))
result = bar(*args, **kwargs)
conn.logout()
redirect(url, code=code)
func(cpy)
xsheet.write_row(0, 0, a)
urlparse.urljoin(url1, url2)
(x1, y1, q11), (_x1, y2, q12), (x2, _y1, q21), (_x2, _y2, q22) = points
[t for t in targets if t.startswith(prefixes)]
fig.subplots_adjust(left=0.1)
mask = (foo < 40) | (foo > 60)
geocalc(55.071, -6.508, 51.622, -8.886)
strprime = str(prime)
getattr(obj, attr_name)[index]
gy = np.zeros_like(f)
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(jar))
sorted(value, key=lambda k: k[0])
bar()
print(json.dumps(dict(data=x.tostring(), shape=x.shape, dtype=str(x.dtype))))
msg.attach(MIMEText(text))
zip(x[0], x[1])
data.append(int(el.text))
p.create_time()
code.interact(local=locals())
dict(e for i, e in enumerate(d.items()) if begin <= i <= end)
HttpResponse()
sys.stdout, sys.stderr = out
datetime.datetime.today()
print(df.head())
max(g(sorted(L)), key=lambda x_v: (len(list(x_v[1])), -L.index(x_v[0])))[0]
pool = mp.Pool(processes=10)
plt.plot(x, L.T)
fig.tight_layout()
get_localizer(request)
sleep(0.1)
zfile = zipfile.ZipFile(path)
self.pack()
app = Flask(__name__)
Cls.foo.__func__ is obj.foo.__func__
deletesys.argv[0]
forms.CharField(required=0),
self.Bind(wx.EVT_PAINT, self.OnPaint)
handlers.append(urllib.request.HTTPCookieProcessor(cookiejar))
result()
[j for i, j in mylist]
fig, ax = plt.subplots()
c.callback()
a, b = map(list, zip(*l))
HttpResponse()
curr_points = [Point(p[0], p[1]) for p in paired_points]
print(my_list[0::2])
self.send_response(200)
rgb = scipy.misc.toimage(np_array)
self.transport.write(message)
item
len(net.layers[0].blobs)
foo()
a = list(filter(partial(ne, [1, 1]), a))
gzf.read()
obj.save(**kwargs)
m.mask = i == j
controlset.a.plot(self.dummyx, self.dummyy, self.dummyz)
app = flask.Flask(__name__)
cap.set(cv.CV_CAP_PROP_FRAME_WIDTH, int(x))
docs = [[0, 1], [0, 0], [1, 0, 1]]
column += 1
initial_list.remove(item1)
df2
cust_dict[row[0]] = row[1:]
name = models.CharField(max_length=50)
files = [f for f in sorted(os.listdir(FileDirectoryPath))]
list1.remove(item)
metadata.create_all(db)
dict()
commatoze(input_str)
event.wait()
idx = np.linspace(0, 2 * np.pi, 100)
print([g.subs(x, k) for k in range(4)])
sys.stdin.readlines()
print(output)
competitors = Competitors.objects.all()
fig = plt.figure()
sa = np.sort(a)[::-1]
number_of_rows = sheet.nrows
seen = set()
np.clip(im[..., (0)], 0, threshold, out=im[..., (0)])
plt.margins(0.1, 0.1)
print(a, b, c)
self.assertEqual(cm.exception.code, 1)
plt.figure()
auth.set_access_token(access_token, access_token_secret)
template = env.from_string(template_string)
app.MainLoop()
process.wait()
[4, 5, 6, 7, 8]
any(check_string(line, word_list) for line in some_file)
fig, axs = plt.subplots(2, 2, figsize=(8, 8))
cursor = cx_Oracle.Cursor(connection)
records = Record.objects.all()
local_path = os.path.join(root, filename)
-1 * np.arange(20)
sleep(0.1)
b = np.array([1, 5, 20, 25])
writer.writerow(dict((h, h) for h in headers))
duration = models.PositiveIntegerField()
inspect.signature(io.BytesIO.read)
np.logical_or.reduce(xyz)
patlist.append(idx)
axins.boxplot(data)
s.sendmail(sender, recipients, msg.as_string())
foo = Foo()
x.most_common(1)
fig = plt.figure()
print(tone2)
__setitem__
pylab.plot(x, psi)
p.terminate()
lines.add(line)
driver = webdriver.Firefox()
Response(status=404)
num2words(1e+25)
print(data)
data = f.read()
np.maximum.reduceat(a, [0, 4, 7])
nested_class()
hxs = HtmlXPathSelector(self.br.page_source)
print(datetime.datetime.now())
a_t = np.vstack((a, np.zeros_like(a)))
[X, L] = octave.eig(A)
data = []
say_hello()
group.to_excel(writer, name)
M = M[:, (M.getnnz(0) > 0)]
self.a = []
blah_name = [k for k, v in locals().items() if v is blah][0]
line = line.split()
name = models.CharField(max_length=255)
ts = (midnight - datetime(1970, 1, 1, tzinfo=pytz.utc)).total_seconds()
diagmat = np.diag(d)
zerolistmaker(5)
sh2 = sct_subscript()
Users().save()
True
data = JSONField(db_index=True)
port = sock.getsockname()[1]
array = list(accumulate(rand(100)))
bv.setall(0)
out = coo_matrix((vals, (idx[:, (0)], idx[:, (1)])), dims).toarray()
fact = lambda x: x == 0 and 1 or x * fact(x - 1)
print(list(counter.values()))
print(r.text)
print([x.group() for x in pat.finditer(mystr)])
random.shuffle(list1)
CELERY_STORE_ERRORS_EVEN_IF_IGNORED = True
time.sleep(20)
print(my_class.__name__)
sorted(lists, key=lambda x: sorted(x, reverse=True), reverse=True)
giveupthefunc()
turtle.end_fill()
self.server = xmlrpclib.ServerProxy(self.url)
dollars = decimal.Decimal(cents) / 100
bool(a)
random_sample_output.writelines(random_sample_input)
logger.setLevel(logging.DEBUG)
rtc.BeginTextColour((255, 0, 0))
cb = fig.colorbar(im, cax=cax)
l.pop(0)
ring += 1
imshow(im)
x = self.get_subclass_name()
print(subprocess.list2cmdline(params))
output += np.sum(integrand(b), axis=1)
__import__(module_name)
root = tk.Tk()
setattr(obj, name, value)
driver = webdriver.Firefox()
print(repr(astr))
today = datetime.datetime.today()
record = dict(grouper(2, fields))
True
soup = BeautifulSoup(html_text)
new_array
compare_listcomp(a, b)
print(names_of1(x, locals()))
f.subs(x, 0)
listen_thread.start()
c = 55.6
Book.objects.filter(**filters)
b = np.array([2, 4, 6])
bpy.utils.register_class(customToolshelfPanel)
l[1::2] += 1
x = np.linspace(xmin, xmax, 100)
cursor.execute(query)
new_list = []
print(list(m))
smoothedData = dataSeries.rolling(10, center=True).median()
pdf.savefig(fig)
[[item] for item in ll[0]]
closey = close.copy()
l1.remove(item)
str(obj)
keys = [k for k, v in list(my_dict.items()) if v < threshold_value]
self.emitter.daemon = True
Image.objects.all().portraits().small()
buf[i:i + 2] = foo
lines = f1.readlines()
settings.py
time.sleep(10)
wr.writerows(list(Counter(textSorted).items()))
one_day = datetime.timedelta(days=1)
conn.rollback()
request.form
my_file.write(c)
f.write(s)
parser = argparse.ArgumentParser()
ax.add_collection(lines)
result = storage.save(djangofile.name, djangofile)
plot_chart(df, fig, ax)
mcastsock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
surface.get_npimage()
df = pd.concat([df] * 1000).reset_index(drop=True)
user = session.query(User).one()
modul.func()
smtp = smtplib.SMTP(server)
G = nx.DiGraph()
deletelist_of_g[to_idx:]
print(key)
list(itertools.combinations(l, 2))
dosomething()
print(next(t))
angle = atan((neuron2.x - neuron1.x) / float(neuron2.y - neuron1.y))
cur_set.pop()
root = Tk()
method()
print(err.lineno)
solve(sin(z) - 2, z)
{1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0}
result[0]
p2out = f.read()
f(*args, **kw)
counts[x] += 1
sys.stdout.write(processed_line)
zinfo.file_size = file_size
get_object_or_404(queryset, **filter)
plt.show()
iconfile.close()
sys.exit = new_sys_exit
gr1.switch()
console._run()
f = signal.filtfilt(b, a, f)
jsondata = json.load(urllib.request.urlopen(url))
x = numpy.arange(0, 10)
signal.signal(signal.SIGALRM, signal_handler)
print(myre.group(1))
cur = con.cursor()
z[np.arange(k - i), np.arange(k - i) + i]
self.finish()
sys.exit(app.exec_())
x.pop(0)
fig = plt.figure()
query_pairs = [(k, v) for k, vlist in d.items() for v in vlist]
getattr(inst, self.name)
x = numpy.asarray(x)
body = response.read()
app = QtGui.QApplication(sys.argv)
Employee.__init__(self, name, salary)
pygame.display.update()
sorted(names, key=splittedname)
z[np.arange(k - i) + i, np.arange(k - i)]
img = (np.random.rand(200, 200) * 256).astype(np.uint8)
Base.metadata.create_all(e)
print(covered_list)
list(map(lambda x: x * 2, [2, 2]))
cells = [str(i) for i in range(1, 10)]
setattr(p, s, new_value)
AB = map(sum, itertools.zip_longest(A, B, fillvalue=0))
m.tolist()
bbox = x.get_window_extent()
new = [k for k, g in groupby(data) if len(list(islice(g, 2))) == 1]
print([next(c) for _ in range(4)])
m1 = (pt1.getY() - pt1.getY()) / 1
map_nested_dicts(x, lambda v: v + 7)
sys.path.append(os.getcwd())
obj[name]
description = models.CharField(max_length=100, blank=True)
list(range(1, n + 1, 2))
sum(f(x) for f in phi)
np.correlate(a, [0, 0] + v + [0, 0])
local_minima.append([i, A[i]])
sorted(list(dct.items()), key=itemgetter(1), reverse=True)
decorator
plt.show()
{}
b = np.vstack((a, a))
app.listen(settings.TORNADO_PORT)
ee.connexion.add(*e.connexion.all())
canvas.tag_raise(firstRect)
layout.addWidget(self.button)
file_.close()
np.add.at(a, b, 1)
df
ax1.plot(pd.Series(np.random.uniform(0, 1, size=10)))
screen.fill(white)
pixel = walnut.getpixel((x, y))
self.linenumbers.redraw()
sys.stdout.write(line)
rowMean = a.sum(1) / (a != 0).sum(1)
print(avg_positive_speed([0.0, 0.0]))
doing_fd.truncate()
user = Column(String)
list1, list2 = filterer(list1, list2)
plt.plot(t, s)
count(s, li)
dis.dis(f)
get_superdicts(a)
print(line)
cv.SetCaptureProperty(video1, cv.CV_CAP_PROP_FRAME_WIDTH, 800)
etree.tostring(tree)
self.f(obj, *args, **kw)
data = json.load(fp)
lower.append(word)
line(src, Q1, Q2, Scalar(0, 0, 255), 1, CV_AA, 0)
t.pack()
pattern.search(html).group()
logdet = np.add.reduce(absd, axis=-1)
list[0] += 1
print(interleave(a, b))
A = np.random.randint(0, 10, 100)
item.setExpanded(True)
reactor.connectTCP(HOST, PORT, factory)
csv_output.writerow(fieldnames)
shmctl(shmid, IPC_RMID, NULL)
display.stop()
p = argparse.ArgumentParser()
distance[0][1]
conn.set_debuglevel(False)
queryset = Profile.objects.all()
{{formset.management_form}}
tree_selection.set_mode(gtk.SELECTION_MULTIPLE)
recurse_matches_py(a, b, alo, blo, ahi, bhi, answer, maxrecursion - 1)
new_nums.append(mean(nums[index - 1], nums[index]))
last_name = models.CharField(max_length=50)
self.ax.figure.canvas.draw()
G.add_nodes_from((n, B.node[n]) for n in nodes)
self.queue.put(message)
[chr(item) for item in range(ord(s[0]), ord(s[-1]) + 1)]
grview.setScene(scene)
conn.rollback()
zip(*theArray)
print(a, b, c, d)
pl.plot(x, dist.cdf(x))
result.reverse()
print(thelog)
session.add(user)
fsizer = wx.BoxSizer(wx.HORIZONTAL)
print(max(map(len, inverse_regex.ipermute(data))))
value = random.choice(mylist)
response.set_status(exception.status_int)
ax2.set_navigate(False)
result.fillna(0, inplace=True)
s.say_hello()
RSI2.plot()
wb.Close()
print(m.group(1))
pickle.dumps(ThreadPoolExecutor(1))
random.shuffle(list2)
b = a.copy()
print(item)
i += 1
pBuf = ctypes.create_string_buffer(init_size)
random.randrange(5, 60, 5)
foo()
root_logger.setLevel(logging.DEBUG)
sqs._endpoint.http_session.close()
unittest.main()
data = json.loads(api_data)
h = HTMLParser.HTMLParser()
dir()
print(get_numbers_from_filename(filename))
print(new.timestamp())
print(e.subs([(a, c), (b, d)]))
df = pd.DataFrame(dict(zip(headers, foo)))
z.append(x[i] + y[i])
print(list(groups.values()))
ax.imshow(A, **kwargs)
sys.stdout.flush()
shift_idx = np.flatnonzero(sorted_a[1:, (1)] > sorted_a[:-1, (1)]) + 1
print(r[0])
sleep(1)
res = [lookupdict[k] for k in arr.tolist()]
a[:2, :2] = np.arange(4).reshape((2, 2))
t.start()
strided.reshape(dim)
print(args)
df = pd.concat([num_df, enum_df], axis=1)
print([a.value for a in arr])
np.divide(sumA, sumB)
op(x, y)
fig, ax = plt.subplots()
G.add_edge((q, r), (q + 1, r - 1))
composite_list = [my_list[x:x + 5] for x in range(0, len(my_list), 5)]
idx = np.array([0, 0, 0])
model.add(act)
sys.exit(a)
(1.0, [1.0, 1.0, 1.0], [0.0, 0.0]),
ID = db.Column(db.Integer, primary_key=True)
dd[key].append(value)
a2Note.play()
submodule1.py
template.format(*x)
signal = signal.sum(-1)
df = pd.DataFrame(list(zip(*foo)), columns=headers)
f2.close()
all(item in list(d2.items()) for item in list(d1.items()))
stdout, stderr = proc.communicate()
madata
print(model.intercept_, model.coef_)
R = np.array([0.5, 0.5, 0.5])
thing = getattr(obj, name)
x + y
[expression for item in list if conditional]
comm.Recv([data, MPI.CHARACTER], source=0, tag=22)
foo.bar(1, 2)
p.terminate()
root.iconify()
list_list = []
list(self._sa_instance_state.attrs.items())
diff.extend([i for i in range(len(small), len(big)) if i not in ignore])
gy = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])
type(x[0])
add_subdirectory(name_of_python_app)
df = pandas.DataFrame(x_scaled)
sleep(5)
print(combs(sampleip))
response = br.response()
tests.test_001_func()
hash(b)
mock_sgc_obj.assert_called_once_with(mock_mail_obj)
self.mocks
list(it)
print(pool.map(worker, list(range(5))))
timezone.make_aware(datetime.now(), timezone.get_current_timezone())
metadata = MetaData()
screen.keypad(0)
arr[:n, :n]
plt.ioff()
cursor = conn.cursor()
print(line)
np.all(s == s2)
tour.append(current_vertex)
holes = np.logical_and(cskel, noholes)
print(convert_excel_time(1.4006944444444))
print([group.mean() for group in np.split(x, np.where(np.diff(x) > th)[0] + 1)])
sum(p)
root = Tkinter.Tk()
Response(serialized_student_detail.data)
data.sort(key=lambda r: r[1])
self.argspec = inspect.getargspec(src_func)
q[p] = np.arange(len(p))
self.fptr = fptr
recursiveBinaryChop(value, elementList, min, max)
ranges = zip(cuts, cuts[1:])
self.screen.blit(self.img, (0, 0))
print(line)
self.fig = plt.figure()
{{form.title}}
elem.clear()
self.__dict__.update(self._defaults)
[k[0] for k in d]
isinstance(sys.stdin, file)
list(set(theList).intersection(theDict))
matrix[2][0] = 5
print(line.split()[1])
label.master.lift()
page = str(BeautifulSoup(response.content))
zf.extract(member, path)
my_cmd.cmdloop()
in_memory_file = s.getvalue()
encodings.insert(0, denc)
{{animal.p}}
row_count += chunk.shape[0]
tweettext = f.read()
p.join()
a.foo()
srf.blit(f.render(unistr, True, (255, 0, 0)), (0, 0))
self.name = name
print(list(df.keys()))
parser = argparse.ArgumentParser()
numbers_float = [float(x) for x in numbers_str]
print(image.get_rect().size)
ax2 = fig.add_subplot(122)
sw.pack(side=LEFT, fill=Tix.BOTH, expand=1)
lasts = []
dict([[i, j[0]] for i, j in enumerate(x)])
image.show()
bins = bins[:-1] + (bins[1] - bins[0]) / 2
serializer_class = SpeakerSerializer
i = np.argmin(np.abs(df.index.to_pydatetime() - image_time))
word[0].isupper()
crawler.crawl(spider)
array([[0, 1, 0], [1, 1, 1], [0, 1, 0]])
plt.show()
q.try_run()
b = a[:, (np.arange(a.shape[1]) != 50)]
[item for _, item in zip(list(range(items)), list(self.items()))]
self.tristate_parent(parent)
ser.write(theinput)
data = f.read()
arr.shape
theta = np.linspace(0, 2 * np.pi, 40)
list(set(first) | set(second))
self.buttonPanel1.Show(False)
print(type(a))
isinstance(s, str)
reader = csv.DictReader(f)
m.hexdigest()
abs(hash(s)) % 10 ** 8
db.init_app(app)
tk.Frame.__init__(self, *args, **kwargs)
wx.Panel.__init__(self, parent)
it.dropwhile(lambda x: x != 4, it.cycle(l))
data.append(el.text)
parser = HTMLParser()
self.count += 1
searchlines = f.readlines()
threadB.run()
a[np.arange(len(a)), lst]
name = models.CharField(max_length=128)
a is np.asarray(a)
browser = webdriver.Firefox()
assert addup(5000) == sum(range(5001))
np.sqrt(np.sum((v1 - v2) ** 2))
time.sleep(0.1)
d = {part: d}
random.shuffle(listOfItems)
L = L[ndx]
column_names = [row[0] for row in cursor]
print(c.most_common(5))
print(line)
bool_arr = np.array([myfunc(row) for row in x])
self.children.append(child)
fig = plt.figure()
b()
e.set_alpha(1.0)
pyfoo
getattr(item[1], item[0])()
soup = BeautifulSoup(htmlSource)
np.array(x)
deletelist
f_out_blg.write(line)
f_out_extkeys.write(line)
partition = lambda p, xs: (list(filter(p, xs)), [f for f in xs if not p(f)])
f(*args, **kwds)
self.name = name
ax.xaxis.label.set_rotation(90)
parser.add_argument()
block = a[y_coords[row, col][:, (np.newaxis)], x_coords[row, col]]
plt.ylim(np.log10(ilim))
main()
axis.set_major_locator(MaxNLocator())
plt.gca().add_artist(leg1)
myarray[0][:1]
b - b.multiply(a)
print(vars())
self.ax.xaxis.set_major_locator(month)
sys.stdout.write(c)
plt.plot(t, 2 * s, c=seaborn.color_palette()[2])
surface.blit(word_surface, (x, y))
print(fmt.format(*x))
json.dumps(value)
functools.reduce(add, list(range(1, 11)))
data = numpy.zeros((200, 200, 4), dtype=numpy.uint8)
yidx = (raw[:, (1)] - yrange[0]).astype(int)
ax = plt.subplot(211)
choices.pop(0)
self.client_tcp_timeout.cancel()
ax.autoscale_view()
last_digit = n % 10
r = congruent.index.to_series().map(lkp).values
A()
a, b = b, a
pickle.dump(results, f)
requests.get(queryurl, auth=headeroauth)
b = list(set(a))
run()
idx_max = max(enumerate(x), key=lambda x: x[1])[0]
a.index(f(a))
sys.path.append(egg_path)
print(string.ascii_lowercase)
cl = HierarchicalClustering(L, lambda x, y: abs(x - y))
file.write(response.text)
df_slcd
d = np.diff(x1.astype(int))
print((lst, sum(lst)))
ax.add_patch(rect)
print(c.most_common(1))
fig.tight_layout()
b.build_platlib
conn.connect((ip, port))
s[n:]
m = np.ma.masked_where(y > 2, y)
new_list = [[x[1] for x in y] for y in the_list]
gprun()
{url.current()}
text.see(tk.END)
cursor = conn.cursor()
count += countit(target, key, count) + 1
new_dict = deepcopy(orig_dict)
c = numpy.repeat(b, a)
self.my_stuff = my_stuff
draw.rectangle((67, 0, 100, 100), fill=(255, 0, 0, 0))
sum(char == c for c in word)
fig = plt.figure()
df
a.py
list(fun(d))
d[item] += 1
plt.draw()
fig = plt.figure()
Response(up_file.name, status.HTTP_201_CREATED)
c = np.arange(10).reshape(5, 2)
np.repeat(np.repeat(A, 2).reshape(2, 4), 2, 0)
c.setopt(c.HEADERFUNCTION, headers.write)
ndates = (reobj.match(date).groups() for date in dates)
plt.show()
pygame.draw.circle(screen, (200, 0, 0), pos, 10, 2)
self.signal.connect(self.receiver, **self.kwargs)
leerdammer = Cheese.slightly_holey()
print(formatdate(timeval=stamp, localtime=False, usegmt=True))
self.image.show()
df = pd.DataFrame(np.random.rand(480, 4000), dates, stoks)
self.rect = self.image.get_rect()
a.append(i)
print((choice_data.i, choice_data.card))
self.damp = damp
counts = Counter((k[1], v) for k, v in dictA.items())
reverseCom([4, 5, 6], 2)
lines = f.readlines()
tick.set_markersize(6)
{valid: true, data: whatyouwanttostore}
print(list(my_splitter))
disable()
key_func()
g.close()
action.click()
[theDict[item] for item in theList if item in theDict]
r = [(a, b) for a, b in itertools.zip_longest(l, l[1:], fillvalue=l[0])]
data = json.load(sys.stdin)
new_nums.append(nums[index - 1])
plt.mlab_source.set(x=x, y=y, z=z)
print(tuple(chain(*base_lists)))
today + relativedelta.relativedelta(weeks=1, weekday=1)
signal.pause()
counters = counters.reshape(len(peptides), 16, 5)
draw.rectangle((0, 67, 100, 100), fill=(0, 255, 0, 0))
test1.foo()
self.remove(value)
fmax = np.maximum(f1, f2)
fout.write(fin.read())
a.foo()
print(m.__class__.__name__)
tuple([(x.fptr if isinstance(x, self.__class__) else x) for x in t])
legend = ax.legend()
fame = models.PositiveIntegerField(default=1)
ctypes.cast(a.ctypes.data, ctypes.POINTER(ctypes.c_float))[0]
b = random.choice(range(a, len(xs)))
ax1.set_xticks(list(range(len(data.columns))))
new_df = pd.DataFrame()
QtDBus.QDBusConnection.sessionBus().send(msg)
server.shutdown()
p1 = subprocess.Popen(args, stdout=subprocess.PIPE)
print(df)
type(self) == type(other) and self.value == other.value
Request(url=self.login_page, callback=self.login)
print(generate(client, sys.argv[1]))
self.queue.add(item)
print(line)
t = Text(root)
glOrtho(0, w, h, 0, 0, 1)
self.assertTrue(wrn)
parser = argparse.ArgumentParser()
print(list(headers.keys()))
self.bttn.grid()
repr(f.__closure__[0])
driver = selenium.webdriver.PhantomJS()
dostufF()
ax.set_yticks(arange(df.shape[0]))
f(test=1)
[4, 5, 10]
app = Flask(__name__)
signal.signal(signum, _kronos)
b.pack()
b_thread.join()
Z = np.zeros((2, 2), dtype=int)
p.append(e)
app = QtGui.QApplication(sys.argv)
ax = fig.add_subplot(111)
mean_vals = np.bincount(out, weights=A) / np.bincount(out)
myfunc()
d[k] = frozenset(v)
rows = cursor.fetchall()[-10::1]
zip_longest(fillvalue=fillvalue, *args)
lines = f.readlines()
sys.stdout.flush()
print(t.timeit(number=1))
print(f(2))
self.scrollbar.config(command=self.text.yview)
app.exec_()
writer = csv.writer(f)
lst = [0, 1], [0, 4], [1, 0], [1, 4], [4, 0], [4, 1]
d += timedelta(days=1)
self.response.out.write(json.dumps(response))
x, y = [], []
self.button.setIconSize(QtCore.QSize(128, 128))
f.close()
self.__dict__.update(kwargs)
log.start(loglevel=log.DEBUG)
print(stdout)
rd.fit(X, y)
df2 = pd.DataFrame(randn(5, 10))
new_df = new_df.append(view)
num_int = int(num_str)
cancel(-a * b * exp(a * b * x) / (1 + exp(a * b * x)))
{{comment.comment}}
file_date_tuple_list.sort(key=lambda x: x[1])
f.close()
gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
wait = WebDriverWait(driver, 10)
all(some_list)
count(i + 1, j) + (count(i + 1, j + 1) if seq[i] == sub[j] else 0)
succs[u].add(v)
print(not any(dict1.values()))
[(x, y) for x, y in zip_longest(it1, it2)]
self[something]
root = Tk()
i = int(i)
animate / path / to / animated.gif
self.clear()
view.sel().add(sublime.Region(0, 0))
frozenset(x).intersection(y)
jobs.append(task2())
d = dict(map(reversed, list(a.items())))
random_sample_output.close()
n -= 1
results.put(simulation_result)
self.a.b.c
sum2 = data1[np.in1d(idx1, idx2)].dot(data2[np.in1d(idx2, idx1)])
keys = [r[1] for r in data]
response = requests.get(url)
pyplot.subplot(2, 1, 1)
m.get_server().serve_forever()
it = chain(a, b)
gevent.sleep(1)
dc.SetBrush(wx.Brush(self.GetForegroundColour()))
a = np.arange(2, 10)
fmt.format(msg, lineno, colno, endlineno, endcolno, pos, end)
match.group(1).upper()
file_write.write(r.read())
gridy = np.linspace(-1, 1, 5)
fp.truncate()
df.loc[~(trans_neg | trans_neg.shift(-1))]
print(df.iloc[i - N:i])
socket.inet_pton(socket.AF_INET6, domain)
file.close()
parsed = json.load(handle)
response
print(type(foo))
acceptable
libvirt.virEventRunDefaultImpl()
pl.show()
QtCore.QCoreApplication.quit()
print((a, b, c, d))
self.uncheck_descendant(item)
sqrt((a.x - b.x) ** 2 + (a.y - b.y) ** 2)
logger.setLevel(logging.DEBUG)
plt.imshow(np.mod(data, 42))
print(dict(**f))
ExampleModel.objects.update(string_field=f)
print((address, networka, networkb))
im.set_data(frame)
fd = os.open(filename, os.O_RDWR | os.O_CREAT)
print(json.dumps(get_classes_from_text(text), indent=4))
res = urllib.request.urlopen(url)
plt.setp(xtickNames, rotation=0, fontsize=40)
data = json.load(open(filename))
recursion(index + 1, result + ls[index])
a = np.sort(a)
[(temp[0] + x) for x in temp[1:]] if len(temp) > 1 else input
srf = pygame.display.set_mode((500, 500))
self.agg_log.addHandler(logging.StreamHandler())
gens.append(gen())
mapf = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_WRITE)
print(round.__doc__)
dict()
print(buff[:-1])
test.cvec()[0] = 0
rs = func(*args, **kwargs)
pygame.init()
print(pd.concat([df.iloc[(0), :], df.iloc[(-1), :]], axis=1).T)
sip.delete(self.widget_name)
a = np.zeros((4, 4))
primerange(a, b)
fig = plt.figure(figsize=(8, 6), dpi=100)
plt.xticks(xvals, xnames)
say_captcha_is_invalid()
numSeq(1, 0, 0)
file_content = f.read()
f = (lambda a, b, c, **rest: lambda x: a + b * c - x)(**locals())
container = models.ForeignKey(Dicty, db_index=True)
iter(foo.splitlines())
self.root.setLevel(logging.DEBUG)
ax.set_xticks(arange(df.shape[1]))
my_path = module_locator.module_path()
self.testbed.deactivate()
pb = gtk.gdk.Pixbuf(gtk.gdk.COLORSPACE_RGB, False, 8, sz[0], sz[1])
sys.stdout.write(frame.tostring())
all_same([])
[v for b, v in self._choices if b & selection]
db = SQLAlchemy(app)
self.companion.stdin.write(datum)
type.__new__(self, name, bases, classdict)
controllers / default.py
img = Image.open(sys.argv[1])
draw()
ret = numpy.zeros(data.shape[:2], dtype=numpy.bool)
WSGIPythonExecutable / path / to / python / 2.5 / exe
plt.clf()
d = os.path.abspath(startPath)
fp.close()
poly = PolyCollection(verts, facecolors=(1, 1, 1, 1), edgecolors=(0, 0, 1, 1))
m.groupdict()
self.Bind(wx.EVT_CHECKBOX, self.EvtCheckBox, self.checkbox[i])
ui.syn()
{{animal}}
saved = locale.setlocale(locale.LC_ALL)
example2(x, a, b, D)
s.setsockopt(socket.SOL_TCP, socket.TCP_KEEPINTVL, 1)
deletesys.modules[__name__]
data.sort()
plot(x, y1)
MagicMock.__init__(self, *args, **kwargs)
G.add_node(1, pos=(1, 1))
user = models.OneToOneField(User)
unittest.TextTestRunner(verbosity=2).run(suite())
a = itertools.chain.from_iterable(x)
self.node = Node()
tup[1] << 8 | tup[0]
assert len(s1) == len(s2)
frame.grid_rowconfigure(0, weight=1)
zip_longest(fillvalue=fillvalue, *args)
self.lock = threading.Lock()
shared_queue_list.append(shared_queue.get())
fig, ax = plt.subplots(figsize=(8, 6))
logger = logging.getLogger(__name__)
digs[0]
confused_array[mask] = 1
child.kill()
c.execute(query, flattened_values)
[list(i) for i in set(map(tuple, (sorted(i) for i in a)))]
person.guilds.append(self.key)
self.master.rowconfigure(5, weight=1)
np.isnan(A)
[l[i:i + n] for i in range(0, len(l), n)]
fig1 = plt.figure()
cj = cookielib.CookieJar()
python - pip
list(islice(missing, 0, count))
PyparsingGrammar.parseString(line)
counts = Counter(a)
os.rename(out_fname, fname)
subprocess.call(cmd)
results.predict(start, end)
{an_object.name: an_object for an_object in object_list}
b = models.ForeignKey(B)
self.buf.read() + self.fileobj.read()
x = SimpleClass()
self.__dict__ = json.loads(j)
uncompressed = zippy.read()
plt.xlim(-1, 1)
df.columns = df.columns.droplevel()
median = df.impwealth[cumsum >= cutoff].iloc[0]
time.sleep(timeout)
help(my_list.append)
array[i, j] += 10
output = p2.communicate()[0]
next_file.write(row)
a.add(1)
dosomethingelse
fobj.seek(0)
int(math.floor(math.log10(self.n) + 1))
br.set_handle_robots(False)
ax1.xaxis.tick_top()
time.sleep(5)
os.chown(path, _user, _group)
stage.py
result = list(create(20, dict))
arrays = [np.asarray(x) for x in arrays]
axes_1.axis([-5, 5, -5, 5])
X = np.linalg.solve(A, np.ones((2 * (n - 1),)))
list(db.collection.aggregate(pipeline))
[pypitest]
bpos += blo
loader.write(response.read())
np.prod(c.shape) == np.prod(a.shape) * np.prod(b.shape)
dict2 = dict(dict1)
id, value = zip(*ans)[:2]
max(mywords, key=len)
socket.inet_aton(addr)
[(row[:column] + row[column + 1:]) for row in matrix]
sorted(set(it.chain(*ranks)), key=c.__getitem__, reverse=True)
a[b].mean()
plt.figimage(a, cmap=plt.gray())
spam_list.sort(key=order.get)
fig, ax = plt.subplots()
apply_labels(p1, labels)
browser.close()
cu.save()
print(item.unique())
coo = numpy.random.randint(0, N, size=(M, 2))
normY = np.sqrt(ssY)
RSAkey = RSA.generate(1024, rng)
self.children.append(node)
print(next(line))
c = conn.cursor()
control = wx.StaticBitmap(self, -1, bitmap)
x = np.linspace(0, 2 * np.pi, 100)
mailServer.close()
project.save()
list()
map(itemgetter(1), sorted(m.groupdict().items()))
win.add(scroll_win)
pylab.gca().add_patch(patches.Polygon(pp, closed=False, fill=False))
[e for e in l if e % 2]
plt.show()
outlist[-1].append(json.dumps({k: d[k]}))
fig = plt.figure()
result_queue.put(res)
pdf = pyPdf.PdfFileReader(p)
assert np.allclose(x, x1) and np.allclose(y, y1)
matplotlib.__version__
tfc = tf.Variable(npc)
word_counter = Counter(words)
result = [item for item in list_y if item[0:2] not in list_x_set]
res.show()
ax.contour(X, Y, Z)
print(l[i])
self.send_blob(blob_info, save_as=False)
self.__dict__.update(kwargs)
self.doc.getroot()
l[i] = l[i] * 2
print(mydict[alias1])
i += 1
data = np.random.random((N, 7))
ax.set_aspect(1)
neurons = [Neuron() for n in range(5)]
getattr(self.obj, self.property_names[item])
res.append(1)
foo(iterable)
joinable.append(mpp)
self.pool = multiprocessing.Pool(processes=N_PROC)
df
c = b.flat
gluOrtho2D(0.0, 1.0, 0.0, 1.0)
plt.show()
ax.figure()
{letter: max(d[letter] for d in dicts) for letter in dicts[0]}
ax.legend()
result = requests.get(url)
rlcn.method2()
resident.ssa_set.all()
i.split()
user = session.query(User).get(someid)
responses.pop()
ax = plt.gca()
print(i)
y[words[0]].append(words[2])
myModule.printY()
fo.close()
[e for e in foo(bar)]
nbr_edgeobjects += 1
foo.bar = bar
target.send((key, n * 10))
__init__.py
handler = logging.StreamHandler()
str.__new__(cls, content.upper())
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj))
response = requests.get(url)
conn = imaplib.IMAP4_SSL(servername)
Queue._put(self, item)
ax.set_zlim([-1, 8])
pdb.set_trace()
2
argsdict.update({argname: argvalue})
plt.plot(list(range(10)))
requests_log.setLevel(logging.WARNING)
html = f.read()
(1.5 < a) & (a < 2.5)
print(list(cm.datad.keys()))
json.dumps(dict(nodes=graph.nodes(), edges=graph.edges()))
c = np.r_[a, b]
fs, data = wavfile.read(filename)
(0, 1), (5, 4)
self.window.move(gtk.gdk.screen_width() - 100, 0)
(xdiff.dot(Sigma_inv) * xdiff).sum(axis=-1)
[0, 0, 0, 0, 0],
mat[0] * (len(ixs) - np.count_nonzero(nzmask)) + nzsum
partition(list(range(105)), 10)
serverSocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
opener = urllib.request.build_opener(authhandler)
app.exec_()
self.outstream.write(self.theA)
plt.clf()
cgi.test()
fig = PLT.figure()
1, 0, 0, 0, 1, 0, 1, 0, 0
ranges.append((group[0], group[-1]))
arr = input()
a.insert(2, x)
shutil.rmtree(tmp_dir)
self.SetTopWindow(self.frame)
self._d[self._s[k.lower()]]
print(model.score(X, y))
B = [4, 5, 6]
all(list_of_bools)
root = ET.fromstring(xml_str)
deleted[k, j]
some_value
p.exists()
fig.canvas.draw()
row_ind.extend([k] * len(v))
gcf().canvas.draw()
dicto[ele[0][0]].append(ele)
Fruit.__init__(self, **kwargs)
width = t.winfo_width()
task.retry(queue=task.request.hostname)
hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
mdls_output = pat.sub(myfn, mdls_output)
print(obj.__class__.__name__)
0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0
pprint.pprint(value)
(a[0], b[0]),
data = numpy.where(selected_indices, [4, 5, 6], data)
pd.DataFrame({n: foo(df.T[row].nlargest(k)) for n, row in enumerate(df.T)}).T
pickle.dump(i, sys.stdout)
df.drop_duplicates().A.value_counts()
self.l.append(Tree(i - 1))
result = urllib.request.urlopen(request).read()
foo(*values)
driver.close()
b = numpy.random.randn(20, 20)
parser = argparse.ArgumentParser()
tree = ET.parse(filename, parser=LineNumberingParser())
print(root.tk.splitlist(filez))
grouped.last()
c1, r1 = np.array([np.arange(10), np.arange(10)])
im = im.resize((int(width / rat), int(height / rat)))
df.groupby(date.values).mean()
ax = plt.subplot(gs[:2, :])
self.nesting += 1
logging.setLoggerClass(Logger)
number += 1
sys.stdout.flush()
imagelist.extend(glob.glob(os.path.join(image_directory, ext)))
deletesys.path[-1]
reader = csv.reader(f)
data.mode
server = smtplib.SMTP()
angle2 = abs(math.degrees(math.atan(slope2)))
df[list_of_cols].dropna(thresh=1).head()
sys.modules[__name__] = Wrapper(sys.modules[__name__])
probs = [0.1, 0.2, 0.5, 0.2]
sys.excepthook = debugexcept
[strs[i] for i in list(ret)]
draw.ellipse([left, top, right, bottom], fill=fill)
a.some.__self__ is a
x += np.random.random(size=12)
toc2(False)
print(django.get_version())
print(str(item))
worksheet.update()
pattern = eval(input())
source = inspect.getsource(func)
tot += (((data[i + 1:] - data[i]) ** 2).sum(1) ** 0.5).sum()
my_set = set(my_list)
x = np.arange(100, 1, -1)
h.digest()
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
fig.canvas.draw()
angle1 = abs(math.degrees(math.atan(slope1)))
slither / slither / __init__.py
columns = [i[0] for i in cursor.description]
c = [(x + y) for x, y in zip(a, b)]
mail.inbox()
pydevd.settrace(suspend=False)
print(f.read())
driver.set_window_size(1024, 768)
url = s.get_location()
self.close()
createsuperuser()
ax = subplot(111)
setattr(theclass, x, logging(getattr(theclass, x)))
i = Image.open(sys.argv[1])
a = qt.QApplication(sys.argv)
ax = fig.add_subplot(111)
sys.exit()
my_opener = urllib.request.build_opener(MyHTTPHandler)
datetime.datetime(*t[:6])
cv2.line(vis, (x1, y1), (x2, y2), green)
[[x.strip() for x in row] for row in reader]
fn = (lambda x: x) if True else lambda x: x * x
ax.add_patch(p1)
k, v = t.pop(0)
blih()
bluh()
sys.stdin.readline()
shutil.rmtree(to_path)
repeated = [i for i in lst if lst.count(i) > 1]
ax.plot(list2)
response = urllib.request.urlopen(req)
logging.info(str(item))
fig = pl.figure()
result = [[i for i, row in enumerate(X) if (s == row).all()] for s in S]
mask = np.ones(a.shape, dtype=bool)
print(new_str)
counts, edges = np.histogram(np.random.rand(100), bins=cdf)
Ig = arange(t1.min(), t1.max(), 1)
sys.stdout.write(c)
nx.simple_cycles(G)
print(str(d))
np.maximum(x, 0)
self.timer = QtCore.QTimer()
final.append(compound[x - 1])
w, h = map(int, f.readline().split())
re.findall(RE, string)
df[cols].sum(axis=1)
dc.SetBackground(wx.Brush(self.GetBackgroundColour()))
pd.DataFrame(Dict)
module = sys.modules[__name__]
GinvVV = np.asarray(GinvVV)
data = urllib.request.urlopen(url).read()
c.release()
jsonObj = json.dumps(data)
key, value = line.split()
parser = argparse.ArgumentParser()
100 * np.round(dfrm, 2)
[2]
result = {}
self.response.write(rv)
self.schedule.cancel(self.event)
win.SetPosition((x, y))
__hello()
word_freq.update(line.split())
foo(a)
self.cursor.close()
cr.set_source_rgba(0.0, 0.0, 0.0, 0.0)
next(func)
s[:i] + s[i:].capitalize()
sys.path.append(os.path.dirname(fullpath))
ax = fig.add_subplot(111)
temp.__setitem__(0, 1)
fig.colorbar(im)
np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)
myset.pop()
self.__dict__.update(*args, **kwargs)
print(key, value)
MyModel2.mymodel1.through.objects
p.open_files()
self.mtx.lock()
test[-1] += 1
ax.yaxis.set_tick_params(size=0)
self.lock = multiprocessing.Lock()
ode15s.set_initial_value(u0, t0)
print(input[indices[indices < 5]])
gen = (n for n in range(0, 11))
pwd.getpwuid(os.getuid())[0]
db.collection.find(condition).limit(1).skip(Math.floor(Math.random() * N))
iter([self.instanceA, self.instanceB, self.instanceC])
new_body_text = re.sub(pattern, FootnoteNumbers(), text)
args.func(**args_for_func)
foo()
myPopy.wait()
SPN[0].shape
QtCore.QObject.__init__(self, parent)
indices = range(len(li) - 1, 0, -1)
self.move(frameGm.topLeft())
nDigits = 1 + floor(log(nmb, base))
print(etree.tostring(root))
p.name()
new_password
f(*args, **kwargs)
print(repr(s.getvalue()))
df
Z = inner1d(X, Y)
ax1 = fig.add_subplot(2, 1, 1)
list(range(10 ** 14, 10 ** 15, 10 ** 14))
form = ModelForm(request.POST, request.FILES)
print(s.rhyme())
pytime = os.path.getmtime(os.path.join(root, sc))
self.cumweights.append(cumsum)
copytree(srcname, dstname, symlinks, ignore)
line = input()
pool = multiprocessing.Pool()
df = df.sort()
mylist.pop(0)
f.seek(0)
db = SQLAlchemy(app)
id(np.nan) == id(np.nan)
x[i] = y - 1
sys.exit()
tree = et.fromstring(xml)
user = models.ForeignKey(User, unique=True)
self.tags.add(tag)
data = np.array(im)
c2.setopt(pycurl.PROXYTYPE, pycurl.PROXYTYPE_SOCKS5)
print(e.tag, e.text, repr(e.tail))
G.add_edge(1, 2)
start_thread()
out.write(txt)
self.SetSizer(sizer)
len(answer) - star_len, star_len, len(prediction) - star_len
G.add_edge(4, 5)
plt.figure()
cmat1 = scipy.sparse.csc_matrix(mat1)
{1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0}
f.set_axis_off()
print(s)
obj = json.loads(s, object_hook=_decode_dict)
zip_longest(fillvalue=padvalue, *([iter(iterable)] * n))
canvas.show()
print(df1.div(len(df.index)))
np.sum(a.dot(b), axis=0)
client.set_missing_key_policy(paramiko.AutoAddPolicy())
df1.update(df1_updater)
sfile.close()
npage = pdf_im.getNumPages()
virtualenv - p / path / to / python - anaconda - version
Xmesh, Ymesh = np.meshgrid(np.linspace(0, 1, Nx), np.linspace(0, 1, Ny))
self.run()
fig, axes = plt.subplots(nrows=2, ncols=2)
tf.pack(states)
s.quit()
args = parser.parse_args()
(a[i:] > a[i]).nonzero()[0][0] + i
tar.close()
cr.rectangle((0, 0) + size)
nanoseconds = int(time.time() * 1000000000.0)
xs = np.random.choice(arr, n - 1)
screen.getch()
page_source = browser.page_source
opener.open(url).read()
handles, labels = ax.get_legend_handles_labels()
open(path, mode)
wPM.restype = wintypes.BOOL
tokens = [t.lower() for t in tokens]
i = i + 1
out, err = process.communicate()
d.setdefault(k, set())
window.mainloop()
line = proc.stdout.readline()
plt.show()
plt.plot(x, s(x))
df = (df1 - df2).dropna().copy()
array[x, y]
print((date_cand, (datetime.date.today() - date_cand.date()).days))
b = [4, 5, 6]
base64.b64encode(dig).decode()
plt.imshow(image)
pygame.init()
local_p = subprocess.Popen(local_command, shell=True, stdout=subprocess.PIPE)
x
mail = outlook.CreateItem(0)
self.updateimage(0)
x.bit_length() - 1
result = float(literal_eval(float_str))
d_out.update(d)
self.server_activate()
mvaddch(y, x, ch)
updated_dict = dict(old_dict, **extra_dict)
get_func.__func__ is Client.get.__func__
pix[x, y] = value
getattr(self, name)
key in self.data
move_set.add(random.randrange(0, 10))
conn.starttls()
self.table.verticalHeader().setTextElideMode(QtCore.Qt.ElideRight)
self.figure = Figure()
now.date()
browser = mechanize.Browser()
popularity = sorted(d, key=d.get, reverse=True)
c[:, 1:] == c[:, :-1]
user = User.objects.get(pk=profile.user_id)
set_columns(widget.columnCount(), 0)
plt.yticks([])
print(platform.mac_ver()[0])
self.cdfunc._func(self.obj, *args, **kwargs)
a, b, c, d, e
plt.plot(X, Y)
defaultdict(partial(numpy.ndarray, 0))
f = urllib.request.urlopen(self.url)
nosetests - s
cv2.LUT(image, table)
driver = webdriver.Firefox()
test_column = Column(Unicode(2), primary_key=True)
(a - b).days
date += timedelta(days=10)
print(time.time() - start)
csv.writer(fw).writerows(data)
position = models.CharField(max_length=128)
monthrange(2011, 2)
np.random.choice(np.arange(len(b)), 5, p=b / len(a), replace=False)
output.append(line)
myset = set(mylist)
pool.map(process_image, data_inputs)
bs = BeautifulSoup.BeautifulSoup(data)
form = CostForm(request.POST)
print(matches.group(1))
l1 = list(set(l1).difference(l2))
self.left.append(v)
self.entry = tk.Entry(self)
sys.exit(-1)
len(set((t0, t1)))
plt.subplots_adjust(wspace=0)
len(d.stack())
grouped.JobNos.sum().idxmax()
ax.set_xticks(his[1][1:] + offset)
s.close()
transCount % 2 == 0
y[(0), :, (0), :]
nums = [random.randrange(1, 10) for i in range(digit_count)]
{k: set(g) for k, g in itertools.groupby(words_sorted, key=len)}
lock = threading.Lock()
curs.fetchone()
diff_unique = list(set(diff_list) - set(source_list))
d.div(d.abs()).fillna(0)
tree = ET.ElementTree(root)
tmp_arr.append(float(j) / float(a))
ch = os.read(sys.stdin.fileno(), 1)
first_it = iter(my_list)
printbob.py
list(zip(s, s[1:] + s[:1]))
self.cam.read()
choices = [random.choice(v) for k, v in list(your_dict.items())]
fig.tight_layout()
output.close()
sum(g)
dbs
dx = 0
df = pd.DataFrame(d)
seen.add(item)
self.crawler.install()
plt.xlim(0, X.shape[1])
loglogmod.fit(x, y)
data.append([c.text_content() for c in row.getchildren()])
os.system
self.board[x]
tuple([x for x, y, z in G])
ourSocket = socket.socket(socket.AF_INET6, socket.SOCK_STREAM, 0)
args = parser.parse_args()
print(values[:, (0)].sum())
getattr(self, attr_name)
max(map(len, stringlist))
g.nth(1).dropna()
wx.EVT_UPDATE_UI(self, self.GetId(), self.onUpdateUI)
b = np.zeros((M.shape[0], M.shape[1], M.shape[1]))
df
names = dir(self.__class__)
df.apply(pd.Series.value_counts)
task_postrun.connect(self.task_done)
self.browser.select_form(nr=0)
result.append(key_result)
dis.dis(test6)
df.loc[:, (cols)] = df[cols].where(df[cols].where.ge(0), np.nan)
z.min(), z.argmin()[0], z.argmin()[1]
self.ser.write(packet)
doc.firstChild.appendChild(elem)
zip_list = zip(A, cycle(B)) if len(A) > len(B) else zip(cycle(A), B)
sns.plt.show()
d = defaultdict(dict)
modify_legend(numpoints=1)
plt.legend()
sum(bits * u[::-1], 1)
dis.dis(bar)
df
r, g, b = hsv_to_rgb(h, s, v)
d = {}
np.ma.MaskedArray(a, mask=(np.ones_like(a) * (a[:, (0)] == 1)).T)
main()
f(d)
self.date = d.astimezone(pytz.utc)
result = sorted((min_value, result, max_value))[1]
list_req = [my_replace(seq, *x) for x in l]
print(element.text)
tmp[i][j] = src[i, j]
print(str(b))
n_items = take(n, iter(d.items()))
array([lapack_inverse(a) for a in A])
p2 = interpolate.PiecewisePolynomial(x2, y2[:, (np.newaxis)])
array([[True, False], [False, False]], dtype=bool)
G.add_edge(1, 2)
memcache_client.set(key, obj)
s.send(line)
line = input.readline().strip()
time.sleep(0.5)
numpy.sqrt(numpy.sum((x - y) ** 2))
ax.scatter(x, y, z)
logging.Handler.__init__(self)
item.setToolTip(item.text())
sleep(0)
structured_dictionary = json.loads(string_received)
simplejson.dumps(userJSON)
axins.set_xlim(x1, x2)
self._data
print(files.sort(reverse=True))
dominated.append(candidate)
f.write(template.format(df.to_latex()))
lines[:, (-offset)]
foo()
self.layout = QtGui.QVBoxLayout(self)
print(list(squares(20, 90)))
result.resize((64, 64), Image.ANTIALIAS).save(sys.argv[2])
self.data[i]
f.readlines()[line_number - 1]
plt.scatter(x, y, c=z)
Base = declarative_base()
[alist[i::sublen] for i in range(numrows)]
map(str.upper, strs)
print(t[1][0])
lines = [line.strip() for line in file if line.strip()]
taskbar.SetProgressValue(self.winId(), 40, 100)
potentialClosest = dist.argmin(axis=1)
myseries_three.iloc[0:2]
writer.writerow(row)
print(yaml.dump(o1))
pd.DataFrame(arr).groupby([0, 1, 2]).max().reset_index()
root.destroy()
print(response.read())
absx = np.abs(X[-np.isnan(X)])
f(*full_args, **kwargs)
mn = s.index(t.lower())
[[map[x] for x in y] for y in input]
my_list = [1, 2, 4, 6, 7]
context = self.get_context_data(**kwargs)
counts = map(Counter, zipped)
mults.append(1)
g.__name__
subprocess.check_call(cmd, stdout=outputfile, stderr=subprocess.STDOUT)
ax.set_aspect(1)
count += 1
pygame.font.init()
wmctrl - l
worksheet.write(r, c, col)
app.run(debug=True)
df1 = df[~mask].copy()
count += 1
accumulationList = []
plt.plot(list(range(5)))
print(df)
A.print_x(b)
data = db.query(sql).store_result()
activate(settings.TIME_ZONE)
sorted_li.sort(key=itemgetter(0))
print(sess.run(y, feed_dict={x: data}))
u, array([len(input[all(input == x, axis=1)]) for x in u], dtype=int)
c = Counter(tuple(x) for x in iter(list1))
start += step
ssq1 = ((yfit1 - ydata) ** 2).sum()
conn.commit()
print(df.index.name)
os.seteuid(0)
signal.signal(signal.SIGINT, signal_handler)
print([T(val, [0.29, 4.5]) for val in data[0]])
isinstance(bar, types.FunctionType)
tws.connect()
canvas.setPageSize(11 * inch, 8.5 * inch)
sorted(x * x for x in range(10))
q = Queue()
OrderedDict((newkey if k == oldkey else k, v) for k, v in _.items())
self.some_text.SetLabel(mysql_data)
final_sorted = [(y, z) for x, y, z in sorted_stuff]
draw.ellipse((0, 0) + bigsize, fill=255)
a = [sorted(i) for i in a]
root = tree.getroot()
app.exec_()
result.append(x)
wordorder.index(word)
choice = input()
items.append(x)
view.show()
tree = ET.parse(pathToFile, OrderedXMLTreeBuilder())
t.start()
width = img.get_width()
start.focus_set()
random.shuffle(lst)
p.xs(0)
unittest.main()
b = copy.deepcopy(a)
BW = 20000.0
fig.get_size_inches()
ax.legend(bbox_to_anchor=(1.1, 1.05))
root = Tk()
X, Y = np.ogrid[0:sx, 0:sy]
pool = multiprocessing.Pool(processes=6)
ax = plt.subplot(111)
map(lambda e: (e, key), elements)
wrapper
list(data_set.itertuples(index=False))
a = np.ascontiguousarray(a)
{{mywidget.body()}}
self.write(self.request.path)
print(p.findall(s))
args = parser.parse_args()
cols = np.ones(rows.shape[0], dtype=np.int)
r.append(random.choice(a))
pl.show()
trans = ssh.get_transport()
self._window.show_all()
sys.stdout = F()
df = sqlContext.createDataFrame(pdf)
height = win.winfo_height()
a.append(1)
j = b.index(p[1])
a = numpy.array([1, 2, 1e1000, 1e1000, 42])
plot(x, y2)
sheet = book.sheet_by_name(name)
self.lock = threading.Lock()
g.map_dataframe(lambda data, color: sns.heatmap(data.corr(), linewidths=0))
c.hello()
ax.plot(theta, mapr(r))
lists.append(lst)
random.randint(1, 100)
array = np.array(list(result.items()), dtype=dtype)
br.select_form(nr=1)
item1, item2 = random.sample(list1, 2)
float.hex(6.6)
exit()
a.quantize(b) == b
self.scrollbar.config(command=self.text.yview)
func()
[k for k in list(mydict.keys()) if k >= 6]
self.text.configure(yscrollcommand=self.vsb.set)
layout.addWidget(self.le)
mocked = MockAnything()
random.shuffle(s)
s.translate(table, string.punctuation)
file.close()
array([0.09, 0.1, 0.1, 0.08, 0.08, 0.14, 0.1, 0.12, 0.09, 0.1])
raise ValueError
df[new_col] += [int(a != 0) for a in df[col]]
_.reshape(-1, ncols)
print(current_credentials.token)
process.start()
s = socket.socket()
print(date.fromtimestamp(d))
self.Layout()
M = np.matrix([[1.0, 0.0], [0.5, 0.5]])
[f(0) for f in fs]
mask = x ** 2 + y ** 2 <= r ** 2
input_thread.start()
p.hello()
print(child.tag, child.text)
os.setsid()
new_list = old_list[:]
print(line)
out.append(s)
f2.write(line)
c.call(1)
repr(tst)
a, b = tee(iterable)
[s for s in students if s[1] == value or s[2] == value]
sys.stdout.buffer.flush()
ax.add_artist(circle2)
ax.add_artist(circle1)
numpy.around(arr, 10, arr)
exec(my_code, mymodule.__dict__)
print(fn(5, 7))
[4]
bf.close()
object.__cmp__(self, other)
[s for s in strs if s.isalpha()]
app = Flask(__name__)
b = [a] * 5
self._socket = socket.socket()
eggs.parent.bar()
r.connection.close()
event.Skip()
conf.write()
tf.reset_default_graph()
2 - 1.0585
form = YourForm()
button.pack(side=RIGHT)
fpout.write(jsonform)
plt.grid(True)
pipe = sp.Popen(command, stdout=sp.PIPE, stderr=sp.STDOUT)
f(*list(newdict.values()))
print(args.foo)
[0, 8, 8, 8, 8, 8, 8, 8, 8, 8]
Pool(processes, initializer, initargs, maxtasksperchild)
df.index = pd.MultiIndex.from_tuples([tup])
count = count + 1
results = multiprocessing.Queue()
l.remove(x)
set_to_string = dict(zip([frozenset(s.split()) for s in strings], strings))
fcntl.fcntl(fd, fcntl.F_SETFL, fl | os.O_NONBLOCK)
y_train_0 = y_train[y_train == 0]
soup = BeautifulSoup(data)
fo.write(fi.read())
fig, ax = plt.subplots()
C[i][j] += A[i][k] * B[k][j]
new_dict = {}
setattr(cls, name, decorator(m))
b.update({key: (a[key], b[key]) for key in set(a.keys()) & set(b.keys())})
fig, ax = plt.subplots(1, 1)
r.supplier.name
favicon.ico
results[el] = [select(ls2, ii) for ii in [0, 1, 2]]
current_user.append(line[9:].strip())
print(wts[1])
img = cam.get_image()
print(someclass())
list_size_1 = numpy.array(list_size_1)
layout.addWidget(frame)
source.applescript
net.layers[1].blobs[1].data.shape
app = flask.Flask(__name__)
rss = psutil.Process(os.getpid()).get_memory_info().rss
row[0] + row[1]
self.delays[type].setdefault(key, 0)
req = urllib.request.urlopen(url)
strings = [frozenset(s.split()) for s in strings]
plt.clf()
ax = plt.gca()
len([c for c in word if c == char])
decorator1(decorator2(func))
time.sleep(0)
[0, 0, 0, 0, 0, 0, 0, 0, 162, 2],
df = pd.DataFrame(np.random.randint(4, size=(5, 1)))
bar1 = Bar.objects.get(pk=1)
now = datetime.datetime.now()
r.append(etree.tostring(item, with_tail=False))
wx.StaticBitmap(panel, -1, gif, (10, pos), (gif.GetWidth(), gif.GetHeight()))
parser = etree.XMLParser(remove_comments=True)
results = [r for r, in results]
plt.plot(pd.Series(data=np.random.randn(100), index=i))
os.fchmod(fd.fileno(), stat.S_IMODE(mode))
(a,) + ((b,) if bret else ()) + ((c,) if cret else ())
res[0] += val
sympy.diff(f, x)
display(yourobject)
Thread(target=print_output, args=(p.stdout,)).start()
df = pd.DataFrame(lst)
xadf = np.diff(xa1)
ax.plot(data2)
match = re.search(pattern, s)
anniversary = models.ForeignKey(Anniversary)
self.numbers = list(range(1, 10))
B = np.array([0, 0, 0])
pyplot.show()
p = multiprocessing.Pool(processes=4)
all_gt10 = [i for i in mylist if i > 10]
u.set_password(password1)
offsets = itertools.product([-1, 0, 1], [-1, 0, 1])
csvfile.truncate()
list.__getitem__(self, item)
action()
[isinstance(x, numbers.Number) for x in (0, 0.0, 0j, decimal.Decimal(0))]
parser = argparse.ArgumentParser()
underscoreize(data)
ax.plot(x, np.sin(x) + i)
Planet.VENUS.radius
handler = logging.StreamHandler()
grdevices.dev_off()
own_fhd = True
df = pd.DataFrame(np.random.rand(15, 5), index=[0] * 15)
AC_PROG_LIBTOOL
plt.legend()
in_tree[0:1] + in_tree[1:][::-1]
print(add(**kwargs))
dir(e.args[0])
[foo]
client_socket.send(strng)
p.kill()
self.items.append(item)
b_to_a = np.argsort(a_to_b)
print(stopword_pattern)
self.view.setModel(self.model)
dropped = df.drop(list(range(5)), inplace=True)
instance = class_()
new_data = ndi.map_coordinates(data, idx)
driver = webdriver.Chrome()
func = lambda x, y: (x, y)
print(f.__defaults__)
print(x.eval())
[ax.add_patch(rect) for rect in rects]
int(argv[2])
Counter(tuple(x) for x in a)
print(df1.combine_first(df2))
logging.Handler.__init__(self)
[next(part for part in path.split(os.path.sep) if part) for path in paths]
plt.plot(h, pdf)
self.ax.set_xlim(xmin, xmax)
k = literal_eval(s)
b_set = set(map(tuple, a))
list(od.keys())
context.vars[macro_name](*args, **kwargs)
2, [True, False, True, False]
termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)
interpreter.process_page(page)
print(input())
list(globals().keys())
ax = self.figure.add_subplot(111)
plt.show()
do_something(current_file)
dict(next(iter(i.items())) for i in g)
it.operands[-1]
is_const(x) and is_datatype_constructor(x)
num = int(s)
next(zip(*G))
td.seconds / 60
print(line, count)
unattachedvolumes()
evts = poller.poll(1000)
newfunc
G.add_edge((q, r), (q - 1, r + 1))
session.query(entity).filter_by(name=name).one()
print(df)
list1[:i]
x, y = screen.get_size()
cur = conn.cursor()
Q0 = e1sq * math.pow(math.cos(phi1), 2)
df6[col] = df6[col].astype(dtype)
sorted(set(li))[-(n + 1)]
p2.join()
pattern.findall(data)
output = int(process.stdout.readline())
[r for r in x if not yy.search(r)]
traces = traces[::-1]
r = [s[i:i + 2] for i in range(0, len(s), 2)]
oggi = datetime.now(IT).date()
sublist(a[1:], b[k + 1:])
dt
nat != nat
fig = plt.figure()
thread.start()
np.put(arr, list(range(num)), np.nan)
list(range(item.start, item.stop, item.step))
print(hash.hexdigest())
dict_words = map(str.lower, list(dict_1.values()))
fig = plt.figure()
x = [True, False, False, True]
f(my_list)
print(len(set(hashes)))
self.window.show()
list(sympy.sieve.primerange(0, 100))
self.urole
b = np.where(a.all(axis=1).any(axis=1))[0]
varience = sum((average - value) ** 2 for value in grades) / len(grades)
start_server()
testVar.append(2)
b = models.ForeignKey(B)
df.columns[1:]
append(result, i, j)
df2.name.str.strip().str.upper()
CoverageACol = arange(10).reshape(2, 5)
result = np.vstack((ranges[starts, 0], ranges[ends, 1])).T
s = {n for v in list(my_dict.values()) for n in v}
print(unique_list)
self.__dict__[attr] = value
ax.yaxis.set_major_locator(MaxNLocator(integer=True))
monkey.patch_all()
[1, 2, 6, 7, 8, 9, 10, 11]
assert not self.test_user.is_staff
start_of_week
temp_data.remove(word)
cv2.drawContours(img, [cnt], 0, (255, 0, 0), 2)
ctypes.pythonapi.Py_DecRef(pyobj)
random.shuffle(lines)
soup = BeautifulSoup(data)
parser.parse_args()
plt.subplot(121)
imshow(mycmap(Z2), extent=extent)
session.cookies.get_dict()
termf.pack(fill=BOTH, expand=YES)
fig.canvas.draw()
timezone.localtime(value)
ldap.set_option(ldap.OPT_X_TLS_REQUIRE_CERT, ldap.OPT_X_TLS_NEVER)
numpy_dict = np.array(values, dtype=dtype)
round_to_1(4)
nms[nms.name.notnull()]
a = np.random.rand(500, 500)
parser.parse(strtime)
option.impliedVolatility(11.1, process)
print(k, v)
c = wmi.WMI()
SUDO_UID
self.value < other.value
a[0, 2]
sum(random.permutation(x))
[df[1:]]
set(l1)
A * numpy.exp(-(x - mu) ** 2 / (2.0 * sigma ** 2))
logger.addHandler(handler1)
text(np.mean(s[:, (0)]), np.mean(s[:, (1)]), str(i), fontsize=14)
self.commitData.emit(self.sender())
user1 = User.query.filter_by(id=1).first()
client = gspread.authorize(credentials)
list(chain.from_iterable(listOfLists))
print(result)
f.write(file_content)
s = paramiko.SSHClient()
tree.write(datafile)
to_product.append([(k, i) for i in v])
ConvertToString(HexString)
app.exec_()
sb.set_palette(cmap, n_colors=8)
HTMLParser.__init__(self)
print(is_int(x))
do_stuff()
main()
self.main_container.grid_columnconfigure(0, weight=1)
sess = tf.Session(config=session_config, graph=graph)
ax2 = pyplot.axes([0, 0, 1, 1], axisbg=(1, 1, 1, 0))
a, b = zip(*z)
config.VAR1
layout = QtGui.QVBoxLayout(self)
file.seek(0, os.SEEK_END)
bool(ImageChops.difference(*imgs).getbbox())
plt.semilogy(xf, 2.0 / N * np.abs(yf[0:N / 2]))
time.sleep(self.interval)
fig = plt.figure(figsize=(10, 6))
Gtk.main_quit()
s2 = my_df.fillna(0).to_sparse(fill_value=0)
max_water_heldover([9, 8, 7, 8, 9, 5, 6])
pool = multiprocessing.Pool()
x[ind] = y[ind]
f(l)
pd.DataFrame({d: df[d] for d in df.columns if d not in dupes})
re.findall(pattern, clause)
cimg = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
self.fmt.format(*self.args, **self.kwargs)
z = zipfile.ZipFile(filename)
df.shift(1)
os.remove(f)
sys.exit(1)
salt = bcrypt.gensalt()
yest = np.array(yests)
coo_matrix(c.multiply(np.dot(a, b)))
plt.ylim(0, X.shape[0])
cls(wfd, bfd, wildfd, tfd)
tostring(element)
sys.path[0] = os.path.dirname(mainpyfile)
update_handler_level(mylogger, logging.StreamHandler)
Books.objects.all()
plt.imshow(result)
f_in.seek(0)
rank = Model.objects.filter(score__gt=obj.score).count()
d = date(year, 1, 1)
soup = BeautifulSoup(page)
str(self.year)
x1 = y1 = x2 = y2 = 0
lst.remove(x)
timedelta(microseconds=1000)
wr.writerow(sh.row_values(rownum))
plt.show()
parser = argparse.ArgumentParser()
hxs = HtmlXPathSelector(response)
parent_dir = os.path.abspath(os.path.dirname(__file__))
print(topological_sort(connections))
plt.figure()
df_norm = (df - df.mean()) / (df.max() - df.min())
app = recording.appstats_wsgi_middleware(app)
assert np.allclose(f(X, Y), X ** 2 + 2 * X * Y + Y ** 2)
matrices[:, (2), (2)] = c
Polygon([(points_x[i], points_y[i]) for i in range(600)])
True
soup = BeautifulSoup(page)
sorted(string)
lst2 = [item[0] for item in lst]
idx = np.nonzero(mask[1:] != mask[:-1])[0]
dict(d1, **d2)
grammar.load()
logging.config.dictConfig(D)
data[school].append(datum)
plt.show()
lines_seen.add(line)
axis.set_major_formatter(ScalarFormatter())
sleep(1)
-libpng - dev
stdin, stdout, stderr = ssh.exec_command(cmd)
tgt.write(uglybuf)
now = time.time()
ax = fig.add_subplot(111)
text_img.drawText(name, 0, 0)
int(argv[2])
Base.metadata
node.render(context)
fig, ax = plt.subplots()
response = FileResponse(os.path.abspath(f.name))
a + b + c
root2.update()
q.task_done()
sys.exit(0)
fig.circle(x, y, color=color, **point_kwargs)
NULL
np.set_printoptions(*args, **kwargs)
z.append(matchobj.group(2))
cursor.execute(insert, (my_point_list,))
print(generate_list(10))
print(my_object.contents)
current.append(x)
print(np.dot(eigenvector.T, np.dot(cov_matrix, eigenvector)))
print(df.index.dtype)
a[0]
print(foo())
lst = list(range(1, 10))
mlab.view(azimuth=45, elevation=60, distance=0.01, focalpoint=(0, 0, 0))
x == n * (n + 1) / 2
asyncio.set_event_loop(loop)
path = os.path.normpath(os.path.expanduser(path))
a = np.arange(125).reshape(5, 5, 5)
[self.classify(x) for x in xs]
threads.append(MyThread(q, args=(t % 2 == 0,)))
True
s.shape
b.sum(axis=2)
new_dict = json.loads(json.dumps(my_dict))
self.connected = True
print(element.firstChild.nodeValue)
p.stdout.close()
print(types[bisect.bisect(points, Point(0.6, 0.6)) - 1])
H = np.meshgrid(np.arange(5), np.arange(5))[0]
y = np.zeros_like(x)
a = NP.empty(shape=(0, 0))
np.sum(a.dot(b), axis=1)
revchoice = arr[~mask]
np.put(arr, list(range(num)), np.nan)
print(line)
[str(chr(i)) for i in h]
assert all(a[key] > b[key] for key in b)
u = random.random() + random.random()
redirect(self.get_success_url())
Py_Finalize()
[10, 12, 14]
print(df[mask])
[map(first, row) for row in data]
print(resp.status_code, resp.url)
inspect.ismodule(os)
str(x)
ipdb.set_trace()
np.random.seed(1)
print(corn.get_next())
cv2.waitKey(0)
input = sys.stdin.read(1)
print(result[0][4])
out = sidx[np.searchsorted(X1D, searched_valuesID, sorter=sidx)]
self.socket.bind(self.server_address)
some_func(foo, bar, baz, quux)
text = ndb.TextProperty()
g = copy_func(f)
logger.setLevel(logging.DEBUG)
e.submit(slow_work, *args, **kwargs)
fn(*args, **kwargs)
plugged()
f.write(tmplines)
foo()
dates_dict[key].append(date)
self.__dict__[key]
words = input.split()
ax.text(*angle_text)
rect.set_xy((dx.start, dy.start))
channel = client.invoke_shell()
time.sleep(2)
plt.setp(ax.get_xmajorticklabels(), visible=False)
next(iterator)
ml.run()
reader = csv.reader(f, skipinitialspace=True)
p = multiprocessing.Process(target=func)
do_something_with(key, value)
print(match.span())
cal_vbox.pack_start(gtk.Calendar(), True, False, 0)
arrayList.append(copy.copy(wM))
driver = webdriver.Firefox()
[mydict[k] for k in list(mydict.keys()) if k >= 6]
plt.plot(X, Y1, lw=4)
t1 = linspace(-50, 50, 100)
ast.literal_eval(d)
Image(path, width=width, height=width * aspect)
print(columns[1])
layout.addWidget(self.button)
packet = packet.__class__(str(packet))
id = Column(Integer, primary_key=True)
numC = random.randint(1, 100)
line = line_data[k]
df.values
result = [copy.deepcopy(result) for _ in range(d)]
os.execv(sys.argv[0], sys.argv)
loop = asyncio.get_event_loop()
print(sys.path)
p2 = np.power(np.linalg.det(cov), -0.5)
l2 = [5, 6, 7, 8]
y = np.arange(-5, 5, 0.2)
int(round(n[0]))
line(res, vertices[1][0], vertices[2][0], color, 5)
my_regex = re.compile(my_pattern, re.DOTALL | re.IGNORECASE)
(a if condition(item) else b).append(item)
client.close()
soup = BeautifulSoup(html)
set(short_list).intersection(long_list)
print(repr(l[0]), repr(int(l[1])))
result = session.query(cls)
conn.setopt(pycurl.DEBUGFUNCTION, test)
plt.show()
t.join()
btn.Bind(wx.EVT_BUTTON, self.changeCursor)
fig = plt.figure()
ret.append(np.zeros(len(tmp)))
__all__ = list(import_submodules(__name__).keys())
plt.gca().invert_yaxis()
set_column(first_col, last_col, width, cell_format, options)
answer = np.linalg.solve(A, b)
startupinfo = subprocess.STARTUPINFO()
solve([0, 10], [12, 20])
a = np.arange(18).reshape(9, 2)
process = Popen(command, stdout=PIPE, stderr=STDOUT, bufsize=1)
line = line.strip()
time.sleep(1)
self.edit = QtGui.QLineEdit(self)
crawler.start()
true_x = np.linspace(0.0, 10.0, N)
df_new
main()
familiesNew = [[x for x in j if x != i] for i, j in enumerate(families)]
self.b2.pack()
colorbar.set_ticklabels(np.unique(data))
axs[1].xaxis.set_major_locator(x_major_lct)
print(s[match.start():match.end()])
all(earlier >= later for earlier, later in zip(seq, seq[1:]))
msg.append(500)
bootfile = subprocess.check_output(cmd, shell=True)
int(hours) * 60 + int(minutes)
mlab.draw()
d2 = dict(list(d.items())[:len(d) / 2])
ax = fig.add_subplot(111)
numpy.percentile(df.a, 95)
out = a + val * np.identity(a.size).reshape(np.append(-1, shp))
f.close()
self.send_response(200)
deleteself.cobj
print(map(lambda x: not x, a))
field.widget = forms.RadioSelect()
glVertex2i(110, 10)
entity_manager.query(Result).filter_by(job_id=job_id).delete()
new_arr.shape
soup = BeautifulSoup(html)
list(product(*[list(range(i + 1)) for i in [x, y, z]]))
a = a.__iadd__(da)
soup_original_1.body.append(element)
data = socket.gethostbyname_ex(x)
plt.grid(True)
canvas = np.zeros((10, 10))
out.close()
fig, ax = plt.subplots()
m.update(f.__class__.__name__)
a.close()
self.root = tk.Tk()
self.transport.loseConnection()
str(self.value)
Py_Initialize()
srf = pygame.display.set_mode((640, 480))
self.video_cap = cv2.VideoCapture(self.device_index)
{y, x, 0}
norm1 = x / np.linalg.norm(x)
session.merge(row_data)
root = tk.Tk()
fig = plt.figure()
match.group(1)
gmpy.divm(1, 0, 5)
td.text
root = lxml.html.fromstring(doc)
str(self._list)
math.ldexp(m, e)
ax1 = fig1.add_subplot(111)
self.name = name
np.mgrid[0:6, 1:10, 0:20][1]
mod.doSomething()
outshift = numbits - obits
max(list(c.items()), key=itemgetter(1))
list(find_creators(f, list(globals().values())))
lens[:-1].cumsum()
ax1.set_yticks(list(range(len(data.index))))
deriv = np.diff(wei.cdf(x)) / dx
np.bincount(np.arange(mask.size) // 20, mask)
True
plt.colorbar(surf, shrink=0.75, aspect=5)
list.__init__(self, *args)
print(ordered_dict)
instance = forms.ModelForm.save(self)
d = dict.fromkeys(list(range(100)))
command.run(timeout=1)
im = np.array(second_subreg * 255, dtype=np.uint8)
thread.start()
gtk.gdk.threads_init()
datetime.fromtimestamp(ts, tz=pytz.utc)
file.close()
[int(x) for row in inputVals for x in row]
ax.hold(True)
db.execute(ddl)
axes[-1, -1].set_ylim(ylimits)
s = map(int, s.split())
result = sm.WLS(y, exog, weight=w).fit()
x, y = np.linspace(x0, x1, num), np.linspace(y0, y1, num)
yaml.add_representer(anydict, _represent_dictorder)
ax.set_xticks(centers)
obj = MyClass()
p = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
print(df.sort_index())
np.allclose(a[:, :, :, (2)], collapse_dims(a)[:, :, 4:6])
shutil.copyfileobj(f, sys.stdout)
print(gaussian_filter())
NULL
s = MLStripper()
json.dumps(json.JSONDecoder().decode(str_w_quotes))
map(print_node, ts.cursor.get_children())
print(line)
log_message_button.Bind(wx.EVT_BUTTON, self._log_message)
Session = scoped_session(sessionmaker())
help(re.sub)
LIST = [1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1]
t.start()
traceback.print_stack()
assert len(set(str(number))) == n - 1 or number == 0 and n == 1
script_dir = os.path.dirname(os.path.abspath(__file__))
plt.ylim(0, 2.1)
x = 10 * np.random.random(100)
mylist = literal_eval(fsock.read())
root = etree.parse(urllib.request.urlopen(url))
axs[i].set_title(str(250 + i))
doc.setHtml(label.text())
a_list[:half], a_list[half:]
irenL.Initialize()
deletea[1]
np.bitwise_or.reduce(c) == c[0]
m_close.Bind(wx.EVT_BUTTON, self.OnClose)
[i_j_k for i_j_k in a if i_j_k[0] + i_j_k[1] + i_j_k[2] > N]
sys.stdout.write(line.lower())
[tuple(g) for valid, g in groupby(init, key=lambda x: len(x) != 0) if valid]
A.sort(axis=1)
root.withdraw()
sum(a * b for a, b in zip(v1, v2))
window.show_all()
htmlSource = driver.page_source
gtk.timeout_add(60 * 1000, my_timer)
root = Tk()
l.append(x)
proc = subprocess.call(command, stdout=out, stderr=subprocess.OUTPUT)
self.lift()
driver = webdriver.Firefox(proxy=proxy)
locale.setlocale(locale.LC_ALL, l)
keys = pygame.key.get_pressed()
reactor.run()
reader = csv.reader(f)
d.sort(key=sorting)
plt.bar(ind, data[1], color=colors[j], bottom=bottom[i - 1])
cr.set_line_width(brush.width)
sys.stdout = Logger()
nll = -1 * numpy.sum(lg)
self._age = value
allUuids.append(x.id)
parser = argparse.ArgumentParser()
p.__dict__.update(d)
ax = plt.gca()
excel.Visible = True
y[:, (newaxis)] - x
title = models.CharField(max_length=100)
net.layers[1].blobs[1].diff.shape
cap.release()
metrics.roc_auc_score(y, scores)
r = requests.get(url)
instance.username = username
s.method()
print(numpy.lib.format.open_memmap.__doc__)
ax = plt.subplot(111)
squaredlengthba = (b.x - a.x) * (b.x - a.x) + (b.y - a.y) * (b.y - a.y)
ax = plt.gca()
unicode_text = r.read().decode(encoding)
session.add(object)
data = np.recarray(data.shape, data.dtype, buf=data)
self.y1 += self.speed * math.sin(self.bearing)
foo()
soup = BeautifulSoup(page.read())
line = next(islice(f, line_number - 1, line_number))
pickle.loads(pickled_value)
T = np.zeros((len(x), len(y), len(z)))
q.put((i, url))
filename = models.CharField(max_length=128)
crawler.signals.connect(add_item, signals.item_passed)
handles, labels = ax.get_legend_handles_labels()
ax.lines
assert all(p.fitness == 2 * p.i for p in particles)
ax2.plot(list(range(10)))
d[x] += 1
Z += np.random.normal(0, noise, Z.shape)
a = np.random.randint(0, 100, 10)
html.document_fromstring(doc)
platform.mac_ver()
pygame.init()
fig.canvas.draw()
n = np.prod([x.size for x in arrays])
self.response.write(template.render(template_values))
print(self.request.id)
max_water_heldover([8, 8, 4, 5])
copy_with_prog(src, dest, lambda pos, total: prog.update(pos, total))
print(request.__dict__)
self.__c = value
s[0:n], s[n:]
res[selfpow + valpow] += selfco * valco
d = datetime.datetime.today().replace(microsecond=0)
get_something(a)
G = nx.DiGraph()
np.apply_along_axis(wrapper, axis, F)
disassemble(x)
grad_vals = sess.run([grad[0] for grad in grads])
proc.start()
tab.add_row(list(row.values()))
wr.writerow(mylist)
fig = plt.figure(figsize=(8, 8))
logger.addHandler(handler)
timeit(easydiff1, easydiff2, 1000000)
a[0]()
ax.set_yticks(np.arange(data.shape[0]) + 0.5, minor=False)
[k.key for k in {IPKey(k) for k in workers}]
soup = BeautifulSoup(urllib.request.urlopen(url).read())
os.chdir(dir)
rChannel.items.append(item)
[1, 8, 8]
print(herp.derp.foo)
M.append(1)
self.list(request, *args, **kwargs)
gca().xaxis.set_major_locator(NullLocator())
pylab.imshow(arr, cmap=cm.Greys_r)
colors = [cm.jet(x) for x in linspace(start, stop, number_of_lines)]
main_str.startswith(check_str) and main_str.endswith(check_str)
s = str(x)
stdscr.getch()
print(H[-1, -1])
pool.close()
print(paramiko.__version__)
outfile.write(line)
root = tree.getroot()
TOA14 = Ta - Td
newList.append(oldList[-1])
list.append(sentence.lower())
total = xtabs.stack().sum(1)
self.send(msg.body)
dframe[gindex]
mymodule.MyClass.getImg()
line(res, vertices[2][0], vertices[0][0], color, 5)
g.write(header(delimiter, fields))
output = list(seq[::-1])
f2(1)
int(a ** b)
lol = LoL([list(range(10)) for i in range(10)])
screen.nodelay(1)
a[0].value
send_post(server, data, files)
Hyphenator.run()
df.agg(*exprs).show()
print(someclass.__name__)
str(2.999999999999999)
id = db.Column(db.Integer, primary_key=True, nullable=False)
idx = np.array(list(d.keys()))
x.append(1)
sys.stderr = sys.__stderr__
list2 = [5, 6, 7, 8, 9]
new_data.apply(directionDescribe)
a.goodbye()
result.append(item)
index = np.arange(len(a))
plt.pause(0.001)
total += int(match.group())
curses.echo()
dis.dis(lambda : a < b < c)
lock = threading.Lock()
picture = pygame.image.load(filename)
xml.etree.ElementTree.dump(group)
bytes([a[0] & b[0]])
self.turnnow
fh.seek(file_size - offset)
ser.read(1)
self._x = x
tmp = tmp.apply(lambda x: str(x[0]))
do_something_1()
ax2 = ax1.twinx()
html = urllib.request.urlopen(url).read()
server.sendmail(username, to, msg.as_string())
cherrypy.quickstart(HelloWorld())
x = np.empty([n, 2])
df[df < pd.Timedelta(0)] = 0
sum(l[::2]) - sum(l[1::2])
print(x.toprettyxml())
db = current_app.db
tocrawl.add(link)
a = np.array([0, 1, 0, 1, 1])
pylab.show()
superstrings.add(stset)
ser.open()
main.show()
logger = logging.getLogger(__name__)
row * (row + 1) / 2 + 1
client.describe_cache_engine_versions()
reversed_dict[value].append(key)
ax.set_zlim(-1.01, 1.01)
os.ftruncate(fd, 0)
len(frozenset(objs)) == len(objs)
print(x)
retval = prof.runcall(self.method_actual, *args, **kwargs)
plt.gca().add_patch(plt.Circle((posx, posy), radius=0.05, fc=color))
df.loc[mask]
plt.yticks(list(range(0, max(yvals), yinterval)))
g.add_edge(5, 6)
YBL007C = ribosome
{{variable_with_html_tag_value | safe}}
{(x + 1): (0) for x in l}
deletelist[index]
print(n)
[20, 40, 60, 80, 100]
inspect.getmembers(parser, predicate=inspect.ismethod)
sns.heatmap(data, linewidth=0, yticklabels=yticks, xticklabels=xticks)
sympy.exp(x)
cmp(adiff, bdiff)
sim = gensim.matutils.cossim(vec_lda1, vec_lda2)
sys.exit(0)
here = os.path.dirname(__file__)
n.append(c)
stats.exponweib.fit(data, floc=0, f0=1)
Euler5(start + 1, end, x)
T.append(df)
self.builder.add_from_file(self.glade_file)
merp[j].append(i)
cpus = multiprocessing.cpu_count()
reactor.run()
logging.shutdown()
ax1.set_title(title)
widget.insertRow(widget.rowCount())
values = heapq.nlargest(2, my_list)
l1.grid(row=0, column=0, padx=(100, 10))
ax.yaxis.set_major_formatter(y_format)
self.setCentralWidget(self.edit)
self.__storage.pop()
print(str.__doc__)
mpl.get_cachedir()
label = input_variable(num_output_classes, dynamic_axes=z.dynamic_axes)
G.data[G.data != 0] = 1
-1 - value
sb.set_palette(cmap)
comment = sh.Cells(1, 1).Comment.Text()
f()
self.var1 = 1
create_table(my_test_db, _create_sql)
cls(reader1, reader2)
ws = wb.get_active_sheet()
r[k][v] += 1
df.join(newFactor.reindex(df.index, level=0))
user2 = User.query.filter_by(id=2).first()
a.start()
hello_world.py
[1.0001]
display.start()
b = [(i * 2) for i in range(1, 10)]
self.ToggleTool(self._NTB2_ZOOM, False)
print(hex(intNum))
r.text
print(A.B.__name__)
main()
print(window.get_name())
df[2].replace(4, 17)
print(s)
plt.show()
g.apply_async()
time.sleep(5)
match.group()
sizer.Add(anotherWidget, proportion=0, style=wx.ALL, border=5)
timeComboBox.currentIndexChanged.connect(self.test)
ax.scatter(x, y)
choose_from_axis(x, 1, 1, 2)
session.login(user, password)
message.pack(padx=8, pady=8)
a[a < 0.7].max()
datetime.timedelta(int(deltatuple))
s = slice(start, stop, step)
ewh.clicked()
session.prepare()
print(pformat(x, formatfloat))
getattr(instance, attr)
df1.foo.isnull().sum() * 100.0 / len(df1)
print(o_form.producetype())
foo = (x * x for x in range(10))
self.my_dict[key] = frozenset(value)
df
[str(x) for x in EmployeeList]
view.set_overwrite_status(True)
date_joined = datetime.now()
display(str(num))
print(list(gen(a)))
id = Column(Integer, primary_key=True)
ymin, ymax = min([i.min() for i in ys]), max([i.max() for i in ys])
csvfile.seek(0)
plt.show()
response
process.stdin.write(modified_line)
dropbox_folder = os.path.join(dirname, subdirname)
multiply_anything(0, 8)
ctypes.addressof(some_long)
len(solns8)
app = QtGui.QApplication(sys.argv)
ax.plot(x, y, lw=2)
test[::-1]
df.apply(lambda s: s[np.isfinite(s)].dropna()).sum()
f2 = f2 * np.max(f1) - np.min(f1) * (f2 - 1)
list(self.__dict__.values())
df.isnull() | df >= threshold
print(df.head())
metadata = MetaData(engine)
Gtk.main_quit()
p = subprocess.Popen([fn], shell=False)
print(l)
self.resize(640, 480)
print(q.cancel())
all(type(i) is int for i in lst)
root.mainloop()
start = time.time()
classifier.fit(X_train, y_train)
ch.setFormatter(formatter)
container.grid_rowconfigure(0, weight=1)
results[i] = urlopen(url).read()
sys.excepthook = my_excepthook
c = cv2.cvtColor(c, cv2.COLOR_BGR2RGB)
array([1, 0])
s.reverse()
GL.glClearColor(0.5, 0.5, 0.5, 1.0)
pp(list(find_days(start, end, 1, 2)))
csvwriter.writeheader()
print(list(accumulate(L)))
self.discard(item)
print(self.correct_response)
data = json.loads(request.raw_post_data)
c.append(solve(new_matrix, size - 1) * matrix[j] * (-1) ** (j + 2))
p.resume()
self.crawler = CrawlerProcess(settings.SCRAPY_SETTINGS)
decisions.complete_workflow_execution()
sys.path.insert(0, cmd_folder)
result.append(offset)
pythoncom.PumpWaitingMessages()
args.value = values.get(args.values)
a[:] += da[:]
print(a[1, 1])
link = Field()
a[0][1] = 10
node.orth_
d.join(s.split(d)[:n])
{(1): 2} in {1, 2}
textdata.columns - csvdata.columns
result.append(i + j)
print(a, b, c)
transactions = Transaction.objects.for_account(account_id)
pgs = pdf.getNumPages()
random.shuffle(results)
s < t.isoformat()
df.max(1)
value = myDict[key]
session.expunge(inst)
not np.any((a == b).mask) and np.alltrue((a == b).compressed())
array1 = [[0, 0], [0, 0]]
set_value(dict_nested, list_address[:-2], *list_address[-2:])
df = pd.DataFrame(d)
json.loads(dict_str)
soup = BeautifulSoup(html)
a.sort(object_compare)
cleared.append(candidate)
ker = 1.0 / 4.0 * np.array([1, 1, 0, 0, 0, 1, 1], dtype=np.float)
self.get_name()
unfold(lambda y: (y, f(y)), x)
[singleitem] = mylist
yourThread.start()
encoder.encodefile(corpusfile_plaintext, corpusfile)
repr(c)
id = Column(Integer, primary_key=True)
interactive(set_cursor, x=ax.get_xlim(), y=ax.get_ylim())
print(word)
bool_list = [False for item in bool_list]
[(d.month, d.year) for d in rrule(MONTHLY, dtstart=start, until=end)]
layout.addWidget(self.table, 1, 0)
form = RecipeForm(request.form)
L.append(L[i])
signal.signal(signal.SIGALRM, handler)
master = tk.Tk()
rootApp.run(debug=True)
print(newcorpus.paras(newcorpus.fileids()[0]))
parsed_url = urlparse.urlparse(url)
file.close()
model.load_weights(weights_path)
self.video_out.write(video_frame)
random.shuffle(iters)
groupedby(enumerate(s), key=itemgetter(1), keep=itemgetter(0))
x_train = np.random.normal(0, 1, [50, 10])
pdb.set_trace()
foo.__annotations__
df.index.get_loc(window_stop_row.name)
csv_reader = csv.DictReader(utf8_data, **kwargs)
tree = ET.parse(source)
amp * np.exp(-(x - cen) ** 2 / (2.0 * sigma ** 2))
coop = task.Cooperator()
type(df1)
pdf_reader = PdfFileReader(f)
m = mp.Manager()
tm.assert_frame_equal(df, df)
output = p2.communicate()[0]
parts = line.split()
expm1(1e-05)
self.pack(side=BOTTOM)
self.view.setModel(self.proxy)
a = [[0, 1, 0], [1, 0, 0], [1, 1, 1]]
s = pd.Series([True, True, False, True])
df2.set_index(np.arange(len(df2.index)))
wr.writerow(sheet.row_values(rownum))
False
doc = lh.parse(urllib.request.urlopen(url))
n = find_words_in_image(open(sys.argv[1]).read())
print(str_list)
self.num = num
out = collections.defaultdict(list)
s.quit()
s.bind((HOST, 0))
result.append(str(s))
(x[i] for x in copies[i])
mylist.sort(key=lambda x: x[1])
sio.reset()
df6 = pd.DataFrame(values2, index=index, columns=columns)
_list.extend(list(range(r[0], r[1])))
self.lom.append(name)
g(1000, y=2000, z=500)
reversed_dict[value].append(key)
d[i].append(x[j])
print(timedelta(hours=time.timezone / 60 / 60))
x = random.choice([left, right])
plt.scatter(delta[idx], vf[idx], c=dS[idx], alpha=0.7, cmap=cm.Paired)
deletesys.modules[name]
assert len(bytes) == 8
pd.concat(frames, keys=dates, axis=1)
getattr(self._instance, attr)
a = [[], [], []]
update_wrapper(result, func)
urlpatterns.append(url(main_view_re, MainView.as_view()))
w = np.fft.fft(data)
self.data[k] = v
print(max(list))
cols = df.columns.values.tolist()
response = urllib.request.urlopen(req)
my_list
data = f.read(1)
inf.seek(0)
app.debug = True
internet.TCPServer(1025, factory).setServiceParent(application)
a = 2
print(data)
shutil.rmtree(dir)
eval(input())
plt.colorbar(sm, ticks=list(range(4)))
dict_result = [item.get_dict() for item in root]
MyClass().id
self.selectedFiles
pdb.Pdb(stdout=sys.__stdout__).set_trace()
cur.execute(query)
gc.collect()
i.update(7)
f.truncate()
my_dict[list[0]] = list[:]
print(f())
duck.quack()
fractExpr.setParseAction(lambda t: sum(t))
h.append({k: td.get(k) for k in get_keys})
plt.clf()
QWebPage.__init__(self)
os.makedirs(outdir)
plt.close()
self.close()
self.assertTrue(parser.long)
pygame.event.wait()
len(x) != len(y) and max([x, y], key=len) or min(x, y)
{{pform.as_p}}
(xdiff.T * lu_solve(Sigma_inv, xdiff.T)).sum(axis=0)
t.refresh()
df = df.astype(int)
{key: [s for s in a[key] if s not in b.get(key, [])] for key in a}
GEN_RUNNING
a.shape
denom_ACGT = list(d1[0].values()) + list(d1[1].values())
test()
a * c == b * d
sherr.pop()
MULTI()
any(x in myDict for x in myList)
users = User.query.all()
parent.wait(5)
[unicodedata.category(c) for c in a]
path, module_name = os.path.split(module_path)
file.seek(2)
p.start()
Response(serializer.data)
args = parser.parse_args()
ordered[k] = mydict[k]
bar.py
res.append(total_sum - 2 * sum_smaller + x * (2 * num_smaller - i))
answer2 = [(i, v) for i, v in enumerate(answer1) if v]
tuple(x for x, y, z in G)
plt.matshow(df_confusion, cmap=cmap)
5 < (1, 2)
s = [[0] * 4] * 4
curs.execute(sql_command)
arr[i:] + arr[:size - (len(arr) - i)]
K.set_value(self.model.optimizer.lr, lr - 10000 * self.losses[-1])
s.sendmail(me, you, msg.as_string())
type(b).mro()
logger = logging.getLogger()
kclass.append(min(data_list))
directory = os.path.realpath(directory)
x = np.hstack((x, x[::-1]))
timings.sort()
print(Xc.todense())
datetime.date(first.year, first.month, lastday)
doSomething(line.strip())
p(sys.path)
self.wfile.write(np.array(buf).tostring())
np.isnan(b)
test2(*args, **kwargs)
pairs = {(x, x + 2) for x in primes if x + 2 in primes}
fftf = numpy.fft.fftn(f)
ser.close()
walk_dict(d)
Y = X.reshape(9, 4, 1).repeat(4096, 2)
df = df.stack()[[1, 0]].reset_index(level=2, drop=True).reset_index()
self.table.installEventFilter(self)
t.daemon = True
print(result)
kalman_x, kalman_y = zip(*result)
1125, 1125, 1125, 1125, 1125, 1250, 1062, 1250
qq.close()
rest = list(i)
app = QtGui.QApplication(sys.argv)
bigram_measures = nltk.collocations.BigramAssocMeasures()
df1 = df.unstack(0)
sector_el = [item[1] for item in remaining]
ax1.plot(xvals, yvals, linewidth=4)
start_response(status, headers)
ax.add_patch(clip_path)
c = np.concatenate((a, b))
gray = cv.CreateMat(img.height, img.width, cv.CV_8UC1)
print(hashlib.sha1(str(a_sorted_list)).hexdigest())
list(dict(reversed(items)).items())
globals(), pickle.loads(pickled_name), pickle.loads(pickled_arguments)
L = L[::-1]
MAIL_USE_SSL = True
result = np.zeros_like(b)
y = x
threads = [threading.Thread(target=func, args=(i, q)) for i in range(5)]
im2, = ax2.plot([], [], color=(0, 0, 1))
r = requests.post(url, files=files)
keys
do_something_with_update(MsUpdate)
df = pd.concat(df_list)
a = np.arange(1, n * m + 1).reshape(n, m)
Repo.clone_from(git_url, repo_dir)
plt.show()
print(urls)
print(delta.total_seconds())
p.print_stats()
results.append(tag)
plt.close(fig)
ax.legend(proxies, descriptions, numpoints=1, markerscale=2)
y = [4, 5, 6]
ax.xaxis.set_ticks(df.index)
df.index
xx, yy = np.meshgrid(x, y)
cur = conn.cursor()
show()
np.column_stack(np.nonzero(result))
Base = declarative_base()
parking_rows.append(ParkingLotRow((1, 20), (496, 41), 25))
expiry_date = models.DateField()
sublist.append(i)
y.set_color(label_colors[y.get_text()])
out.flush()
plt.show()
print(repr(combined_astr))
c = a[(ii), :]
ax.add_patch(ellip)
bysetpos = bysetpos, bymonth = bymonth, bymonthday = bymonthday,
X_train = clf.fit_transform(X_train)
iT += 1
ar = [int(i) for i in input().strip().split()]
gibberish(4)
print(char2, len(char2), len(char2[0]))
textbox.pack()
layout.addWidget(picture)
x = np.isnan(A).ravel().nonzero()[0]
response
contents = output.getvalue()
dh = urllib.request.urlopen(url)
result = mysql_cursor.fetchone()
set(a) < set(b)
list(query_set)
rgba = numpy.concatenate((rgb, numpy.zeros((205, 54, 1))), axis=2)
mark_safe(form_as_div)
help(str.join)
df
self._get_frame_nos()
print_tree(child, indent=next_indent, last=next_last)
dfile.flush()
B()
name = models.CharField(max_length=255)
bullet.DISABLE_SIMULATION
ax.yaxis.set_label_coords(labelx, 0.5)
xs.sort(key=len)
text[-1] + backward(text[:-1])
M.ix[(0, 1), (0, 1)] = 1
ax.set_axis_off()
df2 = pd.DataFrame(d1)
my_path = os.path.abspath(__file__)
session = Session.objects.get(session_key=session_key)
l[n:] = [0] * (n - len(l))
toplevel.update_idletasks()
img = filedescriptor.read()
root = tk.Tk()
do_pre_install_stuff()
old_filename = file_path[-1]
ax = plt.gca()
Base.metadata.create_all(engine)
getattr(self.obj, key)
soup.root.contents[0].name
result.append((k, length, index))
serv.start()
print(df.to_csv())
G.add_edges_from((i, j) for i, j, sim in edges if sim >= THRESHOLD)
pipe = Popen(command_2, shell=True, stdin=PIPE, stdout=PIPE)
lines = set(f)
model = Sequential()
my_dict[key[-1]] = value
bc.as_datetime()
print(cell.text_content())
s.cookies.save()
ax = plt.subplot(111)
data = [np.arange(8).reshape(2, 4), np.arange(10).reshape(2, 5)]
f.write(line)
print(len(s))
proc.start()
print(np.exp(-(A + B)))
counts_counter = Counter(list(counter.values()))
now = datetime.now()
admin.site.register(Author, AuthorAdmin)
pos = nx.spring_layout(G)
plt.figure(4)
idx = np.clip(idx, 1, len(A) - 1)
tabfile = StringIO(contents)
my_map.etopo()
pd.notnull(np.nan)
print(random_list)
self.assertEqual(target.int(), b10)
gevent.spawn(test)
lineno = traceback.tb_lineno
setattr(self, attr_name, fn(self))
num if start < num < end else start if num <= start else end
app = QtGui.QApplication(sys.argv)
plt.imshow(imgmap, zorder=4)
vline.set_xdata((x, x))
ax1 = fig.add_subplot(221)
fig, ax = plt.subplots()
c = p.stdout.read(1)
cap1.set(4, 120)
assert np.allclose(x.todense(), y.todense())
count, division = np.histogram(series, bins=[-201, -149, 949, 1001])
df
cursor.close()
groups = Group.objects.filter(player=p1).filter(player=p2)
myArray.__len__()
gevent.joinall(jobs)
result_queue = Queue()
parser.parse_args()
convert_dict(v)
theList[4:7] + theList[12:18]
A[1] = previous_A[1]
plt.colorbar()
print(list(dd.keys()))
manager.start()
im = Image.open(filename)
msmdsrvini.close()
array_c.append(x)
sess.run(init_op)
csv2.readline()
pool.close()
setattr(self, k, v)
np.take(x, lin_idx)
time.sleep(1)
data = f.read(BUF_SIZE)
logger.removeHandler(logger.handlers[0])
img.save(filename)
itineraryArray.itinerary.append(itinerary0)
np.complex(0, 1)
print(len(your_list))
pylab.xticks(list(range(len(allinterests))), allinterests)
db = SQLAlchemy(app)
f = f.simplify()
ax2.set_ylim(0, ax2.get_yticks()[-1])
sorted_KP.remove(item)
mask = array1 == array2
layout.addWidget(self.button)
g = gevent.spawn(urllib.request.urlopen, url)
d = (1 + math.sqrt(1 + 8 * len(condensed_matrix))) / 2
example[4:1] = [122]
t.start()
self._db = db
print(line)
operator.add(1, 2)
xml.sax.xmlreader
self.serve_forever()
self.txt = ScrolledText(self.root, undo=True)
initdelorean()
initfoo()
print(data)
time.sleep(0.1)
time.sleep(0.5)
c = t[2]
worksheet.set_column(i, i, column_len)
max(0, -n.as_tuple().exponent)
args = parser.parse_args()
co.co_code, co.co_consts, co.co_names
ax.barh(ind, vals, width, color=colors)
first_name = models.CharField(max_length=50)
itertools.combinations(stuff, 4)
file.close()
[10, 4, 1]
print(resp.read())
clusters.setdefault(v, []).append(k)
df1.apply(assign_metric_vals, 1)
ax.plot(x, y)
y_train = np.random.randint(0, 10, [50])
random.uniform(float(start), float(start + width))
s.sendmail(me, you, msg.as_string())
fig, axes = plt.subplots(nrows=2, ncols=2, sharey=True, sharex=True)
fig = plt.figure(figsize=(9, 9))
pprint.pprint(gc.get_referrers(l))
x + y
first_day = today.replace(day=1)
A[:, (0)] = A[:, (D2 - 1)]
s.recv_info(q)
self._bar
diff = np.empty_like(img1)
time.sleep(0.5)
b.max()
x[1][0:2][2]
ser.close()
asyncore.dispatcher.__init__(self)
L = [0] * 10
fig = plt.figure()
ax.xaxis_date()
(2 ** i for i in range(n))
timer.start()
model1.objects.create()
colors = np.linspace(0, 1, N)
result = Image.fromarray((visual * 255).astype(numpy.uint8))
f2.write(Lines[i])
gram_matrix
pd.read_clipboard()
print(res.first_name, res.last_name)
myDict[key] += value
timediff.total_seconds()
eval.__text_signature__
np.allclose(diam, dam_out)
ax.set_yticks(np.arange(0.5, 10.5, 1))
assert all(0 <= element < N for lst in list_of_lists for element in lst)
self.var1
ax2 = plt.subplot(1, 2, 2)
engine = create_engine(dbconninfo)
value = cache[key] if key in cache else cache.setdefault(cache, func(key))
B.objects.create(a=some_a)
tuple(sum(base_lists, []))
df1 = pd.DataFrame([x for x in df2.teams])
figure = pylab.figure(figsize=figsize)
asyncore.loop()
min(list(res.items()), key=itemgetter(0))[1]
Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))
x, y, z = z, x, y
sum_digits(1969)
t.start()
out.close()
main()
p = webdriver.FirefoxProfile()
genn(igap, igap + 1)
toolsmodule.printdatabase()
buffer.append(line.strip())
figure.show()
plt.plot(list(range(10)), x, next(linecycler))
print(type(f))
self.harmstat = harmstat
map(lambda t: t.start(), tlist)
print(df.values)
c = nprect(1, x)
gmpy.divm(1, 4, 8)
self.particles = []
fig, ax1 = plt.subplots()
app = QtGui.QApplication(sys.argv)
[(x, list(y)) for x, y in groupby(mylist, get_field_sub)]
selobj.path
out.append(int(n))
print(A[i, j, B])
a, x, b = np.asarray(a), np.asarray(x), np.asarray(b)
results = map(process_file, [os.path.join(dirname, name) for name in names])
doc = etree.parse(f_source, parser)
curses.noecho()
s.connect((host, port))
plt.figure()
ax.coastlines()
newgrid = [[x[i] for x in grid] for i in range(len(grid[0]))]
ax1 = fig.add_subplot(111)
print(response.status_code)
lst.sort(key=MyStrOrder)
list(sum(tupleOfTuples, ()))
file_writer = csv.writer(test_file)
pet.say()
thread.start()
util.log_to_stderr(level=logging.DEBUG)
arr[mask] = np.nan
c = db.cursor()
httpdkenlogger.addHandler(fh)
print(str.isdigit.__doc__)
c = array([a, b])
pilimg.show()
r = requests.get(url)
sys.exit(0)
self.finish()
pyl.clabel(CS, inline=1, fontsize=10)
print(A.func1.__doc__)
words = my_string.split()
binary_f(lambda x: f(x) != val0, list)
view_menu = tk.Menu(menubar)
dict = {(x ** p): expr.collect(x).coeff(x ** p) for p in range(1, n)}
c.setopt(c.WRITEFUNCTION, data.write)
GPS_EPOCH + datetime.timedelta(seconds=t1_seconds, microseconds=t1_us)
myThread.join()
D = sorted(C, key=lambda x: x[1])
[dict(e) for e in set(lst).difference(dups)]
[0, 0, 0, 0, 0, 0, 0, 162, 1, 164],
dict(form=form)
root.mycontainer.myattr
a.start()
channel = connection.channel()
np.cross(a, b, axisa=0, axisb=0)
setp(ax.get_xticklabels(), fontsize=8)
t.start()
json.dump(row, sys.stdout)
self.output_logger
boundaries = [i for i in range(1, len(x)) if x[i] != x[i - 1] + 1]
temp[0] = 1
WLAN_AVAILABLE_NETWORK_CONNECTED = 1
p = subprocess.Popen(args, stderr=sys.stdout.fileno(), stdout=subprocess.PIPE)
pem = ssl.get_server_certificate((host, port))
self.initial_parameternameX = self.parameternameX
x = f.readline()
ff = webdriver.Firefox()
hash_md5.hexdigest()
store = Gtk.ListStore(str, GdkPixbuf.Pixbuf, bool)
print(tuple([a]))
a = np.asarray(a)
timerthread[0].start()
bisect_right(a, x)
sys.stderr.write(highlight(tbtext, lexer, formatter))
result.addFailure(self, sys.exc_info())
[(i * i) for i in range(5)]
im = Image.open(StringIO(fd.read()))
a.replace(b, c)
XS, YS, ZS = [], [], []
Base.metadata.create_all(self._conn)
pool.close()
self.transport.write(data)
a.sort(key=lambda x: x[1], reverse=True)
print(channel.recv(1024))
ax.legend_.remove()
self.deletecommand(funcid)
C = np.searchsorted(A, B)
df.iloc[-6:-1]
ssh.load_system_host_keys()
x = np.arange(20)
isect.append([event[0], 0])
deletedictionary[oldkey]
print(a - b)
print(x.most_common())
finalurl = res.geturl()
print([row for row in r if row])
print(args)
root.config(menu=menu_bar)
print(list(solve(x)))
result_s.casefold() == result_s.casefold()[::-1]
df = pd.concat(df)
pdb.Pdb.setup(self, f, t)
sum(i for i in x if i in y) * w[i] / sum(i for i in x) * w[i]
print(sys.path[0])
buffer += ser.read(ser.inWaiting())
self.request.user
density._compute_covariance()
test2 = pd.concat(data, ignore_index=True)
print(key, my_dict[key])
ax1.set_xticklabels(data.columns)
self.driver = webdriver.Firefox()
db_crsr.close()
p.start()
abcd = ABCD()
inotify.close()
zipfile.ZipFile(memory_zip)
min(cluster, key=lambda t: abs(ts - t))
window = MainWindow()
f.seek(0)
pprint.pprint(data)
plt.show()
here = os.path.dirname(os.path.realpath(__file__))
s.setsockopt(socket.IPPROTO_IP, socket.IP_HDRINCL, 1)
a.to_frame().join(b.to_frame())
q.shape
dict.__init__(self, *args, **kwargs)
output.addPage(page)
table.insertRow(rowPosition)
piechart[0][i].set_hatch(patterns[i % len(patterns)])
print(repr(y))
server.starttls()
func(*params)
print(count)
f = {x: make_func(x) for x in range(10)}
now = datetime.now()
bcut.ax.patch.set_visible(False)
data = sys.argv[1]
ndarray = np.PyArray_SimpleNewFromData(1, shape, np.NPY_DOUBLE, self.data_ptr)
print([dict(zip(list(options.keys()), p)) for p in product])
image.set_from_pixbuf(handle.get_pixbuf())
result()
sympy_exp.evalf(subs={a: 6, b: 5, c: 2})
foo = lambda x, y, z: x + y + z
[[1, 1], [1, 2], [2, 2]]
A[j], A[k] = A[k], A[j]
get_current_fig_manager().window.raise_()
plt.subplot(211)
A.resize((D1, D2 - 1), refcheck=False)
self._current_browser()
result = []
app.register_blueprint(chat)
[1, 4, 7, 10]
dic[keys[-1]] = value
matchingVals = [x for x in a if x > 2]
ax1.get_xaxis().set_major_formatter(ticker.FuncFormatter(my_formatter_fun))
pylab.setp(ax.get_xticklabels(), visible=True)
file.seek(line_offset[n])
{i: zip(*np.where(z == i)) for i in np.unique(z) if i}
p = Process(target=f, args=(d,))
print(ned)
setattr(inst, self.name, value)
prop1 = db.String
True
columns.append(cd[0])
[foo, bar]
A = np.random.randint(0, 1000, 10000)
x = random.randrange(0, maxx)
print(x)
set(l1) | set(l2)
logging.Formatter.converter = time.gmtime
id, nm, lat, lon, code = line.split()
decimal.Decimal(-1200).exp()
sum(i * i for i in range(5))
ax.plot(x, y)
ng.append(history[_id])
fig = plt.figure()
this_year = DT.date(DT.date.today().year, 1, 1)
help(math)
cat.head(15)
pool.join()
df = pandas.DataFrame(dfdict)
today = date.today()
help(Assignment)
sys.modules[name] = module
b = a[:]
print(func(x))
lines = [l for l in r]
a = np.empty((1,), dtype=np.object)
a[1:1] = [6, 7]
os.path.join([conf.TEMPLATES_UPLOAD_DIR, filename])
print(C.b.__doc__)
self.axis = self.figure.add_subplot(111)
testsite_array = f.readlines()
print(reverse_cumsum(array))
max(files, key=filetimestamp)
print(vc[vc > 2].index[0])
instance = Child.do_something(instance)
f.write(br.response().read())
top.after(1000, start, False)
sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
img = Image.open(image)
deletev[:-1]
client.service.GetWeatherInformation()
show()
page = f.read()
pvt.apply(lambda x: x / pvt.sum(1))
norm = matplotlib.colors.Normalize(vmin=10.0, vmax=20.0)
self.value.increment()
f()
print(x)
check = (a[:, (1)] == 4) | (a[:, (1)] == 6)
df.append(row)
ax = fig.add_subplot(111)
res = f(*args, **kwargs)
4 / float(100)
timestamp = d - datetime(1970, 1, 1, tzinfo=pytz.utc)
gtksink.props.widget.show()
print(mail.unread())
assert np.all(Ay[ix:ix + Bx.shape[0], iy:iy + Bx.shape[1]] == By)
ax.get_yaxis().set_major_formatter(ticker.FuncFormatter(comma_format))
b = a + b
api / __init__.py
df = pd.concat([df] * 10000).reset_index(drop=True)
output = f.read()
map(np.max, np.split(v, np.where(mask)[0] + 1))
arr = np.empty(shape, dtype=object)
result = []
local_filename
--startas / tmp / testdaemon.py
fig, ax = plt.subplots()
draw.line((0, 0) + im.size, fill=128)
plt.gca().add_patch(plt.Circle((posx, -posy), radius=0.1, fc=color))
fliers[i].set_data([fdata[0][id], fdata[1][id]])
b.clicked.connect(self.processButton)
linesamples.add(int(4 * i + 0))
719529
a = np.arange(10)
transaction.rollback()
K[K.argsort()[-5:]]
writer = csv.writer(outfile)
[item[0] for item in d1.items() if item[1] == 55][0]
get_value(dic, 70)
(2 ** 52) ** (log(b, 2) - log(a, 2))
print(list(flatten_group(a)))
ylim(ax1.get_ylim())
cache = self.get_cache()
print_matrix(matrix, size)
B.nbytes
g in df.index.values
pandas.concat(df_l)
t.start()
result
show_url.allow_tags = True
print(string)
[row[cols] for row in self[rows]]
site = SiteData.objects.filter(query)
m = (1 << bits) - 1
funcs.append(func)
print(np.unpackbits(xp))
[2, 2, 2]
imouto.name
numpy.column_stack((a, b))
print(item)
X[0] - a
sum([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])
plt.pcolor(X, Y, f(data), cmap=cm, vmin=-4, vmax=4)
pygame.camera.init()
bow_length = perimeter / (desired_number_of_full_bows + 0.5)
sock.connect((host, port))
a_set
(np.expand_dims(a, -1) == np.expand_dims(b, 1)).sum(axis=-1).sum(axis=-1)
sched.start()
map(functools.partial(add, y=2), a)
[tdgi(item) for item in theList if tdin(item)]
a.set_yticklabels([])
pool.close()
os.getcwd()
print(better_uc)
deleteself._x
ax = fig.add_axes([0, 0, 1, 1])
message = email.message_from_string(email_data)
yaml.add_representer(collections.OrderedDict, dict_representer)
a.pop(2)
consumer.start()
curses.initscr()
multi_line_word = ZeroOrMore(split_word) + word
self.manager.start()
dlclose(handle)
testRunner = unittest.TextTestRunner(verbosity=0)
ws.send(msg)
comprehended.repeat()
list(reorder(a))
soup = BeautifulSoup(html, convertEntities=BeautifulSoup.HTML_ENTITIES)
len2 = math.hypot(x2, y2)
metadata.append(row)
ax1.set_title(title)
doc = html.fromstring(content, base_url=url)
plt.draw()
warnings.showwarning = customwarn
print(D[key])
self.pw.pic = ImageTk.PhotoImage(image)
fig.subplots_adjust(left=0.25, bottom=0.25)
img = image.resize((188, 45), Image.ANTIALIAS)
current.start()
sorted(structure, key=keyfunc)
df_s.groupby(cols).apply(Full_coverage_nosort)
os.mkdir(dirname)
a_new = [d.get(e, e) for e in a]
1, 2
ssh.close()
pp([dict((attr.tag, attr.text) for attr in el) for el in et.fromstring(xs)])
x | y
x * np.sqrt(y)
app.MainLoop()
self.model = QtGui.QStandardItemModel()
self.__key__() < other.__key__()
print(A[np.searchsorted(A[:, (0)], I)])
self.sizer.Add(self.button, flag=wx.EXPAND | wx.ALL, border=5)
RenderJSON(your_json)
getattr(object, f)
a_sorted_list = [(key, a[key]) for key in sorted(a.keys())]
a.read()
()
c = [(a[i] + b[i]) for i in range(len(a))]
columns = [m.key for m in model.__table__.columns]
root = tk.Tk()
pickle.dumps(picklable)
[average(n) for n in zip(*l)]
thread = threading.Thread(target=server.serve_forever)
self.deletecommand(funcid)
ax = plt.gca()
UPPER[LOWER.index(s)]
tup[:ix] + (val,) + tup[ix + 1:]
bokeh.io.save(layout)
house_list.append(House(str(new_house)))
db.session.query(Vehicle).filter(str(Car.id) == Vehicle.value)
print(textwrap.fill(str(collections.Counter(chars)), width=79))
key = operator.itemgetter(0)
time.sleep(polling_interval - work_duration)
sys.exit(app.exec_())
HttpResponse(simplejson.dumps(user.toJSON()))
t1.save()
sess.query(Tag).distinct(Tag.name)
subparsers = parser.add_subparsers()
dc = wx.ClientDC(self)
sess = tf.InteractiveSession()
self._classes = {}
net._setParameters(new_params)
fig = plt.figure(1)
raise Http404()
axes_2.axis([-5, 5, -5, 5])
plt.xlim(0, variability.shape[1])
x = 2
display.popen.kill()
print(cell.text)
df
pd.read_csv(io.StringIO(t), header=0)
process2.wait()
f.write(data)
plt.plot(X, Y2, lw=4)
pandas.get_dummies(input_df)
print(check_for_triangle(tri2, lines))
self.mainframe.columnconfigure(column, weight=1)
b = TestC()
cm.print_stats()
result = [foo(p1, p2) for p1 in people for p2 in people if p1 != p2]
z = np.array([False, False, False, False])
isdefarg()
max(sum(tableData, []), key=len)
self.cowButton.grid(row=0, column=0)
br.form.fixup()
x = list(df1.columns.values)
plt.show()
self.close()
dbconn.commit()
a = []
uppers.append(word) if word[0].isupper() else lowers.append(word)
urllib.request.urlopen(req)
t = tuple(reader)
self.image.set_from_pixbuf(self.loader.get_pixbuf())
id = Column(Integer, primary_key=True)
self.lineedit.clear()
out = np.asarray(out).reshape((xsize, ysize))
datelist = pd.date_range(pd.datetime.today(), periods=100).tolist()
pycurl_connect = pycurl.Curl()
connection = engine.connect()
c1.setopt(pycurl.PROXYTYPE, pycurl.PROXYTYPE_SOCKS5)
print(list(iter(root)))
img = Image.open(FILENAME)
print(ned)
wx.Panel.__init__(self, parent=parent)
a[1].value
file.close()
summt = tf.Summary()
difs = numpy.diff(bounded)
print(df.types)
cb = fig.colorbar(surf)
inspect.isclass(o) and issubclass(o, A)
d.close()
fig, ax = plt.subplots()
curl.setopt(pycurl.WRITEFUNCTION, buff.write)
user1 = forms.ChoiceField(choices=[])
t.play()
deleteL[i]
pprint.pprint(l)
print(a[:, (2)])
win.refresh()
layout = QtGui.QVBoxLayout(self)
count += 1
time.sleep(1)
df1
np.exp(-z) * np.sin(t - z)
weight = tf.Variable(tf.truncated_normal([data_size, target_size]))
self.timeout = timeout
body = models.TextField(null=False, max_length=1024)
s = s.lower()
self.i += 1
isinstance(obj, tuple)
subq = session.query(User.id).filter(User.is_admin == True).subquery()
foo.close()
numcount = dict((num, numlist.count(num)) for num in set(numlist))
result.append((g[0][0], g[-1][-1], k))
listWidget.insertItem(item)
G.add_node(2, pos=(2, 2))
list(Counter(words).keys())
self.handle_read_callback(self)
sess.run(init_op)
fig = plt.figure()
count = (sums.reshape(-1, s1.shape[1]) == 0).all(1).sum()
p1 = Thread(target=process_output, args=(dcmpid,))
grouped = grouped.reset_index()
pizzas_bought = models.ManyToManyField(Pizza)
html = urllib.request.urlopen(url).read()
p.start()
x = copy.copy(x)
parse_qs(parsed_url.query)
fig, ax = plt.subplots()
array([2, 0, 1])
regex.match(data.getvalue())
perms.append(map(list, zip(*tables)))
desks
all(some_func(x) or True for x in some_list if x > 5)
window = tk.Tk()
[1, 0, 2, 1]
ws.column_dimensions[col].width = value
print(data)
self.assertEqual(2, 2)
glEnd()
b = random.randint(0, 20 - a)
u.save()
cal.save()
count = (array_1d == row_scalar).sum()
any(s in l for l in lines1 for s in search_strings)
fig = plt.figure()
b * X(X, b - 1) if b > 0 else 1
instance.save()
np.isnan([nan, nan])
htemp, jnk = np.histogram(d, mybins)
y = np.concatenate(y)
accept.stop()
line = line.rstrip()
celery.init_app(app)
A(1, 2).asdict()
a if len(a) < len(b) else b
plt.show()
sys.__excepthook__(type, value, tb)
filename = os.path.basename(path)
print(i)
df.replace(eq, 1, inplace=True)
self.running = False
getattr(os, s)()
print(x)
Thread(target=process_output, args=[process]).start()
prices[:-1] / prices[1:].values - 1
math.ceil(4500 / 1000.0)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
a + b
list(kw.values())[0]
x + y
clf.fit(X, y)
bools = [True, True, False, True, True, False, True]
help(__future__)
fig, ax = plt.subplots()
reactor.stop()
entity = query.get()
df = df.stack().reset_index()
print(str(some_delta))
imgaxes.set_xlim((x1, x2))
np.sin(theta, out=x[:, (1)])
socket.setdefaulttimeout(60)
text.set_color(color)
self.worker.flag = True
row.append(np.array(list(range(0, num_rows))))
self.select_range(self.position, Tkinter.END)
a.count(item) == 1
print(hello())
[_f for _f in pattern.split(s) if _f]
np.place(dat, np.in1d(dat, old_val), new_val)
os.killpg(os.getpgid(pro.pid), signal.SIGTERM)
patcher.start()
data = np.arange(1, 7)
print(b.z)
arr2d = np.zeros((10, 10))
person = find_person(people_list, name)
f(n)
print(line)
ax.invert_yaxis()
min_value = min(d.values())
indices = tf.constant([0, 2])
dict((c, getattr(model, c)) for c in columns)
s = f.getvalue()
isinstance(0, collections.Sequence)
self.neighbours = 0
app = QApplication(sys.argv)
vol += [volume[key] for key in sorted(volume)]
soup = BeautifulSoup(page)
(a, rec[a]), (b, rec[b])
w.maximize()
x, y = np.meshgrid(X, Y)
obj.user.save()
current_user.append(line[6:].strip())
plt2 = fig.add_subplot(2, 1, 2)
doc = BeautifulSoup.BeautifulSoup(req.content)
group.delete()
cursor = con.cursor()
max_index = np.argmax(a[inds][mask])
obj.starts += timedelta(days=1, hours=2)
a + b + c
df.columns
tcp_send(pickle.dumps(dict))
gs = gridspec.GridSpec(2, 1, height_ratios=[1, 4])
output = os.rename(infilename, newname)
f.read()
html.format(model=model, content=data, theaders=theaders)
[convert(i) for i in obj]
max(map(len, line.split()))
f.close()
plt.legend(recs, classes, loc=4)
opener = urllib.request.build_opener()
next(f)
colr1 = getRGBfromI(i1)
print(sum(1 for x in l if my_condition(x)))
DBSession.commit()
ax2.set_yticklabels(new_labels)
set(chain(*list(obj.values())))
M[row, col]
list(d.values())
m.drawcoastlines()
random.choice(self.items)
[1, 2, 1]
os.makedirs(save_path)
devnull = os.open(os.devnull, os.O_WRONLY)
print(len(f.read()))
arr.reshape(arr.size / 2, 2)
rev_multidict.setdefault(value, set()).add(key)
self.lock = threading.Lock()
glViewport(0, 0, width, height)
diff = [round(abs(x / float(y)), 1) for x, y in pairwise(your_iterable)]
self.conn = MySQLdb.connect()
d[item[0]].append(item)
a[0] = c
df
ax.set_xticks(np.arange(data.shape[1]) + 0.5, minor=False)
pyplot.plot(x, y)
p.start()
n % k == 0
setattr(self, k, v)
Example().run()
interned
_odbcinst_UserINI(szFileName, FALSE)
request.finish()
plt.figure()
pl.plot_surface(X, Y, Z, alpha=0.4)
p.join()
a = np.zeros((2, 2))
process(line)
df = pd.DataFrame(dict(zip(*v)) for v in vals)
print(data)
pprint(stiff.subs({(-nuxy - 2 * nuxz ** 2 + 1): m}))
self.setGeometry(100, 100, 500, 190)
any(i in setA for i in rng)
prefixes[key[:-1]].append(key)
plt.tight_layout()
self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
math.sqrt(x * x + y * y), math.atan2(y, x)
self.currentStack.append(obj)
ax.plot(x, y)
a = []
time.sleep(0.01)
isinstance(Ham2(), Ham1)
c.setopt(c.URL, url)
security_adapter.set_enable_user_folders(True)
print(list(a))
divisors.append(i)
X[:, start:end] = x
A_init = pd.DataFrame(np.random.binomial(1, 0.5, (1000, 500)))
next(tuesdays_of_february)
result = []
interruptable_get(q)
print(nextmatch)
newroot.insert(0, root)
df.diffs[idx] = df.value[idx].diff()
HTMLParser.__init__(self, *args, **kwargs)
writer = csv.writer(f)
tool.stdout.close()
dists.dot([1, 1, 1, 1])
ax = plt.subplot(111)
plt.show()
print(resp.read())
soup = BeautifulSoup(html)
m.load()
plt.show(False)
result.add(tuple(sorted(factors)))
instance.save()
pythons_psutil[0].memory_info()
mask = np.isnan(arr)
cur = con.cursor()
new_dict[k] = filmswiththisname
names_and_jobs = {id: (names[id] + (jobs[id],)) for id in names}
tkinter.createfilehandler(file, mask, callback)
np.fromiter(v[0] for v in data)
funcs[0]()
prev.next = tmp.__next__
print(df1)
plt.hist(numpy.log2(data), log=True, bins=bins)
time.sleep(60)
os.getcwd()
ax.loglog(x, y)
sys.stderr.write(s)
ax.add_patch(patch)
content = wiki2plain.text
print(a.shape, b.shape)
(x < 255 * p).reshape(shape)
collection.save(res)
tmp.write(line)
main()
_, max_value = max(data, key=lambda item: item[1])
reactor.run()
Gtk.main()
ax.set_yticks(k)
i.active()
main()
locals().update(main())
B = [b for _, b in sorted(zip(order, sorted(B)))]
client = Client(url)
img_temp.write(urllib.request.urlopen(url).read())
a = np.arange(27)
self.ax.xaxis.set_minor_locator(day)
self.stop()
ax2.yaxis.tick_right()
J1d = I1d.any(axis=-1).reshape(pairs.shape[:2]).sum(axis=-1)
B.T[r, c] = B.T[c - r, c]
m.start()
re.findall(pattern, string, flags=0)
[X, Y] = np.meshgrid(x, y)
os.setsid()
df.ix[row, key] = val
[0, 0, 1, 1, 1],
link.pack()
{k: sum(map(itemgetter(k), dict1)) for k in dict1[0]}
new_queue[key] = queue[key]
main()
ax.legend()
bpy.ops.transform.translate(value=(0, 0, v.length / 2))
parser = argparse.ArgumentParser()
db = SQLAlchemy()
self.noisycount += 1
self.quietcount += 1
content
text += elem.strip()
os.chdir(directory)
json.loads(data)
print(m.group(2))
lis1, lis2 = [x[0] for x in my_list], [x[1] for x in my_list]
__init__.py
any(keyword in string for string in c_lst for keyword in k_out)
clock = pygame.time.Clock()
newtest = [x[:-1] for x in test]
df.columns.levels[0]
self.status.configure(text=message)
self.scrollbar.config(command=self.data.yview)
all(x.count(value) == number for x in lst)
net.stop()
self.Bind(wx.EVT_LEFT_UP, self.on_left_up)
dir(__builtins__)
self.suggestions = []
opener = urllib.request.build_opener(auth_handler)
out.write(f.read())
self.text = tk.Text(root)
plt.xticks(rotation=90)
x.normalize().to_eng_string()
list(a)
self.treeview.collapse_row(row.path)
otherfoo.bar()
df.index = [np.arange(len(df.index)), df.index]
data = []
ghostscript.Ghostscript(*args)
a + b
print(type(b))
X[k, k] = exp_diag[k]
num_of_weeks = math.ceil((end_date - start_date_monday).days / 7.0)
self.__dict__.copy()
e.foo()
p.data
self.cache[key] = self.func(*args, **kwargs)
plt.bar(idx, c[0], color=hexencode(c[1]))
conn = cx_Oracle.connect(conn_str)
sock.close()
fig.colorbar(im, ax=axes.ravel().tolist(), shrink=0.5)
print(a, b)
PyObject_HEAD_INIT(NULL)
reader = csv.reader(ifile)
time.sleep(0.5 * random.random())
my_copy = {key: value[:] for key, value in list(my_dict.items())}
app = QApplication(sys.argv)
print(list(d(myset)))
btn2.pack()
A[i], A[j], A[k] = new_values
emp.save()
get_stuff(d, get_value, get_subitems)
d[0]
l.extend((21, 22))
np.exp(a * np.log(x) + np.log(b))
d.pop()
print([x for x in thing])
out = np.hstack([xyzcols, eyecols])
[1, 2]
plt.show()
stream = cStringIO.StringIO()
print(Counter(data).most_common())
writer.writerows(enumerate(word_features, 1))
y = np.zeros(yshape, data.dtype)
assert list(itersplit(sample2)) == sample2.split()
x = np.linspace(-5, 9, 10000)
f2.write(f1.read())
self.root.clipboard_append(self.msg)
abs(a - b) <= chosen_value
(0.25).as_integer_ratio()
alist = [(1, 6), (2, 5), (2, 4), (7, 5)]
self.logger.info(data)
ssl._create_default_https_context = _create_unverified_https_context
x = np.linspace(0, 1, 50)
float_array.tofile(output_file)
sys.modules[__name__] = MyReprModule(sys.modules[__name__])
val ^ 1
df.some_property
colors.extend(mpl.cm.jet(np.linspace(0, 1, N - 1)))
etree.tostring(root)
form = EditProfile(obj=user)
partition = lambda p, xs: (list(filter(p, xs)), [z for z in xs if not p(z)])
parser = argparse.ArgumentParser()
print(string.format(**dictionary))
isgenerator(), istraceback(), isframe(), iscode(), isbuiltin()
print(get_extension_id(sys.argv[1]))
self.obj[name] = value
_list.extend(list(range(r[0], r[1], r[2])))
func(*args, **kwargs)
data[:i]
next(obj for obj in objs if obj.val == 5)
command = os.path.basename(sys.argv[0])
exec(f.read())
cv2.drawContours(convexI, [ConvexHull], -1, color=255, thickness=-1)
out = np.column_stack((out_id, out_count))
cm = sns.clustermap(data)
[]
output[token.lower()][line[t + 1].lower()] += 1
rgb = hsv_to_rgb(hsv)
print(match.start(), match.end())
writer = csv.writer(outfile)
self.doc.build(pdf)
tot.append(get_count(data, binmin, binmax, inclusive))
A = numpy.array([(a, 0, 0), (c, d, 0), (0, 0, 1)], dtype=np.float64)
pd.Series(dic)
cap = cv.CaptureFromCAM(0)
fig = plt.figure(figsize=(xinch, yinch / 0.8))
plt.boxplot(x + i * 2, vert=0)
super.__setattr__(self, attr, value)
1
setattr(obj, field_name, sub_object)
app.add_url_rule(url, url, redirect_url)
keys.sort()
fileHandler.setLevel(logging.FATAL)
ent.delete(0, END)
l1.extend(l2)
df
list(json_object[0].items())
writer = csv.writer(g)
quality = models.CharField(max_length=100, choices=CHOICES_QUALITY)
c[key] = list(set(a[key]).difference(b.get(key, [])))
execlist[i][1] = myctype
time.time.__name__
df = pd.DataFrame()
print((df[0] == 0).idxmax())
document.openProtection(spm)
self.model = QtGui.QStandardItemModel(self)
()
Example().run()
json.dumps((i * i for i in range(10)), iterable_as_array=True)
dfy.apply(lambda x: x.between(df.FIRST.dt.year, df.LAST.dt.year)).astype(int)
Bar.bar()
print(colorful_json)
all(it1) or not any(it2)
form.instance.author = self.request.user
driver = webdriver.Firefox()
data[0](*data[1:])
L = list(L[0]) if len(L) == 1 else L
pi.save()
img.paste(source, mask=border)
startupinfo = subprocess.STARTUPINFO()
interact(set_cursor, x=ax.get_xlim(), y=ax.get_ylim())
all_cookies = self.driver.get_cookies()
int(list(filter(str.isdigit, repr(nums))))
soup.body.clear()
i = len(s)
ax = fig.add_axes([0.1, 0.1, 0.7, 0.85])
x = x + 1
crossproduct = (c.y - a.y) * (b.x - a.x) - (c.x - a.x) * (b.y - a.y)
dialog.setFileMode(QtGui.QFileDialog.ExistingFile)
type(d)
A.__init__(self, x, y)
res = func(*args, **kwargs)
z = np.sqrt(x ** 2 + y ** 2) + np.sin(x ** 2 + y ** 2)
True
c = [a[i] for i in b]
root.grab_set()
self.textLayout.addWidget(text)
t.start()
im.draw(x=0, y=0, z=0, width=fig.width, height=fig.height)
t = np.linspace(0, 4 * np.pi, N)
f()
cr.set_operator(cairo.OPERATOR_OVER)
divisibleBySeven = [num for num in inputList if num and num % 7]
app.register_blueprint(my_view)
is_equal(df, using_precomputation, using_apply)
print(t.render(c))
writer.writerow(Digi_Results)
[2, 499]
np.eye(1, size, index)
fig = pl.figure()
d[9].append(100)
browser = mechanize.Browser()
cap = cv2.VideoCapture(0)
t = np.hstack((np.zeros_like(a), np.ones_like(b)))[s]
img = Image.open(filename)
ax.margins(0.05)
fig = pylab.figure()
parts[i] = re.escape(parts[i])
zip(*args)
a.append(1)
p.close()
t1 = threading.Thread(target=task1)
background = pygame.Display.set_mode()
L = [15, 16, 57, 59, 14]
ylim(0, 10)
get_monotonic_nums(2, reverse=True)
0
settings.init()
self.qa.save()
fileSet.add(os.path.join(root[len(myFolder):], fileName))
d.shape
self.label.installEventFilter(self)
self.root.mainloop()
t.start()
main()
xsorted = np.argsort(x)
self.caddr = caddr
Person.first_name
s.value_counts()
fp.close()
out_im.putdata(list(image2cga(inp_im)))
missingItems = [x for x in complete_list if not x in L]
pygame.init()
xmin, xmax = kde.get_xlim()
average = float(total) / len(marks)
type.__init__(cls, name, bases, dct)
type(a)
p.map(f, range(m1.shape[0]))
unique_combs(A, 4)
date = parse_date(date_str)
axes.set_yticks(list(range(10)))
part.get_payload(decode=1)
ax.set_xlim(xmax=100)
main()
g = partial(f, 1, 2)
isinstance(P, (collections.Sequence, np.ndarray))
print(i, Counter(clf.predict(X[50:])))
{k: v for k, v in list(locals().items()) if k in args}
os.dup2(test.fileno(), 1)
all_pixels.append(cpixel)
pygame.draw.circle(screen, (50, 0, 0), p, 10, 2)
busnum = 1
b = B()
query_ob = query_ob.filter(or_(*options))
d = dict(((k.lower(), j), v) for (k, j), v in list(d.items()))
sorted_df = df.T.sort(columns=last_row_name).T
df
files = [os.path.join(search_dir, f) for f in files]
b.myfun()
j = np.random.randint(0, 5)
Py_DECREF(array)
redemption_date.month
myFunction()
im.thumbnail(thumbnail_size, Image.ANTIALIAS)
m = np.array([7, 6, 5, 4])
img = Image.open(filename)
_ = sock.recv_into(mview, AMOUNT)
sess = tf.Session()
opener = urllib.request.build_opener(cookie)
fig, ax = plt.subplots()
add_patch(axes[2], rasterized=False)
print(line)
a2[a2[:, (1)] > 10]
time.sleep(0.1)
print(df)
assert False
result = a[indices]
QtGui.QSystemTrayIcon.__init__(self, icon, parent)
seconds = seconds % 60
fig = plt.figure()
df = pd.DataFrame(testdict)
d1 = dict(list(d.items())[len(d) / 2:])
1.0 / np.linalg.det(a)
client.sd[0].service.setlocation(new_url)
fig = plt.figure()
handle.set_visible(False)
G[1][2]
log.setLevel(logging.DEBUG)
print(docopt(__doc__))
values = np.random.rand(10000)
style = ttk.Style()
print(count)
print(m.group())
grid = dask.array.zeros((100, 100), chunks=(50, 50))
arg = booleanize(arg)
[x for x in user_list]
map(sum, l) == [n] * len(l)
wdb.set_trace()
a = pickle.loads(s)
df = df.reset_index()
PLT.show()
column_view.set_widget(column_widget)
random.shuffle(lists)
obj = model_class.objects.get(product=model.product, comment=model.comment)
[str(chr(i)) for i in h]
obj.__reduce__()
entry2.grid(row=1, column=2)
x = np.array([[1, 0], [0, 1]])
next(itertools.islice(self.it, index, index + 1))
print(datetime.now() - startTime)
full_arr = full_arr[full_arr[:, (idx)].argsort()]
id(ax), id(fig.axes[0])
c = list(zip(a, b))
button.pack()
parser = argparse.ArgumentParser()
title = models.CharField(max_length=256)
NotImplemented
self.orig_method(*args, **kwargs)
fig.savefig(buf)
sorter = np.argsort(b)
config_path = os.path.join(application_path, config_name)
df.iloc[0]
average = session.query(func.avg(sums.subquery().columns.a1)).scalar()
driver = webdriver.PhantomJS()
[6, 15, 24]
my_array = numpy.empty(length)
print(datetime.datetime(1970, 1, 1) + datetime.timedelta(seconds=tt))
ax = fig.add_subplot(111)
parser.print_help()
list(zip(word_list, itemgetter(*word_list)(cnts)))
a, b in x
t = np.linspace(0, 1, n)
parser = argparse.ArgumentParser()
print(lines[i + 7])
print(a, b, c)
second_driver = webdriver.Firefox()
False
clf = linear_model.LogisticRegression()
p = argparse.ArgumentParser()
chunkfile.close()
cursor = cnxn.cursor()
f1()
f = np.vectorize(f)
rows = cur.fetchall()
name = models.CharField(max_length=50)
Py_XDECREF(cls)
q = session.query(Post).join(s, Post.id == s.c.key).order_by(s.c.sort_order)
player.play()
wordslist = line.split()
my_series = pd.Series(my_dict)
nonRepetitive_x.append(x[-1] + 1)
self.pigButton.grid(row=0, column=1)
[[item[0] for item in data] for key, data in groups]
self.response.out.write(data)
client.close()
dict_writer.writerow(dict(zip(fieldnames, fieldnames)))
print(parts[1])
prev_i, next_i = indices[0] - 1, indices[-1] + 1
newR = np.percentile(S, (100 * u).tolist())
fn(self, *args, **dict(self.gen_args, **kwargs))
print(line)
df2.combine_first(df1)
data = fp.read()
parser = argparse.ArgumentParser()
print(a.shape)
a, b, c
s.close()
server.ehlo()
my_c_func(py_object(my_list))
ax4.set_xlim(x1[0], x1[-1])
Tk.__init__(self)
L.sort(key=f)
app = QApplication(sys.argv)
h.request(req.get_method(), req.get_selector(), req.data, headers)
random.shuffle(a_list)
tuple(z)
data_mem = data[:]
all_data.dtype.names
ax.yaxis.set_visible(False)
max_val = max(l)
p.start()
br.set_handle_equiv(True)
choles = np.logical_not(noholes)
subset2 = data[data[:, (0)] == 10002]
fig = plt.figure()
help(gdal.ReprojectImage)
event.SetInt(0)
((d.month, d.year) for d in rrule(MONTHLY, dtstart=start, until=end))
sys.path.insert(0, mypath)
logger.setLevel(logging.DEBUG)
myList.append(1)
print(df)
print(b.calculate(1))
plt.subplot(122)
X = numpy.random.random((N, n))
json.dumps(xmljson.badgerfish.data(xml))
task2.start()
task1.start()
+bcolors.ENDC
self.photo = Image.open(file)
cache.init_app(app)
reader = csv.reader(f)
divider = make_axes_locatable(ax1)
os.rename(tmppath, filepath)
merge_dicts(d1, d2)
im = img[:, 0:50, (0)]
s.unstack()
self.im.seek(0)
n = int(x)
gx = np.array([[1, 0, -1], [2, 0, -2], [1, 0, -1]])
urlparse.parse_qs(o.query)
reader = list(csv.reader(f))
lambda realf: f(realf, *args, **kwargs)
new_matrix = a / row_sums[:, (numpy.newaxis)]
objects = UserManager()
self.children.append(node)
p = argparse.ArgumentParser()
self.Bind(wx.EVT_LEAVE_WINDOW, self.on_leave_window)
group.append([year, 0])
self.recipe.name
ax2 = fig.add_subplot(2, 1, 2)
Gtk.CellRenderer.__init__(self)
main()
foo()
thread1.start()
doi_file.close()
f()
func(self, *args, **kwargs)
[k for k, g in groupby(a) if len(list(islice(g, 0, 2))) == 2]
cv.update()
2142
func2b()
x = r * np.cos(t)
dx = 1
print(v.key, v.values[0].value)
print(elem.text)
y.sort()
np.hstack((vector1, matrix2))
plt.xlabel(ax.get_xlabel(), rotation=90)
c = np.linalg.solve(a, b)
alist2.append(alist[x][:])
item = item.strip()
br.open(url)
end_date = start_date + timedelta(days=1)
run(host=aserver, port=aport, debug=True)
p = subprocess.Popen(cmd, stdout=subprocess.PIPE)
print(B[np.searchsorted(B[:, (0)], I)])
sys.getsizeof(test_dict)
pprint(d)
sys.exit(app.exec_())
globals()[c] = Variable(c)
app = QApplication(sys.argv)
result.append(tree.pop())
df.loc[~((lengths % 2 == 1) & (grouped.cumcount() == lengths - 1))]
draw = ImageDraw.Draw(image)
df.loc[criteria, ser.index] = ser[(np.newaxis), :]
print(cross_val_score(clf, X, y, cv=skf))
traceback.print_tb(err.__traceback__)
fig = matplotlib.pyplot.figure()
mask = np.random.randint(2, size=(500, 500))
i.append(0)
print(x)
plt.show()
assert foo.bar == 1
plt.ioff()
myA.myattribute = 9
(c == loop(x)).all()
{{form.as_p}}
leg = ax.legend()
print([(k, mydict[k]) for k in ordering])
fig = plt.figure()
driver = webdriver.Firefox()
NULL
pool.close()
s = pygame.Surface((1000, 750), pygame.SRCALPHA)
tuple(np.hstack(np.where(a == a.max())))
cursor.execute(query, (AsIs(c),))
order_array.shape
set(permutations(x * 2))
arr = list(arr)
print(list(func()))
print(test[selected(test[:, (1)])])
f.close()
a = A()
print(max(node.y for node in path.nodes))
a = np.linspace(-2, 2, 5)
love_ctx.add((charlie, loves, bob))
wrapped_func(*args, **kwargs)
df2.index = df2.index.map(lambda x: difflib.get_close_matches(x, df1.index)[0])
ssh = paramiko.SSHClient()
sys.exit(1)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
similarity = sum((laplacian1[:k] - laplacian2[:k]) ** 2)
result[cols] = result[cols].div(result[cols].sum(axis=1), axis=0)
ax.relim()
{key: foo(value) for key, value in list(d.items())}
self.frame.pack()
self.SetAcceleratorTable(tbl)
chunk = [next(gen) for i in range(lines_required)]
u = [x for x, y in valCount(lst).items() if y > 1]
dict = {x: 2 * a + 1, (x ** 2): 1}
solve(set(range(2 ** N)), set())
im = Image.fromarray(img)
axes[0].title.set_size(40)
self.stream.close()
pprint.pprint(parse_message_to_tree(s))
self.addHandler(console)
idf = np.log(float(n_samples) / df) + 1.0
np.set_printoptions(suppress=True)
funcs.append((lambda i: lambda x: f(i, x))(i))
f.seek(-4, 2)
im = Image.open(im)
sorted(data, cmp=cmpnan)
pylab.show()
self.inner_test = inner_test
self.observer.start()
appengine.monkeypatch()
boom(x, y)
foo()
image.seek(0)
current_process = psutil.Process()
int(v)
nnz = indptr[-1]
df1.join(df2)
deletesys.modules[key]
z = np.polyfit(x, y, 1)
print(max(abs(clf.coef_ - w)))
fig = plt.figure()
gif.seek(1)
my_bytes = bytearray(data)
self.cformat = cformat
index = bisect.bisect(a, value)
ssh = paramiko.SSHClient()
f.close()
run_func()
line = doSomething(line, next(infile))
[word for word in words_seq if pat.match(word)]
a[::2]
G = nx.Graph()
lastHourDateTime = datetime.datetime.now() - datetime.timedelta(hours=1)
data = cursor.fetchone()
self.name = name
len(s)
Base.metadata.drop_all(bind=db.engine)
filtered_word_list.remove(word)
ax.plot(grouped.get_group(key))
a = numpy.empty((1, 10), dtype=object)
print(data[1])
PREDICT(FOR_ITER)
deltaX = P2_x - P1_x
time.sleep((0.1 + random.random() / 10.0) / float(speed))
Z = np.exp(-(X ** 2 + Y ** 2))
QNetworkAccessManager.__init__(self)
c = np.core.defchararray.equal(a, b)
log.addHandler(JournalHandler())
all_data = pd.concat(dfs, ignore_index=True)
SOAPpy.__path__
t.ix[1], t.ix[2] = t.ix[2], t.ix[1]
cv.SetData(cv_img, img.rotate(180).tostring()[::-1])
x_sorted = [x for y, x in yx]
listbox.autowidth(250)
dx = [size1, -size1, -size1, size1, size1]
pool.join()
cb = plt.colorbar(im)
wx.Frame.__init__(self, parent, id, title, size=wx.DisplaySize())
pd.rolling_std(s, window=5).head(10)
browser.open(url)
yticks(linspace(ylim()[0], ylim()[1], numSteps))
user.save()
root = tree.getroot()
zip(*l)
opener = urllib.request.build_opener(urllib.request.HTTPHandler(), cp)
plt.close()
True
self._reader1 = reader1
response.status = falcon.HTTP_200
a * c + b * ~c
d[i].extend(j)
df2.Date = pd.to_datetime(df2.Date)
pprint.pprint(ll)
counter = collections.Counter(a)
isitIn(char, aStr[len(aStr) // 2:])
dict.__setitem__(self, key, value)
model = Whatever
False
ax.set_ylim(0, 5)
ax.xaxis.set_minor_formatter(plt.FuncFormatter(show_only_some))
closedir(dir_p)
Frame.__init__(self)
msg = MIMEMultipart()
print(s1[s1.index(s2) + len(s2):])
print(line)
do_something_with(node.value)
df = pd.DataFrame(np.random.randn(100, 2))
self.before.append(descendent)
Frame.__init__(self, master)
print(groups.aggregate(lambda x: np.mean(x[x > 0.5])))
os._exit(0)
admin.site.register(SomeModel, SomeModelAdmin)
outdict[tmp[0]].append((tmp[1], float(tmp[2])))
dt.datetime.fromtimestamp(timestamp)
next(b)
central = utc.astimezone(to_zone)
Base.prepare()
log()
a.append(d)
d = dict([(i, [a, b, c]) for i, a, b, c in zip(df.ID, df.A, df.B, df.C)])
repo.index.add(file_list)
gc.collect()
root.update()
difflib.SequenceMatcher(a=c, b=d).ratio()
length = a.shape[0]
n = len(s)
[0.0, 0.0] / np.float64(0)
sorted(personArray, key=lambda a: a.age)
datenow -= timedelta(days=datenow.isoweekday() - 5)
has_permission(permission, resource, request)
self.serial = serial.Serial(self.inport)
sys.exit(0)
Thread.currentThread().interrupt()
df = pd.DataFrame(columns=list(range(8)))
[(k, list(g)) for k, g in evens_odds_grouped]
job.start()
csv_content = requests.get(DOC_URL).text
np.eye(2, dtype=int)
out.reshape(len(arrays), -1)
print(f.read())
Zij = np.arange(N)
fout.write(lines)
g.get().read()
row_dict[col] = row[columns.index(col)]
client_sock.send(response_body_raw)
p.close()
lpr.stdin.write(data_to_send_to_printer)
common_chars = char_list.intersection(test_set)
json.loads(json_data, object_hook=ascii_encode_dict)
p12.get_certificate()
top5 = array[:5]
self.__dict__ == other.__dict__
[LOGGING]
logger.addHandler(sh)
print(match.group(1))
reader = csv.reader(f)
self.session.add(entity)
print(team([1, 1, 1, 1, 1, 1, 1, 1, 1, 9]))
signers = p7.get0_signers(sk)
setups.append(comb)
objectify.deannotate(root, cleanup_namespaces=True, xsi_nil=True)
f.read(1854)
a_sum = a.sum(axis=0)
ax2.contour(theta_edges, r_edges, H)
process.start()
ax22 = fig1.add_subplot(212)
d = collections.defaultdict(list)
dt = datetime.datetime.fromtimestamp(secs)
soup = BeautifulSoup(html_doc)
result.write(line)
label1.pack()
my_new_list.close()
self.ax.xaxis.set_major_formatter(timeFmt)
view.overwrite_status()
print(max(p for p in lst1 if p < 0))
circle1.remove()
res = []
zip_file.close()
baz()
fig, ax = plt.subplots()
axs[i].contourf(np.random.rand(10, 10), 5, cmap=plt.cm.Oranges)
humansize(18754875155724)
descendents_ancestors = set()
offset = datetime.timedelta(days=0)
window.configure(stack_mode=X.Above)
values = np.sum(weights * features) + bias * weights.size
Z2 = np.array([np.dot(X[k], Y[k]) for k in range(10)])
duplicate_dict = dict((k, v) for v, ks in by_val for k in ks[1:])
indata = (ctypes.POINTER(ctypes.c_double) * 5)()
print(sys.argv[2])
filter.uniform_filter(a, size=5)
g = rdflib.Graph()
print(df)
dreload(module)
indicies = random.sample(range(len(data)), k)
dict.__init__(self)
M = np.random.rand(N * 10 * 10).reshape(N, 10, 10)
show()
prof.dump_stats(datafn)
setpath(d[p[0]], p[1:], k)
display.start()
redis.set(key, pickle.dumps(value))
print(_get_column_letter(1))
i += 1
arr[x] = x * np.ones(M)
df = pd.DataFrame(data)
nextprime(n)
django.db.transaction.commit()
PyErr_Print()
arr[i] = -arr[i]
cPickle.dump(root.sclX.config(), f, -1)
response = urllib.request.urlopen(request)
session.run(trainer, {feed_dict})
self.left[-(i + 1)]
p.join()
[x for x, _ in sorted(enumerate(a), key=lambda i: i[1])]
df
text.get_window_extent().width
response.render()
linecache.clearcache()
os.dup2(self.streamfd, self.origstreamfd)
print(list1[:5])
L = L[n:] + L[:n]
fp.close()
Fraction(58, int(X))
Jmask = mask.sum(axis=-1)
df = df.reset_index()
hex(_)
np.rollaxis(a, -1, 2).reshape(a.shape[0], a.shape[1], -1)
G = nx.Graph()
ax.grid(True)
self.reset()
generate_random_data()
dynos = int(sys.argv[1])
a_shared_task(self, *args, **kwargs)
f()
im.show()
ax1 = ax0.twinx()
fit_result = scipy.stats.expon.fit(data, floc=0)
end_date = date(2015, 6, 2)
file.seek(os.stat(filepath).st_size - 1)
self.lst = []
print(count)
std_1 = numpy.std(list_size_1, axis=1)
a = numpy.arange(25).reshape((5, 5))
pool = ProcessPoolExecutor(max_workers=1)
cal = Calendar.objects.get(pk=1)
res = s.translate(remove_digits)
setattr(K, name, eval(name))
Foo().bar.__get__
self.lock.release()
pylab.yticks(list(range(len(names))), names)
a[..., ([True, True])]
plt.show()
b.update({key: a[key] for key in set(a.keys()) - set(b.keys())})
print(type(folder))
[0, 0, 0, 1, 0],
obj = MyModel.objects.get(pk=id)
ax.set_title(str(d))
app = QtGui.QApplication(sys.argv)
start_time = time.time()
arr = np.array([list(map(int, line.strip())) for line in f])
root_path = get_root_path()
farmer = models.ForeignKey(Person)
weights = np.ones_like(x) * mass
client = paramiko.SSHClient()
server_ssl.sendmail(FROM, TO, message)
inner1d(A, B)
d1.split()[0]
col.set_expand(True)
sorted(result.items())
total = sum(get_numbers(input_string))
data = [2, 2, 2, 2, 2]
topsublist[i] = list(L)
dct[p[0]].append(p[1])
dis.dis(test2)
type(logging.INFO)
plt.show()
u2 = (random.uniform(0, phi2) for _ in range(len(part)))
client = mqtt.Client()
keys = list(Digit.keys())
self.setLayout(layout)
plt.figure()
C = np.where(cond, A, B)
combined = defaultdict(lambda : defaultdict(lambda : defaultdict(int)))
image = np.zeros((height, width, 4), dtype=np.uint8)
output_string = json.dumps(o)
server_sock.close()
fd = sys.stdout.fileno()
all_ids.sort()
output.write(line)
file.truncate()
f.write(s)
f.close()
self[key]
x = np.linspace(start, end, N)[:, (np.newaxis)]
django.VERSION
strc_view[0, [0, 1]] = x
sess = tf.Session()
results = pool.map(convert, images[i:i + chunk_size])
index = random.randint(0, len(a) - 1)
X_train_0 = X_train[y_train == 0]
list(d.values())
scipy.version.version
{k: v for k, v in list(a.items()) + list(b.items()) if k in symm_diff}
Session.add(user)
main()
self.lbl.pack()
map(lambda x: x % 2 == 0, l)
G.add_weighted_edges_from(cur)
d = np.arange(1, 21, dtype=np.float)
list(map(d.update, extras))
im.set_data(next(rw))
coords = np.stack(np.meshgrid(x, y), axis=-1)
startupinfo = subprocess.STARTUPINFO()
self.items.append(item)
test_data = data[50:]
c = [(a[x] + [b[x]]) for x in range(len(b))]
check(sys.stdin)
ax.set_xticks(x_ticks[::2])
[0, 0, 0, 0, 11, 12, 0, 0],
lineno = i + 1
lons = np.array([5.5, 102.5, 116.2, 5.5, 102.5, 116.2, 5.5, 102.5, 116.2])
self.server_close()
flush()
int(max(solve(a * x ** 2 + b * x + c, x)))
-0.5 * (x - mean).dot(inv(C)).dot(x - mean)
self.irenR.Render()
app = QtGui.QApplication(sys.argv)
np.array([a.tolist(), b.tolist()])
image.set_data(self.image_data)
args = parser.parse_args()
ax2.plot(xvals, yvals, linewidth=4)
EMAIL_USE_TLS = True
ax.plot(x1, np.sin(x1 / 2.0))
cumsum([0.2, 0.2, 0.2, 0.2, 0.2])
print(b(a, 10))
processBody(line)
foo.stop()
path = db.Key(opaque_id).to_path()
newlist.extend(l)
all_potions[self.name] = self
map(id, b)
pdb.set_trace()
h, s, v = rgb_to_hsv(r, g, b)
flask_login.login_user(user)
ref_to_func()
do_something_else(object_list[0])
sorted(items, key=key())
number_of_lines = len(f.readlines())
self.clear_widgets()
dfa = df.ix[:, ([1, 0])]
y[0][1] = 4
time.sleep(2)
offs -= 1
myset = set()
df
results = defaultdict(list)
b.append(foo())
LoPRIOpoller = zmq.Poller()
flipped[value].append(key)
relaxng_doc = etree.parse(f)
serializer = TaskSerializer(tasks, many=True)
dt.datetime(1970, 1, 1) + dt.timedelta(seconds=int(timestamp))
random.random() < p
hug(a)
cgitb.enable()
parking_rows.append(ParkingLotRow((1, 222), (462, 240), 22))
ax.add_artist(pol2)
lst = [10, 10, 20, 15, 10, 20]
app.run()
client = pymongo.MongoClient()
f.close()
ch.start()
fig = plt.figure()
parsed_url.geturl()
a, b, c
src = Image.open(src)
Counter(string1) == Counter(string2)
t.join()
application = QtGui.QApplication(sys.argv)
self.runButton.clicked.connect(self.callProgram)
x = np.linspace(0, 1, 1000)
parser.parse_args(extra_args, namespace)
X, Y = np.meshgrid(x, x)
self.groups.clear()
replacements = [0, 0, 0, 0]
relaxng = etree.RelaxNG(relaxng_doc)
process = subprocess.Popen(cmd, shell=True)
sympy.solve(exp)
os.chdir(dir_of_your_choice)
re.findall(re2, text)
x = np.asarray(x)
idcord.append(x1)
s.listen(0)
client.service.SomeMethod()
child.sendline(mypassword)
print(p.sub(repl, s))
print(len(argspec.args))
ndates = (regx.split(date.strip()) for date in dates)
defaultdict(lambda : 1)
gencache.Rebuild()
frame = cv.QueryFrame(capture)
root = tk.Tk()
[n for n in dir(f) if isinstance(getattr(f.__class__, n), property)]
data[my_list].mean(axis=1)
cell = xl.ActiveSheet.Cells(1, 2).Text
snake.update()
l.append(num)
d.setdefault(parts[0], []).append(parts[1])
metafunc.addcall()
app = Flask(__name__)
a_f = os.path.abspath(__file__)
ynoisy = y + np.random.normal(0, 0.2, size=len(x))
a.writerows(data)
html += str(tag)
jsonpickle.decode(jsonpickle.encode(Goal(), unpicklable=False))
numpy.arange(25).reshape((5, 5))
root.mainloop()
args = parser.parse_args()
bus = ibus.Bus()
link = soup.find_all(**kwargs)[0]
fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)
__all__.append(module_name)
source / opt / python / current / env
plt.show()
itertools.combinations_with_replacement(list(range(min, max)), num)
model.fit(X, y, nb_epoch=1, batch_size=data.batch_size, verbose=0)
solution = driver.find_element_by_css_selector(css)
print(line)
answer.append([new_list[0][0], new_list[1][0]])
QtGui.QWidget.__init__(self, parent)
narray[i] = NULL
np.array([tuple(values)], dtype)
{{(blog_date | timesince): comment_date}}
a.sort(key=id, reverse=True)
bundle.obj = self._meta.object_class()
foo.bars.add(1, 2)
mux_fn(a, b)
type(value)
df = pd.read_csv(StringIO(text), delim_whitespace=True, dtype=str)
main()
reactor.stop()
decorator(arg)
app.mainloop()
matrix = []
A = np.array([0, 1, 2])
OrderedDumper.add_representer(OrderedDict, _dict_representer)
the_canvas.save()
sig1 = sin(t1 / 2) + np.random.normal(scale=0.1, size=len(t1))
end_date = time.strptime(end_date, fmt)
print(nuc[frame:].translate(table))
self.mock_requests = Mock()
row.append(a[i][j] + b[i][j])
print(df[col_list[2:5]])
b = np.array(zip(a.T, a.T))
soup = BeautifulSoup(new_text)
CornerHarris(gray, harris, 5, 5, 0.1)
readline.set_completer(tab_completer)
Qapp.exec_()
print(s % tuple(x))
unpackbits(arange(2, dtype=uint16).view(uint8))
d = {x: a.count(x) for x in a}
fig.subplots_adjust(hspace=0.75)
setup()
ascii_lowercase.find(letters) != -1
l[:] = first_found(l)
ax.gridlines()
functor = arity.__class__
foo.__getitem__(something)
background.paste(overlay, overlay.size, overlay)
self.a + self.b
res = [lookupdict[k] for k in list(arr)]
print(vars(my_object))
print(str(100).zfill(2))
f.write(text)
some_long_task.delay(x, y)
myDict = defaultdict(int)
Foo().bar
norm.ppf(0.95)
pprint([(k, list(g)) for k, g in groupby(strs)])
plt.show()
Maybe(func(self.val))
lastvals = y[-1] + np.abs(y[-half_window - 1:-1][::-1] - y[-1])
a = np.random.rand(4, 4)
particle.kill()
ax.zaxis.set_rotate_label(False)
result_dict[str(len(word))].add(word)
r = Image.fromarray(numpy.uint8(r_array * 255.999))
same_structure(a[1:], b[1:])
Watchdog(1)
user = User()
raise NotImplementedError
d.setdefault(i, [])
nmask = [ord(c) for c in mask]
ax.grid()
application = get_wsgi_application()
cts = datetime.fromtimestamp(ts)
curr_points = [(x, y) for x, y in zip(first_points, second_points)]
main()
[(not y) for y in x]
time.sleep(sleep_time)
key1 = models.IntegerField(primary_key=True)
ended = time.time()
a = np.array([0, 47, 48, 49, 50, 97, 98, 99])
A.print_x.__func__(b)
rand_x_digit_num(10, False)
f.seek(0)
0.1 * randint(int(min_time * 10), int(m_time * 10))
logging.Handler.close(self)
print(longest_sum([1, 1, 1, 1, 1, 1, 4], 0, 0, 6))
print(calculateDistance(2, 4, 6, 8))
df.reindex(df.b.abs().sort(inplace=False).index)
[[b.pop(0), b.pop(0)] for _ in range(1)]
(1.0 + erf(x / sqrt(2.0))) / 2.0
im = scipy.misc.imread(filename)
z = np.arange(-5, 5, 0.2)
masked_diff.argmin()
myA[(myA > 5).nonzero()[0][:2]] = 0
self.clientSocket.send(data)
[(1, 2), (2, 0)]
remove_odd([4, 5, 4, 7, 9, 11])
fd.write(request.content.read())
self.next_chunk = self.next_chunk[n:]
Py_Finalize()
browser.open(login_url)
evt.Skip()
ssh = paramiko.SSHClient()
contribution.filter()
handle_last_line(remaining)
zip(x, y)
p.start()
hscrollbar.config(command=canvas.xview)
np.random.seed(100)
ret = f(*args, **kwargs)
print(label.get_text())
result = []
session.flush()
df.apply(lambda x: d[x.name].transform(x))
foo(bar)
time.sleep(sleeping_time)
Question.objects.filter(test_id=fr).update(test=test_obj)
t.sort()
mlab.figure(size=(1024, 768), bgcolor=(1, 1, 1), fgcolor=(0.5, 0.5, 0.5))
print(res.getheaders())
second.nonzero()
newlist.append([a, numlist[key]])
pygame.quit()
offset += len(line)
np.amax(a[mask])
msg = queue.get()
print(entry.title)
testclassa().testmethod1()
foo = lambda x, y=2: x + y
sys.exit()
sock.connect((self.host, self.port))
bar2 = Bar.objects.get(pk=2)
options = webdriver.ChromeOptions()
identifier = CharField(primary_key=True)
fcntl.fcntl(w, fcntl.F_SETFL, old_flags | os.O_NONBLOCK)
item1.setBackground(QtGui.QColor(255, 128, 128))
a = MyModel.objects.get(id=1)
thread = threading.Thread(target=target)
file = forms.FileField()
v = -np.cos(np.pi * x) * np.sin(np.pi * y) * np.cos(np.pi * z)
start = time.time()
read = f.read()
primepi(n)
timestamp = time.mktime(ntuple)
t = Thread(target=print_updates, args=(q,))
MAIL_USE_TLS = False
self.panel_sizer = wx.BoxSizer(wx.HORIZONTAL)
json_string = json.dumps(data, ensure_ascii=False)
plt.imshow(np.random.random((10, 10)))
t.start()
plt.figure(figsize=(6, 5))
np.testing.assert_almost_equal([x, x, x], [y, y, y], 5)
p.remove(c)
emitted.append(name)
pygame.init()
AFMT_S16_NE = ossaudiodev.AFMT_S16_BE
sizer = wx.BoxSizer(wx.VERTICAL)
plt.show()
now = dt.datetime.now(timezone)
root = dict()
[idx for idx, el in enumerate(foo) if type(el) == type(arr)]
p4 = ctypes.c_int(0)
max(map(int, MyCount))
words.append(ipta)
client = oauth2.Client(consumer)
self._server.running = True
constant_dic = dict([(c, i) for i, c in enumerate(constants)])
a[:, (1)] *= 5.2
utf8_fh.readlines()
my_answer.append(my_array[i])
Counter(get_all_k_mer(s, k=2))
output = PdfFileWriter()
MainWin().main()
sqlContext.createDataFrame(rdd, schema)
raise OSError(e)
t.start()
NP.cumsum(A[:, (1)])
p.start()
ts = (utc_date - date(1970, 1, 1)).days * 86400
quad(integrand, 0, 1000, points=[750])
arr2 = arr.reshape(20, 500)
l.set_rotation(0)
s.unstack()
ax.grid(False)
df.set_value(i, j, value ** 2)
sys.exit(main(sys.argv[1:]))
np.where(y == 0, 0, x / y)
title = models.CharField()
threading.Thread.__init__(self)
L[:next(n) + 1] = []
ax.xaxis.tick_top()
pool.apply_async(worker, (item,))
y_val = [x[1] for x in data]
Pear
datetime.datetime.now()
G.add_edge((q, r), (q, r + 1))
print(instance[0].instances[0].start())
sizer = wx.BoxSizer(wx.VERTICAL)
corpus = Corpus(documents=[Document(x) for x in lst])
words.remove(word)
listB = [[1, 20], [21, 17]]
pool.terminate()
random.shuffle(indices)
sock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL, 2)
display.set(ast.literal_eval(display.get()))
isinstance(instance, User)
Food._meta.get_all_related_objects()
dist = hamdist(trans[i][:-1], trans[j][:-1])
obj.get_object()
root = Tkinter.Tk()
Frame.__init__(self, root)
soup = parser.parse(text)
plt.contour(X, Y, T[:, :, (round(len(z) / 2))], 64)
data = numpy.random.normal(size=10000)
iterator.__iter__()
word = match.group(0)
numbers = [x for x in range(length)]
a[~mask]
top_matrix.nullspace()
self.treeview.append_column(self.tvcolumn1)
cv_img = adaptors.PIL2Ipl(pil_img)
swin = ScrolledWindow(frame, width=500, height=500)
math.exp(-x)
phases = phases.reshape((10, 1))
tox - -tests / test_loader.py
partial(_update_filename, path=path)
sympy.solve(d)
X = sparse.lil_matrix((100, 100))
signal.alarm(seconds)
plt.scatter(x, y)
self.func_count += 1
cols = df.columns.tolist()
a = np.ones(y[-1], dtype=np.intp)
app = Flask(__name__)
(lambda x: lambda : x)(value).__closure__[0]
max.append(-1 * q.get())
p.get_children()[1].get_paths()
A = [[INFINITY for i in range(n)] for j in range(2 ** n)]
do_something_awesome(lines_of_interest)
self.master.rowconfigure(r, weight=1)
request = QNetworkRequest(QUrl(url))
assert isinstance(f.read(), str)
writer.commit()
print([t[1] for t in Formatter().parse(s) if t[1]])
s.login(user, password)
n = int(input())
next(it)
sleep(5)
base_start += timedelta(days=1)
_cell.style.fill.start_color.index = Color.DARKGREEN
max(left_depth, right_depth) + 1
self.queries = []
lambda x: exp(x)
heapq.nlargest(5, A, key=A.get)
root = Tk()
d = d.reshape(partitions.shape[1], -1)
x[0].append(1)
line = f.readline()
[item for item in list(set(L)) if L.count(item) > 1]
sess = tf.InteractiveSession()
inFile = sys.argv[1]
ax.set_yticklabels(df.index, size=20)
csvfile.close()
y = np.asarray(y, dtype=np.uint8)
mycsv = csv.reader(open(myfilepath))
inverted_dictionary[new_key] = [key]
[x for x in List1 if x in Set2]
time.sleep(2)
self.add(button)
app = webapp.WSGIApplication(url_map, debug=False)
ax1 = plt.subplot2grid((6, 1), (0, 0))
line = line.rstrip()
ax.legend(handles=handles, labels=labels)
y.append(contour[0][1])
fig, axes = plt.subplots(ncols=2, sharey=True)
db.session.add(post)
test_runner = unittest.TextTestRunner().run(test_suite)
wd.implicitly_wait(10)
[False, True]
self.args[i]
self.crawler.configure()
[i[1] for i in l]
a + b
table.horizontalHeader().setResizeMode(0, QHeaderView.Stretch)
fig, ax = plt.subplots()
child.close()
self.f.flush()
pprint(list(all_doublet_tuples(n)))
len(df.index) == 0
c[0] += 1
app = Flask(__name__)
model = gensim.models.Word2Vec(sentences)
loop.close()
res = numpy.empty_like(a)
p.start()
d = {k: default_to_regular(v) for k, v in d.items()}
rfc822.parsedate_tz(date)
f.seek(i * line_len)
xmin, xmax, ymin, ymax = x.min(), x.max(), y.min(), y.max()
queryset = Question.objects.all()
response = urllib.request.urlopen(req)
p = subprocess.Popen(cmd, stdout=subprocess.PIPE)
log.setLevel(logging.DEBUG)
time.sleep(seconds_till_future)
post[0].tags.clear()
print(calculateDistance(2, 4, 6, 8))
parameter_setting.save()
print(x)
self.name = name
srf.blit(f.render(unistr, True, (255, 255, 255)), (0, 0))
labels = np.array([1, 2, 0, 0, 2])
Tk().withdraw()
print(f.read())
answer.extend([k for _ in range(counts[k])])
self.timer.Start(8000)
plt.hist(results, bins=bins)
HTML(style + df.to_html(formatters=frmt))
np.vstack([A[i:i - len(A) + width] for i in range(len(A) - width)])
inset.set_yticks([y_min, y_min + (y_max - y_min) / 2.0, y_max])
False
match.group(2)
s.getId(), s.getName(), s.getCustomer().getId()
wrapper
G.add_edge((q, r), (q, r - 1))
a = ndimage.interpolation.zoom(a, 0.5)
pyplot.show()
colorama.init()
print(sys.argv)
G.add_edge((q, r), (q - 1, r))
print(b[0])
np.set_printoptions(2, threshold=100, edgeitems=10, suppress=True)
image_file = io.BytesIO(fd.read())
driver = webdriver.Firefox(capabilities=caps)
datastream.read(2)
print(calendar.month(2011, 9))
aList = [Entry(**vals) for vals in values]
c, b = hashlittle2(data, initval, 0)
vocab_tage = dict((value, key) for key, value in list(tag_vocab.items()))
ax = plt.figure().gca()
i += 1
foo = Foo()
int(time.mktime(value.timetuple()) * 1000)
field_name = file_name
p.wait()
pool = Pool(2)
PROJECT_PATH = os.path.dirname(os.path.abspath(__file__))
results = multiprocessing.Queue()
ax = fig.add_subplot(1, 1, 1)
lineResult = libLAPFF.parseLine(line)
plt.gca().add_collection(lc)
display(fig)
worksheet.write(row, col, key)
a, b = b, a + b
outdict
self.set = set()
m.append([int(x) for x in input().split()])
root.mainloop()
contrived.foo()
keys.sort()
print ()
numpy.power(x, a + 1.0) - b
arr = [[0, 0, 0, 0] for i in range(5)]
time.sleep(0.2)
stdout = sys.stdout
b = numpy.array([100, 100, 100])
print(f)
logging.Handler.__init__(self)
new_dic[1] = {(2): 5}
A = np.arange(100).reshape(25, 4)
print(parser.parse_args())
Data = NP.random.randint(-5, 5, 1000).reshape(500, 2)
plt.tight_layout()
(evens, odds)[i % 2].append(i)
print(mmc.serial)
fig.tight_layout()
threading.Thread(target=show_progress_A, args=(win,)).start()
a = list()
d = dict((v, k) for k, v in r.items())
df = pd.DataFrame(dict(time=tidx, value=np.random.rand(smp_n)))
res = dict(sorted([(k, v) for k, v in list(L.items())], key=lambda x: x[1])[-2:])
G.add_edge((q, r), (q + 1, r))
math.atan2(-0.0, -0.0)
array = (ctypes.c_double * 100)()
print(tuple(f))
ax1 = fig.add_subplot(111)
df
surface.fill((255, 255, 255))
file.delete()
X[:, (idx0)]
raise KeyError(key)
print(A[ind])
csv_writer.writerow([x[y] for x in hello])
imgplot = plt.imshow(img)
sorted(a)
abort(404)
l.index(a) < l.index(b)
layout.addWidget(self.DataPlot, 1)
irenL.Start()
index = [0, 2]
S1 = set(L1)
cj = cookielib.LWPCookieJar()
get_greenlet_status(greenlets)
db.create_all()
result = func(*args, **kwargs)
inner = result[outerKey].copy()
self.pipeline.send(self)
cnx.close()
sound.play()
self.documents.append(QTextDocument(self))
m = len(list)
self.c = cv2.VideoCapture(0)
client = Client(wsdl=wsdl)
result = collections.Counter(sixgrams)
screen_name = models.CharField(max_length=50, blank=True, null=True)
M.set_value(index, column, new_value)
Two().f()
ast.iter_child_nodes(node)
f.write(inp)
thread.join()
self.drain()
vars(type(obj))[2]
print(tag.nextSibling.__class__)
manager.run()
years_dict[line[0]].append(line[1])
l.add(1)
main.py
len(s)
rex.match(my_string)
self.setCentralWidget(self.window)
print(list(itertools.chain([peek], gen)))
print(np.random.dirichlet(np.ones(10), size=1))
url = opener.open(request)
linspace_y = np.linspace(min(y_range), max(y_range), 100)
fig = plt.figure()
points.sort()
ax.grid()
y.append(b.pop(0))
arguments.method(**vars(arguments))
format_to_year_to_value_dict[format_str][year].append(value)
min(c for c in s if c.isalpha())
A.sort()
y = []
http = httplib2.Http()
float(s)
arr = np.array(img)
setattr(obj, self.name, types.MethodType(f, obj, obj.__class__))
pickle.load(f)
help(a.assign)
init_op = tf.initialize_all_variables()
main()
parser = argparse.ArgumentParser()
A.combineAdd(-B)
zf.close()
d = locals()
ct.iloc[:10, :10]
((x + y, x - y) for x, y in data)
my_server.set(variable_name, variable_value)
canvas.setLineWidth(0.5)
print(m.groups())
Counter(h.split())[n]
diff = filter(lambda x: x not in b, a)
web.show()
draw = ImageDraw.Draw(mask)
ax[1] = data.boxplot()
eline = process.stderr.readline()
zip.extractall(path, get_members(zip))
status = process.wait()
bar = relationship(Bar, uselist=False)
b = np.random.randint(0, size_a, size_b)
x = [0] * 100000000
json.loads(json_str)
random.shuffle(my_list)
indices[val].append(i)
df = pd.DataFrame(existing_data, columns=cols)
count
map(lambda t: t.start(), threads)
c = nprect(a, np.deg2rad(b))
res = cv2.bitwise_and(res, mask)
m.group()
dist1 = (x[0:-2] - x[1:-1]) ** 2 + (y[0:-2] - y[1:-1]) ** 2
f.close()
print(html)
self.window.show()
TP, FP, FN, TN
html = urllib.request.urlopen(req).read()
random.seed()
x.sort()
d = datetime.datetime.now()
vc.release()
np.set_printoptions(threshold=np.inf)
test_func(*args, **kwargs)
print(np.nanargmax(a))
app = wx.PySimpleApp()
str(jinja2.escape(a))
df1 = func(df)
seen.add(x)
imgray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
_foobar.argtypes = [ctypes.c_int, ctypes.c_int, _doublepp, _doublepp]
pd.concat(los, axis=1)
self.queue.get(block=True)
self.fig = plt.figure()
fn(*args, **kwargs)
self.mysignal.connect(self.mySignalHandler)
os.__file__
plt.pie(values, labels=labels, autopct=make_autopct(values))
child.expect(pexpect.EOF)
set_of_150kwords = set(list_of_150kwords)
plt.imshow(sample_images[(i), ...])
session.commit()
plt.gcf().gca().add_artist(circle1)
plt.clf()
logging.basicConfig(level=0)
module.py
loop.run_forever()
output[line[1].strip()] = line[2].strip()
sess = tf.Session()
self.browser.get(self.live_server_url)
self.pack()
a.a = a.a
print(key, myNames[key])
do_something()
xl_file = pd.ExcelFile(file_name)
data = {}
ana(lambda x: (x, f(x)), lambda _: False)(x)
print(line)
Parallel(n_jobs=2)(delayed(foo)(i ** 2) for i in range(10))
output.seek(0)
str(tst)
name = models.CharField(max_length=255)
lines = f.readlines()
self.canvas.draw_idle()
self.assertEqual(request.responseCode, 200)
df1
d2 = {x: sorted(d1[x]) for x in list(d1.keys())}
tk.Frame.__init__(self, *args, **kwargs)
rep = dict((re.escape(k), v) for k, v in rep.items())
df.mask(criteria).fillna(ser)
print(pattern.search(input, start).span())
curdir = os.path.dirname(__file__)
main()
raise GracefulExit()
imdata = iter(imdata)
soup = BeautifulSoup(html)
C.u4_sort(begin, arr.size)
job = Job.objects.filter(client_id=pk)
ax.bar(list(range(5)), rand(5), color=my_cmap(my_norm(my_data)))
result = json.loads(s)
f.writelines(data)
content = fd.getvalue()
self._callback(self._value)
(listScore == [2, 0]).all(1).sum()
value += sum([int(i) for i in str(value)])
ny.append(y[-1])
_nonbmp.sub(_surrogatepair, text)
print(temp_re.findall(data))
rdd2 = sc.parallelize(range(5))
self.txt.see(END)
yaml_parse.py
response = urllib.request.urlopen(request)
field = models.CharField(max_length=255)
entity.before_put()
start_response(status, headers, exc_info)
np.hstack([a[:k] for k in x])
print(calendar.isleap(1900))
sys.executable
print(k, v)
tuples = tuple(set(d.items()) for d in dicts)
print(tuple(a))
wb = Workbook()
deletemylist[:17]
linprog(c, A_ub, b_ub, A_eq, b_eq, options=dict(bland=True))
ax.scatter(xData, yData)
new_array = np.array(means).reshape(new_shape)
assert_frame_equal(csvdata, csvdata_old)
Parent.__init__(self, list(args))
f = open(filename)
print(m.group(2))
d[key] = d.get(key, []) + [value]
sock = urllib.request.urlopen(url)
pool.close()
self.sock.connect((host, port))
blocks[-1].append(line)
counts = collections.Counter(patterns)
dt = datetime.datetime.fromtimestamp(nanos / 1000000000.0)
sum_max(L[1:], accum, max(max_value, accum))
ax = fig.add_subplot(111)
print(__file__)
session = create_session(bind=e, autocommit=False, autoflush=True)
True
len(_)
str(self.mylist)
OTHER_THING = True
big_stokes = np.vstack(stokes_list)
print(len(inspect.getargspec(sum)[0]))
run_benchmark()
p.sort()
ax1.plot(x, y)
s.listen(1)
myapp.models
f(*args, **kwargs)
np.square(df)
y_rev[x.argsort()] = np.arange(x.size)[::-1]
x, y, z
console.setLevel(logging.ERROR)
sys.path.insert(0, dirname)
{k.name: v for k, v in list(g.items())}
urllib.request.urlopen(req)
may_b = numpy.array([False, True, True, False])
app = Flask(__name__)
m.span()
Z = append([[(1) for _ in range(0, len(Z))]], Z.T, 0).T
print(tf.__version__)
np.dot(a, b)[[0, 0, 1999, 1999], [0, 4999, 0, 4999]]
matrix = []
linecache.checkcache(filename)
key = ndb.Key(urlsafe=string_key)
cmyk = gcr(im, 0)
xml.display()
print(filename)
message[i] = (digest[i] ^ message[i - 1]) * 129 % 256
a.upper() == b.upper()
os.dup2(si.fileno(), sys.stdin.fileno())
foobar.foo()
self.view_items.sort(key=key_func)
Y.append(y)
mydata = yaml.load(stream)
x, y = np.meshgrid(np.arange(10), np.arange(10))
scipy.argmin([scipy.inner(q - x, q - x) for x in X])
[(2, 4), (4, 5)]
m.scatter(data.Lon, data.Lat, c=data.Z, s=100, vmin=zi.min(), vmax=zi.max())
self.foo.fset(5)
yip()
allocate(temp(dsize))
admin.site.unregister(Site)
a + b
plt.imshow(img)
process_directory(dirName=os.path.join(dirName, f))
df_cov = corr.multiply(df_std.multiply(df_std.T.values))
d.weekday() == 4 and 14 < d.day < 22
scp = SCPClient(ssh.get_transport())
list_a = [(1, 2), (1, 2), (1, 2)]
plt.show()
job.delete()
app = QtGui.QApplication(sys.argv)
list(chain(*[sorted(g) for k, g in groupby(sorted(lis, key=len), key=len)]))
reverseCom([4, 5, 6], 1)
os.dup2(devnull, 1)
df = df.reset_index(level=0, drop=True)
self.assertTrue(result)
idx = b.reshape(a.shape[0])
id(b[0])
gransons.append(grandson)
ax.set_ylim(0, 1)
architecture / techstack
deployment / installation
deployment / licensing
check_for_duplicates(sys.argv[1:])
data = {h: v for h, v in zip(str(range(number_of_columns)), zip(*values))}
sidx = arr.argsort()
test_debug_json()
datetime.datetime.now(pytz.utc).isoformat()
opcode, dest, src
ax.boxplot(df[column], positions=[position])
print_time_range(train_likes_df.time.dt.time)
os.chdir(command[raw_input][0])
Decimal(1)._isinteger()
lint.py - -generate - rcfile > standard.rc
conn.close()
fig = plt.figure()
print(f.bar.__name__)
app = Flask(__name__)
Thread.__init__(self)
[list(g) for _, g in groupby(numbers, grouper)]
delay = (run_at - now).total_seconds()
0
outf.seek(0)
pool = Pool(4)
driver = webdriver.Chrome()
table_data = h5read(file_input, table_name)
self.opn[op](op1, op2)
logging.getLogger(name)
clf.fit(train_features, train_labels)
df
dict(map(reversed, t))
(self.arr == other.arr).all()
self.f_(obj)
input_img = Image.open(input_image)
ax.yaxis.label.set_rotation(0)
a = np.sort(arr, axis=1)
output = (lambda x: x + x)(data[2])
capture = cv.CaptureFromCAM(0)
Cl.__init__.__defaults__
list(d.items())
movements = set()
print(is_shifted_copy([1, 2, 1], [2, 1, 1]))
keys_b = set(dict_b.keys())
fum.bar
chr(int(x[2:-1]))
module_name = os.path.splitext(os.path.basename(__file__))[0]
lgnd.legendHandles[0]._legmarker.set_markersize(6)
fd.seek(0)
geturl()
db = SQLAlchemy(app)
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
print(r.content)
weatherData = json.loads(jsonFile)
using_mapper_options(save_on_init=False)
fig = plt.figure()
busiest_start = max(rsum, key=lambda x: x[1])
deletesomelist[i]
show()
pprint.pprint(root)
print(a[(1), :].toarray())
Example.foo(self)
xmlrunner.XMLTestRunner().run(suite)
parser.add_argument(*args, **kwargs)
print(sys.version_info)
x.astype(int)
db_data = json.loads(db_col_data)
layout.addWidget(self.tab)
tree = ElementTree()
bid = int(bid)
plt.show()
pdf = distr.pdf(abscissas, *param)
sum([48 * 0.1, 1 * 0.2, 0 * 0.5, 0 * 1, 0 * 2, 0 * 5])
plt.plot(x, y)
patches[i].set_facecolor(jet(i))
ax = fig.add_subplot(111)
print(df.columns.str[0].unique())
plt.show()
print(my_array)
names.remove(name)
c = boto.connect_ec2(ec2_key, ec2_secret)
doc = lxml.html.fromstring(s)
image = image.resize((250, 250), Image.ANTIALIAS)
x[:] = np.ones((2, 2))
print((e, L[i - 1], L[(i + 1) % len(L)]))
self.f.flush()
data = [int(p) for p in image.read().split()]
items = [parse_item(line.strip()) for line in infile]
gems.sprites()
zip(*lis)
screen.fill(BGCOL)
self.value = value
mail.get_payload()
print(x)
self.__name__
self.layout().removeWidget(self.child)
main()
int(log(n, 256)) + 1
thing.put()
XmaxY = coo_matrix((XmaxY, zip(*keys)))
list(range(item.start, item.stop, item.step))
__version__ = 1.0
set(myList)
list(find(l))
processor.terminate()
test.py
app.MainLoop()
text = file.read().lower()
type(test.make_fptr())
server.join()
G.add_edge(x[0], x[1], weight=x[2])
remainder.append(group[0])
x_val = [x[0] for x in data]
driver = webdriver.Firefox()
plt.xlim([-4, 4])
other_variable = int(variable.get())
self.response.write(pic.read())
d = collections.Counter(dict(your_list))
s.feed(html)
lines = f.readlines()
fh.stream.name
b = np.ones(5)
p.start()
plt.subplot(122)
pd.read_csv(io.StringIO(df.to_csv()), index_col=0)
ranked = sorted(timings, key=lambda t: t[1])
writer = csv.writer(f)
print(current_credentials.secret_key)
df[~mask]
epoch = int(time.mktime(time.strptime(date_time, pattern)))
x = np.array([1, 2, 1, 0, 1, 2, 1, 0])
datetime.date(*datetuple)
plt.show()
f.close()
h = np.array(hamiltonian)
t.render(c)
docs.append(yaml.load(raw_doc))
self.after(100, self.read_bytes)
d = np.diagonal(np.tensordot(a, b, axes=()), axis1=0, axis2=2)
ds.addSample(myList[ind - n:ind], myList[ind + 1])
fig, ax = plt.subplots()
s.close()
locals()[choice]()
parser = argparse.ArgumentParser()
theta = 2 * np.pi * np.random.random_sample(n)
allkitties = kitties.get_data()
x.subs([(x, y), (y, z)])
toast()
opener.open(login_url)
list(d.items())
data1.shape, masks1.shape
ax = fig.add_subplot(111)
ax = fig.add_subplot(gs[1])
sum(calc_matrix(l1, l2) for l1, l2 in zip(x1, x2))
cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
pprint(data_copy)
pl.show()
self.__block.wait()
print(self.__hidden)
sys.exit(update(opts))
pygame.mixer.music.load(file)
result = np.apply_along_axis(mahalanobis_sqdist, 1, d1, mean1, Sig1)
Rect(l, t, w, h)
c = random.randint(10, 25)
print(list(csv_reader))
list(intersection.elements())
plt.setp(ax2.get_yticklabels(), visible=False)
client.connect(host, port, username)
diff(n[i], n[j])
app = QtGui.QApplication(sys.argv)
platform.platform()
[1, 2, 10]
[0, 8, 0, 0, 0, 8, 0, 0, 0, 8, 0, 0, 0],
new_list
child.tag, child.attrib
dt = datetime.datetime.now()
deletedata[key]
out = np.split(df1.index[c], np.flatnonzero(r[1:] > r[:-1]) + 1)
pygame.time.Clock().tick(10)
session.add(a)
pd.DataFrame(MM, dtype=int, columns=Col)
intersec = [item for item in a if item in b]
mydict = dict((k[1], v) for k, v in list(mydict.items()))
fig = plt.figure()
int(mktime(dt.timetuple()))
fig, axes = plt.subplots(ncols=2, sharey=True, sharex=True)
bar.baz()
child.grid_configure(padx=5, pady=5)
listen.stop()
plt.subplot(212)
frame.pack(padx=10, pady=10)
w = wfloat.mean(2)
f.__code__.co_names
sys.exit(app.exec_())
b = np.matrix([[2, 2], [2, 2]])
genre = models.CharField(max_length=100)
list(zip(keys, values))
owner = models.ForeignKey(User)
image_list.append(im)
input_list = string_input.split()
a[:-1, :-1]
panel.configure(image=img2)
line.rstrip()
self.transaction.append((name, self.database.get(name)))
df2 = df1.copy()
np.dot(np.arange(len(x)), np.power(x, 10)) / np.sum(np.power(x, 10))
paranoid[:]
where = tf.not_equal(A, zero)
title_label = gtk.Label()
print(opts.some_option.decode(sys.stdin.encoding))
vbar.config(command=canvas.yview)
tk.Tk.__init__(self)
data = f.read(4)
data = conn.recv(1024)
a.T
df = df.reset_index()
window.show()
res.append(0)
self.ui.dragDataEdit.close()
logger.addHandler(hdlr)
print(k, v)
session.execute(u)
rle(np.array([5, 4, 4, 4, 4, 0, 0]))
psutil.net_connections()
print(i)
aList = [random.randint(1, 11) for i in range(100)]
myclass = MyClass()
__path__ = extend_path(__path__, __name__)
C = A[:, ([1, 2])]
form.save()
pool = multiprocessing.Pool(2)
l.__code__.co_argcount
conn.select()
my_randoms.append(random.randrange(1, 101, 1))
array = np.zeros((8, 8))
UserSerializer
df.apply(using_mstats, axis=0)
suite = unittest.TestSuite()
TrueXor(1, 0, 0)
app = Flask(__name__)
buttons[-1].pack()
print(f.getvalue())
plt.show()
Category.append(row[1])
dill.detect.badobjects(f, depth=1)
foo.method1()
soup = BeautifulSoup(html)
tree = lxml.html.fromstring(html)
asample = random.sample(bigset, Samplesize)
t.start()
self.clients.append(client)
parent = Parent()
getattr(obj, name)
----APP2
----APPX
foo()
df2 = df.ix[:, 12:24]
x.extend([4, 5])
lst.sort(key=operator.itemgetter(1))
getFromDict(dataDict, mapList[:-1])[mapList[-1]] = value
plt.close(fig)
x * x
SecondBase.__init__(self, *args, **kargs)
print(time.ctime())
b = np.array([2, 4, 6])
[list(i) for i in set(map(tuple, a))]
mat2.append(temp)
filtered_numbers = [n for n in numbers if predicate(n)]
x = object()
l[start:end:step]
myList = [0.0, 0.0, 0.0, 2.0, 2.0]
q = Queue.Queue()
self.setInitialBreakpoints()
X.__rmul__(2)
list(_f(s, n))
plt.plot(x[(i), :], y[(i), :])
tuple.__new__(cls, (x, y))
date = dateutil.parser.parse(date)
choice([4, 5, 6])
uncompressed_data = zippy.read()
evaled_value = ast.literal_eval(value)
self.created_at = datetime.now()
expected.difference(found)
df = pd.read_csv(StringIO(txt), index_col=0)
msg = email.message_from_string(msg_string)
print(list(dd.items()))
rgb_values += [(r, g, b)]
ax.scatter(x, y, marker=m, c=c, s=SIZE, vmin=VMIN, vmax=VMAX)
dataframe.to_excel(writer, sheet_name=sheet, startrow=0, startcol=0)
children[child] += np.ones(len(children[child]))
hist(b.ravel(), bins=255)
list(enumerate(s))
output = [(a[i] + a[i + 1]) for i in range(len(a)) if i < len(a) - 1]
clf.fit(X_train[:, :-num_feats_to_remove], y_train)
f = imageFile.read()
time.sleep(0.1)
result = cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)
sprite.set_position(sprite.body.position.x, sprite.body.position.y)
render_template_string(name_template, name=name)
x, y = starmap(operator.isub, zip((x, y), (1, 2)))
fig = plt.figure()
print(status.author, status.user)
df.index.isin(df.index[df.index.slice_indexer(start_remove, end_remove)])
foo(iterable, isiterable=False)
x = f(x)
document = lxml.html.document_fromstring(html_string)
print(r.content)
content = render_to_string(template_name, dictionary, context_instance)
transport.close()
print([n.ID() for n in node.fullPath()])
server_socket.close()
-2 * x ** 2 + 4 * x
llist = line.split()
df[col] = pd.get_dummies(df[col])
tuple(recursive_map(complex_list, lambda x: x.__class__.__name__))
self.names.add(node.id)
self.setFileMode(self.ExistingFiles)
cursor.execute(sql)
driver = selenium.webdriver.Firefox()
ax.cla()
cursor.close()
ax2 = fig.add_subplot(2, 1, 2)
job.join()
self.items[-1:][0]
hash = hashlib.sha1()
db.myCollection.insert(records)
self.__getitem__(slice(i, j))
print(string)
listbox = tk.Listbox(master, selectmode=tk.SINGLE)
new_points.append((x, y, z))
effectslist.append(mod)
plt.grid()
writer = csv.writer(self.response.out)
HttpResponseServerError()
d = datetime.date(1970, 1, 1)
sys.getsizeof(0)
DNS.DiscoverNameServers()
ipl_t = np.linspace(0.0, len(points) - 1, 100)
df
not Counter([1, 2, 2]) - Counter([1, 2])
f.write(line)
A.dtype
test.close()
ax2.set_ylim((0, 2.7))
(datetime.strptime(x[0], fmt) - d).total_seconds() > 0
yertle.hideturtle()
log_file.write(fmt_str % tup)
next(blah)
0
plt.fill_between(x, y_old, y_new, color=color)
theA.methB(params)
print(md.myfx(arg2))
self.Bind(wx.EVT_KEY_DOWN, self.KeyDown)
p = psutil.Process(os.getpid())
datetime(*timetup[:6]).isoformat()
pylab.show()
df.iloc[np.roll(np.arange(df.shape[0]), shift)]
copyStruct(inputList, iter(flattenedResults))
root = etree.fromstring(xml_str)
pairs = zip(it, it, nons)
{{another}}
pform2.as_table()
writer = csv.DictWriter(outfile, fieldnames=fieldnames)
numpy.interp(quantiles, weighted_quantiles, values)
min(timeit.repeat(lambda : {keys[i]: values[i] for i in range(len(keys))}))
invoker(test)
results.append((i, j, ret, vol))
getpwuid(stat(filename).st_uid).pw_name
G.add_edge(x[0], x[1], weight=x[2])
app = QtGui.QApplication(sys.argv)
f.write(data)
b = np.array([1, 0, 2, 1])
print(line)
p = multiprocessing.Pool()
lol[i] = [sublist[j] for j in indices]
sum(lists, [])
time.sleep(1)
cb = lambda : self.resp(items, iteration)
print(name[i:] + name[:i])
divtdi(td1, td2)
t.test()
plt.plot(x, [(offset + math.sin(float(i) / 10)) for i in range(len(x))])
pool.close()
maybemodel = model.fit(maybeinliers)
mark_safe(json.dumps(list(object)))
sys.stderr = self.sys_stderr
response
()
data
df1.join(df2)
con.close()
dct[id(lst)] = lst
print(is_all_true(a, b, c))
gona[:, (1)]
module_dict = my_module.__dict__
comp.remove(x)
print(timeit.timeit(lambda : [s.strip() for s in rsplit(TEST)]))
fig, axes = plt.subplots(nrows=2, ncols=2)
main()
time.sleep(0.1)
file_info_instance = file_info_class(f)
id = Column(Integer, primary_key=True)
list_of_ids = list(itertools.chain.from_iterable(cursor))
conn, addr = s.accept()
self.conn.close()
C = p1[0] * p2[1] - p2[0] * p1[1]
X.tocsr().nonzero()
payload = json.loads(message, object_hook=as_payload)
self.variance = tf.Variable(tf.constant(1.0, shape=[depth]), trainable=False)
raise ValidationError()
nosetests
key_name
print(repr(c))
dS = np.random.normal(size=N)
coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))
value = float(value)
gradient.setColorAt(1, QColor(255, 255, 255, 0))
dt.astimezone(pytz.utc).time(), dt.utcoffset().total_seconds()
name = db.StringProperty()
next(gen)
ax.loglog()
a[k] = b[k]
out.reshape(6 * N, 6 * N)
yest
dtime = datetime.datetime.now()
result = []
lst[i] = func(item)
initializer(*args)
walk(tree.getChild(0), ast)
db.session.add_all(list(my_new_posts.values()))
funcs.append(functools.partial(f, i))
b = np.array(b)
words = nltk.Text(coded)
result = pool.apply_async(f)
list1.append(int(digit))
np.allclose(out_ein, out_dot)
NUMBER_OF_EXCEPTIONS = 0
myList.append(2)
d = datetime.datetime.fromtimestamp(ts)
app = Flask(__name__)
l = [[0]] * 4
outfile.write(line)
result = pd.concat([a, b])
self.button.setMinimumSize(QtCore.QSize(128, 128))
self.parser.parseString(s)
grid.addWidget(button, row, col)
a2 = np.arange(10).reshape(2, 5)
my_new_list = [(x + string) for x in my_list]
np.s_[:, :2, :, :540]
ftp.login()
results.append((letter, 1))
x = np.linalg.solve(a, b)
OrderedDict.__init__(self, *args)
self.data = data
seconds = duration.total_seconds()
print(f(1))
x0 = random.choice(range(0, L))
line.split()
{arg: multi(*args[1:]) for arg in args[0]}
mf.grid(column=0, row=0, sticky=(N, W, E, S))
item.setTextAlignment(QtCore.Qt.AlignCenter)
adapt(proxy._get_current_object())
x = np.linspace(0, 1, 100)
loop.run_until_complete(do_request())
sequence1 = [1, 4, 8]
p.interact()
cur = connection.cursor(dictionary=True)
print(df.apply(lambda x: sorted(x, key=lambda y: y == 0), axis=1))
d[c] += 1
ax = fig.add_subplot(111)
raise StopIteration()
n.increment()
pathlib.Path(*p.parts[2:])
seen.add(x)
print(response.content, response.status_code)
reader = csv.reader(f)
layout.addWidget(button)
f, ax = plt.subplots(2, 1, figsize=(12, 6))
sess.run(init)
plt.scatter(x[mask], y[mask], marker=um)
today = datetime.date.today()
signal.alarm(0)
self.view_items.sort(key=attrgetter(*fields))
dfnew.join(dfnew.apply(func, axis=1)).dropna()
render_to_response(template_name, c)
id(sys.modules[foo.__module__]) == id(sys.modules[foobar.foo.__module__])
self._setter(obj, value)
self.sa_grid.removeWidget(widget)
array[idx]
type.__new__(mcls, cls, bases, d)
glfw.Init()
p.start()
print(IPython.sys_info())
r = [a, b, c]
print(moneyx)
print((val, k))
import_submodules(__name__)
ax.yaxis.set_major_formatter(mtick.FuncFormatter(ticks))
app.exec_()
token = models.CharField(max_length=100, blank=True)
im_width = im.size[0]
path.reverse()
[(key, OrderedDict.__getitem__(self, key)) for key in self]
np.array(l, dtype=pd.Series)
dx, dy = statemap[dx, dy]
repr(soup)
result = wx.BitmapFromImage(image)
self.setCentralWidget(self.centralwidget)
myset = set(mylist)
angle = np.linspace(0, 6 * np.pi, 1000)
req = urllib.request.Request(url, data)
key = bucket.get_key(key_name)
x.append(a.pop(0))
greenlets = [gevent.spawn(crawl, each) for each in range(100)]
print(o.hostname)
data_frame.iloc[:100]
jsonify(username=g.user.username, email=g.user.email, id=g.user.id)
self.__class__(*args, **kwargs)
a = np.array([[1, 5, np.nan, 6], [10, 6, 6, np.nan]]).transpose()
dd_process.stdout.close()
cursor = conn.cursor()
connection.connection.ping()
fig.canvas.draw()
parser.feed(res.read())
foo()
lut.append(n / step)
sanitised_path
instance = Example()
threading.Thread.__init__(self)
add_element_to_database(record)
ax.set_xticks(ax.get_xticks()[1:])
scopes.add(s.strip())
ax.scatter(x, y, z, c=scalarMap.to_rgba(cs))
fig, ax = plt.subplots()
x = 0
G = matrix([[2.0, 1.0, -1.0, 0.0], [1.0, 2.0, 0.0, -1.0]])
QtCore.QCoreApplication.exit()
output = PdfFileWriter()
object_class = models.CharField(max_length=20)
y * (y.groupby((y != y.shift()).cumsum()).cumcount() + 1)
print(hex(id(x)))
time.sleep(2)
conn = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
self.buttonPanel1 = wx.Panel(self)
last_modified = db.DateTimeProperty(required=True, auto_now=True)
deletetest[5]
module_name
canvas.grid(row=1, column=0, columnspan=100)
index = np.unravel_index(arr.argmin(), arr.shape)
timeout.start()
plt.colorbar(img, cmap=cmap, norm=norm, boundaries=bounds, ticks=[0, 5, 10])
process.wait()
page = urllib.request.urlopen(url)
[sum(values) for values in zip(a, b, c)]
matcher(l1[1:], l2[1:])
x.reshape(r * b1, c * b2)
o5.magic
log.startLogging(sys.stdout)
axes[1, 0].hist2d(x, y, bins=nbins)
my_stdout_file.write(line)
initlibwrap()
pylab.subplot(122)
stderr_thread.start()
list1[1::2] = [(x + 1) for x in list1[1::2]]
x_new = x[bool_arr]
plt.autoscale(False)
np.random.seed(0)
x, y = zip(*data)
decompressed = gzip.GzipFile(StringIO(compressed)).read()
next(nextword)
self.dictset.update(iterable)
print(line)
my_list = [1, 2]
first_line = next(csv_reader)
unittest.TestCase.__init__(self, *args, **kwargs)
os._exit(0)
killasgroup = true
root = tk.Tk()
id = db.Column(db.Integer, primary_key=True)
[apply(op, *items) for items in zip(*iters)]
cudnn = 1.0
[a, int(b), int(c)]
dist_ = np.array([0, 1, 0, 1, 1, 0, 0, 1, 1, 0])
FancyArrowPatch.__init__(self, (0, 0), (0, 0), *args, **kwargs)
Chainable(list(self.method(args[0], self.data, **kwargs)))
(a == b).sum()
result = process.wait()
pygame.mixer.init()
opener = urllib.request.build_opener()
plt.show()
[True, True]
c = b[1:]
self.mainLayout.addWidget(self.scroll)
plt.plot(sub_data)
src_dt = dt.replace(tzinfo=src_tz)
a[:, (0), (0)] = b[:, (0), (0)]
job.join()
a = np.append(a, x)
now = datetime.datetime.now()
screen = Xlib.display.Display().screen()
c = conn.cursor()
a = 1
newList.append(temp)
browser = webdriver.Firefox()
session.starttls()
e = Egg()
self.x + other
axHistx.hist(x_vals[i], bins=bins, histtype=histtype, color=colors[i])
y = y.A.squeeze()
df.loc[2] = a
fp.close()
f.close()
query = query.filter(condition)
im = Image.open(infile)
contents = fp.read()
singular
ax2.set_xlim([x[1], x[2]])
y0s = imsize * np.random.random(ng)
lgnd.legendHandles[1]._legmarker.set_markersize(6)
current_credentials = credentials.get_frozen_credentials()
foo.write(os.path.join(root, f))
df = pd.read_csv(fn)
unittest.TestLoader.sortTestMethodsUsing = lambda _, x, y: cmp(y, x)
self.num_terms = 1 + max([-1] + list(self.id2word.keys()))
parts = line.split()
ax.set_xlim(-100, 100)
form = ContactForm()
[j[i] for k, g in groups for i, j in enumerate(g)]
dict_col = df.pop(1)
plt.show()
data = json.load(f)
copy + copy_to_depth(item, depth - 1)
pygame.mixer.init()
node_id = Column(Integer, primary_key=True)
print(t.timeit())
dict(results)
parser = argparse.ArgumentParser()
np.array([0, 0]).any()
task = task._get_current_object()
df
count[key] = len(values)
ax = fig.add_subplot(gs[0])
print(datetime.datetime.now(tz))
p = multiprocessing.Process(target=parallel)
-your_code.py
isinstance(x, numbers.Integral)
NULL
db.session.commit()
pprint(lod, width=40)
titled.append(word) if word.istitle() else lower.append(word)
wb.Save()
print(to_s(dt.astimezone(pytz.utc)))
x = np.random.randn(100)
main()
x = np.zeros((n, n))
locals().update(obj.__dict__)
new_text.append(text[i])
a.clip(max=2)
plot(draw, img, xpxl2, ypxl2, rfpart(yend) * xgap, col, steep, dash_interval)
RES = SPMAT.dot(G)
peers.append(dict())
self.clients.add(client)
print(inspect.currentframe().f_code.co_name)
window.show_all()
G = nx.Graph()
x = etree.parse(f)
l.append(1)
given_q = db.session.query(Thank).filter_by(giver_id=user_id)
b.pack()
(d < 0).sum()
extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]
wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)
connection.send_command(*args)
result.update({j: result[j] + [i]})
print(args)
itertools.product(range(self.numrows), range(self.numcols))
map(ingredients.delete, ingredients.get_children())
tailq.put(line)
fig, axes = plt.subplots(ncols=2, nrows=2, sharex=True, sharey=True)
b = [[0, 0, 0], [0, 0, 0], [0, 0, 0]]
p = random.randint(0, j)
sum(max(die().roll_until(6) for i in range(5)) for i in range(n)) / float(n)
df.addCallback(results, name=name)
list(range(f, L + 1))
tokenize.untokenize(res)
json.dumps(value)
list1 + list2
zerolistmaker(4)
time.sleep(2)
counts, bins = np.histogram(X, bins=50, density=True)
df.reindex(index, fill_value=0)
self.transport.write(towrite)
result = [{k: v} for v in vs]
tornado.ioloop.IOLoop.instance().start()
line = line.split()
self.text.pack(expand=YES, fill=BOTH)
df[ws] = pd.read_excel(excelFile, sheetname=ws, parse_cols=c)
my_list.append(json.loads(line))
os.mkdir(dirname)
data = b.getvalue()
db.run_in_transaction(_tx)
main.py
gaz_instance = foo.gaz()
print(r.text)
print(len(points))
axes[-1, -1].set_xlim(xlimits)
my_nullable_string = models.CharField(max_length=15, null=True, blank=True)
iter(self.books.values())
d = {}
self.panel.Bind(wx.EVT_MOTION, self.OnMouseMove)
getattr(self.ham, name)
today = date.today()
loop.run_until_complete(main())
User.drop_collection()
a = np.arange(10)
msg = conn.recv()
modes = list(takewhile(lambda x_f: x_f[1] == mostfreq[0][1], mostfreq))
dict((k, dikt[k]) for k in keys.split())
df
gca().set_axis_off()
{{field.label_tag}}
df.head()
any(map(s.__contains__, substring_list))
painter.drawLine(x1, y1, x2, y2)
results = []
draw()
P = np.zeros((N, N), dtype=int)
user = Channel
fp.close()
html = html.format(**d)
print(gmpy2.sqrt(2))
print(sp.stdout.read())
sys.exit(app.exec_())
PROJECT_ROOT = abspath(os.path.dirname(__file__))
df = pd.DataFrame(d)
print(np.all(a0 == a1))
a_button.pack()
source.gruntfile.coffee
source.gulpfile.coffee
html = requests.get(url).text
self._concordance_index.print_concordance(word, width, lines)
mousemove(int(currentpos.x), int(currentpos.y))
list_dictionaries = [random_dict() for x in range(100)]
self.c.add_section(SERV_SECTION)
dict_writer = csv.DictWriter(f, fieldnames=fieldnames)
cv2.drawContours(cimg, contours, i, color=255, thickness=-1)
options = parser.parse_args(arguments)
inputs = list(it.product([0, 1, 2], [0, 1, 2]))
_winapi.CreateJunction(source, target)
doSomething(x, i, j)
insert(cur[list[0]], list[1:], value)
set_spyder_echo(False)
print(func.__name__)
l2.append(i)
i += 1
merged_list.sort()
True
labels = np.array([[1, 1, 1, 0, 0]]).transpose()
x, y, rho, phi = numpy.loadtxt(itertools.chain(f1, f2))
self.__pList.append(Person(name, number))
do_something()
pygame.font.init()
time.sleep(2)
Foo.square(2)
dialog.show()
s = socket(*args, **kw)
do_something(a1, a2, b)
sum(dct[k] for k in lst if k in dct)
f(x)
parent.kill()
json.dumps(ids_list)
copy
a[subset_b] += 2
channel.send(command)
print(list(kwargs.keys()))
out[:, :, na:] = b
print(df[val_cols].max())
f.close()
cmd.Cmd.__init__(self)
B.__init__(self, z)
meta = MetaData(bind=engine)
self.browser.open(url)
channel.queue_declare(queue=queue_name)
driver = webdriver.Firefox()
plt.show()
dis.dis(add_url_rule)
df2 = df2.reset_index()
df.dtypes
list(range(len(list1)))
fig, ax = plt.subplots()
[idx for idx, item in enumerate(seq) if item in seen or seen_add(item)]
do_something_else()
x += np.random.normal(loc=0, scale=0.1, size=200)
root = tree.getroot()
self.server.running = False
p.save()
print(generate_list(100))
foo = np.random.rand(20).cumsum()
print(df)
pd.to_numeric(s)
root.mainloop()
mvv_list[0]
expanded = list(chain(*zip(*tee(l, n))))
admin.site.register(Car, CarAdmin)
sa, sb, sc = map(str, (a, b, c))
handlers.append(HTTPSClientAuthHandler(somekey, somecert))
sys.exit(ret)
print(len(cycles))
ax = f.add_subplot(1, 1, 1)
take(4, iterate(lambda x: x + [len(x) + 1], [1]))
a.multiply(nmask)
stream.seek(0)
root.clear()
SettableParity = TRUE
x = test()
p.stdin.write(someInput)
csvout.writerows([row[2:4] for _ in range(count)])
prices[:-1].values / prices[1:] - 1
init_op = tf.initialize_all_variables()
do_something()
imp.reload(scriptname)
sess.run(m1)
self.thread.join()
random.shuffle(x)
q.join()
print(a.compressed())
deletex, y
pd.to_datetime(out_ar)
btn.grid(row=row_index, column=col_index, sticky=N + S + E + W)
b = [[], []]
fp.close()
vc = cv2.VideoCapture(0)
values = [max(item) for item in array]
any(el in sb for el in a)
imclip = np.min(Zexact), np.max(Zexact)
repr(self.__dict__)
eav.register(Patient)
A = np.arange(16).reshape(4, 4)
s = QtCore.QString()
painter = QtGui.QPainter(self)
instance.uuid = uuid.uuid4()
f.seek(-1, os.SEEK_CUR)
plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)
root.mainloop()
self.update({element.tag: dict(list(element.items()))})
print(cls.x)
indices[elem].append(i)
dbobject = mymodel.objects.all()
generator() is generator()
logging.basicConfig(level=logging.INFO)
print(counter[0])
collections.deque(iterator, maxlen=0)
pixels[i, j] = data[i][j]
imgplot = plt.imshow(lum_img)
adrlist = [(word if word.isdigit() else soundex(word)) for word in adr.split()]
fig, ax = plt.subplots()
model = QStandardItemModel()
tree = et.parse(datafile)
print(df[df.apply(lambda x: x.A in x.B, axis=1)])
root = Tk()
self.bar % 2 == 0
Sig1 = np.cov(d1[0:25, 0:4].T)
print(pp.pformat(my_dict))
logging.Handler.__init__(self)
vbl.addWidget(self.fc2)
np.vstack((a, b, c))
c.setCompletionMode(QtGui.QCompleter.UnfilteredPopupCompletion)
set(zip(df.number, df.letter))
request.args.getlist(key)
isinstance(result, collections.Sequence)
dst_im.paste(rot, (50, 50), rot)
keys_a = set(dict_a.keys())
print(list(compress(A, B)))
sess.run(apply_placeholder_op, feed_dict=feed_dict)
sys.argv[:] = sys.argv[1:]
self.figure.set_edgecolor((1, 1, 1))
ax.set_xticks(list(range(position + 1)))
np.log(a) + b * np.log(x) + c * np.log(y)
ax = plt.gca()
plt.axvline(x=0.5)
self.connect((server, server_port))
path = list(backwalk(predecessor_map, destination, origin))
sess = tf.Session()
n = ctypes.c_int(x.shape[1])
type(a.get_value())
str(self.id)
d = np.random.randn(1000, 1)
open_tags.insert(0, tagname)
dict[key] = value
sys.exit(1)
plt.title(v)
is_binary = False
self.member_names.append(key)
ax.set_ylim(0, 15)
d.toJSON()
list(accumulate(lis))
some_list[0] is some_list
obj.save(force_insert=True)
x[0]
some_func(something)
func()
p._set_cloexec_flags(p.stdin)
oauth_token = models.CharField(max_length=200)
existing.merge_result([task_from_json(slug, **task) for task in taskdata])
fig.subplots_adjust(hspace=1e-05)
vars(type(obj))[1]
ax.set(xticks=np.linspace(0, 10, 6), yticks=np.linspace(0, 10, 6))
y = tf_spiky(x)
fd.close()
x = x + 1
root = Tk()
x = np.random.rand(N)
denormalized_rgb_color
print(json.dumps(result, indent=4))
df.groupby((df.Grp != df.Grp.shift()).cumsum()).Nums.groups
url = models.URLField()
a = conn.cursor()
myStrList = [x for x in myList if isinstance(x, str)]
mX = np.concatenate((intercept, mX), axis=1)
list = [[]] * 2
i, j = i + 1, j + 1
g = nx.Graph()
Record.objects.filter(**my_queryset_filters)
ax.pcolor(T, R, Z)
cmd()
round_up_to_even(2.25)
print(r.shape)
t = datetime.datetime.today()
self.axes.scatter(self._x_data, self._y_data, picker=5)
p = p.add(1).cumprod()
matplotlib.pyplot.scatter(n.predict(nfeatures), targets)
path = os.path.abspath(os.path.expanduser(path))
print((x, y, element))
raise ValueError()
triples.append((i, j, k))
bool.mro()
next(itercars)
a.fly()
os.makedirs(dst)
sess = tf.InteractiveSession()
foo.start()
{0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0}
p1 * np.cos(p2 * x) + p2 * np.sin(p1 * x)
len(self.directory)
loop.run_until_complete(asyncio.gather(*tasks))
movie = models.ForeignKey(Movie, blank=True, null=True)
Page.query.filter_by(name=name).first()
n * s + 0 * s == (n + 0) * x == n * s
job.join()
length = len(string)
dictonary[k].append(i)
browser.set_handle_robots(False)
integer_timestamp = (dt - epoch) // timedelta(seconds=1)
pagehandle = urllib.request.urlopen(theurl)
sys.exit(0)
a = fig.add_subplot(2, 2, i)
im = Image.open(file_path)
print(repr(Dump(1245427)))
client.load_system_host_keys()
console.setLevel(logging.DEBUG)
str(datetime.timedelta(hours=10.56))
mpu.complete_upload()
a[1, 1] = np.nan
print(a, b, c)
melt_first_half = pd.DataFrame(first_reps.values, columns=col_names)
seen.add(item)
patches.append(mpatches.Wedge(center, we.r, we.theta1, we.theta2))
cur = conn.cursor()
A()
bool([])
cp.close()
response(environ, start_response)
fcntl.fcntl(fd, fcntl.F_SETFL, flags | os.O_NONBLOCK)
plt.step(Xs, n)
root = Tk()
soup = BeautifulSoup(html)
main()
os.rename(self.dest, self.src)
a[i] = 5
values.append(elem.text)
arr_y = arr[(np.newaxis), (np.newaxis), :, :, :]
print(f)
metadata = Base.metadata
self.close()
sftp.get(file, os.path.join(localPath, file))
print(list(divisorGenerator(100)))
hist, bins = np.histogram(data, bins=50)
i[b], i[a] = i[a], i[b]
arr = np.random.random_integers(5, size=(N_rows, 12))
print(list(group))
inspect.getsource(_)
di[key].append(value)
print(lst[-1])
model_name = self.base_field.model_name
lst.append([1])
getattr(self._decoratee, name)
binary_f(lambda v: works(v) != val0, list)
beaker.session.key = appname
divider1 = make_axes_locatable(ax1)
self.ui.setupUi(self)
result = np.abs(diff)
A = np.arange(5 * 7).reshape((5, 7))
count += 1
print(repr(cell))
glFlush()
cls.initialized = True
NotImplemented
s = cStringIO.StringIO()
print(q.get())
append(Button(i))
thread.start()
frame.show()
str(d)
assert isinstance(value, list) or isinstance(value, tuple)
fig = plt.figure()
main()
index.append([keyword, [url]])
text.split()
t[v] = t[2 * v] + t[2 * v + 1]
survival_table = pd.Series(index=multi_index)
self.current += 1
edge_list.update([(x, a), (a, b), (b, x)])
grammar.load()
contents = f.readlines()
new_im = f(new_x, new_y)
(b.x - a.x) * (c.y - a.y) == (c.x - a.x) * (b.y - a.y)
r.render()
np.sum(~a)
x.subs(ordereddict.OrderedDict([(y, z), (x, y)]))
addr = ctypes.addressof(a)
exit()
user.save()
content_type = models.ForeignKey(ContentType, null=True)
result = []
fig1.show()
a = random.randint(1, b - 1)
self.members[i] = NULL
[198.40560401][198.4049081][198.4056042]
[7917.75662561][7917.75682048][7917.75662578]
[6056.87496151][6056.87452659][6056.87496175]
sum(my_sparse_matrices[1:], my_sparse_matrices[0]).todense()
round(float(self) / other)
int(value), True
Variance(X).doit()
postdata = request.body.read()
socket.inet_aton(addr)
os.rename(self.src, self.dest)
time.sleep(num)
b = random.randint(5, 20)
np.random.seed(42)
self.config(menu=menubar)
my_cmap = ListedColormap(flatui)
myclass = MyClass()
plt.bar(his[1][1:], his[0], width=1)
m.drawcounties()
np.minimum(a, 255, a)
values[quality < threshold] = value
print(i)
pylab.plot(y)
ax.set_yticks(np.arange(0, 6, 1))
c[tuple(x)] += 1
out = np.empty((A.shape[1], b.shape[1]))
fig = plt.figure()
myprocess.wait()
p1 = ctypes.c_int(1)
float(m.group(0)), pos + m.end()
files = os.listdir(path)
print(response.read())
d = np.empty(a.shape[0])
arr.append([])
a[0:5:-1]
l.add(2)
queue.put(ii)
socket.inet_pton(socket.AF_INET, domain)
t.start()
c = MyClass()
ser[len(ser)] = ser.iloc[-1]
db.put(counter)
im = Image.open(infile)
self._s.setblocking(0)
doc.Close()
df = pd.DataFrame(np.random.random((5, 5)))
plt.show()
d = datetime.date(2015, 1, 5)
sorted_list = sorted(list(myDic.items()), key=lambda x: x[0])
print(data.getvalue())
answerlist = []
label.show()
jpeg.read(2)
FinalList.append(set(x))
set(rhymes)
ax.yaxis.set_label_coords(*axcoords)
ax = fig.add_subplot(111)
[item[0] for item in list(d1.items()) if item[1] == 55][0]
dString = json.dumps(d)
setup.py
print(cutit(name, 2))
self.assertEqual(v1, v2, msg)
x = np.array([1, 1, 1, 2, 2, 2, 5, 25, 1, 1])
parser = argparse.ArgumentParser()
A.__class__ = np.ndarray
formatted_json = json.dumps(obj, sort_keys=True, indent=4)
__import__, (module.__name__,)
User.__table__.create(migrate_engine)
filtered = [strip_punctuation(word) for word in input]
time.sleep(0.1)
d = list(data)
B = [4, 5, 6]
hxs = HtmlXPathSelector(response)
print(my_func0(1, 2))
x = 4
w.show()
frame.pack()
a = np.random.rand(l, n, m)
x = (list(v) for k, v in groupby(data, lambda x: x < 0))
reactor.stop()
plt.ylim(-2.5, 6)
now = datetime.now()
lis.append(lambda : 2)
element = WebDriverWait(driver, secs).until(find)
(mydict[key] for key in mydict)
objects = [object_map[id] for id in ids]
print(dns.__repr__(), dns.qd[0].name)
conn.send(data)
print(sub_tree.childNodes)
df = pd.concat(chunks)
serversocket.bind((socket.gethostname(), 7557))
list_of_tuples = [(1, 2), (4, 5)]
[c for c in s2]
video1 = cv.CaptureFromCAM(0)
counter[word] += 1
curses.endwin()
ls[0] + listSum(ls[1:])
img.load()
out.reshape(cols, rows).T
oftype[item.__class__].append(item)
venus_thread.start()
earth_thread.start()
mars_thread.start()
excel.Application.Quit()
decor
_quicksort(array, pivot + 1, end)
initialize_db.py
any((a + b == c, a + c == b, b + c == a))
currT = glfw.GetTime()
admin.site.unregister(User)
a = datetime.datetime.now()
df.dtypes
ip = self.request.remote_addr
vertices, np.hstack((bary, 1 - bary.sum(axis=1, keepdims=True)))
mylist = list(range(10000))
new_user.save()
f.close()
fig = plt.figure()
comments.extract()
image.save(output)
signal.signal(signum, receive_signal)
tf.Variable(initial)
f.close()
out.write(prg)
_base.py
app = Flask(__name__)
myqserver = Qserver()
x.append(5)
X, Y
printArray(data, m, n)
a.append([])
new_body_text = re.sub(pattern, make_footnote_counter(), text)
self.setPlainText(text)
C.run()
api = tweepy.API(auth)
cv2.waitKey()
session.add(question)
func(*args, **kwargs)
plt.gcf().add_subplot(421)
np.concatenate(([88], a, [77]))
len([k for k, _ in groupby(a) if k == 1])
suite = unittest.TestSuite()
name, age = the_string.split()
d = dict(globals())
ax = fig.add_subplot(111)
log.err()
print(list(l))
f.close()
edge_list.update([(a, x), (x, b), (b, a)])
[x for x in subsequences if len(x) >= min_length]
do_something(wrapped_dictionary[key])
delta = (mdate1 - rdate1).days
response.body = json.dumps(error_dict)
df
self.initial.update(form.initial)
testCount()
repr(key)
s.setblocking(0)
self.variables[attr].pop()
ax[1].legend(handles=[b1, b2])
decreasing_max_precision = np.maximum.accumulate(precision[::-1])[::-1]
foo.main()
now = datetime.now()
SUBDIRS = src
list_of_substrings
10 * np.cos(x * 2 * np.pi * cycle)
s.append([number])
L.append(li)
extension = os.path.splitext(os.path.splitext(filename)[0])[-1].lower()
print(foo, foo.bar)
print(data)
poll_twitter()
asps.append(file)
self.add_widget(Cell(i))
fo.write(line)
inds[mask][max_index]
now = datetime.now()
class_instance = Class1()
rtn = template.render(request=self.request)
out = np.argsort(reference)[pos]
time.sleep(pollinterval)
self.autocomplete(1)
dWOut = np.zeros((X.shape[1], flag.shape[1]))
pdf_path = os.path.abspath(os.path.join(DOC_ROOT, filename))
ctypes.memset(data, 0, size.value)
os.kill(p.pid, 1)
bins.insert(0, 0)
data = json.dumps(data)
type(Foo.spam)
{{localtime(item.date)}}
f.write(new_txt)
lines = f.readlines()
frozenset(frozenset(p) for p in l)
legs = legs[0]
emptydict = {}
index.date
[job2]
LOOKNEXT = True
fee = models.DecimalField()
list1 = [dict1[k] for k in commons]
print(str.isalpha.__doc__)
writer.writerow([req.date, req.time, req.user])
xcenters = xchunks.mean(axis=1)
print(a, f, b)
conn.close()
r = random.randint(0, 100)
self._whatever
session.add(i0)
sleep(2)
WSGIHandler()
raise ValueError(bcp_identifier)
absfn = os.path.join(root, fn)
book_id = Column(Integer, primary_key=True)
handles, labels = ax.get_legend_handles_labels()
scipy.stats.norm(0, 1).pdf(0)
print(age.total_seconds())
s.send(msg)
ax = fig.add_subplot(1, 1, 1)
frame = inspect.currentframe()
opt = tf.train.AdamOptimizer(self.learning_rate)
lst[idx - p]
dill.detect.badtypes(f, depth=1)
df = pd.DataFrame(dict(amount=[0, 1] * 10))
pipeline.set_state(gst.STATE_NULL)
setattr(self, key, kwargs[key])
out = input[binary_matrix.ravel()[idx[:, (0)] * lat_len + idx[:, (1)]] == 1]
data.append(tag.next_sibling.string)
print(nx.pagerank(G, max_iter=200))
factors(n)
print(df)
isinstance(P, (list, tuple, np.ndarray))
scheduler.enqueue_in(timedelta(hours=6), after_6_hours)
x + y
sum(x)
self.setItemIndexMethod(QtWidgets.QGraphicsScene.NoIndex)
h.close()
np.triu(np.outer(x, x), k=1).sum()
assert s.query(A.id).order_by(A.id).all() == [(1,), (4,)]
coords = list((x, y) for x in range(100) for y in range(100))
getattr(actuator, attr_name)
fig = plt.figure()
order_by(Article.created.desc()).limit(7)
mylist[:] = map(func, mylist)
X_train = X[train_indices]
print([s.get_text() for s in axarr[0].get_xticklabels()])
ybnds = np.array([-20.0, 20.0])
map(operator.sub, a, b)
self.md5.digest()
[0.0, 1.0, 0.0, 1.0],
mac.upper()
pp.show()
ax2.set_xticks(X2tick_location)
session = smtplib.SMTP(server)
im.set_extent((-5, 5, -5, 5))
os.remove(filename)
deleteself[i]
map(lambda x, y: x + y, a, b)
result = [s for s in data if len(s) == len(data[0])]
val = hex(val)
email = models.CharField(max_length=100)
df.head()
self.canvas.delete(self.zimg_id)
channel.close()
frame.update_idletasks()
deleteresponses[-1]
pairs = [(i, j) for i in range(n) for j in range(i + 1, n)]
s.send(tsr.encode())
d = defaultdict(lambda : -1, d)
fn(*args, **kwargs)
self.treeview.expand_all()
input = raw_input
main()
str(bin(7))[2:]
s[last_index + 1:]
abs(1 - 2)
screen.blit(my_image, position)
QtGui.QWidget.__init__(self, parent)
logging.FileHandler.emit(self, record)
Thread(target=startProcess).start()
time.sleep(wait_time)
conn.close()
cx1 = np.random.random_integers(0, size - 2)
mod = imp.load_source(name, path)
self.panel.Bind(wx.EVT_LEFT_UP, self.OnMouseUp)
result = [sum(l) for l in a]
c[tuple(x)] += 1
sys.exit(app.exec_())
per = float(tota) * (100.0 / 500.0)
self.deletes.add(obj)
t.start()
a[np.where(a[:, (-1)])]
page.mergePage(new_pdf.getPage(0))
print(d[1])
print(max(valids) if valids else False)
fig = plt.figure()
opener = urllib.request.build_opener(auth_handler, NoOpHandler())
html_text = f.read()
cosx * signx
deduped = set(lst_as_sets)
x = [np.random.random((10, 10)) for _ in range(5)]
log_file.write(line)
activity = models.CharField(max_length=250)
atexit.register(module.deinit)
m = X.mean(axis=1).reshape(-1, 1)
timer.start()
A[idx]
all_matches = numpy.unique(numpy.array(dates).flatten())
pylab.draw()
cv2.circle(cimg, (i[0], i[1]), i[2], (0, 255, 0), 2)
i.scheduled()
worker.join()
main()
{{content | safe}}
sentences = tokenizer.tokenize(paragraph)
matplotlib.axes.Axes.__init__(self, *args, **kwargs)
found.difference(expected)
layout = QVBoxLayout(self)
d = os.path.join(dir, d)
sizer.Add(self.cb, 0, wx.ALL, 5)
ddtstart = datetime.datetime.now()
xlim([-6, 6])
grequests.map(rs)
a[b != 0]
Base.metadata.create_all(e)
points = np.array([[-2, -2], [2, 0], [-1, 2]])
coords = zip(a.ravel(), b.ravel())
result = cv2.matchTemplate(img, template, cv2.TM_CCORR_NORMED)
sys.exit()
M = np.matrix([[2, 2, 2, 2], [2, 2, -2, 2], [2, 2, 2, 2], [2, 2, 2, 1]])
self.driver = webdriver.Firefox()
session.commit()
s.sendmail(me, [you], msg.as_string())
im = Image.fromarray(rescaled)
array([27, 26, 26, 26, 27, 26, 26, 26, 26, 27])
print(workdaycount(date(2011, 8, 15), date(2011, 8, 22)))
logging.basicConfig(level=logging.INFO)
v = [(t[i + 1] - t[i]) for i in range(len(t) - 1)]
form.save()
ctx.fill_preserve()
today.weekday()
x = someModule.someClass(list(range(1, 5)))
np.apply_along_axis(multi_slice_max, 1, cond, arr)
s.shutdown(socket.SHUT_WR)
g.LgRnk.apply(lambda x: x / len(x))
p = multiprocessing.Process(target=csvreader, args=(string_array[i], q))
atomized
name = models.CharField(max_length=50)
process.send_signal(signal.SIGINT)
olist.append(otest)
[iplocationc]
c.__class__.__mro__
cdf = np.cumsum([0, 0.02, 0.08, 0.16, 0.29, 0.45])
ax = axes([0.1, 0.1, 0.8, 0.8])
g = g.sortlevel()
self.beta = tf.Variable(tf.constant(0.0, shape=[depth]))
apps.get_models()
virtualenv / home / my_envs / env_for_projectname
[[1], [1, 2]]
im.set_clim([0, 1])
print(key, value)
img = Image.open(picture)
pdb.set_trace()
idxNan = np.isnan(a[item]).nonzero()
plt.figure(1)
res = opener.open(req)
gradst = tf.reshape(gradsp, shape=(shapey[0], shapey[1], shapex[0], shapex[1]))
plt.legend(handles=[NA, EU, AP, SA], loc=2)
h = ax.hist2d(x, y, bins=40, norm=LogNorm())
paint()
mp.active_children()
my_companion.close()
table_name = Column(String(50), unique=True)
[0, 0, 0, 17, 0, 0, 0, 40, 0, 0, 0, 40, 0],
pprint(list(ws.iter_rows()))
self.driver = webdriver.Firefox(self.profile)
cursor = connection.cursor()
sys.exit(NO_PYTHON_LIBRARY_ERROR)
jStr = json.loads(jsonString, strict=False)
axx.xaxis.set_major_locator(ticker.FixedLocator([xx]))
list(zip(a, itertools.cycle(b)))
subprocess.Popen([python_bin, script_file])
instance.some_method(data)
other_object.add(obj)
print(list(interleave(range(1, 5), range(5, 10), range(10, 15))))
Mixin.__init__(self)
thread.run()
self.c.set(SERV_SECTION, SERV_NAME, SERV_NAME_DEFAULT)
ax1.plot(xvals, data)
data = models.HStoreField(db_index=True)
handler = logging.StreamHandler(sys.stdout)
re.sub(pattern, repl, text, flags=re.DOTALL)
self.model.transform(X, self.threshold)
run(command)
track.duplicateTo_(newPlaylist)
run_wsgi_app(application)
e = Entry(root, textvariable=v)
p = pyaudio.PyAudio()
ax1.yaxis.set_major_formatter(fmt)
self.factory._send(data)
c = np.empty((a.size + b.size,), dtype=a.dtype)
matrix = ss.coo_matrix((ones, (rows, cols)))
print([id(y) for y in new_strs])
ax = fig.add_axes([0.15, 0.15, 0.7, 0.7])
PyMouseEvent.__init__(self)
pyrodaemon.shutdown()
show()
self.list_of_tweets = []
i = i + 1
output.append(list[prev:index])
callthecommandhere(blablahbla, filename, foo)
plt.xticks(np.arange(0, 25, 5), [0, 25, 50, 75, 100])
checkDict(subword)
white = np.array([255, 255, 255])
pd.DataFrame(records, columns=list(columns.keys()))
out.write(fixed)
a = TestB()
cls.__init__ = instrumented_init
num_seen.setdefault(v, []).append(k)
p1 = N * np.dot(B.T, A)
log.start()
random.sample(randset, 100)
server.quit()
x, y = x + dx, y + dy
K = np.array([i for i in range(n) if i != r and i != s])
nf.close()
fig = plt.gcf()
dict.__setitem__(self, key, val)
application = QtGui.QApplication(sys.argv)
timeit(set(a).intersection(b))
deletelst[i]
b = a[:, (idx)]
_marker_key = db.Column(db.Integer, primary_key=True)
print(sample.collect())
list(string.Formatter().parse(s))
all_pixels.append(0)
format_to_year_to_value_dict = defaultdict(lambda : defaultdict(list))
exit(0)
set_of_all_items = set(list_of_all_items)
df.div(df2.iloc[0])
main()
self.client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
conn.send(msg)
t = zip(a, b, c)
final_ensemble.n_estimators = len(final_ensemble.estimators_)
print(repr(fin.readlines()))
result = mygetter(tup)
self.name
ax = fig.add_subplot(1, 1, 1)
plt.contour(X, Y, F - G, [0])
user.Getinfo()
d = defaultdict(list)
mercury.circle(58, 1)
int(binary, 2)
fcs.append((random.random(), random.random(), random.random(), 0.6))
pdb.set_trace()
axes[0, 1].set_ylim(0)
random.seed()
glEnable(GL_POLYGON_SMOOTH)
self.grid_1 = wx.grid.Grid(self.window_1, -1, size=(1, 1))
ax.set_title(str(temp))
user = fields.ForeignKey(UserResource, user, full=True)
globals().setdefault(name, [])
print(pwd.getpwuid(os.getuid()))
patcher.stop()
t.run()
something = fgn.Class1()
self.canvas.draw()
of.write(l)
{word: list(neighbours(word)) for word in words}
sys.exit(app.exec_())
stdout_redirected(to=sys.stdout, stdout=sys.stderr)
client = oauth.Client(consumer)
print(i0.id)
time.sleep(0.5)
list.__setitem__(self, key, value)
out = [d[k] for k in sorted(d.keys())]
print(paths[2][6])
app.MainLoop()
print(item)
date_registered = date.today() - timedelta(days=1)
x, y = fsolve(equations, (1, 1))
pd.MultiIndex.from_product([letters, letters]),
s = pd.Series(np.arange(10))
matplotlib.pyplot.scatter(Xs, Ys.flatten(), color=cs)
s += random.randint(1, y)
sock.settimeout(10)
cosetCoding.cosetCoding(10, 11, asarray([0, 0, 0, 0, 0, 0, 0, 0]), 0)
writer.UpdatePipeline()
df
(10 - s % 10) % 10
self.data[key] = value
np.savez(filename, row=row, col=col, data=data, shape=shape)
s[offset:offset + amount]
window.show_all()
j = json.loads(your_json)
mutex.acquire()
query = urlparse.parse_qs(url.query)
{{companyForm.company_name()}}
dict(new_d)
plt.show()
sys.stdout = sys.__stdout__
post_save.connect(Activity.cancellation_occurred, sender=Cancellation)
kOUT = kOUT.tolist()
session.add(f)
print(s.groupby([s.index // k]).mean())
outFile.close()
foo = POINTER(temp_foo)
fig, ax = plt.subplots()
f2.write(Lines[i + 2])
isinstance(s, str)
help(str.find)
split_point = int(im.shape[1] / 5)
Thread(target=read_stderr, args=[process]).start()
print(exceptions.html_error_template().render())
myarray[myindexlist]
fig, axes = plt.subplots(1, 4, figsize=(10, 5))
zip(itertools.repeat(prefix), iterable)
x = random.randrange(box[0][0], box[1][0])
ax.yaxis.set_major_formatter(tick.FuncFormatter(adjust_y_axis))
os.path.join(self.path, filename)
f(*args, **kwargs)
cv.Threshold(grey_image, grey_image, 70, 255, cv.CV_THRESH_BINARY)
f
ndimage.map_coordinates(data, [zi, yi, xi], cval=-999)
E += potential(np.sqrt((x[i] - x[:i]) ** 2)).sum()
any(sublst == lst[i:i + n] for i in range(len(lst) - n + 1))
self.t1 = time.time()
pyplot.hist(e_data[selected_values])
func_py.restype = ctypes.c_double
float(self.val)
window.show_all()
list_size_2.append(row)
c = np.arange(24).reshape((4, 6))
window.show()
block.draw()
greet_command()
print(i, chr(i))
c = np.hstack((a, b))
br.set_handle_referer(True)
req = urllib.request.Request(url)
pri = glrhs[0]
plt.yticks(np.arange(0, len(ax1) / r - 0.1, 1 / r), ax1_ticks)
print(is_shifted_copy([1, 1, 2], [2, 1, 1]))
ax = fig.add_axes([0.05, 0.1, 0.9, 0.85])
data.splitlines()
self.__class__.set_x_class(10)
results = [r.get() for r in results]
sys.exit(1)
allFoos()
ax1 = fig.add_subplot(111)
df.append(h, ignore_index=True)
self.old_func1 = module1.func1
dict[key] = value
msvcrt.getch()
y = [p._replace(probability=round(p.probability, 2)) for p in y]
decompressor.close()
main()
fig, axes = plt.subplots(nrows=2, ncols=2)
plt.plot(x, y2)
sys.stdout.flush()
profile.save()
plt.ylim((0, 100))
x.sort(key=lambda item: (len(item), item))
len(self.data)
connection.setblocking(0)
arr.tocsr()
res = [lookuplist[k] for k in arr]
print(l[:-1])
main.py
random.shuffle(combined)
root = tk.Tk()
obj.image.url
s.listen(1)
print(len(main()))
p = subprocess.Popen(some_cmd, stdout=subprocess.PIPE, stdin=subprocess.PIPE)
d = {}
server.ehlo()
lst.sort()
cap.release()
plt.show()
plt.xlim(-2.5, 12)
asset = forms.ModelChoiceField(queryset=Asset.objects.none())
CM_tilde = np.mean(data, axis=1)
raise SystemExit
axes.set_ylim(0, math.ceil(max(logcdfy)))
plt.setp(labels, rotation=0)
n ^ 1 << k
models.User.query.get(user_id)
self.assertEqual(expected.lower(), actual.lower())
[2] + [(2 * i + 1) for i in range(1, n // 2) if sieve[i]]
plt.scatter(x1, y1, label=str(pointset1))
tree = [Node() for _ in range(10)]
self._fileobj.seek(oldposition, os.SEEK_SET)
cj.set_cookie(c)
fh.setLevel(logging.INFO)
plt.imshow(im)
f.write(s)
list(bucket.list())
m.digest()
idx = np.abs(array - value).argmin()
tree = lh.fromstring(content)
fh.setLevel(logging.INFO)
[e.text for e in sel(h)]
print(df1.to_csv())
fig.clear()
fig = plt.figure()
setattr(self, b, button)
ax.add_artist(ell)
print(ast.literal_eval(escaped_str))
coordinates = list(product(range(width), range(height)))
col.domain[0].name, pd.Series(col.to_numpy()[0].flatten())
print(self.invalid_response)
myapp.show()
address = models.CharField(max_length=100)
w1.append(words[0])
survival_table = pd.Series(index=make_category_multiindex(categories, names))
dfUnstacked2
heapq.heappop(heap).x
color_image = cv.QueryFrame(self.capture)
cj = cookielib.CookieJar()
CS = plt.contourf(xi, yi, zi, 15, cmap=plt.cm.jet)
msvcrt.setmode(sys.stdout.fileno(), os.O_BINARY)
word_list.sort(key=lambda i: i[1], reverse=True)
self.func.__call__(*args, **kwargs)
cnxn.commit()
print(highlight(json_str, JsonLexer(), TerminalFormatter()))
app = QtGui.QApplication(sys.argv)
your_json = dumps(serialized_labels)
nbrs.fit(X, Y)
{{my_model.slug_field_name}}
l = sorted(l, reverse=True)
testnum == num
adate -= timedelta(days=1)
ax.grid(True)
d = defaultdict(list)
screen = pygame.display.set_mode((800, 600))
top = curses.newwin(1, 10, 0, 0)
ax.set_ylim(0, 61)
avg_time_at_college = avg_passout_date - avg_start_date
self.inverse.setdefault(value, []).append(key)
list(filter(condition_check, l))
list(map(sum, zip(a, b, c)))
print(psutil.net_connections())
soup.td.contents
filter(good, combinations(list(range(1, n + 1)), r))
(d in set1) == (newd in set2)
whatever
sys.exit(-1)
ax0 = plt.subplot(211)
coo_matrix((data, (c.row, c.col)), shape=(a.shape[0], b.shape[1]))
A = np.zeros((M, N))
self.buffer = [1] * size
a[1:4] = [9, 7]
a = next(i for i in userInput if i in wordsTask)
print(id(x))
B[mask] = A[1][B[mask]]
im.set_clip_path(clip_path)
A = NP.array(A)
list(d)
print(cross_validation_group(test_data, train_data))
df = pd.DataFrame([0])
exit()
a.T
listB = [0, 1, 2, 1, 2, 1, 0]
ax.scatter(x[mask], y[mask])
inqueue.put(i)
name = models.CharField(max_length=100)
root
pygame.mixer.init()
main()
d = cv2.cvtColor(c, cv2.COLOR_RGB2BGR)
n1, n2 = np.arange(5), np.arange(5)
cv2.rectangle(img, pt, (pt[0] + tw, pt[1] + th), 0, 2)
x ** 2
cum = np.cumsum(a, axis=1)
sample_size += len(rn)
ax.plot(t, fun(t))
layout = QtGui.QVBoxLayout(widget)
l.append(i % 10)
c = [a[index] for index in b]
hold(True)
f(n)
player_list = []
df = df.reindex(columns=unused_cols + list(chain(*fill_missing)))
nil
random.shuffle(each)
sample = random.sample(item_names, 2)
freqs = nltk.FreqDist(w.lower() for w in brown.words())
[gu(i) for i in range(len(uo))]
retval, img = cv2.threshold(img, 254.0, 255.0, cv2.THRESH_BINARY)
type(c)
fill_between(x, height - l[1], height, color=colors[1], alpha=alpha)
data2[:, (0, -1)] = np.nan
mycmd().cmdloop()
type({})
print(ObjectJSONEncoder().encode(tree))
tfact(n - 1, acc * n)
item.append(len(item))
map(lambda k_v: k_v[0], L)
sleep(0.5)
deletecursor
reactor.run()
window.show()
print(a)
mapper(Something, select([sometable], sometable.c.deleted == False))
time.tzset()
do_something_2()
df
b = array([2, 4, 7])
f = urllib.request.urlopen(link)
results.append(string[split_points[-1][1] + 1:])
number, factor = input().split()
(list(range(5))[6:7] + [999])[0]
values.append(value)
App().run()
d = {x: (x, y, z) for x, y, z in tuples}
pylab.show()
QApplication.setOverrideCursor(QCursor(Qt.WaitCursor))
d = R * sqrt(x * x + y * y)
app.SetTopWindow(frame)
Job.objects.get(client=client)
print(result.get(timeout=1))
ax.set_ylim(-75, 75)
list(hi_obj.__dict__.keys())
p_lineinfo = frame.f_back.f_lineno
now = datetime.now()
abacus = [0, 0, 0, 0]
foo = np.random.rand(2000000).cumsum()
a = a.__iadd__(b)
html = browser.open(url)
XS = np.asarray(XS)
np.roll(sa, -np.count_nonzero(np.isnan(a)))
rightpanel = wx.Panel(self, -1, size=(200, 150))
bottompanel = wx.Panel(self, -1, size=(200, 150))
exit()
getattr(mod, attr)
app = Flask(__name__)
fcntl.lockf(doing_fd, fcntl.LOCK_EX)
img = cam.getImage()
fig = plt.figure()
pixels = list(im.getdata())
False
lxml.etree.tostring(r.item)
sleep(5)
self.finish()
form = MyForm(request.POST)
proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)
myfile.close()
browser = webdriver.Firefox()
frame = cap.read()[1]
do_plot(ax)
print(line)
maxvalues = heapq.nlargest(20, lst)
ax1.plot(xvals, xvals, linewidth=7)
show()
print(lt_obj.get_text())
out.write(g.read())
parse(new_str)
result = np.c_[original[v[1:-1], v[:-2]], original[v[1:-1], v[2:]]]
min(l[0] + best_choice(l[1:]), l[1] + best_choice(l[2:]))
resp = opener.open(req)
filtered_df = df.where(f(df.a))
do_stuff(a, b)
list(B.items())
canvas.print_png(sio)
writer.writerows((title, intro + tagline) for title, intro, tagline in grouped)
pC = ctypes.cast(rawPointer, ctypes.POINTER(ctypes.c_uint16))
ips = [match[0] for match in re.findall(pattern, text)]
a = np.exp(np.random.randn(5, 10)).astype(theano.config.floatX)
time.sleep(alarm1)
sys.stdout.write(inline)
df
seen.add(key)
plt.xticks(x, my_xticks)
d = date(year, 1, 1)
c = np.array([0, 1, 2])
n = int(temp) * 2
server.shutdown()
conset.add(x)
plt.yticks(list(range(len(labels))), labels)
self.render_change_form(request, context, form_url=form_url, add=True)
isinstance(x, collections.MutableSequence)
y = x.T.tolist()[0]
args = parser.parse_args()
sys.meta_path.insert(0, importer)
self.window.show()
fig = plt.figure(figsize=(10, 9))
print(row[column_number])
a = A()
res = im.crop((0, 0, MAXSIZEX, MAXSIZEY))
xml_output
len(r.content)
copyfile(srcname, dstname)
print(table)
mpf(200) + mpf(2e-26) + mpc(1j)
plt.show()
f.close()
splittedname(s1) > splittedname(s2)
np.abs(df.time - image_time)
user = User.objects.get(pk=user_id)
d = {i: x for i, x in enumerate(a)}
lst.extend((8, 9, 10))
combo = QtGui.QComboBox(parent)
df = pd.DataFrame(cols)
fb.authenticate()
attachment.set_payload(fp.read())
main()
classifier = classifier.fit(X_train, y_train)
str(self.__dict__)
self.Artwork.pack()
pdf.add_page()
df[1] == 4
t = datetime.datetime.now()
pix = im.load()
result = np.array(result)
print(sum(st.issuperset(sub) for sub in b))
data = conn.recv(1024)
exit()
os.system(x)
print(new_str)
crawler.start()
results = sorted(list(results.items()), key=lambda x: x[1])
int(x.split()[0])
confused_array[~mask & (numpy_array == 0)] = 0
result.append((t, c1 + c2))
(a * d).todense()
dataframe = pd.read_csv(f)
ninety - nine
vector / np.linalg.norm(vector)
text[len(prefix):]
WebDriverWait(driver, timeout).until(element_present)
fig = plt.figure()
result += count(haystack[pos + 1:], needle[1:])
{{l.form.city}}
[abs(j - i) for i, j in zip(minmax[:-1], minmax[1:])]
deletedict[key]
print(response.registers[2])
print(arr[local_minima_locations])
gukan(0)
plt.bar(ind, OY, width=width)
audiolab.play(x, fs)
self.a.append(numpy.hstack((numpy.ones((input.shape[0], 1)), input)))
True
outfile.close()
self.d[k]
key.delete()
monkey.patch_all()
uuid.uuid1(random_48_bits)
xmldoc = minidom.parseString(xml_str)
m.sort(key=str.isdigit)
print(rect.PyRectangle(0, 0, 1, 2).getLength())
pst.close()
divider2 = make_axes_locatable(ax2)
columns[i].append(l)
monkey_patch_B()
img.close()
self.loadFinished.connect(self._loadFinished)
bytes([97, 98, 99])
pyplot.gca().add_patch(circle)
today = datetime.date.today()
env = Environment()
some_func()
p.pretty(obj[key])
time.sleep(0.5)
p[pair[0]] += 1
merged.update(add_obj)
timeit(numpy.array(hugeequal1), numpy.array(hugeequal2), 10000)
print(spectra_list[1].dispersion)
fig.tight_layout()
a.sort_index(1, inplace=True)
func()
fig.delaxes(ax)
code = func.__code__
actor = match.group(1).strip()
latest = Foo.all().latest()
np.array(scipy.stats.chi2.interval(0.95, 2 * data)) / 2 - 1
X[[0, 1], [0, 1]]
[dingdong]
ax.xaxis.set_ticks(np.arange(min_x, max_x, int((max_x - min_x) / len(labels))))
sum(v)
buf.readline()
l = map(lambda x: x + 2, l)
metadata.read()
soup = BeautifulSoup(html_doc)
ax.clear()
sys.stdout = Discarder()
conn.setopt(pycurl.USERNAME, username)
window.show()
t[0].start()
plt.vlines([0, 4, 6], -10, 10)
a is a.astype(int, copy=False)
ssh = paramiko.SSHClient()
now = datetime.datetime.now()
conn.send(some_data)
file_name = f.name
T2.method_three()
self.loadFinished.connect(self.on_loadFinished)
self.h2Box.addWidget(self.cmbox)
args = parser.parse_args()
today = datetime.date.today()
df[cols].mean(axis=1)
csvout.write(wstr)
self.sumvariance /= self.sumvariance[-1]
np.interp(width_S, S_values_2, F_values_2)
b = np.linspace(-2, 2, 5)
np.concatenate((new_face, M), dim)
self.file_pointer.seek(0, os.SEEK_END)
form.save_m2m()
print(merge(lst))
regex.split(s)
f(*args, **kwargs)
book = xlwt.Workbook()
self.screen.fill((255, 255, 255))
ax.add_collection(p)
h.request(url, method=method, body=body, headers=headers, **kwargs)
{v: k for k, v in enumerate(calendar.month_abbr)}
parser = argparse.ArgumentParser()
sess = tf.Session()
db.session.commit()
cam.start()
sax.parse(locstm, Handler())
t1 = time.time()
gs.tight_layout(fig)
response
sleep(0.1)
r = re.compile(result)
print(sum(range(49999951, 50000000)))
types = [col.type for col in q.columns]
etree.tostring(otree)
print(json.dumps(root, indent=4))
print(result.key().id())
self.ssh.connect(host, username=user, password=psw, port=22)
sockobj.listen(5)
result = [o for o in list1 if o not in set2]
print(t.render(c))
excel.Application.Quit()
sleep(1)
result.append([t[j + 1]])
foo_from_bar(self.bar_impl(x))
list(s)
line.set_xdata(r[:, (0)])
vf = numpy.vectorize(f)
out.close()
sys.argv[0]
s = requests.session()
print(np.intersect1d(a, b))
idx_start = np.where(sorted_a[:, :-1] != sorted_a[:, 1:])
df
df.dtypes
main()
print(f.data)
f.write(os.linesep)
app = QtGui.QApplication(sys.argv)
user.auth_ids.append(email)
form = AnimalForm(request.POST)
ast.literal_eval(value)
last_entry_date = B.select(B.date).order_by(B.id.desc()).limit(1).scalar()
pool.join()
a, b = 0, 1
df1
y, x = np.ogrid[-m:m + 1, -n:n + 1]
plt.show()
conn = pymongo.MongoClient()
btn.clicked.connect(self.buttonClicked)
self.scat.set_offsets(data.transpose())
m.group(1)
f.write(line)
df.dtypes
hash(x)
out_file.writelines(unique_everseen(f))
response
fig.add_subplot(111)
p.start()
plt.hist(myarray, weights=weights)
os.makedirs(path)
print(fresult)
[sample[i * n:(i + 1) * n] for i in range(count)]
f = urllib.request.urlopen(url)
b = cast(s, POINTER(c_ubyte * 20))[0]
print(df.groupby(df.index).apply(tmpFunc))
ax.set_xticks(np.arange(0, 8) - 0.5, minor=True)
pixels = img.load()
pyplot.show()
c = np.searchsorted(a, b)
types = [col.type for col in res.context.compiled.statement.columns]
libxxx.foo(data, len(data))
order.append((dist, i))
ymin, ymax = kde.get_ylim()
MyMIDI = MIDIFile(1)
list(self).count(obj)
result = set(p[0])
type(x)
customers = defaultdict(list)
regressor.fit(X, y)
self.y -= 1
self.Bind(wx.EVT_CHAR, self.KeyDown)
json.loads(value)
socket.setTimeout(SERVICE_TIMEOUT_IN_mS)
False
self.b = 0
[(k1[0], k1[1], k2) for k1, k2 in zip(itertools.chain(*dge), nde)]
socket.setdefaulttimeout(60)
mydic[key].append(value)
raise Exception()
numpy.clip(A.astype(int) - B.astype(int), 0, numpy.iinfo(int).max)
p.communicate()
sort_idx = np.argsort(a)
c, f = divmod(your_number, 256)
results = {input_list[0]: [input_list[0]]}
arr[idx]
calendar_service = gdata.calendar.service.CalendarService()
u = numpy.linspace(0, 2 * numpy.pi, 100)
self.loop.call_soon_threadsafe(task.cancel)
print(f.read())
sorted(items, key=inner)
main()
out = a[idx, np.arange(a.shape[1])]
color = np.array(color)
future += datetime.timedelta(days=1)
mymethod = add_timeout(mymethod, 15)
df[df < 0] = 0
idx = np.random.randint(10, size=2)
section_sums = np.bincount(np.arange(mask.size) // 20, mask)
ax1.set_yticks(numpy.arange(y1 - 1, y2 + 1, 0.5))
stdout, stderr = process.communicate()
Platform.__init__(self, x, y)
self.callback()
A[np.arange(2), B.T].T
print(visit_element.tag, visit_element.text)
B_Bidx = np.digitize(B, Bbins)
self.pages.append(dict(self.__dict__))
b = a[random.randint(0, len(a) - i)]
driver = webdriver.Firefox()
set(listas[0]).intersection(*listas[1:])
print(xee.tostring(doc))
print(x)
str.__getattribute__(self, attr)
bytes([bstr[0] + 1, 98, 99])
color_norm = colors.Normalize(vmin=0, vmax=N - 1)
df.info()
pdf.image(image, x, y, w, h)
restart()
l.add(i)
idx = np.argsort(df[df.columns[5:]].values)[0]
handle_the_error()
model1.py
sys.path.insert(0, cmd_subfolder)
map(bin, bytearray(st))
(x + y).subs(reversed(reps))
s[-6]
response = urlopen(request).read()
html.strip_tags(htmls)
output = p2.communicate()[0]
print(response.getRegister(2))
chain.from_iterable(combinations(s, r) for r in range(len(s) + 1))
subject = models.CharField(max_length=100)
hl.set_xdata(numpy.append(hl.get_xdata(), new_data))
f1.save()
flask.render_template = _my_render_template
print(response.read())
(k for m in self.maps for k in m.keys())
test2()
count += 1
GetSum(arrs[-1], arrs[:-1])
plt.setp(labels, rotation=0)
self.setSelectionMode(QtGui.QAbstractItemView.MultiSelection)
results = serializers.SerializerMethodField()
filtered_numbers = list(filter(predicate, numbers))
datetime(1970, 1, 1) + timedelta(seconds=local.timestamp())
X, Y = np.meshgrid(xvals, yvals)
random.shuffle(object_list)
self.write(data)
kde = sns.kdeplot(random_points[:, (0)], random_points[:, (1)], ax=ax)
np.where(arr >= threshold)
driver = webdriver.Firefox(firefox_profile=fp)
self.put(item)
plt.plot(x, y1)
(b[c] == a).all()
pi = (a + b) * (a + b) / (4 * t)
tcpcounter += 1
udpcounter += 1
loop = asyncio.get_event_loop()
field = self._fields.get(name)
self.log.write(s)
self.failed_urls.append(response.url)
os.symlink(linkto, dstname)
r = fv(a[:, (numpy.newaxis)], b)
unittest.main()
blocks.shape
writer = csv.writer(f)
layout = QtGui.QVBoxLayout()
print(json.dumps(json_data, indent=2))
vbox = gtk.VBox(False, 10)
len(FinalList)
A = np.random.random((5, 5, 5))
print(s)
data.sum()
add = lambda x, y: x + y
final.append(str(seq[0]))
main()
app.MainLoop()
browser = webdriver.Chrome()
[0, 1, 2]
index_list
non_blank_lines = (line for line in stripped_lines if line)
gnb_loaded = cPickle.load(fid)
decorator
indices[:-(n - 1), (5)] = np.arange(n - 1, m * n)
ax = plt.gca()
C[i, j] = np.dot(A[:, (i)], B[:, (j)])
post_save.connect(ping_handler, sender=MyModel)
wavwriter.setnchannels(1)
canvas.saveState()
print(list(best_range))
a[np.ix_(n1, n2)]
self.__dict__[key]
a = pd.Series([pd.to_datetime(date) for date in date_stngs])
fig1 = plt.figure()
md5.digest()
b1 = np.array([[5, 6], [7, 8]])
Py_Finalize()
a = [1, [2, 2, [2]], 4]
a.set_yticklabels(a.get_yticks(), fontProperties)
json.loads(raw_post_data, object_pairs_hook=dict_raise_on_duplicates)
allatt
fig = plt.figure()
sorted(players, key=lambda player: player.rank)
print(query2.all())
f.close()
setenv(foo)
iter(relatives.items())
df_smooth.plot(ax=axs, alpha=0.7)
contents = Path(file_path).read_text()
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj))
strong.append(value)
fout.close()
ax2.add_line(copy.copy(line2))
serversocket.bind((host, port))
cms_pages = Page.objects.filter(in_navigation=True, published=True)
frame = pd.read_csv(path, names=columns)
X, Y = numpy.meshgrid(list(range(sz[0])), list(range(sz[1])))
self.stream.write(msg)
res_list[i].append(float(val))
cos(x) + cos(y)
s.listen(10)
fixed = s[1:]
session.flush()
sk.push(x509)
hash(s) % 256
MyUser.objects.get(pk=self.pk)
c = C()
panel = Label(root, image=img)
textview = gtk.TextView()
logger.addHandler(hdlr)
f.close()
list(cor[cor > 0.9999].to_dict().keys())
ys = [ys[i] for i in sorted_index]
result += match.group(1).upper() + match.group(2).upper()
Cbins = np.linspace(C.min(), C.max(), 12)
print(cron5)
print(k, sys.getsizeof(v))
a.close()
ax2 = fig.add_subplot(2, 1, 2)
zip_list = zip(A, B)
result_dict
reader = csv.reader(infile)
pool.shutdown()
f.x
server.shutdown()
lines = f.readlines()
r.url
args.type()
{l: set(words) for l, words in groups}
print(procname)
[0, 0, 0, 17, 0, 0, 0, 17, 0, 0, 0, 17, 0],
sizer.Add(self.cbBG, 0, wx.ALL | wx.CENTER, 5)
dataset.withColumn(out_col, udf(f, t)(in_col))
background.fill((250, 250, 250))
f()
today = datetime.date.today()
sns.heatmap(df)
pprint.pprint(content_json)
func = getattr(modulename, funcname)
ax1 = fig.add_subplot(111)
fig, (ax1, ax2) = plt.subplots(nrows=2, sharex=True)
len(one_set & set_of_150kwords)
button.pack()
atexit.register(root.mainloop)
decorator
len(word)
np.random.shuffle(p)
subject = models.CharField(null=False, max_length=128)
_getdents.restype = ctypes.c_int
page = BeautifulSoup.BeautifulSoup(html.text)
r = urllib.request.urlopen(url)
s.send(CRLF.join(request))
self.layout.addWidget(self.button)
f.seek(256, os.SEEK_SET)
self.__class__.__call__ = lambda x: x
t[0] = t[0]
f = scipy.interpolate.interp2d(x, y, data)
mask = np.zeros_like(arr, dtype=np.bool)
image_data = get_image_data_from_blob()
btn.set_sensitive(True)
start = time.time()
time.sleep(2)
title = Column(String(20), primary_key=True)
eval(s, {}, {})
a.append(i)
x.change()
list(f.keys())
post = models.ForeignKey(Blog)
future = asyncio.ensure_future(coro)
x + 1
Test.calc_x.__code__.co_names
out.write(re.sub(pat, s_after, line))
pygame.init()
m = hashlib.md5()
driver = webdriver.Firefox()
self.session.commit()
plt.show()
driver = webdriver.Firefox()
self.assertRaises(models.BadFooError, foo.full_clean)
next(self._iter)
curses.echo()
[i]
append_record(my_dict)
factors2 = list(factors[:i] + factors[i + 1:])
type(a)
print((start, end))
myfast()
myFunc(1, 2)
os.remove(filename)
weekday = today.timetuple()[6]
y.append(np.random.random_integers(0, 10, 20))
self.files = {}
maxval = max(iter(dict.items()), key=operator.itemgetter(1))[1]
text_file.close()
print([x for v in list(anagrams.values()) if len(v) > 1 for x in v])
time.sleep(0.1)
time_keypresses(pygame.event.get())
driver = webdriver.PhantomJS(desired_capabilities=caps)
row.delete()
self.videoSink.set_xwindow_id(hWnd)
print(list(islice(primes(), 0, 1000000)))
proc = subprocess.Popen(cmd, stdin=subprocess.PIPE)
wb.save(response)
make_sine(freq, data_length, fname)
c.seek(0)
help(sys.getsizeof)
b.py
np.array(x.shape).tofile(f)
l.addWidget(self._tv)
list(User.__mapper__.columns)
count = 0
sys.stdout.flush()
df2
s.cookies.save(ignore_discard=True)
ax.set_xlabel(label)
clean_table_grouped.join(for_df)
f.close()
slices = list(takewhile(bool, (list(islice(it, 0, i)) for i in seclist)))
(0, 0, 128), (255, 0, 255), (255, 255, 0), (0, 255, 255), (128, 0, 128)
pd.read_csv(io.StringIO(df.to_csv(index=False)))
leg.draggable()
list(d.items())
tt.Index(0).Set(ea)
numpy.ones((2, 2), dtype=bool)
fcond.wait()
fa[0]()
field = Model._meta.get_field(field_name)
y, d + math.hypot(y[0] - x[0], y[1] - x[1])
user.get_profile().whatever
handler1 = logging.TimedRotatingFileHandler()
Exception.__init__(self, message)
globalist_randomnode = []
self.list.SetItemData(index, key)
os.system(cmd)
mychain.apply_async()
d = np.diag(a)
w = gtk.Window()
interpreter.process_page(page)
graph.add_edge(node_number, random.choice(graph.nodes()))
hs = root.winfo_screenheight()
a()
chessboard.get_king_moves()
print(text.text)
index.create()
setattr(self, key, l)
A.append(B)
D[word] += 1
l = [random.randrange(0, 5) for _ in range(50)]
my_tuple = [], []
list.__setitem__(self, *args)
print(get_overlap(s1, s2))
response = urllib.request.urlopen(url)
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj))
setattr(namespace, self.dest, dest)
task.cancel()
result = []
print(max(s), max(s, key=str.lower))
DEBUG = False
i = np.random.choice(list(range(0, n * n)), size=m)
[s for s in mylist if not myregex.search(s)]
time = time.time()
fig = plt.figure()
timezone.make_aware(yourdate, timezone.get_current_timezone())
print(elem.split()[-1])
L.sort(key=getvals)
self.SetShape(wx.Region())
line[:i]
do_something(line)
imp.load_compiled(name, path)
dfall.head(6)
login(request, user)
merger.write(output_file_path)
text = urllib.request.urlopen(url).read()
painter.drawControl(QtGui.QStyle.CE_PushButton, self.getSyleOptions())
pyplot.show()
[zxcv, zxcv]
type(d.values())
self.observer.stop()
self.photo.save(os.path.basename(self.url), File(open(result[0])))
df1 = pd.DataFrame(lst, columns=cols)
im.set_data(mat)
print(ruamel.yaml.dump(data, Dumper=ruamel.yaml.RoundTripDumper))
data = data.drop(data.index[[0]])
os.kill(pid, 0)
np.allclose(Y1, Y2)
n = minn if n < minn else maxn if n > maxn else n
ax1.minorticks_on()
response.close()
f.writelines(res)
thirdpartymodule_b.dosomething()
output.addPage(page)
col_sums[:, (j)] = row_sums[:, (j)]
r = regex.search(string)
logger2.addHandler(log_handler2)
a.searchsorted(b)
dictionary = {}
self.__dict__[attr] = str(value)
connect.close()
wr.writerow(sh.row_values(rownum))
c.setopt(pycurl.FOLLOWLOCATION, 1)
dot(Phi, R)
ax2.yaxis.set_major_locator(MultipleLocator(0.25))
signal.signal(signal.SIGQUIT, term)
manager = multiprocessing.Manager()
c = np.arange(2, 9)
print(df.d.tolist())
print(match.groups())
print(pattern.findall(txt))
output = process.communicate()
self.deque.append(x)
x + (y if isinstance(y, tuple) else (y,))
data = np.random.normal(size=1000)
yaml.add_representer(MyClass, MyClass_representer)
keyfunc = lambda x: x[0][0]
x * np.sin(y)
re.sub(findthe, lambda matchObj: replacement.pop(0), sentence)
driver.set_window_size(1400, 1000)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
c = [(a[i] + [bi]) for i, bi in enumerate(b)]
t.set_axis_off()
show_float(x)
keys[0] if len(keys) == 1 else keys
cj = cookielib.LWPCookieJar()
hash(list(self.items()))
r = lambda : random.randint(0, 255)
file = cStringIO.StringIO(urllib.request.urlopen(imageUrl).read())
print(pos)
IOLoop().run_sync(func)
graph = facebook.GraphAPI(token)
splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]
a = b[0]
canv.pack()
handler = logging.FileHandler(file_name)
df
r = conn.cursor()
http_server.listen(8888)
consumer_lock_object.release()
perm_tuple = [(x.id, x.name) for x in Permission.objects.filter(user=user)]
zip(*alist)
cast(col, Float)
proc_stdout = process.communicate()[0].strip()
np.column_stack(np.unravel_index(idx, lon.shape)).tolist()
fig = plt.figure()
print([c.b[i] for i in range(5)])
[s.lower()[i:i + 2] for i in range(0, len(s) - 1, 2)]
self.stop()
test = Test()
results_data = results.get()
fig.add_subplot(211)
a = MyClass()
True
_zip.write(in_file)
bool([]) == False
suite
numpy.nonzero(a.max() == a)
bool(obj) and all(isinstance(elem, str) for elem in obj)
bd.sort(key=lambda d: (d.month, d.day))
lis = [1, [2, 2, 2], 4]
s.listen(1)
print(s[:index])
b = random.randint(0, 20)
z < t.isoformat()
print(dec_num == 511)
plt.plot(np.random.random(20))
cmyk_im = cmyk_im.split()
self.send_response(200)
df
contexts
self.left.pop()
root = Tk()
shape.append(len(l))
bounded = numpy.hstack(([0], bits, [0]))
a.set_ylim(-1.1, 1.1)
plt.scatter(x, y, zorder=1)
ax = fig.add_subplot(1, 1, 1)
new_list1.append(i[0])
-g595x842
sqlc = SQLContext(sc)
inters = successives1.intersection(successives2)
w.seek(8)
my_model = MyModel()
self.root.clipboard_clear()
atexit.register(close_database)
owner = serializers.IntegerField(required=False)
print(magicInput[2:4])
newlist.append(i)
path.append(parent[path[-1]])
df = pd.DataFrame(a.T)
b[:, (0), (0)] = t2
pnormal = p.convert(domain=(-1, 1))
df2.letter.unique()
plt.setp(cm.ax_heatmap.yaxis.get_majorticklabels(), fontsize=6)
map(itemgetter(1), groupby(iterable, key))
random_numbers()
a.append(1)
dd = datetime.date(2009, 12, 9)
print(row[0], row[1], row[2])
query = users.select().order_by(-users.c.id.desc())[:5]
conn.setblocking(0)
print(line)
img1y = img1.shape[0]
dom = ET.parse(io.BytesIO(content))
assert np.all(new_data == data)
plt.axis([x.min(), x.max(), y.min(), y.max()])
value = getattr(value, v)
ax = fig.add_subplot(111, aspect=1)
solution = [int(x) for x in solution]
layout.addWidget(self.plot)
random.shuffle(results)
example[4:0]
len(j) - len(set(j))
print(output)
normed.mean(axis=1)
_quicksort(array, start, right)
tree = html.fromstring(text)
rows = [row for row in reader]
axes[1, 1].pcolormesh(xi, yi, zi.reshape(xi.shape))
TRUE
self._reader2 = reader2
total += 1
len(l)
[[1][0][0]]
self.send_blob(blob_key)
self.maxSlider.SetValue(self.minSlider.GetValue() + 1)
all(type(i) is int for i in my_list)
p.map(Processor(credentials), list_of_data)
besterr = thiserr
pool.join()
fig = PLT.figure()
self.label = QtGui.QLabel(self)
print(get_jsonparsed_data(url))
histo = np.histogram(X, bins=5, range=(m, M))[0]
val += 1
ax.legend(scatterpoints=1)
today = datetime.date.today()
df.a.quantile(0.95)
p2.start()
globals()[attr] = getattr(foo, attr)
plt.show()
arr[0]
post_save
time.sleep(1)
meta.reflect(bind=engine)
title, ext = os.path.splitext(os.path.basename(pathAndFilename))
e.delete(0, END)
cmp(list1, list2)
screen = pygame.display.set_mode((800, 600))
nums.pop(i)
manager.shutdown()
pylab.show()
print(h.name, h.hexdigest())
np.bitwise_and.reduce(b) == b[0]
str(counter - 1)
f.close()
True
d = {v[0]: (v[1:] if len(v) > 2 else v[-1]) for v in list(d.values())}
a.show()
heapq.heapify(items)
self.label.setPixmap(myScaledPixmap)
[1, 2]
Test - app
old_settings = termios.tcgetattr(sys.stdin)
yNew = -(x - x0) * sin(theta) - (h - y - y0) * cos(theta) + (h - y0)
form.field(**attrs)
print(config.CONF_VAR1, config.CONF_VAR2)
np.ix_([0, 1], [0, 1])
cursor = self.connection.cursor()
self.updateGUI()
now = np.datetime64(datetime.datetime.now())
df = df[cols_of_interest]
DictInsensitive(csv.DictReader.next(self))
Unpickler(file).load()
self.log.append(data)
data[0, 0]
beginy = 0
[0, 1, 1, 2, 4]
fp.write(part.get_payload(decode=True))
foo(*pair)
sys.getsizeof(a)
F = np.matrix(list(itertools.product([0, 1], repeat=n))).transpose()
__init__.py
self.submitButton.grid()
itertools.zip_longest(fillvalue=fillvalue, *args)
print(df)
mydict = {k: v for k, v in key_value}
zeros1 = zeros[:, 1:-2]
print(timer.timeit())
reader = csv.DictReader(f)
print(np.array_str(x, precision=2, suppress_small=True))
bit_array = bitarray(6000000)
gobject.threads_init()
host.set_ylim(0, 2)
succs = [[] for i in range(n)]
print(tostring(e, encoding=str))
print(soup.html.contents[0])
p = Process(target=do_work, args=(work, results))
line = self.buf.readline()
func(*args)
entry_list = (entry.title.text for entry in feed.entry)
idx = np.where((A > 2) & (A < 8))
ws.column_dimensions = {}
conn.perform()
p.setopt(pycurl.WRITEFUNCTION, devnull.write)
process = BlackScholesMertonProcess(S, q, r, sigma)
self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
self.send_response(200)
dist = min(dists)
data = file.readlines()
cookiejar = cookielib.LWPCookieJar()
print(sum(muls))
s = socket(AF_PACKET, SOCK_RAW)
[type(i)() for i in lst]
L = sorted(list(d.items()), key=lambda k_v: k_v[1][1])
dbapi_con.commit()
x = tup[0]
fig, ax = plt.subplots()
writer = csv.writer(f)
plt.colorbar()
opener.open(a_url)
self.timer = QTimer(self)
list(bucket.list_versions())
l2 = [1, 4, 5]
f = open(f)
fig, ax = plt.subplots()
plt.plot(list(range(10)))
HttpResponseRedirect(reverse(contact_details, args=(new_contact.pk,)))
pickle.dump(network, p_output)
urllib.request.urlretrieve(each, filename)
m = Model1.objects.filter(desadder=1)
foo.__doc__
self.runner = QProcess(self)
config_path = get_xdg_config_home()
nosetests()
script_dir = os.path.dirname(__file__)
plt.show()
do_someting()
df[(df.one == 1) | (df.two == 7)]
lowest_dirs.append(root)
new_columns = df.columns[df.ix[df.last_valid_index()].argsort()]
socket.send(me, zmq.SNDMORE)
self.connect()
NULL
1, 0, 2
obj.main()
s.indices(len(t))
self.outstream.write(self.theB)
list(range(ifnone(item.start, 0), item.stop, ifnone(item.step, 1)))
yourbutton.pack()
math.pi.as_integer_ratio()
m_2 = file_like_io.readlines()
module_b.py
phonenumbers.format_number(parsed_number, phonenumbers.PhoneNumber())
diam = np.empty(200)
dish.id = restaurant_dish.dish_id
B[i] = elem
np.median([0, 0, 2, 6, 5])
print(urlobj.readlines())
ip = IPython.get_ipython()
matchlist = re.findall(pattern, str)
print(probs.sum())
0.47685844, 0.44894925, 0.50727844, 0.45076198, 0.44977095, 0.41455029
dom = ET.parse(xml_filename)
dict_list = zip(list1, list2)
cumulative_histo_counts = histo[0].cumsum()
x = arange(0, 2 * pi, 0.01)
primes.append(i)
m[1, 2]
[[1.0][1.0][1.0][1.0][1.0][1.0][1.0][1.0][1.0][1.0]]
b = np.array([1, 4, 5])
z = x.add(y)
pool = Pool(processes=4)
self.hbox.pack_start(self.hlpass, False, False, 0)
App.get_running_app().stop()
new_ring = LinearRing(new_pol.exterior.coords)
outputStream.close()
relative = os.path.relpath(path, directory)
lambdas_list.append(build_lambda(obj))
ax.plot(theta, r)
lastX, lastY = x, y
df
tags = django.forms.MultipleChoiceField(choices=known_tags, required=True)
f.close()
p.start()
ob = MyClass(a=1, b=2)
myFile.close()
setattr(self, key, FakeSudsNode(value))
path = os.path.join(path, word)
SupportsDTRDSR = TRUE
SupportsRLSD = TRUE
SupportsRTSCTS = TRUE
app = QtGui.QApplication(sys.argv)
result[i].append(next(iterator))
fig.multi_line(x_err_x, x_err_y, color=color, **error_kwargs)
print(parser.parse_args())
self.cookie.load(string_cookie)
MyDiccoSorted = sorted(list(MyDicco.items()), key=myKey)
print((foo, bar))
stext.focus_set()
deletedict_del[k]
rows.append(data[field])
thefile.seek(0, 0)
toYearFraction(dt.today())
ticks = np.arange(x.min(), x.max(), 6)
str(BeautifulSoup(html[:length]))
np.where(abs(arr_f - a) < t)[0]
fig = plt.figure()
print(a.__code__.co_firstlineno)
sys.stdout.write(line[1:])
cb.formatter.set_powerlimits((0, 0))
genn(igap, igap - 1)
ret = [row[0] for row in ret]
dis_vectors = [(l - r) for l, r in itertools.combinations(points, 2)]
sizer.Add(self.fileTextCtrl, 1, wx.EXPAND | wx.ALL, 5)
self.losses = [1, 1]
obj = db.get(obj_key)
groups.apply(lambda x: count_consec_dates(x, start_date))
any(isinstance(e, int) and e > 0 for e in [0, 0, 0])
r = redis.StrictRedis()
root.lift()
print(2 * p)
y.append(dict(list(i.items()) + list(j.items())))
outlist.extend((i, other[0]) for i in ids - known)
ax.xaxis.set_visible(False)
f = urllib.request.urlopen(url)
profile = webdriver.FirefoxProfile()
print(i, j, k, v)
ax.set_xlim(date_min, date_max)
res = [np.array([f1(1, 5), f2(2, 6)])]
label.setPixmap(p)
signal.signal(signal.SIGALRM, signal.SIG_IGN)
next(f)
can.place(x=200, y=200, anchor=NW)
reset_index()
re.split(regexPattern, string, maxsplit)
key, value = map(int, line.split())
id = Column(Integer, primary_key=True)
tree.add(8)
sys.exit(app.exec_())
np_spiky = np.vectorize(spiky)
size = models.IntegerField(blank=True, null=True)
seed(42)
output = mp.Queue()
label_data = np.random.randint(0, 2, (10, 5))
data.append(random.random())
arr[np.ix_(rows, cols)]
A = matrix(A)
minimal(s, len)
self.settimeout(10)
g.apply(lambda x: g.loc[~x.isin(df1[x.name]), x.name])
sqmdist = np.dot(np.dot(xdiff, Sigma_inv), xdiff)
print((x.itemsize, x.nbytes))
predicted = classifier.predict(X_test)
m.EM(data, 40, 0.1)
p1.stdin.close()
print(groups.mean())
architecture / architecture
a = 1 / (2 * std1 ** 2) - 1 / (2 * std2 ** 2)
union_set = set.union(*l)
X = pd.concat([X.iloc[-shift:], X.iloc[:-shift]])
np.set_printoptions(precision=2)
csv.writer(output).writerow(x)
h = np.exp(-(x * x + y * y) / (2.0 * sigma * sigma))
print(df)
func = getattr(self, func_name, func_not_found)
venues.sort(key=getRanking, reverse=True)
False
list(range(first_number, last_number + 1, step))
signal.alarm(5)
strcat(greeting, excla)
0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0
plt.ylim((0, 10))
QWidget.__init__(self)
os.open(os.devnull, os.O_RDWR)
df.High.cummax()
print(np.argmax(a))
self.response
a = [True, True, True, True]
id = Column(Integer, primary_key=True)
my_date = date.today() - timedelta(days=days_to_substract)
index.indices(self.size)[:2]
mask_borders = np.where(img == 0, True, False)
tick_locator = ticker.MaxNLocator(nbins=5)
print([[k, c_sum[k]] for k, v in c_len.items() if v > 1])
classifier.fit(X_train, Y)
sftp = ssh.open_sftp()
buffer.close()
_harden_stdout()
[_f for _f in map(func, collection) if _f]
cleaned_data.update(form.cleaned_data)
fig.set_size_inches(18.5, 10.5)
start_date = datetime.datetime(year=2010, month=1, day=4)
tornado.web.Application.__init__(self, handlers)
a.all_coeffs()
C[1::2, :] = B
l._legmarker.set_ydata(l._legmarker.get_ydata()[1:2])
top5 = itertools.islice(array, 5)
postalcode = models.CharField(max_length=10)
df2
names = pd.append(names, frame, ignore_index=True)
words = list(text.split())
counter = np.sum(id_arr.cumsum())
r[ind1].append(v)
K = [1, 10, 2, 4, 5, 5, 6, 2]
fn = os.path.join(path, name)
plt.xlim(0, complete_longest)
output = fp.getvalue()
root_logger.addHandler(root_log_handler)
out = json.dumps(error_dict)
b = a.reshape((5, 2))
app.login_manager.unauthorized()
foo = urllib.request.urlopen(url, data)
os.remove(fname)
_, keep_this, _ = f()
{word: list(neighbours(word)) for word in words}
fig = plt.figure()
l.append(o)
X = data[:, 1:]
types.MethodType(func, obj, type)
my_ints[i] = a[i]
np.repeat(x, arrivals)
[4, 5, 6]
inspect.getargspec(foo)
newZip.writestr(attr, os.readlink(filePath))
sess.run(max_norm_ops)
xslt = ET.parse(xsl_filename)
a = [1, 1, 2, 4, 4]
(db.table.field1 == x) & (db.table.field2 == y)
plt.ion()
process(line)
ukol1.SummaryFormula()
c.setopt(pycurl.WRITEFUNCTION, b.write)
C.append(b_item)
imputed_array
time.sleep(10)
deletedf[df.columns[0]]
y, x = np.ogrid[-a:n - a, -b:n - b]
pd.DatetimeIndex(df.date) + pd.DateOffset(1)
response
print(chessgame.get_moves())
print(dict(zip(headers, values)))
obj.username == request.user.username
test = [([0.0] * 10) for _ in range(10)]
myPlot.set_ylim(1, 5)
print(mappings)
any(map(partial(contains_nested, elmnt=elmnt), some_iterable))
np.arange(N).reshape(shp).T.ravel()
self.val = 1
print(user.message)
self.response.out.write(jsonpickle.decode(encoded).__class__)
logging.getLogger().setLevel(logging.DEBUG)
df = pd.DataFrame(X, columns=vect.get_feature_names())
shared_settings.py
Py_XDECREF(instance)
X, Y = np.meshgrid(x, y)
L = [1, 2, 1, 1, 1, 1, 1, 1]
s[:match.start()]
self.edit = QtGui.QTextEdit()
m.update(f.__name__)
time.sleep(1)
print(np.dot(x, y).shape)
self._chips = 10
file.close()
list(NestedDictValues(a))
x, y = map(int, matchobj.groups())
module_ok = False
parser = argparse.ArgumentParser()
fig = plt.figure()
ptr[0] = color[0]
partials[-1].append(element)
self.__dict__[key]
setattr(Test, name, mark)
f_new.write(add_text)
raw_data = json.load(f)
self.d[num] = 1
list(zip(x, d))
gen = (x for x in xyz if x not in a)
i += 1
locals()
print(base.__name__)
fig.colorbar(surf, shrink=0.5, aspect=5)
getattr(self._ref1, name)
print(sys.getsizeof(mydict_as_string))
os.chdir(curdir)
sleep(0.01)
DIRNAME = os.path.dirname(__file__)
df.set_index(df.select_dtypes(include=[np.datetime64]).columns.tolist())
self.i = i
raise StopIteration
r = requests.post(login_url, cookies=jar, data=acc_pwd)
partial(evalsymbexp, symbexp=symbexp)
attrs_present = [x for x in a_list if hasattr(a_obj, x)]
stdout, stderr = p.communicate()
signal.signal(SIGTERM, SIG_DFL)
mapper(ActualTableObject, table_object)
self.assertTrue(row[1][0] == counts[index_row][1])
self.serv.close()
inputsList = [str(i) for i in range(20)]
foo, bar = zip(*sorted(zip(foo, bar)))
print(repr(pBuf.value))
wrap_process(i)
form = br.form
NULL
root.text_content()
Foo.instance_count += 1
result = [o for o in list1 if o in diff]
platform.uname()[4]
browser = webdriver.Firefox()
readline.set_startup_hook()
lib.stringfree(p)
self.cbar.draw_all()
int(aString)
o.close()
child.expect(pexpect.EOF)
f()
file.close()
pythoncom27.dll
pool = mp.Pool(mp.cpu_count() + 2)
self.Destroy()
f.write(urlopen(tempurl).read())
s = f.read()
sqrt(x ** 2 + y ** 2)
db.create_all()
print(text)
plt.figure()
x, y = np.linspace(x0, x1, length), np.linspace(y0, y1, length)
width, height = image.size()
print(is_true(y) or is_false(y))
prop1 = db.string
t2.test()
tree = ElementTree.parse(StringIO(string))
stat.S_ISREG(os.fstat(sys.stdout.fileno()).st_mode)
os.getuid() == 0
sp.communicate()
p.wait()
[6, 5, 4, 5, 6, 7, 6, 5],
result.append(foo(x))
user = models.ForeignKey(User)
os.close(in_fd)
msvcrt.setmode(sys.stdin.fileno(), os.O_BINARY)
row = []
svec = [a[rank] for rank in ivec]
d = Image.objects.filter(**kwargs)
fig = plt.figure()
credentials = session.get_credentials()
list1, list2
mat_vals = np.vstack(listvals)
br.set_cookiejar(cj)
mylist.insert(0, last_el)
mdat = np.ma.masked_array(dat, np.isnan(dat))
root = tk.Tk()
print(settings.INSTALLED_APPS)
aClk.start(), numpy.power(c, 2), aClk.stop()
list(d.items())[0]
user = User.objects.create(**validated_data)
clusterList = list(clusterList)
m.search(line)
y_copy = y[:]
re.sub(to_be_replaced, lambda x: random.choice(items), string)
myList.append(name)
parseXMLFromLink()
bool(set(a) & set(b))
counts[n] += 1
setattr(self, k, v)
outputfile.writelines(data_parser(line, reps))
sys.exit(app.exec_())
p = Point(x, y)
v = mahotas.convolve(r - w, pattern)
diamond = 2
self.value = value
map(lambda x: x * 2, args)
contents = f.read()
db = SQLAlchemy()
widget.show()
current_value = next(a)
Ainv[i] = np.linalg.solve(A[i], identity)
plot([40, 50, 60])
df = DataFrame(np.random.randn(10, 2))
fig = plt.figure()
tm += datetime.timedelta(minutes=5)
data = np.random.random((height, width, numframes))
a.insert(lo, x)
DD = datetime.timedelta(days=90)
gevent.sleep(0.5)
[x for x in self]
string = remove_last_line_from_string(string)
xl.sheet_names
soup.html.findAll(text=True, recursive=False)
succs[u].append(v)
unmatched.remove(element)
doc = etree.ElementTree(root)
parser2 = argparse.ArgumentParser()
self.sslobj = ssl.wrap_socket(self.sock, self.keyfile, self.certfile)
L.insert(index, object)
ax.axis([min(x) - 1.0, max(x) + 1.0, min(y) - 1.0, max(y) + 1.0])
jpgs.sort()
ordered = [e for e in ordered if e in unord]
time.strftime(locale.nl_langinfo(locale.D_T_FMT), time.localtime())
html_source = browser.page_source
args.append(parser.parse_expression())
min(max(bottom, num), top)
conn.close()
heap = [(-value, key) for key, value in list(the_dict.items())]
archive.close()
init_op = tf.initialize_all_variables()
self.assertGreater(value, 0)
n == n[::-1]
logger.addHandler(logging.StreamHandler(sys.stdout))
ages = np.arange(100)
f.seek(p)
s.commit()
fig = plt.figure()
writer.writerow(rowinprot)
size = screen.GetSize()
sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
wx.Icon(sys.argv[0], wx.BITMAP_TYPE_ICO)
temp_dict[values[1]] = 1
base = os.path.splitext(thisFile)[0]
root.mainloop()
combined_decorator = compose(decorator1, decorator2)
print(df2)
df.ix[0] = df.ix[2]
X = np.array(X)
update_list(a)
test_suite.addTest(userservice_test.suite())
surf2.set_colorkey(TRANSPARENT)
requests.post(url, data, headers=headers)
seen = set()
g = tf.get_default_graph()
isinstance(N, int)
self.crawler.crawl(self.spider)
True
newpath = os.path.join(dstdir, os.path.basename(path))
print(yaml.load(f))
l.__code__.co_argcount
joystick.init()
fig = plt.figure()
date_of_appointment = models.DateField()
start_time = time.time()
fsb_frame.Show()
driver.get(web_address_desired)
str(s)
sentence_dict[word].append(prev)
reg = line.split()[2]
dec = decimal.Decimal(num)
isinstance(X, type)
chrome = webdriver.Chrome(chrome_options=chrome_options)
p.start()
a = [0, 0, 15, 17, 16, 17, 16, 12, 18, 18]
driver = webdriver.PhantomJS(service_args=service_args)
a = zeros((6, 8))
Session.add(target)
raise Exception()
L.append(a)
len(list(iterable)), -L.index(item)
Base.metadata.create_all(source_engine)
s.close()
data = json.loads(data)
coords = np.vstack([item.ravel() for item in [xi, yi, zi]])
groups[word[:-1]].append(word)
(m + np.random.randn() * s for _ in iter(int, 1))
ans = x / y
m = sock.recvfrom(1024)
queue.append(multiprocessing.Queue())
self.obtainingparams(df, tau_1, tau_2, residuals)
wb = xlwt.Workbook()
ax.xaxis.set_major_locator(copy.copy(Locator))
cur.executemany(insert_query, data)
a = 1
r[:6, :6]
sorted_B = numpy.sort(B)
a = np.arange(10)
print(grades.most_common())
reader1, reader2 = itertools.tee(csv.reader(f, delimiter=d))
curl.perform()
self.button.pack()
ax = fig.add_subplot(111)
process.crawl(EPGD_spider)
plot_res(fig)
f.__call__()
curdict[last_item] += 1
p.wait()
y = np.arange(10)
b = [2, 4, 2]
driver.get(url)
M = M[M.getnnz(1) > 0][:, (M.getnnz(0) > 0)]
ax = fig.add_subplot(111)
b.append(a[i])
np.array(U).argsort().argsort()
http_request = AbstractHTTPHandler.do_request_
bad_emails.append(email)
new_names = names[:i] + names[i + 1:]
smtp_server.close()
np.nanargmax(b, axis=0)
asyncore.dispatcher.__init__(self, socket)
newNums = (i for i, x in enumerate(nums) if x == 12)
print(s[0])
g.close()
print(array(data).reshape(*length))
data = f.read()
my_value = int(my_value)
list(os.environ.keys())
df = pd.read_csv(filename, index_col=0)
soup = BeautifulSoup(data)
lis[0]
self._max_workers += 1
f_old.close()
A[1][1] = 0
sys.getdefaultencoding()
reordered = tf.gather(a, tf.nn.top_k(a[:, (2)], k=4).indices)
d = os.path.getmtime(x)
pd.DataFrame(df.values[ge_start & le_end], df.index[mask], df.columns)
df.mask(mask)
cache.init_app(app)
myFile.myFunction()
suite.addTest(suitefn())
id_arr = np.concatenate((a[:, (0)], b[:, (0)]))
delta - datetime.timedelta(microseconds=delta.microseconds)
df = pd.DataFrame(d)
x = np.random.randn(100, 100, 100)
df.drop(rows_to_drop_indices, inplace=True)
output_df.sort_index(inplace=True)
main()
pandas2ri.ri2py(r[name])
value = blob_reader.read()
parentdir = os.path.dirname(currentdir)
abortable_async_result.abort()
pos = nx.spring_layout(G)
print(x)
self._dictionary[key]
j2 = [x for x in j if x >= 5]
x1[np.where(x1 == input_array.shape[0])] = x0.max()
a = datetime(2011, 11, 24, 0, 0, 0)
mynums = map(int, s.split())
sess.run(outputs, feed_dict=feed)
plt.show()
print([x for x in g if x[2] >= 1.5])
request_headers = {}
print(myconstants.MY_CONSTANT * 2)
sheet = book.sheet_by_index(0)
np.round([6.50000001, 6.5], 0)
driver = webdriver.Firefox(profile)
l.append(5)
b = [4, 5, 6, 7]
fib(1000)
documentation.rst
i[1] * 256 + i[0]
scriptDirectory = os.path.dirname(sys.argv[0])
print(textwrap.fill(text, width=40))
ocsp_url.strip()
df.drop(df.columns[-1], axis=1)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
s.send(dst_addr + src_addr + ethertype + payload + checksum)
gc.collect()
[(lambda x: np.square(np.dot(x, -1 * x)))(x) for x in items]
print(df)
Z.append((a, B[i % len(B)]))
theobject = ast.literal_eval(thestring)
self.queue = mp.Queue()
inputs = tf.nn.embedding_lookup(embedding, input_data)
root = Tk()
mux41(0, 1, 1, 0)(a, b)
java.awt.Toolkit.getDefaultToolkit().beep()
CERTAIN_PERCENTAGE = 100 * (float(new_item) / sum(vari))
arr = numpy.zeros((50, 100, 25))
bk.show(p)
fig, axes = plt.subplots(nrows=2, ncols=2)
print(l)
str(self.val)
raise Error(key)
a.pop(e)
match.group(2) + match.group(4)
some.dothis()
col_nonzeros = np.bincount(m.indices)
render_response()
app = Flask(__name__)
main()
s = np.sqrt((dp ** 2).sum(axis=0))
mongo.init_app(app)
fig.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)
print(im.size[0], im.size[1], white, black)
print(unicode_obj)
f = urllib.request.urlopen(url)
n, b, v = j[4:7]
self.f.write(data)
day_list.index(inp)
x, y = mask.nonzero()
df.y[0].shape
item.son = sons
a = [[1, 2], [4, 5, 6], [], [7, 12, 14, 16]]
time = np.linspace(0, 10, 2000)
shutil.rmtree(tempdir)
output = ps.communicate()[0]
ax = plt.subplot(111)
mime_msg = email.message_from_string(msg_str)
self.hide()
c = [i for i in range(len(A) - n + 1) if (b == A[i:i + n]).all()]
fruit_query = fruit_query.where(filtername == filtervalue)
bucket.delete_key(version.name, version_id=version.version_id)
fig = plt.figure()
print(files)
numpy.fromstring(s)
parser.feed(line)
f.seek(0)
repr(0.1)
A = np.random.rand(5, 2)
glist.sort()
df.dot(df.columns)
f.write(copied_file)
plt.show()
i.close()
acc = numpy.zeros(data.shape[:2])
1 - np.array([[pearsonr(a, b)[0] for a in M] for b in M])
counts_it = itertools.chain(*(iter(c.values()) for c in data.values()))
Fraction(0.25)
df
all_chars = (chr(i) for i in range(1114112))
f = plt.figure()
conn.close()
len(s2)
mainFrame = Tkinter.Frame(root)
x.append(5)
m.group(1)
app = Flask(__name__)
x.append(contour[0][0])
len([x for x in myList if x in myDict]) > 0
adjustment_writer.write()
MyShell().cmdloop()
args = opt.parse_args()
self.hello()
self.y_list[i] + self.slopes[i] * (x - self.x_list[i])
f.pack_propagate(0)
plt.subplots_adjust(right=0.8)
xc(os.path.join(dirpath, f))
fig, ax = plt.subplots()
headers.append(header)
ser.update(df)
os.chdir(tmpdir)
logger.addHandler(handler)
TEXTO = sys.argv[1]
[(a[-i // 2] if i % 2 else a[i // 2]) for i in range(len(a))]
codeop.compile_command(line)
count += 1
dlg.Show()
np.hstack((first, rest))
b = dict(zip(*reversed(zip(*list(a.items())))))
d[index]()
configParser.read(configFilePath)
any(x in sbigger for x in smaller)
response
max_idx = l.index(max_val)
rand_key = d[take_nth(list(d.keys()), random.randint(0, len(d) - 1))]
scons - -pymod
output += 2 * np.sum(integrand(a + h * np.arange(2, num - 1, 2)), axis=1)
print(key, value)
sha5sum
temp.remove(item)
s.setsockopt(socket.SOL_TCP, socket.TCP_KEEPIDLE, 1)
first.replace(month=first.month + 1, day=1) - datetime.timedelta(days=1)
self.z.append(self.a[-1] * weight)
print(vars(cls))
nx, ny, nz = sin(theta) * cos(phi), sin(theta) * sin(phi), cos(theta)
random.shuffle(l)
response = HttpResponse(f.read())
print(pivot[:5])
sys.exit(app.exec_())
sys.getrefcount(x)
data.append(data_item)
functools.partial(self, obj)
sum(_counter(d))
np.random.seed(101)
els[0]
gr2.switch()
self.map(lambda x: x * x)
writer = csv.writer(response)
dd = copy.deepcopy(d)
a.dump()
output = stdout.read()
tf.logging.set_verbosity(tf.logging.ERROR)
df = pd.concat([df] * 10000).reset_index(drop=True)
self.edges = {}
x[np.mod(np.arange(x.size), M) < N]
collections.defaultdict(tree)
result = func(*args, **kwargs)
form
p.terminate()
self.setSizePolicy(QSizePolicy.Preferred, QSizePolicy.Preferred)
t.getroot().text
[x for x in lst if x.isalpha()]
blocks.append(f.read(block_end_byte))
p = subprocess.Popen(cmd, stdout=subprocess.PIPE, shell=True)
print(sys.version)
self.after(1000, self.onUpdate)
conn = db.get_connection()
thread = threading.Thread(target=process)
p1 = ctypes.c_int(1)
arbiter.stop()
instance_b_placeholder = models.ForeignKey(A, null=True, blank=True)
strnumbers = file.read().split()
a[:], b[:] = zip(*combined)
ast.literal_eval(a)
model.Bar()
mainloop()
my_thread.start()
arr.resize((k, M))
self._writecheck(zinfo)
sys.exit(main(sys.argv))
device_props = dbus.Interface(device_obj, dbus.PROPERTIES_IFACE)
plt.show()
input.close()
fileMenu = tk.Menu(menubar, tearoff=False)
print(next(x))
result = np.empty((2 * N + 1, 2 * N + 1))
pyglet.app.run()
len(perms)
print(paths[0][0])
result[key] = value
do_stuff_with(slog)
df.stack().nlargest(1)
title = Column(String(200), nullable=False)
burroughs_wheeler.test(100)
g.bar(1)
print(tn.read_all())
setattr(self, n, v())
raise ValueError(modname)
a = np.array(a)
signal.alarm(0)
ax2.set_ylabel(ylabel)
self.splitter.addWidget(self.inspector)
self.sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
SITE_ROOT = os.path.dirname(__file__)
match = [x for x in range(len(l) - 1) if l[x] == 165 and l[x + 1] == 90]
plt.plot(list(range(10)))
obj[key]
b = [2, 4, 2]
fig, ax = plt.subplots()
mydict[search_age]
print(save_data.value)
len(spam)
map(lambda x: f(fixed, x), thelist)
help(obj.myfuction)
m = myre.match(s)
[c for c in col_names if all(f not in c for f in filter_array)]
a = np.arange(10)
self.assertEqual(42, self.widget.foo())
result
f.write(value)
x = df[pd.isnull(df[col])].index.astype(float).values
easydiff2[0] = 0
arr.T.shape
data.head()
list(range(diamond - 1, -1, -1))
self.setLayout(self.vbox)
basetwo = partial(int, base=2)
time.sleep(15)
list(pair_iter)
new_lists[list_index].append(i)
painted_map.save(sys.argv[2])
df = pd.read_csv(StringIO(txt), delim_whitespace=True)
json.loads(text)
f.close()
t.start()
a * b
cur = con.cursor()
hsizer = wx.BoxSizer(wx.HORIZONTAL)
id = Column(Integer, primary_key=True)
lib.find_vertex(vertices, len(vertices), lower, higher)
foo(*list(vars(args).items()))
plot(img50_order1[(50), :, (1)])
HiPRIOpoller = zmq.Poller()
response
DBSession.begin()
variance = sqr.sum() / N - col.mean() ** 2
sample.sum()
delta.total_seconds()
print(df_concat.mean())
settings.configure()
left, right = ax.get_xlim()
print(new_list)
parser = argparse.ArgumentParser()
as_to_b = a.searchsorted(b, sorter=a_to_as)
str(output[0])
c.close()
assert a.average() == 1
func(s)
cap = cv2.VideoCapture(0)
Base1.bar()
sio.close()
f = urllib.request.urlopen(req)
demandimport.enable()
self.frame = wx.Frame(parent, title=title, size=size)
r = scipy.sqrt(x ** 2 + y ** 2 + z ** 2)
func_results.append(child(*args))
self.assertGreaterThan(len(foo.config.getboolean(str(), str())), 0)
print(myutilities.gen_hex_colour_code())
hello()
sys.stderr = dummyStream()
im = Image.open(sys.argv[1])
root = Tk()
a[:len(idx)] += idx
plot(f(a, b))
df = DataFrame(dict(x=[0, 0, 1, 0, 1], y=[1, 0, 1, 1, 0], z=[0, 0, 1, 0, 1]))
cursor = conn.cursor()
print(hello())
pl.show()
img.seek(n)
cv2.line(img, (x1, y1), (x2, y2), (0, 0, 255), 1)
print((x, y))
stdin, stdout, stderr = channel.exec_command(command)
print(list(next(it) for it in itertools.cycle(iters)))
d[row_key][idx] = col
np.vstack((rlin * first, np.power(rlin, second)))
open(path).readlines() if opath.exists(path) else []
self.__setitem__(key, value[key])
column1.append(column.split(data_separator)[0])
r += 1
page.SetSashGravity(0.5)
result.setdefault(value, []).append(value)
a.get_x(True)
result = []
nosetests - -help
c.showPage()
test()
print(longest_sum([1, 1, 1, 1, 1, 1, 4], [], 6))
a[0][1] = 9
f.seek(-4, 2)
scipy.sparse.csgraph._validation
bucket = conn.get_bucket(bucket_name)
print(iorf.fup(2.5))
AB = map(sum, zip(A, B))
file.truncate()
login(request, user)
do_quit(args)
main.py
vobj.prettyPrint()
my_dict
end_pts = sorted([a_left, a_right, b_left, b_right])
self.type.get_declaration().is_anonymous()
np.all(np.all(arr == arr[(0), :], axis=1))
merge(a[key], b[key], path + [str(key)])
unique_char_count = len(unique)
my_table = table()
self.console.close()
audio.save()
serial_port = serial.Serial(port, baud, timeout=0)
print(cookie.name, cookie.value, cookie.domain)
Example.__subclasses__()
ical_atch.set_payload(ical)
f = requests.get(link)
print(line)
self.driver.get_screenshot_as_file(file_path)
out.append(item)
cPickle.dump(self.__dict__, f, 2)
d.seconds + d.days * 86400
cls._current_instance
next(f)
plt.show()
self.name = name
word = list(word)
bisect.bisect == bisect.bisect_right
self.hello()
[(x + num) for num in y]
bytearray(f.read())
row_count = len(data)
d = np.random.randint(n, size=k)
df.dtypes
len(s) != (s.add(x) or len(s))
Xtranspose = X.transpose()
print(sys.stdin.fileno())
a1, b1, c1 = (a[i] for i in idxs)
plt.plot(x_val, y_val)
self.cool_dict[attr] = value
print(model._meta.db_table)
print(chr(c))
parser = argparse.ArgumentParser()
Thread.__init__(self)
print(result)
parser = argparse.ArgumentParser()
dy = 0
list(links).sort(key=lambda x: (x[1] - 1) / (x[2] + 2) ^ 1.5)
self.transport.write(msg)
results = p.map(do_work, payloads)
root.withdraw()
resp.read()
scalify([(a + 1) for a in args])
assert self.test_user.__unicode__() == self.username
self._running = True
multiprocessing.freeze_support()
df.dtypes
df = df.ix[:, (cols)]
Base.metadata.sorted_tables
print(fmt.format_map(data))
plt.hist(bootstrapped_scores, bins=50)
view_func(request, *args, **kwargs)
pair = frozenset([element1, element2])
x_dt = [datetime.datetime.combine(my_day, t) for t in x]
uncompressed_path = os.path.join(FILE_DIR, fname)
widget.show()
profile = graph.get_object(user)
validate(yaml.load(good_instance), yaml.load(schema))
GENERATE_MAN = NO
GENERATE_RTF = NO
i = df.index.values
x.boxplot()
od[a].append(b)
types.TypeDecorator.__init__(self, length=self.impl.length)
hash((self.x, self.y))
new_contact = form.save()
velcro.left(90)
r = [[i for i in d[x]] for x in list(d.keys())]
print(L)
fig, ax = plt.subplots()
platform.machine()
name = models.CharField(max_length=25)
df
k.fit(X[:, (i)])
nbrs.kneighbors(X)
print(i)
channels = session.query(Channel).all()
CM = np.zeros_like(data)
draw = ImageDraw.Draw(image)
len(cPickle.dumps(a > 10))
np.column_stack(np.unravel_index(idx, lon.shape)).tolist()
Maemo5Spec()
df = pd.concat([df.iloc[:, :4], df.iloc[:, 4:]], keys=(1, 2), axis=1)
self.text.grid(row=0, column=0, sticky=(N, S, E, W))
self.data.append(node.name)
plt.plot(x)
fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(8, 8))
a = np.array([2, 6, 12, 20, 24, 40, 42, 51])
fd.close()
line = p.stdout.readline()
n.activate((2, 2))
fig = plt.figure()
stdout = sys.stdout
fig, ax = plt.subplots(1)
inverted_image = PIL.ImageOps.invert(image)
parser.parse_args(cmdline, namespace=namespace)
plt.scatter(x, y, zorder=2)
axes[0, 1].hexbin(x, y, gridsize=nbins)
target_vertex = graph.vs[target_vertex_id]
bins = np.linspace(math.ceil(min(data)), math.floor(max(data)), 20)
sum(list(takewhile(lambda x: x < 4000000, evenfibs)))
log_file.close()
pygame.camera.list_camera()
self.label.installEventFilter(self)
print(df2.CET.dtype)
[x[:-1] for x in test]
tex.see(tk.END)
assert np.allclose(p1, p2)
lists.append(line.rstrip().split())
sys.exit(1)
print(value)
random.getrandbits(64)
proc.wait()
[v for group in list(result.values()) for v in group]
de.clicked.connect(self.clicked)
merged = merge(string1.lower().split(), string2.lower().split())
process_event(e)
self.__dict__ == other.__dict__
axes = fig.add_subplot(1, 1, 1)
ard.flush()
d[i] += 1
x16 = []
str.__new__(cls, arg)
y = []
panel = wx.Panel(frame, -1)
self.scrollbar.set(*args)
print(pd.concat([df[mask], df[~mask]]))
table.sort(reverse=True, key=Team.getGoalDifference)
self.variables[attr].append(d)
mysend(s, str(i))
Thread.__init__(self)
dt = utc_dt.astimezone(tz)
a = np.array(a)
pool.close()
plt.show()
setattr(self, key, True)
print(data.shape)
self._var0 = 0
requests_api(uri, params=params, cookies=cookies, headers=headers)
ax.plot(np.arange(0, i * 4, i))
react(main)
draw = ImageDraw.Draw(im)
soup = BeautifulSoup(response)
a[abs(a) <= 100]
plt.xlim([-l / 2, l / 2])
im_rgb.putpixel((x, y), (b, g, r))
Thread.__init__(self)
book = xlwt.Workbook()
new_list = np.delete(myList, toRemove)
self.form_invalid(form, **kwargs)
line = proc.stdout.readline()
conn, addr = server.accept()
numpy.random.shuffle(all_idxs)
f2()
map(operator.itemgetter(0), L)
df = pd.DataFrame(c)
len(y)
gunicorn_django - c / path / to / gunicorn_settings.py
User.objects.all()
a = np.array([[1, 2], [1, 2]])
year % 4 == 0 and (year % 100 != 0 or year % 400 == 0)
mask = np.ones(A.shape[1], dtype=bool)
width, height = im.size
[programs[k] for k in result_keys]
print(l.data)
ax2.set_ylim(miny + dy, maxy + dy)
np.add.reduceat(a, [0, 4, 7])
do_something()
y = np.sin(x) + np.random.random(100) * 0.2
email.send(to, headers, body)
_install.run(self)
np.sin(x + y)
isinstance(99 ** 10, int)
rows.append((id, sc))
main()
df
locations = numpy.argsort(A)
b = p.map(func, a)
Form = QtGui.QWidget()
df
cursor = conn.cursor()
self.runner.start(command)
i += 1
soup = BeautifulSoup(xml_string)
sorted(list(range(len(vector))), key=vector.__getitem__)
str_list = [_f for _f in str_list if _f]
cipher = AES.new(key=secret, mode=AES.MODE_CBC, IV=iv)
[(x - 1) for x in constrained_sum_sample_pos(n, total + n)]
time.sleep(5)
sys.settrace(tracefunc)
max(sqrt(stddev / mode), 1) <= x <= sqrt(stddev / mode) + 1
mask[mask] &= x[mask] < -1000
gui.mainloop()
self.conditions = [helper(c, type, params) for c in self.conditions]
MULT(z, z, z)
df
complist = p.map(buildcomp, np.column_stack((VV1, HH1)))
da.focus_set()
pickle.dump(dictname, f)
s.lstrip()
mymodule.py
true
next(iter(d.items()))
d = d.get(k)
func(*args, **kwargs)
soup = BeautifulSoup.BeautifulSoup(htstring)
words = frozenset(chain(wordList[:1], wordList[2:]))
-W15 - -ignore < catalina.log
ax1.legend(h1 + h2, l1 + l2, loc=2)
parsed = urlparse.urlparse(url)
a = np.arange(10)
f(*args, **kwargs)
start_response(status, response_headers)
G.add_edge(1, 2)
poi.reset_index().plot.scatter(0, 1, ax=axes)
batch_request = gdata.spreadsheet.SpreadsheetsCellsFeed()
p = Popen(args, stdin=PIPE, stdout=PIPE, stderr=PIPE)
fp.close()
dict.__getitem__(self, closest_key)
browser.select_form(form_name)
main()
result[header.value].append(col.value)
main.py
log_auth_token(user.get_auth_token())
print(i)
layer
self.grammar = self.multilineCommands
f.seek(0)
plt.draw()
seen.add(obj.thing)
iren.TerminateApp()
fexdata = {}
c[0] is c[1]
l2.grid(row=1, column=0, padx=(10, 100))
d[c] += 1
print(enumerate(words))
fig = plt.figure()
C.shape
mask = np.array([True, False, True])
numpy.frombuffer(bytestream.read(4), dtype=dt)[0]
print(a_set.add(1))
names.add(func.__name__)
print(response.body)
a += b
os.makedirs(dirmk)
patch = ax.add_patch(patch)
next(combs)
confirmed = get_object_or_404(EmailConfirmed, user=request.user)
text = f.read()
m = numpy.random.random_integers(0, 1000000, (1000, 500))
app = wx.App(False)
result = [w for w in vocab if rx.match(w)]
mydict[mykey]
G.edges()
print([r for r in process_row(row)])
serversocket.bind((socket.gethostname(), port))
df[cols] = df[cols].ffill()
self.canvas.itemconfig(self.idImage, anchor=NW)
plt.show()
s.shutdown(1)
response = self.opener.open(url)
self.bar = bar
plt.hold(True)
type(s)
print(s.recv(256))
self.show_frame_in_display(image_path)
ax2.plot(xvals, xvals, linewidth=7)
Py_Initialize()
timeit[Model.objects.filter(date_created__gte=today)]
f.savez(array)
placemark.save()
df = pd.read_json(sys.stdin)
win.show()
handler.serve_forever()
self.transport.write(msg)
server.sendmail(FROM, TO, message)
response.write(xlsx_data)
iwantthis
frozenset(chain.from_iterable(L))
HttpResponse(str(deserialized))
signal.signal(signal.SIGALRM, handler)
reader = csv.DictReader(f)
foo.whatever()
x.hexdigest()
self.value = 1
tree = defaultdict(lambda : defaultdict(lambda : defaultdict(list)))
self.new_attr = 2
cdf_samples = np.random.uniform(0, 1, size=(100, 100))
ax.set_xlim(min_x, max_x)
count.most_common()[1]
X_train = np.concatenate((X_train, catVar), axis=1)
self.bell()
word.append(char)
data_loaded = pickle.loads(data)
lambda : _addup(n)
print(type(1, 2))
os.rmdir(dirname)
main()
row[:] = [row[i] for i in new_order]
file.seek(pos, os.SEEK_SET)
user.save()
ax = fig.add_subplot(111)
mask = np.random.randint(0, 2, size=Y.shape).astype(np.bool)
soup = BeautifulSoup(urllib.request.urlopen(url).read())
print(newurl)
ax.bar(x, y, width, color=c, label=lb)
-settings.py
result.append(attracted_point(p, attractor, f))
result
console_handler.setLevel(logging.DEBUG)
memoryview(s[0:]) < memoryview(s[1:])
bundle
len(self._list)
fh.setLevel(level)
image_path = os.path.join(mypath, each_file)
print([(a + b) for a, b in itertools.product(A, B)])
datetime(tzinfo=utc_offset(x), *args)
your_ip = f.read()
values = [f.get() for f in fields]
arr.append(x)
self.members.append(person)
loop.close()
f.close()
Year.append(row[0])
t2.start()
im = Image.open(StringIO(r.content))
items = deque([1, 2])
time.sleep(2)
db.session.add(user)
t1.start()
compressor.close()
a = np.zeros(shape=(5, 5), dtype=float)
panel = tk.Label(root, image=img)
ndarray = np.PyArray_SimpleNewFromData(1, shape, np.NPY_INT, self.data_ptr)
pool = Pool(processes=4)
L.append(i)
n // 1
result._fields
cc = socket(AF_INET, SOCK_STREAM)
fig = plt.figure()
element_list.append(json.dumps({key: element[key]}))
numpy.core.records.recarray
np.dstack((a1, b1)).transpose(2, 0, 1)
out_list.append([row.lat, row.long])
outGroup.append(n)
views.py
i += 1
y = np.random.randint(0, 10, size=(10, 2))
print(Foo.bar.__code__.co_varnames)
ax.plot_date(ts.index.to_pydatetime(), ts.data)
i += 1
outcsv.writerows(cursor.fetchall())
print(it[2:12:2])
word_list = [s.translate(remove_punctuation_map) for s in value_list]
cmp(x, y)
pycallgraph.start_trace()
print(row.to_frame().T)
keys = list(d.keys())
self.view.form_valid(self.form)
cam = VideoCapture(0)
str_list = list(filter(bool, str_list))
WANTS_DEACTIVATION = _WANTS_DEACTIVATION
DISABLE_DEACTIVATION = _DISABLE_DEACTIVATION
wavwriter.setframerate(fs)
upform = UserProfileForm(request.POST, instance=user.get_profile())
file_name = sys.argv[0]
a.f = types.MethodType(f, a)
all(x == y for x, y in zip(pattern, sequence))
raise exc_info[0](exc_info[1]).with_traceback(exc_info[2])
result = [productcode, amountentered]
result_array, result_variable = result
used.extend(set(x) for x in combinations(c, 2))
path = sys.argv[0]
outfile.write(infile.read())
print(id(S2))
fig, ax1 = plt.subplots()
sys.setrecursionlimit(10000)
new_dict[key] = recursive_dict_eval(evaled_value)
plt.show()
list1 = list(map(int, list1))
sorted(strings, cmp=strcoll)
queryset = get_books()
curs.execute(create_table_stm)
alexander2().sum()
c = Counter([i for j in trainY for i in j])
pdb.set_trace()
self.SetTopWindow(self.fr)
type(MyClass)
up.save()
app = Flask(__name__)
x = pd.DataFrame(np.random.randn(20, 5))
self.canvas = Canvas(self, -1, self.figure)
print(x.format(42))
len(data) - len(list(filter(is_surrogate, data)))
list(vars(Foo()).keys())
foo = pointer(temp_foo)
[0, 1, 0, 0, 0],
inverted_dictionary[new_key].append(key)
print(list(reader))
show()
ax.plot(t, s)
pid = os.fork()
print(line)
m = numpy.zeros((N, N))
sublime.set_clipboard(data)
ax.margins(0.1)
self.setGeometry(0, 0, 1024, 768)
print(x)
x += 1
xv, yv, zv = [i[j] for i, j in zip((x, y, z), indices)]
schedule_once(tasks.some_task_b, interval=120)
ax.set_xticks(xticks_minor, minor=True)
self.cond.wait(self.mtx)
X_rec = pca.inverse_transform(X_proj)
boxintprinter(value)
boxstringprinter(value)
boxsequenceprinter(value)
conf.py
s.close()
numpy.argsort(row)[-6:]
nukedir(path)
cPickle.dump(root.config(), f, -1)
result = func(*args, **kwargs)
plt.contourf(data, cmap=cmap, levels=[1, 4, 8])
sorted(tuples, key=lambda x: x[2])
[0.09558515, -1.96982215, -0.58196525],
df
html = str(soup)
df.dtypes
imshow(im)
index.exposed = True
self.fn(*args, **kwargs)
a = np.arange(20)
related_to_user = Room.objects.filter(content_type=ctype)
to_product.append([(k, i) for i in process(v)])
book = xlwt.Workbook()
c.save()
print(json.dumps(c, cls=AlchemyEncoder))
self.window = stdscreen.subwin(0, 0)
Depends(report, speed)
x1, x2, y1, y2 = 0, 0, 0, 0
termios.tcsetattr(file.fileno(), termios.TCSADRAIN, old_attrs)
ssh_handler(server, command=mycmd)
globals().update(pubattrs)
print(x[2])
s[end_of_leader:start_of_trailer]
query = query.filter(~table_a.id.in_(subquery))
labels = labels.reshape(c)
item2node[node].add_child(ch)
ws = wb.active
data_with_zeros.apply(divide, args=(data_with_zeros,))
json.dumps([dict1, dict2])
[map(counter.__getitem__, all_features) for counter in counters]
urllib.request.urlopen(*args, **kwargs)
lambda x: x.lower() not in stopwords
result.extend(flat(item))
ax = pyplot.subplot(111)
dumper.represent_dict(list(data.items()))
main()
id = Column(Integer, primary_key=True)
out_2.read()
os.kill(os.getpid(), signal.SIGTERM)
plt.grid()
results = table1.objects.exclude(field1__in=inner_qs)
ax.plot(xi, yi)
worksheet.write(row, col + 1, item)
object.__setattr__(self, attr, value)
urllib.request.install_opener(opener)
cur = con.cursor()
settings.setSupportZoom(True)
acids = [aminoacid[base] for base in sublist]
heap = [(v, k) for k, v in list(some_dict.items())]
fig.add_subplot(ax)
fp.close()
NotImplemented
findsubset()
t1 + pd.datetools.relativedelta(months=k)
stophttp.start()
m = hashlib.md5()
print(random.sample(d, num))
pylab.subplot(121)
x, y = np.mgrid[:nr, :nc]
df = pd.concat([df for _ in range(100)], axis=1, ignore_index=True)
instance = session.query(model).filter_by(**kwargs).first()
root = tk.Tk()
[apply(op, *items) for items in zip(*elements)]
json.dumps(final)
ax = plt.figure(figsize=(10, 6)).add_subplot(111)
population = [a for n, a in allele_freqs for _ in range(n)]
numpy.frombuffer(bytestream.read(4), dtype=dt)
plt.semilogx(f, phase)
[i for i in mysites if i in list(sites.keys())]
response = urllib.request.urlopen(request)
print(rd[5])
sys.stdout.write(str(result))
this_list.index(sub_list[0]), len(sub_list)
q.bind()
plt.imshow(X_digits[1778].reshape((8, 8)), cmap=plt.cm.gray_r)
app = create_app()
print(result)
numpy.nan is numpy.nan
oldbase = os.path.splitext(filename)
img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
myapp.run()
pool = mp.Pool()
x = np.array([True, True, False, False])
norm = mpl.colors.Normalize(vmin=valmin, vmax=valmax)
serialized_q = json.dumps(list(queryset), cls=DjangoJSONEncoder)
ax.set_yticks(scipy.arange(-1.5, 1.5, 0.25))
L[a:a + span2] = tmp
print(Counter(yourtext.split()))
c = [1, 2]
db.session.add(user_from_factory)
L = np.logspace(1, 2, N)
repeat(partial(bar, 42))
self.doc.build(pdf, canvasmaker=NumberedCanvas)
()
print(url + urllib.parse.urlencode(getVars))
a.lower() == b.lower()
a.append(visdel())
fig = plt.figure()
conn.close()
json_data_rdd.flatMap(f)
Logger.propagate
os.chdir(sys._MEIPASS)
exogx = np.array(list(range(1, 5)))
othercube[i, j, k] = some2d
stack.pop()
t = threading.Thread(target=wrapped_f, args=(q,) + args, kwargs=kwargs)
p = argparse.ArgumentParser()
a = np.array([[8.0, 9, 7, 0], [0, 0, 5, 6]])
parsed_response
result
f.read()
plt.show()
os.remove(link_name)
oauth_secret = models.CharField(max_length=200)
print(numpy.linalg.norm(x, axis=1))
name = models.CharField(max_length=128)
self.cookies.append(cookie)
json.dump(record, f)
L = pd.concat([data[x[0]].eq(x[1]) for x in list(tmp.items())], axis=1)
map(globals().get, fxnOfInterest)
hashlib.sha512(s + d).hexdigest()
k = np.random.randint(4, 16)
X.nonzero()
f.flush()
soup = BeautifulSoup(html)
count_mers(s, k=2)
M[(rownumber), :] *= scalar
assert len(all_rosters) == len(set(tuple(roster) for roster in all_rosters))
a1 = a
toplevel = Toplevel()
user = User.objects.get(email=username)
matrix
print(x)
plt.draw()
sys.modules[pkgname]
a, b = f[:i + 1], f[i + 1:]
sorted(set(li))[-n]
userhome = userhome.encode(sys.getfilesystemencoding())
s += timedelta(days=1)
httplib.HTTPConnection.send(self, s)
ax2.bar(x, y)
signal.signal(signal.SIGALRM, self.raise_timeout)
pprint(a)
opener = urllib.request.build_opener(urllib.request.HTTPHandler)
a()
myFunction()
pixmap = QtGui.QPixmap.fromImage(qimg)
descendents_ancestors.add(ancestor)
__import__(module)
Maybe(maybe.calc(lambda x: x ** 2))
np.row_stack((a, b))
django.db.transaction.rollback()
y = np.random.rand(10) * (X.shape[1] - 1)
browser = webdriver.Firefox()
dom0.create()
out.write(line.replace(LASTKNOWN, CURRENT))
b = np.transpose(a)
keys.append(word)
session = smtplib.SMTP(server)
result = func(*args, **kwargs)
im.size
print(vectors.T / norms[:, (newaxis)])
handler2.setLevel(logging.ERROR)
list(a)
self.__dict__[key]
img.putdata(new_list_of_pixels)
cdeltaY, crvalY = linwcs(np.amin(glat), np.amax(glat), len(glat))
plot_point(xp, yp, sym)
self.process.start()
list(words_in_string(word_list, a_string))
data = requests.get(u).json()
start_time = time.time()
feature_names = vectorizer.get_feature_names()
plt.colorbar(sst_contour, cax=cbar_ax)
mock_redis_get.side_effect = get
tmap.setdefault(t, len(tmap))
connection.execute(q)
events.sort()
name = Column(String(50), nullable=False)
np.nonzero(x)
(x for _, x in zip(list(range(n)), generator))
parser = argparse.ArgumentParser()
lines = f.read()
[inner for outer in x for inner in outer]
obj._meta.concrete_model
out, err = cproc.communicate(input)
input.isdigit()
print(t.strftime(fmt))
driver.execute_script(script, *buttons)
college = models.CharField(max_length=40)
pause.until(datetime(2015, 8, 12, 2))
print(i)
zip_file.extract(i, dirname)
u /= math.sqrt((u ** 2).sum())
print(sys.exc_traceback.tb_next.tb_frame.f_locals)
exception_list.extend(traceback.format_tb(sys.exc_info()[2]))
numbers.append(i)
sess.run([train_op, loss, global_step])
options, args = parser.parse_args()
vbox = gtk.HBox()
logging.error(e, exc_info=True)
f.close()
filename = sys.argv[1]
str(eval(self.expression))
print(G.number_of_edges())
print(df.loc[np.sort(idx)])
parser = argparse.ArgumentParser()
print(locale.getlocale())
hkweather = bs4.BeautifulSoup(r.text)
np.sin(y * x)
[list(range(x)) for a in selection]
channels = f.getnchannels()
pygame.image.save(game.screen, image_path)
superdicts = []
db.session.rollback()
sheet = pygame.image.load(file).convert_alpha()
df.A.plot()
11111111111111111111111111110101
funcs.append(partial(lambda x: x, x))
list = [self.queryQ.put(query) for query in queries]
found = next((i for i in mylist if predicate(i)))
round(num / res) * res
root = Tk.__init__(self, *args, **kwargs)
bar()
result = []
print(channel[0])
main()
plot(x[i:i + 2], y[i:i + 2], linewidth=width[i])
pname = PyUnicode_FromString(name)
res = res.reset_index()
ar.flatten()
name = StringField()
time.sleep(1)
cell = [title1, title2]
plot(data)
df_both.swaplevel(0, 1).sort_index()
z = bar(foo())
ax.add_patch(Polygon(xy))
print(list(common))
asyncio.get_event_loop().run_until_complete(async_getter())
img = MIMEImage(memf.getvalue())
om.grid(sticky=W + E, padx=5, pady=5)
query = query.decode(charset) % conn.escape(args)
f.seek(0, os.SEEK_END)
s[-1] *= -1
self.selection
response
Session = sessionmaker(bind=engine)
fig = plt.figure()
print(pd.concat([dm] * df.shape[1], axis=1, keys=df.columns))
new_m = coo_matrix((a[:, (2)], (a[:, (0)], a[:, (1)])), m.shape)
sigma = np.std(array)
circmask * anglemask
name = models.CharField(max_length=100)
Base.__init__(self)
data = list(img.getdata())
self.root.after(1000, self.poll)
fig.canvas.draw()
print({a, b})
Question.objects.filter(test_id=fr).update(test_id=to)
app = QtGui.QApplication([])
set_spyder_echo(True)
self.d[k] = v
count = len(words)
counts = Counter(value[1] for value in mydict.values())
foo()
df
word.lower() in english_words
list(range(5))[6:7]
request.GET.urlencode()
ax.autoscale(False)
conn.status
csvout.writerow((country, year))
udf(_in_last_5_minutes, BooleanType())
surf1 = pygame.Surface((200, 200))
data = self.conn.recv(1024)
self.ui.setupUi(self)
len(entries), sum(entries)
sum += int(num_str[i])
writer = csv.writer(csv_file)
print(help(b))
self.data[key] = item
pl.xticks([1, 2], labels)
f.subs({x: 10, y: 20})
self.queue = set()
list = [1, [2, 2, 2], 4]
my_copy = my_dict.copy()
items = list(yourdict.items())
ax = fig.add_subplot(1, 2, 2)
somethingThread = threading.Thread(target=someClass.doSomething)
django.get_version()
f_old.close()
h, w = tpl.shape[:2]
confused_array
ax = plt.gca()
print(x)
print([j for i in spamreader for j in i])
log = logging.getLogger(__name__)
obj.get_id
assert np.allclose(beta, beta2)
pl.subplots_adjust(wspace=0)
element = driver.find_element_by_css_selector(locator)
app.show()
gen().__name__
df_key = pd.concat(df_list)
flask.g.breadcrumbs.append(BreadCrumb(path, title))
smtp.quit()
divs_sum = sum(get_divs(num))
Fruit(5)
worksheet.getCellByPosition(x, y).getString()
calculate_something.call_args_list
s[:]
d2 = dict((v, k) for k, v in d.items())
os.remove(filepath)
dt.replace(year=dt.year + 1)
k = arr.shape[0] / n
main(**vars(args))
primes = [i for i in range(R + 1) if sieve[i] == 0]
B.add_nodes_from(inmates_list, bipartite=0)
args = parser.parse_args()
masked.sum(axis=1)
os.system(self.get_command(file, **options))
self.button.grid(row=2, columnspan=2)
npreds[v] += 1
n == 0 or GetSum(n, arr[1:]) or GetSum(n - arr[0], arr[1:])
axes.scatter(cdfx, logcdfy, s=4, linewidths=0)
nhb
interleaved_array = np.hstack(arrays).reshape(shape)
func(*args, **kwargs)
fig = plt.figure()
numbers = [float(x.strip()) for x in input_list]
md5.update(data)
c.writerow(row)
deletet[4:]
messages = self.args[1]
instance.method(argument)
grpA[mask] = sortedA[:, (-1)]
decoded = base64.b64decode(encoded)
X = np.array([[1, 1], [2, 1], [2.5, 1]])
sum(min(ac[key], bc[key]) for key in ac)
axm.set_xlim(0.0, 1.0)
map(operator.itemgetter(1), L)
fig = plt.figure()
walk(tree.getChild(i), temp)
close_button.set_relief(gtk.RELIEF_NONE)
decoder.start_utt()
data = np.arange(200).reshape((4, 5, 10))
makeIDAT = True
makeIEND = True
myDict[newKey].append(value)
f(*args)
result = cv2.matchTemplate(img, template, cv.CV_TM_SQDIFF)
print(df2)
numbers = (int(character) for character in input_string if character.isdigit())
a_test.__name__
self.listWidgetB.currentItemChanged.connect(self.item_clicked)
fib(n)
df1.fillna(-999) == df1.fillna(-999)
one.py
print(row[0])
numpy.random.seed(1)
painter.drawImage(0, 0, self.mQImage)
self.command()
(a != b).sum() / float(a.size)
numpy.atleast_2d(x[x[:, (1)] == 21])
opt1 = tf.train.GradientDescentOptimizer(1e-05)
foobar(1)
base * power(base, exponent - 1)
list(filter(list1.__contains__, list2))
web.show()
logger.addHandler(handler)
ax = plt.axes()
app = QtGui.QApplication(sys.argv)
city = models.CharField(max_length=50)
True
win.set_keep_above(True)
-Wl, -rpath, your_path
lines = file.readlines()
options = webdriver.ChromeOptions()
problems = True
Matrix(M.T * M)
sys.stdout.write(line)
worker = subprocess.Popen(args)
logger = logging.getLogger()
q.all()
self.setLayout(layout)
dict(zip(*([iter(S)] * 2)))
datetime.now().weekday()
app = QtGui.QApplication(sys.argv)
Greeter().greet()
s = re.search(regex, line)
df.index = index
print([list([_f for _f in x if _f]) for x in df.values.tolist()])
app.MainLoop()
value = datetime.timedelta(0, 64800)
f.close()
ax1 = fig.add_axes((0.1, 0.4, 0.8, 0.5))
remaining = np.arange(len(M))
s = eval(input())
d.foo()
print(cell.value)
print(dict(mergedicts(dict1, dict2)))
AC_PROG_CXX
AC_FUNC_MALLOC
reader = csv.DictReader(csvin)
sys.getsizeof(s)
dir(func)
print(yaml.dump(data))
now = datetime.datetime.now()
backend.py
result[-1].append(t[j + 1])
self.axe.clear()
p1.func == p2.func and p1.args == p2.args and p1.keywords == p2.keywords
print(R.shape)
gss_client = gspread.authorize(credentials)
ax = fig.add_subplot(111)
LETTER, LEGAL, ELEVENSEVENTEEN
button.setMenu(menu)
pickle.dump(lists, f)
id(foo[0])
env = Environment()
print(first_day)
Book.query.with_entities(Book.id)
self.rect.left = p.rect.right
tab.header(list(row.keys()))
self.assertEqual(name, expected_name)
setattr(toclass, attr, cls.__dict__[attr])
print(draft.playernumber)
df == df
x = np.concatenate((x, x))
template = cv2.imread(sys.argv[2])
libraries = []
MULT(z, a, z)
assert len(list(sumdiff(x, y, nskip))) == n / nskip
values = [random() for i in range(20)]
df = pd.concat([df] * 10000).reset_index(drop=True)
input = wx.TextCtrl(self, -1, style=wx.TE_MULTILINE)
d = {}
logdata = np.log(data)
response = connection.read_response()
i = len(A)
inset.set_position([x_fig, y_fig, x2_fig - x_fig, y2_fig - y_fig])
s = socket.socket()
cur = conn.cursor()
es = Elasticsearch()
zip(*a)
list(itertools.permutations(l, 2))
C_Cidx = np.digitize(C, Cbins)
instance.work.save()
print([p for p in range(101) if aks_test(p)])
fileDirectory()
child.setExpanded(True)
img = Image.open(image)
line.interpolate(0.1, normalized=True)
self._points.append(coordinates)
from_user = db.ReferenceField(User, required=True)
HttpResponse(output)
img = Image.open(image.file)
sleep(10)
ax1.yaxis.set_major_formatter(yticks)
l = [copy.copy(x) for x in [[0]] * 4]
_my_whole_freaking_module()
{{p.age}}
ssh = paramiko.SSHClient()
EMAIL_USE_TLS = False
print(fooPy())
tar.close()
xml_str = urllib.request.urlopen(xml_str).read()
print(x.max())
admin.site.register(Poll)
d = d[k]
result = urllib.request.urlopen(request)
painter.save()
listy = [a, a, a]
print(s.recvfrom(65565))
num += 1
tmp = arr.reshape(2, 2, 2, 2).swapaxes(1, 2)
cj = cookielib.CookieJar()
df1.reindex(columns=dummies_frame.columns, fill_value=0)
area([[0, 0, 0], [1, 1, 1]])
self._async_init().__await__()
list(product(x, deepflatten(y, ignore=str)))
np.arange(lllat, urlat, 2.0),
dateobject = datetime.date.today()
print(k, v)
plt.xticks(list(range(len(labels))), labels)
f.close()
help(map)
r = requests.get(url, stream=True)
left = A[idx - 1]
self.log_file = log_file
powerset_abs_file.close()
inner = types.FunctionType(myFunc.__code__.co_consts[1], globals())
print(date_by_adding_business_days(datetime.date.today(), 10))
myList.append(random.randint(0, 1))
term.start()
swapped_pairs = zip(seq[1::2], seq[::2])
df2 = pd.DataFrame(df1, copy=True)
sum(10 ** pos * val for pos, val in enumerate(reversed(test)))
rv_continuous.fit(gamma, x, floc=0, fscale=4)
l[2]
time.sleep(0.1)
now = datetime.now()
np.flatnonzero(np.random.multinomial(1, p, 1))[0]
print(bin(v.value))
print(list([x for x in words if len(x) > avg]))
choices = [(item.pk, item.some_other_method()) for item in some_queryset]
[[2][0][1][0][1][0]]
b = OuterTest()
NORTH, S, W, E = (0, -1), (0, 1), (-1, 0), (1, 0)
self.assertEqual(10, result, result)
MyThread(parent=self)
object.__new__(cls, value)
self.func(*args, **kw)
c.x.append(1)
fig = plt.figure()
os.kill(signal.CTRL_C_EVENT, 0)
set(list1).intersection(compSet)
queue.put((False, exc_info()))
os.remove(tempFile)
count += 1
next(key for key, value in d1.items() if value == 55)
assert align_two_lists(list1, list2) == [new_list1, new_list2]
output = p2.communicate()[0]
ax.autoscale()
c.start()
t = np.linspace(0, 1, 200)
print(title.firstChild.data)
question = models.CharField(max_length=200)
ax2.set_ylim(0, 1)
self._lock.acquire()
self.assertEqual(len(self.seq), 1)
models.py
existing_category.put()
new_type = numpy.dtype(descr)
example().cmdloop()
new_df = df.iloc[only_once.index // len(df.columns)]
list_of_list.append(list(map(float, list_)))
a, b
[4, 5]
B = scipy.sparse.diags([A[:, (0)], A[:, (1)]], [0, 1], [4, 5])
BaseTest.__init__(self, *args, **kwargs)
Response(g, direct_passthrough=True)
print(line)
plt.show(block=False)
et = ElementTree.fromstring(xmlStr)
os.system(filename)
self.b = a
tmp = np.random.rand(np.random.randint(1, 100))
print(q.get())
ax2 = ax1.twinx()
print(f.read())
cr.set_source_rgb(0, 0, 0)
self.btn.pack()
parser = etree.XMLParser(ns_clean=True, recover=True)
Transform.__init__(self)
next.focus()
p = Process(target=f, args=(child_conn,))
arr[:, (np.newaxis)]
lambda x: x(r)
paws = [p.squeeze() for p in np.vsplit(paws_data, 4)]
sock.close()
id = Column(Integer, primary_key=True)
plot_date(timeSeries, data)
self.assertEqual(r.status_code, 200)
result.append(x)
[int(full.split()[-1] in B) for full in A]
listbox.autowidth()
[str(i) for i in range(1995, time.localtime().tm_year + 1)]
G.remove_edge(edge[0], edge[1])
liba.hello()
lines = [screen.display[i].rstrip() for i in range(last + 1)]
zip(a, b)
smallfile.close()
self.bar(arg)
app.Yield(True)
data = f.read().strip()
cache.set(cache_key, result)
print(data)
print(sum(v == dt.hour and dt.weekday() == day for dt in dates))
os.environ[k] = v
file.truncate(10 ** 10)
result = [s for s in all_words if pat.match(s)]
description = models.CharField(max_length=255, blank=True, null=True)
uploaded_file_info = items.children[target_filename].upload(file_to_upload)
(df == a).all(1).any()
print(arg_str)
name = models.CharField(max_length=100)
lst = [1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0]
setattr(obj, parts[-1], value)
points.intersects(poly.unary_union)
self.resize(600, 400)
a = [4, 5, 0, 0, 6, 7, 0, 1, 0, 5]
l = []
post[0].tags.remove(posttag)
sorted(l, key=os.urandom)
abstracts.append(abstract)
out.close()
Dup[Item] = ItemNumber = len(List) - 1
d.cards.append(Card(1, 1))
img = img.resize((size[0] * multiplier, size[1] * multiplier), Image.BICUBIC)
_addup(n - 1) + n
fig = plt.figure()
compare_intersect(a, b)
sizer = wx.BoxSizer(wx.VERTICAL)
xml = Node.toxml()
df_one.show()
np.ma.all(np.ma.masked_invalid(a) == np.ma.masked_invalid(b))
list(d.items())[0]
[os.sep.join(p) for p in product(*matching) if _in_trie(path_trie, p)]
deleteself.__dict__[key]
user_model = sys.argv[1]
zi = np.ma.masked_equal(zi, 0)
writer = csv.writer(f)
outf.seek(0)
id = Column(Integer, primary_key=True)
root.withdraw()
reader = csv.reader(f, delimiter=d)
t = threading.Thread(target=read_stdout, args=(p.stdout, q))
decorator
self._list.index(value)
acc.extend(inner(x, []))
test_foo.py
abscissas = np.linspace(0, 1, 10)
number_of_columns = sheet.ncols
self.x = 5
match = re.match(pattern, s, re.UNICODE)
parentNode.removeChild(element)
person_list.append(person)
original_tag.append(new_tag)
table = Table(domain, [map(str, row) for row in df.as_matrix()])
pipe(list(range(4)), map(lambda i: repeat(i, i + 1)), concat, list)
a.f()
zipped_file.writelines(orig_file)
cat_index = np.searchsorted(categories, A[0])
s.sendmail(sender, recipients, my_as_string(msg))
main(sys.argv)
r, nil
result.map(lambda x: row(DenseVector(x))).toDF(schema)
arr[accmask] = np.nan
y[4:6, 1:8] = 1
out = list(df.T.to_dict().values())
new_list = []
list(sympy.primerange(0, 100))
A1s[([0, 1, 2]), ([0, 1, 0]), :, ([0, 1, 1]), :]
fig, ax = plt.subplots()
self.diagram.SetSnapToGrid(True)
b = a.copy()
nbins = len(ax1.get_xticklabels())
c.point(x, y, color=sp.pixel(x, y))
main.py
shutil.copyfileobj(req, f)
timestamp = (dt - epoch) / timedelta(seconds=1)
minval = min(a[i], a[i - 1])
label_image.place(x=0, y=0, width=image1.size[0], height=image1.size[1])
y_ = np.linspace(1.0, 2.0, 20)
non_transparent.paste(image, (0, 0), image)
a2.append(int(data[1]))
dict.__delitem__(self, key)
print(df)
array([0.91262442, 0.67247516])
fig, ax = plt.subplots()
self._tv.openPersistentEditor(self._tm.index(row, 0))
zip(t[::2], t[1::2])
E.append(np.sqrt(((last - out) ** 2).sum()))
os.read(r_fd, 1)
plot(x[indice], y[indice])
foo = np.array([0.0, 1.5, 1.0])
parsed = ET.fromstring(xml_string)
url_parts = list(urlparse.urlparse(url))
y = y.reshape(-1, 1)
file.close()
df.loc[4]
widget.setLayout(QVBoxLayout())
(df.foo != df.foo.shift()).cumsum()
self.setCentralWidget(self.cw)
isize = im.size
specifics()
eq_y.subs([(x, c), (y(c), y_c), (y(x).diff(x).subs(x, c), dy_c)]),
transaction.commit_unless_managed()
f.close()
df != 0
sympy.__version__
a = np.where(img != 0)
p = widget.grab()
raise NotImplemented
sock.close()
a[a < 0] = -1
print(response.status, response.reason)
signal.alarm(0)
output = PdfFileWriter()
Foo.bar()
a[1]
a = np.array([2, 56, 4, 8, 564])
ax = fig.add_subplot(1, 1, 1)
fig = plt.figure(dpi=100)
form.show()
info = [data[i:i + 2] for i in range(0, len(data), 2)]
cos_x = sin(lat_a) * sin(lat_b) + cos(lat_a) * cos(lat_b) * cos(delta_long)
print((dirpath, len(todays_files)))
Xnew = np.hstack((X, X0))
session.add_all([tableRow(row) for row in listOfRows])
self.generator_outputs.append(tf.clip_by_value(x_gen, -1, 1))
x.append(item)
tn = telnetlib.Telnet(HOST)
fig, ax = plt.subplots()
quicksort(array)
map(lambda x, y: x * y, l1, l2)
d.setdefault(key(item), []).append(item)
do_stuff(match)
os.chdir(directory)
ax.set_yticklabels(ax.get_yticks())
Z = X ** 2 + Y ** 2 + np.random.rand(*X.shape) * 0.01
thread.start_new_thread(input_thread, (list,))
root.grid_rowconfigure(2, weight=1)
sys.exit(1)
api = tweepy.API(auth)
grokster.grok()
ax.set_position([0.1, 0.1, 0.85, 0.85])
f.read()
original_rows = [[1, 0, 1], [0, 0, 0], [1, 0, 0]]
sys.stdin.read()
json_string = urllib.request.urlopen(url).read()
Area = pi * (dr * n) ^ 2 - pi * (dr * (n - 1))
parser1 = argparse.ArgumentParser()
pool = multiprocessing.Pool(processes=4)
finishat = time.time() + timeout
[x for x in data if key in x and x[key] in allowed]
cmap = matplotlib.cm.jet
result.append((0, 0, values))
self.timer.cancel()
fig, axes = plt.subplots(nrows=1, ncols=numdatasets, figsize=(12, 6))
func(*args, **kwargs)
a[i].append(x)
scipy.math.factorial, numpy.math.factorial, math.factorial
channel = ssh_client.invoke_shell()
G.add_edge(1, 2)
data = file.read()
words.most_common()
br.select_form(nr=currentForm)
print([(x ** 2) for x in lst if x % 2 == 0])
np.corrcoef(df, rowvar=False)
exit(0)
x = __import__(module_name)
p = session.query(Parent).get(pid)
bar(list(range(10)), list(range(10)))
[pingpong]
Column(_f(_to_seq(sc, [col], _to_java_column)))
root.mainloop()
t2 = time.time()
f.close()
proc.kill()
y = x + y
print()
app = QtGui.QApplication(sys.argv)
foo_data = json.loads(json_string)
self._c = c
self.Bind(wx.EVT_SIZE, self.OnSize)
sleep(2)
thestrings = [str(s) for s in col.findAll(text=True)]
np.bincount(i, weights=d)
print(np.argmax(spect), np.max(spect))
client = gdata.analytics.client.AnalyticsClient()
pprint(ddiff)
plt.show()
lst = [[0, 1], [0, 4], [1, 0], [1, 4], [4, 0], [4, 1]]
w.wcs.naxis
main_parser = argparse.ArgumentParser()
mc.Property1
localized_time.astimezone(pytz.utc).strftime(fmt)
numpy.float64(numpy.nan) is numpy.float64(numpy.nan)
admin.autodiscover()
sums = a[:-1, :-1] + a[1:, :-1] + a[:-1, 1:] + a[1:, 1:]
B[:, :, (0)] = A
datetime(1582, 10, 15) + timedelta(microseconds=uuid1().time // 10)
print((i, lcm20 % i))
p.terminate()
hex(a)
coords = np.stack(np.meshgrid(x, y, z), axis=-1)
reader = csv.reader(infile)
os.close(fd)
ng.get_name()
foo()
df_2 = pd.DataFrame(np.random.randint(0, 2, (1000, 600)))
print(df)
plt.ion()
[]
p = multiprocessing.Process(target=start_child, args=(server_program,))
prevprime(n, ith=1)
credentials = storage.get()
datetime.datetime(*structTime[:6])
name = models.CharField(max_length=100)
ax.add_collection(lc)
seen = set()
l.pop(i)
plt.colorbar()
do_if_pass([2, 4, 6])
collections.defaultdict(list)
myObject.doStuf()
httpd.serve_forever()
result = []
t = threading.Thread(target=batcher, args=(app.queue,))
getattr(self.child, attr)(*args, **kw)
print(remove_none(data))
s.describe()
field1 = models.CharField(max_length=10)
print(df)
img.show()
np.random.seed(0)
pairs.append((k, v))
G.nodes()
Intersection(self, other)
float(m.group(1))
cols = [x[0] for x in cursor.description]
os.mkdir(blues_sounds_path)
int(v)
se2lib._current_browser()
os.chdir(cwd)
lst = [a, b, c, d, e, f, g]
args = parser.parse_args()
fig = plt.figure()
q = multiprocessing.Queue()
self._num_expectations += 1
local_dt = utc_dt.replace(tzinfo=pytz.utc).astimezone(local_tz)
min(t, key=lambda e: (e[1], -e[2]))
int_arr = np.cumsum(np.cumsum(arr, axis=0), axis=1)
luckynumbers.append(item)
ax = fig.add_subplot(111)
self.position = len(self.get())
prev = np.zeros(src.shape[:2], np.uint8)
heapq.heappop(pqueue)
data = file_to_check.read()
user.set_password(password)
self.x = math.cos(a) * original_x - math.sin(a) * original_y
count += 1
method()
res[k].append(j)
queue = Queue.Queue()
competitors.save()
self.Bind(wx.EVT_SIZE, self._onSize)
fig = plt.figure()
push = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)
reader = csv.reader(f)
m = [x for x in dictionary[i] if len(x) == l]
ret.extend(flatten(v))
ssh_client = paramiko.SSHClient()
r = requests.get(url)
name = models.CharField(max_length=50)
server.shutdown()
s = socket(AF_PACKET, SOCK_RAW)
py > matrix[-1][2]
app = Flask(__name__)
lettered.append(subx)
df1.letter.unique()
axs[0].xaxis.set_major_formatter(x_fmt)
mask = ~np.isnan(x)
list(itertools.takewhile(lambda x: x != 412, even_numbers))
df.Date = pd.to_datetime(df.Date)
img.putdata(newData)
dt = datetime.datetime(*parts[:6]) - datetime.timedelta(seconds=parts[-1])
nx.draw(g1)
print(df1)
ispower(2, 1)
n.close()
m_to = ndb.KeyProperty(kind=UserModel)
self.bmp = wx.BitmapFromImage(image)
end = time.time()
pickle.dump(d, filehandler)
{name: input_zip.read(name) for name in input_zip.namelist()}
register = template.Library()
print(line.rstrip())
assert type(arg) == datetime.date
a, b, c, d
msg = email.message_from_string(response_part[1])
t.append(t[-1] + 1)
print(now_time.strftime(fmt))
p.map(lambda m: merger(*m), mergelist)
distance_matrix_np = np.random.uniform(0, n ** 2, size=(n, n))
obj.save()
activation.prepare()
f.restype = ctypes.POINTER(ctypes.c_int * 10)
print(s)
sleep(1)
x[i], x[j] = x[j], x[i]
alphaDict = dict.fromkeys(string.ascii_lowercase, 0)
result_grey = cv2.cvtColor(source, cv2.COLOR_BGR2GRAY)
binary_search([1, 5, 8, 10], 0)
print((a, b))
print(list(counter.keys()))
AWS_IS_GZIPPED = True
ax.plot(t, y1)
exec(mycode)
test = serial.Serial(baudrate=9600, timeout=0, writeTimeout=0)
print(100 * (b - a) / a)
atexit.register(savecounter)
(17.5).hex()
p.map_async(g, [slice(i, i + step) for i in range(stop_f, N, step)])
hex(65)
wb.Close()
keep_mask = np.ones_like(data, dtype=bool)
pyautogui.click(100, 100)
a = random.randint(0, 20)
list(fields_660.values())
output = [x for x, y, label in L]
self.__dict__.update(profile)
log.addHandler(fh)
writer.writerows(reader)
print(iterator(lambda x: x / 4 + 12, 100, 5))
m.hexdigest()
CACHE_MIDDLEWARE_ANONYMOUS_ONLY = True
dict_del
data_p = data.ctypes.data_as(c_float_p)
self.right = FibTree(n - 2)
new_valss = [(x[0], x[1]) for x in new_vals]
store.close()
local_dt = datetime.fromtimestamp(timestamp)
test.close()
isinstance(v, property)
out.extend(np.where(nonzero)[0][[0, -1]])
main_loop.start()
Session = scoped_session(sessionmaker(bind=engine))
ax.figure.autofmt_xdate()
df.loc[(df[0] == 0).idxmax(), 0] = 100
plt.bar(bins, probs, 1.0 / num_bins)
fig = plt.figure()
test_df
select.select([], [B], [])
mylist2.sort(key=sort_order.index)
plt.subplot(221)
x[k]
print(list(powerreps(X, Y)))
self.holding = item
self._writecheck(zinfo)
signal.signal(signal.SIGALRM, original_handler)
b = np.array([4, 5, 2])
print(x)
print(find_matches(d, item))
c.setopt(pycurl.FOLLOWLOCATION, 1)
_bar.__exit__()
new_xs = [point[0] for point in sorted_points]
ax.errorbar(theta, r, xerr=0.5, yerr=0.4)
ds.addSample((-1, -1), (0,))
p1.start()
self.send_blob(blob_info)
now = time.time()
basis = [(lambda x, n=n: n * x) for n in [0, 1, 2]]
stream.stop_stream()
a[0:2] = b
r.dot(y.reshape(1, -1))
plt.plot(f, ps2)
p.start()
sigma = numpy.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0])
ax2.contour(theta_centers, r_centers, H)
opt = argparse.ArgumentParser()
np.where(np.all(np.equal(w, b), 1) == True)[0]
ob.stackoverflow(2)
QNetworkAccessManager.createRequest(self, operation, request, data)
print(repr(f.read()))
window = gtk.Window(gtk.WINDOW_TOPLEVEL)
mac = get_mac()
d[l[0]] = d.get(l[0], {})
y = math.sin(4 * 2 * math.pi * x / POINTS)
seen = set()
image = Image.open(cStringIO.StringIO(image_data))
number_string = str(myinteger)
res.set_value(index, previous_df_no)
atexit.register(removeFile, path)
node.set_next(node.get_data() + sum(int(i) for i in str(node)))
conn.close()
genotypes = models.TextField()
F = np.random.rand(n, n)
my_dict = json.loads(dict_str, object_pairs_hook=dict_clean)
x + 1
c = list(chain(*zip_longest(a, b[::-1])))
libxxx.foo.argtypes = [ctypes.POINTER(ctypes.c_float), ctypes.c_size_t]
date = parser.parse(x)
my_buffer[:] = itertools.repeat(0, len(my_buffer))
tmp()
print(response.content)
print(sess.run(loss, feed_dict={x: input_x, y_: input_y}))
self.left
pa_stream_peek(stream, ctypes.byref(null_ptr), ctypes.c_ulong(length))
my_thread = QThread()
self.clients.append(client)
Blob.__init__(self, width, height, color, emphasis, highlight)
t = linspace(0, 2 * np.pi, n, endpoint=False)
print(svg.get_width(), svg.get_height())
proc = subprocess.Popen(cmd, stdout=subprocess.PIPE)
canvas.create_image(image.size[0] // 2, image.size[1] // 2, image=image_tk)
count += 1
list(ordered_dict.keys())[2]
foo = np.random.rand(20000000).cumsum()
print([v for v in map_words(sentence)])
b = list(b)
result = np.zeros(len(colors), dtype=np.int)
text = soup.get_text()
print(self.right.PreOrder())
score = sum(i * w(i) for i in xx & yy) / sum(i * w(i) for i in x)
os._exit(0)
plt.plot(x, f(x))
sum(pow(x1 - x2, 2) for x1, x2 in zip(x1s, x2s))
result.update(request)
current_chunk.append((token, tag))
root.mainloop()
event.Skip()
a.a()
gona[:, (0)]
os.dup2(to_file.fileno(), stdout_fd)
parser = argparse.ArgumentParser()
ns[cls.__name__].mocked_method
list(RNA_dictionary.values())
df_7 = df.sample(n=7)
print(strip_tags(html, invalid_tags))
answer[c].append(b)
self.__class__.x = x
track2.play_forever()
AV[j] = n
listD.append(listB[num])
a = [1, 1, 1, 1, 1]
layout = QVBoxLayout(self)
xticks(list(range(1, 40)), list(range(1, 40)))
keyset.update(d[k])
print(pivotdf.head())
s = m.group(1)
parser = argparse.ArgumentParser()
splitter.findall(s)
assert rr.is_preview == False
l.append(id(arg))
conn, addr = s.accept()
print(foo[(np.newaxis), :])
mean_matrix = pd.concat(dfs, axis=1).T
df = pandas.DataFrame(x, columns=column_labels, index=row_labels)
print(oct_num == 511)
y.close()
process.append(multiprocessing.Process(target=wrapper, args=argtuple))
png_recovered = base64.decodestring(png_b64text)
hanoi(n - 1, aux, start, target)
excel.Worksheets(2).Activate()
zip_file = zipfile.ZipFile(content)
zip.save()
list.__setitem__(self, key, value)
iterator(lambda x: x / 4 + 12, 100, 5)
book = open_workbook(file_path)
print(Bar().get_counter())
bins.setdefault(key(value, step), []).append(value)
pid = os.fork()
mybins = np.linspace(datamin, datamax, numbins)
foo(C(), B())
fcntl.fcntl(fd, fcntl.F_SETFL, fl | os.O_NONBLOCK)
result = [str[sp[0]:sp[1] + 1] for sp in split_points]
time.sleep(2)
plt.hold(True)
sol_np = np.array(list(range(n - 1, -1, -1)))
[0, 0, 7, 8, 0, 0, 0, 0],
X = numpy.zeros([10, 4])
lat, lng = gmaps.address_to_latlng(address)
smtp.login(user, passwd)
print(linecache.getline(file, line))
h = hog.compute(im)
print(self.AsyncResult(self.request.id).state)
groups.append(list(map(itemgetter(1), g)))
values = [0, 1, 2]
pyplot.gcf().autofmt_xdate()
q = session.query(col).order_by(col)
zipfile.ZipFile.__init__(self, *args, **kwargs)
bin_data = f.read()
list(desired_cols)
data = np.array(data)
fig = plt.figure()
sheet = book.sheet_by_index(0)
event.Skip()
cursor.execute(query)
dirname, filename = os.path.split(os.path.abspath(__file__))
session.add(u2)
ip.release()
hourlydf = pd.DataFrame(hourlydata)
word = word.strip()
[[i[o] for ix, i in enumerate(a) if l[ix] > o] for o in range(max(l))]
task.delay(arg1, arg2).get()
seen.add(n)
conf95 = np.where(cxy > gamma95)
(seq[pos:pos + size] for pos in range(0, len(seq), size))
self._rooms = {}
module = sys.modules[module_name]
thread.start()
print((key, list(group)))
login_button.click()
b = np.indices(a.shape)
print(video_url)
os.chdir(our_home_dir)
obj.method()
plt.show()
sys.__excepthook__(exc_type, exc_value, exc_tb)
np.argmin(A1[1])
l.append(b)
list(group_660.keys())
1, 1, 0.526015021, 0.581905971
CA
self.initUI()
sys.stdout = old_stdout
myCopy = deepcopy(myDict)
flist.append(funcC(i))
stats.print_stats()
main()
particles[i].fitness = fitness
rs = (grequests.get(u, headers=header) for u in urls)
context = RequestContext(request)
method = cv2.TM_SQDIFF
st = os.stat(filename)
self._server.handle_request()
makesomenoise()
client.start(container)
print(a)
elem.send_keys(Keys.PAGE_DOWN)
resource.setrlimit(rsrc, (1024, hard))
a_s = os.path.abspath(sys.argv[0])
False
data = dict()
cmdp = Popen(cmdline, shell=True, stdout=PIPE, stderr=PIPE)
A = np.asarray(A[indices])
print(is_int_value(x_))
original_handler = signal.signal(signal.SIGALRM, timeout_handler)
final_queue = Queue()
speedresults = [x for x in sorted(results, key=lambda x: x[1])]
numbers_str = line.split()
myShelve.close()
pd.concat(frames, keys=user_ids)
total = model.fee_total(model)
x.dot(x) + sin(np.linalg.norm(x) * np.pi)
result.extend(flatten(el))
wx.FileDropTarget.__init__(self)
right.put(n[0::2])
oddSquares = [(number ** 2) for number in myListOfNumbers if number % 2 == 1]
print(reg_m(y, x).summary())
position[-1] += 1
socket.inet_aton(address)
d[DateK] = val
ehandle.close()
a.salutation(*arg, **kw)
pktdump.write(pkt)
raise ValueError
result[np.arange(len(x)), inv] = 1
df_num = df.select_dtypes(exclude=[np.number])
subplot1.plot(x, y)
exit(0)
a0 * alpha ** np.arange(n).reshape(-1, 1)
df_1 = pd.DataFrame(np.random.randint(0, 2, (1000, 600)))
df
xi = np.linspace(-1, 1, ngrid)
str(self.name) == str(other.name)
node_depth_first_iter(self)
HttpResponseBadRequest()
head[:, (0)] = 16
f_out.close()
ftp.dir(parse)
DF + DF.shift()
sdat = tuple(map(repr, dat))
df = pd.read_csv(input_file, header=0)
stdout.close()
self.update(request, *args, **kwargs)
pool = multiprocessing.Pool()
result = client.service.addPerson(person)
self.store.close()
data = db.BlobProperty()
arr2.extend(np.split(z, indr, axis=0))
logger = logging.getLogger()
count = ((listScore[:, (0)] == 2) & (listScore[:, (1)] == 0)).sum()
pnts.append((i[1], i[2]))
SYS_PATH = os.path.dirname(BASE_DIR)
data = request.body.readline()
print(((n0, n1), (d0, d1)))
df.loc[0] = np.nan
True
K = [1, 2, 2, 4, 5, 5, 6, 10]
queue = Queue.Queue()
main_loop = tornado.ioloop.IOLoop.instance()
type(instance)
csv1.close()
globallock.release()
x = linspace(0, 1, 1000)
print(response.authority)
t.start()
dc.DrawLine(x, y, x + self.gridsize, y)
self.previewImage.setPixmap(pixmap)
print(x_str)
count += 1
G.add_nodes_from(L1)
a.__dict__
ax = fig.add_subplot(111, rasterized=True)
loop.close()
start = DT.datetime(1970, 1, 1),
sum(len(l) for l in self.src)
timeit(stmt2, setup2, number=100)
print(dict_merge(d1, d2))
counts = [(i, year_month_pairs.count(i)) for i in unique]
df = df.astype(int).astype(str)
start()
f.write(fmt.format(*row))
logdet = add.reduce(absd, axis=-1)
root.mainloop()
self.server.serve_forever()
data = file_object.read(chunk_size)
d.show()
plot.show()
urllib.parse.urlencode(params)
wn.lch_similarity(dog, car)
a[i].append(i + j)
b = x.read(1)
pool = mp.Pool()
utc_dt = datetime.utcfromtimestamp(posix_timestamp).replace(tzinfo=pytz.utc)
layer2.append(j)
self.assertEqual(mock_boo_obj.d.call_count, 1)
show()
print(new_filename)
plt.ion()
cur.execute(qry)
ax1 = ax1 = fig.add_subplot(1, 2, 1)
df = pd.DataFrame(values, index=index)
[ii, jj] = np.meshgrid(np.arange(5), np.arange(4))
print(row)
sample = np.random.lognormal(mu, sigma, size=1000000)
sock.send(self.postdata)
e.args[0]
count = 0
rows = np.arange(N)
alphashape = [s for s in complex if s.data[0] <= 0.5]
t2 = threading.Thread(target=task2)
emailer = mailer.Mailer(smtphost.example.com)
G = nx.Graph()
data = np.asarray(df)
print(k, v)
axr.yaxis.tick_right()
fig, ax = plt.subplots()
array = np.random.randint(500, size=(4, 2000))
serializer_class = MyModelSerializer
filter_set = set(filter)
f = lambda x: np.cos(x) - x
session.close()
df1.reindex(date_range2)
current_dir.append(args[0])
r[~np.all(r == 0, axis=1)]
self.addr = addr
curses.start_color()
port = int(sys.argv[1])
deque(pool.imap_unordered(f, itertools.product(pairs, repeat=16)), 0)
self.x.configure(state=NORMAL)
book = models.ForeignKey(Book)
self.setLayout(layout)
app = Flask(__name__)
Py_DECREF(pname)
zip(range(len(l) - 1, -1, -1), l)
self.index += 1
twos = 2 ** np.arange(10)
model = pm.modelcontext(model)
request.finish()
sum(topo[x] * topo[x + 1] for x in range(len(topo) - 1))
text = f.read()
a_test.method_one()
response
p.kill()
process.stdin.close()
fruits = ast.literal_eval(fruits)
datetime.datetime = patched_datetime
print(line)
time.sleep(60)
__import__(mname)
sleep()
plt.hist2d(x, y, bins=(50, 50))
plot_window.control.resize(400, 400)
cursor = connection.cursor()
new_user = User.objects.create_user(args, args, args, etc)
B = np.zeros_like(A)
data = [[] for col in cols]
escapesequence = matchobj.group(0)
figure()
l.append(x)
temp = numpy.zeros(len(x))
app = QtGui.QApplication(sys.argv)
pb = gtk.gdk.Pixbuf(gtk.gdk.COLORSPACE_RGB, False, 8, sz[0], sz[1])
f()
y = np.hsplit(x, temp_array)
a[a == 0] = np.nan
ax1.set_ylim([0, 1])
x = [p[0] for p in points]
f.close()
plt.figure()
[next(it) for it in islice(cycle((iter(a), reversed(a))), len(a))]
next((c, s.count(c)) for c in s if s.count(c) > 1)
next(self.it)
print(x1, x2)
print(repr(x)[1:-1])
unsearched.put(newdir)
sum([True, False, False, True, False])
RAVEN_CONFIG = {}
a = [[0, 1], [0, 4], [1, 0], [1, 4], [4, 0], [4, 1]]
x = [[] for _ in range(n)]
smtpserver.send_message(msg)
d = dict.fromkeys(keys)
handler(request, *args, **kwargs)
print(sess.run(result))
fig = pyplot.figure()
values = [0, 1, 2]
plt.plot(y)
w.write(f, wordpx)
self.add(elem)
turtle = turtle.Turtle()
fmt.Println(zip(a, b))
unique_word_count = len(unique_words)
result = str(soup)
application_path = os.path.dirname(__file__)
font = fontforge.font()
print(mm[:])
self.__message = message
handles, labels = axes.get_legend_handles_labels()
A()
sys.stdin, sys.stderr, sys.stdout = self.saved
list(dct.keys())
app = QtGui.QApplication(sys.argv)
f = cStringIO.StringIO()
widget.show()
self.validate_unique()
raw_img = urllib.request.urlopen(img).read()
fig.text(0.1, 0.1, txt)
file.close()
sys.exit(1)
zip(lst1, lst2)
p = multiprocessing.Pool(processes=10)
df = ds.to_dataframe()
coupled_idx = enumerate(zip(list1, list2))
start = time.time()
soup = BeautifulSoup(html)
fn(args[0])
plt.setp(plt.gca(), xticklabels=[])
body = part.get_payload(decode=True)
pylab.show()
platform.platform()
self.window.set_type_hint(gtk.gdk.WINDOW_TYPE_HINT_DOCK)
nsmallest(4, s, key=len)
Book.query
[dict(l) for l in product(*to_product)]
self.collector
yaml.Loader.__init__(self, *args, **kwargs)
print(df.groupby(df.A // 2).A.nlargest(2))
g.set_xticklabels(rotation=45)
print(repr(ba))
print(L)
np.dstack([vec_data_mag, vec_data_angl, vec_data_avg])
fp.close()
executor = concurrent.futures.ThreadPoolExecutor(max_workers=5)
func(d, d1, d2)
browser = webdriver.WebDriver(firefox_profile=profile)
lambda x: a * x + b
s.query(Demo).get(1).value
repr(x)
w.female.replace(to_replace=dict(female=1, male=0), inplace=True)
root = ET.fromstring(s)
print(aList)
input_str = input_str.strip().lower()
self.daemon = True
content = models.TextField(blank=True)
print(min(dates[ind], dates[ind - 1], key=lambda x: abs(x - date)))
UnsortableList(OrderedDict.items(self, *args, **kwargs))
[lst[i:j] for i, j in zip(sec, sec[1:])]
x.argmin(axis=0)
fig.colorbar(lines)
raise ValueError(msg)
categories = Category.objects.all()
res.set_value(index, 0)
data = self._file.read()
z = density([x, y])
exec(file.read())
print([arr2[i][-1] for i in range(len(arr2))])
menu = Menu(root)
canvas.create_window(0, 0, anchor=NW, window=frame)
date += datetime.timedelta(1)
p = multiprocessing.Pool()
csv_writer.writerow([str(random.random()) for i in range(cols)])
keys.insert(a)
print(repr(cell_value))
print(x)
print(a)
print(df)
fig.tight_layout(rect=[0, 0, 0.9, 1])
size = np.bincount(label.ravel())
self.fields.pop(field_name)
pformat(obj)
shutil.copyfileobj(r.raw, f)
print(print_path(root_node))
app.logger.setLevel(logging.INFO)
child_process.terminate()
data = np.array(data)
div(numericoperand(1), operand)
[list(i[1]) for i in it.groupby(l, key=key)]
sum(y > el for el in x)
np.array(l) ** np.arange(1, len(l) + 1)
shout.stop()
args = parser.parse_args()
ds.addSample((1, -1), (1,))
print(pat.findall(mystr))
all(nested_equal(x, y) for x, y in zip(a, b))
rect.set_height(h)
help(f_with_good_sig)
a = tuple(a)
counts = collections.Counter(words)
inf.close()
dist2 = (x[0:-2] - x[2:]) ** 2 + (y[0:-2] - y[2:]) ** 2
(close.where(starts).ffill() * signals).fillna(0)
cmap = plt.cm.jet
y = np.array([True, False, True, False])
ax.imshow(X, cmap=cm.gray)
c = b.reverse()
datetime.date.fromtimestamp(stamp)
fig = plt.figure()
arg
c = dict([(col, j) for j, col in enumerate(df.columns)])
lst.append(datum)
sortedusers = [userd.get(o) for o in order]
x = np.linspace(0, 10, 100)
fname.close()
self.mygraph.set_xydata(t, self.ydata)
l.sort()
dict(data=rv)
df.head()
np.random.seed(2)
(np.array(old_set) + np.array(new_set)) / 2
func()
False
[field_value(field.field, item) for item in value]
logger.setLevel(logging.INFO)
plot_window.control.show()
prior = np.exp(-np.dot(theta, betas))
assert np.allclose(xRecovered, x)
tree.add(str(result[0]))
rect.set_height(h)
tens, ones = divmod(number, 10)
self.assertEqual(self.nu.test_marshal(), self.nu.FORMAT % self.nums)
print(html_to_text(n))
opener = urllib.request.build_opener(handler)
print(string)
str(b)
i = random.choice(list(range(len(l))))
msg = MIMEMultipart()
fig, ax = plt.subplots(1, 1)
False
float(x)
plt.show()
page = opener.open(url)
clips.PrintFacts()
os.remove(logfilepipe)
items.append((last_seen_date, headline, link))
date_to_datetime(d)
screen.refresh()
self.func.__repr__()
l.sort()
plt.subplot(121)
time.sleep(4)
indices = defaultdict(lambda : defaultdict(set))
xml_string = urllib.request.urlopen(url_link).read()
self.children = []
np.sin(x)
resultlist.append(item)
occurences = np.where(a == a.max())
print(so.lower())
collections.defaultdict.__init__(self, list)
d = dict(p1=1, p2=2)
ax.yaxis.set_major_formatter(y_format)
sub_dict = {}
activity.approved = True
random.shuffle(randomRange)
g.__dict__
ax.set_xticks(data2[ndays[1], 0])
print(word[:j] + word[j + 1:])
cursor = connection.cursor()
CV_Assert(img.depth() != sizeof(uchar))
print(s)
counts.most_common(len(counts))
opener = urllib.request.build_opener(NoRedirectHandler())
hash.update(str(time.time()))
t.to_datetime()
doc.Close()
tuple(sum(base_lists, []))
map(poison, L)
_empty(*args, **kwargs)
event.categories.count()
test(a)
value.split(char)[index]
func()
p + geom_histogram(binwidth=1)
mvnorm.pdf(x)
prices = numpy.arange(10000.0, 50000.0, 10000.0)
s[np.searchsorted(b, a, sorter=s)]
n = int(input())
df
(self.name, self.location) == (other.name, other.location)
self.stdout.write(output)
queryset = Foo.objects.all()
do_something()
obj.delete()
my_data = np.array([json_string, json_string, json_string])
mos_x, mos_y = pygame.mouse.get_pos()
run_bash(submit_cmd)
df[cols].apply(lambda values: sum([(v ** 2) for v in values]), axis=1)
self.view.resizeColumnsToContents()
print(df.dtypes)
soup = BeautifulSoup(page)
net.addConnection(FullConnection(bias, hidden1))
doctest.testmod()
Y = np.dstack([X] * 4096)
df[k] = pd.eval(v)
b[not_index.reshape(-1, 1), not_index] = a
output = p2.communicate()[0]
p.terminate()
db.commit()
self.next_chunk = self.next_chunk + next(self.it)
random.shuffle(control)
len(parser.parse_known_args(option.split())[1]) != 2
c[firstname] += 1
array[idx]
image = Image.open(sys.argv[1])
new_data = next(tail)
o.many2many.add(ModelA.objects.get(id=1))
syslog.setFormatter(formatter)
(4,) + (7,) * 12
dict((k, to_dict(v)) for k, v in list(d.items()))
signal.signal(signal.SIGALRM, _handle_timeout)
text = f.read()
words = (line.strip() for line in f_in)
print(m.result.group(1))
f(*arg_tuple)
days.setdefault(dt.toordinal(), []).append(dt)
result.append((x[0], x[1], step))
grouped.first()
my_schema = json.loads(my_text_file)
print(network)
[0, 0, 5, 6, 0, 0, 0, 0],
search_response = urllib.request.urlopen(url)
r = csv.reader(v)
my_func.foo = new_foo
handle.set_visible(True)
print(len(headers))
datetime.datetime.fromtimestamp(2047570047)
[1.0, 0.0, 0.0, 0.0, 0.0, 1.0],
g = file(path_to_bigfile)
full_real_path = os.path.realpath(sys.argv[0])
d = {e: (0) for e in s}
mpp.start()
app = QtGui.QApplication([])
app = QtGui.QApplication(sys.argv)
original(list(a), list(b))
reader = csv.reader(f)
sha = hashlib.sha256(pub_key_der).hexdigest()
print([mean(cluster) for cluster in cl.getlevel(1.0)])
z1[np.where(z1 == input_array.shape[2])] = z0.max()
data = pd.DataFrame(raw_data)
z = self.im.get_array()[int(y), int(x)]
set(second_list).difference(dic)
print(os.readlink(__file__))
bigList2.append(bigList2.pop(0))
heatmap, xedges, yedges = np.histogram2d(x, y, bins=50)
platform.version()
self.pp.transport.write(data)
self.top.destroy()
gbl[moduleToImport] = importlib.import_module(moduleToImport)
axis.set_minor_locator(mpl.ticker.AutoMinorLocator())
date -= timedelta(days=7)
g(x=1, y=2)
self.cells.append(Cell(self, i))
firstvals = y[0] - np.abs(y[1:half_window + 1][::-1] - y[0])
print(len(tweets))
[1.0, 0.0]
clock = pygame.time.Clock()
print(np.allclose(res1, res2))
x[0] += 1
df = pd.DataFrame()
parser = argparse.ArgumentParser()
remote_file.write(in_string)
rank_a = dict((k, v) for v, k in enumerate(a))
email_body = data[0][1]
field2 = models.CharField(max_length=10)
a[indices]
new_dict = old_dict.copy()
soup = BeautifulSoup(response.get_data())
arr = np.linspace(0, 50, 100).reshape((10, 10))
seq_type().join(filter(seq_type.isdigit, seq))
print(nums.count(1))
loudness_of_chunks.append(chunk.rms)
results = cursor.fetchone()
line_offset.append(offset)
match.group(1), match.start(1), match.end(1)
self.transport.loseConnection()
plt.show()
Y += np.random.normal(scale=0.1, size=Y.shape)
names.append(codegen.to_source(node))
lines = ax.get_lines() + ax.right_ax.get_lines()
pl.xticks(X, list(d.keys()))
win.setCoords(0.0, 0.0, 10.0, 10.0)
type.__new__(cls, name, bases, dct)
plt.show()
x = np.linspace(0, 2 * np.pi, N)
instance = forms.ModelForm.save(self, False)
addch(ch)
print(min(map(min, Q)))
path.reverse()
root.mainloop()
process(line)
print(student.name)
a / n * (x / n) ** (a - 1) * np.exp(-(x / n) ** a)
phases = numpy.random.uniform(0, 1, 10)
timestamp = int(nanoseconds / 100) + 122192928000000000
array_pointer = ctypes.cast(Data, ctypes.POINTER(ArrayType))
df
db_field.formfield(**kwargs)
event = Event.objects.get_for_object(self)[0]
print(str(correctDate))
fig, ax = plt.subplots(1, 1)
user.set_password(password)
model.sims(replace=True)
a = hashlib.sha256(mypass).digest()
s.quit()
fd.write(hash_string)
[job1]
old = f.read()
math.acos(0)
df.apply(lambda x: x.set1.union(x.set2), axis=1)
print(str(most_common))
set.union(*list(obj.values()))
numpy.vstack((a, b)).T
z1.close()
appstats_DATASTORE_DETAILS = False
lg = numpy.log(pdf)
(x + pad_by * (max_len - length) for x, length in zip(lst, lengths))
user = query(User).filter_by(id=1).one()
response = urllib.request.urlopen(URL, parameter)
my_field.my_filter = True
X.add_nodes_from(list(pos.keys()))
key_list.append(td.text)
[2, 2, 2]
req.get_remote_host(apache.REMOTE_NOLOOKUP)
result.delete()
data = stream.read()
figure(1)
l = sc.recv(1024)
Arr1 = Arr1.reshape((100, 10, 1))
list1.append(dict1.get(key))
os.path.splitext(fname)[0][8:]
json.loads(a)
d = {}
p.join()
do_something()
df
id = db.Column(db.Integer, primary_key=True)
self.Bind(wx.EVT_BUTTON, self.onButton, btn)
self.value[0](*args, **kwargs)
roi_gray = cv2.cvtColor(roi, cv2.COLOR_BGR2GRAY)
words = t.split()
print(df[years_month])
Base.metadata.drop_all(engine)
a = x[0]
self.setAttribute(Qt.WA_TranslucentBackground)
User = get_user_model()
Image.fromarray(np.asarray(image)).show()
len(syllables)
a = C()
logout_user()
arbiter.start()
frame.grid_rowconfigure(2, weight=1)
self.items.append(item)
cursor = connect.cursor()
cron2.every_reboot()
EmailAddress = db.Column(db.String(255))
y = np.sin(50.0 * 2.0 * np.pi * x) + 0.5 * np.sin(80.0 * 2.0 * np.pi * x)
screen = curses.initscr()
li = [-1, -1, 2, 2, -1, 1, 1, 1, 1, 1, -1, -1]
func.current_date(type_=types.Date, bind=engine1)
i += 1
deletenew_image, image
(self - _EPOCH).total_seconds()
im = Image.open(filename)
title = models.CharField(max_length=50)
sel = Selector(response)
sys.exit(0)
cur.executemany(query, values)
sequence, best[-1]
application = django.core.handlers.wsgi.WSGIHandler()
myTuple = tuple([int(source), int(target)])
flt = float(random.randint(0, 100))
largest = [(key, -value) for value, key in largest]
ij = np.vstack((i, j))
sftp.close()
trel
keys.insert(b)
lineNum += 1
x = tf.constant([0.2, 0.7, 1.2, 1.7])
self.table.itemClicked.connect(self.handleItemClicked)
[False, False, False, False, False],
Yf[0]
ax.set_aspect(1)
os._exit(255)
fig, ax
srv.serve_forever()
scf_1104442824510(987)
txn.commit()
tool.stderr.close()
str(1)
ndtri(0.95)
driver = webdriver.Firefox(firefox_profile=firefox_profile)
hello()
e = cv2.cvtColor(c, cv2.COLOR_BGR2RGB)
listOfA, listOfB = [], []
bee = ZigBee(ser)
np.intersect1d(av, bv).view(a.dtype).reshape(-1, a.shape[1])
pagehandle = urllib.request.urlopen(theurl)
print(repr(track))
mailserver.starttls()
print(get_selected_text_from_front_window())
chars.extend([digit, symbol])
thirdList.append(listName.index(y))
print(args.cmd)
entity2_id = Column(Integer, primary_key=True)
time.tzset()
1.0 / (1.0 + np.exp(-z))
a[0].shape
array([46]), array([62]), array([61])
cgi.test()
host_data = list()
app = QtGui.QApplication(sys.argv)
uuid.uuid1().hex
my_list1 = [i[1] for i in my_list]
x[i], x[j] = x[j], x[i]
results = [output.get() for p in processes]
resp = conn.getresponse()
Chainable(list(self.method(self.data, *args, **kwargs)))
response.read()
time.sleep(1)
root = Tk()
a = pd.Series([1, 4, 5, 7, 8], index=index)
print(fib(n))
s.upper()
-cr.fetchall()
plt.show()
editor.setCurrentIndex(int(index.model().data(index)))
y = y1 + (y2 - y1) * t
_.group(1)
print(r.text)
df.ix[0] - df.ix[1]
wx.Frame.__init__(self, *args, **kwargs)
paired = [list(t) for t in chain(zip(chain_a, chain_b), zip(C_iter, D_iter))]
session._new = {}
plt.show()
ax.lines.remove(wr())
f.close()
start = datetime.datetime.now()
print(path)
old = sys.stdout
request = urllib.request.Request(url)
rr, tt = zip(*[(i * 10, i * 12) for i in range(4)])
max_y = np.log10(max(y))
process = [do_with_line(line) for line in f]
print(a, b)
funcList.append(lambda m=m: callback(m))
ax.xaxis.set_major_formatter(plt.FixedFormatter(names))
self.csock.setblocking(False)
df
plt.contourf(data, cmap=cmap, levels=[1, 4, 8, 10])
{{file}}
dict(re.findall(pattern, val))
gca().add_patch(rect)
__all__.append(name)
self.constant
mydict[i] += 1
path = os.path.join(settings.MEDIA_ROOT, dir_name)
print(tuple(choice(choices) for _ in range(4)))
Results.objects.all()
json_object = json.loads(json_string)
codeOut.close()
execlist[i][2] = myx
frame.Show()
ax.plot(x[i * 6:(i + 1) * 6], y[i * 6:(i + 1) * 6])
new_queryset
reset = lambda df: df.reset_index(drop=True)
f = cv2.cvtColor(c, cv2.COLOR_RGB2BGR)
self.right.append(v)
result.append([])
b[-1][1] = max(b[-1][1], end)
foo[0][0] is moo
ndimage.map_coordinates(data, [zi, yi, xi])
k = [str(x) for x in list]
cache = [next(it) for i in range(n)]
contact_form = ContactForm(request.POST, instance=my_contact)
u.save()
sys.path = sys.path[:]
node0.start()
c = db.cursor()
tuple((m, m) for m in MONTHS)
ax = fig.add_subplot(1, 1, 1)
view.sel().clear()
df.loc[:, :] = stacked.unstack()
print(line)
nx.draw_networkx_labels(G, pos, labels=node_labels)
pylab.draw()
assert list(itersplit(sample1)) == sample1.split()
func()
grid.flat[ind] = 100
curs.close()
c.update({k.upper(): v})
displayname = firstname + lastname or username
print((x + y)(1))
print((id(n), id(n1), id(n2)))
now = datetime.now()
form = cgi.FieldStorage()
locale.setlocale(lang)
chunk = len(data)
Counter(strs)
do_something_else(lines_of_interest)
len(self.crawler.engine.slot.inprogress)
plt.colorbar()
plt.show()
Parent.__new__(cls, value)
x = np.arange(2 * np.pi, step=0.01)
line
do_stuff()
widget = QtGui.QWidget(self)
pyassoc
self.webview.clearHistory()
f(*args, **kwargs) + 1
inner2()
compose(f, f)
freq, bins = numpy.histogram(values, bins)
DEBUG = True
type(s)
x = [[1, 2], 1, 1, [2, 1, [1, 2]]]
midlen = len(oldstr) / 2
x = np.asarray(x)
canvas.grid(row=0, column=0, sticky=N + S + E + W)
ccw(A, C, D) != ccw(B, C, D) and ccw(A, B, C) != ccw(A, B, D)
np.setdiff1d(a, a[mask])
reads = [p.stdout.fileno(), p.stderr.fileno()]
l.sort(key=getvals)
person = models.ForeignKey(User)
print(settings.fileName())
a = np.arange(16).reshape((8, 2))
df2 = pd.concat(yearly_month_stats, axis=1, keys=years)
writer.writerow(row)
filtered = img.copy()
cap.set(cv2.cv.CV_CAP_PROP_POS_FRAMES, pos_frame - 1)
docker.wait(contid)
model.docvecs[0]
methodReference.__self__
gtk.main()
response
signal.alarm(10)
min_kmeans.fit(vectors)
fig, ax = pl.subplots(figsize=(12, 4))
b.select_form(nr=0)
x[0] -= D[n - 1] * np.sqrt((x * x).sum())
conn.setopt(pycurl.WRITEFUNCTION, body)
aMethod.__code__.co_argcount
full_path = os.path.join(folder, file)
print((line1, line2))
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
AtoCIm.append(Image.open(image))
log.start()
imshow(threshold, cmap=cm.Greys_r)
getcontext()
print(Rational(1, 2) in i6)
p.communicate(value)
nowtimestamp = time.mktime(nowtuple)
a[:0] = [4]
u[i] = len(item)
now = pytz.utc.localize(datetime.utcnow())
newObject = className()
ax.xaxis.set_major_formatter(mtick.FuncFormatter(ticks))
image.show()
sum(b, a)
workList = yourList[::]
cert = X509.load_cert(sys.argv[1])
ax2.set_xticks([])
self.put()
name = models.CharField(max_length=50)
plt.draw()
tab = pd.crosstab(df.A > 0, df.B > 0)
result.extend(list(range(int(x), int(y) + 1)))
sum([(1) for ch in s if ch.isalpha()])
df = df.transpose()
c1.commit()
b = np.tile(a, 1000)
reader = csv.DictReader(fp)
circles = cv2.HoughCircles(gray, cv.CV_HOUGH_GRADIENT, 1, 10)
tornado.ioloop.IOLoop.instance().add_callback(client.watch_queue)
app = QApplication(sys.argv)
os.isatty(fd)
pdb.Pdb.__init__(self, completekey, stdin, stdout, skip)
sys.exit()
x, y = 0, 6
y = random.randrange(box[0][1], box[1][1])
xml_files.sort(key=os.path.getmtime)
emp = Employee.objects.get(pk=id)
self.request.sendall(self.data.upper())
window = gtk.Window(gtk.WINDOW_TOPLEVEL)
main.py
my_str = my_str.strip()
out.release()
globals()[key] = my_shelf[key]
f(*args, **kwargs)
fig.clf()
args = parser.parse_args()
thing.__init__.__func__.__closure__[0].cell_contents
cbar_ax = fig.add_axes([0, 0, 0.1, 0.1])
X, Y = np.meshgrid(x, y)
http = httplib2.Http(cache=memcache)
results.append((numbers[0], numbers[1:]))
foo.__code__.co_cellvars
nelangs.append(nelang)
matcher(l1, l2[1:]) or matcher(l1[1:], l2)
print((ca.key[0], ca.values[0], ca.values[1], ca.title[0], ca.index))
[0.0, 1.0, 0.0, 0.0, 0.0, 1.0],
et.write(sys.stdout, pretty_print=True)
start_ipython()
new_list = map(f, it.takewhile(condition, l))
numpy.core._dotblas.__file__
working_dir = os.path.dirname(__file__)
result.append(prods)
iter(item)
np.in1d(aView, bView)
self.layoutVertical.addWidget(self.label)
f.write(data)
result = {name: result}
max(l)
root.clear()
txt = urllib.request.urlopen(target_url).read()
line = line.strip()
match.groupdict()
SocketServer.TCPServer.allow_reuse_address = True
p = Popen(cmd, shell=True, cwd=newpath)
element = wd.find_element_by_link_text(self.locator)
plt.grid(True)
rect(ctx, (0, 0), (width, height), stroke=False)
cursor.execute(sql, params)
img1x = img1.shape[1]
os.dup2(desired_output_file.fileno(), sys.stderr)
df.loc[df.index.is_quarter_end]
LOOKNEXT = False
plt.bar(his[1][1:], his[0])
print(item)
admin.site.register(Report, ReportAdmin)
app = flask.Flask(__name__)
app = QtGui.QApplication(sys.argv)
pic.setGeometry(10, 10, 400, 100)
left.put(n[1::2])
messages = q.get_messages()
tk.Canvas.create_oval(self, *args, **kwargs)
results = api.retweets(firstTweet.id)
print(data.read())
result = list(Blog.objects.values())
self.config(width=width + w)
video2 = cv.CaptureFromCAM(1)
plt.plot(bins, mlab.normpdf(bins, mu, sigma))
image /= image.max() / 255.0
new.append(new_word.lower())
self.factory.echoers.append(self)
arr = np.empty(find_shape(my_list))
QLabel.__init__(self, parent)
queue.put((-priority, item))
np.dot(np.sum(bidule, axis=1).T, betas)
print(random_with_N_digits(2))
np.degrees(angle)
sec_perf.reindex_axis(secs, 1)
ax = fig.add_subplot(111)
scipy.stats.norm(100, 12)
msg.attach(part)
pruned
apply(operator.itemgetter, tuple(b))(a)
sshcon.set_missing_host_key_policy(paramiko.AutoAddPolicy())
print(data)
1, 0, 0.572864624, 0.725615079
1, 0, 0.578792198, 0.100698871
plt.xticks(rotation=0)
p12.get_ca_certificates()
l = QtGui.QVBoxLayout(self)
func(*cargs)
edit_user = relationship(User, foreign_keys=[last_edit_user_id])
x[~I]
writer = csv.DictWriter(fout, fieldnames=fields)
print(pandas.__version__)
p.join()
sys.stdout.write(str(squared(x)))
b.__dict__
type.__new__(cls, name, bases, dict(classdict))
get_lerp_factor(2, list(range(8)), 6)
x * arr[:-1] + y * arr[1:]
fun = lambda x: (x[0] - 1) ** 2 + (x[1] - 2.5) ** 2
print(pd.DataFrame(ser).T)
int(offset.total_seconds() / 60 / 60)
values = map(lambda key: d[key], list(d.keys()))
sess.run(init)
q.register(stdout, select.POLLIN)
csv_from_excel(sys.argv[1])
MyFrame().mainloop()
pool.close()
print(headers.getvalue())
self.count += 1
print(df.groupby(df.A // 2).A.nsmallest(2))
sorted(x)[len(x) // 2]
tgtdates = [datetime.date(2011, 8, 29), datetime.date(2011, 8, 1)]
wx.Panel.__init__(self, parent)
serializer(obj)
nat_check(nat)
x = np.arange(20).reshape(2, 10)
wrapper
smtp.quit()
v.set(garbage)
merge(a, b, lambda in_a, in_b: in_a and in_b)
user.save()
d = dict(key_value() for i in range(1000000))
bins = np.linspace(df.a.min(), df.a.max(), 10)
opener = urllib.request.build_opener()
_f_array[:, (b)]
fig, ax = plt.subplots(1, 1)
raise AttributeError
pipe.stdin.write(result_1)
f2.save()
lv.sort()
b = np.append(a, [4])
browser = webdriver.Firefox(firefox_profile=profile, capabilities=capabilities)
print(sequence2)
time.sleep(1)
l.append(id(v))
sys.exit(main(sys.argv))
d.replace(hour=0, minute=0, second=0, microsecond=0)
cursor.close()
map(lambda x: x - 1, args)
x = np.linspace(-1, 1, 500)
client.send(response)
print(G.edges(data=True))
messageJSON = json.dumps(message, ensure_ascii=False)
items[0]
globals.default()
c[key] = list(set(a[key]) - set(b.get(key, [])))
class_id = db.Column(db.Integer, primary_key=True)
A = np.vstack([A, newrow])
M[:, (1)] *= 2
main()
print(list(igroups([])))
words = text.split()
[iter(List)] * 2
data = data.reshape(data.shape[:-1])
reader = csv.reader(f)
self.loop.call_soon_threadsafe(task.cancel)
metadata = MetaData()
offsets = [94.0, 95.0, 96.0, 97.0]
fit.apply(lambda x: d[x.name].inverse_transform(x))
classifier.fit(data[:n_samples / 2], digits.target[:n_samples / 2])
cv.SetCaptureProperty(video1, cv.CV_CAP_PROP_FRAME_HEIGHT, 600)
in_memory_blocks = numpy.random.randint(0, _BLOCK_MAX + 1, blocks_per_flush)
groups = IT.groupby(zip(*idx), key=operator.itemgetter(0))
dis.dis(lambda : Foo().bar.add(1, 2))
b[the_slice]
a[:-1, 1:]
A.__init__(self, 4)
[[value for i, value in enumerate(l1) if j == l2[i]] for j in set(l2)]
attr(random.randint(1, 100), *args, **kw)
dis.dis(take2)
List = list(range(1, 20))
df = pd.read_csv(StringIO(text), index_col=0)
self.x + other
print(len([item for item in values[:, (0)] if item == 0]))
main()
method(*args, **kwargs)
len(b)
c = stdin.read(1)
num_rows = np.sum(np.max(partitions, axis=1))
y = np.array([5, 20, 4, 18, 19, 18, 7, 4])
a = np.random.rand(20)
mask = np.zeros(img.shape[:2], np.uint8)
self.axes = self.figure.add_subplot(111)
a = np.arange(9)
wp.A.plot()
Response({}, template_name=template.template.name)
print(japanese)
ctx.set_font_size(font_size)
wilma.delete()
reader = csv.reader(f)
psutil.get_pid_list()
featureSelector.fit(X_train_data, Y_train_data)
styles = getSampleStyleSheet()
pool.close()
zook.myfunc()
im = Image.open(image)
defaultdict.__init__(self, *args, **kwargs)
conn.sendall(output)
c = np.max(b, axis=0)
word = line.rstrip()
pak[TCP].remove_payload()
os.setresgid(0, 0, -1)
clf.fit(X[train_idx], y[train_idx])
f.flush()
b = np.random.randint(0, 50, 1000.0)
print(td.get_text())
utc_offset = fromtimestamp(ts) - utcfromtimestamp(ts)
self._values.append(value)
value
input = sc.textFile(inputFile)
self.quit(file)
y = data[:, (1)]
csr.eliminate_zeros()
google - cloud
os.path.dirname(f)
p = sns.kdeplot(data, shade=True)
node.set_data(node.get_next())
print(cython.typeof(a))
print(resargs)
encoded = base64.b64encode(sys.stdin.read())
soup = BeautifulSoup(data)
entry2.grid(row=1, column=0)
slice(start, stop, step)
max(get_segstarttime(), get_jobstarttime())
all_messages = []
plt.figure(1)
fig = plt.figure()
cmap = mpl.cm.jet
k += 1
et = etree.ElementTree(root)
value = 1
vscrollbar.config(command=canvas.yview)
np.random.shuffle(ar)
p.start()
cheesiness = models.IntegerField()
all_module_names.extend(additional_module_names)
a[2] += [5]
gram_matrix = np.zeros((X.shape[0], Y.shape[0]))
setup(**setup_args)
plotx, plotz = np.mgrid[-4:4:100j, -4:4:100j]
x = np.arange(100)
cheesiness = models.IntegerField()
sum(log(stats.weibull_min.pdf(x, p[1], 0.0, p[0])))
nonlinsolve([x ** 5 + x ** 2 + 1], [x])
print(foo.myfunc.__doc__)
os.unlink(file_path)
id = Column(Integer, primary_key=True, autoincrement=True)
words_to_count = (word for word in word_list if word[:1].isupper())
qapp.exec_()
_curried_func(*(args + moreargs), **dict(kwargs, **morekwargs))
a + b
xticklabels = ax1.get_xticklabels() + ax2.get_xticklabels()
combo = gtk.combo_box_new_text()
a = A.objects.get(pk=A_pk)
0.6411, sym2, 5, 5, 10, 10
inf.close()
a = np.ones((10, 5))
0.250478029251
os.kill(os.getpid(), signal.SIGUSR1)
now = datetime.datetime.now()
plt.yticks([])
cinqdf = pd.DataFrame(cinqdata)
f
tk.Frame.__init__(self, parent)
now_aware = pytz.utc.localize(unaware)
screen = pygame.Surface((width, height), flags, depth)
streak += 1
app.MainLoop()
str(timedelta(seconds=elapsed))
related_tables = [prop.target for prop in relation_properties]
[1, 42] in a.tolist()
result.append(s)
stream.close()
my_array = np.empty((2, 2), dtype=float)
ax = plt.figure().add_subplot(111)
tk = tkinter.Tk()
print(merged_dict)
output = np.zeros((N, N))
pyplot.legend()
sys.exit(main(sys.argv))
lists([12, 4, 15, 11])
plt.axis([0, 7.02, 7 / r, -0.5])
parser = etree.HTMLParser()
str = base64.b64encode(imageFile.read())
print(test.somevalue, id(test))
b = copy.deepcopy(a)
print(df)
parent.get_toplevel().child_focus(gtk.DIR_TAB_FORWARD)
math.pow(-i, 4)
print(df.shape)
szr.Add(self.button_1, 0, wx.TOP | wx.BOTTOM | wx.ALIGN_CENTER_HORIZONTAL, 5)
string[:i + 1]
self.assertFieldsEqual(self.nums, self.initFields)
False
p = Process(target=f, args=(lst,))
sock = socks.socksocket(socket.AF_INET, socket.SOCK_STREAM)
self.driver.close()
x.b
raise socket.gaierror
plt.scatter(x, y, alpha=0.1)
mfun
a = np.arange(start, stop + step, step)
Mids1 = [1125, 1187, 1125, 1156, 1156, 1156, 1140, 1140]
Tops2 = [1125, 1125, 1125, 1125, 1125, 1250, 1062, 1250]
self.setPos(pos)
menu.addAction(exit)
session.add(c2)
np.random.shuffle(indices)
doc = Study(**data)
s[4]
import_delorean()
as_strided(b, shape=b.shape, strides=strides)[a.shape[0]:]
fig.subplots_adjust(bottom=0.2)
seen.add((x, y))
coords = np.vstack((xi, yi))
output.append(json.dumps(item))
sig2 = sin(t1 / 2) + np.random.normal(scale=0.1, size=len(t1))
items.append(lambda i=i: dump(i))
d = defaultdict(int)
w.write(f, s)
self.worker.join()
dictionary = {}
ax = fig.add_subplot(iplot)
l1 = [x for x in l1 if x not in l2]
lena = scipy.misc.lena()
map(a.__getitem__, b)
canvas.pack()
ids.append(map(lambda tup: tup[0], c[0:K]))
[991]
[997]
pool = multiprocessing.Pool(4)
list(chain.from_iterable(new_lis))
print(df)
source_vertex = graph.vs[source_vertex_id]
a[0][0] = 1
app = App()
do_something()
c[1::2] = b
files = glob(sys.argv[1])
unsearched.put(path)
fig = plt.figure()
{{x.y}}
nested_list = map(partial(map, str.upper), nested_list)
data = f.read()
result = [w for w in vocab if len(w) >= 8]
part.get_payload()
False
besseli_vec(0, A)
firstnames = [item[0] for item in all_data]
yd = line.get_ydata()
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
print(os.getuid())
print(page_source)
k = plot((0, 1), (1, 1))
self.stopButton.clicked.connect(self.simulRunner.stop)
image = gtk.image_new_from_stock(gtk.STOCK_ABOUT, gtk.ICON_SIZE_DIALOG)
my_list[7:10], my_list[2:4] = my_list[2:4], my_list[7:10]
index = numpy.argmin(nplats)
list_dir()
drives
y_true = [0, 1, 2, 0, 1, 2, 0, 1, 2]
False
zip_longest(fillvalue=fillvalue, *args)
Wizard.Finish.Click()
myplt.setmydefaults()
x = np.random.randn(5000, 200)
sys.stdout.flush()
df = df.groupby(by=df.columns, axis=1).mean()
func2()
utc_datetime = datetime.datetime.utcnow()
sys.stdout = sys.stderr
cv2.rectangle(im, (x, y), (x + w, y + h), (0, 255, 0), 2)
DIRNAME = os.path.abspath(os.path.dirname(__file__))
df = pd.DataFrame(np.fromstring(arr, dtype=np.uint8).reshape(-1, 8) - 48)
q = session.query(Foo)
main()
b.index[b.argmax()]
G = np.vstack([np.ones_like(x), x, y, z]).T
print(lilfoo.bar)
mask = np.zeros((nrows, ncols), dtype=bool)
bar()
print(local_tz.localize(datetime(2012, 1, 15)))
ax2 = ax1.twinx()
main()
sys.excepthook = excepthook
A = np.random.random((10, 2)) * 100
x.loc[(x.date.idxmax()), :]
process(data.get())
grid(True)
arr[ind]
w.write(list(map(lambda j: i + j, list(lambda j: i in j, listStrings))))
l[0] += 1
gpsgvqsbixtwyakp
self.ssh = paramiko.SSHClient()
sorted_lines = sorted(f, key=operator.itemgetter(slice(0, 24)))
d = {k: recur_dictify(g.ix[:, 1:]) for k, g in grouped}
dict_writer = csv.DictWriter(output_file, keys)
help(datetime.datetime.replace)
unique_values = set(chain.from_iterable(list(d.values()) for d in dictionaries_list))
vmatch = np.vectorize(lambda x: bool(r.match(x)))
ard = serial.Serial(port, 9600, timeout=5)
self.someValue = value
Response(api_result)
x = np.arange(n)
outer.append([e for i, e in g if e != N])
pxi = points[i, 0]
_KDGETLED = 19249
self.Destroy()
Counter(str1)
br.set_handle_refresh(False)
a = numpy.arange(-10, 10)
mask = np.eye(out.shape[0], dtype=bool)
layout = QtGui.QVBoxLayout(self)
toss = np.random.randint(0, 2, 100)
number = int(line)
s = str(i)
wtr = csv.writer(result)
sys.getsizeof(a)
A.setdiag(list(range(1, 11)))
do_stuff()
np.random.seed(1)
parsed = urlparse.urlparse(url)
self.matrix.__getitem__(index)
ff = webdriver.Firefox()
output.close()
cal_window.add(cal_vbox)
parser = etree.XMLParser(remove_blank_text=True)
offsetx, offsety = np.meshgrid(list(range(960)), list(range(540)))
binary_erosion(D, kernel2, border_value=1).astype(int)
soup = BeautifulSoup(open(sys.argv[1]))
self.assertEqual(message, send_message)
swapped = binascii.hexlify(y)
learn(Xtest, Xtrain, Ytest, Ytrain, 5)
list(map(cube, list(range(1, 11))))
im2 = Image.new(im.mode, im.size)
L = [x for i in range(n)]
x[:] = [(not y) for y in x]
print(result.group(0))
encodings.idna.ToASCII(label)
n = len(nums)
pattern[i::4] = -1
self.instance.project_set.add(project)
str(lst[0]), []
hidden_field = forms.CharField(widget=forms.HiddenInput())
print(url_string)
ax.add_patch(circle)
name = models.CharField(max_lenght=255)
print(table_row.format(**row))
my_list = sys.argv[1].split()
dotproduct = (c.x - a.x) * (b.x - a.x) + (c.y - a.y) * (b.y - a.y)
x = np.arange(10)
a, b, c, d, e, g, h, i, j = (True,) * 9
output.write(aes_engine.encrypt(input.read()))
print(vectorizer.get_feature_names())
print(args.columns)
plt.hist(nd, normed=True, bins=n_bins0, alpha=0.5)
req = urllib.request.Request(uri)
print(line_num)
fn(decoratee, *args)
{key: [subdict[key] for subdict in ds] for key in ds[0]}
sort - Vu
db.session.merge(provider)
iter = [random.randint(0, 1000) for i in range(100)]
path = urllib.parse.unquote(path)
w.writerow([id] + list(rest.values()))
[(list1[i], list1[j - 1]) for i, j in zip(list2, list2[1:])]
cursor = conn.cursor()
all_zeros = not np.any(a)
print(row[1])
ax.set_frame_on(False)
(df == pd.Series(conditions)).all(axis=1)
path = os.path.join(dest_dir, file_name)
self.frame.Destroy()
df.filter(df.dt_mvmt.isNotNull()).count()
dict(form=crud())
time.sleep(1)
s.setsockopt(socket.IPPROTO_IP, socket.IP_HDRINCL, 1)
sys.exit()
list(dict(list(grouped)).values())
x.sayHello()
cv2.bitwise_and(d1, d2)
print(mymodule.__repr__())
(np.diff(np.sign(my_list)) != 0).sum()
gc.collect()
opener = urllib.request.build_opener(no_proxy)
fig = plt.figure()
[i for i, j in zip_longest(my_list, my_list[1:]) if i != j]
b = [[1, 5], [8, 12], [15, 18], [20, 24]]
app
i = np.array([0, 0, 1, 2, 2])
conn.executemany(query, test.to_records(index=False))
output[item] += 1
plt.gray()
names.append(name)
print(now2.strftime(fmt))
results = pool.map_async(foo, list(range(40))).get()
items.append((new_key, v))
print(get_python_lib())
self.put_async().get_result()
(220921999, 2427),
x = numpy.linalg.solve(a, b)
user = models.ForeignKey(User)
self.assertItemsEqual(v1, v2, msg)
graph = nx.Graph()
self.border.Add(self.sizer, 1, wx.ALL | wx.EXPAND, 5)
self.out_queue.put(path)
RNA_integers.append(RNA_dictionary[i])
f()
win.setCentralWidget(vispyCanvas.native)
print(json.dumps(pairs))
heatmap = ax.pcolor(data, cmap=plt.cm.Blues)
reactor.stop()
o = json.loads(n)
pool = multiprocessing.Pool()
lst = [a, d, b, a, c, e, e, f, g]
print(stdout.readline())
foo.__code__.co_consts[2].co_consts[2].co_freevars
repo = Gittle.init(path)
self.crawler.start()
print(a[mask])
opener = build_opener(HTTPCookieProcessor(cj), HTTPHandler())
confused_array[~mask & (numpy_array != 0)] = 2
scipy.stats.poisson.ppf([0.025, 0.975], 10)
{b.pop(0): b.pop(0) == 0}
threading.Thread.__init__(self)
yi = np.linspace(-1, 1, ngrid)
self.Bind(wx.EVT_KEY_UP, self.KeyDown)
self.server.serve_forever()
print(df)
color_producer = matplotlib.cm.ScalarMappable(norm=norm, cmap=cmap)
index = letters.index(letter)
p.show()
type(len(x))
group = map(itemgetter(1), group)
noise = np.random.normal(0, 1, 100)
math.sqrt(x + y)
id = db.Column(db.Integer, primary_key=True)
numpy.nextafter(-0.1, 1)
np.count_nonzero(a[mask])
f.read()
p.apply_async(f, args=(i,), callback=adder)
r = np.linalg.lstsq(np.c_[x, np.ones_like(x)], y)[0]
imshow(grey, cmap=cm.Greys_r)
print(f())
queue.append(new_path)
self.updater.timeout.connect(self.update)
assert not qlock.locked()
Fun.dynprop
s.shutdown(socket.SHUT_WR)
main()
cache[key]
layout.addWidget(self.button)
[0, 0, 0, 0]
conn.quit()
self.table = QtGui.QTableWidget(rows, columns, self)
print(add_time(datetime(year=2015, month=6, day=19), relativedelta(months=+1)))
df.index[0]
result = dict(cursor.fetchall())
stdin, stdout, stderr = self.client.exec_command(command)
cv2.rectangle(im, (x, y), (x + w, y + h), (0, 0, 255), 2)
vscrollbar.pack(fill=Y, side=RIGHT, expand=FALSE)
list2titles = list(st1dict[k] for k in list2)
print(sum((Counter(dict(x)) for x in input), Counter()))
A = np.cos(a) * np.cos(b) - np.sin(a) * np.sin(b) * np.sin(c - d)
map(operator.add, first, second)
ylim = ax.get_ylim()
base_datetime = datetime.datetime(1970, 1, 1)
word, s[end + 1:]
__builtin__.raw_input()
66666666, 44444
True
slice_consc(df2, 5)
A.instances.append(self)
data = file.read()
print(root.text_content())
np.lexsort((b, a))
1, 1, 8, 8
file.close()
locations = Location.objects.all()
inp_im = Image.open(imgfn)
np.log2([-1, 2, 4])
np.column_stack((which_in_a, where_in_b))
out.value_counts().head()
new_image.image.save(slug_filename, File(handle_upload_url_file(url)))
m[50:56, 50:56] += scipy.ones((6, 6))
output.write(key)
yaml.dump(test2, stream=sys.stdout)
value
self.STDIN_FILENO = sys.stdin.fileno()
print(tag.getArtist())
ax.plot(x_values, data.iloc[i])
self.wfile.write(content)
groups.rds | intersect(groups.development) | first
C = A[len(A) / 2:]
c.play()
self._thread = threading.Thread(target=self.run)
print(etree.tostring(document, xml_declaration=True))
seconds = float(seconds)
[(x, y) for x, y, label in data]
f.close()
h1.setLevel(logging.DEBUG)
qlock = threading.Lock()
k = keyfunc(item)
l
axis.set_visible(False)
main()
title = models.CharField(max_length=100)
print(turnthis)
result.append(el)
ax = plt.gca()
lms = LMS(np.zeros(filterlen), damp=damp)
Thread(target=foo())
self.table.setItem(row, column, item)
diffkeys = [k for k in dict1 if dict1[k] != dict2[k]]
mask = df.eq(df.iloc[0]).all()
fp = urllib.request.urlopen(request)
dict = {}
result = []
d = defaultdict(list)
result = new_array[0] & new_array[1]
multiprocessing.freeze_support()
help(django.utils.dateformat)
hm.HookKeyboard()
env_cmd = subprocess.list2cmdline(env_cmd)
text = text.strip()
output.addPage(page)
sum_a = [0, 0, 0]
True
utc_dt = dt.replace(tzinfo=pytz.utc)
plt.matshow(A, alpha=0.5)
response.read()
poly = GeoSeries(Polygon([(0, 0), (0, 2), (2, 2), (2, 0)]))
timer.cancel()
sleep(0.5)
Traversal.description()
d = {k: list(f.ix[k].index) for k in f.index.levels[0]}
json.JSONEncoder.default(self, obj)
print(tidx + pd.offsets.Day(15))
print(convert_excel_time(0.4006944444444))
cost1 = db.FloatProperty(default=0.0)
Py_Initialize()
y_pred = [0, 0, 0, 0, 1, 1, 0, 2, 2]
ButtonTestApp().run()
dt = datetime.date(2010, 6, 16)
list(closed_range(10, 1, -2))
l_qa.append((k, m.groupdict()[k]))
self.label.setFrameStyle(QtGui.QFrame.Box | QtGui.QFrame.Plain)
np.std(image)
s.set_debuglevel(0)
parentNode.insertBefore(doc.createComment(element.toxml()), element)
root.wm_iconbitmap(tempFile)
time.sleep(0.5)
df.mean(axis=0)
f()
main()
c.add(datetime.datetime.now())
edges.sort(key=lambda tup: tup[0] + tup[1] / 10.0)
np.allclose(a.indptr, b.indptr)
result = list(clean(flatten(lst)))
row[set_col] = val
name = models.CharField()
data = data[:-data[-1]]
print([i.type.func.id for i in raises])
MyUser.tags.all()
data = [json.loads(row) for row in data]
sys.stdout.write(line)
self.Destroy()
y = dict(a=2, b=2)
string = string[:-len(to_strip)]
ax = f.add_axes([0.17, 0.02, 0.72, 0.79])
json_data_rdd.flatMap(processDataLine(arg1, arg2))
df
cursor = db.cursor()
arguments = parser.parse_args()
rx.match(w)
curOuter = db.cursor()
np.random.shuffle(b[ndx])
cPickle.dump(mat, f, -1)
result
self.proc.kill()
l_qa.append(m.groupdict()[k])
plt.xlim((0, AUC.shape[1]))
{{body}}
fig.savefig(img)
random.choice(seq)
redemption_date.year
my_plot_2(ax2)
test = Test(1)
np.eye(M.shape[1]) * M[:, (np.newaxis), :]
browser = webdriver.Firefox()
fileExt = os.path.splitext(file)[-1]
self.q.put((False, -1, msg))
self.handleError(record)
pool = Pool(4)
np.bincount(h, weights=x)
x, y = randint(0, len(grid) - 1), randint(0, len(grid[0]) - 1)
preincrement(it)
ax.set_color_cycle(colors)
list(s)
g = globals()
print(l)
browser.set_cookiejar(cookiejar)
newParsed = json.loads(parsed[0])
numpy.allclose(c[:-1], d)
allbestcolumns = map(best6, points)
deletelist_1[int(i)]
a = ctypes.cdll.LoadLibrary(source)
main()
logging.basicConfig(level=logging.INFO)
x = np.atleast_1d(np.array(x))
word_pairs = zip(alligned1.split(), alligned2.split())
self.x
urllib.parse.urljoin(url1, url2)
globals()[module] = importlib.import_module(module)
self.rabbit_connect()
test1list = test1filehandle.readlines()
df = pd.concat([prd_df, prc_df], axis=1)
fig = plt.figure()
l2 = [[1], [2]]
codes = {v: k for k, v in list(codes.items())}
t.start()
a[b]
list.insert(2 * i + 1, list[2 * i])
foo()
idx = np.concatenate([[0], 1 + np.diff(g).nonzero()[0]])
seq == list(range(seq[0], seq[0] + len(seq), 1))
self.sock = socket
p.parse_args()
setattr(someobject, foostring, value)
blockLengthY = np.argmin(a[:, (0)] == a[0, 0])
obj.__dict__
[i for i in l if s in i]
platform.python_implementation()
out = subprocess.check_output(args, startupinfo=startupinfo)
dlfile(url)
lth = len(spitches)
cursor = conn.cursor()
fig, ax = plt.subplots(nrows=nrow, ncols=ncol)
plt.imshow(img)
df.apply(pd.Series.nunique)
logger.addHandler(log_handler1)
res = [0] * (len(_s) + len(_v) - 1)
object_list.sort(key=lambda x: key_precedence.get(x.key, default))
b.save()
df.drop(df.std()[df.std() < threshold].index.values, axis=1)
self
print(sum(1 for _ in next(groupby(l), [[], []])[1]))
hehe = MyCallable()
data_frame.to_csv(file_path, index=False)
start_date = self.start_date + add_days
dateString = parser.parse(string, fuzzy=True)
z = hstack2((x, y))
opener = urllib.request.build_opener(proxy_handler)
root = Tk()
a = np.random.random((100, 100, 100))
monday1 = d1 - timedelta(days=d1.weekday())
m.select()
attachment = MIMEText(f.read())
values = set(map(lambda x: x[1], list))
ax.add_patch(r2)
print(cleansed)
json.dumps(*args, **kwargs)
response = urllib.request.urlopen(crawling)
parser = xml.sax.make_parser()
new_list.append(list[i])
pygame.quit()
self.queue.task_done()
intervals.sort(key=lambda x: (x.end, x.end - x.start))
populations = {}
this_array[indices[0]:next_i].fill((before + after) / 2)
same(cont1, cont2, value_same)
layer.draw()
f.read()
pygame.init()
L = []
a = list(range(1, 6))
namespaceURL = resolved.namespace()[1]
{{field.field}}
zombie = Vector2(zombie.rect.x, zombie.rect.y)
bin_ip = socket.inet_aton(ip)
print(NSScreen.mainScreen().frame())
task.delay(arg1, arg2)
neat_data = z.read(z.namelist()[0])
ser = pd.Series(np.random.normal(size=1000))
(k for k, _ in self._list)
sys.exit(app.exec_())
xi = np.array([0.0, 0.5, 1.0])
dir()
session.add(w)
array(1)
img = img.quantize(palette=palette_img)
sys.argv.pop()
output_dict[int(key)] = [int(item) for item in value]
(lambda : x).__closure__[0], set_cell
module = loader.find_module(name).load_module(name)
arr = [int(num) for num in str_arr]
print(Foo())
math.exp(result)
bins.append(x1)
cv2_im = cv2.cvtColor(cv2_im, cv2.COLOR_BGR2RGB)
x = v[-1:]
self.handler.flush()
logger.addHandler(mh)
ps = [(x + dx, y + dy) for (x, y), (dx, dy) in it.product(points, offsets)]
norm = np.linalg.norm(v)
print(list(myDict.keys())[i])
ps_process.stdout.close()
deleted[k]
session2 = Session()
self.button.pack()
a = np.hstack([88, a, 77])
print(words.count(word), word)
np.nan == np.nan
k = arr.shape[0] / 2
all(values == 0)
divider = make_axes_locatable(ax)
-a * (np.exp(-t / c) - np.exp(-t / b)) / (b - c)
a = np.random.random(100)
self.send_error(500)
myNames.append(line.strip())
self.i += 1
x = np.linspace(0, 1, 100)
test2list = test2filehandle.readlines()
tweets.append(json.loads(line))
i = np.arange(0, len(pts))
timeout_timer.cancel()
np.where(x > y, x + y, x - y)
ax.add_patch(r1)
y[::REPLACE_EVERY_Nth] = REPLACE_WITH
fig.canvas.draw()
modules.clear()
results = results.exclude(published=False)
o.x = o.x.__iadd__(5)
fig, axs = plt.subplots(1, 2, figsize=(8, 5))
ax.quiver(x, y, z, u, v, w, length=0.1)
dftmtx = lambda N: np.fft.fft(np.eye(N))
tcflush(sys.stdin, TCIOFLUSH)
it = iter(iterable)
diff = np.diff(a, axis=0)
l1.append(l2)
excel.Application.Quit()
out = process.stdout.read(1)
ax1 = fig.add_subplot(5, 4, 1)
plt.hold(False)
res = ((t, nt(*t)) for t in pairs)
xs = dict.fromkeys(list(range(2)), a)
app = QApplication([])
pairs.append([i, list1.index(elem)])
filtertype = 0
interlaced = 0
root_log_handler = logging.handlers.RotatingFileHandler(file_1, *args)
soup = BeautifulSoup(data)
contains_vectorized = np.vectorize(contains)
wordbank[word] += 1
somelist[:] = filterfalse(determine, somelist)
arq.close()
rpy2.robjects.numpy2ri.activate()
self.PrepareDC(dc)
A = np.zeros((6, 6))
width = measure.winfo_width()
mainwin.add(notebook)
True
st.seed.widget.clamp_to_bounds = False
self.audio = pyaudio.PyAudio()
print(r.name)
print(parser.parse_args())
numpy.extract(choice, a)
group.append(item)
a.n
root = Tk()
width, height = image.size
writer.writerow(fieldnames)
plt.plot(df[c])
self._driver = WebDriver()
[2, 1, 8, 7, 6, 5, 4]
json_data = json.loads(data)
P.show()
print(response.geturl())
assertSequenceEqual(seq1, seq2)
x = np.random.rand(5, 2)
parser = argparse.ArgumentParser()
out = p.stdout.readline()
quitjupyter
now - then > timedelta(hours=1)
writer = csv.DictWriter(f, fieldnames=headers)
foo.Bar = superClassCreator()
loop.run_until_complete(main())
newList.append(oldList[i])
result = numpy.empty((len(r), r.max()), data.dtype)
d = datetime.date(2011, 7, 2)
window.set_size_request(200, 100)
color_list.sort(key=get_hsv)
ax = plt.gca()
decompressed = zlib.decompress(data)
structured_scrubbed = json.loads(scrubbed)
self
f.seek(offset)
type(name, bases, attrs)
ax1 = fig1.add_subplot(111)
list1[:position] + list2 + list1[position:]
matching.append([subpattern])
self.delete(*a, **kw)
ch = logging.StreamHandler()
self.resize(minimumSizeHint())
print(repr(line))
print(cron4)
assert False
plt.subplot2grid((4, 4), [0, 1], 2, 2)
m.group(0)
{parts[0]: pack(parts[1:])}
P.drawOn(canvas, 10, 10)
a = np.arange(1, 4)
prod = session.query(Product).filter(Product.id == 1).one()
maxvi = np.argsort(a, axis=1)
h.start()
-hound
opener = urllib.request.build_opener(*handlers)
xp = np.sum(Z, axis=0)
False
indices = [idx for idx, value in enumerate(a2) if value in wanted]
a, b
d = {k: d2[v] for k, v in list(d1.items())}
colnames = colnames[-1:] + colnames[:-1]
fig, ax = plt.subplots()
b = np.random.randint(n, size=k)
device.close()
response
data[i] = row
data = f.read()
self.inner_sizer.Add(self.tin, 1, wx.LEFT | wx.RIGHT | wx.EXPAND, 50)
layout.addWidget(buttons)
df = pd.DataFrame(np.random.random((5, 5)))
lambda x: x + n
print(repr(e))
mylist = sorted(mylist, key=keyfunc)
print(n)
lowers.append(word) if word.islower() else other.append(word)
cbar_ax.set_axes_locator(get_ax_loc)
x[0].upper() + x[1:]
name = models.CharField(max_length=200)
np.random.seed(0)
int(s, 16)
print(dict(urlparse.parse_qsl(qs)))
print(token.access_token)
min, max = [f(x, y) for f in (min, max)]
s(*args, **kwargs)
self._a = A()
float(x)
plt.show()
url_queue.join()
clf = svm.SVC()
list(self.values())
bg.paste(im, im)
x = [1, 1, 1, 2, 2, 2, 1, 1, 1]
resplot = res.plot()
app = Flask(__name__)
(df > 2) & (df < 10)
tornado.web.Application.__init__(self, handlers)
fig.set_size_inches(8, 11)
setup(ext_modules=ext_modules())
canvas.config(width=interior.winfo_reqwidth())
f()
destinition.put_data(data)
max(k for k in d if k < key)
list((Counter(a) - Counter(set(a))).keys())
plt.axis([-2, 2, -1, max(len(set1), len(set2)) + 1])
a = y(aVariable, bVariable)
print(numpy.bincount(B.ravel(), weights=A.ravel()))
print_x()
window_before = driver.window_handles[0]
q.queue.clear()
stringer.esc_statuses[name]
self.timeout = loop_time
tree = {}
counter = Counter(list(d.values()))
__builtins__.list
data.dtype
a[b] = a, b
mv[0], mv[1], mv[2]
G.add_node(child)
data.commit()
parser.feed(data)
a * b
df.T.fillna(s).T
[model]
root = Tk()
test = re.compile(pat(self.__MEMBER_TYPES), re.IGNORECASE)
list((expected - found).elements())
numbers = [random.randint(a, b) for i in range(10)]
input_queue = Queue.Queue()
HTML(play_beep)
self.name = name
first_name, last_name = get_name()
print(fig.canvas.get_supported_filetypes())
approximate_fraction((1 + math.sqrt(5)) / 2, 1e-05)
deleteordered_dict[i]
result = (count * phyQP + 1) / float(pubKeyExpo)
clf.fit(X_train.values, y_train.values)
hello()
form = SomeForm(request.POST, request.FILES)
plt.plot(np.cumsum(np.random.randn(1000, 1)))
f = plt.figure()
lookup_list.append([lookup[l].index(v) for l, v in zip(labels, msg)])
c = np.equal(a, b)
print(args.options)
time.sleep(2)
len(lst) - 1 - r_idx
ax.scatter(x, y, color=rgb)
self.app(environ, start_response)
s.format(x=1)
self.ax = self.fig.add_subplot(1, 1, 1)
print(item.text)
water_held
sorted(value)
[]
matrix[0][2]
s.count(s[0]) == len(s)
print(event.widget.find_closest(event.x, event.y))
df.dtypes
p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)
rslt.append((x + dx, y + dy))
hdf5_file.close()
myseries_one.iloc[0]
ga.login()
PLT.show()
[([0] * n) for _ in range(m)]
swin.pack()
list_size_1.append(row)
print(random_date(d1, d2))
sdl2.SDL_SetRenderDrawColor(renderer, 255, 255, 255, alpha)
deactivate
user = oauth.get_current_user(SCOPE)
f.read(128)
reactor.listenUDP(8000, EchoUDP())
node_count = sum(1 for _ in db.getAllNodes().iterator())
main()
bcrypt.hashpw(password, bcrypt.gensalt(12))
self.queue = Queue(1)
print(target_list[~numpy.in1d(list(range(len(target_list))), to_exclude)])
func(self.val)
loggify(Working)
result += sorted(sublist, key=g)
smallfile.write(line)
plt.show()
df
__f
self.listener.close()
df.replace(to_replace=to_replace, value=vals, regex=True)
pageContent.readline()
data_rescaled = data_rescaled.astype(np.uint8)
ax0c = fig.add_axes([0.1, 0.68, 0.8, 0.25], sharex=ax0a)
wb.Close()
paw = paw.flatten()
minval = min(a)
a + b * 2 > 5
self.root.lift()
newkeywords.update(fkeywords)
deletet[5:]
obj = someClass()
self.__dict__.update(tmp_dict)
dict.__getitem__(self, key)
logger.addHandler(fhan)
ax.scatter(data[:, (0)], data[:, (1)], c=point_values)
path = urlparse.urlparse(url).path
Sets[userID].add(rowID)
newdict[0].append(100)
self.audio_frames.append(data)
print(a == b)
pyplot.gca().add_line(line)
f.seek(0, 2)
print(x, y)
sample = np.random.rand(n, 1)
sm = plt.cm.ScalarMappable(cmap=my_cmap, norm=plt.Normalize(vmin=0, vmax=1))
answer = [item[0] for item in counter_list if item[1] == max_occurrences]
con.rollback()
data[(-1), :]
f = os.open(filename, os.O_RDWR)
win.window.input_shape_combine_mask(bitmap, 0, 0)
os._exit(0)
futures = [c.submit(f, future, param) for param in params]
coordinates = [(c for c in l.split()) for l in f]
self.clicked.connect(self._handle_click)
GST_REGISTRY
some_object
b[:, :, (1)]
img = adobe_to_srgb(img)
server.rcpt(toaddrs[0])
print(evil_vals[0] in dict_with_evil_keys)
parser = argparse.ArgumentParser()
execute()
f.write(page.read())
self.__dict__.update(state)
printTable(curPG.fetchall(), [c.name for c in curPG.description])
reverse[value].append(key)
form = ModelForm(request.POST, request.FILES, instance=obj)
plt.imshow(img, zorder=0, extent=[0.5, 8.0, 1.0, 7.0])
b().mymethod()
unittest.main()
[x for x in lst if x.isalpha()]
decorator
create_dict()
type(BT)
new = np.repeat(old[jump_indices], repeats)
list(set(a).intersection(set(b)))
port = server_sock.getsockname()[1]
_draw_points(i, 0)
self.members = 0
(-4) ** 2
cache[object_to_cache_as_string] = object_to_cache
songsJSON = json.dumps(songs)
ax.set_ylim(bottom=0)
(np.arange(n) - dfill(b))[i]
a = A()
somedict = dict.fromkeys(somelist, 1)
classes[name] = type(name, bases, {})
print(output)
tokens = list(tokenize(stream))
f[0](f[1:])
datetime.fromtimestamp(local.timestamp())
args = parser.parse_args()
fft_axes.set_ylim([0, 1000])
surf2.fill(TRANSPARENT)
_marker_type_key = db.Column(db.Integer, primary_key=True)
Row(1.0, Vectors.sparse(4, Seq((0, -1.0), (2, 0.5))))
your_template.render(timesince)
print(args)
print(type(img_str))
a.shape
time.sleep(N)
print([n for n in map(test.giveMyNum, q) if n > 1])
months = cdiff.DATE.map(lambda x: x.month)
soup = BeautifulSoup(html)
self.data.append(s)
parser.print_help()
screen = pygame.display.get_surface()
matrix = np.zeros((5, 5))
all(c in it for c in x)
kmeans_m.fit(X_hat, max_iter=100, number_of_runs=10)
my_func.foo
a = Test()
ndata[0] = 2
form = MicroForm(request.POST)
newfunc(*args, **kw)
b = dict([next(iter(x.items())) for x in bar])
df = DataFrame(books).T.fillna(0)
environment = jinja2.Environment()
p2 = Polygon(ring2.coords)
wr = csv.writer(csvfile, quoting=csv.QUOTE_ALL)
fig = plt.figure()
print([i for i, (a, b) in enumerate(zip(it1, it2), 1) if a != b])
run(reloader=True)
next_message.save()
self.finished.emit()
get(remote_path, fd)
s, img = cam.read()
A = np.array([[2, -1, 0], [-1, 2, -1], [0, -1, 2]])
register_blueprints(app)
mark_safe(template % substitutions)
lines = file.readlines()
print(str(soup))
count = lambda x: collections.Counter(c for c in x.lower() if c.isalpha())
c2.setopt(pycurl.PROXYPORT, 8081)
plt.tight_layout()
ax = plt.gca()
line.set_ydata(sin(x + i / 10.0))
divmod(10.5, 1)
shutil.move(file, destination)
my_list[1]()
pygame.quit()
Map(fold=lambda f, g: g(x), bimap=lambda f, g: Right(g(x)))
x = Obj.objects.create(name=foo)
Thread(target=runCommand, args=(command,)).start()
stdout, stderr = process.communicate()
angle = np.linspace(0, 2 * np.pi, arclen * 2, endpoint=False)
grouped.get_group(False)
os.getpid()
req = QNetworkRequest(QUrl(url))
fmap
Fx = np.random.choice(np.array([-1, 0, 0, 1], dtype=np.int8), size=(iters, n))
self.hbox.addWidget(self.label)
debug(str(s))
mod = sys.modules[name]
p = bokeh.plotting.figure(x_range=(0, 4), y_range=(0, 4), plot_height=200)
args = parser.parse_args()
s == c_string
im = sess.run(img_tf)
print(generate_list(1000))
print(list(M.values()))
show(p)
Dinvs = np.sum(Dinv)
df = pd.DataFrame(new_data)
gtk.main_quit()
fh.close()
d[parts[0]] = d.get(parts[0], []) + [parts[1]]
code = models.CharField(max_length=255)
np.polynomial.polynomial.polyfit(x, y, 4)
fig = plt.figure()
print(neighbors(A, 0, 0))
decorator
print(parsed.getroot())
cgen = (cm(1.0 * i / NUM_COLORS) for i in range(NUM_COLORS))
sys.stdout.write(msg.ljust(minwidth))
pickle.dump(member, f, pickle.HIGHEST_PROTOCOL)
x.append([x] * 5)
plt.show()
random_variable_in_range_of_minus_ten_and_plus_ten = random.uniform(-10, 10)
tcpCliSock.send(outputdata[i])
df[df[cols] < 0] = np.nan
issubclass(QuizForm, forms.Form)
a_thread.start()
thiserr = numpy.mean(better_errs)
x = np.arange(2)
my_dict = defaultdict(dict)
f()
print(row0)
self.a = a
f.close()
DOT11_CIPHER_ALGO_RSN_USE_GROUP = 256
writer.writerows(data)
rght += 1
root = Tk()
train_loader = data_utils.DataLoader(train, batch_size=50, shuffle=True)
self.xlBook.Close()
myList
x = x[:, (np.newaxis)]
np.less_equal(abs(x - y), atol + rtol * abs(y))
s2 = zlib.decompress(s1)
p2.stdin.close()
worksheet.write_string(1, 0, name_entry)
wb.save(response)
array_foo(a)
fig, ax = plt.subplots()
self.append(PoiData(lat, lon))
obj = MyClass()
data = cur.fetchall()
fullname = os.path.join(path, filename)
decay_rate = 2e-06
connection.engine.execute(myClass.__table__.insert(), l)
x = np.arange(10)
parent_parser = argparse.ArgumentParser(add_help=False)
MyThread(self.on_thread_finished).start()
output_header.append(input_header[column_index])
f.write(text2save)
self.central.deleteLater()
os.close(out_fd)
torinfo = handle.get_torrent_info()
prev_weekday(date(2012, 8, 20))
popt, pcov = optimize.curve_fit(func, x, y, sigma=sigma, maxfev=10000)
[v for _, v in sorted(zipped, key=key)]
crsr.execute(sql)
key[index].reshape(a.shape)
self.stream.write(msg)
ax.get_yaxis().set_visible(False)
print(lucky(50))
f = urllib.request.urlopen(req)
walkDict(myDict, filterFor)
B.date.apply(lambda x: in_range(x, A.start, A.finish))
root = tree[0]
loop.run_until_complete(main())
object_id = models.PositiveIntegerField()
instance.work.save()
plot_implicit(goursat_tangle)
b.append(4)
client = Client(host, port)
e + hyperbola(xcos - hsin, *pars) * np.cos(th) + xcos - hsin
seen.add(x)
self.already_computed.extend(itertools.islice(self.it, n))
fig = plt.figure()
temp_list.append(np.nan)
result = np.empty_like(X)
answer.append((key, length(iter)))
f1.seek(0)
os.remove(csvfile)
string.decode(i)
foo(z) + 1
python - V
output = sorted([1] * k + [0] * (n - k), key=lambda k: random.random())
nearness[min(nearness.keys())]
m = np.array([[1, 0, 1], [0, 1, 0], [1, 0, 1]])
lens = np.array([len(item) for item in listvalues])
plt.plot(np.arange(10) + i)
file_path = os.path.join(folder, the_file)
session.flush()
zf.close()
exit(0)
0, 1, 8, 27
a2[:x], a1[:x] = a1[:x], tmp
result
next(it)
print(b.__dict__)
context = {}
func
ax1 = fig.add_subplot(111)
arr2 = np.arange(10).reshape(2, 5)
fig, ax = plt.subplots(1, figsize=(16, 16))
soup = BeautifulSoup(xml)
Z.data *= Y[Z.indices]
result.append(idx)
cert_pem = OpenSSL.crypto.dump_certificate(OpenSSL.crypto.FILETYPE_PEM, cert)
exit(0)
setence_list.append(word)
os.close(fout)
de.show()
main()
sorted(tuples, key=lambda x: x[2])[:10]
sys.getsizeof(w)
mask[1:] |= mask[:-1].copy()
col_sums = numpy.zeros_like(img)
s = a[:, (np.array(second).reshape(-1, 1)), (third)]
pathname = os.path.dirname(sys.argv[0])
importlib.reload
table = cur.fetchall()
setattr(Something, name, decorator(fn))
self.saver.restore(self.session, fn)
self.send_response(401)
asyncore.dispatcher.__init__(self)
pprint(mindict)
[0, 1, 2],
[1, 5, 5, 5, 5]
id = db.Column(db.Integer, primary_key=True)
f()
sys.stdout = logger
spam.update()
my_time_list
plt.subplot2grid((4, 4), [2, 2], 2, 2)
set(myDict) & set(myList)
pl.show()
sys.path.append(os.getcwd())
print(retrieve_name(y))
os.path.normpath(mypath) + os.sep
redistributed_points.extend(attracted_point_list(g, a, f))
output[item] = line[i + 1] = i
c = [value for pair in zip(a, b[::-1]) for value in pair]
print(r[numpy.isreal(r)])
df
sdata = np.sort(data, axis=1)
filename = sys.argv[1]
fin.seek(0)
np.nan
output_queue.put(process_me)
Maybe(maybe.calc(lambda x: x * 2))
Xflip = flipall(X)
556, 27.0
s.close()
d = OrderedDict([a, b, c])
print(type(fresult.col1.iat[1]))
fit_df = df.dropna()
session = requests.session()
print(urlparse.urlunparse(newurl))
run_wsgi_app(application)
post_data = request.input_buffer.read(-1)
b().mymethod()
zip(list, list)
x = [0, 0, 1, 1, 2, 2]
s = etree.tostring(root, pretty_print=True)
arr[unconverged] -= f_g[new_unconverged] / fp(arr[unconverged])
((a > 0) & (a < 1)).sum()
print(urlparse.urljoin(testurl, urlparse.urlparse(cleaned).path))
plt.show()
plt.colorbar()
as_dict = dict(is_even)
l2 = [4, 5, 6]
blob_key = str(urllib.parse.unquote(blob_key))
result = [separator.join(map(str, r)) for r in result]
client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
parser = argparse.ArgumentParser()
today = datetime.now(tz).date()
foo.__code__.co_argcount
subtxt = txt[i:j]
datetime.fromtimestamp(value)
fout.close()
datetimes = [(now - dt.timedelta(hours=6) * i) for i in range(10)]
self.fh.close()
self.hbox.addWidget(self.txted)
f.truncate()
True
printArray([str(Array[i][j]) for j in j_indices])
a, b = min(a, b), max(a, b)
trip = models.ForeignKey(Trip)
print(make_hash(foo.__dict__))
widget = QWidget()
l[1]
self.stdout = sys.stdout
print((letter, count))
df.columns = df.columns.swaplevel(0, 1)
tuple(sorted(a.items()))
np.tril(df.unstack().values, -1).sum()
d[type(x)].append(x)
im1 = im.resize((tilesize, tilesize), Image.BILINEAR)
assert np.allclose(C1[:-1, :-1, :-1], C4)
heapq.heapify(a)
x[1] - x[0]
parents[b].append(a)
primary_language = Column(String(50))
a /= a.sum()
print(info.get_content_subtype())
db.session.expunge(product_obj)
generalizedEuclidianAlgorithm(b, a)
print(q.get())
print(ttaken)
print(dectest.test(a))
sum(abs(a - b) for a, b in zip(A, B))
201412
counts = collections.Counter(map(tuple, c))
deleteself.right[0:x]
out = np.split(list1.ravel()[sidx], cut_idx[1:-1])
dates.hist()
members.append(target.id)
print(repr(dest))
b = numpy.array([0, 0, 0, 0, 1, 1])
type(s)
result += str(r)
print(key.hash())
actions = webdriver.ActionChains(browser)
power(lambda x: x * 2, 0)(9)
pp.pformat(my_dict)
test(**dicC)
self.finished.emit()
painter.draw_box(*args, **kwargs)
vbox.addWidget(self.previewImage)
foo(a + b + c)
path.append(k.id_or_name())
sum(s[idx] == j for idx, j in enumerate(s, 1) if idx != len(s))
b = np.array([False, True, True, False])
ll = list(chain.from_iterable(repeat(e, 2) for e in l))
device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)
i += 1
print((i, j))
item
print(access_token)
conn, addr = s.accept()
count.most_common()
user_input = []
print(__file__)
app = Flask(__name__)
rpath
[False, True, False, True]
window.show()
Post.objects.filter(userBy__id__in=friends_and_user)
f = lambda x: Series(np.histogram(x, bins=bins)[0], index=bins[:-1])
nextList.append(newString)
today = datetime.now()
res = requests.get(URL)
os._exit(1)
html = template.render(Context(data))
view.resize(600, 400)
trigram_measures = nltk.collocations.TrigramAssocMeasures()
x = [], []
self.Bind(wx.EVT_BUTTON, self.OnOkayCanButton, canButton)
fs.delete()
print(sorted(flatten(structure)))
firefox_profile = webdriver.FirefoxProfile()
hand = random.sample(DECK, 5)
shape = np.array(arr.shape * 2)
print(len(y))
Graph().setThis(self._this.read(pathbytes))
HTML(style + df_html)
dis.dis(make_adder.__code__.co_consts[1])
cur = conn.cursor()
kd_vals = np.exp(kd.score_samples(x))
val = map1[key]
print(len(list))
a = bar.a
indices = [1, 4, 5, 6, 7]
-0.11112
plt.gca().xaxis.set_major_locator(plt.NullLocator())
mutex.release()
[(1, 5), (8, 11), (200, 202)]
pool.join()
array = np.zeros(10)
x + y
content = fd.read()
[int(0.5 + 10 ** (i * 2 / 19.0)) for i in range(20)]
x.strftime()
memset(location, 0, size)
window.show()
image_file.write(chunk)
entry = tk.Entry(self, textvariable=v)
sys.stdout = codecs.getwriter(output_encoding)(sys.stdout, errors=errors)
print(list(find_ref_names(b)))
a.write(f, os.path.relpath(f, root))
n = random.uniform(0, weight_total)
GO
self.lineedit.setFocus()
mask1 = logical_and(arange(10) > 5, arange(10) <= 8)
math.acos(inner_product / (len1 * len2))
s[s == 12]
urllib.request.urlopen(req)
mlab.outline(extent=(0, 1, 0, 1, 0, 1))
data[line[0]].extend(line[1:])
isinstance(f, numpy.float64)
ax.xaxis.set_major_formatter(ticker.FixedFormatter(ticklabels))
self.page.loadFinished.connect(self.save)
y = x[mask]
e = list(zip(*d))
diff_seconds = (mytime - datetime.fromtimestamp(0)).total_seconds()
ax = fig.add_subplot(111)
tcpSerSock.listen(5)
env.Depends(target[i], out)
plt.show()
sys.getsizeof(frozenset((1, 2)))
overlap = df.index.to_series().diff().shift(-1)
main()
fig, ax = plt.subplots()
ret = np.array([])
print(df.iloc[(-1), :])
m = np.arange(len(df))
f(x) + 1
f.close()
print(result.shape)
out[-1].append(element)
app = Flask(__name__)
a2 = np.split(a, [2, 4])
plt.show()
assert foo.bar == 5
[joiner(words) for words in sixgrams]
OrderedDict.__init__(self, *args, **kwargs)
axes.set_frame_on(frame)
mycsv = csv.reader(f)
[(a, b) for i, a in enumerate(lst) for b in lst[i + 2:]]
self.rect = Rectangle((0, 0), 1, 1)
transsurface.set_alpha(50)
print(str)
merged[k].add(d1[k])
result = {}
app = Flask(__name__)
result[line_number].append(line.strip())
graphA = tf.Graph()
plt.plot(list(range(10, 20)))
print(df1.reindex(columns=comb, fill_value=0))
output.append(pformat(environ))
c = np.hstack((a, b))
print(json.dumps(sample))
fake_writer.writerows(data)
somearray = np.random.random(100)
data = []
ids.extend(list(range(1, int(x[1:]) + 1)))
self.assertEqual(1, c.count)
(df - df2).combine_first(df).reindex_like(df).astype(int)
print(str(node))
ax = fig.add_subplot(111)
resampled_values.diff()
popen.wait()
trimmed.pop(0)
data = numpy.array([0, 0, 0, 2, 2, 0, 2, 2, 2, 0])
h = hexbin(x, y, gridsize=10, mincnt=0)
self.button = QtGui.QPushButton(self)
form.save_m2m()
stream.write(data_to_write)
len(flows[maks]), maks
dill.detect.badtypes(f)
termios.tcsetattr(file.fileno(), termios.TCSADRAIN, new_attrs)
new_failures = [t for t in tests1 if t not in tests2]
ar(a) | ar(b) | ar(c)
f(50, 50)
R_in_six_sec_interval = [R[2] for R in filtered_data]
self.causes
_basedir = os.path.abspath(os.path.dirname(__file__))
a * np.sqrt((b * c) ** 2 + (x - d) ** 2) / b + e
self.clients.remove(client)
classifier.show_most_informative_features()
authhandler = urllib.request.HTTPBasicAuthHandler(passman)
document.prettify()
func(*args, **kwargs)
print(row)
s.partition(delim)[2]
print(heapq.nsmallest(2, list1))
tuple = tuple(l)
self._list.insert(index, item)
fig.colorbar(im, cax=cax)
idcord.append(y1)
print(hi.bye)
raise SystemExit
kernel = np.array([[-1, -1, 1], [-1, 1, 1], [-1, -1, 1]])
signal.Signals(2).name
raise AttributeError(msg.format(type(self).__name__, name))
Maybe(100)
im = numpy.array(img)
im = Image.fromarray(A)
d = np.searchsorted(a, np.setdiff1d(a, b))
s.ioctl(socket.SIO_RCVALL, socket.RCVALL_ON)
gen = (i for i in range(10))
self.user.username
eval(str, os.__dict__)
method(*args, **kwargs)
dict(zip(columnNames, args))
key.set_contents_from_filename(object_name)
screen_width = root.winfo_screenwidth()
suite.addTest(suitefn())
y + np.abs(y.min())
self.name
today.year - born.year
pprint.pprint(d)
print(list(merge(tup)))
mix_arrays(A, B)
Concate[A[i]] += B[i]
pts = [(1, 1), (1, 10), (10, 10), (10, 1)]
l = list(range(1, 100, 4)) + list(range(2, 100, 4))
value.append((node_key, node_value))
body = models.TextField()
func
signchange = (np.roll(asign, 1) - asign != 0).astype(int)
cache.get(self.COUNTER_CACHE_KEY)
type(name, bases, dict)
self._pixels.append((x, y))
B = np.array([2, 4, 6, 8])
myBoxLayout.addWidget(self.listWidgetB)
img[:, :, (0)] = numpy.ones([5, 5]) * 64 / 255.0
(array[:-1] * array[1:] < 0).sum()
print(username, password)
l = s.split()
print(self.left.PreOrder())
cache[key]
conn, addr = socket.accept()
plt.scatter(xAsInts, y, color=color)
xt = DataFrameImputer().fit_transform(X)
a = np.sqrt(d)
earth = 6e+24
main(sys.argv)
word.Quit()
file.write(pickle.dumps(df))
print(i)
soup = bs4.BeautifulSoup(f)
self.assertEqual(self.flushLoggedErrors(ValueError), 1)
cur1 = conn.cursor()
out.start()
mock_last_transaction.assert_called_once_with()
cpick.set_array([])
g1.intersects(poly.ix[0])
frame = inspect.currentframe()
print((i, h, j))
HTMLParser.HTMLParser.__init__(self)
result[d[0]][d[1]] += 1
self.x2 += self.speed * math.cos(self.bearing)
sleep(1.5)
print(response.read())
p = subprocess.Popen(command, stderr=subprocess.PIPE)
main()
(1 == 1) & (2 == 2)
main()
d = dict(list(l.items()))
self.root = Tk()
self.setLayout(layout)
print(sentence_dict)
driver.get(self.login_page)
scrollby.grid(row=7, column=5, rowspan=2, columnspan=1, sticky=N + S + E)
phrase.upper()
tagger = nltk.tag.UnigramTagger(model=model, backoff=default_tagger)
ax.set_xticklabels(xlabels, rotation=20)
f(*args, **kwargs)
c1.my_numpies.append(mn2)
df = df.reset_index()
numpy.array(strings)
p.stdout.close()
writer = csv.writer(outcsv)
s = gtk.gdk.Pixbuf(gtk.gdk.COLORSPACE_RGB, False, 8, w, h)
message = cipher.decrypt(ciphertext)
my_file.write(b)
db.session.commit()
id = Column(Integer, primary_key=True)
list([t for t in list(d1.items()) if t[1] == max(d1.values())])[0][0]
image.set_at((x, y), (255, 255, 255, 0))
d = np.ones((100,))
y = np.random.normal(0, 1, num).cumsum()
PyQt4.QtCore.QPoint(90, 6)
num = num / 2
pd.DatetimeIndex(df.date).normalize()
raise cherrypy.HTTPRedirect(redirect_url)
gtk.CellRendererPixbuf.__init__(self)
a.remove(5)
queryset = MyModel.objects.all()
outbuff.append(line)
exns.append(name)
ax = plt.subplot(111)
tocm = time.clock()
df = df.copy()
print(something)
sys.stdin = sys.__stdin__
mahotas.features.haralick(img).mean(0)
a[:] = a[:].__iadd__(da)
ax.set_xlim([np.min(X), np.max(X)])
pd.isnull(df)
conn.login(username, password)
print(df)
json.dumps(json_d)
x, y = im.size
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
print((key, value))
alen = len(data)
ser.open()
a.sum()
new_list = []
all_sessions = Session.objects.filter(expire_date__gte=datetime.datetime.now())
xfmt = ticker.FuncFormatter(lambda x, pos: label_map[int(x)])
print(eval(t))
count += len(chunk)
Py_Initialize()
[capitalize_nested(s) for s in t]
Response(response_data)
labels = ax.get_xticklabels()
body.append(rv)
newlist2.append(s)
[_heappop_max(h) for i in range(len(h))]
result = result.astype(np.float64)
y1[np.where(y1 == input_array.shape[1])] = y0.max()
lclosure
fb[:] = 0
44718
auth_handler = urllib.request.HTTPBasicAuthHandler()
fig.show()
someDictionary[zipped[0]] = zipped[1]
clone_img = copy.copy(original_img)
plt.show()
self.delta += 1
imshow(img_result)
indata = f.read()
max(mul(*heapq.nsmallest(2, l)), mul(*heapq.nlargest(2, l)))
write_line(of, n, [0.1, 0.1, 0.1, 0.1])
m = df.Col1.str.len().max()
col = get_column_letter(col)
union(jName, kName)
path = os.path.normpath(path)
clipboard = gtk.clipboard_get()
NULL
winlist = []
aw1.show()
rdd.take(5)
1 == True
np.exp(rebased_q - np.logaddexp(-max_q, np.logaddexp.reduce(rebased_q)))
reader = java.io.BufferedReader(java.io.InputStreamReader(stream))
cur = db().cursor()
yourDate = parser.parse(yourString)
data[k].append(i[1])
[n[0] for n in sorted(zip(sorted(B), order), key=itemgetter(1))]
M[numpy.where(M == 0)] = 1000
getcontext()
iter1, iter2 = zip(*compounded_iter)
test()
sorted_list = list(myDic.keys())
rcsplit(np.array(i))
figure()
l.set_option(ldap.OPT_X_TLS, ldap.OPT_X_TLS_DEMAND)
df
self.setLayout(layout)
d[x].append(i)
bucket.delete_keys(delete_key_list)
lines = f.readlines()
user = int(user)
main()
json.dumps(namedtuple_asdict(a1))
pprint(foo(10, depth=2))
sys._getframe(back + 1).f_code.co_name
max_sub = max(l, key=lambda x: x[1])
func
y = vfunc(x)
indices = [i for i, x in enumerate(ar) if re.match(pattern, x)]
ax = fig.add_subplot(111)
True
result.extend(itertools.combinations(x, len))
percent = {key: (value / total) for key, value in list(c.items())}
self.panel.SetFocus()
out.append(np.median(y[mask]))
np.unique(salesdata.Outlet_Size.dropna().values)
mdata
response = urllib.request.urlopen(request)
{7, 8, 9, 10},
combinations.append(x)
httpd.serve_forever()
reader = csv.DictReader(f)
plt.subplot(222)
t[v] = min(t[2 * v], t[2 * v + 1])
data[i].some_key
print(df)
y = np.linspace(0, 2 * np.pi, ny)
logger.setLevel(logging.INFO)
e = int(e_str, 16)
xdiff = [(x[n] - x[n - 1]) for n in range(1, len(x))]
plt.plot(list(range(10)))
value = models.CharField(max_length=100)
console_handler = logging.StreamHandler()
serializer_class = UserSerializer
self.x + other.x
heapq.heappush(heap, (-p1, x - 1, y))
this_year = str(this_year)
soup = bs(root)
deletesys.modules[k]
self.f.write(x)
convert = lambda text: int(text) if text.isdigit() else text
args.func(args)
self.label.setMinimumSize(QtCore.QSize(450, 40))
print(df.iloc[:, (rng)])
args = parser.parse_args()
print(perfect_numbers(n=5))
do_something_with(line)
fnan < pinf
current_node.valid_subword
copylist.append(singleobj)
print(i)
us1 / us2
linspace_y = np.linspace(y_range[i], y_range[i], 100)
screen = curses.initscr()
alllists.append(addlist)
w = w / 2
new_tagged_words
setattr(Cls, key, value)
packet1.show()
__future__.with_statement
y_coords = new_array[:, (1)]
os.chdir(destination)
filtered_array = np.copy(array)
object_id = models.PositiveIntegerField()
timeit(easydiff1, easydiff2, 10000)
resizes = img.resize(resolution, Image.ANTIALIAS)
m, b = np.polyfit(x, y, 1)
p = Presence()
obj1[0], max(obj1[1], obj2[1]), min(obj1[2], obj2[2])
strtime = str(datetime.now())
print(item.key, item.doc_count)
+globals().update(yak)
df = pd.read_csv(tempfile)
assert int(0) < 1.0 < [] < int(0)
value = setattr(self, varname, new_value)
file, pathname, description = imp.find_module(name)
p.haslayer(IP)
__init__.py
stdscr.getkey()
print(x[i], y[i + 1], x[i + 1], y[i])
self.counter = 0
results.append(task.get())
list(self._odict.keys())
file_bytes = numpy.asarray(bytearray(img_stream.read()), dtype=numpy.uint8)
x = numpy.ones(5)
self.growChunk()
print(value)
self.n = n
s.cookies
model_results = pickle.load(f)
print(pool.map(f, list(range(10))))
[0.0, 0.2, 0.4, 0.4, 0.0]
p = im.getpixel((x, y))
glfw.SetTime(0.0)
DataDocumenter.add_directive_header = add_directive_header
result = re.sub(p, subst, test_str)
interpreter.process_page(page)
angle = NumericProperty()
values.append(value)
message = messages.GetLast()
x.stdin.close()
np.arange(1, stop, step)
self.write(json_encode(obj))
csvwriter = csv.writer(csvfile)
result
merged.append((k, sum(e[1] for e in g)))
m_recomposed = x + x.transpose() - np.diag(np.diag(x))
results = mp.Queue()
browser.save_screenshot(img)
canvas.setPageSize((lWidth, lHeight))
plt.semilogx(f, mag)
self[key]
Z.data *= Y.repeat(np.diff(Z.indptr))
set(list1) | set(compSet)
lock.release()
host_data.append(host.serialize())
p_classification = my_svc.predict(x_test)
new_list.append({expression})
app.exec_()
frec(word[1:], values + [word[0]])
os.waitpid(pid, 0)
x - x.mean(axis)[ind]
Time.place(x=0, y=0)
y = np.array([0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1])
self.label.lift(self.frame)
len(wordorder)
dd[item].append(idx)
User.__unicode__ = User.get_full_name
self.canvas = Canvas(self.tk, width=500, height=500)
point_list.sort(key=lambda point: point[axis])
b = 2 * N - 1
funcs.append(lambda x, i=i: f(i, x))
list(UndefinedSilently().items())
ebks, ks = [], []
menu.show_all()
delta.total_seconds()
int(round(math.log(v, 2), 0))
print(freq_distribution.most_common(10))
iterator.__iter__()
result = proc.stdout.read()
df[0].count()
a.sum(axis=0)
register = template.Library()
result[nJ] = fun2(zeta[nJ])
[list(x) for x in zip(*lis)]
s = plt.subplot(1, 1, 1)
canvas.pack()
PyBUF_FULL_RO
id = Column(Integer, primary_key=True)
print(cmap(0.5))
print(dftot.fillna(filldf))
fig = plt.figure()
pd_df = pandas2ri.ri2py_dataframe(rdf)
fb = np.zeros((480, 640), dtype=np.uint8)
res = list(message.DESCRIPTOR.fields.keys())
df[2].replace(4, 17, inplace=True)
plt.subplot(122, polar=True)
p = mp.Pool(processes=2)
x = np.random.rand(50)
do_somethin(cell)
df
sum(v for v in args if args.count(v) == 1)
slug = models.SlugField(max_length=255, unique=True)
print(result)
nx.append(x[-1])
mask.dtype
conn.end_request()
device.close()
c.execute(query)
termios.tcsetattr(fd, termios.TCSANOW, new)
is_staff = True
x.set_visible(False)
dstr = date.tolist()
f.close()
reallocate()
np.tensordot(a, a, (1, 1))
print(self.__dict__)
list(islice(preresult, 100))[-10:]
result = pool.apply_async(worker, args=())
divmod(elapsedTime.total_seconds(), 60)
code.interact(local=locals())
print(uniqify(2))
mylist.append(x)
x = dict()
out.writelines(lines)
self.session.query(entity_type)
main()
B[X] = A
a[1]
axes.set_ylim([0, 70])
a = 1 if b else a
result = self._client.gremlin(script, params).one()
main.show()
Rect(p1.x, p1.y, p2.x, p2.y)
offset += font.getsize(line)[1]
message = headers + body
f.seek(0)
ws.set_panes_frozen(True)
json.dumps(json.load(str_w_quotes))
bar()
datetime.datetime.fromtimestamp(float(time_in_secs))
print(diff.total_seconds())
skipsdist = True
urllib.request.install_opener(opener)
print(line)
deleteself._this
x.do_foo()
os.makedirs(path)
Matrix[0][0] = 1
M.ix[0, 0]
identity = np.identity(A.shape[2], dtype=A.dtype)
deletetrees[i]
assert A.shape[:-1] == B.shape[:-1]
endforeach()
module_dir = os.path.dirname(__file__)
img = MIMEImage(fp.read())
list(product(*[permutations(grp.index) for name, grp in age]))
b = np.array([list(w.center(wid)) for w in a])
Z1 = bivariate_normal(X, Y, 1.0, 1.0, 0.0, 0.0)
lhash = hash(litem)
logging.basicConfig(filename=LOG_FILENAME, level=logging.DEBUG)
lowerList = [item.lower() for item in mylist]
result = []
x_df = df.iloc[map(int, ii)]
print(np.allclose(Z1, Z2))
plt.minorticks_off()
str[:index] + str[endIndex:]
aCash.sum() == (aCash & bNull).sum()
os.waitpid(p.pid, 0)
lock.acquire()
yaml.load(stream, OrderedLoader)
self._queue.cancel_join_thread()
plt.cla()
json.dump(d, o)
[term_appearance.update(x) for x in texts_list]
dict.__getitem__(self, item)
newarray = [0] * n
curtree = curtree.setdefault(c, {})
hash(tuple(sorted(self.__dict__.items())))
socket.send(empty, zmq.SNDMORE)
violin_plot(ax, data, pos, bp=1)
culled_list = [item for item in unculledlist if item % 10 in (0, 2, 4)]
Tr
plt.subplot(121)
map(lambda x: x.start(), threads)
m[i] = False
W = tf.Variable(tf.zeros([784, 10]))
x = np.zeros((depth, size, size))
print([p.spelling for p in file_nodes])
myDict[newKey] = [value]
str(delim.join(result))
self.Bind(wx.EVT_PAINT, self.OnPaint)
print(x)
print(df)
print(b[:, :, (1)])
html.fromstring(broken_html)
first_window = sorted(next(reader) for _ in range(window_size))
print(item)
array += [myNumber]
myDict[temp] = myFunctionThatReturnsData()
self.Meta.model(**validated_data)
i += 1
p1.wait()
print(item)
sys.path.append(dir_of_interest)
draft_list = Player.objects.all()
spl[-1].extend(y)
fig, ax = plt.subplots()
df2 = df1.reset_index(drop=True)
abs(x - y) < epsilon
self.session_store.get_session()
np.allclose(Z1, Z2)
arr1 = np.arange(8).reshape(2, 4)
threading.Thread.__init__(self)
8881 % 2
form.show()
values = list(d.values())
sys.stdout.write(buffer)
signal.signal(signal.SIGHUP, lambda signum, frame: manager.stop())
t.cancel()
elementwiseProd(a, b)
print(s)
stack.append([element])
line = f.readline()
b.start()
bitarray.bitarray(l)
zip(map(tuple, idr), map(tuple, idc), out)
tasks[key]()
df.index
n1 = np.random.random(N)
tester = app.test_client()
jsonpickle.encode(myObject, unpicklable=False)
min(x, y)
z = delrc(i)
dict(union(list_dictionaries))
fig = plt.figure()
foo.__code__.co_consts[2].co_cellvars
[ind_sorted[x[i]:x[i + 1]] for i in range(N - 1)]
t2.append(t[0] + t[-1])
show_times()
instance_name = models.TextField(max_length=20)
assert len(values) == len(keys) + 1
df = pd.read_csv(f)
list(fields_from_list(keys, values))
c = np.hstack((a_t, b_t))[:, (np.argsort(np.hstack((a, b))))]
new_modules
datetime.strptime(date, date_format)
result * result
x = array([[1], [1]])
im = axs[0].imshow(Z, cmap=plt.cm.Greys_r)
fdata = ctypes.cast(vdata, POINTER(float))
React.createClass.toString()
os.mkdir(dir)
A.subtract(B, fill_value=0)
np.array(NumNonZeroElementsByColumn)[0]
req = urllib.request.Request(url)
self._list.__setitem__(key, item)
t.seek(0)
self.setSelectionMode(QtGui.QAbstractItemView.ExtendedSelection)
tk.Canvas.itemconfigure(self, *args, **kwargs)
np.seterr(**eset)
template_rendered.connect(add_template_name_to_context)
result = func(*args, **kw)
data = data[2:]
mydict = args.my_dict
plt.imshow(data)
x == 2
x[0] = 0
res = NP.hstack((my_data, new_col))
sli = [next(diff) for _ in range(n)]
input_thread = threading.Thread(target=add_input, args=(input_queue,))
result = []
concurrent.futures.wait(fs)
x = o
ctx.select_font_face(font, *args, **kwargs)
self.dictionary[key][1]
arr[j][i] = round(arr[j][i], 10)
img = cv2.imdecode(array, 1)
print(tmr.timeit(number=1))
ax.add_artist(anchored_text)
k * math.exp(s * (x - mu) * (x - mu))
name = models.CharField(max_length=100)
parser.feed(text)
G = nx.Graph()
zlib.decompress(part)
pipeA.send(10)
HOST = socket.gethostbyname(socket.gethostname())
renderer.props.wrap_mode = gtk.WRAP_WORD
self.src[i].append(self.src[i + 1].pop(0))
Z[test[:, 0:2].T.tolist()]
q = Queue()
lines = f.readlines()
a[:] = [x for x in a if x <= 4]
combined = dict(union(dict_list))
print(key, value)
Foo.objects.all().delete()
(arr * cond).argmax(1)
angles.append(angle)
sys.stdout = buffer
ax.plot_wireframe(xx, yy, z)
fig = plt.figure()
F()
writer.writerow(row)
next(i for i, (el1, el2) in enumerate(zip(l1, l2)) if el1 != el2)
time.sleep(60 * alarm1)
c.append(a[0])
r = requests.head(url)
int(round(b / 5.0) * 5.0)
[0.0, 0.0, 1.0, 0.0, 1.0, 0.0],
frame.rowconfigure(1, weight=1)
self.patcher1 = patch(path)
self.population[bisect.bisect(self.cumweights, i)]
soup = BeautifulSoup(page)
first, rest = unpack_nfirst(seq, 1)
perform_other_actions()
AHIJ
DGIJ
AZ
BC
plt.vlines(x_median, 0, y_median)
driver = webdriver.Firefox(capabilities=capabilities)
olleh
stack[-2].append(stack[-1])
p = bokeh.plotting.figure(x_range=[0, 10], y_range=[0, 10])
atexit.register(endlog)
[replacer(s) for s in strings if len(s) > 2]
json.dumps(value, cls=DjangoJSONEncoder)
l[a], l[b]
test()
self.circle1.grid()
pool = Pool(5)
df
pixels.append(img[x + opx][y + opy])
array([[0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2]])
deletedf[col]
Node.writexml(f)
print(directory_list)
leg = ax.get_legend()
self.verticalLayout = QtGui.QVBoxLayout(self)
od1 = OrderedDict(sorted(list(d1.items()), key=lambda t: t[1]))
resized_file = orig_image.resize(cur_size, Image.ANTIALIAS)
item_dict[sample[1]]
print(line)
xml.write(escape(data))
names[nickname][weighted_choice_sub([x[1] for x in names[nickname]])][0]
x += 1
self._applecount = 0
plt.show()
self.br.addheaders = self.old_headers
getattr(instance, self.name)
gdi.GetPixel(h, 1024, 767)
numpy.mean(arr, axis=0)
wb = Workbook()
(top_matrix.T * top_matrix).det().factor()
qproc.join()
subset = table[np.array([(i in id_list) for i in table.IDs])]
ax1 = plt.subplot(gs[(0), :])
print(Crypt.find_crypts(706))
fig.tight_layout()
df = pd.concat([df1, df2])
combinations.append(accum)
ax = plt.gca()
new_list = list(itertools.chain(range(1, 6), range(15, 20)))
arr = np.fromiter(chain.from_iterable(combinations(x, 2)), dtype=x.dtype)
self.box.pack_start(self.canvas.draw_area, True, True, 0)
file.seek(here, os.SEEK_SET)
image = image.convert_alpha()
job[1].kill()
drawCirc(ax, 1, 1, 1, 0, 250)
self.monad = monad
widget.deleteLater()
toggle()
np.logical_and(x > -2, x < 2)
line = m.readline()
print(int(floor(f2)))
setattr(Foo, name, make_binding(name))
x = cos(radians(i))
r.raise_for_status()
t = threading.Thread(target=drain_pipe)
[shuffle_word(word) for word in L]
app.run(port=5000)
wmname = window.get_wm_name()
codecs.register(cp65001)
s = spline1dbuildakima(x, y)
True
seen.add(k)
a = [dict(zip(header, map(int, row))) for row in reader]
func(*fargs, **fkwargs)
foundwords
df = pd.concat([df, new], axis=1)
print(type(p))
SomeClass.some_class_method()
ii = np.array([1, 1, 0])
results = json.load(response)
conn.commit()
sys.exit()
print(tostring(fromstring(data, parser=parser)))
self.d[key] = value
[0, 0, 1, 0, 0],
stack[-1].append(element)
json_util.dumps(MyDoc._collection_obj.find(MyDoc.objects()._query))
result.append(i)
words = s.split()
self._matches(found.string, self.text)
ax.set_ylim(ymin=0)
l = func(X, Y, Z)
schema_doc = etree.parse(schema_file)
stdin.flush()
parser = xml.sax.make_parser()
a.shape
msg = socket.recv()
[val(x) for x in a]
request = urllib.request.Request(url)
xmin, xmax = x[mask].min(), x[mask].max()
X_train = np.array(descs_train)
print(bar)
diff = [(a[i] - a[i + 1]) for i in range(len(a) - 1)]
dic.pop(k)
audio_thread.start()
labels = [item.get_text() for item in ax.get_xticklabels()]
fig = plt.figure()
b[5, 6, 7, 8]
newY[x] += 1
data = [random_data() for x in range(0, 10)]
print(list)
parse_qs(urlparse(url).query)
final_df
y_true = [0, 0, 1, 1, 2, 0, 1]
base, str = int(sstr[0]), sstr[1]
setattr(cls, methodname, newmethod)
a_order = numpy.argsort(a)
x0 = x_indices.astype(np.integer)
a = np.in1d(np.arange(m), np.random.randint(0, m, m))
print(i)
p.wait()
self.statusitem.setMenu_(self.menu)
print(first_column, third_column)
app = App()
print(q.all())
name = models.CharField(max_length=16)
A = [[1, 1, 0, 0], [0, 1, 0, 1], [1, 0, 1, 0], [0, 0, 1, -1]]
foo = Bar()
print(df2)
hb = plt.hexbin(x, y)
log.start()
df2[col] = c
map = mmap.mmap(f.fileno(), 0)
self.x
print((freqs.min(), freqs.max()))
session = requests.session()
app = wx.PySimpleApp()
n = np.arange(10, 1000, 10)
foo(*args)
cat / etc / supervisor / conf.d / app.conf
xi, yi = np.meshgrid(xi, yi)
G = nx.DiGraph()
t.objects.all()
ret.sort(axis=0)
word1_synonyms = wordnet.synsets(word1)
oldmodule.__dict__.update(newmodule.__dict__)
self.cntrlPanel.SetSizer(sizer)
assert s.query(B.id).order_by(B.id).all() == [(1,), (4,)]
bools = [success_condition(r) for r in results]
self.appname = appname
d[i[0]] = i[1]
random.seed(seed)
fnew
raw_input = new_raw_input
items[item].append(i)
xyB[:, (1)] *= widthB / (xyB[:, (1)].max() - xyB[:, (1)].min())
self.toolbar.Bind(wx.EVT_MENU, self.OnTool, id=tool_id)
t = time.time()
ax.yaxis.grid()
sc.close()
td.dt.days
axes[0].plot(x, i * (x - 10) ** 2)
print(image.shape)
[dict(zip([col[0] for col in desc], row)) for row in cursor.fetchall()]
self[key].extend(value)
fig = plt.figure()
p = subprocess.Popen(args, startupinfo=startupinfo)
x = some_text % tuple(s)
buf.seek(0)
aapl_50ma.plot(legend=True)
self.nested_whatever_id = nested_object.id
fig = plt.figure()
response.render()
real_decorator
dataframe.plot(ax=f.gca())
df.head(1)
d = collections.defaultdict(list)
StandardPyGTKSpec()
rows = cursor.fetchall()
dict[firstName] = 1
unique[maxpos], counts[maxpos]
inverted_dict = collections.defaultdict(set)
print(string.Template.pattern.pattern)
list(compress(fruits, (f in s for f in fruits)))
root.deiconify()
sum(islice(count(1, step=4), 100))
curdir = os.getcwd()
f.write(line)
q = q.prefetch(Supplier)
dot_product = tf.reduce_sum(tf.multiply(x, y))
ar = cur.fetchall()
print(self.data)
layout.addWidget(self.runButton)
asyncore.loop(timeout=5.0)
TEMPLATE_DEBUG = DEBUG
Availability = 2
Console.ReadKey()
c[:a.shape[0], :a.shape[1]] -= a
fig, axn = plt.subplots(2, 2, sharex=True, sharey=True)
df.combine_first(df.T)
self.addItems(self.list_one)
self.l.pack()
q.get()
np_image = np.asarray(image).flatten()
ctx.set_source_rgb(0, 0, 0)
mask = [any(tup) for tup in zip(a, b, c)]
num_int = int(num_int / 2)
dfa = df.ix[:, ([1, 0])].copy()
b.T
plt.plot(x1, y1)
pic.seek(0)
time.time() - os.stat(pathname)[stat.ST_MTIME]
hn.setLevel(logging.DEBUG)
mark_safe(simplejson.dumps(object))
df = df.reindex(columns=cols)
walnut = Image.open(pattern)
pixbuf = gtk.gdk.Pixbuf(gtk.gdk.COLORSPACE_RGB, False, 8, 1, 1)
s.diff()
dictionary[len(i)] = 1
xi, yi = np.meshgrid(xi, yi)
pygame.init()
self.cur2.executemany(query, self.rows)
np.random.seed(0)
print(newlists)
b = a[new_names]
max_col = old_sheet.get_highest_column()
plt.plot(time[:-1], scipy.integrate.cumtrapz(signal, x=time))
ind = r * cols + c
QWidget.__init__(self, parent)
data = np.random.random((100, 100))
abs(a - b)
fh.writelines(output)
print(os.__file__)
array[0] = 1
alert(msg.data)
m.contourf(xi, yi, zi)
outputfile.close()
tree = doc.getroottree()
connection.test.foo.find_one()
G = nx.MultiGraph()
argparse.ArgumentParser.__init__(self, *args, **kwargs)
g[key] = getattr(file_one, key)
r.status_code
args = parser.parse_args()
sorted(chain(*allrows))[-20:]
self.web_view.page().setViewportSize(frame.contentsSize())
session.quit()
idx = np.array([0, 1, 2])
extent = [xbnds[0], xbnds[1], ybnds[0], ybnds[1]]
text_soup = BeautifulSoup(urlopen(url).read())
HttpResponseNotModified()
time.sleep(0.2)
[1, 4, 9]
ax.set_xlim([-4, 4])
extractDefines(TEST2)
os.chdir(working_dir)
fig, ax = plt.subplots()
data = json.load(jsonFile)
cj.set_cookie(ck)
cursor.execute(query.format(station_id=id))
M[:, (i)] *= -1
do_stuff()
[5, 199]
writer.writerow(values)
plt.plot(x, y, zorder=1)
session_crumbs.pop(0)
log.addHandler(handler)
sys.exit(app.exec_())
G = [list(g) for _, g in groupby(A, key=scientific_notation)]
EMAIL_USE_TLS = True
libpath = matplotlib.__path__[0]
profile = webdriver.FirefoxProfile()
cat / proc / 12992 / status
SimpleHTTPServer.SimpleHTTPRequestHandler.do_GET(self)
self.data.extend(subpickle.data)
x[np.ix_([0], [0, 1, 2], [0, 2])]
ET.tostring(node)
t.start()
ax.xaxis_date()
fig = plt.figure()
d = {}
print(instance.Field2)
print(year + 1)
top = Tk()
plt.show()
X.append(x)
os.remove(self.local_file)
foo.append(df.columns[df.ix[i] == 1])
dict.__setitem__(self, key, val)
result = g.delay()
print(type(ax.get_xminorticklabels()[0]))
Vector([(s + o) for s, o in zip(self.data, other.data)])
y.append(words[2])
parser.parse(s)
print(mystr[mystr.find(char1) + 1:mystr.find(char2)])
s.seek(0)
numdf = numdf[num_df[data_columns].notnull().all(axis=1)]
print(list(itertools.product(input1, input2)))
pylab.xticks([(i / 10.0) for i in range(0, 12)])
print(binascii.hexlify(os.urandom(16)))
ents.entitydefs[m.group()[1:-1]]
axstop = plt.axes([0.51, 0.05, 0.1, 0.075])
results.append(lambda i=i, j=j: nodes[i].value() == nodes[j].value())
assert all(particles[i].i == i for i in range(len(particles)))
s = set(filelist)
a.show()
c = pycurl.Curl()
vS = ser.readline()
root = Tk()
b.append(a)
[2, 4, 5],
self.f.close()
a[0] + a[1] * 0.1
root = Tkinter.Tk()
b = a - int(a)
cashflow = 2 * np.ones(6)
cls.__name__
print(t.myStuffs.all())
content = f.read()
print(x * x)
request = urllib.request.Request(url)
c = Variable(n, 2)
self.x, self.y
text = [ast.literal_eval(line) for line in f]
df_concat = pd.concat((df1, df2))
arr = np.ones((10, 10)) * 10
npi.indices(unique, A)
A = numpy.random.randint(1, 6, size=(1000, 12))
self.assertItemsEqual(a, list(range(0, 4)))
dist = math.sqrt(dx * dx + dy * dy)
pivot.fillna(0, inplace=True)
cj.set_cookie(ck)
mask = np.kron(np.eye(len(L)), np.ones(shp)) == 1
n = len(a)
d = dict(zip(keys, vals))
files.append(i)
assert list == __builtins__.list
ax1.plot(dates, list(range(10)))
curs.execute(sql)
app = QApplication(sys.argv)
self.extend(self._stringio.getvalue().splitlines())
True
df
output_rs = tf.transpose(output, [1, 0, 2])
platform.system()
run(command, pty=False)
sorted_city_pop = OrderedDict(sorted(cityPopulation.items()))
wsize = walnut.size
MCAST_PORT = 5007
dataframe[cols]
print(match.group())
same.append((i, j, string_b[j]))
C = C.view(A.dtype).reshape(-1, ncols)
df
processes.append(p)
print(make_hash([func.__code__, func.__dict__, func.__name__]))
write.writerow(i)
result = [[t[0]]]
prod, x, y = heapq.heappop(heap)
root = Tk()
print_node(root)
df.eq(0).dot(days_in_month)
nprint(polyroots(taylor(lambda x: legendre(n, x), 0, n)[::-1]))
print(k, val)
line
sys.exit()
app.mainloop()
help(assign)
body_data = json.loads(body_unicode)
line = line.strip()
a = np.hstack((a[:, ::2], a[:, 1::2]))
a, b = tee(iterable)
yscroll.grid(row=0, column=1, sticky=N + S)
spec = createSpec()
new_cols = df.columns.values
triple(x) + square(x)
df
bpa = np.asarray(bpa)
hash(str(self.name))
reactor.listenTCP(8080, factory)
0
self.i = min(self.im.shape[2] - 1, self.i + 1)
c = list(b)
f.seek(0)
btwo.on_clicked(two)
itertools.product(a, b)
s.starttls()
self.make_a_fake_request_to_myself()
False
line = line.rstrip()
data.append(row)
print(elementwise_product(list1, list2))
input_wave_file.close()
True
self.sizer = wx.BoxSizer(wx.VERTICAL)
result_set = cursor.fetchall()
os.rmdir(dir)
xticks[i].set_visible(False)
self.tree.pack()
draw = ImageDraw.Draw(img)
article = form.save(commit=False)
ids.append(map(lambda tup: tup[0], sorted(c, key=lambda tup: tup[1])[0:K]))
requests.__version__
theother(item)
frame_data = wave_file.readframes(nb_frames)
all_zeros = not a.any()
True
genn(igap, igap - 2)
process.stdout.close()
handler1.setLevel(logging.INFO)
Base.metadata.create_all(e)
response.render()
self.value = Value()
watermark = Image.open(watermark_path)
request.write(c.name)
p = psutil.Process(pid)
ws = wb.worksheets[0]
spec.drawComboBox()
regex.pattern
name = models.CharField(max_length=50)
self.buffer.append(next(self.iter))
nu = df[col].nunique()
rslt.drop(n, axis=1, inplace=True)
fig = plt.figure()
random_line = f.readline()
ret = int(s)
process = Popen(command, stdout=PIPE, stderr=PIPE)
new_func
obj.save()
urls = [url5, url5, url10, url10, url10, url5, url5]
L[::-1]
result_pic.seek(0)
keys = set(l1).intersection(set(d1.keys()))
draw = ImageDraw.Draw(im)
print(df.apply(lambda x: x.A in x.B, axis=1))
a = np.array([1, 0, 0, 1, 0, 0])
print(i)
print(offset_map[key])
mail = email.message_from_string(email_body)
a.dtype
contour, hier = cv2.findContours(res, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
print(itemgetter(*b)(a))
nx.draw(gr, node_size=500, labels=mylabels, with_labels=True)
xx, yy = np.meshgrid(x, y)
archive.close()
sizer.Add(stc2)
M = scipy.sparse.diags([degs], [0]) - A
self.__c
print(m.group(0))
rpath = path.abspath(path.join(path.dirname(fpath), rpath))
G.nodes()
foo()
np.allclose(C, out)
dataArray.reshape(enc[2])
ax.margins(0, 0)
_location.gsm_location()
print(s.translate(translator))
self.panel = wx.Panel(self, wx.ID_ANY)
os.close(qq.fileno())
d = collections.OrderedDict()
mf.columnconfigure(0, weight=1)
ssq0 = ((yfit0 - ydata) ** 2).sum()
main()
textwrap.wrap(string, 15)
notifier = pyinotify.Notifier(wm, eh)
__delitem__
print(solve(5 * x ** 2 + 5 * x + 5))
a = [1, 2, 4]
lst = [a, d, b, c, e, f, g]
line = f.readlines()[7]
array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]])
min(player(l[:-1]), player(l[:-2])) + l[-1] if l else 0
C1 = Cookie.SimpleCookie()
1000111001100111100111000010111101011110010001010000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000
f(*args, **kwargs)
f = float(s)
arr[0][1]
soln2 = integrate.odeint(f, y2, t2, mxstep=5000)
1
[(i >> p & 1) for p in range(length - 1, -1, -1)]
w = watcher.Watcher(dir, callback)
nonlinsolve([x * y - 1, 4 * x ** 2 + y ** 2 - 5], [x, y])
btn.set_sensitive(False)
driver = webdriver.Firefox(capabilities=firefox_capabilities)
app = wx.App(False)
self.setIconSize(QtCore.QSize(124, 124))
bettermodel = model.fit(betterdata)
console.log(i.toString(2))
urllib.request.urlopen(uri).read()
b / foo.py
fileToSend.close()
n = a.shape[0]
bool(strtobool(str(arg)))
ans[k1].append({k2: v2})
True
time.sleep(10)
x = pd.DataFrame(np.random.randn(10, 5))
urllib.request.HTTPHandler.__init__(self, debuglevel)
output.append(list[indexes[-1]:])
bus = dbus.SystemBus()
do_my_work()
saved_blob_string = gdata.gauth.token_to_blob(token)
print(thedict)
self.ax.grid(True)
delta = dt.timedelta(hours=12)
zdd2 = rdd2.zipWithIndex().map(lambda v_k: (v_k[1], v_k[0]))
Py_INCREF(p_eigen_python_error)
X, Y = np.meshgrid(x, y)
reader = csv.DictReader(infile)
str.__new__(cls)
chr(int(x.group(1), 16))
self.__class__(**d)
record.put()
plt.close(fig)
daemon_cartman.start()
A = NP.random.randint(10, 100, 100).reshape(10, 10)
setup.py
array = file.readlines()
example.insert(4, 122)
root.mainloop()
fig.subplots_adjust(wspace=0.1, hspace=0, bottom=0.05)
app.MainLoop()
lib.foo.restype = c_char_p
main()
draw_ellipse(image, ellipse_box, width=20, antialias=1)
parent.add_widget(GearTick(range=(0, 100)))
req = urllib.request.Request(post_url, json.dumps(postdata), headers)
max(d1, key=lambda k: d1[k])
print(final)
stat(my_filename).st_uid
Button.__init__(self, parent)
cursor = collection.find({})
self.origstreamfd = self.origstream.fileno()
foo = Foo()
-num_decode(s[1:])
key0 += 1
serializer = CommentSerializer(data=data)
sudokupossibilities
[0, 0, 0, 0, 0, 0, 15, 16],
d.setdefault(a, []).append(b)
f = plt.figure()
my_dict = {key: set(value) for key, value in list(my_dict.items())}
example()
s[:1, (1)]
res[k] += l[0:len(l) - n + 1]
angle = np.deg2rad(angle)
status = p.wait()
X_cluster_0 = X_train_tfidf[cluster_0]
etree = ET.fromstring(xml_data)
chunk = proc.stdout.read()
com.convert_robj(a)
f.set_pasv(0)
ax.set_yticklabels(labels)
fig, axes = plt.subplots(1, 2, sharey=True)
Ainv = tf.matrix_inverse(A)
name = models.CharField(max_length=45)
plot(x_av, y)
primeCount = [0, 0, 1]
top = Tkinter.Tk()
plt.draw()
axis[:set_ylim](-1, 1)
H, xedges, yedges = np.histogram2d(x2, y2)
sys.stdout = StringIO.StringIO()
os.umask(0)
x = {(1): 2}
x = np.outer(np.sin(theta), np.cos(phi))
sock.bind(address[0][-1])
lines = (line.strip() for line in text.splitlines())
df = pd.DataFrame(list(ds2.difference(ds1)), columns=df2.columns)
print(np.matrix(A))
data = yaml.load(stream)
values = [col.text for col in row]
transaction.leave_transaction_management()
notebook.set_tab_reorderable(page1, True)
norm = plt.normalize(min_v, max_v)
print(pd.DataFrame(d))
0.6044, sym2, 2, 5, 10, 10
print(item)
self.data.pop()
mask[col] = True
out = np.zeros((N, N))
telephone = models.CharField(max_length=100)
True
data = urllib.request.urlopen(url)
print([x for x in list(globals().values()) if isinstance(x, FunctionType)])
sum_of_grades = sum(my_list)
code.interact(local=locals())
f = np.poly1d([1, 0, 0, -1])
func1()
next(mat)
data_files.append((directory, files))
carIndex = [0] if len(tmp) == 0 else tmp
[atup[n:n + 4] for n, i in enumerate(atup) if n % 4 == 0]
self.arguments = {}
print((r[0], r[1]))
XGBClassifier(**grid)
val = func(self.val)
p.communicate(msg.as_string())
panel = tk.Label(window, image=img)
os.remove(f.name)
grid[i, j] = z
endclass
w.show()
fig.patch.set_visible(False)
msg = MIMEMultipart()
df.clip(lower=0)
norm2 = normalize(x[:, (np.newaxis)], axis=0).ravel()
value, key = key[:size], key[size:]
zip(*[(lft[i] + board[i] + rgt[i]) for i in range(n_rows)]),
args = parser.parse_args(preprocess(sys.argv))
ode15s = scipy.integrate.ode(f)
multi_line_word << (word | split_word + multi_line_word)
marshal.dump(f.__code__, funcfile)
allTrue = all(somePredicate(elem) for elem in someIterable)
shutil.copyfile(source_path + filename, dest_path + filename)
entry1.grid(row=1, column=1)
sess = tf.Session()
TestCase.setUp(self, *args, **kwargs)
self.label.pack(padx=10, pady=10)
A[(idx), :]
self.SetTransparent(50)
ip = self.request.remote_addr
admin.site.unregister(Group)
x.__name__
threads.append(t)
somescript.py
df
self._final_queue.put(self._get_final_result())
os._exit(0)
listen()
PyRun_SimpleString(pycmd)
reduce(np.logical_and, map(pred, list(range(a.shape[1])))).any(axis=1)
result.append(job.get())
id = Column(Integer, primary_key=True)
w = np.asarray([0, 4, 7, 10])
vor = Voronoi(points)
ax.scatter(x2, y2, s=100, lw=0, color=[alpha, alpha, 1.0])
gen_move(list(range(10)))
a = []
key = m[0][0] + m[0][1]
stmt.to_unicode()
glLoadIdentity()
concatenate_per_row(A, B)
FO.write(line)
msmdsrvini.write(msmdsrvText)
self.windowSizer.Add(self.panel, 1, wx.ALL | wx.EXPAND)
self.session_store.save_sessions(self.response)
print(TR8(c))
columns[i].append(h)
nbr_edgeobjects
list(~numpy.array(mylist))
zip_b = zip(*b)
self.assertTrue(flag)
[x for x in range(*s.indices(10))]
ds.addSample((-1, 1), (1,))
Frame.__init__(self, master)
self.callback()
sys.stdout.write(s)
f.sum()
str(self(*args, **kwargs))
hash = random.getrandbits(128)
sel_cur = db.cursor()
out = f.getvalue()
self.doMP()
self.fp = open(self.file_or_path, mode)
A = x.todok()
x = np.linalg.lstsq(a, b)[0]
window1.show_all()
fig, ax = plt.subplots()
a.indices(100)
pd.Series(L)
ret.append(line[:-1])
result = jobs.apply_async()
summarized_info
a = a.reshape(nx, ny, nz)
f.close()
b.build_base
f(**kw)
programmer1.info()
1
isinstance([], list)
line, = ax.plot([], [], lw=2)
g[c] = i
np.vstack([bins[:-1], bins[1:]]).mean(axis=0)
fig, axes = plt.subplots(nrows=2, sharex=True)
solns8 = solve(smin, smax, coef1, coef2)
counts = pd.value_counts(values)
l = []
func(arg1)
grid[-1].append(value)
objs.append(obj)
self.sizer.Layout()
A().B(1, 2)
lines = f.read().splitlines()
query = query.filter(filt)
dill.dump(t, f)
Blob.__init__(self, width, height, color, emphasis, highlight)
self.selected
threading.Thread.__init__(self)
device.open()
glVertex2i(110, 110)
channel.stop_consuming()
[(x, y) for x in a for y in b]
float(s)
reader = csv.reader(f, delimiter=d)
today = datetime.datetime.now()
x = sum(int(digit) for digit in str(n))
entity.before_delete()
pagenos = set()
self.setLineWidth(0.5)
infile = io.open(filename, mode, encoding=encoding)
ax.add_patch(Circle(point, 0.1))
self.log.write(message)
print(your_array[index_array[:10]])
arr.reshape(dim, (n_bins,) * dim)
os.remove(output)
a = numpy.arange(25).reshape((5, 5))
print(G.number_of_nodes())
t.start()
im.putalpha(alpha)
print(b)
inspect.getargspec(members[2][1])
self._callbacks = []
winsound.Beep(17000, 100)
stripped = (line.strip() for line in in_file)
B[~B.client_id.isin(A.client_id)]
np.sqrt(1 - X ** 2 - Y ** 2)
c = y * np.exp(-1j * 2 * n * np.pi * time / period)
xdelta, ydelta = xlim[1] - xlim[0], ylim[1] - ylim[0]
f(*args[0])
output.index = output.index.to_datetime()
session.commit()
operator.itemgetter(*b)(a)
self.setAutoFillBackground(True)
Vector(self.x + n.x, self.y + n.y)
temp_file.seek(0)
cache.set(self.COUNTER_CACHE_KEY, 1, self.PERIOD_LENGTH_IN_SECONDS)
Signature2 = -1
(mask * prior_reci + ~mask * (0.1 * prior_reci)).sum(1)
sys.stdout = tmpout
fn(*args, **args)
print(df.columns.tolist())
{a: 1, b: 2}
server.serve_forever()
some_number = Column(Integer, primary_key=True)
pool.close()
y = np.random.randn(10000, 10000)
plt.plot(xnew, power_smooth)
app = MyApp(sys.argv)
loop.run_forever()
dacl = sd.GetSecurityDescriptorDacl()
f1.close()
c.drawImage(Image, cm, cm, inch, inch)
sys.excepthook = myexcepthook
c.wait()
(fwd[:-2] + back[2:]) / 2.0
a = np.eye(N)
pygame.init()
valued.append(int(suby))
a = np.hstack(np.array(a))
s = pickle.load(f)
g.login(username, password)
sort_index
app = wx.App(False)
rv = np.ones((N, mask.shape[0], mask.shape[1], 4), dtype=np.float)
print(final_regex)
filelist = glob.glob(fileroot)
root.withdraw()
doc = lxml.etree.XML(data)
other and self.a == other.a and self.b == other.b
count(x)
PyErr_Print()
t = Tkinter.Text(w)
plt.show()
res.reverse()
naive = datetime(2015, 2, 1)
print(point.distance(line))
my_dict = {}
numpy.vstack([test, test[::-1]]).T[:(len(test) + 1) // 2]
clock_gettime.argtypes = [ctypes.c_int, ctypes.POINTER(timespec)]
plt.cm.gist_ncar(np.random.random())
G = nx.Graph()
auth_login(request, form.get_user())
b = np.random.rand(5, 4)
any(char in digits for char in value)
print(Counter(alist))
i = iter([(1, 11), (2, 22)])
mylist += [(tup[0], tup[1], list_of_signs[idx1][idx2])]
func()
date_joined = models.DateField()
(lambda x: x).__get__
print(arreqclose_in_list(myarr1, mylistarr))
print(str(selection))
sys.exit(0)
fig, ax = plt.subplots()
print(df)
self.window.show_all()
self.get_db_prep_value(value)
data = {}
self._thread_id
pool = multiprocessing.Pool()
adate - timedelta(days=_offsets[adate.weekday()])
log.addHandler(noop)
V.ravel()
_nextafter(x, y)
numpy.dtype(t)
worksheet = workbook.add_worksheet()
f2.pack(side=LEFT, fill=Y)
pprint.pprint(dict(os.environ), width=1)
self.figure.delaxes(self.figure.axes[1])
df + 1
dt = numpy.linspace(-t[-1], t[-1], 2 * nsamples - 1)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
new_list.append((elem, input_dict[elem]))
svc.fit(X_train, y_train)
self.authenticate(user, password)
k, self.mapping[k]
df[1] = df[1].apply(lambda x: 1 if x else 0).cumsum()
writer.writerow(writenames)
win.window.move_resize(x, y, w, h)
all_pixels.append(255)
print(df)
self.setCentralWidget(self.tree)
t.__sizeof__()
x[0]
json.load(f)
synchIntervall = datetime.day(2)
today = datetime.date.today()
PaginationFormSet
c = cv.WaitKey(7) % 256
mech.submit()
print(x[:, :, (5)])
x[0][0][0] = 11
result.intersection_update(s)
X[-1]
print(is_int_value(x))
print(Example(1))
print(np.std(X, 0) * m.coef_)
x_c = 0.5 * (x_a + x_b)
[scipy.argmin([scipy.inner(q - x, q - x) for x in X]) for q in Q]
form = formset.form
df.where(~is_duplicate, 0)
x.split()
thread.start()
self.window_is_fullscreen = False
seen.add(k)
ax.set_xticks(pos + width / 2)
[(resMag * (math.cos(a) + math.sin(a) * 1j)) for a in resArg]
r = {}
self.textLayout.setMargin(10)
f = np.poly1d([1, 0, 0, -1])
print(l[i])
s = f.read()
btn.pack()
x = np.arange(0, len(data))
fig, ax = plt.subplots(ncols=2, figsize=(5, 2.5))
print(a)
out.reshape((n, n))
in_order_values = list(tree.in_order())
fig, ax = plt.subplots()
a = b[n]
dill.detect.errors(f)
tree = etree.parse(metadata, parser)
word in is_word.words and len(word) > 1
frame.grid_columnconfigure(0, weight=1)
cov / np.dot(s_x[:, (np.newaxis)], s_y[(np.newaxis), :])
fig = plt.figure(figsize=(4, 5))
A[index]
json.dumps(d)
[bar.set_height(hist[i]) for i, bar in enumerate(b)]
upload_file(path)
mysignal.connect_via(app)(listener)
wmclass = window.get_wm_class()
indices = numpy.arange(a.shape[0])[numpy.in1d(a, b)]
dict.__setitem__(self, k, v)
df
pd.__version__
self.src.append([self.src[-1].pop(-1)])
print((r.status, r.reason))
plt.xlim([startTime, endTime])
signal.append(c + corr * signal[-1] + np.random.normal(0, sigma_e))
magneturi
result = solve(m1, m2, std1, std2)
plt.plot(t, s)
lock = mp.Lock()
f.pack(side=LEFT, expand=1)
input.close()
pipe.close()
data.append(float(item.split()[take_col]))
parser = argparse.ArgumentParser()
wb = openpyxl.Workbook()
slither / slither / tests.py
f[2].lower()
np.random.seed(0)
L[a:a + span2] = L[b:c]
r = list(range(start_day, end_day + 1))
df
dt = numpy.arange(1 - nsamples, nsamples)
C()
ranges.append([val, index])
proc.start()
img = np.vstack((c, np.hstack((a, b))))
dt = datetime.datetime.now()
EndDate = Date + timedelta(days=10)
mylist.remove(value)
print(list(d.items()))
f(*args)
q.put(name)
print(x)
fields.insert(bisect(fields, value), value)
ax.add_patch(patch)
vals = [sinval(i) for i in range(quarter)]
dict_writer.writeheader()
context.set_source_surface(self.image, 0.0, 0.0)
input()
tar.close()
np.hstack(lst)
parser = argparse.ArgumentParser()
font = cv2.FONT_HERSHEY_PLAIN
Concate.update({A[i]: B[i]})
self.output.write(result)
print(mylist)
ax.hist(nd, normed=True, bins=n_bins0, alpha=0.5)
response
s.connect((hostname, port))
plt.hist(random_from_cdf, 50)
CATC - ATCAGCATCGACATGCGGCATACG
position = NX.spring_layout(Gh)
p.join()
graphB = tf.Graph()
self._fn(*arg, **kw)
f(1, 1, 1)
hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
d[key] = True
FunctionFlow.start.run(**some_kwargs)
print(repr(array))
cax.pcolormesh(t, r, c.T)
plt.plot([0, 1])
print(l[:N])
print(str(matches))
initialize_necklace()
profile_image_path = models.CharField(max_length=250, blank=True, null=True)
print(data)
r = redis.Redis()
self._name
self.assertIn(key, set(response.data.keys()))
file.flush()
obj = [line[0].strip(), line[1].strip()]
sm = sys.modules.copy()
decorated_func
app
a[:, :, (i), :] *= v[i]
found.add(relation)
word1word2
word2word1
ax.set_xlim(-10, 10)
skew *= ((m - 1) * m) ** 0.5 / (m - 2)
t.append(yourstring[i * 8:(i + 1) * 8])
obj = getattr(obj, attr_list.pop(0))
logging.getLevelName(10)
self._conn
app = Flask(__name__)
some_b.delete()
argtypes = [ctypes.c_int, ctypes.c_double]
print(self.__name__)
cap.release()
app.install(log_to_logger)
decorator
digits = map(str, digits)
date = dt.datetime.today() - dt.timedelta(days=1)
cPickle.dump(gnb, fid)
self.ui.PoseBtn_GridLayout.addItem(spacerItem1, 1, 0, 1, 1)
self.main()
CS = plt.contour(X, Y, Z)
mat = np.random.random((100, 100))
io.StringIO
box.pack_start(combo, False, False)
logger.propagate = False
testdataframe[col].plot(style=style, lw=lw, ax=ax)
ax.figure.canvas.draw()
item.append(10)
d = dict()
sleep(1)
x[:, 1:2, :]
locations = FieldList(FormField(LocationForm), min_entries=2)
person.make_statement(20)
ax.set_yticklabels(nba_sort.index, minor=False)
np.where(states)
moo._min_or_max_axis
b = a[::2].copy()
df.index = pd.DatetimeIndex(df.index)
np.where(a > 5)
ax.set_xlim([xmin, xmax])
{{form.non_field_errors}}
freq.update(line.split())
ax.plot(x, y)
self.fit(X, y).transform(X)
ax.set_ylim(-100, 100)
module1.func1 = self.my_new_func1
t.start()
deleteself.list[-1]
cstring.value
kernelapp.start()
url = urlparse.urlparse(address)
arr = np.roll(arr, num)
f = scipy.signal.lti([1], [1, 1])
filtered_words = (word for word in file_words if word in words)
print(a.qsize())
array2 = [e for e in array2 if e not in set1]
print(n)
X_train = vectorizer.fit_transform(X_train)
app = QtGui.QApplication(sys.argv)
b = TestB()
str_args = [str(x) for x in args]
f = hstack2((a, b))
b = sorted(a, reverse=True)
reverse_dic[v].append(k)
str2.count(str1)
session.add(g)
signal.signal(signal.SIGUSR1, handle_pdb)
df = df.append(sum_df)
f(*args, **kwargs)
array[0]
G.add_edge(1, 2, weight=7)
colorbar.set_ticks([-0.667, 0, 0.667])
max(l_one + l_two)
result = {}
image = Image.all().fetch(1, offset)[0]
message.save()
sidx = X1D.argsort()
M.dot(M)
pprint(res)
root.mainloop()
a = np.array([1, 0, 0])
list_.append(line[2])
frame1.axes.get_xaxis().set_ticks([])
Something.objects.filter(data__a=1)
m, n = x.shape
self.setLayout(grid)
abs(value)
title_year = [fields(i) for i in movie_dicts]
axs[1].xaxis.set_major_formatter(x_fmt)
pythoncom.PumpMessages()
sp.add_source_from_line(ppa_name)
someFunction(**theDictionary)
mask = np.zeros(img.shape, np.uint8)
lst[num] *= 2
xml.sax._exceptions
a[0][0] = 2
myMap[n] += 1
print(nx.simple_cycles(G).pop()[:-1])
myfile = f.read()
pri = gllhs[0]
fig, axes = plt.subplots(nrows=1, ncols=2)
root_logger = logging.getLogger()
values = list(select.stripped_strings)
result_variable = result[1]
User.client_1_query.filter(User.id == 1).all()
0
dis.dis(b)
nbr_edgeobjects = 0
textwrap.wrap(s, 4)
id = Column(Integer, primary_key=True)
fig = plt.figure()
print(linalg.solve(A, x))
x in range(cls.k)
out = data[np.in1d(tags, goodIDs)]
im = img.load()
res = [key for key in list(freq_count.keys()) if freq_count[key] == high]
plt.plot(list(range(10)))
description = models.CharField(max_length=250)
new_cols = df.loc[:, (cols)] / df.loc[ii, cols].values
cv.Threshold(a, a, 0.5, 1, cv.CV_THRESH_BINARY)
adate - timedelta(days=delta)
p.join()
writer.writerow(combined_row)
fig = plt.gcf()
last_name = models.CharField(max_length=100)
next(second)
self.dot.set_offsets((x, y))
df
print(sublist([5, 90, 2], [90, 20, 5, 2, 17]))
result.pop()
plt.colorbar(im, cax=cax)
ax.scatter(x, y, z, alpha=0.1)
__init__.py
result_dict[len(word)].add(word)
layout.addWidget(self.edit)
result[nI] = func2(zeta[nI])
setattr(foo, k, v)
now = datetime.now()
console_client.cmdloop()
value = Column(String(100))
raise OSError(errno_, os.strerror(errno_))
self.driver = webdriver.Firefox()
v.extend(list(i.items()))
parsed.pprint()
item_q = Queue.Queue()
workssheet2.write(row, col, cell_value)
min2(x)[1]
arguments = locals()
content = f.read()
args.func(args.newstate)
i += 1
QtCore.Qt.Unchecked
plt.ylim((-limit, limit))
conv = np.round(alt / 500.0).astype(int)
print(df)
sum(n * 10 ** i for i, n in zip(count(0, -1), a))
ns.extra_file = ns.extra_file if ns.extra_file else ns.filename
(t - B) / A
QTimer.singleShot(200, self.load_content)
ax = fig.add_subplot(111)
extension = entrypoint.load()
dome_something(obj)
handles, labels = pyplot.gca().get_legend_handles_labels()
print(np.array_str(x, precision=2))
main()
get_color(0.5)
original_open(filename, mode)
kmer2count[kmer2] += initcount[kmer1]
inp = input()
_change_this_and_I_will_kill_you_with_my_axe = []
np.insert(a, 1, 5, axis=1)
mean += (x - mean) / n
fig = plt.figure()
(1.0).is_integer()
crawler.crawl(spider)
myCards.append(cardList)
wrapped_f
array([0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9])
map(session.refresh, iter(session))
L[0] + listSum(L[1:])
le.setStyleSheet(ss)
out.close()
print(p2.communicate())
a.ravel()[flat_index]
response
np.add.at(out_count, b_idx, b[:, (1)])
A[c1, r1], A[c2, r2] = A[c2, r2], A[c1, r1]
X0 = np.ones((n, 1))
ba = bytearray(m)
f.__defaults__
new_strs.append(str_record[x])
ebks.append(p1 / p2)
cum = np.hstack((np.zeros((a.shape[0], 1), dtype=a.dtype), cum))
16.6644029617
print(drw)
pmf /= pmf.sum()
pr.enable()
clipped_background = no_background.clip(min=0)
main()
p.print_stats()
param_value = request.query.param_name
out, err = pipe.communicate()
pattern = np.random.rand(PATLEN)
x, y
f.write(tempfile.read())
merged_df
lastdigit = int(repr(n)[-1])
b = [4, 5, 6]
a = np.equal.outer(vect, vect)
curses.flushinp()
print((resp.status, resp.reason))
r = q.T.reshape(-1, 2, 2)
patient_list.sort(key=by_unit_room_bed)
p.put()
_test()
fp.seek(-BOMLEN, os.SEEK_CUR)
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
arr = np.zeros((nrows, ncols))
s = requests.Session()
columns = df.columns.values.tolist()
buf = stream.read(1024)
lst[i:] + lst[:i]
reordered = l[-1:] + l[:-1]
client_connection.close()
b = np.random.rand(6, 5, 4)
httpretty.disable()
mydict.setdefault(key, list())
assert isinstance(x, Iterable) and not isinstance(x, StringType)
b = zip(*a)
pubkey.verify_init()
line1 = LineString([(0, 0), (1, 0), (1, 1)])
print(_string)
f2 = f2 * np.max(f1) + (1.0 - f2) * np.min(f1)
loop = asyncio.get_event_loop()
[s[i:i + 4] for i in range(0, len(s), 4)]
ax = fig.add_subplot(2, 2, a + 1)
m = graphlab.recommender.create(data)
bucket.configure_versioning(True)
tree_dict = {}
do_something_5()
print((key, value))
ax1 = fig.add_subplot(111)
pd.Series(b[1], df.columns, name=df.index[-1])
a[a.argsort()[-10:]]
distutils.util.strtobool(some_string)
index = d * (d - 1) / 2 - (d - i) * (d - i - 1) / 2
msg.attach(msgAlternative)
v = np.random.normal(size=d)
process = Process(target=greet, args=(string,))
sys.exit(main())
obj.put()
datetime.datetime.fromtimestamp(obj[0][1])
processes.remove(p)
arr = numpy.array(numpy.round(arr), dtype=numpy.uint8)
q = np.empty_like(p)
w.show_all()
bokeh.io.output_notebook()
stdscr.clrtoeol()
os.sys.path.insert(0, parentdir)
plt.hist(data, 50, normed=True)
a = np.arange(10)
result = service.resource().method([parameters]).execute()
x /= x[2]
minutes, seconds = divmod(seconds, 60)
s.append(im[x - 1:x + 2, y - 1:y + 2])
result.reset_index(inplace=True)
DataMatrix(data, index=dates)
np.maximum.accumulate(mask, axis=1, out=mask)
{{names | safe}}
p2.rotate(angle)
xx1 = np.linspace(x.min(), x.max(), 50)
print(sys.argv)
fo.close()
a = list(range(1, 50))
self._handle_request_noblock()
print(root)
regex.sub(lambda mo: dict[mo.string[mo.start():mo.end()]], text)
plt.imshow = my_imshow
stdout_fileno = sys.stdout.fileno()
print(chambersinreactor)
pattern = np.ones((24, 16), float)
main()
a + b
masterlist.update((x, False) for x in exceptions if x in masterlist)
self.columnconfigure(1, weight=1)
a, b, c, d = result
self.lc = task.LoopingCall(self.announce)
print(hex(id(a)))
copy(args[0])
cherrypy.config.update(confdict)
pathqueue.join()
gibberish(5)
Astars.append(s)
fig, ax = plt.subplots()
np.vstack((a[(0), :], a[1:, :] + a[(0), :] * 1j))
records = Record.objects.filter(project_id=1)
list()
os.kill(int(ps_output), signal.SIGTERM)
x[0]
docfile.close()
print(m.group(6))
a = os.stat(os.path.join(directory, i))
self.clearLayout(layout)
new_class
print(line)
data = s.recv(1024)
abs(2 - 1)
reader = csv.reader(f1)
ax1 = plt.gca()
length = len(text)
self.init_app(app, db)
ax.legend()
main()
print(myline)
ax0a.set_xticklabels([])
ts = np.arange(0, 1, 0.01)
b = np.random.randint(0, 9, (2, 1)).ravel()
n *= 2
r = min(r, n - r)
Base = declarative_base()
urlhash = models.CharField(max_length=6, null=True, blank=True, unique=True)
print(msg)
main()
1, 8, 8, 8
arr = np.roll(arr, num)
self.write(somedata)
s.mean(axis=0)
vbox.add(image)
grouped = df.groupby([times.hour, times.minute])
start_urls.append(url)
plt.scatter(x, y, c=t, cmap=cm.cmap_name_r)
a = a + 1
ax1.view_init(*init_view)
zip(new_lists, overflows)
num_rejects += 1
transport.close()
window.show()
np.sum(~(a ^ b))
pprint(dict(di))
result = next(x for x in (a, b, c, d, e, default) if x)
app.exec_()
sum(Fraction(1, d) for d in range(1, n + 1))
homebrew / science / opencv
main.run()
md5.update(chunk)
self._b = [A() for x in range(5)]
print(result.get(timeout=1))
result[result.size / 2:]
plt.plot(x, y, zorder=2)
{}
sct_subscript
choices = list(chain(self.choices, choices))
result[key] = row[1:]
x = range(10)
do_something_4()
size = ctypes.c_int()
fruitDB.close()
p_form = [sum(sintervals[:i]) for i in range(len(intervals))]
y[i] += A[i, j] * x[j]
overlap(0, 100, 0, 20)
dates = [re.match(pattern, x).groups()[0] for x in my_strings]
B = get_A()
deletethe_map[i]
[1, 1],
cv.CvtColor(difference, grey_image, cv.CV_RGB2GRAY)
self.obj[self.key] = val
self.root = Tk()
(1 if text[0] == char else 0) + count(char, text[1:])
y = tf.Variable(tf.zeros([]))
i += 1
ssc.start()
p = [(len(str(x)) + 1) for x in l]
list1_new = [x for i, x in enumerate(list1) if list2[i] in list2[:i]]
connection.close()
cur_set.append(A[index])
print(doc.xml.web.offset.string)
today = datetime.date.today()
self.reverser = dict()
view.show()
list(takewhile(lambda date: date.year < 2014, tuesdays_of_february))
canvas.config(xscrollcommand=hbar.set, yscrollcommand=vbar.set)
now_date = datetime.datetime.now()
A = pd.Series(list(range(1, 5)))
Session = sessionmaker(bind=engine)
self.closedmax = closedmax
self.slidermax = slidermax
self.slidermin = slidermin
self.closedmin = closedmin
remain += int(i)
json.dumps(d, sort_keys=True)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
date_ceased_to_act = models.DateField(blank=True, null=True)
main.mainloop()
password()
getMappingsNode(n, nodeName)
df = pd.DataFrame(np.ceil(np.random.rand(1, 10) * 1000))
seconds_since_midnight = time.time() - time.mktime(today.timetuple())
cj = cookielib.CookieJar()
print(tree.getpath(element))
random.shuffle(a)
handler = logging.handlers.RotatingFileHandler(file_name, maxBytes=10 ** 9)
reader = csv.reader(f2)
label.set_rotation(45)
self._copy_attrs(df)
array.remove(array[0])
dlist.append(d.copy())
Base.metadata.create_all(engine)
parent.insert(parent.index(element) + 1, new_element)
print(str(count).ljust(10), conv)
content = response.read()
print(data)
e.__traceback__
[0.0, 0.95510649, 0.0],
dt = datetime.datetime.fromtimestamp(ts).replace(tzinfo=tz.tzutc())
Base.metadata.create_all(e)
SPECIAL_RULES[name]()
a * b
frame = cv.QueryFrame(capture)
plt.hold(False)
help(module)
scroll_win = gtk.ScrolledWindow()
mask = numpy.in1d(numpy_array, repeat_set).reshape(numpy_array.shape)
VERSION,
conn.execute(tb_create)
os.fstat(f.fileno())
L[:] = [(i[:1] + i[2:]) for i in L]
sess.run(train_step, feed_dict={learning_rate: 0.1})
zip_longest(fillvalue=fillvalue, *args)
s.format(**d)
False
parser.feed(pstring)
PySys_SetArgv(argc, argv)
self.Artwork.destroy()
server.serve_forever()
matplotlib.matplotlib_fname()
UserName = db.Column(db.String(40))
p = multiprocessing.Pool()
self.quit()
app.register_blueprint(account_api)
print(df.loc[idx])
lambda x: x % i == 0
buttonList.append(new_button)
ax.figure.canvas.draw()
lines = f.readlines()[:-5]
args = [4, 5, 6]
threads.append(threading.Thread(target=process, args=(items, start, end)))
model = LinearRegression()
keys = (list(x.keys()) for x in d.values())
plt.bar(counts.index, counts)
z_surface[where(ma.getmask(Zm) == True)] = numpy.nan
server.start()
yaml.add_representer(folded_unicode, folded_unicode_representer)
Decimal(1).exp()
d2[k] = f(v)
ctypes.memmove(ctypes.addressof(self), bytes, fit)
inner
cmap = plt.cm.gray
data = [(x, k) for k, x in enumerate(data)]
d.close()
a[b][0] is a
driver = webdriver.Firefox(firefox_profile=profile)
[1, 1, 1, 1, 1, 1, 1]
myShelve.close()
qs = self.model.autocomplete_queryset()
line1 = f.readline()
outfile.flush()
random.shuffle(choose_from)
np.all(xdiff[0] == xdiff)
self.x2 - self.x1 + self.y2 - self.y1
self = dict.__getitem__(self, key)
pp.savefig()
output.append(curr_date)
argmax(enumerate(values))
background = pygame.Surface(screen.get_size())
lst.sort()
max([len(format_field(row[index])) for row in table])
i += 1
g.write(got)
sys.modules.update((mod_name, Mock()) for mod_name in MOCK_MODULES)
lines = list(f)
a2 = a[:]
a ^ b
list(pair(oldList))
x.min(0)
w, h = im.size
d[tup[0]] = {}
cj = cookielib.CookieJar()
sys.getsizeof(sys.getsizeof)
np.argsort(mapper_a), np.argsort(mapper_b)
print(s.query(a_alias, b_alias).all())
do_something()
counts = collections.Counter(test)
np.random.seed(479)
print(win.get_name())
l.append(make_foo(r))
min, max = min(x, y), max(x, y)
root.focus_force()
appstats_CALC_RPC_COSTS = False
stdscr.keypad(1)
test(0, 10, 11, 12, 14, 16)
orig_save(self, *args, **kwargs)
y = collections.Counter(x)
f.close()
print(Counter(a) == Counter(b))
img = np.zeros((height, width, channels), dtype=np.uint8)
self.end_headers()
hsv(float(i) / (len(data) - 1))
print(type(node).__name__)
print(ax.get_xlim())
a = []
[50, 51, 52]
all(line in lines or line[::-1] in lines for line in lines_needed)
self.rows = numpy.delete(self.rows, i, 0)
labels.append(line)
partslist = good_histograms(nballs, nboxes, minballs, maxballs)
f = Foo()
mark_safe(json.dumps(object))
asyncio.get_event_loop().run_until_complete(meth(*args, **kwargs))
next(b)
do_something_5()
print(s1.zfill(5), s2.zfill(5))
B = rand(10000)
print(traceback.format_exc(), file=sys.stderr)
port = int(sys.argv[1])
cameraR.SetPosition(0, 0, 200)
conn.close()
pdfContent = db.BlobProperty()
word = line.strip()
line = f.readline()
subplot(212)
G.add_edge(2, 4)
all(c in hex_digits for c in s)
f.seek(0)
ax1 = plt.subplot(1, 2, 1)
random.shuffle(iters)
only_na = df[~df.index.isin(na_free.index)]
ex.args = (msg,) + ex.args[1:]
meds = df2.median()
first_name = models.CharField(max_length=50)
fo.close()
font.configure(size=size)
np.transpose(np.array(X.T * (y - X * b)))[0]
app = wx.App(False)
context = self.get_context_data()
q = q.filter(User.id == uid())
print(leaders(xs))
theta = 2 * np.pi * np.random.rand(n)
one.click()
radii * exp(1j * angles)
tunnel._rport
pdb.set_trace()
pipe.execute()
build()
_auxset = set(a)
self.lock.release()
self.do_egg_install()
data.most_common()
y = np.array([(0, -5), (1, 0), (2, 5), (5, 20), (6, 25)], dtype=dtype)
pool.close()
rec_split(s)
exit()
ts.to_pydatetime()
list(in_order(x))
queryset.query.__str__()
server_A_thread.start()
os.wait()[0]
sysconfig.get_platform()
cur.close()
http_client = tornado.httpclient.HTTPClient()
row = next(csv.reader([line]))
one_array.append(5)
this_row_std = numpy.std(np_row)
r.status_code
deepest_list, max_depth
baz.__doc__
app = Flask(__name__)
print(datetime.datetime.now())
ax.margins(0.05)
browser = webdriver.Firefox()
print(key, item[key])
x_scattered, y_scattered = np.random.rand(2, N_scattered ** 2) * 2 - 1
list(filter(invent_some_convoluted_name, list(range(10))))
Base.metatada.bind = op.get_bind()
stations[w] = i
-24.1529840248
-7.87165586175
-24.9012815104
-7.44222705099
-6.25705487929
-7.141616656
-15.0906961724
sd.sleep(duration * 1000)
sys.__stderr__ = dummyStream()
self.SaveSettings()
print(i.get())
new[k].extend(v)
plt.imshow(im)
msg.set_payload(zf.read())
curs.execute(sql, dates + [id])
data = json.loads(json_string)
img.view(np.uint8)
fig = plt.figure()
s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
self.other_field = other_field
merged = pd.concat(dfs, axis=1)
bits = int(max(8, math.log(num, 2) + 1))
x = [(i, i * i) for i in range(5)]
new_list = []
tk.Frame.__init__(self, *args, **kwargs)
add.apply_async(args, kwargs, task_id=i)
int_list
a[2] = 55
systems = []
culled_list
iter([item])
cb.stateChanged.connect(self.changeTitle)
m.drawcoastlines()
self.nout = 0
print(list(kwargs.keys()))
writer.writerow(new_row)
student_tuples.sort(key=itemgetter(2), reverse=True)
Clothing | Menswear | Pants | Pajamas
rs = (grequests.post(u, data=params) for u in urls)
print(p.x, p.y)
df
funcfile.close()
do_something_4()
print(df)
bucket = conn.get_bucket(your_bucket)
a = np.array([5, 4])[np.newaxis]
text.translate(tbl)
display(Image(filename=imageName))
allkey = {key for dictio in alldict for key in dictio}
print(nx.topological_sort(g))
B = lfilter([a], [1.0, -b], A)
foo.py
p.join()
cursor.execute(cql_statement, rename_dict)
wipe = Wipe()
newTimeStamp = time.mktime(newTimeStamp.timetuple())
self.triangle_down_color = 1, 0, 1, 1
matched.append(dict(group))
outfilename = os.path.join(path, name)
__file__
n, d = divmod(n, 256)
dst.SetProjection(match_proj)
self._queue.join_thread()
x = np.linspace(0, 6, 200)
shp = b.shape[:-1]
b = np.zeros((N, N + 1))
print(repr(isanything))
tkw = dict(size=4, width=1.5)
c = Counter({k: v for k, v in list(c.items()) if k not in bad_words})
print(soup)
path = os.path.join(basepath, fname)
ctx.set_source_rgb(1, 1, 1)
self.web_view.loadFinished.connect(self._load_finished)
print(a)
df.ix[(df.num - x).abs().argsort()[:5]]
self._array[self._index]
f = Foo()
print(books[i].price)
blocks[1][0]
pickle.dump(biverses, arquive)
self.data.__setitem__(key, value)
[k.key for k in set(IPKey(k) for k in workers)]
print(page.mediaBox.getUpperRight_x(), page.mediaBox.getUpperRight_y())
noholes = mh.morph.close_holes(skel)
file_path = filename.split(os.sep)
help(zip)
print(line)
tree[x][y][z].append(value)
conn = engine.connect()
print((date, enumerate(events)))
mat = lil_matrix((len(arr), len(arr)))
ZS.append(row)
self.taskLogger.__exit__(status, retval, task_id, args, kwargs, einfo)
soup = BeautifulSoup(string)
seq.set_seqs(a.lower(), b.lower())
sys.exit(application.exec_())
rows = cur.fetchall()
print(leadingzerocounts)
print(datetime.now() - startTime)
new_genpost.save()
G.add_edges_from([x, temp.pop()] for x in L2)
print(list(result_strings))
self.Show(False)
self.update(dict(list(parent_element.items())))
mylib.Add.argtypes = [c_int, c_int]
float(op)
reader = PdfFileReader(f)
np.unique(a)
self.response.out.write(self.dump_csv())
pool = multiprocessing.Pool()
tmp = tmp.reshape(2, 2, 4)
hide_spines()
num_in_box = models.IntegerField()
fig.show()
header = {k: v[0] for k, v in header.items()}
YOOOO
print(d[keyList[i + 1]])
fig = plt.figure()
S = myfile.read()
raise MyCustomException()
gtk.main()
plt.show()
self._password = value
sum(x1 * y2 - y1 * x2 for (x1, y1), (x2, y2) in pairs) / 2
struct.unpack(fmt, astr)
pdf_reader = PdfFileReader(f)
ax1.set_ylim(0, 1)
m = np.tril(a) + np.tril(a, -1).T
combined[1::2] = pos
client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
fig = pyplot.figure()
df = ts.reset_index()
plt.plot(b, a2)
arr = numpy.array(arr)
print(os.path.abspath(fullname))
print(a.T)
app.exec_()
X = X.T
print(data)
d = json.loads(text)
p = argparse.ArgumentParser()
self.vLayout = QtGui.QVBoxLayout()
foo()
data = resp.read()
newfunc
pool = Pool(num_items)
p.acquire()
button = QtGui.QPushButton(name, self)
title = models.CharField(max_length=40)
x, y, z = int(x) + 1, int(y) + 1, int(z) + 1
sys.stderr = UTF8StreamWriter(sys.stderr)
res = client.get_job_status(jr)
p.stdin.write(the_input)
f, x, y, z = generate_data(nobservations, a, b, c)
ax.set_xticklabels(row_labels, minor=False)
True
tornado.ioloop.IOLoop.instance().start()
A[:, (0)] = np.log(x)
setattr(cls, attr, prop)
soup = BeautifulSoup(tidy_document(browser.response().read())[0])
[lst[round(division * i):round(division * (i + 1))] for i in range(n)]
temp_csv.seek(0)
signal.alarm(0)
0
print(len(x.tostring()), len(dumps(x)))
type(float(s))
auth_user = form.get_user()
plt.title(title)
A.__init__(self, *args)
sorted_table = [[row[j] for j in js] for row in table]
Doc.images.all()
problems = False
ax.plot_surface(xx, yy, z, alpha=0.2, color=[0, 1, 0])
newImage.paste(im, (x1, y1, x1 + old_width, y1 + old_height))
xyB[:, (0)] *= lengthB / (xyB[:, (0)].max() - xyB[:, (0)].min())
r2 = np.hstack((w, b, w, b, w, b, w))
screen_height = root.winfo_screenheight()
x = np.random.random(1000000)
unicode_text = f.read()
print(msg.SenderName)
sel = Selector(response)
MySerializer
assert np.all(list(filter(df, 1)) == df)
_(calendar.day_name[0])
GL.glLoadIdentity()
request.add_data(data)
deleteself.thisptr
x2D = x.reshape(-1, n / q, q).transpose(1, 0, 2).reshape(-1, q)
some = [random.randrange(10000) for _ in range(1000)]
grouped_cc[ki].add(kj)
grouped_cc[kj].add(ki)
True
pd[0].append(1)
s.any()
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
isinstance(val, int) or isinstance(val, float) and val.is_integer()
main()
nw[0]
sum(a, [])
b[:, :, (2)]
val = d[key]
types.FunctionType(new_code_obj, f.__globals__)
x = np.random.randn(1000)
data[row[0]] = row[1:]
x.shape += 1,
root.withdraw()
ArgumentParser.add_subparsers()
output
clf()
fig.show()
x = numpy.array([Foo(), Foo()])
print(x)
platform.version()
columns = zip(*cursor.description)[0]
result = cache.get(cache_key)
print(M.shape, Msmall.shape)
clientsocket.send(msg)
self.table = QtGui.QTableWidget()
s.add(a)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
vals = np.array([color1, color2], dtype=np.uint8)
instance.put()
print(msgpack.loads(x))
self._bar
e.extract()
result = recursive_dict()
self.oldText.tokens.clear()
app = Flask(__name__)
control.SetPosition((10, 10))
print(data)
individuals.append(individuals.loc[1])
self.x += 1
sizer_1.Add(self.panel, 1, wx.EXPAND | wx.ALL, 0)
self.workers.release()
self.queue[index]
r_ab = np.array([r_a, r_b])
session.query(Beard, Moustache).select_entity_from(stmt)
self.assertEqual(99, s)
a = np.array(a)
f.seek(n)
_threadmap = {}
index[:-1] = groups[1:] != groups[:-1]
x = np.arange(-5, 5)
count1 = len(shortstrings)
plt.ylim((1e-20, 1e-10))
x, y = [], []
some_code()
id = Column(Integer, primary_key=True)
y, x = np.histogram(df, bins=bins, normed=True)
logger.propagate = False
pool.join()
x()
html - page - context(app, pagename, templatename, context, doctree)
rcode = response.rcode()
app.exec_()
print(content)
pypitest
user = request.user
print(tmp.index(K[-N]))
elem.send_keys(Keys.RETURN)
server_socket.listen(1)
df
self.figure, self.ax = plt.subplots()
node = self.head
gdb.start_event_loop
cur = [[14, k, j] for j, k in zip(rows[14], list(range(15)))]
output, error = sp.communicate()
html = response.read()
y = list(max_elements.values())
s = socket.socket()
self.image = gtk.Image()
scipy.nan
i += 1
example()
self.a[-1] = self.z[-1]
fig, axs = plt.subplots(2, 1)
self.mplvl = QtGui.QWidget(Form)
root = tk.Tk()
df.min(axis=1)
stack.append((prev_indent, prev_tree))
ipython - -no - banner
dis.show_code(a_long_tuple)
blo += 1
dic.get(key)
os.chdir(savedir)
------models.py
b = a.copy()
df[1]
print(i)
i = 0
curlstdout, curlstderr = psub.communicate()
column_1 = [float(line.strip()) for line in f]
map.close()
test.reshape(-1, 2)
PrintLn(i)
out, err = proc.communicate()
_curried
my_template = template.Template(template_string)
sys.argv[1]
random.choice(list(open(WORDS_FILENAME)))
counts[char] += 1
db.init_app(app)
os.symlink(target, symlink)
file.flush()
temp_rdd.toDF(schema).printSchema()
unq_count = np.diff(np.nonzero(unq_first)[0])
len(sall)
df = pd.DataFrame(rows, columns=cols)
rsp.raw._connection.sock.getpeername()
set([y, x, 0])
zip(a, b)
configs / __init__.py
self.after(4000, self.draw)
sigmoid(0.458)
fig = plt.figure()
smtp.ehlo()
savetext(filename, a.reshape(1, a.shape[0]))
setattr(namespace, self.dest, values)
comb = itertools.product(uk_rock_stars, uk_pop_stars, us_stars)
h = np.zeros((2, 2, 1))
assert foo.bar == 50
ax.plot(matrix[(i), :])
foo = timeit(foo)
logger = logging.getLogger()
setattr(varobj, k, v)
output_files[i].close()
setup_environ(settings)
10 * -1
paw_code[diff.argmin()]
self.dependency.__enter__()
pygame.event.pump()
session.visit(my_url)
model = Sequential()
False
default_font.configure(size=48)
crawler.start()
output.append(x)
comparison_df = pd.DataFrame(index=matrix.index)
outfile.write(line)
data = heapq.nlargest(2, enumerate(my_list), key=lambda x: x[1])
L.extend([some_mutable_object for x in range(10)])
c.setopt(pycurl.MAXREDIRS, 5)
text
ax.set_position(ax._orig_position)
N = data.shape[1]
output = np.zeros_like(foo)
header = [next(f) for _ in range(header_len)]
ax = plt.subplot(122)
self.image.url
delete_bar
yaml.dump(d, yaml_file, default_flow_style=False)
myimages.append([imgplot])
next(iterator)
but.pack()
y_true = np.array([0, 1, 0, 0, 1, 1, 0, 1, 0])
func(*args, **kwds)
result = [(item, count(item)) for item in set(the_list)]
model = model.fit(X, y)
result = []
sys.stdin.read()
m = numpy.rot90(m, k)
nlist = [x for sub_l in (split_or_not(l) for l in blist) for x in sub_l]
db.commit()
[0] * -1
self.flush()
create_browserid_user(kwargs)
a = [7, 14, 0, 9, 19, 9]
terrf = ax.contourf(xi, yi, height, 15, cmap=plt.cm.Blues, alpha=0.5)
theta = np.linspace(0.0, 2 * np.pi, N, endpoint=False)
im_array = np.array(Image.open(im))
[number] * int(factor)
plt.annotate(annotation_string, xy=(0.5, 0.5))
str2num = (np.fromstring(A, dtype=np.uint8) - 48).reshape(-1, 4)
l.count(True) == 1
hashlib.sha1(url).hexdigest()[:10]
PyErr_Clear()
unfiltered = ((myFunction(C), C) for C in originalList)
my_array.append(e)
ax.add_line(line)
xy_pixels = ax.transData.transform(np.vstack([x, y]).T)
(x < 0).sum()
out = np.zeros((N, shp[0], N, shp[1]), dtype=int)
image = Image.open(image_string)
c.close()
print(args)
leng.count = 0
plt.subplot2grid((4, 4), [2, 0], 2, 2)
urlparse.urlunsplit((scheme, netloc, path, qs, anchor))
len(self._choices)
ax = fig.gca()
axes[2].hexbin(x, y)
counts = defaultdict(int)
main()
self.toolbar.addAction(action)
o.close()
interp_i = np.linspace(0, i.max(), 5 * i.max())
x, y = x.difference(y), y.difference(x)
f.write(png_recovered)
h = np.zeros((2, 2, 2))
img = np.array(img)
fcntl.fcntl(fd, fcntl.F_SETFL, flags_save)
repeats = np.diff(np.r_[jump_indices, [N]])
ax.set_xticks(xlabels)
fig = plt.figure()
tf.add_n([tf.nn.l2_loss(t) for t in list_o_tensors])
soup = BeautifulSoup(r.text)
a_tr = zip(*a_padded)
print(row)
i += 1
print(next(csv.reader([c])))
self.store.append(data)
self.setLayout(layout)
apps2
len(L1) == len(L2) and sorted(L1) == sorted(L2)
df.ix[row_pos]
list.focus(items[0])
subprocess.check_call(cmd.split())
self._bar = value
[[next(it) for c in g] for k, g in grouped]
unquote(unquote(s))
newlist = []
ip.release()
logging.basicConfig(stream=sys.stderr)
image_y[:, :] = image_yuv[:, :, (0)]
ip.close()
any(it) and not any(it)
x = numpy.linspace(0, len(y) + 2, 100)
openlist.put((heuristicf(neighbor), node(neighbor, current.g + 1, current)))
a = np.array([True, True, True, False, False])
q.append(next(i))
main()
print(a)
assert isinstance(value, (int, float))
rpy2.robjects.vectors.DataFrame(od)
ex[0]
urllib.request.urlopen(quoted_url)
sys.path.insert(0, parentdir)
option = EuropeanOption(payoff, exercise)
self.searchobj
baset = datetime.now()
os.remove(path)
self.deal()
string.Formatter().parse(s)
l.append(self.gears[x][index])
user_input = default
plt.rgrids(list(range(5, 20, 5)), angle=290)
b = b.add(1).cumprod()
df_subset = df[(df.B == 1) & (df.D > 5)]
sum(utf8_char_len(c) for c in s)
math.hypot(p1[0] - p2[0], p1[1] - p2[1])
n += 1
os.setresuid(0, 0, -1)
exit()
print(dot(M0, v))
cr.set_source_rgba(0, 0, 0, 1)
result = joiner.join(result)
results = model.fit()
ax.set_ylim(-10, 10)
print(cur.fetchall())
df2 = df1.div(df1.sum(1), axis=0)
sys.__stdout__ = dummyStream()
thefile.seek(-len(line), 1)
dict.__setitem__(self, key, self.default_factory(key))
result = func(*args)
print(json.dumps(d))
client = paramiko.SSHClient()
response = HttpResponse()
self.add(data)
self.save_m2m()
output = StringIO.StringIO()
process = multiprocessing.Process(target=foo, args=(to_self,))
df
print(len(cj))
fig = plt.figure()
print(row[1:12])
a = np.random.uniform(0, 10, size=10)
doSwim(where, why, **kwargs)
result.append(word)
sys.exit(1)
y = numpy.array(x)
f = StringIO.StringIO()
shmdt(shmid)
{buildout: software - parts}
c = b.copy()
self.button1.clicked.connect(self.handleButton)
abs((d2 - d1).days)
ax = plt.gca()
self.lock.release()
print(line)
self.tstore.clear()
Mailbox.user(user)
Image()
cache[object_to_cache] = object_to_cache
df.t.dt.normalize()
deletegraph[i]
print(isinstance(MyClass(), MyClass))
print(type(fresult.col1.iat[2]))
ncol = len(traindf.rdd.map(lambda r: r.image).first())
count2 += 1
u = np.sin(np.pi * x) * np.cos(np.pi * y) * np.cos(np.pi * z)
Z2 = bivariate_normal(X, Y, 1.5, 0.5, 1, 1)
parser = ElementTree.XMLParser(recover=True)
handle.write(block)
pylab.show()
app = Flask(__name__)
z = [0, 0, 0]
first_user = User.objects.all()[0]
ax.margins(0.01)
tdomain = df2domain(df)
words = sum(c.isalpha() for c in s)
client_sock, client_addr = server_sock.accept()
cv.SetImageROI(newCanvas, (image.width, 0, img0.width, img0.height))
a.call_me()
L = list(range(0, 101, 10))
print(np.max(a, axis=axis))
result = np.empty((27, 27))
plt.show()
ax.set_yticks(T)
print(sess.run(parsed, feed_dict={raw: my_data}))
r = np.sqrt(x ** 2 + y ** 2)
soup = bs(html)
a[2] is b[-2]
now = time.mktime(time.gmtime())
self.cursor.close()
reverse_d[value] = key
cursor = connection.cursor()
output.extend(seq[1:])
btn.Bind(wx.EVT_BUTTON, self._onShowCntrls)
pprint.pprint(dict(groups))
electronDensity = eval(vName)
b, c = indices = np.sort(np.random.randint(size + 1, size=(2, size)), axis=0)
datetime.now()
s += A[k] * B[k]
the_dict
self.failureResultOf(self.o.failure()).trap(ConnectionRefusedError)
assert ostr.good()
output = [(0) for x in range(6)]
_.flatten()
fruits[1]
code_object.co_stacksize, code_object.co_flags, code_object.co_code
print(mail.getwelcome())
df.groupby(0).mean()
pythons_psutil.append(p)
r = [ran.random() for i in range(1, 100)]
then = datetime(2016, 1, 1, 0, 0, 0)
gt = ds.GetGeoTransform()
t, y = scipy.signal.dstep(sysd_ss)
self.locator.sub(self._doreplace, s)
socketIO.wait(seconds=1)
time.sleep(10)
start = time.clock()
self.fields.pop(field_name)
main()
fig, ax = plt.subplots()
auth = urllib.request.HTTPBasicAuthHandler()
foo(*args, **some_args)
reader = csv.DictReader(csvfile)
fig, ax = plt.subplots()
process.stderr.close()
username = models.CharField(max_length=100)
b = a[:]
timezone.make_aware(date, timezone.utc)
text.see(END)
env = Environment()
self.__copy__()
solution2 = (-b + cmath.sqrt(d)) / (2 * a)
p = Pool()
data = data.reshape(len(data) / num_channels, num_channels)
today = date.today()
column_entry.show()
self.local_storage._save(filename, content)
line = sys.stdin.readline()
wrapper
plt.gray()
bSizer.Add(button5, 0, wx.ALL, 5)
print(data[np.r_[np.diff(id), True].astype(np.bool)])
a = datetime.datetime(2015, 10, 1)
my_list.append(float(item[0]))
tabrows.append(row)
self.thread.setDaemon(True)
temp = scaler.transform(temp)
time.sleep(5)
pprint.pprint(res)
df = DataFrame(d)
PyErr_SetString(p_eigen_python_error, msg.c_str())
writer.writerow(row + [message])
X, Y = np.meshgrid(x, x)
utc_dt = datetime.utcfromtimestamp(ts)
app.internalerror = myinternalerror
d[i] += 1
print(len(s))
Py_DECREF(py_string)
heapq.heappop(self._data)[1]
br.set_cookiejar(cj)
os.remove(os.path.join(root, name))
print(scapy.__file__)
z = np.tensordot(p2, x, axes=([0, 2], [0, 1]))
rect_one = pygame.Rect(x_pos, y_pos, 10, 10)
h.setdefault(x, []).append(y)
x = np.arange(W)
Subscript
samples[random.randint(0, n_samples - 1)] = line
notifier.loop()
test = df.drop(train.index)
sorted([1, N, 0, 9999, sys.maxsize])
tuple(a)
qlock.acquire()
fh = os.open(outfile, os.O_CREAT | os.O_WRONLY, perm)
customer = models.ForeignKey(Pizza)
proc.terminate()
X = np.random.normal(size=N)
g = f()
print(x)
diffs = (df.sign.diff() != 0).cumsum()
pylab.show()
zip(a, b)
size_width, size_height = image.readline().split()
NSERC_CB04_A0401
session.commit()
mytuple = tuple(mylist)
[line.strip() for line in foo if not line.isspace()]
julia > ma.is_masked(x)
49800000000
4000000000000000000000000000000
frame = inspect.currentframe()
print(list(multi_d.items()))
geocalc(-6.508, 55.071, -8.886, 51.622)
self.username = username
a = np.arange(10)
data = etree.parse(fname)
filename = traceback.tb_frame.f_code.co_filename
plt.draw()
interpreter.process_page(page)
p = Process(target=multiply, args=(5, 4, queue1))
d.year
print(np.array(data))
self._name
array([math.atan2(y, x) for y, x in zip(diff(y1), diff(x1))])
cap.set(cv.CV_CAP_PROP_FRAME_HEIGHT, int(y))
print(a % tuple(b))
handler500 = Custom500View.as_view()
r = np.linalg.norm(R)
file.close()
time.sleep(6)
demo_kalman_xy()
a += b_ext[start_idx[j]:start_idx[j] + n]
count(0, 0)
sets.append(x)
a.py
self.handlers[event].add(callback)
sys.exc_clear()
self.__initialized = True
ax = plt.gca()
A[:, (1)] = 1
b = np.array([0, 1, 0, 1, 0, 1])
print((a, b, c))
sc = proprocessing.StandardScaler().fit(X)
main()
ax = plt.gca()
self.md5.update(o)
print(df.max(axis=1))
signal.signal(signum, _gogentle)
item.setPos(position.x(), position.y())
print(byall())
fig = pyplot.figure()
self.dictList[item][self.key]
d[k] = d[k][0]
string[i:i + len(keyword) + 5]
df.show()
callback(req)
util.run_wsgi_app(application)
module_filetype = os.path.splitext(module_filename)[1]
int(text) if text.isdigit() else text
plt.grid(True)
cur = con.cursor()
TextConverter.__init__(self, *args, **kwargs)
ax.add_patch(patch)
cs.send(c + 1)
self.thisptr.getA()
self.addItems(self.list_two)
rowsums = pd.concat([df.sum(axis=1)] * 2, ignore_index=True, axis=1)
self.splitter.addWidget(self.view)
stringFrom(v)
print(list(splitter(str, split_points)))
p.save()
my_thread.join()
first_day = dt.replace(day=1)
df1 = df1[~dupe_rows]
items.sort(key=keys.__getitem__)
print([(r / s) for r in raw])
generate_random_data(latitude, longitude, 5)
app = Flask(__name__)
alias = db.StringProperty()
C = M.T.reshape(1, ncols, 1, nrows) * M.T.conj().reshape(ncols, 1, nrows, 1)
x = np.ma.array(x, mask=mask)
m = l + [(i + 1) for i in l]
self.value
fig = plt.figure()
x, y = np.meshgrid(np.arange(10), np.arange(10))
func(*args, **kwargs)
print(m.groups())
r = requests.get(login_url, cookies=jar)
setup(**configuration)
freqs = np.fft.fftfreq(len(x))
cursor = cnxn.cursor()
soup = BeautifulSoup(resp.get_data())
time_end = time.time()
np.diff(np.where(np.diff(np.hstack([False, a, False])))[0])[::2]
qs = cgi.parse_qs(urlparse.urlparse(url)[4])
parseLog(sys.argv[1])
location, (latitude, longitude)
print(match.groups())
x * x
tz.normalize(dt.astimezone(tz)).time()
B60 = A60 + B59
self.axes.plot(t, s)
np.abs(A[:, (np.newaxis)] - B)
print(list(Squares(5, 50)))
reader = unicode_csv_reader(open(filename))
cal_window.stick()
result = []
unpickledlist = pickle.load(f)
image.save(output, format)
keys.add(entity.getKey())
list(test)
-ntrees
[]
out_file.write(in_data)
os.close(fin)
int(x)
abs(new - old).max()
print(func())
logger.setLevel(level)
i, j = np.ogrid[0:5, 0:5]
sess.run(train_step, feed_dict={learning_rate: 0.01})
self.child.start()
pubkey.assign_rsa(rsa)
a180 = np.rot90(a.T, 2).T
sorted(files, key=numericalSort)
fig = plt.figure(figsize=(5, 5))
pool.apply_async(f, args=(i,))
client.settimeout(60)
B().a1()
{k: (x.get(k, []) + y.get(k, [])) for k in set(x).union(y)}
response
src_dt = src_tz.localize(dt)
pylab.colorbar()
pdb.set_trace()
y = lab[:, :, 1:]
print(t.timeit(1000))
E(X, X > Y, evaluate=False)
[tuple_array[i] for i in range(0, array.len)]
index, word = line.split()
tk.Frame.__init__(self, parent)
df
list.append(self, a)
do_something_with_connection(b)
print(bv)
driver = webdriver.WhatEverBrowser()
print(char, char.isalpha())
writer.write(tup)
result = seq.index(first_val)
NULL
self.layout.addWidget(self.listWidget)
json_data = json.dumps(response)
cand[i] += 1
cipher = AES.new(self.key, AES.MODE_CBC, iv)
len(s)
c = db.cursor()
self.pushes
basket = dict(basket_one, **basket_two)
draw.ellipse((0, 0, rad * 2, rad * 2), fill=255)
ax1 = fig.add_subplot(111)
model = model.fit(X, y)
opener = urllib.request.build_opener(authhandler)
copy_my_list = copy.deepcopy(my_list)
df2 = pd.DataFrame(values, index=index, columns=columns)
genes_dict[row[0]] = row[1:]
form = UploadFileForm(request.POST, request.FILES)
a = datetime.datetime(2011, 8, 1)
wi = x.Whateveri(5)
df.head()
workbook.add_worksheet(sheet_name)
True
ax.text(p.get_x() + 0.05, height + 1, df.columns.levels[1][i])
fig.tight_layout()
g = df.columns.to_series().groupby(df.dtypes).groups
_find_root(os.path.dirname(start), stop)
diff = difflib.ndiff(open(file1).readlines(), open(file2).readlines())
NULL
headers = df.dtypes.index
PythonEngine.Shutdown()
decorator
time.sleep(wait_time)
s.set_xticks(ind + 0.5)
cols = tuple(df.columns)
a = dict([next(iter(x.items())) for x in foo])
ceiling_key(d, 2)
f.read()
offset += len(line)
unaware = datetime.datetime(2011, 8, 15, 8, 15, 12, 0)
f.close()
(np.arange(n) >= arr[:, (np.newaxis)]).astype(int)
fd = sys.stdin.fileno()
main()
s = pd.Series(hourly_data.flatten(), index=new_ind)
set_lang(LANG, pylons_config=conf)
1, 2, 1
remote_api.get_cached_name(user.id)
colors = plt.cm.jet(np.linspace(0, 1, 10))
irenL.SetRenderWindow(renWinL)
c = a / (b * 1.0)
numpy.save(f_handle, arr)
plt.contourf(data, cmap=cmap, levels=levs)
exist = cursor.fetchone()
lst.append(d)
logger = logging.getLogger(__name__)
[conv(val) for conv, val in zip(castings, line)]
dis.dis(make_adder)
[0.67008007, 0.65984005]
self.loop.run_forever()
p = Process(target=do_work, args=(work, results))
[i for i, j in enumerate(x[:-1], 1) if j != next(i_x)]
a = np.arange(size_a)[::-1]
modulename, ext = os.path.splitext(filename)
time.sleep(5)
newargs = newargs[2:]
app = QApplication(sys.argv)
timeout = 5
my_field = models.CharField()
nx, ny = np.array(ndata).T
out = np.split(C, np.flatnonzero(R[1:] > R[:-1]) + 1)
m = np.max(lens)
signal.signal(signal.SIGINT, self._handle_SIGINT)
[(c.name, c.get_items()) for c in forms[4].controls]
e == N or i > 0 and L[i - 1] == N or i < len(L) and L[i + 1] == N
self.obj = obj
row.Add(m_close, 0, wx.ALL, 10)
test(*args, **kwargs)
strings.sort()
d = {}
inputElement.send_keys(Keys.ENTER)
print(a, b, c)
f.close()
print(max_seq_len)
lookup.sub(lambda x: trans[x.group()], string)
self._table.append(self._dealer.nextCard())
changes.extend(valchange(d1[k], d2[k], k))
x.max(0)
rPM.restype = wintypes.BOOL
it = heapq.nlargest(20, enumerate(allrows), key=lambda x: x[1][2])
i += 1
print(list(reversed(astr.translate(deleter).split())))
handles, labels = ax.get_legend_handles_labels()
sum(1 for i in range(1000000) if str(i) == str(i)[::-1])
cal.events.add(event)
rsa = RSA.load_pub_key_bio(bio)
plt.plot(x, p)
d = dict(zip(a, b))
(1 + erf(x / sqrt(2))) / 2
oodict[line[0:7]] = line[12:]
process(chunk)
self.NEWATTRS = []
self.HTMLDATA = []
a = 2
np.concatenate(ar)
is_admin = models.NullBooleanField(default=False, blank=True, null=True)
parsed_args = parser.parse_args()
soup = BeautifulSoup(html)
av_max_dist = float(sum(max_distanace_list) / len(max_distanace_list))
sqrt = inverse(lambda x: x ** 2, lambda x: 2 * x)
y = [1, 2, 0, 1, 1, 2]
people = list(people_dict.values())
x[slice1][slice2]
c.sum() / c.size
decorator
min(i.number for i in iList)
MIGRATION_MODULES = DisableMigrations()
seen.add(line)
plt.axis([-50, 50, 0, 10000])
GetLogicalDrives.call()
print(f())
a.get_position().bounds
out_view[i] = in_view[i]
self.panel.SetSizer(sizer)
print(random_numbers(5, 100))
a.str
shutil.move(source, destination)
self.lock.release()
globals()[k] = my_decorator(v)
NULL
reader = csv.DictReader(StringIO(testdata))
output = json.load(sys.stdin)
random.seed(42)
help(png)
fields = list(fields)
files = [open(file, mode) for file in files]
self.load(buffer, size)
device.close()
iter([])
self.layout.add_widget(self.canvas_widget)
response = urllib.request.urlopen(req)
result = p.wait()
lines, labels = ax1.get_legend_handles_labels()
print((fully_qualified(f), f.location))
print(ted1(df))
y = scipy.signal.lfilter(h, 1.0, x)
print(i, elem)
multiprocessing.active_children()
web.input(**kwargs)
lines = []
a = numpy.zeros(lnum.bit_length() // 8 + 1, dtype=numpy.uint8)
True
mat1.append(temp)
func(*arg, **kwarg)
np.sum(v[r <= 10])
print(line)
use_setuptools()
print(np.real(roots[i]))
foo.b
a = Fraction(1, 2)
foo = Foo()
encoded = base64.b64encode(image_binary_data)
im = Image.fromarray(np.uint8(cm.gist_earth(myarray) * 255))
write_f.close()
next(iterator)
self.threads[i].start()
data = np.fromfile(file=fd, dtype=np.double).reshape(shape)
array[i, j] = 0
word1 in rhyme(word2, 1)
point(self.x + oth.x, self.y + oth.y)
app.exec_()
canv.pack()
ax.plot(list1)
l_result = [y for x, y in l_counts]
p[2] = q[2]
sums = data_in_group.sum(axis=1)
plt.show()
diam_out = np.maximum.reduceat(dists, shift_idx)
sorted(strings)
todatetime(endtime) - todatetime(starttime)
ax2.set_yticks(numpy.arange(y1 - 1, y2 + 1, 0.5))
[(0, 4), (22, 6)]
c = a.cumsum()
stdscr.keypad(0)
a = list(range(10))
result[length] = dict((k, v) for k, v in groups)
numpy.sin(value)
objects = CustomManager()
self.buffer.write(data)
df_asint = df.astype(int)
diff = zfit[:, :-1] - zfit[:, 1:]
sym_diff = [item for item in itertools.chain(a, b) if item not in intersec]
out = 100 * np.nansum((a[:, (R)] - a[:, (C)]) / a[:, (C)], 0)
myhost = os.uname()[1]
print(datetime.utcfromtimestamp(ts))
df
cursor.execute(query_string, query_args)
list(itertools.zip_longest(*uneven))
self.__getitem__(key)
seq2 = [1, 2, 4, 5, 6, 8, 9, 10]
[1, 2]
print(x)
imgBothH = np.hstack((a, b))
f1.flush()
axe.set_xticks((np.arange(0, 2 * n_ind, 2) + 1 / float(n_df + 1)) / 2.0)
q.put(ret)
main()
t.start()
dis.dis(foo.__code__.co_consts[1].co_consts[2])
tour
id = db.Column(db.Integer, primary_key=True)
map(lambda range: a[range[0]:range[1]], zip(start, end))
ch1.send(ch2)
t = np.arange(10)
set(first).intersection(*others)
first_dict = dict((ks[0], v) for v, ks in by_val)
pool.join()
file.seek(here, os.SEEK_SET)
sleep(0.1)
tokens = a.split()
dict(map(ascii_encode, pair) for pair in list(data.items()))
table.setColumnWidth(1, 80)
s.connect((HOST, PORT))
mask.shape
conn.begin()
query.split()
nk = set(a).intersection(b)
content = f.read()
pygame.quit()
resp.geturl()
p.map(processChunk, li)
time.sleep(1)
outfile = os.path.join(dir, name)
print(s)
wkspFldr = os.path.dirname(existGDBPath)
i = np.array(list(range(4))[::-1] * 6).reshape(a.shape)
df2 = df.loc[np.repeat(df.index.values, df.n)]
result = pd.DataFrame(names_and_values)
layout.save()
self._tunnel()
find_nearest_above(np.array([0.0, 1.0, 1.4, -2.0]), -1.5)
print((i, count_nicematrices(i, i)))
aux = matriz
x + 1
self.test = record_log(self.logs)(self.test)
self.inspector.hide()
child = os.fork()
foo = Foo(mock_helpers)
sys.exit(-1)
[1, 0, 0, 0, 0],
n_eq = A.shape[1]
f()
rsa = RSA.load_key_bio(bio)
clientSocket.send(msg.encode())
v[:] = v - 1
t = Team.objects.get(pk=168)
fig = plt.figure()
print(domain.group())
painter = QtGui.QStylePainter(self)
this.all()
aw2.but.clicked.connect(update_plot)
cb.move(20, 20)
Red = RGBint >> 16 & 255
print(tag.text)
qs = MyClass.objects.all()
map(lambda index: get_column(pyQueryRow, index), range(0, 12))
r.findall(x)
nindex, height, width, intensity = array.shape
doc = etree.fromstring(xml)
print(x[i])
p.tags.all()
concat_list = [j for i in ar for j in i]
p = [sum(p[:i]) for i in range(len(p))]
d = deepcopy(d)
any(x in MyDict for x in MyList)
cython < cython_file > --embed
print(line)
k, self.__dict__.pop(k, d)
sys.exit(app.exec_())
df.info()
data[0]
self.reporter.on_close(self.stats, {})
c = np.array([element for i, element in enumerate(a) if mask[i]])
xlock.release()
writer = csv.writer(ftmp)
cost_ij = train_model(data, target)
skel = np.uint8(skel)
ADDRESS1 = 15298676
tai_epoch_as_tai = datetime(1970, 1, 1, 0, 0, 10)
self.window.show()
vertical = [img[i, int(w / 2)] for i in range(h)]
first_digits[number]
a.get_x()
print(htmldiff(doc1, doc2))
FALSE = 0
result.update(mult_comb(tuple(factors2)))
parser = argparse.ArgumentParser()
QtCore.QRectF(0, 0, w, h)
df = pd.DataFrame(np.random.random((4, 4)))
plt.figure()
cls()
tostr(toval(s) + 1, minlen)
it.ifilter(lambda x: unique([b.c for b in x]), combos)
viewer.kill()
loop.run_forever()
b = mechanize.Browser(history=NoHistory())
_HEXDEC[triplet[0:2]], _HEXDEC[triplet[2:4]], _HEXDEC[triplet[4:6]]
fp.close()
rdd.filter(lambda line: line != header)
setup_envion(settings)
hessian(x)
base_subparser = argparse.ArgumentParser(add_help=False)
window = Tk()
cls.change_mro = True
output = po.communicate()[0]
r.url
bool(aware_dt.dst())
id = Column(Integer, primary_key=True)
pypi
print(dt.item())
s
form = QuestionForm(request.POST, instance=question)
stack.append([i])
day_list.index(inp)
client.close()
AC_PREREQ([2.69])
signal.signal(signal.SIGALRM, signal.SIG_IGN)
webbrowser.open(fetchUrl)
myOjbect.doStuf().doMoreStuf().goRed().goBlue().die()
all_messages.extend(rs)
application = config.make_wsgi_app()
print(0)
source.close()
pool.close()
data.sort()
img1 = cv2.imread(img1_path, cv2.CV_LOAD_IMAGE_GRAYSCALE)
str(timedelta(seconds=c.seconds))
hdu = fits.open(img)
output, err = p.communicate()
jsonify(results=d)
print(best1)
self.__output, self.__error = cmdp.communicate()
y = np.linspace(0, 2 * np.pi, 100).reshape(-1, 1)
data.update(data[vars].fillna(value=1))
print(repr(line))
texts = (x[1] for x in posts)
r.request.send(anyway=True)
a._log
exec(f.read(), globals(), locals())
duration(video_file_path)
cvtColor(src, gray, CV_BGR2GRAY)
df2 = pd.DataFrame(df)
df
HttpResponse(t.render(Context()))
main()
timeout.run()
profile = user.get_profile()
self.wfile.flush()
out_id = np.union1d(a[:, (0)], b[:, (0)])
np.PyArray_ITER_NEXT(ito)
t.start()
g(f(*a, **k))
print(s)
triplets[iT].append(listB[-1])
t * p / c
my_list.append(func)
print(df)
new_inlist.sort(key=lambda x: x.split(separator)[1])
root = logging.getLogger()
server.shutdown()
my_dict = {}
--Important
df
yourThread.cancel()
Testing(2 / 2)
B = [0, 0, 1, 1, 1, 1]
print(output_dict)
problem.main()
h1 = urllib.request.urlopen(req, timeout=10)
fig = plt.figure()
pd.Series(s.values[z], s.index.values[z], name=s.name)
my_pdf = gaussian_kde(osservazioni, 0.1)
C = np.array([[np.linalg.eigvals(m) for m in v] for v in B_blocks])
print(browser.page_source)
print(seq[1::2])
results = DataFrame(results, index=df.columns, columns=df.columns)
CELERYD_HIJACK_ROOT_LOGGER = False
stdout, stderr = p.communicate()
filename = sys.argv[2]
queue.put((tag, line), block=True, timeout=60)
csX.m = X.shape[0]
sorter = np.argsort(perm[::-1])
f.seek(start + 1)
self.de.setText(str(self.current))
f.close()
list(combinations(A, 2))
file_path = os.path.dirname(__file__)
type.__new__(cls, name, bases, dct)
wb = Workbook()
fig = plt.figure()
raise NotImplementedError
getcontext().prec = 100
next(g)
imp.load_source(name, path)
driver = webdriver.Firefox(firefox_profile=fp)
y = data[:, (1)]
server.sendmail(FROM, TO, message)
Py_DECREF(module_name)
cursor = cnx.cursor(named_tuple=True)
rank += permutation_rank(seq[1:]) if seq[1:] else 0
os.rmdir(dir)
print(a_list)
print(np.array(sums).shape)
mylist = ListField()
d[y].append(x)
data.append((batting[1], player, batting[0], batting[2]))
figure(figsize=(8, 8))
parser = argparse.ArgumentParser()
urlparse.parse_qs(urlparse.urlsplit(url).query)
str(self.name) == str(other.name)
treeview_column.set_widget(label)
my_list = flat(d)
numpy.array([x[xs], x[ys]]).T
topsize = pqueue[0][1]
logger.setLevel(logging.NOTSET)
plt.plot(np.arange(100))
ax1 = fig.add_subplot(1, 2, 2)
p = mp.Process(target=Simulation, args=(inqueue, output))
sub_strings = sorted(sub_strings, key=len, reverse=True)
canvas.restoreState()
plt.show()
ax.grid()
gpsgvqsbixtwyakpgefrhntldsjqlmfvyzwjoykhsapcmvjmar
p.terminate()
stdin.close()
opener = urllib.request.build_opener()
self.ClickedLB.move(200, 100)
win.idlok(True)
win.leaveok(True)
object._meta.verbose_name
ex = sys.exc_info()[1]
next(v for k, v in self.items() if x in k)
df.head()
L = [1, 2, 1, 1, 1]
self.process = QtCore.QProcess(self)
df
cardsdiscarded += 1
workbook = xlwt.Workbook()
df
t512.timeit()
p = subprocess.Popen(some_cmd, stdout=subprocess.PIPE)
print(buffer.getvalue())
scatter(X, Y, c=cycol())
page_source = browser.page_source
a = np.arange(100).reshape(10, 10)
ssc.awaitTermination()
f_out.writelines(f_in)
f.write(raw_img)
screen.refresh()
logfile.flush()
loop = asyncio.get_event_loop()
self.received_buffer.seek(0)
a = np.arange(2000).reshape(20, 100)
DEBUG = True
json_output
x = dict(a=1, b=2)
plt.contour(y, x, T[:, :, (round(len(z) / 2))], 64)
self
reader = csv.reader(data)
ui.show()
type(a)
sys.stdout.flush()
csr_matrix = coo_matrix.tocsr()
b_data = binascii.unhexlify(data)
m.show()
widget.show()
signal.alarm(0)
self.get_sub_instance().get_individual()
gevent.monkey.patch_socket()
single_tokens = [k for k, v in Counter(tokens).items() if v == 1]
self.wfile.write(pymjpeg.boundary)
new_bar.update(extra)
set(Ol[:l])
myseries_two.iloc[0]
[ss[i:i + 6] for i in range(0, len(s) - 1, 6)]
HttpResponse()
map(str, a)
xs = [xs[i] for i in sorted_index]
math.floor(f * 10 ** n) / 10 ** n
os.close(fd)
print(keywordlist)
self.setFormatter(formatter)
GetWindowTextW(hwnd, win_name, win_len + 1)
y = [(k, v) for v, k in list(d.items())]
views.py
heapq.heappush(heap, (-p2, x, y - 1))
print(isPower(10, 1))
root = Tk()
b = np.empty(a.shape)
self.root.remove(child)
query_params = parse_qs(query_string)
Af = A.flatten()
print(local_tz.localize(datetime(2000, 1, 15)))
self.data[key] = NotifyList(item, self, str(key))
app = Flask(__name__)
app.ActiveDocument.Close(SaveChanges=True)
pubkey.verify_update(message)
np.random.shuffle(x)
time.gmtime(year_ago * 1000)
pprint(service)
file.truncate(0)
gs - q - dQUIET - dPARANOIDSAFER - dBATCH - dNOPAUSE - dNOPROMPT
math.acos(inner_product / (len1 * len2))
factors[i] += 1
Lt - -titlecase
Lm - -modifier
crawler.start()
bins = np.linspace(0, 1, nbins + 1)
print(mse(model_1.predict(xg_test), y_test))
Gtk.ScrolledWindow
work.start()
pl.xticks(np.linspace(0.0, 100.0, 11, endpoint=True))
test_1_12_example_name.py
np.sum(n * np.diff(bins))
self.file_saving.child.join()
decorator
x = time.time()
xlApp.Quit()
cursor.execute(query_str)
time.sort()
MY_CONSTANT = 50
np.put(x, y, 1)
handler404 = NotFoundView.get_rendered_view()
self.ui.PoseBtn_GridLayout.addItem(spacerItem, 1, 1, 1, 1)
len(self.__dict__)
x1 = np.hstack([[False], x, [False]])
ax.set_yticklabels(ax.get_yticks(), fontproperties=font)
app = Flask(__name__)
d[i] += 1
print(list(c.items()))
self._x
lambda *args, **kw: self.method(cls, *args, **kw)
signal.signal(signal.SIGTERM, cleanup)
self.failureResultOf(self.o.failure(), ConnectionRefusedError)
df.query(query_expr)
f(n) / f(r) / f(n - r)
df.rolling(n).sum()[-1::-k][::-1]
grouped.get_group(True)
ax.plot(x, y)
test_data = [str(x) for x in range(20)]
city = models.CharField(max_length=50)
frame = DataFrame(list_of_dicts)
pd.options.display.max_colwidth = 100
print(get_drive_size(0))
self.threads.append(self.makeThread(particles[i]))
self[key] = value
[]
plot_confusion_matrix(df_confusion)
{tree_list[0]: build_tree(tree_list[1:])}
boxplot(list(mydict.values()), labels=list(mydict.keys()))
df
ids = [row[0] for row in cursor.fetchall()]
index.tpl
ans = np.mgrid[0:1:100j, 0:1:100j, 0:1:100j]
raise TypeError
my_model.MyClassName
np.random.shuffle(rows)
getcontext().prec = 60
a = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
plt.legend(flip(handles, 2), flip(labels, 2), loc=9, ncol=2)
print(a[0, 2])
a[2](), b[2](), c[2]()
Complete = np.where(np.isnan(partial), replace, partial)
edges[i, j - 2].append((i, j + 2))
print(response.text)
a[1:, :-1]
b = random.sample(a, len(a))
fig, ax = plt.subplots()
a = numpy.arange(1, 21).reshape(4, 5)
gryim = np.mean(im[:, :, 0:2], 2)
mystring = repr(myvariable)
(a[2], b[2]),
math.log(x)
sorted_a = np.diagonal(a[:, (idx[:])]).T
c = socket(AF_INET, SOCK_STREAM)
gradient.setColorAt(0, QColor(255, 255, 255, 127))
print(line)
fig = plt.figure()
(time.astype(np.int64) / 1000000.0).astype(np.int64)
contents = output.getvalue()
keys = set(dol1).union(dol2)
result = result()
min(list_date, key=func)
resultList[-1].append(item)
iterables = [iter(it) for it in lists]
soup = BeautifulSoup(data)
time.sleep(1)
a.__dict__
q.task_done()
rec(tf2, rest_paths[1:])
palette.append((i, 0, 0))
model = Sequential()
print(r.text)
bins = np.arange(min_bin, max_bin + 1)
sock.send(chunk)
self.assertEqual(0, len(message))
type.__new__(metacls, name, bases, dct)
fig = plt.figure()
print(data)
exit()
cause = []
a = np.random.randint(0, 200, 100)
getattr(self.m, n)
self.update(*args, **kwargs)
mask = (1 << bitlen) - 1
vector2 = [element for i, element in enumerate(vector) if i not in to_exclude]
print(a)
width, height = img.size
print(intlist(10))
df = df[::-1].fillna(0).cumsum()[::-1]
beta = np.linalg.inv(X.T.dot(X)).dot(X.T.dot(y))
x, y = sat(81.299, 0, radians=False, errcheck=True)
pylab.show()
reader = csv.DictReader(fin, fieldnames=fields)
[Arthur]
df
f.close()
shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)
self.reverser[mo.group()]
streamHandler = logging.StreamHandler()
child.grab_focus()
api = tweepy.API(auth)
X00X
print(type(x).__new__(x.__class__))
fig, ax = pl.subplots(nrows=2)
data = ECD.read()
duck.walk()
pylab.xlim(0, 5000)
[(j, is_even(j)) for j in range(10)]
ser.readline()
-deadsnakes
np.column_stack((a, a, a))
print((i, max(dict[i])))
isect.append([val, 0])
soup = BeautifulSoup(html)
data = sorted(data, key=keyfunc)
f(20)
type(ids)
self.loop.call_soon_threadsafe(task.cancel)
self.ftp_h.cwd(path)
numpy.corrcoef(data)
Departure_Date.objects.extra(where=[where])
frame1.axes.get_xaxis().set_visible(False)
evil_vals = [Evil(n) for n in range(10)]
the_url = response.geturl()
new_list = []
m.shape
self.transport.setTcpKeepAlive(1)
sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)
arr = np.array([])
outdata = (ctypes.POINTER(ctypes.c_double) * 5)()
nx.draw(X, pos)
c.execute(query, keys)
view.setRenderHint(QPainter.Antialiasing)
r.append(blocktag[0])
img_data_cvmat = cv.fromarray(img_data_ndarray)
df1 = pd.concat([df1, pd.DataFrame(columns=list(range(8)))])
pygame.display.update()
vars(module).update(globals())
xs = np.random.randn(n).cumsum()
self.dx = dx
out.append(line)
label.pack()
----models.py
json.dumps(a)
aa = json.loads(j, object_hook=AttrDict)
print(nth(lucky(), 100))
nx.draw_networkx_edges(G_pc, pos, alpha=0.01)
req = urllib.request.Request(url)
res2 = cv2.cvtColor(res, cv2.COLOR_GRAY2BGR)
b[unified_mask[(np.newaxis), ...]] = 0.0
popt, pcov = curve_fit(gaus, x, y, p0=[1, mean, sigma])
self._notify()
cv2.normalize(hist_item, hist_item, 0, 255, cv2.NORM_MINMAX)
points = [(2, 2), (4, 4), (7, 7), (8, 8)]
board.append([])
allocate(y(j))
out = np.zeros(np.asarray(shp) * len(L), dtype=int)
Gtk.main()
print(a)
print(a)
self.createWidgets()
s.ioctl(socket.SIO_RCVALL, socket.RCVALL_OFF)
dd = {k: v for k, v in list(dd.items()) if len(v) > 1}
f()
subprocess.Popen(args, shell=True)
df = MyDF(*args, **kw)
self.name = name
os._exit(code)
n, ext = os.path.splitext(f)
timings.append((result, fname))
seen.insert(i, x)
list(f.values())
self.s = str(*args, **kwargs)
t.start()
access = imdb.IMDb()
df = df.sort()
allspiders.append(makespider(domain, urls))
print(len(s))
doSomething(b)
gray = cv2.threshold(gray, 4, 255, cv2.THRESH_BINARY)[1]
f.bar()
x * 2
minor = numpy.zeros(shape=(len(A) - 1, len(A) - 1))
_y = -x * math.sin(t) + y * math.cos(t)
plotter2.binding_plotter_with_ui()
id = db.Column(db.Integer, primary_key=True)
print(guess_seq_len(list(range(500))))
spelling_dict.get(word, word)
data[index] = new_list
p = Process(target=f)
threading.Thread.join(self)
print(rechunk(ner_output))
plt.figure()
rect = np.array([[bx1, by1], [bx1, by2], [bx2, by2], [bx2, by1], [bx1, by1]])
self._queue.get(False)
print(fexprefix)
names = [row[0] for row in cursor.fetchall()]
lst = [pd.DataFrame(), pd.DataFrame(), pd.DataFrame()]
ax = plt.gca()
b = [a, a]
setattr(namespace, self.dest, values)
stdout, stderr = proc.communicate()
cam = cv2.VideoCapture(0)
ar[:-sum(1 for i in takewhile(lambda x: x, reversed(ar)))]
average = scipy.signal.convolve2d(matriz, kernel)
r = csv.reader(open(filename))
list_of_variables = tf.all_variables()
b = a[1:]
fcond.notify_all()
parent2 = argparse.ArgumentParser(add_help=False)
_int(istart + _int(self.random() * width))
self.flag = False
pool.append(p)
self.name = name
atexit.register(cleanup)
wn.lch_similarity(dog, cat)
conn = pycurl.Curl()
Variance(X).doit(evaluate=False)
-W900
self._cards.append(card)
line = gca().get_lines()[n]
distance_between_points = math.sqrt(dx ** 2 + dy ** 2)
deleteself.Ans[-1]
self.a = 0
etree.ElementTree._write(self, file, node, encoding, namespaces)
len(msg.get_payload())
args = parser.parse_args()
sys.stdin = sys.stdout = sys.stderr = self.desc
values.append([v, [k]])
outf.close()
zip_longest(fillvalue=fillvalue, *args)
array[values] = list(r.values())
plt.plot(Vecpoints, np.exp(logkde))
w, x, y, z
u = np.sin(np.pi * x) * np.cos(np.pi * y) * np.cos(np.pi * z)
print(filename)
linsolve(system, x, y, z)
print(msg.subject, msg.id)
decoded_data = json.loads(encoded_str)
dummy_df = pd.get_dummies(df[column])
tokens = [_f for _f in map(myfilter, tokens) if _f]
the_output = p.stdout.read()
a.isalpha(), b.isalpha()
client = paramiko.SSHClient()
self.my_attr == other.my_attr
author = models.ForeignKey(Author)
tempList.append(rowDict)
pl.figure()
fig, ax = plt.subplots()
data = json.load(data_file)
[action_to_apply(row) for row in X]
Exception.__init__(self, *args, **kwargs)
input_file = open(args[0])
name = db.StringProperty()
do_something(weapons)
turtle.right(angle)
out[product_name].append((bike_number, list_of_parts))
print(cmd())
f(1)
dt + datetime.timedelta(microseconds=us)
root = Tk()
subprocess.call(cmd, stdin=sin, stdout=sout, startupinfo=startupinfo)
format(theList)
axs[i].scatter(pts[i][:, (0)], pts[i][:, (1)], c=colors[lbls])
[sum(1 for _ in group) for key, group in itertools.groupby(condition) if key]
np.putmask(arr, arr >= T, 255.0)
log.addHandler(console_handler)
triples += ((i, j, k) for k in K[K > i])
of.close()
Tk().withdraw()
callback(*args, **kwds)
a = 1 if i < 100 else 2 if i > 100 else 0
dllname = os.path.split(self._welu.__file__)
cv2.imshow(img)
st.issuperset(b[1])
instance = form.save(commit=False)
self.__dict__[key]
setones_between_triggers(A, 2, -2)
f = lambda r: sp.j1(r) ** 2 / r
sys.stdout = sys.__stdout__
[1]
cap.open()
Z2 = mlab.bivariate_normal(X, Y, 1.5, 0.5, 1, 1)
np.random.seed(seed)
{r[key] for key in r if 42 in key}
reg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)
self.after(100, self.poll_serial_port)
self.co.send(*args)
x = collections.Counter(l)
Xfit = np.hstack(((-1, -1, 0, 1, 1), np.arange(1, 10), (-7, 9, 10, 10)))
send_from_directory(UPLOAD_FOLDER, filename)
rescaled = np.mean(rescaled, axis=ind + 1)
do_something(my_object)
[0, 0, 0, 100]
grandchild_pid = int(os.fdopen(r).readline().strip())
xyi = np.vstack((x, y)).T
result.save(sys.argv[2])
l = [4, 5, 6]
sortedwords = sorted(iter(wordbank.items()), key=operator.itemgetter(1))
self.count += 1
doc = le.parse(f)
self.value = 1
sys.modules[__name__] = _MyClass.instance
handle_error()
fig = plt.figure(figsize=[7, 5])
print(v)
cursor = cnx.cursor()
g.ax_marg_y.set_axis_off()
self.feed += 1
print(data)
last_name = models.CharField(max_length=50)
sleep(1)
message, settings.SERVER_EMAIL, [a[1] for a in settings.MANAGERS]
retval
frame.Show()
center = int(x), int(y)
{NULL, NULL, 0, NULL}
self.adjective_count[a] += 1
bindices_zero = array == 0
print(post.text)
res[v].append(k)
results = [result_queue.get() for mc in montecarlos]
my_date = date.today() - timedelta(days=days_to_subtract)
even_numbers = [y for x, y in enumerate(items) if x % 2 == 0]
self._connection.close()
perfect_fit = 60 * numpy.random.normal(size=(n_inputs, n_outputs))
img = mahotas.imread(imname)
print((data, data.GetType()))
fig, ax = plt.subplots()
print(max_dir, max_file)
arr = np.arange(16).reshape(4, 4)
fig = plt.figure()
u[np.argsort(ind)]
z = request.GET.copy()
a[..., (0)] + a[..., (1)]
a_1d = a.flatten()
sortedA = A[np.lexsort(A[:, :-1].T)]
subprocess.call(cmd, shell=False)
jj = np.where(ii)[0]
redirect(success_url)
assert data_tensor.size(0) == target_tensor.size(0)
numpy.finfo(numpy.float64).min
s = s.append(b, ignore_index=True)
p = Pool(number_of_processes)
keypoints = s.detect(gray, mask)
name = models.CharField(max_length=100)
rand2.seed(0)
DerivedClass().do_it()
some_list = []
line = file.readline()
[1.0, 0.0, 0.0, 1.0, 0.0, 0.0],
n &= n - 1
[G.edges(subgraph) for subgraph in subgraphs]
os.close(fi)
session_crumbs.append((flask.request.path, view_title))
palette.setColor(palette.Dark, QtGui.QColor(0, 255, 0))
self.response.out.write(images.image)
V = numpy.sum(xdist, axis=1)
new_col = NP.zeros_like(my_data[:, (-1)]).reshape(-1, 1)
result.extend(s)
np.count_nonzero(x != y)
a._A__foo()
cython.int
self._x = value
foo.MyClass()
daemon_cartman.join()
print(df1.equals(df))
J = sparse.coo_matrix((np.ones_like(ixs, int), (np.arange(ixs.shape[0]), ixs)))
z.nonzero()
d = json.load(json_data)
self.listbox.insert(0, option)
stdout.write(str(i))
a = b[:]
db.session.add(sg)
rounding_swig / testrounding.cpp
pool = multiprocessing.Pool(5)
django.db.connection.user = user
lambda x: bool(int(x))
func(self)
cols.append(col)
connection.close()
commons = set(dict1).intersection(set(dict2))
doTaskB()
ax2 = ax.twinx()
print(twodarray.shape)
type((100,))
self.dbobject = all()
hash(b)
second_largest([2, 2, 2, 2, 2, 1])
list(my_mapping.keys())
pygame.display.update()
print(f.__code__.co_consts)
mock_http_client.get.assert_called_with(url)
os.path.isfile(os.path.join(*path_segments))
bottom.paste(top, (0, 0), mask)
print(a, b, c, d)
np.concatenate([a[offset:offset + length] for offset, length in offset_length])
canvas.saveState()
unseenData_predictions = recreatedModel.predict(X_test_std)
map_nested_dicts_modify(x, lambda v: v + 7)
threads[i].start()
f.seek(0)
the_page = response.read()
df = df.transpose()
print(np.dot(rotation_matrix(axis, theta), v))
mydict[str(key)] = mydict[key]
print(concatd(a, b, c))
tree = lxml.etree.XML(DOC)
v[(-1), :-1] / -v[-1, -1]
self.fields.update(form.fields)
self.dict[self.last]
positive2 = positive[:, 2:-1]
func.__code__.co_varnames
num_ratings = db.IntegerProperty()
client.disconnect()
B = np.random.random((10, 4))
f
ax.yaxis.set_major_formatter(mtick.PercentFormatter())
stdin_list = list(sys.stdin)
hash2 = hashlib.md5()
elements.append(itertools.repeat(iter))
c = df.columns.values
f = os.path.join(dirName, f)
themin, themax
i += 1
gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
self.assertEqual(4, myObj.getDataLength())
a[inds[:, (0)], inds[:, (1)]]
[d1[key] for key in set(d1) - set(d2)]
debug = 1
print(r.cookies)
x = mydict[k]
print(i)
my_saved_data
neighbours = list(itertools.product(list(range(i - 1, i + 2)), list(range(j - 1, j + 2))))
maze_dict = {}
df.dt = pd.to_datetime(df.dt)
ax = fig.add_axes([0.1, 0.2, 0.85, 0.7])
logutils.set_up()
img = np.zeros(Arr.shape, dtype=bool)
print(sum(sub == s[i:i + ln] for i in range(len(s) - (ln - 1))))
{k: (v - 1) for k, v in list(c.items())}
new_im = f(new_x).T
a.many_b.add(*list_of_b)
file.flush()
df
bbox = self.legend.get_window_extent()
s.bind((MY_ADDRESS, port))
argparse.ArgumentParser.add_argument(self, *args, **kwargs)
inputproc0 = Popen(shlex.split(inputcmd0), stdout=PIPE)
df1.join(df2).columns
pairs.append(new_pair)
req = urllib.request.Request(url, urllib.parse.urlencode(params))
regex = re.compile(re.escape(old), re.I)
mod1.py
fileWriter.writerow(row)
self.html = self.mainFrame().toHtml()
im = ImageOps.invert(im)
collections.OrderedDict.fromkeys(x for x in a if x not in b)
df1 = df.groupby([a, b]).count()
my_string = my_string.lower().split()
F(1, 2)
imarr = numpy.array(Image.open(im), dtype=numpy.float)
driver = webdriver.Firefox()
wb.save(out)
xmax, ymax = a.max(axis=0)
chunk.append(line)
deployFiles()
tree = BeautifulSoup(bad_html)
logger = logging.getLogger()
b = np.random.random_integers(2, size=(4, 4))
serie = pd.to_datetime(df.dt)
np.irr(np.r_[-n, cashflow])
conn = http.client.HTTPSConnection(myDestination)
response = urllib.request.urlopen(request)
self.allowed_domains.append(hostname)
psutil.cpu_count()
Function(lambda x: self(x) / other)
alldata = np.array(zip(t, zip(x, y)), dtype=dt)
sum(sum(i) == 100 for i in itertools.product(range(100), repeat=100))
timeit((df == df2) | (df != df) & (df2 != df2)).values.all()
assert isinstance(x, list)
smtp = smtplib.SMTP(smtp_host, smtp_port)
worksheet.set_column(i, i, header_len)
pprint.pprint(sys.path)
fig, ax = plt.subplots()
sizer.Add(lbl, 0, wx.ALL, 5)
seen.add(char)
sys.exit(a.exec_())
usage()
gen_random_decimal(99999999999, 999999999999)
chBuf = create_string_buffer(BUFSIZE)
a.append(dict(b))
B = defaultdict(lambda : defaultdict(int))
gameMap[0:2, 0:2] += piece
fig = plt.figure()
random.sample(xs, sample_size)
time.sleep(-time.time() % 1)
print(type(lengthy_thingy).__len__(lengthy_thingy))
file.close()
self.photo.load()
es_logger.setLevel(logging.INFO)
dis.dis(foo)
result.append(string)
result = df.loc[df_mask]
dbConn.close()
powLF(n)[1]
df_with_x4.show()
country = models.ForeignKey(Country)
clf.fit(train[cols], train.targets)
os.path.relpath(google.__file__, here),
print(myString[0])
worksheet2 = workbook.add_worksheet()
D = dict((k, v) for v, k in enumerate(albums_yesterday))
notebook.set_tab_reorderable(child, False)
z.extractall()
client_socket.close()
d = {}
session.commit()
decorated_func
d2_filtered = dict((k, v) for k, v in d2.items() if k not in ignore_keys)
request = urllib.request.Request(url)
L = list(reversed(list(range(100))))
self.cost += tf.reduce_mean((x_train - y_train) ** 2)
parser.exit()
invalid = np.isnan(data)
X = scale(X, axis=0, with_mean=True, with_std=True, copy=True)
numpy.dot(A_col0_sorted, perfect_fit)[:, (0)],
angle = atan((neuron2.x - neuron1.x) / float(neuron2.y - neuron1.y))
plt.plot(np.arange(10) * (i + 1))
self.columnconfigure(0, weight=1)
result.append(word)
A = pd.Series(list(range(10)))
signal_axes.plot(xs, rawsignal)
1, 2
csv_writer = csv.writer(csv_file)
cursor.execute(statement)
c = a
decoded_pw = base64.b64decode(encoded_pw)
results.append(obj)
my_i, my_card = select_choice()
y = mlab.normpdf(bins, mu, sigma)
Py_DECREF(initresult)
self._alpha(context) * self._backoff.prob(word, context[1:])
rep_shape(a, (4, 2))
new_data = data[np.in1d(arr1, arr2)]
x.extend(y)
name = models.CharField(max_length=25)
A = np.array([5, np.nan, np.nan, np.nan, np.nan, 10])
nw[0] = nw[0] + 1
currentdate = dt.date.today()
f.close()
df = df.sortlevel(0)
a[a < 0] = 0
p = np.empty((n, 2))
match.start()
setattr(TestSequense, test_name, test)
image[coordinates] = 1
canvas.delete(ALL)
str(Fraction(0.25))
cv2.circle(out, (int(x1), int(y1)), 4, (255, 0, 0), 1)
message = Column(String(2000), nullable=False)
data = urlencode(values)
plt.imshow(im.T, cmap=cmap, extent=xr + yr)
p = pyaudio.PyAudio()
df.Date = pd.to_datetime(df.Date)
cols = np.arange(len(df.columns))
m()
{{language.name_local}}
decoder.end_utt()
print(df)
count(1)
f = figure(figsize=(6, 6))
fig = plt.figure()
index[count][1].append(url)
m = hashlib.md5()
fig, (ax1, ax2) = plt.subplots(1, 2)
map(tdgi, list(filter(tdin, theList)))
data_json = json.dumps(data)
loop.run_until_complete(do_work(q))
50 + sum(x * next(cyc) for x in lis[0])
events = events.exclude(eventitem__isnull=True)
asyncio.set_event_loop(self.loop)
colors.insert(index, mean_color([colors[index - 1], colors[index]]))
ax = plt.gca()
ax = plt.gca()
print(tree.find(10))
event_date = models.DateField()
print(x)
string.lowercase[:14:2]
func(*args, **kwargs)
{k: dd[k] for k in list(dd.keys())[:10]}
array2[:] = array1
np.random.seed(1977)
self.causes[node.name] += self.extract_cause(b)
aux = copy.deepcopy(matriz)
[c.send(val) for val in generator1()]
sys.exit(1)
root = Tk()
f.write(templateString.format(**d))
sum(1 if i == j else 0 for i, j in zip(w1, w2)) / float(len(w1))
q = Queue()
f.__code__ is creator.__code__.co_consts[1]
root = etree.fromstring(s)
np.random.seed(seed)
heavy_computation(X, param_1, param_2, arg)
ax.set_xlim([0, 5])
output.append(line)
dcos = np.arccos(np.clip((dp[:, 1:] * dp[:, :-1]).sum(axis=0), -1, 1))
upper_match = match.group(0).upper()
page = urllib.request.urlopen(url)
df
self._log(text)
model = models.MyModel
rng.random()
pixel_value += polygon_shape.intersection(pixel_shape).area * value
deleteTrue
models.py
c = cdll.LoadLibrary(LIBRARY_NAME)
h[x] = h.pop(x, []).append(y)
msg = msg[:-2]
unittest.main()
mapper(tableClass, table)
proc = subprocess.Popen(cmd, shell=True)
i == len(B) or B[i] != a
df[df > df.quantile(0.8)].dropna()
response = self.opener.open(url, data)
b = Test()
self._s.bind((host_address, port))
a.write(f, relpath(f, root))
id = db.Column(db.Integer, primary_key=True)
plt.show()
tuple(p.stdout.fileno() for p in processes)
self.__doc__ = callable.__doc__
input()
object.__ne__(self, other)
int()
print(groups.mean().b)
path = os.path.join(folder, filename)
s = pd.Series(list(range(10)))
getattr(self.get_query_set(), name)
output.write(outputStream)
cs = plt.contour(x, y, vel, levels)
deletemydict[key1]
client_socket.connect((server_address, port))
self.worker.measure_msg.connect(self.showRslt)
f = expr(f)
j = ((x - x0) / dx).astype(int)
a[0:4]
conn.autocommit(True)
created_at = models.DateTimeField(auto_now_add=True)
block.move()
a = numpy.array([[0, 0], [0, 1], [1, 0], [1, 1]])
foo = input()
text.insert(END, output)
parts[0].strip(), int(parts[1])
frob(self.b)
float(s)
df2[ser1.name] = ser1
proc.stdin.write(c)
0.550000000001
result.append(nopreds)
a.a().method()
wx.PostEvent(self, event)
sum(x is False for x in arr)
ax = plt.axes()
df1
cPickle.dump(d, out)
property_bsel = [property_b[i] for i in good_indices]
sum(sorted(dice)[1:])
dt = datetime.datetime.now()
nopreds = [-1] * n
os.dup2(se.fileno(), sys.stderr.fileno())
ser.write(byte_signal)
np.array(y.shape).tofile(f)
row = wx.BoxSizer(wx.HORIZONTAL)
Request(url, dont_filter=True)
protocol = QNetworkProxy.Socks5Proxy
print(lda.print_topic(i))
random.random() * 5 + 10
self.tvcolumn1.set_cell_data_func(self.toggle, self.set_status)
print(np.in1d(values, data))
os.execv(sys.executable, sys.argv)
user = models.OneToOneField(User, parent_link=True, blank=True, null=True)
b = a[names]
print(x, y)
print(eval(code))
rep_shape(a, (5, 8))
help(ttk.Notebook)
cr.set_source_rgb(1, 1, 0)
__init__.py(empty)
pl.colorbar()
form = UserCreationForm(request.POST)
a[i] = f(v)
Py_Initialize()
wynik[i] += 1
synset2domains = defaultdict(list)
_x = x * math.cos(t) + y * math.sin(t)
self.panel.show()
print(id(argv[0]))
df
mydates = pd.date_range(date1, date2).tolist()
textbox = Text(mainwin, width=40, height=10)
x = mystuff()
print(rem == [0, 1, 2, 1, 0])
self.assertEqual(1 + 1, 2)
d2.update(d1)
logger = logging.getLogger(__name__)
plt.axes().yaxis.set_minor_locator(ml)
d = collections.defaultdict(set)
ctypes.c_int,
r.findall(s2)
keys = set(chain(*[list(d.keys()) for d in dicts]))
plt.show()
NECESSARY = 2
rel.save()
print(x[ind], y[ind], z[ind])
out = np.zeros(dims, dtype=int)
matrix.append(list(vals[x * size:x * size + size]))
b = np.array([[5, 6], [7, 8]])
cur = con.cursor()
callback(args[0])
c.diff().fillna(math.max(0, values[0] - ALLOWANCE))
lst1[0:1] + interleave(lst2, lst1[1:])
FILE = open(filename)
[1, 1, 0]
b = np.concatenate([[0], np.where(a[:-1] != a[1:])[0] + 1, [n]])
Bar.bar()
a[-2:] = [0, 4]
stateA()
screen = pygame.display.set_mode((SCREEN_X, SCREEN_Y))
self.data = dict(*args, **kwargs)
a.f()
soup = bs4.BeautifulSoup(html)
hSplitter.SetSashGravity(0.5)
a.sort(key=Vector.__key__)
1, [True, True, False, False]
egg2(a, b)
sorted([x for x in p if x < limit])
main_loop.start()
r = requests.post(url, files=files)
df.head()
print(len(puppies.getdata()))
server.login(USERNAME, PASSWORD)
a.add_child(a)
next(c)
flat = [[(k, v) for v in vs] for k, vs in list(kwargs.items())]
print(df1)
groupby(a, [0])
t = name,
user_func()
workbook = load_workbook(filename, use_iterators=True)
lst = [1, 5, 4]
nopreds = set()
logging.exception(e)
stext.mainloop()
ax.set_ylim([-4, 4])
self.login(response)
etree.fromstring(f.read(), xmlparser)
dall.update(d2)
formatter = logfileformatter
worksheet.column_dimensions[column_cells[0].column].width = length
x
G_LOG = logging.getLogger(__name__)
dictionary.setdefault(x, []).append(y)
print(driver.title)
f.get_prep_value(d.numbers)
qproc.start()
Foo.newmethod = newmethod
list(chain.from_iterable(zip(l[:-1], repeat(0)))) + l[-1:]
closest_point_coords = list(p.coords)[0]
time.sleep(secs)
Job.objects.get(client__id=1)
otherfunc()
help(dict)
print(line)
foo, boo, moo = boo[0], moo[0], foo[0] = moo[0], foo[0], boo[0] = [0], [0], [0]
a.__str__()
caption = models.CharField(max_length=64, blank=True)
button1.configure(command=lambda widget=button1: DoSomething(widget))
handler2 = logging.TimedRotatingFileHandler()
s.capitalize()
start = tk.Tk()
myThread.daemon = True
self.buf.seek(0)
my_list = list(range(10, 17))
frame.Show()
pl.show()
pool.close()
main = tk.Tk()
yaml.dump(self.object, file)
dectheclass
self._protected()
ax.scatter(x, y, label=l, s=50, linewidth=0.1, c=c)
main()
db.foo.c.requires = IS_NOT_EMPTY_IF_OTHER(request.vars.b)
print(k, curve, [angle(p1, p2) for p1, p2 in zip(curve, curve[1:])])
len([is_true for is_true, _ in groupby(a, lambda x: x != 0) if is_true])
print(p.pid)
db.get_conn().ping(True)
cmp(self.s[x + l], self.s[y + l])
750069.25, 750069.25
application = app
self.module = locals
ordered_ips_data_dict = OrderedDict(ordered_items)
print(m.groups())
type(counts_df)
f.close()
heapify(A)
print(data)
tf.close()
logger.addHandler(fileHandler)
math.log(math.exp(logA) + math.exp(logB))
result = func(*args)
doc = fromstring(html)
p[1]
attribute(*args, **kwargs)
ns = parser.parse_args()
print(i, get_hotp_token(secret, intervals_no=i))
repr(self.i)
sys.exit()
names = pd.DataFrame()
print(client.fetchAll())
foo().y
usd_curr = [x for x in temp if x > 0]
k = a[0:2]
br.submit()
print(df.values)
X = R * np.cos(THETA) + 5
-cmp(self.x, other.x)
allocate(fullData(nR, nC))
main.py
math.isnan(item)
n1.add(n12)
Person.__init__(self, name, phone)
arr.reshape(h // nrows, -1, nrows, ncols).swapaxes(1, 2).reshape(h, w)
app = wx.PySimpleApp()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
list(a)
s = sorted(s)
max_idx, max_val
figure()
dividers = sorted(random.sample(range(1, total), n - 1))
restype = ctypes.c_int
self.write(repr(self.request))
names = names.append(frame, ignore_index=True)
words.append(word)
final_l
result += letters[index - shift]
result = df.copy()
tk.Frame.__init__(self, root, *args, **kwargs)
print(line)
self.text = tk.Text(self, height=10, width=40)
os.dup2(t.fileno(), self.fd)
order = np.argsort(x)
d1 = datetime.date.today()
b = np.random.rand(5, 6)
bokeh.plotting.curplot().plot_width = 800
logging.basicConfig(level=logging.INFO)
print(x.reshape((x.shape[0], 1)).type)
print(self.obj.f1(2))
D = ((a - v[i]) ** 2).sum(axis=-1)
plt.xlim([0.0, 9.0])
self.level = logging.DEBUG
cursor.execute(query)
len(a)
ax = fig.add_subplot(111)
table.insert_data(simple_dataframe)
delete_keys_from_dict(v, the_keys)
time.sleep(1)
pool = mp.Pool(NPROCESSES)
count += 1
f = a[0:1]
D = spatial.distance.pdist(A, lambda u, v: getDistanceByHaversine(u, v))
user.set_password(password)
zf._writecheck(zinfo)
DTYPE = np.int
bagel
stdout, stderr = proc.communicate()
images[idx].shape
row, column = map(int, line)
display.display(plt.gcf())
print(list((b - a).elements()))
np.linalg.norm(a * c - b)
test_set[i] = flatten_image(matrix_image(test_images[i]))
x[words[0]].append(words[1])
print(cpy_list)
path.split(os.sep)
new_path = list(path)
self.inner_test = inner_test()
print(regressor.predict(X))
ax = fig.add_subplot(111)
print(sys.path)
print(a_list.sort())
output.close()
a = np.arange(10)
next(reader)
print(dir(module))
print(x)
string.whitespace
request.user == obj
arr[i] = 0
app.MainLoop()
self.geodata_image.blit(0, 0, 0)
snake.foo()
filenames = ftp.nlst()
Frame = Frame.append(pandas.DataFrame(data=SomeNewLineOfData))
self.f = Foo()
outfp.close()
a[b]
ca_one = str(sys.argv[1])
two_array.append(6)
i_xy = np.intersect1d(u_x, u_y, assume_unique=True)
print(applyParallel(df.groupby(df.index), tmpFunc))
self.label = QtGui.QLabel(self)
words = set(f)
edges.add((left, right))
len2 = max(len(el) for el in list(chain(*my_list)))
syncdict = {}
self.get_user_from_cookie()
self.q_in.delete_message(self._current_message)
stop_event = threading.Event()
api = tweepy.API(auth)
next_n_lines = list(islice(f, n))
outputlist.append(current)
self.release()
result = func(*args, **kwargs)
yourdict = pickle.loads(read_dict)
min(chain(l_one, l_two))
doc.build(text)
self.stopFunc()
d.extend(g)
matches.append(x)
low_primes = {x for x in range(1, 100) if is_prime(x)}
intp, fracp = divmod(val, 10 ** prec)
files.append(d)
my_dict = defaultdict(list)
list(Foo.__dict__.keys())
B = np.array([2, 4, 6])
mexico_time = datetime.datetime(2010, 1, 1, 12, 0, 0, 0, tz_mexico)
server.shutdown()
self._data = data
opener = urllib.request.build_opener(ValidHTTPSHandler)
session.expunge(i0)
action.perform()
cur.close()
resultList.append([item])
df
self.model.query.filter(self.model.owner == g.user)
cx2 = np.random.random_integers(cx1, size - 1)
im = Image.open(file)
fast_xor(b, 256)
person = re.findall(regex, line)
y = x[indices]
line = f.readline()
ciso8601
ujson
workalendar
mask.sum()
tmp = pd.Series(np.array(list(col)).flatten())
sys.path.insert(0, flaskfirst)
instance.test_method(instance.sample_method)
addsf1 = addsf1 + int(num)
print(extract_names(s))
incsv = csv.reader(inf)
rows = np.arange(a.shape[0])
ax.annotate(c, xy=pos)
app.url_map
temp = int(temp)
ReligiousSerializer(instance=instance).data
LaySerializer(instance=instance).data
grp.reindex(mux, fill_value=0).reset_index()
G.add_edge(4, 5)
np.ix_(mask1, mask2)
print(test_Dict[obj].name)
pd.DataFrame([dict((x, r.count(x)) for x in r) for r in d]).fillna(0)
power(2, 5)
win = gtk.Window(gtk.WINDOW_TOPLEVEL)
hxs = HtmlXPathSelector(response)
module_name = os.path.basename(module_filepath)
True
deleted[i]
name = models.CharField(max_length=20, unique=True)
list(d.items())
print(newcorpus.paras())
x = remove_values_from_list(x, 2)
errdata = prog.communicate()[1]
plt.show()
v = CountVectorizer(ngram_range=(1, 2))
out.getvalue()
Clock.schedule_interval(self.change_color, 1)
myFunction(*args)
ax.xaxis.get_ticklines()
sys.stdout.write(line)
BLUE_MIN = np.array([0, 0, 200], np.uint8)
a = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=np.bool)
res = []
raise TransportError(e.msg, e.code, e.fp)
augmented = tf.map_fn(_augment, self.training_images)
plt.axes().yaxis.set_minor_locator(ml)
h.close()
[(u.value, u.meta) for u in set([a, c, e]).intersection(set([b, d]))]
stdscr.refresh()
df.index.dtype
out.append(s[i - k:i])
plt.legend()
plt.xticks(x, xticks)
p.close()
[[sum(1 for _ in g), v] for v, g in itertools.groupby(l)]
-gfortran
l.append(read_from(toks))
start = time.time()
wrapper2
cmake
i = 0
maxm = np.array([], dtype=int)
after_setup_logger.connect(initialize_logstash)
print(dir(B))
r[i] = (a * 67108864.0 + b) / 9007199254740992.0
random.shuffle(d)
print(df)
globals()[k] = test.__dict__[k]
next(values())
ax.xaxis_date()
endif
df = pd.read_table(io.BytesIO(data), delim_whitespace=True)
data = next(reader)
from_date.replace(month=2, day=28, year=from_date.year - years)
sys.stderr = sys.stdout
float(a)
dict(map(ascii_encode, pair) for pair in list(data.items()))
f.integral()
self.save_file.append(json.loads(tweet))
print(x, y)
ax2 = plt.subplot(gs[(0), 2:])
self.setup_test_data()
self.append(next(self._gen))
[]
fill_array(subarr, subseq)
{{message}}
strng = socket.recv(1024)
result
df.isin([1, 2]).any(1)
fabric.state.connections[host].get_transport().close()
filename = sys.argv[1]
self.adjacencyList = adjacencyList
self.drawWidth, self.drawHeight
results = collections.Counter(the_string)
do_sth_with(i, somearray[i])
elements.append(Paragraph(content, style))
abs(-1)
result = custom_sort(allsites)
smtplib.SMTP_SSL.__init__(self, host, port, **kwargs)
wx.TheClipboard.Close()
main()
list_of_dict = []
self.canvas.draw()
wr.writerows(csv.reader(f))
QtGui.QColor(rgb).getRgb()[:-1]
s = socket.socket()
json.dump(d, fileout)
print(utmless_url)
frame.set_border_width(2)
process(elt.mylargecontent)
newFile.writerow(row)
array([[1.0, 4.0], [2.0, -1.0]])
list(self._consumers.keys())
next(f)
unittest.main()
application_path = os.path.dirname(sys.executable)
self.set(value)
int(self.x)
test = lambda m: min(timeit.repeat(m, setup))
count[0] += 1
query = users.select().order_by(users.c.id.desc()).limit(5)
conn = MySQLdb.connect(**params)
self.func = func
mm = np.mean(mdat, axis=1)
print(list(diff.elements()))
help(f)
socketIO.wait_for_callbacks(seconds=1)
result = a.format(name=b)
self.DISTRICT
self.lb2 = tk.Listbox(self.root, yscrollcommand=self.vsb.set)
reactor.stop()
self.managed
txt = f.read()
self.zfile = zipfile.ZipFile(self.z)
r = requests.get(url)
pil_image = PIL.Image.open(file)
plt.xlim(0, 5)
[x for x in k if tuple(x) in stuff_in_kDash]
plt.subplots_adjust(hspace=0.4)
print(GLOB_VAR)
print(eval(code))
c = Counter(chain.from_iterable(list(d.values())))
h1 = logging.StreamHandler(sys.stdout)
grad = np.array([-1, -1, -0.2, -0.4, 0.4, 0.2])
ax2.add_line(line)
hxs = HtmlXPathSelector(response)
print(x.dot(y).shape)
type(x)
B.sum()
plt.ioff()
s[::-1]
plt.subplot(212)
logging.root.addHandler(console_handler)
n = X.shape[0]
A.shape
create_app()
{tuple(e) for e in a}
p = multiprocessing.Process(target=f)
d2 = dict(a=1, b=2)
inds = np.ravel_multi_index((rows, cols), arr.shape)
r.json
ascends.append([i + 1, i + 1])
print(roster)
atan_in_degress(2)
object.__ge__(self, other)
[1.0, 4.0, 9.0]
any(test(x) for x in L)
print(xmp_str)
leg.get_frame().set_linewidth(0.0)
app.MainLoop()
leftpath = []
stdin.flush()
resp = views.my_view(req)
val
dialog = QDialog()
pairs_by_number_and_list[pair[0]].append(pair)
trees.extend(parent.children)
self.queue.append(item)
list.append(val)
cv2.circle(vis, (x1, y1), 2, col, -1)
plt.tight_layout()
gb(pt[0], pt[1], 0, 0)
something_else()
HexDump()
a[i][:] = np.concatenate((z, a[i][:][np.nonzero(a[i][:])]))
pprint(_)
results = list(ex.map(len, fl))
fig = plt.figure()
NP.c_[(0.2), 1:10, (60.8)]
k.set_contents_from_string(r.content)
ptr[1] = color[1]
im.paste(255, mask)
print(item)
defaultdict(factory)
print(rowselected[c].value())
plt.plot(x, y, label=label, color=cmap(color), lw=5)
self.x == other.x and self.y == other.y
txt = f.read()
s.quit()
a1 = np.arange(2)
file_size = 0
this_port = my_socket.getsockname()[1]
print(results[entry])
filter.children.pop()
c = connection.cursor()
notifier.loop()
self.key = key
greater = qsort([x for x in inlist[1:] if x >= pivot])
http_server.serve_forever()
elem.pop(elem.index(match))
print(rpy2.__version__)
user = User.objects.get(username=username)
print(hex(id(y)))
i = random.randint(0, len(self.data))
d = random.randint(5, 15)
startupinfo = subprocess.STARTUPINFO()
df_with_cat.show()
dataframe.to_excel(writer, sheet_name=sheets, startrow=row, startcol=0)
client.close()
models.Field.formfield(self, ObjectListField, **kwargs)
line = models.CharField(max_length=12)
U, s, Vt = np.linalg.svd(A, full_matrices=False)
hashes.append(hash_dir(os.path.join(path, dir)))
logger = logging.getLogger(__name__)
plt.hist(x, bins=n, range=(minval, maxval), weights=weights)
sys.stdout.flush()
fitfunc = lambda params, x: params[0] * x + params[1]
print(tb_last.tb_frame.f_locals)
file_name_string = base64.urlsafe_b64encode(your_string)
a = np.arange(1, 11)
print(r.content)
self.diagram.SetCanvas(self)
parser = argparse.ArgumentParser()
dt.now()
count += 1
df
print(values)
tree = objectify.parse(xmlPath, parser=parser)
a + b
X.sum(axis=0)
pdb.set_trace()
signal.signal(signal.SIGINT, cleanup)
sys.stdout, sys.stderr = oldout, olderr
next(reader)
fig, ax = plt.subplots()
curdoc().add_root(page_logo)
b[:, :, (4)]
plt.show()
xml.parsers.expat
a = np.array([0, 0, 15, 17, 16, 17, 16, 12, 18, 18])
links = Post.objects.filter(link__tag__instancemodel=instance)
sess = tf.Session()
deletelst[0]
lines = [line.strip() for line in f]
idx_2D = np.outer(idx, idx)
s = set(fus_d.keys())
exit
unpad(cipher.decrypt(enc[16:]))
sum(summands)
np.column_stack((a, b))
pl.imshow(im_array, cmap=cm.Greys_r)
ts = time.timetuple()
num2 = int(argv[2])
print((hex(num), num))
stdout, notused = process.communicate()
type(c)
stuff()
print(i)
self.file.close()
description = Column(String)
{NULL}
One().f()
joinstr.join(t.queryString() for t in self.tokens[0::2])
QtGui.QDialog.__init__(self, parent)
assert Implementation(thing).foo == thing
random.choice(largest)
books = forms.ModelMultipleChoiceField(queryset=Book.objects.all())
groups = dict(list(gb))
print(my_test.name)
self.t2 = time.time()
out = np.bincount(id_arr.cumsum(), np.take(data, np.concatenate(contribs)))
shortcut.Save()
pygame.init()
self.worker.daemon = True
d[key] = d2[key]
driver = webdriver.PhantomJS(*args, **kwargs)
new_l.append(d)
length = len(lists[0])
meas.append((x, y))
{0, 7, 8, 9, 10, 0, 0},
wmp.Open.Open.Click()
yagmail.SMTP().send(contents=contents)
list(ln).index(1)
diags.append(A[x][x] * B[x][x])
A.nbytes
csv_reader = csv.reader(f)
[1.5, 0.8660254]
x.append(row[0])
sys.stdout = dummyStream()
slope, intercept, r, p, stderr = linregress(x, y)
a.__setitem__(x, a[x][1])
mydict = dict((s[0], s[1:]) for s in myseq)
iconfile.write(icondata)
assert response.data == imgStringIO.read()
self.statusBar.show()
deactivate
aDict[name].append((int(startTime), int(endTime)))
csv_out.write(output_line)
dictionary[parts[0]] = 1
x[0, 0, 0] = value1
now = datetime.now()
[0, 0, 0, 1, 0],
[(a, b) for a in A for b in B if a in b]
dat = pd.DataFrame(np.random.randn(100, 100))
bf.flush()
df2 = df.copy()
df[2]
self.values = set()
subprocess.check_call(params)
b = dict(enumerate(a))
object.__str__(self)
element.findall(search)
next(m)
True
found = False
df.columns = my_columns
d[k] = v
b.pop(0)
df = df[df.C == c_maxes]
c = muX - b * np.dot(muY, T)
array([2, 4])
response.raise_for_status()
main()
b()
a.shape
self.button.show()
temp = np.cumsum(X, axis=0)
l = [k for k in h]
print(dict[key])
cameraR.SetFocalPoint(0, 0, 0)
np.sqrt(val / 2.0 / a.shape[0])
canvas.restoreState()
property_asel = [a for a, truth in zip(property_a, good_objects) if truth]
b().mymethod()
plt.title(title)
x, y = sp.coo_matrix(df.isnull()).nonzero()
Vector(self.x + n, self.y + n)
out = arr.copy()
parser = argparse.ArgumentParser(formatter_class=argparse.RawTextHelpFormatter)
print(darr.min())
df.columns = pd.MultiIndex.from_tuples(df.columns, names=cols)
v = Vector((x, y, z))
out = np.empty((ma, mb, na + nb), dtype=a.dtype)
v1, v2 = Tup()
counts = [(chr(i), v) for i, v in enumerate(counts) if v]
self.panel = wx.Panel(self)
hxs = HtmlXPathSelector(response)
chord(207.652)
chord(195.998)
seed = np.random.randint(0, 100, (200, 206))
P1Sum = P1Channels.sum(axis=1).sum()
numrows = len(input)
unittest.main()
type(x)(y)
bin(y)
list(gen)
Html.fromHtml(html).toString()
[1, 5, 9]
handle.set_missing_host_key_policy(ssh.AutoAddPolicy())
driver.get(URL)
db.authenticate(self.user_name, self.password)
soup = bs.BeautifulSoup(content)
print(p)
M_inverse = M.inv()
word[:-1]
self.queue = multiprocessing.Queue(-1)
[record[0] for record in cursor]
ax.view_init(elev=elevation_angle, azim=azimuthal_angle)
print(ElementTree.tostring(thing))
line.set_color(label)
x = d[x]
result.append(map(decimal.Decimal, line.split()))
img = scipy.misc.imread(fname)
traceback.print_exc()
plot_matrix = np.zeros((height, width))
np.log(a) / (k + 1) * x ** (k + 1)
gevent.joinall(jobs, timeout=2)
r = csv.reader(f)
type(seen.add(10))
k, v
out_str = subprocess.check_output(cmd, shell=True)
sets = np.array_split(arr, 4)
next(g)
df
after_setup_task_logger.connect(foo_tasks_setup_logging)
plt.close(fig)
plt.xlim(1.0, 2.2)
pd.DataFrame(dict(birdType=someTuple[0], birdCount=someTuple[1]))
competitors = Competitors.objects.all()
assert len(lists) == len(values)
out = process.stdout.read(1)
fig, ax = plt.subplots()
set(n for val in list(periodic_gs.values()) for n in val.nodes())
generator.workbook.close()
q[0, 0] = 5
result = [[k, da[k] + db[k]] for k in da.keys() & db]
main()
result = min_value if result < min_value else result
list(samples2)
download = requests.get(url)
body = resp.read()
parse(string)
line = m.readline()
render2Dstuff()
self.assertEqual(mock_boo_obj.e.call_count, 1)
subprocess.call(kill_command, shell=True)
cur.close()
writer = csv.writer(fo)
target.write(str(source.read(), sourceEncoding).encode(targetEncoding))
c.stop()
predict_on_batch(self, x)
data_array = np.array(data)
m.drawcoastlines(linewidth=0.5)
X = np.random.uniform(0, 1, size=(nx, dim))
characteristics = Characteristics()
find_planar_subgraph(G)
response = request.urlopen().read()
draw.ellipse((x_pos, y_pos, x_pos + box_edge, y_pos + box_edge), fill=255)
grow(m, r, c)
ax = fig.add_subplot(111, polar=True)
len(df) == 0
library(rjson)
x = np.array([True, True, False])
b = bytearray()
sys.exit(0)
output = process.communicate()[0]
len(set(x))
line_num += 1
offset += len(i) + len(delimiter)
plt.plot(x2, y2)
width, height = np.shape(img)[0:2]
df2
deleteself.d[k]
isinstance(12, retype)
request.session.save()
os.remove(fullpath)
wb = Workbook()
print(G.edges())
print(line)
ptree.productions()
example[[1]]
d.hexdigest()
r = pd.DataFrame(X.toarray(), columns=vect.get_feature_names())
csv_writer.writerows(rows)
dflist.append(df)
event.process()
print(zzz())
ctr = Counter(frozenset(x) for x in a)
parser.parse(s)
a = Yd()
self._x
a.A
newDf = sqlContext.createDataFrame(df.rdd.flatMap(rowExpander))
is_my = soup.new_string(is_my)
f(2)
axis.set_visible(True)
os.execv(sys.executable, args)
t = datetime.datetime.today()
full_path = os.path.join(directory, name)
print(line)
result.append(tree)
n = len(array)
isinstance(thing, str)
mf.seek(0)
os.path.basename(urlparse.urlsplit(url)[2])
a, b, c = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()
index = find(target, key, start_index)
translate(coding_dna, to_stop=True)
k.extend(a)
main()
output.close()
vdisplay.stop()
love_ctx.add((alice, loves, bob))
df.to_csv(combined_file, index=False)
t.remove(elem)
time.sleep(x)
thread.start()
cls(_hours, _minutes, _seconds)
alist2 = []
nl.append(uniq(base, i))
id = Column(Integer, primary_key=True)
B = np.random.rand(100, 2)
a, b = temp_tuple
result = pd.DataFrame()
ax1.set_aspect(1.0)
ordc = ord(c)
my_main_func()
soup = BeautifulSoup(html)
b = [x for x in a if x not in itemsToRemove]
new_lock = threading.Lock()
uniq = list(uniq.values())
data = request.get_json()
fkwargs.update(gkwargs)
d2 = date(2012, 1, 1)
list(repeat(100, randint, 1, 100))
y = np.arange(W)
a.has_usable_password()
lmask = len(mask)
df = df[cols]
pd.DataFrame(np.fromstring(arr, dtype=np.uint8).reshape(-1, 8) - 48)
pool.join()
height = int(cv.GetCaptureProperty(cap, cv.CV_CAP_PROP_FRAME_HEIGHT))
print(np.all(b == d))
print(line.strip())
member.value
df.ix[df.Col1.isin(search_list) & (df.Col4 > 40)]
G_pc.add_edges_from(edges_2212)
length = len(s)
wa.login(login, password)
layout.addWidget(self.pb)
print(np.allclose(A1, A2))
logger.handlers[0].stream.close()
xml2.getroottree().write_c14n(xml_string_io2)
raw_file = os.path.join(permanent_store, file.name)
os.rename(path, newpath)
plt.ylim([-l / 2, l / 2])
proxy._get_current_object()
print(args)
Rev5 = 1
self.config(image=self.frames[self.idx])
line = line.rstrip()
print(leapyr(1900))
self.brushes.append(brush)
forwarder = serial.Serial(com_port2, baudrate)
words = (w for line in f for w in line.split() if is_difficult(w))
x[()]
main(sys.argv)
mod = __import__(module_name, fromlist=[class_name])
f.close()
print(count)
__init__.py
print(filename)
rolled = np.roll(y, -1, axis=1)
aList.pop()
sorted(set(a))[-1]
print(df)
lines = file.readlines()
unittest.main()
ignored
cls.change_mro = False
object.__new__(A)
max(PlayerList, key=lambda p: max(p[1:]))
result = conn.execute(sql)
random.shuffle(z)
self.__dict__.update(kwargs)
curs = conn.cursor()
self.thread.start()
print(d[4])
print(results)
e, ecov = curve_fit(line_exp, x, y, e0)
B[:, (n)] = np.random.randn(N)
data_copy = deepcopy(json_data)
dlg.EndModal(0)
H = H / np.std(H)
arr = np.zeros((200, 20, 10, 20))
legline.set_linewidth(lw)
logOutput.setLineWrapMode(QTextEdit.NoWrap)
app = QApplication(sys.argv)
stripped_lines = (line.strip() for line in fd)
[n for n, d in list(G.in_degree().items()) if d == 0]
self.setZValue(-1)
print(arr[:])
line1.set_ydata(np.sin(x + phase))
False
data = json.loads(json_text)
args = argparse.ArgumentParser.parse_args(self, *args, **kw)
type.__init__(cls, name, bases, classdict)
df2 = merge(df1, csv2, **kw2)
pattern_obj = re.compile(pattern, re.MULTILINE)
df
fig = plt.figure()
tasks.append(c.delay(a))
country = CharField(max_length=200)
j.environment.filters.update({})
cur = con.cursor()
dis.dis(f)
fig = plt.figure()
print(foo[0:2])
opener = urllib.request.build_opener(handler)
label1.grid(row=i, column=0)
words = text.split()
soup = BeautifulSoup(html)
self.include_dirs.append(numpy.get_include())
len(vals)
n += 1
path += iter(lambda : predecessor_map[path[-1]], origin)
x.__setitem__(0, 100)
[id(i) for i in a]
isinstance(y, (np.ndarray, np.generic))
f.seek(offset)
etree.tostring(doc, xml_declaration=True)
biggest = mylist[-2:]
calculation()
np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)
f()
cls()
plt.plot(p, x, c=(0, 0, 0, 0.1))
print([x for i, x in enumerate(f) if 1 <= i <= 15])
self.tstore.append([osp.basename(f)])
b = np.unpackbits(bitmap[np.packbits(a, axis=1)], axis=1)
process.kill()
input = raw_input
s.headers.update(headers)
yEstArray.append(yEst)
NULL
merged_list.append((x, index1, index2))
18.28165417900891
print(dirichlet([1] * n))
image_file = Image.open(img_path)
self.chambersinreactor += 1
m.drawcoastlines()
y = numpy.array([numpy.array(xi) for xi in x])
int(mktime(obj.timetuple()))
mydict = {k: v for k, v in list(mydict.items()) if k != val}
_quicksort(array, begin, pivot - 1)
fn = os.path.join(dir, name)
dtypes = left.dtypes.combine_first(right.dtypes)
[line.draw(color=(255, 0, 0)) for line in lines]
any(map(lambda c: c.isdigit(), value))
_, s = min((len(values[s]), s) for s in squares if len(values[s]) > 1)
x = np.arange(-1, 1, 0.1)
fig = plt.figure()
dict.__setitem__(self, key, val)
g.db.close()
a.pop(0)
self.tck = fitpack.bisplrep(x, y, z, kx=kx, ky=ky, s=0.0)
self.file_name = file_name
cj = cookielib.LWPCookieJar()
x = np.arange(16).reshape(4, 4)
ax.xaxis_date()
plt.figure(2)
dist = sum(dict[i] for i in range(1, input_key))
str(carray)
df = pd.DataFrame()
animal.save()
p.start()
server = tornado.httpserver.HTTPServer(application)
lambda *a: func(*(a + args))
d = defaultdict(int)
millis = int(round(time.time() * 1000))
[buildout]
a = Apples()
__init__.py
set(ast.literal_eval(line))
a * c
Base.metadata.create_all(engine)
recv2 = recv2.decode()
recv4 = recv4.decode()
net.addModule(hidden0)
TerminateProcess.restype = ctypes.wintypes.BOOL
list = yaml.load(file)
[_f for _f in lis if _f]
theoryX = np.arange(0, 1, 0.1)
result.update(list(range(int(x[0]), int(x[-1]) + 1)))
installation_path = p.__file__
axes.set_xticks(ticks[::n])
plt.imshow(img)
now = datetime.now()
result
total = numpy.sum(x + y)
readFrom(stream_proxy.stream())
dev1 = os.stat(file1).st_dev
form = PersonForm(request.POST)
sniff(prn=makecap)
face_list.add((a, x, b))
j += 1
df.columns = df.columns + 1
user.save()
[0.0, 0.0, 1.0],
first_name = models.CharField(max_length=100)
lst.append((start, length))
arr = np.fromiter(itertools.chain(*it), int).reshape(-1, 2)
xy[:, (1)]
ax = fig.add_subplot(211)
red.setTo(Scalar(255), mask_red)
cursor = db.cursor()
print(a([1, 2, 9999, 4, 9999, 9999, 12], 0, 0))
q.put(getattr(a, target)(*args, **kwargs))
delete_when = db.DateTimeProperty()
print((np.linalg.det(A) - a.det()) / a.det())
stdscr.keypad(1)
pp(expr, use_unicode=True)
show(p)
object_id = models.PositiveIntegerField(null=True)
y.start()
lock = multiprocessing.Lock()
sum(a * b)
intermediate_list.append(td.findNext(text=True))
bets = 2 ** toss2.cumsum()
update_screen()
c = np.setdiff1d(a, b)
Qt.QWidget.__init__(self)
outfp.getvalue()
self.assertFalse(flag)
cv2.waitKey(5)
A = X, Y
datetime.datetime(*map(int, mat.groups()[-1::-1]))
timeit(set(a) & set(b))
pd.DataFrame(dict(columns=box(a).tolist()))
json_data = json.load(json_file)
print(match[0])
self.things_lock = threading.Lock()
d1[k] -= v
t = datetime.time(0, 0, 0)
print(df)
res = np.array_equal(A, B)
h, status = cv2.findHomography(pts_src, pts_dst)
background.paste(img, offset)
path = sys.argv[1]
Y = np.random.uniform(0, 1, size=(ny, dim))
Matrix.map(lambda a, b, **kw: a + b, self, other)
self.response.write(self.jinja2.render_template(template, **context))
f(*args, **kwargs)
image.thumbnail(size, Image.ANTIALIAS)
+1 + 1 + 1 + 1 + 1 + 1 - 1 - 2 + 1 - 1 - 1 - 2
assert os.path.isdir(corpusdir)
response.close()
q_in.delete_message(qmessage)
print(dict(zip(p, i)))
s = json.dumps(foo)
parser.parse_args()
plt.show(block=False)
print(Example.Variable)
dictionary[new_key] = dictionary[old_key]
sys.stdout = sys.__stdout__
img2 = cv2.imread(img2_path, cv2.CV_LOAD_IMAGE_GRAYSCALE)
print(m.group())
vals[bisect.bisect_right(keys, 0.5)]
sysconfig.get_python_inc()
a = [5, 8, 9]
self.channel = self.connection.channel()
count_list = [(i + 1) for i in range(N)]
custm.cdf(2.5)
ax.set_axisbelow(True)
[doc for doc in db.units.find()]
len(rg.findall(regexp))
0
ax = plt.gca()
Canvas.__init__(self, parent, **kwargs)
self.__class__(res)
monkey.patch_all()
run_daemon()
pool = Pool(4)
desired_ages = np.array([4, 16, 29, 80])
nodes.extend(n.comparators)
print(np.tensordot(v, A, axes=(0, 2)))
wget - q - O - icanhazip.com
crawler.start()
year_hour_means = df1.groupby(lambda x: (x.year, x.hour)).mean()
signal.alarm(1)
str.__new__(cls, *args, **kw)
plt.contourf(d)
count += flatten_count(item, element)
os.close(fh)
ax2.yaxis.label.set_color(plot_ax2.get_color())
e1 = tk.Entry(self)
new_dict = dict(zip(keys, initial_list))
img.paste(wmark, (0, 0), wmark)
fig = pylab.figure()
A.__init__(self, 1, 2)
print(r.status_code)
classifier = nbc.train(feature_set)
screen.force_update()
plt.show()
number = random.randrange(10)
item.patch.set_visible(False)
print(unique_rows(data))
sess.run(init)
messages.append(message)
self.d = {}
print(bare_argspec)
now = datetime.datetime.utcnow()
relaxng.validate(doc)
np.random.seed(1977)
cdr = list[1:]
[1, 2, 1]
[0.09558515, 0.0, 0.0],
self.Destroy()
fhan.setLevel(logging.DEBUG)
plt.show()
admin.site.register(User, UserAdmin)
[w for w in wordlist if regex.match(w)]
t = numpy.array([0.24])
sock.listen(5)
s[0][0] += 1
self.scrollbar.config(command=self.yview)
new_dict[pair[1]].append(pair[0])
self.connection.shutdown()
print(s.query(A, B).select_from(subq).all())
r[0].tag
t = TestModel.objects.all()
opener = urllib.request.build_opener(*handlers)
new_foo = []
print(df)
stream.write(self.terminator)
ax.scatter(x, y, s=200, facecolors=rgb)
loc = image.get_rect().center
plt.clf()
df
bigList = [int(1000 * random()) for i in range(10 ** 6)]
sess = tf.Session()
p4 = ctypes.cast(id(tb), ctypes.POINTER(ctypes.c_uint))
fig = matplotlib.pyplot.figure()
name = models.CharField(max_length=60)
counts = np.bincount(a)
plt.xticks(xticks)
idx = np.floor(input).astype(np.int)
spotify.playpause()
UTF - 8
width, height = fig.canvas.get_width_height()
sorted(output.items())
loop.run_until_complete(do_work())
JM2 = JM2.transpose([1, 2, 0])
g.add_legend()
print(map(etree.tostring, x))
df4 = pd.DataFrame(np.random.rand(6, 2))
self.inner_sizer.Add(self.test_panel, 1, wx.LEFT | wx.RIGHT | wx.EXPAND, 50)
self.errorcall = errorcall
self.buttonPanel2.Show(False)
all(type(n) == str for n in f)
url, len(page)
new_driver.set_window_size(800, 450)
response = br.submit()
help(list.__contains__)
Queue.interruptable_get = interruptable_get
next(inf)
self.A = np.arange(1000)
content = models.TextField()
df.idxmin(axis=1).values
scopes = list(scopes)
root = tk.Tk()
print(list(round_robin(teams, sets=len(teams) * 2 - 2)))
width, height = orig_image.size
self.layout = QVBoxLayout(self)
rect(x, 0, dx, y, color)
x = np.arange(0, 10, 0.01)
self.start()
dict.fromkeys(s)
string = string[1:-1]
result.append(i)
results.append(i[1])
tostring(root)
sh = book.add_sheet(sheet)
keypoints = detector.detect(imthresh4)
{{secrets | to_nice_yaml(width=50, explicit_start=True, explicit_end=True)}}
c1.setopt(pycurl.PROXYPORT, 8080)
e.bark()
chars = (ch for word in fileinput.input() for ch in word.rstrip())
print(imsi)
s = binascii.unhexlify(a)
session2 = SessionDST()
self.serialc.start()
indices = np.arange(9)
plt.plot(X_plot, X_plot * results.params[0] + results.params[1])
tornado.options.parse_command_line()
print(line)
browser = webdriver.Firefox()
db.close_connection()
z.close()
f(b=2, **example)
print(b[:, :, (0)])
f, ax = plt.subplots(1, 1)
data.values[bool_indices]
print(t.overlap((-10, 10)))
str(b)
self.update(dict(*args, **kwargs))
shutil.copyfileobj(r.raw, f)
plt.ylim([-8, 8])
paramtoget = {pval: wt_val}
l.append(a)
self.ready.emit()
self.treeview.set_search_entry(self.search_entry)
plt.close()
x = random.choice([a, b])
(x + h & m) - h
values = [item[1] for item in items]
a[:nonzero(a != b)[0][0]]
app = wx.App()
print(cumsum(array))
b = a
[key for key, group in groupby(li) if sum(1 for i in group) == 1]
response = requests.get(newUrl).text
x - np.roll(x, 1)
{key: tuple(d[key] for d in dicts) for key in common_keys}
_odbcinst_SystemINI(szFileName, FALSE)
form.populate_obj(person)
len(self._inner)
cPickle.dumps(object())
match_str = match.group(0)
self.b.clear_cookies()
y6 = x.astype(np.float_)
logger.setLevel(logging.DEBUG)
Hhigh = ifftshift(Hhigh)
venus.circle(108, 1)
print(cmp(list_2, list_1))
max_value = max(sentiment_dict.values())
chain(list_, _foo_suffix())
stopped.set
True
libp = os.path.abspath(lib)
value = process_value(raw_value)
print(doc.prettify())
bar()
G = nx.Graph()
d = defaultdict(list)
sA = pd.Series(A)
sub = s[pair[0]:pair[1]]
set([6])
plusone = []
syscall = libc.syscall
color = QtGui.QColor(0, 0, 0)
unittest_main()
ax.figure.canvas.draw_idle()
sys.exit()
x = np.array(x)
df_r = pipeline.fit(df).transform(df)
print(contents)
_f_values[a][b]
print(count)
self.canvas.widgetlock(self.lasso)
signal.alarm(1)
user1 = forms.ChoiceField(choices=choices)
Encoders.encode_base64(ical_atch)
ax.add_collection(lines)
s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
b = np.array([4, 5, 6])
x0, y0, r = optimize.fmin(cost, (x0, y0, r))
ax.set_zlim(-1.01, 1.01)
data = {}
_jobs[jobname].apply_async(args=args, kwargs=kwargs)
hexdigits = [int(x, 16) for x in hex_string]
Y = np.matrix([[1, 0, 1, 1]]).T
test_set = np.array(test_set)
crawler.crawl(spider)
numpy.random.shuffle(index_array)
cerr << endl
text.pack()
self.setLayout(v_box)
response = urllib.request.urlopen(request)
time.sleep(1.0)
data = s.recv(1024)
print(df[col].value_counts(dropna=False))
fibm(x - 1) + fibm(x - 2)
self.data.pop()
cursor = con.cursor()
False
pairs[mask]
tempCS1 = plt.imshow(frame, cmap=plt.cm.gray)
result.extend(sublist)
w.wcs.cdelt = numpy.array([cdeltX, cdeltY])
print(groups.median())
funcs.append(c)
app.exec_()
next(self.iter)
self.window.get_toplevel().show()
htmlparser = etree.HTMLParser()
os.makedir(sdsd)
defaultdict(int)
increments[n - 1] += 1
os.chdir(tmp_location)
file_handle.write_to(text)
print(re.escape(s))
[4, 1, 1]
yolk - l
string.format(*diff, **some_date)
layout = QtGui.QVBoxLayout(self)
img_color = np.dstack((img, img, img))
A[:, (j)] = x ** j
someList.append(copy.copy(foo))
res = NP.append(my_data, new_col, axis=1)
S2 += len(set(ids))
print(line)
obj = json.loads(encoded)
a = np.arange(10)
df.year = df.year.astype(int)
callback(self._global_wealth)
res.extend(res_females.get())
max_index = np.argmax(a[inds[:, (0)], inds[:, (1)]])
sound.stop()
response.write(bytes)
root = Tk()
print(f[1])
print(elt.eltid)
some_other_func(something_else)
traceback.print_exc(file=sys.stderr)
locationgroup = models.ForeignKey(LocationGroup)
print(add_time(datetime(year=2015, month=12, day=25), relativedelta(months=+1)))
count += 1
id = db.Column(db.Integer, primary_key=True)
idx = np.where(a)[0]
print(model.__name__, [x.name for x in model._meta.fields])
asteroids = Game(600, 600)
self.hbox.pack_start(self.button, False, False, 0)
new_items = {str(item) for item in items}
browser.add_handler(auth_NTLM)
truncnorm_samples = norm.ppf(cdf_samples)
mask = X ** 2 + Y ** 2 + Z ** 2 < radius ** 2
idx = random.choice(list(range(num_outcomes)))
groups.append(newGroup)
withinx = random.randrange(x1, x2 + 1)
cr.rectangle(0.0, 0.0, *widget.get_size())
waw - 0.464188
x.item()
fp = os.path.join(dirpath, f)
data = response.json()
d = collections.defaultdict(list)
data = grouped_count.apply(as_perc, total=df.my_label.count())
os.unlink(filename)
example[4:0] = [122]
[atlas]
counts = collections.Counter(l.strip() for l in infile)
root2 = Tkinter.Toplevel(root)
mvnorm.pdf(x, mean=0, cov=1)
G.add_edge(u, v, weight=w)
peasant.knock_over()
self.f_ = f
obj.__class__ = type(base_cls_name, (base_cls, cls), {})
pythoncom.PumpWaitingMessages()
b.delete_key(k)
instance = reservation.instances[0]
d = {}
ceiling_key(d, 0)
shift_vals = np.hstack((array1[0], np.diff(array1) - lens[:-1] + 1))
positive = set((x, y) for x in range(1, 5) for y in range(1, 5))
print(difft2(time(20, 40, 0), time(22, 41, 0)))
debian
key = bytes([19, 0, 0, 0, 8, 0])
attachment.get_content_type()
passhash = db.Column(db.String(100))
print(C)
print(type(unicode_text))
out.writerow(data)
json.dump(r.json, sys.stdout, indent=4, ensure_ascii=False)
ind1[cx1:cx2], ind2[cx1:cx2] = ind2[cx1:cx2].copy(), ind1[cx1:cx2].copy()
sum_gx = np.trapz(gx, x, dx)
referred_classes = [r.mapper.class_ for r in i.relationships]
oftype = collections.defaultdict(list)
plt.plot(x, kd_vals)
y = np.random.randn(N)
install.run(self)
cell.value = 1
axs[i].get_yaxis().set_ticks([])
self.num = foo.num + 1
a = []
plot(x, y)
set(main_array) - set(second_array)
sportDict[ransport].append(name)
numpy.nextafter(1, 0) > 1 - sys.float_info.epsilon
s.dt.components
self.send_blob(blob_info, content_type=type1, save_as=save_as1)
print(np.intersect1d(B, ind))
f0(s(t))
writer.writeheader()
name = models.CharField(max_length=200)
print(list(text.get()))
self._start = start
d = OrderedDict()
relative = os.path.relpath(path, directory)
a.resize(len(b), refcheck=0)
main()
i[0]
img_w, img_h = img.size
locations.append(locationx)
float(1.0).is_integer()
root = Tkinter.Tk()
post_save.connect(my_post_save_handler)
assert IntInfinity() > 1e+100
lambda : user_is_admin(cherrypy.request.login)
M[index]
player.clearCards()
mask1 = np.in1d(out_id, a[:, (0)])
signal.alarm(0)
print(sc.parallelize(list(range(i * 10000))).count())
x = np.random.randn(10000, 10000)
arr = i * np.ones((2, 4))
{NULL, NULL}
dumper.represent_int(hex(data))
new_pressures = []
browser.submit()
fmin = (N - 1) // f2 + 1
lengths = Counter(len(v) for v in list(testdata.values()))
legend_fig.canvas.draw()
mod1.pxd
spreadsheets_client = gdata.spreadsheet.service.SpreadsheetsService()
print(line, line2)
x.pop(0)
stdscr.clear()
new_settings = termios.tcgetattr(sys.stdin)
d = dict(zip(keys, groups))
X = np.hstack((X, AllAlexaAndGoogleInfo))
0.7105, sym2, 6, 5, 10, 10
self.Bind(wx.media.EVT_MEDIA_LOADED, self.song_is_loaded)
s = df.sum(axis=1, level=[0, 1]).T
self.f1 = MethodType(f, self, self.__class__)
q.put_nowait((url, host))
[_ for _ in iterable if not _.isdigit()]
x = [1, 2]
df = pd.concat([df, dummies], axis=1)
column_widget = gtk.VBox()
c = a + b
data_rows.append(row)
ri = lambda : random.randint(0, 10)
user = models.ForeignKey(User)
np.import_array()
Py_Initialize()
nL = [0, 0, 0, 0, 0, 0, 0, 0, 0]
t.show()
f.z
deletenum_list[0]
worker.finished.connect(self.thread.quit)
alchemy / bin / bpython
xlim(0, 10)
self.sock.settimeout(self.timeout)
pattern = url[0][1]
archives[-1]
print([int(bn[i:i + 8], 2) for i in range(0, len(bn), 8)])
root.mainloop()
print(merge_to_couples(new_list))
df = pd.DataFrame(data2)
print((y, z, bigmat[:, (y), (z)]))
expr.subs({x: 10, y: 5})
self.label
list_of_numbers.append(float(val))
dt = parser.parse(s)
A[(0), :, :]
print(line)
main_window = QtGui.QMainWindow(size=QtCore.QSize(500, 500))
difflib.get_close_matches(dud[0], pc_dud)
print(df1)
df1 = df1.reset_index()
CharField.__init__(self, *args, **kwargs)
sck = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
to_modify[indexes[index]] = replacements[index]
pickle_test()
import_module(moduleName)
m = numpy.random(100, 100) > 0.5
f.write(str_object2)
B = np.reshape(A, (A.shape[0], A.shape[1], np.prod(A.shape[2:])))
f1.seek(start)
V = numpy.dot(X.transpose(), X)
ints = [int(n) for n in s.split()]
mask = tf.placeholder(tf.bool, shape=(n, n))
a = wrp_testchar(byref(steps), byref(in_data), in_char)
print(elem.text)
result = [[(e - 1) for e in i] for i in n]
print(mag(data))
mars.speed(1)
mystring = str(myvariable)
ndb.put_multi(model_dbs)
test.columns = pd.MultiIndex.from_tuples(index_tuples)
data = array([[1.766, -1.765, 2.576, -1.469, 1.69]])
{{form.name()}}
handle_last_line(previous)
array([[1.0, 4.0], [2.0, -1.0]])
[bins[k] for k in np.searchsorted(bins, my_series)]
stack.pop()
shape = [x.size for x in output]
dct = obj if isinstance(obj, dict) else obj.__dict__
self.mainLayout.addWidget(self.scroll)
tree = dict()
a[:, (b)].T
_diff -= timedelta(days=1)
self.tin2.SetLabel(self.tin.GetValue())
integral = scipy.integrate.nquad(f, ([-d / 2, d / 2], [-d / 2, d / 2]))[0]
h2 = hyst(y, -0.5, 0.5, True)
y = np.array([2, 1, 5, 10, 100, 6])
p = mp.Pool(processes=4)
[5, 6, 7]
bp.show()
soup = BeautifulSoup(s)
callable(obj)
yaml.dump(d, default_flow_style=False)
np.allclose(a, collapse_dims(a))
print(jsons_data)
byteString = bytes.astype(np.ubyte).tostring()
plt.figure(i + 1)
reactor.run()
thread.join()
w = Tkinter.Tk()
t = numpy.linspace(t_start, t_end, t_len)
canvas.itemconfig(item, fill=self.on_color)
ax2.set_xlim(-5, 5)
shutil.copyfileobj(sys.stdin, sys.stdout)
pprint.pprint(result)
elements.extend(namedElements)
A = A.view(dtype=np.float64)
print(square(double(Maybe(5))).unwrap())
Data[..., (0)] + 1j * Data[..., (1)]
X.append(x)
APPLICATION_ROOT = path.abspath(path.dirname(__file__))
locale.setlocale(locale.LC_TIME, l)
m.show()
mailServer.login(login, password)
d.foo()
x.T
im.size
print(user.addresses)
transport = ssh.get_transport()
signal.signal(signal.SIGINT, handle_signal)
leftdigits = self._exp + len(self._int)
li2.extend(sublist)
fd.write(t)
print(df)
some_code()
myView.setItemDelegateForColumn(columnNumber, myItemDelegate)
main()
self.register_errors(result)
f2.write(line)
shutil.copy(str(self), str(target))
result
map(complex, c)
self.hof[0].reshape(self.N, self.N), log
self.d[num] = d[num] + 1
mydict[repr(key)] = mydict[key]
array_by_hand.tostring() == array_from_layers.tostring()
list.__setitem__(self, i, 10)
self.data = np.append(self.data, row)
tmp_dlls.append(os.path.join(cdir, dll))
cur = self.connection.cursor()
SimpleHTTPServer.SimpleHTTPRequestHandler.do_GET(self)
True
df2.reindex(df1.index, level=0)
acc[0]
kNN_classifier(train_data, k, distf)
new_list = []
NotImplemented
seen = set()
capture = cv2.VideoCapture(0)
wx.Panel.__init__(self, *args, **kwargs)
cv2.polylines(vis, [corners], True, (255, 255, 255))
print(cache1.value.groups())
layout = QHBoxLayout(self)
foo.__defaults__
self.write(prompt)
counter = counter + 1
a, b, c, d = unpack_list(*sub_list)
print(convert(0))
5, [False, True, False, False]
self.checkWeight()
lim = ax2.set_xlim(0, repeat_length)
isclose(1, 1.00001)
ax = fig.add_subplot(111)
exit(0)
plt.ion()
Interleave(A, B)
encoded_str = json.dumps(data)
uniquekeys.append(k)
ImageQuerySet(self.model, using=self._db)
data = get_data()
method(*args, **kwargs)
self.button.clicked.connect(self.start_thread)
logger = logging.getLogger()
db = create_session()
float(n) / (1 << p)
print(x)
QtGui.QFrame.__init__(self, parent)
i += 1
indices = np.arange(y.shape[0])
self.children = []
self.server.sendMessage(message[::-1])
diff[y, x] = img2[y, x] - img1[y, x]
filehandle.seek(-1, os.SEEK_END)
b = np.roll(b, shift[j], axis=0)
integers = [int(x) for x in fileStr if x.isdigit()]
data = f.read()
Z2 = mlab.bivariate_normal(X, Y, 1.5, 0.5, 1, 1)
mcastsock.bind((mcast_addr, port))
myDate = forms.DateField()
file.close()
self.update(*args, **kwargs)
req = urllib.request.Request(url=url, data=request_data, headers=headers)
self.canvas = FigureCanvasQTAgg(self.figure)
proc.join()
O(n)
foo.__code__.co_consts[1].co_consts[2]
examined_modules.append(calling_module_name)
df = pd.concat([s, rolling_dd], axis=1)
y2 = np.random.rand(10) * 20
unique_list = list()
f.seek(1, 1)
~np.isnan(A)
afile.close()
add5(4)
log_handler.setFormatter(formatter)
db.session.add(self)
days, hours, minutes, seconds = seconds_to_dhms(seconds)
GL.glViewport(0, 0, 200, 200)
_cell.style.font.bold = True
main()
True
print(df.loc[list_of_values])
base.all()
dis.dis(lis[2])
x = [((2, 1), (0, 1)), ((0, 1), (2, 1)), ((2, 1), (0, 1))]
filehandler.close()
[objid_to_idx[id(obj)] for obj in lst]
cur.execute(sql, (pyodbc.Binary(data),))
self.sizer.Add(self.lblname, (1, 0))
list(splitclusters(a))
form.tags.process(request.form)
map(operator.add, A, B)
print(p.map(minimize, args))
filecount += 1
self.result.append(word)
result = [lines[0][x] for x in unique0] + [lines[1][x] for x in unique1]
HttpResponseRedirect(e.response)
print(len(s))
print(expandtabs(input, 10))
im.thumbnail(size, Image.ANTIALIAS)
path = request.get_full_path()
b.pack()
array([1, 2])
s.shutdown(0)
ax = fig.add_subplot(1, 1, 1)
memcache.set(request.my_name, value)
bar.set_alpha(0.8)
xlim(0, 10)
list()
listener.join()
result[index] += 1
print(args)
self.s_out.close()
b = [4, 5, 6]
plt.figure(1)
df = df[df[group] != group_name]
ax.add_patch(patch)
response = urllib.request.urlopen(req)
imnew = scipy.misc.toimage(datanew)
id = db.Column(db.Integer, primary_key=True)
z = np.outer(np.cos(theta), np.ones_like(phi))
app = Flask(__name__)
lay = QtGui.QHBoxLayout()
N = len(list_of_lists)
x + x
token.get_access_token(code)
output.close()
eggs = iplocation
logging_test()
foo = [(a + 42) for a in foo]
response = conn.getresponse()
os.unlink(f.name)
new_df = my_instance.load_dataframe()
ifconfig
{{other_content}}
NULL
fig = plt.figure()
print(newDict)
timer1.start()
user = request.user
reader = csv.reader(f)
x = np.random.randint(0, 10, size=(10, 2))
font = ImageFont.load_default()
response = mechanize.urlopen(request)
update(message)
s = stru()
C = np.linalg.eigvals(B)
c = pd.read_csv(StringIO(s))
np.mean((np.dot(X, W) - y) ** 2) + alpha * np.sum(np.abs(W - W0))
features_it = itertools.chain(*(iter(c.keys()) for c in data.values()))
csr_matrix(M1).dot(M2)
stdin = sys.stdin
print(m.as_string())
np.unique(np.concatenate((a, b)))
totaldict = defaultdict(list)
{4}.issubset(chain.from_iterable(x))
grid.fig.set_figwidth(6)
word.Repaginate()
a = [0] * 8
iszero = df.amount.values == 0
df
saved_result = GroupResult.restore(result.id)
min(triplets, key=distance)
numpy.random.shuffle(data)
a.todense()
1 + 1
dests.add(node)
mtext = m.group(1)
cities.append((city.name, int(distance)))
pygame.display.flip()
wn.synsets(word)
outdict = collections.defaultdict(list)
print(i)
func(value)
outputStream.close()
self.autocomplete(-1)
self.de = QtGui.QPushButton(str(self.current))
xy[:, (1)] > 0
test()
nltk.download()
a = np.random.random_integers(2, size=(4, 4))
z / (1 + z)
plt.contour(Y, X, T[:, :, (round(len(z) / 2))], 64)
assert my_round(9.76) == 9.75
self.show()
colors = np.linspace(0, 1, len(patches))
plt.pause(1)
module = loader.find_module(module_name).load_module(module_name)
lowestsumsdict = {}
np.array([d[x] for x in u])[inv].reshape(a.shape)
[10, 10, 9, 7, 4]
c += a + b
pairs_by_number_and_list[pair[1]].append(pair)
t = Timer(10, lambda p=p: p.terminate())
offset = cet.utcoffset(dt)
f.write(text)
dat = pd.DataFrame(np.random.randn(5, 5))
d = defaultdict(dict)
pylab.show()
root = Tk()
book.save()
f()
print((sectorsPerCluster.value, bytesPerSector.value))
result[i] = cpmethod(i)
dir(int)
x = np.reshape(x, (4, 4))
print(type(img))
matches.append(m.group(0))
ax.yaxis.set_minor_formatter(matplotlib.ticker.FormatStrFormatter(format))
k = np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]])
self._data = data
DEBUG = True
self.send_my_headers()
mailServer.starttls()
img = PhotoImage(width=WIDTH, height=HEIGHT)
s.listen(backlog)
max_len = len(seq) / 2
module = __import__(k)
atexit.register(shutil.rmtree, test_area)
hops.insert(0, url)
aware = datetime.datetime(2011, 8, 15, 8, 15, 12, 0, pytz.UTC)
user = models.ForeignKey(User)
root = gtk.gdk.get_default_root_window()
ps.line(lineFrom, lineTo)
self.assertEqual(expected, list(map(str, sorted(versions))))
tuple(mydata.transpose())
self.out_queue.put(result)
holtwinters(y, 0.2, 0.1, 0.05, 4)
l = logging.getLogger(__name__)
response
a = np.random.randint(2, size=(10000, 100))
basedir = str(os.path.abspath(os.path.dirname(__file__)))
urllib.request.HTTPSHandler.__init__(self)
time.sleep(1)
ws.set_vert_split_pos(1)
layout.addWidget(self.button)
parser = argparse.ArgumentParser()
app.register_blueprint(routes)
df1
output
fig = plt.figure()
mypalette = im.getpalette()
p1.wait()
data = numpy.array([[0, 0, 1, 0, 1], [0, 1, 1, 1, 0], [1, 0, 0, 0, 0]])
remove(file_path)
pr.disable()
t = datetime.now()
df[col] = df[col].shift(periods)
assert my_now() == datetime.datetime(2000, 1, 1, 12, 0, 1)
keys = {k for d in all_dicts for k in d}
today = datetime.date.today()
self.addLine(0, yc, width, yc)
UDBG.enable_pdb()
signif_lastdigit = int(signif_digits[-1])
int((time.time() + 0.5) * 1000)
data = fin.read().splitlines(True)
a[::-1]
twitter = Twython(APP_KEY, APP_SECRET, OAUTH_TOKEN, OAUTH_TOKEN_SECRET)
b = np.matrix(np.ones((2, 4)))
salt = str(random.getrandbits(256))
seq_in[:] = (x for x, k in seq)
n_to_N = n * np.eye(n - 1) - np.diag(np.arange(n - 2, 0, -1), 1)
widget1.grid(row=0)
G = nx.Graph()
im.size
ax.grid(False)
browser._wait_load()
plot(x, y2)
a / (sqrt(2) * inverseErf(P))
mask = np.random.uniform(size=(4, 4))
fn(**kwargs)
time.sleep(self.sleep_time)
points.append((xs[i], ys[j], v))
self.root.after(10, self.Inputs)
{(0): 0, (1): 1, (2): 2}
metadata = MetaData()
text = file.read()
p = Pool(4)
B -= B.mean()
[(i[1:] * int(i[0]) if i[0].isdigit() else i) for i in l]
False
print(bisect(list_, item))
fig, ax = subplots()
net.sortModules()
line = proc.stdout.readline()
fullname = os.path.join(dirpath, fname)
np.array_split(x4D, x.size / (p * q), axis=0)
np.array_split(x2D, x.size / (p * q), axis=0)
next(self._it)
Series(result, index=labels)
stdout.flush()
p.terminate()
mylist.extend(get_more_data())
demo = [[0] for _ in range(2)]
app = Flask()
output += os.read(fd, 4096)
lowercase_letters = [c for c in s if c.islower()]
ax = plt.gca()
l = [0, 0, 1, 1]
obj.foo.__func__ is Cls.foo
clf.set_params(**grid)
nn.activate([0, 1])
query = query.decode(charset) % escaped_args
self.__dict__.update(x)
c, a = s.accept()
D = np.delete(np.arange(np.alen(A)), C)
print(a.get())
asymmetric_enc(session_key, pubkey), symmetric_enc(message, session_key)
B_process.wait()
ax = plt.gca()
response = urllib.request.urlopen(req)
runner.run(mySuit)
print([x for x in list_dirs if os.path.basename(x) not in unwanted_files])
dt.year
raise StopIteration
nonzero(r_[1, diff(st)[:-1]])
s.str[:2]
ax = plt.gca()
count[word] = 1
show()
df
print(escaped_string)
newser.plot(ax=axes[0])
input = PdfFileReader(packet)
[DRIVER_ISSUE]
reader.Update()
dict((key, round_floats(value)) for key, value in o.items())
[2, 2, 1, 1]
sys.stdout = unbuffered
inspect.getgeneratorstate(a)
ax2 = ax.twinx()
self.application.save()
list(islice(iterable, n))
print(inputoutput[ii])
res = df.astype(bool).astype(int)
obj = MyClass()
ndx = orig_indices[numpy.searchsorted(xs[orig_indices], ys)]
h2, l2 = ax2.get_legend_handles_labels()
images = scrapy.Field()
all(c in string.printable for c in hello)
print(item)
myX, myY = text_center[0] - width / 2, text_center[1] + height / 2
print(repr(b))
time.sleep(10)
urllib.request.install_opener(opener)
self.window.show()
s.values
all(A[p] < A[i] for i in get_neighbors(p, len(A)))
app = Flask(__name__)
self.file.flush()
d = datetime.date(2011, 9, 1)
t.setdefault(keyList[-1], value)
do_something_with_o(r())
toAdd = xyzCoord[i][:]
(lambda d: lambda : self.root.change_directory(d))(d)
print(segment.min(), segment.max())
df1 = df.copy()
print(is_png(data))
l = [1, 5, 7]
do_something()
server.socket.close()
hash2 = hash2.hexdigest()
self.button.draw()
True
file = os.path.join(temp_path, baseFile)
self._x == other._x and self._y == other._y
y = sparse.csr_matrix([[0, 1], [1, 0]])
results = []
print(key_val, key_val.etag)
doc = lxml.html.parse(res.content)
glClearColor(0.0, 0.0, 0.0, 0.0)
file_a.write(new_a_buf.getvalue())
plt.close()
image = image_response.read()
a_list = [f(i) for i in a_list]
ranges[:, (1)] - ranges[:, (0)]
row = cursor.fetchone()
a.append([])
print(save_virtual_workbook(wb))
deq = collections.deque(list(range(100)))
alist = [0, 0, 0, 0, 0, 0, 1]
sum_sum_digit(1969)
fig1 = plt.figure()
parse_qs(urlparse(url).query, keep_blank_values=True)
self.myq.put(THEEND)
Dy = cv2.Sobel(image, cv2.CV_8UC1, 0, 1)
df.Seatblocks
print(l)
start + timedelta(seconds=random_second)
st[:i + 1]
foo.bar - foo.baz
doc = html5parser.fromstring(body)
gb = df.groupby(col)
f(v)
root = Tk()
renderer = gtk.CellRendererText()
self.removeItem(line)
raise FileNotFoundError(filename)
self._from2scomplement(self.__next__)
do_something_with_stdout(line)
plt.xticks(np.array([]))
graphs_sizer.Add(chart_canvas, 20, flag=wx.EXPAND, border=5)
urlopen(req)
i2 = getIfromRGB(colr1)
self.sizer.Layout()
plt.hist(random(1000), 100)
df = df.ix[:, :1]
thing.close()
setattr(module, symbol, obj)
x[-1] = binascii.hexlify(x[-1])
[1, 10], [1, 10]
System.out.println(sum)
cam = pmb.expanding(min_periods=1).apply(lambda x: x.argmax())
print(x, y)
stdscr = curses.initscr()
self.stack[-1] += 1
name = models.CharField(max_length=200)
K = np.arange(n - 1)
lens = np.array([len(i) for i in ll])
data = json.loads(line)
torfile.add_node(node)
stack[0]
control_frame = my_bytes[0] & 128
data
data = chunks[-1]
DT.time(hour, minute, second, microsecond)
zipped.sort()
foo(20, 4)
raise KeyError(key)
x = dict([(k, list(l)) for k in range(1000)])
cur.close()
b.f()
dfs.append(df)
conn.close()
print(_.strip())
s = cv2.SURF()
Food._meta.get_all_related_many_to_many_objects()
width = int(cv.GetCaptureProperty(cap, cv.CV_CAP_PROP_FRAME_WIDTH))
mylist = [(a, b), (c, d), (e, f)]
Z1 = mlab.bivariate_normal(X, Y, 1.0, 1.0, 0.0, 0.0)
self.item = item
n1 = dt.datetime.now()
self.load_data()
diffs = dict((k, k2.index(k) - k1.index(k)) for k in dict1)
fig = pylab.figure()
self.create_dummy_request()
p.start()
d = {v: [i for i, x in enumerate(materials) if x == v] for v in set(materials)}
next(a)
d[text_idx, np.arange(len(text_idx))] = 1
l.insert(i, Y)
print(result)
array[idx - 1]
fcntl.fcntl(s, fcntl.F_SETFL, os.O_NONBLOCK)
nx.path.bidirectional_dijkstra(G, 1, 5)
print(C(1, 2).__dict__)
func(**kwargs)
worksheet1 = workbook.add_worksheet()
[hex(x) for x in e]
process(line)
driver = webdriver.Firefox()
fig = PLT.figure()
admin_objects = UserAdminManager()
fun(args)
a[::2]
type(x) == my.object.kind
r[i, j, x[i, j], y[i, j]] = c[i, j]
print(fun1(1, 2))
counts = Counter(word for line in f for word in line.split())
provided.add(item)
d.addCallback(lambda _: reactor.stop())
self._array[self._index[index]]
now = datetime.now()
main()
im.load()
ZZ[t]
c = a.copy()
[0, 1, 1, 1]
os.fchmod(fd.fileno(), mode & 4095)
Base.metadata.create_all(bind=engine)
getattr(p, s)
x = [elt[0] for elt in y]
ax.set_xticks([1.5, 4.5, 7.5])
dict_x[key] = [value]
self.x1, self.y1 = _rot(self.x1, self.y1)
sio.truncate(0)
font.setPointSize(10)
cmap_lin1 = cm.jet
ISLAND_SLEEPING = _ISLAND_SLEEPING
Window.pack()
plt.ylim([log10(0.1), log10(10)])
b = np.zeros((n_b, n_b), dtype=a.dtype)
time.sleep(0.01)
len(file_content) > 0
y = points[:, (1)]
fourier_trans = numpy.fft.rfft(y) / 1000
df
model = create_model()
print(sum_shells(b))
matching_lines = list(filter(filter_func, string_list))
dt = mytz.normalize(mytz.localize(dt, is_dst=True))
False
dt_my_tz = dt_aware.astimezone(tz)
phone = models.CharField(max_length=100)
print(data.values[np.in1d(data.ages, desired_ages)])
plt.subplot(6, 6, i + 1)
decoded = cipher.decrypt(base64.b64decode(encoded))
reactor.listenTCP(8080, site)
Y = np.random.normal(size=(10, 5))
renL.SetActiveCamera(cameraL)
pclose(helper)
[list(a), list(b)]
win.addstr(0, 0, root)
cert = OpenSSL.crypto.load_certificate(OpenSSL.crypto.FILETYPE_ASN1, key)
sys.exit(1)
p = mp.Process(target=some_long_task_from_library, args=(1000,))
ax.plot_surface(x_surf, y_surf, z_surf, cmap=cm.hot)
foo = timeit(foo)
dict(string)
python_exe = sys.executable
img = erode(img, kern_size)
output = np.empty(indices[0].shape)
pivots = zeros((n,), fortran_int)
i = np.arange(len(pts))
result[i] = cpmethod(cpargs)
new_strs.append(x)
a = numpy.arange(1000000)
plt.xlim([log10(0.1), log10(10)])
frame.pack(fill=BOTH, expand=1)
sum(dct.get(k, 0) for k in lst)
config = configparser.ConfigParser()
ebks, ks
tree = ET.parse(file_path)
print(x.reshape((1, x.shape[0])).type)
ax.set_xticks(np.arange(AUC.shape[1]) + 0.5, minor=False)
args = sys.argv[1:]
d1 += timedelta(days=mdays)
b = np.random.rand(6, 5)
print(ddiff)
d = xml.sax.parse(PseudoStream(), SAXHandler())
self.assertEqual(6, s)
window.show()
foo.method2(foo.method1)
self.set_default_size(100, 100)
help(combinations)
destination = os.path.splitext(imagePath)[0]
ax = fig.add_subplot(1, 1, 1)
plt.plot([1, 2], [1, 2])
x = np.arange(1000)
queue = Queue()
self.assertTrue(any(set(lst) <= e for e in self.merged))
104.405 - -hochl
5.018 - -katrielalex
tcpSerSock = socket(AF_INET, SOCK_STREAM)
dis.dis(f)
settings.configure()
bus = dbus.SessionBus()
x = np.random.normal(0, 1, 1000).cumsum()
NP.insert(T, 0, c, axis=1)
ax.draw_artist(line)
data_cols = list(df1.columns)
df = pd.DataFrame(data)
myseries_three.iloc[0]
[syndication]
file_open.close()
g = Github(token)
plt.yticks(np.arange(0.5, 10.5), list(range(0, 10)))
print((step, sess.run(W), sess.run(b)))
app = QApplication(sys.argv)
time.sleep(60)
print(url1, url2)
i.interact(message)
y_list = numpy.random.random(200)
event.ignore()
a = np.zeros((100, 100, 10))
name = forms.CharField()
lfun
checkbox = driver.find_element_by_id(id)
self.mySub()
repo.commits
aMethod.__code__.co_varnames
traceback.print_stack()
instance = MyClass()
choices = Choice.objects.filter(poll__in=polls)
original = Image.open(test_image)
[1, 2, 2]
0
CALLBACK(func)
self.model.query
print(A.indptr)
browser.select_form(nr=1)
logger = logging.getLogger()
answer = [i for i in range(1, 1001) if isSumOfSquares(i ** 2)]
streamdata = child.communicate()[0]
hexagon(50)
A * exp(-(x - mu) ** 2 / 2 / sigma ** 2)
r.content
print(arr[(cond), :])
B = np.concatenate((A, A), axis=1)
celery = Celery()
sent = sock.send(msg[totalsent:])
func
im = np.asarray(Image.open(filename))
restart_line()
a = float(x)
1 / 1024.0 / 1024.0
possibles = [x for x in remaining if x[:1] == start[-1:]]
dir(object)
int(s)
app
s = serial.Serial(5)
setattr(instance, attr, value)
df.a.quantile(0.95)
self._value + n
sorted_stuff = sorted([(ord(x[0]), x, y) for x, y in list(d.items())])
PorterStemmer().stem_word(word)
[0, 1, 1]
rows.append(row)
test = this_friday + timedelta(weeks=-1)
select.select([sys.stdin], [], [], 0) == ([sys.stdin], [], [])
self.pubsub.close()
print(result)
s.translate(str.maketrans(dict.fromkeys(rem)))
propdict[attrname] = getattr(a, attrname)
stopButton.pack()
sys.stdout.write(output)
items.append(item)
root = Tk()
print(v.__dict__)
print(f.as_integer_ratio())
a = date(2011, 11, 24)
fo.close()
ax.set_rgrids(list(range(1, 6)), angle=angle, labels=label)
num = float(num)
foo = MyClass()
self.scrollbar = Scrollbar(self.data, orient=VERTICAL)
Clock.schedule_once(self.set_attributes)
print(offs)
x = np.linspace(-2, 2, num=20)
print(np.asarray(curve.intersection(hline)))
self.request = request
conn.setopt(pycurl.VERBOSE, True)
xdiff = line1[0][0] - line1[1][0], line2[0][0] - line2[1][0]
df
self.children.append(myChild(name, self))
self._result_queue = result_queue
a = bytearray(5)
child_midpoints.append(child_end + width // 2)
setOverlays(cfloats)
show(layout)
x, y = [[] for x in range(2)]
plt.grid(True)
pyi = points[i, 1]
print(item)
end = datetime.datetime.combine(today, end)
x = np.random.random(10)
id = np.append([0], np.any(np.diff(sorted_Ar, axis=0), 1).cumsum())
pre_save
BaseObject._initialize()
x, y = ogrid[0:img.shape[0], 0:img.shape[1]]
pkcs11.load(libacospkcs)
existing.merge_result(task_from_json(slug, **task) for task in taskdata)
words = sentence.split()
print(a.parent)
x * (a + d + g) + y * (b + e + h) + z * (c + f + i)
colorama.init()
event_box.window.set_cursor(gtk.gdk.Cursor(gtk.gdk.HAND1))
L.sort()
pp.plot(ar)
stream_matrix_np = np.random.uniform(0, n ** 2, size=(n, n))
parser = argparse.ArgumentParser()
f = func()
wn.ADV
wn.VERB
self.conn.commit()
y = np.random.randint(0, 10000, size=5000000)
largest, second_largest, third_largest
print(list(sub_findre(s, substring, 2)))
to_product.append([(k, v)])
tmp = ax.transData.transform([(0, 0), (1, 1)])
slice = myarray[..., (i)]
tasks_q, results_q = multiprocessing.Queue(1), multiprocessing.Queue()
isitIn(char, aStr[:len(aStr) // 2])
db_thread.start()
psyco.full()
email = Column(String, unique=True)
ax.set_xlim([0.1, 0.8])
dis.dis(foo.__code__.co_consts[2].co_consts[2])
dest.write(line)
pd.to_datetime(date_time)
app = Flask(__name__)
dominated = []
C = [B.popleft() for _i in range(4096)]
z = itertools.chain(x, y)
qSQLresults = cursor.fetchall()
do_some_ather_thing()
p = PatchCollection(patches, cmap=matplotlib.cm.jet, alpha=0.4)
image = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)
v[:, (0)]
args = parser.parse_args()
print(df1)
sleep(2)
user_ = User.objects.get(pk=1)
edges[i, j + 2].append((i, j - 2))
top = tk.Tk()
sys.exit(1)
os.remove(os.path.join(root, name))
xy = line2d[0].get_xydata()
b = a[:5, :5]
data = np.random.random((10, 10))
data = f_input.read()
Parent.__init__(self)
main()
num_fatals += 1
a = 0
plt.imshow(lab)
awesome_dict
clf()
df_a.join(df_b)
globals()[name] = value
b = np.zeros_like(a)
desired_list = [x for x, _ in tuple_list]
driver = webdriver.Firefox()
EXTRA_DIST = myext.h
ax.set_xticks([])
print(self.name)
logging.basicConfig(level=logging.INFO)
b[:, :, (0)]
array([1]),
list_b = [5, 6, 7, 8]
line = input()
cls
run_initialization_stuff()
logger.addHandler(hdlr)
fd = sys.stdout.fileno()
date(2011, 1, 15) - date.today()
print(hex(agency))
c = threading.Thread(target=consumer, args=[q])
sys.getrefcount(astrd)
axis([0, 25, 0, 10])
Results.objects.saved_once().all()
address = models.CharField(max_length=200)
lines = fp.readlines()
start_date_monday = start_date - datetime.timedelta(days=start_date.weekday())
p.join()
nickname = request.user.profile.nickname
d = defaultdict(lambda d=d: d)
print((i, j))
len(counts)
content = models.TextField
p = kde(x)
r = csv.reader(file_b)
d = datetime.datetime.utcnow()
set(chain.from_iterable([word.lemma_names() for word in synonyms]))
pl.show()
print(np.mean(l))
print(xyzzy)
v_box.addWidget(self.box_one)
func(self, *args, **kwargs)
self.f.write(data)
assert b.x == 2
ii = np.nonzero(y)[0]
peers[i].send(chunk)
list(chain.from_iterable(summ_neg(x)))
SOCIAL_AUTH_GOOGLE_PLUS_USE_DEPRECATED_API = True
d = defaultdict(list)
b = np.where(a == 9)
gx, gy, gz
self.fp = self.file_or_path = file
debug = False
combo.addItems(li)
plt.show()
app.logger.addHandler(logging.StreamHandler())
process.terminate()
time.sleep(1)
c.set_visible(vis)
print(df)
x_ = np.linspace(0.0, 1.0, 10)
listy[1] = [1, 2]
sleep(1)
locals()[name] = a.__dict__[name]
id(1 == 1)
R, C = np.where(mask.T)
funcs.append(lambda x=x: x)
pd.DataFrame(listOfNewRows)
cherrypy.config.update(conffile)
result1 = pd.concat([d1, df1], axis=1)
old_locale = locale.getlocale(locale.LC_COLLATE)
con = pyodbc.connect(odbcstring)
n2 = dt.datetime.now()
handle_line(line)
p.wait()
a = asarray(a)
ax = fig.add_subplot(111)
nrange = np.arange(n)
a, b, c = final(a, b, c)
s.push(10)
self.load_picture()
exp(-(x - mu) ** 2 / (2 * s ** 2))
ylim = ax.get_ylim()
indices = [numpy.where(a <= x)[0][0] for x in b]
match.groupdict()
df
loaded = pickle.loads(dumped)
cursor = connection.cursor()
self.button.setMaximumSize(QtCore.QSize(128, 128))
queryset = Person.objects.all()
obj.get_related_deltas(epk)
[(sum(x) / float(n)) for x in partitions]
fh.write(header)
print(f.method())
code = func.__code__
app.exec_()
any(phrase in text for phrase in word_list)
pd.Series((df.values * (df.columns.values + sep)).sum(1)).str.split()
w2.append(words[1])
not sum([(not i in A) for i in B])
horse_frog
out, err = proc.communicate()
str in [type(entry) for entry in example]
lcl = locals()
B().update()
form = ModelForm(request.POST)
startupinfo = subprocess.STARTUPINFO()
positive1 = positive[:, 1:-2]
user = UserProfile.objects.get(pk=1)
result = pool.map(worker, groups)
self.assertTrue(1 + 1 == 2)
d = defaultdict(lambda : defaultdict(list))
a[0] + a[1] / float(10 ** (int(log(a[1], 10)) + 1))
print(y.shape)
loop.run_forever()
response
print(cmp(list_1, list_2))
order = list(perm)[::-1] + [n]
heapq.heappop(heap)
print(np.random.dirichlet(np.ones(10) / 1000.0, size=1))
p = pyaudio.PyAudio()
hxs = HtmlXPathSelector(response)
nc_new = maskoceans(lons, lats, nc_vars[(len(tmax) - 1), :, :])
ax = fig.add_subplot(111)
HSV_tuples = [(x * 1.0 / N, 0.5, 0.5) for x in range(N)]
lock = multiprocessing.Lock()
entity = query[0]
ret = func(*args, **kwargs)
sum(zip(res, args), ())
a_sps = scipy.sparse.csc_matrix(a)
np.arange(k - i) == ix[:-i]
b = [9, 8, 7, 6, 5]
help(str.replace)
len(read_file(filename))
res = service.cse().list(q=search_term, cx=cse_id, **kwargs).execute()
A.__init__(self)
count = 0
word_len_dict[len(word)].append(word)
parse_with_lxml()
ax.invert_yaxis()
map = random.randrange(1, 10)
datetime.datetime(2000, 1, 1).replace(**fields)
[v for v in list2 if v in list1]
print(mse(model_2_v2.predict(xg_test), y_test))
print(n)
[result.extend(sublist) for sublist in lst]
root = lxml.etree.fromstring(x)
exponent = d.as_tuple()[2]
product = models.ForeignKey(Product)
print(df1)
path = os.path.abspath(sys.executable)
print(num)
oldest = max(people, key=lambda p: p.age)
app = QtGui.QApplication(sys.argv)
f1(f2(*args, **kwargs))
Py_DECREF(str)
raise KeyError(key)
notebook.set_tab_reorderable(child, True)
score = IntegerField(validators=[required])
Fader.update()
print(mention.user.screen_name)
d1_keys = set(d1.keys())
import_array()
mod
Dl = self.angulardist(zcluster)
r.content
line = lines.pop(0)
fig, ax = plt.subplots(1, 1)
self.assertEqual()
csock.close()
xl = pd.ExcelFile(fn)
ax.set_xticks(ind + width / 2)
print(s[sl])
dates = [dt for dt in rrule(MONTHLY, dtstart=strt_dt, until=end_dt)]
server.serve_forever()
d_theano = f_minkowski(x, x, p)[np.triu_indices(nX, 1)]
streng
fn(*args, **kwargs)
instance = form.save(commit=False)
B = np.empty_like(A)
print(combine_dicts(a, b, operator.mul))
window.open(url)
fesetround(FE_TOWARDZERO)
fesetround(FE_UPWARD)
fesetround(FE_DOWNWARD)
ax.add_collection(coll)
mp.complete_upload()
b = a
stmts.append(s)
[y for x in lst for y in untuppleList2(x)]
cmath.sqrt(-0j) == -0j
self.panel = wx.ScrolledWindow(self, wx.ID_ANY)
length = len(input_string)
b = tf.Variable(tf.zeros([10]))
ax.plot(list(range(5)))
ax.mouse_init()
self.line = self.ax.scatter(self.x, self.y)
do_totally_different_thing()
unmatched = list(b)
self.buttonPanel2 = wx.Panel(self)
Test.test_call
self.stream.write(data)
new_list1 = [list1[i] for i in indicies]
indices, vals = zip(*data)
mod.doSomething()
max_index = len(row) - 1
tk = Tk()
rolled = np.roll(y, -1, axis=0)
[4, 5, 6],
setattr(self, item, args_dict[item])
image = cv2.imread(path_to_image, cv2.IMREAD_UNCHANGED)
print([vertex.label for vertex in x])
station = serializers.CharField(read_only=True)
name = Column(String(20))
newdata = newdata.divide(df.sum().sum())
data.append(float(line))
schema_doc = etree.parse(f_schema)
config.readfp(source)
id = db.Column(db.Integer, primary_key=True)
d = d.replace(c, sep)
sqs.meta.client._endpoint.http_session.close()
[(x - 1 - i, n) for i, n in enumerate(range(x))]
a = 2
manager = multiprocessing.Manager()
curl = pycurl.Curl()
print(locals())
fout.write(line)
fixed = s[0:pos] + s[pos + 1:]
MyClass.__dict__ = {}
self._port = port
x = tf.Variable(tf.ones([]))
self.thread = threading.Thread(target=self._wait)
remotezip = urllib.request.urlopen(url)
keyfunc = lambda x: len(x)
print(listD)
K.mean(K.square(y_pred - y_true), axis=-1)
x, y
x, y
print(getSubStrings(a, 2))
assign(subarg, subvalue)
l = np.sqrt(6 * (a + c + np.sqrt(b ** 2 + (a - c) ** 2)))
sys.stdout = sys.__stdout__
df
process_a.start()
b.append(sublist)
b.extend(a)
heappush(self.queue, item)
k.set_contents_from_filename(testfile, cb=percent_cb, num_cb=10)
kOUT[0]
hash.hexdigest()
print(tostring(elem))
t = threading.Thread(target=work, args=(name,))
tf.start_queue_runners()
app = Flask(__name__)
[]
model = linear_model.LogisticRegression()
[5, 8]
slice(start, stop, step)
series1 = np.arange(10)
i += 1
l_o_l = [[int(y) for y in x] for x in list_of_lists]
help(re.sub)
nodeRemovalList = list(filter(in_sphere, nodeList))
pool.map(fn, list(range(10)))
draw.ellipse((25, 25, 75, 75), fill=(255, 0, 0))
deletei
postcount = len(survivors)
x[::-1]
results = []
ax[0].legend()
self.func(*args)
tuples = zip(string.printable, itertools.repeat(0))
a.argmax()
result.append([])
B = numpy.array()
ax.ticklabel_format(useOffset=False)
[1, 0]
df.idxmax(1)
[(u.value, u.meta) for u in set([b, d, f]).intersection(set([a, c, e]))]
model = Sequential()
mainloop.run()
a = np.zeros((nx, nz))
face_list.add((x, a, b))
s.commit()
widget.bindtags((tag,) + widget.bindtags())
self.vtkPolyData.GetPointData().SetScalars(self.vtkDepth)
newlist.append(x)
api = tweepy.API(auth)
pa = pyaudio.PyAudio()
tv.set_search_column(1)
self.x = np.linspace(0, 5 * np.pi, 400)
ceiling_key(d, 4)
2 - (B, C, F, E)
set(l1)
np.dot(output, slicevol) / 2
bool(1)
csv_file = browser.page_source
endpos = text.rfind(bravo)
app = QApplication(sys.argv)
next(other)
writer.writerow([4, 5, 6])
url = db.Column(db.String(2048))
raise ValueError(HELPING_EXPLANATION)
diagonal = np.rollaxis(diagonal, -1)
dis.dis()
ceiling_key(d, 1)
agent_list = [list(ast.literal_eval(line)) for line in f]
first10000 = islice(f, 10000)
my_array = numpy.empty([1, 2], dtype=object)
requests_log.setLevel(logging.DEBUG)
rescaled.shape = newshape
numbers = [1, 2]
queryset = User.objects.all()
contour_info = sorted(contour_info, key=lambda c: c[2], reverse=True)
result.extend(node._values)
print((root, name))
p.join()
(s[i:j] for i in indexes(s) for j in indexes(s[i:], i + 1))
label.set_visible(not win.is_fullscreen)
axes[0].pcolormesh(x, y, z)
[item.upper() for item in arg]
p.poll()
main()
lookup = {n: max((a for a in s if n in a), key=len) for n in s}
QtCore.QThread.run(self)
cv2.imwrite(os.path.join(dirname, name), frame)
np.random.seed(24)
t1 = time.time()
a[:, (non_index)] = b
animals = [Lion(), Tiger(), Bear()]
sys.stdout = sys.stderr
br = mechanize.Browser()
print([list(items) for g, items in groups])
run()
e = a[0:1]
print(count.most_common())
b = a[::2]
result.append(msvcrt.getche())
printcake()
listener.handle_event(event)
print(df)
True
v.append(len(item))
cv2.imwrite(sys.argv[2], skin_ycrcb)
r = np.sqrt(xdist ** 2 + d ** 2)
time.sleep(1)
row[1] = row[1]
app = Flask(__name__)
--nogroup
do_stuff()
print(cob.x)
fig.subplots_adjust(top=0.9)
data = np.fromfile(file, dtype=dt)
result
sorted(enumerate(sample), key=lambda n_v: abs(n_v[1] - pivot))[:k]
self.assertEqual(d1, d2)
ADO.csv
AFG.csv
figure()
data = json.load(o)
logger.log(f.__name__, args, result)
shutil.copyfileobj(f, response)
d = np.diff(np.asarray(a, dtype=int))
map(itemgetter(0), groupby(L))
self.rotate()
dfL = pd.concat([df] * 100)
app.register_blueprint(bp)
y = np.zeros((yt, xt))
scat.set_array(data[i])
self.SetMinSize((100, 100))
twitter = Twython(APP_KEY, APP_SECRET, OAUTH_TOKEN, OAUTH_TOKEN_SECRET)
self.sprockets = set()
b = np.hstack(np.array(b))
f.save()
BaseHTTPRequestHandler.__init__(self, *args)
df.reindex(df.b.abs().order().index)
print(replace_item(lst, to_replace, replace_with))
Table.append(temp)
_func()
d = dict((n, i) for i, n in enumerate(e[0] for e in l))
print(line)
result = urllib.request.urlopen(request)
ipaddress.ip_address(ipv4invalid)
plt.plot(b, a1)
dfB = pd.DataFrame(B)
lr.set_params(params)
xlinear = np.linspace(a, b, num)
x = np.arange(2)
Console.Write(result)
deleteli[i]
print(a[:, (np.newaxis), :].shape)
M = X * A + (W * B).T + Z * G
my_generator.is_just_started
start_time = time.time()
signal.signal(signal.SIGALRM, inputTimeOutHandler)
compact_ranges(comp)
a.sort(numeric_compare)
requests.get(uri)
serial.Serial(dev, *args, **kwargs)
fig.axes.get_xaxis().set_visible(False)
d = {t.tag: {k: (v[0] if len(v) == 1 else v) for k, v in list(dd.items())}}
DOT11_CIPHER_ALGO_WEP40 = 1
print(df)
cv2.circle(vis, (x2, y2), 2, col, -1)
print(self.varname)
df.printSchema()
Py_DECREF(mymodule)
print(root.nodes.node[1].PCDATA)
convert_to_dict(my_dict)
sorted(strings)
my_dict[k] = v
self.root.after(527, self.readSensor)
proc = Popen(cmd, shell=True, bufsize=1, stdout=PIPE)
test_dict = {make_str(10000000): i for i in range(5)}
A[:, :1] = x
fig = plt.gcf()
self.start_urls = get_start_urls()
dmin = dist
free(cfloats)
then = datetime.now() - timedelta(hours=2)
G.add_edge(1, 2)
update_c = tf.assign(c, a.read_value() + b.read_value())
z.close()
plt.xlim((-limit, limit))
fig = plt.figure()
max(curr, subs, key=len)
gevent.spawn(read_stream, p.stdout, stdout)
self.func()
random_frame = pd.DataFrame(x)
addSecurityHeader(client, username, password)
frame.Show()
get_object_or_404(queryset, pk=1)
df
yvalues = 0.1 + np.arange(len(ylabels))
self.cls = cls
content = resp.read()
idx = np.where(indices < arr.shape, indices, clipping_value)
fileobj.write(response.read())
log.setLevel(logging.DEBUG)
blobstore.delete([item.blob_key])
imshow(Iopen)
d = datetime.date(int(y), int(m), int(d))
do_something_6()
self.canvas.mpl_disconnect(self.cid)
_SHGetFolderPath(0, csidl, 0, 0, path_buf)
_Lappend(_normal(0, 1))
random.shuffle(shuffled)
self.buttonPanel2.Show(True)
blank_image.paste(fluid128, (400, 0))
datetime.datetime.now
ax2.bar(dates, list(range(10, 20)))
self._start_worker(pair)
completeset2 = megalist[4:]
print(node.render(Context()))
difflib.get_close_matches
f()
print(value)
sys.modules.update(old_modules)
print(pizza.toppings.all())
cam = Camera()
datam = np.zeros_like(data)
X, Y = np.meshgrid(x, y, copy=False)
pprint.pprint(response)
friendList = friendList.append(self)
ax2.set_ylim(-5, 5)
print(delta.days)
reshaped_X = tf.reshape(X, [-1, 1])
i = int(s, 8)
thread1.join()
l = [0, 2, 4, 5, 9]
True, True, True, True, False, False, False, False, False
mask = np.isfinite(lg)
[True, True, True, True, True],
print(df)
c(a, b)
suite = unittest.TestSuite()
i += 2
a = [list(i[1]) for i in itertools.groupby(data, key=lambda i: i == 0)]
a[a == 0]
label = Label(f, *args, **kwargs)
data = csvfile.read()
button2.configure(command=lambda widget=button2: DoSomething(widget))
file_handles.append(open(file))
json.dumps(object)
con.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)
list2 = list(map(itemgetter(0), grouped))
reverse(view_name, kwargs=kwargs, request=request, format=format)
conn.send(finalLine)
bias = tf.Variable(tf.constant(0.1, shape=[target_size]))
root = tk.Tk()
t.start()
a[(i), :] = line.split()
im = ax.imshow(dat, vmin=0, vmax=2)
keys = [x for x, y in list(dic.items()) if y == maxx]
w.mainloop()
rotated = string[n:] + string[:n]
foo()
result, cursor, more = query.fetch_page(10)
Ihmf = np.expm1(Iout)
print(fmt.format(*row))
print(line)
self._running = False
archive = py7zlib.Archive7z(fp)
d_max = {k: max(d[k]) for k in d}
app.run(processes=8)
r = requests.get(send_url)
houses_in_town = House.objects.filter(street__town__id=town_id)
f(map(rec, iterable))
can_delete = False
value
zs2 = scipy.interpolate.griddata(np.hstack((xs, ys)), zs, points)
time.sleep(2)
df = df.T
plt.rcParams.update(params)
self.__storage.append(p)
data = f.read()
hash(test(10)) == hash(test(10))
stream.write(msg)
application.listen(config.tornadoport)
self.login()
out = a[mask]
fs = [(lambda y: lambda x: x + y)(i) for i in range(10)]
stdin.flush()
print(regx.split(string))
b = a.groupby(level=0).cumsum().groupby(level=0).shift(1)
ax2 = ax1.twinx()
fout.write(line)
process(m)
r.status_code
Base.metadata.create_all(e)
f(1, 0, 1)
print(i, rec_fib(i))
index_list.sort(reverse=True, key=int)
dupl.append(j)
[i.number for i in li]
nrng = np.arange(n)
imgplot.set_clim(0.0, 0.7)
substring in string_
df
metadata = MetaData(bind=engine)
TemplateResponse(request, template_name, context)
xlab.set_size(10)
ylab.set_size(10)
n = sum(1 for line in csv.reader(filename))
G = nx.Graph()
b = [2, 6, 4, 5, 6]
myFunc()
superstrings = set()
ax.set_xlabel(wrap(ax.get_xlabel()), rotation=90)
y_err = np.array([random.random() for i in x])
numpy_array_of_results = func(numpy_array_of_arguments)
response
now = datetime.datetime.now()
li = [-1, -1, 2, 2, -1, 1, 1, 1, 1, 1, -1, -1]
x, y = xs[i], ys[i]
nx.draw_networkx_edge_labels(G, pos, labels=edge_labels)
foo + bar
SHAhash.update(hashlib.md5(buf).hexdigest())
A = np.arange(0, 20.0)
s[0]
a = list(a)
b.extend(c)
np.clip(c, a, b)
parser = ET.XMLParser()
events.sort()
name = models.CharField(max_length=255)
a[0:5:1]
msg.attach(part)
print(a[0, 0])
ax = pyplot.subplot(1, 1, 1)
chambersinreactor, cardsdiscarded
print([next(i2 if x else i1) for x in [0, 1, 0, 0, 1]])
dev = pcap.lookupdev()
MyConcreteClass()
_singleton.foo_func()
MyAbstractClass()
task2 = threading.Thread(target=do_request)
Hvalue = someoperation(Hnodes)
smoothed = np.convolve(data, np.ones(10) / 10)
rotated = list(reversed(zip(*original)))
a.insert(0, a.pop(-1))
not bool(search(strg))
mylist = [True, True, False]
df[col_zscore] = (df[col] - df[col].mean()) / df[col].std(ddof=0)
type(a[1])
request.query_string
s = signal.signal(signal.SIGINT, signal.SIG_IGN)
pickle.dump(object, f)
fig1 = plt.figure()
queryset = ModelName.objects.all()
print(str(table))
ordered_dict = OrderedDict((k, unordered_dict.get(k)) for k in df.Unique_id)
result = _PySequence_IterSearch(seq, ob, PY_ITERSEARCH_CONTAINS)
NULL
this_mod = sys.modules[__name__]
int(s)
django.core.management.setup_environ(settings)
check_matr(b, 0)
self.increment()
fig = plt.figure()
{{group.users}}
f(A)
parse_dates = [[4, 5]],
hxs = HtmlXPathSelector(response)
self.assertEqual(1, 1)
ans.append(letter)
os.mkfifo(pipe_name)
_PyUnicode_NONCOMPACT_DATA(op)
result = getattr(self.contained, item)
paths.append(split[2:-1])
deletea[k]
ax.set_zlim(0, 10)
session = session()
b = pandas.DataFrame(np.arange(1000, 1025, dtype=np.float16).reshape(5, 5))
myFunc(2, 5)
numpy.genfromtxt(*args, **kwargs)
print(i)
gobject.timeout_add(5000, set_mask, win)
cbar.ax.tick_params(labelsize=5)
[1]
2 * a
B[y:y + N, x:x + N]
A = [0, 0, 0, 1, 0, 1]
my_shelf[key] = globals()[key]
permstr
train_test_split(a, b)
byte_array[i] = (val << 16 >> 8 & 16711680) >> 16
self.textinput.bind(text=self.on_text)
set_a - set_b == set_b - set_a
InetAddress.getByName(IP)
df.fillna(s)
fig = plt.figure(figsize=(8, 6))
my_dict = {k: some_func(k) for k in input_list}
print(st[-m.start(1) - len(m.group(1)):-m.start(1)])
proc.wait()
results.extend(tmp_results)
T = np.dot(V, U.T)
QVariant()
w, h = [int(x) for x in next(f).split()]
i += 1
db.BeginTrans()
x = dict((row.SITE_NAME, row.LOOKUP_TABLE) for row in cursor)
full_file_name = os.path.join(src, file_name)
json.dump(dict(value=True), sys.stdout)
func.__code__.co_varnames
output = proc.stdout.read()
pca.fit(df)
result = grouped.agg(combine_it)
s = wx.BoxSizer(wx.HORIZONTAL)
print(row[0 + i:chunckLen + i])
asyncio.run_coroutine_threadsafe(coro, self.loop)
d.utcoffset()
generateFoos()
output = scipy.signal.convolve(signal_in, h)
numpy.all(x == x.T)
f2 = [(2 * x) for x in range(100)]
ori2cent = np.eye(4)
zed = lambda : giveupthefunc()
is_pipe = not isatty(stdin.fileno())
driver = webdriver.Firefox()
self.Count += 1
GEOIP.country_name_by_addr(ip)
np.int(x)
cls.create_table()
InitializeComponent()
request = urllib.request.Request(url)
print(my_data[x], my_data[x + y])
new_x
opener = urllib.request.OpenerDirector()
temp = []
items = [item for item in soup.contents if isinstance(item, bs4.Doctype)]
result = df2.reindex(np.union1d(df1.index, df2.index))
app = QApplication([])
t.create()
layout = QGridLayout(self)
self.__dict__[name] = value
previous_trace = inspect.trace()[1]
set(A) - set(subset_of_A)
fig = plt.figure()
output.close()
xdebug.remote_port = 9000
me = os.getpid()
pylab.imshow(arr)
print(v)
float(strg)
plt.plot(np.arange(10, 1, -1) + i)
data = np.arange(10, dtype=np.int)
session.expunge_all()
time.clock() - start
opener = urllib.request.build_opener()
shortcut.save()
print(first16)
ax.set_xticklabels(empty_string_labels)
np.average(meanNumbers)
sqlContext = SQLContext(sc)
finish()
self.sa = [l[2] for l in L]
os.rmdir(dir)
b.start()
name = Column(String, primary_key=True)
signal = np.cos(5 * np.pi * time) + np.cos(7 * np.pi * time)
tagged.sort(lambda x, y: cmp(x[1], y[1]))
dG.add_edge(word, next_word, weight=maxint - 1)
print(list(fun(iterable)))
list_common.append(a)
loop.run_forever()
conn.Open(dsn)
Z.__init__(self)
self._storage[key].add(word[len(key):])
print(node.render(Context()))
re.sub(pat, replace, txt)
element = np.ones((5, 5)).astype(np.uint8)
name = db.Column(db.String(255), primary_key=True)
zf.write(modfile, os.path.relpath(modfile))
Vx = np.array(X)
w = list(s)
self.im_data_lock.release()
dict(dd)
{}
worksheet = workbook.add_worksheet()
its = {k: iter(v) for k, v in list(mapping.items())}
first, second = tee(f())
dir(l1)
Signature1 = 0
np.random.seed(1001)
z_dense_smooth_bisplrep = interp.bisplev(xvec, yvec, bisp_smooth).T
img.putpalette(palette)
twitter_token = settings.TWITTER_KEY,
x = list(range(1, 10))
reactor.stop()
w2.set_keep_above(True)
cb = plt.colorbar(s)
print(data[index] == values)
G.add_nodes_from(L2)
old_name = settings.DATABASE_NAME
data2 = data1.reset_index()
piv = np.arange(m)
req.send_response(200)
dis.dis(foo)
print(line)
fig, ax = plt.subplots()
dq.append(next(reader))
self.setter(instance, self.name, value)
loop_one = lambda seq: [(lambda el=el: el) for el in seq]
im1.save(tilefilename, self.tiledriver)
sorted(pairs)
r = follow_redirections(r, s)
fn()
(0, 10, 11, 12, 14, 16) == 0, 10 - 12, 14, 16
b = np.delete(a, np.s_[-1:], 1)
strprime += str(x % 10)
deletePoint.__init__
min(a for sub in Q for a in sub)
out = [float(f_interp(XX, YY)) for XX, YY in zip(X, Y)]
oauth_response = urlfetch.fetch(url)
print(months(11, 2010, 2, 2011))
systemtest_1.py
{k: list(v) for k, v in list(ret.items())}
canvas.Canvas.save(self)
len(lst) - i - 1
Base.metadata.create_all(engine)
total_length = sum(len(str(f.get())) for f in fields)
hm.UnhookMouse()
fheader = f.read()
temp.append(0)
day_generator = itertools.cycle(days)
f.baz()
False
specgram(signal)
arrayName.byteswap(True)
s.feed(html)
G.add_edge(2, 6)
df.reindex(ind & ind2).join(df2.reindex(ind & ind2))
fh.readline()
self._age = value
l2 = [4, 5, 6]
my_table.add(tr([th(i, style=header_style) for i in data.columns]))
sys.modules[themodname] = themod
marshal.dump(g.__code__, funcfile)
csv_w = csv.writer(out_file)
primes = [x for x in primes if x == i or x % i]
axes = plt.subplot(111)
plt.xlim(0, 600)
button.grid()
x = np.linspace(0, 100, num)
result[0], result[1]
entity_manager.commit()
sorted(set(x), key=x.index)
my_data
tb = traceback.format_exc()
self._observers.append(callback)
plus(n)
ipList.append(str(IPAddress(ip)))
True
ax = plt.gca()
cur = con.cursor()
other = [x[:] for x in stuff]
assert len(lst1) == len(lst2)
ret.append(t)
np.unique(np.concatenate(x))
soup = BeautifulSoup(html)
fig, ax = plt.subplots()
np.fill_diagonal(mask, 0)
fig.set_size_inches(w, h)
Grid.rowconfigure(grid, y, weight=1)
a, b
view.setModel(model)
self._check_size_limit()
print(map(timestamp, fridays))
other_field = form._fields.get(self.other_field_name)
np.equal(np.mod(x, 1), 0)
con.row_factory = my_row_factory
[(k, sum(1 for _ in i)) for k, i in it.groupby(L)]
mask = np.ma.masked_array(a)
id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
twitter = Twython(APP_KEY, APP_SECRET)
ax = plt.gcf().axes[0]
True
one_week = 7 * 24 * 60 * 60
a = [1, 2]
what_bson_type([1, 2])
start_time = time.time() + 20
ticm = time.clock()
count += 1
s = pd.Series([True, True, False, True])
print(formatdate(timestamp))
zf.filelist.append(zinfo)
hash((self.name, self.location))
cursor = connection.cursor()
item = myset.pop()
Ml
print(df)
passman = urllib.request.HTTPPasswordMgrWithDefaultRealm()
doSomethingWith(instance)
self.mygraph.set_xydata(self.xaxis, self.data[-1])
ns = parser.parse_args()
new_dic = defaultdict(dict)
flipcase | othercommand > ouput.txt
es = ES.Elasticsearch()
good, bad = [], []
f = plt.figure()
self._popup.destroy()
result = []
df
driver = webdriver.Firefox()
print(string)
plt.show()
new_list2.append(i[1])
htmlFile = file.read()
print(hex(id(v)))
master_list = master.readlines()[1:]
prof = webdriver.FirefoxProfile()
popt2, pcov = curve_fit(model, cupper[:, (1)], f2)
x.append(x_center)
y = array([1, 1, 1, NaN, NaN, 2, 2, NaN, 0])
s.add(y)
maxlens = map(len, (max(el, key=len) for el in zip(*x)))
group = map(itemgetter(1), g)
a = numpy.random.randint(100, size=100).reshape((10, 10))
n, mod = divmod(n - len(first), len(digits))
self.assertTrue(ip2.ip in result_ips)
Dummy().a
(i - j) % 9 == 0
[c for c in foo if c not in temp and (temp.add(c) or True)]
trainingData = rawData.map(parseCsvLine)
u, v = np.mgrid[0:2 * np.pi:20j, 0:np.pi:10j]
self.layout = QtGui.QVBoxLayout(self)
rpy2.robjects.conversion.py2ri = conversion_pydataframe
g._group_actions.sort(key=lambda x: x.dest)
print(sorted(L, key=Key))
print(floor(d * 100) / 100)
queue.append([start])
out.write(result)
primes[:bisect(primes, n)]
test.main()
pool.join()
c = func(*args, **kwargs)
answer += s[:-1]
sql.add(customer2)
self.__age
out = list(df.b[final_mask])
synsets = wn.synsets(word)
u = set.intersection(*setlist)
u = random.uniform(0, 1)
deleteseq[index]
x = np.array([-2, -1, 0, 1, 2])
print(diff.total_seconds())
state.commands.update(callables)
words = words[:]
txt.set_color(line.get_color())
df_fmt = pd.DataFrame([fmt], columns=df.columns)
max_logins = db.session.query(db.func.max(User.numLogins)).scalar()
pdb.set_trace()
f.config(width=5)
8
bar = Bar.objects.get(pk=target_pk)
f.write(chunk)
today = datetime.now()
x = np.random.normal(size=(number,))
uniq[index.argsort()]
[factorial(n) for n in nums]
zip(*iterators)
arr[left:right]
metadata = MetaData()
ss.genextreme.fit(data, floc=0)
drives = db.ReferenceProperty(reference_class=Car)
cls.num += 1
deactivate
dict(zip(list(row.keys()), row))
ax = plt.subplot(111)
wrapper
application = get_wsgi_application()
values = numpy.random.randint(6, size=(6, 10))
cv.ReleaseCapture(cap)
df.dtypes
c = dbconn.cursor()
y = keypoints[i].pt[1]
source.clojure
source.cmake
source.coffee
source.disasm
source.dockerfile
source.dosbatch
source.erlang
source.gdbregs
source.gradle
source.groovy
source.haskell
a[ix_(Xinds, Y2inds)]
func(that, session, *args, **kwargs)
old_settings = termios.tcgetattr(fd)
rstring = arr.astype(numpy.uint16).tostring()
event_box.set_border_width(10)
ws.insert_bitmap(file_out, 0, 0)
image[..., (0)] = np.minimum(image[..., (0)], threshold)
cmyk_im
dictionary = json.loads(data.getvalue())
mults.append(int(np.ceil(inShape[i] / finalShape[i])))
plt.bar([1, 2], [4, 5])
root = Tk()
CV_Assert(img.channels() == 1)
entryFrame = Tkinter.Frame(mainFrame, width=454, height=20)
print(compare(expand(a)))
xml.writexml(out)
step = (end - start) / (N - 1)
_.shape
f.close()
x = float(sys.argv[1])
inspect.getsource(f)
fig.show()
fig, ax = plt.subplots(1, 1)
frame.grid_columnconfigure(1, weight=1)
s = requests.session()
df.dtypes
myfuncs[0]()
interned = AwfulHackToGetTheInternedDict()
xyz = np.zeros(x.shape, dtype=dt)
tuple(h - t for h, t in zip(head, tail))
next_emitted.append(name)
self.stepsize = stepsize
inspect.getmembers(Foo, inspect.ismethod)
x1 = x[:, 1:-2]
k.set_contents_from_file(resized_photo)
contents = urllib.request.urlopen(request).read()
self.scrollToItem(self.item(visible.row(), column))
print(enumerate.__doc__)
u = array([array(x) for x in set(tuple(x) for x in input)])
turtle.begin_fill()
list(g)
is_global = remote_conn.recv(1024)
mat_csr[(idxs), :] = 2.0
self.server.server_close()
df1.shape
do_something()
processed_columns = [x for i, x in enumerate(columns) if not_all_zero[i]]
gcc
cmake
setting2 = somesetting
print(sum(x ** 2 for x in lst if x % 2 == 0))
getFoos()
time.sleep(5)
min_value = min(new_array)
df = df[df[c].isin(df[c].value_counts()[df[c].value_counts() > m].index)]
row.append(token)
window = gtk.Window()
lower = tuple(x - 1 for x in lower)
df2.loc[1:] = [list(s1), list(s2)]
long_df = wide_df.stack().stack().stack()
keys.append(k)
y = numpy.array([2.56, 4.79, 6.21])
df.index = df.index[::-1]
br = mechanize.Browser()
updatebins(bins, binsize, x)
f = lambda i=i: i
gtk.main()
a = a - 1
deleteglobals()[name]
[n, m]
full_path = os.path.join(dirpath, filename)
x509 = OpenSSL.crypto.load_certificate(OpenSSL.crypto.FILETYPE_ASN1, der)
f = pd.read_csv(file, index_col=0)
ob.stackoverflow(2)
q = queue.Queue()
result
x * x
f
c = np.vstack(b)
start = time.time()
format(value, spec)
result = f(*args, **kwds)
self.client.close()
tableWidget.setColumnCount(len(entries[0]))
root = etree.parse(f, parser=parser)
d = mat.shape[1]
z = np.zeros((2, 1), dtype=int64)
records = csv.DictReader(f)
ax.scatter(x1, y1, s=100, lw=0, color=[1.0, alpha, alpha])
[0.0, 1.0, 0.0],
x.sort(key=custom_key)
zipfile_ob = zipfile.ZipFile(file_like_object)
thread2.start()
letters.remove(chr(letter))
task.interrupt()
print([(key, median(val)) for key, val in list(data_dict.items())])
ax.set_xlim(-2, 2)
termios.tcsetattr(self.fd, termios.TCSAFLUSH, self.old_term)
a.dot(b)
renWinL.AddRenderer(renL)
self.ax = self.fig.add_subplot(111)
pool = multiprocessing.Pool(4)
self.f.do_it()
a[2:4, 2:4] = 1
log_file.write(line)
sum((i.time_spent for i in self.intervals), timedelta(0))
cv.SetData(image, tiff.tostring())
do_something(line)
c = tensordot(a, b, axes=(0, 0))
self.thread.join()
print(url)
li = st2.split()
_run_finalizers(0)
n = len(G.nodes())
sorted(list(range(len(a))), key=a.__getitem__)
logging.getLogger().addHandler(logChannel)
df
form = ForgotPassword(data=request.POST)
d(10) ** d(10) ** d(10)
dict(zip(a.names, list(a)))
urllib.request.build_opener(proxy_handler, proxy_auth_handler)
ax.semilogy(x)
n
curs = orcl.cursor()
mylist = list(d.values())
assert some_mock_popen.result == result
HTML_with_style(df.head(), style)
regex = re.compile(pattern, flags=re.MULTILINE | re.DOTALL)
print(list(makerange(s)))
dict(keyValList)
self._data.columns.size
[0, 4, 5, 1],
Dx = cv2.Sobel(image, cv2.CV_8UC1, 1, 0)
gtk.main_quit()
fp.seek(i)
print(line)
node = node.getNext()
l2 = l[:c_index]
y_stds = np.array([np.std(y[x == u]) for u in x_unique])
self.data.append(r)
turtle.fillcolor(color)
m.Blit(0, 0, w, h, s, 0, 0)
a, b = next(g)
image = np.fromstring(im_str, np.uint8).reshape(h, w, nb_planes)
cursorObj.connection.commit()
dict(zip(a.names, map(list, list(a))))
help(np.core._dotblas)
print(twrv.join())
ax = fig.add_subplot(1, 1, 1)
groups = groupby(sorted_input, key=itemgetter(1))
xx, yy = np.meshgrid(np.linspace(2000, 2200, 10), np.linspace(540, 740, 10))
B = [1, 2]
print(df.iloc[(0), :])
count += 1
PyObject * PyEval_GetGlobals()
csv_writer = csv.writer(my_new_list)
inlines = [BookInline]
print([sum(aa[i:i + w]) for i in range(len(a))])
request.end()
list(range(args[0], args[1], 1))
sheet.write(cell, value, cell_format)
_draw_point(i, j - 1, fade_amount_i)
self.helpers = helpers
k.set_contents_from_string(out_im2.getvalue())
string_numbers = contents.split()
print(enclosing)
root = tree.getroot()
connection = httplib.HTTPConnection(req.get_host())
slicevol = np.diff(xlinear)
delattr(instance, self.name)
[0, 1, 2, -5, 4, 5, 6, 7, 8, 9]
specgram(signal)
mycoll.insert(stop_dict)
outputStream.close()
iter(input)
np.all(z == x)
gaps = set(str(i).zfill(7) for i in range(1, n + 1)) - set(seq)
profile = UserProfile.objects.get(user=request.user)
sheet.set_clip(pygame.Rect(sprt_rect_x, sprt_rect_y, len_sprt_x, len_sprt_y))
print(line)
print(roundPartial(9.75, 0.1))
print(roundPartial(9.76, 0.1))
plt.xlabel(ax1_label)
lxml.html.document_fromstring(e)
simulate(image, text)
affected_count = cursor.execute(sql_insert, (id, filename))
d[k] = v.lower()
print(e)
self.setCellWidget(row, col, image)
csr_matrix(coo)
pl.yticks(np.linspace(0.0, 1.0, 11, endpoint=True))
plt.plot(yvalue)
sleep(5)
file.seek(-count, 1)
plt.show(block=False)
np.cos(theta, out=x[:, (0)])
threads = [threading.Thread(target=worker) for _i in range(20)]
script2.run(filename)
pool.join()
a = np.arange(10).reshape(2, 5)
round_to(n, 0.05)
dic[k].append(v)
print(x1.dtype, x1.nbytes)
d[k].append(v)
self.num_vertices = self.num_lines * 2
deleteself.dictionary[key]
w.writerow(list(somedict.keys()))
results = Model.objects.filter(pk__in=pks)
writer.writerow(fields)
twitter = Twython(APP_KEY, APP_SECRET)
d = {}
m_1.append(line)
contents = sourceFile.read(BLOCKSIZE)
self.fp2.close()
ang2 = angle(sx2[iseg2], sy2[iseg2])
lines = list(reader)
np.array([[1, 0], [0, 1]]).__array_priority__
x = np.array([1, 2, 0, -2])
monthrange(2012, 2)
sheet = workbook.sheet_by_index(0)
self.button = []
f.write(att.content)
now.microsecond
print(sp.pixel(0, 0))
rows = cur.fetchall()
self.lda[bow]
DOT11_CIPHER_ALGO_TKIP = 2
inputs.append(conn)
name = Column(String(64), nullable=False)
posts = Post.query.all()
f(*args, **kwargs)
entryDate = ensure_datetime(result[5])
np.array(-0.0) == np.array(+0.0)
big_table[nchunks].update({hash: file.filename})
self.process.kill()
imframe = im.copy()
nextelem = li[idx]
wr = csv.writer(your_csv_file, quoting=csv.QUOTE_ALL)
zip(A, cycle(B))
y_range = list(range(-5, 6))
began = time.time()
app = create_app()
non_blank_lines = (line.strip() for line in fd if line.strip())
np.apply_along_axis(wrapper, axis, F)
queue.close()
shpinfo.append(shapedict)
points.set_data(x_c, y_c)
y.__reduce__()[1]
line = sys.stdin.readline()
c[2]
path, folder = os.path.split(path)
todays_files.append(original_file)
hbox = QHBoxLayout()
x = 2
A = A.apply(np.sort, axis=1)
self.CalculatePopularity()
print(item.name, item.birthday)
assert len(kw) == 1
sum_sum_digit(sum_)
root.destroy()
self.mainFrame().load(QUrl(url))
print(sc2().get_subclass_name())
df.dtypes
list(dic.items())
p = figure(plot_width=400, plot_height=400)
show()
ACTIONS = {ONE: value1, TWO: value2}
writer.save()
{{page.title}}
result = collections.defaultdict(int)
[rand_vector() for _ in range(length)]
self.response.out.write(f.read())
self.allowed_domains.remove(hostname)
sector_el = [x[1] for x in remaining]
a = A()
all(x[0] == y for y in x)
self.stdin_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
plt.figure()
updated = request.GET.copy()
yl = list(y)
simplejson.load(f)
grid_sizer_1.Add(self.tree_ctrl_1, 1, wx.EXPAND, 0)
main_loop.start()
objects = InheritanceManager()
func()
new_name()
print(hit.contents[6].strip())
plt.figure()
np.isfinite(diff_images).all()
mock_mail_obj = mock.Mock()
b = np.array([0, 1, 0])
yi = np.array([0.0, 0.5, 1.0])
value[2:4]
alltests = unittest.TestSuite()
np.diagonal(a.dot(b))
ax = np.histogram2d(x_data, y_data, bins=bins)
v = enumerate(printmylist(mylist))
out = np.split(sorted_a, shift_idx)
print(b[0])
[4, 5, 6, 7],
application = app.wsgifunc()
mylist = []
p = figure(x_range=(0, 1), y_range=(0, 1))
reader = PdfReader(input_file)
self.do_open(httplib.HTTPConnection, req)
os.umask(oldmask)
(x >= 0).sum()
np.argmax(aa > 5)
s = str(a).zfill(prec + 1)
self.coconut = coconut
base64.b64decode(data[1])
row_sums = numpy.zeros_like(img)
extmodule.override()
self.c.config(width=w, height=h)
input_file = args[0]
p = multiprocessing.Pool()
tpl = simplejson.loads(jsn, object_hook=_from_json)
cmdutils
assert max_product([]) == 1
json.dumps(f(*args, **kwargs))
plt.xticks(np.arange(0.5, len(df.columns), 1), df.columns)
writer.writerow(row)
self.i += 1
cr.set_line_width(10)
layout.addWidget(self._listview)
unknown = set(self.initial_data.keys()) - set(self.fields.keys())
p.start()
obj.__class__.set_x_class(15)
gc.set_debug(gc.DEBUG_UNCOLLECTABLE | gc.DEBUG_COLLECTABLE | gc.DEBUG_STATS)
session2.merge(obj1)
title[::-1]
pd.Series([timedelta(int(i)) for i in d])
new_x = np.linspace(x.min(), x.max(), new_length)
Y = Y[list(range(n / 2))] / max(Y[list(range(n / 2))])
print(str(newdom))
[(mappend(str(x)) if y else unmappend(str(x))) for x, y in d.items()]
request = urllib.request.Request(url)
tmpdir = str(tmpdir)
print(r.findall(line))
x.append(i * 2)
print(pool.map(f, list(range(10))))
queue.get()
min_idxs = [idx for idx, val in enumerate(a) if val == min_val]
xi, yi = np.meshgrid(xi, yi)
mask = np.isnan(arr)
nx.draw_networkx(gr)
db.init_app(app)
fig, ax = plt.subplots()
x = np.arange(10, 1, -1)
print(link.tail)
func = CALLBACK(lambda x: myPythonCallback(x))
stack.append(msg)
dataAC = ifft(dataFT * numpy.conjugate(dataFT), axis=1).real
resp_dict = json.loads(resp_str)
c = Counter(item for dct in my_list for item in list(dct.items()))
[item for items in zip(first, second) for item in items]
print(parser.format_help())
data = {k: [v] for k, v in list(dr.next().items())}
c._Z15writePixelsRectP8JoxColoriiii(data_array, 0, 0, WIDTH, HEIGHT)
os.stat(fullname).st_ctime
queue.join()
ax = fig.add_subplot(1, 1, 1)
self.progress_bar_lock.release()
a, b = zip(*c)
cd = 1097 * math.pow(ei, 4) / 512
hi_file.write(hi_web.read())
self.rematch = re.match(regexp, self.matchstring)
d = {}
self.ClickedLB2.move(200, 150)
cs = axs[0].contourf(X, Y, zdata, levels=levels)
QWebView.__init__(self)
floatlist = [random.random() for _ in range(10 ** 5)]
print(link.string)
t.cancel()
self.parser = create_parser()
b = a + b
L = [1, 2, 1, 1]
[a.pop(2), a][1]
mock_locations = Location.objects.none()
plt.clf()
keys = {k[0]: (0) for k in list(d.keys())}
self.window = gtk.Window(gtk.WINDOW_TOPLEVEL)
fig, ax = plt.subplots()
sorted(list(kwargs.items()), key=itemgetter(0))
line = line.rstrip()
buffer = buffer_from_memory(y, 8 * array_length)
filehandler.close()
request = self.initialize_request(request, *args, **kwargs)
[7500, 7500]
url = models.CharField(max_length=255, unique=True)
self.l = iter(l)
dense2 = gensim.matutils.sparse2full(lda_vec2, lda.num_topics)
numpy_fillna(data)
pool = Pool()
imshow(im)
findAll(tagname, recursive=False)
print(fmtpairs(list(string.ascii_uppercase)))
a[perm]
parsed_output.close()
start, end = datetime(2015, 11, 2), datetime(2015, 12, 14)
parser = PullSuggestions()
self.assert_equal(mocked_handler.call_count, 1)
notebook = wx.Notebook(self)
content = gzip.GzipFile(fileobj=StringIO(content_raw)).read()
hash((self.value, self.meta))
temp = np.argpartition(-test, 4)
out = np.array([f(i) for i in range(1, n - 1)])
x.a
result = ast.literal_eval(response[1])
inverted_image = PIL.ImageOps.invert(rgb_image)
data = json.load(json_data)
[0, 0, 0, 0, 0],
self.foo()
out[i] = np.count_nonzero(dists < Rsq)
ax.axis([-4, 4, -4, 4])
[1, 1, 1]
ii = np.random.randint(0, 10, (a.shape[0],))
self.flush()
window.show_all()
self.session.flush()
person = models.ForeignKey(Person)
fig = plt.figure()
self.__dict__.update(dict(zip(properties, pslList)))
QtWidgets.QMainWindow.__init__(self)
result_array = f(A)
G = nx.DiGraph()
heappush(heap, item)
np.random.seed(42)
handler = logging.StreamHandler(sys.stderr)
self.successors.remove(other)
self.viewport.add(self.img)
len(get_file_contents(filename).splitlines())
upform = UserProfileForm(instance=user.get_profile())
x[np.logical_and(*b)]
self.func(*args, **kwargs)
dict(id=self.identity, data=self.data)
my_svc.fit(x_training, y_trainc)
s[6]
assert self.test_user.is_active
loginid = line[1].strip()
y, x = np.mgrid[-5:5:100j, -5:5:100j]
df = pd.DataFrame(data)
my_list[0] = my_list[2] = my_list[0] + my_list[2]
triplets[iT].append(listB[0])
ratingsum = sum(ratings)
results = [data[i:i + n] for i in range(0, len(data), n)]
session.add(c1)
user = models.ForeignKey(User)
worksheet.set_column(idx, idx, max_len)
sess.run(init)
id = Column(Integer, primary_key=True)
f()
sys.exit(1)
ax = fig.add_subplot(111)
wrapper(**mydict)
triang = tri.Triangulation(x, y)
itertools.zip_longest(fillvalue=fillvalue, *((iter(itr),) * n))
t.hour * 60 * 60 + t.minute * 60 + t.second
A[j] = (A[j] - factor * A[i]) % q
k = list(d.keys())
a[0][0]
path = os.path.abspath(path)
concatenation.append(selection.pop())
y = ax.get_yaxis().get_clip_box().y1
b_o = tf.Variable(tf.random_normal([input_size], stddev=0.01))
dir(x)
print(np.all(x2[find_map(x1, x2)] == x1))
pl.show()
endfor
time.sleep(1.0)
log.Date = pd.to_datetime(log.Date)
random.uniform(0.1, 2.7)
queue.put(line)
sum(coeff / (i + 1) for i, coeff in enumerate(reversed(coeffs)))
HttpResponseRedirect(post_url)
logging.basicConfig(filename=LOG_FILENAME, level=logging.DEBUG)
display.display(pl.gcf())
result.append(i)
form = UserprofileForm()
rowPosition = self.table.rowCount()
self.root = logging.getLogger()
print(pkl)
surf = pg.transform.rotate(surf, -1)
slice_coords_by_x(arr, xmin=2, xmax=4)
width, height = img.size
char = ord(char)
client = app.test_client()
form = MyForm()
frame.Show(False)
bool(self.match)
output_file.write(l)
seen = set()
next(self)
w = np.sqrt(6 * (a + c - np.sqrt(b ** 2 + (a - c) ** 2)))
a.sort()
df
print(self.recv(8192))
(d.day - 1) // 7 + 1
el2.extend([numpy.nan] * (len2 - len(el2)))
m.groups()
self.command_table[command]()
np.exp(exp_A, out=exp_A)
str(x)
xx, yy = numpy.mgrid[:200, :200]
index = dict(zip(lis, list(range(len(lis)))))
html = template.render(context)
SetValue(reg, pythonkey, REG_SZ, pythonpath)
min(alist, key=lambda x: abs(x - target))
output = popen.stdout.read()
sys.path.insert(0, pth)
down.append(up.pop())
add_to_the_class < AnotherClass > ()
HttpResponse(t.render(c))
arr = np.arange(10)
NotImplementedError
lst = map(int, str(num))
[a], [b]
self.children.append(node)
y = np.rollaxis(y, -1)
a + a
print(f(2))
num_files = float(len(filenames))
unittest.TestCase.__init__(self, methodName)
xs = np.linspace(0, 2 * np.pi, 25)
second_array = array(FFnetlayer[1::2])
self._init_extra(*args, **kwargs)
thelist = list(genreDictionary.items())
cpp.MyClass * _obj
list(group_660.values())
gb.count()
list1[i] = v
map.plot()
[to_nltk_tree(sent.root).pretty_print() for sent in doc.sents]
self.ax.set_ylim(ymin, ymax)
listmix.TextEditMixin.__init__(self)
output = proc.communicate()[0]
lines = f.readlines()
rolled = np.roll(y, 1, axis=1)
gc.disable()
min_distance = distance(min_pair)
itertools.product(iterable, repeat=2)
x.columns = x.columns.droplevel(0)
str(bin(7))
Counter(k for k, g in groupby(strs))
conn = urllib.request.urlopen(url)
ActionChains(context.browser).send_keys(Keys.ENTER).perform()
df = pd.DataFrame()
unittest.TextTestRunner(failfast=True).run(suite)
thread.join()
linesamples = set()
title_tag.string
a.append(i)
result = [C for C in with_distances if C[0] < limit]
my_obj_back = pickle.loads(base64.b64decode(serialized_str))
main()
Queue.get(self, False)
player_thread.start()
arr_list = arr.tolist()
print(s)
plt.show()
group.append(line)
response
client.send(data)
find_green_times(sg_status)
a = numpy.recarray(num_stars, dtype=dtype)
str(path)
print(x)
DEBUG = True
yag.send(contents=message)
already_inserted = all(bitfield)
ftpobj.cwd(dirname.name)
p.i, p
timedelta(**dict((key, int(value)) for key, value in list(d.items())))
last_array = csc_matrix((values, (row_ind, col_ind)), shape=(211148, 211148))
WeakList(list(self) * n)
binary_search([1, 5, 8, 10], 5)
suite = unittest.TestSuite()
stream.close()
mask = (df[0] == 0).cumsum().cumsum()
f
allocate(array(gridsize, gridsize, gridsize))
bynweekday + byweekday
len(cls.__instance)
p = Person()
nose.run()
df
df2
session.add(x)
mean_data = np.append(mean_data, [ur, ua, np.mean(data[samepoints, -1])])
dc.SetBrush(wx.Brush(wx.Color(0, 0, 0), wx.TRANSPARENT))
output.write(output_compressor.flush())
bokeh.io.output_notebook()
print(u, repr(u))
[0.0, 0.0, 0.0, 0.0],
self._value
decompressor = bz2.BZ2Decompressor()
commatoze(s, p + 1)
list[0]
p.close()
logger = logging.getLogger(record.name)
G = nx.DiGraph()
theArray.tofile(f)
img2y = img2.shape[0]
exit(1)
self._close_all_temp_files()
str(self.__dict__)
y_c = np.atleast_2d(func(x_c))
stdscr.addstr(str(i), curses.color_pair(i))
s[start:end]
f2.Show()
Z2 = mlab.bivariate_normal(X, Y, 1.5, 0.5, 1, 1)
s = pd.Series(vals, index=dates)
canvas.saveState()
root = tk.Tk()
[int(x in xs) for x in variables]
self.myfunc(self)
count = multiprocessing.cpu_count()
data.put()
value = models.CharField(max_length=200)
print(a * b)
print(key.name)
pivot = inlist[0]
nav_json = json.dumps(nav_data)
a = A()
MyObj1 = MyModel.objects.all()[index1]
[age for age, person_id in mylist if person_id == 10]
self._coconut = coconut
asyncio.set_event_loop(loop)
data_md5 = hashlib.md5(json.dumps(data, sort_keys=True)).hexdigest()
os.close(fd)
frame.groupby(idx).sum()
self.name = name
text_link.string = text
self.step()
df2
n = len(seq)
q_out = multiprocessing.Queue()
new_tasks.append(result.args[0])
print((cookies, content))
print(my_data)
bar()
clean = [_f for _f in lis if _f]
arr[len_:] = np.nan
turtle.end_fill()
conn = psycopg2.connect(db_conn_str)
cherrypy.quickstart(Band())
p = Process(target=myfunc, args=(child_conn, command))
df1 = df[mask]
F2 = np.array(list(range(N))) / float(N)
print(parser.config.read(parser.files))
main_dir = os.path.dirname(sys.executable)
subplots_adjust(top=0.8)
root = tk.Tk()
print(__name__)
d = collections.defaultdict(list)
y.boom()
sizer.Add(log, 1, wx.ALL | wx.EXPAND, 5)
print(filetime_to_dt(ft_dec))
n = len(s)
plt.xticks(ind + width / 2, OX)
print(A[0])
fd = os.open(filename, os.O_RDONLY | os.O_NONBLOCK)
player = Vector2(player.rect.x, player.rect.y)
my_socket.bind((bind_address, lowest_port))
print(corn + 1)
wrapper
print(n)
key, score = line.split()
print(list(pairs(xs, ys)))
omega = np.exp(-2 * pi * 1j / N)
example = Example()
desired_value = next(value_iterator)
self.builder = Gtk.Builder()
already_inserted = all(bitfield[i] for i in indexes)
len(my_str) != len(set(my_str))
curl.setopt(pycurl.HEADERFUNCTION, hdr.write)
data[:, (0)] = np.random.randint(0, 200, 400000.0)
hoist(e, subexpr(e), c)
app = QtGui.QApplication(sys.argv)
print(driver)
row = row.copy()
crud = Crud(db)
test_ordered_dict = OrderedDict()
y.append(y_center)
f(n)
id = Column(Integer, primary_key=True)
print(A.shape)
print(alist[k], statement.split(k)[1:])
lol = df.values.tolist()
html = lxml.html.parse(url)
masked = np.where(flag > 0, X.T[..., (np.newaxis)], 0)
print(submission)
bpy.utils.register_class(customToolshelfPanel)
fig = plt.gcf()
ax[1].legend()
chosen_templates.append(template_name)
f_output.write(data.translate(reverse_table))
plt.show()
startButton.pack()
restaurant_dish.restaurant_id = restaurant.id
sys.exit(0)
file_contents = re.sub(regex, subst, file_contents)
sys.exit(app.exec_())
print(weights.get_shape().as_list())
sheet.cell(row=r + 2, column=c + 2).value = data_table[r][c]
gmpy.is_square(x ** 7 + 1)
adic[i] = adic.get(i, 0) + 1
GLX.glXSwapBuffers(d, w)
other()
f = interpolate.interp1d(theoryX, theoryY)
part_number = models.CharField(max_length=10)
session = requests.session()
pari.pari_init(4000000, 2)
sel.start()
unsearched.join()
print(repo.name)
smtp.ehlo()
name = models.CharField(name, unique=True)
data_entry.file.save(filename, fid)
a + b + c
a, b
print(sess.run(c))
c = boto.connect_dynamodb()
plt.plot(x, f(x))
item = QtGui.QStandardItem(str(index))
bools = [True, True, False, True, True, False, True]
axis = axis / math.sqrt(np.dot(axis, axis))
filename = askopenfilename()
[(x + y) for x, y in zip(result, self._nmin)]
df_test = pd.concat([df] * 100)
len(self.datatable.columns)
df.groupby(idx2).sum()
reader = csv.reader(file)
version = models.CharField(max_length=10)
self.nametowidget(widget.string)
print(arr.dtype)
Base.metadata.create_all(e)
idict.setdefault(sub_type, {})[sub_name] = sub_dict
self.instance.project_set.clear()
q_out.put((i, f(x)))
cw = csv.writer(si)
func1()
self.data[start:stop].mean()
luns = r.group(1).split()
pool.apply_async(Simulation, (i,), callback=handle_output)
b
df.shape
gtk.Window.__init__(self)
nx.draw_networkx_nodes(Gcc, pos, node_size=20)
True
list1.extend(value)
DEBUG = False
print(type(df))
close_window(iren)
logger = logging.getLogger()
print(depth, traceback.print_stack())
forward(size_length)
{{loop.index}}
type(data)
G.add_edge(i, j)
p.close()
proxy_handler = urllib.request.ProxyHandler({})
{{uform.as_p}}
stime = time.mktime(time.strptime(start, format))
d = datetime.date.today()
tasks = [gevent.spawn(download_file, url) for url in urls]
f.tell()
self.yearLength.get(planetName)
reducedQs
http_packet = str(packet)
halt_thread.start()
send_from_directory(directory=uploads, filename=filename)
self.callback(data)
z[0, 0] = 0
time_updated = Column(DateTime(timezone=True), onupdate=func.now())
update_x([(1,)], (2,))
[(id(x) == id(y)) for x, y in zip(lis, new_lis)]
ax.hist(np.log(np.arange(1, 10, 0.1)), facecolor=color)
nn.activate([1, 0])
rev_bytes = bytes[::-1]
print(df)
nnz = np.prod(partitions.shape)
monkey.patch_all()
cmap = cm.jet
t.start()
time.sleep(0.1)
self.__class__ = GEOS_CLASSES[self.geom_typeid]
show(p)
value = getdict(value)
datetime.datetime.now().strftime(fmt).format(fname=fname)
b = [[] for _ in range(N - 1)]
self.assertEqual(self2.x, SOME_CONSTANT)
print(k)
EVV1 = np.dot(GinvVV, tmp.T)
self.untoggle_mpl_tools()
x = np.outer(np.cos(lons), np.cos(lats)).T
a.hello()
print(minidom.parseString(ElementTree.tostring(tree1)).toprettyxml())
amounts.append(int(multiplier) * float(amount))
Path(__file__).parent
func = classmethod(func)
is_valid = False
keyPub = RSA.construct((seq[0], seq[1]))
r = np.kron(np.arange(ni * nj).reshape((ni, nj)), np.ones((xi, xj)))
time.sleep(rest_time)
True
a = np.zeros(5)
v = np.array([0, 0, 1, 1, 1, 0, 0, 0])
bottle.run(app)
self.projectiles.add(p)
myList = [random.randint(0, 1), random.randint(0, 1), random.randint(0, 1)]
np.asarray(ans)
wx.EVT_TIMER(self, self.timer.GetId(), self.OnExorcize)
cls(newName, s)
imgdata.seek(0)
np.array(result)[::-1]
self.response.out.write(jinja.render(template_path, new_context))
r = parse_timestamp(v)
stack.pop(0)
{l[0]: l[1]}
print(num)
doctest.testmod()
new_dic[1] = {}
dict(ChainMap(*reversed(ds)))
self.NameToInfo[zinfo.filename] = zinfo
[0, 1, 0, 0]
proc = mp.Process(target=handle_output, args=(output,))
mylist = [(0 if x != x else x) for x in mylist]
dc.SetFont(f)
all(np.diff(x) == 1)
app.SetTopWindow(frame)
np.random.seed(0)
frame = rotateImage(frame, 180)
plt.imshow(z)
out.seek(0)
map(func, range(0, L))
result = p.communicate()[0]
int.__add__(self, other)
get_factorizations_of_all_numbers(1, n, 2)
intl = np.ravel(np.column_stack((a, b)))
list(range(0, args[0], 1))
x, y = X
attrvalue.name = attrname
list(it.islice(it.dropwhile(lambda x: x != 4, it.cycle(l)), 10))
literal_eval(obj[1:-1])
a = np.array(mymatrix)
print(response.headers)
int(s[8:16])
random_id = random.choice(list(self.processes.keys()))
np.random.seed(987467)
ax.contourf(DATA[:, :, (i)])
df.loc[max_loc:max_loc + N - 1]
result.append(g[0][-1]) if result else result.append(g[0])
print(string1 == string2)
leftpanel = wx.Panel(self, -1, size=(200, 150))
conn, addr = s.accept()
test(100, 50, 5)
value = value + 1
{k: makedict(v)}
fig.add_subplot(212)
sparse.coo_matrix((sparse_mult(A.T, B, coords), zip(*coords))).tocsc()
print(descend_list)
config.readfp(StringIO.StringIO(test_ini))
cumprobs.append(cumprob)
results = model.fit(train_X, train_Y)
cross_test = np.sign(z[:-1] * z[1:])
file_handler.setFormatter(formatter)
df
stdout.flush()
df[i] = df[i - 100].apply(lambda x: x * i)
numpyMatrix = df.as_matrix()
names = array_type()
f.root.data.append(x)
find_closest(A, target)
ax = fig.add_subplot(111)
a[a == 0] += epsilon
server1.handle_request()
example.test_generic_uint8(numpy.int8(42))
plt.xlim(xmin, xmax)
self.queue.enqueue(line.strip())
root = tk.Tk()
object = MyStatefulModel.objects.get(id=object_id)
subfields = subrec._fields
execlist[index][1] = myctype
[]
PyQt4.QtCore.QPoint(1468, 50)
sunburst(sequences)
getattr(self.func, attr_name)
arrow.now().isoformat()
has_index_in_slice(indices, a, b)
b = a[:-1] + (a[-1] * 2,)
n = len(a)
print(str(proc.communicate()))
print(format_to_re(layout))
logger.addHandler(fh)
self.last_headers = result.headers
9.465419146697968
11.504781467840075
11.625461496878415
9.265848568174988
deletelist[i]
print(x)
pool = ThreadPool(5)
print(help(xyz))
type(a).__module__ == np.__name__
print(foo())
test(100, 5, 11)
np.random.seed(1)
hash(round(6.84, 1))
button = Button(frame, text=b.title(), command=self.callback)
items[1]
print(result)
self.var1 = self.var1 + self.var2
urllib.request.install_opener(opener)
time.sleep(0.01)
df
c = [list(set(sublist).intersection(set(b))) for sublist in a]
p.wait()
tree[parent].append(msg)
DISPATCH()
thedict = dict((k.strip(), converter(v)) for k, v in kvs_restored)
self.result.append(chr(codepoint))
response
print(c.shape)
u = np.linspace(0, 2 * np.pi, 100)
b = numpy.array([x for x in a], dtype=numpy.character)
print(x[max(with_idx)[1]])
J0 = ephem.julian_date(0)
linspace_x = np.linspace(min(x_range), max(x_range), 100)
print(new)
setattr(cls, n, wrapit(cls, method))
sys.tracebacklimit = 0
s.login(login, password)
df.merge(df.drop_duplicates(group_vars).reset_index(), on=group_vars)
func2d(arr1d.reshape((n, m)))
my_list
assert isinstance(string, str), repr(string)
self.finish_progress()
simplejson.dumps(list(people))
print(line)
datachunk = data.file.read(1024)
show()
list(X())
clens = np.cumsum([len(item) for item in contribs])
data = f.read(4096)
dest = os.path.join(dest, filename)
data = r.content
q.get()
Py_XDECREF(g_stdout)
df -= df.min()
{i: (randint(0, 4) + input) for i in range(10)}
client = OSC.OSCClient()
p.wait()
d.append(block)
print(html)
a = np.arange(25).reshape(5, 5)
hex(buffer.rd(0))
ax1.set_xlim(-5, 5)
plt.show()
plt.subplot(152)
sys.stdout.buffer.write(line)
app = QtGui.QApplication(sys.argv)
z[i] = paste0(x[i], y[i])
x /= copy(x[2])
A_r = A.ravel()
start = time.time()
sentences = sentence_splitter.tokenize(text)
ax.yaxis.tick_right()
type(my_decoded_str)
self._pcapw.writepkt(self._ethernet)
width, height
basecost += tax.calculate(basecost, othertaxes[:i])
pymc.close()
fout.close()
thedir = os.path.dirname(thedir)
a[1] = 2
print(f.read())
request_headers[header] = request.META[header]
random.shuffle(a, lambda : r)
font = ImageFont.truetype(fontname, textsize)
arr = np.arange(100 * 100 * 100).reshape(100, 100, 100)
start_time = datetime.datetime.utcnow()
ax.yaxis.set_visible(False)
ff_array = numpy.array(ff_list)
value
arrow2.remove()
f(args[0])
p.kill()
print(df.reset_index(drop=True))
result[-1].append(word)
e.selection_get()
wrpcap(pname, pkts)
numpy.bincount(x[keep], weights=w[keep])
df
data.rename(columns=str.lower)
canvas.showPage()
self.tab.addTab(widget, widget.windowTitle())
y5 = x.astype(np.float64)
result = [([0] * size) for _ in range(size)]
dt + datetime.timedelta(0, rounding - seconds, -dt.microsecond)
base = ndpointer(*args, **kwargs)
sys.modules[().__class__.__bases__[0].__module__].open
set(l1) | set(l2)
True
total += sum(map(int, row))
im = Image.open(filepath)
map.add_child(feature_group)
c = conn.cursor()
thisTable.open(mode=dbf.READ_ONLY)
i += 1
plt.clf()
self.lines.set_ydata(ydata)
remaining = np.cumsum(colors[::-1])[::-1]
notify_another_process()
{{comment | safe}}
tk.Tk.__init__(self)
tf_softmax = tf.nn.softmax(tf.matmul(tf_in, tf_weight) + tf_bias)
self.initialize()
files = list(filter(os.path.isfile, os.listdir(search_dir)))
new_power = [sum(x[1] for x in v) for k, v in groupby(zip1, key=itemgetter(0))]
tlist[max(0, i - 1)], tlist[i]
run(quiet=True)
plt.subplot(224)
http = credentials.authorize(http)
output.close()
n = s.num_constructors()
sorted(sample, key=lambda i: abs(i - pivot))[:k]
-1
last = paw
a = []
items = list(d.items())
inlines = [LinkedItemAdmin]
subprocess.Popen([program] + params)
make_array_proxy(T & array)
self.setHandshakeOp(handshaker)
client = paramiko.SSHClient()
q = Queue()
frame = inspect.currentframe()
another_obj.save()
f.seek(0, os.SEEK_END)
sys.exit(1)
h.update(block)
start_op = tf.initialize_all_variables()
print(lines[0].shape)
b = np.ones((2, 4))
self._stream.flush()
f.write(user_code)
find_nearest_above(np.array([0.0, 1.0, 1.4, 2.0]), 1.5)
decoded_json = json.loads(json_string)
sys.stdout = sys.__stdout__
response = HttpResponse()
foo = Foo()
self.response.write(template.render(template_values))
values[~valid_mask] = np.min(values) - 1.0
print(foo.X)
Grid.columnconfigure(root, 0, weight=1)
fig, ax = PLT.subplots()
Post(*args, **kw)
myfunc()
file.truncate()
f()
self.tstart = time.time()
x_fit = np.linspace(samples.min(), samples.max(), 100)
soup = BeautifulSoup(r.content)
l = np.random.randint(0, 10, size=n)
data = sys.stdin.read(1)
word_list2 = sorted(word_list, key=lambda l: l[0].lower())
_stack = []
FileApp(filepath)
co_firstlineno, code_object.co_lnotab, code_object.co_freevars
print(shared_stuff.a)
np.transpose(np.nonzero(x))
instance = MyClass()
pipeA.send(20)
top10 = np.argsort(clf.coef_[i])[-10:]
parent1 = argparse.ArgumentParser(add_help=False)
print(json.dumps(output, indent=4))
sys.exit(0)
print(np.max(np.abs(slow_result - fast_result)))
labels = labels[::2]
hanoi(pegs, 0, 1, 4)
command = lambda : mod.add_to_queue(self.ea1_ent.get)
output_file.write(d[syllable])
ax0a = fig.add_axes([0.1, 0.1, 0.8, 0.25])
setattr(p, s, new_value)
app = wx.PySimpleApp()
self.external_method(arg1, arg2)
response
msg.attach(part2)
new_a.test()
server.serve_forever()
file_path = os.path.dirname(__file__)
self._stop.isSet()
popt, pcov = curve_fit(fit, x, y)
signal.signal(SIGCHLD, SIG_DFL)
sys.stdout.write(line)
fig = plt.figure()
data = data.transpose()
print(child.tag, child.text)
byte = f.read(1)
df2.head().T
mask[:, (~np.in1d(np.arange(mask.shape[1]), A))] = 0
frames = []
a = np.random.rand(6, 5, 4)
serializer = UserSerializer
print(img.shape, img.dtype)
Arr2 = Arr2.reshape((100, 1, 5))
(dx * dx + dy * dy) ** 0.5
main()
mydate = datetime.datetime.now()
hi()
ctx = cairo.Context(img)
result = -temp[:4]
results = defaultdict(set)
extent = im[0].get_extent()
char = sys.stdin.read(1)
list1, list2 = map(list, zip(*origlist))
background.paste(foreground, (0, 0), foreground)
os.setuid(0)
N = 1000000
it.starmap(func, it.repeat(args, times))
stream.feed(data)
4 / 100.0
10007, 10008, 10007, 10008, 10008, 10008, np.nan, 10010, 10010, 10010
print(random.choice(a))
print(lucky(500))
total += nested_sum(i)
frame = cv.RetrieveFrame(capture)
np.round(ccn.todense(), 2)
l = [group[:] for group in list_of_groups]
key = Column(Integer, primary_key=True)
print(poly.intersects(p))
l = [1, 5, 8]
f()
f.write(jpgtxt)
pylab.plot(f, Xdb)
True
a = np.random.randn(S, S, N)
sys.stdout = StringIO.StringIO()
df.truncate(before=d1, after=d2)
self.dictList.__len__()
mod = sys.modules.get(name)
temp_list = []
zurich_datetime = zurich_tz.normalize(local_datetime.astimezone(zurich_tz))
b = [4, 5, 6]
dft_of_x = W.dot(x).dot(W)
b = a.copy()
p = a[100:].ctypes.data_as(ctypes.POINTER(ctypes.c_double))
NULL
db = SQLAlchemy()
[x for i in range(1)]
fileData = f.read()
block = np.array(block)
numpy.linalg.det(numpy.dstack([a, b, c]))
print(datetime(2008, 12, 2))
all_found.append(founds)
a = a.astype(float)
list(filter(set(b).__contains__, a))
result[0]
result = tree.xpath(path)
ydiff = line1[0][1] - line1[1][1], line2[0][1] - line2[1][1]
mat[list(range(n)), list(range(n))] = 0
lkp = pd.Series(memberships).apply(set)
indata = numpy.ones((5, 6))
y = np.exp(-x * x)
list(self.__iterPerson(**kwargs))
w = QtGui.QWidget()
p.join()
app = QApplication(sys.argv)
np.mean(arr, axis=0)
r = tf.mod(x, 1)
browser.select_form(nr=2)
module.workflow_set.filter(trigger_roles=self.role, allowed=True)
count += 1
scope = locals()
rot = Quaternion((1, 0, 0), pi)
self.index += 1
consumer_lock_object.lock()
heapq.heappush(r, (-x * y, x, y))
e = Tkinter.Entry(w)
print(repr(f))
masterSet = set().union(*iterable)
ax2.yaxis.tick_right()
self._lines = []
data.domorestuff()
print(sample2.count(True))
fig = plt.figure()
s.close()
pprint.pprint(z)
zfile = zipfile.ZipFile(zipsrc)
self.canvas.SetBackgroundColour(wx.Colour(0, 0, 0))
screen = pygame.display.set_mode((250, 250))
A = numpy.array()
b[0][0] = 1
tree = et.ElementTree(root)
app.MainLoop()
window.set_border_width(5)
np.concatenate([(element_offset + x) for x in range(a.itemsize)])
response = urllib.request.urlopen(url)
t.start()
store_last_lineprocessed(last_line)
pThread = Thread(target=p.run(), args=())
decdeg2dms(dd)
x = __import__(module)
new_file.write(data)
n = len(my_list[0])
np.sum(seq, axis=0)
z = np.empty((100, 1, 4), dtype=float)
mount(prefix, app, **options)[source]
dt = datetime.datetime.now()
print(result)
load_json_file(filename)
proc.wait()
lg = np.log(pdf)
cbar = plt.colorbar()
p = math.exp(-delta / T)
m.end()
NotImplemented
next(iterator)
print(repr(__bar))
orig_py_compile(file, cfile=cfile, dfile=dfile, doraise=True)
count[0]
r.mainloop()
sess.run(train)
print(r.groups())
A = NP.random.rand(8, 5)
ax1 = fig.add_subplot(121)
False
lock = multiprocessing.Lock()
cols = [c.copy() for c in table.columns]
res = np.zeros_like(a[0])
df.sortlevel(0).index.lexsort_depth
print((s, found, tail))
id = Column(Integer, primary_key=True)
widget.queue_draw()
rows = cur.fetchall()
bucket = conn.get_bucket(BUCKET)
contents = f.read()
r = requests.get(settings.STATICMAP_URL.format(**data), stream=True)
files = [name for name in tar.getnames()]
bp.show(fig)
d = datetime.datetime.utcnow()
time.sleep(0.1)
ax.barh(ind, data, color=color, left=left)
pl.show()
uuid.uuid4().int & (1 << 64) - 1
my_dict = dict((k, []) for k in keys)
array([4, 9, 7, 9, 2])
modfile = os.path.abspath(mod.__file__)
donecounter += 1
mypolygon = [(randint(0, 100), randint(0, 100)) for _ in range(10)]
c = conn.cursor()
parser = argparse.ArgumentParser()
json.dump(hugeData, f)
set(x + 1 for x in aset)
s[ind1 + 1:ind2]
ax.yaxis.tick_right()
key = rev[value]
root = tk.Tk()
EMAIL_USE_TLS = False
numpy.nextafter(0, 1)
remove.add(index)
daemon_cartman.setDaemon(True)
e.foo()
self.widget.see(tk.END)
self.setUpClass()
pd.Timestamp.max
k in self.__dict__
result = set()
list_of_lists[0][0] = 7
n = len(lst)
result = sum(x, [])
kern = np.ones((kern_size, kern_size), np.uint8)
solve(equations, [a, t, vi, vf, d])
d.update({k: v})
G.add_edges_from(node_edges)
rows = cursor.fetchall()
pidx = np.indices((df_1.shape[1], df_2.shape[1])).reshape(2, -1)
frame.pack()
browser.set_handle_refresh(False)
print(repr(m))
client = oauth2.Client(consumer, token)
print(a)
df1 = s1.reset_index()
a * x ** n + b * x - c
the_type = type(ast.literal_eval(stringy_value))
xp = np.linspace(-1, 6, 100)
self.treeWidget.addAction(self.treeAction)
isdefarg(5, 7)
print(item)
LIVEHOST = True
c = a[:] + b[:, (np.newaxis)]
rating = models.IntegerField(default=0)
app.MainLoop()
dt + datetime.timedelta(0, rounding - seconds, -dt.microsecond)
a()
cur = [[14, k, j] for j, k in (rows[14], list(range(15)))]
print(tds[0].string, tds[1].string)
f.close()
print(getitems(bleah))
stream._add_io_state(state)
[p.start() for p in proc]
square = sys.argv[1]
HAVE_CURSES = True
log.removeHandler(ch)
rename_code_object(wrapper, f.__name__)
print((k, v))
self.searchobj = searchobj
filenames = [n for n in filenames if not fnmatch(n, ignore)]
dst.SetGeoTransform(match_geotrans)
requests.head(url, allow_redirects=True).url
x, y = y, x
print(a[i])
reactor.iterate()
raise StopIteration()
recs = m.recommend()
Testing(1 / 1)
print(meds)
asyncore.dispatcher.__init__(self)
drive, path = os.path.splitdrive(test)
f.seek(0)
A = np.arange(n * m * k, 0, -1).reshape((n, m, k))
L[a], L[b] = L[b], L[a]
str(document)
output.getvalue()
f.write(data)
post_syncdb.connect(add_view_permissions)
plt.colorbar(m)
fig = plt.figure()
matrix = [([0] * ncols) for i in range(nrows)]
grid.fig.set_figheight(4)
d = {}
model_to_dict(instance)
c.flags.owndata
self.__class__.PARAM
count2[i] += 1
t = df2.unstack(level=0)
[0, 1, 1, 0]
root = tree.getroot()
right = A[idx]
MyImplementation.do_stuff(self.lookup_string(request.something))
os.umask(0)
{{render_class(subclass)}}
lookup(dic.get(key, {}), *keys)
self.origstream.write(self.escape_char)
vec = xa1[1:-1]
img.write(data)
max(left, right, left_half + right_half)
logging.getLogger().addHandler(ch)
l[t] = something
column2.append(column.split(data_separator)[1])
self.i = value_of_self_i_before_itervalues(X) + len(X) % N
ax.set_xticklabels(xticklabels, minor=False)
[row for row in reader]
documents = map(itemgetter(0), documents)
df = pd.DataFrame(dict(col=a))
print(my_min([0, 2, -1]))
print(sum(1 for _ in next(groupby(l))[1]) if l else 0)
A = np.zeros((x.size, ndim + 1), dtype=float)
model_tunning.fit(iris.data, iris.target)
regressionmodel(X, Y, Z)
list1 = [1, 1, 1, 1, 1]
OrderedDict(zip(self._fields, self))
0
browser.open(post_url, data)
asign = np.sign(a)
axis([0, 1500, 1000, 0])
name = db.Column(db.String())
print(grouplist(l, 4, 2))
answer.append(elem)
self.ClickedLB2.resize(400, 20)
opener = urllib.request.build_opener(auth_handler)
mod = __import__(os.path.splitext(i)[0])
deletemxd, df, newlayer
dbb.autocommit(True)
pprint(result)
np.empty(arr1.shape, result_type(arr1, arr2))
percent_list = [percent.get(str(i), 0.0) for i in range(5)]
df = pd.DataFrame(np.random.randint(0, 2, (2, 8)))
pygame.init()
False
now = time.time()
file1.write(toFile)
q.create_queue(1)
self.errors.update(form.errors)
strcpy(save_path, SYSTEM_FILE_PATH)
d = feedparser.parse(feed)
alltests = unittest.TestSuite()
a.shape
a.extend([random.random() for _ in range(10)])
y = np.array([(i ** 2 + random.random()) for i in x])
psutil.network_io_counters(pernic=True)
my_logger.addHandler(handler)
session.add(w_2)
start_date = end_date - datetime.timedelta(days=8)
fig = plt.figure()
xs = np.exp(-((ts - 0.4) / 0.1) ** 2) + 2 * np.exp(-((ts - 0.8) / 0.1) ** 2)
decorator(fn)
fig = plt.figure()
t = tuple(d.items())
locals()
b.capitalize()
df = pd.DataFrame(data1)
type_of_fave = models.CharField(max_length=1, choices=FAVE_CHOICES)
print(fibonacci(10))
sys.stderr.write(s)
k = quaternion(0, 0, 0, 1)
parser = argparse.ArgumentParser()
max_value = df[feature_name].max()
OffsetTime(offset).localize(datetime.strptime(value, format))
df[col] = df[col].ffill()
active = User.select().where(User.active == True)
self.a + self.b
b = list(a)
list(range(x1, x2 + 1))
r = int(numeric(s))
G = nx.Graph()
synchIntervall = datetime.hour(10)
arr = numpy.row_stack((arr, row))
x = np.random.random(num)
c = Kls()
int(err.split()[-2])
ax.boxplot(data, notch=1, positions=pos, vert=1)
fig = plt.figure()
1
st = os.stat(filepath)
order = {item: i for i, item in enumerate(presorted_list)}
q = multiprocessing.Queue()
ax.set_ylim(yl[0] - (yl[1] - yl[0]) * pad, yl[1])
do_some_database_stuff()
width, height = result.size
f.close()
print(inspect.getmembers(mymodule, predicate=is_subclass))
zi = z[x.astype(np.int), y.astype(np.int)]
print(queue.get())
r.withdraw()
apsched.add_interval_job(checkFirstAPI, seconds=5)
apsched.add_interval_job(checkSecondAPI, seconds=5)
theFile.close()
yy2 = func(tplFinal2, xx2)
session.add(TS1(datetime(2001, 1, 2, 2), 1))
size = fig.get_size_inches() * fig.dpi
w = copy.deepcopy(x)
QtGui.QTableWidget.__init__(self, *args)
random.shuffle(randomized_list)
b = list((i, j) for (i, _), (j, _) in itertools.combinations(enumerate(a), 2))
manager.connect()
extra_files.append(filename)
random.shuffle(x, lambda : r)
twitter = Twython()
mail = email.message_from_string(email_body)
sys.exit(main(sys.argv[1:]))
ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
soup4.html.__next__
stext.pack(fill=BOTH, side=LEFT, expand=True)
h.split().count(n)
g.sum()
data = f.readlines()
engine = sa.create_engine(DSN, convert_unicode=True)
res = np.array_equiv(A, B)
matches[0].fromy, matches[0].fromx
z()
print(key, value)
server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
height = db.IntegerProperty()
b = np.swapaxes(a, 2, 0)
arr = np.roll(np.roll(arr, shift=-x + 1, axis=0), shift=-y + 1, axis=1)
name = db.Column(db.String(100))
S = n(n + 1) / 2
sound.play()
word_gen = ((word, word[::2], word[1::2]) for word in words)
split.append(([], []))
print(traceback.format_exc())
df[col] = numpy.roll(df[col], 1)
bin(1 << 7)
stdout, stderr
self._value = v
trimmed.pop()
uno.systemPathToFileUrl(os.path.realpath(path))
w = csv.writer(sys.stdout)
np.fill_diagonal(corr_table.values, np.nan)
allobjc
data = np.random.random(size=(50, 50, 50))
self._mqpush(request)
(x0, y0), (x1, y1) = rect.get_bbox().get_points()
fig = plt.figure()
results = (c_char_p * 4)(addressof(create_string_buffer(7)))
x = np.where(x < 0, 0.0, x * 10)
match.group(0)
gen()
np.mgrid[:4, :5].transpose(1, 2, 0)
j = np.arange(2, -1, -1)
cache[s1, s2] = 1 + lcs(s1[:-1], s2[:-1])
stream.close()
deletea
self.current.append(token.strip())
Pdb
os.linesep.join(helplines)
setattr(args, self.dest, values)
environment = jinja2.Environment(whatever)
o.one()
r, g, b, a = np.rollaxis(arr, axis=-1)
points = np.concatenate([points[:-1], points[1:]], axis=1)
Z = np.sin(X) * np.sin(Y)
id(df2._data)
c.write(sys.stdout)
tree = ElementTree.fromstring(response.content)
self.assertListEqual(expected_urls, css_urls)
B.shape
user = models.OneToOneField(User)
inspect.getmembers(OptionParser, predicate=inspect.ismethod)
[A[b] for b in range(end, start, stride)]
model_instance.image_field.save(uniquename, ContentFile(upload.read()))
setattr(destination, key, value)
bounding_boxes.append((x, y, w, h))
num_eq = np.equal(a, b, out).sum()
plt.show()
li = line.strip()
[0, 1, 0, 1]
isinstance(yourNumber, numbers.Real)
data.append(listofgroups)
ax.set_aspect(5)
self.order = datetime.now()
Ainv[j] = (Ainv[j] - factor * Ainv[i]) % q
self.func(obj)
gtk.widget_set_default_colormap(colormap)
x[:] = np.where(norms != 0, x / norms, 0.0)
wx.ListCtrl.__init__(self, parent, ID, pos, size, style)
out = np.take(x, lin_idx)
err = np.abs(a - b) / b * 100
kks[0] = 1.0
np.triu(A.T, 1) + A
main()
opener = urllib.request.build_opener(proxy_handler)
json.dumps(data)
zip(a, b)
p.terminate()
self.L.append(k)
server.login(SERVER_EMAIL, EMAIL_HOST_PASSWORD)
fitness = np.linalg.det(individual.reshape(self.N, self.N))
res = np.split(idx_sort, idx_start[1:])
axes.set_yticklabels(labels)
pool.close()
OC.check_output(self, want, got, optionflags)
bool({})
set_item(9)
workbook = Workbook()
a, b = 1, 2
x = np.random.random(10)
ds = datetime.date.today()
f(a)
line_split.append(annos.pop(0))
final_func = functools.partial(intermed_func, lst)
server.sendmail(fromMy, to, msg)
map(lambda x: x >= 4, a)
data = np.ones(N, dtype=int)
time.strftime(format, time.localtime(ptime))
pool.join()
d = np.abs(data - np.median(data))
print(F.__code__.co_consts)
pool.close()
mycsv = csv.DictReader(f)
z = np.empty(ind.shape, dtype=x.dtype)
print(repr(better_uc))
headers = dict(req.headers)
po.close()
print(date)
os.fsync()
Unicode(500)
new_dict[v] = k
temp = numpy.copy(my_array[:, (0)])
driver = webdriver.Firefox()
print(list[i])
window = Gtk.Window()
np.array([res])
print(scores.mean())
doctest.run_docstring_examples(f, globals())
html = render_to_string(template_name, context)
htmldocstr = infile.read()
m.close()
assert data.shape == (10,)
self.property_names = list(names)
selection.set(selection.get_target(), 0, iter_str)
plt.show()
x[1][0][0] = 21
print(dykSuperstring(deqs))
func(*func_args, **func_kwargs)
artist_count = len(artists)
logger.addHandler(fh)
x, y = zip(*points)
myfile.write(chunk)
c = zip(*a)[0]
chunk = f.read(4096)
burroughs_wheeler.test(1000)
data = json.loads(open(file).read())
print(x.foo)
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj))
Thread(target=reactor.run, args=(False,)).start()
block.text = hilited
set(df1.x).symmetric_difference(df2.y)
print(f(2))
self.pool = multiprocessing.Pool(processes=processes)
r_server.ping()
tex.insert(tk.END, s)
pos == len(b)
b = (a * b).sqrt()
test_dict = autoparts()
Py_Initialize()
print(np.allclose(q, t))
A.add_edges_from(G.edges())
df.sort_index(inplace=True)
event.setDropAction(QtCore.Qt.CopyAction)
assert isinstance(node, Tree)
x.append(temp)
logging.getLogger().addHandler(ch)
Py_DECREF(name)
a = array((1, 0, 0, 1, 1, 0, 0))
render_window.Finalize()
t.join()
tar.addfile(tarinfo=info, fileobj=string)
p = Polynomial.fit(x, y, 4)
clf = sklearn.tree.DecisionTreeClassifier()
text = doc.toPlainText()
cv2.floodFill(result, maskborder, seed_pt, (255, 0, 0))
lst[-1] += old_d[key][i]
newimg = np.zeros((img.shape[0], img.shape[1]))
indices = list(g)
x % 1000
handles, labels = ax.get_legend_handles_labels()
FAQ
print(tavnit % row)
a / foo.py
path = sys.argv[1]
next(wood)
termios.tcsetattr(fd, termios.TCSAFLUSH, old)
gdal.UseExceptions()
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
MenuItemComponent.objects.filter(menuItem=menuitem)
[chr(n & 255)] + to_bytes(n >> 8) if n > 0 else []
x1, x2, y1, y2 = ax.axis()
HttpResponseRedirect(redirect_url)
jsonify(data=cursor.fetchall())
print(arr.shape)
print_one()
all_matches = [matches(list2, v) for l in list1]
hex_data
loop.run_forever()
test_date = date_list[0]
mail.list()
prof.print_stats()
df1 = df.loc[pd.MultiIndex.from_arrays(edge_subset2.T)]
data = sockfilefile.readline()
dfasamplefive = dfa[5:]
node.val = some_val
print(base_url)
print(matchResult.group(1))
HexDump()
print(inspect.stack())
self.valid_keys.remove(key)
email_message = email.message_from_string(raw_email_string)
print(args.f)
lowest_values.append(x)
CalculatorUI.__init__(self)
func2()
metadata = MetaData(bind=engine)
sys.exit(1)
float(num)
file_words = (word for line in fileobj for word in line.split())
os.path.dirname(path)
print(df.drop(idx))
new_body_text = re.sub(pattern, make_create_footnote_numbers(), text)
cdvirtualenv
{{message | safe}}
repo = Gittle.clone(repo_url, repo_path)
text = f.read()
x, y = get_point(foo)
my_user.username
{protocol, internal_ip, internal_port, foreign_ip, foreign_port}
globals()[name]
serializer_class = UserSerializer
ax = fig.add_axes(ax_size)
df
ax2 = ax.twinx()
username_field.send_keys(self.user.username)
-W15
data[i] = random.random()
d = {(1): 1, (2): 2}
ser.setDTR(level=0)
os.chdir(workingdir)
__init__.py
htmlString = response.read()
lookup[l].add(v)
func
list_two = [4, 5, 6]
time.sleep(0.1)
plt.pause(0.5)
c = canvas.Canvas(file, pagesize=landscape(letter))
shifts = [(-1, 0), (0, -1), (0, 1), (1, 0)]
logger.setLevel(logging.DEBUG)
root_logger.setLevel(logging.DEBUG)
self.builder.connect_signals(self)
type(b)
order = np.argsort(x)
s = socket()
widget.configure(foreground=color)
ordered(a) == ordered(b)
xy[xy[:, (1)] > 0]
sorted(animals, key=lambda animal: animal[2])
d[v].append(k)
ranges = [(1, 5), (10, 20), (40, 50)]
x = np.arange(16).reshape((4, 4))
csv_writers[k].writerow(row)
np.cross(a, b)
Iopen = bwareaopen(Iclear, 120)
now = datetime.utcnow()
globallock.acquire()
server = SocketServer.TCPServer((HOST, PORT), MyTCPHandler)
numbers.append(current)
print(list(gen))
[0, 0, 1]
G.edges(data=True)
y = v[:, (1)]
print(foolib.__file__)
b = [x for x in a if a.count(x) > 1]
m = re.match(regex, s)
paw_number += 2
book1 = Workbook()
weights.append(W - sum(weights))
[x for n in getNeighbors(vertex) for x in getNeighbors(n)]
connect_timeout = 100
new_pdf = PdfFileReader(packet)
ranges[i:i + 2] = [[ranges[i][0], ranges[i + 1][1]]]
ax1 = fig.add_subplot(211)
main()
4.0 / 100.0
xi = np.array([0.0, 0.5, 1.0])
ax.set_yticks(minorticks, minor=True)
self.timer.timeout.connect(self.updateClock)
id_list = id.readlines()[1:]
sorted((minval, value, maxval))[1]
Tkinter._test()
self.fail(self._formatMessage(msg, standardMsg))
_f(*args)
bar = forms.ModelChoiceField(queryset=Bar.objects.none())
power(5, 2)
wrapper
print(data)
signal.alarm(0)
self.input_queue = mp.Queue()
gradients = 1.0 * (data > 0)
tmp += int(sline[1])
im.set_transform(im_trans)
random_sample_output.writelines(random_sample_input)
Test.calc_a.__code__.co_names
children = []
sys.meta_path.append(MyImporter())
custom_cv = zip(train_indices, test_indices)
cur_list.append({keys[i]: values[i][j]})
(x + y).subs(reversed(100 * reps))
hfile.seek(pos, os.SEEK_SET)
queryset = User.objects.all()
sys.stdout = capturer
self.e = Entry(top)
pic = QtGui.QLabel(window)
os.dup2(0, 1)
numOccurences = len(pattern.findall(target))
u = f.read()
t = ssh.get_transport()
s.plot()
fig.set_figheight(96)
Gtk.init([])
foo.map(lambda x_y: (x_y[0], [x_y[1]])).reduceByKey(lambda p, q: p + q).collect()
exit(1)
pd.Series(sm.OLS(y, x).fit().predict())
run_main()
out[i, j] = lst[i] in lst[j]
image.save(pic, image.format, quality=100)
self.view.setModel(self.treeModel)
queryset = Widget.objects.all()
cursor = conn.cursor()
Py_Initialize()
a = list(range(1, 101))
diam = np.zeros(len(seed))
A[0, 1] *= 0.5
x1, x2 = np.nonzero(accum)
chain.from_iterable(map(f, seq))
signal.alarm(10)
f.write(binary_representation)
lines = []
insummer = datetime.datetime(2009, 8, 15, 10, 0, 0)
res = split(cols, inverse_rows[1:])
left = random.randrange(0, x1)
answer += str(i)
data = json.loads(json.dumps(data))
isprintable = set(yourstring).issubset(printset)
a = np.array([])
novel.append(word)
tuple()
fig = plt.figure(figsize=(8, 6), dpi=80)
x, y
process.stdin.write(data)
print(next(reader))
DO_STUFF
loop = asyncio.get_event_loop()
output = output[:-1]
output = [x for x in L]
Py_Initialize()
simplejson.dumps(finalObj)
{k: dct[k] for k in keys}
zipFile.close()
scores = cross_val_score(clf, X, y, cv=cv_custom)
app = QtGui.QApplication(sys.argv)
0
os.unlink(db_fname)
browser = webdriver.Firefox(capabilities=firefox_capabilities)
self.shutdown()
im = Image.open(im_file)
foo = Foo()
ssh = paramiko.SSHClient()
c = cs.send(c + 1)
stringbuilder_test.py
answer.append(d)
sorted(x)
fig, ax = plt.subplots()
fig, ax = plt.subplots()
network.add_layer(1)
myl[myl.index(item)] = 44
df = pd.DataFrame(np.random.randn(4, 4))
dict.__getitem__(self, key)
p1.conversations.filter(participants__in=p2)
bool(a) ^ bool(b)
Z = VV / WW
wait_for_element_visibility(welcome_button).click()
therest = []
s.close()
P = np.array(mean_data)[:, (1)]
df = pd.concat([df] * 1000).reset_index(drop=True)
dictlist.append(temp)
p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
self.f = f
assert len(lines) == N
4015
im = np.zeros((imsize, imsize), dtype=float)
df_a.div(df_b)
Z = np.random.random((500, 500))
rows = np.arange(y.size)
swap_rows(my_array, 0, 2)
uniquifier.uniquify(a_timestamp)
cb = pyplot.colorbar(cs)
print(set(c) <= set(a))
latest_file = max(list_of_files, key=os.path.getctime)
plt.plot(lowess[:, (0)], lowess[:, (1)])
tuple(v)
main()
np.random.seed(1977)
self.fp.seek(position, 0)
1 + countit(target, key, where + 1)
color = image.getpixel((x, y))
printTree(myTree)
objectA = get_object_from_db()
pyplot.bar(histo[1][:-1], cumulative_histo_counts, width=bin_size)
MyObject()
A1 = A.reshape(4, 2, 2).transpose(0, 2, 1)
aspectRatio = image.shape[1] / image.shape[0]
f is f()
entropy = np.array(entropy)
grequests.map(rs)
ax.set_ylim(-0.6, 0.6)
print(text)
-1
False
ax = plt.gca()
class_items = iter(self.__class__.__dict__.items())
print(letters_in_order_of_frequency(string))
unittest.TextTestRunner(verbosity=2).run(suite)
s = requests.session()
a = np.array([1, 5, 50, 500])
lst_intensities.append(img[pts[0], pts[1]])
cmd.Cmd.__init__(self)
o.__dict__
s2 = sum(x * x for x in samples)
results = list(foo())
self.user
random_index = random.randrange(len(cells))
region_el = [item[0] for item in remaining]
scene.camera.location.z = tz
decoded_data = chan.decode(sample_data)
method = possibles.get(method_name)
fig = plt.figure()
timeit(hugeequal1, hugeequal2, 1000)
{{form.csrf_token}}
ax1.set_yticklabels(data.index)
data = open(filename)
Base = declarative_base()
InfoDF = pd.DataFrame()
love_ctx.add((bob, hates, charlie))
print(bar())
args = [iter(iterable)] * n
d(a, b)
data = {x: y for x, y in zip(df.columns, df.iloc[0])}
cardsdiscarded = 0
count += 1
data = reader.GetOutput()
response = browser.open(request)
a = np.random.randint(1, 5, (500, 500))
bool(match)
some_func(l, 5)
ax.set_zlim([0, 4])
stck.append(crnt)
WHITE = 255, 255, 255
df = pd.DataFrame(s)
a / b
print(Temperature.identifier)
a.get(1)
self.webview.setWebViewClient(self.wvc)
d.hexdigest()
ax = fig.add_subplot(111)
len(data)
df = df.append(h, ignore_index=True)
photo = models.ImageField(upload_to=photo_path, blank=True)
index = self.model.index(0, 0, QtCore.QModelIndex())
bins.append(x0)
group_list = grouped.map(lambda x: list(x[1]))
myfile = open(os.path.join(MEDIA_ROOT, f.Audio.path)).read()
full = os.path.join(os.path.dirname(module.__file__), thing)
parsed = urlparse.urlparse(url)
b = np.array([5, 6])
x + 1
signal.alarm(0)
b = np.dot(X.T, (mask * Y).T)
df = pd.DataFrame(ls).set_index(0)
sizer.Add(self.log, 1, wx.ALL | wx.EXPAND, 5)
cc = Country.objects.all()
s = pickle.dumps(lambda x, y: x + y)
newax.imshow(im)
266248
sys.path.insert(0, pluginsDir)
diff(nges_uneval, n[5]).doit()
self._window = gtk.Window()
m = pat.match(s)
listener.bind((HOST, PORT))
G = nx.DiGraph()
freqs = np.fft.fftfreq(len(w))
request
items = re.findall(itemfinder, html)
Py_DECREF(key)
logging.root.addHandler(file_handler)
print(dp(n, left)[1])
index += 1
self.sock.connect((self.host, self.port))
urllib.request.install_opener(opener)
X[np.abs(X) < 0.1] = 0
exit(1)
b.fly()
address = ws.Cells(row, col).Hyperlinks.Item(1).Address
data[:, (1)]
args = sys.argv
new_bar = updated(bar, extra)
r = [(i / s) for i in r]
print(id(a))
df
result = max(iter(d.items()), key=lambda x: x[1])
kthsmallest(A[:i], B[j:], k - j)
digs[0]
npa = np.asarray(a)
filtered_string = [x for x in myStr if x in string.printable]
c.setopt(c.URL, host_url)
a = Addressbook()
print(allimports.sum(1, 1))
df.id.apply(str)
current_vertex = graph[0][0]
True in ((start < date) & (date < finish)).unique()
jsonobj = json.loads(jsonstr)
log_handler2 = logging.handlers.RotatingFileHandler(file_2, *args)
myFunction()
ax = plt.axes(projection=ccrs.PlateCarree())
exec(urllib.request.urlopen(x), globals())
fig = plt.figure()
categories.extend(animal.categories.all())
IT.chain.from_iterable(IT.combinations(s, r) for r in rvals)
v_box = QtGui.QVBoxLayout()
perm(prefix + [rest[i]], rest[:i] + rest[i + 1:])
db.close()
plt.subplot(121)
it.chain.from_iterable(it.repeat(i, i) for i in range(1, 5))
box = ax.get_position()
idx = np.argmin(np.abs(sw - sCut))
z = np.ones((nr, nc))
args = parser.parse_args()
GL.glRectf(-0.8, -0.8, 0.8, 0.8)
ticks = np.linspace(0, 1, num_ticks)
a = np.array([[5, 4]])
CE, BD, BE, BF, BC
v = list(d.values())
f.set_axis_off()
self.root.destroy()
parser = argparse.ArgumentParser()
fn(*args, **kwargs)
clf.estimators_
partitions.append([e])
a = [Foo(), Foo(), Foo()]
queue = collections.OrderedDict()
self.glade = gtk.Builder()
ax.bar(x, y, log=1)
len((a > 10).tostring())
sum += distance(randoms[offset][0], randoms[offset][1])
session.execute(i)
self.x = x_
final_image = Image.fromarray(np.uint8(im.clip(0, 255)))
pyqt5.vext
MasterObject.__init__(a, b, c)
(Sxy * N - Sy * Sx) / det, (Sxx * Sy - Sx * Sxy) / det
f.write(content)
np.mean(counts)
image = Image.open(buffer)
f.write(l)
my_list = list(N.values())
client = paramiko.SSHClient()
res = [(-1) for i in range(len(myLists))]
A = diag(arange(0, 10, 1))
subsymbtree
print(item)
N = np.logspace(2, 5, 4)
w = csv.writer(f)
print(soup)
plt.plot(t, s, c=seaborn.color_palette()[2])
fig, ax = plt.subplots()
print(query)
self.show()
cur = con.cursor()
local_dt = timezone.localize(dt)
result = defaultdict(int)
r = s.post(URL, data=login_data)
Z1 = mlab.bivariate_normal(X, Y, 1.0, 1.0, 0.0, 0.0)
print(list(roundrobin(*groups)))
print(string)
df = pd.DataFrame()
doc = xee.fromstring(data)
logresults = log_stream.getvalue()
sc = SparkContext(conf=sconf)
out[:, (0)] = np.repeat(arrays[0], m)
data = dict(zip(labels, [int(x) for x in starf]))
p.start()
print(lst2[0])
my_engine.commit()
t1.stop()
weekly = numpy.sum(by_week, axis=1)
memory_file.seek(0)
f[i] = 0
p = np.array([[1.5, 0], [1.4, 1.5], [1.6, 0], [1.7, 1.8]])
result.append(str[last_end:])
self.gravity = 982.0
parser.print_help()
check(my_list[:start], tracking=tracking)
idx = np.where(m.any(1), idx0, np.nan)
b = np.zeros(a.shape, dtype=a.dtype)
hi_result = hi()
_sum(iterable, start)
days.index(inp)
df2 = pd.concat([df, df1], axis=1).sort_index(axis=1)
data = f.read(block_size)
results = {}
AppHelper.runEventLoop()
Process.__init__(self)
grid()
foo = Foo()
django.db.transaction.leave_transaction_management()
type(self) == type(other) and self.value == other.value
yaxis.set_minor_locator(MinorSymLogLocator(0.1))
fig = plt.figure()
data = np.random.random(numdense)
lis1, lis2 = map(itemgetter(0), my_list), map(itemgetter(1), my_list)
Base.metadata.create_all(engine, tables=[DeclarativeTestModel.__table__])
Bar() < Foo()
Z = np.arange(2000).reshape(20, 100)
print(str(obj.node))
group = groupby([1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1])
np.log(gev.pdf(data, *fit0)).sum()
PyQt4.QtCore.QPoint(1509, 549)
process_f()
dtype2 = np.dtype({name: arr.dtype.fields[name] for name in fields})
help(re)
sleep(1)
sIO.__init__(self, *args, **kwargs)
b.sum(axis=1)
clock.tick(20)
v_box.addWidget(self.box_two)
object.__eq__(self, other)
digits = len(foo.split(dec_pt)[-1])
ax.add_patch(patch2b)
attr = getattr(self.obj, name)
a1.yaxis.tick_left()
B_process.stdin.close()
self.iterator = iter(generator)
response
plt.show()
name = models.CharField()
time.sleep(1)
conn.send(data)
[nan] == [nan]
image.load()
do_something_here(*args, **kwargs)
fig = plt.figure()
fp = np.polyder(f)
bdm = boto.ec2.blockdevicemapping.BlockDeviceMapping()
F[np.triu_indices(n, 1)] = 0
self.root = Tkinter.Tk()
transport = TTransport.TBufferedTransport(socket)
X = np.random.rand(100)
compile(expr, filename, mode, PyCF_ONLY_AST)
append()
form.instance.created_by = self.request.user
[l]
lattice[i] = mksite(pair[0], pair[1])
[]
Base = sqlalchemy.ext.declarative.declarative_base()
print(df_means.head())
obj2.decrypt(ciphertext)
ModelID = Column(Integer, primary_key=True, autoincrement=True)
self.changeLayout(QtCore.Qt.Horizontal)
tagger = nltk.UnigramTagger(nltk.corpus.brown.tagged_sents())
ax = fig.add_subplot(111)
print(result[0])
values.append([a, a + 200])
e.sum(axis=0).shape == (2, 2)
g()
br = mechanize.Browser()
b = B()
a = [1, 2]
launchVim()
existing(self, *args, **kw)
rnd = 2.0 * np.random.rand(n)
root = elem.getroot()
zip(*(islice(cycle(elem), max_length) for elem in inputs))
print(a)
numpy.lib.stride_tricks.as_strided(stacked, shape, strides)
new_url
v1fColor = NP.array(lst, dtype=NP.uint8)
fig = plt.figure()
print((i, j, k))
print(hex(id(w)))
arr = np.array(im)
os.path.relpath(datastore.__file__, here),
B = [2, 6, 5, 4, 2]
[0, 0, 0, 0]
print(a)
a().method()
items = map(dicttolatex, items_to_clean)
csv_in.close()
cv.WarpPerspective(cv.fromarray(im), out_2, cv.fromarray(h))
print(b)
t[:] = np.arange(4).reshape(2, 2)
abs(gTob(a) - gTob(b)) == 1
fig = plt.figure()
list(gexpr)
full = np.random.randint(1, 99, size=(8, 8))
d.groan()
print(x)
obj.get_object()
arcpy.RefreshActiveView()
x = np.random.standard_normal(n)
print(item)
fig = plt.figure()
rows = np.array([0, 1]).reshape(-1, 1)
my_task.delay()
c = [_f for _f in [list(set(sublist).intersection(set(b))) for sublist in a] if _f]
b = a[:]
f.close()
c = ctypes.cast(pBuf, ctypes.POINTER(ctypes.c_char))
my_code = get_my_code(ParentA)
list(deque(fin, n))
[1, 1, 2]
gc.collect()
node = character.ENodeId(int(node + 1))
client = paramiko.client.SSHClient()
new_a * b
parser.print_help()
app = Flask(__name__)
hax2.set_axis_off()
readx = select.select([proc.stdout.fileno()], [], [])[0]
pickle.dump(obj, file, protocol=4)
print(line.strip().upper())
x = 0
self.pkwargs = pkwargs
N = A.shape[0]
foo(1, 2)
re.findall(notes + accidentals + chords + additions, line)
self.memo[id(obj)] += 1
sub_df
stream.stop_stream()
(b - a).days
ax.xaxis.set_minor_locator(plt.FixedLocator([50, 500, 2000]))
new_a = np.empty(a.shape)
sizer = wx.BoxSizer(wx.VERTICAL)
msg.attach(attachment)
setattr(cls, k, v)
short_desc = forms.CharField(widget=forms.Textarea)
avgs.append(total / count)
print(line)
sys.setrecursionlimit(10 ** 6)
knnres = KNN(lowdimtrain, trainY, lowdimtest, k)
visited.add(self)
fff = os.path.join(working_folder, f)
stop_event.wait(random.randint(0, 5))
action.visit(this)
print(testfunc(1))
iris = datasets.load_iris()
arr[i][j] = numpy_arr[i][j]
a = np.array([True, True, False])
logging.Handler.__init__(self)
plt.xticks(rotation=90)
sympy.nextprime(50)
slice(n if k > 6 else k)
zip(a, b)
s.sort(reverse=True)
sys.stdout.encoding
setattr(self.obj, self.method, self.orig_method)
ax.set_yticklabels(yticklabels, minor=False)
res.sort()
img = Image.open(sys.argv[1])
some_exit_code
False
self + [fillvalue] * (n - len(self))
os.path.exists(sys.stdin.name)
tuple(flatten(args))
mock(*args, **kwargs)
new_arr.shape
cpy.seek(0)
datetime.utcfromtimestamp(dt64.astype(int) * ns)
os.setpgrp()
df
data = self._fp.read()
a = np.zeros((N, N), a.dtype)
b.append(i if i else b[-1])
data = json.load(f)
logging.getLogger().setLevel(getattr(logging, FLAGS.logging_level))
ax.set_xticks(ind + width)
self.refresh()
parser = etree.XMLParser(remove_blank_text=True)
imgBoth = np.dstack((a, b))
filename = os.path.basename(url)
writer = csv.writer(output_file)
df = DataFrame(resoverall.fetchall())
root = tk.Tk()
bestfit = bettermodel
list([t for t in list(d1.items()) if t[1] == m])[0][0]
test_suite = unittest.TestSuite(suites)
df
threading.Thread.__init__(self)
unq_first = np.concatenate(([True], a_sorted[1:] != a_sorted[:-1]))
loop.close()
upp = np.array([0.1, -0.2])
mf = mmap.mmap(f.fileno(), 0)
sock.sendall(msg)
title = title_search.group(1)
gf.seek(-4, 2)
print((k, g))
self.testbed.deactivate()
process = Popen(command, stdout=PIPE, stderr=PIPE, bufsize=1)
print(t.getvalue())
conn.shutdown(2)
zip = zipfile.ZipFile(zipinmemory)
print(dollars)
output.addPage(page)
axes[0].imshow(z)
sh.setLevel(logging.DEBUG)
locale.atof(num)
EAGAIN or EWOULDBLOCK
app.run(port=9001)
le.inverse_transform([0, 0, 1, 2])
x_a = np.linspace(-8, 0, 60)
switch_path if sum(switch_path) < sum(stay_on_path) else stay_on_path
hugeData = json.load(f)
retval = ser.readline()
mydb.commit()
print(response1.text)
sqrt(2, precision(100))
print(s.unpack_from(y))
args.command(subparsers.choices[sys.argv[1]], args)
a[:] = da[:]
subcats.extend(dirnames)
self._ssh = paramiko.SSHClient()
tree = ET.fromstring(content, parser=ET.HTMLParser())
value = getattr(self, key)
self._s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
s.head(10)
ax.set_yticks([])
o.a
ptext = h[0].text_content()
desk.picture.set(mactypes.File(f.name))
output, errors = p.communicate()
lines = proc.stdout
orig_dev = os.stat(path).st_dev
label = gtk.Label()
self.master.after(1000, self.change_label)
x = np.linspace(-5, 5, 100)
op.pow(a, b)
getattr(self, name)
options = parser.parse_args()
arrayList.append(wM)
utils.formatdate(nowtimestamp)
sum(it.imap(doSomething, originalList), [])
data = [(1, 2), (40, 2), (9, 80)]
Base = declarative_base()
a.registerCallback(listener2)
post_data = urllib.parse.urlencode(post_data)
self.beep.emit(i)
print([(elem * 2 if elem % 2 == 0 else elem) for elem in a_list])
pool = Pool(processes=8)
dict_data = json.loads(venues)
print(b.shape)
ax.grid(False)
time.sleep(1)
kill(proc.pid)
mt.roundrobin(*([iter(list1)] * (n - 1) + [list2]))
next(self.it)
method(**keywords)
frame_size = cv.GetSize(frame)
table.create()
1
out = np.count_nonzero(m[1:] > m[:-1]) + m[0]
w.resize(600, 400)
handled = pygame.mouse.get_pressed()[0]
new_list.pop()
chunk = fp.read(BUFSIZE)
to_search[NAME]
TEST_RUNNER.run(TEST_SUITE)
sorted([x for x in res if x < limit])
relative_path = os.path.relpath(local_path, local_directory)
t = threading.Thread(target=f)
water_held += (pos - stack[-1].pos) * well_height
d.cards.remove(card)
[0, 0, 1, 1]
help(distutils.version)
out.close()
bpy.utils.unregister_class(customToolshelfPanel)
id(s.index), id(s.values)
plt.title(slope)
{}
pprint(ddiff, indent=2)
assert f() is f()
correlations_array = np.asarray(df.corr())
other_f(other_f(s[1:])) + s[0]
time.sleep(4)
data = collections.defaultdict(list)
list(self.data.keys())
word = s[:end + 1]
raise urllib.error.URLError(err)
self._choices = []
df2 = df.copy()
print((c.id, c.title, c in u.channels))
shift = max([t.get_window_extent().width for t in legend.get_texts()])
print(df.groupby(df.A // 2).A.apply(pd.Series.sample, n=1))
HiPRIOpoller.register(socket_0_pull, zmq.POLLIN)
fig, ax = plt.subplots()
bins = [0, 0.1, 0.9, 1]
handler[cookie[0]] = cookie[1]
[2] + [(2 * i + 1) for i in range(1, n // 2) if sieve[i]]
{1} & {1}
urllib.request.install_opener(opener)
bool(-1)
some.development.host
print(d[str])
point_buffer[:, (0)] * 0.5
[(1 / egg) for egg in eggs if egg != 0]
log_handler1 = logging.handlers.RotatingFileHandler(file_1, *args)
self.src[-1].insert(0, itemtoshift)
0.6625, sym2, 8, 5, 10, 10
f(d, name)
[any(t) for t in zip(a, b, c)]
main()
[0, 1, 0]
first, rest = list[0], list[1:]
print(sys.argv[0])
result.append(a_class)
x = np.array(x)
non_empty = [line.rstrip() for line in lines if line.strip()]
stack.append(s)
p = psutil.Process(somepid)
rolled = np.roll(y, 1, axis=0)
sys.exit(1)
self.connection.channel(self.on_channel_open)
response = requests.get(my_url)
vis = cv2.cvtColor(vis, cv2.COLOR_GRAY2BGR)
fig.autofmt_xdate()
self.web_view = QWebView()
print(in1d(b, a).all())
start, end, step = len(out) - 1, -1, -1
mime_msg.get_payload()
print(sys.argv)
self.x, self.y = x, y
do_something_else_2()
max(chain(l_one, l_two))
list(x)
res = A[:, (B)][(B), :]
_widget = QtGui.QWidget()
b.decode()
a = np.arange(10)
self.pushButtonSimulate.clicked.connect(self.on_pushButtonSimulate_clicked)
s = set(fus_d.keys())
data = {}
b.build_purelib
results.append(common)
is_equal(df, using_precomputation, using_index)
print(df)
fig.patch.set_alpha(0.7)
(min(r1.end, r2.end) - max(r1.start, r2.start)).days + 1
do_something(line)
os.startfile(command[input][4])
tuple(gen(d) for d in deques)
classname = self.__class__.__name__
tornado.ioloop.IOLoop.current().start()
a + -1 / L * math.log(1 - u * (1 - math.exp(-L * b) / math.exp(-L * a)))
decorator
df = DataFrame(np.random.randint(0, 10, size=100).reshape(10, 10))
Y = X[:, (j)].reshape((N, 1))
{{analysis.simple_info}}
a = b + a
reverse_fks = my_model._meta.get_all_related_objects()
raise MyCustonException(attr)
grid_x, grid_y = np.mgrid[0:149:150j, 0:149:150j]
self.current += 1
locals()
line = p.stdout.readline()
list(dep.triples())
x[i], y[i], z[i] = data.GetPoint(i)
QtCore.QThread.start(self)
self.arg1 = arg1
print(line)
pylab.ylim([len(names) - 0.5, -0.5])
isinstance(f, types.FunctionType)
res1 = np.zeros((ni, nk))
x[:, 1:2] * y[:, 1:2]
middle = [end_pts[1], end_pts[2]]
l[i] = bar
Year.add(row[0])
self.write(File.read())
zip(*lines[1:])
log_capture_string.close()
print(child.read())
outfile.close()
k = np.tile(k, (1000, 1))
distutils.log.set_verbosity(distutils.log.DEBUG)
g = g.map_diag(sns.kdeplot)
index[1:] = groups[1:] != groups[:-1]
app = web.application(urls, globals())
number = next(iterator)
lambda : arg() if callable(arg) else arg
[0.0, 0.0] / 0
end = lst.index(item, start + 1)
out = a[np.sort(sortidx[valid_ind])]
last_updated = DateTimeField(required=True, default=datetime.now())
test(name)
_assertSquareness(a)
self.dataChanged.emit(index, index)
max(iter(c.items()), key=itemgetter(1))
C = np.cumsum(lens)
i = i + 1
node = row[0]
mask = np.cumsum(np.isnan(arr), axis=1).astype(bool)
[5, 6, 0, 1, 2]
cycles.append(list(c))
self.setAcceptDrops(True)
r = random.randint(0, 10)
[Fraction(n) for n in (degrees, minutes, remainder * 60)]
FancyArrowPatch.__init__(self, (0, 0), (0, 0), *args, **kwargs)
h = logging.StreamHandler()
column_widths = []
[0, 0, 0, 1]
requirements.txt
setheading(180)
result.append(-1)
model.update(**kwargs)
authorization = DjangoAuthorization()
df = pd.DataFrame(sample)
time.sleep(0.0001)
joined.fillna(-1, inplace=True)
print(tokens.asDict())
page = urllib.request.urlopen(urls).read()
map(lambda e: urlparse.urljoin(base, e), es)
dir = os.path.basename(filepath)
x = my_list.pop()
b = np.logical_not(a)
self._value = value
dodgy.append(i)
logging.Handler.__init__(self)
old_keys = [(x[0], x[1]) for x in old_vals]
self.data.config(yscrollcommand=self.scrollbar.set)
browser.set_cookiejar(cookies)
self.timer.start()
i += 1
self.lom = []
self.is_active
lambda x: x
crsr.close()
[reduce_num(num) for num in list1]
[blas]
bson_obj.decode()
min_num, max_num = min(nums), max(nums)
urllib.request.install_opener(opener)
S = P_i.sum(axis=1)
WSGIApplicationGroup % {GLOBAL}
f.read(bom_len)
li[-1]
myArray[i] = [i, i + 1, i + 2]
temp = models.IntegerField()
b2.grid(row=1, column=4)
print(sorted(z, key=lambda x: x[1])[-2:])
widget.setGeometry(200, 200, 100, 50)
r.push(bests[best[1]])
t = QtGui.QTableView()
groups.append((test_size, train_size))
cap = cv2.VideoCapture(0)
X, Y = np.meshgrid(x, y)
n = mat.shape[0]
self.memo[str]
mismatches.append(seqloc)
final_list.append(tuple_item)
c[i, j] = b
pos += 1
f.__name__
QItemDelegate.__init__(self, parentView)
m.span()
root = Tkinter.Tk()
a = numpy.array(l)
line = next(i)
import_array()
app = Flask(__name__)
thefile.flush()
print(cmp(list_1, list_1))
self = Foo()
0
np.array(tuple(it.islice(it.cycle(arr), length)))
flags = fcntl.fcntl(fd, fcntl.F_GETFD)
elem.append(match)
the_table.set_zorder(10)
context.set_source_rgb(0, 0, 0)
self.type.get_object_for_this_type(id=self.id)
indent = len(line) - len(line.lstrip())
self.id
self.callback()
p.text()
f.vals[0] = 10
draw = ImageDraw.Draw(img)
result += [(v + p) for p in perms(s[:i] + s[i + 1:])]
profile.print_stats()
sys.stdin = dummyStream()
a = [(lambda x: x * i) for i in (1, 2)]
name = event.GetEventObject().myname
self.b = b
a = np.ma.zeros((500, 500))
minm = np.array([], dtype=int)
q.put(item)
cls.x = 1
pprint(output)
fig, ax = plt.subplots()
count[0] += 1
current = array[:, (i)]
z = pickle.loads(s)
self.method(key)
im = Image.fromarray(cm.jet(s, bytes=True))
np.abs(a - val) < tol
print(n)
forms.remove((form, question))
object.__new__(cls, *args, **kargs)
str(self.list)
fh.write(str([data]))
ix_j = np.tile(np.arange(x.shape[1]), (x.shape[0], 1))
levels = np.linspace(-1, 1, 40)
hourly_data = df.values[:, :]
x[0] = Decimal(1)
handle.close()
indices = rows.nonzero()[0]
getchar()
MyException, (self.arg1, self.arg2)
count_arr = np.concatenate((a[:, (1)], b[:, (1)]))
self.cursor = self.connection.cursor()
a.test()
raise web.nomethod(cls)
t = np.mean(t, axis=2)
X = u.dot(np.diag(s))
list.__delitem__(self, key)
result
hash - r
name, path, args, kwargs
email = Column(String)
myqserver = Qserver()
print(a)
Foo.__init__(self)
result.update({j: [i]})
__init__.py
print(cube(-8))
category[key].append(i)
getLogger().addHandler(StreamHandler(stream=logfile))
os.mkdir(dir)
assert not any(x in d for x in lst)
s == json.loads(t)
content.append(info)
plt.plot([1, 2])
A[idx[0]]
host = hosts[host_id]
f, ax = plt.subplots(2, 1, figsize=(12, 6))
df1.div(df1.sum(1), axis=0)
lst = literal_eval(string)
dict.__setitem__(self, val, key)
t.stop()
[i for i in range(5)]
dates.append(date)
time.sleep(10)
self.assertEqual(expect, result)
BananServer, GulServer, SolServer, RymdServer, SkeppServer
df
im = cv2.imdecode(np.asarray(bytearray(im_data), dtype=np.uint8), 1)
fig = plt.figure()
logger.addHandler(sh)
pickled_value = redis.get(key)
plt.colorbar(im)
imarray
get_type_hints(__main__)
tree = KDTree(numpy.array(ecef_cities))
forced_managed = False
concatenated_df = pd.concat(df_from_each_file, ignore_index=True)
ax.add_collection(lc)
nn.activate([0, 0])
layout.addWidget(self.datetime)
pd.Series(np.tile(c, n), [i.repeat(m), v.ravel()]).unstack()
image = wx.ImageFromStream(sbuf)
jagged_slice_of_a = a[:, (entries_of_interest)].diagonal()
BOOST_PYTHON_MODULE(__main__)
self.ToggleTool(self._NTB2_ZOOM, False)
pipe = subprocess.Popen(args, stdin=subprocess.PIPE, stdout=subprocess.PIPE)
utc_date = datetime.utcnow().date()
fig = plt.figure()
fexps = list(range(-1, -int(precision + 1), -1))
os.makedirs(dest)
H = np.random.randn(n, n)
get_index(lst, num, index + 1)
print([x for x in g2 if x[2] >= 1.5])
ax2.add_artist(bbox_image)
text = f.read()
points.intersects(poly.ix[0])
bars = forms.ModelMultipleChoiceField(queryset=Bar.objects.all())
mdev = np.median(d)
sns.heatmap(data=df2, annot=True, alpha=0.0)
self.__dict__ == other.__dict__
s = s.strip(string.punctuation)
dateeastern = dategmt.astimezone(eastern)
poly = np.polynomial.Polynomial(np.random.rand(d + 1))
os._exit(0)
dc.SetBackground(wx.Brush(self.GetParent().GetBackgroundColour()))
start_response(status, response_headers)
B = numpy.lib.stride_tricks.as_strided(A, shape=newshape, strides=newstrides)
aa = N.zeros((len(br), 2))
print(somelist[index])
rectangles.add(new_rectangle)
print(myFunction(myCount))
element = etree.Element(CDATA)
x, y = np.meshgrid(np.linspace(-2, 2, 200), np.linspace(-2, 2, 200))
Location4 = motion_plan(increasor(0, -1), alternator(0, 1))
Values = [f(x) for x in range(0, 1000)]
str(self.karma_delta)
AppHelper.runEventLoop()
sys.stdout.buffer.flush()
any(d for d in self.digits)
new_df = df.where(df.date >= last_week)
next(a)
df
data = urllib.request.urlopen(url).read()
now = time.time()
sys.stdout = os.devnull
print(datetime.date.timetuple(t1))
log.addHandler(ch)
count += 1
newlist.append(l[(i + j) % d])
myX, myY = text_center[0] + height / 2, text_center[1] - width / 2
client.set_string(key, str(val))
g = Group.objects.get(id=1)
self[key]
app = Flask(__name__)
d1[k].append(v)
d_keys = list(d.keys())
client_sock.send(response_headers_raw)
locations = Location.objects.all()
self.process_events()
index = [0, 2]
response
t.extend(t2)
sns.set()
args = parser.parse_args()
p2 = np.tensordot(p1, w, axes=([0, 2], [0, 1]))
df1 = df[swapidx]
id, value, _ = zip(*ans)
f.write(s)
print(form.errors)
main()
r, c = np.unravel_index(np.argmin(a), shp)
a, b, c, d, e, f, g = [object() for i in range(7)]
x, y, z = zip(*data)
sum([(i - 1) for i in list(c.values()) if i > 1])
self.lock.acquire()
wrapped_decorator
session1 = SessionSRC()
c.append(itemgetter(len(b) - i - 1)(b))
kmeans.labels_
X, Y = np.meshgrid(xi, yi)
module.init()
np.choose(x > 0, [-1, 1])
self.Layout()
(i for p, i in l1 if p), (i for p, i in l2 if not p)
fig = plt.figure()
wait = WebDriverWait(driver, 10)
fd = set(d.items())
HttpResponse(json.dumps(result))
pool = Pool(processes=4)
max(0, min(b, d) - max(a, c))
response.status = falcon.HTTP_404
already_loaded = s.query(A).filter(A.id.in_(random.sample(ids, 10))).all()
df
socket.send(toAddr, zmq.SNDMORE)
x = ClassName()
STARTMSB = [0]
table_name.addParseAction(noWhitespace)
logger.console(s)
critical_code()
index = pd.MultiIndex.from_tuples(list(product(individuals, time)))
MySQLdb.__version__
f = open(input_file)
dict(scores)
items = len(list(group))
all(l)
setattr(self, klass.__name__, DummyClass())
cur.execute(query)
result.append((int(k), na_list[0]))
your_application_main()
test_suite
ret = func(*args, **kwargs)
pycrypto_key = Crypto.PublicKey.RSA.construct((n, e))
win.scrollok(True)
self.queue = set()
root.mainloop()
a = np.arange(50)
app.login_manager.init_app(app)
encoded.hexdigest()
self.canv.drawImage(self.img, 0, 0, height=-2 * inch, width=4 * inch)
[l[0] - 1] + decr(l[:1])
len(ws.strip())
t.save()
w / w.sum().astype(float)
y = np.arange(100)
mailserver.quit()
print((name, seq))
h.hexdigest()
fpp = POINTER(c_float)()
d = dict(l)
list_a[k][j][i]
a[0:][::2]
canvas.setPageSize(landscape(letter))
[-2.0, 0.0, -2.0, 4.0, 10.0, 4.0]
model.py
corr_table = pd.concat([c(*t) for t in tups], axis=1)
[tuple[1:] for tuple in temp]
d = Naughty()
value_s = locale.currency(value, grouping=True)
fig = plt.figure()
unknown = set(data.keys()) - set(self.fields.keys())
doc = html.fromstring(body)
df = pd.DataFrame(sample)
var_c = 15.5
pn5 = pd.Panel(data, df.columns, df.index[4:], pd.RangeIndex(5))
gs1 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=outer[0])
naive_dt = datetime(2020, 10, 5, 15, 0, 0)
s = inspect.getsource(func)
bcrypt.hashpw(passwd_to_check, passwd) == passwd
pygame.draw.rect(*self.stim[stimType])
counter = Counter.objects.get_or_create(name=name)
p.print_help()
inputdict[key] = newvalue
self.destroyed.connect(self.handleDestroyed)
sys.stdout = f
f_out.write(block)
new_lis.sort(key=len)
print(date.to_ical())
npage = pdf_im.getNumPages()
outputs.remove(s)
plt.colorbar(sm, cax=cax)
j = json.loads(s)
subclass2.bar()
result.remove(a)
df_new
yag.send(contents=contents)
self.s = s
DEPENDS = []
WSGIPythonHome / path / to / python / 2.5 / exe / directory
Response({})
foo.x = 0
default_proxy_opener = urllib.request.build_opener()
self.cj.save()
list(triangle(100, 0.5))
self.data.insert(END, str(i))
root = pomFile.getroot()
s = requests.Session()
pygame.event.pump()
mat[x].append(random.random())
msg = MIMEMultipart()
row_count = sum(1 for row in fileObject)
A = np.array(np.random.randn(N, N))
f(10, 20)
myfunc()
c = np.mean(c, axis=0)
print(value, array2[i])
users = db.session.query(User).join(sub, sub.c.ml == User.numLogins).all()
print(outaction.default)
deploy()
bbox = np.min(a[0]), np.max(a[0]), np.min(a[1]), np.max(a[1])
b.index[b.argmax()]
max(v1 - v0 for v0, v1 in zip(values[:-1], values[1:]))
punc = punc.decode()
name = models.CharField(max_length=255)
s.push(20)
len(first)
source / usr / local / bin / virtualenvwrapper.sh
assert os.path.isdir(basedir)
self.sizer.Add(self.editname, (1, 1))
ax.grid(True)
len(A)
newfunc
[-2.0, -1.0, 0.0, 1.0, 2.0],
d.update(buf)
marky = interp(markx, x, y)
a[out.sum(axis=0) == 1]
any(equals)
list_y.remove(ely)
fig = figure()
f.seek(pos)
data = np.random.random((4, 10, 10))
root.deiconify()
self.__is_shut_down.wait()
self.axes.set_xlabel(xlabel)
pprint(A)
position = fin.tell()
U = np.zeros((N, N))
div = make_axes_locatable(ax)
line = next(infile)
c.most_common(1)
pdq.append(x1)
user = django.contrib.auth.get_user(django_request)
nose.main()
array([0, 2, 5, 9])
result = numpy.empty(data.shape[0])
upload_date = models.DateTimeField(auto_now_add=True)
ts = pd.to_datetime(str(date))
s = socket.socket()
label.set_fontproperties(ticks_font)
palette.setColor(palette.Light, QtGui.QColor(255, 0, 0))
count += 1
surf = ax.plot_surface(X, Y, mat)
print(cluster2)
1 + max(-1, min(a.dateEnd, b.dateEnd) - max(a.dateStart, b.dateStart))
df
x = list(range(5))
plt.subplot(121)
a.test()
print(m.__name__)
print(traceback.format_exc())
print(driver.current_url)
response_body = response.content
name = os.path.basename(os.path.abspath(filepath))
self.newString
_list.append(data)
result = [foo(x) for f in seq if bar(x)]
main()
barbarbar
do_something(cell)
b = np.reshape(a, (np.product(a.shape),))
print(PlaintextWriter.write(doc).getvalue())
sys.stdout.isatty()
print(x)
title = models.CharField(max_length=100)
plot(x, y1)
np.array(y)
jfile = json.loads(chunk)
application.listen(8888)
df
i, o, e = select.select([sys.stdin], [], [], 1)
b = [0, 2, 4, 5]
ax.plot(x, y, color=col_dict[class_col[i]], **kwds)
chardet_detector.result
dict(y=a.y, z=a.z)
map(type, a).count(int)
fig.canvas.draw()
pb.run()
rooms = Room.objects.filter(school=self)
bs = BeautifulSoup.BeautifulSoup(data)
signal.signal(signal.SIGALRM, lambda a, b: sys.exit(1))
n.parent
cache[s1, s2] = max(lcs(s1[:-1], s2), lcs(s1, s2[:-1]))
f.close()
len(rng)
fig = plt.figure()
server.login(username, password)
newpath, tail = os.path.split(path)
server.serve_forever()
tree = {}
plt.show()
aDict.update(dict(list(element.items())))
points.append((cos(radians(startAngle)), sin(radians(startAngle))))
ax.set_xlim(-0.6, 0.6)
a = np.ascontiguousarray(a)
lambda x: f(g(x))
d.quantize(Decimal(1)) if d == d.to_integral() else d.normalize()
a, b, c
ax.hist2d(x, y, bins=(xbins, ybins))
logging.getLogger().addHandler(fh)
result = curs.fetchall()
draw.flush()
lines.append(line)
x = [1, 0]
result
sfi = SHFILEINFO()
ET.tostring(root)
description = Column(String(100))
sum(sum(l))
[15, 8, 9, 6]
obj._meta.concrete_model._meta.app_label
blob_key = files.blobstore.get_blob_key(zip_file)
method = getattr(my_cls, method_name)
jsonf.write(data)
raise KeyError()
result = days[days.index(weekday):] + days[:days.index(weekdays)]
fig, ax = plt.subplots()
[Arthur]
data2b = np.array(np.random.uniform(0, 1, batchSize))
sock.bind((source_ip, 0))
opener = urllib.request.build_opener(urllib.request.HTTPSHandler(debuglevel=1))
s[-amount:]
app = wx.App(redirect=False)
soup = BeautifulSoup(page)
o.__hasattr__(a)
random.shuffle(words)
print(found[0].text)
call(*args, **kwargs)
df.dtypes
df
w, -x, -y, -z
self.configMap[key]
o.many2many.add(ModelB.objects.get(id=2))
ax = fig.add_axes([0.12, 0.12, 0.68, 0.78])
result_dict = collections.defaultdict(list)
self.right = right
method.__class__
self._callback(self._value)
setattr(self, item, value)
s[s.map(type).ne(str)]
rrset = response.authority[0]
result = [value_if_false, value_if_true][condition]
list(find_creators(f, builtins))
d = {}
pygame.draw.circle(srf, color, (x, y), radius)
username == line[1].strip()
bar = Foo()
xs = np.linspace(0, 8, 200)
Qapp = QApplication(sys.argv)
print(test.__dict__[a_string])
parent = elem.getparent()
np.diff(s.values)
ModelA.objects.instance_of(ModelB)
ax.set_xticklabels(ax.get_xticks(), fontproperties=font)
tips = pd.read_csv(url)
self._var1 = val
self.request.send(self.data.upper())
pts2_ = cv2.perspectiveTransform(pts2, H)
float(v)
yi = np.array([0.0, 0.5, 1.0])
[{(1): 2}]
time.sleep(1)
chapters += 1
cc0 = [x for x in cc]
5 / 2
i
USE_L10N = True
USE_TZ = True
y = np.matrix(x)
print(myre.group(0))
freq4[char] += 1
pprint(FW)
self.n += 2
distance_matrix_np = np.array(distance_matrix)
indices = np.empty((sizes[-1],), dtype=np.intp)
res.append(t)
MB_OKCXL = 1
cbar = plt.colorbar(surf)
t.left(90 * random.randrange(4))
screen = pygame.display.set_mode((200, 200))
out = process.stdout.readline(1)
app.debug = True
soup = BeautifulSoup(response)
b = np.random.rand(4)
new_d = pickle.load(file2)
crawler.crawl(spider)
NOTHING = object()
r = session.post(URL, data=login_data)
jsonify(**request.json)
allocate(tmp(gridsize, gridsize, gridsize))
x[y] += 10
height = GetSystemMetrics(1)
print(k)
ypxl2 = ipart(yend)
unhexlify(s)
self.list.setIndexWidget(index, button)
product = models.ForeignKey(Product)
regressor.score(X, y)
upload_directory(path, upload_file)
a = 42
w.start()
columns = [list() for i in range(10)]
f = Foo()
plt.contourf(grid)
xpointer = ctypes.addressof(asdouble)
extractor.runInParallel(numProcesses=2, numThreads=4)
sys.exit(app.exec_())
deactivate
df.columns = columns
setattr(targetCls, name, closure(name, func))
line_contents_expr.runTests([sample1, sample2])
request.start_time = time.time()
output = proc.stderr.read()
root = Tk()
os.close(fileHandle)
raise NotImplementedError
init()
self.view.setScene(self.scene)
ans_time = time.mktime(dtime.timetuple())
summary[s] = [int(x) for x in list(set(summary[s]))]
target_dict[key1][key2] = val
self.results = {}
my_set
self.children.append(kiddo)
print(key)
element = WebDriverWait(driver, 10).until(find)
loop1()
fd = os.open(os.ctermid(), os.O_RDONLY)
label.set_fontsize(15)
y = np.outer(np.sin(theta), np.sin(phi))
about = About.objects.get(id=1)
count += 1
df.replace(to_replace, np.nan)
show()
letter = input(prompt).strip()
t.append(z)
source_key.copy(dest_bucket_name, dest_key_name)
rms = audioop.rms(data, 2)
dict(zip(*([iter(List)] * 2)))
particles = [Particle(i) for i in range(500000)]
f.write(raw_img)
line_number -= 1
MyClass.defaults[key]
b = Boo()
cls()
v[:len(tmp)] += tmp
x_list = numpy.random.random(200)
ysize = len(np.unique(lons))
s2 = s1.index.to_series().shift(-1).loc[idx].astype(int)
self.SetSizeHints(minW=-1, minH=hsize, maxH=hsize)
i += 1
markx, marky
Thread(target=guiloop).start()
df
ax = plt.gca()
lab.pack()
ax2 = plt.subplot(122)
fig, ax = plt.subplots()
np.sqrt(self.variance)
phi2 = np.linspace(0, 5 * 2 * np.pi, 1000)
xml_output = response.read()
xx, yy = np.meshgrid(x, y)
print(list_of_strings)
np.cov(data.T)
ret.reserve(funs.size())
plt.setp(g.ax_heatmap.get_yticklabels(), rotation=0)
console.start()
mantissas[fixmsk] *= 10.0
reservations = conn.get_all_instances()
visited.append(rule)
np.random.seed(1)
print(tn.read_eager())
y.nonzero()
ax.axis((0, 2, 0, 2))
np.testing.assert_almost_equal(x, y)
df = pd.concat([df, pd.DataFrame(np.tile(np.nan, [len(df), 50]))], axis=1)
self._byhour
self._byminute
self._bysecond
df[sum_columns] = df.groupby(axis=1, level=1).sum()
ax2 = plt.subplot(2, 1, 2, sharex=ax1)
decorator1(f)
self.name = name
cpid = os.fork()
b = int(x)
print(t.get(timeout=1))
sublime.get_clipboard()
self.updater.setInterval(10)
print(m_swapped.shape)
sleep(5.0)
df.index += 17
minmax = [(min(v) if k else max(v)) for k, v in groupby(lst, lambda a: a < 0)]
r = requests.post(endpoint, data=request_parameters, headers=headers)
np.count_nonzero(y == 1)
tlist = []
file.close()
print(self._concrete_method())
d = sum(li[:4])
[(x + y) for x in xs for y in ys]
dis.dis(lambda x: str(x))
h.feed(page)
value = dictionary[key]
all(map(somePredicate, somIterable))
u.close()
print(res.status, res.reason)
args = docopt.docopt(_(__doc__))
print(data)
array[1]
print(obj.number)
sess.run(D)
f.close()
clientSocket.send(data.encode())
output.append(tmp)
print(i)
print(data[4].text)
sum(ord(c) for c in L)
fig, ax = plt.subplots()
os.write(out_fd, PASSPHRASE)
drawing = numpy.zeros([100, 100], numpy.uint8)
x, y = zip(*points)
help(newImg1.save)
a = handle.readlines()[1:]
oldtrace = [sys.gettrace()]
plt.xticks(list(range(ncols)), col_labels)
driver = webdriver.PhantomJS()
set([pd.Categorical(x, l[::-1], True).max()])
res.setdefault(k, [])
ha.plot_surface(X, Y, data)
main()
result = client.service.IsHealthy()
tf.truncated_normal_initializer(stddev=stddev)
self.session = Session()
Y = numpy.repeat(X[:, (j)], n).reshape((N, n))
print(x.bar())
a.pop(0)
results = [line.strip().lower() for line in f if line]
print(pir(df))
type = models.CharField(max_length=255)
A[0].shape
mercurial.__file__
fig = plt.figure()
print(hash.name, hash.hexdigest())
self.observer.join()
leng(s[1:], count)
slices_start = np.array([s.start for s in slices])
root = tree.getroot()
fig.colorbar(im1)
the_queue = multiprocessing.Queue()
self.readonly_fields
seen.add(found)
cls
partition(a_, equiv_)
soup = BeautifulSoup(br.response().read())
origlist.append(t)
session_config = tf.ConfigProto(gpu_options=gpu_options)
train, test = train_test_split(df, test_size=0.2)
app = Flask(__name__)
print(t.timeit())
a = np.empty(0)
Ni = f.shape[0]
data = json.loads(json_str)
hline.set_ydata((y, y))
ax = plt.subplot(111)
get_result()
c = conn.cursor()
client = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
afun
s.close()
a(your_list)
b_sub = b[mask]
self.gamma = tf.Variable(tf.constant(1.0, shape=[depth]))
z = np.linspace(1.0, 2.0, 20)
lock.acquire()
matplotlib.pyplot.yticks(yint)
self.op = op
s.post(url, data=user_data)
fl.close()
comment.save()
john.save()
tile_array(a, 2, 2)
AlwaysCallable(self.__class__)
fig = plt.figure()
max(0, min(x, 255))
pool = Pool(8)
self.grid.CreateGrid(25, 8)
self.vline.set_xdata((x, x))
now = datetime.now(timezone.utc)
conn1 = psycopg2.connect(dsn1)
len1, len2 = len(string1), len(string2)
time.sleep(0.1)
print(c.fetchall())
pythonbrew_install
list(d.items())
n = len(l)
pylab.legend()
np.random.shuffle(cols)
files = pattern.findall(str)
XmlStream.__init__(self)
screen = curses.initscr()
cmd = sys.argv[1]
x = [0] * 51
self.testbed.init_user_stub()
architecture / webservice_tech
print((n, sorted(p)))
path.append(lastnode)
data = response.read()
self.lbl.grid()
y_vals = np.cumsum([0] + pieces)
db.tbl.insert(**db.tbl._filter_fields(newRowAsDict))
p1.join()
Py_XDECREF(module)
list_of_tuples.append((x, y))
a = np.random.rand(6, 4)
array = [([0] * len(Split_Line[1])) for i in Split_Line[0]]
win.unmaximize()
assert x.shape == y.shape
app = Flask(__name__)
to_stream.write(processed_buf)
print(d[0])
next_down(x)
command = lambda i=i, j=j: update_binary_text(i, j)
print(path_buf.value)
weights.dot(features) + bias * len(weights)
here = lambda x: os.path.abspath(os.path.join(os.path.dirname(__file__), x))
g = sns.pairplot(iris)
fig = plt.figure()
image = Image.open(filename)
not [v for v in list(remaining_weights.values()) if v != 0]
c_ulong_type = PyTypeObject.from_address(id(c_ulong))
ax.set_ylim(ymin, ymax)
unixtime.days * 24 * 60 * 60 + unixtime.seconds + unixtime.microseconds / 1000000.0
f.close()
endif
ax.set_xticklabels(xlabels)
seen = set()
stdin_fileno = sys.stdin.fileno()
dic = {x: [] for x in lis}
win2.destroy()
print(x)
gray = cv2.medianBlur(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), 5)
a = np.empty(guess.shape, dtype=int)
result = pipe.stdout.read()
self.sys_stdout = sys.stdout
now = datetime.now()
cv2.drawContours(close, [cnt], 0, 0, -1)
print(new_dict)
int(0.5 + 10 ** ((n - 1) * K))
matched_data.append(d)
zf.close()
{{}}
8595000
px = pygame.image.load(path)
A = A.view(A.dtype[0]).reshape(-1, len(A.dtype))
i, WSSSE
cursor = conn.cursor()
os.abspath(os.path.join(__file__, os.path.pardir, file_name))
p.start()
filedescriptor = urllib.request.urlopen(req)
reader = csv.reader(f)
numpy.subtract((10, 10), (4, 4))
str(h)
os.startfile(filepath)
csv.writer(f).writerows(list_of_lists)
wb.ActiveSheet.ExportAsFixedFormat(0, path_to_pdf)
ax = fig.add_subplot(212)
data_stream = Popen(mycmd, stdin=PIPE, stdout=PIPE)
cap.release()
zipped = [list(t) for t in zip(x, y)]
print(e.__traceback__)
my_iterator = iter(sorted(a + b + c))
noise = np.random.randn(100)
CS = ax.contourf(xi, yi, zi, 60, cmap=plt.cm.jet, zorder=1)
print(songs[song_index])
len(self.nodes)
s = requests.Session()
options, args = parser.parse_args()
infile.close()
ws.add_image(img)
reader.Update()
False
print(link)
[1, 2, 0]
x = a[:i]
E += potential(np.sqrt(np.sum((x[i] - x[j]) ** 2)))
a = np.array([2, 6, 4, 8])
matches = (i for i in range(len(b), 0, -1) if b[:i] == a[-i:])
content = forms.CharField()
nomwe_corpus.append(nomwe.split())
f, ax = plt.subplots(1, 2)
responses_dir = os.path.dirname(os.path.realpath(__file__))
match = match_obj.group(0)
csvfile = StringIO.StringIO()
ax = fig.add_subplot(111)
seen.add(first)
writer.writerow(row)
self.__str__()
bundle
vector = vector.reshape(1, len(vector))
d = np.diff(np.asarray(b, dtype=int))
app = Flask(__name__)
device.close()
seq = chain[:]
k0.lst.append(1)
host = req.get_host()
False
next(result)
src_address = Column(String(16), index=True)
max(map(commonprefix, pairwise(suffixes)), key=len)
max(hand, key=lambda c: rank_cards_map[c[0]])
df = df.replace(nan, 0)
fp[(i), :] = fp[(i + 1), :]
p = Pool(1)
keybd_event(Key, 0, 1, 0)
solar_time = datetime.combine(dt.date(), time(0)) + timedelta(minutes=tst)
df2.L = df2.L.str.strip()
setattr(instance, attr, value)
run_time = time.time() - start
sess = tf.Session()
1 == 1 + 0j == 1.0
nums = np.array([1, 1, 1, -1 - 1, 1, -1, 1, 1, -1, -1, -1, 1, -1])
fruitdict = {}
raise AttributeError
out = out[::-1]
app = Flask(__name__)
p.save()
B = dataset[where[~a_idx]]
df.groupby([df.Type, isnull]).size().unstack()
mydict[k] = mylist.count(k)
value
bg1 = cv2.BackgroundSubtractorMOG()
[(c in this.d and this.d[c] or c) for c in this.s]
yaml.Loader.yaml_constructors
[row[column_number] for row in array]
year = int(yourString[0:4])
data = np.arange(n_data)
p.children.append(Child(loc=cloc, status=cstat))
port
x + y.todense()
(1, 2) == 1, 2
[True, False, False],
buff = f.read()
Y[-fc:], alpha, beta, rmse
np.sum(-p * np.log2(p) for p in probs if p > 0)
sys.stdout = St_ampe_dOut()
p.close()
x.append(2.2)
f.read(8)
y = a[2] * b[0] - a[0] * b[2]
abs(z.T - z)
len(self._data.values)
object_class = models.CharField(max_length=20)
x1 = np.random.normal(0, 10, 100000)
sorted(s, key=lambda t: -t[0] * t[1])
f_new = pickle.loads(f_string)
pcolor(df1.T)
type(unicodecontent)
install_hooks.post_install()
threadB.join()
1 + x + x ** 2 / 2.0
figures = [x for x in matplotlib._pylab_helpers.Gcf.get_all_fig_managers()]
Base = declarative_base()
Story.append(paragraph)
palette.extend((v, v, v))
print(difft(time(20, 40, 0), time(18, 41, 0)))
line_num += 1
self.id == other.id
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
a = models.CharField(max_length=42)
color = QtGui.QColor(value)
im.thumbnail(size_maxi, Image.ANTIALIAS)
something()
self._fail(self.failureException(msg))
meds = df2.median().sort_values()
np.nan
response
{offset(k, base): v for k, v in list(dct.items())}
reactor.listenTCP(8001, server.Site(root))
print(result.column_name)
self.lock = threading.Lock()
mdb.connect(**connectParams)
root = LH.fromstring(text)
soup = BeautifulSoup(html)
headers = {}
result = can_count_a * a + can_count_b * b
print(f.upper())
logger2.addHandler(logfile)
print(key, word_dict[key])
self.treeview.append_column(self.tvcolumn0)
vals_array.fill(np.nan)
my_dict = defaultdict(list)
out = input[binary_matrix.ravel()[lin_idx] == 1]
PolarAxes.LogPolarTransform(self._axis, self._use_rmin)
iter([data])
print(df1.T)
pool = mp.Pool()
target_path = imp.find_module(target)
fig, ax = plt.subplots(2, sharex=True)
pp.savefig(plt.gcf())
self.happiness = self.wealth / global_wealth
self._intersections[a][b] += 1
{{login.login_date}}
child.join()
heapq.nlargest(n, iter)[-1]
set(l1) & set(l2)
process.join()
items = Item.objects.filter(created_date__gte=aMonthAgo)
PyType_FastSubclass(Py_TYPE(op), Py_TPFLAGS_LIST_SUBCLASS)
b = [a]
b = arr(a)
name = Column(String)
link.next_sibling.next_sibling
Clock.schedule_once(self.quit_screen, 0)
db.session.add(group_from_factory)
word.lower()
ws = wb.get_active_sheet()
self.parent = weakref.proxy(parent)
X = np.random.randn(10, 4)
app = QApplication(sys.argv)
list1 = [[-2.0, 0.0, -2.0, 2.0, 10.0, 2.0], [-1.0, 0.0, 2.0, 1.0, 5.0, 4.0]]
pylab.draw()
self.connect((host, 80))
[(10 ** (i * 2 / 9.0)) for i in range(10)]
a * x + b + c * np.exp((x - d) / e)
self.grid(sticky=N + S + E + W)
0
module1.func1 = self.old_func1
spam._original(testcon)
socks.setdefaultproxy(socks.PROXY_TYPE_SOCKS5, ip, port)
cv.WriteFrame(video_out, frame)
isinstance(50, list)
plt.hist((a, b, c), **common_params)
ser = serial.Serial(s_name)
list(filter(exists, L))
object.__new__(cls, *args, **kw)
query_set.filter(active=False)
self.var_a + self.var_b + x
b = [45, 42, 0, 1, -1, 0]
getattr(obj, name)
GetCurrentProcessId() == GetWindowThreadProcessId(wnd)
self._a
new_cmap
lines[0]
parsed = urlparse(url)
A.foo()
response.headers
top.after_cancel(job1)
[0, 0, 1, 0]
t = time.strptime(line, fmt)
ax1.add_line(copy.copy(line1))
h.file.read()
resultFyle.close()
b = c_[a, c]
ax1.set_ylim(-5, 5)
df[df != 0].cumsum(axis=1).min(axis=1)
tree = etree.parse(response, htmlparser)
print(html)
out = dat[top_left[0]:bottom_right[0] + 1, top_left[1]:bottom_right[1] + 1]
[f(0) for f in fs]
print(child.tag, child.text)
zeta = 50
pos = nx.spring_layout(G)
self.__dict__.update(x.__dict__)
d = distances[clust[i].id, clust[j].id]
a[2:7 + 1] = b
response
N = len(perms[0][0])
asyncore.loop()
s = s.replace(hit, chr(entnum))
float(s)
sftp_client = ssh_client.open_sftp()
f = Foo()
pet_food.save()
response
first_sheet = book.sheet_by_index(0)
set(array1) & set(array2)
fnew[0]
dire = sys.argv[1]
count
conn = engine.connect()
logistic.cdf(0.458)
worksheet.fit_num_pages = 1
X[np.arange(len(Y)), Y] = 1
dist = udist.data
text.draw(fig.canvas.get_renderer())
funcs[2]()
root = Tkinter.Tk()
result
reader = csv.reader(f)
fig = plt.gcf()
parser = etree.XMLParser(schema=schema)
mymean = [np.mean(myarray[t, yy, xx]) for t in np.arange(5)]
raise MemoryError()
m_action.add(action1, action2)
img = img[c1:c1 + 25, r1:r1 + 25]
bot.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
w, v = np.linalg.eig(A)
writer.writerow([name, membership])
result = res.pop(0)
result
httplib.HTTPConnection.__init__(self, *args, **kwargs)
anobj.amethod(x)
loop = asyncio.get_event_loop()
fig = plt.figure()
0
print(GetUserInput(listOfOptions, True).getInput())
l[0]
xcode - select - -install
self.server.shutdown()
print(datetime.datetime.fromtimestamp(time.time()))
result = [[] for i in range(n)]
conn.endheaders()
img = Image.open(StringIO.StringIO(file_body))
AMOServer.Restore(AMORestoreInfo)
True
df
self.transport.loseConnection()
self.window.add(self.button)
actions.move_to_element(element)
points.append((xs[i], ys[j], zs[k], v))
data
show_banner()
isinstance(9, int)
d2.year - d1.year + (d2.month - d1.month) / 12, (d2.month - d1.month) % 12
right_thresh[:, :w - i] += img[:, i:]
setattr(self, kw, arg)
config = tf.ConfigProto(log_device_placement=True)
signal.alarm(10)
plt.imshow(g)
some_dict = dict(zip(sample(population, n), sample(list(range(1, 100000)), n)))
soup = BeautifulSoup(f.fp)
self.content_length = content_length
d[k].append(v)
l_counts.sort(reverse=True)
a = numpy.empty(shape=(4,), dtype=object)
example.print_value_2(s)
iter(self._choices)
a[mask] = 10
response = requests.get(URL.format(**params))
parent = elem.getparent()
f.close()
jsonObj = json.load(f)
unq_count = np.bincount(id)
Doc.update(set__VAR=Val, set__VAR2=Val2)
fig = plt.figure()
self.button1.pack()
print(p.sub(lambda mo: d[mo.group(1)], mystring))
x = np.random.randint(0, 4, size=(8, 10))
treeaslist.extend(self.makeList(aNode.rChild))
np.allclose(pi[0, 0, 0], np.linalg.pinv(b[0, 0, 0]))
os.close(1)
r = requests.get(url)
plt.ion()
self.__dict__.clear()
fig, ax = plt.subplots()
result = df2.reindex(np.union1d(df1.index, df2.index))
elem.clear()
f = scipy.linspace(0, fs, N, endpoint=False)
sequence2 = record2.seq
posts = db.ListProperty(db.Key, indexed=False)
ax.plot([1, 2], [1, 2])
img_file = Image.open(image_name)
transitions == 2
signal.alarm(0)
print(partsChild.childNodes[0].nodeValue)
name.ljust(15)
dct = json.loads(my_json_str)
print(USAGE)
True
fig = plt.figure()
self.crawler_process.start()
pinit = [1.0, -1.0]
len(set(y))
pd.Series(1, set(x))
foo = Foo()
gc.collect()
m = len(df)
mask = np.ones(len(array), dtype=bool)
ax.set_yticks(np.arange(AUC.shape[0]) + 0.5, minor=False)
_generate_range_values(start, end)
cb = fig.colorbar(cf, cax=cax)
plt.barh(yvalues, xvalues, figure=fig)
a = a[:, ::-1]
non_list_items.append(item)
suite = unittest.TestSuite(l)
myParent.__init__(self, customParam)
A -= A.mean()
fig = plt.figure()
soup = BeautifulSoup(urllib.request.urlopen(url).read())
print(len(seq_record))
itertools.compress(d, map(lambda x: x > 4, a))
app = QtGui.QApplication(sys.argv)
plt.pause(0.02 * 200)
os.remove(temporarylocation)
log.addHandler(custom_logger.MyHandler())
user = request.db.query(User).filter_by(id=userid).first()
print(self.a, self.b)
cls.funky = 1
x = np.array([u0, phi0])
parser.print_help()
b.sum(axis=0)
n, mod = divmod(n - 1, len(digits))
list_1 = [item for item in list_1 if f(item)]
cv2.waitKey(0)
server.sendmail(emailfrom, emailto, msg.as_string())
df1.dot(t)
q.task_done()
p = readdir(dir_p)
len(x)
a = np.array([list(range(1, 10)), list(range(1, 10))])
heapq._siftup(h, i)
bundle
full.paste(img, (x * w, y * h))
self.accept_imports()
False
df
chunks = [files[i:i + chunksize] for i in range(0, len(files), chunksize)]
random.shuffle(l)
data_frame = data_frame.where(data_frame < 0, 0)
np.median([9, 2, 0, 1, 0])
text = text.replace(key, value)
plt.plot(t, s, color=c)
pylab.plot(t, s)
print(self.x)
res.append(tasks.process_read_pair.s(r1, r2))
gevent.sleep(0.5)
BY = np.take(B, y + 1)
self.assertEqual(self.expected, isEven(self.num))
db.session.add_all(items)
json_object = json.load(response)
self.conn.set_isolation_level(0)
app = wx.PySimpleApp()
{{element.product}} - {{element.price}}
data = s.recv(1024)
figure()
initquacker()
sys.getsizeof(2 ** 99)
self.__dict__.pop(*args)
zi = ml.griddata(x, y, z, xi, yi)
print(nCr(4, 2))
string = json.dumps(lst)
df.iloc[-6:-1, (2)]
pprint.pprint(list(chunks(list(range(10, 75)), 10)))
print(NL)
m = np.random.randint(20, 100)
x.astype(int)
buffer.open(QtCore.QIODevice.WriteOnly)
print(f.readline())
state = models.ForeignKey(USState)
serializer_class = WdigetSerializer
work.join()
src_proj = src.GetProjection()
df.dot(v2)
fooarray[key1, key2] = value
d = OrderedDict({x: x for x in range(10)})
v = -np.cos(np.pi * x) * np.sin(np.pi * y) * np.cos(np.pi * z)
Quota.extend(lstnans)
random.sample(list(range(100)), 20)
c.append(a[k])
root = tk.Tk()
cli.cmdloop()
array = array[mask]
log.addHandler(handler)
f(i)
dt = datetime(2008, 1, 1, 0, 0, 0, 0)
D = NP.random.randn(10000 * 10).reshape(1000, 10)
app = Flask(__name__)
w.close()
search_response = urllib.request.urlopen(url)
deleteL[write_i:]
d = np.diff(condition)
http_server = tornado.httpserver.HTTPServer(application)
self.f()
i += 1
W = nx.DiGraph()
response
ax.imshow(gray_data, cmap=cm.gray)
area += x[i] * y[i + 1] - x[i + 1] * y[i]
print(i, repr(time.time()))
self.finish()
dat2 = np.array([1, 2, 1, 2])
len(self.m[0])
id = Column(Integer, primary_key=True)
f = lambda x: x * math.cos(x - 4)
json_data = data.dumps()
do_stuff(line)
heapq.heappop(gens)
out_f.getvalue()
g.ax_joint.plot(row[0], row[1], color=colors[i], marker=markers[i])
display.stop()
request = mechanize.Request(url)
profile = webdriver.FirefoxProfile()
f = inspect.currentframe()
screen.fill((200, 100, 200))
print(data)
ax2.plot(dates, data)
prime_slices = [[prime for prime in primes if prime < n] for n in range(1000)]
self.rowconfigure(0, weight=1)
self.sck.recv()
b = a[:]
[0, 1, 2]
name = models.CharField(max_length=100)
white_areas = (red == 255) & (blue == 255) & (green == 255)
math.pi
1, 8, 1, 8
{func: result.get() for func, result in list(results.items())}
gene = info[this_re.start(0):this_re.end(0)]
result = self.func(x)
sys.getsizeof(foo1.__dict__)
fig = plt.figure()
gf.seek(0)
fig, ax = plt.subplots()
count += 1
nltk.__version__
k_keys_sorted = heapq.nlargest(k, dictionary)
hax = plt.subplot(1, 2, 1)
session.add(w_1)
test.plus(1)
console = logging.StreamHandler()
db.session.add(group_from_factory)
self.sock.connect_ex(self.socketpath)
points = np.random.random((10, 2))
b[a > 80] = funcC(a[a > 80])
Fraction(1, int(xc) + 1)
r = list(range(-int(n / 2), int(n / 2) + 1))
fcntl.fcntl(fd, fcntl.F_SETFL, flags_save & ~os.O_NONBLOCK)
self.idImage = self.canvas.create_image(0, 0, image=image1)
s.connect((host, 9))
l.sort()
product.append(i * 5)
a = [4, 6, 12]
db_thread = threading.Thread(target=main_loop, args=(socket_file_name,))
data = [[x.text.strip() for x in row] for row in table.getchildren()]
os.path.join(sys._MEIPASS)
app = Flask(__name__)
request.user and request.user.is_authenticated()
form = Product(request.form)
i, j = np.indices(A.shape)
decompressor.decompress(part)
Vote.objects.filter(choice=self).count()
kOUT[i] = func(TempLake[i], Z)
type(foo)
read_pdf = PyPDF2.PdfFileReader(pdf_file)
gui.show()
columns = [list() for i in range(len(headers))]
do_final_thing_with(obj)
pickle.dump(somedata, f)
distance(a, c) + distance(c, b) == distance(a, b)
foo(depth + 1)
X.tocsc()[:, (unique_columns)]
deque(f, maxlen=n)
csv_contents.append(line)
pd.io.json.dumps(summary)
numC = random.randint(1, 100)
stdout.read()
self.output.reset()
window.reserve_space(0, 0, height, 0)
data = sorted(data) + [100000]
label.show()
data_loaded = json.loads(data)
killasgroup = true
numeric = lambda x: int(x) if x.isdigit() else 0
name = db.Column(db.String(100))
text[text.startswith(prefix) and len(prefix):]
stack.pop()
subsets = list(range(1, 2 ** n))
base_pic.save(file=result_pic)
out_queue.put(result)
print(repr(points))
result
parse(InfiniteXML())
self.f.flush()
plt.imshow(im_out)
i += 1
x &= ~(1 << index)
sm.stats.lillifors(x)
handler = logging.FileHandler(filename)
self.dataChanged.emit(QtCore.QModelIndex(), QtCore.QModelIndex())
self.extend(list(args))
print(info.groups())
window = MainWindow()
img.show()
nms = nms.dropna(thresh=2)
self.player.add(self.source, self.scaler, self.fvidscale_cap, self.sink)
jfile = json.loads(line)
l = [1, 5, 7]
print(Ellipse((1.0, -1.0), (2.0, 0.5)).distance_from_origin())
cls
self.__dict__
fs2 = frozenset([666, 42])
buf.append(data)
app.register_blueprint(admin)
d.my_attr
wrapper
isinstance(f, io.IOBase)
s = socket.create_connection(*args, **kwargs)
print(x.data)
findex.fromfile(f, findex[0])
{{department.product_count}}
func(**kwargs)
self.a.b.c = value
print(np.roll(v2, -rot)[:v.size])
brush.add_point((event.x, event.y))
seq.ratio()
split = [l[i:i + len(l) / cols] for i in range(0, len(l), len(l) / cols)]
arr = [(a * 2 if a < b * 10 else -a) for a in arr]
x = bar(x)
delattr(Dummy, attrname)
embed = tk.Frame(root, width=500, height=500)
computed[n]
d[c] += 1
rows = [row for row in reader]
data = json.load(data)
ind = np.arange(0, 12, 2)
False
do_your_subprocess_stuff(temp_file)
before = datetime.datetime(year, 1, 1)
seen = set()
self.conn.set_isolation_level(old_isolation_level)
dis.dis(lambda : str(100000))
keys.sort()
opener = urllib.request.build_opener(proxy_support)
utcnow = Utcnow()
y = np.interp(t, np.arange(len(y)), y)
id(df.index), id(df2.index)
plt.show()
Base = declarative_base()
self.get(username__iexact=username)
x = np.linspace(np.min(roots) - 50, np.max(roots) + 50, num=1000)
hov = ActionChains(wd).move_to_element(element)
parse()
currdir = os.path.dirname(os.path.abspath(__file__))
soup = BeautifulSoup(content)
a = np.random.randint(N, size=n)
x = np.ravel(A).reshape((9, 1))
get_field = cls._meta.get_field
foo.method1()
list(A.__dict__.keys())
[0, 0, 0, 1]
w = gtk.gdk.get_default_root_window()
arg_dict[o] = ast.literal_eval(arg)
list(range(start, stop + step, step))
lst.append(old_d[key][i])
delta = n / 10
l = []
i += 1
jsonf.close()
len(self._od)
noo = Foo()
print(i, foo())
self.Add(self.buttonPanel2, 0, wxALL | wxALIGN_LEFT, 5)
next(bar)
funcs.append(lambda : x)
fig = plt.figure(1)
hxs = HtmlXPathSelector(response)
filteredKeys = [key for key in list(aDict.keys()) if searchString in key]
d[keys]
json_data = open(json_file)
handler.response.write(content)
pprint.pprint(L)
response
self.open(self.host, self.port)
self.my_class = my_class
academic_year = models.CharField(max_length=255)
print(response)
fig, a = plt.subplots()
x + x
wrapper
[1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0]
f.read()
outfile.write(file1.read())
plt.plot_date(dates, y_values)
digits = (character for character in input_string if character.isdigit())
map(lambda k: nthRootOfr * exp((t + 2 * k * pi) * 1j / n), list(range(n)))
plt.scatter(group.x, group.y, s=sizes[i], alpha=0.5, label=labels[i])
df
ipc_event_cmd.buffer.add(data_str)
print(i)
self._tarobj = tarobj
sample.index = pd.MultiIndex.from_tuples(list(product(list(range(100)), time)))
my_mesh.SetControlPointAt(v, 0)
d[i].append(x[i])
L.remove(M)
self.value
obj = MyModel.objects.create(val=1)
self.list_one.setGeometry(0, 0, 500, 100)
threading.Thread(target=op).start()
p = Pool(5)
matplotlib.__version__
d1.update(d2)
self._test = get_initial_value()
tests.append(make_test(i))
bio_tagged_sent.append((token, tag))
[1, 1, 0, 1]
app = Flask(__name__)
ax.xaxis.set_major_locator(plt.FixedLocator(x_coordinates))
print(re.sub(pat, repl, str))
list(x.values())
lengths = {key: len(value) for key, value in d.items()}
next(generator)
pprint.pprint(fruit)
self._stdout.close()
self.setPath(path)
existing_item.put()
cskel = np.logical_not(skel)
li.append(li[-1] + 1)
type(0)
B[2, inverse[A[1] == 2]] = A[2, A[1] == 2]
self.submit_form(login_form)
data = []
indices[tuple(column)].append(index)
a = []
max(stats, key=stats.get)
test()
math.ceil(4500 / 1000)
my_handler.setFormatter(log_formatter)
reshaped_data_m = tranposed_data_m.reshape(250000, 64, 64, 2)
[(x + [nan] * (max_lenght - len(x))) for x in l]
lst.append(i + 1)
fileobj.close()
d = np.arange(1, 21)
print(args.a, args.b)
print(sorted(finder.nbest(bigram_measures.raw_freq, 2), reverse=True))
plt.xlim(1.8, 9.2)
plt.plot(data2)
s.bind((HOST, PORT))
a += 1
self.template = self.template.lower()
Thread.run(self)
os.fstat(g.fileno()).st_nlink
merged = collections.defaultdict(list)
sample_func()
a = [[0] * 10] * 10
mydict = recursivedict()
dataQ = Queue.Queue(maxsize=0)
do_something(line)
parser = argparse.ArgumentParser()
[7, 0, 7],
y, x = np.nonzero(img)
chars.append(escaped_str[i + 1])
permissions[0].id
pool.join()
f = interpolate.UnivariateSpline(x, y, s=0)
sum((w[i] * (y[i] - s(x[i]))) ** 2, axis=0) <= s
dict(form=g)
list(calendar.day_name)
fh.close()
yf = np.random.uniform(np.min(y), np.max(y), size=(f,))
print(str(1).zfill(2))
[1, 1, 1, 0]
subplot(121)
sock.settimeout(0.01)
merged = pd.concat(df_list, axis=0)
np.array(data[:]).reshape(shape[:])
data = np.tile(data, (50, 50))
self.list.insert(i, v)
c = array([[1, 1, 1]])
print(row)
count += 1
b, a = butter_bandpass(*args, **kwargs)
file, line
glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR)
d
self._window.add(vbox)
foo_noniterable(noniterable)
validate_email(email.strip())
session.add(new_prod)
p(1) / 2 + p(1) / 2 + 1 / 2
self.proxy.setSourceModel(self.model)
setattr(self, key, value)
l.append(foo)
cls(list(datadict.items()))
my_list = json.loads(data[0][1])
f = x & 255
username = db.Column(db.String(80), unique=True)
b.extend([0] * (minlen - len(b)))
self.layers += [NeuronLayer(self.n_outputs, self.n_neurons_to_hl)]
m = regex.match(s)
[i for i in eq2.atoms(Pow) if i.base == a]
ispower(50, 5)
dftmtx = np.fft.fft(np.eye(N))
response = urllib.request.urlopen(request_object)
[]
nan_idx = np.where(np.isnan(a))[0]
count += 1
a = np.array([0.1, 0.2, 1.0, 1.0, 1.0, 0.9, 0.6, 1.0, 0.0, 1.0])
json_text = json.load(json_file)
colors = np.r_[np.linspace(0.1, 1, 5), np.linspace(0.1, 1, 5)]
print(df)
page.mergePage(new_pdf.getPage(0))
Foo.x = range(1, 4)
format_to_year_to_value_dict = defaultdict(dict)
sampleip0 = []
m = [0] * (N ** 2 + 1)
sendSock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, True)
lock.release()
lxml.version
row in self.data[column]
keys = list(dictionary.keys())
bin(a & b)
extension = mimetypes.guess_extension(content_type)
updiag = [0.5] * n
app = Flask(__name__)
r = q.T.reshape(-1, k, n)
logger.propagate = False
print(f.root.data[1:10, 2:20])
list(islice(set(a).difference(b), 100))
out[0]
main()
splits = list((m.start(), m.end()) for m in re.finditer(pattern, string))
w.setLayout(layout)
self.properties = {}
self._close_database()
ipshell()
response = br.submit()
ctx.stroke()
oldmodule.__dict__.clear()
poller.register(client_receiver, zmq.POLLIN)
ax = plt.subplot(111)
print(np.dtype(float).itemsize)
tree_selection = treeview.get_selection()
output_notebook()
log.error_log.addHandler(h)
outputfile.write(line)
basename = os.path.basename(filename)
log.msg(response)
plt.show()
print([word for word in lst if word in test])
exclude_patterns = []
s = Search.from_dict(body)
LB[i] <= x[i] <= UB[i]
logging.config.fileConfig(_log_config_location)
poly_verts = [(2, 2), (5, 2.5), (6, 8), (2, 2)]
a * x * x + b
chars += len(word) + 1
columns = list(set(columns))
pixel = walnut.getpixel((x0, y0))[:-1]
as_strided(A2[0], shape=(2, 2, 2), strides=(8, 8, 4))
HttpResponseBadRequest()
object_list.filter(user=request.user)
com.convert_robj(rdfrm)
p(10)
fig, ax = plt.subplots(1, 1, figsize=(9, 5))
print(s)
y = np.cos(angle)
result.result
dates = [df.index[i] for i in row_pos]
app.MainLoop()
v_box.addWidget(self.list_one)
plt.colorbar()
BLUE_MAX = np.array([50, 50, 255], np.uint8)
FACTORY_FOR = Comment
threading.Thread(target=tail_forever, args=(fn,)).start()
a.argsort()
timestamp = time.mktime(foreign_dt).astimezone(pytz.utc).timetuple()
L = sorted(zip(x, y), key=operator.itemgetter(0))
new_df = multiindex_me(mydf)
False
bytearray(content[current_pos:final_pos])
spamwriter.writerow(row)
list(islice(iterable, n))
-0.0121994
result = [(item * item) for item in get_list() or []]
[1, 2]
newImage.paste(im, (x1, y1, x1 + old_width, y1 + old_height))
image = ImageGrab.grab()
mymodule.myfunc()
single = [i for i in chain.from_iterable(combined)]
mng.resize(*mng.window.maxsize())
print(parser.parse_args())
patch_distutils()
self.set_positions((xs[0], ys[0]), (xs[1], ys[1]))
words = string.split()
keys = A.keys() & B.keys()
data, addr = sock.recvfrom(1024)
dis.dis(fr.f_code)
thingys.append(x)
wrapper
loop = asyncio.get_event_loop()
line = line.rstrip().split(delimiter)
count_2.most_common()
f = mux41(0, 1, 1, 0)
b = [4, 5, 6, 7]
self.number_of_employee = number_of_employee
max_list = group_list.map(reduce_by_max).collect()
print(f.read())
spl = [list(y) for x, y in itertools.groupby(lst, lambda z: z == w) if not x]
data = f.readlines()
cls.D[t]()
get_something(a)
zvalues = f(xvalues, yvalues)
root.lift()
dy = [0.5, 0.5, 0.5]
self.obj = obj
print(df1)
filehandle.truncate()
fig.subplots_adjust(hspace=0.1, wspace=0.1)
-ea
xlock = threading.Lock()
gram_matrix
a.append(5)
df.Name.str.contains(pat)
df1 = pd.DataFrame(d)
print(f())
pimage.putpalette(PALETTE)
{}
opener.add_handler(my_handler)
self.scrollbar.grid(row=0, column=1, sticky=(N, S, E))
customer = models.CharField(max_length=150)
pyplot.show()
old_stdout_fileno = sys.stdout.fileno()
frame.pack()
random.shuffle(target)
arg(a, b, c)
Process(target=loop_a).start()
app = QtGui.QApplication(sys.argv)
grid = np.random.random((10, 10))
self.typemap = {}
s.close()
idx = np.argmax(means)
root = tree.getroot()
maxx = max(dic.values())
min(later, key=lambda d: get_datetime(d[0]))
self._add(val, self.root)
self.view.setDragDropMode(QtGui.QAbstractItemView.InternalMove)
_decorator
histo = gg.apply(lambda x: x.count())
arr[i] = get_something_from_database()
X = np.arange(size)
fn = sys.argv[1]
print_size(**dict)
signal.signal(signal.SIGHUP, handler)
L = [1, 1, 2, 2, 2, 2]
imported_modules = {m: importlib.import_module(m) for m in modules_to_import}
A * x
clf = linear_model.LinearRegression()
counts, bins = np.histogram(x, bins=num_bins)
np.vectorize(d.__getitem__)(a)
existing_category = db.get(category_key)
print(clusters.shape)
ElementTree.dump(root)
W = DFT_matrix(N)
os.mkdir(newdir)
req = urllib.request.Request(path, mydata)
_autoargs
False
admin.autodiscover()
x = dict((row.SITE_NAME, row.LOOKUP_TABLE) for row in cursor)
chrome_options = webdriver.ChromeOptions()
f.subs({x: 0})
conn.commit()
title = models.CharField(max_length=100)
df = df[df.date1 == df.date2]
a[a > 0.7].min()
p.close()
B = pd.Series(list(range(1, 5)))
numpy.unravel_index(a.argmax(), a.shape)
figs = list(map(plt.figure, plt.get_fignums()))
y, x = find_image(im, tpl)
saver = tf.train.Saver()
gtk_dlls = []
frame.Show(True)
IsoInB = 0
IsoOutA = 0
IsoOutB = 0
self.parser.set(self.name, attr, str(value))
logger.addHandler(ch)
df = pd.read_csv(io.StringIO(temp), names=list(range(10)))
mapping = dict(zip(lookup[:, (0)], list(range(len(lookup)))))
index += 1
arr[i, j] += 1
base_value * 1.0 / 2.54
pos = nx.spring_layout(G)
print(is_new_style(old_style))
A = np.random.uniform(0, 2 * np.pi)
x = [[]] * 4
x.add_to_one(b=9)
self.console.pack(fill=tk.BOTH)
df
obj.foo
os.path.normpath(path1) in list_of_paths
self.button.clicked.connect(self.handleOpenDialog)
root.mainloop()
assert len(string_1) == len(string_2)
new_queue = OrderedDict()
profiler.runcall(self._handle, *args, **options)
self._advance()
m.set_array([])
children.append(node.keys[i])
recall = np.linspace(0.0, 1.0, num=42)
print(os.strerror(e.errno))
observation = iter(data)
s.ix[x:y].asfreq(BDay())
graph = fig.add_subplot(111)
sys.exit(1)
random.random() >= p
f = interpolate.interp1d(x, y)
false
all_lines = infile.readlines()
functype = ctypes.CFUNCTYPE(restype, *argtypes)
self.matrix.__setitem__(index, item)
stackstr
title = models.CharField(max_length=50)
dif = np.setdiff1d(col, a[:, (0)])
[snip]
help(foo.myfunc)
incrementerBy2 = Incrementer(2)
t2start, t1end
t1start, t2end
t1start, t1end
lu_obj = scipy.sparse.linalg.splu(a_sps)
sys.stdout = orig_stdout
result.append(item)
print(estimate_pi(s1, s2))
data = socket.gethostbyname(d)
plt.imshow(polar_grid, extent=(theta.min(), theta.max(), r.max(), r.min()))
ctx.load_verify_locations(capath=sys.argv[2])
xidx, yidx, zidx = np.where(hist > 0)
t = Thread(target=getabit, args=(pobj.stdout, q))
httpd.serve_forever()
c.append([(A - B) for A, B in zip(a[i], b[i])])
profs.append(user)
print(result)
self.arrays[j][i + shift]
byte = f.read(1)
finder.apply_ngram_filter(creature_filter)
sleep(5)
app = QtGui.QApplication(sys.argv)
new_user
vals = sorted((sinval(i), i) for i in range(1024))
sys.argv.insert(1, name)
thread.start()
array2.max()
print([i for i in sentence.lower().split() if i not in stop])
a, b, c = [fgen(n) for n in L]
self.fn(*sub_args)
increment()
K = np.arange(n - 2)
s.send(l)
outline = np.array(list(dict(reversed(coords)).items()) + list(dict(coords).items()))
dt_sec = helper(dt)
print(json.loads(thing, object_hook=object_hook))
writer.save()
mktime(gmtime())
im = ax.imshow(data)
container.__iter__()
print(repr(dt))
foo[1]
NEWLIST.append(i)
self.saver.save(self.session, fn)
output.write(left + new_delimiter.join(row) + right + newline)
s.add(i)
lc.set_linewidth(2)
self.temperature += 1
globals()[name] = __import__(name)
b.extend(s)
[0, 0, 1, 1]
ax2.xaxis.set_major_locator(copy.copy(Locator))
self.exec_()
[list_to_int(l) for l in combine(xs, ys)]
logger.info(__name__)
Test.A
dist = np.sum(dist, axis=1)
tree = {}
match = pattern.match(s)
result.put(target(*args))
width = self.canvas1.winfo_width()
ax2 = fig.add_subplot(222)
abspath = lambda *p: os.path.abspath(os.path.join(*p))
f.write(next(rbg))
output.write(line)
self[self.nearest_key(key)]
x = MyClass(*args, **kw)
afile.close()
ax2 = plt.subplot(gs[2])
self.setPen(QPen(Qt.red, 1.75))
head = models.BooleanField(default=True)
xml = doc.toprettyxml()[len(declaration):]
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
p.append(tuple(k))
seen_add(element)
url = urllib.parse.urlunsplit(url)
inst.__dict__[self.name]
post.save()
fLim = [(x / 7.0) for x in range(1, 8)]
(a + b + c ^ 2 - (a ^ 2 + b ^ 2 + c ^ 2)) / 2
df = DataFrame(data=list(result), columns=list(result.keys()))
x -= 1
do_something_with(out)
l = [0, 1, 1]
plot(1)
fruit[1] = int(fruit[1]) + 1
tree = parse(BytesIO(some_byte_string))
logger = logger.YarnLogger()
2 - 1 < 0
print(result.get())
inArray = np.asarray(inArray, dtype=np.double)
data = [sheet.cell_value(0, col) for col in range(sheet.ncols)]
user = authenticate(username=username, password=password)
y = np.random.random(10)
communication_set = CommunicationFormSet(request.POST, instance=my_contact)
a.set_xticklabels(a.get_xticks(), fontProperties)
True
True
saver = tf.train.Saver(sharded=True)
instance.save()
b = copy.copy(a)
user = oauth.get_current_user(SCOPE)
ax = fig.add_subplot(111)
arr = numpy.arange(10)
result = []
product.listing.save()
output.addPage(page)
ax = fig.add_subplot(111)
dt = nofrag_dt.replace(microsecond=int(frag))
pos = np.arange(len(alphab))
self.save_object(sub_object)
ax.scatter(x, y)
more_settings.modify(globals())
result.update({k: v})
deleteself.left[0:x]
doubles = dict()
line_dic[last].append(x)
OrderedDict()
df_confusion = pd.crosstab(y_actu, y_pred)
print(user.id, user.email)
os.utime(path, (accessed_time, modified_time))
line = line.lower()
func.current_timestamp(type_=types.Time, bind=engine2)
False
individual_dict[a.individual].append(a)
np.abs(stats_z) > 2
result = pickle.load(infile)
parser._actions[0]
-libxml2 - dev
-libfreetype6 - dev
test.sin_2_(byref(x))
pairs = set(frozenset((w1, w2)) for w1 in words for w2 in prefixes[w1[1:]])
condition = np.abs(x) < 1
console.log(String(i), String(i / 10))
intercept = np.ones(mX.shape[0]).reshape(mX.shape[0], 1)
Base = declarative_base()
touch(os.path.join(root, filename))
results.append(line)
ques_type = models.SmallIntegerField(default=2)
df[filter_col]
state = models.CharField(max_length=100)
pp.imshow(matrix)
print(sum(1, 1))
list(choice(j[user_input]).values())[0]
ofp.write(line)
[(part1 + part2) for part1, part2 in zip(xs[1::2], xs[2::2])]
greetings.hello()
a = np.array([[1, 5, np.nan, 6], [10, 6, 6, np.nan]])
soup = Soup(open(filename))
df
screen = curses.initscr()
tag, body = next(iter(list(d.items())))
app = current_app._get_current_object()
fig = plt.figure()
db = SQLAlchemy(app)
test = Test()
map.seek(0)
print(type(self))
fig.canvas.draw()
print(a[167])
n_rows = len(list(data.keys()))
out.println(msg)
app = QtGui.QApplication(sys.argv)
dfs_rec({Sequence1: [Translate], Translate: [Sequence1]}, Sequence1)
print(jsbeautifier.beautify(script.string))
child.sendline(user_password)
session = Session()
my_list = in_list[:]
random.seed(seed)
print(repr(profile))
contourf(X, Y, out)
capture = cv.CaptureFromFile(filename)
x = np.zeros(N, N)
DTYPE_f64 = np.float64
c = pycurl.Curl()
B.shape
np.linalg.matrix_rank(a)
print(match_obj.group(1))
dmap[d] != dmap[newd]
COMPRESS_OFFLINE = False
raise TimeoutException(message)
non_unique_column_idx = npi.multiplicity(a, axis=1) > 1
x[-1]
d[k].append(v)
self.store.append(self.key, df, data_columns=True)
-next_up(-x)
enc.n_values_
a, b, c, d = np.ogrid[:n, :n, :n, :n]
s.setsockopt(socket.IPPROTO_IPV6, socket.IPV6_V6ONLY, 1)
print(ind[A[ind] == value])
t = currT
y.groupby((y != y.shift()).cumsum()).cumcount() + 1
c.setopt(pycurl.TIMEOUT, 10)
categories_w_rand_books.append((category, collection[category.id]))
logging.info(line)
argrelmax(y)[0]
print(roundPartial(11.12, 0.25))
print(roundPartial(5.24, 0.25))
print(roundPartial(9.76, 0.25))
bodylist.append(tempset)
res
items = db.get(random_keys)
a, b, c = int_list
rads = atan2(-dy, dx)
bins = bins[:-1] + (bins[1] - bins[0]) / 2
pixbuf = loader.get_pixbuf()
AT & F0
time.sleep(0.1)
[p.stdout, p.stderr],
sys.stdout.buffer.write(os.urandom(1000000).translate(tbl))
exampleName(row, column, name)
print(x)
queryset = User.objects.all()
myfunc(*mylist)
[0, 2, 1]
set_.update(list(dict_.keys()))
plt.legend(loc=0)
sqsregion = sqsregion or SQSREGION
pythoncom.PumpWaitingMessages()
print(k, v, x)
a = np.random.random(100)
canvas.itemconfigure(interior_id, width=canvas.winfo_width())
False
print(res)
[]
instance = SomeClass()
widget.hide()
configure_blueprints(app)
mail.quit()
self.lines.append(self.addLine(xc, 0, xc, height, pen))
self.Bind(wx.EVT_TIMER, self.onTimer, timer)
[1, 0, 1]
print(a)
ax2 = fig.add_subplot(122)
df.columns = cols
repr(d)
split_points = [(x, y + 1) for x, y in split_points]
ftp_handle.cwd(name)
cr.paint()
[0, 0, 0, 0, 0, 0, 162, 1, 162, 2],
ET.ElementTree(root), ns
test_suite.addTest(suiteFilter.suite())
[False, True, True, True, True],
print(files)
[1, 1, 0, 0]
x = np.random.rand(m, n)
print(df1.date.dtypes)
InterfaceClass(iface.__name__, (iface,), fields)
b = Counter(0, 1, 1)
t.daemon = True
scraps.save()
t.join()
numpy.fix(a).astype(int)
print(df)
do_work()
a.attr.append(1)
print(a + b)
slither / setup.py
np.fill_diagonal(b, 0)
dis.dis(use_floordiv)
print(retrieved_body)
groups.size().unstack()
unique = {urlparse(u).netloc for u in urls}
setattr(cls, name, op_hook)
response = self.client.get(url)
print(string2[match.b:match.b + match.size])
X, Y = np.meshgrid(x, y)
X = np.random.normal(size=(10, 5))
numpy.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)
y.groupby((y != y.shift()).cumsum()).cumcount()
print(word)
col2 = matrix[:, (2)]
extractDefines(TEST4)
x.f()
seekpoint = fro.tell()
y = np.arange(-1, 1, 0.2)
chapter = form.create(parent=book)
signal_axes = fig.add_subplot(211)
c()
line = linecache.getline(filename, lineno, traceback.tb_frame.f_globals)
layout = QtGui.QHBoxLayout()
row_as_dict = dict(row)
client = client(url)
idx = [val] + df.index.drop(val).tolist()
request.GET._mutable = False
mydic[key] = [value]
list == [1, 2]
a()
Py_Initialize()
my_content.append(data)
args = parse.parse_args()
x = np.arange(0, size, 1, float)
create_ranges(start, stop, 5, endpoint=False)
firstline = next(f).split()
col_ind = [i for ids in list(d.values()) for i in ids]
indices = [i for i, x in enumerate(ar) if fnmatch.fnmatch(x, pattern)]
mngr = plt.get_current_fig_manager()
new_labels = labels[2:]
l2 = [a[:i + 1] for a in l1 for i in range(len(a))]
cipher = AES.new(key, AES.MODE_CBC, IV=iv)
df
not array[0]
g += a
dG.add_node(word)
str(n)
res1 = numpy.array(list(zip(*zip_longest(fillvalue=0, *a))))
print(len(ids))
scene = bpy.context.scene
collection.set_facecolor(face_color)
spl.append([])
points = [(random(), random()) for _ in range(1000)]
vectors = np.random.rand(100, 25)
raw_data += bytes
curses.setsyx(-1, -1)
od.setdefault(ele[0], []).extend(ele[1:])
z.close()
heapq.heapify(self._data)
y_coord = radius * np.sin(theta) * np.sin(phi)
False
check_token
ax1 = plt.subplot(2, 1, 1)
recvSock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, True)
cursor = self.db.cursor()
out.append(A[0][::-1])
session.expire_all()
forced_managed = True
x = np.array([6.4, 6.500000001, 6.5, 6.51])
x.append(5)
result.append(word)
conn.quit()
start = time()
f.cwd(DIRN)
a = []
x += mydict.get(count, 0)
x, y
value = df.iloc[5]
word_list2 = sorted(word_list2, key=itemgetter(1), reverse=True)
print(i + --+i)
tuple(v)
adobe_to_srgb(image)
QObject.__init__(self, *args, **kwargs)
fig = plt.figure()
self.queue.put(message)
int(number / interval) * interval
plt.draw()
np.all(x[idx, J, I] == y)
v = [1, 4, 5]
root = Tkinter.Tk()
my_secure_rng.randrange(n, m)
a[inds][mask]
lib / nark
cashflow
p.print_help()
application.main.show()
colorjh = jmag - hmag
map = mmap.mmap(f.fileno(), 0, prot=mmap.PROT_READ)
print(list(squares(5, 50)))
killer = GracefulKiller()
worksheet = workbook.add_worksheet()
plotlyjs
split_string.append(identifier[previous:match.start()])
d[x[4]]
f.seek(0)
self.app = MyApplication(param1, param2).getApplication().test_client()
example()
print(myModule.variableX)
requests_logger.setLevel(logging.DEBUG)
packet = ip.assemble(ip_packet, 0)
df1.columns = df1.columns.droplevel(level=1)
sim.start()
url_pattern.findall(urls)
print(df)
dataframe[column].value_counts().index.tolist()
z = list(zip(t, t2))
lookup[key(item)].append(item)
property2 = ndb.StringProperty()
dt = nofrag_dt.replace(microsecond=int(frag))
b = np.array([a])
fig = plt.figure()
2 * x
json.dump(data, jsonfile)
self.end_headers()
part_number = models.CharField(max_length=10)
print(df)
closest_keys = [k for k, v in list(d.items()) if abs(v - target) == min_diff]
main(sys.argv)
your_domain = Site.objects.get_current().domain
args = [iter(iterable)] * n
__file__
img = img.smooth()
b = np.random.randint(l, size=k)
lay.addWidget(le)
setd2 = set(d2)
lst.sort(key=weight_key)
response
defaultdict(ddict)
pprint(data)
b = [4, 5, 6]
server = BaseHTTPServer.HTTPServer(server_address, TestHandler)
imputed_array = np.copy(arr)
s = requests.Session()
[mysqld]
r = list(csv.reader(file_obj))
B.shape
overlay = mask * image1 + -mask * image2
match = re.match(regex, thestr)
dct = {}
self.a = a
out_csv.writerows(in_txt)
results.append(word_length)
self.__fill_left()
p.join()
result += Data[..., (0)]
ranking = []
app = QtGui.QApplication([])
ax.add_patch(sea_patch)
buf = StringIO.StringIO(req.read())
[fn(*args, **kw) for x in range(count)]
~reduce(np.logical_and, map(pred, list(range(A.shape[1])))).any(axis=1)
successed += 1
curses.endwin()
movie = input()
d2[key] = d1[key]
Py_XDECREF(result)
trainer = DeepBeliefTrainer(net, dataset=dataSet)
HTTPFound(location=request.application_url)
daemon_runner.do_action()
[1, 0, 0, 0]
count = 0
progname = sys.argv[0]
newlist.append([alist[i]])
X = np.c_[x, np.ones_like(x)]
a = np.random.rand(N, N)
zip(*args)
d = json.loads(j)
sum_chunk(a, 2)
ax.hold(True)
curses.resizeterm(y, x)
print(int_no)
rtn_words.append(word_without_exclamation)
plt.bar(bins[:-1], hist, widths)
Response(url, response.status_code, {}, response.content)
mm.stop()
zipwrite.writestr(item, data)
layout.addWidget(self.output)
print(a)
random.choice(animals)
JSONEncoder().encode(YourModel.all().fetch())
combs = []
print(test.vec()[0])
(t ** 2 + 4.0) ** 2 / 16.0
ret
items = []
etree.tostring(t)
first_arg = sys.argv[1]
HAVE_CYTHON = True
df.as_matrix()
M = M[M.getnnz(1) > 0]
Z2 = [np.dot(X[k], Y[k]) for k in range(10)]
fixed = [(pos, item) for pos, item in enumerate(items) if item.freeze]
group = Group.objects.get(pk=1)
seen_add(k)
temp = my_array[:, (0)]
getline(cin, input_line)
list.__setitem__(self, i, x)
f.close()
data = client.recv(1024)
ax.add_patch(clip_path)
a[slice(*a.nonzero()[0].take([0, -1]))] = True
f = numpy.vectorize(f)
char = screen.getch()
discoverer = GstPbutils.Discoverer()
game.main()
d[key].append(word)
resp = urllib.request.urlopen(req)
word.lower() == word.lower()[::-1]
not_index = np.array([k for k in range(n_b) if k not in index])
column_label = gtk.Label(column_title)
app = QtGui.QApplication(sys.argv)
fig, ax = plt.subplots(1, 1)
color_data = np.random.random((numframes, numpoints))
rot_sprite = pygame.transform.rotate(image, angle)
results = [list(islice(c, length)) for length in b]
time.sleep(5)
mainDlg.Show()
bands = im.split()
result = f(*args, **kargs)
layout.addWidget(vline)
y = np.array([-2, -1, 0, 1, 2])
count = 0
n = s * (zp + z) ** 2 / d ** 2
main()
axis = fig.add_subplot(111)
value = 4294967295
app.py
p.start()
outfile.write(format % ([i] + row))
ch.setLevel(level)
Counter(chain.from_iterable(linewords))
self.fields[str(f.id)] = forms.BooleanField(initial=False, required=False)
http = httplib2.Http()
file.close()
total = 0
print ()
page = opener.open(uri)
self.alertParent(str(key), str(item))
btn.bind(on_press=partial(self.foo, btn))
vals = list(range(1, 2000))
quad(integrand, 0, 1000)
writer.writerow(newrow)
df = DataFrame(dict([(k, Series(v)) for k, v in list(food2.items())]))
buffer = f.read(1024)
data = pandas.DataFrame(y)
shlex.split(text)
print(tds[0].text)
var_a + var_b + x
pprint.pprint(d)
plt.close(fig)
arr_2 = np.array([False, True, False, True])
mime_msg = email.message_from_string(msg_str)
peaking = np.random.random() < alpha
result = dict(mainDict)
number = sorted(number, reverse=True)
name = cls.__name__
layout.addWidget(picture)
x0s = imsize * np.random.random(ng)
fs.add_file(file)
c = np.zeros((a.shape[0], b.shape[1]), dtype=DOUBLE)
df = pd.DataFrame(my_data, dtype=str)
print(foo)
bytes.close()
os.chdir(command[input][0])
etime = time.mktime(time.strptime(end, format))
new_im_vec = new_im.flatten()
False
t = threading.Thread(target=self.receive)
old_init(self, *args, **kwargs)
l = []
print(Counter(contents))
string
L.__code__.co_filename
smtpd.SMTPServer.__init__(*args, **kwargs)
dis.dis(afunc)
options, args = parser.parse_args()
assert np.all(np.isclose(convolved, convolved_2))
output.add(x)
ptr[2] = color[2]
print(i)
frame = pd.DataFrame()
word.capitalize() if len(word) > length else word
ax = fig1.add_subplot(111)
self._bymonthday + self._bynmonthday
print(name)
all_keys = set(chain.from_iterable(dict_list))
sys.exit()
typing.get_type_hints(Node.__init__)
a.size
updated = request.GET.copy()
counts, bins = numpy.histogram(a, bins=100, density=True)
loop = asyncio.get_event_loop()
cv2.drawContours(mask, [best_cnt], 0, 255, -1)
y = x[1:5]
conn, addr = s.accept()
root = tk.Tk()
print(df)
response
my_df.reset_index(inplace=True)
row_json = json.dumps(row)
print(stealth_check[stealth_roll])
arr.keys
ivalue = Column(Integer)
SimpleXMLRPCServer.SimpleXMLRPCServer.__init__(self, *args, **kw)
self.load_results()
np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))
print(totals.argsort())
n - 1
numOfRuns += 1
plt.subplot(211)
parser = argparse.ArgumentParser()
b.foo()
self.window = gtk.Window(gtk.WINDOW_TOPLEVEL)
print(get_image_info(data))
dir()
IedConnection_getServerDirectory.restype = c_int
seen = {(row[0], row[2]) for row in r}
show_strings.visit(root)
print(df.dtypes)
df
1128
last_inner_append(cont[-1], el)
object.__setattr__(self, attr, value)
panel.draw()
sys.exit(1)
df
print(random_list)
sps_acc = sps.coo_matrix((rows, cols))
[1, 0, 1, 1]
db.session.commit()
print(pos, word.lower())
pipdeptree
n % lcm20 == 0
ax.xaxis.set_major_formatter(EpiCycleScalarFormatter())
print(msg)
label_sequences = [[0, 1, 0], [1, 0], [1, 1, 1]]
ctx.set_verify(VERIFY_PEER | VERIFY_FAIL_IF_NO_PEER_CERT, self.verifyHostname)
atexit.register(cleanup)
a = sin(x)
self.assertCountEqual(self.result, self.expected)
print(time.time() - start)
root = Tkinter.Tk()
H, xedges, yedges = np.histogram2d(x_axis, y_axis, bins=10, weights=z_axis)
lens = np.array([len(i) for i in data])
list(islice(c, size))
[func(group) for group in np.split(S.data, S.indptr[1:-1])]
gc.enable()
2 - 1.781216
print((first_string, second_string, third_string))
np.set_printoptions(1)
plt.plot(xf[1:], 2.0 / N * np.abs(yf[0:N / 2])[1:])
cv2image = cv2.cvtColor(img, cv2.COLOR_BGR2RGBA)
a is a.astype(int)
fig = plt.figure()
s[0] * s[1] + s[2]
print(isCircular(bigList, bigList2))
toss2 = np.array(toss)
image.paste(outline, mask=mask)
dist = sqrt(sum([(x * x) for x in hist_sel - hist]))
jar = cookielib.CookieJar()
df_running = df_change.cumsum()
self._data_filter.update(attr_dict)
max(SubDirPath(d), key=os.path.getmtime)
PySys_SetArgv(argc, argv)
xmlhttp.send()
badtuple = tuple(badlist)
-1
self.get_year_sales(datetime.now().year)
retval, img = cv2.threshold(img, 200.0, 255.0, cv2.THRESH_BINARY_INV)
df2 = df.apply(pd.to_timedelta)
Variance(X + Y).var_expansion()
vars(self) == vars(other)
l = list(range(1, 10))
check(my_list[start + 1:], tracking=tracking)
a = numpy.float64(numpy.nan)
Xi[0] = Yf[0]
d = defaultdict(int)
1,
channel = connection.channel()
_unpickle_method, (func_name, obj, cls)
self.peercert = self._connection.sock.getpeercert()
ax.plot([-1, 0, 1, 2], list(range(4)))
foo.db
f.write(req.content)
s.close()
present - datetime(2000, 4, 4)
{2, 4}.issubset(chain.from_iterable(x))
data.boxplot()
all(x in mystr for x in ls)
buffer
program = tapjoy - game1, tapjoy - game2
print(row[col])
self.previewImage = QtGui.QLabel(self)
menu.addAction(a)
t1.start()
group = np.zeros((len(values[0]),), dtype=np.int64) - 1
Session.query(Record.id, Record).filter(Record.id.between(chunk[0], chunk[-1]))
array([100, 1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000])
root.attrib
process(chunk)
f = list([l for l in a if t[0] <= int(l[0]) < t[1]])
assert d.x == 1492
print(f)
np.ndarray(arr.shape, dtype2, arr, 0, arr.strides)
name = db.Column(db.String, nullable=False)
np.bitwise_and.reduce(c) == c[0]
f.flush()
regex = re.compile(regex_txt, re.IGNORECASE)
User.delete_auth_token(user_id, token)
b = np.array([2, 4])
self.thread.start()
z = np.logical_or(y, rolled)
process.start()
surf.write_to_png(image_file)
fig = figure(figsize=(6.5, 12))
example()
top = curses.newwin(1, 10, 0, 0)
assert len(w) == 1
singlet_list = []
html = browser.open(url)
prod = [(i * 5) for i in lst]
parser.print_help()
print(wow)
id = sa.Column(sa.Integer, primary_key=True)
cb = plt.colorbar(im)
bv[0] = 1
d = {}
[k for k in list(d.keys()) if not d[k]]
update_index.Command().handle()
cursor.execute(query_string, query_args)
self.old_handler(*self.signal_received)
ax.legend()
firstname = Column(String(50))
dataBitMap.CreateCompatibleBitmap(dcObj, w, h)
cmyk[i][x, y] = cmyk[i][x, y] - gray
x + 1
max_indices.append(i)
coll = Elasticsearch()
env = Environment()
foo = threading.Event()
ax = plt.gca()
loop.run_until_complete(client_handler(CTX))
cont, = ax.contourf(x, y, z, 500)
self.root = tk.Tk()
doWork()
d = QtGui.QDialog(self)
od.setdefault(n, []).append(s)
process.communicate()
ax = fig.add_subplot(111)
dill.detect.trace(True)
g.output(index)
test(100, 50, 11)
np.array([np.cos(r), np.sin(r)])
output = [6, 4, 2, 2, 1, 1]
atexit.register(DataBase.close_database)
False
l[t[0]] = {}
help(cv2.HOGDescriptor())
main()
plot = fig.add_subplot(111)
f = self[name]._fields.get(ftmp)
print(get_decorators(Foo))
lons.append(float(row[2]))
u, s, v = np.linalg.svd(a)
psutil.Process(doc.pid).get_children()[0].kill()
f()
soft, hard = resource.getrlimit(rsrc)
Employee.__init__(self, name, wage * 26)
axes = plt.subplot(gs[1, 0])
deltas = np.diff(data)
np.array([ax2_cid[axs] for axs in x2_Kaxs_2.flat], dtype=object).shape
soup = BeautifulSoup.BeautifulSoup(s)
self.flush()
date = datetime.now(tz=pytz.utc)
obj = c()
ax = fig.add_subplot(111)
(),
output_dim = len(y_train[0])
self._dynprop = value
view1[1] = 5
sum_a = list(map(sum, a))
writer = csv.writer(outfile)
ax = s.cumprod().plot()
user = request.user
seq[start:end] = replacement
f.write(opener.open(request).read())
math.floor(1.5)
req = urllib.request.Request(starturl, datagen, headers)
print(Dog().speak())
ssh = paramiko.SSHClient()
np.array(lst)
queryset = models.Bloop.objects.all()
socket.setdefaulttimeout(timeout)
np.arange(n)[b[:-1]].repeat(np.diff(b))
True
self.SetSizer(box_sizer)
self.finish()
g.edges()
email.send()
plt.show()
chunk = next(self)
s.add(el)
pool.close()
ys[0] + (x - xs[0]) * (ys[1] - ys[0]) / (xs[1] - xs[0])
pl.imshow(z2, extent=[-5, 5, -5, 5], alpha=0.5)
self.map = {}
sys.modules[name] = mod
hdu.writeto(filename)
bool(0)
sign * np.exp(logdet)
calendar.day_name[my_date.weekday()]
server_B_thread.start()
res.append((x - 1, x, x + 1))
df
signal.alarm(0)
shutil.rmtree(instance.repo)
data = self.leftover
self.increment_counter()
print(int((t2 - t1).seconds))
bytes(c ^ mask[i % lmask] for i, c in enumerate(byt))
l.append(b)
y, x - a / b * y
Line2D([0, 1], [0, 1], color=color, **kwargs)
self.rect.top += self.dir.y * SPEED
proxy_client = SSHClient()
k.press_key(k.left_key)
loop.run_forever()
self.count = 0
print(response.code)
a[index]
self.allClasses = []
reportlab.platypus.Flowable.__init__(self)
res = df[df.cluster >= 0]
pytz.all_timezones
set([8, 9]) & a
print(slice_coords_by_x(2, 4, coords))
Dict[wn + 1] = [(d + timedelta(days=k)).isoformat() for k in range(0, 7)]
_chord.AsyncResult(callback_id), r
logging.getLogger(LOG_AREA1).addHandler(stdoutHandler)
pdf.savefig()
list(gen)
pprint.pprint(build_structure(jdata))
t.start()
lcms.cmsCloseProfile(outprof)
bigrange = tf.range(-1, rank + 1)
print(sum(x / 2 for x in sq_inc))
my_norm = matplotlib.colors.Normalize(vmin, mmax)
df
node = node.__next__
args = parser.parse_args()
assert len(l1) == len(l2)
plt.show()
print(name_age.name)
sum(bool(e) for e in l) == 1
CUDA_TRACE = False
result += int(i)
np.core.defchararray.add(a1, a2)
self.i
print(a)
output.stdout
hash(s)
z2.namelist()
opener = urllib.request.build_opener(urllib.request.HTTPHandler(debuglevel=1))
num_ones = (y == 1).sum()
my_mesh.EndPolygon()
laparams = LAParams()
zip(a, b)
text += elem.strip()
fig, (ax1, ax2) = plt.subplots(1, 2)
print(data)
view.show()
f.close()
row = curs.fetchone()
result.save()
do_things(test_image)
zip_longest(fillvalue=fillvalue, *args)
takewhile(lambda x: x <= max, numbers)
arr[mask] = np.nan
standardized_data = StandardScaler().fit_transform(your_data)
pyplot.gca().add_patch(circle)
set(l1).difference(l2)
server_socket.listen(5)
Method(self, key)
print(r.content)
self._canvas.place_forget()
email_body = data[0][1]
a = argparse.ArgumentParser()
[0]
(u - v) ** 2 * self._norm
a, b, rest = list[0], list[1], list[2:]
code = Column(String(20))
register = template.Library()
map(lambda p: myFunc(p, additionalArgument), pages)
unittest.main()
start = len(my_list) // 2
str(self.to_dict())
s = str(n)
time.sleep(0)
Model.objects.filter(Q(m2m_field=1) & Q(m2m_field=2))
assert 5 * 60 * 60 + 20 * 60 + 25 == delta.total_seconds()
ZZ.old_poly_ring(x).quotient_ring([x ** 2])
plt.plot(*zip(*testList2))
1 << len(self.array)
b = np.arange(10)
series2 = series1[::-1]
sleep(0.5)
_iterencode(o, 0)
self.files = []
self.city = city
t.start()
ax1 = fig.add_subplot(211)
root = Tk()
p = subprocess.Popen(cmd, stdout=subprocess.PIPE)
olist = [Foo() for j in range(n)]
print(data)
sourcelines = inspect.getsourcelines(cls)[0]
layout.addWidget(self.label)
queryset = User.objects.all()
b = np.random.rand(1000)
ax.plot([1], [1])
model.sample(10000)
p = Process(target=f, args=(num, arr))
password = str(random.getrandbits(8000))
client.on_message = on_message
df = df[~(df == 0).any(axis=1)]
slug = models.SlugField(max_length=255)
ax = fig.add_subplot(111)
np.take(np.cumsum(np.log(np.arange(1, m + 1))), n - 1)
upper_color = np.array([color + sensitivity, 255, 255])
print(k)
queue.put(line)
print(line)
G.add_edge(subject_id, object_id, weight=1)
result = list(some_complex_algo(source_data))
plt.plot(x, y)
x = np.arange(9)
fig = plt.figure()
aa = arr.ctypes.data_as(ctypes.POINTER(ctypes.c_ubyte * len(str_bytes)))
as_list = list(ast.literal_eval(args))
self.__dict__.update(new_self.__dict__)
cal_window = gtk.Window(gtk.WINDOW_TOPLEVEL)
newlist = mylist[2:-2]
self.widget(field, **kwargs)
mask = np.hstack((True, np.diff(lid[sidx]) != 0, True))
turtle.goto(x, y)
BaseObject.initialized
main()
im.wcs
X_train_to_add = X_masked[(indices_to_add), :]
col.set_color(color)
lst[:] = list(range(1, 4))
x = np.linspace(-1, 2, 151)
digits.append(digs[x % base])
seen = set()
df = DataFrame(index=list(range(5)))
leglines.append(legline)
ax.set_ylim(y_min, y_max)
db.session.commit()
random.seed(x[0][0])
print(sqrt(diag(cov)))
fp.close()
cls(**d)
r.close()
mat[:, (diag[0]), (diag[1])] = numpy.nan
min_value = df[feature_name].min()
module
setattr(cls, name, wrap_method(cls, name))
writer.add_document(spelling=item.Title)
f.readline()
col_index = np.isnan(a).argmin(axis=1)
lines = [(int(row[0]), row[1]) for row in lines]
s = List()
self.object.get_absolute_url()
setattr(obj, self.name, result)
DA = pd.DataFrame(A).T
pool.close()
path, _ = self._treeView.get_cursor()
links = linkregex.findall(str(msg))
text_list = []
func()
vline.set_xdata((x, x))
b1.pack()
[1, 1]
row1 = next(reader)
preparser = argparse.ArgumentParser(add_help=False)
mf.close()
author = models.ForeignKey(Author)
batch.add(service.animals().list(), callback=list_animals)
lr2 = clone(lr1)
print(ftp.getwelcome())
x = x.rstrip()
obj = self.__dict__.get(key)
ID = Column(types.Integer, primary_key=True)
board = [[(0) for x in range(n)] for x in range(n)]
s = ttk.Style()
init_b = min(y)
shutil.rmtree(d)
numpy.flatnonzero((lst > a) & (lst < b))[:10]
print(item)
cookies = driver.get_cookies()
Session.begin()
df[df.B == B_maxes]
df.dtypes
content_type = models.ForeignKey(ContentType)
self.show()
t[-1][1]
XGBClassifier(grid)
pickle.dump(obj, fh)
x.add(2)
ordered.append(t)
np.argsort(p)
max2here = pd.expanding_max(ser)
obj.user_set.count()
array2 = np.empty((20, 20) + array1.shape, dtype=array1.dtype)
self.store.insert(i, (key, value))
a1 = A.objects.create()
axe = fig.add_subplot(111)
print(df)
ids.append(int(x))
Grid.columnconfigure(frame, 0, weight=1)
event.accept()
logger = logging.getLogger(__name__)
self._value = val
x = [k for k in list(d.keys()) if d[k] == 1]
P.show()
output.write(outputStream)
lines = my_file.readlines()
health < max_meath or armor < enemy.attack < attack > enemy.defense
d = datetime.utcnow()
a = [str(f) for f in range(n)]
a = np.random.randint(2, size=(10000, 6))
a = []
foo == bar
pyplot.show()
config = configparser.ConfigParser()
fullpath = os.path.join(path, *paths)
cmd.Cmd.__init__(self)
xidx = (raw[:, (0)] - xrange[0]).astype(int)
keys = pygame.key.get_pressed()
k = (k + 1) % len(l)
zip(*([chain(iterable, repeat(padvalue, n - 1))] * n))
print(npdata)
window = Gtk.Window()
youget = the_idea
BOOST_PYTHON_MODULE(get_dir_list)
b = [numpy.vstack((a.real.T[i], a.imag.T[i])) for i in range(a.shape[2])]
a is a[0]
self.x = 0
plt.show()
repo.heads[0].commit.message
event = models.ForeignKey(Event)
change_request.save()
a + b
outputStream.close()
log.put()
x + y
freq += lemma.count()
y = data[:, (1)]
result = pd.DataFrame.from_records(data).mean().to_dict()
self.user = user
X = np.ascontiguousarray(X)
n_neighbors = tree2.count_neighbors(tree1, r=4.2)
t * b + a
memset(id(s) + offset, 0, len(s))
total = sum(counts.values())
image_string = cStringIO.StringIO(base64.b64decode(rawbase64))
sum(c * x ** (n - i) for i, c in enumerate(self.coef))
print(datetime.datetime.now())
joe = name, age, location
self.__dict__[key] = item
result = []
print(df)
print(asizeof.asizeof(list(range(N))) / N)
list(x)
retcode = cmdp.wait()
min(bar)
app.deleteLater()
root = Tk()
boo = Boo()
particles1.move()
reviewURL = scrapy.Field()
a = numpy.array([-128, -1, 0, 1, 127], dtype=numpy.int8)
dists = sklearn.metrics.pairwise.manhattan_distances(r)
percentiles = [percentileofscore(data, i) for i in data]
rv.append((labels[x[0]], x[1]))
s.commit()
key = pygame.key.get_pressed()
self.buttons.rejected.connect(self.reject)
x, y = minloc
key = cv2.waitKey(20)
db = SQLAlchemy(app)
fig.colorbar(cax)
here = os.path.dirname(os.path.abspath(__file__))
len(_)
df1.sort_index(axis=1, level=1, inplace=True)
print([([k] + val) for k, val in list(od.items())])
df
sns.heatmap(df)
app = QtWidgets.QApplication(sys.argv)
writer = csv.DictWriter(csvfile, fieldnames)
image1 = Image.open(f)
outlist = [k for k in mylist if k[1] not in other]
b = cv2.erode(b, element)
dfc = df.copy()
fn
max(seq)
s = requests.session()
os.dup2(so.fileno(), sys.stdout.fileno())
auc1, auc2 = sklearnAUC(Y_test, Y_pred)
args = parser.parse_args()
settings.py
np.argsort(arr + np.random.rand(*arr.shape))
self._list = list()
vec = DictVectorizer()
c = a[b]
dot(v1, v2)
user_lon > this_lon - omega and user_lon < this_lon + omega
root.mainloop()
main()
print(t.timeit())
root.withdraw()
print(dt.timedelta(seconds=hms.seconds % resolution.seconds))
response = conn.getresponse()
print(x)
print_node(node)
one_week = 604800
items.issubset(set([1, 2]))
base_classes.Bookcollection = Bookcollection
observer.start()
False == 0
self.server.shutdown()
b = np.cumsum(a)
df
self.idle()
i, j = np.mgrid[:10, :10]
item = db.get(key)
kl.setMath(f.getBody())
word_set = set(word_list)
row.append(mapper[row[1]])
now = datetime.now()
x[1:] *= m[:-1] < m[1:]
self.takeItem(self.row(item))
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cookiejar))
True, s[1:]
a[(0), :, :] = b
x = -1.1111
values = [random.randint(1, 100) for _ in range(n)]
opener = urllib.request.build_opener(BindableHTTPHandler)
self.setFlag(QGraphicsItem.ItemIsMovable)
pd.DataFrame(data=dct).T.reset_index()
[x[0]] + f([m for m in x if len(m) != len(x[0])])
cursor = connection.cursor()
f.seek(0)
t = list(range(len(x)))
prepdf.xs(sheet).to_excel(writer, sheet_name)
dx, dy = x2 - x1, y2 - y1
time.sleep(snooze)
header_cell = sheet.cell(row=1, column=j)
print(l)
q = multiprocessing.Queue()
n = sum(1 for line in pd.read_csv(filename))
print(log_contents.lower())
deleteself.thisptr
soup = BeautifulSoup(htmlstring)
i += 1
b = np.arange(10)
df_new
TaskBase.__call__(self, *args, **kwargs)
a.sum()
self.local_storage._save(name, content)
func(b)
test = sess.run(e)
print(b.get())
log = logging.getLogger(__name__)
lines = df.plot(ax=ax)
tree = ET.fromstring(data)
term_appearance = Counter(chain.from_iterable(l))
serializers.ModelSerializer.to_representation(self, data)
f.read().splitlines()
foo(a)
print(A[ind] == value)
self.x = 1
sums = np.add.reduceat(a, reductions)[::2]
f()
os.setpgrp()
d.update(b)
os.kill(pid, signal.SIGKILL)
plt.figure()
f = urlopen(url)
[0, 0, 1, 0]
json.dumps(_)
switches = [True, False, True]
tree = ElementTree.ElementTree()
validate(request.json, current_app.config[schema_name])
up = np.genfromtxt(lines[4::4], dtype=str)
deleteinst.__dict__[self.name]
b = np.array(a)
b = json.dumps(json.dumps(a))
print(sh1.col_values(1))
c.save()
pattern_obj.sub(replacement_string, originalstring)
u = numpy.linspace(0, 2 * numpy.pi, 100)
result
plt.legend(loc=0)
self.exit()
ax.set(aspect=1)
root = Tkinter.Tk()
myList = np.random.random(100)
print(x)
queryset = queryset.all()
garbage.append(line)
data.apply(lambda x: dump_sframe_to_dict(x, a))
print(CreateTable(table))
sys.stdout.write(reader.read())
colors = plt.cm.rainbow(np.linspace(0, 1, 20))
fig.set_size_inches(w, h)
epoch = datetime.datetime(1991, 9, 1, 0, 0, 0)
self.name + str(self.age)
img_np = cv2.imdecode(nparr, cv2.CV_LOAD_IMAGE_COLOR)
listD = []
a_polygon.contains(a_point)
self._results.append(result)
document2.body.append(copy.copy(element))
b = datetime.now() - a
req = urllib.request.Request(starturl)
time.sleep(5)
newopen.write(line)
print([v, w])
func = functools.partial(self.on_button, name=name)
request = urllib.request.Request(url, data=data)
b = zip(*a)
sline = line.split()
input = default
a = [0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1]
item
result = list(toposort2(dep_dict))
M[4, 1]
self.free.append(seq_num)
new_list = []
s = s.replace(hit, chr(htmlentitydefs.name2codepoint[name]))
h.endheaders()
yaml.dump(d, f, default_flow_style=False)
worker_thread.start()
data
help(getattr(dict, me))
parsed_input = json.loads(input_data)
background_label.place(x=0, y=0, relwidth=1, relheight=1)
d1 = {x: x for x in range(1, 6)}
b = a.reshape(s)
[mindist, (x_coord, y_coord)]
data = np.loadtxt(input_filename)
4 / 100
1 + (n - 1) % 9 if n else 0
some_method(my_data)
session.connection().commit_prepared(xid, recover=True)
ascii_fh.readlines()
i.seek(0)
item
sh.write(m, 1, e2)
app.Dispatch()
Object(self)
cardValue = card[0]
df
{}
new = interpolate.splev(np.linspace(0, 1, 500), tck)
py > matrix[2][4]
b = a.compress(logical_not(z), axis=1)
len(subs)
down_thresh[:h - i, :] += img[i:, :]
sys.stdout = writer
main()
r.delete(key)
mask = cv2.GaussianBlur(mask, (BLUR, BLUR), 0)
print(Counter(L))
print(xopt)
f(1, 0, 0)
NullColumn = partial(Column, nullable=True)
last_lines = []
epoch = datetime(1970, 1, 1, tzinfo=timezone.utc)
form = playlistform(request, request.POST, instance=playlistmodel)
(1 - coeff * z ** -2)([0, 1, 0, 0, 0, 0, 0]).take(inf)
kingdom = models.ForeignKeyField(Kingdom)
default_mro[1:2] + default_mro
compressor.add(file)
cap0 = cv2.VideoCapture(0)
d[text[i:i + n]].append(i)
data2 = np.empty((h + 2, w + 2))
result = data[:data.size // width * width].reshape(-1, width).mean(axis=1)
timeout = 60
d = {i: [] for i in x}
fieldnames.extend(reader.fieldnames)
my_db.close()
df.loc[g.groups.get(1, [])]
self.cnt += 1
libadd.Add.argtypes = [ctypes.c_int, ctypes.c_int]
ax.plot(x, y, color=col_dict[class_col[i]], label=label, **kwds)
op = np.zeros(n.shape[0])
unittest.main(testLoader=loader, verbosity=2)
index = np.argsort(x)
D_Didx = np.digitize(D, Dbins)
time.sleep(random.uniform(0, 0.02))
vocab_tage = {value: key for key, value in list(tag_vocab.items())}
shutil.copyfileobj(source, temp_file)
pb = gtk.gdk.Pixbuf(gtk.gdk.COLORSPACE_RGB, False, 8, sz[0], sz[1])
server_thread.start()
m = defaultdict(lambda : defaultdict(list))
liPos = [(2, 5), (8, 9), (18, 22)]
matplotlib.hatch._hatch_types.append(CustomHatch)
sum(1 for row in matrix for cell in row if cell == WATER)
second_smallest([a, b] + rest)
NULL
loop.run_until_complete(asyncio.gather(*pending))
data[index]
B = np.asarray([A] * N)
Test.objects.filter(id=fr).update(id=to)
np.unique(_25.index.get_level_values(1).dayofweek)
stack.insert(0, x)
output.write(field.ljust(fieldlength))
{{spygames / games | length * 100 | round(0) | int}}
c.clip(a, b)
t = int(list[i])
now = datetime.datetime.now()
stdin = subprocess.PIPE
Variance(X)
print(user.name)
t.setDaemon(daemonic)
consumer.run()
server.ehlo()
plt.pause(delay)
i += 1
flask.session.modified = True
print(a + b)
popt, pcov = curve_fit(goal.__call__, xdata, ydata)
result = count(l, 4)
reversed = line[::-1]
item, = []
linprog(c, A_ub, b_ub, A_eq, b_eq, options=dict(bland=True, tol=1e-15))
print(l)
x_2 = odeint(sis, [0, 0], t, args=(acel_interp,))
datafile.save()
registered_plugins.append(shortname)
FATAL = 5
ycenter = len(y) / 2
BDF.to_excel(writer, sheet_name=B, index=False)
a2.yaxis.tick_right()
ss.connect((host, int(port)))
theList.append(4)
zip(*((x,) * n))
s = map(sum, zip(*([iter(s)] * 2)))
d = np.eye(foo.shape[1]) * foo[:, (np.newaxis)]
self.foo = functools.partial(__, self)
print(e.headers)
mask = np.zeros(len(ar1), dtype=np.bool)
child_count = len(instance.children.all())
connection = engine.connect()
plt.tight_layout()
assert r.status == 400
new_data = []
sock.send(chunk)
stdout, stderr = p.communicate(scpt)
port = self.mailport
D = D[:, :-2]
[]
v = -np.cos(np.pi * x) * np.sin(np.pi * y) * np.cos(np.pi * z)
n0 = a / math.pow(1 - math.pow(e * math.sin(phi1), 2), 1 / 2.0)
decorator
uncompyle2.uncompyle_file(sys.argv[1], f)
model.metadata.create_all(engine)
html = BeautifulSoup(html)
self.worker = Worker(self)
isclose(a, b, rel_tol=1e-09, abs_tol=0.0)
A(self.value + other.value)
fitness_landscape = np.random.uniform(0, 1, size=(N,) + (2,) * K)
line = line.rstrip()
Fraction.from_float(1 / 2.54)
licenses = set()
hsv[:, :, (2)] += value
file_two.seek(0, 2)
n += 1
queue.append(obj)
user.save()
writer.close()
ymin, ymax = y[mask].min(), y[mask].max()
popt, pcov = curve_fit(func, x, yn)
mylist = [1, 2, 5, 4, 7, 8]
ppxml2 = etree.tostring(xml2, pretty_print=True)
self.p.stdin.close()
yaml.add_representer(str, unicode_representer)
logging.Handler.__init__(self)
SlicableDict(items[index_slice])
f = test.make_fptr()
poly = PolyCollection(verts, facecolors=fcs, closed=False)
chr(_)
text.pack()
P[idx_tuple]
print(Fraction(0.25))
[0, 0, 0, 0]
egg2(*argList)
x = np.random.uniform(high=maxi, size=ntot)
any(i > 10 for i in range(19))
self.parser.result.append(word)
self._initializeStream()
print(list(sec))
groups.append(list(g))
map(partitioner, data)
self.stop_process = True
registry.add_field(cls, self)
duplicate_shaders_dict = {}
self.container[self.item]
endfor
plt.imshow(data)
end_time = datetime.datetime.utcnow() - start_time
[(1 if is_cjk(ch) else 0) for ch in text]
[v for v, ret in [(a, True), (0, bret), (0, cret)] if ret]
obj = json.loads(encoded)
shuffle(seq)
set(string).issuperset(substring)
d[n].update(g.values.tolist())
fn(self)
unsure_rows = dict.fromkeys(csv_reader.fieldnames, [])
result = np.zeros(reference.shape)
local_filename
from_date = datetime.now()
cmp(a[10:], b[10:])
do_error()
pool.close()
print(get_deep_text(element_of_interest))
hllDll.wrp_testchar.restype = c_int
sys.getsizeof(aStrOBJECT)
axes.xaxis.grid(False)
hax2 = plt.subplot(1, 2, 2)
self.show()
new_list[jj].append(some_tuple)
im = Image.open(old_image_path)
json_dict[self._KIND2_PARAM] = self._reader2.to_json()
engine.start()
print(df)
arr.resize(shape, refcheck=False)
order = {A.index(j): i for i, j in enumerate(sorted(A))}
myA.myattribute = 9
parse_code_2 = compose(2, 1, 1)
grid = np.vstack((grid, np.ones((1, grid.shape[1]))))
unique_features.sort()
vectorizer = TfidfVectorizer(ngram_range=(1, 2))
SOAPpy.__file__
a = MyOrderedField(0)
handler = logging.StreamHandler(sys.stdout)
i = 0
kOUT = np.zeros(N + 1)
p.join()
Fx = np.random.rand(100, 50, 10)
csvfile.seek(0)
m = T.matrix(dtype=theano.config.floatX)
t = time.time()
a = np.column_stack((x.ravel(), y.ravel(), z.ravel()))
a == b
data = []
session.flush()
pid = os.fork()
range_list.append(i)
print(response.json())
arr = np.delete(arr, np.arange(0, arr.size, 4))
fig, ax = plt.subplots()
board = [1, 1, 2, 1], [0, 2, 1, 1], [2, 2, 2, 1], [1, 0, 0, 1]
{}
1
source / opt / python / run / venv / bin / activate
cmap = mpl.colors.ListedColormap(colors)
axes.set_ylim(-0.5, 9.5)
it = random.choice(iters)
log.setLevel(loglevel)
p = zip(t[::2], t[1::2])
data = json.loads(source)
r, c = np.where(N[row_idxs] == 6)
print(csv2)
e.execute(ins)
result
sys.getdefaultencoding()
newsocket, fromaddr = bindsocket.accept()
angle = math.atan(float(dx) / float(dy))
userhome + path[i:]
root.withdraw()
client.close()
K.argsort()[-5:]
print(key, value)
garbage.append(line)
self.grid()
self.server_bind()
HAVE_CURSES = False
func(*args, **kwargs)
data.sort(key=key)
main()
print_two()
x = NP.arange(0, t.shape[0])
points.append((px, py))
deletedict[k]
Dummy.a
ax4 = plt.subplot(gs[(1), 2:])
fs = [(lambda x, _i=i: x + _i) for i in range(10)]
x = object()
sublist.reverse()
x[x.first_valid_index()]
self.list1[i], self.list2[i]
ssh.connect(remote, username=username, password=password)
fig = plt.gcf()
fp.seek(BOMLEN, os.SEEK_CUR)
self._setup_widgets()
seq = [1, 4, 6, 9, 11]
querywords = query.split()
somemodule = importlib.import_module(module_name)
glClearColor(0 / 255, 0 / 255, 0 / 255, 0 / 255)
sys.path = old_path
newopen.write(line)
bytearray(data[i] ^ key[i % l] for i in range(0, len(data)))
np.set_printoptions(precision=17)
mask = np.zeros(gray.shape, np.uint8)
tree = etree.ElementTree(root)
key = self.window.getch()
pool = Pool(processes=numProcesses, initializer=initPool)
d = {x: i for i, x in enumerate(t)}
result_dict[key] = list(value)
inner
output = PdfFileWriter()
len(get_file_contents(filename).split())
df = df[reordered]
tck, u = interpolate.splprep(data)
end_date = time.strptime(end_date[:-ulr], fmt)
self.Close()
a = map(int, [(x ** 0.5) for x in range(20)])
1, int(x)
pygame.init()
self.resize(frame.contentsSize())
porter = PorterStemmer()
ax = fig.add_subplot(111)
self.grid = gridlib.Grid(self, style=wx.BORDER_SUNKEN)
cutoff = df.indweight.sum() / 2.0
np.ix_([0], [0, 1, 2], [0, 2])
list.append(num)
tt.tm_year * 1000 + tt.tm_yday
inlines = [BookInline]
x = np.arange(8.0)
EPOCH_DATETIME = datetime.datetime(1970, 1, 1)
raise Timeout()
a = [1, 2]
numberPlate = models.IntegerField(primary_key=True)
df = df.iloc[idx]
print(type(inputList))
matcher.a[match.a:match.a + match.size]
rcount(a)
self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
result = thirdparty.go()
sys.stdout = old_stdout
process_count -= 1
meta.add_tags()
parser = argparse.ArgumentParser()
m = re.search(r, s)
df[df1.columns.unique()] = df1.groupby(df1.columns, axis=1).sum()
sys.modules[newk] = sys.modules[k]
locals()
q.join()
p.get_device_info_by_index(4)
window.show()
newList.append(list(range(r[0], r[1] + 1)))
d = defaultdict(dict)
btn.set_style(style)
any(i) and not any(i)
print(int_list)
lst.append(i)
Base.metadata.create_all(engine)
print(a)
alpha.paste(circle.crop((0, 0, rad, rad)), (0, 0))
A = np.array([1, nan, nan, 2, 2, nan, 0])
br.open(url)
print(SequenceMatcher(a=s_1, b=s_2).ratio())
circularity = circumference ** 2 / (4 * math.pi * area)
fig, ax = plt.subplots()
print(i)
auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
print(posneg([-1, 1, -4, 5]))
pygame.init()
testa4.testa4(strvar_p)
self.func(self, *args, **kwargs)
a = a[:-1]
y += 0.5 * y.max() * np.random.random(num)
f = urllib.request.urlopen(req)
ax.set_ylim(-2, 2)
profile.save()
asin(2).rewrite(log)
print(get_long(b, 1))
formset
created_at = models.DateTimeField(auto_now=True)
np.sqrt(g, out=g)
print(a)
app = Flask(__name__)
index.reshape(-1, k)
float_to_str(0.1)
s = requests.session()
window.add(frame)
soup = bs4.BeautifulSoup(html)
cities = City.objects.all()
masks = [p for p in product([0, 1], repeat=len(data))]
stdscr.addstr(i, 0, line)
libc.cprogram(wts, res, kks, n, ex)
df.columns
print(s)
df1 = merge(csv1, csv2, **kw1)
digit_product2()
count = len(s)
doc = minidom.parse(myXmlFile)
im_norm = (im_g - im_g.min()) / (float(im_g.max()) - im_g.min())
True
func(*args, **kw)
cur_set.pop()
result_list.append(queue.get())
ax = fig1.add_subplot(111)
sum(s[i] != t[i] for i in range(len(s)))
t.start()
smtp.starttls()
{k: [max((a for a in s if n in a), key=len) for n in v] for k, v in list(my_dict.items())}
w = gtk.gdk.get_default_root_window()
data = []
self.data[key].add(element)
found_dates.append(m.group(1))
rhythmbox_dbfile = os.path.expanduser(dbfile)
self.timer.Stop()
deleteself.all[self._key]
rect = plt.Rectangle((i, -0.5), 1, 1, facecolor=col)
sum(y)
data
rand_x_digit_num(10)
p = mp.Process(target=twitter, args=())
wb = Workbook()
n -= 1
o.pull()
A.setdiag(b[:-1], k=1)
numerator = sum([(vec1[x] * vec2[x]) for x in intersection])
ipsh()
mask = np.isnan(arr)
val = np.asarray(imgTk)[x, y]
content_type, width, height
sys._getframe(back + 1).f_code.co_filename
df
ll = [[(x * N) for x in y] for y in hh]
msg = str(_sys.exc_info()[1])
a[1](1)
xlim, ylim = ax.get_xlim(), ax.get_ylim()
a = datetime.now()
max_val = max(l)
print(x)
True
cumdims = (np.maximum(A.max(), B.max()) + 1) ** np.arange(B.shape[1])
ic = image.crop(box)
cur = con.cursor()
print(asubkey)
user_id = 142187
page = urllib.request.urlopen(request)
close(child2father_pipefd[0])
pyautogui.moveRel(0, 10)
to_product.append([(k, list(l)) for l in c])
self.assertRedirects(response)
raise TypeError
new_stack
uniq.append(x)
self.foo = foo
x.start()
result = []
Counter(map(tuple, a))
self._find(val, self.root)
llslice[1][1:2] = [10, 11, 12]
pd.concat([sales, pd.DataFrame(hours, index=sales.index)], axis=1)
max_value = max(scores.values())
res
print(cookie.name, cookie.value)
sidx = a.argsort()
i += 1
[]
lst = [list(grp) for i, grp in groupby(lst, key=len)]
value[:2]
pylab.ylim(-1.5, 2.0)
v = float(s) if pattern.findall(s) else int(s)
p = multiprocessing.Pool()
x[0] = 100
m4x = np.sum(Z * X4) / np.sum(Z)
m4y = np.sum(Z * Y4) / np.sum(Z)
data.splitlines()
self.queue.put_nowait(s)
[1, 0, 0, 0]
ax.set_yticks(list(range(0, 9000, 1000)))
v = float(s) if any(c in chars for c in s) else int(s)
x[1] < seq[end - 1][1]
minutes, seconds = divmod(seconds, 60)
serializer.save()
Thread(target=write_input, args=(file, process.stdin), daemon=True).start()
rabbit_frog
rabbit_horse
offset = (today.weekday() - 2) % 7
print(a, b, c)
print(integrate.quad(func2, -pi / 2, pi / 2, args=(-pi / 2, pi / 2))[0])
helper = np.vectorize(lambda x: x.total_seconds())
height = rect.get_height()
axc = fig.add_axes([0.85, 0.1, 0.05, 0.85])
newk = []
spam(5).__closure__[0].cell_contents
f = urllib.request.urlopen(url)
self.val = val
fig = plt.figure()
start = pyqtSignal(str)
[c for c in s]
n += 1
Q, R = np.linalg.qr(X)
print(np.ma.MaskedArray(Z, mask=~mask).sum())
print(lucky(10))
struct.unpack(format, frame_data)
self.func(*self.args, **self.kwargs)
indices = numpy.arange(a.size)
[26.7, 8.0],
t2.close()
random.shuffle(combined)
client, address = self.sock.accept()
self.body = body
all_data = pd.DataFrame()
type.__new__(meta, classname, bases, newClassDict)
current_dir = os.getcwd()
layout.deleteLater()
m.captures(4)
Session.commit()
b = a[:, (np.newaxis)] * np.ones((1, 7, 1))
df = pd.DataFrame(np.random.choice([1, np.nan], (100000, 150), p=(0.01, 0.99)))
children.add(ast.children.get(i))
glMatrixMode(GL_MODELVIEW)
c.execute(q)
termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)
method(self, *args, **kwargs)
c.append(a[index])
linkers = []
self.L.sort()
Swallow.i += 1
mlab.pipeline.volume(grid, vmin=min, vmax=min + 0.5 * (max - min))
self.view = QtGui.QTreeView()
MI.Open(directory + file)
a[a < 0] = 0
edgar.database.load(quarters)
new_s += chr(n)
pool = mp.Pool(processes=4)
pl.imshow(z0, extent=[-5, 5, -5, 5], alpha=0.5)
counts = Counter(list1)
app = web.application(urls, globals())
1 / 0
base64.b64encode(aes.encrypt(message)).decode()
self.yvel -= self.jump_speed
app = Flask(__name__)
set([t.farm for t in qs])
result = {}
print(stored_file.content_type)
h
do_error()
validate(input, schema)
channel.exec_command(remote_command)
r = redis.StrictRedis(connection_pool=pool)
x = np.ones((5, 1))
self.window_list = []
p, e = optimize.curve_fit(piecewise_linear, x, y)
print(bar())
np.sort(data.reshape(N, -1))
print(o.foo())
cPickle.dump(root.sclX.config(), f, -1)
pickle.dump((a, b), f)
soup = BeautifulSoup(str(response))
ax = fig.add_axes([1, 1, 1, 1])
match = matchre.match(character)
verts.append(zip(xs, ys))
ipshell
x[:, (0), (0)]
secgen = map(operator.itemgetter(1), gen)
root.mainloop()
total += int(col)
ranges.append(s)
0
do_something(arr)
ax4.xaxis.tick_bottom()
dialog.ui = Ui_MyDialog()
J.append(np.arange(start, end))
next(g)
pickle.dump(d, f)
row.pop(6)
np.array(result)
table(ax, df)
fig = plt.figure()
l = [x for x in l if x[0] != last[0] and x[1] != last[1]]
IPython.Cell.options_default.cm_config.lineWrapping = true
num_chars += len(line)
self.show_file(self.save_image(image), **options)
samples = np.empty((0, 100))
x
img = LoadImage(sys.argv[1], 1)
fo.close()
s = sorted(zip(list_2, list_1), reverse=True)
print(a, b)
n = 0
pwd = os.path.dirname(__file__)
app = QtGui.QApplication(sys.argv)
worker.start()
self._timeCreated = time.time()
terms = vectorizer.get_feature_names()
print(thing)
opener = urllib.request.build_opener(proxy, auth, urllib.request.HTTPHandler)
rndseries.head()
html.title
power(base, exponent - 1, result * base)
latlong = transform.TransformPoint(x, y)
image = image.resize(size, Image.ANTIALIAS)
[[]]
logger.setLevel(logging.ERROR)
self.f.write(x)
a[~((a < -100) | (a > 100))]
train, test = mylist[0]
np.vstack((unq, unq_avg))
foo()
strs = repr(s)
response
window.add(image)
f(*a, **kw)
data.append(m.groups())
ax.pole(*mplstereonet.vector2pole(x, y, z))
print(repr(process.stdout.readline()))
b = [4, 5, 6]
random.seed()
[1, 0, 1, 1]
conn.close()
array([46, 62, 61])
data = zipread.read(item.filename)
m = stats.trim_mean(X, 0.1)
arr = np.array(some_sequence)
size = f.tell()
e = ET.ElementTree(ET.fromstring(xml_string))
list(sum(list_, ()))
ancestor.before.remove(descendent)
func(ret, *args)
angles = np.arange(0, 2 * np.pi, d * np.pi / 180)
ax = fig.axes[0]
it.chain(*mt.roundrobin(mt.chunked(list1, n - 1), list2))
minutes = utc_offset / timedelta(minutes=1)
store_file(new_file, nchunks, hash)
matrix[4][4] = 2
Testing(4 / 4)
pool.map(worker, list(range(10)))
Test.__init__
df = df._get_numeric_data()
repr(bar)
plt.xticks(rotation=90)
colors = img.getcolors(256)
scat = ax.scatter(x, y, c=z, s=200)
self.var1 = class_a.var1
outfile.write(doc.prettify())
ax.set_ylim([0.1, 0.8])
n, k = int(eval(input())), int(eval(input()))
Row(*A)
x[np.nonzero(x)]
print(k, list(v))
from_date = datetime.datetime.today()
turtle.right(90)
nums[1]
particles = [Particle(i) for i in range(100000)]
do_something_else(arr)
id(a[1])
command = sys.argv[1]
np.random.seed(2015)
model_class = self._get_model_class(query)
ranked = sx.expanding().apply(lambda x: ranking(x))
ccv1
ccb1
print((der_a.a, der_a.z))
results.extend(result.groups())
print(args)
print(r.findall(s))
print(temp)
dt = dt.replace(hour=0, minute=0, second=0, microsecond=0)
mask = np.zeros(image_src.shape, np.uint8)
file_path = request.url[7:]
plt.setp(ax.xaxis.get_gridlines(), clip_path=circle)
df
b[-1] = b[-1][0], end
form.permissions.data = [p.id for p in user.permissions]
threading.Thread(target=self.listenToClient, args=(client, address)).start()
val_to_delete = max(d.values())
_lazyprop
results = (c_char_p * 4)(addressof(create_string_buffer(7)))
file.seek(0)
curses.wrapper(main)
kernel[1, 1] = 2.0
decorator(fn_or_output)
self.logwindow.AppendText(msg)
ab = np.where(a[:, (np.newaxis)] == b[(np.newaxis), :])
process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)
arr = np.array([False, True])
l = sc.recv(1024)
0
f.write(DATA)
params = {}
output = capturer.getvalue()
s = pylzma.compressfile(i)
decoded = decode_columns(out.indices).reshape(X.shape)
counter.most_common()
lengths = Counter(len(v) for v in list(userIdDict.values()))
w.start()
f(0, 0, 0)
self.assertEqual(expect, foo)
B_out[:, (col_idx)] = np.add.reduceat(A[:, (sidx)], grp_start_idx, axis=1)
tcpCliSock.close()
self.d = self.m.dict()
fnx = lambda v: NP.random.randint(0, 10, v)
my_instance = MyClass()
cert_path
build_base = my / build / dir
screen_names = [user.screen_name for user in api.lookup_users(user_ids=ids)]
t.daemon = True
myapp.run()
y = list([0, 1])
[1, 0, 0, 1]
l = list(range(20))
self.loginPage()
yourThread = threading.Thread()
wrapped
self.sizer = wx.BoxSizer(wx.VERTICAL)
np.sum(x != y)
k = np.array([True, False, False, True, False])
self.start()
event.fire(*args, **kargs)
img2x = img2.shape[1]
sample_object.users.through.objects.create(user_id=1, sample_id=sample_id)
data = inf.read(BLOCKSIZE)
dateData.append(end)
poly = np.poly1d(coeffs)
worksheet = workbook.add_worksheet()
yrloc = matplotlib.ticker.MaxNLocator(steps=[1, 2, 5, 10])
r = list(range(1000))
manage.py
sparsemax(X, Y)
df = pandas.DataFrame(data)
func(that, session, *args, **kwargs)
im.blit(0, 0, window.width, window.height)
c[c < 0] = 0
pprint(get_driver_name_from_guid(x))
words = line.split()
ar.reshape(ar.shape[0], 1)
toolz.valmap(f, my_list)
colorama.init(autoreset=True)
f = lambda x: map(neg, x)
user_email = instance.email
self.left = left
A = scipy.delete(A, 1, 0)
isinstance(obj, str)
df.index = df.index.get_level_values(0) + df.index.get_level_values(1)
key = operator.itemgetter(0)
t = np.linspace(0, 4 * np.pi, N)
print([i for i in lib.make_array().contents])
fibonacci(n - 1) + fibonacci(n - 2)
noVow(seq[1:])
seclist = [2, 4, 6]
tk = tkinter.Tk()
serializer_class = SpeakerSerializer
wedding_obj
df = pd.DataFrame(df)
H, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0
r1 = Range(start=datetime(2012, 1, 15), end=datetime(2012, 5, 10))
t.render(context)
(1 - coeff * z ** -2)([1, 0, 0, 0, 0, 0, 0]).take(inf)
result = np.empty((4, 2), dtype=int)
df = df[df.TMP.notnull()]
timer1.stop()
mysets = (set(x.items()) for x in MyList)
im_out = np.dstack([r, g, b])
traceback.print_exc()
str(root)
plt.boxplot(weighted_appearances)
list(spam.items())
x = np.empty(len(a))
ax2.autoscale(False)
b.flags.owndata
Foo.py
d[str(k)] = v
self.optionmenu_b.pack()
ax1 = fig.add_subplot(221)
col.append(row[i])
model1 = build_model()
lst.extend(words)
w, h = win.GetSize()
triplets = [[a] for a in listA]
lines.append(self.context)
[1, 1, 0]
jobscheduler.configure(jobstores=jobstores)
remote_conn = remote_conn_pre.invoke_shell()
old_path = sys.path
arr.copy()
mask = ~np.any(np.isnan(x), axis=1)
ax2.scatter(bins_mean, n)
repr(dict)
self._task_handler.start()
anadict = loadvars()
s.dropna().plot()
button.Bind(wx.EVT_BUTTON, func)
file.__init__(self, *args, **keyws)
self.mainLayout = QtGui.QVBoxLayout(self)
print(line)
plt.subplot(122)
yourNewSet = map(set, list(set(map(tuple, yourSet))))
range_start = 10 ** (n - 1)
writer.writeheader()
func(*func_args, **func_kwargs)
x = np.arange(10)
print(c)
plt.plot(x, intg / fullpower)
b1 = np.random.randint(0, 100, 50)
self.func(*args, **kwargs)
a.take((1,), axis=0)
self.qa.save()
ax.set_title(label, size=20)
self.head = tmp.__next__
s.ioctl(socket.SIO_RCVALL, socket.RCVALL_ON)
print(True)
self.b_set.add(b)
[_f for _f in map(self._func, collection) if _f]
contents = fp.readlines()
id(my_dict)
can.place(relx=0.5, rely=0.5, anchor=CENTER)
sorted(iterable, key=natural, reverse=reverse)
print(len(shared_items))
inds = np.triu_indices_from(a, k=1)
lines = stdout.readlines()
gmm.delta = 0
f.getvalue()
dt = datetime.datetime.fromtimestamp(jsts / 1000.0)
b = a
count += 1
random.shuffle(listOfItems)
client2.close()
Whatever().dosomething()
np.where(cnt, hi[ind[cnt - 1]], initial)
dic = dict(zip(lis, lis[1:]))
c = lambda a, b: [list(c) for c in zip(a, b)]
s.ioctl(socket.SIO_RCVALL, socket.RCVALL_ON)
L.append(results.get())
error_class = err.__class__.__name__
sys.stdout = old
k.release_key(k.alt_key)
a.clip(0)
print(sum(res))
i += self.shape[0]
r = np.minimum(np.arange(n)[::-1], np.arange(n))
incrementerBy1 = Incrementer(1)
dis.dis(greet)
print(list(Foo().foo()))
self.d = {}
print()
Frequency = Pitch(data)
fig = plt.gcf()
m.group(2)
do_some_thing()
t = timeit.Timer(foo)
session2.close()
zip(table, list)
tmp2[:, (0)] *= -1
main.write(ccode)
print(b.shape)
display.display(pl.gcf())
fw.close()
inMemoryOutputFile.seek(0)
process.get_memory_info()[0] / float(2 ** 20)
plt.imshow(image)
num += cur.execute(sql, arg)
client = docker.Client()
k = [(x, l.count(x)) for x in set(l)]
sum(1 for k in ks if k_v1s.get(k) != k_v2s.get(k))
n, p = map(int, input().split())
picked.append(random.choice(data))
item_length = len(item) + 1
print(test_unicode)
d = {}
root = Tk()
a[i] = x + 4
x + y
print(poly.containsPoint(QPoint(1, 1), Qt.OddEvenFill))
catpcha = find_catpcha(response)
response = urllib.request.urlopen(request)
app.exec_()
connection.execute(ins, values)
self.pack()
clf = linear_model.LinearRegression()
string.split(divs[0])
print(list(recurse(dirDict)))
sum(row) > 0.5
ordered = OrderedDict()
QtGui.QSystemTrayIcon.__init__(self, icon, parent)
df = pd.DataFrame(invs)
s = q.get()
chrome_options = webdriver.ChromeOptions()
all(ord(c) < 128 for c in s)
inputs = [1, 1, 0, 2]
x = np.linspace(data.min(), data.max(), 100)
inputarr = sys.stdin.read().split()
tree = etree.parse(testf, parser=parser)
[hyde]
obj_list.append(obj[i])
list(range(lowerBound, upperBound + step, step))
fig.autofmt_xdate()
foo = np.array(foo_array)
count += 1
a[row, col] = a.sum(axis=1) - a[row, col]
MonkeyDevice.__init__(self)
Signal.send(sender, **kwargs)
print(a % np.sign(a))
s1rev = inter.InterpolatedUnivariateSpline(x[::-1], y[::-1])
copyfileobj(fsrc, fdst)
DL_path = os.getcwd()
max(chars, key=chars.count)
print(i1 & 16777215, i2)
surf = pg.Surface((200, 200), flags=HWSURFACE)
dct[elem_name]
keys = sorted(sorted(shaders_dict), key=shaders_dict.get)
tick.set_markeredgewidth(2)
parser.argparse.ArgumentParser()
timeit(stmt1, number=100)
u, v = np.mgrid[0:2 * np.pi:20j, 0:np.pi:10j]
cols = df.columns.values
has_add_permission(self.request.user, self.request)
print(data)
index, item
a[0] + a[1] * 0.1
print(repr(packet))
Py_Initialize()
cv2.line(out, (int(x1), int(y1)), (int(x2) + cols1, int(y2)), (255, 0, 0), 1)
dict_of_lists = defaultdict(list)
sum = 0
dllname = os.path.split(dllname[0])
expr.setParseAction(Expr)
print(REGEX.findall(test_string))
ax = fig.add_subplot(111)
setattr(mod, attr, value)
pubs[0].num_books
do_something(obj)
json.dump(testarr, test_file)
output.close()
screen.fill((159, 182, 205))
self.nout = a
tmp = np.zeros((height, width))
data.update(a_dict)
t = np.floor(x)
ans.extend([(a, x) for x in l2[b:e]])
print(polygon(4, 100))
fd.write(data)
f.writelines(lines[-LIMIT:])
qcookiejar.setCookiesFromUrl(qnetworkcookie_list, QUrl(requested_url))
httplib.HTTPConnection.putheader(self, header, value)
loop_start = time.time()
foo = Foo()
fbhandle.close()
dir(test)
pd.__version__
train_set, valid_set, test_set = pickle.load(f)
cnxn = pypyodbc.connect(conn_str)
login_form = LoginForm(request.POST)
assert istr.good()
print(arguments[i].value)
pool = multiprocessing.Pool(1)
result
value
merged.update(obj)
Py_Initialize()
s.append(item[0] + item[1])
result_data[mask] = np.mean(values[mask])
True
print(list(all_combos(ceiling=6, target_sum=12, num_cells=4)))
im_out = (im_out * 255).astype(np.uint8)
op.__dict__.update(locals())
PyErr_Print()
train_data[:, (indexes[0])]
plot(times, sin(2 * pi * freq * times))
palette_img.putpalette(flat_palette)
img = feature.canny(img).astype(np.uint8)
print(type(node), node)
dictionary[x].append(y)
image.save(file_obj, ext)
file.write(i)
output[parts[1].strip()] = parts[2].strip()
line = plt.plot(t, y)[0]
c.stop()
assert a.average() == 7.5
x1 = np.random.permutation(100000)
one_set = set(one_list)
splits = list(m.start() for m in re.finditer(pattern, string))
{{response | safe}}
result = re.sub(p, subst, test_str)
existing_alias.put()
df = pd.DataFrame(data, columns=mux)
show(p)
obj = get_object_or_404(CustomModel, id=some_id)
0.6942, sym2, 7, 5, 10, 10
req = urllib.request.Request(url, stream)
np.nanmax(grouped_2Darray, 1)
print(a.__dict__)
print(line1.intersection(line2))
locale.nl_langinfo(locale.RADIXCHAR)
ranges.remove(i)
deploy(hosts, command)
base_value * (1.0 / 2.54)
browser = mechanize.Browser()
correlations = df.corr()
self.names = set()
df
cur = con.cursor()
a = numpy.array([[2.0, 0.0, 0.0], [0.0, 2.0, 0.0], [0.0, 0.0, 4.0]])
popularity = sorted(set(a), key=lambda x: -a.count(x))
gtxt = [pat[b[0]:b[1] + 1] for b in bloc]
y_rev = x.size - y - 1
result.groups() if result else []
self.delete()
account.objects.get(pk=42).accounttypeb
out = x[idx[count == 1]]
lockedmethod.__name__ = methodname
x.visit(t)
print(property.content)
h = 1 << bits - 1
comment_tree.append(create_tree(record, comment_set))
client, address = s.accept()
b = 1
Counter(s) == Counter(t)
expressions.append(list(itertools.product(o, v)))
ipshell.mainloop()
np.percentile(data, percents)
attrs
m = s.str.len().max()
gevent.spawn(read_stream, p.stderr, stderr)
df = df.fillna(0)
d2 = myfun(d)
name = models.CharField(max_length=50)
print(a)
type(b)
a = len(may_a)
lexer = lex.lex(optimize=1)
user = form.save()
pool = ThreadPoolExecutor(max_workers=40)
y = (lambda x=x: [(x + i) for i in range(1)])()
L = dot(diag(D ** -0.5), dot(A, diag(D ** 0.5)))
lib.test.argtypes = POINTER(darray), POINTER(darray)
f(5)
curses.endwin()
S = pd.Series(np.random.normal(size=200))
print(l)
regex.sub(repl, string)
main()
root.mainloop()
fig = figure()
print(foo, bar)
triples.append((i, t1, t2))
A()
out = zip(r, c, a[r, c])
ctypes.sizeof(ctypes.c_uint16)
L = [1, 1, 2]
array([6, 8])
flab_nickers,
x = np.random.random((M, N))
row = line.split()
result = [idx for idx, item in enumerate(a) if item in a[:idx]]
max_value = a[mask].max()
rs = (grequests.get(u) for u in urls)
nrange = np.arange(n)
po = Pool()
mat[0][0] = 1
np.set_printoptions(linewidth=1000, edgeitems=5)
Base = declarative_base()
random_sample(data, timesteps=2, batch_size=2)
ystart = 0
b.getDouble_B()
e = Environment(loader=fileloader, autoescape=True)
d(10) ** d(10) ** d(10) == d(10) ** d(10) ** d(10) + 1000000
xml.sax.parse(f, ch)
df_test.loc[idx]
d.update(value)
arr = (i >> nxn) % 2
numpy.asarray([my_list]).shape
http_server.listen(8080)
self.identity.do_something()
plt.grid(True)
new_list.extend(letters[start_index:start_index + n])
jsonresponse = json.loads(response.body_as_unicode())
self.func(*func_results)
print(yaml.dump(d))
key_fu = lambda x: x[0][0]
print(a[(np.newaxis), :, :].shape)
gca().add_patch(rect)
FirstBase.__init__(self, *args, **kargs)
plt.semilogy(xdata, ydata)
print(prng.random())
pageContent = urllib.request.urlopen(httpRequest)
df
i, j = 0, 0
print(password)
self.setLayout(layout)
row_names.append(name)
slices = sorted(random.sample(list(range(0, len(index))), 2 * n))
self.heap = []
d = defaultdict(list)
load_file(self.md5)
logging.error(self.headers)
line2 = LineString([(0, 1), (1, 1)])
write_and_close_docx(word_doc, tree, new_word_doc)
Lv = np.append(Lv, [last])
lst = list(range(4))
data = json.loads(elevations)
Pdb
print(page_html + news_script_output)
td = datetime.timedelta(hours=2)
cmp(v1, v2)
dtype2 = np.dtype({name: arr.dtype.fields[name] for name in fields})
arr = np.arange(2000).astype(float)
A.__dict__
self.add_widget(widget)
s1.erase(*iter)
server_url = models.CharField(max_length=255)
histogram[img.getpixel((x2, y2))] += 1
loop = asyncio.get_event_loop()
arr
out = np.zeros((maxt, maxdimx, maxdimy))
list(seen2)
a = []
matches = my_regex.findall(string)
searchlines = f.readlines()
print(df[inds].to_string())
button.pack()
df.B.ix[:4].last_valid_index()
R.append(psi)
print(stringtest)
stars1 == stars2
True
s2crazy = inter.UnivariateSpline(x[::-1], y[::-1], s=500000000.0)
[gdb.Breakpoint(m) for m in method_names]
A = np.zeros((nr - 1, nr))
plt.plot(x, delay)
stdoutdata, stderrdata = p.communicate()
Notification.objects.exclude(pk__in=objects_to_keep).delete()
line.setOpacity(opacity)
last_index = -1
print(k[2])
db.run_in_transaction(txn)
ans = x / y
dis.dis(a_long_tuple)
discoverer = Discoverer(sys.argv[1])
execute_from_command_line(sys.argv)
np.array([5.6]).dtype.num
outfile.write(mystring)
BoundingBox = cv2.boundingRect(c)
item
t = t + (1,)
parser = argparse.ArgumentParser()
mask_idx = ~np.in1d(pairs1D, positions1D).reshape(-1, 2).all(1)
_render_template(*args, **kwargs)
sh = wb.get_active_sheet()
i = 0
x += 1
size = len(value)
print(sql)
nrm = stats.logistic.cdf(1) - stats.logistic.cdf(0)
conn.close()
True
random.shuffle(b, lambda : r)
{{YOUR_CUSTOM_SETTING}}
test(1000, 50, 11)
ax = ax.ravel()
double_to_hex(-17.5)
x = np.interp(t, np.arange(len(x)), x)
list(csv.reader(inf))
fn = sys.stdin.fileno()
finalresults = results.execute()
alpha = 2 * math.pi * random.random()
config = ConfigParser()
out_count = np.zeros_like(out_id)
frame = sys._getframe(1)
skyscrapers[building_number] = AIR
output.write(encrypted_secret_key)
collator = PyICU.Collator.createInstance(PyICU.Locale.getFrance())
deleteelem.getparent()[0]
x = arange(0, 1, 1.0 / POINTS)
row_names, col_names, data_table = [], [], [[]]
[1, 0, 0]
k1 = sorted(dict1, key=dict1.get)
handle = models.CharField(max_length=255)
mydict = {}
od2 = OrderedDict(sorted(list(d2.items()), key=lambda t: t[1]))
labels = [item.get_text() for item in ax2.get_xticklabels()]
main()
transposed = zip(*arr)
result[i]
1 + len_recursive(s[1:])
to_dict(y)
App().root.mainloop()
y = (i for i, v in enumerate(l) if is_odd(v))
QtGui.QSystemTrayIcon.__init__(self, icon, parent)
Department.objects.raw(sql)
asyncio.set_event_loop(self.loop)
assert sum(A) == sum(B)
pd.DataFrame(dict(l1=lp1, l2=lp2))
globals()[name] = ClassFactory(name, params)
renWinL.Render()
generate_n_primes(10)
print(item)
str(m)
minutes, seconds = divmod(remainder, 60)
sys.getsizeof(n)
ax1 = fig1.add_subplot(1, 1, 1)
os.waitpid(pid)
time.sleep(0.1)
getattr(self._parent, name)
df.head()
results = sorted(lists, key=lambda x: (x[0], int(x[1]), int(x[2])))
order = np.lexsort((data, groups))
show_graph(adjacency)
t5.join()
cfd(treebank.tagged_words())
s = dff.isnull().apply(sum, axis=0)
response = urllib.request.urlopen(crawling)
s = set([4, 5, 6])
fh = logging.FileHandler(LOG_FILE)
np.asarray([a[(n), :, (p)] for n, p in enumerate(b2)])
file_date_tuple_list = [(x, os.path.getmtime(x)) for x in files]
pd.get_dummies(s, drop_first=True)
self.fn(*args, **kwargs)
filehandler.write(image_data)
self._s.bind((self._host_address, port))
setup2DstuffModelview()
G = nx.Graph()
B_out = np.zeros((len(A), n_cols))
curs.close()
c[:, (np.concatenate(([True], c[(1), 1:] != c[(1), :-1])))][0]
w, h = Image.open(imlist[0]).size
count_list = list(range(1, N + 1))
f = Foo()
convolved = np.zeros((nx, ny, nz))
print(minimal_dims.shape)
the_list = [5, 7, 6, 5, 5, 4, 4, 7, 5, 4]
sys.stdout.encoding
df = DataFrame(d)
ba = bytearray(fh.read())
dirpath = sys.argv[1]
mask = np.hstack((mask1, mask2))
title = models.CharField(max_length=255, unique=True)
article = Article.objects.all()[random.randint(1, 15)]
my_random_bytes = bytearray(randbytes(1000000))
f.close()
shutil.copy2(src_file_name, tf.name)
out.append(d)
print(message.format(value))
print(help(a))
mylist = []
a is b, a is c, a is d, c is d
self.pack()
record.append(line)
n = np.prod(shape)
divider = make_axes_locatable(ax)
full_name.strip()
print(list(p))
contents = f.read().split()
t = Thread(target=self._run, args=[self])
f = [0] * nfactors
keys = sorted(d.keys())
self.get_year_sales(datetime.now().year - 1)
build_matrix(f1, (A, B))
self.assertItemsEqual(lst1, lst2)
response = urllib.request.urlopen(request)
p.append(1)
dato = forms.DateField(widget=SelectDateWidget(), initial=yesterday)
shell.interact()
collections.defaultdict(tree)
ax = df.plot()
transport = paramiko.Transport((ssh_host, ssh_port))
a.dtype.type is np.string_
ssl.__file__
position = center[0] - 10, center[1] + 10
value = self._get_val_from_obj(obj)
True
form = YourForm(data)
mythread.start()
themod = __import__(themodname)
foo.x
sess = tf.InteractiveSession()
form.category.choices = categories
text = f1.read()
result = cur.fetchone()
a = df.values
urljoin(url, quote_plus(term))
ax.spines[pos].set_edgecolor(color)
{{formset.management_form}}
f = tempfile.NamedTemporaryFile(delete=False)
_init_func()
handles, labels = ax.get_legend_handles_labels()
out.close()
d = feedparser.parse(url)
arclen = 2 * np.pi * r
True
main()
ax.contourf(xs, ys, zs, cmap=cm.autumn)
ax.set_ylim(0.5, max(y))
t = Thread(target=newFunc)
string.seek(0)
self.send(s)
draw.rectangle(transparent_area, fill=0)
draw.text((0, 50), txt)
contents = output.getvalue()
muY = Y.mean(0)
plt.show()
b = [4, 5, 6]
s = pylzma.decompressobj()
np.linalg.det(a)
a, b = pickle.load(f)
zf.close()
rc2f = np.ravel_multi_index(rc2, A.shape)
results = proc.stdout.readlines()
math.floor(-1.5)
result
mpp.join()
my_dict = dict(list(tmp.values()))
book.py
out = my_array[cond]
req = urllib.request.Request(url)
numpy.searchsorted(a, v, side=numpy.CONSTANTS.SIDE.RIGHT)
print(elevation)
threads.append(thread)
file = os.path.abspath(file)
good = np.where(np.isfinite(A))
self.parent.Iconize()
output_wave_file.setparams(input_wave_files[0].getparams())
config.get(section, name)
pickle.dump([obj0, obj1, obj2], f)
action.triggered.connect(self.mapper.map)
tar.addfile(tarinfo=info)
docs.append(raw_doc)
df
foo = 1
page = f.read()
print(df)
BOOST_PYTHON_MODULE(example)
sum([(1, 2), (1,), ()], ())
-[a, b, c]
filepath = os.path.join(path, filename)
cp = urllib.request.HTTPCookieProcessor()
max(self.root.left.height(), self.root.right.height()) + 1
dW[:, (y[ii])] -= XX[(ii), (jj), (ii), :].transpose((2, 0, 1))
t.start()
X = pd.DataFrame(data)
response.peer = self.sock.getpeername()
db.put_async(self)
inputproc1 = Popen(shlex.split(inputcmd1), stdout=PIPE)
fp.close()
doStuff()
e.property
surf.fill(BGCOL)
ax = plt.subplot(111)
u = User.objects.get(id=1)
unittest.TestSuite.run(self, testResult)
plt.tight_layout()
split_ip(item[0])
line_count += 1
my_module
vbox1.addWidget(self.edit1)
Thread(target=loop).start()
print(len(results))
i = np.argsort(a, axis=1)
maxlen = max(map(len, data))
np.multiply(normal, -1)
ax.get_xaxis().set_visible(False)
log = logging.getLogger()
doStuff(self.model.documents)
L[left:right]
C = np.random.rand(N, N)
draw = ImageDraw.Draw(mask)
DeckForm.__init__(self, *args, **kwargs)
Evaluation.EXCLUDE_AND_CONTINUE
getPermutations(string[:i] + string[i + 1:], prefix + string[i])
corrected_link = upper_match.replace(match.group(2).upper(), match.group(2))
main(args)
app = Flask(__name__)
self.labels = self.ax.get_xmajorticklabels()
abs(x) / abs(y) * cmp(x, 0) * cmp(y, 0)
worksheet = workbook.sheet_by_name(workbook.sheet_names()[0])
self.serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
dist / hello.app / Contents / MacOS / hello
[f.name for f in matplotlib.font_manager.fontManager.afmlist]
yhi = yhi if yhi <= imsize else imsize
print([(r / psum(raw)) for r in raw])
len(b)
2 - 1
box.pack()
self.a = a
xpxl2 = xend
x = y[0] * y[1]
iter(self._inner)
sys.stdout = file
root = lxml.html.fromstring(html)
cur = conn.cursor()
d.a[i:i + k] == d.b[j:j + k]
words_found.append((k, v))
xml.sax.expatreader
res.append(Gap(min(random.randint(1, 5), l - t)))
print(args)
auto_generate_test_cases(Tester, Testee)
row.append(DataReader[j].ToString())
line += next(f)
inner_nodes.sort(key=lambda n: len(subtree[n]))
fig = plt.figure(figsize=(6, 6))
bi_tag.evaluate(cess_sents[train + 1:])
notebook.set_tab_reorderable(page2, True)
register = Library()
max_x = scipy.optimize.fmin(lambda x: -f(x), 0)
os.mkdir(newDir)
response
y = np.outer(np.sin(lons), np.cos(lats)).T
statbuf = os.stat(filename)
self.src[i].insert(0, itemtoshift)
l, = ax.plot(x, y)
sys.stdin = sys.stdin.detach()
self.path = path
SOME_OTHER_CONSTANT = 2
ws = wb.active
list(date_range(begin, end, 4))
matches[1].fromy, matches[1].fromx
print(funcs[1]())
print(unrooted_tree)
end_date = datetime.datetime.utcnow()
time.sleep(8)
then = now - datetime.timedelta(days=90)
print(json_data)
self.__init__(self.sl)
tuple(a.tolist())
root.grid_columnconfigure(1, weight=2)
self.fault = fault
ax4.legend(loc=5)
lines = lines[-10:]
self.handleFontChanged(self.font())
self.buf.seek(0, 2)
self.a = a
[1, 0, 1, 0]
response.status
r = re.search(lun_q, s)
lines = file.readlines()
[truncate(f, n) for n in range(7)]
hash(True)
result.append((longest_keyword, ()))
random_list = random.sample(list(genes_dict.items()), int(length))
c = conn.cursor()
r = list(range(1, loopcount))
True
resultset.append(dict(row))
main()
et = ET.ElementTree(document)
type(a)
np.sum(arr ** 2)
bool(set(fruit_dict2).intersection(fruits))
start = time.time()
self.destinitions_list.append(destinition)
file.write(dictionary_content)
PrintLn(f)
print(myset)
all(nested_equal(a[k], b[k]) for k in list(a.keys()))
serial = LadySerializer(tiger, many=False)
sock.close()
zip_write.writestr(item, data)
timeit[n / 100, n / 10 % 10, n % 10]
self.cntrlPanel.SetPosition((0, 0))
a()
a = [4, 2, 1, 5]
x[i] = x[i] + 1.0
array.sort(lambda L, R: -1 if R is 0 else 0)
os.dup2(self._devnull, 1)
purple_count = len(set(list_of_purple_items).difference(list_of_all_items))
self._bar = bar
re.sub(findthe, lambda m, r=iter(replacement): next(r), sentence)
offset += 1
profile = webdriver.FirefoxProfile()
result.append((1, record.id, values))
d2 + datetime.timedelta(calendar.monthrange(d2.year, d2.month)[1])
self._func(*args, **kwds)
datetime.time(hour, minute, second)
print(nsmallest(4, indices(), key=keyfn))
results[key] = params[key]
PyErr_Print()
aa.set_axis_off()
False
northing = 10000000 - northing
print(result)
os.kill(p.pid, signal.CTRL_C_EVENT)
self._session
png_formatter.for_type(Image.Image, display_pil_image)
p = argparse.ArgumentParser()
_generate_range_values(value, end)
add_colorbar(im)
logger = logging.getLogger(__name__)
print(df)
emonth1.insert(10, 1)
title = models.CharField(max_length=255)
[nest(x, n - 1)]
url = url_test.format(i)
method_to_be_executed_in_case_of_exception_or_pk_is_false()
Foo.y
foo.bar = types.MethodType(partial(foo.bar, qux=1), foo)
groups = list(groups)
np.ix_(rows, cols)
x = np.arange(16).reshape((4, 2, 2))
D = {k: v for v, k in enumerate(albums_yesterday)}
session = dryscrape.Session()
result = {}
print(msg.Subject)
print(A.T)
sqr = int(math.sqrt(n)) + 1
self.after(100, self.updateimage, (sprite + 1) % self.num_sprintes)
foo.num += 1
time.sleep(0.2)
chambersinreactor += 1
ret = np.concatenate(ret)
pd.DataFrame(self.values.copy(), self.index.copy(), self.columns.copy())
rStandalone.reassign(7)
original = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)
threshold(imgrey, imgrey, 100, 255, 0)
raise KeyError(key)
__slots__ = []
last_friday_at_16 = datetime.datetime.combine(last_friday, datetime.time(16))
plt.subplot(2, 1, 1)
user_email = db.Column(db.String(128), unique=True)
zinfo.CRC = CRC
writer = csv.writer(out_f)
idx = arr[arr.hour >= 17] + pd.offsets.Day(1)
nodaemon = true
surf1.set_alpha(100)
surf2.set_alpha(100)
print(longest_common([a, b, c]))
soup = BeautifulSoup(markup)
u = [np.zeros((n, n)) for i in range(N)]
sum(counts)
print((m, b))
app
print(categorize(event))
addlist.append(item)
Sw = np.cumsum(cw[1:] ** 2)
np.take(bins, np.digitize(a, bins, right=True))
my_set = set(my_list)
self.panel = wx.Panel(self, wx.ID_ANY)
all_features.sort()
ax.broken_barh([(midpoint - 0.1, 0.2)], (perc[1], perc[2] - perc[1]))
print(p.stdout.readlines())
instance = RemoveNoise()
app = Flask()
inlines = [PageFileInline]
[operation(n) for n in list]
self.listbox.pack()
test_settings(self.request.user)
wiringpi2.wiringPiISR(4, wiringpi2.INT_EDGE_BOTH, my_int)
pl.show()
print(df)
slen1 = len(s)
coeffs = np.polyfit(x, y, 2)
chain(*(map(iter, self.children) + [isingle(self.value)]))
good = df.ix[df.index - sub.index]
stop_timeout = 20
vals = data_rvs(k).astype(dtype)
ax = plt.gca()
print(df1)
testarr = np.asarray(test)
graph.set_ydata(Y)
my_set.add(5)
f(150, 150)
root = Tk()
np.testing.assert_almost_equal(x, y, 5)
str(soup)
Y = np.dot(beta, X.T)
q.put(line.strip())
piexif.insert(data, path)
self.fileobj.seek(offset, whence)
ret.append(i ** 2)
rec += connection.recv(1024)
ax.yaxis.set_minor_formatter(matplotlib.ticker.ScalarFormatter())
main()
0
processBody(line)
self.items.pop()
abbreviation = models.CharField(max_length=4)
ipc_event_cmd.execute()
indexes.append(idx)
y_indices = indices[1]
m_t.bind()
self.connection.settimeout(self.timeout)
[0, 2, 2]
cssutils.log.setLevel(logging.CRITICAL)
myTurtle.done()
cond = np.logical_and(arr[:, (0)] >= dtx, arr[:, (0)] < dty)
pDF = sqlContext.createDataFrame(pdDF)
print(df[order])
nbits = n.bit_length() + (1 if n < 0 else 0)
df.to_html(out, float_format=fmt)
node0.join()
block_list.extend(sequences[::-1])
list(range(df.EVALUATION_GRADE.min(), df.EVALUATION_GRADE.max() + 1)),
timeout = Timeout(seconds, exception)
sx = np.sqrt(np.sum(x2 * xp) / np.sum(xp))
gram_matrix[i, j] = K(x, y)
d = defaultdict(list)
np.vsplit(a, 2)
alpr.is_loaded()
testsuite = unittest.TestSuite()
channel.exec_command(COMMAND)
os._exit(1)
result.append(item)
log.err()
QtCore.Qt.CopyAction | QtCore.Qt.MoveAction
button.setIcon(icon)
self.arrays[j][i - shift]
is_sum_of_numbers(18, numbers)
csvout.writerows(repeat(row[2:4], count))
cache.get(key)
list_a = ModelA.objects.all()
seen = set()
ax.plot(list2)
idx = mask[xarr, yarr].astype(bool)
iter(obj.items())
scatter(X, Y, c=next(cycol))
map.remove(coord)
_cell.style.alignment.wrap_text = True
lucky = []
fp.close()
color = px[x, y]
len(a)
counter = collections.defaultdict(int)
s[d[i]] = rearranged_data[i]
a[2:]
req = urllib.request.Request(url_2, data)
[0, 2, 0],
results = cursor.fetchall()
self._callfunc = lambda s: s
self.appExeCB = QtGui.QComboBox()
ret, gray = cv2.threshold(gray, 10, 255, 0)
entry2 = tk.Entry(root, width=15, textvariable=stringvar2)
handles, labels = ax.get_legend_handles_labels()
c = mkunion(a, b)
fig.savefig(filename)
msg.send()
response.peercert = resp.peercert
f(a)
app.debug = True
blob_reader = blobstore.BlobReader(blob_key)
do_something(vals[key])
event = pygame.event.wait()
new_usage = [sum(x[1] for x in v) for k, v in groupby(zip2, key=itemgetter(0))]
tree[0].text
thread.start()
name = file.filename
sympy.__version__
df
m_ = np.ma.masked_where(y > 2, x)
start_date.replace(year=start_date.year + 1)
print(result)
fig = plt.figure()
self.nodes.append(n)
any(some_list)
mylib.Add.restype = c_int
a = numpy.arange(1000.0)
print(line)
[plt.plot(i, 0, marker=markers[i], ms=10) for i in range(16)]
BrotliCompression.Decompress(input, output)
threads[t].start()
foo_copy = copy.deepcopy(foo)
type(self)(self.default_factory, copy.deepcopy(list(self.items())))
type.__setattr__(cls, attr, value)
list2 = list1.split()
[0, 2, 0]
f.seek(2, 1)
print(f)
layout = QtGui.QVBoxLayout(w)
binary.insert(0, bit)
foo(**args_dict)
[(i, z) for i in [1, 2] for z in itertools.filterfalse(lambda x: x in ys, xs)]
f = pickle.loads(x)
True
loggerCent.addHandler(ce)
wrapper_object.close()
content = conn.getresponse().read()
print(data)
parser = argparse.ArgumentParser(usage=usage)
plt.plot(x, f2(x))
df1
res.get()
d = datetime.timedelta(days=21)
feed = feedparser.parse(url)
qry = session.query(Page)
hasher.update(block)
dict.__setitem__(self, key, val)
Review.objects.filter(venue__pk=2)
b()
sleep(1)
items = [i.items() for i in items]
f.write(html)
print((table, field, row[field]))
new_list
input = input()
list_of_numbers = sorted(list_of_numbers)
res.head(10)
self._ngrams.add(ngram)
p2.stdin.write(data)
tick.label1 = tick._get_text1()
fig = plt.figure()
view.replace(edit, sublime.Region(0, view.size()), text)
p = Popen(cmd, stdout=PIPE)
green_list.append(s[0] - green_start)
doc = docx.Document(filename)
device.close()
fliplr(flipud(m))
im.show()
self.assertEqual(untrusted, res)
a.sort_index(1, inplace=True)
explain.my_selfexplaining_method()
client = paramiko.SSHClient()
first_elts = [x[0] for x in my_tuples]
z = np.zeros((5, 5))
testloader = unittest.TestLoader()
basepart, ext = os.path.splitext(filename)
replace(list, 1, 7)
sorted_chunk = sorted(islice(input_file, 50000))
foo = lambda x: pd.Series(pd.qcut(x, 10, labels=False), index=x.index)
ADOMDConn.Open()
sentencecount += 1
subdict = {x: bigdict[x] for x in interesting_keys if x in bigdict}
last_key = line[:-1]
self.worker = Worker()
alist.sort(key=natural_keys)
result = pool.map_async(task, list(range(10)))
print(sess.run(b))
D()
X = [np.sin(e) * np.cos(a), np.sin(e) * np.sin(a), np.cos(e)]
df = pd.DataFrame(np.random.randn(10000, 10000))
feedparser.parse(url)
self.window.setWindowFlags(QtCore.Qt.Widget)
second += timedelta(days=1)
result = []
srn(my_number)
circle[0]
main()
User.master_query.filter(User.id == 1).all()
do_something(fname)
a1 = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]])
a = np.random.random((10, 10))
self.assertEqual(1 + 1, 2)
a = Article.objects.all()[0]
+b * cos(u) * sin(v)
r_server = redis.Redis(connection_pool=pool)
cc.get_violating_points()
g = g.reset_index()
horizontal.sort(key=lambda x: x[1])
start = time.time()
table[i][W - 1]
rgb_to_hsv = np.vectorize(colorsys.rgb_to_hsv)
print(Crypt.find_crypts(0))
self.view = QtGui.QTreeView()
response = connection.getresponse()
print(authentry.parseString(text).dump())
box_form = workbook.add_format()
layout = QtGui.QHBoxLayout()
sources[:MAX_SOURCES]
time.sleep(0.7)
writer.writerow(newline)
self.centralwidget = QtGui.QWidget(self)
np.where((abcd <= data2a) & (abcd >= data2b), 1, 0).sum()
items[bisect.bisect(added_weights, random.random() * last_sum)][0]
sorted_input = sorted(input, key=itemgetter(1))
can.pack()
d = {}
a = np.array(quantized)
z = zipfile.ZipFile(some_source)
print(outputStr[:-1])
print(cert.prettyPrint())
new_val = sum([d[topkey][key] for d in dicts])
process.start()
df[columns]
ord(hashlib.md5(s).digest()[0])
PyErr_Print()
S[col] = int(homescore) - int(awayscore)
style = wx.DEFAULT_DIALOG_STYLE | wx.RESIZE_BORDER
i = np.where(mask)[0][0] + 1
A = np.random.randint(1, 5, (N, N, K))
ax2.set_xlim(51, 56)
self.reader.__iter__()
testlist = random.sample(list(range(0, 20)), 10)
edges[i - 2, j].append((i + 2, j))
self.creation_date = datetime.datetime.now()
x = 1
primes = []
__bootstrap__()
[self[i] for i in range(*idx.indices(len(self)))]
writer = csv.writer(fp)
[1, 2] in {1, 2}
r, w, e = select.select(r, w, e, timeout)
ax.plot(scipy.randn(8))
model.add(Dropout(dropout))
soup = BeautifulSoup.BeautifulSoup(html)
n_lsb(n) & ~n_lsb(m)
counts = Counter(chain(*map(set, mylist)))
b.shape
self.b.clicked.connect(self.clickHandler)
figure()
nltk.__version__
many = True
crawler.signals.connect(reactor.stop, signal=signals.spider_closed)
wp.interpolate()
b = np.matrix(b).T
i += 1
salt = bcrypt.gensalt()
fig, ax = pl.subplots()
result = list(camel.camel_search(text, search_words))
a.getSingle(), b.getSingle(), b.getSingle_B()
M = Matrix(([x, y], [a, b]))
plt.figure()
[1, 0, 0, 1]
a = datetime.now()
train_op = optimizer.apply_gradients(capped_gvs)
self.portfolio.append(entry)
plt.show()
col = np.tile(ii, (a.shape[1],))
price2
start = end + 1
print(cur.fetchall())
a = representatives[a]
process()
p.close()
result
data = conn.recv(1024)
repo.index.commit(commit_message)
total_columns = len(the_tuple)
False
print(selected_option.text)
self.fp.write(buf)
test2.timestamp = datetime.datetime.now() - datetime.timedelta(hours=1)
x = []
stack.pop().append(element)
data = mmap.mmap(f.fileno(), 0)
pylab.xlim([min(lefts), max(rights)])
print(fin.read().strip())
cause.append(n.id)
bool([x for x in list(results.values()) if set(x) == match])
dfs.append(psql.read_frame(sql, cnxn))
111111
[p.join() for p in proc]
self.remoteuser = remoteuser
self.remotehost = remotehost
resized_file = orig_image.resize(scaled_size, Image.ANTIALIAS)
x * y
window = np.asarray(window)
self.statusItem.setHighlightMode_(TRUE)
fftf = scipy.fftpack.fftn(f)
adlen = ctypes.c_ulonglong(len(ad))
self.recv_buf_i += 4
today = datetime.datetime.now()
do_something()
com = serial.Serial()
-cr.fetchone()
time.sleep(1)
print(unpickle_regexes(pkl))
value
d = dict(l)
len(self._list)
urls.py
os.utime(fileName, (orgTime, orgTime))
print(out)
[(not b) for b in x]
line = f.next().strip()
powers.append(i)
object_session(self).query(Foo).filter(Foo.bar == self).count()
a = A()
loop.run_until_complete(run())
fig.set_size_inches(1, 1)
server.login(username, passwd)
h2o.auc(best_model, valid=TRUE)
current = datetime.date(2010, 8, 1)
set(deletes + transposes + replaces + inserts)
dict(zip(it1, it2))
session.configure(bind=engine)
kill_proc_tree(me)
value = count_list.pop()
AxesWidget.__init__(self, ax)
self.sprockets.remove(spr)
km.load_connection_file()
f.write(counter)
df[df.ge(0)].fillna(-9999).where(df < 0, df.eq(df.max(1), 0).astype(int))
a.foo()
canvas.create_polygon(*coords)
sleep(0.1)
mro = self.__class__.mro()
1
self.__offset = timedelta(minutes=offset)
setattr(TestSequence, testmethodname, testmethod)
draw_ellipse(image, ellipse_box, width=20)
df
channel = connection.channel()
self.update(rawdata)
user = User.objects.get(username=username)
myseries_one.loc[0:2]
logger.setLevel(logging.INFO)
print(myglobal)
result
print(f.__defaults__)
f()
i -= 1
print(df)
sorted_ab = zip(*sorted(chain(keyed_a, keyed_b), key=lambda t: t[0]))[1]
cbar_ax.set_position([posn.x0 + posn.width + 0.01, posn.y0, 0.04, posn.height])
dict(ChainMap(*a))
processBody(line)
line = line.strip()
Function(lambda x: self(x) / other(x))
self.stdout = sys.stdout
ax1 = fig.add_subplot(111)
date = dt.datetime(1970, 1, 1)
df[subset.isin(myList).rolling(2, axis=1).sum().max(axis=1) >= 2]
ch1 = stackless.channel()
eval(method_name2)
window_name = window.get_wm_name()
assert np.allclose(means, funcmeans)
1
m.group(1)
counts[i] = counts.get(i, 0) + 1
counter[0] -= 1
archive.write(path, relname)
users = api.lookup_users(user_ids=ids)
cj.load()
df.dtypes
ax = fig.add_subplot(111)
L[a + span2:c] = L[a:b]
min_dist = np.empty(n)
main()
copy_of_a = list(a)
nl.append(base)
list(zip(a, b))
ax.yaxis.set_major_formatter(FixedOrderFormatter(-9))
s = open(filename).read(512)
p.insert(0, a)
Test.method_two()
file.close()
self.layoutVertical = QtGui.QVBoxLayout(self)
iter1, iter2 = [x[0] for x in compound_iter], [x[1] for x in compound_iter]
logging.config.dictConfig(LOGGING)
g.readinto(q)
ret = float(s)
_a(cos(p[0]) * p[1], sin(p[0]) * p[1])
df
k = k[k != test].reshape(-1, 2).astype(float)
bs = BeautifulSoup(html)
image_yuv = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)
t.set_priv(True)
retval += chr(node[1][0][1][0])
palette = imframe.getpalette()
z = np.logical_or(z, rolled)
np.dot(L1_sums, L2_sums)
data = s.recv(1024)
list = [7, 6, 5, 7, 6, 7, 6, 6, 6, 4, 5, 6]
pygame.time.Clock().tick(10)
reader = csv.reader(f)
ax.add_collection(col)
sock = socket_create(AF_INET, SOCK_STREAM, 0)
plt.plot(ipl_t, x_i)
d[k] += v
[7, 8, 9],
raise ConnectionError(err, request=request)
dict(d)
ransport = random.choice(list(sportDict.keys()) + [sport])
distutils.log.set_verbosity(-1)
fig, (ax, ax2) = plt.subplots(1, 2, sharey=True, tight_layout=True)
aut.add_word(s, s)
mins.sort()
self.bar % 2 == 0
unquote(value)
new_arr.append(new_val)
session.flush()
image = Image.open(data)
func.__get__(obj, cls)
nx.draw_networkx_edges(Gcc, pos, alpha=0.4)
ax.set_ylim(-0.5, 0.5)
settings.MYAPP_SETTINGS_1
save(random.choice(classes), arg)
[self[x] for x in range(i.start, i.stop, i.step or 1)]
Object.__getattr__(self, name)
print(len(x))
sys_exit.assert_called_with(1)
pylab.plot(list(range(10)))
df
threads.append(t)
atexit.register(web.quit)
print(sdi)
plt.yticks(np.array([]))
match = [0] * (len(s) + 1)
timeout.cancel()
session.flush()
print(time.clock())
client_socket.send(size)
df[~df.stack().between(0.1, 1).unstack()].dropna(axis=1)
window_size = np.abs(np.int(window_size))
a + b
True
image_input = tf.placeholder(tf.uint8, shape=[22500])
subprocess.check_output(command).strip()
isinstance(p, list)
print(lst)
o = Object()
print(match)
self.delete(self.index(Tkinter.INSERT), Tkinter.END)
self.tgtkey = self.currkey = self.currvalue = object()
session.add(new_bike)
setattr(obj, accessor_name, object_list)
m = a[k]
message = self.queue.get()
edgex2 = region2 ^ np.roll(nregion2, shift=shift, axis=0)
c = formC.save(commit=False)
print(platform.python_version())
dest.blit(tmp, (0, 0), dest.get_rect().clip(maskrect))
fmt_values
self.store.remove(key)
divider = make_axes_locatable(ax1)
pd.crosstab(df.Event, df.Status)
a += [4]
clusters[-1].append(point)
tmp.seek(0)
branch[1].append(path[-1])
progress.setValue(100)
x * 2
merge_Sort(list1, list2, new_list)
Z.data *= Y[Z.row]
d[c] = i
args, subargs
self.factory.echoers.remove(self)
video_window.destroy()
sct.norm.ppf(q=0.05, loc=60, scale=40)
string[string.find(substring) + len(substring):]
response = requests.get(_GOOGLE_TRENDS_URL % term)
0, [True, True, True, True]
loaded_dict = json.loads(dumped_dict, object_hook=date_hook)
wx.Panel.__init__(self, parent)
L = [0, 8, 5, 6, 4, 5, 6, 14, 8]
myTurtle.forward(size)
myObject.die()
file.seek(currentReadPos)
scene.objects.active = lamp_object
result[key] = value
f1 = lambda x: np.sum(x) - 1
nested.__closure__[0]
ax = fig.add_subplot(111)
G.add_edge(parent, child)
self._conn.timeout = timeout
fscale = t / max(t)
df
obj0, obj1, obj2 = pickle.load(f)
kwonly = oldcode.co_kwonlyargcount
jsondata = JsonData(**result)
file_list.extend(join(root, f) for f in files)
b = np.random.randint(N, size=n)
image = Image.open(stream)
print(soup.contents[0].string)
x.cumsum()
current_color = px[i, j]
print(count.most_common())
print(len(match_foo))
dt_now = datetime.now()
result = task.get()
db.put(fu_list)
idx = list(df.index)
print([x for x in words if len(x) > avg])
init = tf.initialize_all_variables()
os.dup2(fd_stdout, 1)
print(type(value))
{{block_of_text | nl2br}}
html
ast.dump(node)
fig = plt.figure()
idx = cutoffs.searchsorted(np.random.uniform(0, cutoffs[-1]))
s.intersection(*ip)
heapq.heappush(pqueue, (-atime, fsize))
result[-1].append(s)
self.set_weights([random.uniform(0, 1) for x in range(0, n_inputs + 1)])
self.min_value, self.max_value = min_value, max_value
im = np.vstack((im[1:], im[0]))
n = len(x)
self.rematch.group(i)
B[idx[1]]
generate_random_data(latitude, longitude, 5, file_n)
l2 = [4, 5, 6]
uform = UserForm(data=request.POST)
t = threading.Thread(target=worker)
x2 = np.linspace(0, 2, 100)
B = np.rollaxis(A, 2)
draw = ImageDraw.Draw(image)
id(gb1.a)
ax.set_ylabel(label, size=20)
pzi = points[i, 2]
data.append(group)
self.view = QtGui.QTableView(self.centralwidget)
(x.index if isinstance(x, arg) else -1 for x in pargs),
titled.append(word)
a
assert b.get_value_indirect() == 0
content = urllib.request.urlopen(url).read()
self._list = list(data)
df
d.hexdigest()
s.kill()
memoizer
obj.companyid.name
polygon_coordinates = [[5, 10], [7, 9], [8, 11], [11, 20]]
my_dict = MyDict()
session = sessionmaker(binds=binds)()
json.dumps(data, indent=2)
X, Y = np.meshgrid(row, row)
query_string = urlencode(OrderedDict(data=initial_url, search=search))
child_list.append(child)
old_handler = signal.signal(signal.SIGALRM, timeout_handler)
self.oldglobals = {}
f(**kwargs)
xmin, xmax, ymin, ymax = x.min(), x.max(), y.min(), y.max()
b = B()
x = np.linspace(np.min(sample), np.max(sample))
total = 0
True
buffer.seek(0)
stat2[k] += v
all(lst) or not any(lst)
C = []
array = getarray[i]
print(np.outer(x[(10), :], y[(10), :]))
BeautifulSoup(badString, markupMassage=myNewMassage)
somefile.seek(0, os.SEEK_END)
prev, current = current, next(self.__iter)
query
lin = np.linspace(0, 5, 100, endpoint=False)
df[df.columns[1:]]
context = {}
rotated_df = largest_haloes.dot(x)
group = models.ForeignKey(Group)
l_counts = [(l.count(x), x) for x in set(l)]
nones.append(ind)
setattr(self, name, float(x))
template.format(userinfo)
s = np.argsort(b)
k = json.dumps(m)
n = sum(1 for row in csv.reader(filename))
io.show()
sub_arrays = [arr[ds] for ds in data_slices]
+models.py
x = np.arange(1.0 * 2 * k).reshape(2, k)
pprint(h)
cleansed = cleaner.clean_html(code)
atexit.register(save_history)
curpath = os.path.dirname(os.path.abspath(file))
libcap.cap_to_text.restype = ctypes.c_char_p
cols = np.array([1, 2])
pprint.pprint(codes)
wnl.lemmatize(greatest)
self.value.__str__()
print(A.method_c.__func__.__code__.co_firstlineno)
pl.imshow(z1, extent=[-5, 5, -5, 5], alpha=0.2)
print(list(rand_days))
a = ctypes.create_string_buffer(lnum.bit_length() // 8 + 1)
ax1.grid(True)
screen.blit(sys_font.render(l, 0, hecolor), (x, y + fsize * i))
np.stack(np.where(df.values)).reshape(-1, 2)
thread.start()
radii = np.linspace(0.5, 1, 10)
w.head()
buf = (c_char * n).from_address(p)
s = pd.Series(words, index=idx)
data[i] = valuej
client_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
A.shape
data = f.read()
template = env.get_template(templatefile)
p = subprocess.Popen(filepath, shell=True, stdout=subprocess.PIPE)
layout.addWidget(de)
f.write(chunk)
parser.write(f)
y = [4, 5, 6]
Foo.instance_count += 1
self.name
line = eval(input())
self.oparg = oparg
start = dt - timedelta(days=dt.weekday())
app = wx.PySimpleApp()
cls.__old_init(self, *a, **kw)
set([(d1 + timedelta(days=i)) for i in range(delta.days + 1)])
y = [4, 5, 6]
app = wx.App(False)
pos = nx.spring_layout(G, fixed=list(fixedpos.keys()), pos=fixedpos)
c.persist()
delta = timedelta(days=-delta_days, weeks=delta_weeks)
print((my_num, my_string))
x = x.__iadd__([4, 5, 6])
check(float(sys.argv[1]), float(sys.argv[2]))
out, err = p.communicate()
X[([10]), :]
self.old_handler = signal.getsignal(signal.SIGINT)
excel.Visible = 0
print((x[N], y[N]))
regr.fit(chntrain_X, chntrain_y)
kwargs = dict(kwargs)
stream.close()
self.files += 1
assert len(c) == 1
texter.setPlainText(infile.read())
ss.sort(key=lambda a: a[1].order)
a.a = 2
print(temp.weekday())
destination.set_contents_from_file(myfile)
my_map.bluemarble()
filename = sys.argv[1]
rowspans[daynum] -= 1
b = [0, 2, 4, 5]
output = ps.communicate()[0]
n = b.shape[0]
child.close()
self.inverse.setdefault(self[key], []).remove(key)
print(x)
repr(test.f_call)
NULL
width, height = self.width, self.height
dG.add_node(next_word)
f.__closure__
self.Bind(wx.EVT_LIST_BEGIN_LABEL_EDIT, self.OnBeginLabelEdit)
cumsum = df.indweight.cumsum()
Descr = row.Cells(2).Range.Text
doc = etree.parse(fp)
logger = logging.getLogger()
v = numpy.diff(t)
m_action.perform()
print(combs(sampleip1))
print(combs(sampleip0))
data = pd.read_csv(filename, names=headings)
df = pd.DataFrame.from_records(t, columns=t.columns)
print(c)
data_string = pickle.dumps(data, -1)
new_button.configure(command=callback_factory(new_button))
img_result = numpy.dstack([img, img, img])
not_contains = ~df.isin([0.1, 1.2]).any(axis=1)
elapsed2s = []
z
filepaths.sort(key=lambda filename: filename[1], reverse=reverse)
base = np.arange(size)
gcs_file = gcs.open(filename)
tuple(self.construct_sequence(node))
df
parser.parse(d)
res.append(defaults[f])
log.startLogging(sys.stdout)
now = datetime.now()
c[1, 2] = 5
print(i + 1)
self.response.write(gcs_data.gcs_read_blob(dyn))
x = np.linalg.solve(a, b)
src = driver.page_source
draw = ImageDraw.Draw(img)
a = s[0:24].uintle
site = self.request.db.query(Site).filter_by(id=key).first()
self.process.finished.connect(lambda : self.runButton.setEnabled(True))
ssh = createSSHClient(server, port, user, password)
utc_offset = local_dt.utcoffset()
print(g(x))
[1, 2] == [1, 2]
self
current_line = my_file.readline()
datetime(date.year, date.month, day)
print(max(list(kmer2count.items()), key=lambda k_v: k_v[1]))
map(operator.itemgetter(1), L)
repl += repl_pattern[len(match_str):]
ax = plt.subplot(111)
display = Xlib.display.Display()
list(chunker(x, 2))
t.join()
serializer.object
angleInDegrees = atan2(deltaY, deltaX) * 180 / PI
dx = x2 - x1
result = []
self.axes = self.figure.add_subplot(111)
pickle.dump(value, f)
grid()
outliers = X[labels == -1]
CustomPaginateNode(paginator_class, objects, **kwargs)
tally[item].append(i)
myDict = {x.index: x for x in xs}
key = row[1], row[2]
group_by(input, 1)
g.usersview.render()
s.sum(level=1)
header = gtk.HBox()
z.insert(0, z.pop())
np.random.shuffle(mask)
lambda cls: make_threadsafe(cls, methodnames, lockfactory)
idx = np.random.choice(np.arange(len(x)), 1000, replace=False)
Py_DECREF(index)
lst = sorted(iter(d.items()), key=itemgetter(1))
http = httplib2.Http()
tuple(getattr(self, slot) for slot in self.__slots__)
app = wx.App(False)
localtime = time.localtime()
myIntList = [x for x in myList if isinstance(x, int)]
print(string[6])
br.geturl()
temp.append(i)
name, age = noglobaltest()
self._waitready = set()
db1 = SQLAlchemy(app1)
w = w.translate(table)
print(folder.name)
views.py
deleted[1]
data[:, (0)]
new_word = word[:index] + char + word[index + 1:]
stdin, stdout, stderr = ssh.exec_command(prepare_command(command))
only_words = list(filter(str.isalpha, my_list))
self.name = name
print(json.dumps(d, indent=2))
print(self.treeWidget.currentItem().text(0))
fexdata = {}
hash1 = hashlib.md5()
print(z)
s = a.argsort()
E = np.array((xp, yp, zp))
a = Decimal(str(a))
rs = q.get_messages(10)
start = time.time()
ang = math.atan2(b[0] - a[0], b[1] - a[1])
downloadFiles(source, dest)
self.rect.left += self.dir.x * SPEED
result2 = pd.concat([d1, df1], axis=1)
self.ax = self._fig.add_subplot(111)
client.remove_flags(msg_ids, [SEEN])
NSScreen.mainScreen().frame().height
data = literal_eval(f.read())
self.count += 1
args = parser.parse_args()
result.append(dict(type=key, items=list(v[0] for v in valuesiter)))
data = np.zeros([N, 4114])
logging.disable(logging.CRITICAL)
conn = pycurl.Curl()
{{forms.render_field(field)}}
raise ndb.Return(buildings)
np.random.shuffle(col0)
global_objs = list(globals().items())
print(response.msg)
passw = [record[1] for record in records]
print(page.read())
Pdb
a = [4, 5, 0, 0, 6, 7, 0, 1, 0, 5]
aList.pop(0)
np.nonzero(b)
me = np.zeros(n.shape[0])
main()
p.join()
QtGui.QDirModel.setData(self, index, value, role)
print(x)
print(pandas_select(df, select_dict).to_string())
myShape.translate(Base.Vector(2, 0, 0))
stock = data.ix[idx]
(df == window_stop_row).all(axis=1)
lambda self, *args: getattr(self.num, name)(*args)
time_series.append(forecast_append)
q = manager.Queue()
t2 = threading.Thread(target=thread2, args=(2, t2_stop))
self.cursor.execute(sql, (reason, id))
logging.getLogger().addHandler(fh)
x.append(words[1])
self.ax.set_thetagrids(self.angles, labels=titles, fontsize=14)
set_lst = set_lst.difference(check_file)
grid = np.arange(100).reshape((10, 10))
argsdict = {}
base_string % values
std2 = 1.0
PersonQuerySet(self.model)
iter(list(itr)[1:])
a, b = list[0], list[1]
parser.print_help()
map(x.count, x)
appended_data.append(data)
A.T
p.append(2)
[atleast_2d(_m) for _m in tup]
input.close()
mx = np.matrix(x)
self.layout = QtWidgets.QVBoxLayout()
C2 = Cookie.SimpleCookie()
imp.find_module(module_name)
cursor = conn.cursor(cursors.SSCursor)
{{number}}
tmp.blit(mask, destpos, maskrect, special_flags=pygame.BLEND_RGBA_MULT)
widget.layout().addWidget(label)
n = int(math.sqrt(2 * x))
cc.run()
r = requests.get(url)
logging.FileHandler.__init__(self, filename, mode, encoding, delay)
env = jinja2.Environment()
print(result.get(timeout=1))
f.read(1)
modela = models.OneToOneField(ModelA)
params.append(filtervalue)
self.weight = weight
heatmap = plt.pcolor(data)
b = int(a)
consume(some_func(x) for x in some_list if x > 5)
r = pd.Series(list(range(len(df))))[::-1] + 1
value = line.split()[-1]
l[i] += 1
transactions.sort(key=operator.itemgetter(0))
a + 0
output = PdfFileWriter()
combined[key1].append(key2)
screen = pygame.display.set_mode([100, 100])
counts = np.zeros(shape=arr.shape)
tutorials = [frozenset(tutorial) for tutorial in tutorials]
setattr(obj, proxy.value_attr, value)
self.read_events()
self.inner_test = InnerTest()
plt.tight_layout()
df[keys] = df[j] - df[from_joint]
h2.setLevel(logging.WARNING)
seen.add(x)
cap = cv2.VideoCapture(0)
A, B, C = np.polyfit(x, np.log(y), 2)
arg_dict = {}
[(grouper, list(values)) for grouper, values in my_groupby_generator]
count[word] += 1
ax.w_zaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))
obj_a.my_method()
axis1.plot(list(range(10)))
blank_image[:, 0.5 * width:width] = 0, 255, 0
[1, 0, 1, 0]
self.__dict__[name]
print(foo.args)
N = col.shape[0]
FIN.seek(random.randrange(length), 0)
[2, 0, 1],
float(timedelta.days) + float(timedelta.seconds) / float(86400)
dir(parrot.Norwegian)
c1.say_my_name()
ctx.set_line_width(1.5)
signal = wave_file.read_frames(wave_file.nframes)
v = A[position:][:length]
self._build_calendar()
self._fileobj.tell() - self._offset
foundwords = []
PyErr_Print()
output.write(input.readline())
mplrun()
upper_white = np.array([180, 25, 255])
A[(_), :]
b = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
parseiter = iter(ElementTree.iterparse(rhythmbox_dbfile))
quarters = []
d_ini = dict((c, 0) for c in string.ascii_letters)
table[n - 1] if n else 1
a = 1
1, 1, 1, 8
p.join()
axes = plt.subplot(gs[0, 1])
edges = np.reshape(edges, (edges.shape[0] / 2, 2))
print(Dog.__bases__)
print(primeslt(int(i)))
keep_default = False
D = set()
min(compress(my_lookup, my_list), key=my_lookup.get)
n == 1
root = Tk()
clip = Gtk.Clipboard.get(Gdk.SELECTION_CLIPBOARD)
p.join()
lcls = inspect.stack()[2][0].f_locals
r = requests.get(url)
df = json_normalize(data)
ser.plot(ax=axes[0])
d1 = pd.concat([d1.loc[[1]].rename(index={(1): 0}), d1])
sys.stdout = stdout
result = list(product(all_files, all_files))
print(x == 247)
d = date.today()
items = sorted([(k.lstrip().lower(), v) for k, v in list(d.items())])
self._result = result
app = QApplication(sys.argv)
k1 = 0
node = lxml.html.fromstring(node)
y = np.outer(x, k) + b + np.random.normal(size=(50, 1000), scale=1e-10)
type(name, (Parent,) + bases, dict)
20000000000
list(range(0, len(list1)))
self.transport.write(self.factory.text)
lapack_routine(n, n, tmp, n, pivots[i], 0)
self.value = value
entry = menu.addAction(item)
print(type(p))
json.loads(data)
image = open(filename)
socket.inet_aton(address)
p.apply_async(f, (np.random.rand(1000, 1000), np.random.rand(1000)))
a = numpy.float64(42.0)
a = csv.writer(b)
print(mo.group(0))
IsoInA = 0
p.hello()
True
title = models.CharField(max_length=255)
new_row.append(row[column_index])
count(6)
y_tick = np.arange(-0.5, 0.5 + unit, unit)
getattr(self.get_query_set(), name, *args)
alice.toys = toys
soup = BeautifulSoup(page)
my_model = MyModel.objects.all()
data = os.read(fd, 1024)
x, y = new_x, new_y
name = models.CharField(max_length=255)
DBListings()
hash((self.x, self.y))
process.stdout.readline()
self.DataPlot.draw()
p.close()
dict[firstName] += 1
max_pub_date_time = datetime.combine(pub_date, time.max)
assert sum_nested([[([8, 9], 10), 11], 12]) == 50
y = canvas.canvasy(event.y)
reader = csv.reader(infile)
socket.gethostbyname(i.strip())
actions.perform()
lines = lines + 1
new_date = old_date + relativedelta(years=1)
P.figure()
list(all_but_n_last(data, 1))
driver = webdriver.PhantomJS(service_args=args)
A = scipy.io.mmread(sys.argv[1])
b = pickle.load(handle)
select.order_by(func.random())
sys.exit(app.exec_())
callUponTimeout(*args, **kw)
Py_Initialize()
s = s[n:]
b = min([n for n in list2 if n > i])
print(folder.name)
print(soup)
max = len(lst)
flat_y = tf.reshape(y, [-1])
assert isinstance(n, int)
converters = [str.strip] + [float] * (len(headers) - 1)
soup = BeautifulSoup(r.text)
dollars += 1
root = tk.Tk()
key = row[0]
self.stream.write(msg.encode(self.stream.encoding))
child.sendline(mypassword)
top.mainloop()
logger.addHandler(someutils.null_handler)
time_list = np.array(time_list)
render_to_csv_response(qs)
fig, ax = plt.subplots()
self.__setattr__(key, value)
a[:], b[:] = zip(*combined)
next(f)
x = np.array([1, 1, 1, 2, 2, 2, 5, 25, 1, 1])
frec(word[len(s):], values + [s])
print(fileinput.filename(), fileinput.lineno(), line)
fW.flush()
session.add(user2)
curs = conn.cursor()
__slots__ = ()
df
output.append(number)
gona[(1), :]
pool.apply_async(test, (k, multi_d))
logging.basicConfig(level=logging.INFO)
tracks = [i[0] for i in list(radio.items())]
standard_scalerX.fit(X_test)
leng(s[1:], count + 1)
b = [5, 6, 7, 8, 9]
str(r)
log.addHandler(journal.JournaldLogHandler())
user_id
ax1 = plt.subplot(gs[(0), 0:2])
a.get(0)
figure = np.random.uniform(size=(4, 4))
5 - 0.464188
addvec2(mat, vec)
self.append(text)
b = a + b
self.d = {}
df = df[::-1]
new_array = array[mask]
encoded_pw = base64.b64encode(raw_pw)
a = np.array([[1, 0, 1], [0, 0, 1]])
f.__setitem__((slice(5, 10), 100), 2)
print(poly.intersection(merged_cells).area)
tf.get_default_graph().finalize()
result = defaultdict(int)
help(enumerate)
key_list = sorted(value.keys())
0
child.expect(pexpect.EOF)
n = len(archive.getnames())
diff(nges, n[5])
self._fill(index)
list(range(start_val, start_val + 10))
cursor = connection.cursor()
MyPickler(output).dump(thingee)
dic = dic.setdefault(key, {})
ret, mask = cv2.threshold(result_grey, 10, 255, cv2.THRESH_BINARY)
self.properties.update(attr)
xmlFile.childNodes[0].appendChild(newScript)
shutil.copy(os.path.join(source, fname), os.path.join(dest, fname))
self.transport.loseConnection()
result = []
A = np.arange(24)
key, val = list(e.items())[0]
zip_path = os.path.join(zip_subdir, fname)
include_dirs = []
sel = Selector(response)
self.name = name
it = zip(*([iter(L)] * 2))
ui.write(e.EV_KEY, e.KEY_LEFTSHIFT, 1)
c = c.ravel()
content = f.read()
print(new_items)
ans = (x - y) ** 2
df = df.loc[mask]
PrintLn(Abs(vi))
script.extract()
print(str(msg))
newargs = list(funcsig.parameters.values())
g.get_all_shortest_paths(0, 15)
w = gtk.Window()
self.type
ax.set_ylim((-1, 1))
time.sleep(1)
print(arg)
d1.keys() & d2.keys()
result.append(dict(zip(recordset.column_names, row)))
msvc9compiler.VERSION = 11
item_dict = json.loads(json_data)
email = Column(String, primary_key=True)
x()
list1, list2 = list2, list1
print(k, v, highest_values, len(highest_values))
dirname, filename = os.path.split(name)
inner
driver.switch_to_default_content()
big = np.arange(Nbig * Nbig).reshape([Nbig, Nbig])
logger.addHandler(file_handler)
True
x, y
test2.test()
df.reindex(t.index)
[int(round(i)) for i in net.activateOnDataset(ts)[0]]
print(line)
datetime = Column(DateTime, primary_key=True)
plt.legend()
dicta = dict(zip(listanum, lista))
q = multiprocessing.JoinableQueue()
driver = webdriver.PhantomJS(*args, **kwargs)
d = sqrt((y2 - y1) * (y2 - y1) + (x2 - x1) * (x2 - x1))
soup = BeautifulSoup(html)
connection = engine.connect()
a, b = itertools.tee(iterable)
swap_cols(my_array, 0, 1)
type(f())
ang1 = angle(sx1[iseg1], sy1[iseg1])
yb = yum.YumBase()
screen.blit(px, px.get_rect())
0
mercury_thread.start()
np.round(dfnum)
y = poly(x) + np.random.rand(n) - 0.5
print(add_odd_numbers(10))
c.start()
next(mygen)
value = Column(String)
f.close()
ax.w_xaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))
response
seq[0] + listSum(seq[1:])
TRY
copy
funcs.append(makeFunc(x))
lons = np.array([102.5, 5.5, 116.2, 102.5, 5.5, 116.2, 102.5, 5.5, 116.2, 100])
V.reshape(V.shape[:len(D.shape)] + (-1,))
stack.append(n)
Py_Initialize()
it = iter(seq)
df
self.filename = filename
nameserver
doctest.testmod()
opts = {}
mybucket / files / pdf / abc4.pdf
array = [array[i:i + s] for i in range(0, len(array), s)]
data = [2, 2]
self.func = func
audio / mpeg
reader = csv.reader(input_file)
pickle.dump(dictname, f)
random.shuffle(x)
labels.reshape(data.shape)
a = [[], [], []]
ax = plt.subplot(gs[(2), :])
lam_f = sympy.lambdify(x, f(x))
print(dir(data))
print(npstr)
-1
decorator
temp_csv.flush()
print(newcorpus.raw().strip())
assert all(len(set(roster)) == len(roster) == 8 for roster in all_rosters)
values = [r[1] for r in result]
rows = array.shape[0]
glo = [[x for x, y in g] for k, g in groupby(lki, key=itemgetter(1))]
a - b * 4
[np.sum(x ** 2 + a), 2 * x]
results.append(res)
soup = BeautifulSoup(file_h.read())
self.ses.get(URL).text
Shell_NotifyIcon(NIM_ADD, nid)
x += b
df = df.stack().reset_index()
t = np.linspace(0, u.max(), 20)
-__init_.py
chars.append(escaped_str[i])
web.setDisabled(True)
callwith5(setanitem)
sizer.Add(self.comboBox1, 0, wx.ALL | wx.CENTER, 5)
root = tk.Tk()
s
values = Value.objects.filter(record=record).select_related()
x = somequeryset.query
params[:n + 1]
s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
self.opt.kill()
date_after_month = datetime.today() + relativedelta(months=1)
inv_mapping = {i: u for i, u in enumerate(labels)}
print ()
pool.close()
d[k] += v
t[2]
self.variables = tf.get_collection(tf.GraphKeys.VARIABLES, self.scope_name)
ax1.scatter(list(range(10)), list(range(10)), c=list(range(10)), alpha=0.2)
application = bottle.default_app()
fig = plt.figure()
new_stdout1.seek(0)
math.sqrt(0.241 * r ** 2 + 0.691 * g ** 2 + 0.068 * b ** 2)
result[mask] = 0
print(set(list2) - set(list1))
camcapture = cv.CaptureFromCAM(0)
zip(a, b)
stderr = ferr.getvalue()
pb = pb.get_from_drawable(w, w.get_colormap(), 0, 0, 0, 0, sz[0], sz[1])
perform_some_action()
common.get_users()
s.close()
print(i)
signal.signal(signal.SIGINT, term)
print(line)
split_string
np.arange(n) >= m
idx = np.random.permutation(4)
self.list_two.setGeometry(0, 0, 500, 100)
ax = fig.add_subplot(111)
soup = BeautifulSoup(file)
df = dfA[dfA.index.labels != -1]
data = [map(int, row) for row in csv.reader(f)]
arg.upper()
s = s[k:]
df1 = pd.read_csv(StringIO(df1_text), delim_whitespace=True)
print(next(product(count(1), count(1))))
self.z = z
example1(x, a, b, D)
root_element = xml.get_root()
plate_chars += str(chr(results[0][0]))
sys.stdout = StringIO.StringIO()
df
wx.Panel.__init__(self, parent, size=wx.Size(806, 450))
position.append(0)
f(name)
hist, bin_edges = np.histogram(np.random.randint(0, 10, 100), normed=True)
self.get_card(card_id).invert()
ranges = ((n, n + step) for n in range(start, stop, step))
Label(root, textvariable=timeVar, width=8).pack()
next(self)
timeit[Model.objects.filter(date_created__contains=today)]
y_uspline = uspline(x)
start = sum(range(n)) + 1
lists = f.readlines()
new_list = sorted(playlist, key=lambda L: next(by_artist[L.artist]))
interp([9, 10], x, y)
client.send(msg)
t1, t2 = tee(iterable)
root = Tk()
A = A.reshape(4, 6)
parser = argparse.ArgumentParser()
os.system(c)
plt.grid(True)
my_instance.c()
self.is_active = True
sum(1 if c1 != c2 else 0 for c1, c2 in zip_longest(w1, w2))
match = pattern.match(line)
new_contact = form.save(commit=False)
[self.list[i] for i in range(key.start, key.stop, key.step)]
G.add_node((0, 0))
g = lambda a, b=b: f(a, b)
e1.pack()
hformats = []
contents = f.read()
self.rowconfigure(0, weight=1)
f, ax = plt.subplots(1)
text = p.stdout.read()
ADDRESS2 = ctypes.create_string_buffer(64)
list(theDict.keys() & theList)
pandas.core.frame.DataFrame
self._parent.AppendUpdate(self.myproc.stdout.readline())
c[k] += a[j] * b[k + j * K]
readme.close()
new.append(a[i])
w[[a, a + 1]] + np.array([0, -2])
geoms = []
main()
arr
start = time.time()
hash(self.name)
f.seek(start)
len(md5bytes)
dict_out
new_grammar._productions.append(nltk.grammar.Production(lhs2, [lhs]))
ax.set_zlim(-1, 1)
cursor = conn.cursor()
reader = csv.reader(f)
print(res.read())
output[words[0]] = words[-1]
s.sort()
r_mid = 0.5 * (r_edges[:-1] + r_edges[1:])
testmethod = lambda self: self.assertEqual(fn(i), output[i])
root = lxml.html.fromstring(response.body)
tmp[(2), :, :] = np.ones((sy, sz))
f2.write(line)
print(result)
shuffle.append(newEl)
self.execute(sql)
cursor = conn.cursor()
self.x1, self.y1 = int(event.x), int(event.y)
names.append(i)
print(cf.read(99))
min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)
xmin = logdata.min()
fd = self.process.stdout.fileno()
self.setCentralWidget(self.text)
print((date_cand, (datetime.date.today() - date_cand).days))
print(r.raw._original_response.peer)
print(x)
log_observer.start()
d = dict(l)
b = [str(f) for f in range(n)]
list1.remove(item)
self.cond.wait()
self.buf.seek(0, os.SEEK_END)
self.panel.top()
Grid.append([])
print(my_array + [e])
group = models.ForeignKey(Group)
calendar.monthrange(2012, 1)
m = pattern.search(line)
n = 10
np.exp(np.dot(mX, vBeta)) / (1.0 + np.exp(np.dot(mX, vBeta)))
0
newList = map(lambda x: x / myInt, myList)
main.destroy()
to = len(list)
self.markdown.htmlStash.store(self.unescape(element))
clf.predict(iris.data[125])
+apache2
diag_indices = A.indices[idx_begin:idx_end]
main()
z = zipfile.ZipFile(io.BytesIO(r.content))
self.released.connect(self.update)
self.f.setsampwidth(sampwidth)
d[k].append(v)
datetime = dt.datetime.combine(date, time)
self.avail_ranges.remove(ip_network)
bSizer.Add(button1, 0, wx.ALL, 5)
print(c.html.strip())
_triple_file.close()
str(d)
pip - -version
new_lst = []
add(1, [])
mask = np.all(np.isnan(a) | np.equal(a, 0), axis=1)
print(dict(filter_dict_path(old_dict, sub)))
my_dict[x] = 4
IS_SETUP = True
print(repr(tokzr_QA_non_canonical(inp1)))
print(input[a])
self.assertListEqual(self.result, self.expected)
data = f.read().strip()
lst = numpy.array([random.uniform(0, 5) for _ in range(1000)])
method = getattr(foo_obj, command)
print(args.doh)
newlist = []
columns.append([7, 7, 7])
plt.subplots_adjust(left=0.2)
axone = plt.axes([0.1, 0.05, 0.1, 0.075])
distribution = scipy.stats.norm(loc=100, scale=5)
vals[mask].reshape(-1, out_shape[1])[:out_shape[0]]
any(map(bool, list(d.values())))
left_thresh[:, i:] += img[:, :w - i]
print(hex2.neighbors())
dirname, basename = os.path.split(filename)
arr_2 = np.array(multidim_list2)
transaction.rollback()
print(window.get_name())
48.1145061659
time += 1
self._async_interrupt.wait_for_receive()
a = A()
x[2:10]
df = s.reset_index()
print(self.companies[index])
0
result1.append(x)
file = sys.argv[1]
help(Test)
self.data.extend(list(other))
c = a * b.reshape((b.size, 1))
children.append(node.values[i])
tokens = nltk.word_tokenize(text)
line = line.strip()
assert_array_compare(operator.__eq__, x, y, err_msg=err_msg)
sdl2.SDL_SetRenderDrawColor(renderer, 255, 255, 255, sdl2.SDL_ALPHA_OPAQUE)
list.__getitem__(self, index)
number = models.CharField(max_length=50)
xpos, ypos = np.meshgrid(xedges[:-1] + 0.25, yedges[:-1] + 0.25)
Servername = MYSERVER
axtwo = plt.axes([0.21, 0.05, 0.1, 0.075])
print(any(list_item in fruit_dict1 for list_item in fruits))
root = tix.Tk()
self.edit = QtGui.QLineEdit(self)
lines.append(linecache.getline(filename, curline).rstrip())
salt = bcrypt.gensalt()
opener = urllib.request.build_opener(cookies)
a = np.random.normal(0, 1, N)
print(element)
hrago = now - timedelta(hours=1)
lensub1, lensub2 = len(subset1), len(subset2)
pos = entry.get_position()
self.children = []
a, b = [iter(x)] * 2
print(o.foo())
outlen = in1.shape[-1] + in2.shape[-1] - 1
br = mechanize.Browser()
print(x)
formatter = logging.Formatter(LOG_FORMAT)
b.sort()
print(files)
os.close(rpipe)
columnNames = [d[0] for d in cursor.description]
s.set_debuglevel(1)
blob_reader = blobstore.BlobReader(blob_key)
print(gitpath.root())
np.isnan(x)
flatten = [item for sublist in temp for item in sublist]
code_to_profile()
work.append(nope)
request = Request(url, headers=headers)
print(d[int])
main()
curses.noecho()
smprint()
test_dict = {}
retDirs.append(os.path.join(root, i))
setattr(namespace, self.dest, value)
f = Foo()
self.data = data
print(etree.tostring(tree.getroot()))
min([(x, distance(word, x)) for x in lst], key=itemgetter(1))
first.request.SetInParent()
entry = tk.Entry(self)
sleep(0.001)
self.name
self._fileobj.seek(offset)
nx.draw(G, with_labels=False)
proc = mp.Process(target=worker, args=[q, arr])
hax.set_position([0.1, 0.1, 0.8, 0.8])
obj = Try()
d[k].append(v)
L = fo.readlines()
os.rename(tmp, myfilepath)
twitter = Twython(APP_KEY, APP_SECRET, oauth_token, oauth_token_secret)
[0, 2, 0, 1, 0, 1, 0, 1, 1, 1, 2, 0]
sys.exit(app.exec_())
print(Type[x][x], len(Type[x][x]))
GameApp().run()
driver.get_screenshot_as_file(screenshot_file_path)
driver.switch_to_frame(iframe)
dt = datetime.datetime.now()
a[:, (0)] == 1
r[v].append(k)
reader = csv.reader(file)
t.start()
tokens = text.split()
calendar.timegm(utc_timetuple)
segment_two = csv.reader(file_two)
cax = ax.matshow(cm, cmap=cmap)
[[[0, 1]]]
sum(c.isalpha() for c in s)
app = Flask(__name__)
stacked_conv_neibs = T.stack(*multiple_conv_out).T
arg_list
x += 1
im_temp = im_temp.resize((250, 250), Image.ANTIALIAS)
assert np.allclose(point, round_trip)
b1.grid(row=0, column=0, pady=10, padx=10, sticky=Tkinter.SE)
sorted_tuples = sorted(initial_ranges)
d = dict(foo=1, bar=2)
input_list = set([0, 1])
dct = json.loads(json_string, object_hook=datetime_parser)
thisRDD.count()
root = etree.fromstring(broken_xml, parser=parser)
result = list(islice(it, n))
list(dates)
df1
df2 = pd.DataFrame(data2)
list(unique_everseen(items))
fig, ax = plt.subplots(figsize=(20, 10))
deepReduce(f, f(y, xs[0]), xs[1:])
splittime / parsetime
app = Flask(__name__)
exec(self.raw)
s
lattice = list(range(0, len(inputs)))
palette.append((0, 0, 255 - i))
filters.append(Q(tree_id=n.tree_id, lft__gt=lft, rght__lt=rght))
friendList.append(self)
[l[0] - 1] + recurseDecrMap(l[1:]) if l else []
Queue.__init__(self, maxsize)
tsp = [(el[0], el[-1]) for el in ts]
edgey2 = region2 ^ np.roll(nregion2, shift=shift, axis=1)
some_heavy_calculations()
i = a.index(p[0])
print(cv2.isOpened())
catalog = dict((name, idx) for idx, name in names.items())
timeit.timeit(lambda : bytearray(os.urandom(1000000)), number=10)
form = forms.ChapterForm(request.POST)
json_str = json.dumps(data)
env = _Env()
crsr.fetchall()
id(a[1])
a = Example()
samples2 = [samples2[i:i + 2] for i in range(0, len(samples2), 2)]
app.config_from_object(Config)
map = base_map.set_a_map()
cont = ax.contour(X, Y, Z)
unittest.TestSuite([DataTestCase(n) for n in numbers])
result = []
merged
CONTINUOUS_INTEGRATION = true
d = datetime.datetime(2011, 8, 29)
os.makedirs(dirmk)
Fy = np.random.rand(100, 10, 40)
execlist[index][2] = myx
tz = pytz.timezone(zonename)
list(range(10, 20))
manager = urllib.request.HTTPPasswordMgrWithDefaultRealm()
S.remove(10)
newlist
expire_events.py
response.replace(body=new_body, encoding=self.encoding)
proc.start()
self.list[index], self.list[-1] = self.list[-1], self.list[index]
redis - cli
echo.py
plot(x, z)
a[I, J]
tuple.__new__(cls, initialValue)
mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, se2)
setup_func(a_cxx_foo)
seq.insert(i, item)
zipname = sys.argv[1]
diff2 = np.sqrt(diff2)
nowtuple = nowdt.timetuple()
value_counts = df.stack().value_counts()
sleep(time)
--enable - pythoninterp
print(c)
results.append(tuple([row[i] for i in headers]))
plt.plot(data1)
ax.add_collection(coll)
fs.visititems(callback)
trends1 = api.trends_place(1)
self._pred_map[self]
client_tcp[1].send_data_to_tcp(self.data)
L1 = [i for i in L if i in L1]
arr_1 = np.arange(10)
logger.addHandler(handler)
clf.fit(X_, vector)
f = f.reshape(())
test = math.inf
diff = ImageChops.difference(im2, im1)
utc_time = datetime1 - datetime1.utcoffset()
g()
M = M[M.getnnz(1) > 0, M.getnnz(0) > 0]
y = lambda u: u ** -2 + 8
func.__get__(instance, cls)(*args, **kwargs)
crawler.crawl(spider)
options = ChromeOptions()
print(len(list(filter(is_div_three, r))))
rotated_image = cv2.warpAffine(image, rot_mat, shape, flags=cv2.INTER_LINEAR)
print(etree.tostring(tree))
widget1.update_idletasks()
count
hello()
self.timer = QtCore.QTimer()
request.session.cycle_key()
self.title, self.artist, self.album, self.source, self.dest
x = np.linspace(data.min(), data.max(), 100)
np.repeat(arr, rep.flat)
self.type = type
connection.endheaders(request_body)
q = Queue()
print(r(-1, 1))
referrer.append(x)
round(base * round(float(x) / base), prec)
x_mean = np.mean(x, axis=1, keepdims=True)
Py_DECREF(pystdout)
y2.append(random.randint(1, 100))
sympy.randprime(0, 100)
kde = stats.gaussian_kde(data)
Base = declarative_base()
np.hstack((np.zeros(shape), data))
print(g[first_row:last_row + 1, first_col:last_col + 1])
print(user_postition)
ftp.login()
data = json.load(f)
now = datetime.datetime.now()
hamming_distance(a, b)
copy = df.copy()
auth.save_session()
main.show()
hash(self.name)
frame.Bind(wx.EVT_WINDOW_DESTROY, self._unregister)
english_dict[word]
y += np.random.randn(6) / 10
deps.append(str(name))
np.bitwise_and.reduce(a) == a[0]
r.terminate()
stoppool = threading.Thread(target=close_pool)
dsolve(eq)
a.insert(0, i)
sys.stderr = sys.__stderr__
confusion_matrix(y_true, y_pred)
list(f(doc))
print(num)
idx = np.argsort(a)
newMethod.__get__(a, A)
table.show()
result.append(x)
subs = [set(j) for i in range(len(s)) for j in combinations(s, i + 1)]
name, score = line.split()
srf.blit(f.render(unistr, True, (255, 255, 255)), (0, 0))
recall
len(bin(100)) - 2
print(inspect.signature(f).parameters)
sys.stdin = s
fun(indata, indata.size, outdata)
mod.HelloWorld()
meta = MetaData(bind=migrate_engine)
logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)
pl.plot(x, us(x))
(2, 1)(2, 1)
propfaid.set_cache(*settings)
A[:(A < np.percentile(a, 90)).argmin()].sum()
mins.append(i)
bool(self.value)
self.__add__(-i)
triplets = list(permutations(lst, n))
x = True
s.indices(10)
data_ratio = plt.gca().get_data_ratio()
dothat(item)
print(list(my_range(4, 20, 2)))
d.bar
fig, axes = plt.subplots(nrows=2, ncols=1, sharex=True)
self.do_something(name, value)
object._state.db
time.sleep(self.interval)
self.output_queue = mp.Queue()
parent = Parent()
cat / etc / nginx / sites - enabled / myapp.conf
bool_arr = np.array([True, True, False])
index = random.choice(list(range(len(MY_LIST))))
p[0] + p[1] * x ** p[2]
mailList = [i.strip() for i in urlFile.readlines()]
type(-maxint - 2)
draw.line((i, 0, i, 100), fill=random.randrange(256))
self.crawler.stop()
out = x.truncate(before=datetime.datetime(2015, 12, 2, 12, 2, 18))
print((val, k))
b = a[(0), (1), ::2]
valid_file = False
sys.exit(1)
a.add(1)
txt = self.proc.stdout.readline()
tag = node.tagName
spider
lines = []
show()
result = []
match.group(1)
persist_file.Save(shortcut_path, 0)
myfield = QuerySelectField(query_factory=fill_field)
r.append(blocktag[1])
np.poly1d(p)(x)
render_user(request)
browser = spynner.Browser()
ax.matshow(m[(0), :, :, (j)], cmap=cm.gray)
sequence[0:len(sequence):2] == sequence[:len(sequence):2] == sequence[::2]
self.close()
print(self.value, self.foobar)
xmldoc = minidom.parse(usock)
list_magicInput.append(letter)
array([5, 7])
s.rollback()
QtGui.QMainWindow.__init__(self)
print(tokenize.untokenize(output))
x = new_array()
vmin = min(map(lambda x: min(abs(x)), data))
b = numpy.array([0] * n + [1] * 2)
reactor.callLater(1.0, heartbeat)
created = models.DateTimeField(auto_now_add=True)
fig, ax = plt.subplots()
next(gen)
output = requests.get(url).text
os.dup2(oldstderr, sys.stderr.fileno())
ax1 = fig.add_subplot(gs[0, 0])
result = {k: [expand_string(s, all_strings) for s in v] for k, v in list(my_dict.items())}
superstsets.add(stset)
non_numeric_chars = string.printable[10:]
worksheet = workbook.add_worksheet()
setattr(self.obj, self.method, self.called)
unique.append(obj)
auth_handler = urllib.request.HTTPBasicAuthHandler()
print(x)
data = parser.parse_args(contents.split())
model_subklass(**kwargs)
parser.parse_args(args.split())
ys.append(y)
f(1)
date.day
app.jinja_env.globals.update(can_access=can_access)
raise PartialImport(locals())
MIGRATION_MODULES = DisableMigrations()
np.log10(df.timeLength)
sow = today - datetime.timedelta(days=now.weekday())
fp[:, (i)] = fp[:, (i + 1)]
curs.execute(sql)
n = 0
signal.pause()
profile = webdriver.FirefoxProfile()
self.base.foo = f
df.dtypes
a = models.CharField(max_length=5)
x = numpy.random.randint(0, 1000, 1000000)
do_stuff(level_lookup[key])
x_indices = indices[0]
df.loc[mask == 1, 0] = 200
codepoint = ord(c)
worksheet.setRowCount(worksheet.getRowCount() + 1)
quicksort(array, start, i - 1)
1 if S == 0 else 0
print(list(inverse_regex.ipermute(data)))
triple = line.split()
foo(args)
s = self.fileobj.read(1)
x if x % 100 == 0 else x + 100 - x % 100
result = []
setofcols.add(tuple(column.A1.tolist()))
todayDate += datetime.timedelta(7)
req.has_data()
print(df1)
logger = logging.getLogger(__file__)
scene.objects.link(lamp_object)
color_cycle = ax._get_lines.color_cycle
test = coo_matrix((val, (row, col)), shape=(nele, nbus), dtype=complex)
dict.__delitem__(self, self[key])
Z1 = mlab.bivariate_normal(X, Y, 1.0, 1.0, 0.0, 0.0)
bar.__doc__
print(line)
importer.find_module(RUN_MODULE).load_module(RUN_MODULE)
np.bincount(ids, weights=data)
self.parsedData.append(dataRow)
date_created = models.DateTimeField(auto_now_add=True)
plt.imshow(H)
output = proc.stdout.readline()
B, C = split_list(A)
print(browser.html)
cur = con.cursor()
batch = service.new_batch_http_request()
my_counter = Counter(my_list)
a = numpy.random.random(size=100) * 100
results = pool.map(process_line, source_file, 4)
df_no
sizer.AddSpacer(10)
image_field.seek(0)
r = r[0].isoformat() + tz
serializer_class = UserSerializer
result = tocontainer(result)
plt.plot(x, -y)
c = array([1, 1, 1])
b2 = tf.Variable(tf.zeros([10]))
tri = np.zeros((67, 67))
application.listen(8888)
True
X4, Y4 = np.meshgrid(x4, y4)
Astarrs = list(ApStars)
sheet.write(cell, value)
0.16515994072
body = part.get_payload(decode=True)
mainwin.set_default_size(200, 200)
wb = Workbook()
print(T(lambda : fj(controls)).repeat(number=REPS))
[]
self._cards[card_ID].invert()
numbers = [d.setdefault(i, next(c)) for i in names]
coc = CopyOfC()
x = ax.get_xlim()
self.assertEqual(42, s2)
Area2(a, b, c) < 0
f
publish_date = db.Column(db.DateTime, default=tomorrow)
self.byName[person.name].append(person)
xi = np.linspace(X.min(), X.max(), 1000)
data = urllib.parse.urlencode(params)
{4}
np.fill_diagonal(product, 0)
self.Bind(wx.EVT_CLOSE, self.OnCloseWindow)
response.close()
eroded = binary_erosion(data, structure, border_value=1).astype(int)
fig.canvas.print_png(ram)
name = db.Column(db.String())
cr.set_source_rgba(0.5, 1.0, 0.0, 1)
fig = plt.figure()
gtk.main()
main()
sm = plt.cm.ScalarMappable(cmap=my_cmap, norm=plt.normalize(vmin=0, vmax=1))
host
exit(0)
print_sorted(filename, sort_col)
y.append(ind_2)
library(SnowballC)
print(p.ne(p.shift()).cumsum())
df
left_key, right_key, max_groups = self._get_group_keys()
input = [server, sys.stdin]
sys.stdout = StringIO()
config = configparser.ConfigParser()
signal = np.sin(50 * 2 * np.pi * x)
ax1 = fig.add_subplot(111)
b = np.array(b)
p_values = scipy.stats.norm.sf(abs(z_scores))
f(1)
Frame.__init__(self, master)
pylab.rcParams.update(params)
list(it)
new.append(recursivereverese(k))
print(x)
c = orcl.cursor()
X -= np.mean(X, axis=0)
contained(a, b)
id = row[0]
x + self.y
stdout.write(x)
self.img_id = self.canvas.create_image(x, y, image=self.img)
sess.run(training_net, feed_dict={inputs: batch[0], labels: batch[1]})
row0_sum = mat[0] * (len(ixs) - np.count_nonzero(nzmask))
Py_XDECREF(self.members[i])
x.append(y)
print(row)
tbl[-1].append(str(td.text_content()))
plt.figure(2)
l.set_option(ldap.OPT_DEBUG_LEVEL, 255)
s.dt.days
f = f_wrapper(_f_call, _f_ptr)
command = os.path.realpath(command)
closex = close.copy()
count = 0
response = urllib.request.urlopen(req)
response = requests.get(url)
my_instance.save()
data[header].append(value)
grouped.size()
pprint.pprint(result)
print(ulst)
L.reverse()
Base * get_other_base()
print(out_str)
data = ser.read(4)
sys.exit()
yappi.start()
today = date.today()
count = len(values)
DD = datetime.timedelta(days=-90)
print(saber)
min(Mylist)
ceo.greets(emp)
data = pandas.DataFrame(np.transpose(df_std))
data = string[0]
t, y, x = numpy.indices(J.shape)
print(get_size())
sentence_dict[word] = []
result = f(*args, **kargs)
m_ind, n_ind = w.T
zvals = np.random.rand(100, 100) * 10 - 5
db.run_in_transaction(txn, cat_alias.keyname_for_category())
s.listen(5)
plot = ax.plot_surface(X, Y, soln, **plot_args)
msgBox = QtGui.QMessageBox()
list(chain(*[([x] * i) for i, x in zip(A, B)]))
operator.itemgetter(*b)(a)
print(1)
fill_color = line.get_color()
arr = array(arr, copy=False, subok=True, ndmin=2).T
ser = serial.Serial(port, 9600)
w.show_all()
result = []
os.unlink(f.abspath)
dis.dis(f)
wide
pool.map(worker, [(i, array) for i in range(n)])
keys = [wx.WXK_LEFT, wx.WXK_RIGHT, wx.WXK_UP, wx.WXK_DOWN]
pymongo.version
np.array(*args, **kwargs).view(myarray)
cr = csv.reader(f)
wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)
tokenizer.tokenize(text.strip())
A = A.astype(int)
im1.set_clim([smin.val, smax.val])
setting1 = config1
self.name = name
x = np.linspace(0, 2, N)
lightened25 = [lerp(c, w, 0.25) for c, w in zip(my_color, white)]
p.terminate()
csvreader = csv.DictReader(inf)
arr = np.empty(len(lst), dtype=object)
print(a.shape)
it = iter(iterable)
cw.writerows(csvList)
deactivate
ans.append(s[0])
self.readonly_fields
p = x.pop()
assert len(c) == 1
module_code = __import__(name)
pat.match(s)
sh.write(n, 1, col2_name)
self._thread_id = tid
results.append(out.toString())
keys = list(myDict.keys())
idx1 = np.arange(len(desc1))
pickle.dumps(cycle)
line2 = f.readline()
print(df1.fillna(df2))
x.shape
axis[:set_xlim](0, 10)
p = psutil.Process(1694)
msg = next(myproducer)
b.append(i)
vec = numpy.zeros(num_rows)
main.py
r = np.arange(X.shape[0])
cluster = dict()
id(a[2]), id(b[-2])
myDict = {}
print(id(string[0:5]))
False
[freetds]
terminator.cancel()
line.set_ydata(sin(x + i / 10.0))
f.write(decodestring(imagestr))
print([num, diff])
data = f.read()
kernel.execute(command)
len(df[np.isclose(df.R, 0.9)])
inner_qs = table2.objects.all()
r
data = np.ascontiguousarray(data)
_to_etree(v, ET.SubElement(root, k))
print(b[0].dtype)
ax = fig.add_subplot(111)
name = models.CharField(max_length=100)
_array[::][1:]
ax.invert_yaxis()
tb.show()
queue.append(item)
img = Image.fromarray(maxi)
print(update_doc(b))
this_prize
(v for m in self.maps for v in m.values())
globals()[key] = value
remote_client = SSHClient()
self.test(*self.arg)
print(r)
backdrop = pygame.Rect(0, 0, SCREEN_X, SCREEN_Y)
self.co = self.sink()
assertTrue(True)
p = multiprocessing.Pool(2)
nz = np.nonzero(cells)[0]
str.__new__(str, arg=1)
app.register_blueprint(child2.child2)
n = float(n)
print(handle_csrf.__doc__)
f.close()
(y, m) if m else (y - 1, 12)
self._1d_array = np.arange(10)
left, bottom, width, height = [0.25, 0.6, 0.2, 0.2]
self.output += data.strip()
col = array([0, 2, 2, 0, 1, 2])
out = {}
df.index = list(range(len(df)))
m.update(string)
inverse_dict = defaultdict(list)
B.add_nodes_from(cells_list, bipartite=1)
int(s)
print(self.a)
X = StandardScaler().fit_transform(X)
PyLong_AsByteArray(lnum, a, len(a), 0, 1)
mask = np.in1d(pairs1D, positions1D).reshape(-1, 2)
args_dict = vars(args)
new_list = list(filter(keep_this_element, l))
g = (i for i in range(100))
min(results, key=test_string.index)
execute_from_command_line(sys.argv)
y = y[mask]
d = {}
stackless.tasklet(a)()
ax.broken_barh([(midpoint - 0.01, 0.02)], (perc[0], perc[1] - perc[0]))
sys.excepthook = handle_exception
all_records = NCBIXML.parse(handle)
ret = os.popen(cmd + file).readline().strip()
df
x = random.choice([left, right] * adjpx + [withinx])
print(df)
now = datetime.utcnow()
di[pos][1].append(listb[i])
colors = [(color * (0.5 + norm(v) * 0.5)) for v in shade]
self.bar(**args)
pos_frame = cap.get(cv2.cv.CV_CAP_PROP_POS_FRAMES)
L = list(range(0, 101, 10))
n
x_err = np.array([random.random() for i in x])
out[2]
form_user = UserForm(request.POST, instance=request.user)
link = self.br.find_element_by_link_text(month)
p = QPixmap.grabWindow(widget.winId())
b = a[:-4]
ax4 = plt.subplot(gs[-1, 0])
collection[obj.category_id].append(obj)
dis.dis(test4)
[length] = set(map(len, list_of_lists))
b = a + 1
b = np.linspace(0, 1, 16, endpoint=False).reshape(4, 4)
app.installEventFilter(win)
r, g, b = im.getpixel((i, j))
conn = engine.connect()
data.append(integers)
path = os.path.realpath(path)
flatten(something, a)
file_handler = logging.FileHandler(filename)
unique_name = models.CharField(max_length=255)
roundedB = b.replace(hour=0, minute=0, second=0, microsecond=0)
raise StopIteration
ard.write(setTemp1)
temp_dir = tempfile.gettempdir()
formData.append(name, val)
self.seek(-blocksize, 1)
width = label.fontMetrics().boundingRect(label.text()).width()
somemodule.someclass = debug_signals(somemodule.someclass)
[gb.get_group(x) for x in gb.groups]
out = [float(f_interp(*p)) for p in points]
p.map_async(func, iterable).get(timeout=10000000)
a.update(b)
es = Elasticsearch()
[(string + repr(i)) for i in range(11)]
driver.get(url)
Pxx_dB = np.log10(Pxx)
self.text = tk.Text(self, width=40, height=20, yscrollcommand=self.vsb.set)
ax = plt.subplot(111, polar=True)
print(str(x))
i = patch_instance(x.get_instance())
f(*arg)
seq[int(self.random() * len(seq))]
result = np.array([[f(i, j) for j in b] for i in a])
myTurtle = turtle.Turtle()
type, value, tb = sys.exc_info()
swap(xs, a, b)
self.foo = foo
self._global_wealth = 10.0
test_data = tf.Variable(1000)
main()
x.append(ind_1)
canvas.Canvas.save(self)
ret[ret > 0].sum()
times[-1]
b = object()
f.truncate()
sum(base_lists, [])
sys.stderr.write(u)
weight_total = sum(item[1] for item in items)
i += 1
yesterday = now - timedelta(days=1)
ax = plt.gca()
list(x) is x
shutil.rmtree(apppath)
new_user.save()
0
out[k].append(recursive_asdict(item))
df
image = image.resize((nw, th), Image.ANTIALIAS)
print(line)
b = values(numpy.arange(100))
asdf = form.save(commit=False)
locals().update(adict)
root = lxml.html.fromstring(driver.page_source)
deleteself.weapon
fp.write(chunk)
iter(iterable.items())
loop.add_timeout(time.time() + seconds, callback=gen.Callback(some_unique_key))
listbox.pack()
rand_var_1 = tf.Variable(rand_t)
b = np.append(a, [False])
page_next_app_table = template.render()
txt = wx.TextCtrl(self)
self.data = [[(0) for c in range(cols)] for r in range(rows)]
self.noload = unpickler.noload
main.show()
pprint.pprint(lines_to_dict(d))
type(dates[0])
self.frame = Frame(self.root)
--__init__.py
t = np.linspace(-10.0, 10.0, 100)
df
data = []
plt.plot([(x * x * curvature) for x in range(0, 11)])
self.var1 = 1
print(inspect.getsource(Tester))
superstrings.remove(sup)
a = models.ForeignKey(A)
self._cards[card_ID].invert()
words = sentence.split()
solution[1], sum(oldmoves[solution[1]]), oldmoves[solution[1]]
decorated.sort()
True
axarr[0].plot(x, y)
sys.stdout = stdout
result = []
lst = [(val * 2) for val in lst]
X_kpca = kpca.fit_transform(X)
y = [(max(k), v) for v, k in list(d.items())]
sess.run(init)
date = parser.parse(text)
ser.str.isdigit().sum()
max_range = list(range(start, end))
[(key, [self[key]]) for key in self.order]
diff[y, x] = img1[y, x] - img2[y, x]
json.loads(raw_post_data, object_pairs_hook=KeyWatcher)
result = set()
corner2 = [1, 1, 1]
Py_DECREF(result)
value = list(value)
contour = numpy.array([[[0, 0]], [[10, 0]], [[10, 10]], [[5, 4]]])
modules = map(__import__, myList)
register = template.Library()
ax = fig.add_subplot(111)
do_first_thing_with(obj)
PyArray_Descr * descr
i = np.array([0, 0, 1, 2, 2])
fr.f_code.co_name
corners = np.squeeze(np.int0(corners))
e = pygame.event.poll()
graph.append([])
b[x].append(x)
cx2
n = len(txt)
result1 = pool.apply_async(solve1, [A])
nums = [6, 10, 4, 8, 2, 12, 10]
self.optionmenu_a.pack()
session.add(doc)
gplt.show()
app = wx.App(False)
pagination_serializer_class(instance=page, context=context)
question = session.query(Question).first()
members[index]
cutoffs = np.cumsum(probs)
linepos.append(offset)
user = models.ForeignKey(User)
canvas = numpy.zeros((12, 12), dtype=int)
df.set_index(rng, inplace=True)
pprint.pprint(w.fields)
overlaycolour = [255, 0, 0]
ax2 = fig.add_subplot(5, 4, 2, sharex=ax1)
[t[:2] for t in data]
df = pd.DataFrame(np.random.choice([1, np.nan], (1000000, 15), p=(0.01, 0.99)))
a[(a >= -100) & (a <= 100)]
print(res)
lmul(ll[0], [[item] for item in ll[1]])
np.random.seed(0)
team = models.ForeignKey(Team)
c = np.intersect1d(a, b)
t = et.fromstring(df.to_html())
CC1 = CC1a * (CC1b + CC1b.T + np.eye(n1))
third_friday = first_friday + timedelta(days=14)
sin = np.sin(angles)
lines = file.read().splitlines()
db.create_tables([Person])
self.ui = Ui_MainWindow()
tuple(prime_factors(100))
createIndex(row, column)
a(4, 5)
value, count = c.most_common()[0]
ax.set_xticklabels(())
arr.tocsr()
real_f.close()
actions.move_by_offset(x_to, y_to)
-setup.py
proc = multiprocessing.Process(target=wrapper, args=(queue, bob))
mkl_rt.mkl_set_num_threads(ctypes.byref(ctypes.c_int(48)))
df = df.reset_index(drop=True)
parsed = json.loads(your_json)
True
a = x.copy_with(y=4)
hash1 == hash2
a.clip(0, 10)
print(user.username)
sums = itertools.accumulate(seq)
type.__new__(meta, classname, bases, newClassDict)
tree.query_ball_point([london], r=euclidean_distance(100))
np.putmask(array, numpy.random.rand(array.shape) < prob, np.logical_not(array))
fig1 = plt.figure()
os.rename(outfile.name, inpath)
ax2 = ax1.twinx()
l = []
print(parse(test))
self.draw()
lib.a.A()
lst.sort()
tick.label.set_fontsize(14)
[[1], [4, 5, 6], [10], [15, 16, 17, 18], [22], [25, 26, 27, 28]]
data
nt = etree.ElementTree(root)
[f for S in s for f in [FunkyFunction(a[S])] if f > 0]
result = []
print(data)
contents = output.getvalue()
m = np.median(foo[foo > 0])
self.mainframe = ttk.Frame(self.root, padding=(6, 6, 12, 12))
Dy = L1[0] * L2[2] - L1[2] * L2[0]
oFig1.add_subplot(4, 4, 11)
print(filename)
sums = a.sum(axis=1).A1
hashed_passwd.startswith(salt)
print(filename)
savek = list(k)
{{modelform1}}
{{modelform2}}
my_command.py
p.join()
mp_handler()
sorted_files = []
out[1:-1]
Map(fold=lambda f, g: f(x), bimap=lambda f, g: Left(f(x)))
x, y, p
set(lst1 + lst2)
lines_counter += 1
s = slice(2, 4)
values = [5, 10, 15, 20]
d1 = date(2008, 9, 26)
string_dec = str(dec)
f1 = lambdify(x, diff(f(x)))
print(line)
glClear(GL_COLOR_BUFFER_BIT)
float(s)
tokens = nltk.word_tokenize(raw)
a = Counter(0, 1, 2, 1)
ip_range = netaddr.cidr_merge(ip_range)
f.writelines(datum + os.linesep for datum in data)
myClass.py
image.thumbnail((256, 256), Image.ANTIALIAS)
response = unirest.post(url, headers=headers, params=params)
pprint(result.data)
b = a[index, index]
sys.getsizeof(test_ordered_dict)
print((u[i], i, u, len(u)))
f.set_figwidth(15)
a += 1
vec /= np.linalg.norm(vec, axis=0)
sys.stdout = StringIO.StringIO()
orig_import(name, *args)
Ainv
strcat(greeting, name)
traceback.print_stack(file=self.stdout)
f_name = func.__name__
self.fn(*args, **kwargs)
form = ArticleForm(request.POST, instance=article)
np.random.shuffle(indices)
cls
a[1:2]
mydict[currentid].append(currentvalue)
stefan.append(list(args))
self.__do_layout()
print(sys.version)
[a]
data = request.GET.copy()
ax = plt.axes(projection=ccrs.Robinson())
result = dict(pool.map(f, inputs))
filepath = os.path.join(root, names)
output_wave_file.close()
[(x / sum_samples) for x in samples]
y -= 2
models.Field.formfield(self, StringListField, **kwargs)
cols = cols[-1:] + cols[:-1]
platform.release()
ssh.connect(l_host, username=l_user, password=l_password)
t = np.arange(-0.5, 1, 1e-05)
Y = np.array([2, 0, 1, 1])
cval = int(c)
value = 1
ExampleModel.objects.filter(some_datetime_field__range=[start, new_end])
pause(1)
l[x] = l[x][1024:]
file.write(data)
zipfile = ZipFile(StringIO(url.read()))
self.listWidgetA.currentItemChanged.connect(self.item_clicked)
mat.close()
U = np.random.rand(n, n)
dict_[methodname] = lockmethodfactory(methodname, lockattr)
loop.run()
todayDate = datetime.date.today()
result.x
wb.save(output)
shortset.add(seq[i:i + shortlen])
print(b.base is a)
z = np.polyfit(x, y, 1)
A[[0]].shape
all(map(lambda x: x == l[0], l))
a[i] = int(a[i][::-1])
data = globals()
raise NotImplementedError
a = numpy.empty((ix.sum(), h5_array.shape[1]), dtype=float)
print(avg_positive_speed(speed))
p = lambda x, y: x + y
self.width = width
string.punctuation
plt.ylim(0, 2500)
meth
self.extend(db.get(key, []))
wf.close()
gevent.Greenlet.__init__(self)
bpy.ops.transform.rotate(value=rot.angle, axis=rot.axis)
fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True)
pool.close()
B = csr_matrix((5, 2), dtype=int)
mail.check()
keys, values = zip(*list(my_dict.items()))
print(ctypes.get_last_error())
m = np.ma.masked_where(y > 5, y)
sys.stdout = devnull
os.mkdir(corpusdir)
db.add(marker_type)
p = figure()
l = []
cv.SetData(image0, rotated_image.tostring())
rotmat = np.array([[0.0, 0.0, 1.0], [0.0, 1.0, 0.0], [-1.0, 0.0, 0.0]])
self.stack.append(0)
higher = Vertex()
text_link.insert_after(is_my)
i = j + 1
gtk.main()
grid = [0, 5, 10, 15, 20]
result[-1].append(text)
self.columnconfigure(2, weight=1)
A = A.T
mask = np.tril(np.ones((4, 4), dtype=bool))
fig2 = plt.figure()
diff_idx = np.flatnonzero(np.linalg.norm(b[1:] - b[:-1], axis=1) > thresh) + 1
total = sum(el for el in list(val.values()))
d = datetime.datetime.utcnow()
writer.writeheader()
bearing = math.atan2(y2 - y1, x2 - x1)
m.move(x, y)
br.set_handle_redirect(True)
self.__dict__ = kwargs
im_hsv = cv2.cvtColor(im, cv2.COLOR_BGR2HSV)
sys.stdout = mystdout = StringIO()
PyEval_AcquireThread(myThreadState)
pop_conn.quit()
new_matrix = []
d = {}
p = Point(1, y=2)
form = CustomerInfoForm(request.POST)
img = filedescriptor.read()
dyna_join(df, [0, -2])
print(config_file[opt_name])
print(list(build_notes(DF)))
list(someDict.keys()) & someSet
self.dummy.x = value
n % 10 + digitalSum(n // 10)
parameter = eval(file_text)
root = Tk()
idx = numpy.random.choice(len(choices), 4)
res = [test[(i + 1) * i // 2:(i + 1) * (i + 2) // 2] for i in range(bound)]
EMAIL_USE_TLS = True
new.append(graph[i])
d.nonzero()
st.norm.cdf(1.64)
decoder.decode(s)
dict(add=_add)
output[lake] = lake.sum() < 6
self.hair = hair
data.text
count[0] += 1
print(b - a, len(numbers))
self.i += 1
df
s = requests.session()
some_thing_that_fails()
print(e.findall(data))
odict[key]
req.setRawHeader(k, v)
M = np.random.randint(2, size=(h, n))
fig.autofmt_xdate()
Z2 = plt.mlab.bivariate_normal(X, Y, 1.5, 0.5, 1, 1)
attachedvolumes()
self._async_interrupt.interrupt()
conn = engine.commit()
p.start()
now = datetime.utcnow()
finalizebins(bins, binsize)
X_subset = [X[idx] for idx in indices]
os.kill(int(pid_str), sig)
result = collections.defaultdict(list)
print(i)
df[1] = df[0].diff() > 600000000000.0
keys = list(d.keys())
results = pool.map(do_work, work)
datamean = data.mean(axis=0)
y.byteswap()
lines.append({})
rev_ref = dict((v, k) for k, v in ref.items())
w.add(a)
hashes.append(sha1OfFile(os.path.join(path, file)))
res_lst.append(out_queue.get())
print(result)
generations.append(generations[-2] + generations[-1])
b.py
t.start()
plt.legend()
kwallet_example.get_password(wallet)
m = pd.Series(to_filenames.values, from_filenames.values)
char * saveptr
axes = plt.subplot(gs[0, 0])
System.err.println(tmpFunction.getClass())
reader_p = Process(target=reader, args=(queue,))
bin(x)
c = wmi.WMI()
p.start()
s = map(set, g)
self.broken = True
some.unrelated.development.host
picture.putdata(colors)
session.expunge_all()
rle = [(k, len(list(g))) for k, g in groupby(li)]
test()
job.get()
s.astype(np.datetime64).fillna(pd.NaT)
self.size = max(self.size, self.position)
t = datetime.date.today()
ispower(625, 5)
0
print(str(err))
fig = plt.figure(figsize=(ncol + 1, nrow + 1))
f = StringIO()
x, y, z
subprocess.call(commandline)
X_test = np.array(descs_train)
cursor = db.cursor(cursor_class=MySQLCursorDict)
a2.remove(e)
A[row] = [data]
test2()
lib.TessBaseAPIGetUTF8Text.restype = ctypes.c_char_p
s = sys.__stdin__.readline()
authhandler = urllib.request.HTTPBasicAuthHandler(passman)
data = Column(String(20))
gcf().canvas.draw()
self.happiness = self.wealth / self.data.global_wealth
driver.execute_async_script(load_jquery_js, jquery_url)
7, array([4, 5, 6]), array([8, 9])
timedelta.days * 86400 + timedelta.seconds
result = pipe.stdout.readline()
roster = []
x[:, (x_range), (y_range)]
n >>= 8
queryset = Location.objects.all()
total_distance = numpy.hypot(*numpy.diff(numpy.array(points), axis=0)).sum()
kclass = []
a = A()
root = tkinter.Tk()
json.JSONEncoder.default(self, obj)
a1.append(int(data[0]))
print_tree(d)
np.fromiter(dropwhile(lambda x: x, ar[::-1]), dtype=bool)[::-1]
print(a, b)
result, index = arraysums_recursive((a, b), lower=5, upper=6)
sys.stdout = f
ax = plt.gca()
print(now.strftime(fmt))
fig = plt.figure()
r1 = np.hstack((b, w, b, w, b, w, b))
nx.draw(G, pos, alpha=0.75)
requests.get(url, auth=auth)
new_dic = {}
print(p, p.is_alive())
b.set_clip_on(False)
dirName = os.path.abspath(dirName)
np.array(signal)
self.tree_filter.refilter()
response.append(line)
vertices, np.hstack((bary, 1 - bary.sum(axis=1, keepdims=True)))
values = np.random.rand(1000)
connection = pyodbc.connect(connection_string)
n[i] = next(iterators[i], done)
g.draw()
edges[i + 2, j].append((i - 2, j))
model._meta.verbose_name
xpp = (x.ctypes.data + np.arange(x.shape[0]) * x.strides[0]).astype(np.uintp)
sums.append(data[groups == group].sum())
letters.remove(chr(part[1]))
dict(one=1, two=2)
b[x] = 1
ctypes.pythonapi.Py_IncRef(pyo)
fig.delaxes(fig.axes[2])
car2 = pygame.transform.rotate(car1, 10)
module_a.py
k = k + 1
len(self.buffer) > 0
output = process.communicate()
outfile.write(outline)
the_data = json.loads(json_string)
outlist.append([])
ssh = paramiko.SSHClient()
print(n.predict(B))
x()
output = PdfFileWriter()
array([[0.5, 2.5, 4.5], [0.5, 2.5, 4.5], [0.5, 2.5, 4.5]])
main()
set_state(args.state)
print(ensure_datetime(x))
pygame.camera.init()
diff = datetime.now() - birthday
app.run(debug=True)
reps = [(y, x ** 2), (x, 2)]
cv2.drawContours(mask, [best_cnt], 0, 0, 2)
print(value)
funcname = func.__name__
found = False
main_window.setCentralWidget(enable_window.control)
print(line)
values = np.hstack([np.random.normal(0, 1, 10), np.random.normal(10, 1, 100)])
plot(row, x, y)
glEnd()
ax.draw_artist(col)
fin[i[0][0]] = i[-1]
dd = dd.replace(year=dd.year - 100)
img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)
Matrix(final).expand()
ui.setupUi(Form)
sys.stdin = progA.stdout
main()
self.send_response(200)
webbrowser.open_new(url)
data[:-(data[-1] if type(data[-1]) == int else ord(data[-1]))]
ws.send(json.dumps(dict(received=message)))
set(b).issubset(set(a))
print(date_dict.get(date, []))
df = pd.DataFrame([[y[0] for y in x] for x in outputdata], columns=Molecule)
b, c = zip(*zipped)
x = np.arange(xmax)
self.should_run.clear()
complex_process(df.ix[idate], idate)
self.src[-1].append(item)
np.not_equal(c[1:], c[:-1], out=flag[1:])
myList[-1]
d = hashlib.md5()
current_class.append(node.tag)
s = fh.read(40256)
times = pd.to_datetime(df.timestamp_col)
print(df_final)
client2 = socket.socket()
self.__or__(other)
sys.exit(2)
im.set_ylim((125, 1000))
points = np.random.rand(15, 2)
entropy
img = cv2.merge((r, g, b))
value = self.__variable
radius = vor.points.ptp().max()
fake_csv.seek(0)
matrices.append(np.random.random_integers(100, size=(1000, 1000)))
y = 10 * np.random.normal(mu, sigma, 5000)
pprint(soup.find(text=pattern).__dict__)
print(my_globals.thing)
help(Foo.bar)
tables = connection.introspection.table_names()
plt.imshow(green_img)
qproc = Process(target=sub_proc, args=(q, fn))
app = Flask(__name__)
ax1.set_xticks([])
lambda : reqd_email == cherrypy.request.login
column_widths[i] = len(cell)
l[-1] += s[:r]
usage()
date_requested = DateField()
data = urllib.request.urlopen(str(i)).read()
points = np.mgrid[1:6, 2:5, 8:10]
newlist[-1].append(alist[i])
vec < -vector()
stdscr.refresh()
self.counter += 1
pl.show()
issubclass(instance.__class__, object)
mask = np.zeros((all_i.shape[0],) * n, dtype=np.bool)
print(mystring.format(wash_clothes, clean_dishes))
self.user = auth_user
fig = plt.gcf()
maxes = (np.diff(np.sign(np.diff(xs))) < 0).nonzero()[0] + 1
self._body = self.read()
yaml.add_representer(str, str_presenter)
max(pairs, key=lambda x: x[1])[0]
gobject.idle_add(discoverer.discover)
path = sys.argv[1]
results[i % 2].append(e)
driver = webdriver.Firefox()
content = response.read()
float(m(256))
dest.addPage(PDF.pages)
TESTING = True
dir(Foo)
dis.dis(empty)
rdd.mapPartitionsWithIndex(remove_header)
vectorized_array = vectorized_sparse.toarray()
wsgi.py
plt.xlim(ax, bx)
idx = [(np.ones(len(a)) * i) for i, a in enumerate(arrs)]
le.fit([1, 2, 2, 6])
now = datetime.datetime(2009, 5, 5)
fig = plt.figure()
found.append(word)
index += match.group(1)
present = datetime.now()
posts.fetch()
intersection = max(a[0], b[0]), min(a[1], b[1])
set().union(*(x.nodes() for x in list(periodic_gs.values())))
sys.stderr.flush()
label.setPixmap(pixmap)
dict_writer.writeheader()
1.0 / 2
p = re.compile(regex, re.U)
generators = [read_values(file) for file in datfiles]
nb.train(v)
IS_SETUP = False
img = ImageTk.PhotoImage(Image.open(path))
fig.set_size_inches(18.5, 10.5)
uexpr.doit()
idx = [1, 4, 8, 10, 22]
[(self._min_x, self._min_y), (self._max_x, self._max_y)]
job.start()
cv.Copy(img0, newCanvas)
ax = fig.add_subplot(111)
out[R, C] = A[R].multiply(B[:, (C)].T).sum(1).ravel()
corner1 = [0, 0, 0]
mylst = list(range(10, 20))
list_1_sorted = [x[0] for x in sorted_together]
logger.addFilter(dup_filter)
r.append([d, f])
print(tfidf.todense())
entry.configure(show=random_char())
shape = tf.shape(image)
_create_unverified_https_context = ssl._create_unverified_context
datetime.datetime(*dt_args)
self.foo_impl(x)
rows, cols = np.triu_indices_from(arr, k=k)
f = float(s)
ax = plt.axes()
indices = [i for i, v in enumerate(a >= 4) if v]
meta = MetaData()
logger
lock.acquire()
hash(self._vals())
print(posneg([6, 44, 1, -7, -6, 19]))
b[2] += 7
ax0 = plt.subplot(gs[0])
dump(indata, 5, 6)
min(points, key=self.compute_distance_to)
SublimeLauncherApp().run()
get_color(0.2)
hash(str(self))
self.cells[index] = new_value
print(df)
b0 = tf.Variable(tf.zeros([256]))
file.seek(position)
np.allclose(out1, reduce_after_multiply(M1, M2))
output = StringIO.StringIO()
df.shape
dict(iterableOfKeyValuePairs, **dictOfKeyValuePairs)
A = p1[1] - p2[1]
assert not p.poll()
root = ET.fromstring(xml, parser)
importPath = os.path.dirname(path)
plt.grid(True)
file_args = compdb.getCompileCommands(source_file_path)
print(new_list2)
hours = sales.index.hour
pieces = urlparse.urlparse(url)
token_dict = keystone.auth_ref
-libjpeg - dev
tour = []
xy = (np.random.random((10, 2)) - 0.5).cumsum(axis=0)
print(get_script_dir())
f.close()
hashes[newhash] = newurl
li = st.split()[::-1]
print(result)
ax.plot(list(range(10)))
df2 = df.copy(deep=True)
X = np.reshape(lena, (-1, 1))
a = pandas.DataFrame(np.arange(25, dtype=np.float16).reshape(5, 5))
print(result[0])
ax = plt.subplot(111)
f(*arg, **kw)
self.index += 1
f = Foo()
self._attr_value_to_obj_set[attr_value].add(obj)
[(f[::-1] if needs_flip[f] else f) for f in orderless_faces]
sys.modules[mod_name] = Mock()
self.tabs[index].append(CQWebView(self))
subset[subset.isin(myList)].stack().duplicated().unstack()
axis.set_ylim(y_min - 0.1, y_max + 0.1)
cj.save(ignore_discard=True)
pprint.pprint(my_structure)
arginfo = inspect.getargvalues(s[1][0])
a2.eliminate_zeros()
email = db.Column(db.String(120), unique=True)
ax.plot(list1, list2)
{{answer.someattribute}}
self.panel.hide()
context.set_source_rgb(1, 1, 1)
mpu = bucket.initiate_multipart_upload(key)
gen.close()
a[5:0:-1]
matching_solutions.append(sol)
user.save()
p1.stdout.close()
ya.set_major_locator(MaxNLocator(integer=True))
image_content = base64.b64encode(image.read())
mask = np.isnan(a)
print((item.subject, item.body, item.attachments))
ans[-1] += letter
__contains__
CM = CM.sum(axis=1)
print(line)
--tasks
[ax4.plot(i, j) for i, j in graph_data]
p.start()
raise NotImplementedError()
logging.Handler.setFormatter(self, fmt)
cls.__items[item]
next_up(x)
a.getDouble(), b.getDouble()
int_array = [int(a, 16) for a in ar]
math.hypot(self.x, self.y)
ai = np.argsort(a)
print(i)
temp = np.random.randint(1, 10, 10)
print(nltk.sem.relextract.show_raw_rtuple(rel))
cursor = db.cursor()
lab = color.rgb2lab(rgb)
response
pipeline.set_state(gst.STATE_PAUSED)
ind = np.lexsort((a[:, (1)], a[:, (0)]))
(1 if text[i] == char else 0) + count(char, text, i + 1)
paths = []
a.data
k = bucket.new_key(full_key_name)
print(len(dodgy))
sorted(a)
ax.set_xlim(min(x) - offset, max(x) + offset)
print(X_train_tfidf.shape)
print(x.size)
foo(node, p.copy())
my_data = [list(range(5)) for i in range(5)]
num_bin = num_bin_reversed[::-1]
app = tornado.web.Application(Router.urls, debug=settings.DEBUG)
np.dot(m, prior_reci) + np.dot(1 - m, 0.1 * prior_reci)
p.terminate()
key = bytearray([19, 0, 0, 0, 8, 0])
b = pd.DataFrame(a)
column_entry = gtk.Entry()
print(data)
self.current = next(self.__gen)
TTY / dev / ttyS0
container[key].update(values)
lF.grid()
kl.getFormula()
print(my_random_string(6))
ttlist = []
tree.left = self.left
dictfetchall(cursor)
self.doc = ET.parse(fname)
d.append(t)
Main()
data = conn.recv(1024)
x, y, w, h = x - 2, y - 2, w + 4, h + 4
width = db.IntegerProperty()
output.flat[ind] = res
dir = os.path.dirname(path)
conn.setopt(pycurl.WRITEFUNCTION, response.write)
end_dt = datetime.date(2005, 6, 1)
a[0, 0]
new_list = [(x + str(y)) for x in the_list for y in range(n)]
oldval, oldidx = val, index
output.addPage(pdfOne.getPage(i))
recovered_time_shift = dt[xcorr.argmax()]
df = pd.read_csv(StringIO(txt), skipinitialspace=True)
Counter(x) == Counter(y)
ex.show()
keyValues[key].append(value)
imc = im.crop((w - 50, h - 50, w + 50, h + 50))
client = app.test_client()
fig.axes.get_yaxis().set_visible(False)
types.FunctionType(self.func.__code__, new_globals)
copyData(data, arr)
c.executescript(query)
self.print_usage(sys.stderr)
dict2 = copy.deepcopy(dict1)
any(elem in test2 for elem in string)
models.DateTimeField(blank=True)
B = NP.array([0, 1, 0, 1, 0])
sorted_points = sorted(points)
True
INVENV = 0
self.response.write(g.text)
print(itertools.permutations.__doc__)
self.var1
url = key.generate_url(expires_in=0, query_auth=False, force_http=True)
driver = webdriver.Firefox()
print(str(10).zfill(2))
output[-1] += char
fnan < 0
True
header[key] = [x.strip() for x in header[key]]
client.close()
myObject = myObject.doStuf()
sigma = np.matrix([[4, 10, 0], [10, 25, 0], [0, 0, 100]])
i += 1
raise ValueError
parser = argparse.ArgumentParser()
Gvalue = someoperation(Gnodes)
app = QApplication(sys.argv)
th = np.linspace(0, 2 * np.pi, M)
d = d[k]
full_dir = os.path.join(home, directory)
axis2.plot(list(range(10, 20)))
squre_pts.push_back(R4)
plt.plot(x, y)
print(first(l for l in lettfreq if lettfreq[l] == 1))
ax5 = plt.subplot(gs[-1, -2])
reader = csv.reader(f)
k.delete()
is_linear(eq1, [a, d])
i = np.random.randint(0, nrows - 1, numdense)
axis([-1.5, 1.5, -1.5, 1.5])
dfs = [df1, df2]
d = {}
print((fit_alpha, fit_loc, fit_beta))
plt.contour(np.log(r))
re2_matches = re.findall(re2, text)
key = Key(bucket, filename)
b = [(10, 40), (40, 60), (60, 90), (90, 100)]
filename = os.path.join(dirname, basename)
result.append(mofile)
print(res[0])
f.diff(x).diff(x) < 0
x = np.linspace(0, 2 * np.pi, 100)
show(ptr, 0)
c = np.hstack((a, np.atleast_2d(b).T))
fig.canvas.draw()
self.__dict__[key]
c.perform()
np.lib.stride_tricks.as_strided(arr, shape=shape, strides=strides)
0
map(operator.itemgetter(0), L)
self.__dict__.update(state[0])
X.tocsc()[indices]
Y[..., (1)] = np.clip(np.abs(X) / absmax, 0, 1)
round_total_digits(x)
IOLoop.add_timeout(deadline, callback)
hist, xedges, yedges = np.histogram2d(x, y, (xedges, yedges))
dayafter = now + timedelta(days=2)
[([x] + p) for x in [4, 5, 6] for p in product(*seqs[1:])]
img = ImageTk.PhotoImage(Image.open(path))
part.speed = [random.uniform(smin, smax) for _ in range(size)]
print(sys.getsizeof(x))
send_from_directory(directory, filename)
seed = np.zeros(data.shape, dtype=bool)
help(sys)
print(numpy.nanmean(A))
plt.contour(X, Y, F, [0])
r = np.sqrt(x ** 2 + y ** 2)
fig.show()
b = r_[a, c]
all(i is a[0] for i in a)
default = parser.parse_args(args[:-1], namespace=ns)
print(map(tuple, output_sent))
k = cv2.waitKey(0)
self.z = z
b = [a, a]
X = np.linalg.solve(A, y)
t = set([1, 2])
self.listOfVideo
data
np.random.seed(0)
fibs = [fib(i) for i in range(fib_n)]
rec.set_clip_on(False)
series2 = series1[::-1]
pygame.init()
empty_keys = [k for k, v in metadata.items() if not v]
content = result.read()
self._oldstdout_fno = os.dup(sys.stdout.fileno())
fd.floatarr.argtypes = [POINTER(c_int), POINTER(POINTER(c_float))]
utils.py
total.finish()
a = [1, 2]
ind = np.column_stack(np.unravel_index(idx, lon.shape)).tolist()
new_rows = []
YourTask.apply_async(args=[some, args, here], eta=when)
a = list(a)
all_keys = set(chain(*[list(x.keys()) for x in dd]))
v = np.arange(0, original.shape[0], 0.5).astype(int)
tree.body[1].names[0].name
ssh.load_system_host_keys()
np.dot(arr, arr)
myNewList[i] += math.copysign(0.01, n)
d.x
encoded_data = urllib.parse.urlencode(data)
mw.show()
fig.colorbar(surf, shrink=0.5, aspect=5)
t = datetime.datetime.fromtimestamp(float(s) / 1000.0)
runner = unittest.TextTestRunner(f)
superman
image = Image.open(image_file)
color = sns.color_palette()[5]
dt_aware = pytz.timezone(tz).localize(dt_naive)
[tensor.name for tensor in tf.get_default_graph().as_graph_def().node]
cscope - R
FlakyClient.call()
os.seteuid(os.getuid())
tree = ET.parse(newfile)
print(funcs[0]())
datetime.date(2012, 11, 22), datetime.date(2012, 12, 25), datetime.date
strcpy(cpy, str)
modified = {k: max(v) for k, v in list(d.items())}
results.append(line)
int(self) > int(other)
d = dict(zip(val_old, val_new))
True
reader = csv.reader(fin)
output = pandas.DataFrame(index=outDates, columns=strData)
self.tapDetected()
signal.alarm(timeout)
df
Vector([(s + other) for s in self.data])
nmean = autojit(mean_numba)
name = models.CharField(max_length=255)
handler = logging.StreamHandler()
from_date - relativedelta(years=years)
tmp_planes = ax1.zaxis._PLANES
j += 1
result = []
array = list(range(10))
raise
mysql_cn.close()
objects = PersonManager()
self.pk
word = word.strip()
cv.SetData(cv_im, pil_im.tostring(), pil_im.size[0])
print(string_numbers)
print(sys.argv[1])
plot(xdata, ydata)
fp = webdriver.FirefoxProfile()
zip(list(range(start, stop)), collection)
finalinfo[s] = finalinfo.get(s, 0) + t
new_dict
np.multiply(d, d, out=g)
a.indices(1)
signals.pre_save.connect(update_timestamp, sender=Post)
print(doc.to_json())
print(x)
x = random.random()
xx = np.linspace(0, 1, 1000)
os.close(self.pipe[1])
h2o.init()
d = p.dirname(somepath)
table[i - 1][j - 1] = data[str(i)][str(j)]
result += [i for i in range(len(values)) if values[i] == sv]
res = cursor.fetchall()
a, b, c, d = np.ogrid[:n, :n, :100, :n]
concurrent_suite.run(testtools.StreamResult())
ylim(10, 17.5)
print(key, my_dict[key])
random.seed(newseed)
im = numpy.random.randint(0, 50, (5, 7))
print(sub_toks)
ui.write(e.EV_KEY, e.KEY_A, 1)
ax.plot(xdata, ydata)
test_greet()
t.start()
abspath(getsourcefile(lambda : 0))
10.0 ** 10 ** 10
1, 1, 8, 1
[(16, -16), (40, -40)]
main()
list(closed_range(1, 10, 2))
first_ungrouped_idx = np.where(matching)[0][0]
[(l == value) for l in lst]
ax.scatter(x, y, marker=symbol[sign(chg)], s=175)
print(first_day + relativedelta(months=1))
localrandom = random.Random(id_num)
y = y + y
time.sleep(0.2)
time.sleep(50.0 / 1000.0)
fig, axs = plt.subplots(1, 1)
self.rop = rop
print(data)
module = __import__(module, fromlist=[name])
obj.actor.scale = [0, 0, 0]
data = np.array([6])
other + str(self)
outputmapping[idx] = val
new_stack.append(old_stack.pop())
a_thread.join()
customer.save()
stack.extendleft(reversed(node.children))
a = numpy.arange(10000, dtype=numpy.double)
self.dot.set_data([[value], [value]])
df = DataFrame(columns=list(range(100)), index=list(range(1000)))
next(op)
results = []
self.b = b
self.update()
self.session_store = sessions.get_store(request=self.request)
self.systemTrayIcon.setVisible(True)
dict = {}
Container(result)
scalemap[:] = scale * xmap
x == y
copy_of_a = a[:]
emails.append(email.fetch())
map(id, a)
line = line.rstrip()
legs = 0
a = a[0]
sinks = sys.argv[1:]
no_vow(seq, index)
axes.bar(x2, y, facecolor=getCycledColor())
df = concat(tp, ignore_index=True)
axes = plt.subplot(111)
locals()
df.update(df_small)
dropped_copies.append(x[i] for x in copies[i])
Log.setLevel(level)
x = np.linspace(-1, 1, 500)
t /= np.linalg.norm(t)
poison(spam)
logger = logging.getLogger(__name__)
pool.join()
self.value
only_words = [token for token in my_list if token.isalpha()]
y_test = np.random.randint(0, 10, [50])
self.value = value
b = a()
data = xmltodict.parse(data)
DEBUG = True
object_list.filter(username=request.user)
new_queryset = queryset.none()
fig.canvas.draw()
logger.py
dpi = fig.get_dpi()
f.__closure__[0].cell_contents
strt_dt = datetime.date(2001, 1, 1)
xmean = xwin.mean(axis=1)
self.hide()
t.stop()
float(s)
bval[q - 1] ^= 1 << r
loop.close()
np.diff(np.sort(a))
g = io.BytesIO(f.read())
seconds = value.total_seconds()
self.Bind(wx.EVT_MENU, self.OnMinimize, id=minimize.GetId())
[0, 1, 1]
im = Image.open(img)
print(rows[len(ray) - idx])
self._index += 1
self.img_label.pack(side=tk.TOP)
np.hstack((arr.reshape(x * y, z), indices))
client_receiver.RCVTIMEO = 1000
print(utc.localize(test2))
mask = np.ones(a.shape, dtype=bool)
res = a[0] * b[0] + a[1] * b[1] + a[2] * b[2]
self.collector = collector
msg = xmpp.Message(self.request.POST)
search_results = search_response.read()
SettableDataBits = TRUE
form = UsersForms.UserImage(request.POST, request.FILES)
foo = my_func(your_func(their_func()))
flattened = chain.from_iterable([x] if isinstance(x, str) else x for x in lst)
bus = dbus.SessionBus()
metadata.drop_all()
filt1(signal) * line(dur, 0, 1) + filt2(signal) * line(dur, 1, 0)
j = np.array([[0, 0, 0], [1, 1, 1]])
display = Xlib.display.Display()
main.show()
print(result)
line = line[:-1]
print(p1.x.x)
last_build = my_job.get_last_buildnumber()
print(total)
options = parser.parse_args()
cvtColor(img, img_bw, COLOR_BGR2GRAY)
consecutive_diffs = (y - x for x, y in pairwise(xs))
path = os.path.join(dir, name)
print(name)
seen.add(item)
a_test.method_two()
n_interior = abs(diff(a, axis=0)).sum() + abs(diff(a, axis=1)).sum()
UserSerializer(user).data
arrangement = list(list(row) for row in itertools.islice(iterator, 4))
logger.removeHandler(handler)
df = df.applymap(format)
self.flush()
setattr(self, field.name, new_filename)
TextWidget.focus_set()
crsr = cnxn.cursor()
print(finder.nbest(trigram_measures.likelihood_ratio, 10))
path = os.path.join(dirpath, filename)
store.close()
cleared = []
False
basis_vecs = sorted_eigvecs[:, -num_basis_vecs:]
digit_to_char(m)
decorator
self.y += 1
keyValues[key].append(value)
pickle.load(f)
CM_tilde = np.mean(data, axis=1)
zinfo = zipinfo
itertools.chain(f(reversed(a[:i])), [a[i]], f(a[i + 1:]))
time.sleep(SECONDS_TO_WAIT)
new_path.append(current_neighbour)
code.interact(banner=banner, local=namespace)
self._a = a
CALLS += 1
list = []
plt.yticks(yvalues, ylabels, figure=fig)
app = Flask(name)
f = urllib.request.urlopen(req)
self._heartbeat = heartbeat
list(iterable.keys())
StartDance(*list(range(5, 9)))
driver.get(url)
literal_eval(x)
[1, 8, 6]
C = A.dot(B)
dir(img)
C.copy(ffi.from_buffer(arr_in), ffi.from_buffer(arr_out), 16)
frequencies[character.lower()] += 1
b = set(a)
itertools.groupby(list(range(10)), lambda x: x < 5)
a = [2, 7, 9]
df_index = np.insert(np.arange(arr.shape[0]), idx + 1, idx, axis=0)
corner2Copy = (len(arr) - 1) * numpy.array(corner2)
serverSocket.bind((HOST, PORT))
print(str)
0
BOOST_PYTHON_MODULE(s)
p.start()
B = [[0, 0, 1, 0], [1, 0, 1, 0], [1, 1, 0, 0], [1, 0, 0, 1], [1, 0, 0, 0]]
loadedArchive = np.load(outFile)
found = False
tasks = multiprocessing.Queue(1)
print(test(15))
main()
False
oss.str()
parser
screen = pygame.display.set_mode((800, 600))
x = np.zeros(2, dtype=dt)
search(s)
self._cache = {}
sys.exit(app.exec_())
b[a]
plt.figure(figsize=(15, 5))
{}
deleteself.list[i]
x, p = set(range(2, n)), 2
x.A.count() * (x.A.count() - 1) * 2
pqueue = []
imframe.putpalette(palette)
current_dir.pop()
done.add(row[0])
j2.sort()
ax0 = fig.add_subplot(1, 2, 1)
[t for t in grouper(s) if t[0] in vowels]
config = ConfigParser.ConfigParser()
result = PyClass()
print(doc.reprJSON())
wave_file.close()
ext = os.path.splitext(path)[1]
subprocess.Popen(args1)
subprocess.Popen(args2)
x[1::2]
diff = [(a[i + 1] - a[i]) for i in range(N - 1)]
f.close()
t.set_axis_off()
print(str[:6] * 2)
a = np.transpose(a)
{0, 1, 0, 0, 0, 0, 0},
b1 = np.array([[5, 6], [7, 8]])
d[date] = {}
self.kNN = initializekNN()
server = urllib.request.build_opener(ph)
a * b
m.predict([1, 1, 1])
print(df)
QtCore.QAbstractListModel.__init__(self, parent)
date_joined = models.DateField()
result.append((longest_keyword, all_occ[longest_keyword][0]))
write(file)
X_min = np.min(X[idx])
assert nextafter(0, 1) - nextafter(0, 1) == 0
sys.path = sys.path[:4]
it = iter(it)
a = np.arange(10)
fig2 = plt.figure(figsize=(4, 4))
white = np.array([255, 255, 255])
pprint(offset_keys(dct, datetime.date(2015, 7, 12)))
self.print1()
cc = np.load(f)
wr = csv.writer(your_csv_file, quoting=csv.QUOTE_ALL)
besseli_vec = np.frompyfunc(mp.besseli, 2, 1)
plt.hist2d(new_x, new_y, bins=(50, 50))
decrypted = crypt_object.decrypt(decoded)
pygame.init()
resp
plt.plot(x, norm_vals)
clients += 1
p.start()
x, y = x + dx, y + dy
np.random.seed(1977)
p4 = ctypes.c_int(0)
y_growth_flips = np.where(np.diff(np.diff(y) > 0))[0] + 1
getattr(urlparse, method).append(scheme)
[5, 2, 2, 1, 4, 1],
my_user.save()
cv2.drawContours(close, [cnt], 0, 255, -1)
pool.join()
f = eval(s)
b.T
events = (a[0] + a[-1] + sum(a[i] != a[i - 1] for i in range(1, len(a)))) / 2
self.maps = maps
0, 1, [t]
menu = Menu(root, tearoff=0)
db_field.formfield(**kwargs)
test = [[0.0] * 10] * 10
b[:, (a)]
deleteposix
print(image.shape)
echo((foo + bar) * baz / (bar + foo))
scipy.stats.norm(100, 12).cdf(98)
printTree(tree, child)
findex.fromfile(f, 1)
args = parser.parse_args()
len(self.datatable.columns.values)
version[0] == 6 and version[1] == 0 and version[8] == VER_NT_WORKSTATION
ModClass.class_method()
f_new.close()
button.pack()
print(root.getprevious())
cr.set_source_rgb(1, 1, 1)
df1 = pd.DataFrame(data1)
split = shlex.split(s)
data = urlopen(info_url).read()
out.write(buf[0])
cyclic_equiv(a, b)
ctx.push()
inF.close()
uniq = list(OrderedDict.fromkeys(lst, 0))
False
count += 1
dtype.append((field, object))
c = Counter(list(d.values()))
numeral = numerals[numeral_index]
b = int(sys.argv[1])
partners = np.empty_like(X, dtype=int)
cv.ResetImageROI(newCanvas)
print(form.errors)
str(s)
wx.CallAfter(self.frame.Close)
repr(d)
print(network)
driver.maximize_window()
result
app.main()
_ROOT = os.path.abspath(os.path.dirname(__file__))
print((c.x, c.y, c.z))
t = threading.Thread(target=do_work, args=(work, results))
(10, [2, 5]),
print(m.group(1))
usernametoken.insert(uname)
self.delete(save=False)
plt.imshow(np.random.randn(100, 100))
df
print(a)
setattr(foo, generatedClass.__name__, generatedClass)
img[data[i, 0], data[i, 1]] += 1
a[1] = np.ma.masked
timeit.Timer(myTImedClass.square).timeit()
queue.put([e, traceback.format_exc(e)])
id(a[0])
obj.set_password(obj.password)
aapl_50ma = pd.rolling_mean(aapl, 50)
p = np.poly1d
result[k] = result.get(k, 0) + v
user_count = serializers.SerializerMethodField()
self.index += 1
f, x, y, z
qbtn.move(50, 50)
means = np.mean(complete_matrix, 1)
app.debug = True
df[cond1 | cond2]
generations.append(generations[-2] + generations[-1] - 1)
src = inspect.getsource(target)
self.assertTrue(element in self.seq)
self.transport.loseConnection()
a = models.ForeignKey(A)
result.append(p[:i] + [l[0]] + p[i:])
bind_layers(PPPoE_Tag, Padding, tag_type=0)
f.close()
mydict.setdefault(currentid, [])
suite.run(defaultTestResult())
dir(nodebox)
founds.append((inters, list_number1, list_number2))
cell.value = 2
assert a == b
self.renderer0 = gtk.CellRendererText()
asyncio.wait(self._set)
app.wsgi_app = LoggingMiddleware(app.wsgi_app)
fd, path = tempfile.mkstemp()
current += 1
self.tearDown()
L2 = [u, v, w], [x, y, z]
main()
event.fire(*args, **kargs)
self._q.put(self.o)
name = Column(String, primary_key=True)
df = df[df.apply(lambda x: x.A in x.B, axis=1)]
array2 = np.broadcast_to(array1, (20, 20, 2, 4))
min(lis2, key=func)
sys.stdin.read(1)
rlcn = RLCN()
hb1 = plt.hexbin(x1, y1, norm=norm)
sp.solve(lst)[0][x]
self.label = QLabel(self)
dis.dis(lambda : True == True != False)
find_common = lambda a, b: a.intersection(b)
elapsed = time.time() - now
p.join()
f2.close()
cls._bar = value
nhb if random.random() < p else x
y = ax.get_ylim()
self.index += 1
z.close()
meta.reflect(bind=someengine)
5 - +-+-+2
module = import_module(module_name)
a * 2.0
X = np.ma.masked_equal(X, 0)
1 << 100
address = models.ForeignKey(Address, blank=True, null=True)
print(author.first(), author.last())
which = numpy.array(list(itertools.combinations(list(range(10)), 2)))
uri, tag
[[(x + y) for x, y in zip(*row)] for row in zip(outgoing, incoming)]
y = y.reshape(-1, x.shape[0])
array = [random.uniform(1.5, 12.4), random.uniform(0, 5)]
foo(A(), A())
p = Process(target=MP_Stuff, args=(self, id))
p.map(worker, nums)
ilabel.grid(row=1, column=1)
print(mondays[-1])
items = list(some(**m) for m in dl)
self._conn = self._pool.get()
line = file_obj.readline()
out, err = process.communicate()
fp = webdriver.FirefoxProfile()
do_whatever_else()
connection.commit()
car2 = pygame.transform.rotate(car1, 20)
dudette = form.save()
foo * a + str(bar)
file.close()
__builtin__.object = orig_object
fig.colorbar(qmesh, ax=ax)
img.seek(0)
L[i] = L[idel]
proc.join()
z = np.outer(np.ones(np.size(lons)), np.sin(lats)).T
lines = np.empty((len(x_range) + len(y_range), 2, 100))
response = self.client.get(some_url)
tree = []
deleteself.z[-1]
print(platform.python_version())
print(r.text)
setCustomWidth(2)
result = []
x + y + z
traceback.print_exc()
el = fromstring(some_string)
[1.000051]
x.split()
print((key, list(grp)))
stdout, stderr = p.communicate()
c = np.concatenate((a, b))
driver = webdriver.Chrome()
doc = ET.parse(xmlfile).getroot()
pprint.pprint(zip(chain.from_iterable(expressions), results))
f(*args, **kwargs)
{}
p.map(e.op2, arg_list)
new_t = [names[item] for item in t]
my_list[7:10], my_list[2:4] = my_list[2:4], my_list[7:10]
new_lst = [sorted(sublist) for sublist in lst]
im = imclearborder(im)
dc = wx.WindowDC(window)
b.shape
xlim = ax.get_xlim()
cap1 = cv2.VideoCapture(1)
print(utc_date)
label = Label(window, textvariable=result)
np.trapz([-1, 0, 1])
item
spreadsheets_client.ProgrammaticLogin()
self._inner[index]
captcha = CaptchaStore.objects.all()[0]
self.update(*args, **kwargs)
loop = asyncio.get_event_loop()
moneyx = float(l)
df_list = [pd.read_table(file) for file in filelist]
main()
echoer.transport.write(data)
i += 1
end_ts = time.time()
composed
(vmax - vmin) * np.random.rand(n) + vmin
print(arr.columns)
df
avariable()
listtwo = [4, 5, 6]
session = requests.session()
my_urls + urls
M = np.random.rand(N * 10 * 10).reshape(N, 10, 10)
res = np.zeros(reslen, dtype=a.dtype)
obj = mlab.imshow(img)
nonzeroind = np.nonzero(a)[0]
self.panel.SetScrollbars(1, 1, 1, 1)
ii = np.where(a[:, (0)] == b.reshape(-1, 1))[1]
print(sorted(product(xs) for xs in itertools.product(*values)))
a.helloThere()
biglist[:] = unique(biglist)
A = 1e-07
rows.append(row)
rows = cursor.fetchall()
n = int(line)
self.renderer(name, str_value, final_attrs, choices)
np.set_printoptions(2, threshold=100, edgeitems=5, suppress=True)
1 - 1 - 1
[6, 6, 6, 6, 6]
covariance = np.diag(sigma ** 2)
a[:] = b
temp = [key, value]
leg = ax.legend()
horizontal = [img[int(h / 2), i] for i in range(w)]
self.assertEqual(2 + 2, 4)
L[:][1]
print(result)
output.write(chunk)
exit(0)
all_vars.update(globals())
width = 2 * np.pi / N
s.hist()
print(map(applyEpsilon, inputList))
print(lh.tostring(doc))
print(item)
a * np.exp(-c * (x - b)) + d
fullDict.setdefault(row[0], []).append(row[1])
h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)
Console.ReadLine()
X[mask1.nonzero()[0], mask2.nonzero()[0]]
sidx = a.argsort()
counts = np.diff(a.indptr)
request.user = User.objects.get(id=1)
set1 = set(array1)
death_year = death_data.get(1).value
end = time.time()
chunks = [bin_string[i:i + 6] for i in range(0, len(bin_string), 6)]
p.suspend()
height = len(data)
the_time = the_time.replace(second=0, microsecond=0)
runrec(new_src, level + 1)
inds = np.arange(A.shape[0])
r.div(r.sum(1), 0).plot.bar()
repr((self.name, self.grade, self.age))
x, y
fig = plt.figure()
n += 1
min(PlayerList, key=lambda p: min(p[1:]))
sum((xa - xb) ** 2 for xa, xb in zip(a, b))
x = np.random.random(10)
df
r = b * sympy.sin(c)
mro = inspect.getmro(self.__class__)
whereclauses = []
next(f)
plt.pcolormesh(gridx, gridy, grid)
df2 = pd.read_table(io.BytesIO(content2))
b.String()
self.render()
print(type(fh.read(100)))
x = [1, 7]
store.append(tabular_key, store.get(key), data_columns=True)
buf = f1.read(1024)
run_start = time.time()
data_pipeline.close()
closing(inner())
list(join_unescaped(list_1))
listStore = gtk.ListStore(int)
self.data
i += 1
a = [1, 1, 2, 1, 1, 4, 5, 6]
t1 = threading.Thread(target=thread1, args=(1, t1_stop))
x = linspace(0, 2 * pi, 20)
total = next(it)
app.update_template_context(context)
self.setResizeColumn(0)
soup = Soup(htmlFile)
signal.alarm(0)
self.n = 1
val = f.f_back.f_locals[x]
x[2], x[1] = x[1], x[2]
matplotlib.hatch.Shapes.__init__(self, hatch, density)
not sum([(not i in data) for i in data2])
df
self.flush()
forks.append(Fork(names, goal, success))
value
xs.sort()
r = np.random.randint(rows, size=100)
a, b = 0, 1
example()
loop.run_until_complete(user_func())
print(list(m))
sh.write(n, 0, v_desc)
kalman = cv2.KalmanFilter(4, 2)
W = W.reshape(8, 10)
Area2(a, b, c) == 0
raise NotImplementedError()
height, width = image.shape[0:2]
list(bcdDigits(characters))
x -= 0.5 * (bins[1] - bins[0])
[self.cousinitt(x) for x in self.gomez * n]
df.b.loc[s & (s != s.shift(-1))].tolist()
my_button1.bind(on_press=self.changer)
func
resultlist.append(M)
sklearn.feature_selection.f_regression(X, Y, center=False)
result = {}
items = [conv(val) for conv, val in zip(converters, vals)]
deletex
splitList.pop(0)
rgb_values.pop(i)
rc1f = np.ravel_multi_index(rc1, A.shape)
print(infer_spaces(s))
signal.signal(signal.SIGALRM, alarmHandler)
gevent.spawn(read_stream, p1.stdout)
decay_rate = 5e-06
exec(code, m.__dict__)
soup.original_1.body.append(b)
self.canvas.repaint()
myOjbect.doStuf().doMoreStuf(arg1, arg2).goRed().goBlue().die()
indices = list(range(N))
b = [4, 5, 6]
session = sessionmaker(bind=engine)()
print(network)
self.a()
item = item.lower()
df
app = QApplication(sys.argv)
seps
self.connections.append(self)
sentences.append(sentence)
print((val, ty.currentLevel()))
quantiles = numpy.array(quantiles)
record._cache.update(record._convert_to_cache(values, update=True))
k = i * len(b) + j
a[x] = a[x][1]
eday1.insert(10, 10)
arg in arg2value
xsgn = np.sign(x)
panel.SetSizer(sizer)
M = np.random.randint(2, size=(h, n))
index = clang.cindex.Index.create()
x.extend(item)
previous = [0] * len(criteria)
foo(parent2)
layout = QHBoxLayout(self)
Tools | SublimeREPL | Language
wd = webdriver.Remote(server_url, dc)
iseq = iter(seq)
lines = ax.plot(list(range(10)), pylab.randn(10), list(range(10)), pylab.randn(10))
root_logger.setLevel(logging.INFO)
len(frozenset(objs)) == len(objs)
grp = (isone != idx.to_series().diff().eq(1)).cumsum()
outdata = numpy.empty((5, 6))
files.finalize(zip_file)
count_helper(len(text) - 1)
df.index = df.index + pd.DateOffset(days=15)
assert a.average() == 5.5
username = Martin.Thoma
np.array(y)
db_list = insp.get_schema_names()
b = datetime.datetime(2015, 10, 29)
self.fig = pylab.figure()
l = list(map(itemgetter(0), g))
page = page[n:]
test2 = test1.astype(int)
endif
outfile.write(line)
new_instance.put()
total += 1
X = np.arange(-2, 2, dx)
splitext(path)
data = fin.read(end_index - start_index)
df.dtypes
thing.getSecret()
s.get_matching_blocks()[:-1]
logger.addHandler(handler)
sum += x
write_lamb(sys.argv[1])
print(x)
foo().baz()
response = requests.post(url, params=data, headers=headers)
tuple(l)
y[0]
print(df)
uniques[col] = uniques[col].union(chunk[col].unique())
text = first_td.renderContents()
q, r = divmod(q, l)
listSum(ls[1:], result + ls[0])
print(ignore_upper(a, skip_rows=1, skip_cols=2))
item.setEditable(False)
get_key(d, 10)
df
console.setFormatter(formatter)
NULL
created_at = models.DateTimeField(default=timezone.now)
any(map(my_dict.__contains__, my_list))
frame = sys._getframe()
a[get_x()]
df
y = np.array([1.5e-10, 1.5, 1500])
mask = np.random.random_integers(0, 1, N * M).reshape((M, N))
itit = iter(thedict.items())
carray[:5]
arr[:] = lst[:]
f.__setitem__(Ellipsis, 100)
s.bind((HOST, 0))
stsets = sorted(stset_string, key=len, reverse=True)
myLib.RegisterNofityCallback(45454, 0, self.getCallbackFunc())
print(list(find(l)))
print(item)
setattr(instance, self.name, min(self._max, max(value, self._min)))
when = models.DateTimeField(null=False, auto_now_add=True)
transf1d(f, x, y, out)
System.out.println(value.scriptResult)
QMainWindow(parent)
x.__reduce__()[1]
Counter(str1)
log_file.write(line)
a = A(b)
endif
signal.alarm(5)
parser.delete_first_token()
module
s.get(url)
frame = inspect.currentframe()
time2 = datetime.datetime.now()
plt.errorbar(x, y, yerr)
httplib.HTTPConnection.debuglevel = 1
L = [15, 16, 57, 59, 14]
ts = time.mktime(time.gmtime())
ax.imshow(data)
list1b = list[5:]
driver = webdriver.PhantomJS()
fig.savefig(fname, dpi)
Z1 = np.abs(np.sin(2 * X ** 2 + Y))
bins.append([min])
newImage.save(new_image_path)
fig.set_dpi(dpi)
-1
self.planet = Planet.EARTH
urllib.request.HTTPSHandler.__init__(self)
l = len(s)
wi.food(2.5)
len(empty)
output, error = someprogram.communicate()
connection.close()
df = xl.parse(xl.sheet_names[0])
node.start()
authors = stage2.findall(preliminary)
app.register_blueprint(main)
ol.add(1)
isinstance(result, (collections.Sequence, collections.Iterator))
groups.setdefault(key(sub), []).append(sub)
points = np.vstack([x, y]).T.reshape(-1, 1, 2)
xs, ys = zip(*sorted(zip(xs, ys)))
visited.add(path)
collections.Counter(df[0])
print(i[0], list(i[1]))
self.skipTest(MyTestCase)
1, 1, 0
count += 1
cov[(5), :] = np.arange(num_vars) ** 2
self.ui.setupUi(self)
1, 8, 8, 1
M = sparse.lil_matrix((10, 10))
app = QtGui.QApplication(sys.argv)
a.__class__
clientSocket.send(endmsg.encode())
os.remove(tmp_filename)
max_index = index
plt.imshow(image)
root.withdraw()
a * b
set(a)
self.username
print(result)
df.index.slice_indexer(start_remove, end_remove)
print(content)
p.apply_async(e.op1, arg_list)
mapper.SetScalarVisibility(1)
soup = BeautifulSoup(doc)
type(g._productions[-1])
stream.getvalue()
self.send_response(200)
groups.setdefault(len(e), []).append(e)
df[~df.stack().between(0.1, 1).unstack()]
assert is_palindrome(s)
np.abs(a[2] - a).max(axis=1)
K = abs(A - C) < abs(B - C)
print(stderr)
BaseHandler.__init__(self)
fn()
new_list = []
arr.fill(np.nan)
plt.figure()
t = np.arange(0, 40000, 4000)
print(model_tunning.best_params_)
main()
print(find_subimage(screenshot, subimg_path))
c = C()
img[:, :, (1)] = 50
print(id(text))
f = open(path)
img_data_ndarray = cv2.imdecode(file_bytes, cv2.CV_LOAD_IMAGE_UNCHANGED)
ax1 = fig.add_subplot(111)
is_file_like = not isinstance(fp, str)
minutes_id = models.IntegerField(blank=True, null=True)
d = d.month + 1
arr[slices]
self.value = value
_wrapper
connection.start()
s.listen(10)
_authentication_required
logger = sc._jvm.org.apache.log4j
dingo
f
xstring = infile.readlines()
selected_item = self.main_window.widget_layers.selectedItems()[0]
model.load_weights(weights_path)
n - 1
settings.py
filename = os.path.splitext(os.path.basename(sys.argv[0]))[0]
block = f.read(bufsize)
copytree(srcname, dstname, symlinks, ignore)
fig.colorbar(surf)
print(C())
f.close()
os.linesep
a = np.arange(1000)
cls.open_files()
pdb.set_trace
type(z)
fp.close()
print(pool.map(f, list(range(10))))
print(word)
p[0] > p[1] > p[2]
result
idx = np.where(a[i] > 0)
data = source.get_data()
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
type(name, bases, new_dict)
any(x % 2 == 0 for x in mylist)
rec_dd = lambda : defaultdict(rec_dd)
img = PIL.Image.open(file_like)
foo.__code__.co_consts[1].co_consts
print(item)
CD, BF, BE, BC, BD
2, 2, 2, 0.1
grpA = np.empty(mask.shape)
query = query.filter(table_a.id == table_b.id)
print(itertools.__doc__)
myFunc(2)
related_classes = [prop.mapper.class_ for prop in relation_properties]
data2[(0, -1), :] = np.nan
result = match.group(1)
p = Process(target=editDict, args=(mlist[i], mlist, i))
name in dir(__builtins__) + kwlist
children = {}
data = df.loc[(mask), :]
self.a = a
im = ImageGrab.grab()
type(k)
x[-1:4, -1:4]
np.allclose(a[:, :, :, (0)], collapse_dims(a)[:, :, 0:2])
current_dt = datetime.datetime.now()
sorted_a = a[np.argsort(a[:, (1)])]
self.axes.draw_artist(self)
image = Image.open(source_path)
table = [[(0) for x in range(count)] for x in range(count)]
sieve = [1, 1] + [0] * (R - 1)
first_list = []
pdb._runscript(mainpyfile)
main()
valid_utf8 = False
np.bitwise_or.reduceat(m, ind.ravel())[::2]
a[1:4]
firstName = db.StringProperty()
b
next(lines)
point[0] + k * vec[0], point[1] + k * vec[1]
print(time.clock() - start)
timer_thread = Thread(target=start_timer)
response = urllib.request.urlopen(urllib.request.Request(self.pubmed_url))
fW.write(y)
self.verbosity
self.log.removeHandler(handler)
regressions = np.polyfit(X, A2, degree)
[X, Y] = meshgrid(x, y)
myseries_two.loc[0:2]
form = form_class(data)
--start
list = []
file_content = f.read(1)
sys.exit(app.exec_())
exit(0)
DOT11_CIPHER_ALGO_CCMP = 4
c[0].set_color(time_color)
result = cv2.warpPerspective(img2, Ht.dot(H), (xmax - xmin, ymax - ymin))
zsum, areasum
W_o = tf.Variable(tf.random_normal([num_units, input_size], stddev=0.01))
time_tuple = dt.timetuple()
res = [dict(zip(res1, t)) for t in zip(*list(res1.values()))]
data = line.split()
self.assertGreaterThan(len(foo.config.mock_calls), 0)
s = list(iterable)
vmax = max(map(lambda x: max(abs(x)), data))
field = QtGui.QLabel(text, self)
response.url
pool.join()
dict(zip(spec.args[-len(spec.defaults):], spec.defaults))
s[pd.isnull(s)] = n
nmask = sparse.csr_matrix(~mask.A)
ax = fig.add_subplot(1, 1, 1)
time.sleep(0.25)
delta = numpy.eye(5)
self.c.set(SERV_SECTION, SERV_DESC, SERV_DESC_DEFAULT)
dir(string)
gd_client = gdata.photos.service.PhotosService()
b.ques_type
jar = Cookie.SimpleCookie()
results = mysql_cursor.fetchone()
ax1 = fig.add_axes([0.05, 0.8, 0.9, 0.15])
compose(compose(f, f), f)
a, b = tee(iterable)
plt.hold = True
ax = plt.axes()
preview = Preview()
t2 = datetime.now()
ax = fig.add_subplot(n_rows, n_cols, n + 1)
name = self.aliases.get(name, name)
print(df)
s = requests.Session()
item.save()
inspect.getargspec(foo)
response
sys.exit(segmentation.exec_())
df = df.join(s)
p.pop()
locals().update(f())
pylab.show()
dtoff = datetime.timedelta(days=1)
print(root_tree)
f = lambdify(t, a)
gmaps = GoogleMaps(API_KEY)
login(self.request, new_user)
x = 1.2876
print(sline[-1])
self.left = []
kernel /= kernel.sum()
list_result
form = FooForm
self.response.out.write(template.render(path, template_values))
y = np.arange(100).reshape(10, 10)
p = Pool()
output_lambda = df.apply(lambda x: [x.value_counts().to_dict()])
sqrt(v1[0] ** 2 + v1[1] ** 2 + v1[2] ** 2)
list(d.items())
django.db.transaction.managed(True)
plt.figure()
NULL
ax.yaxis.get_major_locator().base(2)
print(lst[0])
ceiling_key(d, 6)
po.apply_async(mine_page, (filepath,), callback=save_data)
ranks1 = dict(map(reversed, enumerate(sorted(dict1, key=dict1.get))))
s = np.argsort(ab)
form.instance.author = self.request.user
_get_elements_by_tagName_helper(node, name, rc)
by_val = [(v, list(ks)) for v, ks in itertools.groupby(keys, shaders_dict.get)]
index = self.get_index()
overlay_pic.close()
PyErr_Print()
self._var0 = val
transitions = transitions + array[0] + array[-1]
tk.LabelFrame.__init__(self, root, **options)
pprint_on()
matches = {}
imgx, imgy = REGION.max.x + 1, REGION.max.y + 1
getattr(obj, attribute)
atexit.register(cleanup)
__init__.py < ---empty
location_out = list(splot(location_in))
arr = random.random(N)
product(L[1:], tmp + [i])
print(random.choice(verb_list))
x = np.arange(1, 15.1, 0.1)
newclass = getattr(amodule, classname)
setattr(self, member[0], withx(member[1]))
a = np.argsort(dist, axis=1)
ex.show()
l._legmarker.set_xdata(l._legmarker.get_xdata()[1:2])
not sys.stdin.isatty
fff(index)
timezone.utcoffset(dt)
description = models.TextField()
show()
id = Column(INTEGER, primary_key=True)
tmp.seek(0)
args = parser.parse_args(args, namespace)
path = os.path.join(root, fname)
current_base = len(rest_digits)
id_s = {c: i for i, c in enumerate(set(list))}
graph.add_edge(node_number, random.choice(graph.nodes()))
np.log2(x)
dow = my_date.weekday()
{{your_python_data | as_json}}
x + y
self.timer.start()
file_like_io.seek(0)
plt.ion()
A = np.random.random_sample(10000.0)
screen.nodelay(False)
ctx.move_to(-x_bearing, -y_bearing)
cax = fig.add_axes([0.12, 0.1, 0.78, 0.8])
type(myObj)()
colmax += i
file.close()
result = rec(a)
stream.close()
CHECK_RE.match(mystring)
result = np.vectorize(operator.le)(lhs, rhs)
accounts = [Account(x) for x in user_list]
slice(0, 0, 1)
zip(*([chain(iterable, repeat(padvalue, n - 1))] * n))
X, Y = np.meshgrid(x, y)
str(self.contract)
task = AsyncResult(task_id)
pdb.gimp_image_delete(image)
df.a = df.a.astype(float)
draw.text((10, 25), txt, font=font)
matches = list(filter(fulfills_some_condition, lst))
False, False, False, False, False, False, False, False, False
self._store_aggregation_timer.cancel()
self.append(self._fx())
x = plot(t, x)
lock = threading.Lock()
svc.fit(X_train, y_train)
z_indices = indices[2]
simulation_params = simulations.get()
newdata = json.loads(myData.text())
start = time.time()
print(line)
self.SetBackgroundColour(wx.Colour(0, 0, 0))
city = models.CharField(max_length=75)
buff = StringIO.StringIO()
new_list1 = [v[0] for v in decorated]
print(i)
name_value_dict = dict(itertools.zip_longest(names, values))
print(urllib.parse.urlencode(params, True))
df = df.set_index(index_name)
tableWidget = QtGui.QTableWidget(10, 2, self)
print(df)
find(query)
app.setQuitOnLastWindowClosed(False)
oldstdout_fno = os.dup(sys.stdout.fileno())
c.setopt(c.HEADER, 1)
x = int(input())
c = Counter([letter for letter in message if letter.isalpha()])
cursor = dbapi_conn.cursor()
self.clients.remove(client)
cv2.circle(out, (int(x2) + cols1, int(y2)), 4, (255, 0, 0), 1)
chrome = webdriver.Chrome(chrome_options=chrome_options)
sorted_files_with_size = sorted(files_and_sizes, key=operator.itemgetter(1))
f.writelines(res)
shortcut.save()
old_stdout = sys.stdout
pairwise = np.empty((n, n), dtype=np.float)
link = f.read()
logging.debug(pprint.pformat(ds))
self.size += 1
num *= 1
deque.extend(words[:n - 1])
self.newText.tokens.clear()
dll_excludes = w9xpopen.exe
q.put((key, count))
fp.close()
formset = WorkoutInlineFormSet(instance=workout)
plt.semilogy(x)
im2 = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
s = socket(AF_INET, SOCK_DGRAM)
set(c) < set(b)
print(adam)
self.driver = WebDriver(firefox_profile=profile)
x.run()
count = 1
proc = pool.apply_async(processfile, args=[filename, cursor, end])
rng2 = reikna_norm_rng(1, 100, 10000, 0, 1)
print(key)
v = [random.gauss(0, 1) for i in range(0, n)]
matcher = difflib.SequenceMatcher(a=string_a, b=string_b)
True
Base = declarative_base()
message = models.CharField(max_length=100)
{{formset.management_form}}
value
logger.addHandler(stream_handler)
raise
Py_Finalize()
particle.speedy = int(circle.speedy)
self.data += [val]
exec(fh.read())
f.__code__ = g.__code__
print((x, timeit.timeit(lambda : h.update(data), number=100)))
new_row = temp
mat = pat.search(os.path.split(x)[-1])
inds = np.where(np.isnan(a))
5.8
fig.canvas.manager.window.raise_()
myList = []
self, self.__class__(other)
resp = make_response(f(*args, **kwargs))
searchable_file = FileSearcher(file_to_search)
getcontext().prec = 6
job.hour.every(4)
png.load()
pprint(get_connection_name_from_guid(x))
x.extend(compress(a, a))
test.eval.restype = ctypes.c_double
t.write()
ax.set_ylim(bottom=0)
driver.get(url)
bucket = conn.get_bucket(bucket_name)
ax.yaxis_date()
row_pointers = Ks.indptr
env.use_ssh_config = True
signal.alarm(0)
code_out = StringIO.StringIO()
sline = i.split()
plt.clim(-4, 4)
v = tk.StringVar()
s[-2:]
[0, 0, 2, 1]
fig = plt.figure()
y = a * t ** alpha + b
page = br.open(base_url, timeout=10)
logger.setLevel(logging.INFO)
plt.show()
server.serve_forever()
A = np.asarray(AList)
df = pd.DataFrame(s, columns=heirIndex)
cache[key] = fun(*args, **kwargs)
self._logger
exit()
pyplot.gca().add_line(line)
print(overall_structure.parseString(test).asList())
output = list(range(input + 1))
xi = np.linspace(xmin, xmax, numx)
result = [(x + [y]) for x in result for y in pool]
print ()
print(os.path)
y1.append(random.randint(1, 100))
csv_w.writerow(columns)
register_openers()
fig.colorbar(surf, shrink=0.5, aspect=5)
list((y - x).elements())
d = defaultdict(list)
df
setattr(self, key, value)
fig.set_size_inches([5, 5])
result.append([])
intArray_getitem(mylibrary.V, 0)
app = Flask(__name__)
local_dt = datetime.fromtimestamp(expiration_utc_ts)
__getitem__ = object.__getattribute__
k = k.parent()
x = etree.fromstring(body)
i += 1
os.chdir(file_path)
CS = plt.contourf(xi, yi, zi, 15, cmap=plt.cm.rainbow, vmax=zmax, vmin=zmin)
deletesprocket
glLoadIdentity()
mkstring(10)
sorter = numpy.argsort(values)
[a] + li
integer = int(str_dec)
self.dealloc_cb_p(self.p, self.l, self.dealloc_cb_arg)
arr[:, 1:] = float(10)
db_crsr.execute(_stmt)
df = PD.concat(data, axis=1, keys=[s.name for s in data])
t = np.linspace(0, 2 * np.pi, 100)
print(myfun(l, 0))
nlargest(1).reset_index()
id = ndb.ComputedProperty(lambda self: self.key.id())
table = {}
grouped = df.groupby(lambda x: x.day)
root = lh.tostring(sliderRoot)
x2 = np.random.permutation(100000)
fit0 = so.curve_fit(model0, xdata, ydata, p0=(p1, p2))[0]
html_parser = HTMLParser.HTMLParser()
self.send_response(200)
t1.join()
where = [m.start() for m in re.finditer(sub, string)][n - 1]
self.msgs.add(record.msg)
time.sleep(0.2)
dictonary = dict((i, []) for i in drug_list)
Py_DECREF(myfunc)
print(result)
fileHandler.setFormatter(format)
s[4:6]
s = [item.capitalize() for item in s]
plt.imshow(data)
mySet = set()
stdin = sys.stdin.read()
self.data = {col: set() for col in columns}
str(my_uuid)
t = datetime.now()
full = np.random.random((1002, 1004))
headrev = revlog[0].revision.number
plt.ylim(1e-06, 1)
letters.lower() in ascii_lowercase
parser = argparse.ArgumentParser(description, usage)
test(0, 10, 20)
result = re.sub(pattern, substitute, string)
print(df.loc[mask])
data = list(reader)
new_stepListB.extend([pathList[n][0], pathList[n][2]])
t = my_date.weekday()
inv = ax.transData.inverted()
objects = models.GeoManager()
B = np.where(np.isfinite(A), A, f(inds))
G.add_nodes_from(rank_of_nodes)
print(a, b, c, d)
n, remainder = divmod(n, 10)
fig, ax = plt.subplots()
okays = [r for r in results if success_condition(r)]
devnum = 10
df
json_str = json.dumps(json_object, indent=4, sort_keys=True)
globals()[name] = some_decorator(getattr(some_module, name))
a_set = set()
cache_file = os.path.join(__cache_dir__, cache_key)
something.jpg
print(user.screen_name)
init_op = tf.initialize_all_variables()
req = con.getresponse()
img = Image.open(infilename)
color_bar.draw_all()
MyTimeDelta(hours=12) / MyTimeDelta(hours=2)
region_dict[a.region].append(a)
datetime.timedelta(**{interval_type: interval_num})
r(a[:i] + m + a[i + 1:])
iw, ih = img.getSize()
df_possible_dup.apply(lambda x: worker(x, fuzz_ratio))
self.currentStack = []
app.request_class = MyRequest
foo.mymethod = mymethod
xv, yv = np.meshgrid(x, y)
brr = brr[::-1]
result = tuple(islice(it, n))
ctr = Counter(frozenset(x) for x in a)
df
choice = get_input()
exns = []
tck = interpolate.splrep(x, y, k=2, s=0)
master = Tk()
0
text_file.seek(os.path.getsize(filename) - len(os.linesep))
self.set_val(val)
print(new_list)
b = a
x, y, w, h = cv2.boundingRect(c)
django.setup()
lock.acquire()
fit_result[-1]
deleteself._cache[self._job]
my_array[my_array > 255] = 255
cw.writerow(one_line_of_data)
thefile.seek(0, 2)
im.set_data(data)
np.allclose(a[:, :, :, (1)], collapse_dims(a)[:, :, 2:4])
print(x, y)
ln - s / proc / self / fd / dev / fd
y()
writer.writerow(data)
x, y = l.split()
list(range(5))[4:5]
outputPDF = PdfFileWriter()
False
self.axes.set_ylabel(ylabel)
a.foo()
print(list(merge(times)))
inputfile.close()
time.sleep(2)
newList = []
np.dot(mX.T, logit(mX, vBeta) - vY)
i = Image.open(StringIO(r.content))
vect = TfidfVectorizer(vocabulary=emoticons)
cwd = os.getcwd()
self.draw_figure()
decorator
app.Documents.Open(word_file)
ax.add_collection(lines)
print(list(spamreader))
image_without_exif.putdata(data)
workbook.Close()
zerostr(s)
start()
base_parser = argparse.ArgumentParser(add_help=False)
np.median(rdd.collect()), quantile(rdd, 0.5)
print(sys.argv)
zip_longest(fillvalue=fillvalue, *args)
y = np.random.random(10)
s += x
Color(255, 255, 255)
anadict.sort()
d2 = datetime.datetime.strptime(d_string, fmt)
c = a.astype(float).cumsum()
glLoadIdentity()
cout = np.empty_like(arr)
shutil.rmtree(dirname)
accmask = np.cumsum(mask, out=mask, axis=1)
f.close()
(np.diff(np.sign(data)[np.nonzero(data)]) != 0).sum()
self.all_items.add(item)
dict(zip(I, I))
[pypi]
print(find_matches(im_haystack, im_needle))
df.shift(1).min(1),
coords = np.stack(np.meshgrid(*args), axis=-1)
fig, ax = plt.subplots(1, 1)
dct = dict(splt(item) for item in lst)
test_login()
module = sys.modules[thing.__module__]
loss(y, y_pred)
next_link.__class__.__name__
is_even = generate_is_even(reject_zero)
c_double_p = POINTER(c_double)
argmax = lambda keys, func: max(map(lambda key: (func(*key), key), keys))[1]
i.save()
handle.write(sort_by)
menu.appendItem(fileItem)
o.first_item()
env = Environment(ENV=os.environ)
app.mainloop()
print(x)
[int(item == max_val) for item in my_list]
output_logger.error(line)
result = {}
dset.resize(row_count + chunk.shape[0], axis=0)
x0, y0, z0, w0 = np.rollaxis(quaternion0, -1, 0)
round_to_1(19)
new.append(num)
p.map_async(f, [slice(stop_f)] * M)
coo = coo_matrix((data, (row, col)))
print(a.value)
1062, 1062, 1062, 1062, 1062, 1125, 1000, 1125
sess.run(train, feed_dict={X: batch[0], y_: batch[1]})
a = b
h[a, b, c].append(value)
log.start(loglevel=log.DEBUG)
daemon.restart()
out = optimize.leastsq(errfunc, pinit, args=(logx, logy), full_output=1)
nk = min((k for k in self), key=lambda k: NearestDict.__dist(key, k))
now()
x = df[cols].ix[0] > 0
d = date(year, 1, 1)
self.func
plt.draw()
list(thedict.keys())
age = int((date.today() - birth_date).days / days_in_year)
HttpResponseRedirect(reverse(contact_details, args=(new_contact.pk,)))
normalizedscores[u] = float(l) / maxscore
{{inner2()}}
os.close(fd)
fig, ax = plt.subplots(1)
inds = np.ones(rng[-1], dtype=np.int)
ax = fig.add_subplot(111)
a.__dict__
result = []
[]
Second / Third / Fourth / Fifth
d = {}
restart()
url = urljoin(response_url, url)
move(y, x)
myDict[key] = 10
ax = fig.add_subplot(111)
type(cls.__name__, tuple(classes), dict(cls.__dict__))
print(X[0], Y[0], calc_slow(X[0], Y[0]))
solns7 = solve(smin, smax, coef1, coef2)
print(checksum, hex(checksum), chr(checksum))
lemmas = set(chain.from_iterable([word.lemma_names() for word in synonyms]))
files = [os.path.join(os.getcwd(), f) for f in files]
printFoo()
print(mm.filled(np.nan))
sleep(random.randint(10, 1000) / 1000.0)
assert ceil_dt(t7) == t7
main.show()
NULL
root.mainloop()
colors.remove(c)
cursor.execute(query, station_id=id)
result = []
print(line)
opener = urllib.request.build_opener(handler)
total / (len(items) - 1)
b = np.zeros((nx, nz))
q.join()
o.close()
x = np.array([6, 1, 7, 6, 9, 0, 8, 2, 1, 8])
print(fmt.format(*container[0]))
a = numpy.random.random(100)
state = self.__dict__.copy()
numpy.vstack([test, test[::-1]])
htmlcolor(0.1, 1.0, 0.9)
self._filename = filename
teams = collections.defaultdict(list)
[2]
soup = BeautifulSoup(html)
rand_index = random.randint(0, len(graph[unmatched_woman]) - 1)
unmanhattan = manhattan.envelope.symmetric_difference(manhattan)
root = Tkinter.Tk()
sum(i != j for i, j in i.izip(s_1, s_2))
name = models.ForeignKey(School)
self.process.terminate()
pool = list(Content.objects.all())
columns = line.split(column_separator)
autorestart = true
autostart = true
f.close()
colors = [(0, 0, 255), (0, 255, 0), (255, 0, 0)]
tableWidget.setRowCount(len(entries))
instances = formset.save(commit=False)
tentativeLength = len(json.dumps(row))
x.add_row(row)
print(e.args)
list(common_entries(da))
end = datetime.datetime(2009, 2, 10, 16, 0)
ea = LinearRing(a)
a = [somestuff]
cv.GetQuadrangleSubPix(image, output_image, map_matrix_cv)
assert isinstance(v, str)
b[i] += x[i]
value &= ~(1 << 10)
name = models.CharField(max_length=100)
src_geotrans = src.GetGeoTransform()
ptw = fR.tell()
mls.geom_type
df.values[mask] = s[s.index.searchsorted(df.index)].repeat(mask.sum(1))
fig = plt.figure()
deleteresult[-1]
output.append(s)
ax1.plot(np.array([1, 5]) * i, label=i)
libc.syscall(186)
sum(cents_list) == 500
nx.draw(G)
math.atan2(0.0, 0.0) == math.atan2(-0.0, 0.0)
type(y[0])
self.counter += db.run_in_transaction(_tx)
dates1[mask]
labels = np.arange(1, num_labels + 1)
therest.append(para)
unrooted_paths.append(path)
y = np.ravel(B).reshape((9, 1))
d[k] += int(v)
triang.vertices
map(csv_writer.writerow, json_dict[entity])
ax2.set_ylim(0, 1500)
fig = plt.figure()
ax = fig.add_subplot(111)
ax.add_patch(p)
print(request.error_code)
1
pool.join()
deletedict_del[k]
m_normalized = m / m.sum(axis=1).reshape((m.shape[0], 1))
df
result.append(c)
linspace_x = np.linspace(x_range[i], x_range[i], 100)
result.append(position)
predictions = results.predict(data[half:])
profile_text = pattern.search(script.text).group(1)
cert.decode(der)
True
lookup = collections.defaultdict(list)
sys.stdout.write(frame.tostring())
self.__dict__ = somearg.__dict__.copy()
os.makedirs(dir_name)
memory = defaultdict(list)
i += 1
increment()
(t[0], ()) + t[2:]
days_in_month = calendar.monthrange(start_date.year, start_date.month)[1]
func
filename[len(root):].lstrip(os.path.sep).lstrip(os.path.altsep)
aList[i] = 0
stars = set(random.sample(range(n + k - 1), k))
date_before_leaps - timedelta(seconds=leap(date_before_leaps))
C[x, y, z] += A[x1, y1, z1] * B[x2, y2, z2]
a[:] = [(x + 2) for x in a]
print(tags)
takewhile(bool, (list(islice(stream, size)) for _ in count()))
f(add, 10, 7)
axis(2)
is_separately_linear(eq1, [a, d])
result = cv2.matchTemplate(image, template, method, mask=transparent_mask)
tornado.auth.TwitterMixin.get_authenticated_user(self)
print(username)
oba.name
target.append(idx)
data = clientsocket.recv(1024)
count += 1
iB = 0
glLoadIdentity()
self._mod.__dict__[attrname]
h1 = hyst(y, -0.5, 0.5)
resp = json.loads(json_str)
rdr = csv.reader(source)
temp = {v[1]: ([k] + v) for k, v in list(rays_starters.items())}
_mkdir(miniature)
df
blockwise_times.append(best)
D = L1[0] * L2[1] - L1[1] * L2[0]
PyEval_InitThreads()
f[0].data
student = form.save(commit=False)
a = np.random.random_integers(low=0, high=1 << 10, size=2 * n).reshape(-1, 2)
endfun
posn = ax.get_position()
img.im_feeling_lucky()
vertices.clear()
self.ser.read()
os.killpg(pro.pid, signal.SIGTERM)
hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
y = (x + 1) // 2
self.master.bell()
root.mainloop()
values.append(float(value))
a.remove(b)
people = Person.objects.all()
m = X.mean(axis=1, keepdims=True)
t = TestClass()
poly = GeoSeries([Polygon([(0, 0), (0, 2), (2, 2), (2, 0)])])
out = np.zeros(x.shape, dtype=int)
data = []
match = re.search(regexp, str)
datarows.append(row)
body_content = message.body
print(get_nesting_level())
heapq.heappop(heap)
{{docimage.image.url}}
xi = np.linspace(0, 5, 10)
12568
df
dict(ChainMap(*ds))
x[x < 0] = new_value_for_neg
unique_rows(a)
self.foo = 5
d_next += datetime.timedelta(weeks=1)
indexes = np.arange(len(labels))
my_list.append(abe)
self.request_log.append(suffix)
predicted = classifier.predict(X_test)
result = []
open_cv_image = numpy.array(pil_image)
self.nesting = 0
z = numpy.array([[0.1, 0.1, 1.0], [1.0, 0.1, 0.09], [0.1, 1.0, 0.2]])
dct = OrderedDict()
self.show_progress(test_progress_bar.value)
print(b[0])
print(frames_to_timecode(26))
df
encoded = base64.b64encode(cipher.encrypt(msg_text))
grandFather.removeChild(father)
setattr(obj, k, v)
ipaddress.ip_address(ipv6)
x = 1
id_counter = Counter(dct.get(k) for dct in my_list)
a.flat[idx]
self.datadex = {f: (42) for f in foo}
self.parent.iadd_x(val)
f(**{kw: True})
t.daemon = True
decorator(method_or_name)
br = mechanize.Browser()
name_son1.parents_backref.append(name_father1)
timediff = datetime.datetime.now() - time_posted
s = p.stdout.readline()
destination_ou.com_object.MoveHere(str(user.as_string()), str(user.Name))
A[:, (second), (third)].flatten()
time.sleep(x)
y = numpy.random.rand(2)
x, y = intersections(a, b)
err = random.randint(0, 4)
print(x[0])
Dx = L1[2] * L2[1] - L1[1] * L2[2]
result = ImageOps.colorize(gray, (0, 0, 0, 0), color)
cax.get_yaxis().set_visible(False)
s[1:] + s[:1]
xs = s.strip()
matplotlib_fig = plt.figure()
UTF - 8
a180 = a[..., ::-1, ::-1]
c = pymongo.MongoClient()
field1 = models.TextField()
seq[:i], seq[i:]
audio.add_picture(image)
root = Tk()
lambda x: func(rec_func(x))
ends = np.hstack((nonoverlapping, [-1]))
entries = nltk.corpus.cmudict.entries()
dict(message=message)
x_max = xs.max()
s1.is_valid()
foo.method(2)
a[5:7]
s = np.cos(t)
y[1] = 4
formatted = [[format(v) for v in r] for r in m]
exch(k, k / 2)
device.send_command(CMD_BLINK, 100)
message = messages.GetFirst()
content = self._request.read()
cb = plt.colorbar(p, shrink=0.5)
tr2 = np.fft.rfft(in2, n)
result = self.output.getvalue()
outfd, outsock_path = tempfile.mkstemp()
count = 1
ax1 = plt.figure(1).add_subplot(211)
k = json.loads(j)
print(f.data)
binplace = np.digitize(avgs, bins)
masked_diff = np.ma.masked_array(diff, mask)
x = np.linspace(0, np.pi, 100)
config_parser.read(config_files)
parser = argparse.ArgumentParser()
df
process1.wait()
df
print(check_for_triangle(tri1, lines))
p.join()
frame.f_locals.clear()
form = MyForm
self.log.SetBackgroundColour(self.bgColor)
[Request(x, callback=self.parse_link) for x in links]
print(line)
result = []
batch.delete()
groups[len(e)].append(e)
address = models.ForeignKey(Address)
result.append(sorted_intervals.pop())
meta = MetaData(bind=engine)
data = Column(String)
y[:, (0)] = 0
Xcum[(t - H), :] = np.sum(X[t - H:t, :], axis=0)
buffer = cStringIO.StringIO()
timerthread[0].cancel()
print(a, b, c)
x_min = xs.min()
its = [iter(l) for l in lists]
rlist.append(tuple((k, tuple(gg[1:][0][0] for gg in g))))
print(df)
print(data)
time.timezone
signal.connect(self._checkSignal)
print(img_tf.get_shape().as_list())
self[key] = self.__class__()
active = models.BooleanField(default=True, editable=False)
last_value = 0
C[:, :, (0), (0)] = a[:-1, :-1]
m[i] = int(row[0]), int(row[1])
arry.append(-1)
a = [1, 0, 0, 2, 0]
print(L)
s.connect((host, int(port)))
[argv[i] for i in range(start, argc.value)]
theclass = TheClass()
df2
decoded_string = base64.b64decode(encoded_string)
response
print(datetime.datetime.now())
x[0]
L = [1, 2]
self.dataobj = dataobj
name, extension = os.path.splitext(self.file.name)
aux = matriz[:]
foo = df.groupby(level=0).mean()
serializer_class = EstablecimientoSerializer
-Evan
fields
displays = (wx.Display(i) for i in range(wx.Display.GetCount()))
p[:i] + [l[0]] + p[i:]
d = pd.DataFrame(randint(1, 10, (n_rows, 8)))
print(repr(process_line(line).strip()))
list2 = np.zeros(len(lis))
i += 1
attrnames.append(name)
min_distance = min(min_distance, distance(p0, p1))
baseFile = os.path.basename(url)
SSL_CTX_set_options(ctx, flags)
abc = myFunction
response
b.int
addresses = session.query(address_table).filter(address_table.c.retired == 1)
doctest.testmod()
(person for person in self.__pList if person.match(**kwargs))
df_l.append(pandas.DataFrame([val], index=MI))
dx_intersect = -dx / (z[1:] - z[:-1]) * z[:-1]
sess = tf.Session()
df_stops = df_stops.reindex(full_index, fill_value=0)
plt.show()
2 * 11 - (2 + 10)
dna.lstrip(string.uppercase)
doc.close()
dict[1] = a[0]
settings.INSTALLED_APPS += app_name,
plt.yticks(list(range(nrows)), row_labels)
B = np.zeros(A.size)
self.text.append(data)
cell_format = self.workbook.add_format(cell_format_dict)
next(next_lines)
wsgi_app = create_your_wsgi_app()
img = Image.open(imlist[i])
_kls = Klass()
x = [x]
print(ax.get_xticks())
self.func = func
f1.close()
item
m.groups()
arr = coo_matrix((data_f, (row_f, col_f)), df.shape, dtype=np.float64)
np.random.seed(1)
cnxn = pyodbc.connect(databasez)
False
a + b
arr.append(inner)
coupler = (idx for idx, (x, y) in coupled_idx if x != y)
s2 = pd.Series(new_items)
result = np.reshape(result, (chunk_length, channels))
L[i] = result
result = MyTask.AsyncResult(task_id)
date = datetime.strptime(date_string, fmt).replace(tzinfo=tzinfo)
round(2.500000001)
pid = os.fork()
coll = db.test_collection
df = pd.read_csv(filename[0])
keyPub = RSA.importKey(keyDER)
print(df)
q.put([list(range(200)) for j in range(100)])
createIndex(sourceIndex.row() + 1, sourceIndex.column())
print(value)
a = Foo()
body = f.read()
print(args.foo)
parser = argparse.ArgumentParser()
pattern = np.ones(N, dtype=int)
time.sleep(4)
Nj = f.shape[1]
second_largest([10, 7, 10])
x_mid = xs[:-1] + np.diff(xs) / 2
t.join()
my_dict = recursively_default_dict()
f.show()
c = getattr(cls, c)
imgray = cv2.cvtColor(aframe, cv2.COLOR_BGR2GRAY)
QAbstractTableModel.headerData(self, section, orientation, role)
buttonwin = tk.Frame(root, width=75, height=500)
print(stdout)
mem.Blit(0, 0, size[0], size[1], screen, 0, 0)
f = Foo()
image = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)
circle1.destroy()
trace.text = str(a_numpy_array)
f.close()
self.a.b.c = 10
self.lda[self.tfidf[bow]]
[0, 0, 1]
0 < ------------------------------------8 < -9
myDict = defaultdict(int)
test_printFoo()
Y[..., (2)] = np.clip(np.abs(X) / absmax, 0, 1)
b[-1] = b[0] + b[1]
now - then > timedelta(days=1)
plt.scatter(x, y, c=z)
m.drawcountries()
s.getvalue()
keys = [i.strip() for i in keys]
result.extend(v * v for v in vals)
p.join()
g()
self.z = z
Z2 = np.abs(np.cos(2 * Y ** 2 + X ** 2))
remove_common(x, y)
1 - 1
last = MyModel.objects.count() - 1
sigma = np.matrix([[20, 10, 10], [10, 25, 1], [10, 1, 50]])
ax = fg.add_subplot(1, 1, 1)
scores.append(subcheckio(nstones, left, rite + stones[0]))
plt.title(date)
ct = ContentType.objects.get_for_model(GRmodel)
Image.open(strio)
raise ndb.Return(True)
df
[(letter, matches.count(letter)) for letter in letters]
dill.dumps(f)
self.rect = Rectangle()
parser.print_help()
f(2, range(5))
pprint(get_info(soup.li))
self._rooms.clear()
x, y, z = np.ogrid[-10:10:20j, -10:10:20j, -10:10:20j]
a = []
self.value = value
1 - 10
{{form.content}}
{{form.as_p}}
a = []
linecache.clearcache()
-betaln(1 + n - k, 1 + k) - np.log(n + 1)
matches = tokens[1::2]
a_label.pack()
print_tree(tree)
self.response = app.get(*args, **kw)
print(type((1,)))
print(s.strip())
p = Popen(shlex.split(job), stdout=PIPE)
self.wordList = list(wordList)
print(f.read())
[(x + (z.get(x[0]),)) for x in l]
y_mean = np.mean(y, axis=1, keepdims=True)
foo(A(), B())
list_size_2 = []
p.map(f, itertools.chain(((0, x) for x in females), ((1, x) for x in males)))
formfield.queryset = Cars.objects.filter(owner=person)
b = a.copy()
np.count_nonzero(np.eye(4))
table.style = style
classifier.predict(datum)
prodmap[:] = np.memmap.dot(xmap, ymap)
plt.plot(a)
Qt / QtGui / __init__.py
df
foo().wrong
interpreter.process_page(page)
vbox.addWidget(linetext)
x - x.mean(axis)
mask = np.ones(a.size, dtype=bool)
c = np.array([np.linspace(i, j, 12) for i, j in zip(a, b)])
print_ephemeris_for_month(year, month, bodies)
row = array([0, 0, 1, 2, 2, 2])
d.rectangle([(80, 0), (150, 20)], fill=(220, 0, 0))
True
logger.addHandler(gm)
x = np.sin(angle)
df
w.setEditable(True)
app = wx.App(False)
soup.contents[0].name
result = func(*args)
print(bar.a)
form
mynums = [int(i) for i in s.split()]
input_with_timeout(5)
q = Comment.query.filter(any_(11, Comment.path))
sample_func()
self.map.key
z1.namelist()
r < -raster(mat, xmn=0, xmx=n, ymn=0, ymx=m)
print(n)
shuffle(x)
M = max(max(x) for x in list(foo.values())) + 1
m.drawcoastlines()
print(item)
generate([list(range(1, 11)), list(range(10, 21))], 100)
my_dictionary = json.loads(args.my_dict)
paths[T]
self.assertTrue(user.username == iunicode(testuser.upper()))
iter(x)
datetime.datetime.utcfromtimestamp(u)
{0, 0, 0, 0, 0, 0, 0}
b[-2] += [10]
inverted_dict.add(actor)
self.store.save()
data = urllib.parse.urlencode(forms, doseq=True)
print(df)
xx, yy = np.meshgrid(np.linspace(-7, 7, 500), np.linspace(-7, 7, 500))
print(np.asarray(testdataset).shape)
DOT11_CIPHER_ALGO_WEP104 = 5
pylab.plot(tst_xdata, tst_ydata)
filedata = imgstr.read()
rhs = dict([(D[k], pop(D, k)) for D in rhs])
df = df.convert_objects(convert_numeric=True)
out = out.reset_index()
process_b.start()
print(file.character_count())
row = dict((name_map[name], val) for name, val in row.items())
bytes is str
c = BinominalCoefficient(2 * n, n)
tags = django.forms.CharField(required=True)
session.add(obj1)
print(A.shape)
sock = socket(AF_INET, SOCK_STREAM)
s.close()
lock.release()
os._exit(0)
parser.print_help()
df
indices = np.nonzero(X)
cursor = self.conn.cursor()
my_list = []
f.write(data)
gmpy2.isqrt((10 ** 100 + 1) ** 2 - 1)
d[key].append(word)
holes.append((int((x1 + x2) / 2), int((y1 + y2) / 2)))
self._observers = []
b = numpy.array([conv[x] for x in a], dtype=numpy.uint8)
self._insert(bisect.bisect_left(self, value), value)
tree.printTree()
m = numpy.swapaxes(m, 2, axis)
exec_globals.update(frame.f_globals)
PyObject_HEAD_INIT(NULL)
created = models.DateTimeField(auto_now_add=True)
x = [65] * 9999999
name = traceback.tb_frame.f_code.co_name
[list(permutations(grp.index)) for name, grp in age]
self.RUNNING = JOBSTATE_RUNNING
self.FINISHED = JOBSTATE_FINISHED
hessian = np.empty((x.ndim, x.ndim) + x.shape, dtype=x.dtype)
proc.wait()
others = [n for n in G.neighbors((1, 1)) if n != neighb]
file.seek(position, 0)
Py_XDECREF(pFunc)
self.test_panel.SetSizer(self.panel_sizer)
x = kbfunc()
reader = csv.reader(csvfile, dialect)
new_time = newdt.time()
zedges = np.linspace(-10, 10, 10)
m.drawstates()
utc_date = date(2008, 1, 1)
test()
instance.is_initialized = True
i += 1
ax = plt.subplot(111)
close(father2child_pipefd[1])
line_new = word[0].rjust(10) + word[1].rjust(10) + word[2].rjust(10)
triplets[iT].append(listB[iB + 1])
pool = multiprocessing.pool(args)
f, ax = plt.subplots(figsize=(7, 7))
list.append(calc)
s = pd.Series(test)
dates = [nextdate(i) for i in range(value)]
x = []
Z = tf.pow(Z, 2.0)
stdout.write(beeString)
[[x] for x in seqs[0]]
offset = values[0][1] - datetime.fromtimestamp(values[0][0] * factor)
exec(pyCode, global_namespace, lobaca_namespace)
x = np.arange(0, 10)
m_list
self.bind(a=self.set_c)
sizes = np.concatenate(([0], np.cumsum(sizes)))
solns = sympy.solve(sym_df)
x = np.linspace(0, 50, 100)
level = operator.itemgetter(1)
i < len(self._list) and self._list[i][0] == k
proxy.ProxyRequest.process(self)
cache[args]
c = np.random.randint(m, size=k)
num = int(line)
p.start()
raise StopIteration()
self.map = {}
code_obj.co_stacksize, code_obj.co_flags, code_obj.co_code
plt.figure(dpi=dpi)
print(sub_k_list(a, k))
df_dict[col_index[j]].append(cell.value)
sorted_dict = SortedDict(**unsorted_dict)
isinstance(Ham1(), Ham2)
results = Result.objects.all()
assert qlock.locked()
L.append(a)
self.rtype = rtype
INSTALLED_APPS += ()
n -= 1
CONVERSION_DICT[source](temp)
s[start:end]
points_unique[:, (0)], points_unique[:, (1)]
ax.set_xlim(xmin, xmax)
fhandle.seek(0)
print(n)
print(k, mydict[k])
print(a[2, 1])
left = a[max(0, index - num_neighbor):index]
0 - 0
sorted(ordered(x) for x in obj)
X_train_pca = estimator.fit_transform(X_train)
overlap(0, 50, 0, 50)
new_stepListA.extend([pathList[n][1], pathList[n][2]])
quote = m.group(1)
pub = Publication.objects.all()[random.randint(1, 2)]
print(L)
y = butter_bandpass_filter(x, lowcut, highcut, fs, order=6)
logger_1.addHandler(hdlr_1)
b = (a[..., (np.newaxis)] > np.arange(n)).astype(int)
processor.start()
res.append(arr)
readline.set_pre_input_hook(rl_autoindent)
transposes = [(a + b[1] + b[0] + b[2:]) for a, b in splits if len(b) > 1]
conn.set_debuglevel(False)
body = json.loads(request.content.read())
max_depth.update({i: find_depth(dep, MyDict[i])})
matplotlib.rcsetup.validate_backend(name)
main(*sys.argv[1:])
memview = memoryview(buffer)
frame = inspect.currentframe()
mutex.acquire()
sys.exit(1)
[2, 2, 1]
yTrain = np.array([[0], [1], [1], [0]])
cbar1 = fig.colorbar(im1, cax=cax1)
result = []
y = np.array([int(i[0]) for i in data])
f + f
get_all_object_keys(bucket, prefix, last_key, keys)
arr = numpy.array(list(itertools.zip_longest(fillvalue=numpy.nan, *lst)))
now = datetime.datetime.now()
ts2[0] = 99
area_dict = dict(zip(lakes.area, lakes.count))
form_args = dict(username=dict(validators=[no_root_allowed]))
plt.xticks(indexes + width * 0.5, labels)
genedata = OneOrMore(genebit).parseString(fastasrc)
parts_dict, list_of_parts
os.getcwd()
self.assertEqual(handler.request.recv.call_args[0], 1024)
result = defaultdict(list)
cost = tf.reduce_mean(losses)
self._locals
bodylist.append([edge[0], edge[1]])
foo = models.ForeignKey(Foo)
self.sum = 0
print(string_set(string_list))
result.get()
print(x, y, z)
cls._instances.append(instance)
filterfalse(pred, t1), list(filter(pred, t2))
assert 1 == 0
self.table.setHorizontalHeader(HeaderView(self.table))
B[0, 0]
self._format(object.foo, stream, indent, allowance + 1, context, level)
self.adjacencyList = []
Repeat.count += 1
vbox1.addWidget(self.button)
np.hstack((vector1[:, (np.newaxis)], matrix2))
self.fp.write(zinfo.FileHeader())
writer.writerow(payload)
f(**args)
deletemylist
f.close()
root.withdraw()
ax.set_xlim(x_min, x_max)
cast(v.vendorName, c_char_p).value[7]
loop.run_until_complete(asyncio.wait(tasks))
fig.subplots_adjust(hspace=0)
print(df)
g.write(new_entry)
master_indices = dict((r[1], i) for i, r in enumerate(csv.reader(master)))
indptr = np.zeros((2,), dtype=np.intp)
print(line)
serializer_class = UserSerializer
self.assertEqual(12 * 12, 144)
x = np.arange(0, n * len(A), n)
body = response.read()
summary = conn.get_account_summary()
w
t.seek(0)
m[0][0] * m[1][1] - m[0][1] * m[1][0]
security.insert(usernametoken)
byweekday = (TU, WE),
self.name.lower()
chunk = f.read()
start, end = L[0], L[-1]
lines = text_file.readline()
t = type(x)
fn(*args, **kwargs)
pool = multiprocessing.Pool(processes=pool_size, maxtasksperchild=4)
out[mask] = np.concatenate(L).ravel()
heapq.nlargest(2, x)
print(repr(m_float))
print(isPower(1, 1))
greet_self()
revbin = bin_n[::-1]
rawImage = f.read()
DistutilsInstall.run(self)
ax.set_ylim(ymin, ymax)
d1 = pd.concat([df.loc[[1]].rename(index={(1): 0}), df])
self.size -= 1
l = threading.Lock()
np.count_nonzero(y == 2)
x = np.random.rand(50)
[4, 4]
best[n][1]
bk.show(p)
Xi, Yj = np.indices(shape)
print(c.Pear)
print(c.Fish)
self.canvas.move(oid, dx, dy)
cPickle.dump(root.config(), f, -1)
f2()
c = np.dstack([r, g, b])
r1 = Range(start=date(2016, 1, 1), end=date(2016, 2, 5))
cr.fill_preserve()
count = 0
A[i], A[j] = A[j], A[i]
y = np.array([2, 4, 6])
self.popitem()
merged = merge(string1.lower(), string2.lower())
y = np.sin(x) + np.random.random(100) * 0.2
[0, 1, 0],
Test().__init__
COV = np.divide(C, V + 1e-119)
dec
np.linalg.matrix_rank(b)
delimiter = firstline[1][-1]
GPIO.setup(7, GPIO.IN, pull_up_down=GPIO.PUD_DOWN)
dic = dict((x, 0) for x in lis)
df
df_out = pivoted.cumsum() + (pivoted == -1)
print(res)
z = eval(y)
df = pd.read_json(json.dumps(dictionary_example)).T
t.daemon = True
fig = plt.figure()
shutil.rmtree(tempdir)
close_button = gtk.Button()
array = np.tile(np.arange(1, 4), (N, 1))
f2 = lambda x: np.dot(x, P) - 760
all(i > 10 for i in range(19))
pylab.grid(True)
res = defaultdict(lambda : defaultdict(lambda : defaultdict(list)))
self.name = name
self._buf += next(self._file).strip()
self.qux()
print(response)
float(n) / 1 << n.bit_length() - 1
column.append(row[key])
((days * 24 + hours) * 60 + minutes) * 60 + seconds
app = wx.App()
all_rosters.append(roster[:])
pool = multiprocessing.Pool(processes=numthreads)
HttpResponse(data, **response_kwargs)
self._dict[key]
plt.plot(a)
new_string += char
print(xquery.execute())
flush()
p.close()
f
print(min(matches, key=len))
filtered = [i for i in full if not regex.search(i)]
xi = np.linspace(0, 2, 10)
timestamp = calendar.timegm(utc_dt.timetuple())
output[contig] += 1
value
loop = asyncio.get_event_loop()
parser = etree.XMLTreeBuilder()
session.flush()
sess.run(training_op, feed_dict={X: X_batch, y: y_batch})
globals()[k] = MyDict(v)
country = models.CharField(max_length=100)
gtags - f / tmp / list
self.assertEqual(user.username, testuser)
strs[ind:ind1]
pyobj = json_pkloads(json_str)
min(r1.end - r2.start, r2.end - r1.start).days + 1
np.maximum.at(diam, data[:, (0)], dist_to_center)
show_all.set(True)
Node.__init__(self, identifier)
self.parent().setCursor(Qt.PointingHandCursor)
a = randint(0, 10)
bcw = csv.writer(bc, csv.excel, b.encoding)
splitted = my_string.split()
samples, labels = zip(*data)
img = misc.imread(fp)
Blue = RGBint & 255
new_dict = {}
self.detach_webview()
app = wx.App(False)
infilename = os.path.join(folder, filename)
abclass
Nfeval += 1
shared_row = theano.shared(numpy.zeros((1, 10)), broadcastable=(True, False))
User.create_table()
theta = np.arctan2(y, x)
_members_ = {}
s - set([4, 5])
s = pd.Series(t2.index.get_level_values(1), t2.index.get_level_values(0))
driver = webdriver.PhantomJS()
idx, val = s.index.get_level_values(0), s.index.get_level_values(1)
values[1] = values[:]
self._assert(cap)
old_a.f()
a = numpy.zeros(10, dtype=str)
x.subs(ordereddict.OrderedDict([(x, y), (y, z)]))
y = x.swapaxes(-1, -2)
command = os.path.abspath(command)
ax.contourf(np.random.rand(10, 10), 5, cmap=plt.cm.Oranges)
print(add2(10))
partition(X, my_relation)
f = fileinput.input(filename, inplace=1)
sorted_keys = sorted([x for x in d])
nlines += 1
dis.dis(foo)
show()
ax = fig.gca()
print(queue1.get())
len(self.inner) < len(other.inner)
self.mainLayout.setMargin(10)
ax = fig.add_subplot(111)
G = nx.DiGraph()
comp = wmi.WMI()
print(np.ma.compressed(m))
object_id = models.PositiveIntegerField()
os.dup2(0, 1)
[unrank(list(range(5)), 2, i) for i in range(20)]
x_train = np.array([i[1::] for i in data])
diff_idx = np.where(np.any(np.diff(sorted_arr, axis=0), 1))[0]
result.append(item)
county_colors.append(colors[idx])
time.clock()
myList = list(f)
process.start()
df
csv_out = csv.writer(out)
c = wmi.WMI()
xml.sax.saxutils
year = sorted(set(map(lambda x: x[0], file_contents_values)))
pool = mp.Pool()
x = np.random.randn(N)
plt.show()
exit(a)
print(new_d)
socket = context.socket(zmq.PUB)
True
figure(1)
pool.close()
measure = lambda x: -x.count_ops()
lis.append(lambda : 1)
e2 = tk.Entry(self)
uf = np.frompyfunc(lambda a, b: a + (b - a) * 0.5, 2, 1)
f.close()
platform.platform()
x = np.array([0, 1, 2])
gtk.main_iteration(False)
ws.set_panes_frozen(True)
sleep(10)
Thread(target=begin).start()
values = np.random.uniform(low=0, high=1, size=ages.shape)
print(sub.recv(zmq.NOBLOCK))
d = {tuple(i): a.count(i) for i in a}
tuple_dict = {}
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj), authinfo)
(nonzero_array[:-1] * nonzero_array[1:] < 0).sum()
print(parser.format_help())
tar.addfile(info, data)
sys.exit(1)
self.numbers[-i - 1] = 0 if num == 9 else num + 1
loss = tf.reduce_sum(tf.abs(tf.sub(x, y_)))
self.c = cv2.VideoCapture(0)
res_ols.params
B = np.random.randint(k, size=(n, m))
daemon_kenny.start()
vals = np.empty(len(s))
print(lst)
password = models.CharField(max_length=100)
output = subprocess.check_output(command_line)
xlmodule.CodeModule.AddFromString(strcode.strip())
print(len(chuck))
plt.title(title, figure=fig)
print((first, second, third))
self.Artwork = Label(self.frame, image=self.photo)
notify_another_process()
print(s)
print(a[167])
date_of_appointment = models.DateField()
Point(other.x, other.y)
plt.savefig(outputname, dpi=80)
print(screen_name(api.lookup_users(i)))
sizer = wx.BoxSizer(wx.VERTICAL)
print(content)
XtX = np.dot(np.transpose(X), X)
wavfile.write(WAVE_OUTPUT_FILENAME, RATE, result)
tgrid = np.linspace(times.min(), times.max(), 100)
maxm = np.array([])
minm = np.array([])
print(Expression(4))
setattr(self, attr, val)
A.sort()
draw = ImageDraw.Draw(img)
a = np.arange(10)
self.flush()
worksheet = workbook.add_worksheet()
numbers.append(my_alphabet.index(letter))
[4, 8, 7]
my_dict = {}
data = EXIF.process_file(f)
__import__(sys.argv[1])
thread.join()
line_list = list(self.readlines())
hy = T.hessian(y, [A, b, c])
id = db.Column(INTEGER(unsigned=True), primary_key=True)
walk(path)
app = Flask(__name__)
train_op.run()
urls.append(page.url())
dfnew = pd.concat([dfnew, dfnondup], axis=0)
opener = urllib.request.build_opener(auth_handler)
fig, (axes_1, axes_2) = mpl_plt.subplots(2, 1)
b = date(2011, 11, 17)
stdout_lines.append(line)
question.id = str(question.key().id())
A = np.zeros((5, 100))
stack[-1].append(item)
True
self.timer = QtCore.QTimer()
L = list(range(-10, 10))
AI2 = 0
colors = np.outer(0.5 + norm(shade) * 0.5, color)
c = Kls().set_var_1(2)
d = collections.defaultdict(int)
pattern = re.compile(regex_txt, re.IGNORECASE)
window = screen.get_active_window()
queryset = Experiment.objects.all()
doit()
[0, 0, 2, 0]
crypt_object = AES.new(key=key, mode=AES.MODE_CBC, IV=iv)
worker = Worker()
lines = [span.get_text() for span in spans]
N[row_idxs[r], c] = 0
logsum += log(x)
data = f1.read(chunk)
w.join()
fh.setFormatter(formatter)
stream.truncate()
self._num_expectations = 0
GObject.threads_init()
now = datetime.now()
print(df1)
shlex.__init__(self, *args, **kwargs)
wb = excel.Workbooks.Open(doc)
print(Foo.baz.__code__.co_varnames)
fl = fcntl.fcntl(fd, fcntl.F_GETFL)
print(sum(a for a in fibonacci_iter(4000000.0) if not a & 1))
thirdpartymodule_b.dosomething()
h.pop()
set_globvar_to_one()
request = scrapy.Request(url=url, callback=callback)
response = request.execute()
superdicts.append(fd)
todos = ToDo.objects.filter(user=request.user)
paramstr = urllib.parse.urlencode(params)
transaction.commit()
serial.flushInput()
p.send(message)
by1, by2 = sorted([random.random(), random.random()])
foo = Foo()
fig, axes = plt.subplots(nrows=2)
True
self.test(*self.arg)
print(encoded)
__cache = {}
arr_1 = np.array([False, False, True, True])
self.scroll.setWidgetResizable(True)
sb.palplot(sb.color_palette())
pool = Pool(4)
pattern = re.compile(format_to_re(layout))
flt = lrg[lrg == 0]
parseHTML(curRes)
cheese = make_cheese(Goat().milk())
bool(regex.match(s))
warnings.show_warning(message, category, filename, lineno, file, line)
f.readline()
figure(1)
541
cov[i, j] = calculate_value(i, j)
sizer = wx.BoxSizer(wx.VERTICAL)
False
dict.__getitem__(self, x)
y0 = y_indices.astype(np.integer)
pypreprocessor.parse()
run(app=myapp)
self.br
b = [4, 5, 6, 7]
print(choice)
ax = fig.add_subplot(2, 2, i)
print(df.query(qry))
time.sleep(24 * 60 * 60)
words = x.split()
q.put(item)
os.chdir(destination)
self.stack.pop()
wrapper_object.open()
anotherfile.isatty()
ppxml1 = etree.tostring(xml1, pretty_print=True)
gs = gridspec.GridSpec(4, 4)
self.__class__.count += 1
d2 = {x: x for x in range(1, 6)}
leadingzerocounts = [0] * m
print(df1)
root = tk.Tk()
print(r.cookies)
byte_s = f.read(1)
self.date = self.evaluation_id.date
end.time()
nextlevel.append(n.right)
restorer = tf.train.Saver([w])
bokeh.io.show(grid)
textview.modify_font(fontdesc)
do_it_lots()
X = np.matrix([[0, 0], [1, 0], [0, 1], [1, 1]])
do_generator_empty()
sys.exit(0)
n -= 1
img = pygame.image.load(filepath)
abstrapz([-1, 0, 1])
pylab.show()
ts = time.time()
cummax(a)
plt.ion()
client.sendPreparedMessage(preparedMessage)
self.name
handler.setFormatter(formatter)
cls.initStuff()
TextWidget.pack()
f()
your_plot.set_xticklabels(ticks)
store_to_request(request)
self.put(data)
builder.connect_signals(LoseFocusHandler())
network[x][y] = common
stream_handler = logging.StreamHandler()
render_template(template, mydict=mydict)
self.A = np.asanyarray(A)
login(request, user)
list1 + list2
a > 2
df.idxmin(axis=1)
stackless.tasklet(b)()
out = np.lib.stride_tricks.as_strided(x, shape=shp, strides=(M * n, n)).ravel()
net.layers[1].blobs[0].diff.shape
Pear = 6
out = np.empty_like(y)
test_timing()
mpl.rcParams.update(pgf_with_pdflatex)
RGH = 8
list(partitions(s))
x * self.z
layout = QVBoxLayout(self)
print(result)
logfile.write(output)
libraries[:10]
status = models.CharField(max_length=25)
len(unequal_pos[0])
np.save(f, a)
f(*args)
np.random.seed(8)
a = list(range(10))
out.write(line)
bokeh.io.show(layout)
rsp = urllib.request.urlopen(req)
b = b - 1
np.any(count > 1)
connection.cursor()
print(x)
f(xv, yv)
i = int(f)
c.append(map(sub, a[i], b[i]))
Pdb(def_colors).set_trace(sys._getframe().f_back)
data = np.random.normal(mu, sigma, 10000)
self.U[:, :n] * self.d[:n]
print(keyword, x.strip()[:5])
next(i)
deleteyshape[axis]
mat1[1][i] = 1
Node.__init__(self, identifier)
print(lt_obj.get_text())
self.doSomething(Notification)
nlesser_items = heapq.nsmallest(n, items)
pygame.mixer.music.load(wav_path)
self.dict[self.first]
print(df.dtypes)
x = (i for i in range(10))
imgB = numpy.array(imgB)
data = socket.gethostbyname_ex(d)
T = tri.Triangulation(x, y)
lines_gen = islice(infile, N)
ax1 = plt.subplot(gs[1], sharey=ax0)
print(len(zero_crossings2))
max(i.arity() for i in s)
root.grid_columnconfigure(2, weight=1)
-Flask - Testing
self.toolbar = self.CreateToolBar()
width, height = img_padded.size
func1(gen1)
[lambda : 2][0]()
line_count = 0
f.write(line)
replchars[i] = replchars[i].upper()
prod(list)
previous_day = read_date - datetime.timedelta(days=1)
self.__dict__[attr_name]
pp.show()
assert foo(5) == 10
addresses = [address.strip() for address in addresses]
A = Matrix([[5, 6], [7, 9]])
lut2 = lut.reshape(-1, 4)
attachment = msg.get_payload()[1]
http_server.listen(8888)
self.src.append([item])
self.save_object(related_item)
PROG = os.path.basename(os.path.splitext(__file__)[0])
lines[-1] += segment
soup = BeautifulSoup(response.body)
fullPathToFile = os.path.join(root, file)
raise IndexError()
self.__ntrue
ax.set_xlim(0, 9)
cj
lst.append(sp.Eq(i, j))
app = Flask(__name__)
self.data[self.start + idx]
self.window.set_border_width(10)
book_ct = ContentType.objects.get_for_model(Book)
print(Foo.objects.in_a_number_order())
tkmc.set_timeout(timeoutSp)
old_settings = termios.tcgetattr(fd)
a
preallocate_file(fn, size)
201112
iter(lookup.items())
x = 10 * np.random.normal(mu, sigma, 5000)
print(merge(d1, d2))
show()
x = np.arange(100).reshape(10, 10)
print(b)
{{body}}
coords = nx.spring_layout(G)
lines.set_facecolors(cm.jet(np.random.rand(1)))
self.df.log(request, self.spider)
result = [s + timedelta(days=(calendar.FRIDAY - s.weekday()) % 7)]
words = s.split()
a, b, c = myfunc()
self.layoutVertical.addWidget(self.canvas)
conn.sendmail(fromaddr, toaddrs, msg.format(txt))
atexit.register(exit_handler)
b = a
a, b = b, a
rs = [grequests.get(url, hooks=dict(args=print_url)) for url in urls]
y = [0, 0, 0]
self.func, self.args = func, args
self.iterator
var_dict[s]
xk = np.arange(7)
s.into_raw()
self.wfile.write(message)
l.sort(key=alphanum_key)
im.size
lines.append(line.strip())
signal.signal(signal.SIGINT, signal.SIG_DFL)
href
to_modify[index] = replacement
blog_entry = get_cached(BlogEntry, pk=4)
ra.append(float(line.split()[0]))
False
df[start:end]
vote.delete()
os.setuid(471)
dict(zip(p[:100], p[100:]))
random.sample(WeightedPopulation(population, weights), k)
df.index[-1] + pd.offsets.MonthEnd(0)
self.restart_celery()
foo.error
re.sub(r, replacer, string)
result = dict()
x_key = keyfunc(x)
print(c)
averages = [([k] + [(sum(x) / len(v)) for x in zip(*v)]) for k, v in list(d.items())]
[1]
l_copy = [x for x in l]
self.worker.moveToThread(self.thread)
show()
rv = self.next_chunk[:n]
filesystem.GetFileAttributes(filepath).hidden
ind = np.indices(myarray.shape)[0]
self.axes.hold(False)
sum((ea - eb) ** 2 for ea, eb in zip(ka, kb))
work.join()
total += ampl * math.cos(cosarg * math.pi / 180)
origin = 0, 0
ff = [functools.partial(lambda i: i, x) for x in range(100)]
self._compare(other, segment=-1)
sign *= np.multiply.reduce(d / absd, axis=1)
c.update(set(v))
foo_noniterable(thing)
zero = numpy.zeros(10)
points = np.hstack((p1, p2, a, b))
DataFrame(self.model.predict(X))
soup = BeautifulSoup(source_code)
b.burn(library, lighter)
results.append(option)
obj
soup = BeautifulSoup.BeautifulSoup(content)
f_old.seek(0)
items = [i.strip() for i in items]
pool = multiprocessing.Pool(1)
max(v1 - v0 for v0, v1 in zip(values[:-1], values[1:]))
int(gmpy2.mpz(12))
Application().Run(MyWindow())
data_dict = json.loads(data)
sys.exit(4)
copy_file(src, self.target_dir)
setattr(self, key, value)
plt.xticks(list(range(width)), alphabet[:width])
f.seek(0)
im = im.crop((left, top, right, bottom))
n_samples += int(self.smooth_idf)
dt + (datetime.min - dt) % delta
mymap = [m for m in mymap if m[0] > 0 and m[1] > 0]
RAWR = lR
next(gen())
assert np.all(Ax[ix:ix + Bx.shape[0], iy:iy + Bx.shape[1]] == Bx)
result.append(buff)
self.host = host
print(repr(e))
[-2.0, 0.0, -2.0, 2.0, 10.0, 4.0]
loop.run_until_complete(example())
k.open()
myseq = tuple(sorted((k,) + v for k, v in mydict.items()))
r1 = conn.getresponse()
time.sleep(0.1)
n2 = np.random.random(N)
self.username
ax.bar(pos, vals, width=width, label=cond, color=cm.Accent(float(i) / n))
match.index[0]
df.T
can.save()
str(digit)
output = []
c += 1
fig, ax = plt.subplots(1, 1)
old_settings = termios.tcgetattr(sys.stdin)
managed = False
clipboard.SetText(data)
module1.Relay(GPIO)
max_step = 100
l += 1
server.bind((host, port))
dictionary[parts[0]] += 1
dd[v].append(k)
argsdict[arg].append(val)
Base.metadata = metadata
data_sum = data.sum()
print(len(allkitties))
show(p)
N = int(sys.argv[1])
zip(a, b)
self._ref2 = ref2
self.my_setting = my_setting
Y.__init__(self)
a = A()
matches.append([value, values[x]])
layout.addWidget(button)
dmin = len(trans[0])
df
sys.stdout.writelines(merge(key=second_column, *sorted_files))
process.poll()
[]
yaml.load(_)
fh.flush()
{NULL, NULL}
YourObject.id.generation_time
session = sessionmaker(bind=engine)()
image_type, width, height = getimageinfo.getImageInfo(imgdata)
self.tag = tag
sleep(0.1)
df.dot(s)
file1.write(toFile)
o = Observable()
client_sock.close()
two_d[np.ix_(first, second)]
[1, 1, 1]
count += 1
periods = dict(zip(times, labels))
path_file = os.path.join(path_file_dir, file)
diag = np.arange(M.shape[1])
[a, b]
i += 1
tidx + pd.Timedelta(days=15)
timeit(lambda : list(fulldict.keys()))
self.current - 1
L = Linitial
replace(l, 1, 7)
raw_values = [o.i for o in MyList]
os.remove(new)
m.add(k, dict1.get(k))
d1[1]
first_col = np.array([1, 0, 0, 0])
parser = argparse.ArgumentParser()
self.__keys.append(key)
X.toarray()
b[a[:, (0)], a[:, (1)]] = 10
b = np.random.normal(0, 1, (N, M)).mean(axis=1)
xd = np.linspace(0, 15, 100)
print(sheet[0][0])
df.value1 = df.value1.round()
dis.dis(a)
procs = [Process(target=f, args=(d,)) for _ in range(10)]
fh.write(str(buf))
screen.blit(draw_me, backdrop)
average = total / count
sum
fig.subplots_adjust(hspace=0, wspace=0, top=0.925, left=0.1)
pprint(d)
hog = cv2.HOGDescriptor()
dicc = parse_qs(request.query_string)
df
tksupport.install(root)
sys.path.insert(0, mysite)
hours = df_energy2.index.hour
img1 = cv2.imread(fn1, 0)
picklable.append((r, p, code))
self.s_in.close()
print(t, expr.parseString(t).asList())
a.x
lists = sorted([sorted(x) for x in lists])
print(i)
wfloat = wally.astype(float)
h1 & 4294967295
st.norm.interval(0.95, loc=np.mean(a), scale=st.sem(a))
X = np.ones((n, 2))
my_second_egg = my_related_object.egg
print(p.mass, p.position, p.velocity, p.force)
proc.start()
clf.fit(X.iloc[(train_idx), :], y[train_idx])
groups = list(groups)
ca_two = str(sys.argv[2])
print(self.bar)
df_ordered_multi_cols = pd.DataFrame(df_ori, columns=multi_cols)
start_time = timeit.default_timer()
actcount += 1
d = {key: a.rx2(key)[0] for key in a.names}
_srcfile = os.path.normcase(_srcfile)
python - i
output = p.communicate()
results.append(result)
p.communicate()
print(ET.fixtag(some_node.tag, NS_MAP))
cookies = requests.utils.cookiejar_from_dict(pickle.load(f))
assert abs(new_version - old_version) == 1
index_start = df.index[-1] + 1
child = pexpect.spawn(ssh_cmd, timeout=timeout)
id = Column(Integer, primary_key=True)
sparse + 0.228869672266
fig = plt.figure()
self.fed.append(d)
eventloop.run_forever()
f(x) ** 2
a = [(lambda : i) for i in range(5)]
str(self.value)
print(mat.A)
a += b
tok_gen = tokenize.generate_tokens(sys.stdin.readline)
my_mesh.BeginPolygon()
process = sp.Popen(shlex.split(cmdline), stdout=sp.PIPE, stderr=sp.PIPE)
os.makedirs(dirmk)
d = collections.defaultdict(dict)
outcsv.writerow(x[0] for x in cursor.description)
cmd.append(command)
axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])
clf = AdaBoostClassifier(n_estimators=2)
mymod = importlib.import_module(module)
ipython - noconfirm_exit
dev2 = os.stat(file2).st_dev
loop.run_until_complete(main())
print(parser.print_help())
A2[mask] = 0
res = urllib.request.urlopen(req)
_dict = simplejson.loads(json_data)
a = [4, 5, 0, 0, 6, 7, 0, 1, 0, 5]
lines = f.readlines()
blob_info = blobstore.BlobInfo.get(resource)
seq[start], seq[end - 1] = seq[end - 1], seq[start]
random.shuffle(sequence_containing_z_vals)
tree = chunker.parse(postoks)
get_color(0.7)
q = int(a / b)
open_file.close()
content = f.read()
multiprocessing.Process.__init__(self)
keys.append((h, r))
sys.getsizeof({})
print(pd.factorize(np.hstack(df.values)))
[babel.extractors]
L = Linitial[:]
gridsize = (len(lines) - 2) / 2
self.root = tk.Tk()
Py_Initialize()
my_view
raise StopIteration
pylab.grid(True)
frame = bytearray()
line = plt.plot(list(range(10)))
np.random.seed(1)
self.errors = errors
sys.path.insert(0, project_dir)
z = (df != 0) * 1
bool(p)
a[0] = 7
[flake8]
print(s)
request = urllib.request.Request(my_url, data)
context = cairo.Context(surface)
(i & (1 << length - 1) - 1) << 1 | i >> length - 1
thedir = sys.argv[1]
print(x)
assert set(x.id for x in all_) == to_load
d = defaultdict(int)
data = [tuple(x) for x in frame.values]
print(IOB_to_tree(sentence))
A.__init__(self)
y()
self.sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
get_class = lambda x: globals()[x]
len(self.data)
test_func()
request.response.headerlist.extend(headers)
cv2.putText(out, string, (x, y + h), 0, 1, (0, 255, 0))
ranges.pop(0)
idx = c.index((1, 4))
a = math.cos(theta / 2.0)
result = {}
output = StringIO.StringIO()
1, 0, 1
f = figure(figsize=(6.2, 5.6))
ret.append((point[0], point[1] - 2 * (point[1] - BOTTOM_LEFT[1])))
self.q = Queue(1)
draw.text((5, 0), title, font=font, fill=(0, 0, 0))
ax.set_yticks([])
cache = Cache()
db.run_in_transaction(_tx)
zipdata = result.read()
fig = plt.figure()
drvs
cv.WriteFrame(writer, frame)
lambda x: a * x + b
base_close += timedelta(days=1)
mouseclickdn(60, 100)
queue = collections.OrderedDict((key, queue[key]) for key in keys)
type(xml.__loader__) in CUSTOM_LOADERS
unqID_mask = np.append(True, np.any(np.diff(sorted_coo, axis=0), axis=1))
xs, ys = np.meshgrid(x, y)
np.sum(np.abs(x - y) > 1)
gene = this_re.group(1)
self.view.setSortingEnabled(True)
next(b)
layout = QtGui.QHBoxLayout()
parser.config_files.extend(values)
y = np.arange(len(x))
spl = [func(x) for x in inputText.split()]
photos = json.loads(parsed_photos[0])
instance.app.amqp.queues.select_add(queue)
output += cssin.read()
print(pruned)
y = np.linspace(0, 100, 100)
writer = csv.writer(fl)
print(b, repr(b))
print(list(generator_overlap_split_list(l, s)))
mySocket.connect((SERVER_IP, PORT_NUMBER))
print(response.read())
sampled_df = df.ix[rows]
f(kw)
qry = session.query(Parent)
diff = np.diff(a, axis=0)
stripped_line = line.strip()
self.wrong_values = []
method = getattr(self.data, name)
datetime.datetime.strptime(s_date, pattern).date()
[4, 2, 9]
print([toHex(x) for x in numbers])
print(value)
out = merge(left, right)
print(gen_hex_colour_code())
parent = Parent()
func2 = somedecorator(func2)
args = parser.parse_args()
urlretrieve(image_url, outpath)
xml_dict(childnode, name, dic)
index = np.searchsorted(data, values)
print(s)
dwg.save()
ax1 = np.histogram2d(x_data, y_data, bins=bins)
b = set([9, 7, 6, 5, 1, 0])
sum_a[i] += x
l_y.append(s[-1])
list1 = [[-2.0, 0.0, -2.0, 2.0, 10.0, 2.0], [-1.0, 0.0, 2.0, 1.0, 5.0, 4.0]]
find_intersect(x_down, y_down, x_up, y_up)
Deidre
Felicity
Harriet
Craig
Greg
Edward
Andrew
ftp = FTP(host, user, passwd)
numbers = sum(c.isdigit() for c in s)
sudokupossibilities[1][1][1] = 2
predicted = classifier.predict(X_test)
[7, 2, 6]
fig, axes = plt.subplots(1, len(df.columns))
pow(2, 2)
LR_Multi.fit(X_stack[:, :half], y_stack[:, :half])
do_something_with(line)
print(i)
employee = sc.parallelize(employee).map(lambda e: (e[1], e[0]))
print(bool(Something()))
theta %= 2 * np.pi
darray = np.array([distances(s) for s in new_shapes])
print(x.format(42))
f.write(s)
assert len(c) == 2
ax = plt.gca()
xyz = [0, 12, 4, 6, 242, 7, 9]
t()
fig = plt.figure()
python - V
rolled_view = np.transpose(coords, rolled_axes)
net.layers[1].blobs[0].data.shape
humansize(1049)
groups[groupcol].add(col)
self.obj[frozenset((idx,))]
myseries_three.loc[0:2]
itemset = set(randint(0, X) for _ in range(100000))
self.inspector.setPage(self.view.page())
tri = qhull.Delaunay(xyz)
print(team([1, 1, 50, 50, 50, 1000]))
mimedata = QtCore.QMimeData()
label_height, label_standoff, label_text_align, label_text_alpha
setterific(larry) == setterific(moe)
a = numpy.arange(1, 15)
zip_longest(fillvalue=fillvalue, *args)
frame = Tkinter.Frame(root)
a
x[1][2]
soup = BeautifulSoup(str(content))
sleep(time)
raise ImportError(msg)
attr(*args, **kwargs)
__all__ = []
DEDENT
f.close()
next(reader)
b = np.array([1, 2, np.NaN])
ax2.xaxis.set_major_formatter(FuncFormatter(fmt_zToEta))
class_name = db.Column(db.String(128), unique=True)
console_handler = logging.StreamHandler()
app = create_app(logger)
threading.Thread(target=show_progress_B, args=(win,)).start()
df
decimal.Decimal(-1200)
PyArray_Descr * descr
stream.render(out=f)
Xc.setdiag(0)
l[0]
s = requests.Session()
print(config_root.log_file)
plt.colorbar(im)
set_4 = {100, 20, 40, -40, 60, -20, -80, 0, -60, -100}
c = Counter(elem[0] for elem in list1)
minm = argrelextrema(y, np.less)
print(itteration)
m1 += np.bincount(a + m.shape[1] * b, minlength=m1.size)
itertools.cycle.__init__(self, self._iterable)
[0, 1, 0]
oaischema = etree.XMLSchema(schema_doc)
(4, 1)(4, 1)
most_frequent(y for x, y in Ns[:self.k])
round(f)
df
word_counts
good.append([m])
plt.scatter(roc_x, roc_y)
view.setRootIndex(model.index(QDir.homePath()))
response = opener.open(request)
pstack.append(i)
newlist.append([val])
Base * get_base()
print(dsum(x, y))
arr = [[[(i + j + k) for i in range(5)] for j in range(5)] for k in range(5)]
HOST = socket.gethostbyname(socket.gethostname())
self.variables[attr] = []
l = [list(g) for k, g in groupby(x, lambda x: x.isalpha())]
_to_etree(e, ET.SubElement(root, k))
slots = [(e if e else next(it_A)) for e in slots]
rpath = rpath[4:]
module = new_module(name)
df1 = df1.stack()
self.fig = f
l = l[1:]
self.button.customContextMenuRequested.connect(self.on_context_menu)
view.setModel(model)
print(key, mydict[key])
colormap.SetHueRange(0.667, 0.0)
context[self.attr_name]
f.write(bitbuf)
com.open()
widget.set_size_request(200, 200)
data.shape
seaborn.set()
pygame.draw.rect(windowSurface, self.color, self.rect)
df
foo.set_a_to_three(globals(), locals())
rdd = sparkdf.rdd.zip(new_col).map(process)
im = Image.open(image_io)
HAVE_CYTHON = False
plt.xlim(0, 8000)
print(b.text)
user = oauth.get_current_user(scope)
pylab.ion()
flat_for(a, lambda x: x + 5)
min_x, max_x, min_y, max_y, min_z, max_z = minmaxes(triplets)
user = User.objects.get(email=email)
[-1, -1, -1, -1, -1]
np.save(f, b)
number % 2 != 0
foo()
self.data = str
CELL_LIST.append(Cell(v == 1, x, y))
ax = plt.subplot(111)
callable(object) == True
javascript_html = Render(url).html
e[0]
obj[key] = mod.__dict__[key]
b = list(a + i for i in range(10))
b[:] = 0
self._name = name
m, n = len(seq) + 1, len(sub) + 1
kml = simplekml.Kml()
path = str(path, sys.getfilesystemencoding())
w = wmi.WMI()
self.db = db
fmstr.format(*args)
clf2 = joblib.load(filename)
easy_csv.append([row_preprocessed])
[(splt[0], splt[1]) for s in strings for splt in [s.split()]]
f.write(output_from_parsed_template)
primeList.append(num)
7, 8, 9
counts[name] += 1
a = object()
traceback.print_exc()
x = np.eye(2)
a, _, _ = numbers()
mask[indices] = False
PQRGQQGTSQEGEQKLQNILEIAPRKASSQPGRFCPFHSLAQGATSPSRKDTMSTESMIRDVELAEEALPQKMGGFQNSRRCLCLSLFSFLLVAGATTLFCLLNFGVIGPQRDEKFPNGLPLISSMAQTLTLRSSSQNSSDKPVAHVVANHQVEEQLEWLSQRANALLANGMDLKDNQLVVPADGLYLVYSQVLFKGQGCPDYVLLTHTVSRFAISYQEKVNLLSAVKSPCPKDTPEGAELKPWYEPIYLGGVFQLEKGDQLSAEVNLPKYLDFAESGQVYFGVIAL * REWVFIHSLPSPHSDPFTLTPLLSTPQSPQSVSF * LRKGIMAQGPTLCSELSTTTQKHKMLGQ * PGLWASHAPPSRTQMGFPNSLEPRMSIPEFCKGRVVRLPLSQNEAG * DLRPSYLQTFPDSSLRCNAQPSSQSQPPSIYICTYYLLFIYYLFICL * MYLFGRPGCPGGPSVGSCLQTDMFSVKTELSCPHLASLPCCLLFCLCLKQNIYLTQLS ** R * FGDQAVATSLNLCSPREP * L * SPYGSLREI
indexes[i] = reference[data[i]]
df.index.dtype
x = 2
os.startfile(command[myIraw_inputput][1])
self.trell.append([word, copy.deepcopy(temp)])
element.tag
p.start()
a = tf.Variable(init_a)
table[0]
data = np.genfromtxt(f, usecols=list(range(5, num_cols)))
2
licenses.add(get_plate())
self.my_table.insert(dict(item))
s.add(2)
loop.run_forever()
wrapper
o.date = datetime(2012, 4, 15, 1, 0, 2)
False
[data[b:e] for b, e in [(spl[i - 1], spl[i]) for i in range(1, len(spl))]]
dsp.setparameters(AFMT_S16_NE, nc, fr)
x = data[:, (0)]
uniqueDF = df.drop_duplicates()
AB = [(A[i] + B[i]) for i in range(min(len(A), len(B)))]
{{YOUR_CUSTOM_SETTING}}
zlib.decompress(strobj, 15 + 16)
ret.insert(0, r)
tweets = line_data[1:-1]
summed_vals = np.bincount(id_arr, count_arr)
f.read()
plt.hist(data, 50)
some_global_variable = Foo()
np.uint64
chart_toolbar.SetSize(wx.Size(fw, th))
b[0]
SIGN_CHARACTER + num_encode(-n)
fn.__dict__.update(f.__dict__)
plt.show()
counts.update_point(r, 1)
DEBUG = True
print(self.a * self.b * self.c)
self.socket.listen(128)
blobs = BlobInfo.all().fetch(500)
s = pd.Series([np.NaN, np.NaN, 1.0])
writer = csv.writer(foutput)
themax = arr[0]
index = bisect([i.lower() for i in my_list], insert_string.lower())
app_log.removeHandler(hdlr)
items = collections.defaultdict(list)
True, s[2:]
print(args)
np.where(data[:, (1)] == yr + 72)
print(data)
print(row[1])
server.close()
start = dt.datetime.now()
foo.bars = [1, 2]
df
plt.show()
main_loop = tornado.ioloop.IOLoop.instance()
win.show_all()
bcut.on_clicked(_yes)
mergedlist = listone + listtwo
length = len(list1)
indices.sort(axis=axis)
self.a = a
f1.close()
print(df)
self.wfile.flush()
session.add(prod)
a = np.rint(x)
d.clear()
PROJECT_PATH = os.path.realpath(os.path.dirname(__file__))
target_file_name = os.path.basename(filename)
sorted_eigvecs = eigvecs[:, (eig_idx)]
A2 = np.random.randint(-4, 10, size=(100000, 100))
True
ZZ.old_poly_ring(x).ideal(x ** 2 + 1)
mask = np.tile(np.any(im, axis=0), (2,))
the_files.append(target_file_name)
x = int(x)
ret.append((point[0] - 2 * (point[0] - BOTTOM_LEFT[0]), point[1]))
self.widget.see(END)
app.quit()
fn
list(a)
group = list(group)
k, v = s.split()
a = np.random.randint(0, 100, 100000)
time.sleep(SECONDS)
odd.append(num)
a = df.t.values
fh.level = logging.WARNING
print(row)
self.render_to_response(context)
sys.exc_info()[1]
number = int(eval(input()))
do_some_stuff(k, v)
fitfunc = lambda params, x: params[0] * x
self.data[dataKey].remove(item)
PCO_api.PCO_OpenCamera(ctypes.byref(camera_handle), 0)
np.array(list(itertools.zip_longest(fillvalue=0, *v))).T
count += 1
d = np.empty(n)
tree = etree.HTML(doc)
name[0][0]
btn.Bind(wx.EVT_BUTTON, self._onShowHelp)
fig = Figure()
client = oauth.Client(consumer)
suite = indentedBlock(stmt, indentstack, True)
mydict[index] = +1
mw.ui.plotWidget.setGeometry(1, 1, s.width() - 2, s.height() - 2)
functools.update_wrapper(wrapper, fn[0])
obj.b()
is_new_style_class(int)
nodes.append(Node(ndx[k], []))
J = sparse.coo_matrix((np.ones_like(ixs, int), (np.zeros_like(ixs, int), ixs)))
fig, ax = plt.subplots()
divisors = []
m1.create_all(conn)
random_array = np.array(random_array, dtype=np.uint8)
raise sqlalchemy.exc.DisconnectionError
weeks.count()
d1[start:end].value_counts().index[0]
x[1, 0, 2]
hash(self.item1) * hash(self.item2)
G.add_edges_from(megalist)
row = next(itertools.islice(csv.reader(f), row_number, row_number + 1))
cj = cookielib.CookieJar()
first_list = [1, 2, 2, 5]
user = User()
print(df_expanded)
ax.w_xaxis.line.set_color((1.0, 1.0, 1.0, 0.0))
pygame.quit()
number = eval(input())
1, 1, 0
o_func1()
set([t.id for t in prerequisites_complete]) == set([a.id, b.id])
new_lock.acquire()
abspath = os.path.join(dirpath, f)
_PIDS.append(pid)
print(f)
self._inner.insert(index, item)
w.wcs_pix2world(100.0, 100.0, 1)
value_to_key[v].append(k)
len(bin(1000)) - 2
do_something_with(line)
l[:] = (i for i in l if counts[i] == 1)
a.sort(reverse=True)
ipaddress.ip_address(str)
wnd.show_all()
dircontainingqueuedotyaml = os.path.dirname(os.path.dirname(__file__))
CUDA_ENABLE_CURAND = True
data = Column(String)
settingstime_zone = timezone(settings.TIME_ZONE)
print(d.pop(min(d, key=d.get)))
y = np.add.accumulate(x)
ax2 = np.histogram2d(x_data, z_data, bins=bins)
self.session.query(self.model).filter(self.model.paid == True)
DF.columns = DataFrame(np.matrix(cursor.description))[0]
db.create_all()
app.exec_()
os = __init__.os
splitS.append(s[start + 1:end])
self.subframe.Close()
fig, ax = plt.subplots()
self.b.follow_link(link)
float(n_ab) / (n_a + n_b - n_ab)
opener = urllib.request.build_opener(auth_handler)
plt.subplot(2, 1, 2)
data = json.load(infile)
idx = a.cumsum()
time.sleep(1)
fig, ax = plt.subplots()
diff[key] = merge(lhs[key], rhs[key])
f(*[v for _, v in sorted(newdict.items())])
show(fig)
a = [1, 2, 5, 1, 6]
Ihmf = (Ihmf - np.min(Ihmf)) / (np.max(Ihmf) - np.min(Ihmf))
fig.add_subplot(axes=self.traceax)
parent_map = dict((c, p) for p in tree.getiterator() for c in p)
d = collections.defaultdict(list)
dict_out[key] = value
d.dtype.names
s.value_counts()
self.smtp.close()
print(x.format(42))
g(*args)
raise NotImplementedError()
Py_Initialize()
p_guess = np.median(x), np.median(y), 1.0, 1.0
tokens = nltk.word_tokenize(text)
fig = pyplot.figure()
print(list(squares(4, 16)))
results = zip([x[0] for x in results], smoothed)
start_of_week = today - start_delta
words += len(wordslist)
parse.py
self.__fpointer
a = a[::-1]
str(self.author)
fig, ax = plt.subplots()
isinstance(value, CheckboxInput)
x += N
array([10, 14, 15, 56]),
original_rows = [[1, 0, 1], [0, 0, 0], [1, 0, 0]]
state = models.CharField(max_length=25)
b = np.array([4, 5])
row.append(DataReader[j])
writeFileObject.close()
(1 << x) - 1
xz = NNN.mean(axis=1)
func()
num = 9
a1_edit.textChanged.connect(lambda text: self.TxtChanged(a1_edit, text))
ypos = np.searchsorted(x[xsorted], y)
self.sizer.Add(self.button, (2, 0), (1, 2), flag=wx.EXPAND)
self.log_queue.append(self.format(record))
print(name)
print(args_values)
scores.append(subcheckio(nstones, left + stones[0], rite))
signal.signal(signal.SIGTERM, term)
retstr.close()
print(x, y, x * y)
ax.set_xticks(ind + width)
instance.save()
__builtins__.max
os.chdir(SCRIPT_DIR)
po.join()
random.shuffle(sequence_containing_y_vals)
print(gpsp.get_current_value())
sniffer = csv.Sniffer()
req.write(resp.data)
beta = cov[1, 0] / cov[0, 0]
coskew(df)
es_logger.addHandler(es_logger_handler)
plt.show()
self.data = self.request.recv(1024).strip()
plt.show()
out.append(sum)
c.style
i = row[0]
chr(ord(c) + x)
driver.set_window_size(1400, 1000)
geom.LineString(((1.1, 2.0), (0.1, 0.4))),
sftp.stat(path)
x.date()
self.children.append(Tree(child, self))
df
json.JSONEncoder.default(self, obj)
cookie = urllib.request.HTTPCookieProcessor(cookie_jar)
rows.append(row)
array[0]
mylist = list(myiterator)
b_mock = mock.Mock()
self.queue = []
xml_file.seek(0)
print(20)
buf = f.read(1024)
fig = plt.figure()
df = pd.read_csv(StringIO(temp))
dialog.ShowModal()
s.close()
end = len(lst)
raise RuntimeError(msg.format(this.db_name))
parser = argparse.ArgumentParser()
os.unlink(f.name)
app = QtGui.QApplication(sys.argv)
W = np.random.normal(size=(X.shape[1], 1))
age = models.IntegerField()
type.__new__(cls, name, bases, dict_)
pool = mp.Pool(num_processes)
results = []
B5 = A5 + B4
l.append(k)
words = [line.strip() for line in open(WORDS_FILENAME)]
self.session_store = sessions.get_store(request=self.request)
wx.EVT_TIMER(self, self.belltimer.GetId(), self.OnBellTimer)
x
consumer.start()
height = math.sqrt(max(outer_radius * outer_radius - i * i, 0))
ls[1] = int(ls[1])
print(self.layers[2][0].value)
print(A * x)
layout.addWidget(button)
formdata.update(data)
b = np.random.choice(vals, size=w)
property1 = ndb.StringProperty()
4, 5, 6
b.sort()
images = ImageItem.objects.filter(user=user)
donut = numpy.logical_and(circle < 6400 + 60, circle > 6400 - 60)
rng[argunsort(np.argsort(l))]
all(a == z)
resultList = [1, 2, 5, 7, 9]
self._store_aggregation_timer.start()
sortkeys = {v: k for k, v in enumerate(b)}
x._get_numeric_data().apply(axis=0, func=np.log2).mean()
ax = fig.add_subplot(1, 1, 1)
pad(a, b, offset)
c = Cl()
filename = os.path.abspath(sys.argv[1])
errors.append((srcname, dstname, str(why)))
DataFrame(simpleObject.exe(), ssqlContext)
plt.show()
self.addLine(xc, 0, xc, height)
path = self.args[0]
s.index = s.index.droplevel(-1)
p.terminate()
values = map(float, f2.read().split())
X, Y = np.meshgrid(np.linspace(0, 5, 100), np.linspace(0, 5, 100))
print(c)
self.xoo = x
os.path.dirname(os.path.realpath(sys.argv[0]))
im = Image.open(old_image_path)
thread = threading.Thread(target=your_code)
result.append([l])
l[0]
mu, sd = 0, 1
f(1, 2)
self
result[i] = np.random.hypergeometric(colors[i], remaining[i + 1], m)
a[0].append(7)
N(h, 6, 9)
stud = session.merge(stud)
Q.set_UVC(U, V)
setattr(instance, key, value)
print((event.x, event.y))
p = ProcessPoolExecutor(2)
json.loads(responseJSON)
ax = pylab.gca()
cnx.close()
content = json.load(file_handler)
df2[needed_columns] = df.reindex(index=df2.index, columns=needed_columns)
timestamp1 = time.mktime(datetime.now().timetuple())
driver.get(pageLink)
ModelForm = self.get_form(request)
d = collections.defaultdict(list)
func(self, *args, **kwargs)
dict = pickle.load(file)
x, y = cluster[:, (0)], cluster[:, (1)]
links.append(t.post_set.distinct())
QtGui.QMainWindow.__init__(self)
arrA = np.asarray(A)
timer2 = fig.canvas.new_timer(interval=50)
odict[key] = odict.pop(key)
self._rooms = {}
row_result = []
Atomic.register(str)
True
self.errors = np.ndarray(0)
np.bincount(r, dists < R ** 2, minlength=tot_vec)
p = Process(target=start_server)
nextelem = next(licycle)
second.append(4)
n = np.random.randint(400, 800)
--main.lua
max_area = 0
result.append(prev)
log.close()
a = read_dict_from_file()
reactor.callLater(timeout, sendelayed, data)
x_new = np.linspace(np.min(x), np.max(x), x.shape[0])
output.append(letter)
arr[97][99][98]
node_data.append(node_to_dict(lnode, {}))
numpy.mean(a), numpy.std(a)
d.update(buf)
sh = shape[0], a.shape[0] // shape[0], shape[1], a.shape[1] // shape[1]
self.socket.sendto(data, self.address)
elem.clear()
res = np.zeros_like(arr, int)
print(self.x)
ans = []
math.factorial(arg)
self.window.set_border_width(10)
X = np.random.randn(1000.0, 5)
pubkey.verify_init()
sentence_dict = {}
sys.__excepthook__(type, value, tback)
sizer.Add(btnGreen, 0, wx.ALL | wx.CENTER, 5)
ax.plot(np.sin(x))
reader = csv.DictReader(csvfile, dialect=dialect)
data = urllib.parse.urlencode(values)
a.printout()
print(some_list)
False
items = match.groups()
pre_save.connect(do_something, sender=MyModel)
bri.close()
iter(list(range(expecting(offset=0))))
self.request = request
print(yaml.dump(data))
a[tuple(idx.T)] = [5, 10, 15]
strings = [x for x in listEx if isinstance(x, str)]
YAR002W = apoptosis
parser = xml.sax.make_parser()
newlist = [newdata[v] for v in ordering]
tail = list(it)
phi0 = a[-1]
list_a = np.array([1, 2, 4, 6])
self._sub_results[key]
p = pyaudio.PyAudio()
someModule.init(NECESSARY_DATA)
out = np.zeros((m, n))
x = pattern.sub(lambda i: substitutions.pop(0), some_text)
data = np.random.normal(0, 1, (1, 5))
cleaned_url
C = list(Concate.keys())
concurrent.futures.wait(futures)
_value
data = image.load()
o = urlparse(url)
k.release_key(k.left_key)
math.pi
i += 1
json_obj = json.loads(res.content)
stuff()
fil = os.path.join(fol, fil)
(x1 + x2) / 2.0
t.set_position((shift, 0))
colors = cm.RdYlBu(np.linspace(0, 1, n))
L = [sample(xr, 5) for each in xr]
app.run()
zip_longest(fillvalue=fillvalue, *args)
df2.iloc[0, 0] = 42
True
cursor.execute(some_statement)
it = iter(data)
slices = [sli for sli in (list(islice(it, 0, i)) for i in seclist)]
list(d.items())
a * np.exp(-b * x) + c
s2str = series2.astype(np.str)
MyList = [d[k] for k in [x, y, z]]
exch(k, j)
iters.remove(it)
socket.listen(5)
a[2] = 4
sd.append(step_decay(len(self.losses)))
range_end = 10 ** n - 1
scat = ax.scatter(x, x, s, c)
count = 0
plt.legend()
df = pd.concat([df, pd.read_csv(file)])
saver = tf.train.Saver(variables_to_restore)
example.get_time()
Child.do_something()
current.append(line.text)
print(item)
query = select(e for e in MyEntity if e.attr > f(x, 200) and g(x, e))
dec(f, *args, **kwargs)
v.clear()
numpy.dot(a.T, numpy.cross(b, c))
globals_.update((name, modict[name]) for name in names)
results = []
myData.close()
print(multiprocessing.current_process())
someDict.keys() & someSet
app = web.application(urls, globals())
items.append((lambda i: lambda : dump(i))(i))
first_loop()
Z1 = plt.mlab.bivariate_normal(X, Y, 1.0, 1.0, 0.0, 0.0)
deleteArtofWarCounter[word]
scoreB += 1
xs, ys = (x[0] for x in xs), (y[1] for y in ys)
np.bincount(binNum)
values.append(value)
hxs = HtmlXPathSelector(response)
o.writebits(ord(c), 7)
db = conn.test
alist == sorted(alist)
mask = series1 > series2
get_pickling_errors(K)
ax.set_xlim(0.0, width_of_im)
betas = rdf.apply(beta)
self.process = self.process.load()
self._box.close()
response = br.submit()
print([(int(col) if type(col) == float else col) for col in df.columns])
self.errorcount = 0
self.noisycount = 0
x ** 2
color_radios_ax = fig.add_axes([0.025, 0.5, 0.15, 0.15], axisbg=axis_color)
raise SystemExit(0)
groups = df.groupby(np.digitize(df.a, bins))
mydict = {}
target_f.write(_bytes)
d1[k] = v2
cartesian(a, b)
gen = (x[0] for x in tups)
yertle.end_poly()
ModelAdmin.__bases__ = (CustomModelAdmin,) + ModelAdmin.__bases__
self.lock = Lock()
fg1 = bg1.apply(frame)
myList.append(random.randint(0, 1))
id(foo.__code__) == id(foobar.foo.__code__)
db.create_all()
0, 0, 4, 1, 0, 48, 8, 1, 64, 48, 7
self.rectangle = numpy.hstack((self.pos, self.size))
table.setdefault((w1, w2), []).append(word[0:-1])
np.minimum(b, np.maximum(a, c))
arg_test()
swap(i, 0)
object.__new__(Parent._children[k])
f / 2.0 ** (len(b) - s) if s else f
print(args.xDate)
channel = self.ssh.invoke_shell()
StringIO.__init__(self, stdout)
depth = root[len(path) + len(os.path.sep):].count(os.path.sep)
temp = map(str, L[j:])
dis.dis(x)
response = urllib.request.urlopen(req)
deletetest[1]
output = {}
lis.append(x + y)
False
plt.subplot(211)
m[int(y) + (x - 1) * N] = 1
draw.line((0, i, 100, i), fill=random.randrange(256))
crawler_process.start()
primfac.append(n)
b = np.diff(a)
CLOCK_REALTIME = 0
crawler.configure()
print(p.map(lambda x: (lambda y: y ** 2)(x) + x, range(10)))
t = f()
df = DataFrame(table, columns=headers)
positions = np.vstack([xx.ravel(), yy.ravel()])
imshow(mycmap(Z1), extent=extent)
a_sorted = a[idx]
text
exit(i)
axes.plot(rx(t), ry(t), t)
food_ctx.add((alice, likes, chocolate))
mail.login(SMTP_USERNAME, SMTP_PASSWORD)
new_command
a.value
draw()
plt.show()
self.text1.pack(side=TOP)
client.add_flags(msg_ids, [SEEN])
a * math.exp(-(x - b) ** 2 / (2 * c ** 2)) + d
buf = f.read(8192)
outputData.append(str(i))
threshold(gray, bin, 127, 255, THRESH_BINARY_INV)
df.Tm.cat.set_categories(sorter, inplace=True)
clf.estimators_[1]
dt = numpy.dtype(dt)
disj_part = list(combinations(nots, k))
b_ext = np.row_stack((b, b[:-1]))
ss = sum((x - c) ** 2 for x in data)
logger.addHandler(ch)
len(self.datatable.columns.values)
formatted(1e-21)
self.lock = threading.Lock()
print(solve([fCamel, fCamel, fCamel, gap, bCamel, bCamel, bCamel]))
new_list = remove_empties(new_list)
self.figure.canvas.flush_events()
punkt.train(fin.read(), finalize=False, verbose=False)
bucket = conn.get_bucket(bucket)
print(q.get())
im = [np.zeros((nums + 1, nums + 1)) for i in range(len(xs))]
WORKDIR / srv
deletea[k]
lst_as_sets = map(frozenset, lst)
socket.__file__
os.seteuid(501)
foo.BAR
id = fields.String()
self.close()
m_list[i] = v.union(m_list.pop(j))
mfg / recommend
ln, = plt.plot([])
ax = fig.add_subplot(111)
print(self.data)
bg.close()
b = models.CharField(max_length=5)
idx = bisect(fst, 2)
[0, 0, 2]
PnP = 1
s[1:] + s[0]
foo = Foo()
sortToFile.write(line)
cur_num = int(os.path.basename(files[-1])[6:-4])
numbers = list(range(1, 11))
p.leading = 120
list(closed_range(10, 1, -1))
d = visdel()
km.fit(some_data)
print(result)
xy = np.vstack([x, y])
memory_zip.write(parent_zip.open(child_zip_path).read())
print(item)
ws.set_paper(9)
gx, gy = np.gradient(Z, 0.05, 0.05)
beta = scipy.solve_triangular(R, Q.T.dot(y))
diff[key] = list(set(a[key]) - set(b.get(key, [])))
c1 = Counter(l1)
callers_local_vars = list(inspect.currentframe().f_back.f_locals.items())
fig, axs = plt.subplots(1, 2)
n = len(archive.getnames())
youtube_regex_match.group(6)
user_fistName = db.Column(db.String(64))
self.src[-2].insert(0, itemtoshift)
pinf == ninf
sh.write(m, 0, e1)
a = [True, False, True]
assert all(r1 == r2 for r1, r2 in zip(result, result2))
scriptable = Scriptable()
results.append(point)
base64.decodestring(self._data)
n = a.shape[0]
seen.update(b)
self._jrdd_deserializer = rdd._jrdd_deserializer
func(*a_b)
fig, ax = plt.subplots()
instance.do_stuff()
self.textLayout.setMargin(10)
name, ext = os.path.splitext(os.path.basename(os.path.normcase(FILE_NAME)))
diff.append(all)
number = models.IntegerField(default=0)
execute_from_command_line(sys.argv)
self.roomManager.set_handlers()
plt.savefig(*args, **kwargs)
curl.setopt(pycurl.PROXYTYPE, pycurl.PROXYTYPE_SOCKS5)
cls.INVITE_MESSAGE
mail.send(fail_silently=fail_silently)
-54.5
-51.9
data = self.fd.read(size)
test(re)
platform.python_compiler()
PLT.show()
f = figure(figsize=(10, 10))
ind = np.nonzero(lo_or_hi)[0]
data = connection.read()
Makefile
pl.show()
indata[i] = (ctypes.c_double * 6)()
l = [0] * n
c = np.concatenate((a, b), axis=1)
address = models.CharField(max_length=50)
ttt = ttt + 1
oldWindow.get_child().reparent(newWindow)
next(f)
isinstance(n, numbers.Number)
results = []
sys.stdout = s
plt.yticks(np.arange(0.5, len(df.index), 1), df.index)
kwargs.update(dtype=float128)
print(any(list_item in fruit_dict2 for list_item in fruits))
print(F)
s.login(hostname, username, password)
application.listen(8888)
name = models.TextField(max_length=100)
s = frozenset([1, 2])
transitions = (array[1:] != array[:-1]).sum()
q = q.prefetch(Order.supplier)
sign(self.predict(inputs))
list.selection_set(items[0])
self.reader = csv.reader(self.f)
x = x + K * y
[1, 0, 2, 0]
print(hello_world)
queue.append((key, result))
raise TimeoutError(error_message)
fout.write(line)
QtGui.QBrush(QtCore.Qt.darkBlue)
xcenter = len(x) / 2
np.random.seed(1)
value = df.loc[5]
Py_DECREF(pName)
x = canvas.canvasx(event.x)
[0, 1, 1, 1, 1],
wrapper
lens = np.array([len(item) for item in v])
pf.close()
array([4, 6])
heatmap, xedges, yedges = np.histogram2d(x, y, bins=50)
d[keys[-1]] = value
key, val = line.split()
[mo.group(1), mo.group(2)]
w = dict((x, i) for i, x in enumerate(a))
y = [(k, v) for k, v in x if d[v] == k]
image.deleteThumbnail()
ret = np.maximum.reduceat(csr_mat.data, csr_mat.indptr[:-1])
c.my_property
tn.write(idpass)
datetime.date(self.year, self.month, self.day)
b = [[(y if y == max(x) else 0) for y in x] for x in a]
start = time.time()
print(test.f(666))
print(x[5], x[8], x[9])
--allow - all - external
a = (10 * np.random.randn(10, 10) + 127).astype(np.uint8)
do_three()
roi = cv2.bitwise_and(source, source, mask=mask)
PyErr_Print()
self.addCleanup(patcher.stop)
raise argparse.ArgumentError(self, message)
G = nx.DiGraph(input_data.values)
dict([(c, 0) for c in strg])
y = np.repeat(y, 100, axis=0)
data = json.loads(json_txt)
grouped_by_soundex = defaultdict(list)
0 - 0 - 0
sparse_mult(a, b, [(0, 0), (0, 4999), (1999, 0), (1999, 4999)])
c[:len(a)] += a
self.regularization = j
oldval = oldval * random()
nums = map(bin, map(int, _in.read().split()))
match = sm.find_longest_match(0, len(answer), 0, len(prediction))
string
a = []
d = np.delete(a, np.where(mask == False))
main()
F0 = numpy.where(mask0, F_mid, F0)
data = np.random.rand(nrows, ncols, nframes)
response = urllib.request.urlopen(req1)
X_train = Xy_train[:, 1:]
msg
(np.array(pts) ** 2).sum()
df.AVG_GRADE = list(map(list, zip(df.HOUR, df.AVG_GRADE)))
df
np.savez(filename, **attributes)
bytes = input()
aapl_200ma = pd.rolling_mean(aapl, 200)
raise ValueError()
df = pd.DataFrame(np.random.choice([1, np.nan], (10000, 1500), p=(0.01, 0.99)))
doc2vecmodel.train(sentences)
lstm_variables = [v for v in tf.all_variables() if v.name.startswith(vs.name)]
print(data.text)
form = FooForm
pruned = [[i for i in sublist if i < n][:sublist_length] for sublist in ls]
n ^ 1 << k
print(elb.getInput())
df = pd.DataFrame(data=np.random.normal(0, 1, (20, 10)))
XmingProc.wait()
print(item)
obj.__set__(self, value)
zip(a, b)
rolling_dd = pd.rolling_apply(s, window_length, max_dd, min_periods=0)
print(test.__defaults__[0])
config = tf.ConfigProto(allow_soft_placement=True)
print(mystring % (wash_clothes, clean_dishes))
sys.exit(2)
user_input = input()
my_checker = SpellChecker(my_dict)
l.append(id(x))
str_num = str(num)
ord1[0] += 1
sorted(indices)
valid_date = datetime.datetime.strptime(date, fmt)
print(queryset.query)
data = f.readline()
r = urllib.request.urlopen(urllib.request.Request(url))
fig = PLT.figure()
[output]
libraries.append(arg[2:])
Tools > Prefences > General
line.set_data([], [])
plt.figure(figsize=(18, 6))
df = df.astype(int)
print(new_grammar.productions()[-1])
app = main(settings)
self.cleaned_data
ax = fig.add_subplot(111)
tableWidget.setCellWidget(0, 1, ImgWidget1(self))
agged = df.x.groupby(df.x.isnull().cumsum()).agg(f)
key = self.rel.get_related_field().name
author_id = Column(BigInteger, nullable=False, index=True)
a.A
cmap = matplotlib.cm.jet
UserModel().set_password(password)
i += 1
main()
wx.Bell()
result = df.loc[(first[0]), first[1]:last[1]].min()
self.sum += value
file_B.do_B_stuff
b.append(j)
deleteordered[tN]
value = str(int(value))
threadLimiter.acquire()
response
tn = telnetlib.Telnet(HOST, PORT)
element.text = text
self.FileModel.setCondition(text)
hash(x)
root.destroy()
yet_to_run += 1
soup.span.renderContents()
a.sum()
head[(0), :] = 16
f.seek(step, os.SEEK_END)
num = np.array([1.0])
redis.Redis.RESPONSE_CALLBACKS[command](response)
logit_val = sess.run(logits)
self.__func__(self.__self__, *args, **kwargs)
assert len(c) == 0
print(self.x)
results = Result.objects.filter(id__in=obj.result_set)
d_with_str_keys = dict((str(k), v) for k, v in d.items())
pyplot.savefig(sio, format=format)
plt.xlim(0, 47)
self.i = 0
corn = Corn(201212)
a = numpy.array([d, d, d], dtype=numpy.dtype(decimal.Decimal))
result = [m.group() for m in matches]
inner()
print(myformat)
7, [False, False, False, False]
Counter(y) - Counter(x)
msg_contant = process_multipart_message(msg)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
win.add(bro)
iter(f.readlines())
print(tuple(exp.findall(st)))
ascii_lower = set(string.ascii_lowercase)
df
reps.append(rep)
niceText = pprint.pformat(yourDict)
self.assertEqual(t.render(c), output)
self.is_running = True
cls(key_name=key_name, delete_when=deadline)
plt.show()
libraries[4:12]
set_request(request)
req = urllib.request.Request(url, data)
p.join()
logger = logging.getLogger(__name__)
frequency_list.sort(reverse=True)
vectorized_sparse = vectorizer.fit_transform(train_as_dicts)
d.most_common()
bytes += stream.read(1024)
arr = np.empty((initial_guess, M))
1
self.children = children
print(data[0])
ws.set_horz_split_pos(1)
t[2] += AddIDemo([5, 6])
names = Employee.objects.filter()
self.text_area.grid(row=1, column=1)
df2 = df1.copy()
d.setdefault(x % 10, []).append(x)
brr[:] = brr[sort_indices]
dt = datetime.fromtimestamp(posix_timestamp, tz)
ss.dtype
sm.OLS(y, X)
guess_mean = np.mean(data)
print([f(k) for k in range(4)])
result[i][j] = result[j][i] = val
print(my_content)
old_stdout = sys.stdout
plot(y1[1])
raw_value = int(eval(input()))
json_obj = json.load(response)
d[key].extend(flatten_group(preserve_path(value)))
q += 1
File.close()
self.right.sillywalk()
X, Y = np.meshgrid(x, y)
list1.extend(map(str, value))
logging.basicConfig(format=FORMAT)
log.addHandler(handler)
size = os.stat(fn).st_size
fig = oldfig(*args, **kwargs)
ix = np.unravel_index(i, ax.shape)
pd.DataFrame(arr)
neighbors.remove(parent)
g.__name__
C = numpy.swapaxes(temp, 1, 2)
n += 1
b = a.reshape(-1, N)
pylab.close(fig)
fmt.Println(s)
nextB = iter(self.Blist)
s = requests.session()
args = parser.parse_args()
self._lock = threading.Lock()
b = pd.Series(pd.np.random.randn(100000))
cap.set_markeredgewidth(10)
short_sha = repo.git.rev_parse(sha, short=4)
thread.start()
cols = [2, 2]
objects = models.GeoManager()
ax2 = ax.twinx()
Foo.f = f
result = Image.composite(background, foreground, mask)
form = BlogForm(request.POST)
h, l, s = colorsys.rgb_to_hls(r, g, b)
sgn = -1 if n < 0 else 1
attr_names = [c_attr.key for c_attr in inst.mapper.column_attrs]
1, 8, 1, 1
a = np.where(np.isnan(a), b, a)
a = 1
print(rPM(PROCESS, ADDRESS1, ADDRESS2, 64, ctypes.byref(bytes_read)))
stdscr = curses.initscr()
b2.grid(row=0, column=1, pady=10, padx=10, sticky=Tkinter.SE)
a = 6.75
line = infile.readline()
print(i)
False
new_array = a == b
print(x)
df2
Queue(maxsize=0)
print(normalized(A, 2))
self._bymonth
M.append(counter)
print(df)
asyncio.get_event_loop().run_until_complete(wait_first())
a = A()
std_dev = math.sqrt((s0 * s2 - s1 * s1) / (s0 * (s0 - 1)))
logo = logo.resize((100, 100), Image.ANTIALIAS)
auth_handler = urllib.request.HTTPBasicAuthHandler()
node = path[-1]
flattened = np.array([x_data[i].flatten() for i in range(0, numImages)])
print(get_title())
l1[:target_index]
outf.write(int(line, 16))
i = 1
print(driver.current_window_handle)
log.write(message)
t.start()
yi = np.linspace(Y.min(), Y.max(), 1000)
ast.parse(code)
b = [6, 7, 8, 9, 10]
cur = con.cursor()
pickled_string = pickle.dumps(a)
fit.params[1], fit.params[0]
dave = person
data = np.arange(-50, 50).reshape(10, 10)
agf(2)
print(out.decode())
curdir = os.getcwd()
env.AddPreAction(target, action)
s.indices(sys.maxsize + 2)
paw = models.CharField(max_length=2, choices=paws)
wide_df = pandas.read_csv(mockcsv, index_col=[0, 1, 2], header=[0, 1, 2])
self._post_init(srid)
execute(task, hosts=hosts)
Delete()
print(x, y)
self.close()
n = len(lst)
t.start()
print(s)
FigureCanvasWxAgg.__init__(self, parent, -1, self.figure, **kwargs)
w.writerows(data)
roundedA = a.replace(hour=0, minute=0, second=0, microsecond=0)
self.crawled_urls.update(x[0] for x in cur.fetchall())
json.dumps(dudette.json())
df[cols]
set(a).intersection(set(b)) == set(a)
n_values = np.hstack([[0], n_values])
output.close()
result = {}
q = session.query(myClass)
cNorm = colors.Normalize(vmin=0, vmax=values[-1])
root.mainloop()
print(slugify(text))
transaction.get().addAfterCommitHook(redirect_to_trial, kws=kwargs)
main()
gtk.main_quit(*args)
input = [server]
print(line_with_keyword)
dict_del
countries_dict = dict(COUNTRIES)
sb.palplot(sb.color_palette(n_colors=8))
today.year - born.year - 1
yacc.yacc()
globals().update(borrowed_globals)
a = [-2, -2, 0, 0, 0, 0, 0]
df.index = pd.to_datetime(df.date)
[5]
testfunc()
average_speed = numpy.average(speeds, weights=speeds > 0)
np.random.seed(0)
gc.collect()
question = Question.objects.get(pk=id)
ax, _ = mpl.colorbar.make_axes(plt.gca(), shrink=0.5)
print(len(Example))
main()
f.write(content)
driver = webdriver.Firefox()
print(yaml.dump(a))
X_test = np.concatenate((X_test, catVar), axis=1)
np.ndarray(arr.shape, dtype2, arr, 0, arr.strides)
lg = numpy.where(lg == -numpy.inf, 0, lg)
ReturnStatement().act()
256 * tup[1] + tup[0]
importlib.import_module(module)
_f_array[a, b]
b = attrdict()
a = pixels[:num_pixels]
s.close()
f.read()
c.close()
big_array[chosen_slice][chosen_part]
self.mouth = 1
start = datetime(start_year, start_month, 1)
wnd = gtk.Window()
G_mean1.append(G)
self.setLayout(self.hlayout)
print(df2)
prod, x, y = heapq.heappop(heap)
hxs = HtmlXPathSelector(response)
response = client.get_spot_price()
print(serializer.getvalue())
type.__new__(metacls, name, bases, dct)
df
d[x] = []
N = int(eval(input()))
self.window = gtk.Window(gtk.WINDOW_TOPLEVEL)
fit0 = gev.fit(data)
print(sum)
x = 5
x = sum(starmap(similarity, product(a, b)))
_compile(pattern, flags).findall(string)
self.request.send(self.data.upper())
process(arg)
f(a)
sb.toString()
pil_im = Image.fromarray(cv2_im)
response = requests.post(url, data=data, headers=headers)
laparams = LAParams()
V = (1 / r).sum(axis=1)
tornado.ioloop.IOLoop.instance().start()
result = {}
chr(97)
text
cell = sheet.cell(r, c)
going = False
self.add_widget(my_box1)
x_decor.sort(key=lambda itm: itm[1])
f.close()
self._list.__delitem__(key)
cursor = conn.cursor()
args = parser.parse_args()
_clients[name]
data = np.ones(N, dtype=dtype)
heapify()
codecs.unicode_escape_decode(x)[0]
plt.plot(xx, piecew(xx))
net.addConnection(FullConnection(hidden0, hidden1))
loc = ax.xaxis.get_major_locator()
print(op(1, 2))
polygon = plt.Rectangle((x, y), w, h, color=c)
y = defaultdict(lambda : defaultdict(lambda : 0))
a == b
out = []
x
request.user.is_authenticated() and request.user.is_admin
Logger.manager.getLogger(name)
plt.colorbar()
M.sum((0, 1))
self.left.sillywalk()
print_lock = threading.Lock()
eigvals, eigvecs = np.linalg.eig(np.cov(xy))
d = json.loads(h)
do_something(server.local_bind_port)
cups_lib.cupsFreeDests(num_dests, dests_p)
scheduler.start()
ids.extend(list(range(int(xr[0]), int(xr[1]) + 1)))
ax = fig.add_subplot(111)
table.wrapOn(c, width, height)
(a == b) | (a != a) & (b != b)
OPTION_C = 1 << 2
dir(parrot)
a = A()
child_count = instance.children.count()
self.stream.write(msg.encode(self.stream.encoding))
_members_[key] = value
root.wait_visibility()
nums = [1] * n
image = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
tree.parse(source, parser)
client.auth_token = gdata.gauth.OAuth2TokenFromCredentials(credentials)
t.join()
B = np.where(A == value)[0]
points = [(0, 10), (10, 20), (20, 40), (60, 100)]
b = randint(0, 10)
arr = [[]]
np.array([u[1], -u[0] + np.sqrt(u[0])])
list(range(len(list1), 2))
True
out = (mask * prior_reci + ~mask * (0.1 * prior_reci)).sum(1)
BaseObject.x
canvas.create_image(image.size[0] // 2, image.size[1] // 2, image=image_tk)
df[numeric_cols].apply(zscore)
tk.Tk.__init__(self)
c[c < 0] = 0
order_array.dtype
self.i = i
x, y, z = np.ogrid[0:500, 0:500, 0:500]
style = window.get_style()
b = numpy.power(a, 2)
self.write_cell(sheet_name, cell, existing_value, updated_format)
src / Makefile
ax1 = fig.add_subplot(212)
min(start1, start2), max(end1, end2)
array_of_strings[0, 0][0, 0]
print(list(zip(x, y)))
new_dic_defaultdict[1][2] = 5
df
sys.modules[module_name] = module
T = numpy.linspace(-10, 10, 100)
not True == 0
event.Skip()
print(d)
original_init(self, a)
data = {h: v for h, v in zip(header, zip(*values))}
entropy(data) - weighted_ent, subset1, subset2
new_string
df = pd.DataFrame(data2)
frame = cv.RetrieveFrame(cap)
sift(0, i)
a[1:4] = [9, 7]
jython
C = np.dot(A, B)
hist, bins = np.histogram(data, bins=50)
c = list(zip(*b))
deletesieve[::item]
my_dict = dict((k, some_func(k)) for k in input_list)
screen.nodelay(True)
http = cred.authorize(httplib2.Http())
FFT_FREQS_INDS = -numpy.ones_like(FFT_FREQS)
result = _addup(n)
hets.append(1 - pf)
fh.write(bytes)
t = threading.Thread(target=self.handle_request, args=(c,))
s.truncate(0)
self.background_color = [1, 1, 1, 1]
self.logger.error(error.message)
pp.show()
first_length = len(first) + 1
plt.gca().add_collection(coll)
l1[:target_ibdex + 1]
x ** (m * n)
work_with_cube(array[x, y, z])
globals()[module_name] = m
logkde = kde.score_samples(Vecpoints)
auth = OAuthHandler(consumer_key, consumer_secret)
ygrid = np.linspace(y.min(), y.max(), 100)
print(number_string[:2])
nearest = min(sources, key=lambda s: distance(s, demand))
target_metadata = Base.metadata
source = urllib.request.urlopen(url).read()
times = list(range(8, 21, 4))
bool(())
print(felf.__name__, felf.__doc__)
d = datetime.datetime(2011, 2, 28)
Py_DECREF(args)
print(sys.version)
pl.figure(figsize=(10, 5))
event.canvas.draw()
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
print(match.group())
ax2.grid(False)
print(calendar.month(2011, 8))
Contexts
app = QtGui.QApplication(sys.argv)
file_handle.write(text)
index.append([keyword, [url]])
suite = eval(sys.argv[1])
xyz = np.array((x, y, z))
self.members.append(person.key)
sites[parts[0]].append(fname)
some_value = new_value
r = tf.reduce_sum(A * A, 1)
y = random.random()
faction
True == 1
object.__new__(cls, *args, **kwargs)
self.height = height
celery.current_app.control.inspect().ping()
df2.A.plot()
self
match = regex.match(line)
x_coord = radius * np.sin(theta) * np.cos(phi)
conds = [x < 0, (x > 0) & (x < 1), (x > 1) & (x < 2), x > 2]
obj = Test()
img1_k.append(0)
conn.send(chunk)
d.append(x.kpc)
word.istitle()
B = np.array([[7, 8, 9], [10, 11, 12]])
readline.clear_history()
total += nested_sum(item)
channel = client.invoke_shell()
print(x)
common = len(set(left) & set(right))
wa = np.bincount(a)
folder = FTPTree()
smtp.connect(mx[1])
b = A(20)
self._seed = int(x) + 1, int(y) + 1, int(z) + 1
print(thetd.string)
b = a + (4, 5, 6)
x = foo()
writer = csv.writer(fin)
x.pop(l - i)
ax.invert_yaxis()
Decimal.__round__
t = np.arange(0.0, 1.0, 0.001)
B.append(a)
client.set_missing_host_key_policy(AllowAllKeys())
preproc = image / average
Page.__init__(self, *args, **kwargs)
self.assertDictEqual(dict1, dict2)
print(d)
print(Xfit_mono)
matches = [x for x in lst if fulfills_some_condition(x)]
np.sum(v)
int(argv[1])
angle += 2 * math.pi
axes = fig.add_subplot(1, 1, 1)
print(f.__dict__)
us.append(dict(zip(fs, t)))
print(a is b)
result = doc.getvalue()
minList.append(a)
deletepak[IP].chksum
self.show()
name = StringField()
pr.disable()
m = int(n * (log(n) + log(log(n))))
[False, True, False],
x = frozenset(x)
L = [list(range(5)) for each in range(5)]
self.thisobj = obj.thisobj.clone()
final = np.zeros((6 * N, 6 * N), dtype=A.dtype)
ax = plt.gca()
print(converted_value, type(converted_value))
data = json.loads(st)
author_id = models.AutoField(primary_key=True)
db.collection.update(criteria, objNew, upsert, multi)
a[j, i]
cdf.append(total)
email
A = 0.5 * ((1 - s) * np.cos(a - b) + (1 + s) * np.cos(a + b))
self.object_list = self.get_queryset()
np.maximum.at(diam, data[:, (0)], dist_to_center)
vif = minv.dot(corr).dot(minv)
y = numpy.array([4, 5])
n = ord(b)
fd = sys.stdin.fileno()
regex = re.compile(regex_string, re.MULTILINE)
logger.handlers.pop()
print((item, others))
hours, minutes, seconds
view_func(request, authenticated_by_ip, *args, **kwargs)
df.sum()
data = [math.sin(2 * math.pi * freq * (x / frate)) for x in range(data_size)]
X = np.array([(n.x, n.y, n.z) for n in cell])
result = [i for k, g in groupby(lst, f) for i in (g if k else (sum(g),))]
print(sys.version)
death_month = death_data.get(2).value
module = __import__(module_name)
dreload(myCoolModule)
print(server.div(10, 2))
type(filt)
resize_canvas()
features = tf.parse_example(batch_serialized_examples, feature_to_type)
raise ValueError(msg.format(a, b, c, len(L)))
recurddict = lambda : defaultdict(recurddict)
cache.product_part_number
config
self.axes = self.fig.add_subplot(111)
pygame.init()
list(OrderedDict([frozenset(list(Counter(tup).items())), tup] for tup in data).values())
K.mean(K.pow(y_true - y_pred, 2) * W)
calculator.show()
today = date.today()
index += 1
beeper()
lr = LinearRegression(**params)
fig = plt.figure()
rows, cols
exampleItem.exampleName(row, column, name)
dot(self.Vt[:n].T, (self.dinv[:n] * p).T).T
NULL
soup = BeautifulSoup.BeautifulStoneSoup(s)
server_url = app_identity.get_default_version_hostname()
print(line)
print(word)
x, y = a[b], a[mask]
set.add(item)
names = np.random.choice(np.arange(N), size=100, replace=False)
print(repr(strs))
AFMT_S16_NE = ossaudiodev.AFMT_S16_LE
self.countdown(10)
print(browser.url)
logging_thread = threading.Thread(target=logData, args=(input_queue,))
ret[l[1]].add(l[0])
l.append(v)
self.y_without_NaNs = y.copy()
a = np.random.randn(100, 2500)
a = np.random.randint(0, 100, 1000)
plt.subplot(122)
0
assert c.shape == (a.shape[0], b.shape[1])
metadata = sa.MetaData()
self.right.pop()
soup = BeautifulSoup(HTML)
Foo.initStuff()
index.sort()
D = C.reshape((1, 8))[0]
print(pd.DataFrame(d1))
input_file = sys.stdin
now = dt.datetime.utcnow()
ax.yaxis.set_major_formatter(EpiCycleScalarFormatter())
item_q.put(StopIteration)
data = file_.read()
values = [e.value for e in CommonNames]
a = [0] * 10
print(x[(0), :])
draw = ImageDraw.Draw(im)
print(key, value)
print()
ax.axis([1, 10000, 1, 100000])
b = jpeg.read(1)
readline.set_completer(MyCompleter().complete)
A - mean
something
work()
self._log_handler
schema = etree.XMLSchema(schema_root)
p = figure(width=400, height=400)
self.app.exec_()
G = (list(x) for _, x in groupby(enumerate(L), lambda i_x: i_x[0] - i_x[1]))
found = False
yaml.load(s)
fhandle.seek(1, 1)
np.sum(r ** 2 - r) * 4
a.__dict__
rand_num = random.randint(0, 99)
logger = logging.getLogger(__file__)
basis = [(lambda x, n=n: n * x) for n in [0, 1, 2]]
im.set_data(arr)
canvas = Canvas(master)
os.path.splitext(fname)[0][8:]
temp = [line.split() for line in datfiles[0]]
print(list(l))
TOP = os.path.dirname(os.path.dirname(your_application.__file__))
a[key] = b[key]
keybd_event(Key, 0, 2, 0)
f.encoding
conn = session.connection()
print(key, value)
fig = plt.figure()
df = grouped.aggregate(lambda x: tuple(x))
time.sleep(5)
self.bcount = 0
current += os.path.getsize(path)
outputStream.close()
grouped = df.groupby(keys)
x[-1]
y = list(range(h))
a.dtype
event.accept()
count += 1
xcen, ycen
pickle.loads(pickle.dumps(x))
print(list(vary(target, pattern, subst)))
pos = available[random.randint(0, len(available) - 1)]
idx = a.cumsum()
G = nx.DiGraph()
sleep(0.1)
tf.random_uniform_initializer(-init_range, init_range)
event.canvas.draw()
os.lseek(fd, 0, os.SEEK_END)
self._global_wealth = value
s[positives].mean()
i = 0
length = len(string)
listOf[elem].append(idx)
b = a.ravel()
plt.setp(ax2.get_yticklines(), visible=False)
sys.exit(app.exec_())
True
w.start()
self.b = b
True
fig = pyl.figure()
a = collections.OrderedDict()
HTMLParser().unescape(s.get_data())
out = np.bincount(id[mask1] - 1, x[mask1])
im.putalpha(mask)
slen0 = len(s)
asyncore.loop()
explore()
print(repr(s))
next(f)
secondTest()
pd.isnull(y)
list(A.instances)
x = [[1, 2], 1, 1, [2, 1, [1, 2]]]
signal.alarm(seconds)
app = Application(__name__)
2, 2, 2, 2, 2, 2, 2, 2
switch[case_variable].__call__()
types_dict[t].setdefault(k, []).append(v)
getattr(self, name)
f(x=2)
myDict = defaultdict(int)
self.delete_async().get_result()
degrees(acos(distance)) * 69.09
v1 = e.args[0]
998
to_translate.translate(translate_table)
myfile = opener.open(myurl)
h, yedges, zedges = np.histogram2d(y, z, bins=50)
df = df.reset_index()
g()
ax2.grid(False)
L[i] += L[i - 1]
cased = lambda c: c.upper() != c or c.lower() != c
print(random_array.dtype)
self.queue = queue
l.append(42)
print(p, np.nonzero(rowsum == p)[0])
seenstrings.add(s)
result = input(msg).strip()
x = np.random.random(50)
stuff()
user_sessions.append(session.pk)
unittest.TestSuite(MyTest(num, expected) for num, expected in data)
ax.xaxis.major.formatter._useMathText = True
(1)(a, c)
analytics_data
g.add_edge(p, from_p)
A = sp.lil_matrix((5, 5))
print(foo.output)
numbers = [d[ni] for ni in names]
result = []
total_count += 1
b_result = []
round(2.4)
dill.detect.badtypes(f, depth=1)
self.current += 1
self._app = app
any(x > 4 for x in mylist)
r_getname()
sf = pd.DataFrame(data, index=[0])
bad.getparent().remove(bad)
q.task_done()
now = datetime.datetime(2009, 5, 5)
{t.tag: map(etree_to_dict, t.iterchildren()) or t.text}
lines_list = file_handle.readlines()
myapp / __init__.py
U, s, Vh = np.linalg.svd(a, full_matrices=False)
gen = ((x, y) for x in a for y in b)
o1 = np.argsort(arr1)
pro = subprocess.Popen(cmd, shell=True, preexec_fn=os.setsid)
r = requests.get(get_url, auth=auth)
font = ImageFont.truetype(font_path, font_size)
agf(1)
cust = models.ForeignKey(Customer)
numpy.save(memfile, a)
np.power(x1, x2)
ax6 = plt.subplot(gs[(2), 2:])
self.setFocus()
keys = list(d1.keys()) & l1
browser = webdriver.Chrome()
Evaluation.INCLUDE_AND_PRUNE
y = np.load(filename)
client.logout()
t.cancel()
stack.append([])
self.output_pipe.close()
cipher = AES.new(key, AES.MODE_CBC, iv)
self.sock = sock
writer.writerow(row)
rails = list(range(numrails - 1)) + list(range(numrails - 1, 0, -1))
main()
set_children_clip_box(cbar_ax, hdl.get_clip_box())
print(group_names(names, num_pages))
white = 255, 255, 255
tz._transition_info
print(N, i, sum / (N * 2 ** i))
logger.addHandler(fh)
sorted(value, key=sort_by, reverse=reverse)
newarray[ivec[j]] = averank
a + b
box = 70, 70, 100, 100
now += datetime.timedelta(days=7)
a[a == 255] = 1
child_queue = queue_manager.Queue()
new_time = time.time()
output = buf.getvalue()
Y[i] = Y[i - 1] * decay
driver = webdriver.Firefox(firefox_profile)
imgdata.seek(0)
collection = PatchCollection(patches, cmap=plt.cm.hsv)
np.rec.fromarrays(test2.T, mytype)
p = Pool(1)
list_.append(df)
u = np.array([1, 0, 0])
print(item)
self._initialize(result)
Final_Product = A.reshape(-1, R).dot(Combinations.T).T.reshape(-1, M, N)
print(core.publish_string(text))
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cookie_jar))
self._queue.put(line)
page.mainFrame().load(QUrl(url))
outf.truncate()
p = pyaudio.PyAudio()
print(df2)
abort(404)
response = self.browser.submit()
app = QApplication(sys.argv)
any(t.start() for t in threads)
a = tf.Variable(a0)
pent_new(i)
1 - y | 2 - n | 1 - n | 1 - n
d1 = {key: value for i, (key, value) in enumerate(d.items()) if i % 2 == 0}
y_itp = r * np.outer(np.sin(theta_itp), np.sin(phi_itp))
provided = set()
plt.show()
log(e)
self.__dict__, self.__class__.PARAM
z = r * cos(phi)
(fn(x + delta) - fn(x)) / delta
w = QtGui.QWidget()
self.sys_stderr = sys.stderr
set(larry) == set(moe)
c[0]
kwargs.append(params)
sentence = []
s[::2] + s[-1 - len(s) % 2::-2]
driver.quit()
found.add(item)
os.dup2(self.prevfd, self.fd)
doSomething()
hash = hashlib.md5()
df.date2 = pd.to_datetime(df.date2)
application = QtGui.QApplication(sys.argv)
self._succ_map[self]
print(oct(stat.S_IMODE(mode)))
user
B[:, (I)] = A[:, (L == I)].sum(axis=1)
cmd, call(cmd, stdout=outputfile, stderr=STDOUT)
test
init = tf.initialize_all_variables()
response = br.submit()
self.filter(age__gte=min, age__lt=max)
six_months = date.today() - relativedelta(months=+6)
test()
item = self.listWidget.takeItem(self.listWidget.currentRow())
startTime = time.time()
self.get_queryset()
_a(arctan2(c[1], c[0]), (c ** 2).sum(0) ** 0.5)
array
type.__new__(mcs, name, bases, dict)
shlex.split(command)
10 < a < 20
int(argv[1])
seconds = int(time.time() - time_start) - minutes * 60
matrix = np.array([i for i in range(24)]).reshape((6, 4))
Atomic.register(bytes)
fd.floatarr(pointer(ip), pointer(fpp))
d = np.sqrt((n - n.T) ** 2 + (m - m.T) ** 2)
gray = cv2.equalizeHist(gray)
prefix = a[0][:prefix_len]
x = 0
cax.get_xaxis().set_visible(False)
itemtypes = meta.ManyToManyField(ItemType)
lSongs.append(info)
D.__bases__
print(format_exception(e))
date_set = set(date_list)
beginx = 0
x = numpy.arange(20).reshape((4, 5))
widemapIV = dict((ord(x[0]), x[1]) for x in zip(normal, wide))
w.setCompleter(c)
self.submit.grid(row=1, column=2)
instance.project = Project.objects.get(title=offset)
df = DataFrame(np.arange(25).reshape(5, 5))
[self.from_db_value]
json_dict = json.load(f)
print(instance.Field1)
{0, 0, 0, 0, 0, 0, 0},
WSGIScriptAlias / khdx / home / galdosd / khdxweb / rel / khdx / apache / django.wsgi
plot(arange(44))
a.__setitem__(x, (a[x], a[y]))
mindist = numpy.min(pdist(x))
setattr(obj, name, value)
w.close()
x + y + z
vals = redis.hgetall(key)
fig, axes = plt.subplots(nrows=2, ncols=2)
plot(dayswanted, y, label=label)
s = socket.socket()
client.service.Method(parameter)
_objects = models.Manager()
new_rrule_object = pickle.loads(serial_str)
fnn = buildNetwork(trndata.indim, 5, trndata.outdim, outclass=SoftmaxLayer)
list(upper[upper.index(strs[0]):upper.index(strs[-1]) + 1])
add(a, b)
funcs = [run, jump]
plt.plot(a)
item_q.put(item)
axes.set_xlim(min(latencies), max(latencies) * 1.01)
print(i, l[i])
array_data = array([1, -1, 1, -1, 1, -1, 1, -1, 1, -1])
l[i] += 10
print(xml_files[-1])
data = numpy.random.random((nx, ny))
datetime.datetime.fromtimestamp(dt).isoformat()
A = np.unique(A)
shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)
[locals()[arg] for arg in inspect.getargspec(foobar).args]
cols = df.columns.tolist()
d = {k: dict(x[1:] for x in g) for k, g in groupby(data, key=itemgetter(0))}
c.notify_all()
root = tk.Tk()
self.loop.start()
M.add_edge(1, 2, weight=7)
cv.WriteFrame(writer, frame)
endwhile
df1 = df.copy()
q = Queue.Queue()
print(self.path)
ch.setLevel(logging.ERROR)
print(words)
seed += 1
random.shuffle(unfrozen_set)
A = next(rng1)
d[i] += 1
cmp(self.value, obj.value)
list(dic.values())
print(test.class_method())
a.x, a
self.a = 1
logging.basicConfig(level=logging.INFO)
b1 = B.objects.create()
ast.literal_eval(max(lengths, key=len))
cursor.execute(cmd)
plt.setp(ax.yaxis.get_gridlines(), clip_path=circle)
raise KeyError
root = tk.Tk()
i += 1
self.height * self.width
subplot(122)
map(itemgetter(0), _)
process(line)
z = np.random.random((len(ra), 1))
i += 1
ax2 = fig2.add_subplot(1, 1, 1)
D[i, j] = abs(x[i] - x[j])
collection.append(item)
left = int(input())
url
processes.append(row[2])
MyMixin.__mro__
a[8:9]
print(c.fetchall())
ret[l[1]].add(l[1])
d1 = p[1] - b[1]
b = [i for i in range(20) if i % 2 == 0]
facecolor = plt.gcf().get_facecolor()
img2 = cv2.merge([r, g, b])
help(itertools)
d1[k_d1] = b1[k_d1]
s = date(d.year, d.month, 15)
a * x * x + b
self.append(next(self._num_gen))
request = urllib.request.Request(url)
client_socket.shutdown(1)
x_fit = np.linspace(x[0], x[-1], 1000)
browser = Firefox()
result = [productcode, amountentered] + changecoins
self.create_main_frame()
raise NotImplementedError
_realssl.sslwrap_simple(sock, keyfile, certfile)
g = s.groupby([s.index.year, s.index.month]).mean()
df2
path = sys.path.copy()
np.apply_along_axis(nGauss, -1, x1, mu, cov)
result.append(perfect_corr)
buf.append(line)
self.mps_in_process.remove(kill_id)
[1.85, 9.6]
key
gb = df.groupby(group)
newstdout = os.dup(1)
response = memcache.get(request.my_name)
img.size = tuple(i * 10 for i in img.size)
roll_right = np.roll(img, i, axis=1)
a = np.random.rand(dim, dim)
random.shuffle(sequence_containing_x_vals)
for_js = int(time.mktime(d.timetuple())) * 1000
cols = [ele.text.strip() for ele in cols]
np.array(set.union(set(a), b))
f.seek(block_number * BLOCK_SIZE, 2)
b = [x for x in a if l.count(a[x]) == 1]
findContours(maskCirc.clone(), vertices, CV_RETR_LIST, CV_CHAIN_APPROX_NONE)
row.append(model.get_value(dragged_iter, i))
MAIN_SURF = pygame.display.set_mode((x, y))
print(o.x + 5)
globals()[targetclass]()
self.widget.bar()
mask[sample_indexes] = 0
get_long_path_name(str(short_path_name), buffer, BUFFER_SIZE)
sindata = np.sin(data)
keyValList = [(i, i * 2) for i in range(10)]
b = [2, 6, 7]
jinja2.Markup(scrubber.Scrubber().scrub(text))
self.data.__getitem__(key)
norm(5, 5).pdf(7)
j = Job.objects.get(pk=1)
raise ctypes.WinError()
sidx = ids.argsort()
self.initialized()
plt.subplot(121)
count = sum(os.path.splitext(f)[-1] in extensions for f in files)
self.start_urls.append(urllib.parse.unquote_plus(link[0]))
d2 = threading.Thread(target=dep2)
model = Sequential()
ctpMocks = [mock.Mock(), mock.Mock()]
ret.append((point[0], point[1] - 2 * (point[1] - TOP_RIGHT[1])))
self.__dict__[key]
indices = rng.random_integers(0, len(y_pred) - 1, len(y_pred))
ax.yaxis.set_major_formatter(y_format)
1, 0, 0
args = parser.parse_args(argv[1:])
self.buffer = [1] * size
bar = [4, 5, 6]
self.start_urls = start_urls
{x: -y - 1, z: 2}
y_bin_midpoints = y_bins[:-1] + np.diff(y_bins) / 2
loop.close()
self.get_queryset().hard_delete()
prefixes = (key[:i + 1] for i in range(len(key)))
z = 2.0 * round(y / 2.0)
print(the_matrix[0][1][2])
screen.blit(circle_surface, POS)
root = Tk().withdraw()
board = []
url = sel.select(item_url_xpath).extract()[0]
children.append(parse_inner(toks))
response
nums = [float(x) for x in sys.argv[1:]]
print(title.text)
lcms.cmsDoTransform(xform, byref(inbuf), byref(outbuf), 1)
newRow.append(row[i])
output = {}
data_string = json.dumps(data)
dss.delete(keys)
a, _, _, _ = np.linalg.lstsq(x, y)
print((a, b, c))
myfoto.write(block_of_data)
forward_tunnel(local_port, remote_host, remote_port, transport)
main.show()
flags = FLAG1 | FLAG8
print(request.path)
a = np.array([1, 2, np.NaN])
a = []
{{inline_admin_form.pk_field.field}}
b = np.zeros((N, n), a.dtype)
glViewport(0, 0, self.width, self.height)
self._fileobj.__exit__(*args)
string = fp.read()
ATE0
polB = patches.Polygon(xyB, **kwargsB)
primes.append(a[0])
s.index = pd.DatetimeIndex(s.index)
to_translate.translate(translate_table)
cgitb.enable()
p.join()
grp.div(grp.shift(-1)).groupby(level=0).nth(0)
df = pd.DataFrame(data=data[1:], columns=data[0])
self.should_run.set()
len(self.__dict__)
q.put(e)
y = array([[[2.5]], [[6.5]]])
fig, ax = plt.subplots()
filename = wget.download(url)
self.stream.write(self._convert_row(row))
b = len(may_b)
a.b
func.__code__.co_argcount
insert(d, keyList1, value1)
ylim([0, 25])
parentView.setMouseTracking(True)
ax2.yaxis.set_tick_params(size=0)
tdlist = []
False
x += 1
print(ret[-2][6:])
a = pd.Series(pd.np.random.randn(100000))
reader = csv.reader(f)
obj_as_dict
print(len(connection.queries))
ax2 = ax1.twinx()
type, value, traceback = sys.exc_info()
np.append(xs, remain)
Func(lambda x: self(x) - other(x))
i += 1
f.write(data)
stack[-1][-1][-1] += token
getattr(self, self._attr_name)
print(findItem(a, b))
pathqueue.put(path)
True
f.quit()
collatz(12)
next(it)
ch.setLevel(logging.DEBUG)
np.percentile(S, [0, 100])
lifetime = models.IntegerField()
a = [7, 14, 0, 9, 19, 9]
----APP1
self.inbox = self.outlook.Folders(folderindex)
np.maximum(one, two)
print(user.last_message_time)
print(char)
next(it)
5 - 0.5615
plt.show()
writer.writerow(line)
print(x[::-1])
d = {}
start_date.replace(month=start_date.month + 1)
attr(*args, **kw)
extension = os.path.splitext(file_name)[1]
house_list = []
now = datetime.now()
start = time.time()
t.join()
window.show()
wx.lib.pdfwin
client.set_options(wsse=security)
local.py
self.logger.log(self.level, message)
r / np.sqrt((r * r).sum(0))
result[nearest].append(demand)
a == b
root.mainloop()
self.ui.PoseBtn_GridLayout.setColumnMinimumWidth(4, 4)
x
soup = BeautifulSoup(html_google)
col_combos = cartesian([new.columns[1:], master.columns[1:]])
self.value
print(x)
Py_DECREF(result)
print(new_arr)
a = np.array([np.array(list) for _ in y])
getattr(self.__class__, method).__code__.co_argcount - 1
p.close()
print(soup.prettify())
self.__dict__.update(dill.loads(obj).__dict__)
f = s.makefile()
resp = make_response(df.to_csv())
ind = np.array(list(range(59022)))
loop.call_soon(watch_for_file, args.file_path)
b = Counter(a)
args, varargs, varkw, defaults = inspect.getargspec(f)
f = urllib.request.urlopen(req)
input = input_variable(input_dim)
j.set_color(colors[i])
your_file.py
y = np.cos(x)
app = Flask(__name__)
paths.extend(find_all_paths(graph, node, end, path))
session.add(f)
sorted(strings, key=collator.getSortKey)
x = 12
app = Tk()
letters.reverse()
item
ctrlText.SetBackgroundColour(wx.BLACK)
hist, bin_edges = np.histogram(datas, bins)
rconsole
writer.write_table()
show(layout)
ax = plt.gca()
small_primes = primes[:bisect.bisect(primes, n)]
doSomething(a)
results.append(list(itertools.product(allfiles, allfiles)))
clientImage = np.asarray(bitmapBits, dtype=np.uint8).reshape(height, width, 4)
pen = QPen(QColor(255, 0, 100), 1, Qt.SolidLine)
df_list = pool.map(reader, file_list)
self.zimg_id = self.canvas.create_image(event.x, event.y, image=self.zimg)
a * b
print(df.apply(assign_metric_vals, 1))
size = len(data)
dis.dis(haskey)
a = np.arange(11)
result = []
fn(Af, rc1f, rc2f)
data = urllib.parse.urlencode(forms)
x = np.mgrid[-2:5:120j]
os.strerror(2)
True
PyMODINIT_FUNC
user = cursor.fetchone()
q.append(item)
myHist = plt.hist(data, 100, normed=True)
ax.autoscale(True)
tag.update()
count += 1
div(self.rop, self.lop)
1, 2
[1, 2, 1]
{i: j for i, j in zip(data, data[1:]) if i[:-1] == j[:-1]}
ncols = sheet.ncols
f[1].data
locals_prop_object.SetValNumber(var_name, 0, teststand_nan)
cls.x = value
STARTLSB = [0]
print(str(keys))
subprocess.call([cmd, your_executable_to_check_here])
Foo.__class__ = Base
replaced.append(text[pos:m.start()])
self._table = []
print(item)
info = {}
a(1, 2, x=10, y=20)
notify.uninit()
word_list.append(line.rstrip())
B[i][j] = [i, j]
l = sc.recv(1024)
dis.dis(my_fun)
prctl(PR_SET_PDEATHSIG, SIGHUP, 0, 0, 0)
manager.start()
Author.objects.all()
water_held = 0
ipca.partial_fit(data[i * chunk_size:(i + 1) * chunk_size])
rmin, rmax = np.where(r)[0][[0, -1]]
only_singulars = [w for w in noun_list if w == en.noun.singular(w)]
partition(list(range(105)), 10)
obj = jsonpickle.decode(result.content)
pool.apply_async(parallel_worker)
database.py
print(end_date)
x = np.arange(-1, 1, 0.2)
X, Y = np.meshgrid(x, x)
page + strplus(1)
df
result.add(now)
print(num)
f.readline()
fib(x - 1) + fib(x - 2)
python - V
[2, 4, 6, 8]
tree = html.fromstring(page_as_string)
myservice.listen()
4
OrderedDict().monkey()
myfoo(*extras, **vars(args))
outputFile.close()
garbage = []
output = check_output(cmd, shell=True, stderr=STDOUT).lower()
self.transport.write(line)
print(a)
factory = APIRequestFactory()
points.set_data(x, y)
obj.isoformat()
fut.set_exception(e)
list_dir = os.listdir(path)
center = vor.points.mean(axis=0)
a | b | (x | y)
set1 = set(list1)
event.widget.tk_focusNext().focus()
img_file = BytesIO()
libfile.py
n = np.empty_like(df)
response
ax2.yaxis.tick_right()
values = list(i.values())
a_list = list(map(int, query.split()))
avg_round2 = float(sum(b for _, _, b in players)) / len(players)
imp.load_module(name, f, path[0], info)
mat2[1][i] = 0
sock.close()
[]
text_area = Text(frame)
deletetokens[:]
is_even(0)
button.grid(**buttons[b])
x = min(((key, abs(value - v)) for key, value in list(d.items())), key=lambda k_v: k_v[1])[0]
cdeltaX, crvalX = linwcs(np.amin(glon), np.amax(glon), len(glon))
self.daemonize()
celery.worker.job.RESULT_MAXLEN = 1048576
count[letters] += 1
thread.interrupt()
wb = load_workbook(filename, use_iterators=True)
u = json.loads(s, object_hook=json_util.object_hook)
columnindex += bytechunk / sizeof(double)
self.value
dir(foo)
vfunc = np.vectorize(func)
res = res.add(c, fill_value=0)
pprint.pprint(r.__dict__)
cropped_example.show()
do_sth_with(i, item)
delattr(this, n)
s[s != 0]
list(d)
print(pix[x, y])
b = [float(x) for x in b]
re(integrate(1 / (x - y + I * eta), (x, -1, 1))).simplify().subs({eta: 0})
out = [(x, y) for x in a for y in b]
a = [4, 5, 0, 0, 6, 7, 0, 1, 0, 5] * 1000
pairwise.fill(np.nan)
sh.write(n, 0, col1_name)
step_1 = pd.concat([df, just_dummies], axis=1)
self.assertEqual(val1, val2)
self._validate_unique(self)
r = n - len(s)
data = sorted(data, key=keyfunc)
df = pd.DataFrame(ts)
(1 + 1 + 1) * 1.0 / 10
session.auth = username, password
im = Image.open(sys.argv[1])
print(list(split_text(d)))
df.a = df.a.astype(float).fillna(0.0)
r(sys.argv[1])
A[::2] += 0.1
ax.zaxis.label.set_rotation(a)
M[(i), :] *= -1
colNameList.append(desc[0])
f()
self.buffer = [1] * size
self.clear_cache()
db.system.users.find()
print(len(content))
result = func(*args, **kwargs)
s = set(val for dic in lis for val in list(dic.values()))
Counter(dict(zip(vocab, counts)))
sys.excepthook = info
print((dict1, dict2))
fig = plt.figure()
self.overrideredirect(True)
r = csv.reader(f)
labels = [item.get_text() for item in ax.get_xticklabels()]
functools.reduce(lambda x, y: str(x) + sep + str(y), x)
lat.iter().zip(lon.iter())
True
foldl(f, f(head, acc), tail)
student.save()
filename = askopenfilename()
True
plt.show(plot)
self._lock.release()
doc = QtGui.QTextDocument()
m = np.ma.masked_where(np.isnan(array), array)
print(x)
show(p)
bar = models.CharField()
x = [0.1, 0.2, np.nan, 0.4, 0.5]
0
uid = pw.pw_uid
mix_matrices(A, B)
form = cgi.FieldStorage()
y = np.sin(u) * np.sin(v)
mylist = [(0 if math.isnan(x) else x) for x in mylist]
p.name
idx = np.where(mask.ravel())
sum += value
prediction = tf.nn.softmax(logits)
x = [0] * a.count(0)
data = vals[8:]
print(resp.status)
Package - 2 / namespace / __init__.py
x = Foo()
extra_field = db.Column(db.Integer)
print(Foo().get_counter())
app
products = models.ManyToManyField(Product, through=ProductQuantity)
d = {(1): [1]}
ax = plt.axes(polar=True)
irenR.Initialize()
pylab.figure()
watcher = Watcher()
inqueue = mp.Queue()
target_path = os.path.join(TARGETDIR, member.filename)
result.append(array[mask])
do_action()
a, b = tee(iterable)
keys = sorted(keys)
created = models.DateTimeField(auto_now_add=True, db_index=True)
x += np.random.randn(6) / 10
pixels = pygame.surfarray.pixels2d(srf)
y = x
self.feed(data)
blog_post_mapper = mapper(BlogPost, blog_post_table)
pickle.dump(d, f1)
df.dtypes
ax.xaxis.tick_top()
print(custom_sort(population))
self.before.append(other)
1, 1, 1
running_median = [np.median(Y[idx == k]) for k in range(total_bins)]
circles1.detectcollision(particles1)
args = parser.parse_args()
myfunc = itertools.cycle([0, 1]).__next__
dists = np.sqrt(((data_sorted[:, 1:] - seed_ext[:, 1:]) ** 2).sum(1))
time.sleep(1 + random.random() * 5)
dropbox_path = os.path.join(dropbox_destination, relative_path)
queryset = User.objects.all()
f = urllib.request.urlopen(link)
print(x)
h, w = a.shape
title = models.CharField(max_length=225)
columnNames = [d[0].lower() for d in cursor.description]
print(df)
self.start()
resource = WSGIResource(reactor, reactor.getThreadPool(), app)
print(s.recvfrom(65565))
ulst[j], ulst[i] = ulst[i], ulst[j]
frame.Show()
each.make_noise()
n += 1
smtp.connect()
srf.blit(f.render(unistr, True, (0, 0, 0)), (0, 0))
tai_timestamp = (gps_time_as_tai - tai_epoch_as_tai).total_seconds()
accepted_eula = models.BooleanField()
date
r = requests.get(url)
l.extend(other)
map(int, strnumbers)
timeit(lambda : list(fulldict.keys()))
withiny = random.randrange(y1, y2 + 1)
suds.client.Client(URL, transport=https)
zip(*([iter(seq)] * n))
httpd.serve_forever()
self.check_all()
np.bincount(c)
self.model.fit(*args, **kwargs)
True
count[x] += 1
self.num = num
month_end = month_dates[-1]
image = image.resize((1000, 800), Image.ANTIALIAS)
p.join()
height = max_height * len(lines)
Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
func()
mySmallSquareIterator = cycle(i * i for i in range(10))
not CHECK_INV_RE.search(mystring)
child_strs = [child.display() for child in self.children]
xticks = ax.xaxis.get_major_ticks()
font.setPointSize(20)
start_urls = []
self.con.write(data)
plt.figure()
a and b or c
runUntil(end)
joined = pd.concat([master, other_data], axis=1)
c[1].append(2)
comb_dict.setdefault(key, 0)
A, B = B, A
output
bins = np.arange(256).reshape(256, 1)
counts = Counter(x)
lats = np.linspace(-90, 90, bm.shape[0])[::-1] * np.pi / 180
f[0]
1.1 - int(1.1)
seen = set()
half = (x.max() - x.min()) / 2
random.random()
words = line.split()
other_list = []
iter(self.list)
socks.setdefaultproxy(socks.PROXY_TYPE_SOCKS4, proxy_ip, port, True)
d.append(Distance(_, unit=u.kpc).value)
im = cvt2cga(imgfn)
BOOST_PYTHON_MODULE(hello)
a = cyclicallist([0, 1, 2])
f()
file.close()
self.kNN.fit(X2, y2)
assigned_to = models.ManyToManyField(to=User)
l = [1, 0, -2, 0, 0, 4, 5, 0]
cursor = cnxn.cursor()
byyearday = byyearday, byeaster = byeaster, byweekno = byweekno,
sys.excepthook = exception_handler
MSE = ((Y - EY) ** 2).sum() / (n - X.shape[1])
p.search(s).group()
grand = os.path.join(agrandie, filename)
1.0 / (i % 2)
s = socket.socket()
bin(a | b)
anim = animation.FuncAnimation(fig, animate, frames=Nt)
result.append(element)
c = 0
y_series_2 = [1, 2, 5, 6, 7]
df = pd.DataFrame.from_dict(d_collapsed)
parser = xml.sax.make_parser()
plt.xlim(0, 160)
l = list(s)
timeout_timer.start()
beats.reverse()
ignore = np.zeros([b.shape[0] - 1, a.shape[0] - 1], dtype=bool)
cumprobs = [(p / cumprobs[-1]) for p in cumprobs]
jobs.append(p)
app.debug = True
ts2.head()
map.put(i, i)
args[0], args[1], args[2:]
a = Swallow()
NP.insert(T, 4, c, axis=1)
reader = csv.reader(f)
changewriter.writerow(result)
Al = A.tolil()
widget.layout().addWidget(label)
hist, bins = np.histogram(x, bins=20, density=True)
sh = logging.StreamHandler()
relaxng.validate(doc2)
callback(arg, self)
transport.close()
s1 * s2.values
listy = [item[1] for item in data]
do_something(logf)
print(name)
cv = Canvas(root)
s
self.model = cv2.SVM()
s1 = [(i + 10) for i in range(0, 11, 2)]
first = np.mean(arr[:toslice].reshape(-1, stride), axis=1)
clear_mappers()
section.insert(0, table)
pyplot.show()
reloadkeys = set(globaldict) & set(sys.modules)
result = []
print(sys.maxsize)
type(b)
outputs.set_shape(inputs.get_shape())
self.a = a
int(val)
fig = figure()
t.close()
fig = plt.figure(figsize=figsize, dpi=dpi)
myset = set()
a_thread = threading.Thread(target=get_a)
StartupNotify = true
False
sorted_list = sorted(my_list)
file_toload.close()
t2 = [(a + b) for a, b in zip(t, t[1:])]
yacc.restart()
ycenters = ychunks.mean(axis=1)
minmax = [(min(v) if k else max(v)) for k, v in groupby(lst2, lambda a: a < 0)]
base.extend([ii] * count)
plt.yticks(list(range(len(corr.columns))), corr.columns)
aaB
self.flush()
brr = np.reshape(arr, arr.shape[0] * arr.shape[1])
it = lambda : list(chain(*tupleOfTuples))
True
parser = argparse.ArgumentParser()
np.where(np.any(np.isnan(df.convert_objects(convert_numeric=True)), axis=1))
my_trigger()
y2 = np.array([f(t, 50).real for t in time])
game.process()
r = self.build_response(request, resp)
1 | MD5
Column(_groupConcat(_to_seq(sc, [col], _to_java_column)))
x = datetime.timedelta(hours=hours, minutes=minutes, seconds=seconds)
help(plt.ylim)
self.assertLengthIsOne(self.seq)
Frame.__init__(self, parent)
757
760
761
pygame.draw.circle(surface, (0, 0, 0), (10, 10), 15, 0)
Al = [0, x, x, x, x, x]
times = [800.0, 790.0, 780.0, 770.0]
example[1:5, 10:15]
print(urow_avg)
monthToNumber = dict((name, i + 1) for i, name in enumerate(months))
t = threading.Thread(target=task, args=(sc, i))
characters += len(word)
datafilter = datafilter & Q(publish_date__month=now.month)
theta, r = np.meshgrid(thetas, radii)
plt.grid()
results = parse_jid(sys.argv[1])
sprockets_to_dealloc = self.sprockets.copy()
plt.show()
print(render_user(userinfo))
Z[test[:, 0:2].T.tolist()] = test[:, (2)]
pprint(_)
type(my_set)
np.concatenate(out)
self.Bind(wx.EVT_TIMER, self.NextFrame)
_ * 2 - math.pi
b = formB.save(commit=False)
minutes = int(secs / 60) % 60
self.send_response(500)
self.subplot.clear()
print(signed_url)
result = []
sort_index = numpy.argsort(vals)
self.send_response(200)
s2 = df.groupby([lambda x: x.year, lambda x: x.month]).sum()
Z = tf.sqrt(Delta_tilde)
float * cfloats
getsizeof(json.dumps(my_dictionary))
cast = models.ForeignKey(Casts, null=True)
d = {x: i for i, x in enumerate(set(a))}
a = A()
fig = plt.figure()
print(len(binary_split_array.tobytes()))
page = bokeh.plotting.gridplot([[fig], [current_selection]])
fd.write(data)
data = clientsocket.recv(1024).decode()
self.loop.stop()
module = REVERSE_MAPPING[module]
self._set(**kwargs)
new_list.append(item + 10)
names.append(name)
a[np.isnan(a)] = b[np.isnan(a)]
y = object()
num_processes = multiprocessing.cpu_count()
decorator
print(alist)
image = tf.cast(image, dtype=tf.uint8)
dill.detect.badtypes(f)
generate_n_primes(10, 1000)
count = max(0, len(sequence) - n + 1)
cls
pub_key_der = b64decode(pub_key_pem)
self.sync_string(node)
x = np.linspace(0, 2 * np.pi, 10)
metadata = MetaData()
grayed_rgb_color
fdst.write(buf)
self.f = f
self.item_id = item_id
curOuter = db.cursor()
plt.close(fig)
adjlist_find_paths(a, n, m)
result = contains_sequence(test_iterable, search_sequence)
goto(x, y)
cxt.mount()
{{message}}
os.dup2(0, 2)
C = zip(A, B)
p.line(50, 660, 560, 660)
inputLayer = [neurons[0], neurons[1]]
klass = getattr(mod, name)
clips.Reset()
s += l[i]
print(ret.read())
deletions.append(keepers[key][0])
path = os.path.join(directory, fl)
counts = Counter(zip(predicted, gold))
a[1] = 4
process_messages()
tar.addfile(tarinfo=info, fileobj=string)
plt.close(fig)
scrollbar.config(command=self.data.yview)
phrase.capitalize()
results = q.fetch(10)
initial = np.random.rand(1000)
pl.ylim(-1.2, 1.2)
[8, 9, 10, 11],
float(s)
plt.plot(b)
__metaclass__ = ModelBase
df.plot(ax=ax1)
((n,) + t for n, t in enumerate(zip(*iterables), start))
schedule_once(tasks.some_task_a, interval=60 * 5)
log.append(p.url)
print(a[0, 1])
df.dtypes
variable0
A = np.random.randint(2, size=(n, n))
yaml.add_representer(folded_unicode, represent_folded_unicode)
argparser = argparse.ArgumentParser()
file.close()
render_to_response(renderer, values)
new_image.show()
manager = mp.Manager()
fig = figure()
queryset = Company.objects.all()
plot(t, s1)
fig = plt.figure(1, figsize=(figwidth, figheight))
eigs(A, n)
Thread(target=read_stdout, args=[process]).start()
triplets[iT].append(listB[iB])
f.write(z)
cursor = connection.cursor()
x ** (m * m)
assert os.path.isfile(subimg_path)
csv_reader = csv.reader(count_file)
request = urllib.request.Request(url)
x * x * x
np_d_spiky = np.vectorize(d_spiky)
file_size = values[0]
textlist.append(str(a))
people = result.fetchall()
app.exec_()
n = np.empty((1,), dtype=object)
R = dot(u, vh)
messages = Message.objects.all()
R = random.randint(1, 8)
np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)
item_forms = items_formset()
list(gen_all_substrings(string))
kl = KineticLaw(2, 4)
test_file.write(bytearray(binary_data))
1, 2
numpy.logspace(0, 2, 10)
self.current - 1
print(a + b + c)
canvas.tag_raise(object)
start = pd.datetime(2016, 5, 22, 8, 0, 0)
b = set(counts.keys())
print(i, line.strip())
json.JSONEncoder.default(self, obj)
d[key] = {}
lst.append(element)
self.fc2 = FigureCanvas(self._fig)
foo(bar)
args, varargs, varkw, defaults = inspect.getargspec(method)
mean, sigma = a.mean(), a.std(ddof=1)
round(x, sig - int(floor(log10(x))) - 1)
pd.DatetimeIndex(df.t).normalize()
prime_form(11, 1, 0)
current_dict = current_dict.setdefault(letter, {})
plotter(im, i)
print(new_a)
a.run()
b = datetime.timedelta(minutes=1, seconds=1)
n = len(points) - 1
m = random.randint(0, 1000000)
blocks.append([])
P.show()
foo + bar
print(l)
msglist.append(chunk)
node = Node(node, category, name)
setattr(F, name, TextField(name.title()))
sess.run(init)
newshapes = np.diag(np.array(shape) - 1) + 1
gevent.spawn(read_stream, p1.stderr)
list.append(self, x)
print(np.all(rs[(find_map_sorted(r2[:-10], rs)), :] == r2[:-10]))
value = getattr(self, varname)
deleteresult[key]
plt.plot([(x * slope) for x in range(0, 11)])
now = datetime(datetime.now().year, datetime.now().month, 1)
chr(26)
x = np.asanyarray(x)
train_idxs.append(X_train_1[i_1:i_1 + 1].index)
f1 = plt.figure()
response = HttpResponse(content_type=mimetype, status=206)
arr = np.empty([len(a) for a in arrays] + [la])
plt[:show]()
rank, v[rank:].T.copy()
now = datetime.now()
fp.write(decompressor.decompress(chunk))
self.result = []
time.sleep(1.0)
mult = np.hstack((np.repeat(4, p1.shape[0]), np.repeat(2, p2.shape[0]), 1, 1))
tb = e.__traceback__
print(type(b))
subnets
db_instance = db_instance_qs.get()
main()
tabin = [ord(char) for char in tabin]
Tkinter.Text.__init__(self, parent, cnf, **kw)
gs = gridspec.GridSpec(1, 2, width_ratios=[10, 1])
d = {}
persons = [re.match(pattern, x).groups()[0] for x in my_strings]
y = np.empty((Ndown, Ndown))
myfunc()
theta = x[1]
models.Model.__new__(cls, *args, **kwargs)
ingredient_list.append(ingredient)
expanded = os.path.expanduser(dirpath)
client(clientsocket, address)
y[:] = np.where(mask, np.nan, np.log(r) * np.sin(t))
log = logging.getLogger()
a[index] = 1.0
a.show()
line = line.strip()
sleep(1)
l = p.stdout.readline()
self._val += 1
os.chdir(curdir)
plt.boxplot(data)
a[1:4, 1:4] = np.nan
print(df1)
print(a.calculate(1))
coeffs2 = np.corrcoef(a.todense(), b.todense())
ax.draw_artist(ellip)
pixels = img.load()
print(find_centroid(im, 1))
self.x + other
time = rrdMetric[0][0]
n * fact(n - 1)
A = np.linspace(0, 100.0, 200)
zip(a, b)
plt.bar(ind, dat, color=col, bottom=bot)
deleteoutputter
a = int(part)
child.interact()
do_something_else()
b.B()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
a.denominator
labels = ax2.get_xticklabels()
webElement.clear()
x = [[1, 2], 1, 1, [2, 1, [1, 2]]]
self.app(environ, start_response)
len_arrayIN = arrayIN.shape[0]
self.col0 = [1.0, 0.0, 0.0, 1.0]
print(x[n - 1])
F = treecomp(T, L)
[(L[i] + L[i + sep]) for i in range(len(L) - sep)]
r.content
tempShape = tuple([(i * j) for i, j in zip(finalShape, mults)])
self.nodes[self.get_index(key)]
ret.append((point[0] - 2 * (point[0] - TOP_RIGHT[0]), point[1]))
q.put(i)
args.insert(0, sys.executable)
print(textwrap.dedent(s))
foo.__new__(foo, arg=1)
d4.update(d2)
time.sleep(self.timeout)
data.pop(word[i - 1:i])
rest = [factors[i] for i in range(len(factors)) if i not in which_is]
token.authorize(client)
s.upper()
~Q(Q)
test = np.random.normal(0, 1, 1000)
f(f, *p, **kw)
system / __init__.py
field_class = forms.ModelMultipleChoiceField
ax[1].plot(dates, list(range(10)))
self.quit(file)
BisBigger.data = np.where(BisBigger.data < 0, 1, 0)
sum
UTC_OFFSET_TIMEDELTA = datetime.datetime.utcnow() - datetime.datetime.now()
ax = fig.add_subplot(111)
new_list1, new_list2 = zip(*create_matchs(list1, list2))
swap(L[:])
plt.figure()
length = variable[0][1]
client = Client(url)
user_input = eval(input())
form = ImportExcelForm(request.POST, request.FILES)
s.ix[x:y]
spade = 4
w = png.Writer(len(s[0]), len(s), greyscale=True, bitdepth=1)
result = input(s)
connect_signal2_to_slot2()
self.page = QWebPage(self)
data[i].pop(pos)
np.allclose(method1, method2)
x.extend(a)
columns = len(next(reader1))
sum += number
pool.join()
ls = [set(l) for l in ll]
self.assertEqual(Foo.query.count(), 0)
foo.do_interesting_stuff()
lstB = [number_list[i]]
tcpcounter = 0
udpcounter = 0
sums = [sum(tab[i:i + 4]) for i, v in enumerate(tab) if i + 4 <= len(tab)]
d = {}
y[1:] = x[1:] - x[:-1]
f.write(FOOTER)
flags = re.MULTILINE | re.DOTALL
glMatrixMode(GL_MODELVIEW)
new_df = new_df.fillna(0).astype(int)
True
assert find_max([-1]) == 0
logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)
field2 = models.TextField()
d = {}
pattern.search(t)
pd.DataFrame({cn: cv for cn, cv in zip(colnames, col_iterator)})
System.out.println(i)
self.worker = Worker(self.spinbox.value())
result = list(zip(*withspaces))
b = [(10, 40), (40, 60), (60, 90), (90, 100)]
print(hex2(-1))
arr = eval(repr(([[0] * 5] * 10)))
self.name = name
basicConfig(level=log_level)
df2 = df1.copy()
last = row[1]
44.44444444444444, 55.55555555555556, 66.66666666666667
size -= len(data)
img.save(file_out)
a.update(b)
x = np.arange(10 * 10).reshape((10, 10))
print(shortcut.Targetpath)
json.dumps(serialize(obj))
days = df.groupby(diffs).size()
df
df1 = df.copy()
rectangle.draw()
True
iterate_file(file_name)
dev1 == dev2
rows = results(exec_immediate(connection, sql))
start_date.replace(month=1)
data = res.read()
MAKE_NOISE = False
document.write(xmlhttp.status + xmlhttp.statusText)
gen = get_line()
b.f()
frame.Show()
red = np.random.hypergeometric(nred, ngreen + nblue, m)
toc = time.clock()
p = pyaudio.PyAudio()
his = np.histogram(a, bins=list(range(5)))
dst.copy_key(k.key.name, src, k.key.name)
secs = x.total_seconds()
a2 = A.objects.create()
self.__getattribute__(key)
acos(cos_x) * EARTH_RADIUS_IN_MILES
self.value = 1 / (1 + math.exp(-x))
test_Dict = {}
p.join()
a = np.random.rand(10, 10, 10)
os.makedirs(self.cache_location)
func(*args)
r = view(request, *args, **kwargs)
root.after(0, download_chunk)
long_desc = forms.CharField(widget=forms.Textarea)
fig = matplotlib.pyplot.figure()
filename
ax.set_xticks(ind + width + width / 2)
a2.append(s)
combinedRDD = zdd1.join(zdd2).map(lambda k_v: k_v[1])
new_row = row
self.comovingdist(z) / (1 + z)
triple(square(x))
assert len(demangled) == len(names) + 1
print(path)
response = opener.open(request)
result.append(current_string_split)
plt.legend()
fig = plt.figure()
print(self.__ordered_fields__)
desired_list = list(d.values())
app = QtGui.QApplication(sys.argv)
{k: (v[0] if len(v) == 1 else v) for k, v in list(items.items())}
characters.append(char_image)
secondbut.pack()
x + y
self._load()
extract_file.write(bytearray(binary_data))
do_stuff
c.save()
self.tin = wx.TextCtrl(self, size=wx.Size(600, 400), style=wx.TE_MULTILINE)
A = np.random.randn(1000, 2000)
pdf = FPDF()
t.setDaemon(True)
lens = [max(map(len, col)) for col in zip(*s)]
result = set()
type.__call__(A)
d = {}
self.tab.removeTab(index)
listofzeros
frags.append(items[0])
create_object(form_class=FooForm)
abcba
abcdcba
abcdedcba
items.append(lambda i=i: dump(i))
x = []
print(v)
{{formset.empty_form.as_p}}
4, [False, True, True, False]
binop.setParseAction(lambda t: ops[t[1]](t[0], t[2]))
pool.join()
elements = (len(xedges) - 1) * (len(yedges) - 1)
cache[args] = f(*args)
ax2.plot(list(range(1, 10, 1)))
mydict = dict()
app = QtGui.QApplication(sys.argv)
cur = fromdb.cursor()
print(df)
p.html()
OrderedDict(sorted(l))
uinfo = user.get_profile()
mgr = urllib.request.HTTPPasswordMgrWithDefaultRealm()
len(str(name))
list1 = []
infilename = os.path.join(path, folder, filename)
recursivedict = lambda : defaultdict(recursivedict)
x * x
[1.000049]
len(n)
a = numbers()[0]
kind2 = params.get(cls._KIND2_PARAM)
utc_date = date_aware_la.astimezone(pytz.utc)
self.assertEqual(FooCycle.query.count(), 0)
df = df[col_order]
self.indexdict[r]
chunks.append(chunk)
num += 1
df
self.irenL.Render()
1.0 / (x + 1)
iter(self.__dict__)
currdir = os.getcwd()
model.setItem(row, column, item)
sys.meta_path.append(self.collector)
track1.play_forever()
merged = dict()
time.sleep(wait)
root.quit()
flist.append(func)
b = models.CharField(max_length=42)
print(mylist)
out = check_output(args, stderr=t)
print(np.arange(100).itemsize)
kv = [(bits[i][-1], bits[i + 1][0]) for i in range(len(bits) - 1)]
logger.addHandler(fhandler)
print(a, b)
o.join()
print(x)
index = nanargmin(zfit, axis=1)
sess.run(init)
f.close()
instance._prefetched_objects_cache[instance.children.prefetch_cache_name]
locals().update(d)
queue.put(result)
a = time.time()
self.cub2 = cub2
self.setPixmap(pic)
self.exns.add(node.name)
callback = tsum.subtask()
my_module.my_reload()
name in self.archive.getnames()
p = Process(target=instance.start_listener)
traceback.print_exception(type, value, tb)
f(**kwargs)
u = np.linspace(0, 2 * np.pi, 50)
a = 5
vector
grid_x, grid_y = np.mgrid[min(x):max(x):100j, min(y):max(y):100j]
server_A_thread = threading.Thread(target=server_A.serve_forever)
Package - 1 / namespace / __init__.py
i += 1
merged = pd.concat((df1, d_teams), axis=1)
bind(myfn, arg(1), 17, arg(0))(19, 14)
fig = plt.figure()
row.append(SchemaTable.Rows[i][j].ToString())
client = paramiko.SSHClient()
f.seek(4, 1)
ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
gc.disable()
model = QtGui.QStandardItemModel(rows, columns, self.table)
cursor.close()
a = A.__new__(A, *args, **kwargs)
serialize(obj.__dict__)
xlim, ylim = axis.get_xlim(), axis.get_ylim()
assert my_round(5.24) == 5.25
root, ext = os.path.splitext(filename)
s = [i for i in range(100)]
plt.xlim(bin_edges.min(), bin_edges.max())
icon = wx.Icon(path, wx.BITMAP_TYPE_PNG)
nexts = cycle(iter(it).__next__ for it in iterables)
str(int(other).__add__(self))
al.spline1dcalc(s, val), func(val)
lines = file.readlines()
now = datetime.now(tz=timezone(zonename))
kOUT = np.zeros(N + 1)
timeout_decorator.timeout(GLOBAL_TIMEOUT)(unittest.main)()
nodes[0] = 1, 2
d = {}
writer = csv.writer(outfile)
batch = [val for i, val in enumerate(my_deque) if i in idx_batch]
[False, False, False],
assert b.f() == 2
dis.dis(lis[0])
main()
wb.SaveAs(newFileName, constants.xlHtml)
self.items.append(item)
self.__pList = []
re.search(self.regex, text)
print(tempfile.gettempdir())
print(data)
a[np.in1d(np.mod(np.arange(a.size), 5), idx + offset)] = 100
t = urllib.parse.unquote_plus(s)
setattr(targetCls, name, closure())
cumsum = lambda a: [sum(a[:i + 1]) for i, x in enumerate(a)]
780000
txnbkwrfkpkmiexloxrifdsnjumkex
xlnmlhobtsswjvmqnjupaybkspptpo
difference_in_years = relativedelta(end_date, start_date).years
[] if S == [] else [S]
curs = conn.cursor()
df
f.levels
data = json.loads(obj.to_ecma())
setattr(args, self.dest, strategy)
M[:, (j)] *= s
mutex.release()
widget.setLayout(layout)
app1 = Flask(__name__)
l.pack()
response
deleteself[key]
json = urlopen(request).read().decode()
B().do_something()
HttpResponse(tmplt.render(context))
print(rd[4])
dis(f)
t.show_all()
turtle.done()
q.put(1)
shuffle(numbers)
print(f(a))
df.values
list(one_duplicate(4))
C - 0.120282
r = np.empty(n, dtype=np.int64)
rIndex.reassign(9)
df
self.aws.send(data)
five_months_ago = datetime.datetime.now() - relativedelta(months=5)
cleanfile.append(line)
pool.close()
d[t[0]] = d.get(t[0], 0) + int(t[1])
context
email = EmailField(required=True)
ustyle = nl.create_userstyle()
b = np.array([int])
x1 = (x - x0) * cos(theta) - (h - y - y0) * sin(theta)
self.data = []
HttpResponseNoContent()
features = [feature_names[i] for i in tree.tree_.feature]
Point(1, 2)
abort(404)
score_pairwise(seq1, seq2, blosum, -5, -1)
df
content = db.StringProperty(multiline=True)
my_func(42)
x()
somelist.remove(x)
nth_element(my_list, 4, key=f)
x[0, 1, 1] = 111
col = scipy.array([2, 4, 6, 8, 10])
f.write(decodestring(b64data))
socket.inet_ntoa(unpacked)
[[], []]
y[1][0] = 4
{{link.href | escape}}
df.b.loc[s & (s != s.shift(-1))]
df = pd.DataFrame(rslt[0])
C = np.hstack(C)
row.pop(4)
img2 = ImageTk.PhotoImage(Image.open(path2))
df
assert -1 <= sinval(i) - sintable(i) <= 1
root = Tk()
app = Bottle()
holidays = [datetime.date(2012, 5, 1), datetime.date(2012, 6, 1)]
print(fileSystemNameBuffer.value)
turtle.forward(n)
print(render())
request = response.wsgi_request
print(QWidget)
res = func(*args, **kwargs)
data = list(range(4000000))
[0, 0, 0, 0, 164, 1, 161, 2, 161, 4],
pt.plot.bar()
getattr(prototype, name)
matrix = [np.random.rand(N) for _ in range(M)]
unested = [list(itertools.chain(*sub)) for sub in nested]
ax2 = ax1.twiny()
Area2(a, b, c) > 0
strmap[string]
button1.pack()
stdscr = curses.initscr()
w[i] = -1
f
startingmods = modules.copy()
logOutput.setReadOnly(True)
z = [[(0) for _ in range(8)] for _ in range(8)]
print(results[0])
data.append([name] + [dct[key] for key in obs_keys])
True
reader = csv.DictReader(csvfile)
index = letters.index(letter)
[7, 14, 21],
bins.append([min, max])
fly.rect.y += fly.vspeed
zz = file.readline()
frame1.axes.yaxis.set_ticklabels([])
self.button.clicked.connect(self.handleTest)
sc = ax.scatter(x, y, *args, **kwargs)
queue.append(new_path)
plt.plot(x, y)
os._exit(0)
print(row)
s.shutdown(socket.SHUT_WR)
print(msg.Body)
result.append(next_third_friday(result[-1]))
weights
money = price.quantize(cents, decimal.ROUND_HALF_UP)
print(x)
test[0][0] = 1.0
where_mask = arr[:, :, (ind_vals)] == values
noop = logging.NullHandler()
vals == (0, 1)
[(row[:j] + row[j + 1:]) for row in m[:i] + m[i + 1:]]
dict.fromkeys(range(4000000))
follow(open(filename))
pythonpath, top = os.path.split(os.path.realpath(sys.executable))
myThread.setDaemon(true)
df
serializer = self.get_search_pagination_serializer(page)
A = np.cos(a) * np.cos(b) - np.sin(a) * np.sin(b) * np.sin(c - d)
import_array()
x_max = tf.reduce_max(weights)
[]
row = len(row_names) - 1
getattr(self._wrapped, attr_name)
stdout
display = Display(visible=0, size=(800, 600))
pyobj = json.loads(json_str, object_hook=as_python_object)
z = 10 * np.random.normal(mu, sigma, 5000)
visited_ids.add(node_a_id)
b[0] = -1
sns.reset_orig()
reraise_with_context(key=key)
new_df = pd.DataFrame()
pp.pprint(tup)
html = markdown(some_html_string)
[num for num in range(n) if A[num]]
x = [1, 1, 0, 0, 0]
set_time_limit(0)
observer.start()
a == 2
result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)
pFact.append(num)
layer2 = []
result = float(node.text_content().lower().count(word))
y1 = scipy.sqrt(1 - (abs(x) - 1) ** 2)
print(df2)
zero_crossings = numpy.where(numpy.diff(numpy.sign(a)))[0]
print(df)
hold(True)
1, 0, [t]
self.connected = True
ix = [i for i in df.index if i not in blacklist]
k = 0
d = -np.dot(np.array(point), np.array(normal))
app.url_map.strict_slashes = False
dis.dis(foo.__code__.co_consts[1])
p.move()
creds = tools.run_flow(flow, store)
y0 = self.canvas.canvasy(0)
oct_num = oct(int(oct_string, 8))
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
output = [[]]
value
Session.add(f)
fig.canvas.draw()
gray = im.sum(axis=-1)
obj.reprJSON()
zip(a, chain(b, [next(b)]))
np.dtype(float)
g = g[(g.date >= g.beg_date) & (g.date <= g.end_date)]
lst1 = [1, 2]
delattr(mod, modname)
thefile.write(replacedText)
self.setSelectionMode(QtGui.QAbstractItemView.ExtendedSelection)
0
sizer.Add(btnRed, 0, wx.ALL | wx.CENTER, 5)
b = np.bincount(a)
ax.w_zaxis.set_major_locator(LinearLocator(10))
request.notifyFinish()
packetcount
writer.grab_frame()
show()
ret, frame = cap.read()
self.assertEqual(user.username, testuser.upper())
zip(*([iter(iterable)] * n))
z().visit(t)
x = plt.colorbar(ticks=v)
writer.writerow(line)
x = X()
bmpf.seek(start)
self.set_encoding(encoding)
event = threading.Event()
print(cls)
Pagination(query, page, per_page, total, items)
sleep(0.1)
transform = etree.XSLT(etree.XML(xslt))
ret.append(work_on)
u_new = np.linspace(u.min(), u.max(), 1000)
random_sample_input = random.sample(f.read().split(), 10)
+---__init__.py
mailhost, port, self.username, self.password, self.fromaddr
cbar = fig.colorbar(CS, ax=ax)
A.__init__(self, a)
df_list.append(f)
response = urllib.request.urlopen(req)
f.write(res)
True
sys.version_info
button = QtGui.QPushButton()
prototype = c.CFUNCTYPE(c.c_double, c.c_double, c.c_double)
conn.connect()
django.db.transaction.enter_transaction_management()
itergroup([0, 0], 0)
ax.plot(xx, yy, zz)
print(q)
fig, ax = plt.subplots()
sps_a.toarray()
tix.Label.__init__(self, parent, **kwargs)
X, Y = np.meshgrid(x, y)
a[(i), :] = map(float, line.split())
print(list(M.keys()))
server = smtplib.SMTP(smtpserver)
print(self.crawler.stats.get_stats())
items_view.show()
map(second_lowest, lst)
result = [tuple([(item + minval) for item in tup]) for tup in result]
employee = json.loads(j, object_hook=class_mapper)
create_grid(4, 5)
formset = QuoteFormSet()
wb.save(output)
whos
dict.__init__(self)
rows * array_shape[1] + cols
count += 1
x < 1
print(df1.assign(sum=df1.sum(axis=1)))
8, 1, 8, 8
df1.T.max() - df1.T.min()
mask = (B == i).astype(int)
res[v] += 1
roots.add(target)
my_date = datetime.strptime(test_date, date_format)
a[x], a[y] = a[y], a[x]
QListIterator(self)
add_str_to_lines(f_name=f_name, str_to_add=str_to_add)
os.mkdir(folder_location)
job.delete()
tableWidget.setCellWidget(1, 1, ImgWidget2(self))
BaseHTTPServer.test(CORSRequestHandler, BaseHTTPServer.HTTPServer)
elem = ElementTree.parse(file)
lhs = dict([(D[k], pop(D, k)) for D in lhs])
namespace = parser.parse_args()
json.dump(doc, fw, indent=4)
f = itemgetter(0)
print(r.getc)
a.extendleft(b[::-1])
handles, labels = plt.gca().get_legend_handles_labels()
count = diff.nonzero()[0]
df.dic.apply(pn.Series)
name = models.CharField()
json.dumps(self._items)
s
test.tell()
matrix = [([0] * size) for i in range(size)]
__builtins__[attr] = getattr(module, attr)
self.output_pipe.close()
result[np.arange(len(x)), inv] = 1
l.sort(key=lambda x: x.lower())
sizer.Add(btn)
result.append(current_set)
your_csv_file.close()
msg
print(inputList)
letters = [chr(i) for i in range(97, last_letter)]
xcen, ycen = xgrid[arr == 255].mean(), ygrid[arr == 255].mean()
fd = sys.stdin.fileno()
all_other_cases(param)
to_translate.translate(translate_table)
ls = [1, 7, 0, 4, 9, 6, 150]
start = start + math.log(random.random()) / i
logging.basicConfig(level=logging.INFO)
a = np.arange(1, 10000.0, dtype=int)
queryset = queryset.filter(name=name)
out[int(n)].append((val, v))
log_add2(logB, logA)
len(output)
id(a.bar)
np.diff(data.value.index.values)
path_lengths = nx.single_source_dijkstra_path_length(G, node)
desired_ages = np.array([1, 4, 16, 29, 80])
print(char1, len(char1), len(char1[0]))
i.append(x)
stdout, stderr = process.communicate()
index_list.append(i)
y = a[2] * b[0] - a[0] * b[2]
xedges = np.linspace(0, N, nbin)
c = cv.WaitKey(10)
deletetag[attribute]
[x] + xs
f[:]
a = numpy.random.randint(0, 10, 10) * 1.0
merge(a, b, lambda in_a, in_b: in_a or in_b)
a = NoBCArray([[1, 2]])
stock_values[stock][days]
interpolator((lats, lons, alts, time), data, point)
compressedString = zlib.compress(originalString, 9)
tree = etree.iterparse(xml_file)
y[:, ::2] = 0
driver.close()
y.append(x)
p.stdin.close()
indices.append(idx)
data_dict[regNumber] = details
modifiers = QtGui.QApplication.keyboardModifiers()
d_view = [(v, k) for k, v in d.items()]
response = urllib.request.urlopen(req, timeout=int(TIMEOUT))
eq2 = TestableEq()
args = tuple([CallableWrapper(args[0])])
int(key)
ax.yaxis.set_major_formatter(ptick.ScalarFormatter(useMathText=True))
axe = fig.add_axes([0.4, 0.4, 0.2, 0.2])
func()
cv_image = img_as_ubyte(any_skimage_image)
Rule(SgmlLinkExtractor(process_value=delete_random_garbage_from_url))
client.service.GetServiceById(arg1, arg2)
packet = f.read()
find_merged_group(date_time - 1, date_time + 1)
df
f_myfile.close()
sio.seek(0)
ax2.imshow(Z)
print(user.screen_name, user.followers_count)
self.op._getsymbols()
do_something(i)
df = [DataFrame(e) for e in data]
response = urlopen(url)
docfile = open(path)
groups = conn.get_all_security_groups()
ax1 = fig.add_subplot(111)
pydevd.GetGlobalDebugger().setExceptHook(Exception, True, False)
cimg = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
post_save.disconnect(my_post_save_handler)
natsorted(x, key=lambda y: y.lower())
Python - virtualen
pool.join()
new_cipher.append(letters[letters.index(letter) - shift])
modict = module.__dict__
_Py_ReleaseInternedStrings()
a1 = sheet.cell_value(rowx=0, colx=0)
ax.plot(np.cos(x))
print(dict(zip(headers, values)))
foo[:]
res = np.split(idx_sort, idx_start)
os.remove(str(file_path) + xfile)
sympy.simplify(Lagrange(Lx, Ly))
parser = argparse.ArgumentParser(formatter_class=CapitalisedHelpFormatter)
regex = re.compile(re.escape(before), re.I)
ch = logging.StreamHandler()
a = int(round(a * 255))
self._metadata = MetaData()
list(parser)
digits = digits[1:]
-(-x // 500) * 500
result = np.empty((m, n), dtype=np.float)
pos = nx.spring_layout(G, fixed=[1, 2])
print(int(floor(f1)))
output_wb = copy_workbook(input_wb)
res.append(0)
temp.append(i[0, j])
[get_column(pyQueryRow, index) for index in range(0, 12)]
writer.writerows(row + [0.0] for row in reader)
inner()
calendar.timegm(aprilFirst.timetuple())
html = response.read()
mod = getattr(mod, comp)
m.load()
yourlist = [[0, 0, 0], [0, 1, 1], [1, 0, 2]]
ax = fig.add_subplot(111)
line_segments.append([(x, y) for x, y in vor_.vertices[simplex]])
X, Y = np.mgrid[:2 * np.pi:0.2, :2 * np.pi:0.2]
source_key = source_bucket.get_key(source_key_name)
out = np.zeros(tot_vec, dtype=int)
cum.tail(1)
py26
self.func = func
ss = s.split()
self.sTitle = os.path.basename(self.fileName)
a + b
height = self.canvas1.winfo_height()
h = [(i[0], int) for i in c.description]
fsq = np.fft.rfft(xstep)
logger.setLevel(logging.DEBUG)
end[r[1]].add(r[2])
l.append(val)
self.statusItem.setEnabled_(TRUE)
unittest.main(argv=unittest.sys.argv)
metadata1 = MetaData()
df = df.append(dff)
waitKey()
y = 10 + np.sin(50.0 * 2.0 * np.pi * x) + 0.5 * np.sin(80.0 * 2.0 * np.pi * x)
concat(dict(A=A, B=B), axis=1)
print(longest_common([b, c]))
list(range(5))[5:6]
conn = SSH2()
user = models.OneToOneField(User)
f = Foo()
info = json.loads(urllib.request.urlopen(url).read())
process(line)
tic = time.clock()
self = self.setdefault(key, {})
objects = getattr(a, link).all()
stream.close()
server.test(*[1, 2])
getattr(self, self.object_class)
Model.objects.filter(m2m_field=1)
a_normalized = [(float(x - min_a) / (max_a - min_a)) for x in a]
serializer_class = UserSerializer
L.sort(my_cmp)
[supervisord]
examined_modules = []
thislevel = nextlevel
raise TypeError
b_minus_a = [item for item in b if item not in a]
app = config.make_wsgi_app()
print(arr)
softmaxval = sess.run(softmax)
MyModel2.mymodel1.through
q = m.Queue()
USE_SHIPPED_BOOST = True
list_2_sorted = [e[0] for e in s]
elt = ris[0]
f.__add__(f)
i, card
print(df)
p.parse_args()
-Xmx800m
dynamic_import_hack(__name__)
import_foo()
print(dingo)
curs = conn.cursor(MySQLdb.cursors.SSCursor)
fig = plt.figure()
fn(val1, val2)
max(sum(tableData, []))
callback(file, mask)
clf.tree_.value
p = np.cumsum(np.append(0, z))[:-1]
_nextkey = 0
result.sort()
members = models.ManyToManyField(Person)
print(row)
b = a[:]
d[x] += 1
data.show()
datum = caffe.proto.caffe_pb2.Datum()
args.append(value)
X1D = np.ravel_multi_index(X.T, dims)
A[np.maximum.accumulate(~np.isnan(A))]
yappi.get_func_stats().print_all()
df2 = (df.ix[:, 1:] - df.ix[:, 1:].mean()) / df.ix[:, 1:].std()
fig = Figure()
init = tf.initialize_all_variables()
tz2 = pytz.timezone(tz_string)
my_tuples = literal_eval(s)
models.CharField(blank=True)
fig, ax = plt.subplots()
tmpset = set(L2)
set(data) == set(data2)
result
loss.eval({input: x, label: y})
a.UID
ax.scatter(df.index, df.AdjClose)
raise ImportError
unfiltered = [(myFunction(C), C) for C in originalList]
chessboard = Chessboard()
new_test
self._init_B()
main(sys.argv)
numpy.genfromtxt(io.BytesIO(x.encode()))
ax.set_aspect(1)
a.argmin()
0
curses.echo()
self.cj.load()
df.shape
deleteself._dict[key]
Decimal(0.2)
a = 1
A()
mask = np.random.randint(0, 2, a.size)
i += 1
indices = heapq.nsmallest(10, np.nditer(arr), key=arr.__getitem__)
data = fi.readlines()
l = s.length
self.delete(name)
base64.encodestring(s)
value
new_ys = [point[1] for point in sorted_points]
ax2 = plt.subplot(gs[1])
ax.plot(plots[curr_pos][0], plots[curr_pos][1])
manufacturer = models.ForeignKey(production_models.Manufacturer)
__metaclass__ = ValidateType
long_word_set = set(long_word_list.split())
lstm_variables = tf.get_collection(tf.GraphKeys.VARIABLES, scope=vs.name)
data
x = x + A.__class__((xj[w], (w, tempj[:len(w)])), shape=b.shape, dtype=A.dtype)
small_nda = numpy.arange(25).reshape(5, 5) > 10
self.a = a
items = Item.objects.all()
cub_left.append(points[0])
l = s.split()
x, y = np.unravel_index(indices, full.shape)
kwargs
y = np.cos(x)
s.quit()
y.insert(0, y0)
newList = json.load(infile)
ans.append(cur_set[:])
sys.stdout.flush()
out = np.zeros(x.shape, dtype=int)
ranges.append(middle)
Console.WriteLine(test.GetTest())
{{form.as_p}}
print(word)
im.thumbnail(size, Image.ANTIALIAS)
j_content = json.loads(line)
ax = plt.gca()
s.groupby(level=0).value_counts().unstack(fill_value=0)
date_values = xlrd.xldate_as_tuple(cell_with_excel_time, wb.datemode)
True
time.sleep(delay)
print(oct_num)
bin_midpoints = bins[:-1] + np.diff(bins) / 2
[4, 1],
self.word_type = str(i)
stream.close()
srand48(100)
yTrain = np.array([[1], [0], [0], [0]])
nk1 = not_allowedclass()
nk = not_allowedclass()
nopreds.discard(v)
A = M.sum(0).sum(0)
id = Column(Integer, primary_key=True)
print(data)
grouped = df.groupby(groupbycol)
pool = Pool(processes=4)
pig
data = f.readlines()
words.append(teens[u])
value = dirty_data[key]
print(next(reader))
res = requests.get(url)
print(u)
p = figure()
summer_funcs(arguments)(1)
response
union_set.update(*l)
user = User.objects.get(username=username)
gen = (len(lst) - 1 - i for i, v in enumerate(reversed(lst)) if v == elm)
chunk_file.writelines(sorted_chunk)
length_of_int = int(math.log(x, base))
array = img.get_array()
parents = defaultdict(list)
items_view = gtk.TreeView(self.items_store)
current[name] = {}
1, 2
ret = np.array(arr)
clusters.append([])
iframe_soup = BeautifulSoup(response)
[Frameworks]
self.fmt.format(*self.args, **self.kwargs)
res.append(item)
hexList = re.findall(reg, hexes)
[a for a, m in mapped if m == minVal]
app = QtCore.QCoreApplication(sys.argv)
pprint.pprint(type)
myDict[tupleItem[1]] = myDict.get(tupleItem[1], 0) + tupleItem[2]
pool = Pool(processes=5)
print(inner.__code__.co_freevars)
v = np.ma.array([10.0, 11, 0], mask=[0, 0, 1])
Py_INCREF(IorFError)
timeit(lambda : iter(fulldict.keys()))
hour, minute = divmod(minutes, 60)
graph = GraphAPI()
False
records = cursor.fetchall()
text = Column(String)
counter += 1
newFile.writerow(midterm1Scores)
pAUC = numpy.trapz(tpr_array, fpr_array)
struct.unpack_from(fmt, self.recv_buf, self.recv_buf_i - sz)
con = pymongo.MongoClient()
res = set()
sA = sparse.csr_matrix(A)
item = list(item)
unq = unq.view(my_array.dtype).reshape(-1, my_array.shape[1])
f[keep_col]
print(marker.group(1))
next(tokens)
todict(X)
htmltree = lxml.html.fromstring(htmlstr)
[0, 0, 1],
not Counter([1, 2]) - Counter([1, 2])
src_files = os.listdir(src)
uniq = np.unique(data.view(data.dtype.descr * data.shape[1]))
byte_array = client.read_bytes()
alt.write(content)
print((dirpath, count))
f.close()
A = 2 * np.arange(10)
app = QtGui.QApplication(sys.argv)
sys.modules[borkenmod.__name__].__file__
timezone = pytz.timezone(tz)
idx = np.hstack((X.nonzero(), Y.nonzero()))
dok = SparseDOK()
False
print(boo, boo)
self._fileobj.__enter__(*args)
id = Column(Integer, primary_key=True)
fig, ax = plt.subplots()
tmp.add(tuple(i))
words = line.split()
r.text
inputList = ast.literal_eval(sys.argv[1])
p.join()
k_chars = [(m[0][0] + m[0][1]) for m in k]
dic1.keys() | dic2.keys()
client = oauth2.Client(consumer, token)
b = [4, 5, -10]
rescaled = (255.0 / data.max() * (data - data.min())).astype(np.uint8)
B.do_your_stuff()
max_val = l[max_idx]
self.master.mainloop()
a = np.hsplit(x, np.arange(12, 129, 12))
_fake_tb()
p = Popen(cmd, bufsize=1, stdin=open(os.devnull), stdout=PIPE, stderr=STDOUT)
root = Tk()
browser.visit(url)
keyword = CharField(max_length=100)
myarray = numpy.zeros((N, M))
string = df.to_string(header=False, index=False, index_names=False)
equal.append(x)
c1 = conn.cursor()
testsuite.addTest(unittest.defaultTestLoader.loadTestsFromModule(module))
file
is_approved_by_company_admin = models.BooleanField(default=False, null=False)
settings = json.load(f)
isclose(100, 97.1, rel_tol=0.02)
s += fh.read(SOME_CHUNK_SIZE)
lookup[(a[:, (0)] - 1), :]
Weight = celltext(columns[2])
list(RecursiveList.flatten(self))[index]
new[i, j] = xy[i][j]
argsdict[arg] = [val]
imputed_array
f.variables
print(parser.parse_args())
getCards(subList)
data_files = os.walk(path_to_files),
definition = models.TextField()
ax.bar(x_values, log_y_values)
results = list(csv.reader(inputfile))
bar_from_foo(self.foo(x))
http_server = tornado.httpserver.HTTPServer(Application())
result.append([])
char_counts[char] += 1
temp = os.walk(sys.argv[1], topdown=False)
activity.setContentView(self.webview)
subject = email_message.subject, body = email_message.body,
c = [[np.s_[i:j] for i, j in zip(r[:-1], r[1:])] for r in rgen]
buffer = QtCore.QBuffer(array)
print(text)
string = string[len(to_strip):]
self.handlers = collections.defaultdict(set)
x.executemany(q, itemBank)
self.libc.freelocale(self.ctx)
infile = open(sys.argv[1])
p.join()
A_process.wait()
test_set = set(string_to_teat)
root = ET.fromstring(TEST)
itertools.product(*list(rc.values()))
print(cell_value)
A[0, 1, 2]
print(img_tag)
numpy.repeat(vec_row.toarray()[0], numpy.diff(mat_row.indptr))
self.filter(group_set__pk=group.pk)
print(b1.to_array())
self.create_test_data()
self.height = height
pre_save.disconnect(pre_save_callback, sender=models.MyModel)
im = np.vstack([x] * len(x))
self.element_tree.write(xml_file)
ax.plot_surface(xx, yy, zz, alpha=0.5, color=cmap(c))
ax.yaxis.get_major_formatter().base(2)
dispatcher.connect(self.dont_close_me, signals.spider_idle)
-1
stopped = False
y = np.random.rand(20, 10)
j = np.lexsort(a.T)
pylab.imshow(img)
taker = manager.taker()
fig = pylab.figure()
cmp(self.number, other.number)
response
IFBIsFifo = 0
retrieved_a = d[b]
value & ~(1 << bit)
parsed_object = parser.loads(jsonString)
users_count = db.users.count()
Particle[i].AddNeighbor(Particle[j])
args = parser.parse_args()
pil_img = PIL.Image.open(StringIO(data))
stack.pop()
cursor.execute(query, params)
idx = np.argmax(np.abs(w))
print(body_content)
test(n)
print(word)
print(row)
a, b = select(L, 2, 5)
t.sort()
print(numbers)
a = list(range(10))
path = unsearched.get()
print(x)
soup = BeautifulSoup(html_doc)
f()
self.__dict__.update(kwds)
gamma95 = 1.0 - 0.05 ** (1.0 / (edof - 1.0))
count = 0
s = list(range(5))
result[key] = value
True
palette = img.getpalette()
data = [10.01, 5.001, 4.89, 5.1, 9.9, 10.1, 5.05, 4.99]
hash = hashlib.sha1(object_to_cache_as_string).hexdigest()
l = [4, 5, 6]
raise StopIteration
arr2d = np.meshgrid(np.linspace(0, 1, 6), np.linspace(0, 1, 11))[0]
render_mpl_table(df, header_columns=0, col_width=2.0)
self.change_label()
output = [(len(new_string[0]), new_string) for new_string in output]
print(key)
description = models.CharField(max_length=12)
topic = Topic.objects.get(pk=1)
fields = urlparse.parse_qs(field_data)
args = sys.argv[2:]
DT = Column(DateTime(timezone=True), default=func.now())
self._hash
box = x, y, x + w, y + h
np.random.seed(42)
waitKey()
d = {}
parser = argparse.ArgumentParser()
wave_file.writeframes(sample_str)
remainder = proc.communicate()[0]
A = A.astype(np.float64)
tbl.append(list())
array.ravel()[step:-step:step]
customAction
a.indices(10)
fout.close()
response = my_view(request)
show(p)
rows = [(d, random.random()) for i, d in enumerate(dates) if i not in omit]
app = QApplication(sys.argv)
print(neighbors(5, 5))
curdir = os.getcwd()
show()
precision = np.random.rand(42) * (1.0 - recall)
list(map(set, out))
B = expm(A).view(matrix)
[1, 2]
project_points(x, y, z, *calc_plane_bis(x, y, z))
beats = audio_file.analysis.beats
sys.exit(0)
a / b
stdout, stderr = process.communicate()
Nk = f.shape[2]
rect = self.addRect(r, Qt.white, gradient)
fig, ax = plt.subplots()
check = np.logical_or(a[:, (1)] == 4, a[:, (1)] == 6)
cur = [[14, k, j] for j, k in zip(rows[14], list(range(15)))]
sys.stdout.flush()
list[:] = newlist
print((i, item, len(line)))
xLim = [(x * 500) for x in range(1, 8)]
X = np.arange(1, 17).reshape(4, 4)
np.random.seed(0)
im = ax.pcolormesh(phi_itp, theta_itp, d_itp, cmap=plt.cm.coolwarm)
cft2.append(t.timeit(number=reps))
factory = ParentFactory()
hello.hello.restype = ctypes.c_char_p
x, y = points.get_data()
df.dtypes
True
result = is_abbrev(abbrev, text)
filtervalue = obtain_filter_value_for(filtername)
t = Test()
df
line_len = len(line)
d1.update(d)
print(nx.pagerank(D, max_iter=200))
a, s = s[:n], s[n:]
task1 = threading.Thread(target=do_request)
soln = np.zeros((size, size))
row = np.array([5])
ax.plot(list(range(100)))
links.append(recursiveUrl(link, 0))
set([OriginalExampleObject[A][1], OriginalExampleObject[C][2]])
df[col] = preprocessing.StandardScaler().fit_transform(df[col])
a = [1, 2, 4]
self.location = 0.0
df
p = ggplot(dat, aes(x=x, y=y, fill=z)) + geom_tile()
output = np.copy(arr)
1
fin.close()
5.88199996948
agenda_id = models.IntegerField(blank=True, null=True)
args = opt.parse_args()
comp.compile()
agacatacagagacatacagagacatacag
form = ProjectAdminForm
sorted(s)
orders = OrderSerializer(many=True)
x = datetime.datetime.combine(today, x)
c.join()
slcs2 = slcs[:]
[setattr(j, col.name, getattr(i, col.name)) for col in i.__table__.columns]
user = User.objects.get(username=username)
first = word[0]
self.setIconSize(QtCore.QSize(124, 124))
root = Tk()
get(remote_path, fd)
path
img = ImageTk.PhotoImage(image)
PyMODINIT_FUNC
self.setLayout(QtGui.QFormLayout(self))
lengthy_thingy = Thingy()
ma = np.ma.masked_array(a, mask=mask)
print(a.avariable)
rectangle.erase()
j = np.unravel_index(i, a.shape)
list(ips_data.keys())
x = (np.random.random((10, 10, 20)) + 0.5).astype(np.int)
frame = inspect.getouterframes(frame)[1]
print(dist.squareform(dist.pdist(data, lambda x, y: ss.pearsonr(x, y)[1])))
user = g.get_user()
d = datetime.date(2010, 12, 5)
next(it)
print(format_table(L_in_columns))
logging_thread.start()
functools.update_wrapper(_d, d)
globs = set()
sleep(1)
output_csv.close()
signal.signal(signal.SIGTERM, handle_signal)
linkto = os.readlink(srcname)
fig.subplots_adjust(bottom=0.2)
midpoint = vor.points[pointidx].mean(axis=0)
rows.append(row)
self._dump()
ax = fig.gca()
ether = dpkt.ethernet.Ethernet(data)
x.lower()
print(tag.getAlbum())
signal_handler(*args, **kwargs)
t = numpy.arange(81.0).reshape((9, 9))
part = sock.recv(size - len(msg))
worksheet.hide_gridlines(2)
x = math.floor((-b - math.sqrt(b ** 2 - 8 * i)) / 2)
b, c = [e[0] for e in zipped], [e[1] for e in zipped]
l = [(k, process(v)) for k, v in list(stuff.items())]
cls.__name__.lower()
self.left = tree
second_mask = np.zeros((4, 4), dtype=np.bool)
text.partition(left_identifier)[2].partition(right_identifier)[0]
data = {}
fclose(retclam)
pool.waitall()
sum(c * x ** p for p, c in enumerate(arr))
fig, ax = plt.subplots()
show()
mean = cv2.mean(bottom)[0]
c1 = Cookie.SimpleCookie()
qs = self.model._default_manager.all()
autostart = true
extarg = 0
p.set_array(colors)
vals[i]
listB[0][1]
c = a + b
time_d_ms = time_d / datetime.timedelta(milliseconds=1)
cameraL.SetPosition(40, 0, 200)
p.start()
arrB = np.asarray(B)
helpers.bulk(es, actions)
index[axis] = z2.argsort(axis)
chr(pos + 97)
logger = get_task_logger(__name__)
print(item)
print(date.toordinal(date(1971, 1, 2)))
d = {}
main()
df
d[parts[0]] = d.get(parts[0], []) + [parts[1]]
match_geotrans = match_ds.GetGeoTransform()
con = pymongo.MongoClient()
counts = idx[1:] - idx[:-1]
yinch = ypixels / dpi
self.msg = msg
a = np.linalg.inv(np.dot(X.T, X))
mat1 = []
mat2 = []
print(datetime.datetime.utcnow())
X, Y = np.meshgrid(x, y)
out = [x[0] for x in gona]
form = CreateUserForm.new()
slcs1[i] = slice(0, -1)
ten
sum(c1 != c2 for c1, c2 in zip(string_1, string_2))
func(*args, **kwargs)
func
[2] + [(i * 2 + 1) for i, v in enumerate(sieve) if v and i > 0]
self._data[self._keys[key]]
parseXMLFromString()
make - j4
reader = csv.reader(f)
(16, [2, 2, 2, 2]),
words_sorted = sorted(my_string.lower().split(), key=len)
self.name
self._realOutput.write(text)
colors = (np.random.random((N, 4)) * 255).astype(np.uint8)
pyplot.show(one.plot())
base_h, base_s, base_v = rgb_to_hsv(base_r, base_g, base_b)
self.write(text)
b[0]
A = sc.parallelize().map(partial(worker, V=V))
mkl_rt.mkl_set_num_threads(ctypes.byref(ctypes.c_int(cores)))
test_results = ldaModel.transform(wordVecs)
sizer = wx.BoxSizer(wx.HORIZONTAL)
countup(N, n + 1)
my_thread.start()
sys.getwindowsversion()
string[:string.index(suffix) + len(suffix)]
self.response = app.post(*args, **kw)
print(b.Pear)
out = s.index[maxidx + np.arange(maxidx.size)]
np.broadcast(*args).shape
addArray(array)
result
log_file.write(s)
raise Exception((status, reason))
L.append(a)
res.append(np.diag(vif))
the_data_model.delete()
suite = unittest.TestSuite()
func_globals.update(_namespace)
v.shape
line = line.strip()
d = {}
[cleaned(x) for x in re.finditer(WORD_REGEX, s)]
ClassA.__init__(self)
words = str_.lower().split()
d = {}
pp = scipy.interpolate.interpolate.spltopp(tck[0][1:-1], tck[1], tck[2])
frame.pack()
PyArray_ITER_NEXT(it1)
self.SetSizer(sizer)
root = html.fromstring(encapsulated_text)
Tkinter.Tk().withdraw()
raise Exception()
forms[1].controls[0].name
dict = {}
a.x
self.sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
words = sorted(counts, key=lambda word: (-counts[word], word))
mylist = [random.randint(0, 1500) for _ in range(10000000)]
parameters = param7, param8, param9
json.loads(json.dumps(members))
driver = webdriver.Firefox()
index2count[i] += 1
print(line)
sleep(1)
bigset = set(random.sample(range(Max), Setsize))
print(foobar.__name__)
x = np.arange(10)
pool = Pool(16)
self.func(v1, v2)
soup = BeautifulSoup(f)
self.nstep = nstep
self.form_valid(form, **kwargs)
{}
column = int(sys.argv[2])
basePath = os.path.dirname(os.path.abspath(sys.argv[0]))
20, 20, 2, 2, 18, 5
records = list(json.loads(df.T.to_json()).values())
1 - (A, B, E, D)
grids[idx[i, 0], idx[i, 1]] += 1
plt.pcolormesh(xi, yi, zi)
self.d[k] = v
f.name
print(sum(map(lambda x: x ** 2, [x for x in lst if x % 2 == 0])))
r.headers
n = x.shape[0]
msgBox.exec_()
A[0, 1]
res
plt.sca(ax)
transport.open()
sys.stdout.write(screen_code)
cython.long
plugin.plugin_main(*args, **kwargs)
dst.copy_key(k.key, src.name, k.key)
can.save()
path, filename = os.path.split(path)
ax.plot(list(range(10)), rd.random(10))
value = blob_reader.read()
Makefile
app = WSGIApplication()
print(s.getvalue())
MI.Close()
np.allclose(old, new)
user = models.ForeignKey(User)
l = [2, 6, 5, 4, 2]
s.lower() in keywords
temp_path
val = np.sum(1.0 - np.cos(a - b))
count += 1
view = QtGui.QTableView()
ax2.set_ylim([-200, 200])
dic = dic[key]
raise ctypes.WinError(ctypes.get_last_error())
result.append(opv)
extend_nums(nums, 5)
r = {}
print((len(perms), perms[0:10]))
a = np.arange(90).reshape(10, 9)
view_fields(a, keep_names)
plt.plot(x, y)
termf.pack(fill=BOTH, expand=YES)
now = np.datetime64(datetime.datetime.now())
mask = np.arange(images.shape[0]) % 6 != 0
print(serial_ports())
plt.contour(np.log(r / 1.2))
list(clusters.values())
pygame.time.wait(100)
row.append(field[k][i])
C[1::2] = B
inspect.getargspec(aMethod)
tkimage = ImageTk.PhotoImage(image.rotate(angle))
url = key.generate_url(expires_in=0, query_auth=False)
ipdb.set_trace = f
result
res = self.func(*args, **kwargs)
session_key = asymmetric_dec(session_key, prikey)
checker.validate(data, schema)
self.points = [Point(random(), random()) for _ in range(numpoints)]
sample_weight = np.array([(5 if i == 1 else 1) for i in y])
process_count += 1
file.seek(pos_dec + word_len)
styles = getSampleStyleSheet()
npreds[v] -= 1
fig, ax = plt.subplots(figsize=(9, 5))
temp.append(num)
print((location.latitude, location.longitude))
counter[0] += 1
p = Process(target=self.proc, args=(i,))
True, True, True, True, True, True, True, True, True
activation.done()
heapq.heappush(gens, succ)
filteredKeys = (key for key in list(myDict.keys()) if userInput in key)
ax1 = plt.subplot(gs[0])
layout = QtGui.QVBoxLayout()
INS
sortedDict = sorted(subjects, cmp=make_comparator(cmpValue), reverse=True)
x = list(range(0, 7))
f = sys._getframe()
self.end_headers()
cur.execute(string)
res = __import__(mod)
p1 = os.path.join(path, p)
mfun
repr(self.__dict__)
connection.text_factory = str
nx.draw(G, with_labels=True)
themin = arr[0]
script_elt.extract()
dim_array = np.ones((1, a.ndim), int).ravel()
G = C_abs + C_abs.T
ordered = sorted(iter(colour.items()), key=itemgetter(1))
chardet.detect(s)
line_list[-lines_2find:]
np.exp(x) + np.sin(y)
True
cls
out[k].append(item)
choice(seq)
rms = sqrt(mean(square(a)))
zip.close()
p.join()
self.assertFailure(d, ValueError)
C.shape
app.start()
c = sys.stdin.read(1)
data = []
print(row)
sys.exit(1)
results = a[np.triu_indices(len(x), 1)]
lab = color.rgb2lab(io.imread(each_file))
d = 2
thread.start()
dupl = []
print(nonlinear_invert(f, x, y, z))
m = r.search(str1)
endfun
now = datetime.datetime.now()
pool.close()
a = int(a) if int(a) % 2 == 0 else int(a) + 1
np.random.seed(101)
[(ord(x.lower()) - 96) for x in string.letters]
ascript
xa.execute()
globals()[k] = self.oldglobals[k]
print(arr)
draw.text((0, 0), text, font=font)
functor()
assert memprg.date_registered < date.today()
username = db.Column(db.String(80), unique=True)
x, y = np.random.random((2, 10))
response = urllib.request.urlopen(request)
program.py
p = etree.HTML(r.text)
is_sub(b, a)
dlg.Destroy()
bob0.save()
x()
self.assertTrue(result > 0)
d = datetime.date.today()
xlock.acquire()
b = [False, False, True]
com_instance.Quit()
droid = android.Android()
raise TypeError(node)
resultList = [item for sublist in resultList for item in sublist]
install_all_the_things()
overlap(0, 10, 80, 90)
aes.decrypt(base64.b64decode(encrypted))
df
self.grid()
send_from_directory(UPLOAD_FOLDER, filename)
wdict = words_dict()
capital = models.CharField(max_length=50)
my_model
in_.seek(-min(size, chunk_size), 2)
do_stuf = fun1(do_stuf)
l = [4, 5, 6]
data = list()
login(request, user)
wb = Workbook()
bin(2)
z = np.random.random((len(r_test), 1))
db_session = scoped_session(sessionmaker(bind=engine))
t = plt.gca().transData
base.__dict__[name]
qproc.join()
plt.show()
rsum.append((x[0], rsum[-1][1] + x[1]))
pool.close()
p.join()
self._channel.basic_ack(basic_deliver.delivery_tag)
numbers = [number for number in numbers if number % results[-1] != 0]
communicator = Communicator()
dests = set()
print(imgray.shape[:2])
print(a[:4])
out = write()
Gh = NX.Graph()
[2, 4, 6]
parent_map = {c: p for p in tree.iter() for c in p}
x + 1
self.callback()
outputfile.write(*args, **kwargs)
start_urls = [URL]
stack.extend([v for v in self.graph[vertex]])
obj.pop(i)
sig2 = numpy.interp(t, t2, sig2)
small_list_set = set(small_list)
mutex.release()
image = np.array(image, copy=True)
[y ** (1 / 2), -y ** (1 / 2)]
xx = np.linspace(0, 10)
s.format(**d)
n = uniform(0, weight_total)
print(cell)
samples = [[0, 0], [0, 1], [1, 0], [1, 1]]
assert a == b, (repr(s), a, b)
df5 = df.ix[:, 48:60]
listbox.insert(0, myTkObject.clipboard_get())
writer.add_document(title=item.Title, content=item.content, url=item.URL)
print(y)
cls.var1
ip
z.argmin(1)
res
data_val = np.random.rand(len(data_id))
res.append(1)
l[1]
result.append(p)
a.append(99)
wildfd.inc((w1, w2))
y_subplot = fig2.add_subplot(2, 2, i)
output = proc.communicate()[0]
name
df
first_set = set([0, 1, 2])
test(constrained_combinations)
dvalue = Column(DateTime)
rv = self.parse_statement()
current_string = current_string[0:-1]
p4[8], p4[9] = tb.tb_frame.f_lasti, tb.tb_frame.f_lineno
stripped_line = line.strip()
soup = BeautifulSoup(s)
self.traceback.append(self.col_seq[j - 1].lower())
a = np.ascontiguousarray(A).view(rowtype).ravel()
print(repr(obj), obj.__dict__)
word1 = equivalence.lemmatize(word1)
fl.close()
std_devs = np.diag(np.sqrt(cov))
s += n % 10
nondupes = [(original & all_uniques) for original in allsets]
list(d.keys())
[name for name in namespace if namespace[name] is obj]
NA = NA_()
np.array([p for i, p in enumerate(A.flatten()) if i > i / N * (1 + N)])
new = list(it.imap(int, old))
plot_visible(ax.azim, ax.elev)
numpy.add.reduceat(a, [0, 2, 4])
print(data)
sorted(personArray, key=compare_person)
gc.collect()
b = np.zeros(100, 10)
login_user(user, remember=True)
plt.show()
Mn = set([])
bar = Entry(master).grid(row=1, column=1)
item = self.combo.model().item(row)
print(config_root.server.version)
render_template_string(template_form, form=form)
print(request.command)
dict(t)
HTMLParser.__init__(self, strict=False)
d[0] += 1
pprint.pprint(Y)
b = np.ma.masked_where(mymask, a)
inqueue.put(sentinel)
sys.exit(1)
b = [4, 5, 6]
myTurtle.goto(0, 250)
phi, theta = np.meshgrid(phi_array, theta_array)
self.initSearch()
foo(line)
m = X.mean(axis=1)
sys.stdout = out
ax.plot(np.arange(0, i * 4, i))
n.bit_length() - 1
a, b = 1, 1
print(my_func(1, 2))
shutil.copyfileobj(open(infile), outfile)
print(listbox.selection_get())
LM2ML(vecs[:k])
nodes = draw_networkx_nodes(G, pos)
self.is_running = False
byte = f.read(1)
n & 1 == 0
pool = Pool(16)
as_strided(b, (n - 1, n + 1), (b.itemsize * (n + 1), b.itemsize))[:, 1:]
[6, 5, 4],
path[0]
res = pd.Series()
rows = itertools.product(df1.iterrows(), df2.iterrows())
self.initialized()
result = result.difference(dateRange2[b])
a.write(str(f) + os.linesep)
result = d.groupby(level=0).apply(lambda x: pd.value_counts(x.values.ravel()))
Y[:, (1)] = 1
fig = plt.figure()
soup = bsoup(r.content)
print(x)
yourproject / yourapp / middleware
to_remove.append(index)
executor.submit(submit_to_gui, f.result())
list(map(set, out))
self._db = db
x += 1
br = mechanize.Browser()
nums = [int(i) for i in line.strip().split()]
epoch = datetime.datetime.fromtimestamp(0)
p = itertools.permutations(l)
pool.append(p)
modules.append(thing)
True
cur.append(c)
loop = asyncio.get_event_loop()
str(datetime.now())
hsh = urllib.request.HTTPSHandler()
Create(Path.Combine(directory, Path.GetRandomFileName()))
response = HttpResponse(wrapper, content_type=mime_type)
new_string += escape_dict[char]
my_contact = Contact.objects.get(pk=contact_pk)
glob.iglob(pathname)
dfr = df.ix[rindex]
cur = con.cursor()
self._cards[card_ID].shift(amount)
columns = defaultdict(list)
json1 = json.dumps(dict2, ensure_ascii=False)
simplejson.dump(data, outfile)
print(my_date)
summary_dict = {col: [] for col in new.columns[1:]}
r.sendline(line)
a = a & b
max(s, key=len)
f1 = [(x + 20) for x in range(80)]
bitmask = [True] * len(source)
canvas = Canvas(root, width=640, height=480, bd=0, highlightthickness=0)
int(aString, 8)
alphs = string.ascii_lowercase
vals[bisect.bisect_right(keys, 0.464897)]
id(self._obj)
sum(map(operator.mul, *pairwise(l)))
True
print(regx.sub(repl, ss))
mask = np.array(out.sum(axis=0)).ravel() != 0
site = ftplib.FTP(hostname, username, password)
figlegend.show()
row_count = chunk.shape[0]
doit()
leng.count
r1.shutdown()
subfn
attempt(attempt_something, lambda : foo(bar))
pairs = []
print(names)
a[not_indices] = 888
x, n = np.mgrid[0:20:0.01, 1:100:1]
procs.append(p)
x = np.linspace(0, 10 * np.pi, 1000)
start = dt.datetime.now()
self.typemap = {}
filter = np.array([True, False, True, False])
tmp_dict = cPickle.load(f)
last_name = models.CharField(max_length=40)
table.setdefault((w1, w2), []).append(stopword)
a == b
min_time.replace(hour=hour, minute=minute)
ax.add_collection(PC)
d = dict(self.__dict__)
a = np.asfarray(a)
value = func(self)
s.close()
UTF - 8
print(ldamodel.print_topics(num_topics=2, num_words=4))
[buildout]
defaults.update(kwargs)
a = BitArray(6000000)
current = []
start_new_thread(task, ())
y = [4, 5, 6]
main()
feet = float(floatfeet or 0) + float(feetnum or 0) / float(feetdenom or 1)
x = not x
cherrypy.engine.block()
raise TypeError
client = Client(url, transport=ntlm)
sys._getframe(back + 1).f_lineno
args = p.parse_args([])
pos_list.append(item)
closedir.argtypes = [c_dir_p]
True
getattr(__builtins__, name)
IFBIsFastSer = 0
pylab.plot(f, Xdb)
first_col = np.where(cols == False)[0][0]
c = get_config()
raise
_f
app = QtGui.QApplication([])
wolfer = tempdata[:, (1)]
df2
data = {k: [convert(v, float)] for k, v in list(dr.next().items())}
p_surplus += 1
wiringpi2.wiringPiSetupGpio()
sp.Popen([programName, fileName])
filtered.append(line)
f = gen2()
print(significant_1(0.45))
n = df.shape[0]
baz()
bode(f)
[(a + b + a) for a, b in matches]
A[subset][j] = min(A[subset][j], A[subset ^ 1 << j - 1][k] + get_dist(j, k))
a in {0, 1}
logger.propagate = False
rolled_mask = np.roll(np.roll(mask, -2, axis=0), -2, axis=1)
{x, 0, y}
out[1]
500000000000000, 600000000000000, 700000000000000, 800000000000000
new_matrix[t, conv[t, z, y, x], y, x] = temp[t, z, y, x]
r.url
sorted_ab = list(zip(*sorted(chain(keyed_a, keyed_b), key=lambda t: t[0])))[1]
d[k] += v
b = [4, 5, 6]
prev = date.today().replace(day=1) - timedelta(days=1)
{{key}}
shared_time += (min(t1_stop, t2_stop) - t1_start).total_seconds()
doc_dict.update(doc.attrib)
print(testme, len(testme))
base.summary(my_pandas_dataframe)
keyword.kwlist
a = [(aa if i < 20 else 0) for i, aa in enumerate(a)]
print(c)
x / blub10.txt
y = np.random.normal(0, 1, num).cumsum()
flask.jsonify(time=time.time(), value=value)
xmin = data.min()
dictb = dict(zip(listbnum, listb))
confirmed = get_object_or_404(EmailConfirmed, user=request.user)
freduced = interpolate.UnivariateSpline(x, yreduced, s=0)
self.archive = py7zlib.Archive7z(fp)
imgB = imgB.astype(float)
l2 = [2, 1]
p.map(unpack_wrapper(merger), mergelist)
sess.run(init_op)
myTurtle.speed(0)
ip_address = db.StringProperty()
i += 1
x = np.linspace(10, 110, 1000)
rows = cur.fetchall()
c = ChessBoard()
month = SelectField(choices=MONTHS)
dumper.represent_dict(data.convert_to_yaml_struct())
self.multiply(self.x, self.y)
print(nestedExpr().parseString(data).asList())
getattr(logging, key)
adj = widget.get_vadjustment()
fig, ax = plt.subplots(1, 1)
self.pred(obj)
characters = splitre.split(credits)
df
b = bytearray(f)
measurements = np.random.normal(loc=20, scale=5, size=100)
df1 = df.T
stream = cStringIO.StringIO(value)
1, 2, 0, 0
V = (np.arange(M * N) / (M * N)).reshape(N, M)
easygui.egdemo()
print(funcs[2]())
x = 1
dic[a] += b
p_values = scipy.special.ndtr(-z_scores)
df.index = df.index * 10
names = list(row.keys())
timeit(lambda : fulldict.keys())
deq.append(p)
newlist = []
bin(1)
print(test.g(666))
mean2 = g.mean()
options = webdriver.ChromeOptions()
read = p.stdout.readline()
MI = pandas.MultiIndex.from_product([i, j[0]])
SEARCHENGINE = NO
lg.string
is_invertible(b)
xx = np.arange((len(A) - 1) * n + 1)
options.remove(current_option)
filelist = ftp.nlst()
namedict[key] = val
v = [[1], [1, 2]]
print(name)
shared_time += (min(t1_stop, t2_stop) - t2_start).total_seconds()
vbox.addWidget(button)
r = np.zeros((rows, rows))
c.join(l)
form_class = self.get_form_class()
azi = np.arctan2(X[:, (1)], X[:, (0)])
self.get_nowait()
print(str(err))
json_object = json.loads(myjson)
serializer_class = serializers.UserSerializer
print(theQ.get())
print(status)
((np.cumprod(x) - 1) * p)[-1]
poly_coeff = np.polynomial.polynomial.polyfit(w, v, 2)
i = df.index.values
self.left.insert(othernode)
process_data(data)
composed
carnamit = iter(carnames)
q.put(x)
mview = memoryview(tmp_buf)[OFFSET:AMOUNT]
show(p)
self.color = color
[serialize(item) for item in obj]
b.set_list(list(range(5, 10)))
screen = pygame.display.set_mode((640, 480), FULLSCREEN)
index = []
clisocket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
seen_add(element)
auth = OAuth1(API_KEY, API_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET)
hash(self.x)
i, self.store[i][0]
f = (lambda a: lambda x: x ** a)(a)
console_handler.setLevel(logging.DEBUG)
result[1::2] = list2
print(parse(stream))
a.save()
newfile.write(line)
print(json2xml(j))
plt.grid(True)
v = x * np.cos(5) + y * np.sin(5)
b = [4, 5, 6]
f(1, covered_list)
app.MainLoop()
im_data = np.ndarray(shape=(cols, rows), dtype=np.uint8)
y = np.sin(x)
loop.close()
vfoo(I, J, K)
df[0] - df[1]
v = [7, 4, 5]
exponents = list(range(-1, (-precision - 1) * 2, -1))
entry_date = models.DateTimeField(default=datetime.now)
f.close()
d = dict()
A[j] = n
self.f.write(text)
url, len(response)
output_notebook()
file.tell()
self.deadline = self.env.cr.fetchone()[0]
Y = np.arange(size)
ppc
cholupdate(R1_, u.copy())
delattr(mod, symbol)
request = cherrypy.serving.request
p = [l[i:i + 2] for i in range(0, len(l), 2)]
print(msg_str)
theState = models.CharField(max_length=64)
out.flat[np.ravel_multi_index(data.T, dshape)] += 1
current_string.append(chr(inkey))
t.render(c)
obj = ref()
foo(42)
decorator
first_name
maxword = max(len(x) for x in words)
main()
hist, x_bins, y_bins = np.histogram2d(x, y, bins=(50, 50))
cols = df.iloc[:, 2:].columns
bucket_name = settings.AWS_STORAGE_BUCKET_NAME
dateData.append(date)
player_wins = rps()
br.submit()
split_list
B[:, (col)] = np.prod(A[:, (mask)], 1)
self.assertEqual(Foo.query.count(), 1)
si = StringIO.StringIO()
idnumber = Int64Col()
tmv[i, j] += 1
total += os.path.getsize(path)
frame.Show(True)
list({gameId: bitrate for _, gameId, bitrate in reversed(myListOfTuples)}.items())
libadd.Add.restype = ctypes.c_int
lons, lats = numpy.meshgrid(lons, lats)
logging_handler_out.setLevel(logging.DEBUG)
dict(user=g.user)
tuple_foo(t)
print(json.dumps(x, indent=2))
ys = np.sin(xs) + np.random.normal(0, yerrs, xs.shape)
self.fig.axes[0].set_title(self.line_edit.text())
q.put(s[-4:])
writer.write_array(output, pixels)
lines = islice(f, 0, 2 * N - 1)
main()
print((d - epoch).total_seconds())
csr.indptr[1:] = np.cumsum(nnz_per_row)
img_temp.flush()
hosp_info
xy = 10 * np.random.random((chunksize, 2))
conn, addr = s.accept()
ax.view_init(elev, azimuth)
f.close()
b = np.random.randint(0, 5, size=(6, 4))
logger_2.addHandler(hdlr_2)
losses.append(b.eval())
trgtext = trgtext.split()
result[i, j] = a[i] * b[j]
self._n = n
search_str = self.text_to_find.get_text()
idx = random.choice(indices)
bsizer = wx.BoxSizer()
maxsort = counts.argsort()[::-1]
d = d[partial_key]
cv2.rectangle(char_mask, (x, y), (x + w, y + h), 255, -1)
df.iloc[:, (i)] = i * df.iloc[:, (i - 100)]
G = nx.Graph()
transaction.savepoint_rollback(sid)
r = random.randint(0, i)
parse = argparse.ArgumentParser()
loop.create_task(do_work(envelope, body))
n_pages = document.get_n_pages()
isitIn(char, b[:len(b) // 2])
name = models.CharField(max_length=128)
weights.pop()
nums = (b for a, b in zip(a, count(a[0])) if a != b)
table.row_cells(r)[c].text = cell
all_data = numpy.hstack((A_noisy, B_noisy))
out = np.repeat(tmp12, color_occupations.ravel())
data.sort(key=lambda c: c[1])
inblock = nextnl + 1
rows = np.isnan(g).all(axis=1)
main()
print(i)
text[:text.index(c)].rstrip()
PTS = lambda x: 1.0 * x
renWinR.AddRenderer(renR)
jump_indices = np.where(jumps)[0]
print(line)
n = len(a)
NewClass
map(print_node, node.get_children())
np.random.seed(seed=0)
[set(v) for v in arr]
a = np.arange(1.0 * 2 * 2 * k * k).reshape(2, 2, k, k)
dom = ET.parse(os.path.join(cd, xmlfile))
b.argsort(1)
self.dialog = QtGui.QDialog(self)
interlocked = [word for word, a, b in word_gen if a in words and b in words]
a = Column(Integer, primary_key=True)
set(b) in set(a)
data = np.array([line.strip() for line in f.readlines()])
intree = True
self._x = value
f
response.json()
self.given_server_is_offline()
matches = [r.match(s[i:]) for i in range(len(s))]
csvwriter = csv.DictWriter(outf, fieldnames)
json = response.body
ax = fig.add_subplot(221)
sess = tf.Session()
pointers = [ctypes.addressof(ctypes.create_string_buffer(8)) for i in range(4)]
np.nan_to_num(data)
self.pop(i)
lsb_release.get_lsb_information()
tst = models.ForeignKey(someData)
urllib.parse.urlencode(z)
cost = [int(i) for i in cost]
self.mysignal.emit(text)
self.check_object_permission(request.user, obj)
pool.apply(locale_aware_sort, [strings, loc])
bodylist.append(body)
key = row[0], row[1]
arr = np.array(img)
list.add(1)
p.register(f.stdout)
d[1]
self.__setstate__(s)
x = S1()
ax = plt.gca()
aresult = q.get()
my_decorator
NULL
sample = np.random.uniform(0, 1, 50)
result
self.trayIcon.show()
keys.sort()
Foo().spam
size = sys.getsizeof(string) - 20
(list(map(sub, chain(s, e), chain(b, s))) for s in splits)
self.broken = False
sess.run(init_op)
test.foo(x)
dir = frob
this_friday = sow + timedelta(days=4)
indexing_with_clipping_v2(arr, indices, clipping_value=2)
str(soup)
r.encoding
tor_process.wait()
n_edges = data.shape[0]
grouped = df.map(lambda row: (row.a, (row.major, row.cnt))).groupByKey()
print(item)
result = result.astype(np.bool_)
a.insert(i + 1, [0, 0])
im = rgb2gray(im)
celery.start()
mock(), mock()
print(test.data)
pool = Pool(processes=8)
mat[i, j] = random.randrange(2)
fig, ax = plt.subplots()
f.seek(0, 2)
self._cookies = pickle.loads(string)
requestOpener = urllib.request.build_opener()
c = s[:, ([i, j])]
numpy.hypot(d0, d1)
sys.exit(0)
CO = np.corrcoef(X_.T)
x = np.linspace(-20, 20, 500)
x, y = m(lon2, lat2)
path = os.path.join(savedir, filename)
mask = np.random.random((10, 10)) < 0.2
data[start:start + size]
false
img.paste(face, tuple(coord[::-1]), mask=face)
print(list([w for w in wordlist if prog.match(w)]))
messageprocessok = False
{}
A = np.array(a.data).reshape([4, 4])
idx = (A[:, (0)] > from_date) & (A[:, (0)] <= to_date)
fig.add_axes(ax)
topbottom[(0), 0:im.shape[1]] = np.argmax(im, axis=0)
numpy.add.reduceat(data[f], i)
a[:, (1)]
x = np.array(np.random.normal(size=(4, 4)))
n = sum(int(d) for d in str(n))
result
c.head()
num_overlap = sum(1 for t in zip(list1, list2) if all(t))
setattr(random, f, our_decorator(getattr(random, f)))
list(self._sections[section].keys())
fig = plt.gcf()
canvas.pack()
OrderedDict(sorted(list(d.items()), key=lambda t: len(t[0])))
print(D.x)
d_truncated = datetime.date(dt.year, dt.month, dt.day)
spline = UnivariateSpline(x, blue - np.max(blue) / 2, s=0)
thread.daemon = True
email.utils.parseaddr(email_address)
np.ma.masked_array(np.interp(value, self._levels, self._normed))
matrix = vect.fit_transform(traindata)
queue.append(x)
filtered1.append(leftData[i])
output.append(new_output)
lol(x, 7)
serializer_class = MyModelSerializer
x = a, b, c
show()
df_test.update(df_update)
self.__f(x + 1)
imgplot = plt.imshow(img)
ax = fig.add_subplot(1, 1, 1)
df
shell()
i += 1
x, x + 2
xedges = np.linspace(-10, 10, 100)
a = asarray(list(s), dtype=h)
logging.basicConfig(stream=log_stream, level=logging.INFO)
y_sample = y[idx]
2 + 2
load(a)
left = randint(0, len(L) - 1)
L[c] += 1
Base.metadata.drop_all(engine, tables=[DeclarativeTestModel.__table__])
date = dt.datetime(date.year, date.month, date.day) + dt.timedelta(hours=10)
myObject1 = MyObject()
repr(0.1000000000000999)
new_dc_files.append(dc)
print(numbers)
x = next(stack[0])
print(f.subs(n, 6))
output.append(row)
fig = plt.figure()
data = json.loads(request.data)
main()
autodoc.add_documenter(DocsonlyMethodDocumenter)
train_text[11]
vdisplay.stop()
user_options = []
ntlm = WindowsHttpAuthenticated(username=user, password=password)
print(columns[1])
gr = P.Group(P.OneOrMore(key_equal + val))
html = file.read()
fibpy(x - 1) + fibpy(x - 2)
ws = excel.Workbooks.Add().Worksheets(1)
rand_list = random.sample(range(100000000), num)
sorted(globs)
os.close(output_fd)
results = []
plt.clf()
print(b.x)
df == pd.Series(conditions)
x = s[1] - s[0]
ws = wb.active
Tree()
q1m0[k] = -q0m1[k]
f.seek(randint(10, 250))
d = len(l)
result.update(self._attr_value_to_obj_set[attr_value])
result = result[::-1]
print(significant_1(1999))
print(significant_1(1945.01))
items = list(d.items())
li = iter(object_list)
print(net.num_addresses)
seen = set()
b()
print(new_random)
ind = ind[third_mask]
self.func = func
data = [cmap[i] for i in img1_k]
diags
plt.ylim(ymin, ymax)
logging.warning(message, extra=extras)
levels.pop()
qapp = QApplication(sys.argv)
t.join()
self.redraw()
group = models.ForeignKey(Group)
dosomethingelse(),
slice(2)
smtp.starttls()
roundup(101)
print(node.getData())
result = job.apply_async()
data = json.load(response)
M = np.arange(1500 * 2000).reshape(1500, 2000)
old_init = thirdpartymodule_a.SomeClass.__init__
self.b = b
self._add(val, node.l)
q = Queue()
partition.append(justseen)
width, height = img.size
pymysql.install_as_MySQLdb()
start = datetime.now()
data.append(0)
show_children(parse_root(tokenize(example)))
a, N - a * a
iterateFinitely(lambda y: [f(y)] if y else [], x)
a * (not p) or [sub_k_list(a[:p], k), sub_k_list(a[p:], k)]
root = tk.Tk()
module = __import__(modulename)
z = func((x, y), a, b, c) * 1 + np.random.random(101) / 100
ip = models.CharField(max_length=200, blank=True)
m[1, 1]
print(df1)
req_json = request.get_json()
[D, [[B, A, C], [F, E, G]]]
find_file(drive, rex)
item.wickets[10] *= 2
number = Wire.read()
self.dock1.setWidget(QtGui.QTextEdit(self.dock1))
idx0 = np.where(m, a, np.nanmin(a) - 1).argmax(1)
csX.nzmax = X.data.shape[0]
self.field4price = msg.price
b = []
result
sleep(2)
args = parser.parse_args()
err()
data[tuple(ind)]
A = np.random.rand(20, 20, 2, 2, 18, 5)
mp_handler()
res.get()
print(a.shape)
r += (x[i * DIM + d] - x[j * DIM + d]) * (x[i * DIM + d] - x[j * DIM + d])
next(r)
print(s % x)
auth.refresh_token()
self._count += 1
print(parser.parse_args(c.split()))
ui[1:] = (diff != 0).any(axis=1)
df1.columns = df1.columns.values.astype(str)
bSizer.Add(button2, 0, wx.ALL, 5)
cpy.write(pgcopy.tostring())
print(df2)
req = urllib.request.Request(url_1)
raise Error(key, context=ex)
some_list[start:end:step]
timer = Timer(timeout, timeout_handler)
solve(equations, P, Q, S, T)
knownAdds = set(line.strip() for line in infile)
job.start()
time.sleep(0.1)
thefile.seek(0, 2)
test()
self.set_list(list(range(n)))
exampleText = f.read()
cherrypy.engine.start()
z = np.ceil(x)
False
t = threading.Thread(target=my_thread, args=[a_stop_event])
entryFrame.grid_propagate(False)
(list(range(5))[4:5] + [999])[0]
self._worker_handler.daemon = True
response.raise_for_status()
self.assertEqual(99, s1)
ssqlContext = sqlContext._ssql_ctx
img = np.zeros((256, 256))
serializer = self.get_serializer(page, many=True)
self.parse,
Type[int(RNumX + 0.5)][int(RNumY + 0.5)].append((RNumX, RNumY))
(x >> power2 - 1) + 1 >> 1
ab = [o for o in itertools.chain.from_iterable(genny(x) for x in y)]
get_user_model().objects.get(pk=username)
conn = xmpp.Client(jid.getDomain())
print(QtCore)
punkt.train(abbrv_sent, finalize=False, verbose=False)
a = 0
buf[:] = names
random.choice(lists[category])
pl.show()
print(StudentTCI(1, 2, 10, 0.99))
self._subs_list(sequence)
tmp = [os.path.join(root, f) for f in files if f not in exc]
1 * p(x)
client = Client(url)
last_dir = os.path.dirname(last_dir)
now = datetime.datetime.now()
bins[1] = bins[1] - bins[1] / 2
lft -= 1
A[:] = {1, 2}
assert np.all(c_order == f_order)
print(repr(instance.method))
splitter.show()
result = urllib.request.urlretrieve(image_url)
data = infile.read()
print(next(spamreader))
joystick_count = pygame.joystick.get_count()
result
d.astimezone(est)
B = A[:, (np.newaxis)]
register = template.Library()
sorted_list = sorted(initial_list, key=move)
clock = pygame.time.Clock()
y_mad = left_mad * np.ones(len(y))
combo = QtGui.ComboBox()
json_doc = json.dumps(doc, default=json_util.default)
do_stuff_with(b)
self.draw_counter += 1
train_data = data[:50]
out[start:end] = a.reshape(-1)
m = np.random.random((6, 6))
x = np.random.rand(10, 10)
im = ax.imshow(z, *args, **kwargs)
b[b < 0] = 0
self.list = QtGui.QListWidget(self)
[F(N), F(N - 1)]
a[indices]
[buildout]
fig.autofmt_xdate()
self.s = s
xyz = [0, 12, 4, 6, 242, 7, 9]
tocall(*args)
print([data])
new_modules
r = random.random()
print(find_skew(list(range(256 - 256 % 26))))
x, y
print(tag.name)
contact_form = ContactForm(instance=my_contact)
varName(x)
camera_pos_x, camera_pos_y, camera_pos_z = s[12:15]
cursor.skip(4000)
r = requests.get(zip_file_url, stream=True)
new_list.append(0)
merged = collections.defaultdict(set)
False
self.timestamp = time.time()
parser.add_argument(args1, args2, help=desc, **options)
target_file.write(line.translate(trantab))
output = []
dic = {randint(0, 100): x for x in range(10)}
selected = [names[bisect.bisect(cumprobs, random.random())] for i in range(N)]
logger = logging.getLogger(__name__)
i = np.append(np.where(y), n - 1)
x, y, z = arr.shape
lat, lon = radians(lat), radians(lon)
print(span.text)
show_messages()
c[i].append([])
sess.run(init)
buf = buffer.buf
print(tag.__class__)
roll_left = np.roll(img, -i, axis=1)
t = numpy.linspace(0.0, tmax, nsamples, endpoint=False)
subset[subset.isin(myList)].stack().duplicated()
True
G2 = nx.Graph()
max(community.membership)
name, val = line.split()
header = f.read(4)
args_dict = vars(self.parser.parse_args())
child.setText(0, str(key))
pp(list(sections()))
print(response.registers)
sol = solve((x + I * y) ** 2 - z, (x, y))
groupdict[key].append(dict([(k, v)]))
dt = datetime.datetime(year=2012, month=2, day=9)
self.img_label.configure(image=imgtk)
print(table.name)
dur = datetime.timedelta(hours=h, minutes=m, seconds=s)
df = df.T.stack()
ylo = ylo if ylo >= 0 else 0
[(51 * ((int(c) + 25) // 51)) for c in colour]
console.setFormatter(formatter)
curr_num += 1
assert me.age == me[2]
S = np.sign(dY)
print(i)
layout.addWidget(self.custom_widget)
i = a.intersection(b)
myseries_one.loc[0]
inputs = []
r2 = requests.post(post_url, cookies=r.cookies, data=payload)
lines = []
page.mergePage(new.getPage(i))
self._type = classtype
d[k] = ddict2dict(v)
MainWindow.setCentralWidget(MainFrame)
WHAT_BEATS_WHAT = {ROCK: SCISSORS, PAPER: ROCK, SCISSORS: PAPER}
rows = [line.split()[1:] for line in fp if line.strip()]
a.e()
tuple()
comp.compile()
a = A()
p = Person.objects.get(pk=x)
a[:, (0)]
solutions.append(copy.deepcopy(board))
current_string_split.append(s[j])
radar.ax.legend()
main.show()
self.copy()
a = np.sum(np.abs(xs), axis=1)
aframe.iloc[locs]
active = models.BooleanField()
draw = PIL.ImageDraw.Draw(image)
plot(time, y)
f.format(fmt, **d)
print(x)
leg = ax.get_legend()
host, port = self.client_address[:2]
self.x += 1
r.write_results()
res[k].append(v)
original_convert(str)
self.buttonCalc.clicked.connect(self.handleCalculate)
book.authors.add(george_author.id)
[tb.format_exc()]
print(diffl, lev, sor, jac)
img = cv2.imdecode(arr, -1)
[output]
data = np.random.random(shape)
print(a)
a = list(range(10))
m[i - 1, j - 1] = 1
df
f(numpy.array([[[1, 2]]]))
ip_range = netaddr.iter_iprange(ip_start, ip_end)
funs[eggs]()
os.open(name, flag | os.O_TEMPORARY, mode)
exec(my_code, mymodule.__dict__)
print(config.DEBUG)
deltas = [(a - b) for a, b in zip(zones[1:], zones[:-1])]
cursor.add_option(8)
self.spawn()
print(intify(maybeLst))
session_start()
ret, gray = cv2.threshold(gray, 250, 255, 0)
x += y,
app = Flask(__name__)
my_array.append(str(i))
file = forms.FileField()
scipy.version.full_version
[[0] * len(coef)]
self.id = id
locals()[k] = getattr(module, k)
style = xlwt.easyxf(style_string)
PyArray_Descr * descr
imgBothH.shape
-pypy
p.findall(s)
[11.4, 4.0],
res = numpy.empty_like(arr)
module = sys.modules.get(name)
session.delete(a)
x * x
readline.write_history_file(historyPath)
notebook = gtk.Notebook()
scores.update({key: int(score)})
self._value = value
p.waitFor()
s = json.dumps(data, indent=4)
next(g)
list(unique_everseen(a, key=chained(sorted, tuple)))
wb = Workbook()
fig, ax = plt.subplots()
columnList = list(data[0:])
tuple(pixbuf.pixel_array[0, 0])
browser = webdriver.Firefox(firefox_binary=binary)
luns = [int(lun) for lun in luns]
sys.stdout.write(out_str)
arr = arr.T
S.Sixth.ABs.Eighth
tagger = nltk.TrigramTagger(train_sents, backoff=default_tagger)
user = models.OneToOne(User)
list(map(list, out))
logging_handler_err.setLevel(logging.WARNING)
parent_mock._kids[1][2] is child_mock2
print(generate_chain(409, 5))
x + y
G.add_edges_from(edges)
result[k] = result.get(k, []) + [v]
list(_)
bundle
b = [6, 1, 0]
self.d[self.key].value()
foos = [Foo() for i in range(10)]
df_out
[int(s.endswith(t)) for s in A]
SPEED = 4
gevent.joinall(tasks, timeout=12.0)
msg.attach(basemsg)
msg.attach(signmsg)
dictionary = json.load(response)
count = 0
self.threads = []
nfactors = len(factors)
df
main()
r = requests.post(url, data=data, allow_redirects=True)
b[5, 6, 7, 8]
A = np.random.rand(M, N, R)
self.tag_test(template, context, output)
fig = plt.figure()
ax = f.add_subplot(111)
d[b]
a, b = 0, 1
self.left.reverse()
etree.XML(xml)
n = 2
probability = np.sum(kd_vals * step)
b = np.array([[4, np.inf], [np.nan, -np.inf]])
bin_n = bin(n)[2:]
call_logger = lambda *a, **kw: lambda f: f
some_tag = etree.fromstring(XML)
pprint.pprint(root, width=1)
x_fine = np.linspace(-1, 1, 2001)
mymin = np.min(a)
x_sorted = x[order]
g.user = user
graphs_sizer.Add(chart_toolbar, 1, flag=wx.ALIGN_CENTER, border=5)
np.random.seed(0)
print(x)
fig = bokeh.plotting.figure()
kmeans = KMeans(n_clusters=n_cluster).fit(X)
self.x = x
roll_up = np.roll(img, -i, axis=0)
start = random.randint(0, len(partition) - k)
response
699
L = list(itertools.repeat(10, 20))
dest.update(extra)
(comp.string.encode(enc) % tuple(params)).decode(enc)
assert time.clock() == 1
self.__dict__[name] = value
print(X_train == X_train_init)
plt.xlim([min(xvals) - 0.5, max(xvals) + 0.5])
set(zip(*[string[i:] for i in range(n)]))
desired_shape = np.array((5, 8))
cLoss = sum([(1 - x * one_zero_sum[dist_[y]]) for y, x in enumerate(TLabels)])
person_dict[person.last_name].append(person)
dy = [size2, size2, -size2, -size2, size2]
print(a.shape)
crawler.configure()
to_del.append(y)
p.start()
temp = np.partition(-test, 4)
image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
capture = cv.CaptureFromCAM(i)
ds2 = set([tuple(line) for line in df2.values.tolist()])
frame = inspect.currentframe()
self.value = value
result_dict = {}
main()
df_formatted = pd.concat([df_fmt, df])
arg2value = {}
sent = BooleanField(default=False)
print(i)
enable = W0601, W0612
stats.kendalltau(B[col1], B[col2])[0]
print(m.headers)
id = Column(Integer, primary_key=True)
True
print(max(multiples, key=lambda a_b: a_b[0] * a_b[1]))
d.seconds
sig1 = numpy.interp(t, t1, sig1)
a = np.arange(1, 11)
print(i, word)
result = []
plt.show()
Py_DECREF(result)
ydata.append(np.exp(-x ** 2) + 10 * np.exp(-(x - 7) ** 2))
ax.set_xticks(arange(len(genres)))
plt.plot(x, y, x, -0.5 + h1, x, -0.5 + h2)
print(result)
fig = plt.figure()
input = [input]
session = create_session(bind=engine)
DG.add_edge(stnode, ennode, name=edge)
b = datetime.datetime(2011, 8, 29)
dt_tuple = xlrd.xldate_as_tuple(cell_value, workbook.datemode)
sock.settimeout(prev_timeout)
[-2, -1, 0, -1, -2],
column_series = pd.Series(list(range(columns)))
data.repeat(5)
pformat(vars(self), indent=4, width=1)
match_proj = match_ds.GetProjection()
event.widget.master.focus_set()
env = jinja2.Environment()
rescaled
subprocess.Popen([program]).wait()
tempcreator.__exit__()
self.le = QLineEdit()
print((x, y))
bucket = conn.get_bucket(your_bucket)
DEBUG = 1
log4jLogger = sc._jvm.org.apache.log4j
new_dict[length][mykey] = name_num[mykey]
self.dictionary[key][1] = value
x = T.dmatrix()
freq4.timeit(10)
logger.setLevel(logging.DEBUG)
torfile.add_url_seed(url_seed)
i1 = [0, 2, 4, 6]
ignore[np.ma.maximum(y11, y12) < np.ma.minimum(y21, y22)] = True
HttpResponseRedirect(url)
a[~mask] = 999
rle([True, True, True, False, True, False, False])
self.aws.__aexit__()
True
[i for i in range(amount)]
tree = etree.parse(metadata, parser)
blob_info = upload_files[0]
print(str(a))
IFAIsFastSer = 0
model = Bilag
tester.dothis()
d = dict(t)
time.sleep(0.001)
b = time.time()
list.append(self, item)
fig = plt.figure()
output = tf.transpose(tf.pack(outputs), perm=[1, 0, 2])
attrs = [(x.attr if hasattr(x) else {}) for x in y]
con = pool.get_connection()
d4 = eastern.localize(datetime(2016, 11, 5, 5, 0, 0))
ff(x, y)
paths = [os.path.abspath(path) for path in paths]
game_score / max_score * 0.7 + game_score / total_hits * 0.2 + game_score_per_life / hits_per_life * 0.1
numpy.nextafter(1, 0) - (1 - sys.float_info.epsilon)
o = TestObj2()
self.cur2.executemany(query, self.rows)
p_df = pd.DataFrame(data)
plot(times, freq)
lib.test(darray.fromnp(a1), darray.fromnp(a2))
fig, ax = plt.subplots()
print(e.extra_info)
error_list = total_error_list(python_filename)
login_form.full_clean()
sentence.append(newword)
upload_fd.write(read_slice)
pagenos = set()
klass = getattr(mod, name)
os.seteuid(471)
self.dictionary[key] = [index, value]
max_list.append(s)
b.initialize_options()
models.signals.pre_init.connect(self.pre_init, sender=cls)
acc.extend(items)
lines
self.running = False
self.assertTrue(ip1.ip in result_ips)
grp.nlargest(2).div(grp.shift(-1), level=1).groupby(level=0).first()
print(current_line)
True
value, params = cgi.parse_header(header)
lst.remove(v)
print(linetext.text())
context = ssl.SSLContext(ssl.PROTOCOL_TLSv1)
df
db.session.delete(self)
doc.build(story)
df
Base.metadata.drop_all()
system = models.ForeignKey(System)
cPickle.dumps(d)
arr.count(0)
basmod = BaseModule(argv[0], argv[1])
allhist, allbin = np.histogram(dat, bins=ebins)
text = Text(root)
a = A(4)
U, S, V = np.linalg.svd(sigma)
g = tf.Graph()
p = Process(target=f, args=(child_conn,))
m = [csr_matrix(x) for x in m]
intersection = np.all((params >= 0) & (params <= 1), axis=(-1, -2))
cursor.execute(query_str)
params = dict()
can_delete = False
config = bucket.get_lifecycle_config()
u = urlparse(url)
print(line)
diag_T = T.diagonal().copy()
df.irow(loc - 1)
print(i)
order_by(t1.c.time)
sys.getrefcount(b[-2])
x_n = np.sum(x_n, axis=1)
ranges.append(new_range)
(dates - dateshift).fillna(0).dt.days.cumsum().describe()
b = np.repeat(888, a.shape)
dst = cv2.bitwise_and(image_src, mask)
list(reversed(counts.most_common()[-to_find:]))
keys = d.keys() | d1.keys()
x, y = np.mgrid[0:a.shape[0], 0:a.shape[1]]
key in self.g
form = self.get_form(form_class)
print(my_string[my_interval])
x | x << 1
app = Flask(__name__)
create_archive(paths, arc_paths, archive)
string.digits
head, tail = os.path.split(os.path.split(pathname)[0])
buffer.close()
newest_file
np.isnan(y)
print(str(is_visible_1(link)))
stop = datetime.datetime.now()
seq[int(self.random() * len(seq))]
d = BidirectionalDict()
centroid = sum(x) / len(points), sum(y) / len(points)
print(l)
urllib.request._urlopener = AppURLopener()
my_name = messages.StringField(1, required=True)
remote, address = s.accept()
text_string = text_string.splitlines()
a = zeros((2, 5))
a = A(1)
lcd.setPalette(palette)
self.members.add(member)
[0.0, 1.0, 1.0, 1.0, 1.0, 0.0],
m = [inner_list] * rows
NoStringWrappingPrettyPrinter().pprint(yourobject)
md5 = hashlib.md5()
dist_a_b = dist(a, b)
time.sleep(24 * 60 * 60)
b_in_a = [x for x in a if x in set(b)]
fullstring, name, number = r.groups()
x.loc[(x.date.idxmin()), :]
one_day = timedelta(days=1)
letters = set(string.ascii_letters)
print(first_user.email)
date_ints = set([d.toordinal() for d in dates])
result.append(str[last_end:sp[0]])
int(whole) + fractions.Fraction(frac)
res = conn.getresponse()
print(value)
total_loss = l2_loss_sum([layers[j].weights for j in range(self.n_layers)])
mpz_set(modulus, n)
pprint(data)
print(string.punctuation)
d = {}
mapper(Orders, orders_table)
tree = etree.parse(StringIO(text), parser)
ss = ssl.wrap_socket(s)
a = np.arange(16).reshape(4, 4).astype(float)
plt.plot(t, cos(w * t))
re.sub(pattern, replacer, text)
append((word, word_offset, running_offset - 1))
request = opener.open(url)
np.allclose(out1, out2.toarray())
print(said)
middle = len(strg) // 2
np.vstack((rlin * first, np.power(rlin, second)))
locals().update(somedict)
ax2 = fig.add_subplot(212)
f, a = plt.subplots(1)
parser = etree.XMLParser(remove_blank_text=True)
bar()
print(q.statement.compile(dialect=postgresql.dialect()))
result = self.contained[item]
field_name = funct()
0
row = numpy.array([(0.0001, 0.002)], dtype=type1)
pool = mp.Pool()
p.x = 5
a = np.array(a)
bloop_list = Bloop.as_view()
soup = BeautifulSoup(html)
value = args[int(key)] if key.isdigit() else kwds[key]
n[0]
df_test = df_test.append(rows_list)
partials = []
print(df)
multiset[bin_] += 1
app = wx.PySimpleApp()
d2 = datetime.date(2012, 1, 1)
self.clientSocket.send(data)
setattr(instance, _UNSAVED_FILEFIELD, instance.image)
diff_keys = [k for k in A if A.get(k) != B.get(k)]
list(binomial_choice(list(range(5)), 1))
keynames[i] = k[1:]
tf.import_graph_def(basegraph.as_graph_def())
mx_hosts = DNS.mxlookup(hostname)
ROOT_PATH = os.path.dirname(__file__)
s = al.spline1dbuildakima(x, y)
mindate = datetime.date(datetime.MINYEAR, 1, 1)
x[1:] = x[:-1]
print(df_b)
[d[k] for d in ds for k in d if match(k, pat)]
nondirectories.append(filename)
all(i == first for i in it)
soup = BeautifulSoup(s)
to_remove = [n for n in outdeg if outdeg[n] == 1]
new_list = []
self.listener.close()
i = self.obj_type.__mro__.find(self.obj_type)
Xt = ax.transData.transform(X)
i = 1
results = pool.map(cube, list(range(1, 7)))
self._data_filter
wb = o.Workbooks.Open(wb_path)
mainwin = Tk()
b = copy(a)
self._storage[key].has_prefix(word[prefix_index:])
im = img_padded.load()
exec(code, module.__dict__)
output = PdfFileWriter()
my_set.update({6, 7})
nf.close()
print(list(l))
edges = collections.defaultdict(list)
ax = pylab.gca()
f.close()
tree = etree.XML(content)
cls(value)
app = Flask(__name__)
R1 = 0
nfailed = 0
new1
total = 0
d1.update(d2)
l[0] is l
print(a, b)
B = copy.copy(A)
mail.set_debuglevel(debuglevel)
r < -reduce(Intervals(cbind(start, end)))
word = Column(String)
cython.int
worksheet = workbook.add_worksheet()
x = df.values
setup4 = setup2
dr = csv.DictReader(f)
num1 = int(argv[1])
time[i], signal[i] = q.get()
bisect_iter_to_list(str.isalpha, iter(l))
c()
dupcount = 0
old_init(self, *k, **kw)
self.array_pool[i] = np.frombuffer(buf, dtype=self.dtype).reshape(self.shape)
numbers = [10, 20, 1, -11, 100, -12]
np.log(gev.pdf(data, *fit)).sum()
k, v = build(r, v)
self.toolbar.Realize()
variables = list(arr[0].keys())
a = s.split()
df
clf = ensemble.RandomForestClassifier().fit(X[:100], y[:100])
value_counts = df[col].value_counts()
app.MainLoop()
starts = np.zeros(len(counts), dtype=int)
glLoadIdentity()
df
a = A()
print(regx.split(DATA))
reviews = session.query(Review).filter(Review.id.in_(review_ids)).all()
self.data[index]
result = getattr(image, method)
fig = plt.figure()
fig, ax = plt.subplots()
print(next(d(myset)))
self.transport = transport
data = urlopen(push_url).read()
FormRequest(url, formdata=payload, callback=self.parse_stores)
sess = tf.Session()
f = tar.extractfile(member)
tuple(s[i:i + 4] for i in range(0, len(s), 4))
ds = SupervisedDataSet(2, 1)
dm = pdist(X, lambda u, v: np.sqrt(((u - v) ** 2).sum()))
sx, sy = np.sqrt(vx), np.sqrt(vy)
logging.basicConfig(level=logging.DEBUG, filename=logfile)
timestamp = db.DateTimeProperty(auto_now_add=True)
print(Point(1, 2))
actual_number = random.choice(list(range(k)))
cbar2 = fig.colorbar(im2, cax=cax2)
lines.append(str(self.context_mark))
y = [(x + i) for i in range(1)]
a[i - 1]
t = threading.Thread(target=self.server.shutdown)
mimetypes.guess_type(path, strict=False)
mydict[e] += 1
print(is_admin)
end_date = dateutil.parser.parse(end)
df = pd.concat([df, df2])
overlap(0, 50, 40, 90)
print(res)
pytz.__version__
thumbnail = serializers.ImageField()
u, urlparse.parse_qs(q)
data = np.random.random(n)
m = Mock()
prop.__set__(entity, ref_entities[ref_key])
widget.setGeometry(widget.geometry())
False
result = [(x + [y]) for x in result for y in pool]
instance = cls(*args, **kwargs)
groups = df.groupby(pandas.cut(df.a, bins))
respawn
result = [x for k in sorted(d) for x in k * d[k]]
epoch = datetime.datetime.utcfromtimestamp(0)
{1, 0, 0}
permstr += permtype.lower()
G.add_node(n1, obj=n1)
A = array(a).reshape(len(a) / 2, 2)
line = f.readline()
st = os.stat(filename)
x = np.random.rand(10, 6, 7)
m.add(k, dict2.get(k))
signal.alarm(2)
mapper.SetInputData(self.vtkPolyData)
session.add(ed_user)
session.save()
b = numpy.array(list(range(5)))
new_dic_defaultdict = defaultdict(dict)
W = tf.Variable(tf.random_uniform([d, 1], -1.0, 1.0))
g = map(set, g)
c = C(2)
print(a)
self.val
df
1
b_inv = np.linalg.inv(b)
sum_of_two = sum(num_list)
tpp, tdv = [], []
parser.config_files.append(values)
p.join()
tags = exifread.process_file(f)
retval = self.my_class.__call__(*args, **kwargs)
patch.set_facecolor(color)
print((a, b, c))
df = pd.concat([X] * 10 ** 5, ignore_index=True)
sec = glrhs[2]
Py_XDECREF(pName)
two - 0.444106
df
print(names[i])
self.queue.put(f)
new_tokens.append(translated)
prefixes.sort(key=lambda s: len(s))
h = matrix([[-0.02], [0.05]])
pathA = cheapest_path(path_list, A, [])
print(result)
coords = (0, 0), (0, 2), (2, 0), (2, 2)
int_part = int(abs(x))
ax = f.add_subplot(1, 1, 1)
parse_tree = etree.parse(StringIO(xml_str))
g.series(x, y, 0, 0)
self.selenium = webdriver.Chrome(desired_capabilities=CHROME)
x = create1m()
x = create1g()
self._c = c
nr, nc = imgdata.shape[:2]
old_window[0] = gdk_window.get_screen().get_active_window()
test1 = array([[True, False, True, False, True]], dtype=bool)
df1.columns = df1.columns.droplevel(1)
func = lambda x: x + 1
fd.seek(0)
self.loop.call_soon(self.event.set)
print(optimization.curve_fit(func, xdata, ydata, x0, sigma))
utc_dt = datetime(1970, 1, 1) + timedelta(seconds=timestamp)
output.append(str1)
app = QtGui.QApplication([])
p2 = Popen(cmd, stdin=p1.stdout, stdout=PIPE, stderr=tempFile)
areaofpolygon(polygon, i + 1)
subplot2.plot(y, x)
result
sock.setproxy(*self.proxy_info.astuple())
print(match)
self.it = iter(range(10))
ie = webbrowser.get(webbrowser.iexplore)
G = nx.DiGraph()
substrings = [a[i:i + n] for i in range(len(a) - n + 1)]
grouped = defaultdict(list)
True
workers.append(child)
plot = fig.add_subplot(111)
data = cursor.fetchall()
c = conn.cursor()
pool.close()
print(chambersinreactor)
print(cardsdiscarded)
sqlContext.createDataFrame(temp_rdd, schema).printSchema
pic.seek(0)
bmarks = json.load(f)
noisycount += 1
quietcount += 1
client.loop()
ops = random.choice(list(op.keys()))
q = db.Query(PC_Applications, keys_only=True)
_data[k] = hex(v)
atexit.register(functools.partial(kill_children, c_pid))
plt.show()
monotone_increasing(lst) or monotone_decreasing(lst)
fig, ax = plt.subplots()
nx.draw(G, pos=coords)
a = a[:-1]
Bar()
pool = multiprocessing.Pool(n_workers)
a = A()
proc = subprocess.Popen(lstrun, close_fds=True)
start.insert(0, ind)
print([i for j in zip(start, repeat(0)) for i in j][:-1])
ch = sys.stdin.read(1)
time.sleep(random.randrange(4))
rtn.append(a)
countup(N, n + 1)
self.response.out.write(utils.GqlEncoder().encode(results))
y_train = self.y[train_mask]
now2 = la.localize(datetime.now())
self.key
l = mpl.pyplot.gca().legend_
self._add(attr.get(), obj)
tty.setraw(sys.stdin.fileno())
init_op = tf.initialize_all_variables()
plt.colorbar(c)
result.append((curr[2], self[curr[2]]))
d = defaultdict(dict)
file_obj.seek(0)
rand_x_digit_num(5, False)
df
provided_ips = request.access_route
bytes = str.encode(my_str)
time = time_xpath(row)[0].strip()
a = []
request = urllib.request.Request(url)
startsecs = 5
installer.install(options)
d
tree = lambda : defaultdict(tree)
f1 = f.subs(b, 10)
panel = wx.Panel(self, wx.ID_ANY)
x = 2
d[k] = [dictionary[k][column_name] for column_name in column_order]
b = copy(a)
Pdb
self.buf.read(*args, **kwargs)
myTaskId = abortable_async_result.task_id
node = node[char.upper()]
num_cols = len(f.readline().split())
print(df)
mixer.init()
datetime.datetime.utcnow()
arr.put(ind, [a, b, c])
data = request.data
numbers.append(i)
self.x = 2
print(a[0, 0])
print(L)
hostname = match.group(1)
y = np.exp(-x / 2.0) * np.sin(2 * np.pi * x)
combs = set()
serial_data = ser.readline()
log.flush()
ts1, ts2 = p(l)
z = np.array((old_val, new_val)).T
df.index[9:], df.columns
idx = np.argsort(dst)[:f]
list(d1.keys())[v.index(max(v))]
cos += (-1) ** n * x ** (2 * n) / math.factorial(2 * n)
cov.load()
assert 0 == 1
cookies = urllib.request.HTTPCookieProcessor()
f.close()
X = np.repeat(X, 100, axis=0)
der = ssl.PEM_cert_to_DER_cert(pem)
parser.parse(a_datetime).astimezone(tz)
value
session.expunge(stud)
ws = wb.worksheets[0]
tag_labels = tag_list(repo)
f = ET.fromstring(data)
F = np.array(list(itertools.product([0, 1], repeat=n))).T
print(l)
cvMerge(realInput, imaginaryInput, NULL, NULL, complexInput)
r, c = a.shape
serializer.is_valid(raise_exception=True)
print(i, f)
np.linalg.norm(sortedA[1:] - sortedA[:-1], axis=1)
Particle[j].AddNeighbor(Particle[i])
chars = []
train_indices = list(range(40)) + list(range(50, 90))
death_year = death_data[2]
adj = gtk.Adjustment(1, 1, 99, 1, 1, 1)
z0 = z_indices.astype(np.integer)
xdata = np.vstack([x, y, z])
do_something(line)
print(docopt.docopt(__doc__))
putstr(prompt)
list_of_bools = [True, True, True, True]
summary[entry[0]] += entry[1:]
yaml.add_representer(literal_unicode, represent_literal_unicode)
diff = np.setdiff1d(b, a)
pylab.show()
schema = etree.XMLSchema(schema_doc)
result = np.ma.array(yindex, mask=mask)
index.create(engine)
(1 - -1) * np.random.random() + -1
print(i)
urls.append(url)
charlie = NS.charlie
chocolate = NS.chocolate
hates = NS.hates
dislikes = NS.dislikes
[n for n in list_to_test if isinstance(n, type_of)]
self.on_message = on_message
self.d[k]
print(is_png(data))
os._exit(0)
width, height = image.size
data = plt.cm.jet(data[x_data, y_data])
cv2.polylines(h, [pts], False, col)
np.dot(af, af).astype(int)
my_list[0][0] = 5
y = list(x)
self.write(line)
c = Counter(s)
axis.set_minor_locator(NullLocator())
df1 = df1.apply(closest, axis=1)
candidates[index] = bases[index] * nums[candidates_indexes[index]]
signal.alarm(5)
ax = plt.gca()
iregex
cache[method_name]
a = np.asanyarray(a)
vbox.pack_start(self.button, False, False, 0)
ind = (posx > 0) & (posx <= bins[0]) & (posy > 0) & (posy <= bins[1])
pl.hist(data, bins=10 ** np.linspace(np.log10(MIN), np.log10(MAX), 50))
C = A * B
x.foo()
np.exp(x)
pseudocolor(80, 0, 100)
unserialized_data = pickle.load(handle)
self.assertRaises(exc, f, *args, **kwargs)
self.index -= 1
decimal.getcontext().prec = 6
self.click_positions.append(event.pos())
a()
remove(argv[0])
b = list(a)
a.x
datos.append(float(item))
l.append(g.name)
ax.invert_yaxis()
something()
contents = self.buf.read(size)
max(S)
a = np.zeros(42)
srcname = os.path.join(src, name)
x / y
dt = datetime.utcnow()
z = exp(-x)
i += 1
a = []
cur = conn.cursor()
rows = json.loads(x)
print(old_s)
reduce(lambda d, k: d[k], keys[:-1], result)[keys[-1]] = value
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
fig = plt.figure(frameon=False)
dragged_iters.append(model.get_iter_from_string(iter))
data = np.random.randn(N)
print(df)
config.read_string(s_config)
sqr = col.copy()
outThread.start()
len(dir(aStrOBJECT))
self.x = x
view
screen.blit(treeImage, pygame.rect.Rect(0, 0, 128, 128))
Z = mlab.bivariate_normal(X, Y, sigma, sigma, 0.0, 0.0)
end_date - start_date - datetime.timedelta(days=number_of_weekends * 2)
print([v for v in list(anagrams.values())])
y = np.arange(-5, 5, 0.25)
print(repr(testObject))
a = np.array(list(range(1, 10)))
struct.unpack(fmt, data)
groups = df.groupby(cols)
fig.tight_layout()
today = date.today()
DONT_RESOLVE_DLL_REFERENCES = 1
self.clientSocket.close()
output += markdown2.markdown(mkin.read())
res = {}
derangements = (tuple(derange(list(range(n)))) for _ in range(10000))
m, n = len(seq), len(sub)
True
self.page.mainFrame().load(self.currentUrl())
print(longest_sum([1, 2, 7, 8, 11, 12, 14, 15], 0, 0, 10))
db.delete_async(self)
files = []
mask = np.in1d(np.arange(np.max(out_id) + 1), out_id)
area
painter.drawPixmap(event.rect(), self.pixmap)
n
dx_cell = max(abs(lattice_vectors[0][0]), abs(lattice_vectors[1][0]))
output
[TYPECHECK]
User()
labels_one_hot = np.zeros((num_labels, num_classes))
www.myurlnumber1.com
dic[4]
x[a][b].update(C)
book.user == bundle.request.user
sqrt(y - (p[0] + x * p[1]) ^ 2 + (x - (pinv[0] + y * pinv[1])) ^ 2)
print(recv5.decode())
lock.release()
print(decimal.__version__)
self.width = self.winfo_reqwidth()
tree.takeTopLevelItem(tree.indexOfTopLevelItem(i))
MyTestResult(self.stream, self.descriptions, self.verbosity)
func(request, *args, **kwargs)
y, x = np.mgrid[:10, :10]
c1, c2
im.seek(len(seq))
pixmap = QPixmap.fromImage(image)
fmin = (N + f2 - 1) / f2
df2 = pd.DataFrame(index=idx, columns=idx)
quotes = formset.save(commit=False)
columnNames.append(str(SchemaTable.Rows[i][0]))
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
set(itertools.product(s1, s1, s1))
print((25.4 / 10.0 * (1.0 / 2.54)).__repr__())
True
p.terminate()
sin_data = np.sin(data)
4, 5, 6
data = np.loadtxt(file, skiprows=8)
token = gdata.gauth.token_from_blob(saved_blob_string)
soup = Soup(handler)
qs.filter(is_active=1)
json_object = json.loads(myjson)
self.a = a
output = PdfFileWriter()
np.array(B)
Model.objects.filter(m2m_field=1).filter(m2m_field=2)
print(df)
cj.load()
sheet = book.active
print(a._x, a._y)
crypts = crypts[1:]
opener = urllib.request.build_opener(authhandler, urllib.request.HTTPHandler(debuglevel=1))
initials = models.CharField(max_length=20, blank=False, null=False)
tmp()
allowed_domains = []
ax.autoscale_view()
d[value].append(key)
not any(d.values())
a = [1]
obj.set_x_self()
queryset = Game.objects.all()
p.feed(xhtml)
sum += random.randint(0, 100)
x.append([x] * 5, ignore_index=True)
my_thread = QThread()
comparison = tf.equal(a, tf.constant(1))
A1 = [[A[i][j] for j in new_order] for i in new_order]
a = list(range(10))[::-1]
A = A - A.mean(1)
D = list(Concate.values())
l = fnmatch.filter(string_input.split(), pattern)
b.ndim
self.check_word_type(self, self.filename)
tlist += ttlist
template_globals.update(render=render_partial)
hash(self.s)
x2 = np.random.normal(size=N)
axes[0, 0].set_ylim(0)
dis.dis(myfile)
print(i)
a // 1
print(line)
ax = plt.gca()
os.chdir(destination[0:len(destination) - 1] + path)
merge(a, b, lambda in_a, in_b: in_a and not in_b)
axs[i].get_xaxis().set_ticks([])
processHandle = OpenProcess(PROCESS_ALL_ACCESS, False, pid)
dt = utc_dt.astimezone()
s.boot
print(result.fetchall())
16777215
type.__new__(mcs, classname, bases, dictionary)
self.f.flush()
client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
-Bob
() < []
x = {row.SITE_NAME: row.LOOKUP_TABLE for row in cursor}
a = Fraction(1, 2)
zlib.decompress(compressed)
print(f_x([9, 10]))
0
screen.clear()
[a.insert(i, a.pop()) for i in range(1, len(a) + 1, 2)]
hashlib.sha512(s).hexdigest()
lines = f.readlines()
worksheet.update_cell(1, 2, form_value_1)
print(uuid.uuid4())
subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)
d1 = datetime.date(2008, 8, 15)
root, extension = os.path.splitext(filename)
first_ten = df[:10]
-1, -2
print(f.func_count)
my_node.think()
raise TypeError(node)
a.fn()
print(df)
Orange.data.Table(tdomain, tinsts)
True
c = 1
conn = httplib.HTTPConnection(proxyHost, proxyPort)
self.finish()
{{fqdn}}
self.child_pipe.send(result)
x = len(self.left) // 2
a_minus_b = [item for item in a if item not in b]
man.start()
len(self.text)
x2fr = min(x2, inarr.shape[0])
check_matr(a, 0)
self.addButton = Gtk.ToolButton()
df
pickle.dump(db, f)
file.seek(seek)
rect = rect.move((x, y))
inside_points.append(point)
print(line)
self.x -= 1
d = datetime.datetime.fromtimestamp(posix_now)
cir.draw()
print(field)
start = datetime.datetime(2009, 2, 10, 14, 0)
self.type = type
z = np.random.random(10)
NAMES.append(name)
thread.stop()
words = line.split()
opt2 = tf.train.GradientDescentOptimizer(0.0001)
x = np.arange(12).reshape(2, 6)
[e] = S
thread = threading.Thread(target=read_from_port, args=(serial_port,))
full_path = os.path.join(root, fname)
plt.plot(xi, yi)
result[key] = [item for item in group]
cur.execute(sql)
func(*args)
y = np.ma.masked_where(x == 0, x)
egg2(*argList)
foo.foo()
inp.setchannels(1)
a = np.arange(4)
resonator.default
print(sp.coo_matrix(m.where(m.notnull(), 0)))
471
n = datetime.now()
any(filter(someDict.__contains__, someList))
v = -np.cos(np.pi * x) * np.sin(np.pi * y) * np.cos(np.pi * z)
plugin.do_work()
sys.settrace(globaltrace)
p = multiprocessing.Pool(np)
_change = models.IntegerField(default=0)
curPG.execute(sqlCmd)
animal_proxy.make_noise()
d.addCallbacks(callback, errback)
regex.sub(lambda match: conv[match.group()], text)
stdscr.clear()
loop.run_until_complete(task)
c = Counter(list1)
pickle.dump(data, outfile, pickle.HIGHEST_PROTOCOL)
multiprocessing.cpu_count()
pkg_resources.require(requirement)
s.listen(1)
context.enter_context(session)
r = [x.sum() for x in y2d]
print((x, y))
numpy.__version__
ofh.seek(0)
util.run_wsgi_app(application)
logger = logging.getLogger()
print((test.a, test.b))
end = time.clock()
globals.update(frame.f_globals)
self.stop()
hm.HookMouse()
name = forms.CharField(max_length=100)
print(next(c))
form.fileName.file.save(PATH + myFile)
x = [0.2, 0.2, 0.8]
[1, 1, 1, 1, 1],
clf = RandomForestClassifier(n_jobs=-1, random_state=42, oob_score=False)
f(*args, **kwargs)
writer = csv.writer(f, dialect=SomeDialect)
environment[k].update(v)
zip_longest(*(islice(l, i) for i in range(n)))
id(var1)
inner_sum += dk * f_big(A, k, 1e-05, 1e-05)
mylist1 = [i.strip() for i in mylist]
dest = bytearray(10)
X = vectorizer.fit_transform(lectures)
txt_frm.grid_propagate(False)
install.run(self)
self.request.close()
print(thefile.cleaned_input())
print(name_or_id)
io.clear()
print(sess.run(correct_prediction, feed_dict={x: test_images, y_: test_labels}))
matches = matches.reshape((rows, cols, cols))
d.append(val)
my_array = rand(int(50000000.0), 1)
dis.dis(foo)
soup = BeautifulSoup(s)
nli.get_item()
weights = np.array([16, 4, 2])
index = np.searchsorted(colkeys, keys, sorter=sorter)
block(chr(2944))
f.seek(-offset, os.SEEK_END)
p = ss.expon.fit(data, floc=0)
curs.close()
print(s)
sns.set(font_scale=0.8)
out[product_name] = []
country = models.CharField(max_length=150)
print(inst.id)
plt.figure(figsize=(10, 5))
fig = plt.figure()
fp.close()
alembic.config.main(argv=alembicArgs)
inspect.getsource(myfile)
target_h, target_s, target_v = rgb_to_hsv(target_r, target_g, target_b)
d = defaultdict(list)
df1.div(df2squeeze())
app.run(use_reloader=False)
columns = [column.key for column in mapper.columns]
painter.restore()
new_rows = []
result.insert(0, l)
len(b)
df = sc.parallelize(row(chr(x)) for x in range(97, 112)).toDF()
a = test.Array()
print(search_result.group())
sock = socket.socket()
reverse(x)
scikits.audiolab.play(data, fs=44100)
x[(0), :, :][:, ([0, 2])]
data
Y = R * np.sin(THETA) - 2
objs.append(parse_obj())
c = concatenate((a, b))
product = models.CharField(max_length=150)
print(newer_grammar.productions()[-1])
builder = gtk.Builder()
object.__getattribute__(self, x)
data.shape = -1
0
curdict[item] = {}
print(proc.pid)
lockup
crackdown
result.append(option)
plt.show()
COMPRESS_ENABLED = True
permutations_helper(elements, [0] * n, n - 1)
chars = list(chain.from_iterable([list(set(word)) for word in l]))
_f = dill.dumps(f)
print(args.n)
expr
col_names = first_reps.columns.get_level_values(2)
print(list(generate_digits_permutation()))
print(mse(model_2_v1.predict(xg_test), y_test))
ip = get_ip(request)
[2, 2, 2]
print(list_to_html(toc))
temp.append(j)
min_kmeans.fit(vectors)
[]
cookie2 = value2
y - fitfunc(p, x)
a[2][1] = a[2][1] + 5
self.name = name
False
print(a.x, a.y)
a.add_rule(phyrule)
dates_dict = defaultdict(list)
print(resp.read())
pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)
response
g.writelines(ss + line for line in f)
wrapper.__doc__ = func.__doc__
print(match)
a = matrix(n)
print(True)
set.seed(1)
parser = argparse.ArgumentParser()
arr = df1.values[:, :-2]
all_subclasses.extend(get_all_subclasses(subclass))
lang.terminology
pprint(dict(year2students))
x2 = np.random.normal(-15, 7, 100000)
scr.exitonclick()
rendered1 = template.render(var1=5)
d = {}
a.insert(0, 1)
pid = sys.argv[1]
list_.append(lines[i + j][2])
os.close(fd)
diffs = array1 - array2
p.cpu_times()
kernel = np.zeros((2 * radius + 1, 2 * radius + 1))
loop.run_until_complete(run(loop=loop))
lista = [df.columns[:,].values.astype(str).tolist()] + df.values.tolist()
restored = pickle.loads(pickled)
x = sin(pi * t)
Py_DECREF(keywords)
out += ser.read(1)
reducedQs = reducedQs.filter(participants__id=p.id)
print(b.shape)
my_date.setTime(time_t * 1000)
self.errorcall(E, *args, **kwargs)
a = [4, 5, 6]
cv2.circle(img, center, radius, (0, 255, 0), 2)
self.__dict__ = dict(module.__dict__)
foo.something
print(s, sense2freq[s])
issubclass(p2, p1)
dt.replace(tzinfo=self)
mydriver.get(baseurl)
A.setdiag(b)
pyplot.grid()
repr(self.val)
G.add_edges_from(edges)
time_epoch = time.time()
dict.__setitem__(self, key, value)
gevent.sleep(0)
mycursor = db.cursor()
results = api.lookup_users(user_ids=page)
plt.title(str(i))
X.foo = 67
num_array.append(int(n))
self.figure = Figure()
print(type(first_arg_unicode))
l_x.append(len(s) - 1)
infile.write(text)
result = (x for x in l if f(x))
values.append((frame, row, col, data[row, col, frame]))
[1, 0, 0],
a = np.random.randint(0, 5, size=(6, 4))
mask
myList = [gen_rand(item) for item in myList]
True
f(l)
weights = np.array(initial_weights)
arr = []
main(sys.argv)
out = np.empty((m, n, 2), dtype=int)
toks_with_adjectives.extend(adjs)
do_something_with(self._implementation())
watcher.start()
reader = csv.reader(f)
np.add.at(grids, (idx[:, (0)], idx[:, (1)]), 1)
print(len(stack))
x = mu + sigma * np.random.randn(N)
drawdown.plot(legend=True)
leftfile, rightfile, leftvarname, outvarname = args
tag = db.ReferenceProperty(Tag)
first, rest = ks[0], ks[1:]
self.c += 1
dist_python_DATA = foo.py
time = np.random.random(10)
a = [0]
data = {}
files.sort(key=lambda x: os.path.getmtime(x))
df
in_file.seek(seek_offset, os.SEEK_END)
type(test.f)
df = df[::-1]
x += 1
R1 = numpy.linalg.cholesky(V1).transpose()
user_lastName = db.Column(db.String(64))
total = 0
c4 = sum(1 for i in y if 0.9 < i <= 1.8) / 10000.0
swig_wrapper.py_copy(img, mem, length)
vol.append(volume[start:end])
wrapper
client.load_system_host_keys()
parent.append(self)
new_grammar._productions.append(singapore_production)
gobject.timeout_add(60 * 1000, my_timer)
x, y if x <= y else y, x
tornado.web.Application.__init__(self, handlers, **settings)
deleteoutlook, msg
text = open(path).read()
window.add(box)
new_values.append(value)
leftfile2rightfile2
user = myuser
print(is_int(x_))
lastname = Column(String(50))
name = person.key().name()
b = int(round(time.time() * 1000))
print(b)
setattr(namespace, self.dest, list)
manager = multiprocessing.Manager()
statinfo.st_size
loop.close()
foo(*args.pos, **vars(args))
self.output = QtGui.QTextEdit()
register = template.Library()
manager.operations.util.build_filter = brcd_build_filter
s = list(range(10))
b = numpy.random.randint(0, 10, 10) * 1.0
list(range(item.start, item.stop))
demo[0][0] = 1
inst.__dict__[self.attr]
1 << 8
o1 = np.lexsort(arr1.T)
x = scipy.arange(size)
loop.stop()
Customer.objects.create(**validated_data)
self.loop.stop()
strings = [str(i) for i in range(10)]
piece_hash = hashlib.sha1(piece).digest()
print(mytuple[2])
print(i)
b.join()
do_two()
t += 1
_recursivePop(tree, nodes[1:])
duplicate_shaders_dict
f = itemgetter(0)
c.pop(0)
self.value = min(self._max, max(value, self._min))
writer = csv.writer(buffer)
l1.append((result1, result2))
a = 4
x, y = 1, 2
print(id(object()))
value
print(bilinterp(22000, 2))
test = models.ForeignKey(Test)
inbuf = DblTriplet(60.1, 20.2, 0.5)
values = self.request.get_all(argument)
strio.write(buffer.data())
df[df.T.convert_objects().dtypes != object]
dcObj.DeleteDC()
res2 = np.sum(a * b, axis=1)
fig, ax = plt.subplots()
c = np.random.randint(cols, size=100)
context.push()
[item.serialize for item in self.many2many]
customer_number = models.IntegerField(default=1)
print(json.dumps(obj, cls=MyEncoder))
print(x)
df.AVG_MINUTES = list(map(list, zip(df.HOUR, df.AVG_MINUTES)))
self.write(str(i))
np.exp(-x ** 2)
sh.setFormatter(formatter)
plt.scatter(xx, yy)
getattr(self, self.map[cb])()
app = Flask(__name__)
d = defaultdict(list)
l.insert(0, x)
a = np.array([[2, 4], [1, 2]])
print(n_neighbor(G, 1))
outputs.append(s)
print(sm2.getName())
args = parse.parse_args()
dst[0] = tmp
myzipfile = zipfile.ZipFile(zipdata)
curl.perform()
assert isclose(a, b, abs_tol=10 ** -n)
indices = numpy.indices(shape)[axis]
unpickler = Unpickler(file)
found = re.findall(patbase % x, ss, re.DOTALL)
self.validate(parser, value)
rs.get()
idx = df.index.str[0]
atexit.register(exit_handler)
out.write(line)
data = np.array(data)
A[np.isnan(A)] = np.interp(x, xp, fp)
d = [c.isdigit() for c in r]
reverse.py
print(repr(decoded))
answer2 = func(remaining_map2)
answer1A = func(remaining_map1)
groups = [df.customer, df.invoice_nr, df.date, df.amount.abs()]
self.functor = functor
queue.add(my_func, False, somearg, somekwarg=someval)
self.editname = wx.TextCtrl(self.panel, size=(140, -1))
self.request.send(data)
median = partial(quantile, p=0.5)
self.__dict__ = dict
1 + max(depth(exp[0]), depth(exp[1:]))
PP.pprint(x, width=len(x))
np.random.seed(101)
Response(status=status.HTTP_205_RESET_CONTENT)
t.join()
print(df)
b.shape
self.current = range_list[0]
f.flush()
my_data[my_data == 0.0] = numpy.nan
l.remove(l)
self.lst.append(x)
input = raw_input
sqs = SearchQuerySet().filter(content=q_clean)
auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
match = p.search(s)
y2fr = min(y2, inarr.shape[1])
train_labels = np.array([labels.index(x) for x in train_labels])
n
count += 1
[(i, 100, 1000), (i, 100, 1001), (i, 100, 1002), (i + 1, 101, 1001)]
self.fnames.append(name)
loaded_mm.close()
Point(0, 1).wkt
Ybase = medfilt(Y, 51)
map(lambda x: 1 if x else 0, testList)
a_frame.pack()
paw_number = np.arange(len(paw_coords))
print(hpattern % tuple(headers))
print(mystring)
B = scipy.delete(B, 2, 0)
self.console.configure(state=tk.DISABLED)
type(a)
print(f.upper().newMethod().lower())
a = a.astype(float)
pix[x, y] = value
k = np.asarray(keys)
s = im.tostring()
imageLarger = cv2.pyrUp(image)
string2 = unique_words(string1)
x = scipy.linspace(0, pi, 100)
self.camera.input_queue.put(self.idle_data_buffers.pop())
setattr(self, special_attr, value)
image = pyexiv2.Image(file_path)
result[0, 0, 0, 0, 1]
list(grps(l, 4, 2))
angle = 0.5 * np.arctan(2 * u11 / (u20 - u02))
self._meta.db_table
data = file.read()
q = Queue.Queue()
ignore[np.ma.minimum(y11, y12) > np.ma.maximum(y21, y22)] = True
dd[v].add(k)
hops
cout
ctx.move_to(0, 0)
assert resp.status == 200
unittest.TextTestRunner().run(suite)
root = Tk()
assert fx1
demo(1)
retcode = proc.poll()
t = np.linspace(0, 2 * np.pi, 20)
dfi = dfi.set_index(my_column)
results = defaultdict(lambda : defaultdict(dict))
new_file.save()
time.sleep(1)
instance = BillboardTracker.objects.get(id=some_id)
find([])
DEBUG_PROPAGATE_EXCEPTIONS = True
rank = tf.rank(x)
f.seek(8, 1)
my_list
raise StopIteration
sleep(0.1)
False
content = sock.read()
d.setdefault(k, [k]).append(v)
formatted(10000000000)
list_of_bools = [True, True, True, False]
print(Bar.get_counter())
JM1, JM2
f(4)
self.parent().viewport().mapFromGlobal(QCursor.pos())
self.done = True
root = Tk()
test(1, 2)
seen = set()
next(reader2)
buckets = sorted(buckets, key=get_index)
input_str_lower = input_str.lower()
set(d.items()) - set(d2.items())
self.xaxis.set_zorder(0.5)
func.value
mock = patcher.start()
browser = mechanize.Browser()
[comment.extract() for comment in comments]
result = numpy.sin(a)
repr(fs2)
C = [6, 8, 7, 9, 6]
lambda *a, **kw: self.command(attr, *a, **kw)
user = client_form.save()
Ti.UI.setMenu(menu)
ax1 = fig.add_subplot(111)
f.free_symbols
print(nltk.sem.relextract.rtuple(rel))
print(i.name, i.pid)
repr(obj)
seq = itertools.takewhile(lambda x: x < MAXNUM, itertools.count(2))
r[np.all(r == 0, axis=1)]
fk = models.ForeignKey(ModelB)
df
user1.friends[0].added_by
qp.waitForFinished()
args = parser.parse_args()
serversocket.close()
traceback.print_stack(sys.stderr)
response
autorestart = true
feedback = form.save(commit=False)
sys.excepthook(*sys.exc_info())
out.append(word)
df
Surface.fill((255, 255, 255))
c = db.cursor()
max(set.intersection(*matches), key=len)
py.test.cmdline.main(args)
fig.clf()
app = Flask(__name__)
chr(65)
data = f.read(8192)
1 - 10 < 0
frame = cv2.flip(frame, 180)
self.list[i]
print(df1)
parsed_message = json.loads(message)
self.pt_plot.set_xdata(x)
logging.captureWarnings(True)
x = np.arange(start=0, stop=5, step=0.1)
leaf[lst[-2]] = lst[-1]
first, last = [], []
user_ids.append(user_id)
neighbors = [e for e in neighbors if e not in visited_nodes]
self.assertResultEqual(expected, s)
img = cStringIO.StringIO(fp.read())
data = json.loads(data)
[MYSERVER]
html = response.read()
increments = [0] * len(a)
X ** 2 + Y ** 2 + Z ** 2 < radius ** 2
item_dict[sample[0]]
s = sum(ind[:i - 1])
form = ItemForm(request.POST)
a = np.random.random((10, 10, 10, 10, 10, 10, 10))
print(my_tz.normalize(my_tz.localize(dt + delta)))
columnsums = numpy.sum(points, 0)
mouse_tooltip.show()
[ascends.pop() for _ in range(idx)]
{1} in x
signal.siginterrupt(signal.SIGHUP, False)
df.sum()
self.pipewritestreams = []
rec.levelno in (logging.DEBUG, logging.INFO)
[1]
register = template.Library()
STOCK_ORIENTATION_REVERSE_PORTRAIT
np.nan != np.nan
self.right = []
db.session.add(user1_from_factory)
joystick = pygame.joystick.Joystick(i)
idx = np.argmax(a[i])
self.received_cookies.get(key)
s[:amount]
root = tkinter.Tk()
[a, b - a, c - b, 40 - c]
text2 = open(file2).read()
y = deepcopy(x)
print(isinstance(b, A))
glClearColor(0, 0, 0, 0)
a[::-1][200] = 6
self.view.teasers = self.prepare_teasers()
self.dg.DataContext = self
CENTROIDS = np.array([0, 10, 50])
b = np.random.random((2, 5))
list_1_sorted = [e[1] for e in s]
f(x, A)
msg, address = s.recvfrom(1024)
data = numpy.zeros((x, y))
s = str(d)
xlbls = ax.get_xmajorticklabels()
data = list(range(1, 11))
happy(vs.unhappy)
y = 500 + r * math.sin(theta)
best = [1.0] + [0.0] * n
m = sorted(l)
plt.waitforbuttonpress(0)
list((found - expected).elements())
sdict
f.close()
mime = mimetypes.guess_type(file)
g.write(q)
letter_set = frozenset(string.ascii_lowercase + string.ascii_uppercase)
(list(range(5))[5:6] + [999])[0]
n11, n10, n01, n00
b(2, 5)
c2 = pickle.loads(pickle.dumps(c))
address = StringField()
names = []
d[word] += 1
receive_newsletter = forms.BooleanField()
HttpResponseNotAllowed(list(table.keys()))
assert True
list2 = [(i, i * 2, i) for i in list1]
bus = dbus.SessionBus()
cgi.escape(site_title), cgi.escape(URL)
label.mainloop()
w.update()
print(md.myfx(arg1))
collections.Counter(l)
mpl.show()
result
dt_aware = pytz.utc.localize(dt_naive)
i = bisect.bisect_right(intvals, x)
_byhour = False
s = s[:20]
a = random.randint(0, 20)
nosetests - -exe
df2 = s2.reset_index()
q.set_message_class(RawMessage)
args = parser.parse_args()
Yhat = np.dot(X, bhat)
flist.append(partial(func, i))
b = []
data[name(row)].append(row)
df
internet_set_option(0, self.INTERNET_OPTION_SETTINGS_CHANGED, 0, 0)
lst = [x, y, numberofcolumns, numberofrows]
self._file.close()
dict([(k, v) for k, v in list(self.items()) if fnmatch(k, match)])
y = sin(x * 2) + sin(x + 1)
print(list(od.values()))
mu, sigma = stats.norm.fit(np.log(x))
mpu.upload_part_from_file(stream, partCount[0])
rop = str(self.rop)
print(s)
print(row)
ax = fig.add_subplot(222)
display(bg_img)
FG().f()
myfile = get_file(path)
series1 = df.iloc[(0), :]
a,
hdf.close()
resmatrix = [[newresnums[i], resindices[i]] for i in range(len(newresnums))]
txet
sigmoid(W * (x1 + x2) + B)
r = NumericProperty(0)
l = l.split()
nodes_nummpy_array[:, (2)]
sys.float_info
wn.wup_similarity(dog, car)
print(columns[0])
a = int(sys.argv[1])
sub_lst = [i for i in lst if isinstance(i, str)]
print(i)
len(list(range(max(x[0], y[0]), min(x[-1], y[-1]) + 1))) > 0
DEFAULT_DATE = datetime.datetime(datetime.MINYEAR, 1, 1)
xslt_doc = ET.parse(io.BytesIO(xslt))
points = np.linspace(x.min(), x.max(), N)
classmethod(bar).__get__(foo)()
A = [np.random.random((5, 5)) for i in range(4)]
old_text = entry.get_text()
root = tk.Tk()
print(repr(a))
print(df)
l = list(range(1, 10))
name = cls.__name__
total += i
lens = np.array(map(len, a))
print(sql)
temp.append(v)
items = ((x,) for x in sorted(ps, reverse=True))
a = numpy.arange(5)
self.updates.add(obj)
json.loads(self.data)
pprint(dict(busbar._asdict()))
self.apply_async(func, args, kwds).get()
dt = datetime.datetime.combine(d, t)
[1, 2]
the_dict[b.pop(0)] = b.pop(0)
g1 = ((i, i + 1) for i in range(len(list1) - 1))
[k]
ser = serial.Serial(0)
stream.map(model.MyClassifier.do_something).pprint()
check_for_use(True)
csv_reader = csv.reader(utf8_data, dialect=dialect, **kwargs)
s.close()
assert testlength == 1 or testlength == 2
ranges.append(group[0])
sigma = np.cov(X, rowvar=True)
pyplot.axis(ex2)
deleteself.__dict__[name]
df.join(cs)
self.__dict__.update(kw)
setattr(cls._meta.get_field(field), prop, val)
axes = all_data[ASK_PRICE].plot(figsize=(16, 12))
escapesequence = matchobj.group(0)
print(buffer(s, i, j - i))
A = np.zeros(p)
i = len(string) - 1
start = time.clock()
error()
m = A.mean(axis=1)
pp(expr)
pandas.concat(ret_list)
install_python_dependencies
app = QApplication([])
self.session_store.save_sessions(self.response)
df
self.clients.remove(client)
studentname = name
random.random()
A = [[1, 0, 1, 1], [0, 1, 1, 0], [0, 1, 0, 1]]
print(repr(0.1))
user = models.ForeignKey(User)
self.inner_sizer = wx.BoxSizer(wx.HORIZONTAL)
self.cells.append(Cell(self, i))
a = np.array([2, 4, 6, 8])
numloss
df8 = df.ix[:, 84:96]
x1, y1, z1, w1 = np.rollaxis(quaternion1, -1, 0)
wx.App()
x.add(j)
[0.5, -1.0, 0.5, 0.0],
A = np.zeros((2 * (n - 1), 2 * (n - 1)))
req
print(data)
x == y
someday = datetime.date(2008, 12, 25)
addChild(image2)
S = np.cumsum(c[1:] ** 2)
x += y
print(self.foo)
hande_file(file)
changed = [(k, v) for k, v in list(self.byName.items()) if id(person) == id(v)]
df
plt.show()
l = [(0) for i in range(n)]
fig, ax = plt.subplots()
x = mu + sigma * np.random.randn(10000)
print(new_text)
parts.append(path)
departments = Department.objects.all()
self.p.stdin.write(image.tostring())
print(normalized(A, 1))
p1out, p1err = p1.communicate()
sys.stdout.flush()
Gtk.main()
f.write(t)
x = T.dmatrix()
serializer = MyPhotoSerializer(data=request.data)
self.items
mpl.ticker.ScalarFormatter.__call__(self, value, pos)
grammar.load()
data = fh.read()
msg = MIMEText(content, text_subtype)
self.wfile.close()
time.sleep(1)
ei = sys.exc_info()
ip
19921.8126944154,
flush_transaction()
my_record = MyModel.objects.get(id=XXX)
destination.write(chunk)
Base.metadata.create_all(engine)
name = models.CharField(max_length=80)
tmr.stop()
setattr_func(self, attr, value)
image = Image.open(path)
len(ln) - list(reversed(ln)).index(1) - 1
type(parsed_tree)
v = np.array([10.0, 11, np.nan])
args = parser.parse_args()
pp.savefig(plot2)
mlab.axes()
f.write(source)
pa - p0, pb - p0, pc - p0
fs1, y1 = scipy.io.wavfile.read(filename)
a = Question.objects.create()
print(fcst_serie)
a = np.array(a)
transmission_array = []
self._format(object, self._stream, 0, 0, {}, 0)
type = models.ForeignKey(ContentType, editable=False)
driver.switchTo().window(curWindow)
command = os.path.normpath(command)
ax = plt.subplot(111)
f.write(text)
type(self)(self + val)
x = np.zeros((200, 2000), float)
type(obj) in (type, type)
listening_sockets.append(listening_socket)
response
b = tf.Variable(tf.zeros([1]))
angle = 2 * math.pi / s
mylist = [a, b, c]
os.nonexisting()
print(h.getresponse().read())
picture.pictureClicked.connect(self.anotherSlot)
display(self.fig)
instance = object.__new__(cls, *args, **kwargs)
data = urllib.request.urlopen(url).read()
self.lines.append(self.addLine(0, yc, width, yc, pen))
client.load_system_host_keys()
idx = np.random.randint(0, 10, (yt, xt))
print(hash(foo))
inc2 = functools.partial(add, 2)
f = urllib.request.urlopen(req)
chainCalling(funcs[0](arg), funcs[1:])
lock.acquire()
residuals(p_guess, x, y)
packetcount = packetcount + 1
dict((k, sorted(v)) for k, v in list(result.items()))
main()
data = {}
lock.acquire()
print((MyEnum.a, MyEnum.b))
test()
formatqn.allow_tags = True
a.append(x)
admin.site.unregister(User)
y = x ^ 1 << j - 1
sys.stderr.write(message % self.pidfile)
get_model(app_label, model_name, seed_cache=False).objects.count()
self._odict.__repr__()
lrx, lry = latlontopixels(lrlat, lrlon, zoom)
session = cluster.connect()
total = total + int(n)
True
autovivify = lambda : defaultdict(autovivify)
insert_many(l)
df
grid = mlab.pipeline.scalar_field(xi, yi, zi, density)
m = mmap.mmap(fh.fileno(), 0, access=mmap.ACCESS_READ)
os.remove(sockfile)
created = db.Column(db.DateTime)
print(text)
content = f.read()
result = ws.recv()
exit_codes = [p.wait() for p in (p1, p2)]
self.request_roster()
self.itemChanged.connect(self.changeBG)
btree_container.setdefault(Gnodes, []).append([Hnodes, score, -1])
delattr(self, name)
matcher = re.compile(myExpression, re.IGNORECASE)
s += element.tail
x1, y1 = np.random.random((2, 10))
rng = arr.max() - arr.min()
combined = list(zip(a, b))
David
alnPDBseq = aln[0]
s += a
df
print(x)
plt.show()
rospy.spin()
self.spider = MySpider()
value = int(eval(input(prompt)))
lock.release()
words = s.split()
fig = plt.figure()
f
2 == True
api = tweepy.API(auth)
a = i & 1
print(result)
results.append(row)
df = pd.read_sql_query(sql, con)
uple1[1][0]
deletesys.argv[1]
skip = int(1.0 * total / surplus + 0.5)
s.bind((HOST, 0))
ax.fill_between(x, low, high, alpha=0.2, color=palette.pop(0))
f = io.StringIO()
print(i + ++i)
a = asarray(a)
updated_on = models.DateTimeField()
x(r)
fig, ax = plt.subplots()
partslist = good_histograms(nballs, nboxes, minballs, maxballs)
columns = zip(*original_rows)
print(ceil(lgamma(100000 + 1) / log(10)))
root.clear()
nosetest
cache[args] = obj(*args, **kwargs)
dmesg = dmesgProcess.communicate()[0]
mat[list(range(n)), list(range(n))] = list(range(n))
rounding_swig / testrounding.py
data = conn.recv(1024)
ax1.plot(yp, np.linspace(0, len(yp), len(yp)))
r, g, b = im.split()
map = dict(list(token.tok_name.items()) + list(symbol.sym_name.items()))
datetime.datetime(**values), tz
print(i)
i.start()
inmap(lambda x: x ** 2, a)
all(any(c == ch for c in it) for ch in x)
result[element] = result.get(element, 0) + 1
obj.isoformat()
x = A
self.window.setCentralWidget(QtGui.QTextEdit(self.window))
sshcon = paramiko.SSHClient()
gevent.spawn(self.counter_loop)
db.init_app(app)
x[i] = i
out[0] = X[0] ** 2 - X[1] ** 2 + params[0] * X[0] + params[1] * X[1]
temp = sorted(list_of_medals, key=itemgetter(0))
print(cache.value.groups())
distances = pdist(X, wminkowski, 2, [1, 1, 1, 10])
mask = np.ones((rows,), dtype=np.bool)
s2.difference(s1)
self.process.terminate()
x, y = arr.shape[0], arr.shape[1]
1
json.dumps(value)
i += 1
list(data.keys())
app.run(ssl_context=context, **kwargs)
lut = []
print(re.sub(expr, replace_by, mystr2))
print(myDict)
w = numpy.random.random(ndims)
top = random.randrange(0, y1)
i += 1
print(a)
x = np.linspace(0, np.pi, nx)
file.readinto(buff)
kth_order_statistic2(r, k - len(l) - len(m))
greeter.greet()
self.start()
r.clipboard_clear()
data = np.sqrt((x - s / 2) ** 2 + (y - s / 2) ** 2 + (2 * z - s / 2) ** 2)
age = FloatField()
np.random.seed(1)
new_list_1, new_list_2 = zip(*_zips)
INVENV = 1
result
ps = Popen(cmd, shell=True, stdin=PIPE, stdout=PIPE, stderr=PIPE)
conf.check_python_version((2, 4, 2))
[[counter[feat] for feat in all_features] for counter in counters]
caller = inspect.currentframe().f_back
root = Tk()
L = np.array([1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, -1, 1, -1])
offset = time.clock()
d = AtomicDict()
AbortSavepoint(self, transaction.get())
1, 4, 5, 6, 12
t = np.arange(25, dtype=np.float64)
df[0] = list(range(15))
metadata = MetaData()
bar1.__class__.num
-dtrflow - mdmbuf
A = np.asmatrix(np.arange(N)).T
self.show()
time.sleep(10)
df.to_dict()
ax = plt.subplot(111)
q.set_callback(cb)
pinot_noir
help(ContextManager)
args, extras = parser.parse_known_args()
hsh.set_http_debuglevel(1)
s.mode()[0]
line.set_xdata(x1)
self.x = x
input_as_vector = tf.reshape(input, [-1])
self
Foo.bar()
literal_eval(i)
Serial.println()
g = df.groupby(lambda x: x / 60)
FORMAT = pyaudio.paInt16
plt.xticks([]), plt.yticks([])
self = int.__new__(cls, *args, **kwargs)
clientSocket.send(subject.encode())
L1_unique_values = set(L1) - unwanted
myfilter.is_safe = True
eval(input())
print(get_ax_size(ax2))
int(str(num)[::-1])
self.timer = wx.Timer(self)
Covariance = numpy.cov(a, b, bias=True)[0][1]
query
w = UICPS()
quad(f, 0, 1, args=(T,))[0]
time.sleep(i)
raise MemoryError()
print(e.args[0])
(X - xmin) / (X.max(axis=0) - xmin)
result = result.filter(or_(*_filters))
self.server = Flask(__name__)
object.__new__(cls)
plt.subplot(212)
[account2]
im_hsv = cv2.dilate(im_hsv, element)
site = request.context
ignore_list.append(file)
isinstance(other, cls)
json.dump(self.object, file)
cb()
self._value
self.data[item]
print(item)
string = repr(lst)
lst = anything
idx = np.zeros(len(m), dtype=np.int)
A.func = classmethod(func)
logger = logging.getLogger()
obj.timestamp = current_time()
r = s.get(URL)
writer.save()
logger.addHandler(sh)
sm.ReadConfig(Filename=sys.argv[1])
renL.AddActor(actor)
thread = Thread(target=handler, args=(result,))
print(a.text)
cursor
new_list = []
assets = Environment(app)
deque(enumerate(itertools.accumulate(x), 1), maxlen=1)
pprint(mydict)
y = random.choice([top, bottom])
sys.settrace(tracefunc)
evnt.ignore()
bin8(6)
self.fed.append(d)
neighbors.remove(parent)
2
lst = []
showpageno = True
data = np.random.randint(1, 5, 20).reshape(10, 2)
c[:] = a + b
time.sleep(5)
print(df)
df
date_ceased_to_act = models.DateField(blank=True, null=True)
1, 0, 1
conn.read()
loss = tf.reduce_mean(tf.square(y_ - y))
axs[0].xaxis.set_minor_locator(x_minor_lct)
b = np.array([9, 8])
QCoreApplication.processEvents()
raise ValueError
cursor = connection.cursor()
self.yaxis.set_zorder(0.5)
s.sort()
L.reverse()
chunk = bytes_to_int(f.read(2))
last_name = models.CharField(max_length=40)
ora_conn.close()
sm = plt.cm.ScalarMappable(cmap=my_cmap, norm=plt.normalize(min=0, max=1))
soup = bs(r.text)
out_dict[row[0]] = float(row[1]), float(row[2])
print(e)
b = a.ravel().view(dt)
any(elem in test for elem in string)
print(types.IntType())
print(circle.popleft())
statv = os.statvfs(rootfolder)
s = sub.stdout.readline()
remove_pass(v)
PyObject * a
argnames = func.__code__.co_varnames[:func.__code__.co_argcount]
temp = tempfile.NamedTemporaryFile(delete=False)
cls.x
root = tk.Tk()
menu = QtGui.QMenu()
True
out = np.concatenate(np.take(a, uind))
print(i.leaves()[-1])
Msg.Attachments.Add(attachment2)
omega = det(dstack([a, b, c]))
x += a
signal.alarm(timeout)
pd.options.display.max_colwidth = 100
result = []
sys.getrefcount(i)
firefox_profile = webdriver.FirefoxProfile()
indices = scores.argmax(axis=1)
neighbours.remove((i, j))
g * u + h * v + i * w + g * x + h * y + i * z
s = m.group()
np.sum(na, axis=0)
next((start, end) for start, end in regions if start < x < end)
len(context.products) == length
index += 1
full_path = os.path.join(dirname, fname)
x += 1
itertools.permutations(stuff, 4)
buffer.append(duo)
ax.add_artist(ab)
func_new(a)
divide(2, 7, 70, True)
X, y = datasets.make_circles(n_samples=200, factor=0.5, noise=0.05)
c = Constants()
df.power200c[7]
tempFileObj.seek(0, 0)
source[PATH_TO_YOUR_ENVIRONMENT] / bin / activate
Decimal(1).exp()
len(self.data)
cur = conn.cursor()
x = np.random.rand(N)
result += text.upper()
pyfiles
founds = []
sys.stdout = sys.stderr
a2 = np.array([[2, 2, 2], [2, 2, 2], [2, 2, 2]])
print(word)
collect()(0).getInt(0)
print(next(test))
self.indexdict = {}
feet_entry.grid(column=2, row=1, sticky=(W, E))
actualstdout = sys.stdout
True
fs = fluidsynth.Synth()
result.append(s_copy[:index])
self.values = []
f.seek(random.randint(0, int(unc_size[0])))
a[len(a) // 5 * 5:][1:4] = 100
(4, [2, 2]),
resp = make_response(f(*args, **kwargs))
df = df[col_list]
pool.apply_async(func=worker, args=(i,), callback=callback)
self.then_client_receives_connection_refused_error()
a.data /= np.repeat(norm_rows, nnz_per_row)
result = f()
filetered = any(i in line for i in black_list_2)
ipy
x * y
1 / Fraction.from_float(2.54)
p = Process(target=myfunc, args=(child_conn, commands))
sess.put(url, data=xmlfile, headers=headers)
x_test = np.random.normal(0, 1, [50, 10])
output_list
m.logout()
l.sort()
ts.tm_sec
matching_solutions = []
file.write(line1)
data = self.cleaned_data
self.stackVals.pop()
self
start = datetime.strptime(start_date, date_format)
df.loc[(df.val1.shift(1) != df.val1) | (df.val2.shift(1) != df.val2)]
myiter = iter(list(range(0, 10)))
ret = df.loc[start:end]
start_time = Column(Integer)
[a0[start[i]:stop[i]] for i in range(len(start))]
output_lambda = df.apply(ratio).to_dict()
soup = bs(urlopen(url))
n > 0 and n & -n == n
target = np.array([-2, 100.0, 2.0, 2.4, 2.5, 2.6])
i = arange(len(a)).repeat(a)
plt.close(plt.gcf())
s = string[0:i]
pdf = file.read()
worksheet = workbook.add_worksheet()
ax = fig.add_subplot(111)
vc = cv2.VideoCapture(0)
{}
A = zeros(D.shape)
print(u.screen_name)
stamp = os.stat(self.filename).st_mtime
median = np.median(points, axis=0)
ser = ser.sort_values()
list(d.values())
distance = np.sqrt((ix - center_x) ** 2 + (iy - center_y) ** 2)
n * n
data[slcs2][repmask] = data[slcs1][repmask]
data[slcs1][repmask] = data[slcs2][repmask]
start, stop = np.flatnonzero(x[:-1] != x[1:])
dt = a.dtype
reader = csv.reader(hosts)
print(str(tab.render()))
menu.append(menu_item)
final.append(word if word in exceptions else word.capitalize())
x = np.random.normal(i, 0.04, size=len(y))
autocovariance(Xi, N, k, Xs) / autocovariance(Xi, N, 0, Xs)
sys.stdout = sys.__stdout__
users = group.user_set.all()
t = np.linspace(0, len(x), M)
ctx.text_extents(text)
json.dumps(mydict, cls=DjangoJSONEncoder)
D = sparse.csc_matrix(np.diff(np.eye(L), 2))
x, y = 1, 1
c = randint(0, 10)
sys.exit(app.exec_())
len(data)
result += str[start:]
logging.Formatter.__init__(self, msg)
x = np.array([random() for x in range(100)])
fs, data = wavfile.read(filename)
candidates_indexes[index] += 1
(2 << n - 1) - 1
cls_attr = cls.__dict__
rlist, wlist, xlist = select.select([p1.stdout, p2.stdout], [], [])
add_timeout(deadline, callback)
p.wedge(x=0, y=0, radius=1, start_angle=starts, end_angle=ends, color=colors)
count.most_common()[0]
model = Item
print(out)
self.clear()
d.update(child.dictify())
print(date)
mod = sys.modules[module]
lines = i.readlines()
ans = [random.choice(c) for c in constraints]
output_file.close()
lcl = zzz()
row = [item.decode(encoding) for item in row]
self.parse_response(connection, command_name, **options)
a = test(a)
dtypedict.update({i: sqlalchemy.types.DateTime()})
out.truncate(1024 * 1024 * 1024)
v
plt.xticks(ind, a)
t.render(c)
df
a[index] = item + 1
mats.append(sps.lil_matrix(np.array(df2)))
matches.extend(filenames)
y = list(range(100))
pool = mp.Pool()
output, unused_err = process.communicate()
aClk.start(), c[:, :] * c[:, :], aClk.stop()
cb = functools.partial(self.resp, items, iteration)
r = a + b
ax1 = fig1.add_subplot(111)
1 - ab_sum / sqrt(a_sum * b_sum)
some_object.save()
i, j = np.unravel_index(a.argmax(), a.shape)
double_to_hex(17.5)
quote_swap(json.dumps(quote_swap(s)))
dataBitMap.SaveBitmapFile(cDC, bmpfilenamename)
vector_b = array([1, 1, 1, 1])
x[f:] + x[:L + 1]
django.setup()
a = 1
t5 = MyObject()
id(a[0])
ax.add_collection(p)
nones = df == n
e2.pack()
now = datetime.now()
print(jvdata)
browser.webframe.load(req, QNetworkAccessManager.PostOperation, data)
desc = [d[0] for d in curs.description]
print(last_index)
len1 = math.hypot(x1, y1)
current_permissions = stat.S_IMODE(os.lstat(path).st_mode)
bar
f.close()
file = models.ImageField(upload_to=settings.FILE_PATH)
queryset
url = request.url
indices, data = zip(*data_items)
SHAhash.hexdigest()
a.data.nbytes
listOfElements[:] = [el for el in listOfElements if el.MeetsCriteria()]
matches.append(st.find(needle, i, i + len(needle)))
stack[-1].append(x)
result = list(camel.word_emitter(text))
os.chown(filepath, uid, gid)
layout = QVBoxLayout(self)
50, 0.057658, 0.114725
sys.stderr = LoggerWriter(log.warning)
t -= p * (a - an) * (a - an)
tokenizer.tokenize(txt)
x[:100, :100] = np.random.random(size=(100, 100))
red = pygame.Surface((200, 100))
print(x)
parser.disable_interspersed_args()
Feed.drop_collection()
print(b)
min_x = image_src.shape[1]
A.Multiply(False, V, B)
svalue = Column(String)
d[key]
f(x=0)
cc = Counter(l)
deletes[-10:]
job = models.ForeignKey(Job)
bisect.insort(r, i)
np.fill_diagonal(a, -np.inf)
print(reverse_pat.format(**matches.groupdict()))
12954124
my_bigdict.lookup()
newclass
fig, ax = plt.subplots()
LR.fit(X1[:half], y1[:half])
f(20, b=10)
self.server_id = server_id
(df.a < bval).sum() / len(df.a)
sys.meta_path[-1]._suffix = sys.meta_path[-1]._c_ext_tuple[0]
conn.close()
rotatedRect = [(minX, minY), (minX, maxY), (maxX, maxY), (maxX, minY)]
self._values[self._key_to_index[key]]
self.assertEqual(actual_output, expected_output)
conn = psycopg2.connect(conn_string)
list_x_set = set(list_x)
l_i = l[i]
clean_users.close()
do_stuff(line)
w2n, n2w
pd.Series(x).rank(pct=True).values[-1]
result = []
a * b
lst2 = line.strip()
found.append(name)
plt.plot(x, y, out[0], out[1])
img1 = numpy.asarray(img1)
filepath = os.path.join(dirpath, filename)
X = ma.mask_rowcols(X)
print(r.headers)
string.lowercase[:14]
out2D = squareform(out)
print(list(the_subset))
self._waitready.add(sender)
CC1b = np.zeros((n1, n1))
time.sleep(0.5)
main()
name = Column(String)
self.initialize(request, response)
vals_array = np.empty(lat_vals.shape + lon_vals.shape)
math.atan2(-0.0, 0.0)
nones = []
t = threading.Thread(target=dummy)
remove_your_temp_file(temp_file)
print(guess_seq_len(list_b))
Handler = SimpleHTTPServer.SimpleHTTPRequestHandler
d[j] = j
ax.plot(x, y, color=color, **kwargs)
self.Refresh()
random.choice(self.possible_strings)
original_string.replaceWith(BeautifulSoup(text))
result.append(self.format_option_help(formatter))
arr -= arr.min()
self.path = path
c.acquire()
[num, num]
v1 = {x2 - x1, y2 - y1}
ax.broken_barh([(midpoint - 0.1, 0.2)], (perc[4], perc[5] - perc[4]))
self.thread.start()
wf.setframerate(RATE)
all_potions = {}
self.root = Node(element)
utc_dt = pytz.utc.localize(datetime.utcnow())
d_time = datetime.date(2010, 11, 12)
opt = parser.parse_args()
winsound.PlaySound(memory_file.getvalue(), winsound.SND_MEMORY)
start
popped = {key: self[key]}
body = response.body
x = (x + apositiveint // x) // 2
PyObject_Print(obj_ptr, stdout, 0)
print(map(lambda x: x ** 2, [x for x in lst if x % 2 == 0]))
x * 100 + y
all(n % j > 0 for j in range(2, n))
im.putalpha(mask)
ax.yaxis.labelpad = 50
(2)(1)
print(result)
vline = ax.axvline(1)
k, v = next(iter(list(d.items())))
im = im.crop(0, 0, int(height_count * width / width_count), height)
dirs.remove(d)
print(x)
shutil.copyfileobj(f1, f2)
modules = map(__import__, moduleNames)
print(line)
sys.argv.remove(args[0])
self.subplot = self.figure.add_subplot(111)
d = OrderedDict()
rand_x_digit_num(5)
sess.run(init)
timing = dict()
main()
res[0] = 1.0
data_in_group = np.zeros_like(data_stack)
match.b
interleave(s, t, res + s[i], i + 1, j, lis)
result = []
order = np.argsort(groups)
any()
process(newfiles)
Y = np.zeros(1000)
a.first()
assert numpy.all((R - R_) ** 2 < 1e-16)
b[0] = 0
output.write(new)
new_li = [item[1:] for item in x]
start = time.clock()
output
raise AttributeError(attr)
self.__dict__[key] = item
memory_file.close()
[as_row(v) for v in obj]
print(i)
idx = np.array([True, False, False, True])
[]
r = urllib.addinfourl(fp, hdrs, req.get_full_url())
myHist = ax.hist(data, 100, normed=True)
x, y, z = d[key]
builder = Gtk.Builder()
y = np.linspace(-10, 10, npts)
webelement.text()
index = -1
next(I2)
curl.setopt(pycurl.PROXYPORT, SOCKS_PORT)
r = csv.reader(file_obj)
epoch = int(time.mktime(time.strptime(d, p)))
self.loader = gtk.gdk.PixbufLoader()
y = np.random.rand(N)
cj = CookieJar()
o[-1].append(x)
response = requests.get(token_url).content
result = []
N = data.shape[1]
result = c.fetchall()
doctest.testmod()
myArray = []
formatdate(time.time())
time.sleep(10)
im[i, j] = im[i, j] + 1
x, y = generalizedEuclidianAlgorithm(b, a % b)
pix = Pix.from_rgba(image)
Serial.println(value)
data -= np.mean(data, axis=0)
pdf_contents.file.write(pdf)
(array(mat) for mat in combinations(nvectors(n), m))
i += 1
unpack_list(*list(range(100)))
fb_[i] = zeta[i] / (np.exp(zeta[i]) - 1.0)
str(d)
start_dict = {item[0]: item for item in tpl}
l[i + 1] = l[i] + n // 2
sizeY = sizeX
s = socket(AF_INET, SOCK_DGRAM)
print(df)
keys = tuple(data)
cols = np.isnan(g).all(axis=0)
df = pd.DataFrame([1])
foo2 = Foo()
h2.encode()
latest = MyObject.latest()
self.setCentralWidget(self.table)
iter.open()
prefix_match(s, taglist)
self.__ParseString(rawdata)
r = fileobj.read_into(buf)
self.crawler = CrawlerProcess(settings)
window.show()
q.submit()
self.logger.log(self.level, message)
main()
fig.add_subplot(ax)
client = Client.objects.get(pk=1)
x_range = np.linspace(-10, 10, 100)
x_range = list(range(-5, 6))
s = b.total_seconds()
new_lis1 = deepcopy(lis)
list(_)
a[tuple(l.T)] = b
inner()
wb = Workbook()
m, se = np.mean(a), scipy.stats.sem(a)
self.width, self.height = width, height
self.__dict__.update(attrDict)
print(S1, S2)
up = upform.save(commit=False)
print(patient_element.tag)
dyn.put()
request.response.status = 400
y = reversed(x)
print(df)
print(x.get())
str1 = str(dict1)
False
self.stream.write(data)
plt.yticks([])
1, 0, 0
exit = Quitter()
mask = np.random.choice([True, False], size=df.shape, p=[0.2, 0.8])
fig = plt.figure()
dout = pd.concat([pd.get_dummies(df), dl, dr], axis=1)
plt.imshow(train_x[0].reshape((28, 28)), cmap=cm.Greys_r)
line = f.readline()
self.clients = []
A = np.arange(n).reshape(n // 4, 4)
HTTPServer.serve_forever(self)
last_element = dd.pop()
p[np.diag_indices(p.shape[0])] = np.ones(p.shape[0])
djangofile = File(local_file)
self.data[0:key[1] + 1] + list(key[0].indices(key[1]))
self._content.seek(i)
+i
self.delta
my_list[0]()
Wizard.Minimize()
n + u
fd.close()
ftype = 0
newlst = []
data = ff.read(4)
piecew(np.asarray([2.1]))
print(p.wait())
[list(group) for is_key, group in itertools.groupby(l, key) if not is_key]
df.date_time
foo(1, 11)
df.dtypes
print(WEEKDAYS.fri)
lglobals = sys.modules[lmoduleName].__dict__
l = list(s)
conn = engine.connect()
client = socket.socket()
flt = [[x, 0] for x in sorted(keys, key=len, reverse=True)]
list(set(first + second))
x = np.random.normal(mu, sigma, 10000)
train_data = tf.Variable(999)
xmlfile.close()
logging.config.dictConfig(logging_config)
image = pygame.image.load(name)
grid_x, grid_y = np.mgrid[0:1:100j, 0:1:200j]
n += 1
self.aws.receive()
store.append(key, df)
np.mean(arr)
hxs = HtmlXPathSelector(response)
self._reqId += 1
print(data)
temp_dict[values[1]] = temp_dict[values[1]] + 1
ext = os.path.splitext(f)[1]
ax.legend()
(1, 1)(1, 1)
window_width = int(img.shape[1] * scale)
d.setdefault(j, []).append(i)
df2[i] = 0
print(a_new)
self.tiles = tiles[:4] + tiles[5:]
members = []
0.0
[L[i] for i in slice_indices(len(L), start, stop, step)]
self.ref_object.method()
print(lst[f])
all_items(get_location(get_creators(get_surrounding_cities(printer()))))
word_counter[word] += 1
step(dates, counts)
print(type.text)
rdtype = np.rec.fromrecords(arrs[:1, ::-1]).dtype
url = urllib.request.build_opener(HTTPSClientAuthHandler(self.key, self.cert))
deletes = [(a + b[1:]) for a, b in splits if b]
self.name = name
x[a.argmin(0), np.arange(a.shape[1])]
s = str(n)
ax2 = ax1.twinx()
data = [random.choice((0, 1)) for _ in range(2500)]
instance.user = request.user
wrapped_mod = pickle.loads(p)
b = np.sqrt(e)
list(compress(arr, mask))
m2.save()
x = patricia()
yaml.add_representer(str, represent_str)
self.memory[key].append(value)
counts = [0] * n
set_color(b, initcolor)
fig = plt.figure(figsize=(2, 2))
yaxis = np.linspace(-1, 1, 20)
x + y
i = iter(list(d.items()))
images = mat2cell(im, size(im, 1), split_point * ones(5, 1))
print(next(g))
phone_book[name].append(number)
np.random.seed(101)
max_time = max(data[1])
jsonpickle.encode(Goal(), unpicklable=False)
plot.append(axMiu)
chunk = tuple(itertools.islice(it, size))
struct.unpack(format, buffer)
print([i for i in df])
s & 1 << x
density = gaussian_kde(data)
element, = myset
print(a, b, c)
np.clip(out, 0, 255)
df[good]
result.append(element)
app = QtGui.QApplication(sys.argv)
x = linspace(-1, 1, n)
print(field.name)
row_idx = np.array([1, 2])
2868466484
1649599747
2670642822
1476291629
self.get_solr_results(solr_sort)
y.remove(item)
output.close()
rows, cols = arr.shape
theText = f.read()
self._devnull = os.open(os.devnull, os.O_WRONLY)
adjs.append(tok)
data = json.dumps(options.__dict__)
i = 0
fh.setFormatter(f)
now = time.time()
self
new.append(new[i - 1] * df.A.values[i] + df.B.values[i])
wins[name] += 1
walls = [True, True, True, False]
a = np.vstack(([im], [im.T])).T
print(tab.draw())
l1 = [0, 1, 0, 0, 1]
dims = np.append(maxlen[::-1][:-1].cumprod()[::-1], 1)
total += 1
[start] + maxchain
self.__dict__[key] = value
self.sqsregion = sqsregion or SQSREGION
list_of_numbers.reverse()
[]
transmission_array.extend([rand_num] * 400 * duration)
crawler.crawl(domain_pk)
vectors = np.array([[0, 1], [0, -1], [1, 0], [-1, 0]])
i = np.arange(M)[:, (np.newaxis)]
Digit = OrderedDict(Digit)
coords[:, 1::2, :] = coords[:, 1::2, ::-1]
soup = Soup(xml)
ydata = list(range(10))
d += 1
16 ** (1.0 / 2)
u = np.sin(np.pi * x) * np.cos(np.pi * y) * np.cos(np.pi * z)
row += 1
tree = dict(name=os.path.basename(path), children=[])
True
row.append(SchemaTable.Rows[i][j])
api / views.py
data = np.zeros((len(ax1), len(ax2)))
self.__variable = 6
day_idx = (date.weekday() + 1) % 7
result = self.a + self.b + self.c
p.connections()
print(better_uc_hex)
k = inkey()
(np.inner(a, a) - n) // 2
wtr = csv.writer(result)
p = ThreadPool(1)
s.__dict__
args[0]
print(df)
newText[:-1]
a and b
ends.reset_index(drop=True, inplace=True)
IFAIsFifo = 0
results = np.empty((4, 5), int)
tmp = np.append(b, [[clipping_value], [clipping_value]], axis=1)
b = s.post(url, data=payload, headers=headers, allow_redirects=1)
dt = datetime.now()
0
appList.add(line)
total_cost += self.session.run((self.cost, self.train_step), feed_dict)[0]
toc()
r.url
name = Column(String)
BASE_DIR = os.path.dirname(os.path.dirname(__file__))
sidx = np.argsort(searchvals)
[11, 5, -12]
merge(r1, r2, lambda a, b: a != b)
self.showNormal()
r = [s for s in sentence if s.lower() not in hello_dic]
line = sys.stdin.readline()
print(traceback.format_exception(type, value, tb))
41149
filename = sys.argv[1]
self.f.close()
dates = matplotlib.dates.date2num(list_of_datetimes)
+__init__.py
L.reverse()
myFile.close()
type(x[()])
bool(i)
tabulate(grouplist(list(range(1, 11)), 4, 2))
MyClass().ff[0]
net.addModule(output)
result = im.copy()
s = json.dumps(u, default=json_util.default)
ctx = krbV.default_context()
redirect(to, *args, **kwargs)
self.sleep_time = value
m = mmap.mmap(f.fileno(), 0, prot=mmap.PROT_READ)
func()
b = Decimal(str(b))
plt.plot(time, signal)
mkwargs = [x.__repr__() for x in list(kwargs.values())]
terminator.start()
c = ntplib.NTPClient()
threads.append(threading.Thread(target=play_audio))
funcs.append(lambda x=x: x)
0
point_symbolizer = mapnik.MarkersSymbolizer()
ax.set_ylim(0, 7)
gr.add_edges_from(edges)
print(line)
print(args)
myFile.writerows(rows)
self.stopped = True
current = []
instance.register_signals()
result = (a - p) * (b - p) % p
testauthor = session.query(Users).filter_by(id=test.author_id).first()
all_pixels.append(bw_value)
Member.objects.in_group(one_group).not_in_group(another_group)
values[~valid_mask] = np.min(values) - 1.0
func(np.array([1, 2]))
self.help
self.i == other.i
s.write(urllib.request.urlopen(self.creative_url).read())
res = [value] * (2 * len(seq) - 1)
self.matplotlibWidget.axis.clear()
preprocessed = process.read()
root = Tk()
idx = np.searchsorted(sw, sCut)
b = np.ma.masked_array(a, mask=mask)
x[0] += 1
metadata2 = MetaData()
metadata4 = MetaData()
a[s]
print(result)
NULL
print(xml)
fig = plt.figure()
n
g._productions[-1]
window = pygame.display.set_mode((800, 600))
LIN[:, :d], e_values, e_vectors
data.seek(0)
ag012456789
next(iterator)
m[0] is m[1] is m[2]
cumulative = [0] * (len(l) + 1)
norm = tf.sqrt(tf.reduce_sum(tf.square(x), 1, keep_dims=True))
setattr(self, column.name, column.default.arg)
lst.sort()
context = self.get_serializer_context()
a = list(chain.from_iterable(npa))
auth_handler = urllib.request.HTTPBasicAuthHandler(passmanager)
print(arr[(5), :])
self.it = iter(it)
Point(midx, midy)
J.sum(axis=0) * mat
self.stream.close()
plt.title(cat)
alphabet[0]
app = QApplication(sys.argv)
main()
print(MySpider.start_urls)
evenmorestuff
print(df)
frame.pack()
a.intersection(b)
theQ = Queue.Queue()
self.user.save()
changelist = p4out.readline().split()[1]
word = matchobj.group(0)
result = []
wrapper
p = Pool(processes=2)
input = PdfFileReader(f)
gm.setLevel(logging.ERROR)
self.q.put(new_item, *args, **kwargs)
self.finish()
result.extend(replace_with)
self._replace(x=self.y, y=self.x)
self.instance(*args, **kwargs)
self.days = days + 7 * weeks + self.seconds // 86400
s.iloc[first_valid:]
url = url.strip()
plt.hist(a, 9, weights=b)
driver.close()
threadB = Thread(target=loobB)
np.__version__
email = db.Column(db.String(120), unique=True)
self.assertTrue(mock_warnings.called)
a == b
h1, w1 = img1.shape[:2]
msg = email.message_from_string(j)
rand = [mylist[i] for i in randIndex]
self._attr_value_to_obj_set.pop(attr_value)
print(replchars.sub(replchars_to_hex, inputtext))
ohandle.close()
addr = ctypes.addressof(c.contents)
library(sunburstR)
loop = asyncio.get_event_loop()
result = dict(dol1, **dol2)
print(data)
A.a()
now_epoch = calendar.timegm(now_tz.utctimetuple())
stdev = sqrt(sum_x2 / n - mean * mean)
name = Column(String)
print((pp + 1).year, (pp + 1).month)
100000010000
d[1] = 5
print(line.strip())
pprinttable([data])
ax1.view_init(-10, 45)
doc = docfile.read()
f = lambda x: Decimal(np.mean(x))
numpy.random.shuffle(shuffled_points)
df2.index = df2.index.map(lambda x: get_closest_match(x, df1.index))
P = mp.Pool()
do_stuff()
True
words = sentence.split()
self.id = self.num
settings.setAttribute(QWebSettings.PluginsEnabled, True)
index.append([keyword, url])
signal.connect_via(app)(listener)
print(distance(ListOfCoordinates[0], ListOfCoordinates[i]))
window.show()
threads.remove(thread)
[]
transport.open()
obj.bar = obj.foo
self.set_password(value)
total_distance = sum(distances)
old = sys.stdout
year += 1
trees = self.get_dump(fmap)
self.pack_start(gtksink.props.widget, True, True, 0)
bar().baz()
print(row.rstrip(), repr(row))
array(array(1))
a(4)
print(eval(input()))
recipe = Recipe.objects.create(**validated_data)
utc_dt = datetime.now(timezone.utc)
fig.append_trace(trace2, 2, 1)
ax = [plt.subplot(g) for g in gs]
iren.start()
coocc = df_asint.T.dot(df_asint)
new_pol = ops.cascaded_union(pols)
U.fromstring(B)
a.coeffs()
root = tk.Tk()
b.A
get_absolute_url = permalink(get_absolute_url)
letters += 1
self.sizer.Add(self.result, (0, 1))
map(d.update, extras)
st = np.mgrid[1:101, 1:101]
df
self.d[k]
D().f()
thread.start_new_thread(flaskThread, ())
values = numpy.array([0, 1, 1, 0, 0])
table = [int(x) for x in table_[1::2]]
plt.plot(b, a)
results.set_value(i, j, v)
self.result = re.search(pattern, text)
g = nx.DiGraph()
dst = tk.PhotoImage()
coll = db.dataset
self.f.write(e.strip())
cursor = connection.cursor()
((key, locs) for key, locs in list(tally.items()) if len(locs) > 1)
self.f = f
data._get_numeric_data()
cache[n]
c = b.upper()
n.bit_length()
subplots_adjust(bottom=0.14)
print(type(data_for_browser_retrieverd.json))
foo = args.one
evaluated = expression.subs(*zip(vars, your_values))
a * np.sin(2.0 * np.pi * f * t + p)
region_el = [x[0] for x in remaining]
multiprocessing.Process(target=uploader, args=(filenames,)).start()
rotations = rotations.reshape((-1, 2, 2))
print(row[1:12])
headers = [col.text for col in next(rows)]
keys = [k for k in list(self.keys()) if value in k]
self.func = func
freq = Counter(tuple(s[i:i + n]) for i in range(len(s)))
sys.stdout = self._stringio = StringIO()
np.sum(A, axis=0)
tmp = [a] * len(a) + [b] * len(b)
winsound.Beep(FREQ, DUR)
filtered2 = []
date
print(list_2)
type.__new__(cls, clsname, bases, dct)
c = Counter(words)
df.tail(1).T.assign(passes=df.tail(1).values[0] > 1)
parts = urlparse(url)
print(last_wednesday)
M[0, 0]
newfunc = globs[func.__name__]
a = {}
text.set_font_properties(font)
int(self.selenium.is_element_present(xpath1))
img.close()
HOME / anaconda / bin
p.join(DURATION - time_waited)
tv.set_rules_hint(False)
new_list
getattr(module, className)
height = GetSystemMetrics[1]
print(line)
t1 + pd.DateOffset(months=k)
pixel_at(25, 5)
self.lists[row].append(value)
sys.stdout = actualstdout
strobj2 == strobj
[p for p in database if p.y == 2]
doWalk(where, why)
foo_view(request)
new_list = [item.lower() for item in old_list]
self.name = name
(listScore == listScore[ind]).all(1).sum()
b[1:2, 1:2] = False
arr[0:2] += someVector
set_alpha_color(alpha_max)
g = parser.add_mutually_exclusive_group()
x = np.random.randn(100, 200)
os.dup2(devnull.fileno(), 1)
matches = [(t, p) for t, p in product(targets, prefixes) if t.startswith(p)]
1
a.min()
glLoadIdentity()
parsed = pool.apply_async(Process1, [largefile])
x0 = np.array([-0.72, -0.64])
A = NP.random.randint(0, 10, 100)
print(str_repr)
abc = lambda : myFunction()
user = models.OneToOneField(settings.AUTH_USER_MODEL)
ss.communicate()
pir(df.x.values)
Qt / __init__.py
item
some_template_functor < double > some_template_functor_double
values
a = [partial(lambda x: x, i) for i in range(5)]
MessageBox.Show(str(self.value.value))
ps = pandas.Series([tuple(i) for i in x])
a, b, c
f.write(string_to_write)
root = tk.Tk()
self.recent.append(mod)
funny_stuff()
temp.extend(m)
l = [(x[0], list(x[1])) for x in g if x[0] == 9]
print(len(test.vec()))
print((index, second))
self._thread.start()
request.args[key]
csvwrite.writerow(row)
urls = []
loop = asyncio.get_event_loop()
self.x = x
{{team.name | e}}
WSGIRequestHandler.log_request(*args, **kw)
self.append(next(self.gen))
screen = pg.display.set_mode(SIZE, HWSURFACE | DOUBLEBUF)
p = Popen(cmd, stdout=PIPE, stderr=PIPE)
curses.curs_set(0)
s = json.dumps(arr.tolist())
custers = scipy.ndimage.find_objects(labels)
x += 1
last_state = tf.nn.embedding_lookup(output_rs, last_index)
nges_uneval
threadLimiter.release()
l.append(2)
ax.set_xlim(xmin=-0.5)
os.waitpid(pid, 0)
self.parent._fsb_controllers.remove(self)
print(sum([(x ** 2) for x in lst if x % 2 == 0]))
data = yaml.load(text)
thumb_io = StringIO.StringIO()
zlib.decompress(unknown_compressed_data)
result
x = numpy.array([[9.5, 7.5], [10.2, 19.1], [9.7, 10.2]])
duplicates = [i for i in c if c[i] > 1]
iter(M)
print(fsolve(func, guess, args=(a, b, c, n)))
Grid.columnconfigure(frame, x, weight=1)
self.wfile.write(line)
toc()
curr_value = SomeModel.objects.get(pk=obj.id)
python_script = sys.argv.pop(0)
i += 1
self.__dict__ = original.__dict__
results[i] = []
sim = np.sqrt(0.5 * ((np.sqrt(dense1) - np.sqrt(dense2)) ** 2).sum())
print(b.x, b.y)
stream.filter(locations=GEOBOX_GERMANY)
p4.connect()
output.write(outputStream)
t1 = time.time()
True
html = url.urlopen(s.url).read()
actions.perform()
print(line, name)
raise AssertionError(message)
some_date.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
df.count()
max = numpy.max(numpy.abs(T))
np.sum(tmp[:, i::col_sp] for i in range(col_sp))
Forename = Paul
show(p)
self._x
self.canvas.widgetlock.release(self.lasso)
ind = ind[second_mask]
main()
add_method(e, bark)
fig = plt.figure()
a, b = c[:, (0)], c[:, (1)]
form.submit()
object_list = list(list(Content.objects.filter(foo=bar).values())[:100])
write_file(data)
int(n)
Y = np.fft.fft(y) / n
init_op = tf.initialize_all_variables()
i += 1
bus = dbus.SystemBus()
set(random.randint(0, 100))
[5, 6, 1, 17, 9, 18, 1, 16, 17, 10]
df
value = getattr(struct, field)
list1 = [2, 7, 8, 5]
sys.exit(main())
val = int(userInput)
food = OrderedDict((v[0], (v[1], i)) for i, v in enumerate(foods))
len(s) != l
duos.append(duo)
list(range(len(iterable)))
self.b = 2
toAdd = xyzCoord[i][:]
format_to_year_to_value_dict[format_str][year] = value
a.attr2
Models.my_model.MyClassName
order = models.IntegerField()
csvwrite.writeheader()
result[offset].append(name)
Hlow = ifftshift(Hlow)
ucd.name(u2[1])
denom = sum([(x ** 2) for x in list(rec.values())]) ** 0.5
proc.kill()
data = df.values
ax = plt.subplot(gs[x, y])
print(file.line_count())
pickled_object = pickle.dumps(obj)
tornado.options.parse_command_line()
(10 ** 0.5) ** 2 == 10
dis.dis(fun)
test_n(n)
m = sparse.lil_matrix((100, 100))
self.updater.setSingleShot(True)
abort(401)
Xfit_mono = zeros(Xfit.size)
assert parrot(inp) == expected
fmt.format(msg, lineno, colno, pos)
test(regex)
time.sleep(60 * 5)
self.fp.__exit__()
imp.acquire_lock()
a = np.arange(1, 10, 0.5)
point(self.x + oth.x, self.y + oth.y)
x
c.append([])
filecols = [readcol5(f) for f in files]
savout = os.dup(1)
groups = df.groupby(df.L)
list(filter(operator.isNumberType, list_1))
self.ui.gridLayout.removeWidget(self.ui.dragDataEdit)
print(output)
(s.map(type) != str).any()
ufmt_str.format(**kwargs)
line = input()
widget = event.GetEventObject()
os.remove(tempfile)
base.metadata.create_all(engine)
b = partial(a)
self.app = Flask()
cbar = fig.colorbar(mappable=plotted)
xdelta2, ydelta2 = xin - xlim[0], yin - ylim[0]
band = ds.GetRasterBand(1)
self.forest.append(tree)
mymodule.foobar2
masterReader = csv.DictReader(f1)
x = np.arange(-5, 5, 0.25)
dispatcher.connect(self.spider_error, signal=signals.spider_error)
my_own_magic(foo)
pycallgraph.stop_trace()
df.show()
var_name = value
hf = plt.figure()
a = np.array([[1, 0], [0, 1], [-1, 1]])
vals[i] = abs(np.dot(u, m2))
plt.imshow(zz, extent=(x.min(), y.max(), x.max(), y.min()))
curl.setopt(pycurl.SSL_VERIFYPEER, 1)
ordered.ordered_fields
False
g.LgRnk.rank(pct=True)
[0]
output = p.stdout.read()
main()
f.write(data)
diff = abs(results[i] - value)
valuesCopy.update({state: convergedValue})
H, X1 = np.histogram(Z, bins=10, normed=True)
res = urllib.request.urlopen(starturl)
self.fp.close()
pdb.gimp_file_save(image, drawable, file, file)
arr = np.asarray(bytearray(req.read()), dtype=np.uint8)
child = models.ForeignKey(Child)
fig = plt.figure()
t2.__sizeof__()
df = pd.DataFrame(data)
muX = X.mean(0)
trimesh = refiner.refine_triangulation(subdiv=4)
print(type(1))
child = pexpect.spawn(cmd)
temp.append(k)
o.two()
print(t)
self.date_start_processing = timezone.now()
result
data = csock.recv(1024)
string_size = len(string)
post_save.connect(create_user_account, sender=User)
cwd = os.getcwd()
hash_md5 = hashlib.md5()
require(selectr)
main()
PyErr_Print()
exec(c, m.__dict__)
next(fo)
ipdb.set_trace()
scatter(X, Y, c=Z, **scatter_kwargs)
print(A().a1())
outputList.append(os.path.join(root, f))
im2 = im.crop(im.getbbox())
handles.append(mpatches.Patch(color=c, label=labels[i - 1]))
pts = [(np.linalg.norm([x - w, y - v]) - r) for x, y in zip(X, Y)]
print(np.sum(primes, dtype=np.int64))
self.points = [Point(i, self.coords) for i in range(numpoints)]
count += 1
hash.update(block)
w.pack()
self.user_id = user.id
sheet1 = book1.get_active_sheet()
print(row)
reader = csv.DictReader(theFile)
result = connection.getresponse()
self._metadata.reflect(bind=self._conn)
insp = sa.inspect(engine)
new_btn.pack()
raw = f.read()
__import__(module_name)
br = mechanize.Browser()
search_set = ancestors_descendents & descendents_ancestors
input = sys.stdin.read(1024)
grid = scipy.sparse.coo_matrix((weights, xyi), shape=(nx, ny)).toarray()
self.do_stuff()
timeout = time.time() + 60 * 5
print(cmd())
d = defaultdict(int)
loss = tf.square(x - y)
summation += int(letter)
lambda x: exp(x)
sct.norm.cdf(x=50, loc=60, scale=40)
m.captures(1)
img_grand.readMetadata()
ss.listen(2)
is_sum_of_numbers(5, numbers)
posts.insert(post)
f.close()
X = np.arange(200) - 100.0
connect_signal1_to_slot1()
print(res)
os.execl(python, python, *sys.argv)
L = [1] * 5
layout.addWidget(ipyConsole)
pool.close()
devnull = open(os.devnull)
outFile.close()
a = np.random.random((20, 22))
count += len(mapping[y])
--docstrings
rows = []
self.session.Logon()
np.ones(10 ** 9, dtype=np.bool)
objects = models.Manager()
message = mailer.Message()
B = np.where(A < 0.1, A, 0).astype(float)
gs = goslate.Goslate()
d.setdefault(word, []).append(i)
loop.run_until_complete(main())
i += 1
tb.activate()
c = [(lambda i=i: i) for i in range(10)]
os.remove(batch_filename)
elem.send_keys(ARROW_DOWN)
foo = Foo(list(range(10)))
points.append((-1, -0.5))
print(a)
b = a[4]
startupinfo = subprocess.STARTUPINFO()
df.info()
line = handle.readline()
out = timeobj.astimezone(pytz.utc)
index += 1
frame.pack()
city_name = city.name
loop = asyncio.get_event_loop()
love_ctx = Graph(conj.store, NS_CTX.love)
print(sympy.__version__)
self.handleError(record)
pl.plot(x, dist.pdf(x))
my_hash = self.md5.digest()
0.0, 0.0, 0.0, 0.0, 0.0
keys[key[0]] = keys[key[0]] + d[key]
count[s] += 1
client = paramiko.SSHClient()
row.extend(sixplus(previous_row))
x = np.linspace(0, 10, 100)
user_registered.connect(user_registered_callback)
iter.destroy()
worker.moveToThread(self.thread)
print(f)
{{i}},
Xs = np.average(Xi)
True == 1
mtime = os.stat(filename).st_mtime
(x + y).subs(reps)
imagem = 255 - imagem
ts2 = ts[datetime(2011, 1, 8):]
print(id(Point(1, 2)))
key1 = models.IntegerField()
atok = asttokens.ASTTokens(line, parse=True)
fs.program_select(0, sfid, 0, 0)
p = Pool(5)
obj_dict = pickle.load(output)
res.append((s[i], j - i))
fig = plt.figure()
tn = telnetlib.Telnet(HOST, PORT)
df
hash(self._key())
j += self.shape[1]
Py_Initialize()
main_program.py
alist = [arr[(0), :-1], arr[:-1, (-1)], arr[(-1), ::-1], arr[-2:0:-1, (0)]]
intersections
print(df1)
filtered_primes = map(int, primes)
dx, dy = NORTH
df
elem = ElementTree.parse(file)
data = list(tuple(i) for i in data)
int(builtins.round(number))
b = itertools.zip_longest(*a)
t = np.linspace(0, 4 * np.pi, 100)
d[v] = [i]
cap = cv2.VideoCapture(fn)
self.do_open(self.http_class, req)
True
attrs.update(list(get_choices(attrs)))
__init__
self.setFlags(QGraphicsItem.ItemIsSelectable | QGraphicsItem.ItemIsMovable)
X = np.linspace(0, 10, 100)
res.asList()
pool = Pool(pool_size)
gona[0:2, (0)]
jobs.append(job)
x = min(x, 1)
print(read_pipe())
sqrt(6 * s)
first.nonzero()
openers.append(opener)
name = models.CharField(max_length=100)
plt.legend()
d[int(key)] = val
output = [x.reshape(s0[:i] + (-1,) + s0[i + 1::]) for i, x in enumerate(args)]
mtime = os.path.getmtime(name)
g.series((x, y), (0, 0))
ret, im_thresh = cv2.threshold(im, 128, 255, cv2.THRESH_BINARY)
fs.release()
bounding_boxes.append((center, (x, y, w, h)))
mpl.rcParams.update(mpl.rcParamsDefault)
profile = user.get_profile()
i += 1
print(sli)
list(g(arr, 8))
b = np.arange(0, 25, 1).reshape((5, 5))
layer1[:] = layer2
lines = f.read_lines()
print({elem: get_linked_list(elem, d, [])[1:] for elem in list(d.keys())})
spampwriter.writerrow((s1, item, i, list1[item - 1], er1))
df
HTT += HTTflips
print(df)
n = mat.shape[0]
count = collections.Counter()
ax.broken_barh(xranges, yrange, facecolors=facecolors, alpha=1.0)
request_object = urllib.request.Request(url, post_data, http_headers)
foo = Foo()
Lv = []
result = [[]]
polygon = mplpl.Polygon([(x1, y1), (x2, y2), (x2, 0), (x1, 0)], color=c)
xlmodule = objworkbook.VBProject.VBComponents.Add(1)
center = xy.mean(axis=-1)
list(b.values())
row, col = im.shape[:2]
r = s.get(url)
numpy.dot(a, a)
result = np.sum(corr_time2(t_output, JM1, JM2), axis=(1, 2))
encoded = json.dumps(obj)
method()
HttpResponseRedirect(secure_url)
results = DataFrame(results, index=df.columns, columns=df.columns)
assert self.test_user.get_short_name() == self.email
self.omega = omega
os.chdir(curdir)
f.write(chunk)
dx = POINT2[0] - POINT1[0]
arr = [bitarray(50) for i in range(10)]
I = np.nonzero(np.in1d(abc, c))[0]
type(100)
print(repr(test.read()))
print(item)
print(ascend_list)
d = df.column1.diff()
count = (cdist(listScore, np.atleast_2d([2, 0])) == 0).sum()
self.setParams(**kwargs)
print(x)
s = stdscr.getstr(0, 0, 15)
sys.path.append(basepath)
new_dict = defaultdict(list)
themsg.attach(msg)
proxy_handler = urllib.request.ProxyHandler({proxyscheme: proxyurl})
cur_line = f.readline()
eval(command)
s.add(Math.abs(n))
Py_DECREF(pName)
False
data = json.loads(response)
7.12802865169
print(a.MY_CONSTANT)
grades[i]
utc = utc.replace(tzinfo=from_zone)
math.sqrt(2) * erfi(2 * p - 1)
easy_install - -always - unzip
ws.set_remove_splits(True)
self.session.startRunning()
print(response.status_code)
cur.rowcount
plt.subplot(2, 2, 1)
print(item)
self._whatever = whatever
y_a = np.sin(x_a)
endpoint(*args, **kwargs)
Simbad.reset_votable_fields()
cv2.waitKey()
superm
x = x + 5
y * y
d[k] = round(v)
logger = logging.getLogger(__name__)
assert not self.test_user.is_superuser
self.start()
ax.set_yticklabels(yticklabels, minor=False)
assert_equal(foo, 10)
maxindex = a.argmax()
incsv.read()
ax = fig.add_subplot(224)
preliminary = stage1.search(text).group(1)
p.map(mp_worker, data)
fig = plt.figure()
my_user = User.objects.get(pk=1)
psutil.wait_procs(children, timeout=5)
pl.plot(x, blue)
df = pd.DataFrame(y, index=x)
self.webview.getSettings().setJavaScriptEnabled(True)
math.degrees(math.atan(x))
sys.getrefcount(sys)
print((name, score))
result[..., (0)] = np.clip(im[..., (0)], 0, threshold)
df = pd.DataFrame(arr)
vault.set_vault_notifications(vault, notification_config)
trel = [(t / tabs[0]) for t in tabs]
[11, 14, 15, 16, 17, 18]
self.setAcceptDrops(True)
a = np.empty(10)
6, [False, False, True, False]
lum_img = np.flipud(img[:, :, (0)])
get_conf = lambda : model_name.objects.get()
arr = arr[~mask]
pyaudio.pa.__file__
n
data[:] = [data[i:i + 50] for i in range(0, 2500, 50)]
cython.float
days, hours, minutes = map(int, (days, hours, minutes))
peaks = freq[mask]
print(x, y)
pickled_state[0], pickled_state[1], new_state
d[i] = l[s:s + i]
shape = len(arrays) * a.shape[0], a.shape[1]
print(type(first_arg))
DEBUG = True
img2 = converter.enhance(0.5)
a[2, 4] = 1
mat.move(-7, -2, 0, r=True)
_multiprocessing.sendfd(parent_pipe.fileno(), socket_to_pass.fileno())
k = np.random.rand(1000)
lst.append(1)
print(output)
qs = self.get_filtered_queryset(qs)
list2 = [2, 2, 2, 2, 2]
{{form}}
matrix = np.random.randint(0, 10, (5, 5))
groups = dict()
fields.append((name, field.clone()))
parser.read([filename])
x = np.cos(u) * np.sin(v)
sorted(list(s1)) == sorted(list(s2))
counter += 1
avg_time = sum(data[1]) / len(data[1])
next(generator)
module_name = inspect.getmodule(f).__name__
mapper.SetColorModeToDefault()
self.port = port
idx_c = (colorjh > 0) & (colorjh < 1)
[([x] + []) for x in seqs[0]]
data = bytearray(os.path.getsize(FILENAME))
ur = np.array([bx2, by2])
subcheckio(stones, 0, 0)
lock.release()
results.extend(result)
self.assertEqual(delta(9, 7), 2)
self.initfunc = initfunc
img.autoscale()
print(url)
this_array
exit(1)
np.clip(X, self.loclip, self.hiclip, out=X)
str(vars(self))
book.unload_sheet(name)
a = A()
random.shuffle(unfrozen_indices)
(128, 0, 0), (0, 128, 128), (0, 0, 255), (0, 204, 255), (204, 255, 255)
streamHandler.setFormatter(formatter)
n = int(math.ceil(math.log(abs(x2 - x1) / epsilon) / math.log(2.0)))
p = pyaudio.PyAudio()
mu, sigma = norm.fit(datos)
pool = Pool(CONCURRENCY)
Node.tree.filter(q)
x = 0
ret[np.diff(csr_mat.indptr) == 0] = 0
form = CostForm()
self.window = gtk.Window(gtk.WINDOW_TOPLEVEL)
data = self.page.mainFrame().toHtml()
self._data.columns.size
out[..., :outlen].copy()
idx_end = A.indptr[i + 1]
generator_code = inspect.getblock(sourcecode[gline - 1:])
print(df)
os.unlink(filename_larry)
fig, ax = plt.subplots()
t = threading.Thread(target=IOLoop.instance().start)
self.setBrush(Qt.green)
print(client.fetchAll())
w.pack()
result2 = pool.apply_async(solve2, [B])
words = [pair[0] for pair in v]
A = A[1:][::-1].T
title = models.CharField(max_length=255)
h[i] = h[-1]
mu = np.array([0.0, 0.0])
print(CatalanNumbers(511))
image = Image.open(filePath)
rec.levelname
min_key = k
v = np.linspace(0, np.pi, 100)
low, pivot, high
print(Foo.foo_string)
replaced.append(text[pos:])
first_row = np.where(rows == False)[0][0]
nodeMap = dict()
app = QtGui.QApplication(sys.argv)
bets = 2 ** np.cumsum(toss2)
myResponse.raise_for_status()
self.main = MainWindow()
im.set_data(tmp)
[(-value) for value, key in smallest]
[coslat * math.cos(lon), coslat * math.sin(lon), math.sin(lat)]
print(line)
passmanager = urllib.request.HTTPPasswordMgrWithDefaultRealm()
power(lambda x: x * 2, 1)(9)
context.update(extra_context or {})
start_response(status, response_headers)
result[1:4] = np.floor(result[1:4])
artist.add_reviews(review_id)
out = []
print(F[1])
y_fit2 = func1(x, *popt2)
bins = NP.array([0.0, 20.0, 40.0, 60.0, 80.0, 100.0])
row.pop(5)
lengths = map(len, lists)
sheet = doc.sheets[0]
transactions.sort(key=lambda date_data: date_data[0])
f = urllib.request.urlopen(req)
l1 = []
layout.set_font_description(font)
process.join()
ids = [row[0] for row in cursor.fetchall()]
food
d = {}
insanelib.xyz = myxyz
object2 = ClassB()
self.queryset = queryset
x, y, z = observation_points
X = 2 * X
b[0] = 97
ax.add_patch(p)
pl.xticks(x, xticks)
ret.reshape(self.shape)
roles = models.ManyToManyField(Role)
print(b.shape)
[(i if t else v) for i, (t, v) in enumerate(each)]
L.append(np.log(gev.pdf(data, *fit)).sum())
deps.func()
print(line)
fileHandler.setFormatter(formatter)
kicks = [0, -5 * noise, 5 * noise]
copy[i], copy[j] = copy[j], copy[i]
qproc.start()
rank = list(p.values())
line = line.strip(os.linesep)
test()
self.x = x
s.send(CONNECT)
total += num
assert np.all(self.d[:-1] >= self.d[1:])
layer.paste(mark, ((im.size[0] - w) / 2, (im.size[1] - h) / 2))
a, b = tee(iterable)
a = A()
count = 0
val += int(w)
samples = np.random.lognormal(mean=1, sigma=0.4, size=10000)
v = np.exp(2 * mu + sigma ** 2) * (np.exp(sigma ** 2) - 1)
random.seed(0)
startTime = time.time()
print(tags.tag, tags.text)
b = np.corrcoef(a)
print(n[-1])
classdecorator
result[i] = foo(data[i])
tmap = []
deletez[2:-1]
channel.shutdown_read()
doc = etree.ElementTree(page)
nltk.data.path
result = self._result_queue.get()
profiler.stop()
pprint.pprint(solution)
p /= numpy.sum(p)
print(values[ind])
x = 0
fig = plt.figure()
posts = FacebookFeed.get_posts(user=user)
o.write(line)
d = {x: [] for x in l1}
self._x
rgb = io.imread(filename)
best = [(0, []) for _ in range(n + 1)]
line = canvas.create_line(0, 10, width, 10, width=4)
f(arg_a=0)
bool(collections.Counter())
graph.html(data)
test(B())
pix = im.load()
[-5, -5]
pdb.Pdb().set_trace(frame)
print(threading.currentThread().getName(), self.receive_messages)
setattr(args, self.dest, [strategy, path])
my_list.append(key)
print(info.st_mtime)
my_dict = defaultdict(dict)
key, valuelist = oldDict.popitem()
print(f(X, Y))
color + vector * percent
target = random.uniform(0, total)
pyplot.legend(newHandles, newLabels)
setattr(self, self._attr_name, value)
first_arg_unicode = first_arg.decode(sys.getfilesystemencoding())
A[0, 1] * 0.5
df.values[[np.arange(5)] * 2] = 0
M[num_nonzeros != 0]
process_byte(b)
vd = dict((v[1], v[0]) for v in my_list)
hash(self.name)
bins = algos.quantile(np.unique(ser), np.linspace(0, 1, 11))
jsonify(count=counter.value)
list_of_all_primes(start, end)
context = etree.iterwalk(root)
print(timeit.timeit(lambda : split(TEST, SEPS)))
d = yaml.load(s)
tt = dt.timetuple()
sys.settrace(self.func)
assert [str(n) for n in node_depth_first_iter(tree)] == expected
pp.imshow(paw)
k2 = sorted(dict2, key=dict2.get)
self.context = context
print(len(holes))
data[k] = int(v)
min_y = image_src.shape[0]
edges = cv2.Canny(gray, CANNY_THRESH_1, CANNY_THRESH_2)
data + (chr(length) * length).encode()
zorder_images.sort(key=lambda x: x[0])
username
login(config.username, config.password)
writer.writerow(window.popleft())
string
print(l)
out += arr[:-2, 1:-1]
oldget(key)
d.callback(0)
out = np.nanmax(grouped_2Darray, 1)
u_idx_x = np.argsort(x)
org = Column(Boolean, default=False, nullable=False)
self.queue = Queue()
self.regenTree()
x + y + z
solutions = matching_solutions
cax = ax.contourf(theta_mid, r_mid, H.T, 10, cmap=plt.cm.Spectral)
a.append(1)
da.destroy()
dupe_rows = dupe_rows.apply(lambda row: row.duplicated().any(), axis=1)
mat = IndexedRowMatrix(traindf.map(lambda row: IndexedRow(*row)))
blahblah
top[0].reshape()
origlist = list()
B.func()
filt = resonator.poles_exp(freq=freq * Hz, bandwidth=bw * Hz)
d.wup_similarity(g)
print(df)
node_data.append(node[key])
_sounds = {c: str(i) for i, code in enumerate(_codes, 1) for c in code}
self[key]
axs[1].plot(clust_data[:, (0)], clust_data[:, (1)])
548, 410
566, 424
print(sess.run(x_max))
ex.args = (msg,) + ex.args[1:]
0.000158164
x + 1
data = list()
app.py
M.add_edge(1, 2, weight=19)
self.a = a
mp = MultiPolygon(list(polygonize(mls)))
diffs = map(ptdiff, zip(pts, pts[1:]))
result
f.write(response.content)
newImage.save(new_image_path)
r = R * cuberoot(u)
name = ndb.StringProperty()
print(vars(obj))
print(timeit(lambda : pool.map(mmul, matrices), number=20))
opener = urllib.request.build_opener()
form = ClientForm(request.POST, instance=client)
len(host_bytes) == 4 and len(valid) == 4
image = image.convert()
plt.plot(np.arange(10) + i)
self._stream.write(text)
parser = nltk.RecursiveDescentParser(lgrammar)
ds = audiere.open_device()
nx.__version__
P(func)
m = a.reshape((a.shape[0], -1))
plt.figure()
guess_type(filename)[0]
list2.append(t)
close()
G.add_path([10, 11, 12])
-1
cv2.cvtColor(self.cvImage, cv2.COLOR_BGR2RGB, self.cvImage)
print(synset.lemmas[0].name)
vars(Example())
item.created.year, item.created.month
f.close()
two.py
root = ET.fromstring(data)
[2011, 5, 8]
a[np.isneginf(a)] = inf
sys.stdout = buffer
blah()
print(root.filename)
print(e.__context__)
writer = csv.writer(output_file)
name = name.lower()
pseudocolor(20, 0, 100)
[6, 7, 8],
old_value = getattr(cls, name)
converted = df.apply(lambda f: to_number(f[0]), axis=1)
Parent.__init__(self, args[0].x, args[0].y, args[0].z)
archive.close()
print(pos[vertex])
client = oauth.Client(consumer)
MAJ = np.argmax(axes)
fp.close()
self.data = data
result
foo.foo()
image = image.resize((tw, nh), Image.ANTIALIAS)
sys.getsizeof(anIntOBJECT)
pygame.quit()
ax2 = fig.add_axes([left, bottom, width, height])
query = parse_qs(str[1:])
zip(a, b)
first_pair, pair_freq = list(d2.items())[0]
print(get_diagonal(m, 1, 4, -1))
q.urlencode()
raise KeyError(key)
translation.activate(self.old_lang)
m = np.array([([i] * 4) for i in range(4)])
chars.extend([digit, next(symbols)])
result = []
print(et.tostring(r.getroot()))
fullname = os.path.join(root, f)
lambda *a: cls(method(*a))
r = s[-1::-1]
pylab.show()
h2 = logging.StreamHandler()
deletelines[i]
print(link)
popt, pcov = curve_fit(func, x, y)
cbar = plt.colorbar()
xv = numpy.linspace(0, 100, 200)
sector_count = collections.Counter(item.sector for item in a)
ninja = create_or_update_and_get(NinjaData, data)
t.start()
extruded[list(range(N)), cords[:, (2)], cords[:, (0)]] = 1
print(x)
self.webview.clearCache(True)
Py_Initialize()
calendar.day_name[0]
start += len(sub)
xs.sort()
fill_array(arr, my_list)
content_type = models.ForeignKey(ContentType)
(i for i, _ in enumerate(seq, start=start))
data
f = Foo()
a = 2
nf = [x for x in data1 if x in data2]
fig = plt.figure()
value
doc = lxml.html.parse(s)
Qux.java
f(x=1)
py_string = PyString_FromStringAndSize(c_string, 1)
template = self._lookup.get_template(self.template())
datab = numpy.empty_like(image_data)
(dates - dateshift).fillna(0).dt.days.cumsum()
np.fromiter(x, int)
False
extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]
item = heapq.heappop(items)
a = (10 * np.random.randn(200, 200) + 127).astype(np.uint8)
aa.indices[aa.indptr[0]:aa.indptr[1]]
print(jo.key1)
Python - execnet
zeros_and_ones[x, y] = 1
s = StringIO.StringIO()
s = np.sin(x_axis_rotations)
random.randint(1, self.sides)
np.multiply(ray_point, 0)
x[r] = x[s]
merged = {}
d = dict(a=a)
dir(li)
pkt = pkt[IP]
search(parser.ast2list(st))
imap_utf7.decode(imap_utf7.encode(x))
array = np.asarray(array)
func1()
print(s)
sf_client = beatbox.PythonClient()
b = klass()
rects = faces[0]
sum(answer) / 2
window = Tk()
mainloop.run()
show()
self.app = app
request_parameters = json.dumps(request_dict)
q.set_message_class(RawMessage)
f = NamedTemporaryFile(delete=False)
bunch = BunchOFiles(*sys.argv[1:])
eventlet.monkey_patch()
form = TestForm()
delta = A[nhb] - A[x]
testName = testName.lower()
n = sparkdf.rdd.getNumPartitions()
b_thread = threading.Thread(target=get_b)
turtle.update()
p = x.ctypes.data_as(ctypes.POINTER(ctypes.c_double))
schema = f.read()
pool = Pool()
interact(set_cursor, x=(1, 9, 0.01), y=(0, 5, 0.01))
pyximport.install()
deserialized_a = pickle.loads(serialized)
np.int8(128)
floor(0, 1)
raise suppress_context(TheErrorClass())
ax = plt.gca()
print(a, b)
ciphertext = cipher.encrypt(plaintext + (16 - len % 16) * PADDING_BYTE)
res.sort()
other[0][0] = True
window = Window(root)
hold_lines.append(row)
p = np.asarray(prior)
newDate = datetime.datetime(2008, 11, 42)
row = []
ids = [row[0] for row in cursor.fetchall()]
json_dict = json.loads(json)
self.instance = MyAbcClass()
fig, axes = plt.subplots(nrows, 2)
self.ren.GetRenderWindow().Render()
pp.savefig(plot1)
sum(1 / k ** 2 for k in range(1, n + 1))
args = [iter(iterable)] * n
tasks.register(PowersOfTwo)
len(left), len(sep) + len(right)
l = LineString([(0, 0), (10, 10)])
float(sum) / n
zip(*results)
i.close()
chunk = stringio.read(256)
print([i for i in generator_overlap_split_list(l, s)])
df = df.astype(int)
1, 1, 0
d[key1] = sheet.cell_value(row_index, column_index)
sorted.__text_signature__
db.fleas.truncate()
z = numpy.arange(4 * 4).reshape(4, 4)
print([next(iters[i]) for i in dx_combo])
y[1, 1, 2]
arr = np.arange(5)
plt.sca(axes[1, 1])
x[:, ([2, 1])] = x[:, ([1, 2])]
result.append(result[-1] + 1)
print(traverse(re.sre_parse.parse(regex).data))
leng.count += 1
-Xms128m
self.dropbox_fn(filename)
lid = np.ravel_multi_index(x.T, x.max(0) + 1)
dir(newImg1)
ipdb.set_trace()
dis.dis(swap_xy)
df = df.reset_index()
repr(eval(self.expression))
global_list.append(x)
self.button.clicked.connect(self.reset_counter)
Electronics | Computers | Laptops
b = [2, 5, 6]
time.sleep(i * 10)
print(i.geoms[0].coords[0])
root.iconbitmap(default=datafile)
(d.day - 1) // 7 + 1
d = MyDict(a=1)
self.assertTrue(mock_subproc_popen.called)
a = []
fig = plt.figure()
self.template = template
[(k, OrderedDict.__getitem__(self, k)) for k in self]
wrapper
print(numpy.linalg.norm(y - clf2.predict(X)))
print(xl.__module__)
urlparse.urlsplit(url)
h[0]
c = a_type(b)
output = printme.format(user=x, date=y, User=x.capitalize())
help(numpy.sin)
self._b = b
self.button.setIcon(self._icon)
json.dump(data, outfile)
login_manager.unauthorized()
client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
data = self._fp.read(size)
variable = int(stringToInt)
l = logging.getLogger(logger_name)
x.sort()
soup = BeautifulSoup(res)
number_of_tries += 1
BOOST_PYTHON_MODULE(example)
array.append([])
head, rest = split_list(my_func())
baz.func()
print(counter.value)
print(list(unpack(data, 11)))
col_i += 1
n -= 1
response.text
draw()
ListenStream = 55556
filename = db.StringProperty()
[f.name for f in self.model._meta.fields]
cor.loc[:, :] = np.tril(cor, k=-1)
foo.func(bar)
cr = func(*args, **kwargs)
reshaped2 = sqlContext.createDataFrame(grouped.map(make_row))
libc.prctl(15, byref(buff), 0, 0, 0)
s += 1
fout.writelines(g)
print(table_name)
print(longest_sum([1, 2, 7, 8, 11, 12, 14, 15], [], 10))
help(setattr)
ax = plt.gca()
dt[(hr >= 10) & (hr <= 16)]
process.crawl(MySpider)
setA = frozenset([frozenset(element) for element in listA])
self.input.GetValue()
sess.run(init_op)
a.method2()
g[:] = (elem[:2] for elem in g)
os.chdir(app_root)
_features[name]()
ret.append(link[0])
System.Security.AccessControl
C().f()
b = object_array(a, a, a)
print(df)
x = np.random.randn(5)
order_cheese()
max_idx, max_val
sku_dict[color_id].append(sku)
n = len(df[mask])
app = Flask(__name__)
log_file.write(s)
a + b == c
sys_ss = scipy.signal.tf2ss([1], [1, 2])
self.layers = [NeuronLayer(self.n_outputs, self.n_inputs)]
conn = MySQLdb.connect(**db_params)
x
self.parser = ArgumentParser()
miny, maxy = ax2.get_ylim()
can.create_image((x_coordinate, y_coordinate), img)
diam_out = np.maximum.reduceat(dists, shift_idx)
l.sort()
raise Exception(stdout)
best, n1, n2 = a[i] * b[j], a[i], b[j]
rows = cursor.fetchall()
data2 = pickle.load(pkl_file)
print(cell.value)
d = datetime.date(tgtdate.year, tgtdate.month, i)
print(list(ip_to_datum_map.values()))
pt2.getX() == pt1.getX()
print(sums(listgen(), 20000))
self._x = a._x
new_self = self.__class__.objects.get(pk=self.pk)
my_cls = MyClass()
wrapper
txt = txt.replace(k, v)
results.append((i, li[i], j - i))
self.delays[type] = self.manager.dict()
X_reduced_train = pca.fit_transform(X_train)
rng1 = reikna_norm_rng(0, 100, 10000, 0, 1)
ax.add_patch(circ)
inp = alsaaudio.PCM(alsaaudio.PCM_CAPTURE, alsaaudio.PCM_NONBLOCK)
self.app(environ, start_response)
qs.none()
self.data = self.request.recv(1024).strip()
pixel_position = point[0] + point[1] * w
get_language()
save_uploadfile_to_disk(a_path, file)
s.bind(i[4])
b.attr
download_thread.start()
Total = Total + int(number)
imap.logout()
image *= 255.0 / image.max()
db_session.add(parent)
fig = plt.figure()
[pri, sec, tot]
Gtk.init([])
rv = self.next_chunk
server.mail(fromaddr)
f2 = partial(f, 42.0)
ii = np.argsort(maxvi[:, (-1)])
self._attr
start_response(status, response_headers)
newlist = []
handles, labels = ax.get_legend_handles_labels()
i += timedelta(1)
fig, ax1 = plt.subplots()
eq_(0, len(instances))
new_array = np.empty((len(uinqPos), 4))
print(fp.read())
colortype = 0
df = pd.read_fwf(data_file)
writer = csv.writer(results)
self[key]
d[year].append(month)
style = ttk.Style()
original(*args, **kwargs)
msg = MIMEMultipart()
pool = Pool(processes=4)
set_color(w, newc)
file = sys.argv[0]
surface = pygame.surfarray.make_surface(base)
self.src[-1].extend(items[:remainder])
a.a
d = json.loads(response.get_data())
self._data.columns[col]
chunked.append(word_pos)
self.spawn(self.listener, get_your_channel_label(message))
self.request.close()
print(numpy.argwhere(a == 4.0))
logging.root.addHandler = tracer(old_addHandler)
x.stdout.close()
fig = plt.figure()
response_body = str(int(request_body) ** 2)
QtCore.QEvent.__init__(self, InvokeEvent.EVENT_TYPE)
mGui.mainloop()
optionmenu.config(width=width)
cv2.line(frame, pred[i], pred[i + 1], (0, 0, 200))
fig, ax = plt.subplots()
lens = [len(list(g)) for k, g in groupby(sorted(l1, key=key), key=key)]
results[i, ind] = val
response
a = [1, 4, 8]
printRecur(root)
plot([0, 1, 5, 2, 9])
dictionary = dict(zip(*([iter(List)] * 2)))
parser.feed(buffer)
plt.plot(xs)
arr = np.asarray(points)
result += 1
[n][n - 1][n - 1]
current_dict = current_dict[letter]
self.omega.append((int(round(event.ydata)), int(round(event.xdata))))
cpid = os.fork()
A.shape
df
theta = np.concatenate((theta1, theta2))
fn = os.path.join(base, file)
pygame.quit()
curve = plot.plot(list(xdict.keys()), y)
dt.timestamp()
t = cv2.cvtColor(cam.read()[1], cv2.COLOR_RGB2GRAY)
raise KeyError(key)
res = c.fetchall()
count[0]
NULL
x = a[1] * b[2] - a[2] * b[1]
i = 0
y = func(x)
seen = set()
article = models.ForeignKey(Article)
count[1:] = count[1:] - count[:-1]
print(key, value)
dt = datetime.datetime(year=2014, month=5, day=2)
deleter(root)
plt.show()
result = {}
[i for i in original if i > lower and i <= upper]
datetime.utcnow() + timedelta(days=1)
fig = plt.figure()
print(sp.width, sp.height)
values[1:] = values[1:] - values[:-1]
yaml.add_constructor(_mapping_tag, dict_constructor)
L = []
list(mem.keys())
f = 440.0
r = requests.post(url, data=postdata)
q = Queue(maxsize=1)
t = set([7, 8, 9])
gtk.rc_parse_string(_gtk_styles)
Function(lambda x: self(x) / other)
variances + covariances
widget.clear()
col.append(np.array(num_rows * [i]))
main()
start = time.time()
resp.group()
transformed = assembler.transform(parsedData)
results = multiprocessing.Pool(number_of_processes).map(createpdf, data)
self.form.save.assert_called_once_with(owner=self.request.user)
upper_white = np.array([180, sensitivity, 255])
Languages | LANGUAGES
groups = [data[strt:stop] for strt, stop in zip(strts, stops)]
plt.plot(x, c)
sys.exit(a.exec_())
text = node.text.encode(encoding)
password = input(prompt)
user = models.ForeignKey(settings.AUTH_USER_MODEL)
width, height = fig.canvas.get_width_height()
defaultdict(type)
self.it, self.nextit = itertools.tee(iter(it))
raise AttributeError
self.app.exec_()
0, 2, 1
tk.Frame.pack(self)
application = Cling(get_wsgi_application())
cursor = connection.cursor().execute(sql)
grid = np.arange(100).reshape((10, 10))
assert p(f.read(2)) == 5
total += (i / j).sum()
handle.read()
tree = html.parse(url)
yy = np.hstack([-1 * y[::-1], y])
firstDigit = x[0]
words = list(map(process_group, groups))
pic = cStringIO.StringIO()
data1 = pickle.load(pkl_file)
zip_ok = 0
print(StudentTCI(1, 2, 10))
X, X().foo()
deferred.defer(count_colors)
self.upper()
x_test = np.array([i[1::] for i in test_data])
sess = tf.Session()
d = pd.to_datetime(df.last_updated)
emit(doc.location, [meta.id, doc.location])
print(i.geoms[1].coords[0])
self.i = 0
self.zipfile.extractall(tmp_dir)
plt.colorbar(myplot, format=ticker.FuncFormatter(fmt))
p.join()
img_list = os.listdir(path)
imp.reload(module)
M[sorter[index]]
print(cur.getDatabases())
ascii_counts[ord(c)] += 1
cur.close()
self.theWholeList.append(x)
np.maximum.reduceat(dists, shift_idx)
a.difference(b)
t = threading.Thread(target=target)
data = np.random.randn(100, 10)
np.mean(values_sorted[[median_index, next_median_index]])
c = Console.getconsole()
print(respose.headers)
self.baseDict = baseDict
unique_word_count = len(set(words))
big_df = big_df.append(df)
smean.on_changed(update)
print(h.unescape(s))
eltsize = ctypes.sizeof(typ)
popt, pcov = scipy.optimize.curve_fit(vcurve, xdata, ydata, p0=[2.0])
test1.timestamp = datetime.datetime.now() - datetime.timedelta(hours=2)
last_name = models.CharField(max_length=80, blank=False, null=False)
dy_dt = np.gradient(a[:, (1)])
f.headers.headers
canvas.delete(ALL)
bg_img.composite(fg_img, left=100, top=100)
answer.append(flatResults.pop(0))
A_exact = 20 * numpy.random.random((n_samples, n_inputs))
result = result.intersection(s)
prevday = theday - datetime.timedelta(days=1)
bw2 = thinning(bw2)
ax = subplot(111)
cx1 = self._gen.random_integers(0, self.N - 2)
self.menu.addItem_(menuitem)
col_size[i] = max(col_size.get(i, 0), len(col))
width, height = im.size
logger.addHandler(fh)
x_min = tf.reduce_min(weights)
c = np.dot(a, b)
now = datetime.datetime.now()
process = subprocess.Popen(command, stdout=writer)
mlab.close(fig)
form = ContactForm(request.params)
Xd = manifold.LocallyLinearEmbedding().fit_transform(X)
x * x
a2 = np.empty((M, 2, 2))
cnt[word] += 1
h1, l1 = ax1.get_legend_handles_labels()
sniff_on_connection_fail = True
x = np.random.rand(1000) * 10
Vprods = np.multiply.reduceat(values, group_changes)
o = json.loads(s, object_hook=as_person)
arr = np.vstack(values)
d == 1
first_shaders_dict = {}
z_itp = r * np.outer(np.cos(theta_itp), np.ones_like(phi_itp))
fields = [val for val in form._fields]
xfiltered
opener = urllib.request.build_opener()
poly = np.polynomial.polynomial.Polynomial(poly_coeff)
df.columns
image.set_from_pixbuf(pixbuf)
args = parser.parse_args()
test2 = Test()
handler = MyHandler
cls.from_buffer(a, aligned - addr)
font_args = [cairo.FONT_SLANT_NORMAL]
tabWidget.load(QtCore.QUrl(url))
Frame.__init__(self, master)
sm_obj.set_x509_stack(sk)
assert x.dtype == y.dtype
print(one_array, two_array)
unixtime = dt - datetime.datetime(1970, 1, 1)
a1 = A[..., (1)]
foo.__code__.co_argcount
idx[0] -= 1
self.base = Base()
op = s.pop()
1
cols.insert(0, x)
print(combination)
self.thisptr.calculate(a)
isanimated = True
c = [(i[1] - i[0]) for i in zip(a[:-1], b)]
Child().access_eclipsed()
wait = WebDriverWait(driver, 10)
mh11 = mh10 - h1 / 20 + h21 / 20
reader = csv.DictReader(inf)
z = a[0] * b[1] - a[1] * b[0]
fd.close()
s.send(pickleData)
pixels = []
a = [4, 5, 0, 0, 6, 7, 0, 1, 0, 5] * 1000000
column_names = []
do_something_else_2()
assert 0.0 + nextafter(0, 1) > 0.0
is_canceled = Column(Boolean, default=False)
hashtags.append(name)
ndarray = np.array(array_wrapper, copy=False)
matriz = np.random.randn(10, 10)
l[t] = something
filechecker()
page = response.read()
data = StringIO.StringIO(data)
temp_list.append(a)
main()
d.append(new_row)
individuals.append(individuals.loc[1]).dtypes
plt.plot(*p.linspace())
rows, cols = np.nonzero(img)
_f = sc._jvm.com.blu.bla.MySum().apply
f.close()
nll = -lg[mask].sum()
instance.is_initialized = False
print(row)
request.write(values)
f = lambda x: 2 * x
res.append(func(*args))
str1_list = list(str1)
chromeOptions = webdriver.ChromeOptions()
print(lt.tm_gmtoff / (60 * 60) - (1 if lt.tm_isdst == 1 else 0))
d = json.load(json_data)
time.sleep(60)
tree = etree.parse(data)
self.setWindowFlags(Qt.Popup)
im = Image.open(buf)
[item for sublist in lst for item in sublist]
q += 1
n = n - 1
new_list = [x for x in filled_list(src_list, 100)]
assert isinstance(value, datetime.datetime)
text = sys.argv[1]
item += [1]
self.db[self.collection_name].insert(dict(item))
print([x for x in roundrobin(*list(group.values()))])
G = nx.MultiGraph()
result.append(next(g))
cnx._open_connection()
b = np.array([line for line in a[:, (0)]])
the_dict
email = models.EmailField(max_length=50)
father.appendChild(tag)
stdout.write(choice(ascii_lowercase))
len(self.object_list)
traceback.print_exception(type(cause), cause, cause.__traceback__)
streak = 0
flag.Parse()
image = cv.CreateImageHeader(tiff.size, cv.IPL_DEPTH_8U, 1)
newdf = df.select_dtypes(include=numerics)
rows = np.array([1, 100, 1000])
perf_func(child, func, level + 1)
w = 2 * np.pi * r
cbar4 = plt.colorbar(im4, cax=cax4)
flooded = img.copy()
sin(x) + cos(x)
d = datetime.date(2011, 7, 2)
z = np.array([[0.0 + 0j, 2.0 + 1j, -1.0 + 4j]])
app = Flask(__name__)
pilImage = Image.open(inputImage)
a[a > 0] = 255
Counter(pop_flat).most_common()
list(helper(parts))
shape = np.sqrt(np.log(sol))
getattr(handler.request, method).add()
np.clip(dat, 0, 1, out=dat)
B.ham == A.ham
print(x)
cherrypy.quickstart(HelloWorld(), config=conf)
data = json.loads(response.body)
found = set([])
my_func_called_inside_a_task(celery_callback=True)
print(data)
args = docopt(__doc__)
self.comboBox.currentIndexChanged.connect(slotLambda)
ax.add_artist(plt.Circle((xvals[q], yvals[q]), rvals[q], color=[0, 0, 0]))
sequence = [seq2.index(element) for element in seq]
ret = ipcap.geterror()
indices = np.arange(y.shape[0])
self.children = []
dom = minidom.parseString(xml)
string.Template(tem).substitute(m)
self.axes = fig.add_subplot(111)
Tk.after(parent, 1000, change)
t1.join()
pool.apply(func=update, args=(counter, i))
data[i - window:i + window + 1].mean()
-1
cls._metadata = get_class_metadata(cls)
log.addHandler(txt_handler)
driver.find_element_by_id(id).click()
assets = []
fig, (ax1, ax2) = plt.subplots(nrows=2)
s.any() == 1
z = map(float, z)
Result = map(tuple, list(d.items()))
olApp = gencache.EnsureDispatch(clsid)
s[:2]
imap.login(username, password)
print(key, value, d2[key])
db = _get_db()
fig = plt.gcf()
recv2 = clientSocket.recv(1024)
recv4 = clientSocket.recv(1024)
recv5 = clientSocket.recv(1024)
lst
soup = BeautifulSoup(response)
self.dependency.__exit__(exc_type, exc_val, exc_tb)
pg.QtGui.QGraphicsPathItem.__init__(self, self.path)
self.connection.login(username, password)
n = _nbits[c].sum()
ch = logging.StreamHandler(sys.stdout)
p(2) / 2 + p(2) / 2 + p(4) / 2
appName = NSProcessInfo.processInfo().processName()
self.data = list(data)
wlist.append(proc.stdin)
raise KeyError(key)
exitstatus, signum = os.WEXITSTATUS(status), os.WTERMSIG(status)
a = C()
t.set_visible(False)
my_set = set(first_list)
shared_items = set(x.items()) & set(y.items())
print(StringIO(file2.read()).getvalue())
first, rest = unpack(*seq)
d = {(0): l}
weighted_sum = np.apply_along_axis(exp_func, 0, clipped_background)
db_engine = create_engine(DATABASE_CONNECTION_INFO, echo=False)
mybasemodel_set = MyBaseModelField(many=True)
geo = Geometry(0, 0, 1, 1)
json.dumps(d)
ax5 = plt.subplot2grid((6, 1), (4, 0), rowspan=2)
age = db.StringProperty()
hub.wait(watcher)
std = np.sqrt(sy2 / n - mean * mean)
b += [c]
abs(n - m)
translater.install(str=True)
user = User.objects.get(pk=user_id)
SubClassWithoutDocstring().__doc__
fly.rect.bottom = hit.rect.top
levels = np.linspace(vmin, vmax, 200, endpoint=True)
data
datetime.min + (q + 1) * delta if r else dt
pumpedThread = threading.Thread(target=pumpWx, args=())
final_ensemble
results.append(left[0])
df
-1 // 2
datetime.min + math.ceil((dt - datetime.min) / delta) * delta
plt.scatter(xc, yc, c=cols, label=cla)
fout.write(line)
a[:len(b)] = b
self.queue.put(event)
print(foo)
foo1()
print(repr(path), (newpath, tail))
img_grand = pyexiv2.Image(grand)
print(canonical_form([1, 1, 1, 0, 0, 2, 6]))
fig, ax = plt.subplots()
accum0 = []
(x + (n,) for x in seq for n in f(x[-1]))
socket = pyudt.pyudt_socket()
others = l[:index] + l[index + 1:]
item = Item()
a = A()
print(a.current)
writer = csv.writer(output_file_handle)
lines.append(string[i:i + every])
tid
ser = pd.Series([-1, 1, np.nan])
f.__name__
x = np.linspace(-5, 5, 101)
_f
systems.append(system)
x + 1
CrawlSpider.__init__(self)
print(arrayT(data[0], [0.29, 4.5]))
raise ConcurrentModificationError(cls.__name__, self.pk)
df
in_first = set(first_list)
ctx.select_font_face(font, *font_args)
plt.fill_between(x, 0, s)
self.Gender = Gender
str(attribute)
print(getmembers(clf.tree_))
deleter(data)
DEBUG = True
file
df = df.stack()
reps = []
ABCD = numpy.concatenate([AB, CD], 0)
Expression(body=BinOp(left=Num(n=2), op=Add(), right=Num(n=2)))
s = set([0, 1])
_[0]
two[0, 0, 0] = np.array([[2, 2]])
arr = np.asarray(str_bytes)
g, x, y = egcd(a, m)
points = data[:, 2:4]
query = users.select().order_by(users.c.id.desc())[-5:]
new_array[i, Y[i]] = 1
0
thread.start_new_thread(do_it, ())
a = [1] * 50
resultlist = []
datasets[-1].append(stripped_line)
x = y
crawler.crawl(RaEventSpider())
norm = matplotlib.colors.Normalize(vmin=np.min(Z), vmax=np.max(Z), clip=False)
print(result)
w = pyglet.window.Window()
d[j].append(i)
Py_Initialize()
spam_lite.update()
self.__dict__.pop(k, d)
fly.rect.top = hit.rect.bottom
raise
g.logout()
sizer = wx.BoxSizer(wx.VERTICAL)
self._protected()
C1.__init__
M[(1), :] *= 2
print(globals() is locals())
d = {}
mailserver.ehlo()
LHS, RHS = [0, 1], [-LHS[0] / LHS[1]]
person = Person()
__init__.py
cls._registry.append(cls)
centroids[i][m] += row[m] / len_best
application = app
my_dict = dict(string)
time.sleep(0.1)
int(s)
array[0]
self.pipereadstreams.append(readStream)
a = [[]] * 10
socket.setdefaulttimeout(new_timeout)
app = Flask(__name__)
outFile.write(buf)
MyModel.timestamp._auto_now = False
random.shuffle(pool)
print(resource_path)
item.firstChild.replaceWholeText(data[name])
print(df)
print(config_root.server.name)
indicies_nonzero.append(index)
print(df)
self.canv.restoreState()
o.write(line + plat[platform])
files = os.listdir(directory)
assert numpy.all((R1 - R1_) ** 2 < 1e-16)
source_list = inspect.getsourcelines(my_module)
print(df.reindex(cum.index))
dset_y.append(y_chunk)
row = df.iloc[0]
p[0]
self.create_response(request, game.start())
plt.matshow(plot_matrix, cmap=colormap)
predictions = model.predict(gaussianKernelGramMatrix(Xval, X))
message.attachments = [(attachment_name, attachment.value)]
process_handle = OpenProcess(SYNCHRONIZE, False, pid)
out = os.read(proc.stdout.fileno(), 10)
data_md5 = hashlib.md5(bencode.bencode(data)).hexdigest()
df2[column] = list(map(diff, df[column], ref[column]))
fig, ax = plt.subplots()
dstname = os.path.join(dst, name)
print(property.name)
print(addsf1)
print(str(datetime.datetime.now()))
new_time = time.time()
queue.write(json.loads(line.strip()))
self.saturated()
see(x)
data * 2
driver.get(target_url)
bmp = wx.EmptyBitmap(size[0], size[1])
True
zeros_and_ones = numpy.zeros([width, height])
X, Y = NP.meshgrid(x, y)
newI()
page.close()
other[0][0] = False
1024.0
print(row)
arr[0, -1] = 100
interpolator(x)
Ml = mat.tolil()
a.sort()
result += letters[index - shift]
type(my_pandas_frame[100])
pointCloud.addPoint([0, 0, 0])
plt.xticks(np.arange(min(bins) + bin_w / 2, max(bins), bin_w), bins, **kwargs)
self.song1.setVolume(1 - fadevalue)
any(value in x for x in self.sets)
crawler.queue.append_spider(another_spider)
probabilities = numpy.random.multinomial(n, zip(*pairs)[0])
arr = np.split(arr, indc, axis=1)
j += 1
result = copy(dateList)
results = sorted(results_dict.items())
Z = X * Y.T
event_date = models.DateField()
singles.append(p)
self.file, self.filename
mvv_array = [int(i.mvv) for i in mvv_list.collect()]
sprites.append(sprite)
QApplication.clipboard().setImage(QImage.fromData(buf.getvalue()))
Y = EY + np.random.normal(size=n) * np.sqrt(20)
x, y = line.split()
processes[i] = multiprocessing.Process(target=child_process.run, args=(i,))
u = np.empty(n, dtype=np.int64)
self._queue = q
df = pandas.DataFrame(df, dtype=str)
self.alist.extend(args)
err_ys.append((y - yerr, y + yerr))
password = args.password
denominator = df.sum(0).sum(0)
profile = Profile.objects.create(user=user, **profile_data)
update.alters_data = True
crawler.configure()
--report_task.py
l
pr.enable()
supported_file_types = fcb.get_supported_filetypes()
new_path = list(path)
c // (n + 1)
i += 1
Clock.schedule_interval(self.add_string, 0.5)
print(outQ.get_nowait())
conn.sendto(some_data, MY_SERVER)
cron.write()
new_jk = numpy.random.multinomial(1, numpy.reshape(p, T * S)).argmax()
df.Date = pd.to_datetime(df.Date)
{song.album for song in self.allSongs}
hstack((B2, D))
flask.jsonify(error=404, text=str(e)), 404
getattr(self, method)()
tokens = deque(f.read().split())
update_object(form_class=FooForm, object_id=object_id)
get_stems_recursive(list(all_stems.items()), list(), result)
transferData.upload_file(file_from, file_to)
Book.objects.filter(**filters)[:limit]
self.goal.field.add(new_field)
is_word.words = {word.strip() for word in f}
output.flush()
a[l[i][0]][l[i][1]] = b[i]
cal = France()
pygame.init()
print(len(parts))
ratio = float(len(a)) / float(len(a) + len(b))
print(MyClassFactory.theWholeList)
plt.figure()
self.ready.notify_all()
M.ix[0]
tf.concat(0, data)
test()
r.delete(key)
doc.build(text)
output.write(string_fin)
a = A()
tplsum = np.array([tpl[:, :, (i)].sum() for i in range(D)])
[(ay + be) for ay, be in zip(a, b)]
print(maximal_sum(M))
main_parser.parse_args(replace_dashes_from_args(sys.argv[1:]))
time.sleep(wait)
owner.what = owner.what.__iadd__(2)
dict_writer = csv.DictWriter(fou, fieldnames=fieldnames)
any(isinstance(e, int) and e > 0 for e in [0, 0, 1])
Wizard.NextButton.Click()
[np.arange(s, e) for s, e in zip(start, end)]
res
gevent.sleep(0.1)
cols = list(set(result.dtype.names).intersection(a.dtype.names))
foo[0] is boo
PyEval_RestoreThread(mainThreadState)
self.__dict__.update(decoratee.__dict__)
DataFrame
s.blit(alpha_img, (0, 0), special_flags=pygame.BLEND_RGBA_MULT)
[1, 24, 4, 5] in a
gb = df2.swaplevel(0, 1, 1).sort_index(1).groupby(level=0, axis=1)
prefix = decPrefixes[-1]
root.mainloop()
self.sender.disconnect(self.handle)
plt.colorbar()
do_something(my_value)
n / 1 << n.bit_length() - 1
mask1[idx1], mask2[idx2]
counter += 1
mod = importlib.import_module(var1)
print(a)
tmp = a2[:x].copy()
string[0]
rmin, rmax = np.where(rows)[0][[0, -1]]
d = OrderedDict()
dill.detect.trace(False)
parsed_result[name].append(value)
self.connected = False
d_time2t_stamp = pd.to_datetime(d_time)
cookies = cherrypy.response.cookie
print(results.get())
int(21 / 5) + (21 % 5 > 0)
True
list(fields_660.keys())
years = collections.defaultdict(list)
s = io.BytesIO()
new_shape = rows / 2, cols / 2
tk = tkinter.Tk()
clientSocket.close()
foo = d[x]
not all(row)
gst.element_link_many(self.source, self.scaler, self.fvidscale_cap, self.sink)
keep.append(item)
m[1][0] = 99
df = pd.read_csv(StringIO(txt1))
seq.append(next(it))
setattr(cls, name, decorator(m))
entity.after_put()
a = numpy.random.random((10, 10))
print(add5(10))
file_handler.setFormatter(formatter)
ctx.restore()
selected.append(perm)
r = requests.put(post_url, auth=auth, headers=headers, data=json.dumps(doc))
self.wv.webview.getUrl()
badset = set(badlist)
tag.replaceWith(s)
n, bins = np.histogram(samples, bins=int(np.sqrt(N)), density=True)
data = [float(v) for v in line.split() for line in file]
[s]
pprint.pprint(d)
m_to_M[1:, (0)] = -nrange[1:-1].reshape((n - 2, 1))
proc.start()
self.data = data
d = datetime.date(2011, 9, 28)
print(list(k))
y[0] = 5
a + b
self.__class__(**arguments)
s.update(list(range(4)))
source = s.get_source()
start = time.time()
d = date(year, 1, 4)
Base = declarative_base()
fig.add_axes(ax)
formset = QuoteFormSet(request.POST, request.FILES)
x = 1
[2, 1]
a[idx]
X_ = X - X.mean(0)
type(True)
x2 = np.interp(width_S, S_values_2[-1:idx - 1:-1], F_values_2[-1:idx - 1:-1])
addChild(image)
a, b = tee(iterable)
providers = Provider.objects.all()
tree = etree.fromstring(XML)
self.client = redis.Redis(connection_pool=self.connection_pool)
new_lists.append([])
print(content.readlines())
opener = urllib.request.build_opener()
False
np.allclose(cdist_split(pairs, positions), XYZ_merged(pairs, positions))
b = a + b
mask[y:y + h, x:x + w] = 255
fig = figure(width=500, plot_height=500)
dates = [20020514, 20020515, 20020516, 20020517, 20020520]
print(a[(1), :])
overlaps < -int_overlaps(int[index[1,]], int[index[2,]])
ob.stackoverflow()
webcode.html
a = foo()
fig = plt.figure()
cursor.batch_size(1000)
output = StringIO()
data = globalsfiltered()
proc.terminate()
include_dirs.append(arg[2:])
pos = nx.spring_layout(Gcc)
safe_matches = [re.escape(m) for m in matches]
mystrategy.example()
w = wave.open(wave_file)
last_mod = variable[4][1]
num = 1
setattr(self.instance, name, value)
i += 2
days, hours = divmod(hours, 24)
self.totalsize
len(self.data)
raise AttributeError()
a = b[:, (0)].copy()
len(sys.argv) > 1 and scan(sys.argv[1])
print(ws.cell(rx, cx).value, ws.cell(rx, cx).ctype)
print(count_common(l1, l2))
raise AttributeError(attr_name)
df = pd.DataFrame(d.T)
print(myList)
m = multiprocessing.Manager()
content = urllib.request.urlopen(base_url + symbol).read()
a = [(float(val) / pow(2, 15)) for val in a]
name = models.CharField(max_length=255, blank=False, null=False)
s.describe()
line.replace(self.ind, self.outd)
print(the_matrix[0])
a = np.arange(24)
test_module1.py
a.name, b.name = b.name, a.name
hanoi(n - 1, start, target, aux)
master_writer.save()
transaction.savepoint_commit(sid)
tag, body = next(iter(list(d.items())))
mask = x ** 2 + y ** 2 <= radius ** 2
self.lop._getsymbols() + self.rop._getsymbols()
t
1
enc = base64.b64encode(base64.b64decode(s)).strip()
b.values.argmax(1)
unpickler = cPickle.Unpickler(f)
protocol = QNetworkProxy.HttpProxy
d = collections.defaultdict(int)
tcl = Tcl()
out = np.zeros((A.shape[0] + len(cut_idx), 2), dtype=A.dtype)
v[:] = [0, 0, 0]
combos = it.product(*list(by_parent.values()))
x = f.read()
bin_array.append(int(byte, 2))
re.split(regexPattern, example)
a = np.ndarray(shape=(N, 0))
themodule_foo(PyObject * self, PyObject * args, PyObject * keywds)
mylog = logging.getLogger(logname)
print(eastern.localize(test2))
p.wait()
im.axes.figure.colorbar(im, cax=cax, **kwargs)
self.sock.connect(self.host)
seen.update(rn)
P.drawOn(canvas, doc.leftMargin, 10)
y16 = []
np.save(f, c)
stats.binom_test(500, 10000)
self.song2 = song2
ax = fig.add_subplot(1, 1, 1)
context = {}
split[-1][-1].append(r)
idx = np.flatnonzero(flags)
print(val)
username = user.username
text = subprocess.check_output(command)
pythons_psutil = []
a.apples()
False
results.append(string[last_stop:start])
attr_name_to_attr[attr_name].set(attr_value)
boston = load_boston()
res1 = np.dot(A, B)
dictpsl[key] = []
obj = np.asarray(input_array).view(cls)
first_a.test()
dataframe = pd.DataFrame(data=mat.astype(float))
self.foriterator(self.start, self.stop, self.step)
res[i, j] = dot_product(Aview[i], Aview[j], A.shape[1])
print(df)
foo.bar = partialmethod(foo.bar, qux=1)
result[0], result[-1]
username = models.CharField(max_length=256, null=True)
stretch_unpooling_out = neibs2images(stacked_conv_neibs, self.pl, self.x.shape)
df = pd.io.json.json_normalize(d)
ordered = OrderedDict(pairs)
seconds = dhms_to_seconds(*convert_timedelta(duration))
os._exit()
a.sort()
a, b, c, d
u.load()
print((x, len(seen)))
nextone = min((current // a + 1) * a, (current // b + 1) * b)
fig = plt.figure()
print(key, count[key])
year_range = np.arange(min_year, max_year + 1)
lock.acquire()
id(a) == id(b)
[], 1
xx, yy = np.meshgrid(list(range(-1, 1)), list(range(-1, 1)))
msvcrt.fflush(msvcrt.stdout)
out = []
util1.py
data = np.arange(k ** n).reshape((k,) * n)
x1 = np.random.normal(size=N)
pylab.show()
t1 = timeit.timeit(lambda : var1 == var2, number=10 ** 4)
path = self.in_queue.get()
print(list(l))
new_matrix
x, y, w, h = win.get_allocation()
blob_info = blobstore.BlobInfo.get(resource)
treeselection = treeview.get_selection()
res
fig = plt.figure(figsize=(ypixels / dpi, xpixels / dpi), dpi=dpi)
print(avg)
ind = np.arange(len(data)) + window
arrays[0].__array_wrap__(numpy.hstack(arrays))
v = numpy.linspace(-1 * numpy.pi / 2, numpy.pi / 2, 100)
b = c_ulong(2)
print(a)
ABSTRACT_FACTORY = True
solution1 = (-b - cmath.sqrt(d)) / (2 * a)
print(combineArs(dict1[dimmKey], dict2[pwfs2Key]))
json.dumps(self)
scipy.misc.imshow(extracted_filter)
22.152261
0.284024
7.580967
Bar(income_df, notebook=True).show()
print(x * 10)
plt.legend()
a = binascii.hexlify(bytes([1, 10, 15, 16, 255]))
tr = tender_data.values[:, 5:]
ax.scatter(data.Lon, data.Lat, c=data.Z, s=100, vmin=zi.min(), vmax=zi.max())
a = a + 10
print(df2)
portfolio.append(entry)
lock = threading.Lock()
recurse()
df.index.inferred_freq
time.sleep(15)
str(dict(self))
green = pygame.Surface((100, 100), 0)
test_updates(my_dict)
plt.imshow(pic)
root = tk.Tk()
encoded = ohe.fit_transform(orig.reshape(-1, 1))
l, d = foo()
tmp = np.zeros((n + 1, n + 1), bool)
portfolios = list(p for p in cp if sum(p) == 100)
read = p.stderr.readline()
l = [8, 10, 4, 5, 7]
print(date.toordinal(date(1970, 1, 1)))
curr = curr[1:] + (x,)
t, p = f_oneway(*list(data.values()))
myobj = MyClass()
d = NP.digitize(A, bins)
crossing = [math.copysign(1.0, s) for s in signal]
print(merge([L1, L2]))
data = np.abs(data)
A = A[1:].T[::-1]
cimage.seek(0)
c()
procd = [c for c in string]
y = np.asanyarray(y)
heapify(i, 0)
__all__.append(name)
total = np.sum(values[mask])
im = Image.open(fn)
req = requests.post(url, data=my_json_data)
collections.OrderedDict.__init__(self)
xy = np.random.random((2, num)) + 0.01 * np.arange(num)
print(i)
out, err = p.communicate()
window_height = int(img.shape[0] * scale)
dx, dy = dy, dx
b = copy.copy(a)
script_path = os.path.realpath(__file__)
print(msg.SentOn)
df[col] = df[col].ffill()
crypt.mksalt(crypt.METHOD_SHA512)
y
tpool.execute(m)
False
IPython.embed()
p.join()
self.stream.send(p)
Thread(target=volume_switcher).start()
child_midpoints = []
print(mode(data, axis=0))
client_cmd = client.invoke_shell()
df.FREQ = pd.cut(df.FREQ, bins=bins, labels=labels)
f_inrange
raise
x, y
array([7, 11])
Q_UNUSED(parent)
Spam.update(self)
x[0] = 10
increments_sum += increments[i]
newfunc.func = func
shared_str.value
client_to_server(messag, host, port, size)
cThread = Thread(target=c.run, args=())
font.configure(size=max(size, 8))
server_B_thread = threading.Thread(target=server_B.serve_forever)
app.run()
root = tk.Tk()
b = 2
clb = plt.colorbar()
self.vtkDepth.Modified()
bitlist = [1, 0, 0, 0, 0, 0, 0, 0]
[5, 0],
xnew = np.linspace(x.min(), x.max(), num=41, endpoint=False)
mask_inv = cv2.bitwise_not(mask)
a = my_class()
i += 1
y = np.random.normal(0, 1.0, 100)
df.loc[:, (cols)] = df[cols].where(df[cols].ge(0), np.nan)
sh1 = wb.sheet_by_index(0)
0
Base = declarative_base()
doc.build(text)
plt.plot(x, val, alpha=0.05)
stopx = img2x - img1x + 1
Entry(form, textvariable=celular, width=15).grid(column=1, row=1, sticky=W)
termios.tcsetattr(fd, termios.TCSAFLUSH, attrs_save)
print(date)
cnt.send_msg(data)
stud = session.query(Student).first()
print(v.data)
correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
description = Column(Text)
opts = parser.parse_known_args()
n * factorial(n - 1)
deletetokens[-1]
json_object = json.load(response)
num2 = int(argv[2])
value = root.A[0].B[0].C[0]
parsed_url = list(urlparse(url))
obj.__reduce__()[1]
julia > pytype_query(x)
rectangle(maskRoi, roi, Scalar(255), CV_FILLED)
ax.legend_.remove()
cmap = {(1): (255, 255, 255), (0): (0, 0, 0)}
pre_save.connect(pre_save_callback, sender=models.MyModel)
plotter()
key in self._info_axis
result.append([v])
m.shape
arr1 = np.arange(10000).reshape(20, 10, 50)
a + b + c
index = items.index(item)
self.edit.setText(text)
procs.append(subprocess.Popen(ARGS_GO_HERE))
fig.set_size_inches(6.4, 5.12)
self.queue.put(item)
Response(e.message, status=400)
Fraction(1, int(yc) + 1)
int(aString, 16)
id_arr.cumsum()
print(type(domain))
seen = set()
X, Y = np.meshgrid(x, y)
DecodeAES = lambda c, e: c.decrypt(base64.b64decode(e)).rstrip(PADDING)
i += 1
by_bins.get(True, ()), by_bins.get(False, ())
r.mainloop()
my_worker.moveToThread(my_thread)
fig = matplotlib.pyplot.figure()
suite.addTest(unittest.makeSuite(Class1))
_f
a = np.random.rand(N, N)
b = datetime(2010, 12, 7)
A1 = Al.tobsr()
print(list(o))
c += 1
redirect(list_)
defaultdict(nested)
self.spider = spider
path = os.path.dirname(path)
randomword(10)
os.mkdir(path)
i, i + len(small)
sys.stdout.write = inner
seen = set()
d = {}
output = ctypes.c_int()
curr_num = int(temp_fh.readline().strip())
self.data = data
try_one(downloader, 15)
[item for item in vqs]
log.setLevel(logging.ERROR)
g.ax_marg_x.set_axis_off()
s = list(iterable)
it = iter(iterable)
print(result[1])
s.run()
data = file.read()
np.cumsum(inds, out=inds)
self._content.seek(0)
str
l1 = [1, 1, 1]
print(len(retval))
Queue.get(self, False)
mantissas *= 10.0
print(basis[0](1))
i - len(list2)
find_leading_zeros(14)
new_result
glMatrixMode(GL_MODELVIEW)
wr.writerow(RESULT)
print(valchange(a, b))
print(platform.python_implementation())
d = lambda a, b: map(list, zip(a, b))
x[ix_i, ix_j]
output.addPage(cover_pdf.getPage(0))
y_score = np.array(output)[:, (1)]
min_z, max_z = z_surface.min(), z_surface.max()
cls.instances.add(instance)
parsed_result
MyModel.BLAH_FOODALLY_BOOGALY
b = [4, 5, 6]
z = np.zeros(700)
e.set_sensitive(False)
opcodes = [op[0] for op in list_of_all]
ei = (1 - math.pow(1 - e * e, 1 / 2.0)) / (1 + math.pow(1 - e * e, 1 / 2.0))
Y_test = lb.fit_transform(y_test_text)
val = label_map[int(x)]
dict(name=self.name, firstname=self.first, address=self.addr)
self.fields.update(fields_for_model(User, _fields))
ser.isOpen()
print(Sentence.translate(rep_dic))
my_items = models.ForeignKey(MyModel)
x_series.append(int(x))
Worker(request_queue).start()
list(range(max(a.start, b.start), min(a.stop, b.stop), 1))
a = np.arange(4)
fd.close()
x, y = np.meshgrid(np.arange(nx), np.arange(ny))
_, image_summary = sess.run([train_op, image_summary_t])
last_index = word.index(letter, last_index + 1)
here = os.path.dirname(__file__)
db.session.commit()
words = string.split()
city = db.StringProperty()
words[i] = word_list[words[i]]
h = plt.plot(x, rv.pdf(x), lw=2)
[tuple(g) for k, g in groupby(init, delimiter.__eq__) if not k]
zip(*([chain(iterable, repeat(padvalue, n - 1))] * n))
{members}
the_indices = [2, 5, 7]
cell_value = worksheet.cell_value(row - 1, i)
self.wtree.start()
print(result)
sC.on_changed(update)
cw = boto.cloudwatch.connect_to_region(Region)
t.join()
D = np.prod(C[..., 1:], axis=-1)
os.chdir(cwd)
b = str(a)
merge(list1, 0, 1)
app = QtGui.QApplication(sys.argv)
abcde
HhighShift = scipy.fftpack.ifftshift(Hhigh.copy())
arr
1
pool.imap(func, images)
b = [a]
data = client_socket.recv(1024)
lst.remove(what)
pygame.display.update()
slots[s] = next(it_B)
old_val = [1, 2]
timer = QTimer()
q = queue.Queue()
first_type = type(next(iseq))
wrap(text, 16)
dflist = [df1, df2]
print(output)
print(result)
len(read_file(filename).splitlines())
values = pd.Series(df.values, index=index)
yieldFoos()
a.update([1])
new.append(a[j])
array[index].append(int(item))
parser = argparse.ArgumentParser()
patches[2]
sys.exit(0)
b = np.arange(10, 20).reshape(2, 5)
n = len(l)
[0, 0, 0, 1, 1],
c = ws.cell(row=5, column=5)
ssc.stop()
worker.dowork(lock, processes)
-1 * p(x)
x
defaults.update(kwargs)
numbers = input[2:]
main.py
factors = list(factorGenerator(n))
get_user_model().objects.all()
x = ET.fromstring(a)
turtle.penup()
assert len(population) == len(weights) > 0
children = [n for n in nodes if n.parent == parent]
dx = r * np.cos(angle)
indx = np.ravel([np.where(x == i) for i in r])
wxbmp = wx.BitmapFromBuffer(w, h, img)
result.pop()
p = json.loads(x)
print_ephemeris_for_date(datetuple, bodies)
axes[0].append(string1.index(i))
saver.restore(sess, fileName)
show_views_channel[1]
worksheet.write_string(r, c, col)
self.close()
nums[-1]
l[index] = item.strip()
allowed_domains.append(hostname)
ret[key].append(item)
powerpoint.Visible = 1
print(output)
df2 = df.copy()
bits_generator = (set(x) for x in itertools.combinations(list(range(n)), k))
stats = pstats.Stats(profile, stream=stream)
do_something_further_image_processing_to_decrease_size
d[partial_key] = dict()
answer = []
self.not_full.notify_all()
d[x.tag] = x
print(self.id)
seps = []
print ()
security.tokens.append(userNameToken)
thedata = r.content
test_string = test_string.lower()
final_values = [n[i] for i in max_indices]
output = p2.communicate()[0]
i = 1
ax = fig.add_subplot(111)
computed[n] = fib(n - 1, computed) + fib(n - 2, computed)
stack.extend(iter(v.items()))
prob_matrix = prob_weights / prob_weights.sum(axis=0, keepdims=True)
x()
cap.release()
lst.append(0)
actions.move_by_offset(x_from, y_from)
{key: self.schema[key] for key in fields}
tcpCliSock.send(buff[i])
conn.close()
l = {}
entries_of_interest.choose(a.T)
p = np.poly1d([1, -1, 0, 0, -(stddev / mode) ** 2])
ax.set_xticklabels(xticks)
y = py_func(x)
ogl.CGLSetParameter(context, 222, ctypes.pointer(v))
f4 = [2.0, 2.0, 2.0]
main()
print(args[0], args[1])
a = df.append(pd.DataFrame(mydict, index=[0]))
search_form = UserSearchForm(request.POST)
globals()[funcname] = func
data = np.zeros(num, dtype=dtype)
sys.stdin = s
print((step, sess.run(W)))
df.iloc[4:6, (1)] = np.nan
logfile.write(f.read())
np.random.seed(2015)
thelist = [(key, genreOptions[key]) for key in genreOptions]
model = mc.MCMC([mean, std_dev, custom_stochastic])
CELERY_IMPORTS = detect_tasks(project_root)
t = threading.Thread(target=workon, args=(h,))
checktime = datetime.datetime.today() - datetime.timedelta(days=int(2))
self.array[arr.mylog2(index + 1)]
pylab.plot(x)
repr(1)
(0.01).hex()
fulldata = np.append(fulldata, audio_data)
matrices[:, (0), (0)] = 1
cursor = con.cursor()
df.index = [[i] for i in tup]
User.objects.get(pk=user_id)
x0, y0, z0, w0 = np.split(quaternion0, 4, axis=-1)
current_set = set()
stat2 = defaultdict(list)
cjson.decode(obj)
t = Thread(target=enqueue_output, args=(p.stdout, q))
sys.exit()
s = df.a[:5]
strab = str(ab)
False
print(tone1)
click(10, 10)
s
print(all_steps(pathList))
instance.method()
dests = [dest[1] for dest in list_of_all]
visited.add(node)
Thread.sleep(500)
root = ET.parse(urllib.request.urlopen(requestURL)).getroot()
path = os.path.normpath(path)
c = np.tensordot(A, B.T, 1)
map(chars.extend, fd)
o = RelatingModel.objects.create()
begin = time.time()
d1 = date(2008, 8, 15)
barbar
self.GetEventHandler().ProcessEvent(event)
month = calendar.monthcalendar(2010, 7)
print(repr(obj), obj.__dict__)
np.put(s, p, i)
cr.fill()
p1.poll()
request.user = user
secrets.randbelow(n)
lines_after_17 = f.readlines()[17:]
self.body
print(names[idx])
dll.myfunc(ca_array, len(ca_array))
index += 1
p.join()
exiting
prefix = commonprefix((a, b))
print((left, right))
country = models.CharField(max_length=50)
arclength = scipy.integrate.cumtrapz(sqrt(dydx ** 2 + dxdx ** 2), x, initial=0)
l = []
lang.install()
choice
axes[0].imshow(img)
s.sendto(NTP_QUERY, (host, port))
area1 = 0.5 * sides[0] * sides[1] * math.sin(math.radians(angles[1]))
output.append((first, last))
http_server.listen(options.port)
draw_line(event.xdata, event.ydata)
col = np.array([7])
parent = Tkinter.Tk()
l = s.split()
replacement.seek(0)
print(sample_dict)
subparsers = parser.add_subparsers()
df.show(5)
L.append(chr(i))
result = output.getvalue()
ax.set_xlim(-1, 11)
o = urlparse.urlparse(self.path)
obj_list = []
WLAN_AVAILABLE_NETWORK_INCLUDE_ALL_MANUAL_HIDDEN_PROFILES = 2
k = np.arange(n)
print(z, x, c, v)
chain.from_iterable(combinations(s, r) for r in range(1, len(s) + 1))
WLAN_AVAILABLE_NETWORK_INCLUDE_ALL_ADHOC_PROFILES = 1
user = ReferenceField(User)
print(b)
a[a == 0] = -1
c = congruent.columns.to_series().map(lkp).values
bool_arr = [True, True, False]
np.linalg.norm(np.asfarray(p1) - np.asfarray(p2))
loop = asyncio.get_event_loop()
fig.clear()
np.nan == np.nan
True
print(cmd.group())
cookies = driver.get_cookies()
response_data = {}
self._d = d
main.show()
complex(x, y)
u, s = n, n + 1
s1.difference(s2)
print(self.state)
d = deque(s)
ax.legend()
y = list(range(200))
os.close(devnull)
foo = Foo()
stream.write(data)
my_string
diff = dict((k, n - k2.index(k)) for n, k in enumerate(k1))
d = dict(a=1, b=2)
my_types = [str, int, float, MyClass]
lookup = iD - iB - iC + iA
container = np.zeros((N, 2))
output.append(item)
plt.imshow(img2)
result = method(self, *args, **kwargs)
p.process()
deallocate()
foomodule.alist.append(1)
soup = BeautifulSoup(txt)
res
ax = plt.subplot(grid[0, 0])
conn = l.accept()
self.send_response(200)
self.quit_button.clicked.connect(self.capture.quitCapture)
dic
jj = [ii[i] for i in range(1, len(ii)) if dd[i - 1] > 2]
animal.save()
assert b.x == 0
self.errorcount += 1
print(c)
x, y
a = df.values
a[(2), :2, 2:]
gc.get_referents(some_list)
n2w[narrow].add(wide)
soup = BeautifulSoup(html)
SimpleHTTPServer.SimpleHTTPRequestHandler.do_GET(self)
iter.close()
df = pd.DataFrame(M).convert_objects(convert_numeric=True)
res[accmap[i]] += a[i]
[string for string in string_list if len([x for x in string_list if string in x]) == 1]
filtered = MyObject.objects.all()[start_point:inc]
opts = dict(page=context)
{}
plt.plot(x, y_fft)
callers_namespace = inspect.currentframe().f_back.f_locals
col_index = {j: cell.value for j, cell in enumerate(row)}
opener = urllib.request.build_opener(cert_handler)
pts = [(1, 1), (1, lim), (lim, lim), (lim, 1), (1, 1)]
shutil.rmtree(name)
L
unconverged[unconverged] = new_unconverged
data = np.random.randn(10, 10)
m_to = db.ReferenceProperty(reference_class=UserModel)
sys.stderr = mystdout
Thread(target=reader, args=[process.stdout, q]).start()
set()
chunk = response.read(CHUNK)
self.ax = plt.gca()
some_bad_code()
values = [col.text for col in row]
b[1, 2] = 999999.0
self._a = a
result[i].append(e)
betweenness_centrality(G, k=k)
self.b
tms = [(v[0], v[1]) for v in values]
kwargs = {}
rv = self.jinja2.render_template(_template, **context)
ax.ticklabel_format(useOffset=False)
shape = []
df.info()
raise StopIteration()
f.truncate()
s1.values.append(1)
countries = Country.objects.all()
root = tk.Tk()
plt.show()
print(foo_q.__str__())
1 if text[i] == char else 0
writer = csv.writer(fout)
right = other.reindex(index=common, copy=False)
print(c.Bread)
credentials = GoogleCredentials.get_application_default()
t1 = timeit.timeit(closure, number=10 ** 4)
serial_out = listener.read(size=1)
lettered = []
figure(figsize=(10, 10))
files = glob.glob(fullpath)
print(s.before)
c.setopt(pycurl.SSL_VERIFYPEER, 0)
self.id < other.id
print(point.x, point.y)
copy.copy(self.pred)
self.X == other.X and self.Y == other.Y
console = logging.StreamHandler()
QNetworkAccessManager.createRequest(self, op, request, device)
ax = plt.axes()
print(isinstance(b, B))
BASE_DIR = os.path.dirname(os.path.dirname(__file__))
test.debug()
array1.tolist()
r = conn.getresponse()
c1.acceptor_id = c2.donor_id
self.update(n=starting, b=birthrate, i=imrate, e=emrate, d=deathrate)
c1.acceptor_id = c2.acceptor_id
m = np.random.normal(0, 1, size=(5, 2))
True
getattr(mod, kls_name)
fileobj = cStringIO.StringIO(strobj)
a[index] = float(value)
kde = stats.gaussian_kde(values)
color_segment(polygon_coordinates)
print(dir(p))
deleteself.indexdict[index]
to_sequence(range(5))
x = 0.0
sj.load(f)
pos_a, pos_b, size = s.find_longest_match(0, len(s1), 0, len(s2))
subprocess.Popen(console + cmd)
print(roundPartial(9.74, 0.1))
GeeElem(self.doc.getroot())
print(next(results))
True
gunicorn == 18.0
C = np.outer(A, B)
print(v)
self.memoized = {}
tuple(i / inch for i in tupl[0])
fig.clf()
total_seconds = turnaround.seconds + turnaround.days * 24 * 60 * 60
sct.norm.isf(q=0.05, loc=60, scale=40)
print(common_dict(json1, json2))
qmessage
resp = conn.getresponse()
doSomething(value)
x_itp = r * np.outer(np.sin(theta_itp), np.cos(phi_itp))
min_val = min(d.values())
self.period, frozenset(list(self.dimensions.keys()))
start, end = match.span()
merge(main, 0, 1)
key
filepath = os.path.join(root, name)
cap.destroyAllWindows()
start = time.time()
bar = request.args.to_dict()
self._results = []
a = [5, 8, 9]
out[i] *= 2
args = parser.parse_args()
word = models.CharField(max_length=255, unique=True)
pdb.post_mortem(traceback)
val = d2.get(k, 0)
salt = models.CharField(max_length=40)
print(start.dt)
res = collections.defaultdict(lambda : 0)
cd / System / Library / Frameworks / Python.framework / Versions
filtered_array[area_mask[id_regions]] = 0
d[s]
rows[i].pop(pos)
expr = Word(ch).setParseAction(lambda tokens: [ch, len(tokens[0])])
printTree(tree, child, nodeMap)
sleep_for_a_bit()
print(self.name)
do_something_with(database)
pyobj = ctypes.py_object(obj)
x = np.linspace(0, 4 * np.pi, 100)
(1)(1, 40020)
serializer = UserSerializer(queryset, many=True)
intersected = set(lists[0]).intersection(*lists)
p = random_derangement(N)
ret.append(result)
serializer_class = PurchaseSerializer
XGBClassifier(max_depth=10)
print(in_[0][i], out[0][i])
observer.join()
print(k, tally[k])
plt.figure().show()
fit2 = sm.tsa.ARIMA(df, (0, 0, 0), exog=exogx).fit()
p = Pool(12)
polynoms = [polyGen(i) for i in range(5)]
not len(unique_list) == len(set(unique_list))
d[t] = [next(iterator) for _ in range(n)]
MyModel(number=i).save()
df = pd.DataFrame(l, columns=l[0]._fields)
self.celery.wait()
a[:, (0)]
p2y = -tx2 * sinang + ty2 * cosang + cy
minm = np.append(minm, i)
df
df
x % m
min(list_date, key=func)
categories = [d for d in os.listdir(root) if isdir(join(root, d))]
model = db.StringProperty()
generator_fn.__code__.co_flags
print(row)
gevent.spawn(read_stream, p2.stdout)
df = pd.DataFrame(dict(A=np.arange(len(tidx))), tidx)
legline.set_transform(trans)
pywintypes27.dll
total = sum(amounts)
count += 1
sess = tf.Session()
d[k] = v
names = os.listdir(src)
x[x < -1000] = np.nan
self.pargs = pargs
mults = []
messages = inbox.Items
task = getattr(self, next_task_name)
print(columns[0])
es_tracer.setLevel(logging.DEBUG)
set.union(*l)
users.insert(1, users.pop())
d = defaultdict(list)
curses.use_default_colors()
g = lambda x: x + 5
do_something_with(start_date, list(group))
values = np.asarray(values)
args
point = [xF, yF, zF]
setofcols = set(tuple(x) for x in product.T.tolist())
l[i]
a = []
print ()
root = Tk()
file.write(b)
res = urllib.request.urlopen(req)
ax.barh(arange(len(x)), x, 1)
arithmetic_progression = itertools.count(start, step)
f.seek(pos)
old = np.concatenate([x[b:e] for b, e in zip(start, stop)])
math.sqrt(dot(v, v))
server_socket = socket.socket()
a ^ b
name = MyClass.__DefaultName
A += F[i, j] * V[(i), :] * V[(j), :]
print(df)
root_tree = {}
False
lengthB *= unitPpix[0, 0]
out[nr - 1:] = col2_2D
pool.close()
print(d.get(42, default))
contributions = user_profile.contributions_chosen.filter(**query_args)
outF.write(inF.read())
context = inspect.currentframe().f_back.f_locals
random.seed(4)
x[-9]
Y, X = np.mgrid[y.min():y.max():20j, x.min():x.max():20j]
locale.setlocale(locale.LC_TIME, lc)
next_run_date = d + timedelta(days=n)
num = abs(num)
A = np.arange(N)
instance = form.save()
stream_handler.setLevel(logging.INFO)
ftp = ftplib.FTP()
ctx = cairo.Context(surface)
ax.cla()
idx = np.argsort(r)
y = int(line.strip()) + int(line.strip())
print(s.model())
t = name,
ax.add_line(self)
str.upper(m.group(0))
active_window = GetWindowText(GetForegroundWindow())
server.start()
print(json_files)
assert response.status == 200
print(somelist[start:stop])
np.allclose(a[:, :, :, :, (0)].ravel(), collapse_dims(a)[:, :, :200].ravel())
solve([Eq(int_fx, m), Eq(int_gx, m)], (a, b))
print(myunique(a))
wrapper
PyUnicode_IS_COMPACT(op)
rot_matrices = np.empty((angles.shape[0], 2, 2))
sm.stats.normal_ad(x)
doc = libxml2.parseMemory(content, len(content))
x = np.linspace(0, 20, 100)
second = itemgetter(1)
df
curline += 1
print(obj.value.T)
np.clip(out, 0, 255)
product_obj = products.all()[0]
hash(str(self))
timer = threading.Timer(timeout, thread.interrupt_main)
C.__mro__
self._setup_queues()
result = []
ranks2 = dict(map(reversed, enumerate(sorted(dict2, key=dict2.get))))
BY = np.take(B, y + 1)
self._list[index]
treeaslist.extend(self.makeList(aNode.lChild))
wrapper.__dict__ = func.__dict__
my_namedtuple(final, first_step, second_step)
print(sorted(permutations(L), key=space_sum, reverse=True)[:100])
print(line)
x0 = self.canvas.canvasx(0)
c + 1
reset_index = np.cumsum(counts1)
d.a[i:i + k]
field2 = forms.IntegerField(required=False)
s.f2()
result.clear()
FACTORY_FOR = User
print(data)
df.loc[index_list]
-W900 - -ignore < catalina.log
alns_list.append(aln)
print(item)
tabin = [ord(char) for char in tabin]
raise KeyError(key)
print(first_user.name)
self._log.close()
v1_api.register(UserResource())
desired_capabilities.update(options.to_capabilities())
c = csv.writer(f)
scenario.skip(require_not_executed=True)
test_suite.addTest(unittest.makeSuite(UserServiceTest))
app = wx.App()
print(enu.count)
Thread.__init__(self, group, target, name, args, kwargs, Verbose)
testit
print(wx.GetDisplaySize())
Output = np.vstack((Output, data))
os.umask(0)
do_some_other_thing()
p.data = np.random.choice(np.arange(20) - 10, len(p.data)) / 10
print(b.shape)
fh.setLevel(logging.DEBUG)
x = np.random.random(100)
gg.plot(graph.data.values(x=dt, y=xcorr), plotstyles)
self.assertEqual(testuser, user.username)
NotImplemented
[comment.extract() for comment in comments]
pool = Pool(4)
df = s.groupby([s.index.weekday_name, s.index.hour]).sum().reset_index()
idx = np.arange(m.shape[1])
ignore[np.ma.maximum(x11, x12) < np.ma.minimum(x21, x22)] = True
USE_TZ = True
(df.location != df.location.shift()).cumsum()
post_save.connect(invalidate_portfolio_index, sender=Entry)
func(*args, **kwargs)
print(l)
self.name
even, odd = w[::2], w[1::2]
tOut = result[0].time()
print(df)
engine.block()
f = plt.figure()
y = (x + n // x) // 2
json_data = json.dumps(model_to_dict(user_obj))
WSGIScriptAlias / sauron / home / galdosd / finalsauronweb / django - root / apache / django.wsgi
temp = []
cipher = AES.new(self.key, AES.MODE_CBC, iv)
smtp_conn.starttls()
all(sympy.Eq(sympy.diff(expr, *t), 0) for t in combs)
lst = [0] * (r + b)
active_window = screen.get_active_window()
index = dict((tuple([n]), i) for i, n in enumerate(leaves))
Testing(8 / 8)
df.describe()
f = tar.extractfile(member)
lines = []
setattr(namespace, self.dest, mypass)
s.quit()
print(s)
sixgrams = ngrams(sentence.split(), n)
it = iter(list(range(4)))
array = np.empty(shape=(2, len(result)), dtype=float)
self.bind(b=self.set_c)
B = Y.imag
f(arg_b=0)
X, Y = np.meshgrid(xs, ys)
newcardID = card.id
kwargs[field_name] = getattr(model_instance, field_name)
print(list_bars[int(i) - 1])
self.comboBox = QtGui.QComboBox(self)
lines = iter(lines)
next(infile)
t.amount += 1
type(os.urandom(10))
bSizer.Add(button4, 0, wx.ALL, 5)
self.projectiles = []
roundup(100)
cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)
x = np.arange(0, 1000)
self.old_headers = self.br.addheaders
dic = {}
string[n]
args = inspect.getargspec(f)
np.set_printoptions(1, threshold=100, suppress=True)
self
trav(listD)
ax.set_ylim(-1, 9)
self.data = self.request.recv(1024)
p.search(s)
False
result = np.cumsum(some_array)
print(self.some_param)
fig = plt.figure(figsize=(11, 11))
q = Queue()
len(word) > 5
repeatlist(B, len(A))
data = []
greater.append(x)
foo.bars.add(bar2)
self.items.extend(other.items)
df1.join(df2)
self.linkHovered.emit(anchor)
seen.add(n)
dom = parseString(data)
conn.endheaders()
form = SQLFORM(db.foo)
plot(time, y2)
length = int(s)
self.var1 = par1
outfile.write(out)
name = models.CharField(max_length=64)
buf = f.read(8192)
self.turnnow,
app = QtGui.QApplication(sys.argv)
self._host = host
distance_vectors = [x[0][0] for x in distance_vectors]
func(a=2, b=6, c=8)
X = iris.data[(iris.target == 0) | (iris.target == 1)]
app = Flask(__name__)
handler = logging.StreamHandler()
seqlen = len(seq)
canvas.print_png(png_output)
plt.loglog(x, y, basex=np.e, basey=np.e)
df = pandas.DataFrame(data=numpy.random.random((m, n)))
print(df)
self.value = value
print(a + 2)
tk.Frame.__init__(self, master)
output[0].lower() + output[1:]
c1 = csv.reader(f1)
print((a,))
d = defaultdict(bool)
conn.send(result)
df = pandas.DataFrame(a).groupby([0])
list({song.album for song in self.allSongs})
x = np.sort(x)
movie_dict[actor] = [key]
sample_size = 0
print(mkl_get_max_threads())
print(etc.__file__)
values = np.atleast_2d(func(points))
b = [(binsize * k) for k in range(imin, imax + 1)]
entries = [list(entry) for entry in entries]
(2009, 1, 1), datetime.date(2009, 1, 19), datetime.date(2009, 2, 16)
koch_fractal(yertle, 2, 100)
str(self.matrix)
pool.close()
df2[df2.mi.isin(df2.mi.value_counts() > 2)]
[10, 9, 8, 9, 10, 11, 10, 9],
result.append(self.visit(z))
data = yaml.load(txt, yaml.SafeLoader)
r = f.read()
termf = Frame(root, height=400, width=500)
y.remove(i)
self.children.count()
l1[0:1] = l2
item[0], int(item[1][1:] or 0)
conn.login(account)
list(dic1.keys()) | dic2
df5.head(10)
s.a.b.c.d
sys.stderr = _LogWriter()
self.remove_unpickleable_attributes()
cmd_parts.append(password)
mahotas.polygon.fill_polygon(pts, canvas)
str(self.__dict__)
myhelp = buffer.getvalue()
id = models.AutoField(primary_key=True)
self.memo[str] = self.fn(*args, **kwds)
ylim([-4.5, 4.5])
method
1 < {}
pure = np.linspace(-1, 1, 100)
ax = fig.add_subplot(111)
conn.login(user, passwd)
l2_copy.remove(i)
y = np.sin(x) + np.random.random(N) * 0.2
bufsize = 0
cert = ssl.PEM_cert_to_DER_cert(cert)
print(template.format(*map(str, l)))
nonoverlapping = (ranges[1:, (0)] - ranges[:-1, (1)] > 1).nonzero()[0]
binsm = (bins[1:] + bins[:-1]) / 2
s.prompt()
self.remove_fields_from_representation(representation, remove_fields)
signal.signal(signal.SIGALRM, alarmHandler)
{{login_form}}
parser = HTMLParser(recover=True)
new_save
cursor.execute(stmt)
name = models.CharField(max_length=255)
Decimal(0.1)
self.weights = []
dict(list(kwargs.items()) + zip(spec, args))
starts = np.hstack(([0], nonoverlapping + 1))
process = subprocess.Popen(command.split())
app.exec_()
loop = asyncio.get_event_loop()
result = {t: [p for p in prefixes if t.startswith(p)] for t in targets}
globs = frame.f_globals
new_value = f([getattr(base, name) for base in cls.__bases__], old_value)
fig = pylab.figure()
colors = cmap(np.linspace(0, 1.0, len(kinds)))
x, y, z
ModelName = Column(Unicode(255), nullable=True, index=True)
x = np.linspace(0, 1, 1000)
width = int(cap.get(cv2.cv.CV_CAP_PROP_FRAME_WIDTH))
app_api = Api(self.app)
colb[n] = 0
result = map(_fuc1, samplez)
(b.A == 2) & (b.B == 2) & (b.C == 2)
self.wealth = 1.0
df.index.freq
sorted((c for c in nx.simple_cycles(DG) if node in c), key=len)[0]
result.append(self.indent(s))
tf.reduce_sum(tf.mul(tensor, identity_matrix(n)), [0])
aaaa
mvMatrix = glutils.lookAt([0.0, 0.0, -2.0], [0.0, 0.0, 0.0], [0.0, 1.0, 0.0])
self.stream.parse(data)
BEGIN
print(match)
sportDict[ransport].append(name)
person.items.update(other.items)
transaction.enter_transaction_management(using=self.db)
yaml.add_representer(np.ndarray, opencv_matrix_representer)
self.serialc.quit()
print(df)
y = np.mean(X, 0)
binary_insert(r, Node(5))
l[i]
print(os.name)
variable = client.get_spot_price()
self.cursor.execute(sql, args)
repo.remotes.origin.pull()
acc_test = accuracy_score(y_test, y_pred)
df6 = df.ix[:, 60:72]
main()
x = np.linspace(1, 5, 10000)
test_func()
records.append(record2)
stdout = sys.stdout
map(chr, list(range(65, 91)))
d[k] = int(v)
scene.camera.location.y = ty
q = q.filter(or_(*conditions))
sys.setrecursionlimit(maxint)
print(new_dict)
sps_acc = sps_acc + sps.coo_matrix((d, (r, c)), shape=(rows, cols))
b = 2
df = tempDF
print(d1 + td(days=i))
sibling = page.find_next_sibling()
myarray[(myarray >= 2) & (myarray < 5)] = 100
os.getcwd()
show()
print(guess_seq_len(list_a))
c = count_events(e)
[self.combine(x) for x in X]
main()
[server - symlinks]
page_sanitized = json.loads(json_util.dumps(page))
indices = np.vstack(np.unravel_index(np.arange(x * y), (y, x))).T
self.a = a
temp = [item for sublist in listD for item in sublist]
print(t)
moreVerbs.extend(getVerbsFromConjunctions(moreVerbs))
ax.plot(x, y)
popt_pl, pcov = curve_fit(pl, x, y, p0=[0, 0, 0, 0])
self_dict[attr]
resid.flatten()
ftp_handle.cwd(original_cwd)
platform.uname()
output.put((pos, rand_str))
time_in_seconds = int(time())
c.append(itemgetter(i)(a))
getsizeof(dict((n, 0) for n in range(5461))) / 5461.0
(np.convolve(np.convolve(A, K) >= WSZ, K)[L:-L] > 0).astype(int)
a = X()
length = ctypes.c_ulong(0)
ndb.put_multi(users)
process(line)
page = paginator.page(1)
outputdict = sqlcol(df)
serializer_class = UserSerializer
filters.append(Q(is_default=False))
InteractiveConsole.__init__(self)
y = sum(x > i for i in x)
self.limit = 10
list(seen_twice)
arr = sparse.coo_matrix((data_f, (rows_f, cols_f)), df.shape, dtype=np.float64)
print(sys.getrefcount(X))
html = Template(fp.read())
writer.writerow(row + [to_append])
yertle.begin_poly()
t.show()
diag = np.ones(n - 1)
t.start()
x, y
b = datetime.now()
reader.Close()
wb = Workbook()
asc.append(i)
dt - timedelta(seconds=time_tuple[-1])
TYPES[type_name].from_dict(value)
dis.dis(my_fun)
print(filename, lineno, strrepr)
os.setgroups([])
print(df.star_name)
df_list = []
instance = reservation.instances[0]
rate = lambda t: 200 * exp(-t) if t > 200 else 400 * exp(-t)
form = DjForm(data=data)
document.exitFullscreen()
a = f()[0]
bar.close()
idx = np.ravel_multi_index(arr, arr.max(1) + 1)
False
type(d)
session = sessionmaker(bind=engine)()
cap0.set(4, 120)
ax = fig.add_subplot(111)
print(sum(2, 4))
candidates = [base for base in bases]
print ()
print(a)
f.write(content)
st = time.time()
serial.flushOutput()
True
marshal.dumps(code)
new_map = [[x, y] for x, y in a_map if not (x < 0 or y < 0)]
DOT11_CIPHER_ALGO_WPA_USE_GROUP = 256
HTML(style + df_html)
a[0]
news = News.objects.filter(pk=news_id)
crontab - e
self.q.put((True, msg.errorCode, msg.errorMsg))
result.append(dictionary[last_match])
setattr(targetCls, name, wrap(name, func))
t = d.unique()
_install_lib.run(self)
self[key] = kwargs[key]
print(T(data[0], 0.29, 4.5))
fr.close()
type = models.CharField(max_length=255)
timezone.make_aware(d, timezone.utc)
tocopy_wb.Sheets(1).Cells.Copy()
framenp = np.fromstring(framestr, dtype=np.uint16).reshape((1024, 1280))
MyArray([(k, self.data[k]) for k in key])
length = np.random.random(10)
type(foo1)
self.module = importlib.import_module(module_name)
print ()
self.data[self.size] = x
self.data[idx] = item
y = time.time()
sub_compunds.extend(generate_sub_compound(tok))
data = file.read(1024)
input = request.json
newlist = [temp[0]] + [([0] + i) for i in temp[1:]]
s.close()
f()
serverEndpoint.listen(factory)
[str.upper() for str in args]
print(metrics.confusion_matrix(y_test, y_predicted))
Base = declarative_base()
comment.replace_with(tag)
self.master.wait_window(self.w.top)
high = len(input) - 1
f(d, name)
list_of_lists = []
b = np.arange(0, 5)
g += b
print(sorted(values.items()), expr.subs(values))
foo.bar
instance
sum(max(die().roll_until(6) for i in range(6)) for i in range(n)) / float(n)
self.cs = LockableCursor(self.connection.cursor())
block_list.append(y)
out.stop()
current_command = random.choice(commands)
self.filter(owner=owner)
head(d, 10)
pairs_by_number_and_list = collections.defaultdict(list)
mylist = mymethod()
ax.hold(True)
B = np.vectorize(inds.get)(A)
foo_dir = os.path.dirname(os.path.join(os.getcwd(), __file__))
self[:1] = []
a[np.arange(a.shape[1])[:] > a[:, (0), (np.newaxis)]] = 0
getattr(p, s)
x_a = points[..., :-1][..., (mask)]
a.shape
name = models.CharField(max_length=50, null=False, blank=False)
replacements[mo.group()]
m.show()
data = os.read(STDIN, 1024)
profile = pform.save(commit=False)
np.random.seed(0)
older_books.append(books.title)
x = np.linspace(0, 20, 500)
f.__dict__
dis.dis(lambda : Foo.bar.add(1, 2))
indexes.append(int(index))
data = s.readframes(nf)
print(args_dict)
partial(operator.mod, b=i)
createdate = subprocess.check_output(args)
np.conj(x, x)
fig, ax = plt.subplots()
urlparse.urljoin(response.url, extractedLink.strip())
next(it2)
__DBNAME__ = name
ax.stem(x, y)
result
locale.getdefaultlocale()
self.close_button.pack()
turtle.pendown()
result = dict(curs.fetchall())
date_ = date.today()
cooMatrix = sparse.coo_matrix((ones, (edges[:, (0)], edges[:, (1)])))
df = df.swaplevel(0, 1, axis=1)
map(eq, a, b).index(False)
self.parent.vLayout.insertWidget(1, self)
quit = True
self.layout.addWidget(self.btn_run)
cursor.close()
wx.Panel.__init__(self, *args, **kwargs)
self.sock.sendall(data)
Kiwi
run.py
res
layout = QHBoxLayout(self)
df + 2
compose1(f1, f2)
res.fill(np.nan)
start = datetime.datetime.combine(today, start)
pdf.closed
u = User.query.get(id)
article = get_objects_or_404(Article, pk=id)
dsqrd = (y2 - y1) * (y2 - y1) + (x2 - x1) * (x2 - x1)
l[:n] + [0] * (n - len(l))
series.fillna(0)
translation.deactivate_all()
a = np.arange(20).reshape((4, 5))
my_data = np.random.random((210, 8))
print(string1[match.a:match.a + match.size])
angles = np.linspace(0, 2 * math.pi, n_angles, endpoint=False)
x, w = leggauss(deg)
plt.legend()
print(enclosing_class())
texter.show()
df = pd.read_csv(fo)
sieve()
fun = self.weak_fun()
bins_labels(bins, fontsize=20)
self._picked_indices.append(index)
getattr(value, arg)
result = list(queryset_1) + list(queryset_2)
icS = scipy.linalg.inv(cS)
c = get_redis_connection()
s.add_dependency(tasks[p[0]], tasks[p[1]])
ba = bytearray(c)
handler = logging.StreamHandler()
assert n > 0
groups = []
list_of_files.push(file)
file.close()
print(x, y)
bar_id = Column(Integer, ForeignKey(Bar.id))
n1 += 1
replchars = list(replstr)
response
self.resize(600, 400)
price_series.pct_change()
self.filename = tkFileDialog.askopenfilename()
results if len(results) != 1 else results[0]
f2.print_world()
img.save(js.framebuffer)
url_queue.put(1)
y = NP.row_stack((fnx(), fnx(), fnx()))
y = y[indices]
model.add(e)
unique_a.view(a.dtype).reshape((unique_a.shape[0], a.shape[1]))
globals()[func_name] = getattr(m, func_name)
fig = pyplot.figure()
hist = np.histogram(A, bins=bin_count)
results = service.files().list(maxResults=10).execute()
masked_array = np.ma.array(a, mask=np.isnan(a))
print(a, b, c)
tt.Index(1).Set(eb)
result
axis = PlotAxis(tick_generator=tick_gen)
v = np.arange(100).reshape(10, 10)
self.d[k] = v
tar = tarfile.open(fileobj=file_like_object)
logger.info(result.get())
result.append(dictionary[match_parts[i]])
np.frombuffer(mp_arr.get_obj())
city_type = db.StringProperty()
plt.xlim(50, 70)
big_df = df.copy()
self.cdfunc = cdfunc
pl, u = lu(a, permute_l=True)
s = len(l)
result = np.array([np.sum(corr_time1(t, JM1, JM2)) for t in t_output])
cls
print(intdate2date(20160618))
DD, EE, FF
f1.close()
xs = ys = np.arange(0, 1.01, 0.01)
len(l)
G = nx.complete_graph(20)
b.close()
zipdata.write(get_zip_data())
2, 2, 5
sherr = []
combs += combinations(remove(e, elems), m - 1)
n += 1
print(dis.dis(f))
ch = screen.getch()
print(name)
pst_dt.strftime(fmt)
a = 20
value = value.strip()
getattr(self._queue, name)
result
axs[1].xaxis.set_minor_locator(x_minor_lct)
y = np.empty(s.size, dtype=np.int64)
[queue.get() for queue in queues]
self.name = zipinfo.filename
value = datetime.date(1, 1, 1)
F = list(S1)
pyperclip.paste()
new_d[key.upper()] += val
field = self.fields[field_name]
_build_ext.finalize_options(self)
df
lines.append(line)
ipx
myList = []
print(e.inserted_primary_key)
max_value = value
1 / 1024.0
random.choice(list(self.__cache.values()))
all_keys.add(k)
headers.customContextMenuRequested.connect(self.header_popup)
self.val += 1
liPos = [(a, b + 1) for a, b in liPos]
x = 2
self.x, self.y = x, y
ax.plot(1 / u * cos(phi), 1 / u * sin(phi))
Include / etc / apache2 / conf.d / phppgadmin
res = OrderedDict()
new_soup = bs4.BeautifulSoup(new_html)
n = -1
GMax_idx = np.where(neg_y_grad == GMaxI)[0][0]
merge_dict(v1, v2)
response
p_file = frame.f_back.f_code.co_filename
tuples_in_nxn = [divmod(x, n) for x in numbers_in_nxn]
width
self.button = QtGui.QPushButton(self)
divs[j][1] += divs[i][0]
c = db.cursor()
fields = []
print(test[0])
im2 = Image.fromarray(data)
retval += chr(node[1][0][1])
list(range(item.start, item.stop))
frame = inspect.currentframe()
args = parser.parse_args()
rows = cur.fetchall()
df = areas.apply(multiply_by_demand).unstack(0)
value = mc.get(key)
word_len = _len(word)
print(tests.test_002)
button.click()
hist, _ = np.histogram(values, bins=[1, 4, 7, 10], weights=freqs)
print(x)
y = np.array([1, 2])
body = []
d = defaultdict(list)
decoder.process_raw(buf, False, False)
B = np.zeros_like(A)
assert sides[0] + sides[1] >= sides[2]
urllib.request.HTTPSHandler.__init__(self)
df
df
df
result
base_d = datetime.strptime(base_date, fmt)
File.Delete(FilePath)
type([]) is list
df_new
normal = [sin(tF) * cos(pF), sin(tF) * sin(pF), cos(tF)]
df.iloc[-6:-1, (2)].values
self.button.bind(on_release=self.button_click)
help(scipy.special.erf)
sorted_objs = sorted(list(dic.values()), key=signature)
loop.run_until_complete(low_level())
execute_sql(s)
np.diff(np.hstack((0, run_ends, nums.size))).max()
ndX = PyArray_NDIM(X)
a[0, 0, 1] = [0, 0, 5]
top = min(len(a1) - 1, len(a2) - 1)
cosine(pink, car)
a.bar
comma_ending_prettyprint(row, stream=outfile)
s.get_available_ranges()
df = pd.read_csv(filename)
do_something(val)
imshow(resultScaled.astype(uint8))
object_serializer_class = MyModelSerializer
index_type()
nxt = _st + timedelta(days=1)
queryset = User.objects.all()
driver = webdriver.Chrome(chromedriver)
l = list(range(100))
sys.stdout.write(session.recv(4096))
print((count, p))
app().mainloop()
API_ERROR = 1
power(lambda x: x * 2, 2)(9)
clf.fit(iris.data, iris.target)
pd.Series(factors, df.index).apply(np.binary_repr, width=width)
cur_set.append(A[index])
start = time.time()
lft = [([0] * i) for i in range(n_rows)]
map(word_tokenize, texts)
someSignal = QtCore.pyqtSignal(int, QtGui.QWidget)
Point(self.x - point.x, self.y - point.y)
ts = np.concatenate(ts)
d[k] = v
p.is_running()
x, y, w, h = cv2.boundingRect(cnt)
oAccess.Quit()
gg.plot()
n_points = len(points)
L = [0] * 10
os.mkfifo(logfilepipe)
lvls = np.concatenate((lvls[:-1], np.linspace(1000, 10000, 5)))
orders = models.ManyToManyField(Order)
statement = query.statement
print(nonsub)
self.environment.handle_exception(exc_info, True)
value[0] += 1
merge(value, node)
dis.dis(lis[1])
len2 = math.hypot(x2, y2)
person = models.ForeignKey(Person)
r.append(-1)
{(8): 8, (6): 6, (7): 7}
stdout, stderr = proc.communicate()
ax1 = fig1.add_subplot(221)
numloss += 1
a
slice(0, 0, step)
popd
self._classes[cls.__module__, cls.__name__] = cls
y = [0] * n
salt = bcrypt.gensalt()
t = datetime.now()
soup = BeautifulSoup(text)
count += 1
self._fig = Figure()
print(regex.findall(test))
x = 0
repr(0.01)
sns.distplot(x, ax=ax, rug=True, hist=False)
edges = zip(rows.tolist(), cols.tolist())
asdas
cluster_lookup = dict((node, i) for i, node in enumerate(graph.nodes))
shom_im(cir)
res_list.append(res)
tz_aware_dt = dt.replace(tzinfo=UTC)
isitIn(char, aStr)
root = tk.Tk()
count += countnodes(ele.left, 0)
BEHI
CFHJ
AC
thread.start()
output = [(first, second) for first, (second, count) in list(d_max.items())]
best_merit_yet = merit2
f.close()
print(repr(x), ucd.category(x), ucd.name(x))
lists = list(filter(len, lists))
idx = np.floor(input).astype(np.int)
duplicates = [keys for key_str, keys in reverse_d.items() if len(keys) > 1]
x[-44]
decorator
input_from_xpath = driver.find_element_by_xpath(path)
category = models.ForeignKey(Category)
a.insert_node(a.root, 2)
bar = Bar()
QtGui.QDirModel.flags(self, index) | QtCore.Qt.ItemIsUserCheckable
dat = gauss(x, amp, cen, sig) + np.random.normal(size=len(x), scale=0.1)
w.grid()
print(parser.prog)
self.im.putpalettealpha(i, a)
counts = Counter(seq)
np.random.seed(0)
ip = get_ipython()
loop = asyncio.get_event_loop()
res = []
suite.addTest(unittest.defaultTestLoader.loadTestsFromName(t))
HTH += HTHflips
info = json.loads(details)
newArray = copy(theArray)
print(log.text)
repr(self.tokens[0])
indices[indices >= arr.shape] = clipping_value
do_staging_stuff()
serializer_class = MyModelSerializer
()(())
self.__dict__.update(kwargs)
config = ruamel.yaml.load(open(file_name), ruamel.yaml.RoundTripLoader)
inner
self.waiters.append(new_lock)
MooBase.metadata.create_all(engine)
[5, 17, 8, 7]
pylab.show()
value = json.loads(jsonValue)
app = wx.PySimpleApp()
spreadsheet = client.open_by_key(docid)
c = x = x + 1
total = sum(g[1] for g in group)
net.sortModules()
n = [(1.1, 5), (2.4, 7), (5.4, 6), (9.8, 14), (10, 4)]
pix = pixl.get_pixbuf()
groups = result.groups()
print(f())
y = numpy.zeros(x.shape)
arr = shm.zeros(N, dtype=np.uint8)
user_input.append(entered_text)
deferred.addBoth(callback)
new_x, new_y = x + new_dx, y + new_dy
print(mydata)
ok = True
print(soup)
B = A[::-1, :]
self.addCleanup(patcher.stop)
l.insert(0, y_axis[i])
f(x[:, (t - 1)], params, x[:, (t)])
infinitedict = lambda : defaultdict(infinitedict)
alist.append(1)
print(insp.get_table_names())
plt.show()
readRequest += chr(self.transactionID / 256)
sys.stdout.write(c)
self.line = line
image_db.close()
Color(*[r, g, b])
B.shape
json.dumps(f(*a, **k))
fig = plt.figure()
data = numpy.fromiter(points, float)
dowrap
REDIS_CONNECT_RETRY = True
bar()
two = np.empty(three.shape, dtype=object)
roots = np.polynomial.polynomial.polyroots(poly_coeff - [99, -1, 0])
elem.clear()
df = pd.read_csv(fo)
z = {}
indices = np.array(list(range(len(a))))[inter]
print(qr.data)
a.dtype = newtype
main()
key = bucket.new_key(filename)
print(repr(binary_split_array[0]))
out_put.append(participation_details)
idx = np.unique(idx)
r[:, (0)]
self.obj.my_attr == other.obj.my_attr
(0)(1, 40020)
ax
print(dumps(bob))
body = s.to_dict()
data.shape
ax2 = ax.twinx()
smtp = smtplib.SMTP()
output = cmd.communicate()[0]
logger = logging.getLogger(__name__)
words = f.readlines()
connections.append(connection)
out = np.zeros((a.shape[0], a.shape[0]))
main()
cursor = conn.cursor()
queue = Queue.Queue()
total = 0
bytesPerSector = ctypes.c_ulonglong(0)
x0, y0, z0, w0 = np.split(quaternion0, 4, axis=-1)
subprocess.Popen(args0)
i += 1
G, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0
sub(a)[:] = np.ones((2, 2))
sentencecount = 0
self.sum
find(resolved)
conn.close()
path = Column(ARRAY(Integer))
response
m = [([0] * n_classes) for i in range(n_classes)]
pprint(d)
self.update(*args, **kwargs)
obj.my_custom_method()
print(totals[totals.argsort()])
map(double, list_[1::2])
fetch(r)
Mx = np.zeros((n, n))
list2 = [x for x in list1 if x]
outputlist = []
source = ColumnDataSource(data=dict(x=[0, 1], y=[0, 1]))
ax1.imshow(bw, cmap=plt.cm.gray)
ibm_db.execute(query_stmt)
MyIterator(list, random.sample(list(range(n)), k))
lens = np.array([len(item) for item in v])
next(self)
canvas.Canvas.showPage(self)
self.assertEqual(result, (self.v.version, self.v.prerelease))
b[c]
ax = fig.gca()
field
notes = Notification.objects.filter(user=self.user)[:4]
y = pow(x, p - 2, p)
(True != False) != False
indices.append(index)
saver = tf.train.Saver()
print(self.server.conn)
Date(date.year, date.month, date.day)
autostart = true
_mydecor if clams else _myclassdecor
hm.start()
a, b = [float(s) for s in line.split()]
foo_on_scalars(x)
num = 0
HTMLParser.feed(self, data)
x.isupper()
print(contents)
arr = np.sum(np.exp(-4 * abs(val - val.reshape(len(df.index), -1))), axis=0)
counts, sums = Fenwick(len(a)), Fenwick(len(a))
myseries_two.loc[0]
g(arr, numbers, i + 1)
cls
USE_X_FORWARDED_HOST = True
numsum = sum(list(numbers))
box = ax.get_position()
model = QFileSystemModel()
new_func.__code__ = code
result = tuple(islice(it, n))
mask[np.triu_indices(len(df))] = False
print(nextfetch)
foo.bar - foo.baz
data = np.random.random((1000, 10))
s = list(iterable)
a = [(lambda y: lambda x: y * x)(i) for i in (1, 2)]
c = Counter(words_to_count)
root.remove(element)
False
print(optimize.fixed_point(func, 0))
datam = np.zeros_like(data)
lines_seen = set()
stophttp = threading.Thread(target=httpd.shutdown)
dump(outdata, 5, 6)
time.sleep(0.01)
print(s)
self._foo = val
dt = aware_utc_dt.astimezone(tz)
y = x.__add__(x)
le.transform([1, 1, 2, 6])
answer.append((L1[tuple(row)], i))
result = comment.upper()
func2()
hamming_sets[0].add(l[0] + l[1])
image.data = f.read()
doSomething()
True
bnds = tuple((0, 1) for x in start_pos)
globals().update(load_dictionary(fpath)[0])
o4 = int(ipnum) % 256
x + x
exifdict = im._getexif()
df
randint(range_start, range_end)
np.vstack((np.zeros(shape), data))
{4, 5, 6},
list(map(set, out))
show(p)
y = foo()
d[key_list[-1]] = params[key]
self._locked
draw = ImageDraw.Draw(img2)
fin.seek(start_index)
b = [6, 7, 8, 9, 0]
list(islice((x for itr in (l, repeat(0)) for x in itr), n))
bar.set_hatch(hatch)
a = numpy.array([0.0, 0.25, 0.75, 1.0])
queryset.get(slug=self.slug)
[MyObject(), MyObject()]
x, y = data.T
print(int_array)
df.C
just_object_result = array_result[1:-1]
diff_as_html = ghdiff.diff(markdown1, markdown2)
print(dict_mul(dict1, dict2))
handle_results(proc.stdout)
current_string_split[-1] += s[j]
weights = numpy.array([0.5, -1])
assert e.errno == errno.WSAECONNREFUSED
np.array([inner(row, *args, **kwargs) for row in vec])
prevnode.left == node.right
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
first.append(ele)
list(foo() for x in range(10))
startpos = text.rfind(alpha, 0, endpos - len(alpha)) + len(alpha)
L.append(x * k)
primes = [p for p in table if p][1:]
pymysql.install_as_MySQLdb()
found = True
data = json.loads(ninja_json)
q.join()
Y += 0.1 * np.random.random(N)
k = int(round(n * (float(percent) / 100) / 2))
a[something]
x[(0), 48:52]
j = json.loads(data)
form
app.MainLoop()
a = 1
socket.send(args.bar)
config.write(fp)
self.q.task_done()
show_error()
set(chain.from_iterable(periodic_gs[key].nodes() for key in periodic_gs))
rest = list(it)
Y.append(y)
type(sys.maxsize + 1)
exitonclick()
response = requests.post(searchUrl, files=multipart, allow_redirects=False)
NULL
y.sort()
serializer_class = UserSerializer
a = [5, 8, 9]
d = OrderedDict()
type(d)
form.category_select.choices = [(key, categories[key]) for key in categories]
args = []
A = matrix([[0, 0, 0, 1], [0, 0, 1, 0], [0, 1, 0, 0], [0, 0, 0, 0]])
t.print_exc()
result.add(word)
result.add(item)
print(df.dtypes)
result.append(next(g))
thread.join()
serializer_class = UserSerializer
self._current_message = qmessage
self.children = []
price = forms.DecimalField(required=False, max_digits=6, min_value=0)
ax.plot(arange(10), rand(10))
print(x)
sum(val * self.weights[i] for i, val in enumerate(inputs))
result = cache.get(key)
newDict = []
logging.basicConfig(format=FORMAT)
159575276
m = alen(t)
countec = [0] * len(ec2j)
m = MyModel(**data_dict)
entity.after_delete()
extractedData = data[:, (idx_IN_columns)]
distancesDF = pd.DataFrame(distances)
root.after(0, download_chunk, readsofar + len(data), chunksize)
print(data)
self.SetTopWindow(frame)
(0, 10) == 0, 10
result = pool.apply_async(f, [10])
row = rows[0]
as_list = list(eval(args))
offset = lst.index(element, offset + 1)
mypad.scrollok(True)
__import__(modname)
result[last].append(obj)
print(one, two, three)
result |= Counter(d)
int(hex(200 - (1 << 16))[-4:-2], 16)
print(f(1.0, a=-1.0, b=1.0, n=4))
recall_accumulator.append(recall_score(y_true, y_pred, **kwargs))
reactor.connectTCP(host, PORT, BlastFactory())
hover.perform()
x1, y1, x2, y2 = lines[i][0]
raise AttributeError
hfile.seek(-bsize, os.SEEK_CUR)
X = np.asmatrix(np.arange(N * N).reshape(N, N))
self.delegate = delegate
print(a)
attributes = inspect.getmembers(MyClass, lambda a: not inspect.isroutine(a))
self.run_console_command(line)
cmap_lin = cm.jet
f.close()
count = 0
plt.scatter(x, y, c=color, s=90, alpha=alpha)
ret0, frame0 = cap0.read()
Lv.append(last)
i += n + 1
grouped_df = df.groupby(group_id)
print(z.namelist())
labels2 = plt.clabel(CS, inline=1, fontsize=12)
self.name = name
jobs = multiprocessing.Queue()
asyncio.set_event_loop(eventloop)
f.add_done_callback(set_if_success)
_repr(o)
print(np.shape(c))
result = func(*args, **kwargs)
a.update(b)
self.loadFinished.connect(self._result_available)
do_once = {t: False for t in output_file_names}
isinstance(inst, self._decorated)
iter(x)
arr[i:size + i]
0
is_active = models.BooleanField(default=False)
parliament = models.CharField(max_length=128)
shutil.rmtree(self.__str__(), onerror=delete_dir_handler)
reader.close()
my_global_fun(data)
start = time.time()
C = np.empty(N, dtype=int)
funcList.append(factory(m))
0
heapq._siftdown_max(heap, 0, len(heap) - 1)
datalines_str.info()
pool.map(func, input_sequence)
~array
counter = Counter(line.split()[0] for line in fp)
k, v = next(iterator)
serializer = self.get_serializer(queryset, many=True)
self.__dict__[key] = item
df.date1 = pd.to_datetime(df.date1)
x
loop = asyncio.get_event_loop()
IOLoop.instance().add_timeout(time.time() + 5, self._process)
self.height = self.winfo_reqheight()
password = forms.CharField(widget=forms.PasswordInput)
first_day_of_month = datetime(now.year, now.month, 1)
theta = np.deg2rad(angle)
z.close()
match = pattern.search(lines)
print(client.wsdl)
df
visited.append(i)
list2.insert(i, x)
time.sleep(0.45)
ipython - -matplotlib
no_background.append(orig[:, (i)] - np.median(orig, 1))
data = [tuple([d[0], dict(size=int(d[1]))]) for d in data]
print((a, args[a]))
self.panel = wx.Panel(self)
it = iter(numbers)
Blob.__init__(self, width, height, color, emphasis, highlight)
percentageDifference = 100 * float(difference) / len(a)
z.close()
l2 = []
self.grid(sticky=W + E + N + S)
numpy_surface = numpy.frombuffer(surface.get_buffer())
amount_to_pad = self.block_size
deleten_lst[-1]
response
df = DF[DF.isin([eq]).any(1)].reset_index(drop=True)
projected_data = np.dot(data, eigenvectors)
plt.xlim(xmax=2)
func(*args, **kwargs)
newobj
sts = os.waitpid(p.pid, 0)
a[0]
siftDown(A, start, len(A) - 1)
cur = conn.cursor()
print(dt)
d.func1(name)
count[w] += 1
i += 1
dot_product = np.dot(normal, unit_ray)
np.random.seed(0)
extractor.runInParallel(numProcesses=2, numThreads=4)
self.cntrlPanel.Show()
file.seek(sequence_start, 0)
print(norm.ppf(y))
sum(opt(value) for opt, value in zip(ops, lst))
permutations[tuple(sorteditems.index(item) for item in items)] += 1
a, b = tee(iterable)
print(group)
value
A = np.random.rand(N, N, N)
min(scores)
self.__c
active_required(my_view)
days[index:] + days[:index]
maxsentences = random.randrange(1, 5)
d = {}
lst = [5, 20, 15]
df_bad_idea.sum()
firstLine = infile.readline()
fd, filename = tempfile.mkstemp()
x = np.linspace(0, 10, 20)
all_data = all_data.append(df, ignore_index=True)
z.write(os.path.join(absdir, f), os.path.join(zip_dir, f))
result = []
self._value + n
self.assertEqual(200, res.code)
mean_of_distribution = numpy.mean(data)
sio.seek(0)
g.head(2)
PorterStemmer().stem_word(word)
vecData.columns = vec.get_feature_names()
list(range(5))
self.notifyObservers(old, self.value)
f = tempfile.TemporaryFile()
data = urlfile.read(chunk)
response = service_request.execute()
d = {printer(i): printer(j) for i, j in t}
Add()
self.ses.post(url_auth, data=my_dict)
res = {}
d = {}
out[-1].append(ele)
lilfoo = Foo()
out = StringIO.StringIO()
self.name
self.my_float_layout.add_widget(self.button)
a = []
p1 = figure(plot_width=900, plot_height=500, y_range=[8, 10.5], tools=TOOLS)
module_obj = __import__(module)
self.timeout.reset(_timeout)
file.close()
d = {(1): 2}
self.int2base(self.current - 1, self.base)
display.start()
a, b, c
datadex[x] + 1
val = np.fromiter(list(d.values()), int)
op = s.pop()
foo = MyClass()
f_set = f[(f.year >= 2002) & (f.year < 2010)]
(2 < arr) ^ (arr < 6)
funct(*args, **kwargs)
cat.save()
ax.hold(True)
timer.timeout.connect(tick)
settings.py
est = stats.pareto.fit_fr(rvs, 1.0, frozen=[np.nan, locest, np.nan])
plot(t, s2)
obj = C()
self.closefd = closefd
te = time.time()
1
proj_path = os.path.dirname(script_path)
issubclass(bool, int)
x
request = HttpRequest()
args = parser.parse_args()
dothis(item)
print(form)
ch.setLevel(logging.INFO)
a + b + c
val = [len(list(g)) for _, g in groupby(l)][-1]
n_component = np.array([curvature * ds_dt * ds_dt] * 2).transpose()
a, c
tokens = astr.split()
setup(**configuration)
check_thread.start()
ax.scatter(xs, ys, zs)
b = Swallow()
[]
result = remove_rows(df)
cax = fig.add_axes([0.27, 0.8, 0.5, 0.05])
os.kill(pid, SIGTERM)
csvdata.set_index(mergecols, inplace=True, drop=False)
cPickle.dumps(d, -1)
complements.append(2 ** (depth + 2) + 1)
fhd.close()
edgePoint.y += self.bounds.size.height / 2.0 - self.center.y
file_name = part.get_filename()
c = get_config()
x, y = [], []
parser.print_help()
ratings_rdd = transformed.map(lambda r: Rating(r.user_id, r.item_id, r.rating))
c = [comb for i in range(n) for comb in combinations(x, i + 1)]
searchbox.clear()
a = np.arange(N)
points.append((1, 0))
self.k = min(k, len(train_data))
hour, minute = divmod(int(hhmm), 100)
seen = set()
GLX.glXMakeContextCurrent(d, w, w, context)
scnt += 1
fig = figure()
print(datetime.datetime.now() - now)
then = time.time()
arr2 = np.zeros((arr.shape[0], arr.shape[1] + column_pad))
obj = {}
fig = plt.gcf()
print(format % tuple(row))
frame1 = cv.QueryFrame(video1)
print(sum(l, ()))
domain = splitting[1]
pen = QtGui.QPen(QtCore.Qt.red)
new_solution.append(data.pop())
c = pycurl.Curl()
virt - install
browser = webdriver.Firefox(profile)
df.loc[1]
reverse_d[key_str].append(key)
dotted_notation.setParseAction(name_notation_type)
print(b.build_lib)
im = im.crop((left, upper, right, lower))
tidx = pd.to_datetime(tidx).sort_values()
rcode = response.rcode()
result = datetime.strptime(date, format)
db.connect()
dol[k].append(d)
cv_im = cv.CreateImageHeader(pil_im.size, cv.IPL_DEPTH_8U, 1)
stemmer = PorterStemmer()
subset = table[np.in1d(table.IDs, id_list)]
antigravity
int.__init__(self, *arg, **kwarg)
t[n - 1]
test_module_1.py
instance
process(path)
print(richard)
assert_frame_equal(df1.sort(axis=1), df2.sort(axis=1), check_names=True)
c = C(0, 1, 2)
[x[1] for x in links if x[0] == node]
ax.plot([-1, 0, 1, 2], list(range(4)))
NUM_REPEATS = int(sys.argv[2])
(s.index[0] - s.name).total_seconds()
COMMIT
tf.write(sf.read())
False
[ChildClass(stream) for i in range(stream.read_ui16())]
GuiMixin_FunctionalityB.__init__(self)
a = a.__get__(C)
pacific_now.utcoffset().total_seconds() / 60 / 60
np.lib.stride_tricks.as_strided(arr, new_shape, new_strides)
d = dict()
print(answer)
data.append(val)
username, password = sys.argv[1], sys.argv[2]
driver.init()
combined = defaultdict(list)
idict[sub_name] = new_dict
Potato(**validated_data)
GL.glShadeModel(GL.GL_FLAT)
source.close()
a = numpy.array([(n + datetime.timedelta(minutes=i)) for i in m])
[FreeTDS]
reimport(module)
A[:, (~drops)], drops
m.hexdigest()
ActionChains(context.browser).send_keys(Keys.ARROW_UP).perform()
params
self.factory.broadcastMessage(message)
y = pattern.match(x).groups()
pool._processes
True
print(sorted(list(func(n))))
h = ax.plot(x, rv.pdf(x), lw=2)
m_to_N[:, (0)] = -nrange[1:].reshape((n - 1, 1))
column_align = gtk.Alignment(0, 0, 0, 0)
df.index = df.index.map(str)
traingraph = tf.Graph()
f.write(libtorrent.bencode(torfile.generate()))
links[word].push_back(word.c_str())
n, [n]
datetime.datetime(2012, 10, 4, 1, 0, 51, 759000)
[1, 2] == [2, 1]
soup = BeatifulSoup.BeautifulSoup(data)
is_ok[idx] = np.logical_or(is_ok[idx], val)
BaseObject.initialized, ObjectOne.initialized, ObjectOne.x, ObjectTwo.initialized, ObjectTwo.x
a += 1
self.obj = obj
maxIntEl = max(int(element[0]) for element in elements)
deleteself.mapping[key]
tmr.start()
n = len(points)
nodes.append(key)
(tuple(seq[pos:pos + size]) for pos in range(0, len(seq), size))
smtp = smtplib.SMTP()
end_time = Column(Integer)
print(l)
df.corr()
total
self.total += 1
print(a.shape)
plt.bar(X[:-1], Y, color=C, width=X[1] - X[0])
m.p
A = sps.coo_matrix((v, (i, j)))
print(list(missing_elements(L, 0, len(L) - 1)))
D1, D2 = A.shape
n_tr_1 = (y_train != 0).sum()
r = int(max(0, 255 * (ratio - 1)))
print(first_fifty_results[0].media_url)
name = Column(String)
username = NullColumn(db.String(80))
self.electric_conductivity = electric_conductivity
y_sorted
self._queue = Queue(maxsize=1)
blocks.append(f.read(BLOCK_SIZE))
a = np.array([9, 9, 9, 9, 9, 9, 9, 9, 9, 9])
ax_axis.offsetText.set_visible(False)
word = word.rstrip()
b = c = a[10:40:4]
__builtin__.__import__ = newimp
pcolor(data, cmap=new_map)
len1 = len(s)
DEVELOPMENT = True
f = np.vectorize(f)
print(s)
runrec(srcname)
current_list.append((header_id, header.string))
u_x.append(len(s) - 1)
options.parse_command_line()
code = marshal.load(f)
print(results.get())
ar[0:0]
u_y.append(s[-1])
do_other_stuff_to_header(line)
data = get_image_data(infile)
s[-amount:]
y[:] = np.where(mask, np.nan, r * np.sin(t))
self.__parser.add_section(attr)
formatfunc(thing)
r2 = (x - cx) * (x - cx) + (y - cy) * (y - cy)
r = re.search(pat, txt)
mysum += (a - b) ** 2
py_version = sys.version_info[:2]
app.route(*args, **kwargs)(view_func)
df2
diag = [-1] * n + [1] * 2
dict.__delitem__(self, key)
self.m[r][c]
total = 0.0
print(i)
math.factorial(6)
cls(name=name, email=email)
array = np.empty(len(args), dtype=np.object)
print(user_input)
df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)
sql = f.read() % params
pil_im
ax = s.cumprod().plot()
result2.add(k + 1)
hash - r
a.append(a_t)
print(i)
authed = g.get_user()
self.loop = asyncio.new_event_loop()
post_install()
ufmt_str.format(*args)
b = a[s]
q |= Q(name__icontains=merchant)
children = list(_get_ordered_child_nodes(node))
middle_min = df.iloc[first_row + 1:last_row].min().min()
metadata = MetaData()
value = models.IntegerField()
number = m.group(1)
imgf = ndimage.gaussian_filter(img, blur_radius)
x = abs(x)
df = psql.frame_query(sql, cnxn)
difference = end_date - start_date.replace(end_date.year)
sys.float_info.max
td, tdend, keytd = map(Suppress, (td, tdend, keytd))
print(sess.run(y))
d[v] += 1
X_neg = X[y_neg]
location = forms.ModelChoiceField(queryset=Location.objects.all())
getattr(self._original, key, value)
r, c = np.triu_indices(tot_vec, 1)
t[0]
q.put(2)
self.some_method = self.some_method
a[0:1] = [4]
next(g)
parsed = ET.parse(url_link)
my_list
handler = urllib.request.HTTPHandler()
join(idx, n)
print(uploaded_files)
self.testdata = open(TESTDATA_FILENAME).read()
y[s] = np.arange(s.size)
random.randint(0, 10000)
labels = [0, 1, 1, 2]
y[nans] = np.interp(x(nans), x(~nans), y[~nans])
app = Flask()
seconds = float(milliseconds) / 1000
x = np.empty(5)
f = Foo()
console = logging.StreamHandler()
newSingle.getHeader().setField(transacttime)
do_something(chunk)
today = datetime.datetime.today()
children.add(v)
myobject.__acl__ = load_acls(myobject)
data = json.loads(document)
print(last_array[211147, 9])
l.sort(key=alphanum_key)
clf.estimators_[0]
ttaken = time.time() - ttaken
self.initfunc()
payload_hash = hashlib.sha256(request_parameters).hexdigest()
difference_in_years = date_as_float(end_time) - date_as_float(start_time)
self.dot.set_offsets((x, y))
delattr(cls, name)
np.array([100 - x, x + y, 100 - y])
enddef
channel.settimeout(2)
sftp = s.open_sftp()
Base = declarative_base()
yedges = np.linspace(0, N, nbin)
person = Person.query.get_or_404(id)
my_instance.a()
pairs = list(itertools.product(l1, l2))
destination.save()
output = sys.argv[2]
string, stream[pos + 1 + length:]
len(block)
itrange = list(range(100))
local_datetime = datetime.now(local_tz)
d[x] += 1
d = datetime.date(2012, 2, 7)
print(x)
sorted(coursesList, key=len)
image.write(chunk)
[node.aspython() for node in nodelist]
Architecture
Management
{word for word, times in list(anagrams.items()) if times > 1}
C[A.nonzero()] = A[A.nonzero()]
titles = []
rows, cols = matrix.shape[0], matrix.shape[1]
data[n] = line.rstrip()
jsonText = json.dumps(arr)
encryptionKey = {s[i]: s[i + 5] for i in range(len(s) - 5)}
dict_str = json.dumps(my_dict)
setattr(self, unit, value)
False
show()
a = float(x)
dis.dis(foo)
test = sum(tests)
x = np.arange(Norig * Norig).reshape((Norig, Norig))
plt.setp(patches, linewidth=0)
self.scene.addPolygon(QtGui.QPolygonF(self.click_positions), pen)
threads.remove(thread)
print(var_dic)
all(value in x for x in self.sets)
self.value = value
__rxor__ = __xor__
Foo.bar.__self__ is Foo
parser.print_help()
cur.connection.autocommit(True)
self.val -= 1
thequickbrownfoxjumpsoverthelazydog
self.send_response(200)
b.compute(date, date)
os.remove(temp_file_name)
ws.write(row, 1, row)
do_totally_different_thing()
db.foo.remove({})
self._s.sendto(str(data), self._server)
weights[k] = 0.0
file_A.do_A_stuff
self.mc = wx.media.MediaCtrl(self, szBackend=wx.media.MEDIABACKEND_WMP10)
session.modified = True
col_sums[:, (j)] = col_sums[:, (j - 1)] + row_sums[:, (j)]
ar[np.bitwise_or.accumulate(~ar[::-1])[::-1]]
answer_for_first_set = list(filter_bits)
ipdb > X[k, k].shape
b = pandas.get_dummies(a)
tmp2 = np.sqrt((scalar1 - a[:, :, (1)]) ** 2 + (scalar2 - a[:, :, (2)]) ** 2)
p = Process(target=worker)
mod
attachment = MIMEText(fp.read(), _subtype=subtype)
new_result = np.zeros(im.shape)
self[i - 1][j - 1] == 1
peasant.knock_over()
self._s.sendto(str(data), self._addr)
keyfunc
QtCore.QTimer.singleShot(5000, self.showChildWindow)
id(df._data)
plt.subplot(2, 2, 2)
j = np.random.randint(0, ncols - 1, numdense)
arr = np.random.random((1000, 1500))
self.est = est
sent = np.zeros((len(vocab), len(text_idx)))
len(self._data.values)
pp.close()
print(obj.__class__)
twitter = Twython(APP_KEY, APP_SECRET, OAUTH_TOKEN, OAUTH_TOKEN_SECRET)
diff.sort()
a.dtype
mask = np.where((array >= x) & (array <= y), True, False)
fig = plt.figure()
combinedRDD = combinedRDD.map(convert)
boto.storage_uri()
a_list
sum((a - b) ** 2 for a, b in zip(u, v))
doSomethingWith({{user.username | tojson | safe}})
eff = 50 - 10j
df
value
singlet_list = [2]
udf(lambda c: label_maker_topic(c, topic_words))
do_whatever()
self.assertEqual(captcha_count, 0)
self.openfile()
x % 2 == 0
ans = np.take(myarray, sorted(set(ind) - set(rm)))
a - a
t = threading.Thread(target=test)
f.close()
msg_decorator
tmp_file.flush()
found = False
GL.glClear(GL.GL_COLOR_BUFFER_BIT)
-math.log(theta * beta)
time.sleep(max(requiredDuration - connectionDuration, self._latency))
current.append(label2index[label])
cur = con.cursor()
words.update(test.split())
last_result
print(x)
print(value)
allUuids = []
print(args.c)
print(qs)
wset.add(narrow)
A[0] = previous_A[1]
_multigen
print(pat.search(content).group())
get_page_labels(pdf)
a = Vector(1, 2)
number = 0
np.multiply(arr1[i], arr2, out=out[i].reshape((1, arr2.size)))
a.copyApply(A.foo)
logging.INFO
toimage(data).show()
assert app2.tasks[test.name]
d[nan2]
set([x for x in list(storage.values()) if list(storage.values()).count(x) > 1])
foo()
f.close()
print((w, follows(w)))
print(next(self.fibo))
fid.close()
print(max_number(1000))
self.x, self.y
id(b)
blockwise_times = []
lambda func=self.test: func()
login(self.request, form.user)
filters.pop()
web.setPage(downloader.page)
content = db.Column(db.String(255))
print(content)
abc = myFunction
True
output = PdfFileWriter()
uglybuf = src.read(1)
map(lambda x: x.extend([0] * (inner_max_len - len(x))), lst)
p.show()
r = urllib.request.urlopen(datasrc)
ax = fig.add_subplot(2, 1, 1)
self.file.flush()
indexes = np.zeros_like(data, dtype=int)
u[s] = np.arange(n)
HttpResponseRedirect(self.get_success_url())
[]
print(a[(idx == 0), :])
Z = np.zeros((2, 2))
RED, GREEN, BLUE = (255, 0, 0), (0, 255, 0), (0, 0, 255)
nNew = np.random.random_integers(low=1, high=100, size=1)
sts = os.waitpid(p.pid, 0)
index.append(start)
url = sys.argv[1]
res1[:, (k)] = U[:, :, (k)].dot(V[:, (k)])
r = []
print(line)
random.randrange(start * f, stop * f, step * f) / f
expatparser.Parse(xml)
title = db.StringProperty()
jsonobject = fromJSON(jsonstring)
pid = os.fork()
cv.Rectangle(image, pt1, pt2, cv.RGB(255, 0, 0), 5, 8, 0)
number // 2
print(x)
running = True
count(5)
link = soup.link.nextSibling
lb = tk.Listbox(root, width=50, height=20, yscrollcommand=scrollbar.set)
t.push(s.pop())
ttaken = time.time()
repo.remotes.origin.push()
qs = Room.objects.filter(name=self.name)
response = urllib.request.urlopen(sampleRequest)
__initialized = False
w, h = im.size
app = QtGui.QApplication(sys.argv)
url += urllib.parse.urlencode(self.params)
main()
data = f.read()
print(query)
t1.start()
print(ast.literal_eval(assignments_removed))
self.sendHello()
df
model = treeview.get_model()
bitstring.BitString(uint=i, length=(i.bit_length() + 7) / 8 * 8).bytes
newshuffle(l)
print(chunk.values)
{{companyForm.locations()}}
fmt_values = [formatter(x) for x in self.values]
-a.py
Alfa = list(modules.keys())
worker_process.start()
app.exit(1)
window = Gtk.Window()
print(ndimage.map_coordinates(data, [zi, yi, xi]))
print(self.server.arg1)
int(number + 0.5)
data = json.dumps([r for r in csv_reader])
nonRepetitive_x.insert(0, x[0] - 1)
key = min(iter(self.keys()), key=lambda x: abs(x - key))
Chainable(self.data, method)
nx.path.bidirectional_dijkstra(G, 1, 2)
cols = []
scroll = gtk.ScrolledWindow()
self._task = asyncio.ensure_future(self._run())
generations[-1]
result = [(i > maximum / 2) for i in diffs]
Audio(url=sound_file, autoplay=True)
app.logger.setLevel(debug)
self.factory = RequestFactory()
curl.setopt(pycurl.FOLLOWLOCATION, 1)
x[[0, 2], [1, 4]] = np.nan
print(a, b, file2freq[a, b])
self._cache.append(next(self._g))
h.Send()
eyecols = np.tile(I, n).T
grouped = s.groupby(level=0)
pool.join()
file = matplotlib.font_manager.findfont(font)
plot(s[:, (0)], s[:, (1)], color=dark2[c])
col_paddings = [get_max_col_w(table, i) for i in range(len(table[0]))]
frame.worker.join()
xi, yi = np.meshgrid(new_row, new_row)
daemon.start()
y_series.append(int(z))
HttpResponseRedirect(url)
x = numpy.arange(0.0, 8, 0.1)
form = ArticleForm(instance=article)
print(arreq_in_list(myarr0, mylistarr))
s1 = set((0, 1))
print(dest_path + filename)
blosum.update(((b, a), val) for (a, b), val in list(blosum.items()))
sys.argv = [str(num)]
t.join()
self.webSocket.broadcastMessage(request.content.read())
wr = csv.writer(your_csv_file, quoting=csv.QUOTE_ALL)
timeit[Model.objects.filter(date_created__startswith=today)]
ewma = pandas.stats.moments.ewma
X.mean()
here_using_my_module.py
print(s2)
dict_df
tempset.update(x)
client = requests.Session()
sum(matrix[(row), :])
deleteself.data[index]
self.attr2 = attr2
[item[i] for i in self.columns]
print(img.getpixel((0, 0)))
score = pickle.load(file)
trainY = np.array([i for j in trainY for i in j])
socketIO.wait_for_callbacks(seconds=1)
do_stuff(chunk)
myhtml = lxml.html.document_fromstring(string)
assert a.shape == b.shape
bool(set(array1) & set(array2))
g()
sys.exit(not result.wasSuccessful())
self.tables.append(self.rows)
datetime.utcfromtimestamp(ts)
vars(self).update(somedict)
result = Test.objects.filter(actions__contains=kwargs)
fig.patch.set_alpha(0.0)
x.f2()(1)
bar_id = Column(Integer, ForeignKey(Bar.id))
dur2 = 1
end = datetime.strptime(end_date, date_format)
self[attr] = value
server.serve_forever()
rozza = Person.objects.first()
layout.addWidget(self.list_widget)
len(s)
value
print(np.all(Z.A == np.maximum(X.A, Y.A)))
region2 = thresh2 < gryim
serialized_user = yaml.dump(user)
size = icon.availableSizes()[0]
add(10, 5)
fig1.colorbar(im, ax=ax1)
b = [9, 8, 7, 6, 5]
p = QPixmap.grabWidget(widget)
fullpath = os.path.join(root, f)
self.log.Show()
hello(a, b)
zaxis = np.linspace(0, 1, 20)
form = _get_link_form(request.POST)
print(myFunct())
df2
length = len(encoded)
node.left = Node()
print(fn.match.groups())
axes[1].append(string2.index(i))
t = np.linspace(0, T, N)
unsearched.task_done()
0
print(serv_resp_body)
Animal.objects.all()
mycode.my_func()
deleteself.dict[item]
print(id(string[-10:-5]))
ax1.set_xlim(-4, 15)
mult_fact = np.ones(shape, dtype=int)
request = urllib.request.Request(sys.argv[1])
df.to_csv(tmp, index=False)
length = len(l1) + len(l2)
cond = np.array([[False, True, True], [True, False, True]])
self.loop.call_soon_threadsafe(self.loop.stop)
s = StringIO.StringIO()
increment_deal_count(dbconn, userID)
df.groupby(idx2.astype(object)).sum()
text = tk.StringVar()
self.save()
b_h = tf.Variable(tf.zeros([n_out]))
logger.addHandler(console)
lst1[0:1] + interleaveHelper(lst2, lst1[1:])
order = list(range(len(some_list)))
df_wide = df_indexed.unstack().fillna(0)
print(type(b))
tf = tempfile.NamedTemporaryFile()
data = self.data[:self.size]
isinstance(x, number.Number)
Arr = np.random.standard_normal([500, 201, 2, 2])
logger = get_task_logger(__name__)
e = Element(qualifiedName, namespaceURI, prefix)
b = np.sin(theta)
parser.set_defaults(type=do_stdout)
z = tf.matmul(x, y)
d = defaultdict(int)
not len(non_unique_list) == len(set(non_unique_list))
output.append(x)
img2 = np.uint8(np.random.randint(0, 255, (480, 640)))
assert not sequence_in(c, a)
index_li.append(idx)
{{email}}
zip_longest(fillvalue=fillvalue, *args)
l = []
print(row.text)
-1
sys.modules.update(old_modules)
type(_)
self.process()
parent.remove(r)
print(commaSeparatedList.parseString(s).asList())
self.after(100 * i, change_name)
model = PandasModel(your_pandas_data)
isinstance(t, str)
print(reversed(conn.execute(query).fetchall()))
{}
neisets = [set(g.neighbors(i)) for i in range(g.vcount())]
rmdir(root)
headers = {}
math.degrees(math.atan(1))
nparr = np.fromstring(img_str, np.uint8)
message = inbox.Messages.GetFirst()
print(emp.name, emp.title)
self.root.addHandler(self.qh)
b.__doc__
rainbow_fill(X, Y)
self.start_time = time.time()
[tuple for tuple in tuples if term in tuple]
self.__getitem__(k)
fh.setLevel(logging.INFO)
user.save()
df
headline = models.CharField(max_length=100)
digits = escapesequence[2:]
foo.close()
z[list(np.indices(z.shape[:-1])) + [a]] = 1
data = []
myapp / somelibfile.py
self.char_y += 10
points = [random() for _ in range(1000 * 2)]
monkey.patch_all()
x = np.linspace(0, 10)
p = Process(target=f)
diff(nges_uneval, n[5])
self.cookies = MyCookieJar()
os.killpg(0, signal.SIGKILL)
allocate(tmp(gridsize, gridsize, gridsize), work(gridsize))
print(strc)
list(d.keys())
unpack.append(item)
result
new_list = []
soup = BeautifulSoup(content)
assert find_max([]) == 0
print(find_skew(list(range(256))))
session.close()
Package - 1 / namespace / module1 / __init__.py
print(True)
parser = MyArgumentParser()
compressor.write(chunk)
felf = globals()[sys._getframe().f_code.co_name]
is_admin = os.getuid() == 0
True
req.setUrl(url)
fig = plt.figure()
print(n)
callable(elt.text)
PyLong_AsByteArray(lnum, a, a.size, 0, 1)
p = MyPickler(f)
ps.image(box, im, dpi)
np.random.shuffle(idx)
email_message
y[i][j] = x[i][j]
print(today - BDay(4))
key_result[name_key] = groups[0][name_key]
the_list = numpy.array(list(range(0, 101, 10)))
print(line1.buffer(EPS).intersects(LineString([pt, pr])))
s = StringIO()
y = T.dmatrix()
birth_years = {nm: year[idx] for idx, nm in enumerate(name)}
formattedJson = json.dumps(teams, indent=1, sort_keys=False)
print(Animal.__bases__)
f.__defaults__ = f,
ax = fig.add_subplot(1, 2, 1)
sinv = np.sin(x_axis_rotations)
d = np.diff(x)
fout.write(line)
current_script = os.path.realpath(__file__)
app = Flask(__name__)
self.globals[key]
cap = cv2.VideoCapture(0)
max_occurrences = max(counter_list, key=itemgetter(1))[1]
mlab.surf(subtract.outer(sin(xx), cos(xx)))
variables = list(array[0].keys())
d[6] = 1
excel.Visible = False
u = np.hstack([[0], u])
path
[lower_keys(v) for v in x]
self.directory = os.listdir(*args)
a, b = b, a + b
b = Base()
canvas.setPageSize((lHeight, lWidth))
sphinx - apidoc - o / my / docs / live / here / my / source / lives / here
a, b = tee(iterable)
print(sortSparseMatrix(m))
result = defaultdict(dict)
c = b[:2]
bad_data = data[(0), :][data[(0), :] == 0.0]
b[a == k] = v
HTTPRedirectHandler(), urllib.request.HTTPHandler(debuglevel=0)
neighbors = G.neighbors(root)
form = CategoryForm
inputs.remove(s)
self.assertEqual(t[0], str(NumberedVersion(*t)))
list(lower[lower.index(strs[0]):lower.index(strs[-1]) + 1])
copy_list = copy.deepcopy(org_list)
limit += 1
print(randomList)
print(find_parent(D, class_set))
np.PyArray_ITER_NEXT(itf)
self.assertEqual(some_method(), False)
fig.set_size_inches([8.0, 12.0])
doit()
a = Field()
extra_compile_args.append(arg)
parent_map[el].remove(el)
p1.daemon = True
self.fp.seek(offset, *args)
a_set = set(a)
visible = Column(Boolean, default=True)
dirname = os.path.dirname
shp = L[0].shape
print(grids[0].dtype, grids[0].nbytes)
data_con = bytes.fromhex(data)
f.close()
a.ravel()[5] = 99
raise StopIteration
plt.show()
B.__init__(self, a, b)
app = params.get(cls._APP_PARAM)
plain_text = get_plain_text(soup)
fig = plt.gcf()
a = int(round(time.time() * 1000))
local_beta = tf.identity(self.beta)
self.checkBoxList.append(checkBox)
content = models.TextField(max_length=250)
b = np.array(b)
pprint.pprint(obj)
df.col1 = pd.to_datetime(df.col1)
cache[args]
rs = r1[(np.lexsort(r1.T)), :]
statement = query.statement
plt.ylabel(ax2_label)
pc.append(Path.CLOSEPOLY)
stuff.py
cam.release()
self.v = v
count[c] += 1
self.get_queryset().in_group(group)
mask = np.cumsum(mask, out=mask, axis=1)
self.index - 1
df
maks = max(flows, key=lambda k: len(flows[k]))
name, val = s.split()
x = len(self.right) // 2
len(dir(anIntOBJECT))
self.fingerprints.add(fp)
list(df[df > df.quantile(0.8)].dropna().index)
1 / 0
url = request.build_absolute_uri(request.get_full_path())
utf8[:i]
dz = NP.random.randint(1, 5, 10)
dev_sda1 = boto.ec2.blockdevicemapping.EBSBlockDeviceType()
out.seek(0)
s = np.array([20, 10000, 10000])
shutil.rmtree(dir_name)
Hvalue = someoperation(Hnodes)
lenIter(s[1:])
print(len(object_keys))
result = dict(defaults)
b = np.random.rand(N, 1)
result = []
newlist.append(word)
a = np.random.rand(100 * 100).reshape((100, 100))
print(stream.get(cv.CV_CAP_PROP_FRAME_COUNT))
print(nums.std(axis=1))
Py_DECREF(pyth_val)
fmap[fid] += 1
w = wcs.WCS(naxis=2)
_NestedClassGetter(), (WidgetType, self.__class__.__name__)
a.somefield = somevalue
console_handler.setFormatter(log_formatter)
gevent.joinall(jobs)
child.setText(0, str(value))
[-2, -1, 0, 1, 2],
pymysql.install_as_MySQLdb()
df
curl.setopt(pycurl.SSL_VERIFYHOST, 2)
layout.set_font_description(font)
line_number = random.randint(0, total_num_lines)
app = flask.Flask(__name__)
ch.setLevel(logging.DEBUG)
self.axes.plot(self.data[(0), :], self.data[(1), :], self.data[(2), :])
plt.xticks(rotation=25)
PassengerID, Survived, Pclass, Name, Sex
df = pd.DataFrame(index=missing)
c = wmi.WMI()
show(p1)
html = page.read()
a = numpy.array([])
print(df)
someDict[num].append(line)
a + b
output = 4 * np.sum(integrand(a + h * np.arange(1, num, 2)), axis=1)
loop = asyncio.new_event_loop()
conn.close()
cnts = df.sign.iloc[diffs.drop_duplicates().index].value_counts().to_dict()
widget = InlineButtonWidget()
myA[np.where(myA > val)[0][:n]] = 0
plt.xlim([-1, 10])
servicemanager.Initialize()
__modpath__ = module_path(main)
args = foo.__code__.co_varnames[:foo.__code__.co_argcount]
Foo.bar == foo
stream.write(input_array)
msg = MIMEMultipart()
ls[1] = ls[1] - (ls[1] - ls[0]) / 2
a = calc_a(d1, d2)
x = np.array([[10, 0, 10, 0], [1, 1, 0, 0], [9, 9, 9, 0], [0, 10, 1, 0]])
noay = word[:len(word) - 2]
a1 + csr_matrix((x - a1[ind], ([0] * x.size, ind)), (1, a1.size)).toarray()
outdir = os.path.dirname(outfilename)
next(generator())
print(resultMD5)
a = a.reshape((-1, 1))
os.close(self.pipe[0])
logging.setLoggerClass(CustomLogger)
rollback()
count -= 1
s.append(ALPHABET[r])
assert END == pickle.loads(pickle.dumps(END))
title = models.CharField(max_length=100)
True
m = mmap.mmap(f.fileno(), 0, prot=mmap.PROT_READ)
deleteobj.__dict__[self._name]
table = d.add_table(numrows, numcols)
twodarray = np.array(map(lambda x: x.flatten(), threedarray))
PyObject_Print(item, stdout, 0)
len_part = int(math.ceil(len(data) / float(k)))
print(etree.tostring(html))
data = urllib.parse.urlencode(values)
input_zip = ZipFile(input_zip)
sleep(randint(10, 100))
sublime.set_timeout(test_progress_bar, 100)
df
print(s)
self.__class__.PARAM
x1 = min(x_normalised) - 1
client = self.get_current_client()
daynum += 1
start = get_start_input()
zip(ii, y[ii])
win.setCoords(0, 0, 10, 10)
a % 10 + digit_sum(a / 10)
url = urlparse.urljoin(url, match.groups()[0].strip())
deletetime.sleep
a = {}
output = [((k,) + v) for k, v in list(output.items())]
out, err = process.communicate()
files = list(x for x in filePath.iterdir() if x.is_file())
c(1)
pairLambs[2]()
Queue.put(self, (datetime.now(), item), False)
tf.file.close()
blocks[0][0]
ax2 = fig.add_subplot(gs[1], sharey=ax1)
True * 2
color_bar.set_alpha(1)
a = numpy.random.normal(size=10000)
os.makedirs(dest_dir)
seconds = tdelta.total_seconds()
count = 0 if count == N else N + 1
self.events.append(item)
f = sympy.exp(x + y) - sympy.sqrt(z)
A = numpy.array([[5.0, 5.0, 5.0], [8.0, 9.0, 9.0]])
X = numpy.random.normal(size=(100, 10))
print(clean_text)
Session = sessionmaker()
np.int(x)
request = urllib.request.Request(BASE_URL, headers=HEADERS)
codepoint = ord(c)
async_list.append(action_item)
len(done) == len(container)
res = res * scaling_factor
args = parser.parse_args()
l = list(range(10))
b[elem - 1].append(indx)
stack.extend(item)
vec = [random.randint(minval, maxval) for i in indices]
(comp.string.encode(enc) % params).decode(enc)
text += e.strip()
self._reject(request, REASON_BAD_TOKEN)
detA = np.linalg.det(A)
print(parsed_values)
merged_tuple = min(c_start, n_start), max(c_end, n_end)
args = command.strip().split()
print(sum(score_pairwise(seq1, seq2, blosum, -5, -1)))
plt.plot(dates, values)
end_date = datetime.datetime.today()
http_server.listen(8888)
c, addr = s.accept()
deleteself._x
l.append(number % base)
p.pretty(key)
result.append(copy(path))
new_func = func
fn(**arglist)
assert mocks[mocked].call_count
root = tk.Tk()
queue.append(start)
description = models.TextField(max_length=200)
math.factorial(temp)
app.debug = True
lines.append(str(self.problem_mark))
df.assign(z=df.x * df.y)
pylab.grid()
num += 1
os.umask(oldmask)
y = all_lists(negate(x))
raise KeyError(key, val)
event.widget.quit()
F.X[:, (0)]
unittest.main()
plt.grid(True)
print(df)
mydict = pickle.load(output)
out += str(serial.read(1))
array[slices]
y[::2]
tmp = np.bincount(idx, w)
p.close()
cax.set_array(colorv)
ns.c
True
keystone.roles.list()
lstatout = str(ftp.lstat(i)).split()[0]
now = datetime.datetime.now()
print(convert(52))
type(d.day)
print(value)
t = field.field.widget.__class__.__name__
elem.tag = elem.tag[i + 1:]
self.ui.gridLayout.addWidget(self.ui.dragDataEdit, 0, 0, 1, 1)
i = np.arange(M)[:, (np.newaxis), (np.newaxis)]
list(s.cookies.keys())
draw = ImageDraw.Draw(img1)
codecs.decode(s, originalencoding, errors), len(s)
CM[bmask] = data[bmask]
z = zipfile.ZipFile(StringIO.StringIO(r.content))
a = t
seen.add(field.data)
receiver.interrupt()
b = np.array([4, 5, 6])
X, Y = numpy.meshgrid(x, y)
x = uniq(0, [[[0]] * 5] * 5)
buffer[loc] = line.strip()
cls(len(a), a.ctypes.data_as(c_double_p))
Story.append(p)
event_box.show()
ch = logging.StreamHandler()
arr = df.a.values
X = np.random.randint(0, 99, (6, 5))
t = socket.htons(int(port))
svos = []
(okays if success_condition(r) else errors).append(r)
fig.add_axes(ax)
alters[0]
p = c_char_p(s)
foo = decorator(dec_args)(foo)
row = cur.fetchall()
main_loop = tornado.ioloop.IOLoop.instance()
indices = np.arange(data.shape[0])
new_queryset = new_queryset | obj.get_ancestors()
self._x = value
argsdict, unknownargs, execlist = prs.parse_args(cmdlineargs)
p = Process(target=f)
ax.contourf(xi, yi, zi, 5, cmap=plt.cm.Oranges)
nested[outkey][inkey] = val
sys._argv = sys.argv[:]
db.session.add(stuff)
y = map(str, x)
a + step == b
EmailMessage(subject, message, to=to, from_email=from_email).send()
parsed = urlparse.urlsplit(url)
elementwiseApply(add, [4, 0], 4)
time.sleep(0.05)
binvalues.read(file, num_lon * num_lat)
d_sum[topkey][key] = dic1[topkey][key]
self.button.move(250, 50)
y = np.arange(10)
array2 = np.array(zip(*list2))
self._x
self.val *= 2
authenticate(username, password)
self.lframe.pack(side=tk.TOP)
associations = []
helper(stack[:], [])
num_words += len(words)
a, b, c, d = [t(s) for t, s in zip((int, float, bool, str), input.split())]
print(process_backspaces(process_shifts(test_string)))
HTTPCACHE_EXPIRATION_SECS = 0
socket = context.socket(zmq.REP)
self.axes.zz_dataLim.intervalx
{{field.errors}}
s.enterabs(t0 + 10 + i, 0, f, (t0,))
a = np.random.rand(100000, 2)
y = tf.constant([[1.0, 1.0], [0.0, 1.0]])
b = [True] * len(a)
print((one, four, ten))
fp = webdriver.FirefoxProfile()
reading = ser.readline().decode()
zip(a, a)
pos += len(char)
add.addtwo(4, 5)
self.cool_dict[attr]
f = interpolate.interp1d(theoryX, theoryY)
doc.build(elements)
it.chain.from_iterable(it.repeat(i, i) for i in range(1, n + 1))
a = [1, 2]
jpeg = buf.getvalue()
A = np.random.sample((n, n))
freqs[char] += 1
res = []
im = pl.contourf(data[(i), :, :])
EARTH_RADIUS_KM * c
textbox.pack()
A = 10 * np.eye(10) + np.random.rand(100).reshape(10, 10)
print(c.shape)
is_sub_with_gap(b, a)
D[i, j] = abs(x[i] - x[j])
sort(less) + equal + sort(greater)
tree = objectify.fromstring(your_xml)
df
c.perform()
True
f(x=5)
review.save()
print(x)
df[date_col_name] = pd.DatetimeIndex(df.index)
w, h = P.wrap(doc.width, doc.bottomMargin)
bisect.insort_left(l, 8)
web = QWebView()
autoCov += (Xi[i + k] - Xs) * (Xi[i] - Xs)
result += numbers[i:j]
y = eval(x)
tuples = itertools.zip_longest(*A)
evens.append(i)
filename = sys.argv[1]
random.randint(1, 100)
r = coo_matrix((data, (row, col)), shape=(M, N))
pylab.ylim([0, 100000])
ports_strs.append(str(port))
local_ret = local_p.wait()
elapsed = timeit.default_timer() - start_time
[(k, v) for k, v in list(aliases.items()) if q in k or q in v]
x, y = width // 2, height // 2
task2.join()
Thread(target=reader, args=[process.stderr, q]).start()
result = []
f(2, covered_list)
square[np.logical_not(has_neighbor)] = 0
False
print(B.shape)
aspect = ih / float(iw)
second_axis.set_yticks([0.2, 0.4])
DummyRequest.__init__(self, postpath, session)
vals[idx]
next(testcsv)
print(a[0])
some_module.hello_world()
fig, ax = plt.subplots()
SimpleHTTPServer.SimpleHTTPRequestHandler.do_GET(self)
self.lower() == other.lower()
points = []
filename, file_extension = os.path.splitext(original_file)
1
mofile
a, b, c, d = argv
result[0]
reversel.append(orig.pop())
self.K = self.P.dot(spsolve2(S.T, C).T)
offset = datetime.fromtimestamp(epoch) - datetime.utcfromtimestamp(epoch)
JM1, JM2 = precalc(jmat)
results.append(right[0])
arr = np.array(your_list, dtype=np.int16)
result = []
cache[key]
self._index = dict()
lst = df.A.values.tolist()
print(paragraphsep)
dir.append(d)
p = lambda x: sum(phi(x) for phi in phis)
sdl2.SDL_RenderDrawPoint(renderer, offset.x + x, offset.y - y)
plt.pcolor(X, Y, v, cmap=cm)
blogpost.tags = new_tags
condition.notify()
y = np.zeros(2 * len(bins), np.float)
a()
self.imgdir = fcb.get_filename()
result = f.read()
a.sort()
value
dict.__getitem__(self, key)
kpt_data = h_r.reshape(-1, phase.shape[0]).dot(phase)
a = np.random.random((16, 16))
context
chr(97)
loop = asyncio.get_event_loop()
i, j = np.ogrid[0:n, 0:m]
self.__dict__
diff_unique = [v1 for v1 in diff_list if v1 not in set(source_list)]
manager = multiprocessing.Manager()
x = op.inputs[0]
os.dup2(desired_output_file.fileno(), sys.stdout)
form = AnimalForm(request.POST, instance=animal)
handler.setLevel(level)
firstJan = date.today().replace(day=1, month=1)
it.starmap(func, it.repeat(args))
ax = plt.subplot(111)
traceback.print_exc()
free(my_array)
l.append(val)
col.set_sort_column_id(0)
result = Queue.Queue()
output = template.render(index_variables)
bloc122[[0, 1, 2], [0, 1, 0], [0, 2, 2]] = 0
te = time.time()
x1, x2, y1, y2 = im.get_extent()
root = lxml.html.fromstring(n)
dpoints, dloops, dtime, bT, sT, hI, LI, tm = vals[:8]
f.add_subplot(2, 1, n)
a.append(1)
a = [0] * (imax - imin + 1)
print(data.dtypes)
c.__doc__
bananas(dingo)
self.pid = pid
fig = plt.figure()
x = [[4], [6, 4, 9], [4, 6], [0], []]
self.message = message
self.allowed = self.funcB
x, x + 1, x + 2
print ()
print([x.classId for x in uniqList])
d.setdefault(i, []).append(j)
setattr(namespace, k, v)
installed_apps = [app.__name__ for app in apps.get_apps()]
print(strong_tag.text, strong_tag.next_sibling)
self.crawler.engine.pause()
result = self.send(soapenv)
tree = etree.fromstring(xml).getroottree()
plt.subplot(212)
value = int(field)
event = wait_for_event()
lis.append(lambda : 0)
coal = Jewel()
print(selectiveEscape)
np.rad2deg(lat), np.rad2deg(lon)
self.mapping[key]
1, 4, False
out = np.concatenate((pic, separator_str), axis=1).tostring()
s = codeErr.getvalue()
link.cwd(path)
messages = list([_f for _f in messages if _f])
l = [True, True, False, True]
deletedict[k]
sf.flush()
{getattr(self, k): v for k, v in kwargs.items()}
print(my_tz.normalize(my_tz.localize(dt) + delta))
crypts
p2 = np.array([[1, 1]])
ax.set_ylim(min(y) - offset, max(y) + offset)
a = np.array([True, True, True, False, False])
saver.restore(sess, dir_path + ckpt_file)
a = 5
x = np.asarray(x)
signal.signal(signal.SIGWINCH, update_terminal_width)
Py_DECREF(v)
now_timestamp = time.time()
x = []
HSV_tuples = [(x * 1.0 / N, 0.5, 0.5) for x in range(N)]
df = DataFrame(table)
data = data.decode(encoding, data).encode(new_coding)
False
body = Column(UnicodeText, nullable=False)
logutils.set_up_only_once()
out.append([ele])
x = np.random.rand(1000)
cur = con.cursor()
print(err.args)
data = f.read(length)
int(newSave)
app = wx.App(False)
draw = ImageDraw.Draw(mask)
clf = clf.fit(X[:50, :], y[:50])
doStuffStart()
start = datetime(2015, 1, 1)
current.append(x)
time.clock()
result = [SQLRow(cursor, r) for r in cursor.fetchall()]
r1, r2 = spline.roots()
self.timer.timeout.connect(self.reply)
d = collections.defaultdict(list)
p1, _ = optimize.curve_fit(f, x, y, (0, 0, 0, 0, 0), sigma=sigma)
r.content
tmpsize = client_socket.recv(1)
len(c)
reduced.pop(key, 0)
print(i)
Py_DECREF(it)
window = gtk.Window()
dz = [5, 4, 7]
js[key] = eval(value)
x0, y0, z0 = 10, 10, 10
match = max(d.get_matching_blocks(), key=lambda x: x[2])
t.join(timeout)
today = pd.datetime.today()
self._password
x[1]
True
shost = self.le.text()
plt.axes([0.45, 0.45, 0.45, 0.45])
save_cookies_lwp(r.cookies, filename)
zdd1 = rdd1.zipWithIndex().map(lambda v_k: (v_k[1], v_k[0]))
x, y = np.meshgrid(np.linspace(-1, 1, 100), np.linspace(-1, 1, 100))
my_dict[key] = new_value
process_data(datum)
coord = tf.train.Coordinator()
prime_form(9, 1, 5)
thread_.start()
pcmat = PCA(trainX, n)
print(f(v, 0, sum))
exit()
m.indices = (indices + 1) % m.shape[1]
pl.set_line(line, [p1x, p2x], [p1y, p2y])
app = QApplication([])
screen = pygame.display.set_mode(SIZE, pygame.RESIZABLE)
output.write(output_compressor.compress(chunk))
out = []
tmpfile.write(oldline)
self.STDOUT_FILENO = sys.stdout.fileno()
end_index = first_index + len(s1) - 1
feed = feedparser.parse(content)
Z = random.random((50, 50))
df = drop_col_n(df, 2)
m = adate.month - 1
c = np.arange(24).reshape((4, 6))
s[:p], s[p + 1:]
idx0 = np.concatenate(I)
img.save(path)
fig, axes = plt.subplots(nrows=4, ncols=4, sharex=True, sharey=True)
fig, ax = plt.subplots()
map(word_to_action, w)
sidebar_data_views.append(fn.__name__)
df = pd.DataFrame.from_records(foo).T
float.fromhex(new_hex_equiv)
a = np.arange(15)
print(o.x)
groups = []
next(it)
Any()
self.im.seek(j)
a = np.arange(5, dtype=np.double)
output = re.sub(regex, subst, output)
dx = np.diff(np.sort(x))
years, months = int(years), int(remainder // avgmonth)
listLen = len(listA) / 2
A = numpy.array(A)
df
df
users = [User.load(db, uid) for uid in db]
print(enc.encode(obj))
CM = ax2.contourf(XC, YC, YC, levels=levls, norm=LogNorm())
avg = avg - datetime.timedelta(microseconds=avg.microseconds)
app = QtGui.QApplication(sys.argv)
ctx.text_path(text)
window = Gtk.Window()
self.obj[frozenset(idx)]
urlretrieve(urlparse.urlunparse(parsed), outpath)
Map(*maps)
d = {}
pred = clf.predict(priv_fea[basic_feature_names])
self.__missing__(key)
column_align.show()
a = Foo()
x = list(range(1, 10))
ret.time = self.time.__getitem__(item)
temp = np.dot(datam[i:], datam[i].T)
cmyk = []
bins = np.linspace(0, 1, nbins + 1)
ax = plt.gca()
self
printMetric()
[5, 6]
data = client.recv(size)
ax.cla()
fo.seek(0)
x_idx, y_idx = np.unravel_index(idx_1d, a.shape)
print(key)
pool.close()
G.remove_node(bad_minor[0])
no_integers = list(filter(is_integer, mylist))
float_str
instance = reservation.instances[0]
df
s[-1]
head.read()
z.dtype.names
files = [stack.enter_context(open(fname)) for fname in filenames]
f()
l.count(True) == 1
A.__init__(self)
clf1.fit(X, y)
arr[x] = row
reactor.listenTCP(8080, site)
print(msg.CC)
[s]
result.append(word_map.get(w, 0))
chain.from_iterable(islice(iterable, *i) for i in args)
age = forms.IntegerField()
worksheet = workbook.add_worksheet()
pool.apply_async(mytask, (runlist[sendcounter], q))
A[:] = [A[i] for i in new_order]
self.serv = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
self.buf = cStringIO.StringIO()
authhandler = urllib.request.HTTPBasicAuthHandler(passman)
tlen = len(elidetxt)
f.write(xmlstr)
y = np.linspace(1.0, 2.0, 101)
print(s.recv(65000))
c = numpy.zeros((4, 2, 2))
(x for _, x in nlargest(k, ((random.random(), x) for x in it)))
groups = [list(g) for k, g in groupby(seq, lambda x: x != -1) if k]
print(e, q)
bins[i] += 1
process(i for i, v in zip(generator(), counter))
frame[~(b1 | b2)] = 0
TestCase = decallmethods(login_testuser)(TestCase)
a is a + tuple()
sorted = numpy.sort(a)
logging.config.dictConfig(LOGGING)
cv2.floodFill(result2, maskborder, seed_pt, (0, 255, 0))
t = pd.DataFrame(dict(val1=[1, 2, 0, 0], val2=[0, 0, 2, 1]), df1.columns)
cookie = Cookie.SimpleCookie()
idx = a.cumsum()
copy_list = org_list[:]
app = Flask(__name__)
frame = pd.DataFrame(data)
PyObject_Del(self)
print(response.read())
plugin_callable = entry_point.load()
f = open(fn)
list(menu_links.items())
item, = [1, 2]
f.seek(0, os.SEEK_END)
round(a, 4)
d = Image._getdecoder(self.mode, d, a, self.decoderconfig)
print(d[..., (2)])
i = bisect.bisect_left(float_list, 2.5)
connection.close()
0
print(combine(a, b))
item
kp2 = detector.detect(img2)
do_all_the_processing()
frame.values.squeeze()
test[5] = 6
img = Image.open(BytesIO(img))
round(x * 4) / 4.0
current_group.extend(group)
p = Popen(cmd.split(), stdout=PIPE, stdin=PIPE, stderr=STDOUT, bufsize=1)
baz = blar()
outer_sum += inner_sum * dk
self.flush()
self._y = self.y = y
serializer_class = ExperimentSerializer
student_detail = Student.objects.all()
test.test_func()
ax.patch.set_alpha(0.0)
local_t = t.astimezone(Local)
textobj.set_text(wrapped_text)
self.cursor = self.conn.cursor()
min_index = len(L)
b, c = zip(*matches)
enable()
carx = Car.objects.all()
len(listing), total
a = C()
res2 = slice_array(arr, 4)
u = np.cumsum(dist)
[1, 1, 1, 1, 0],
loop()
obj
file_like_object = io.BytesIO(byte_array)
now = datetime.now(local_tz)
Foo.lock = threading.Lock()
test1.put()
p.waitFor()
[i for text in myList for i in textwrap.wrap(text, 10)]
painter = QPainter()
fh = logging.FileHandler(filename)
answer2 = result2.get(timeout=10)
df = pd.DataFrame(dict(A=np.arange(len(tidx))), tidx).sort_index()
out = np.zeros_like(x)
print(link)
instance = ModClass()
loop = asyncio.get_event_loop()
output = ImageOps.fit(im, mask.size, centering=(0.5, 0.5))
one_array, two_array = [], []
s1[:i]
bound_method(*args)
stream.stop_stream()
temp_handle.write(command)
type(0)
df.Time = pd.to_timedelta(df.Time)
web.Response(self.format_data(data))
Orange.feature.Continuous(str(d.name), number_of_decimals=0)
self.HTMLDATA.append(data)
t.start()
grandFather.appendChild(tag)
im = cv2.imread(sys.argv[1])
print(args_name)
help(WebKit.WebView)
topic.users.get(pk=1)
print(e)
last = value[1]
left = randint(0, len(L))
print(self.b)
self.file.readline()
bounds = [len(lst) for lst in lists]
A[:] = D[slc]
wedges, texts = ax.pie(np.abs(np.random.randn(5)))
instances = [i for r in reservations for i in r.instances]
word_list.append(k)
plotx, ploty = np.mgrid[-4:4:100j, -4:4:100j]
ploty, plotz = np.mgrid[-4:4:100j, -4:4:100j]
row = xy[1]
called.append(True)
soup4.div
particle.append()
names = pd.DataFrame()
obj = json.loads(chunk.group(2))
json_data = json.loads(urlobj)
len(data)
self.fig = ax.figure
Grid.columnconfigure(grid, x, weight=1)
show()
print(df1[mask])
Clothing | Menswear | Pants | Shorts
print(Xfit_mono_ind)
header += file_handle.readline()
p[np.triu_indices(p.shape[0], 1)] = pf
f
self.close()
count_primes(10 ** 9)
chained.extend(li.pop(0))
b = np.average(a, axis=2)
g = g.add_legend()
pprint.pprint(list(gen))
print(t)
app = QtGui.QApplication([])
recstack = np.r_[arrs[:, ::-1], arr1[:, ::-1]].view(rdtype).view(np.recarray)
self.count > 0
method_code = sys._getframe().f_code
_crawled = []
list(run(5, 5))
np.transpose(np.matrix(data))
a = np.arange(4).reshape(2, 2)
form.show()
{{page.title}}
func_name = method.__func__.__name__
x = x + b
zmin, zmax = np.where(z)[0][[0, -1]]
q.get(False)
exec(sys.arg_set)
files = os.listdir(dir)
r.real = a.real * b.real - a.imag * b.imag
print(ps.maybe_random_prime_from_range(4000, 4200))
print(sorted_dict.iloc[2])
y_min, y_max = min(y_data), max(y_data)
self.parent.id
_pix_write_implied_format(filename, self, quality, progessive)
ipcounter += 1
writer = csv.writer(new_a_buf)
max_range = np.asarray(max_range, dtype=int)
parsed_url = urlparse(url)
pwd.len() < minlen
MyClass.does_something()
xfmt = ticker.FuncFormatter(xformatter)
inited = False
session = Session()
dict(posts_page=_posts_page)
self.method = method
values = df.Prices * df.Amount
url = urllib.parse.urlsplit(url)
l1.append(i)
value = get_value(value)
ax = plt.axes(projection=ccrs.PlateCarree())
fileobj = requests.get(url, stream=True)
current_dict = current_dict.setdefault(letter, {})
admin.site.register(MyGroup, MyGroupAdmin)
print(content)
r_ndegen_tile = np.tile(r_ndegen.reshape(1000, 1), 10000)
gc.is_tracked(d)
show()
xs.append(expr)
self.finished.emit()
cursor = conn.cursor()
s.dt.components.hours
df = pd.DataFrame(data_points)
column_names = [d[0] for d in cur.description]
parent = element.getparent()
ints = list(filter(str.isdigit, line.split()))
4, 5, 6, 7
g = f.__globals__
list = []
self.token.join([str(s) for s in value])
sys.exit(1)
c.A7
count_dict[base] += 1
asset_alert_setting_id = Column(Integer, primary_key=True, autoincrement=True)
array[array < 0] = 0
skyscrapers[building_number] = BUILDING
fig, ax = plt.subplots()
meta.reflect(bind=someengine)
table.setdefault((w1, w2), []).append(word)
type(lst)
raise StopIteration()
allelts.add(u)
self.swallow = swallow
y = np.sin(x * 2) + np.sin(x + 1)
C.__init__(self, a, c)
print(results)
print(row)
serv_resp = urllib.request.urlopen(serv_req)
print(name)
print(draw.get_font_metrics(img, artext))
glClearColor(0.5, 0.5, 0.5, 1.0)
(0 * pq.degC).rescale(pq.degF)
func
self._array = array
df
d = {s: 1}
rand_var_2 = tf.Variable(rand_var_1.initialized_value())
tbsCertificate.decode(cert[0])
thread.join()
val + 1
MyApplication()
self.popup.show()
print(name)
menu = wx.Menu()
maps = [dict(), dict(), dict()]
hanoi(pegs, aux, target, n - 1)
writer = csv.writer(f)
print(line)
print(req.text)
print(filename)
df
self._end = end
i = s.find(t)
coords = np.column_stack(np.nonzero(img))
Fin
auth.redeem_refresh_token(service_info.service_resource_id)
story.append(image)
resp_dict = json.loads(resp_str)
p.showPage()
q = q_key.get()
not any(chain.from_iterable(x))
B = np.asmatrix(np.arange(N)).T
y = extrapolator(dayswanted)
sys.exit(1)
print(root.nodes.node[0].PCDATA)
ts = pd.Series(np.random.randn(len(rng)), index=rng)
b_symm = (b + b.T) / 2
tf.add_to_collection(collection, clip_weights)
res = []
root = tk.Tk()
self(*args, **kwargs) + other(*args, **kwargs)
stream.close()
date = sheet.row_values(rownum)[0]
p.print_help()
dx, dy, dz = 1, 1, 2
G.number_of_edges()
outGroup = [e for e in items if not _filter(e)]
cls(data)
counter += 1
img.write(artwork)
assert isinstance(lambda m: m, LambdaType)
pprint.pprint(A)
image = numpy.array(image)
pool = multiprocessing.Pool(initializer=init, initargs=(l,))
print(set1 == set2)
iexps = list(range(length_of_int, -1, -1))
print(foo()[0])
math.atan2(0.0, 0.0)
dfr = dfr.fillna(dfr.max().fillna(0) + dfr.isnull().cumsum(axis=0))
some_time_num = mpl.dates.date2num(some_time_dt)
obj = Child()
a1[i] ^= a2[i]
print(type(my_time))
dataFT = fft(data, axis=1)
team = team_xpath(row)[0]
console = logging.StreamHandler()
keys = list(i.keys())
set_qt_bindings(sys.argv[-1])
fig = plt.figure()
shootnum = int(shoot)
a = [12, 4, 15, 11]
print(i)
self.list = TestListCtrl(self.panel, style=wx.LC_REPORT)
d1 = pickle.load(fp)
d[value].append(index)
self.im = im
result = itertools.chain(qs1, qs2)
print(newurl)
self.assertEqual(some_method(), True)
print(colornames[color])
result = []
[0.0, 1.0, 0.0],
received_socket = socket.fromfd(fd, socket.AF_INET, socket.SOCK_STREAM)
pprint(lod)
df
data = list(input_file)
theta = random.uniform(0.0, 2.0 * math.pi)
bins = np.linspace(0, 1, nbins + 1)
sol = r[(r.imag == 0) & (r.real > 0)].real
lst.append(1)
atexit.register(readline.write_history_file, histfile)
f.write(json.dumps(settings))
count += 1
self.visit(node.value)
new_lst.append(int_i)
os.close(0)
a_list = [(randint(0, 100), randint(0, 100)) for _ in range(N_ITEMS)]
reps
parser.close()
Matrix(M)
data_from_django = {{my_data}}
localFile.write(packet)
angles = [90, 95, 75, 100]
print(line)
print(matplotlib.__version__)
next(cr)
word_length = len(x)
application.listen(9999)
simplex = tri.find_simplex(uvw)
print(value.i)
selflink.allow_tags = True
bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
l = [1, 2]
perm1_map = dict((v, i) for i, v in enumerate(perm1))
print(lines)
matches = [m for m in pattern.finditer(target)]
print(d)
d = dict()
numbers = remove_indices(numbers, indices)
no_digits.append(i)
print(x)
print(custom.vformat(templatestring, [], valuedict))
fd.read()
lines, _ = ax.get_legend_handles_labels()
l.append(x + 1)
xx = np.random.randint(0, 5, 1000000)
arr.shape
fig = plt.figure()
self.high = range_list[-1]
res.append(dic)
insert(d, keyList2, value2)
bts = pytesseract.image_to_string(img)
z = np.diff(np.append(-1, i))
numbers = {int(line) for line in integers}
EMAIL_USE_TLS = False
mylist[i] = item ** 2
db.session.add(user2_from_factory)
cursor.append(dict(zip(fieldnames, values)))
qimg = QtGui.QImage.fromData(image_data)
m = ma.masked_where([True, False] * 5, arange(10))
main(args)
outer_sum
[1]
self.load()
nArray[nArray == 10] = 9999
a = (zfront + zback) / (zfront - zback)
rows, cols = a.shape
patches.append(self.fill(x, y, closed=False, edgecolor=c, fill=False))
event = Event.objects.get(content_type__pk=ctype.id, object_id=self.id)
a = np.linspace(-1, 1, 4) ** 2
li.sort()
first_name = CharField()
print(countOccurencesAtTheEndOfTheList([1, 2, 1, 1, 1]))
keys = bucket.get_all_keys(prefix=key_prefix)
scrapy / linkextractors / lxmlhtml.py
2 + value
popen = subprocess.Popen(args, stdout=subprocess.PIPE)
sched.start()
self.hline.set_ydata((y, y))
1558 < [1]
fig = pylab.figure()
min_score, min_player = min((min(a, b), player) for player, a, b in players)
logging.basicConfig()
size = len(f.read())
endings = numpy.where(diffs == -1)
app.py
self.text = text
print(arr[:])
kclass
result
deg, mnt = divmod(mnt, 60)
arr1[k] = 2
positions1D = np.dot(positions, dims)
bsi = 4
result = model.objects.get(**kwargs)
s[end + 1 - best:end + 1]
c.setopt(pycurl.WRITEFUNCTION, txtcurl.write)
Index = list(set(list(df1.index) + list(df2.index)))
print(node.toxml())
printable_string = [x for x in your_string if x in string.printable]
page = urllib.request.urlopen(url)
s1.values.append(2)
a = A()
cls(name, bases, dct)
app = wx.PySimpleApp()
avariable = thing2
shutil.rmtree(tmpdir)
sample_data_rdd = file_sample_rdd.repartition(160)
output.paste(0, mask=mask)
result = func(x, y)
subsequences.append([data[-1]])
list.append(Food(4))
opener = urllib.request.build_opener(handler)
g.__call__
dir(Bar)
y11, y21 = np.meshgrid(A[:-1, (1)], B[:-1, (1)])
min_x, max_x, min_y, max_y = minmaxes(alist)
m = p.match(line)
func(context, *args, **kwargs)
x ** 2 + y ** 2 + z ** 2 <= 1
soup
frame = pylab.gca()
fridays = third_fridays(date.today(), 2)
self.server = make_server(self.host, self.port, handler, **self.options)
num_rejects = 0
set_trace()
x < -1000
matrix = []
print(sys.prefix)
print(colnum_string(28))
zipped.close()
__builtin__.object
b = a - numpy.fix(a)
False
s = Session()
L.extend([4] * 10)
sourcelines = inspect.getsourcelines(func)[0]
self.v = v
sfile.close()
4805
tempCS1 = plt.imshow(frame, cmap=plt.cm.gray)
n, d = int(n_d[0]), int(n_d[1])
ts.tm_hour
ignore[np.ma.minimum(x11, x12) > np.ma.maximum(x21, x22)] = True
key = get_cache_key(request, key_prefix=key_prefix)
x.Foo()
bins = numpy.linspace(-10, 10, 100)
rv = func(*args, **kwargs)
0
assert True
subprocesses = {}
doctest.testmod()
miny, maxy = -miny, -maxy
regexp - assemble
count = 0
xml = ET.tostring(root)
ax.set(axisbelow=True, xticklabels=[])
i = [0] + numpy.cumsum([len(i) for i in contribs]).tolist()[:-1]
V[..., (0)] + V[..., (1)]
data = np.random.random_sample((20, 10, 10))
df
df = pd.DataFrame(data)
mat.numCols()
curses.mousemask(curses.ALL_MOUSE_EVENTS)
replacement if c[0] == n else match.group(0)
log2int_fast = math.frexp(x)[1] - 1
children = set()
bytes = fcntl.ioctl(fd, _KDGETLED, bytes)
cell.eventson
splitList = match.group().split()
dc.annotation.remove()
print(num)
dst.close()
Fun.name
len(m)
xx = np.lib.stride_tricks.as_strided(xx, shape, strides)
type(bytes)
d = HashableDict(a=1, b=2)
new_pos += 1
a = map(str, a)
self._y = self.y
print(df)
self.__class__(self.func.__get__(obj, type))
self.tvcolumn0.pack_start(self.text, True)
m.show()
ws.Columns.AutoFit()
file_in_memory.seek(0)
show()
attr_name_to_attr[attr_name].get()
request.PUT = QueryDict(request.body).dict()
utc_time = utc_time.replace(tzinfo=pytz.UTC)
newR = np.array(newR)
start + nones + end
apply_vectorized(funcs, a)
buf = f.read(4096)
result = sum(map(mult, pairs))
length_line = 0
cond.wait(timeout - current_time + start_time)
server.serve_forever()
time_a_method(m, s)
print(result)
shifts = [1] * (len(pattern) + 1)
year_start + datetime.timedelta(days=iso_day - 1, weeks=iso_week - 1)
strided = as_strided(a, mask.shape, (0, a.strides[0]))
f
instance = TestClass()
print(df)
plt.sca(current_ax)
filetime = time.localtime(filetimesecs)
len(final_subnets)
i = len(words) - 1
599999900, 600000000
x[1:] += x[:-1]
d
p = argparse.ArgumentParser()
y = [(k, v) for k, v in x if max(d[v]) == k]
o.write(p)
idx = np.unique(index).tolist()
np.clip(dat, 0, 1, out=dat)
image = pyexiv2.Image(sys.argv[1])
some_lib.do_something_with(SomeMockObject)
math.sin(x)
content = gzip.GzipFile(fileobj=some_file).read()
remove = [k for k in mydict if k == val]
print(root.attrib)
self.arr[key]
first_day_of_current_month = date.today().replace(day=1)
bd = os.path.join(b, d)
x = np.linspace(0, 4, 50)
signals.post_save.connect(Revision.send_email, sender=Revision)
towers = np.random.rand(n_towers, 2)
ord(a), ord(b)
g()
response = Response(resp.content, resp.status_code, headers)
xrat = width / float(MAXSIZEX)
raise KeyError
indentstack = [1]
c = vs.mean(axis=0)
data = numpy.arange(0.0, 16.0).reshape((4, 4))
date = models.DateTimeField()
a = list(range(5))
panel.draw()
n = 1
resp.sendRedirect(userService.createLoginURL(req.getRequestURI()))
b.append(6)
char = msvcrt.getch()
[15, 8, 9, 6],
print(ms.group(1).strip())
s = set()
pyDT = from_excel_ordinal(excelDT)
ids = avgDists.argsort()[::-1][:n]
print(do_add(s, 4))
print(link.string)
self.start = start
socket.inet_ntoa(unpacked)
record = self.browse([NewId()])
fp = os.path.join(root, f)
main()
que.put(a * b)
JAVADOC_AUTOBRIEF = YES
app.setWindowIcon(app_icon)
decorator
now_utc = datetime.utcnow().replace(tzinfo=pytz.utc)
n = len(data)
max(freqs)
newlist = list(oldlist | addlist)
spiral_ccw(np.arange(nrow * ncol).reshape(nrow, ncol))[::-1]
print(f(4, 2))
fp.write(part.get_payload(decode=True))
a
movie_dict[actor].append(key)
t = app.jinja_env.get_template(template_name)
loop.stop()
book_author = BookAuthor.objects.get(author=georfe, book=great_american_novel)
a = []
self.wait_for_prompt()
df2
(ds1 + ds2).to_netcdf(new_file)
sp = parser.add_subparsers()
df
x = random.random()
functools.update_wrapper(wrapper, fn)
excerpt = deferred(Column(Text))
np.random.seed(1)
grp1.append(s)
buff.append(line)
p = bk.figure()
out.write(chunk)
max(map(len, values))
counts = list(enumerate(uniq_count(words), 1))
self.assertEqual(captcha_count, 1)
width, height = im.size
(arr - amin) * 255 / rng
output_iter = map(unwrap, heapq.merge(*input_iters))
f = sys.exc_info()[2].tb_frame
key = cv2.waitKey(20)
cmdout, cmderr = cmdp.communicate()
queryset
print(item)
average_values = np.bincount(ID, values[sortidx]) / np.bincount(ID)
subVal[key]
pos = (j - i for i, j in enumerate(lst))
print(word)
b.instance_a.save()
a = a.reshape(a.shape[2:])
x0, dx, dxdy, y0, dydx, dy = ds.GetGeoTransform()
self.parent._fsb_controllers.append(self)
parent_zip = zipfile.ZipFile(parent_zip_path)
context = ogl.CGLGetCurrentContext()
__old__getattr__(self, name)
closedir(dir_p)
counts = Counter()
x = np.fromstring(np.random.bytes(n), np.uint8, n)
c = np.dot(X.T, Y)
next(r)
factor = inversemodp(A[i, i], q)
HTMLParser.reset(self)
print(bar)
interleave(s, t, res + t[j], i, j + 1, lis)
assert isinstance(csv_line[i], str)
series = models.CharField(max_length=50)
post_serializer = PostSerializer(posts, many=True, context=context)
gevent.spawn(read_stream, p2.stderr)
OneOrMore(blockOfText).parseString(bigHonkingString)
Base.metadata.create_all(engine, tables=[SaneTestModel.__table__])
sys.getrefcount(empty)
model = MyModel
opts, args = parser.parse_args()
df_c = df_a.reindex(df_a.index | df_b.index)
plt.ylim(ymin=-1.1, ymax=1.1)
time.time.__name__
bodylist.remove(x)
df = pd.DataFrame([1, 2, np.inf, -np.inf])
mytask.apply_async(args, kwargs, connection=conn)
blob_info = upload_files[0]
stdscr.clear()
permutes.append(list(permutations(values, subset)))
print(res._size())
op(A, B)
status, result
mask = x * x + y * y <= r * r
self.update_prop(legline, orig_handle, legend)
fig, axes = plt.subplots(ncols=2)
N - (fmin + 1) * f2
pygame.display.flip()
hash(1)
itertools.chain(self.vals, self._gen_iter())
self.systemTrayIcon = QtGui.QSystemTrayIcon(self)
tokenizer.transform(sentenceDataFrame).show()
cls
iren.Initialize()
np.import_array()
pickle.loads(pickle.dumps(e))
x.pos[int(x.n)]
pos = networkx.spring_layout(G)
arr = np.ndarray((10, 4), dtype=object)
aSrt = np.sort(a.flatten())
2 * f
start_urls = []
floodfill(painted_map, POINT_STATE[k], 255 - color)
f.close()
self[key] = other[key]
df = pd.lreshape(df, d)
ff.seek(0)
A.__init__(self, name)
zf.write(fpath, zip_path)
np.uint8(np.abs(np.int16(img1) - img2))
x = np.random.normal(size=1000)
y = negate(x)
registered = models.DateField()
start = numpy.array([1, 5, 7], numpy.int16)
b = make_chess_board()
Ay = np.arange(Aymin, Aymax + dy, dy)
node = jinja2.Markup(html)
food_ctx.add((alice, dislikes, pizza))
modules_to_reload.add(name)
reader = csv.reader(afile, dialect=snift)
value
reactor.listenTCP(1025, factory)
False
e.args
m(1)
a = a[~np.isnan(a)].astype(int)
rconsole
stat_queue.task_done()
fields[key]()
fn
s.add(4)
table.show()
o2 = np.argsort(arr2)
production.py
p.feed(s)
cv2.imshow(win, vis)
n = len(matrix)
t.join()
ym_start = 12 * start_year + start_month - 1
weights = faces[2]
data = f.read()
foo = Foo(1, 2)
valid_strings[start] = tuple(seq[start:start + length])
myList, myTuple = list(range(10)), tuple(range(10))
OrderForm(tickets=available_tickets)
[testenv]
self.__dict__
self
it = iter(it)
cb = plt.colorbar(im)
e = etree.fromstring(s)
threading.Thread.__init__(self)
r.withdraw()
self.name = name
resource.setrlimit(resource.RLIMIT_STACK, (2 ** 29, -1))
getline(cin, input_line)
a.__add__(b)
count1 += 1
fig.show()
l[:2]
setattr(TestCase, name, login_testuser(obj))
obj = getattr(obj, attr)
imgdata = urllib.request.urlopen(href)
buf.bind()
ax = pylab.subplot(111)
register = template.Library()
print(countOccurencesAtTheEndOfTheList([1, 1, 2, 2, 2, 2]))
mask = np.ones([len(x_2) - 1], dtype=bool)
help(foo.bar)
print(result)
self.density_water = 0.001
bounds = [(low, high) for low, high in zip(xmin, xmax)]
result = getattr(im, method)
test.paths()
print(string_list)
__main()
convert(f, 2)
a = [1, 2]
env = Environment()
print(test.param1)
self._db_recycles += 1
[node for node, length in path_lengths.items() if length == n]
ns = {}
pool.map(process_all, pathfile, 1)
str(self())
self.tree = [0] * (n + 1)
self.name = name
self.members = set()
g = coo_matrix((ares, (col, row)), shape=(2, 2))
event_date = models.DateField()
device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)
print(line)
s.add(x)
temp = dict()
i = a.tolist().index(2)
an_image.point_data.scalars.from_array(colors)
yet = False
exit(1)
isinstance([], collections.Sequence)
ax.add_patch(rect)
set_x = frozenset(x)
widget.init(data_from_django)
result.result()
x, y = pts.T
data = urllib.parse.urlencode(values)
dt = tz.localize(datetime.datetime(2011, 6, 20, 0, 0, 0, 0))
self.selenium[browser].quit()
print((a, b))
print(conn.list())
sequence[0]
self.__class__.PARAM
floor(2 * (N - i - 1), 1 + 4 * i)
y = x * f(x)
s = list(s)
ims.append([im])
f.read(6)
handler2.addFilter(MyFilter(logging.ERROR))
querylist.union(wordlists[wordno])
sum(1 for v in seq if pred(v))
[seq[i:i + length] for i in range(0, len(seq), length)]
b1 = tf.Variable(tf.zeros([256]))
keepers[key] = i, row[2]
Tprime.sum(-1).sum(-1).sum(-1).sum(-1)
X_test = X[test_indices]
list(dic1.keys()) - dic2
result = []
image_samples.append(im.crop(box))
opts
authenticate(bytearray(creds))
coursesList.sort()
blob_info = upload_files[0]
merge(list1, 0, 2)
x = np.zeros(n)
response = urllib.request.urlopen(url)
combis.append(guess)
fig = p.figure()
result
print(total)
ssplit = string.split()
True
ret, frame = cap.read()
print(a.add(1, 2))
value_to_key = collections.defaultdict(list)
lfilter(num, den, a, axis=0)
foo = Foo()
results[parent(u, mapping)].add(u)
myTurtle.right(50)
description = models.TextField()
response
718.7747248407644,
logger.addHandler(log_handler)
Ol = list(Os)
df[ops[op](df[col], val)]
loc_dt = eastern.localize(datetime(2002, 10, 27, 6, 0, 0))
S1 += len(set(ids))
metainfo = bencode.bdecode(torrent_file.read())
soup = BeautifulSoup(browser.page_source)
server.daemon = True
top = tkinter.Tk()
p.start()
parser = argparse.ArgumentParser()
b = np.copy(identity)
entity = json.loads(data)
print(blah2)
p = Process(target=crawler, args=(domain,))
result = dict((key, len(list(group))) for key, group in groupby(sorted(words)))
now = datetime.datetime.now()
cfg = dev.get_active_configuration()
print(date)
username = db.Column(db.String(20))
vars = {}
p = argparse.ArgumentParser()
t = time.time()
parser = optparse.OptionParser()
lines.append(self.note)
s
bmp.CreateCompatibleBitmap(srcdc, width, height)
encoding_pipeline.fit_transform(fruit_data)
bits = bin(ord(c))[2:]
repr(self.data)
gc.set_debug(gc.DEBUG_SAVEALL)
l[0]
b = np.random.rand(100 * 100).reshape((100, 100))
node_data
self.form = Mock()
EMAIL_PORT = 587
period += 1
mydict = {}
w, h = im.size
counter2 = Counter({k: (v / 2) for k, v in list(counter.items())})
type(t[:1])
table[i][W - 1] = knapsack(i - 1, W)
ff.read()
ax2 = ax1.twinx()
font = cv2.FONT_HERSHEY_SIMPLEX
db.create_all()
root = Tk()
form = Product(request.form, category=2)
res = c.spelling
c = df.columns.values
basename = os.path.basename(name)
ret, gray = cv2.threshold(roi_gray, 250, 255, 0)
ClergySerializer(instance=instance).data
mkl.set_num_threads(2)
PyList_SET_ITEM(p, i, item)
d[k] = v
old_stderr_fileno = sys.stderr.fileno()
last, lastG = 0, 0
subparsers = parser.add_subparsers()
assert len(target) == 1
word = line.strip().lower()
d1 = date(2001, 5, 1)
p = subprocess.Popen(cmd, stderr=outputfile, stdout=outputfile)
msg = server.recv()
folder = client.GetResources(q=q).entry[0]
reshaped = [x.reshape(y) for x, y in zip(vs, newshapes)]
diff_calendar_days = pd.date_range(a, b).size
parse(matches.group(0))
arr.size()
optionmenu.grid(column=column, row=row)
newlist = []
end = len(ranges) - 1
Z = np.sqrt(X ** 2 + Y ** 2) + np.cos(Y)
count += 1
points = np.random.rand(1000, 2)
logits = tf.matmul(hidden, W_logits) + b_logits
print(counter[input_char])
print(bybuf())
print(byline())
print(a, b, c)
audio_fft = np.fft.fft(a, bestFFTlength(len(a)))
digest = hashlib.sha256(pubkey).hexdigest()
my_list = my_list.insert(0, my_string)
A().f2()
QuerySet._filter_or_exclude = _filter_or_exclude
print(df)
replchars.sub(replchars_to_hex, inputtext)
type(b)
pub_date = date.today()
keyed_dict = defaultdict(list)
dept_id = models.CharField(max_length=255)
shadow_password = p.communicate()[0].strip()
bin((1 << 8 | 2) << 8)
date.month
result.join()
ax.scatter(args, color=next(palette))
new_pdf = PdfFileReader(packet)
od = defaultdict(list)
print(sum(df_subset.C * df_subset.E))
cen = -0.2 + 1.2 * np.random.rand()
syncdb.Command().execute(noinput=True)
bool(set(fruits).intersection(fruit_dict2))
ranges = np.concatenate([np.arange(count) for count in counts])
print_set(email.get())
database = db
signal.signal(signal.SIGALRM, handler)
_recursivePop(tree, nodes)
tmpfile.close()
True == 1
img.close()
c = img.layers[0]
type(x)
print(row.name, np.mean(df2))
df
as_strided(b, (n - 1, n + 1), (b.itemsize * (n + 1), b.itemsize))
a = sorted(a, reverse=True)
controllers
helpers
queryset = Bloop.objects.all()
main()
method(self, *args, **kwargs)
a = np.array(a)
M = NP.empty(shape=(10, 5), dtype=float)
changed = [(k, v) for k, v in list(self.byEmail.items()) if id(person) == id(v)]
reversed_dict = defaultdict(list)
print(df2[mask])
R = array.shape[0]
self.items.append(item)
db.put(entities)
msg = clientsocket.recv(1024)
entries = re.split(regex, allLines)
arr[:, (0)] = int(10)
print(difft(time(20, 40, 0), time(22, 41, 0)))
map(numpy.random.shuffle, array)
print(foo.getI())
object_list = object_list.filter(user__in=request.user.patients.all())
result = cursor.fetchone()
self.__refs__[self.__class__].append(weakref.ref(self))
True
df
admin.site.unregister(Group)
DBSession = scoped_session(sessionmaker(extension=ZopeTransactionExtension))
entity = models.ForeignKey(CancellationEntity)
sqldf(q, globals())
test.open()
dispatcher.connect(reactor.stop, signals.spider_closed)
b = numpy.array([(n + datetime.timedelta(minutes=i)) for i in m])
info = response.info()
doc.remove(tag)
sunday = date - datetime.timedelta(days=day_idx)
diam = np.zeros(len(seed))
glViewport(0, 0, self.width, self.height)
result = urllib.request.urlretrieve(self.url)
l[0] = 0
x = df.ix[(0), 5:]
startTs = time.time()
something_useful()
http = credentials.authorize(http)
n_values = np.max(X, axis=0) + 1
y, x = np.mgrid[:nrows, :ncols]
print(cl.run())
res += YIELD
print(f(11))
ipdb.set_trace()
self.users = self.session.query(User).all()
-1
r = np.array([random.randrange(1, 1000) for _ in range(0, 1000)])
Model.objects.count()
x, y = event.x, event.y
b = 2
ws = book.worksheets[0]
__metaclass__ = ModelBase
m[j - 1, i - 1] = 1
new_tuples
estimator.fit(X_digits, y_digits)
meter_row = sel_cur.fetchone()
cmd.Cmd.default(self, line)
inner_result = pool.apply_async(setinner, (Q, G, n))
seq = difflib.SequenceMatcher(a=a.lower(), b=b.lower())
links = sorted(links, key=lambda x: x.popularity, reverse=True)
d[get_key(f)].append(f)
print(df)
b = []
counts = {}
self.print_stats(stats)
reactor.stop()
list(proxy.keys())
app.MainLoop()
dane = c.fetchall()
y.diff(x)
app = wx.App(False)
my_diag = numpy.zeroes((2, 2))
con.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)
params.sort(key=lambda k_v: len(str(k_v[0])), reverse=True)
self.frame.Raise()
self.user = user
myMap[n] = 1
profile_link.allow_tags = True
filename = part.get_filename()
False
psutil.swap_memory()
register.filter(hash)
A = np.vstack((x, np.ones(n))).T
layout.addWidget(self.datetime)
name = os.path.splitext(os.path.basename(sys.argv[0]))[0]
values = np.array((0, 0, 0, 0, 0))
p = [4, 10, 5]
b = form.save(commit=False)
print(s)
l += t + t2
Ht = array([[1, 0, t[0]], [0, 1, t[1]], [0, 0, 1]])
print(xi, yi, value, color)
minsum = min([iter(entry.values()).next()[1] for entry in groupvallist])
c = a[:]
test > 1
result_strings = (s for s in http_strings if not any(e in s for e in exclude))
i1, i2 = p1[0], p2[0]
root.children.append(t(1))
print(df2)
a = np.linspace(0, 2 * np.pi, 500)
client.do_handshake()
xmax = logdata.max()
scipy.version.short_version
v = df.stack().unique()
f(phases)
s = f.read()
patch.stopall()
f.__setitem__(0, 1)
stats.strip_dirs()
data = np.random.randint(1, 10, N)
stopy = bigary - hereary + 1
d[k] = myfun(v)
item = items.popleft()
df
p1p2_chessboard = max(abs(p1[0] - p2[0]), abs(p1[1] - p2[1]))
bad_os()
two = Decimal(2)
protest, 1
dist_lower = distance([triplets[iT][0], listB[iB]])
thirdpartymodule_a.SomeClass.__init__ = new_init
slices.append(slice(r, r + np.random.randint(1000)))
print(-np.sort(-a))
print(MySubClass().a_property)
df
l = sc.recv(1024)
GenPasswd2(8, string.digits) + GenPasswd2(15, string.ascii_letters)
print(schema)
p = np.arange(256, dtype=int)
data2.to_csv(filename)
pool.join()
s = ctypes.cast(s, ctypes.c_char_p)
xlim(0, 5.5)
module = inspect.getmodule(inspect.currentframe().f_back)
x = np.linspace(0, 2 * np.pi, 100)
pympler.asizeof.asizeof(abr)
self.min_set[self.store[key]].remove(key)
[0.68800002, 0.62400001]
matplotlib.rcsetup.all_backends
v = np.array([1, 2])
self.orig_method = getattr(self.obj, self.method)
help(so27.myfunc)
R = np.empty(N, dtype=int)
func = cls.__dict__[func_name]
socket.fromshare(share)
mydict = {a: 1}
past = datetime.now()
logger
self._check_setup()
print(root.Document.Placemark.Point.coordinates)
groups = [funA, funB, funC]
result_list
srcBB = ax1.get_position()
_testee = Testee()
message = MessageForm(request.POST)
result[1, 0, 0, 0, 0]
array = np.array(array)
ax.grid(False)
print(sqc)
n = sum(1 for line in open(filename))
WEIGHTS = np.array([0.4, 0.4, 0.2])
pool.spawn(time.sleep, 1)
self._expensive_operation
str(self._data.values[index.row()][index.column()])
myseries_three.loc[0]
print(data_value.text)
newick = getNewick(node.get_left(), newick, node.dist, leaf_names)
[pep8]
p.memory_percent()
info_data = info.unpack(input.read(info.size))
a[:]
MSWord.Documents.Open(filename)
fcntl.lockf(file_handle, fcntl.LOCK_EX | fcntl.LOCK_NB)
lines = f_in.readlines()
i = 0
m_to_N = np.zeros((n - 1, n - 1))
xy_pixels = ax.transData.transform(np.vstack([x, y]).T)
self.loadFinished.connect(self._result_available)
ax2.set_xticks([])
cam = AVTCamera()
fig.colorbar(surf, shrink=0.5, aspect=5)
spark.createDataFrame([row]).dtypes
print(a.a)
img = images.Image(blob_key=str(profile.avatar.key()))
id = np.where(fdata[1] == fdata[1].min())[0][0]
response = gss_client.session.get(full_feed_url)
G.remove_edge(keys[1], b[keys[1]])
print(m.groups())
logsum += log(p)
p.start()
numpy.finfo(numpy.float64).max
list1 = map(itemgetter(0), origlist)
sys.exit(make_main(sys.argv))
print(groups.mean().b)
offset += size1 * byte_size
print(df)
a += [i]
cr = func(*args, **kwargs)
q.put(url)
plot2 = plt.plot(x, mlab.normpdf(x, m2, std2))
c.my_stuff
RFPDupeFilter.__init__(self, path)
col_mean = np.nanmean(a, axis=0)
python - Qnew
ecdf = np.cumsum(counts).astype(np.float64)
X = dataset[:, :60].astype(float)
Sxx = Sxx + x * x
all = list(range(1, 7))
self.file = zipextfile
print(get_file_names_from_file_number(fds))
File(file_obj, name=name)
a * np.cos(2.0 * np.pi * f * t + p)
iso8601.parse_date(mydate)
print(sdk)
numpy.logaddexp(0, logB - logA) + logA
int(str)
d = defaultdict(int)
fflush(stdout)
curses.init_pair(i, i, -1)
response.status_code
s.update(list2)
df_br = df_b.reindex(df_a.index | df_b.index)
height, width, channels = scipy.ndimage.imread(filepath).shape
process(cl)
INS = lambda x: 72.0 * x
NULL
plt.show()
self.events.append(datetime.now())
recipient = User.objects.get()
std1 = 1.0
self.__class__.instances.append(weakref.proxy(self))
l = max(l, max(longest(elem) for elem in list1))
app = Flask(__name__)
csock, addr = sock.accept()
hash(tuple(sorted(self.items())))
x
self.fields[key].required = False
currentMatch = pattern.search(remainingStr)
input = np.array([1.0, 1.0])
my_instance.b()
a.b_list.append(B())
filemenu = tkinter.Menu(menubar, tearoff=0)
output = mp.Queue()
loci = loci[1:]
exit()
resolutin = 250.25
setattr(self, attr, getattr(other, attr))
session.flush()
x = np.linspace(0, 2 * np.pi, 400)
http_server2.listen(8081)
self.timestamp = time.time()
raw = f.read(4)
recvall(sock, msglen)
g.user = current_user.get_id()
result = _SHGetFolderPath(0, CSIDL_COMMON_APPDATA, 0, 0, path_buf)
controller.authenticate()
filtered = scipy.signal.lfilter(b, a, data)
l2 = [TrackedObject(x, index) for index, x in enumerate(l1)]
v.discard(k)
set(t[0])
violations1 = [k for k, v in list(collections.Counter(df[0]).items()) if v > 1]
lightened25 = lerp(my_color, white, 0.25)
pred = sess.run([prediction], feed_dict=feed_dict)
dY = np.abs(YY - YY.T).reshape((1, Y.size ** 2))
data = np.ones(y.size, dtype=dtype)
print(bytes)
tri[np.triu_indices(67, 1)] = dm
bad_lines.append(j)
d = {}
self.arg1 = arg1
display_name = models.CharField(max_length=255, blank=True, null=True)
out[k:k + cnt] = np.arange(cnt)
t = Timer(20 * 60, timeout)
x509.parse(s)
print(f.name)
value
stokes_list[i] = stokes_line
labels = cls.fit_predict(X_hat)
print(df)
opener = urllib.request.build_opener(cookie)
args[i] = args[i] * args[i]
content_type = models.ForeignKey(ContentType)
filename = args.output.name
serialized.save()
post_save.connect(signals.do_some_stuff_with_mymodel, sender=MyModel)
print(model_admin.search_fields)
main()
b = pd.Series([49, 54, 62, 74], index=[2, 6, 4, 0])
soup = BeautifulStoneSoup(xml_str)
wf.setnchannels(CHANNELS)
better_errs = model.get_error(betterdata, bettermodel)
parse_object = urlparse(url)
hash(key)
f.write(c)
print(dt)
self.label.width(), self.label.height()
locations = np.arange(0, 50, 1)
b = int(max(0, 255 * (1 - ratio)))
yajl.load(f)
ujson.load(f)
req = urllib.request.Request(url)
self._namescallback[channel][0].append(d)
self[k] = v
self.z + x
zipinmemory = io.BytesIO(remotezip.read())
print(line)
s = s.execute()
[float(row_list[0]), int(row_list[1])]
j = jinja2.Jinja2(app)
print(dir(etc))
doStuff()
formset = BuyerInlineFormSet
app = Flask(__name__)
result = [x for x in A if x in B]
g.get_group(0)
long_string
client = suds.client.Client(my_wsdl, transport=WellBehavedHttpTransport())
print(nx.pagerank(D))
jobs = []
s.translate(translate_table)
query = celery.events.state.tasks_by_type(your_task_name)
head.append(i)
assert isinstance(value, int)
response = requests.get(url)
print(x, x is y)
dosomething(alist)
win = curses.initscr()
scipy.maximum.accumulate(x)
dec
settings = propfaid.get_cache()
wallet
main()
self.response.write(w)
sprite = sheet.subsurface(sheet.get_clip())
ax2 = ax.twinx()
signal.setitimer(signal.ITIMER_REAL, seconds)
Py_Initialize()
im = ax1.pcolormesh(t, r, c.T)
id(1) == id(1)
ans = np.array([map(float, mat.next().split()) for i in range(length)])
repeated = np.broadcast_to(arr, (1000, arr.size))
dt_aware = timezone.make_aware(dt_unaware, timezone.get_current_timezone())
res[j] = numbers[f:b]
cursor = conn.cursor()
y_train = Y[train_indices]
main()
col = pd.MultiIndex.from_product([df.columns, [0, 1]])
A().update()
df
exit_status = process.wait()
print(a, b)
database = myDB
app = Flask(__name__)
x = x.replace(k, v)
inblock = 0
scipy.stats.poisson.interval(0.95, data)
mtime = os.stat(full_path).st_mtime
writer.writerow([t, u, v, w, targets[t][u][v][w]])
self.path = path
_exhausted = object()
httpd.serve_forever(variable)
obj.ds.append(d)
df_list_of_list = map(f, row_list[:-1])
deletelang_name[k]
do_something_else_1()
x, y
vec = [(i - 1) for i in dim]
list(s)
fp.close()
sys.exit(1)
self.code_map[code] = {}
axs.add_patch(rect)
lst1 + [x for x in lst2 if x not in lst1]
x + y + z
ax = plt.gcf().gca()
s = set(range(10))
a = np.int64(np.random.random_integers(0, _BLOCK_MAX, blocks_per_flush))
start, end, step = 0, len(out), 1
args = parser.parse_args()
python
c.execute(schema)
x = np.cos(u) * np.sin(v)
s.close()
eq_map.append((coeff, power))
ranges = sum((list(t) for t in zip(nums, nums[1:]) if t[0] + 1 != t[1]), [])
self
client_socket = socket.socket()
len1
l = arr.shape[1] / m
finfo64 = np.finfo(np.float64)
test()
x ** 2
loader = unittest.TestLoader()
cv.CvtColor(frame, frame, cv.CV_BGR2RGB)
foo = choice(elements)
v = self.cache[key] = f(*args, **kwargs), time.time()
form = AuthorForm(request.POST)
U = (np.arange(M * N) / (M * N)).reshape(M, N)
lst.remove(choice)
int(maybeLst)
iqr = qhigh - qlow
CJK_Radicals = 11904, 42191
sys.exit(app.exec_())
print(X_train.shape)
[0, 0]
b.sum()
file2.close()
inputoutput = ArrayType()
print([co for co in c if not any(st.issubset(co) for st in sts)])
self.params = dict(params or [])
nil
self.connection.shutdown(1)
factorial(*[5, 6, 7])
uvw = np.random.rand(n, d)
print(item)
glColorPointer(2, gl.GL_FLOAT, 0, vertices_gl)
bynweekday, byweekday = (), ()
table.rename(index=str)
print(model_tunning.best_score_)
self.obj = obj
lines = [line.strip() for line in handle]
grid.addWidget(text_edit)
B = np.repeat(A[(np.newaxis), ...], 4, 0)
bins = np.linspace(X.min(), X.max(), total_bins)
fly.rect.left = hit.rect.right
iter(obj)
self.Bind(wx.EVT_LIST_COL_CLICK, self.OnColumn)
lis[index[6] + 1]
True
int(x)
a[:, (1)] = x
sB = sparse.csr_matrix(B)
self.client_address[0]
X_sim = csr_matrix([[1, 1, 1, 1, 1, 1, 0]])
result = [example[i:j] for i, j in pairs]
d = dict(COUNTRIES)
print(a)
add.delay(4, 4)
text = f.read()
loop.run_until_complete(task)
W.shape
bool(st.st_mode & stat.S_IRGRP)
r = requests.get(zip_file_url)
homedir = shell.SHGetFolderPath(0, shellcon.CSIDL_APPDATA, 0, 0)
cmap = mpl.cm.Blues
r.findall(strs)[:-1]
right = randint(left + 1, len(L))
ax.add_patch(PolygonPatch(j, alpha=0.5))
a.x = 1
numbers = map(int, list(filter(str.isdigit, input_string)))
print(list(reversed(numbers)))
lol = [list(range(i)) for i in range(5)]
print(latest_file)
inc = incgen()
stderr_queue = Queue.Queue()
VARIABLE5
VARIABLE6
VARIABLE7
VARIABLE8
VARIABLE9
VARIABLE10
VARIABLE11
VARIABLE12
VARIABLE4
print(matches.groupdict())
fg.canvas.draw()
setattr(self, attr, self.get_column(pyQueryRow, i))
im = ax.contourf(xi, yi, zi)
numbers[0]
app.yaml
print(str(s))
df
temp_rdd_dense.toDF().show()
res = []
dictionary[section][option] = config.get(section, option)
i = cv2.imdecode(np.fromstring(jpg, dtype=np.uint8), cv2.CV_LOAD_IMAGE_COLOR)
block = infile.read(BLOCKSIZE)
True
length = len(items)
a.nbytes
print(f.vals[0])
tcks = nax.get_yticks()
out = np.empty(sum(cnts))
print(a, b, err)
c.pop()
cnt = MyObject.objects.count()
img50_nd = scipy.ndimage.interpolation.zoom(img, (0.5, 0.5, 1))
new_bigmat
keys = [0.5, 1]
angle *= 180 / math.pi
dotime(func, int(argv[1]))
self.view = QtWebKit.QWebView(self)
db = SQLAlchemy(app)
row_sums[(i), :] = row_sums[(i - 1), :] + img[(i), :]
ind = np.arange(N)
+yak.update(locals())
ax = axes[i, j]
assert x.foo == 1
Xm = np.where(missing, np.nan, X)
ys = np.arange(512)
s = pickle.dumps(sys)
x, y = [], []
y + 5 * x
df = pd.DataFrame(a)
t0 = time.time()
r
time = json.loads(json.dumps(time))
screen.force_update()
self.pre_app(environ, start_response)
s * 5
[x for x in a]
bed_info = {}
g.append([])
epochdt = datetime.datetime.fromtimestamp(epoch)
1 / 0
sys.stdout.flush()
circles = np.uint16(np.around(circles))
df.gdp = df.gdp.shift(-1)
target = sys.stdin.readline().strip()
layout = QHBoxLayout(self)
days = dict(zip(day_list, list(range(len(day_list)))))
result
result = []
next(myIterator)
use(line)
group = models.ForeignKey(Event)
print(a - b)
l2[4][1:]
A = coo_matrix((data, (row, col)), shape=(4, 4))
server.test(1, 2)
(0)(a, b)
print(next(a))
q = lambda x: tuple(range(x, x + 4))
p2 = os.path.join(relname, p)
doSomethingElseWith(pos.x, pos.y, pos.z)
self.q = queue.Queue()
fig = plt.figure()
c = 2 * atan2(sqrt(a), sqrt(1 - a))
divider = make_axes_locatable(ax)
key
plt.plot(xdata, ydata)
attrValue = attr[1]
True
parsed = urlparse.urlparse(url)
pts.append(temp)
parser = argparse.ArgumentParser()
settings.INSTALLED_APPS.append(app)
manager = mp.Manager()
f = plt.figure(figsize=(10, 10))
self.keyToId = {}
print(y.x.i)
total.update(sample)
result = dict(source_dict)
D12 = round(TOA12 * c, 2)
self.pred(obj) and predicate(obj)
fq[n].append(v)
aa = np.load(f)
X(X, b)
zip(a, b)
out[x] = multidict(*args[1:])
count = 0
UglyGen(x + 1, y, z), UglyGen(x, y + 1, z), UglyGen(x, y, z + 1)
self.destroyed.fire(self)
r = tf.reshape(r, [-1, 1])
print(s)
metadata = MetaData()
chunk = min(bufsize, length)
print(key)
paths()
sender._meta._field_name_cache.append(self)
z = [1, 2, 4, 5, 6]
n += 1
thread.start()
z = chain(x, y)
us2 = td2.microseconds + 1000000 * (td2.seconds + 86400 * td2.days)
all_second_keys = set(key for value in d.values() for key in value)
asdf.owner = request.user
handle.write(arg.data)
session_cookie = SimpleCookie()
tmp = np.empty((4, sy, sz))
gc.collect()
b = complex(-1, 0)
params = libtorrent.parse_magnet_uri(magnet_uri)
event = screen.getch()
[]
n = len(ls)
sys.exit(1)
self.request = request
table = table.fillna(0)
nb = NB()
map(lambda *z: list(z), *a)
A(obj.get_num())
s
fig = plt.figure()
d.extend(x)
shutil.copyfileobj(r.raw, f)
new_attrs = old_attrs[:]
desktop = shell.SHGetDesktopFolder()
pandas.__version__
__library.terminate()
list(map(attrgetter(*fields), listobj))
(wrapper_unpickler, (factory, ParentClass, r[0]) + r[1][1:]) + r[2:]
answer = []
lines = [row.split() for row in lines]
a + b * x[0] + c * x[1] + d * x[0] * x[1]
encodings.insert(0, enc)
k.append(mydict[item])
logmod_rsquared = logmod.score(x, y)
_write_record_to_csv(row[1:])
self.wfile.write(value)
str(self.recipe)
key.send_file(f)
dirname = sys.argv[2]
stream.close()
print(x, y, z)
tup = fin.readlines()
alias.save()
print(cmp(test1, test2))
getname(woohoo)
traceback.print_exc(file=sys.stdout)
new_row = row[:-1]
number_of_pages = read_pdf.getNumPages()
hamming_sets[0].add(l[1] + l[2])
p2, _ = optimize.curve_fit(f, x, y, (0, 0, 0, 0, 0))
now = datetime.now()
method = getattr(builtins, name)
k = min(n, k)
print(convert_consolodate(ranges))
y = [z.element for z in x if x.frobnizzle == 5]
pprint(finalData)
action()
response = HttpResponse()
client_socket.send(size)
plt.grid(False)
win.clear()
Testing(6 / 6)
res
s.ehlo()
obj_set.remove(obj)
print(val)
out = abs(z.T - z)
b2 = [True, False, True, False]
b = np.ascontiguousarray(my_array).view(dt)
process_item_method(self, item, spider)
b = dict(enumerate(a))
[uwsgi]
results = []
print(list(r))
max = self.trell[i][1][k][0]
n_str = binascii.hexlify(n_bytes)
input.read(128)
s = re.search(search, fullstring)
Command2
-codeclimate - test - reporter - -file.coverage
MSWord.Documents.Open(filename)
body = self.rfile.read(content_length)
K.set_value(opt.lr, 0.01)
variance(self.args[0], **kwargs)
D[n, s, x] = sum(P(n - i * x, s - i, x - 1) for i in range(s))
n = len(data)
df_out
x, y, z
ex_type, ex, tb = sys.exc_info()
s = Sound()
print(np.array(foos))
stderr_lines.append(eline)
in_memory_blocks = a.view(np.uint64)
-1
count += 1
xs.min()
plt.title(title)
pixbuf = pixbuf.get_from_drawable(rw, rw.get_colormap(), x, y, 0, 0, 1, 1)
y = np.linspace(1, 10, 20)
args[0], fun(*args[1])
list_display.append(str(x))
setattr(args, self.dest, values)
req = urllib.request.Request(url, data)
root = Tkinter.Tk()
sha.hexdigest()
Perimeter = cv2.arcLength(c, True)
l = len(list1)
a * x ** n + b * x - c
Color(r, g, b)
Installed / home / prologic / tmp / hello - py - c
cur[list[0]] = {}
foo = Foo()
match = regex.search(content)
y1 = np.random.normal(0, 7, 100000) / 10.0
x.start()
jenny = FamilyItem()
fds = [p.stdout.fileno() for p in processes]
data2 = np.ma.masked_equal(data2, 0)
self
self.assertEqual(BRConfig.WEBROOT, sel.get_location())
file_contents = the_file.read()
row_sums[(i), :] = img[(i), :]
im = ax.imshow(np.arange(100).reshape((10, 10)))
otherfile.txt
dist = np.hypot(np.diff(x - x.min()), np.diff(y - y.min())).cumsum()
jpal += 1
[0, 2, 1, 1, 4]
lpSystemTime = ctypes.pointer(SystemTime)
print(getname(f.bar))
packet = sock.recv(n - len(data))
imshow(red)
f.destroyedObjectListener(self)
title = db.Column(db.String(64))
sentRDD = messageRDD.mapPartitions(sendkafka)
fig = plt.figure()
l[n] = f(i)
thread = threading.Thread(target=worker, args=(chunk,))
a = np.arange(16).reshape(4, 4)
salt
fd.write(chunk)
from_zone = tz.tzutc()
lst.sort(key=str.lower)
foo(d)
Base = declarative_base()
S[a] = m
db_field.formfield(**kwargs)
json_obj
sum(map(sum_nested, astruct))
module = make_module_from_file(module_name, program_filename)
print(list(Example))
count = 0
False
groups = GroupSerializer(many=True)
x[index] = 1.0
file
id_arr = np.ones(idx.sum(), dtype=int)
post_syncdb.connect(add_user_permissions, sender=auth_models)
f = sp.sin(x) * sp.cos(y) * sp.sin(z)
label_text_font_size, label_text_font_style, label_width
f.__code__.co_cellvars
[a for a in list2 if a not in set1]
obj = A.__new__(args)
c = np.cumsum(a)
stdout, stderr = pipe.communicate()
c.drawAlignedString(x, y, testo)
a = tonumpyarray(data, size)
x, y = event.pos
seen = []
df.value = df.value.astype(int)
S.mean()
op_func = ops[op_char]
cblas_matrixproduct(typenum, ap1, ap2, out)
x.close()
stream.stop_stream()
[Service]
d.A > d.C
ax1.set_ylim(10.0 * np.ceil(y.max() / 10.0), y.min())
arr = np.ascontiguousarray(arr)
foobar2
self.x & other.x
r.append(a)
data = digits.images.reshape((len(digits.images), -1))
print((test_item.p1, test_item.p2))
trip_id, arrival_time, departure_time, stop_id, stop_sequence, stop_headsign, pickup_type, drop_off_type, shape_dist_traveled
pdb.runcall(test.foo, 1, 2)
c = PublicC()
self.my_init()
print(i)
d.quantize(Decimal(10) ** -places, rounding=ROUND_DOWN)
scale = mode * x
print(UserCreateForm())
{}
Grid.rowconfigure(root, 0, weight=1)
serializer_class = UserSerializer
parser = OptionParser()
data
fig = plt.figure()
oldtype = a.dtype
pet_list.append(pet)
a.append(2)
deletepacket.chksum
sel.start(True)
old_label_image.destroy()
i, j = self.maxI - 1, self.maxJ - 1
print(id(c2))
plt.ion()
body.extend(rv)
rpath
print(decoded)
self.ranges[k] += 1
fig = plt.figure()
result.setdefault(k, {})[property_str] = v
start_server()
DOT11_PHY_TYPE = c_uint
print([(item, tri_tokens.count(item)) for item in sorted(set(tri_tokens))])
t.start()
y = data[:, (1)]
session.remove()
deleterenWin, iren
arr = numpy.array(im)
pairs += s[0], s[-1]
rows = np.random.choice(df.index.values, 10)
np.random.seed(42)
plt1 = fig.add_subplot(2, 1, 1)
data = []
img.setPixel(0, 0, 5)
value = vinterp(xcenter + r * np.sin(angle), ycenter + r * np.cos(angle))
soup = BeautifulSoup(source)
args = parser.parse_args()
getattr(external, name)
parameters = urllib.parse.urlencode(parameters)
ax = fig.add_subplot(111)
print(is_new_style(new_style))
x if x > 100 and y < 50 else y
x = random.gauss(100, 50)
ranked = sx.expanding().agg(lambda x: rankdata(x)[-1] / len(x))
ordered.append(heappop(heap))
acceptable = []
K.sort()
args = parser.parse_args()
print(sorted(d))
88888888, 55555
poly = np.polynomial.Polynomial(params)
myapp.db.drop_all()
m.login(user, pwd)
len(self.datatable.index)
count += 1
errorcodes.lookup(e.pgcode)
main()
file_list = files_to_delete(rootfolder, extension)
autolabel(rects1)
True
porter.stem(greater)
response = urlopen(url)
t1 = time.time()
y = numpy.roll(x, 1)
soup.body.append(wrapper)
ser.setDTR(level=0)
1.0 / sigma * (y - func(x, *p))
db.expire_all()
b = np.ones((2, 2))
self.assertEqual(1 + 1, 2)
reversed_dict = collections.defaultdict(list)
print(len(clf.feature_importances_))
syncdict = manager.syncdict()
arr = np.fromiter(iter(im.getdata()), np.uint8)
DataFrame1.plot(legend=False)
gs = gridspec.GridSpec(rows, cols)
False
combiner = lambda x, y: np.where(x.isnull(), y, x)
1244489871.0
hamming_sets[0].add(l[0] + l[2])
collections.defaultdict(Tree)
g.append(el)
values.append(int(x))
_HTTPConnection.connect(self)
results[obj].append(size)
n, seconds = divmod(t, 60)
push((nextbasesquared, nextbase, 2))
result = SomeResult()
M = arange(10).reshape(2, 5)
results.plot()
self.signal.disconnect(self.receiver)
1, 2
f = urllib.request.urlopen(url)
t = np.arange(0.01, 10.0, 0.01)
root = etree.fromstring(xml)
print(d.shape, len(k))
data = Data()
[self.x - 1, self.y - 1], [self.x + 1, self.y - 1]
data = {}
q, r = divmod(a, b)
doc = html.fromstring(s)
book = xlrd.open_workbook(sys.argv[1], formatting_info=1)
file.open()
G.add_edge(5, 17)
l = line.split()
print(next(generator))
a = [random.randint(0, 1000000) for _ in range(100000)]
xlim = ax.get_xlim()
[sum_vectors(v, w) for w in ws]
drw = ImageDraw.Draw(img)
tuple(sorted(widget.items())) in widget_set
zip(cycle(tup[0:1]), tup[1:])
split = len(l) / 2
instance_method_ref()
x = i + 1
z = r * cos(theta)
i1 = [1, 2]
fetcher = urllib.request.build_opener()
print(z)
print(find_gt(R, x))
print(heapq.nlargest(10, numbers))
l = [0, 1]
my_dict[get_group_from_angle(a)].append(l)
user_name = db.StringProperty()
set(dir()) - set(dir(__builtins__))
repos.git.add(submodule.path)
l2 = [4, 5, 7]
largest_area = sorted(contours, key=cv2.contourArea)[-1]
self._items = dict(*args, **kwargs)
sqlplus.communicate()
input.sort(key=cmp_to_key(cmp_items))
print((item, item * 2))
out = [next(it)]
win.clear()
print(normalized(A, 0))
imp.load_module(name, fh, abs_path, description)
field1 = forms.IntegerField(required=False)
y, x = np.ogrid[-a:nx - a, -b:ny - b]
print(width, height)
out = []
x = data[:, (0)]
ips.append(i)
self.type = ContentType.objects.get_for_model(self.__class__)
A = np.random.random(10)
b * a(a, b - 1)
regex = re.sub(define, lambda m: defines[m.group(1)], regex)
cap = cv.CaptureFromFile(path)
row.update(nominations)
decorator
self = tuple.__new__(cls, arc)
k = item[:-1]
self.device.send_command(CMD_BLINK, 100)
ret.append((s, e))
profile = webdriver.FirefoxProfile()
req = urllib.request.Request(authurl)
[1, 5, 21],
a, b, c = 0, 1, 1
shop = models.ForeignKey()
feed.read()
lSongs = []
this_row.append(val)
root.left = self.insert_node(root.left, element)
assert divisibility_predicate(number) == n - 1 or number == 0 and n == 1
os.stat(arg)
bboxes = []
y /= sum(y)
len(self.__storage) == 0
token, _ = Token.objects.get_or_create(user=original_request.user)
results = expr.parseString(s)
queryset = User.objects.all()
all_idxs = numpy.arange(A_noisy.shape[0])
points = np.asarray(points)
print(df)
plt.xticks(list(range(width)), alphabet[:width])
input_keys = set(self.initial_data.keys())
instance = cls()
print(resp.info())
new_peak = PyPeak()
self.execute()
times = []
list(out)
B = A[idx]
pm = svm_parameter(kernel_type=RBF)
df
transform = ET.XSLT(xslt)
new_cols.columns = list(string.ascii_uppercase)[:len(new_cols.columns)]
t0 = time.time()
print(link)
aws_access_key_id = AxxxZ
turtle.exitonclick()
absdists = np.abs(dists)
dir(p)
lemmatizer = Lemmatizer()
BaseServer.__init__(self, server_address, HandlerClass)
n = self._sock.send(data)
df = df[(df.StartTime <= df.Timestamp) & (df.EndTime >= df.Timestamp)]
l = list(a)
title = StringField()
a, b = tee(iterable)
base._subclasses.add(cls)
listB = [(20 * random.random()) for i in range(20000)]
page.setLayout(vbox1)
draw.text((0, 100), txt2)
set |= Set(form2.objects.filter(keyskills=i))
parser = argparse.ArgumentParser()
epoch_in.append(x)
False
a = np.random.random((10,))
pid = os.fork()
q.put(x)
object2 = ClassB(object1)
sshcon.connect(hostname, username=myuser, key_filename=mySSHK)
d1 * Bo
reactor.stop()
name = models.CharField(max_length=128)
renderer = fig.canvas.get_renderer()
window = QWidget()
simulations_to_run.put({})
Ainv = np.matrix(identitymatrix(n), dtype=int)
z = numpy.polyfit(x, y, 1)
wn.wup_similarity(dog, cat)
f = (x - d) / _diff[:, (index)]
n = (alen - flen) / struct.calcsize(before_char) + 1
deletemetadata[k]
list(islice(c, i))
keep.append(item)
MOUSE_RIGHTUP = 16
vals[i] += abs(np.dot(u, m[j]))
data
sieve = [False] * (limit + 1)
x = np.arange(10)
8, 1, 1, 8
self.appendleft(value)
print(dataframe)
sys.exit(0)
self.response.out.write(template.render(path, template_values))
print([(coin / 100.0) for coin in coins])
isnan(a)
feature_names = np.array(iris.feature_names)
method_to_decorate(self, *args, **kwargs)
a = [random.choice(list(range(1, 7)))]
pathjoin = os.path.join
show()
i = quaternion(0, 1, 0, 0)
values = []
popular_words = sorted(word_counter, key=word_counter.get, reverse=True)
get_thread.start()
out = dict(map(get_key_value, columns))
x = np.empty(len(a))
output = (lambda x=data[2]: x + x)()
expr = Forward()
self.lookup_tables[field][value].append(index)
my_a = A(**params)
result = {}
plt.show(open_plot=True)
print(caller.f_locals)
type.__new__(mcs, name, bases, dct)
self._x = 0
pygame.display.update()
dt_obj = datetime.fromtimestamp(timestamp)
output_df = output_df.reset_index(drop=True)
x
hash(list())
--ignore < catalina.log
my_list[index] = new_item
f.write(c)
output.put(rand_str)
reader = csv.reader(input_file_handle)
max(keys, key=f)
cx2 = self._gen.random_integers(cx1, self.N - 1)
vectorized_array
tree = find_dependent_modules()
entries = (os.path.join(dirpath, fn) for fn in os.listdir(dirpath))
self.queue.join()
models.signals.post_init.connect(self.post_init, sender=cls)
{{self.title()}} - example.com
this_week.append(date)
a = models.ForeignKey(Foo, null=True)
fig.tight_layout()
path.append(previous)
r = random.random()
11 - 2 + (11 - 10)
p = np.linspace(0, 2 * np.pi, 50)
result
rest = map(lambda x: urllib.parse.quote(x), new_base)
Console.WriteLine()
name = cleanco(name).clean_name()
plt.subplot(122)
0
flip_stack_helper(s, t)
self.module
np.stack([np.outer(A[:, (i)], B[(i), :]) for i in range(A.shape[1])])
axdendro.set_yticks([])
socket.__path__
next(reader)
np.random.seed(101)
all_labels = np.array(all_labels)
remainder = dict(remainder)
self[i] = v
pool.join()
a, b = random.sample(indexes, 2)
pform = UserProfileForm(data=request.POST)
wrapper.__name__ = func.__name__
threadA.run()
hough_transform_p(img, templates[0], i)
i += 1
t.start()
d
image.SetMaskColour(255, 0, 255)
split_at = [2, 4, 5, 8, 11]
write_line(indiv, window, coverage, snp)
print(df)
out = np.column_stack((starts, stops))[valid_mask].tolist()
r, g, b = img_file.getpixel((i, j))
math.atan2(0.0, -0.0)
print(id(a), id(b))
m = s.model()
text_cell = first_sheet.cell_value(row_idx, COL_IDX)
myfunc()
found = True
C = splits[1]
query = datamodel.User().all()
points.append((xs[i], ys[j], v))
prefixes = [line.strip() for line in words]
mask = np.dstack([mask, mask, mask]) / 255
test_m = np.concatenate((test_m, q.get()), axis=1)
emp = Employee.objects.get(pk=emp_id)
result_list.append(json2xml(sub_elem, line_padding))
result = []
thread.start()
obj = MyClass()
reactor.iterate()
recursion(i + 1)
new_x.append(x[i])
main_loop = tornado.ioloop.IOLoop.instance()
trainer.trainEpochs(epochs)
plt.plot(dummy)
result = rdd.groupByKey().collect()
sum_array = np.array([compute(i) for i in range(n_points)])
loss = tf.reduce_mean(tf.square(y - y_data))
sumvars_with_intermediates(x, y, z).final
in1 = innertype(*list(range(10)))
W = tf.Variable(tf.random_uniform([1], -1.0, 1.0))
print(obj)
w = gtk.gdk.get_default_root_window()
False
8, array([5, 6, 7]), array([9])
1020068010
end_months = (dt2.year - dt1.year) * 12 + dt2.month + 1
print ()
fig, ax = make_example_plot()
now = datetime.now()
qualname = qpid
a = TC()
test(0, 10)
jobForm.cleaned_data
print(sess.run(A_upper_triangular, feed_dict={mask: npmask}))
logging.getLogger().setLevel(logging.DEBUG)
lis.append(_)
it = iter(it)
wrapper
print(myList[0])
self.events.append(something)
the_dict = {}
ldict = locals()
architecture / linux_host_architecture
X, Y = fig.get_dpi() * fig.get_size_inches()
print(foo.bar, foo.quux)
shutil.copyfileobj(f, tf)
plt.plot(self.dat)
self.name = fn.__name__
figure, imshow(label2rgb(ccompv), [])
0
im = ax.imshow(data)
name = Column(String)
func_wrapper
max_item, max_size = L[0], key(L[0])
(b.ffill() + b.bfill()) / 2
print(df)
expected = array[:, (cols)]
f
numpy_arr = np.asarray(view)
my_norm = Normalize(vmin=0, vmax=5)
contents.append(line)
char * cstring
s.append(a + b)
addr = sys.argv[1]
list_A.append(arr[current_set])
shifts = np.zeros(A.size, dtype=int)
b = Point(x + 1, y)
res = [formula(a, b) for a, b in zip(listA, listB)]
profiler.print_stats()
geoms.append(intersect)
c = [8, 9, 0, 1]
self.plot = pg.PlotWidget()
b[:, :, (1)] = 255
pool.map(do_log, list(range(100)))
df2 = df.copy()
res1 = dict(zip(dicts[0], zip(*[list(d.values()) for d in dicts])))
count = 0
dtg0, dtg1 = itertools.tee(mdtimes)
id0, id1 = l.split()[:2]
shapeX = PyArray_SHAPE(X)
self.matrix = []
scrw.add(self.tview)
image_tk = ImageTk.PhotoImage(image)
bins = algos.quantile(arr[~mx.mask], np.linspace(0, 1, 11))
df2 = df.loc[df.area == area]
views / largemodel_view.py
view.show()
line, = plot(x, sin(x))
A = np.ones((50000000,))
out = np.empty_like(x)
db.save(doc)
a = lil_matrix((4, 4), dtype=int)
print(b)
pprint(list(values))
name = db.Column(db.Unicode(50))
print(tree.leaves())
doTaskA()
points = [(1, 1), (1, 10), (10, 10), (10, 1)]
layout = QtGui.QHBoxLayout()
data.append(df[col_name].values)
print(compiled_code.co_consts)
g.ra, g.az, g.dec
parser = ElementTree.XMLParser()
Recurse(y, number - 1)
print((event, elem, float(f.tell()) / total_size))
result_pic.close()
uid = Column(String(80), primary_key=True)
print(line12)
_file = os.path.abspath(sys.argv[0])
cpy_list = []
p.register(r_fd, POLLIN)
self.replay()
dis.dis(foo)
test()
barwidth = 1
colors = cm.rainbow(np.linspace(0, 1, len(ys)))
Review.objects.filter(venue__pk=2)
cregex_token_iterator(s.begin(), s.end(), r, -1),
df = pd.DataFrame(data=int_matrix, columns=cats)
self.root = Tk()
t.start()
tar = tarfile.open(args[0])
p = multiprocessing.Process(target=f)
time.sleep(int(the_time))
result
interp_i = np.linspace(pad, i.max() - pad + 1, 5 * (i.size - 2 * pad))
self.add_widget(self.my_float_layout)
listener.listen(1)
self.run(statement)
new_dict = {}
banned_words = set(word.strip().lower() for word in wordbook)
numpydata = numpy.hstack(frames)
stiff = stiff.applyfunc(lambda x: together(expand(x)))
np.min(2 * np.arcsin(np.minimum(np.sqrt(a), len(a)))) * radius
data = json.loads(json_text)
total_length / num_words
jinja2.get_jinja2(factory=jinja2_factory)
_get_dict(object).contents.value
score += 1
print(net)
self.session = session
vol = sum(volume[i + 1:j + 1])
cardservice.connection.connect()
print(stored_file.filename)
print(selection_sort(ran))
print(heapq.nsmallest(10, numbers))
lxc.aa_profile = unconfined
pl.figure(f1.number)
df = df[df > 0].apply(lambda x: x / x.max(), axis=1)
fig, axs = plt.subplots(1, 2)
a = b
ToTSize = [sum(row) for row in testdata]
histo = numpy.histogram(num_dates)
X = np.random.rand(1, 20, 40, 50)
idx = s1.loc[(s1 == -1) & (s1 != s1.shift(-1))].index
lines = [line for line in spamreader]
obj = str(obj)
sz = w.get_size()
self._doc + self.attributes_string()
json_docs = []
alias.update_points()
ax12 = fig1.add_subplot(212)
violations2 = [k for k, v in list(collections.Counter(df[1]).items()) if v > 1]
arr = df.values
self.var1 = arg1
logging.getLogger().info(msg.format(**vars()))
print(l[2])
n = 10
client.get_string(key)
sched.start()
modul.func = newfunc
data = np.load(f)
b = temp_a + b
mpb.pack()
image.save(pic, image.format, quality=100)
half * divmod(number, half)[0]
sum(temp)
i += 1
weights = np.array(weights)
start - stop - daemon
raise
self.deletes = set()
data = np.histogram2d(Y, X, bins=[len(Yr), len(Xr)], weights=Z)
islice(primes, 0, n)
Response(g())
data = stream.read(chunk)
abababab
aaabbbc
abcabc
alpha = im.split()[-1]
fig = plt.figure()
print(s.lower())
t = Thread(target=f, args=(loop,))
data = socket.gethostbyaddr(ip)
pprint(d)
s = pd.Series(np.random.normal(0, 100, 10000))
foo = serializers.CharField()
sum((replace_with if i == to_replace else [i] for i in lst), [])
unittest_main()
np.random.seed(42)
np.asarray(res)
cent2ori = np.eye(4)
sys.getsizeof(fs1)
stamp = mktime(now.timetuple())
main()
coord = np.random.normal(size=(1000, 1000, 1000))
elements
False
assert a == b
array_[:] = rint(multiplied)
match = True
dfs.append(df)
mylst = Session.query(MyList).get(1)
print(form.instance.my_field)
new_string.remove(i)
xml = ET.fromstring(contents)
sys.stdout.write(string_type())
self.client
count, division = np.histogram(series)
False
conn.connect()
yacc.parse(s)
l2set = dict()
print(sin_data)
self.send_my_headers()
replace(inputList, flat_results)
app = config.make_wsgi_app()
X = list(range(1, 100000, 1000))
print(s)
output = cStringIO.StringIO()
x2 = next(y)
allobjc = {}
allatt = {}
msg = self.format(record)
b = np.random.random_integers(-2000, 2000, size=(N, N))
obj = self.weak_obj()
bin / gunicorn
acts
contentdiv = contentnav.getparent()
print(message)
b *= ~unified_mask[(np.newaxis), ...]
dict.update(dict2)
pvt = pvt.unstack(0)
R.add(tuple(x))
ax.set_xticklabels(xticklabels, minor=False)
col = len(col_names) - 1
c = con.cursor()
pylab.figure()
target_device.write(content)
fileinput = fopen.read()
prevList = Permute(string[1:len(string)])
n = len(pattern)
list1 = [int(x) for x in list1]
print(sorted(((c, b) for b, c in count.items()), reverse=True))
vertices = np.take(tri.simplices, simplex, axis=0)
conn.close()
False
__builtin__.set
A.B(1, 2)
test(1)
clock = pygame.time.Clock()
args = parser.parse_args()
reps = []
df
monkey.patch_all()
print(sha.hexdigest())
fig = plt.figure()
assert isinstance(IntInfinity(), int)
dir(MyClass)
text = str(html)
self.sum = 0
words.inc(word.lower())
cr.paint()
foo.ModClass.class_method()
ogl.CGLSetParameter.restype = ctypes.c_int
out.show()
print(df)
I, M = im, np.zeros(im.shape, np.uint8)
zip(bins, count)
buffer = StringIO(urllib.request.urlopen(url).read())
result = []
fig = plt.figure()
screen = pygame.display.set_mode(px.get_rect()[2:])
bane.view(np.complex128)
s[1] + s[0]
x = 0
ABC = AdaBoostClassifier(base_estimator=DTC)
html
b.a
clusters = np.zeros(data.shape[0])
type(converted.iloc[0])
template.format(last=y, *x)
pickle.dump(your_data, handle, protocol=pickle.HIGHEST_PROTOCOL)
myapp = MainWindow()
ax.view_init(45, 60)
non_consecutive_combinator(list(range(1, n + 1)), r)
SYNCHRONIZE = 1048576
set(d2.items()).symmetric_difference(list(d.items()))
args[i] = random.randint(1, 100)
BAEtMAsGCWCGSAFlAwQBAjALBglghkgBZQMEAQUwBwYFKw4DAgcwCgYIKoZIhvcN
Ac = np.triu(Ac)
print(start, start.weekday(), prev, prev.weekday())
NP.ediff1d(x)
dialog = QtGui.QFileDialog(parent)
print(x)
print(request.url_root)
D = Counter(words)
match_values.append(_match(query, corpus[m:m - 1 + qlen]))
time(hours, minutes, seconds)
Base = declarative_base()
shift_idx = np.append(0, np.nonzero(np.diff(data_sorted[:, (0)]))[0] + 1)
net.load(model_path)
PLT.show()
plt.plot(xdata, ydata)
list(filter(dct.get, dct))
count += lin
resized = cv2.resize(img, (250, 250))
module = getattr(pkg, item)
strided = np.lib.stride_tricks.as_strided
idx = np.nanargmax(b, axis=0)
result[x_offset:a.shape[0] + x_offset, y_offset:a.shape[1] + y_offset] = a
reactor.listenTCP(8080, web)
assert n <= len(array) and n % 2 == 0
the_canvas.show_page()
proxy.soapproxy.config.debug = 1
self.bmp = wx.BitmapFromBuffer(width, height, frame)
d = {}
cm = 2.54
print(a.max(1))
M.ix[0, 0] = 1.0
df.d = df.a + df.b
[_f for _f in (f(char) for char in string) if _f]
print(a, b, c)
res = pd.concat([df] * repetitions)
y = np.arange(0, 10, 0.1)
print(b.base is a)
show(vform(fig, select))
a.append(1)
vdisplay.start()
maks_length, maks_key
instance = constructor()
records[k] = 0
L.append(codes[int(num)])
(vmax - vmin) * np.random.rand(n) + vmin
codecs.latin_1_encode(x)[0]
model.add(Dense(2, input_dim=2))
assert n == sum(ks)
checkinstance(not_allowedclass)
G = nx.Graph()
driver.service.process.send_signal(signal.SIGTERM)
window = sublime.active_window()
frame = Frame(master, width=200, height=200)
plt.subplot(_subplots[name])
text += get_deep_text(subelement)
1 / (1 + z)
mtrans.Transform.__init__(self)
p = Process(target=grandchild, args=args)
len(set(flattened)) == len(flattened)
parent = tk.Tk()
BUFSIZE = 10
x, y, p, q = map(float, line.split())
d = {}
print(previous_line)
strprime
_CURRENT_YEAR = datetime.datetime.now().year
a = Assignable()
integer.setParseAction(lambda t: int(t[0]))
json_dict = json.load(filein)
pol_ext = LinearRing(poly.exterior.coords)
result.close()
mylist[i] = key
self.x = 2
a2.set_xticks([])
order_check(result)
df1.ne(df1.shift().bfill()).any(1).cumsum().add(1)
a, b = b, a
d_sum[topkey] = {}
sys.stdout.write(data)
iter(d.items())
self.name
print((TOS1, TOS))
ax = subplot(1, 1, 1)
list([p for p in arr if xmin < p[0] < xmax])
r = requests.get(url)
a = [numpy.arange(100000) for _ in range(10)]
sys.stdout.write(p.stdout.read())
raise SomeProblem(value)
Orange.feature.Continuous(str(d.name))
idx = df1.stack().index
zip = zipfile.ZipFile(zipinmemory)
a = numpy.arange(cols * cols).reshape((cols, cols))
app.exec_()
sys.stderr = Logger()
forks = []
res.append(e + 1)
len(x)
x * 2
a = np.random.normal(size=1000)
fig = plt.figure(frameon=False)
new_func_name = my_func
print(v)
5 // -2
hash.set(x, hash.get(target).concat(property))
params
{{micro_form.as_p}}
convert(remain / current_base) + rest_digits[remain % current_base]
type, value, tb = sys.exc_info()
mp = numpy.arange(0, max(data) + 1)
d[key] = sum(map(operator.itemgetter(1), group))
tuple(res)
current + min(distance_to_a, distance_to_b)
qp.loadFromData(image_data)
a = A()
converter = PIL.ImageEnhance.Color(img)
raise StopIteration()
myTurtle.left(25)
loop = aio.get_event_loop()
print(s)
self.remove_edge_by_id(edge)
ax1 = fig.add_subplot(gs[0])
ancestor = widget.get_parent()
print(Al.A)
gridx = np.linspace(-1, 1, 5)
pdf = stats.lognorm.pdf(x, s, scale=scale)
assert len(source) == 1
z = sum((a[:, :, (np.newaxis)] - b) ** 2, 1)
min_keys = [k for k in d if d[k] == min_val]
tup[0] is a
subs = [sample(sub_df, i) for i, (_, sub_df) in enumerate(gb)]
ast.dump(_)
p.terminate()
print(x.shape)
sys.stdin = UTF8Reader(sys.stdin)
a = A()
h = httplib.HTTPConnection(parsed.netloc)
overlap(0, 50, 40, 45)
hasher.hexdigest() if ashexstr else hasher.digest()
addx = functools.partial(add, 2)
print(counter[0])
el1.extend([[]] * (len1 - len(el1)))
data = numpy.array(values, dtype=dtype)
test = record_log(self.logs)(test)
newImage = Image.new(mode, (canvas_width, canvas_height), new_background)
rot = im.rotate(angle, expand=1).resize(size)
th[1:][th[:-1] & th[1:]] = False
d = OrderedDict()
fig = plt.figure()
a = ma.masked_array(a, a == fill_value)
print(e)
sleep(5)
diff_seconds = (mytime - since).total_seconds()
print((num, data))
self.close_connection()
b = a[:len(b)]
traverse(node.left)
any(n % x for x in range(20, 1, -1))
con.ping(True)
sleep(2)
set(a) & set(xyz)
parser.set_document(doc)
print(i)
{}
fig = matplotlib.pyplot.gcf()
primes = (n for n in count(2) if all(n % d for d in range(2, n)))
list(reversed(list(range(diamond - 1))))
doc = fromstring(requests.get(url).content)
x.normalize()
self.foo(n=n)
type(object)
network_select.grid()
self.timer.timeout.connect(self.readData)
qry = qry.filter(Parent.child_count_ex(stime, etime) > 0)
np.array([f0, f1])
np.random.seed(10)
df2.columns = cols
show()
messages[0].attributes
os.chdir(tmp_a)
print(df)
show()
links.append(link)
print(config_root.server.host)
not_all_zero = [any(x) for x in columns]
obj = model_class.objects.get(name=model.name)
counts = np.fromiter(counts_it, np.intp, nnz)
X = [[1.0, -1.0, 2.0], [2.0, 0.0, 0.0], [0.0, 1.0, -1.0]]
content = open(match).read()
str(self) + other
by_bins = dict((k, tuple(v)) for k, v in by_bins_iter)
col = pd.MultiIndex.from_product([df.columns, [0, 1]])
reverse_edge_list = [t[::-1] for t in edge_list]
a.filled(0).sum(axis=axis) * 1.0 / counts
sig = np.sin(2 * np.pi * f * t)
urllib.request.urlopen(req)
(name for name in names if re.match(glob2re(pat), name))
chunk = request.read(handler.chunk_size)
response
self._popup = gtk.Window(gtk.WINDOW_POPUP)
newtype = numpy.dtype(dtype)
list.__init__(self, lst)
plt.ylim(ymin=0)
print(is_perfect_cube(64))
print(dameraulevenshtein(gene_stringify(list1), gene_stringify(list2)))
Py_Initialize()
xyz = np.vstack([x, y, z])
logging.debug(e)
traceback.print_exc(sys.stderr)
self.x, self.y = x, y
btn = Button(frame)
response = HttpResponse()
stations = {}
self.print_help()
xy[1]
b[0, 0]
text = text.lower()
starts[1:] = np.cumsum(counts[:-1])
constructors = [int, float, str]
(0.8, 0.6, 0.6),
A = list(range(10))
plt.plot(numpydata)
mytime += timedelta(hours=6)
print(getargspec(f))
stdout, stderr = process.communicate()
foosparse = scipy.sparse.lil_matrix((N, M))
self.x = x
result = client.read_input_registers(1, 1, unit=1)
self.__fill_right()
config = ConfigParser.RawConfigParser()
values = json.load(f)
TempLake = np.zeros((N + 1, Nlayers))
ax.set_title(t)
new_page
self.subplot.clear()
self._data[key]
plt.matshow(image)
self.seek(0)
array([Y[1], a * Y[0] + b * Y[1]])
mysql.commit()
a = np.arange(24).reshape(4, 6)
xa = np.hstack([[0], x, [0]])
im0 = Image.open(tilefilename)
mprev = exists_re.search(currline)
fq[w] += 1
bar
self.num_gears = len(self.gears)
print(f.tail(5))
signal.alarm(timeout)
parent.list_child_properties()
a[i, j] = random.random()
Dummy()
s1 = Singleton()
gps_epoch = datetime(1980, 1, 6, 0, 0, 0)
bins = numpy.arange(-1, 11)
subprocess.Popen(args)
True
arr1 = array[:i + 1]
sys.exit()
last_monday = datetime.date.today() + rd.relativedelta(weekday=rd.MO(-1))
django.core.management.setup_environ(settings)
fcntl.ioctl(console_fd, KDSETLED, 0)
np.random.seed(1)
sum(generate() for i in range(1000000))
a, b = b, a + b
M[5, 5] = 1
d1 = threading.Thread(target=dep1)
G2 = nx.Graph(G)
out = [f(df.iloc[i:i + N]) for i in ii]
is_active = True
new_data
li = []
assert subclass.__doc__ == parent.__doc__
tree = etree.HTML(s)
bar()
res.get()
result.astype(int)
print(r.pattern)
expr = (a + b * x) / (c + d * x)
formset = QuoteFormset(request.POST)
file.close()
self.color = [1, 1, 1, 1]
L2[1] = 5
x, y = 10, 25
x = np.arange(6)
transaction.leave_transaction_management(using=self.db)
deF = 789
zipInfo.external_attr = 511 << 16
cbar_ax = fig.add_axes(datco)
fd.write(chunk)
binlims = zip(bin_edges[0:-1], bin_edges[1:])
remove_all(v)
db.session.merge(my_new_posts.pop(each.id))
output.addPage(review_pdf.getPage(0))
arr.reverse()
n
nullhandler = logger.addHandler(NullHandler())
Vector(x + y for x, y in zip(self, a))
queryset = Person.objects.all()
index_offset = np.arange(num_labels) * num_classes
Test().seasonal_greeting()
all(a_replaced == a_new)
result = localtime(some_time_object)
[False, False, False, False, True],
print(index_of_last_nonzero(lst=b))
x[(i), :] = np.cos(x[(i), :])
get_col = str(worksheet.cell_value(row - 1, i))
ydata
DEVICES = [0, 1, 2]
c = a + b
indices = np.cumsum(n_values)
dx, dy, dz = xs[1] - xs[0], ys[1] - ys[0], zs[1] - zs[0]
copy[alert_status]
df
out[4, 2] = 1
s = s[::-1]
series.hist(ax=ax, bins=100, bottom=0.1)
form = CustomBarModelForm
pl.figure()
printList.append(line)
obj = self.request.user.account
axicon.set_xticks([])
print(the_matrix[0][1])
[arr[cond], arr[~cond]]
vars(Foo())
client.load_system_host_keys()
self.server_activate()
method.__code__.co_argcount - 1
randomList
fig = plt.figure(1, figsize=(5, 5))
numpy.float64(1.0) / 0.0
count = Counter(x)
obj = json.loads(line)
my_logger.addHandler(handler)
not bool(+b_count)
cv.EqualizeHist(image, image)
t = dt * np.arange(num_samples)
{{data | safe}}
po.close()
print(hello_ext.greet())
result.append(-1)
np.random.seed(6)
client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
self.children = collections.defaultdict(lambda : self.__class__())
end = time.time()
model.add(Dropout(0.5))
l2norm_inv = tf.rsqrt(tf.reduce_sum(x * x, dims, keep_dims=True))
dist = (om1 - om2) ** 2
mylist = []
result.__doc__ = cls.__doc__
frontier_index += 1
Departure_Date.objects.all()
Y[:, (2)] = 2
imsave(target_path, image)
foo.save()
amounts = []
postal_code = db.PostalAddressProperty()
vect = np.arange(float(N))
cols = df.columns.difference(unused_cols)
myResult.append(key)
total += numa
self.path == other.path and self.title == other.title
sample = random.sample(yourlist, sample_size)
optionN = True
list(ChildForm().fields.keys())
W = np.asmatrix(np.arange(N * N).reshape(N, N))
qry = session.query(Group).order_by(Group.name)
tmax += 2 * np.pi
(g[1] for g in groupby(iterable, f))
V[i] = np.sum(dV)
buffer = bytearray(size)
dict((next(i[1])[0], list(next(groups)[1])) for i in groups)
df.index = list(range(i * chunksize, i * chunksize + len(df.index)))
dice = random.randint(1, 6)
self.process.started.connect(lambda : self.runButton.setEnabled(False))
items.reverse()
self._data_filter = {}
result
self.Bind(wx.EVT_CHECKBOX, self.onCheckChangeBG, self.cbBG)
B = A[:len(A) / 2]
res = defaultdict(list)
x = mu + sigma * np.random.randn(N)
f = opener.open(req)
s.read()
html4css1.Writer.__init__(self)
a = QApplication([])
column_index = Ks.indices
skyscrapers[-i] = AIR
ax = fig.axes[0]
quote2.text
transaction.enter_transaction_management()
pylab.figure()
1 / (N - 1) * autoCov
(2, 0) - 0.0182867906276
b = np.sort(a)
B = numpy.zeros(len(A), dtype=int)
r = s.get(url)
writer = csv.writer(output_file)
x = np.arange(10)
print(l)
print(df1)
foo = Foo()
properties.append(val)
do_something
parser.set_document(doc)
dbCursor.execute(sql)
assocs_exist
seen_add(k)
-some_project2
channel = connection.channel()
image._dump(format=self.get_format(image))
cC = pd.cut(C, 11)
reader = csv.reader(lines.splitlines(), skipinitialspace=True)
C = np.cov([x - x.mean(), y - y.mean()])
feed = f.read()
vals.append(frame_from_dict(v, depth - 1))
print(quote)
recreatedModel.load_weights(fname)
a = []
stiff.simplify()
b = a
new_val.append(x[2])
imageItem.save()
f_inrange
count = IntegerField()
self.error_handler.check_response(response)
n = ctypes.cast(m, ctypes.POINTER(someTime))
alts = np.arange(1, 1000, 21.717)
pos1 = ax.get_position()
15 % 4
f.write(file_data)
resp = requests.get(dls)
cls = KMeans(n_clusters, n_jobs=-1)
self.celery.terminate()
rows[:, :] = [255, 0, 0, 255]
choices = numpy.array([[0, 0, 0], [255, 255, 255]])
children = []
hist[b == bins[0]] = 0
wb = excel.Workbooks.Add()
t = range_tuple(1, 2)
queue.put(temp)
signal.signal(signal.SIGALRM, lambda *args: handle_alarm(self))
logger = logging.getLogger(__name__)
plt.scatter(x_arr, y_arr)
tar.addfile(tarinfo, StringIO.StringIO(data))
p.join()
y.shape
data.append(name)
m.set(r, c, 0)
n = a.shape[0]
ef
_write_to_cache(cache_key, value)
[bar.set_x(bins[i]) for i, bar in enumerate(b)]
d.cards.append(card)
seen = set()
scatter_plot.set_facecolors(new_facecolors)
ret = _aligned_array_type(name, (aligned_array,), d)
b = np.ascontiguousarray(B).view(rowtype).ravel()
ds2 = set([tuple(values) for values in df2.values.tolist()])
lines = []
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
a[i] += 5
[0, 0, 0, 0, 0, 1],
popt, pcov = curve_fit(fourier, z, Ua, [1.0] * 8)
plt.figure()
mantissa * 10 ** exponent
a.coeffs()
raise web.nomethod(cls)
app = QtGui.QApplication(sys.argv)
int(numre.search(s).group())
workbook = writer.book
JTIwQXV0aG9yaXR5KDgpLmNydDBNBggrBgEFBQcwAoZBaHR0cDovL2NvcnBwa2kv
app.grid()
cj = cookielib.LWPCookieJar()
a = models.CharField(max_length=42)
pub_dict[p.key] = []
result[key] = list(v[0] for v in valuesiter)
same_edge_id = graph.get_eid(source_vertex_id, target_vertex_id)
indexes = mydict.setdefault(item, [])
print(numbers)
self.application.pc.connection.channel(self.rabbit_channel_in_ok)
weak = weakref.WeakValueDictionary()
main()
worksheet = XSCRIPTCONTEXT.getDocument().getSheets().getByIndex(0)
value = m[1]
print(total_length)
hashed_array = (base * array).sum()
orig_indices = xs.argsort()
f = lambda *args, **kwds: self.fn(obj, *args, **kwds)
d = deque(list(range(5)))
api = restful.Api(app)
PUSH(map)
data = A.flatten()
Relational(all_on_left, sympy.sympify(0), op)
list(chain_(map(C, chain_(map(B, A())))))
numbers = map(int, numbers.split())
epoch = datetime.datetime(1970, 1, 1)
print(lengthy_thingy.__len__(lengthy_thingy))
items = list(range(10))
y12, y22 = np.meshgrid(A[1:, (1)], B[1:, (1)])
True
libc.prctl(16, byref(buff), 0, 0, 0)
cv2.destroyWindow(winName)
do_more_stuff()
a.apply(func)
print(solution2)
time.sleep(1)
raise
low, high = ax.get_ylim()
arr = _owndata.test()
x_key = x[1]
indice = numpy.where(y != 0)
values(np.arange(len(A)))
print({key1: key2})
pylab.ion()
result = []
result_ch.send(f(*args, **kwargs))
val
pprint(res.asList())
args.parser.print_help()
princ = cc.principal()
print(r.json())
http_server.listen(port)
s = timedelta()
d = {}
self.mainLayout.setMargin(10)
n = json.dumps(m)
chan = ssh.invoke_shell()
serves_pizza = models.BooleanField()
myFile = csv.writer(fp)
a.py
mtransforms.Transform.__init__(self)
d = Dummy()
mat.move(7, 6, 0, r=True)
self.canvas.add(self.children[0].ig)
print(i)
func()
plen = len(lst) / n + (1 if rest > 0 else 0)
keys = set(sum([list(dic[topkey].keys()) for dic in dicts], []))
df
username = session.settings.key().name()
print(args.files)
_helper()
message
chid.py
dict(list(grouped))
p0 = sy.array([1, 1, 1])
grayed_rgb_color = hsv_to_rgb(*grayed_hsv_color)
print(listEven)
webpage.close()
patterns = zip(*[table[p] for p in group])
myimg = models.ImageField(upload_to=img_file_path)
math.sqrt(x)
Image.open(infile).save(outfile)
a, b
myprocess.stdout.close()
b_bins.agg([mean, median])
exc_info = sys.exc_info()
listbox = tk.Listbox(master)
df_test = pd.read_csv(filename, nrows=100)
print(ch)
print(lines.shape)
o.unschedule_all()
not any(any(inner) for inner in x)
url = Field()
plt.yticks(y, yticks)
y = np.vstack((x - 1, x, x + 1))
data = urllib.parse.urlencode(values)
int(zahl)
sys.getrefcount(astrd)
t = t.setdefault(k, {})
os.close(fd)
abs(a - b) <= max(rel_tol * max(abs(a), abs(b)), abs_tol)
print(date - delta)
[0, [0, values, 2], 2]
a = datetime(2010, 12, 5)
factorise(4999)
[2, 491]
self.x = x
L = np.polynomial.legendre.legval(x, np.identity(50))
clf = RandomForestClassifier(n_estimators=20, max_depth=5)
print(sys.argv)
llcrnrlon = lllon, llcrnrlat = lllat, urcrnrlon = urlon, urcrnrlat = urlat,
Dictionary = dict(Arr)
df
ax2 = fig.add_axes([0.05, 0.475, 0.9, 0.15])
ancestors_descendents.add(ancestor)
type(self)(self.default_factory, self)
d2_keys = set(d2.keys())
Py_Initialize()
fig = plt.figure()
install_miniconda
items = []
print(np.ma.compressed(m_))
print(temp.array[:])
xor_2str(xor_2str(and_2str(x, y), and_2str(x, z)), and_2str(y, z))
Session = scoped_session(sessionmaker())
b_o = tf.Variable(tf.zeros([n_out]))
maxlen = np.max(pairs, axis=(0, 1))
yedges = np.linspace(-10, 10, 100)
m, _, _, _ = np.linalg.lstsq(G, f)
result_list.append(input_list[i] * input_list[j])
temp = a[0:1]
batch_size = tf.shape(output)[0]
self.connection.publish(self.key, data)
s = 2 * ((p1 + p2) / 2) * (1 - (p1 + p2) / 2)
args = parse_arguments()
func(*listOfFiles)
print(isPower(5, 5))
count = (i + 1) * (n - i)
out += arr[1:-1, :-2]
res = OrderedDict()
result = []
unittest.main()
print(data)
chBuf = create_unicode_buffer(BUFSIZE)
locale.atoi(s)
result = []
print(root.getpath(e))
ymulti = multiroll(x, shift)
a[:, (0)] = np.min(points, axis=0)
a, b = b, a + b
html = response.read()
s = pickle.dumps(lambda x, y: x + y)
root.children.append(t(2))
count += pattern == [row[j:j + ncols] for row in area[i:i + nrows]]
a = i * x
sum(a)
br = mechanize.Browser()
result
pdb > pdbs.r()
doc = ElementTree(node)
CMD + B(OSX)
print(line)
dt = dateutil.parser.parse(date)
164
(a1, min(b1, a2, b2)) if a1 < a2 else (a2, min(b2, a1, b1))
fig0, ax0 = plt.subplots(1, 1)
points.append((-1, 0.5))
fig = gcf()
lens = np.array([len(item) for item in v])
mydict2 = {}
print(item.name, item.birthday)
bagoftricks.bagoftriks.geofind()
block = f.read(block_size)
root
print(r)
sys.excepthook = logexception
total_size += os.path.getsize(fp)
A = np.random.rand(N, N, N)
x = df[milestones_df.index[milestone_index]:df.index.max()]
self.foo = foo
out = np.empty(N)
midpoint = vor.points[[p1, p2]].mean(axis=0)
base.Main()
outer_fn()
Like.user_likes_article(request.user, article)
[[n]]
c = MyClass()
x[x > 1] = 1
assert len(a) == len(b)
wrapper
threads = []
b_padded = np.append(b, np.zeros(pad_size) * np.NaN)
print(list(dict.keys()))
nest([x], n - 1) if n else x
stdout, stderr
df2
A_noisy[outlier_idxs] = 20 * numpy.random.random((n_outliers, n_inputs))
False
mylist.append(t)
s.send(dst_addr + src_addr + ethertype + payload + checksum)
y = np.ones_like(x)
seen = list()
self.memo.update(json.load(f))
result = {}
process(i)
PyList_Append(list, dict)
self.sleep_time = sleep_time
i = sum_a.index(min(sum_a))
d
fpr[:p + 1], tpr[:p + 1]
pylab.plot(freq, numpy.abs(Y))
2 * t
[f[value]] + multimap(f[value], f, count - 1)
pixPunit = trans.transform([(1, 0), (0, 1)]) - ax.transData.transform((0, 0))
self._close_database()
future_time = utc_time + timedelta(90)
self.values = values
t = t.upper()
getcontext().prec = 6
self.query.get_count(using=self.db)
df.columns.names = df.columns[0]
d.close()
c = tuple(map(sub, a, b))
a[:]
x(1)
garbage = []
b = f.read(1)
out = np.empty((m, o), dtype=np.result_type(A, B))
exit(1)
combined = numpy.zeros(len(neg) + len(pos))
self.getter(instance, self.name)
listOfStuff = [a, b], [c, d], [e, f], [f, g]
module = inspect.getmodule(fun)
self.x = 1
proper_name = name.title().split()
cache[to_calc]
options, args = parser.parse_args()
recursive_del(a, keepset)
com.setDTR(False)
current_set.append(item)
parser = argparse.ArgumentParser()
r, c = np.unravel_index(a.ravel().argsort()[:4], a.shape)
print(StringFormattingParser.getKeyNames(value))
sorted_pairs[0][1]
logger.addFilter(ContextFilter())
show_defaults(foo)
print(mysql_time_epoch)
1
next(self)
base = urlparse.urlparse(base)
a[1:1] = b
n = iter(range(len(L) - 1, -2, -1))
y = np.mgrid[1:9:120j]
d = [tuple(int(el2) for el2 in el) for el in c]
mydict2
common = set(x[0])
dx_dt = np.gradient(a[:, (0)])
a = formA.save()
output.write(line)
self.lbl.configure(text=data)
needs_pressing = False
self.pred(obj) or predicate(obj)
people_map[name] += int(number_str)
main()
created = models.DateTimeField(auto_now_add=True)
ax1.set_yticks([])
print(Bar.x)
a = set()
dir(g)
l = []
p.daemon = True
server = smtplib.SMTP(SERVER)
ch = f.read()
sample = random.sample(rects, NUM_RECTS)
ncolors = len(colors)
utc_secs = time.ctime(utc_secs)
runit(lambda : cube_generator())
filepaths.append(filename)
floor(0, 5)
s[axis] = slice(start, stop)
ret.append(np.zeros(fixed_length))
mngr = plt.get_current_fig_manager()
print(seq.dump())
{}
b = bytearray(s)
X.mask
w.Sheets(1).Copy(wb.Sheets(1))
vectorizer = TfidfVectorizer()
type(x).__name__
pyparsing.Optional(aTag)
fd, filename = tempfile.mkstemp()
jsoned = json.loads(x)
g = abs(g)
data.update(value)
idx_begin = A.indptr[i]
logOutput.moveCursor(QTextCursor.End)
s_as_str = codecs.charmap_encode(s)[0]
absp = os.path.abspath(ProgPath)
iterables = [iter(it) for it in iterables]
from_date.replace(year=from_date.year - years)
dis.dis(code.co_consts[1])
stack = [[]]
_data = self.request.recv(1024)
self.b = b
prob_list[sel1][0], prob_list[sel2][0]
ip_dict = dict(zip(ip_addresses, list(range(len(ip_addresses)))))
count += 1
samples.append(line)
stdout.write(resultString)
body = mail.get_payload()
r4 = next(reikna_norm_rng(seed2, rows, cols, mu, sd))
Ah = np.vstack(A)
pickle.dump(classifier, output)
manager = mp.Manager()
answer = {}
rolling_window(b, 100)
corner12 = [0, 1]
f(*args, **kwargs)
new_style.append(line)
mylist = [100, 2000, 1, 5]
data.append(v)
2
config = ConfigParser.ConfigParser()
self.calls.append(self.current)
a % b
[(k, v)] = list(d.items())
d.set_state(gst.STATE_PLAYING)
key.upper()
self.char_count.grid()
y = np.random.rand(100)
signal.alarm(t)
log(x ** 72) / log(2)
plt.show()
node_to_dict(instance, suds_data)
pool = Pool(processes=16)
False
os.mkdir(dir)
[[current]]
d = docx.Document()
a, b, c = np.unique(data, True, True)
pdf_text_object = canvas.beginText((PAGE_WIDTH - text_width) / 2.0, y)
enc = base64.urlsafe_b64encode(test)
json.dumps(self._items.get(name))
True
TOA12 = Ta - Tb
ax.set_title(x_str)
self.separator.join(ret)
partitions = [data[i:i + n] for i in range(0, len(data), n)]
i = i + 1
xml.sax.handler
p.join()
overflowed = (number & 256) >> 8
False
source = browser.page_source
self.window.set_size_request(200, 200)
fail()
autorestart = true
comm = MPI.COMM_WORLD
by_parent[branch.p].append(branch)
print(field, value)
d = etree.HTML(s)
form = CustomForm
A = A[::2]
varargMethod(someArgs)
c.wait()
[x for x in a if x not in b]
result
queue_state = channel.queue_declare(queue, durable=True, passive=True)
dog.save()
IPython.embed()
cstr = (ctypes.c_char * BUFSIZE)()
r = requests.get(url)
main.object1[0]
raise AttributeError()
parent_mock._kids
pxarray = pygame.PixelArray(surface)
print(other.f(1))
valid = set(string.ascii_letters)
sum(tupleOfTuples, ())
Z *= np.exp(0.25j * np.pi / 2.0)
words = lst2.split()
x = 1
lcd.setSegmentStyle(QtGui.QLCDNumber.Flat)
self.already_computed[index]
ntup = itertools.tee(iterable, n)
False
stdout, stderr = p.communicate(input=input)
fig = plt.figure()
driver = webdriver.Chrome(desired_capabilities=d)
words[last_p].append(word)
proc.communicate()
map_level(double, data, 2)
m.press(x, y)
win.refresh()
f.read()
print(word)
fib_to(20)
opener.open
myfile.writelines(var1)
city = models.CharField(max_length=150)
last_seen_date = daterow.text
result = np.zeros((len(x), len(uniq)), dtype=int)
clientThread.start()
json.dumps(theQuery)
dt = 4e-08
perm_list.add(tuple(temp))
[list(u.args[:2])] if isinstance(u, Interval) else list(u.args)
cus_Y4o9qMEZAugtnW
t.create()
wrapper
func_decorator
BOW.add(dsc)
house_list[new_house].window_list.append(Window())
mongo = PyMongo()
i = 0
results = timer.timeit(10000)
point = geom.Point(x, y)
out += arr[2:, 1:-1]
first, middle, last = [0], list(range(1, n)), [n]
np.array(r, dtype=np.integer)
data = json.loads(cleaned)
setattr(cls, field_name, field)
test_import.py
len(np.unique(sample_ix))
f_no_opt = types.FunctionType(code, globals())
(0.01).hex()
caller = inspect.stack()[1][0]
ctx.set_verify(SSL.VERIFY_PEER, verify_cb)
Qapp = QApplication(sys.argv)
z.T.dot(z)
p += 1
foo.__code__.co_consts
[2, 4, 1],
plot(x, interp(x, x[y != 0], y[y != 0]))
self.listWidget.setSelectionMode(QtGui.QAbstractItemView.MultiSelection)
app.add_autodocumenter(SimpleDocumenter)
db = SQLAlchemy(app)
xyz(x)
repr(self.val)
results.append(fullname)
p.start()
pl.show()
response += read_bytes
Py_Initialize()
mylist = []
stacked = numpy.vstack((a, fill, a))
s.add(i)
l2(1, 2)
char
format(1)
yint = list(range(min(y), math.ceil(max(y)) + 1))
w1back = numpy.array(json.loads(w1string))
print(df)
nx.path.bidirectional_dijkstra(G, 1, 4)
npad = (0, 0), (1, 2), (2, 1)
X = boston.data
stringfier
fig = plt.figure(figsize=(8, 6))
os.mkdir(dirname)
mycounter
xdebug.remote_enable = 1
self.name
words = len(word)
wait(time.Millisecond * 200)
self.exclude(groups_set__pk=group.pk)
-1
self.flip()
yl = ax.get_ylim()
index = tf.range(0, batch_size) * max_length + (length - 1)
page = urllib.request.urlopen(root_url).read()
key = cv2.waitKey(10)
time.sleep(pause)
a, b = b, a + b
j.ra, j.az, j.dec
passphrase = base64.b64decode(passphrase)
context.extend(after_buf)
xpointer = ctypes.addressof(asdouble)
result = dict()
data = eval(input())
reshaped1.show()
quit()
self.modified_date = datetime.datetime.now()
sigma = np.sqrt(2) / n
y = x * x
array([])
command = e.get()
p = figure(x_range=[0, 10], y_range=[0, 10])
save()
text.append(line[:-1])
N = len(X)
event.Skip()
res = defaultdict(list)
print(r.json())
row_indices, col_indices = np.nonzero(both_top_n)
print(i, sub_seq(li, i))
objectify.deannotate(root, cleanup_namespaces=True)
a[i]
True
df_dict = {}
uniq = []
x + y
s.quit()
p.close()
job.hour.every(4)
canvas = Tkinter.Canvas(window, width=image.size[0], height=image.size[1])
xfmt.set_useOffset(10000)
spaces = sum(c.isspace() for c in s)
get(True), get(False)
cols = []
oname = sys.argv[2]
connection_file = os.path.basename(connection_file_path)
a.newMethod()
sys.exit(1)
name = get_name()
L_in.insert(idx, new_v)
raise MyError()
MULT(z, table[index], z)
sha.hexdigest()
level.extend(tree(el, indent + 2))
self.map[val]
youtube_regex_match
rank_cards_map = {c: i for i, c in enumerate(rank_cards)}
b = os.read(fd, blksize)
False
query = self.session.query(self.model).filter_by(mid=term)
~np.in1d(Ad, Bd, assume_unique=True)
vecfunc = np.vectorize(myfunc)
cam.start_camera()
driver = webdriver.Firefox()
assert isinstance(line, str)
post = np.sum(npseq[i + 1:]) / (n - i - 1)
win.set_colormap(rgba)
next((result for result in comparer_iter if result), 0)
nf.write(contents)
ascii_lower.symmetric_difference(candidate_lower)
loop = asyncio.get_event_loop()
filename = os.path.splitext(base)[0]
result[widget_type].append(app)
print(str(myList))
self.serversocket.bind((socket.gethostname(), i_port))
print(np.mean(figure > 0.5))
foo = [1]
proc = subprocess.Popen(sys.argv[1])
print(res.getheaders())
email.utils.format_datetime(dt)
ec2 = boto.connect_ec2()
Ti.App.exit()
rows = models.ManyToManyField(Row, blank=True)
reductions = np.column_stack((start, end)).ravel()
print(new_string)
value[0]
weights.append(max_weight * np.random.random(numtimes + 1))
tuple(serialize([item for item in obj]))
np.sqrt(((x1 - x2) ** 2).sum(axis=0))
result = conn.execute(query)
self._content.read()
f = lambda x: x
self._func = func
cell = make_closure_cell(5)
age = db.IntegerProperty()
axes_1.add_patch(Ellipse1.art())
sorted_pairs[0][0]
foo.bars.add(*pk_list)
p = Pool(4)
value
ax.dataLim.update_from_data_xy(xy, ignore=False)
lista_elegir[indices]
traverse(node.right)
myfunc()
grid = list(zip(*grid))
print(p(42))
output = p2.communicate()[0]
True
datadex = get_dict()
test = Test(sys.argv[1:])
results = pool.map(starfoo, zip(words, numbers))
self.data = data
req = urllib.request.Request(url, data, headers)
writer.save()
os.close(1)
o.subscribe(c.instance_handler)
no_proxy_opener = urllib.request.build_opener(no_proxy)
module.__path__ = [os.path.dirname(os.path.abspath(file.name))]
print(df)
spec.loader.exec_module(foo)
elen, vlen = int(elidelen), len(value)
acl = key.get_acl()
sum_y = np.sum(arr[:, (1)])
result
b = numpy.array = [4, 5, 6]
group = map(itemgetter(1), group)
last_col = len(cols) - np.where(cols[::-1] == False)[0][0] - 1
circle(maskCirc, center, radius, Scalar(255), 5)
crawler.crawl(RaListSpider())
y2 = np.random.normal(-10, 10, 100000) / 10.0
r = random.randint(0, i)
wr(n, val)
col_index = list(np.arange(a.size))
(word[i] for word in words)
x2_Kaxs[j] = [random.randint(0, 9) for k in range(random.randint(1, 5))]
table_name = self.model._meta.db_table
print(readFileObject.readlines())
handler.setFormatter(formatter)
pprint(B_rref[0].applyfunc(lambda x: mod(x, 5)))
a = datetime.timedelta(minutes=1)
self._mod = __import__(modname)
print(first_arg_unicode)
ax.autoscale(tight=True)
self.logentry = []
form.instance.user = request.user
heap = []
no_background = np.array(no_background).T
tags = ListField(StringField())
strcpy(cpy, str.c_str())
mother = names[0].strip()
BEGIN
ELSE
pathB = cheapest_path(path_list, B, [])
zip(a, b)
db.documents.insert(entity)
root = Tk()
[myfunc(a, b) for a in myarray]
self.right = right
start, end = seq[0], seq[0]
offset = 0
y = normal(0, 1, n)
show(p)
raise CTError(errors)
SERVICE, DESK, ANALYST - IT - Support
wm.add_watch(filename, mask)
ax = fig.add_subplot(111)
lst[:] = range(1, 4)
phones = PhoneSerializer(required=False, many=True)
b2 = set(b)
django_file = ContentFile(result_pic.getvalue())
m_t.release()
readline.remove_history_item(readline.get_current_history_length() - 1)
conf = ConfigParser.ConfigParser()
itertools.starmap(func, zip(*args))
dict = pickle.loads(tcp_recieve())
fig = plt.figure()
linkers.append(arg)
e = Entry(win, width=10)
j = int(j)
tree = et.fromstring(xmltext)
mylib.do_something()
self.count = 0
type(io.BytesIO.read)
args = request.args.copy()
log.startLogging(sys.stdout)
SGMLParser.reset(self)
dir = dir[:-1]
print(dframe)
print(rdelta)
baz()
textstring
print(ctypes.c_char_p(p).value)
connection.execute(log_table.insert(), inserts)
True
stdout_queue = Queue.Queue()
self.menuTasks = QtGui.QMenu()
a + b
H, xedges, yedges = np.histogram2d(glat, glon, bins=[ybins, xbins], weights=Av)
list(queue)
print(repo.head.ref)
args = parser.parse_args()
store.close()
self.randrange(a, b + 1)
Surface = pygame.display.set_mode((1000, 600))
palette.setColor(palette.Background, QtGui.QColor(0, 170, 255))
size = file_bytes.tell()
ws = wb.active()
math.inf
ids = {}
print(norm(15.0))
pool.join()
first.stdout.close()
res[f]
sysconfig.get_python_lib()
createtable.ignore(comment1)
sheet_rect = sheet.get_rect()
fig = plt.figure()
tensordot = np.tensordot(p, A, (0, 0))
id = db.Column(db.Integer, primary_key=True)
self._in(wrapped.__get__(self, cls), *args, **kwargs)
old_clusters = np.zeros(data.shape[0])
l = sorted(l, reverse=True)
[new_solution.append(data.pop()) for x in range(SET_LENGTH - 1)]
raise ExitCommand()
queue = Manager().Queue()
item.addChild(child)
self.zoomcycle += 1
entity2_id = Column(Integer, ForeignKey(Entity2.entity2_id))
print(result)
CSV_dictionary = file_open(my_file)
data_files = []
rad = np.linalg.norm(X, axis=1)
n = L[0][0]
Form.show()
x = [0] * 51
df
plat = sys.platform
print(data.values[np.searchsorted(data.ages, desired_ages)])
sleep(1)
MB_YESNO = 4
result = {k: v for k, v in list(result.items()) if v}
form.populate_obj(team)
a
self.lbl.grid()
grouped = groupby(_sounds[c] for c in word.lower() if c in _sounds)
self.data = dict(*args, **kw)
t = tuple(text for text in div.stripped_strings)
dist = min(y) - max(x)
pid = os.fork()
newdata[a] = [a, b, c]
pt0 = time.time()
file = models.FileField(upload_to=get_random_filename)
print(sys.exc_info())
self.ax.plot(angle, values, *args, **kw)
b = x + y
fig = plt.figure()
children = li.findChildren()
ig0 = itemgetter(0)
_, values = zip(*sorted(obj.items()))
filename = data.filename
deleteself._inner[index]
archive = py7zlib.Archive7z(fp)
type(o)
label_text_baseline, label_text_color, label_text_font
candidates.extend(cchildren)
ax = plt.gca()
Foo = ctypes.POINTER(myStruct)()
foo.foobar = 2
y = array(100.0)
pipe = subprocess.PIPE
self.symb = symb
res
conn.autocommit(True)
w = np.where(np.isnan(x))[0]
df
self.a = 42
m = pd.Series(f[0], f[1])
x, y = np.meshgrid(np.linspace(-5.0, 5.0, num), np.linspace(-5, 5, num))
dddcccba
C.__setstate__(self, ds[0])
application.listen(8000)
y = cos(x) * x ** 2 + x + sin(x - 1.0)
tracker.save()
[1, 1, 0, 0, 1],
dvals.mean()
cursor = connection.cursor()
importlib.import_module(self.mapToTarget(name))
lists = a, b, c
xml_to_dict(root)
ax.set_xticks(major_locations)
result
1,
assert issubclass(w[-1].category, DeprecationWarning)
p.showPage()
Sender(host, port)
point_neighbors.append(points[index])
N, bins, patches = pl.hist(pl.rand(1000), 20)
s
io.seek(0)
process(x.groups())
print(f)
print(child.GetObjectDescription())
argsdict = dict()
lly = lly.flatten()
urx = urx.flatten()
ury = ury.flatten()
final_ensemble = copy(all_ensembles[0])
myList[0]
heights = np.sin(2 * np.pi * np.sqrt(X ** 2 + Y ** 2) / N)
title = db.Column(db.String(255))
domain, level, url, text = the_tuple
lines(SL)
options.append(False)
-x + x * Log[x]
sqs = sqs1 | sqs2
print(a.f1(10))
dict(chain(*map(dict.items, dicts)))
(a[ti[0]] == a[ti[1]]).any()
postsort.append((category, sorteddata))
istream = ZipFile(zname).open(zipextfile)
multi.start()
args.extend(names)
a = list(range(1, 10))
stdout = subprocess.PIPE
self.im_data_lock.acquire()
fum = Fum()
setattr(namespace, group, groupspace)
mysql.init_app(app)
time_info = [_f for _f in str_list if _f]
subscription_id = db.Column(db.Integer)
a1 = np.array(list(np.zeros(20)) + list(np.ones(20)) + list(2 * np.ones(17)))
last_row = len(rows) - np.where(rows[::-1] == False)[0][0] - 1
laparams = LAParams()
key = path[-1]
comp = lambda x, y: cmp(x.ID, y.ID)
setup.py
TORNADO_PORT = settings.TORNADO_PORT
print(a)
l if len(l) > 1 else l[0]
a[ind]
self.scat = self.ax.scatter(X[:, (0)], X[:, (1)], X[:, (2)], c=c, s=200)
result = ws.recv()
tfidf = TfidfVectorizer().fit_transform(twenty.data)
sorted_dict = {k: {n: list(v) for n in d[k]} for k, v in ordered_kv}
Day = int(current_date[0:2])
Sxy = Sxy + x * y
import_array()
pool = multiprocessing.Pool(THREADS)
b.argmax(1)
sys.stdout.write(text)
it = iter(iterable)
s = s[1:]
sess = tf.InteractiveSession()
o.close()
AnonymousUser()
root = Tkinter.Tk()
a = math.floor(math.log10(y))
print(key)
new_list = []
oldperson = Person()
product = np.dot(A, A.T)
x = arr[7].max()
point_neighbors_list.append(point_neighbors)
df = pd.crosstab(df.actual, df.predicted)
run_multiple_jobs()
loop = asyncio.get_event_loop()
weights = array(list(range(1, 4)))
self.__parse_xml_declaration(xml_file)
data[name][attr_name][attr_year] = value
fig.clf()
ABCD
xvals = np.arange(0, 10, 0.1)
y, x = np.ogrid[-radius:radius + 1, -radius:radius + 1]
communication_set = CommunicationFormSet(instance=my_contact)
small_primes = itertools.takewhile(lambda p: p < n, primes)
biggest_label = size[1:].argmax() + 1
server.data(msg)
self.__dict__[field] = value
dict(count)
pads = tuple((0, i) for i in desired_shape - arr.shape)
l = [1, 2, 5]
sorted_ = sorted(myList, key=itemgetter(0))
__path__ = pkgutil.extend_path(__path__, __name__)
n = arr.shape[1]
print(xbee.wait_read_frame())
d = df.values
s = df.a[::-1].diff().gt(0).rolling(2).sum().eq(2)
response = urllib.request.urlopen(request)
folder = folder.strip(path)
print(rsp.raw._fp.fp._sock.getpeername())
data = in_file.read()
TOKENBLANKS = 1
part_num = random.randint(0, len(l) - 1)
1 + x + x ** 2 / 2.0
df = sqlc.read.options(catalog=catalog).format(data_source_format).load()
df
controller.send_keys(key)
counter.update(d)
CAPTCHA_TEST_MODE = True
scalars = np.arange(N)
dims = np.maximum(B.max(0), A.max(0)) + 1
imag_part = a.real * b.imag + a.imag * b.real
increment()
print(np.c_[xx.ravel(), yy.ravel()].shape)
buf = cmpr.flush()
url = models.URLField(max_length=255, unique=True)
a = df.iloc[:, 1:4].ge(df.High, axis=0)
numerical_bids.sort(reverse=True)
dict_compare(v, db[k])
shot_sequences = product(*([list(range(7))] * len(bird_data)))
get = np.concatenate((get, np.zeros((1, get.shape[1]))))
conv = json.loads(code)
_convert(node_or_string)
print(t.render(items=items))
print(the_map)
fr = df.groupby([df.index.year, df.index.month]).sum().unstack(fill_value=0)
request.data
d = datetime.strptime(base_date, fmt)
client = app.test_client()
filtered = itertools.compress(s, b)
result = query.first()
line += self.fileobj.readline()
res = parser.parse_args()
dictname = pickle.load(f)
n_strings = [item.replace(number, letter) for item in n_strings]
print(self._concrete_method())
population = models.IntegerField()
indexed = {v: i for i, v in enumerate(sorted(a))}
shift_axis -= 1
ref_sort = reference_array.ravel()[sort_idx]
[]
curs = orcl.cursor()
self.sumvariance = np.cumsum(self.eigen)
tf_weight = tf.Variable(tf.zeros([A, B]))
l = c.recv(1024)
sns.set_color_codes()
result = js2py.eval_js(js)
aaa
counter_list = Counter(a).most_common()
ctr = np.arange(N)
print(duncan_prestige.__doc__)
ax = plt.axes()
self.trayIcon = gtk.StatusIcon()
size_sample2 = len(sample2)
pyramid_includes = pyramid_beaker
arr = np.delete(arr, -1, axis=0)
plt.plot(epoch_in, Y_observed)
name = db.StringProperty()
mform
print(repr(doc))
move(abs_path, file_path)
8, 1, 1, 1
root.mainloop()
dt.datetime.combine(self.date, self.time)
id(b[0])
b = [1, 2, 5, 7, 2]
weights = numpy.array(list(range(1, 4)))
self._cond.notify()
data = self.fd.read(self.line_length)
pipe = sp.Popen(command, stdout=sp.PIPE, bufsize=10 ** 8)
d[x] = d.get(x, 0) + 1
board = [[(0) for x in range(n)] for x in range(n)]
line[0]
self.frame = tk.Frame(self)
x[0] = 0.0
self.root = tki.Tk()
dt.timestamp()
n.activate()
im = glumpy.image.Image(M, colormap=glumpy.colormap.Hot)
True
self.a = new_a
name = m.group(1)
inter = np.in1d(a, b)
ytext = y + (ax.get_ylim()[1] - ax.get_ylim()[0]) / 20
factor5 = 0
form
subclass2.fun()
print(tmp)
out.append(seq[int(last):int(last + avg)])
ax = fig.add_subplot(111)
l = len(a) if a.shape else 0
time.sleep(5)
print(element.text.split()[0])
False
dataset.create()
dfA = pd.DataFrame(A)
min_key, min_value = next(it)
self.password = password
False
b = [45, 42, 0, 1, -1, 0]
a.a
y2, x2 = np.unravel_index(sort[1], result.shape)
log.addHandler(ch)
q = [(i, depth + 1) for i in list(d.values()) if isinstance(i, dict)]
self._name = func.__name__
newPathList.append(i)
[{company: [user1, user2]}]
makeGUI = MakeGUI(root)
self.data[key]
it = np.nditer((A, B))
f2 = np.array([1.000051])
find([-1])
data.append(row[idx])
p.drawImage(imagem)
p1.say_my_name()
store[key]
self.value = value
print(type(C))
depth += 1
temp = np.array([(p[m] * A[m]) for m in range(len(p))])
i = l.index(v)
wrapper
result.append(i)
print_names()
self.waiters = collections.deque()
y = adate.year
array1 = np.array(list1)
num = int(str)
n, m = int(n), int(m)
b[0, 0] = 0
items = list(d.items())
plt.plot(binsm, n)
BeautifulSoup(urllib.request.urlopen(urllib.request.Request(url, headers=header)))
speed = D / (t2 - t1)
f(example)
lines2d[0].set_data(oldx + 0.1, oldy + 0.2)
cls.setup_test_data()
corrs
x1.append(t)
writer = csv.writer(f)
arr2d.shape
line_number = random.randint(0, total_num_lines)
run()
ques_type = models.SmallIntegerField(default=2)
next(a)
{{companyForm.hidden_tag()}}
self._hash
traverse(cyclic_graph, Sequence1, process)
ret = app.exec_()
jsonify(success=False, errors=inputs.errors)
Base.metadata.create_all(engine)
ast.show()
test(SP, CP)
root.destroy()
sqrt(2)
lid = Column(String(80), primary_key=True, default=_newid)
n_tr_0 = (y_train == 0).sum()
vers2 = x ** 2 + 2 * x * y + y ** 2
self.is_started = True
raise PyflakesError(path, w.messages)
axPA = plt.subplot(gs1[(2), :], sharex=axF)
self.child_win.show()
get_latin1_char(ch)
asyncio.iscoroutine(mock())
comments = models.TextField(blank=True)
File(identifier=collection_entity, name=name).save()
response = requests.get(zip_file_url)
self.parent and self.parent.on_thread_finished(self, 42)
axE = plt.subplot(gs1[(1), :], sharex=axF)
thread = threading.Thread(target=func)
_, path = os.path.splitdrive(path)
deleteself.thisptr
print(x, permutation([1, 1, 2, 2, 2], x))
self._pcapw.writepkt(self._ethernet, ts=1412977616)
next(i)
show()
ax = fig.add_subplot(111)
dump.write(json.dumps(arbitrary_data))
kernel2
label_input = tf.placeholder(tf.uint8, shape=[])
d[k] = f(v)
self.observer.schedule(self, path, recursive=False)
currentList.append(line.strip())
print(TestClass())
parser = MyHTMLParser()
plot(list(range(80)))
score = len(name) + sum(c in vowel for c in name.lower())
print(self.theConfig)
ward_form = WardForm()
z = dict(Counter(x) + Counter(y))
initial = tf.constant(0.1, shape=shape)
rPM(PROCESS.handle, ADDRESS1, ADDRESS2, 64, 0)
seq = np.arange(counts.max())
fig.scatter(df.icol(0), df.index)
indices, l = zip(*x)
arr1 = np.array([[1, 7], [4, 8], [4, 0]])
doc.SaveAs(txtpath, wdFormatUnicodeText)
print(result.get(timeout=1))
print(round(1.0 / 7, 6))
left_depth = self.left.depth() if self.left else 0
data = b.getvalue()
logging.getLogger().exception(msg.format(**vars()))
assert pubkey.verify_final(signature) == 1
activity = models.ForeignKey(Activity)
video = VideoItem.objects.filter(user=user)
np.random.seed(42)
y = 5 * np.sin(x) + np.cos(2 * np.pi * x)
query_params[param_name] = [param_value]
diff = np.sqrt(diff)
self.full_clean()
result.append(c)
self.active_writer_lock.acquire()
plt.colorbar()
self.trell = []
print(intersect(b1, b2))
print(sqlparse.sql.TokenList([t for t in _filter(sql)]))
B[-i] += x
employee.join(department).map(lambda e: (e[1][0], e[0])).collect()
var_dict = {}
res[0] = func(*args, **kwargs)
x = 5
f.close()
o = MyClass(1, 2)
A = np.random.rand(100, 100)
pca.fit_transform(data_scaled)
id_arr = np.zeros(clens[-1], dtype=int)
compare()
self.text = text
y_pred = pipeline.predict(X_dev)
type(ts.index)
plot(ax, ay)
result[::2] = list1
i += step
a
thread.start_new(extract_bigrams2, (cpnt, len(text), a + 1))
self.arrays = [arg for arg in args]
fhandle.seek(size, 1)
k = 1
ship = collections.OrderedDict(ship)
a, b = 0, 1
[]
p = Pool(4)
new_profile.save()
new_list = [A_list, B_list, C_list, D_list]
narr_view
dictCursor = dbConn.cursor(MySQLdb.cursors.DictCursor)
raise Exception()
time = Column(TIMESTAMP, server_default=func.now())
x.extend(b)
print(soup.prettify())
test_case.assertEqual(set(expected), set(actual))
split_string = []
weighted_errors.append(error)
seq.append(im.copy())
0, 1, 1
Point(self.x + point.x, self.y + point.y)
x = inner(x)
self.readsofar += len(data)
response.status_code = 500
smtpserver.login(gmail_user, gmail_pwd)
a.insert(lo, x)
csvout = csv.writer(fout)
temp = defaultdict(list)
r = np.arange(0, 90, 0.01)
m[np.searchsorted(np.cumsum(m), stop):] = 0
print(bin(value))
print(data)
Permutations(a, t)
hash[word] += 1
[Frameworks]
d = defaultdict(int)
listForm = list(d.values())
offsets = [dt.fields[name][1] for name in names]
self._s = value
merge(main, 0, 2)
new_emails, new_other_list = zip(*filtered)
False
dirname, filename = os.path.split(name)
y = np.array([1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0])
print(os.path.abspath(p))
s_tot = s.sum()
x = np.random.normal(0, 1.0, 100)
demo = [[0]] * 2
sa_query.paginate(page, per_page, error_out)
print(list(sameLevel.values()))
_clients = {}
A = np.array(list(range(6)))
login1 = urllib.request.urlopen(request).read()
self.__setitem__(k, v)
goodkeys = set(x[0] for x in flt if not x[1])
not Counter([1, 2]) - Counter([1])
m, n = A.shape
new_query_string = urlencode(query_params, doseq=True)
salt = uuid.uuid4().hex
stack.append(Wall(pos + 1, height))
cells = np.zeros((side, side, side), dtype=np.uint)
myData = JSON.parse(myJSONList)
x += y
step = forms.IntegerField()
start_dir = os.getcwd()
bigsquare = make_square(0.5, 0.5, 1.0, 1.0)
tmp[:cut], tmp[cut:]
res = [f for f in os.listdir(path) if m.search(f)]
self.send_response(200)
y = sin(angle) * self.radius.imag + self.center.imag
conn = libvirt.open(URI)
print(c.nbytes == len(c.data))
b = np.array([1, 1, 0])
self.visit(node.right)
result = subprocess.check_call(call)
parts = [[], []]
assert l() < 0 < m()
self.calltime = time.time() - self.timeout + value
result = defaultdict(lambda : defaultdict(str))
plt.subplot(155)
gzip.wait()
my_cmap_r = mpl.colors.LinearSegmentedColormap(name, LinearL)
cv.Resize(image, smallImage, cv.CV_INTER_LINEAR)
wx.NO_BORDER
time = models.IntegerField()
sum(mat, vec.A)
a = c[:5]
cropped_example = original.crop((left, top, right, bottom))
a, b = itertools.tee(iterable)
szr = wx.BoxSizer(wx.VERTICAL)
sun = Sun()
print(result)
tree = et.parse(xmlfile)
my_instance = qs[0]
cartesian(arrays[1:], out=out[0:m, 1:])
pl.boxplot(data)
d = collections.defaultdict(int)
self.lock = threading.Lock()
f(a, a.size)
index = list(np.ix_(*[np.arange(i) for i in z2.shape]))
turtle.right(45)
a = [2, 4, 6]
arr
height = int(cap.get(cv2.cv.CV_CAP_PROP_FRAME_HEIGHT))
os.remove(filename)
f.__code__ in creator.__code__.co_consts
mycode.things()
RES = n.zeros((SPMAT.shape[0],), dtype=complex64)
lock = threading.Lock()
print(x)
interval_df_intersection(mydataframe2, mydataframe1)
{self.body()}
a.shape = a.size // ncols, ncols
rlist1 = list1[::-1]
now = time.time()
player.set_media(media)
[np.sum(x ** 2 + a), 2 * x]
no_proxy = urllib.request.ProxyHandler({})
li.append(4)
current = current[name]
os.unlink(file_name)
str(0.1000000000000999)
node = rootnode
writer.save()
data = simplejson.loads(self.data_string)
logger.addHandler(consoleHandler)
row_rank = np.argsort(row_order, axis=1)
blank_image[:, 0:0.5 * width] = 255, 0, 0
base_pic.close()
values[bisect.bisect_left(keys, query)]
page = read_pdf.getPage(0)
queryset = self.filter_queryset(self.get_queryset())
print(sys.getsizeof(y))
detokenizer = MosesDetokenizer()
G.subgraph(to_keep)
context.paint()
print(self.data)
idx = np.argsort(e_values)[::-1]
False
print(my_test)
sys.stdout = NewOut()
missing_dates.append(test_date)
digraphs = defaultdict(list)
col_data = col.text_content()
setattr(testcase, test_name, test)
deviceparent
matches = words.intersection(pwords)
bins = [0, 0.25, 0.5, 0.75, 1]
params_json = json.dumps(params)
mapper._validate_polymorphic_identity(mapper, state, dict_)
img1 = to_grayscale(imread(file1).astype(float))
s.listen(5)
df = df.join(df_my_ones)
t1 = time.time()
settings.configure()
query
soup = BeautifulSoup(html)
4048
sizer = wx.BoxSizer(wx.VERTICAL)
p.dump(obj)
self.create_old_data()
text_format.Merge(file_content, graph_def)
newlist1.append(s)
CYAN, MAGENTA, YELLOW = (0, 255, 255), (255, 0, 255), (255, 255, 0)
self.x + 1
fig = plt.figure(figsize=(8, 8))
Testing(10 / 10)
np.invert(s)
shapes = [find_shape(subseq) for subseq in seq]
b = f.read(2)
prob += colsums[c] == sum(mat[r][c] * rowselected[r] for r in allrows)
switch[var1, var2]
firstNumber = line[:12]
assert np.max(abs(a - a2).data) < 1e-05
df.index.lexsort_depth
X2tick_location = ax1.xaxis.get_ticklocs()
distance_matrix[i, j] = haversine(loni, lati, lonj, latj)
b.set(2)
i, n, m = -1, len(seq), len(subseq)
value = self.func(obj)
print(value)
f.close()
y1 = xsin(theta) + ycos(theta)
self.person_name = person_name
print(pattern.findall(document))
timer_process.start()
descr = PyArray_DescrFromType(typenum)
LabeledPoint(fl[l - 1], fl[0:l - 1])
self._classes[module, cls_name].from_dict(dct)
findspark.init()
scipy.stats.norm(100, 12).pdf(98)
distance_vectors = [cosine_distance([pair[0]], [pair[1]]) for pair in combs]
jinja2.get_jinja2(app=self.app)
x[a.nonzero()] += a.data
pool = tuple(iterable)
self.vtkPolyData.SetPoints(self.vtkPoints)
y = tf.nn.softmax(logits)
serializer = self.get_pagination_serializer(page)
sess.run(tf.local_variables_initializer())
logger = logging.getLogger(name)
mySet.add(p1)
temp.append(seq.pop())
larray = []
pyobj = json.loads(rjson[0])
-build - essential
mydict[mychar] += 1
t = np.arange(0.0, 10000.0, 10.0)
prvy = col[0].string.strip()
self._age
print(session2.query(Datum).all())
self.do_thing_with_message(val)
parser = argparse.ArgumentParser(description=description, usage=usage)
address
0, 1, 2
religious_order = models.ForeignKey(ReligiousOrder, blank=True, null=True)
nark
cython
pyinstaller
ax = fig.add_subplot(1, 2, 2)
cls.__items[item] = kls
data = {}
instance.update()
last_dict[l[-1]] = value
out = np.hstack([up, low]).ravel()
Frame.__init__(self)
W = np.power(omega, i * j) / sqrt(N)
df = dftst.stack(0)
all_matching = list(filter(matchCondition, lst))
f1, f2
id = row[0]
start[r[0]].add(r[2])
lft, rght = n.lft, n.rght
print(df)
l[1], l[i] = l[i], l[1]
d.weekday()
serialized = json.dumps(dict_obj)
after_buf.pop(0)
tree = parser.parse_string(diagram_definition)
y = [random.gauss(4, 2) for _ in range(400)]
item = get_max(item)
df.head()
list(reversed([1, 2]))
list(chain.from_iterable(islice(v, x) if k else v for k, v in groups))
ticklabs = cb.ax.get_yticklabels()
self.host = host
ax = fig.add_subplot(1, 1, 1)
print(key)
self.layers = [NeuronLayer(self.n_neurons_to_hl, self.n_inputs)]
listEven = list1[::2]
line.set_data(x, y)
phantom.exit()
c.close()
{{forloop.counter}}, {{item}}
u[i][x, y] = 1
print(non_ascii.sub(escape_unicode, line))
df2 = df2.rename(columns=d)
smtpserver.ehlo
arr2 == arr[0]
edgex1 = region1 ^ np.roll(nregion1, shift=shift, axis=0)
df1
my_item = MyItem()
uuid = uuid[:5]
text
res.sort()
a[2, 2] = -999
filtered = cv2.filter2D(skel, src_depth, kernel)
it = itertools.groupby(text, lambda w: w.isspace())
input.iloc[i].X
div = int((div - module) / 26)
i += len(node[0])
form = FooAdminForm
internet_set_option(0, self.INTERNET_OPTION_REFRESH, 0, 0)
s = StringIO()
time.sleep(0.01)
axdendro.set_xticks([])
D = yaml.load(f)
result += numbers[i:]
print(RegisteredNumber.numbers)
mech = mechanize.Browser()
assert np.allclose(using_unique(), using_digitize())
C = np.zeros((dimC, dimC, dimC))
x = np.ones(10, dtype=bool)
x = random.random()
phi = np.linspace(0, np.pi, 20)
x + y
finalizer()
keywords = set(extract_keyword(line) for line in f)
e.errno == errno.EPERM
dataset[0].intersection(*dataset[1:])
elem = etree.XML(xml_str, parser=parser)
false
Fail if not m else (m.group(1), text[m.end():])
print(row)
HttpResponseRedirect(url)
self.printfiles(result)
tree.write(xmlfile, xml_declaration=True)
maintype = mail.get_content_maintype()
bar = np.array([4, 5, 6])
print(Child.mro())
file_like.seek(0)
delta = n / 10
heapq.heappush(self._data, (self.key(item), item))
self.count -= 1
registry.add_field(cls, self)
1401828155.0
self.treeAction.triggered.connect(self.printTreeItem)
x, y, z = gradients.T
self.cls = my_class
data[0:10]
prime = False
bins = list(range(15, 25))
func(self, x + 1, func)
source_bytes = base64.b64encode(source_image.read())
z = numpy.array([0, 0.5, 1, 0])
print(name, value)
hash(tuple(frozenset(sorted(new_o.items()))))
le = preprocessing.LabelEncoder()
fb_ = np.zeros_like(zeta)
s.add(5)
info = logging.getLogger(__name__).info
lastelt
newfunc
sorted(list_date, key=foo)[-1]
fig = plt.figure()
li = [(filename, i, number_of_chunks) for i in range(number_of_chunks)]
set(b1).intersection(b2)
xi = np.linspace(xmin, xmax, nx)
print(i)
h = lambda x: x.apply(g, axis=1).mean(axis=0)
help(re)
entity_manager.add(r)
item in self.g
test_logger.addHandler(handler)
pl.imshow(l)
print(type(savedtweets_datetime))
True
s
date(y, m, d).toordinal() - date(2005, 1, 1).toordinal()
h = np.random.uniform(-150, 150)
x, y = meshgrid(x, y)
_shared_tasks.add(constructor)
cursor = connection.cursor()
dis.dis(bar)
app.exec_()
plt.show()
ssh = paramiko.SSHClient()
pil_im.show()
application.listen(5000)
self.data[key[0]:key[1] + 1]
out2[0][0]
w = df.strings.str.split()
self.pa = pyaudio.PyAudio()
print((x, y))
z = np.array([2, 5])
self.fd = f.fileno()
print(df)
raise TypeError(msg)
[9, 4, 8],
sys.exit(app.exec_())
basegraph = tf.Graph()
RNumY = 0.5 + 10 * random()
console_handler.setFormatter(formatter)
browser = Browser()
counter = np.count_nonzero(mask)
user_input.append(entered_text)
list = s.split()
chunk = proc.stdout.read(1)
a = cplxarr.copy()
b = lambda : a + 2
fp = A[-np.isnan(A)]
setB = frozenset([frozenset(element) for element in listB])
is_binary = True
m = np.ma.array(a, mask=~np.isfinite(a) | (a == -999))
l = zip(*transposed_l)
values = set(lst)
p.register(f, select.POLLPRI | select.POLLERR)
self.file.read(outputfilename)
x, y = m(lons, lats)
iend = i - 1
svg = rsvg.Handle(data=data)
c = lambda : (a, b)
freqs = Counter(words.split())
sleep(0.025)
s[i] = y
count = 0
parser = etree.XMLParser(remove_blank_text=True)
[0.004 - 2e-08 - 0.75]
self.write_csv_test_data(temp_csv)
self.thread = threading.Thread(target=self.run, args=())
channel = 0
print(dict(zip(def_args, defaults)))
match = a[:-n].copy()
1, 1
isclose(1, 1.00000000001)
np.round(df.loc[:, (msk)], 2)
np.array(inds)
ax2.set_xlim(bin_edges.min(), bin_edges.max())
p._x = 9
print(file_name)
DataFrame(entry_frame)
settings.production.py
node.setPos(QPointF(path.elementAt(i)))
itertools.islice(iterable, stop)
raise KeyError(k)
aw1.redraw_plot()
arr[0]
raise ValueError
print(basepairs)
fileobj.seek(0)
obj.address_2_html()
matching = np.ones((len(values[0]),), dtype=bool)
myfunc()
[x for x in p.get_connections() if x.status == psutil.CONN_LISTEN]
FirstName = db.Column(db.String(40))
thetas = np.linspace(0, 2 * np.pi, 20)
sess
Py_DECREF(temp_p2)
drawMatches(img1, kp1, img2, kp2, matches[:10])
cnp.import_array()
X, Y = np.meshgrid(x, y)
align_yaxis(ax, np.mean(grp2), ax2, 0)
my_stuff = []
popt1, pcov1 = curve_fit(func1, x, y)
v1, col1 = d1[0], d1[1]
Unknown
sub_dict
line.set_color(colors[klass])
isitIn(char, b[len(b) // 2:])
df_crawls
abcde.co.uk
self.X < other.X and self.Y < other.Y
Simplify[A.x]
a = 1
x = np.arange(100, dtype=np.float64)
x = list(range(0, 100))
ret, frame = cap.read()
root_logger.addHandler(handler)
ds[:] = x
path.pop()
menubar = tk.Menu(self)
connection.daemon = True
t.setModel(m)
f = ftplib.FTP()
A()
times.map(lambda x: x + MonthEnd())
recursive_iter_map(f, e)
a = map(int, [(x ** 0.5) for x in range(20)])
params = {}
l2[0][0] = 1
queue.put(ip)
start = time.time()
my_func0 = my_func_factory(lambda x: 2 * x, lambda x: 2 * x)
mutex.acquire()
old = termios.tcgetattr(fd)
s.close()
frame.f_locals.update(self.namespaces.pop())
self.Show()
ret = df.iloc[start + 1:end]
print(rcv)
bin(4)
var_1 = copy.copy(var_2)
input_filename = sys.argv[1]
output, _ = diskpart_handle.communicate()
m = 2j * math.pi
vec_dict = {}
user.user_permissions.add(custom_permission)
l = multiprocessing.Lock()
names_list = [y for y in (x.strip() for x in names.splitlines()) if y]
LastName = db.Column(db.String(40))
_fix_exception_context(new_exc_details[1], exc_details[1])
c = zip(users[:n // 2], reversed(users[n // 2:]))
indices = list(es.indices.get_aliases().keys())
[1, 9, 9],
writer = csv.writer(s)
process_list.append(p)
urlpatterns += api.urls
signal(SIGPIPE, SIG_IGN)
x = np.arange(100)
test_suite.addTest(file_tests_main.suite())
value = process_value(int(raw_value))
cur = conn.cursor()
xslt_doc = ET.parse(io.BytesIO(xslt))
ax = fig.add_subplot(111)
self
vend = vspell[2]
batch = service.new_batch_http_request(callback=delete_file)
_ctypes.dlclose(lib1._handle)
result.append(this.d[c])
print_keyword_args(**kwargs)
parse_code_1(*split_secret_code(secret_code_1))
items_formset = inlineformset_factory(Parent, Item, form=ItemForm, extra=1)
m_from = ndb.KeyProperty(kind=UserModel)
st.norm.interval(0.68, loc=np.mean(a), scale=st.sem(a))
dtypedict.update({i: sqlalchemy.types.NVARCHAR(length=255)})
uniq = uniq.view(data.dtype).reshape(-1, ncols)
Queue.put(self, item, block, timeout)
r.status_code
len(s) + 2 == len(repr(s))
week = int(yourString[-2:])
set_interval(func, sec)
self.counter = 0
fig1.show()
colormap = window.get_screen().get_rgba_colormap()
other_field = form._fields.get(self.other_field_name)
module_filename = inspect.getfile(module)
self.bitmap_1.SetBitmap(wxbmp)
False
passman = mechanize.HTTPPasswordMgrWithDefaultRealm()
plot1 = plt.plot(x, mlab.normpdf(x, m1, std1))
csc_matrix = temp_sparse.csc_matrix(temp_matrix)
res_ols = sm.OLS(y, statsmodels.tools.add_constant(X)).fit()
True
a.replace(False, np.nan).idxmax(1)
raise NotImplementedError
a, b, c = [fgen() for global_n in L]
print(scores.mean())
len(pytz.common_timezones)
AppHelper.runEventLoop()
simplex = np.asarray(simplex)
post.tags.remove(sometag)
l_idx = list(range(len(l)))
self.value = value
print(np.finfo(np.double).precision)
abs(a) % abs(b) * sign
self.bar = bar
convert = pound * 56 / 100
replace(stack, [text])[0]
settings.Delete()
findContours(bin.clone(), contours, CV_RETR_LIST, CV_CHAIN_APPROX_NONE)
arr[i] += 1
prefixes = my_groupby(iter(C.items()), key=lambda k_v: k_v[0][:-1])
vc = df.a.value_counts()
key += str(self._unique)
[self.x - 1, self.y + 1], [self.x + 1, self.y + 1]
all_s = (x for x in st if x in word)
output
plot(s)
key = list(mem.keys())[0]
new_module.__file__ = filename
print(df)
fp_plain = hashlib.md5(key).hexdigest()
a[Idx]
base_pic.save(file=result_pic)
f2(A())
ownUid = [p.uid for p in psutil.process_iter() if p.pid == ownPid][0]
idx = np.where(variance > 0.5 * np.max(variance))
page = infile.read()
b = a.swapaxes(axis, -1)
i = 0
self.value + other
(residuals ** 2).sum()
ff = ff.reshape((5, 4, 1, 1))
assert my_round(11.12) == 11.0
i = bisect.bisect_left(a, x)
k2 = k.copy(k.bucket.name, k.name, k.metadata, preserve_acl=True)
process.shutdown()
unittest.makeSuite(TestSomething)
ack_message()
split[-1][-2].append(r)
self._age
help(me)
connection.close()
searchbox.send_keys(searchkey)
ranges.append(range(group[0], group[-1]))
pairs = reversed(list(my_dict.items()))
sum((x - y) ** 2 for x, y in zip(singlePoint, pointFromArray)) ** 0.5
nk1
madata = np.ma.MaskedArray(data1, ~masks1)
mydir([])
lol[1][0]
cv.Copy(image, newCanvas)
FilteredObject(obj_id[9:])
num = ceil(num * 100) / 100.0
fibs.append(fibs[-1] + fibs[-2])
a, b = fa(x, y)
parent = getattr(form, self.parent)
save.close()
e = sys.exc_info()[1]
iter(self._od)
template_name = fn()
arr.shape
velcro.left(140)
d[c] += 1
l = list(a)
w.focus_set()
time.time() - start
self.cache[regex_string]
B = NP.array(B, dtype=bool)
Returns
c = np.linspace(0, 1, 1000)
results = {}
count += 1
doSomething(line)
wid = termf.winfo_id()
response = http.HttpResponse(response_html)
statvfs(path)
dict_time[key] = value
True
result = a.flat[i[d > TOL]]
self.console.see(tk.END)
s.setDTR(False)
res = []
X, Y, Z = np.array([]), np.array([]), np.array([])
os.removedirs(dirname)
notes = models.TextField(blank=True)
x, y, z = r * np.cos(th), r * np.sin(th), angle * r * np.sin(th)
self.item.product_name
response = requests.post(full_url, json.dumps(data))
max(die().roll_until(6) for i in range(6))
id_seq = curs.fetchone()[0]
encryptFile(fileName)
p = ConfigParser.ConfigParser()
self.end_headers()
x = x + 10
sys.stdout.writelines(diff)
p2 = map(lambda x: tuple(chain.from_iterable(x)), product(*lists))
abort(400)
data = list(s)
item = row[i]
pool = multiprocess.Pool(process_count)
token_response = requests.get(url=cls.token_url, params=cls.params)
pow = lambda x, y: _pow(x, y)
OPTION_A = 1
D = np.sqrt(a + a[np.newaxis].T - 2 * np.dot(X, X.T))
print(sum_shells(a))
x ** 2
circle(im, Point(center.x, center.y), radius, Scalar(0, 255, 255), 2)
frags.append(generate_sample(grammar, prod.rhs()))
myfile.writelines(var1)
gray = ImageOps.grayscale(src)
studentform = StudentForm()
fig, ax = plt.subplots()
et.tostring(t)
do_foo_stuff()
final_list = []
foo = models.ForeignKey(Foo)
mask = 255 - mask
col = int(m.group(2))
key, value = pickle.load(f), pickle.load(f)
self.box.current(0)
sieve = [True] * (n // 2)
stdscr.keypad(0)
status = models.IntegerField(choices=STATUS_CHOICES, default=REGULAR)
print(obj)
print(sorted(x for x in a if x < limit))
bitfield(255)
i += 1
plt.close()
hilbertC(256, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1)
df
df1_a, df1_f, df2_a, df2_f
print(p)
py.offline.plot(fig)
total += multinomial(n, list(Counter(a).values()))
y_2_val = sample_transform(x_2, y_2)
unique_kpts.append(i)
sess = requests.Session()
z_scattered_evil = fun_evil(x_scattered, y_scattered)
last_day_of_month = calendar.monthrange(year, month)[1]
sqlalchemy.orm.session.make_transient(a)
print(b)
functools.update_wrapper(self, target)
count += int(s[0].isalpha())
print(i)
colors = [(0.0, 0.0, 0.0), (1.0, 1.0, 1.0)]
map(lambda p: preprocess(data, p), funcs[procid])
self.buf.seek(oldpos)
app = Flask(__name__)
common_words = set(x[0] for x in flatten(h)) & set(x[0] for x in flatten(p1))
a = list(perm_unique([1, 1, 2]))
False
data.pop()
tokens = set(s.split())
sess.run(init)
fresult.col1 = fresult.col1.replace(np.inf, 100)
typ = f.read(1)
(sp.j0(r) + sp.jn(2, r)) ** 2
luts += list(range(256))
plt.imshow(first_array)
sensor.geolocate()
x = x.strip()
max_col = int(5000000.0)
content = request.get_json(silent=True)
new = list(text)
amass.delay([], tasks)
YAL001C = metabolism
t = lxml.html.parse(url)
buffer = BytesIO(request.urlopen(url).read())
angle = math.atan2(b, a)
w = np.fft.fftfreq(N) * N * dw
upload_handlers = request.upload_handlers
ax2 = plt.subplot2grid((m, n), (row_2, col_2), rowspan=height)
format_u = format_.decode(locale.getlocale()[1])
app = pywinauto.application.Application()
files = sorted(glob.iglob(files_path), key=os.path.getctime, reverse=True)
print(count)
A.join(B)
c = wrapper.__code__
f.seek(0)
filename = inspect.getframeinfo(inspect.currentframe()).filename
1
s = list(s)
out = sys.stdout
print(json.loads(content))
main()
assert first([f, g, h]) == 1
price_diff = models.DecimalField(max_digits=10, decimal_places=2, default=0)
result = HTMLParser.HTMLParser().unescape(urllib.parse.unquote(decoded))
print(a, b, c)
r = Tk()
np.get_printoptions()
count += 1
myprocess = psutil.Process(process_id)
DictTable(d)
p1 = np.tensordot(v, a, axes=([0], [0]))
extend_array(data, 10)
self.__dict__[key] = value
self.on_change()
tf.nn.softmax(incoming)
c = C()
choices = [population[i] for i in choice_indices]
main()
d = np.array([5.0, 1])
cell_value = cell.value
print(True)
i = np.random.uniform(1.5, 12.4)
seed(_SEED)
last_name = models.CharField(max_length=50)
background.paste(foreground, (0, 0), foreground)
run(server=server)
title = db.StringProperty()
ax.scatter(xcorners, ycorners, c=zcorners, s=200)
x ** 2 + y * 2 + z
self.crawled_urls = set()
df
file.seek(index)
func(**d)
f(depth + 1)
adj = numpy.zeros(shape=(n, n))
twitter = Twython()
ret = ifft(fftx * np.conjugate(fftx), axis=1)
logger = logging.getLogger(__name__)
TextField(question.text)
n += 1
colorsys.rgb_to_hsv(r, g, b)
y = Counter([1, 1, 2, 5, 6])
Server2.__base__ += PluginA,
color = np.sqrt((points ** 2).sum(axis=1)) / np.sqrt(2.0)
candidates.append((lead_obs, other_obs))
d[x].append(y)
buf.readline()
scatter(X, Y)
logger.addHandler(handler)
deletemodules[modname]
order = {v: i for i, v in enumerate(a)}
lib = ctypes.cdll.LoadLibrary(path)
f2.close()
print(result.get())
a.copyApply(A.bar)
memoryview(s[0:]) > memoryview(s[1:])
data.value.diff()
foo()
a, b
user = authenticate(username=username, password=password)
hxs = HtmlXPathSelector(response)
my_sat.put()
req = urllib.request.Request(PP_URL, params)
self.__next__()
print(new_list2)
the_date += timedelta(milliseconds=milliseconds)
shpinfo = []
print(v)
ret1 = tn.read_eager()
qa
self.user = UserFactory.create()
main()
last_indiv = first_line[0]
axes.set_xlim(-0.5, 9.5)
results = getSQL()
num_of_bits = 8
files = WidgetFile.objects.filter(widget=self)
e.filename, e.lineno, e.offset, e.text
print(df.irow(i))
b = random.sample(range(100000), 10000)
graph.add_edge(edge)
value() if callable(value) else value
pool.map(preprocess, zip(data, preds))
output.write(outputStream)
p.join()
l1.extend(l2)
os.open(outfile, os.O_RDWR | os.O_CREAT)
writer.commit()
cols = list(df)
output.write(outputStream)
hello
time.sleep(2)
test_treebank_tagged_words = cfd(chain(*test_set))
dep_field[0].rel.field_name
print(b is a)
result = re.search(your_stuff_here)
df
assert os.path.isdir(some_dir)
deletea.a
n_col = A.shape[1]
isf = float(iss)
print(find_prev_next(list(range(2)), 10))
i = j + 1
driver = webdriver.PhantomJS()
image.composite(background, 0, 0, PythonMagick.CompositeOperator.SrcOverDst)
img = utils.ImageReader(path)
print(json.loads(line))
print(str(e))
a + weight * (b - a)
os.chown(path, int(uid), int(gid))
unqs = data[np.sort(ind)]
value = value.strip()
b = 2
threads = [p.apply_async(f, [i]) for i in range(20)]
country = models.CharField(max_length=2, blank=True)
test[np.in1d(test, states)] = 1
qry = session.query(Bar, Bar.foo_count).filter(Bar.foo_count > 0)
1 / 2
np.finfo(float).eps
numpy.asarray(result)
pygame.display.list_modes()
fig = plt.figure()
v = df.values
PyObject * py_callback
rf.set_params(**g)
a * b
[0, 0, 1, 1, 0, 0],
new_data2[~mask] = 0
globalcopy = globals().copy()
jsonify(success=0, error_msg=str(e))
main()
result = []
A2 = np.random.randint(-4, 10, (6, 7))
print(df)
df.shape
isinstance(v, dict)
content.append(data)
SHEETS.spreadsheets().batchUpdate(spreadsheetId=SHEET_ID, body=DATA).execute()
wnl.lemmatize(greater)
pd.get_dummies(dummy_col, prefix=dummy_col.name)
print(polygon)
result.append([base_start, base_close])
print(your_sample_text)
print(about[0].title)
dec_idx = np.random.choice(8, N, replace=False)
linesB = f.readlines()
jinja2.__version__
f(i + 1)
c += dict(flatten(d))
cell = gtk.CellRendererText()
jsonify(dictToReturn)
events = Event.objects.filter(active=True)
f.__closure__
last_index = tf.shape(output)[1] - 1
root = Tk()
len(l1)
luhn_residue(getImei(14))
app = TestApp(self.application)
True
cls
print(match[0])
fig = pylab.figure()
print(list(j))
list.__delitem__(self, key)
df.index = [df.index, df.Name.notnull().cumsum() - 1]
(9, 4) - 0.051971584115
assert time.clock() == 2
window = tk.Toplevel(self)
df = mylib.load_data()
a, b = x
__new__ = cls.__new__
x = np.linspace(0, 100, 100)
ms, mb = (dict(a), dict(b)) if len(a) < len(b) else (dict(b), dict(a))
list[1] = [2.5]
ax.margins(0.04)
fill = numpy.zeros((cols - 1, cols), dtype=a.dtype)
XV = np.random.uniform(low=-4, high=4, size=n)
result = list(map(run, list(range(100)), list(range(100)), list(range(100))))
df = sqlContext.createDataFrame(input_iso.map(extract_iso), schema)
input(prompt)
cls
value = model.get_value(tree_iter, 0)
im1 = ax.imshow(im)
oldsysstdout = sys.stdout
self.treeview.expand_to_path(row.path)
out.getvalue()
http_server.listen(8888)
a = stream.read(chunk)
remaining_stems = stem_sets[i:]
self.setUrl(request.url())
main.quit()
list.append(ord(g2))
self._list.__len__()
result = json.JSONEncoder.encode(self, o)
list2 = [(x * 0.5) for x in range(2 * x1, 2 * x2 + 1)]
print(ans)
m = multiprocessing.Manager()
data = self._data
date = qdate.toPyDateTime()
cr.set_source_surface(ImageSurface.create_from_png(buffer))
theta = np.linspace(0, 2 * np.pi, 51)
deletestart_dict[start]
df
Y = numpy.resize(X, (4096, 9, 4))
print(filled[:, :, (5)].astype(np.int))
y.eval()
result
model.appendRow(item)
python
console.write(e)
C = csr_matrix((5, 2), dtype=int)
dis.dis(foo)
memorizedPaths[item] = item
known_words[len(word)].append(word)
previous = predecessor_map[previous]
tb.activate()
karma_delta = models.SmallIntegerField()
max_per_dir = int(sys.argv[2])
app = Flask(__name__)
intersection = set_ranlet.intersection(word)
myList = []
print(os.read(fd, 22))
np.allclose(C1, C2)
print(abacus)
others = np.vstack((a, c, d, e)).T
output.close()
testDict = {}
xs = [np.array([i, i, i + 1, i + 1]) for i in range(N)]
d1 = D.mean(axis=1)
self.composite_actuator.move(100, -100)
stack.append((y, d + 1))
PAGE_WIDTH = defaultPageSize[0]
a[:, (1)] = np.max(points, axis=0)
fig = plt.figure()
mask = np.ma.less_equal(diff, 0)
colnames = [desc[0] for desc in curs.description]
video = models.FileField(upload_to=vid_get_file_path)
u_idx_y = np.argsort(y)
queue.put([hdd, line.split()[9]])
f(head, foldr(f, acc, tail))
os.unlink(fifo_path)
b = int(b) if int(b) % 2 == 0 else int(b) + 1
id = db.IntegerProperty()
print(x)
y
numpy.vectorize(test.__contains__)(data)
df
data_for_browser.put()
do_stuff(data)
pid = os.getpid()
start_response(status, headers, exc_info)
loop.run_forever()
print(type(clause))
widgets.append(forms.TextInput(attrs=attrs))
self.model.stop_training = True
end = time.time()
element
col_ind = [i for ids in list(d.values()) for i in ids]
columns = len(my_dataframe.columns)
x_vals = np.arange(-20, 21, 1)
print(df1)
path = os.path.join(dirpath, file)
self.get_sum_moves_rec(i, j, self.a[i][j], [(i, j)], ans)
POINTS = 1980
x = []
d[index] = 0
ln2, = ax.plot(x, 4 - y, lw=10)
fp = self.__getid(request.url)
False
numpy.save(file=f, arr=my_array)
StreamingHttpResponse(stream_response_generator())
show()
height * np.exp(-(x - center) ** 2 / (2 * width ** 2)) + offset
t.start()
print(id(S1))
lst = list(yielding(x))
with_divisible(7, 1, 21, lambda x: x)
auth_handler = urllib.request.HTTPBasicAuthHandler()
hello = messages.StringField(1, required=True)
q = int(s, 0)
callback_func(channel, method, properties, body)
threads = []
print(a * b * c)
zipinmemory = cStringIO.StringIO(remotezip.read())
response
print(zlib.compress(a))
c = tf.matmul(a, b)
df
d = SortedDict({(1): 5, (2): 5, (4): 5})
num = num[0].rstrip()
char = cv.WaitKey(99)
my_array = np.random.randint(1, 10, (4, 5))
opener = urllib.request.build_opener(proxy)
set() in subs
counts[value[1]] += 1
wsgiref.handlers.CGIHandler().run(app)
df
subplot(2, 1, 1)
eq2 = b * a ** 2 + d + c
fin.close()
True
results = connection.info()
execute(background_run, your_command)
inner_sum += dk * f_big_nb(A, k, 1e-05, 1e-05)
raise argparse.ArgumentTypeError(msg)
file.readline(), new_position
res
mungeddata
obj.lock()
s.close()
plt.grid(True)
zen = np.arccos(X[:, (-1)] / rad)
print(Contacts.all_contacts)
ax = plt.gca()
endDate = startDate.replace(startDate.year + 1)
visited_nodes = set()
line = scan_process.stdout.readline()
ax1.bar(list(range(l)), Two)
n
print(character)
colorjh = jmag - hmag
assert isinstance(res, float)
f, ax = plt.subplots(1, 1, figsize=(n * size, size))
sum
plt.contourf(x, y, Z)
picklable = []
self.settings = QtCore.QSettings()
settings.INSTALLED_APPS += new_app_name,
loop_thread.start()
sys.path
output.write(outputStream)
self.__port
print(train_likes_df.time.dt.time.head())
self.bar = 1
d.popitem()
np.corrcoef(data)
last = next(reversed(my_iter))
output.addPage(page)
global_method_decorator_list.append(my_callable)
ax = plt.subplot(1, 1, 1)
sample = distribution.rvs(size=10000)
seen = set()
wrapped_func
person.py
window = numpy.ones(int(window_size)) / float(window_size)
foo().debug_info()
2 * x
mydictionary[Col1].append(row[0])
s[:-len(suf)]
cls
makes_valid_word = False
bool(0)
ladd = []
seq_num = RNG.randint(0, len(self.nodes) - 1)
a = csr_matrix(a)
chunk = f.read(chunksize)
b[b == 0] = -1
(tgtdate - startdate).days // 7 + 1
pylab.pcolor(xx, yy, zz)
maxi = np.amax(max_array, axis=0)
res.index = pd.to_datetime(res.date)
print(clean_chunked)
print ()
print(self.a)
fields = map(lambda x: x[0], cursor.description)
self.count = 0
np.maximum.accumulate(without_reset * reset_at)
plt.annotate(labels[i], xy)
ax.plot(np.arange(10) * (i + 1))
b = B()
QuerySet()
client.invoke(args, kwargs)
self.len += 1
print(repr(x))
find_all_paths_aux(adjlist, start, end, [])
output = StringIO.StringIO()
print(event.Position)
meta.Session.add(userChoices)
tasks.put(Task(i))
complex_out.append(comp_row)
print(a + b)
S = sparse(i, j, s, m, n, m * n)
users = [p.user for p in people]
http_server = tornado.httpserver.HTTPServer(application)
self._timer = Timer(self.interval, self._run)
sp_mat - sp_mat.multiply(zero_mat)
print(repr(ba))
converged = True
transport.connect(username=nodeusername, password=nodepw)
sps_a.nnz
screen = wnck.screen_get_default()
app = web.application(urls, globals())
libc.printf = _printf
csvdata.update(textdata)
config.make_wsgi_app()
signal.disconnect(self._checkSignal)
cols.append(i)
cnt1
func
cmd = cmd.split()
a, b, c = 10.0, 4.0, 6.0
result[len(result) - 1:0:-1] -= result[len(result) - 2::-1]
print(myA)
DEBUG = True
entnum = int(name)
ax.yaxis_date()
i = np.argsort(your_permutation)
table = QtGui.QTableWidget(1, 1)
l
mySocket = socket(AF_INET, SOCK_DGRAM)
upperlist.append(l)
-1
t = tuple(range(2, 129, 2))
y_sorted = y[order]
sizeof(pycvex_Stitcher_t),
x = np.random.rand(D)
res.x
queryset = Question.objects.all()
x.append(x[i - 2] + x[i - 1])
Z = W + lam * D.dot(D.transpose())
new_string, 1, enc
count = 0
a[:, (0), (0)] = t1
lookup[k] = list(v)
len(last_question_marks.search(text).group(0))
result
b.extend(a)
raise ValidationError(e)
self.cbar = self.fig.colorbar(CS1, cax=self.fig.axes[1])
do_stuff_to_last(elt)
combs2 = 5165700
envelope_plot(x, y, winsize=40, ax=ax2)
d = [i[0] for i in enumerate(c) if i[1] > 2]
LIN = np.dot(d_e_vecs, np.dot(d_e_vecs.T, X_.T)).T
curs = conn.cursor()
last_window = int(first_line[1])
pari.pari_close()
intersected = intersected.intersection(set(range(first, second + 1)))
self.portfolio[ticker].extend(list(msg.values()))
file.close()
print(getSubStrings(a, 1))
i = j + 1
x, y = ax.transData.transform_point([i, i])
n = len(board) - 1
[1, 2, 7]
A() == A()
foo(x)
myfuncs = [functools.partial(random.normalvariate, *args) for args in arg_sets]
x0, x1 = _cubic(b, 1.0, 0.6), _cubic(b, 0.0, 0.2)
JM2[(ii), :, (ii)] = 0
keptticks = yticks[::int(len(yticks) / 10)]
jsonData = json.dumps(data)
clock.tick(15)
value = ndb.StringProperty()
fig, ax = plt.subplots(1)
jobs = [pool.schedule(Check, args=[i], timeout=5) for i in range(10)]
ret[i] = a[i] + b[i]
a = ref([1, 2])
a == b
thismanager.window.SetPosition((500, 0))
artist.set_visible(not artist.get_visible())
value
angle = getAngleBetweenPoints(-1, -1, -2, -2)
original_set_item(self, header, value)
print(pd.concat([table1, table2[table2.columns.intersection(table1.columns)]]))
number = list(map(int, str(n)))
self.threshold = threshold
x = a[1] * b[2] - a[2] * b[1]
[mysqld]
C[i] = full_array[2]
retstr.close()
form.populate_obj(user)
tfidf_matrix_train = tfidf_vectorizer.fit_transform(train_set)
fun(**dic)
print(a + 1)
test = [it for it in l for _ in range(2)]
print(self.t0[self.event_id].text, millis - self.now - deltaMillis)
Ecliptic(sun).lon
self.height = event.height
found = emojis.findall(search)
r, c = np.unravel_index(np.argmin(M2Dr), shp)
d[id(b)] = b
a[rows, cols] = 0
x = y.ravel()
array = np.array([i, j, k, l, m])
assert all(lst[i][0] < lst[i + 1][0] for i in range(len(lst) - 1))
result = np.empty((len(unique_lats), len(unique_lons)))
col = prop.columns[0]
result = func(*args, **kwargs)
max_indices = []
one, four, ten = operator.itemgetter(1, 4, 10)(alist)
ArtofWarCounter = Counter(x for x in ArtofWarLIST if x not in ignore)
print([i for i in f().contents])
other + self.x
schema = avro.schema.parse(schema_string)
printstats(counts)
a = random.sample(range(100000), 10000)
pred.append((int(tp[0]), int(tp[1])))
fft_axes.set_autoscaley_on(False)
penup()
sw, sh = root.winfo_screenwidth(), root.winfo_screenheight()
plt.plot(np.arange(10, 0, -1) + i)
fronts
x[small_indices] = 0
B = sp.lil_matrix((5, 5))
result = original_import(module_name, *args)
cmd_out.seek(0)
pilImage = Image.open(StringIO(rawImage))
vals, idx = np.unique(c, True)
f = Foo()
x = np.arange(10)
int(x / 0.05) * 0.05
panel.mean()
i.call(1)
print(list(islice((p for p in postponed_sieve()), n - 1, n + 1)))
line[x] = child._text.encode(self.codec)
Py_DECREF(arglist)
answer.append(vector)
data.boxplot()
fields = [(entity, prop) for entity in entities for prop in props]
db.test_collection.drop()
do_some_database_stuff()
soup = BeautifulSoup(r.text)
ccvv
ccbv
epoch = datetime.datetime.utcfromtimestamp(0)
pytest.fail(exc)
self.finish()
body
index = pandas.MultiIndex.from_product([y.index, z.index])
waitress
land = output.astype(bool)
im = im[im > 167]
a = 1
df2 = df.copy()
fig, ax = plt.subplots(1, 1)
highest_values.append(v)
txt = proc.stdout.readline()
arr
os.listdir(dir_name)
self.b = 10
a.dtype
_log_to_logger
format_to_year_to_value_dict = defaultdict(dict)
data.splitlines()[-lines:]
items[index_slice] = list(value.items())
self.a = a
lst2 = [(i, i, i) for i in range(10 ** 4)]
zippy = gzip.GzipFile(fileobj=StringIO.StringIO(data))
coll.remove(data)
cors = CORS(app)
b_in_a.remove(ordered)
print(a_new == expected_a_new)
ps.end_document()
handler.setLevel(logging.DEBUG)
np.r_[x, x[-2::-1], mx[1:], mx[-2:0:-1]]
curses.wrapper(test)
corpus = Corpus(documents=[Document(d) for d in paragraphs])
tmean(arr, limits=(lower_limit, upper_limit), inclusive=(False, False))
property_asel = [x for x, y in zip(property_a, good_objects) if y]
plot.line(x_range, y_range)
seed1 = df[msk].mean()
f.close()
first_int = int(list_of_items_in_line[0])
prefix = next(p for p in strings if p not in suffixes)
self.serialize(s)
common_neis[w, u] += 1
EMAIL_USE_SSL = False
counts, xedges, yedges, im = ax.hist2d(x, y, bins=40, norm=LogNorm())
html = r.frame.toHtml()
ShortName = MyReallyBigClassNameWhichIHateToType
first, second = itertools.tee(iterable)
save_cookies(r.cookies, filename)
p = Particle(foo)
not decompose(l)[1]
True
list(itertools.islice(args[0](), args[1]))
ggplot(df, aes(x=cups_of_coffee, y=productivity)) + geom_line()
deleted[self._key]
pylab.cos(x) + pylab.sin(y)
print(main())
float.__new__(self, value)
method_name = method_to_cache.__name__
i -= 1
a[:, :, (0)] = 255
list(permutations(age.get_group(21).index))
f1 = np.array([1.000049])
jinja2.escape(a)
i = 0
self[context].prob(word)
T = NP.random.randint(0, 10, 20).reshape(5, 4)
fp.getvalue()
baz(5)
outputmapping = {}
results.append((sender.name, result))
partitions.append(a[index:])
print(x)
x ** 2 + self.i
a = list()
serverSocket.listen(1)
list(combined.elements())
c = 2j * np.pi
data.update(value)
keys = list(toCSV[0].keys())
mask = np.isnan(arr)
sys.exit(0)
array_crator(a, (7, 11))
files = []
_, lastday = calendar.monthrange(first.year, first.month)
[logger_qpid]
sha = hashlib.sha1()
key, score = line.split()
Gtk.Grid
0.98
babel.dates.format_datetime(value, format)
BLOCKSIZE = 1048576
self._real_executor = ThreadPoolExecutor(max_workers=cpu_count())
etree.cleanup_namespaces(root)
parser.setContentHandler(StreamHandler())
local_time.isoformat()
p.start()
print(item)
some_date.astimezone(timezone(loc.time_zone))
res = f(*arg, **karg)
np.add.at(grids, idx.T.tolist(), 1)
pos = np.where(my_array > 5)
out.release()
self.customer = customer
diff_business_days = pd.bdate_range(a, b).size
x = fit_df.index.astype(float).values
diff.append(x)
fixname = self._fixname
adj.set_value(adj.upper - adj.page_size)
user = get_object_or_404(pk=user.id)
outp.write(out_str)
alarm.start()
layout = QtGui.QVBoxLayout(self)
biverses_reloaded = mycorpus.aligned_sents()
nr_lines += 1
pool = multiprocessing.Pool(processes=pool_size)
X, Y = np.meshgrid(dx, dx)
dill.detect.trace(True)
a = np.array([[5, 6, 1], [6, 7, 1], [7, 8, 1]])
haversine(origin, paris, miles=True)
cdf = np.cumsum(prob_matrix.T, axis=1)
xlApp.Workbooks.Add()
plt.scatter(intersection_points[:, (0)], intersection_points[:, (1)], s=20)
print(s)
self._odict.update(state)
df = df.fillna(0)
seconds = round(seconds, 6)
res = pd.rolling_apply(tmp.ii, 50, lambda x: gm(x, tmp, 5))
url = models.CharField(max_length=255, unique=True)
print(bar.baz)
stream.close()
A[0][2][0].simplify()
len(res)
self.app.quit()
local_tz = get_localzone()
ksort = np.argsort(x)
x = np.arange(5)
fig.add_axes(ax)
set(d2.items()) - set(d1.items())
getattr(obj, self._attr_name)
A[:] = [sub for sub in A if st.issubset(sub)]
r.status_code
f(*a)
glob.iglob(pathname, recursive=False)
a_deciles = pd.qcut(a + jitter(a), 10, labels=False)
x = numpy.arange(0, 1, 0.05)
a = self.input.read(1)
list_B.append(arr[current_set])
print(line1.contains(pr) or line1.buffer(EPS).contains(pr))
t.doX(arg)
res
title = models.CharField()
new_a = np.zeros((rows, new_cols))
notifier = pyinotify.Notifier(wm)
walk_dir = sys.argv[1]
serversocket.listen(5)
random.shuffle(l)
start = datetime.datetime.now()
plt.legend(loc=1)
a.other = 5
pl.quiver(X, Y, U, V, color=cm.jet(nz(C)))
pylab.pcolor(xx, yy, zz)
ICD.display(grp)
arr = np.delete(arr, -1, axis=1)
file_path = os.path.join(indir, infile)
do_something(a_map[B_object.string])
str(x)
best, jin, jpal
corner22 = [1, 1]
command = input()
R = {i: Vector([SomeCoordinates]) for i in range(1, n + 1)}
datagramRecieved = False
verts = [(0.0, 0.0), (0.0, 1.0), (1.0, 1.0), (0.0, 0.0)]
key_list = list(recursive_dict.keys())
cont = plt.contourf(x, y, z, 25)
self.b = 2
cherrypy.request.scoped_session_class.remove()
queryset = User.objects.all()
m = p.match(line)
mydict[item] = True
np.multiply(unit_ray, closest_plane_distance)
print(pt.get_items())
x, y
self.__keys[idx]
True
b.Print()
zlib.decompress(compressed)
False
x = np.asanyarray(x, dtype=float)
browser.web_view.load(r)
print(a.f2(10))
title = db.Column(db.String(255))
7
r = defaultdict(list)
percent(0.1565, 2)
mock._callable = _patched_callable
arr2[:, ([min_window, min_window + 1])]
orig_test()
SEED = 448
z = zip(a, b)
self._decoratee = decoratee
max(szl, szr) + stackSize + 1
data = Column(BLOB)
cache[param]
area / 2
a = nltk.word_tokenize(text)
df1
sympy.exp(x)
mobile = models.IntegerField(max_length=12)
power_find(11)
x = np.linspace(0, 1, 20)
browser.set_handle_robots(false)
my_list = []
Bar.x
etree.tostring(tree.getroot())
n_errors += 1
signal.alarm(t)
_callg(c, copy_generator(c))
punkt.finalize_training(verbose=True)
self.progress_bar.pulse()
channel.sendall(read_bytes)
ndprint(x)
do_smth(loop_id, i, k)
Fig = plt.figure()
testlist.sort()
list(pd.DataFrame(d).dropna().index)
tr1 = np.fft.rfft(in1, n)
[list(filterfalse(lambda w: w == val, l)) for l in lists]
skip = sorted(random.sample(range(1, n + 1), n - s))
funcs.append(partial(callback, source))
response.app_iter = file_streamer()
1
result.append(x.unpack_from(buf))
layout.setContentsMargins(0, 0, 0, 0)
times.sort()
count = 0
res[k] = [j] = [D[k]]
print(df1)
x[i], x[j] = x[j], x[i]
print(result)
print(output)
print(f.bar())
lid_close()
s.values
results.append(s)
fig = pylab.figure(figsize=(8, 8))
self.text_strings.text_string
sd = copy.copy(d)
urllib2.getproxies = lambda : {}
object.__setattr__(self, name, value)
Base = declarative_base()
tojoin.append(element)
pool.close()
a, b = itertools.tee(nd)
PyObject * p(NULL)
print((name, value))
root.setLevel(logging.DEBUG)
agen = (i for i in a if not i in set(b))
print(stderr)
(d ** 2).sum(axis=0) ** 0.5
f.m
l = SparseList()
arcana = serializers.SerializerMethodField()
labels = np.arange(10)
assert called == [True]
phonenumbers.format_number(parsed_number, phonenumbers.PhoneNumberFormat.E164)
self.end_headers()
d = {(1): [2]}
dec_idx = np.random.choice(2 ** m, N, replace=False)
fig = plt.figure()
len(self.list1)
Template.render = instrumented_test_render
write_to_lmdb(image_db, str(itr), image_datum.SerializeToString())
end = time.time()
print(a1[n] + a2[n])
assert from_date.month == 2 and from_date.day == 29
L.append(4)
self.buttons.accepted.connect(self.accept)
print()
deactivate
Base = declarative_base()
x[1, 0, 0] = value2
Notes
triplets[iT:iT] = [triplets[iT - 1][0], listB[iB + 1]]
self.broken = True
bar.a
lines = np.random.random((numlines, numpoints, 2))
print(welcometext)
print(a)
result = set1.union(set2)
proc.terminate()
print(sy.fu(c, measure=lambda x: -x.count_ops()))
data_fit = est_std * np.sin(t + est_phase) + est_mean
http = credentials.authorize(http)
output = []
l = tf.unpack(state_placeholder, axis=0)
sys.exit()
parser = argparse.ArgumentParser()
print(arr.sum())
data = json.loads(chart_data)
self.mainWindow.settings.setValue(self.cookiesKey, cookiesArray)
fft_axes.set_autoscaley_on(False)
x = numpy.random.normal(size=(size, n))
x.set_sensitive(False)
s[:c]
range_template.py
output
quicksort(array, pivot + 1, right)
total += n
os.dup2(devnull.fileno(), sys.stderr.fileno())
X, Y = np.meshgrid(x, y)
print((m.start() - len(s), m.end() - len(s)))
s.poll()
socket.socket = socks.socksocket
l = [len(i) for i in a]
std = np.std([0, 0, 1])
st.issuperset(b[0])
s = StringIO.StringIO()
l = len(s)
result = {}
np.random.shuffle(yx)
is_sum_of_numbers(9, numbers)
reslen = np.max(accmap) + 1
d = hashlib.md5()
tabrows = []
group(callback.clone([arg]) for arg in it)()
models.py
new_settings[6][termios.VTIME] = 0
main_loop.start()
next.click()
diff = now - datetime.fromtimestamp(time)
decoder = json.JSONDecoder(object_pairs_hook=collections.OrderedDict)
df[i] = df[i - 100].apply(lambda x: x * i)
mask = a[:, (1)] == -1
model = sm.OLS()
alphabet = string.letters + string.digits
self.__f(x - 1)
base64.b64encode(zlib.compress(s))
any(map(lambda match: match in temp, lists))
argspec = inspect.getargspec(sum)
dic = {x: (0) for x in lis}
c = [x for x in map(rect, a, b)]
mapped.repeat()
mat_row.data -= numpy.repeat(vec_row.toarray()[0], numpy.diff(mat_row.indptr))
print(args)
p.map(partial(foo, depth=depth - 1), list(range(x + 1)))
sct.norm.cdf(x=80, loc=60, scale=40) - sct.norm.cdf(x=60, loc=60, scale=40)
ElementTree.XMLTreeBuilder = SimpleXMLTreeBuilder.TreeBuilder
velcro.right(140)
[9, 9, 9]
latest_file = max(files, key=os.path.getctime)
cbar = plt.colorbar(mappable=s, ax=ax)
assigned_leads = lead.objects.filter(assigned_to__in=usercompany).distinct()
b.py
itertools.zip_longest(fillvalue=fillvalue, *([iter(iterable)] * n))
FLANN_INDEX_KDTREE = 1
sf.where((sf.my_col > date_from) & (sf.my_col < date_to))
cls
y.pack(side=BOTTOM)
group.setdefault(key, []).append(item)
MyWidget()
print(rpn)
self.initial_parametername = self.parametername
results.append(dict(zip(columns, row)))
eng = db.engine
imy = np.tile(np.arange(ylo, yhi, 1), nx).reshape((nx, ny)).transpose()
cv.SetImageROI(newCanvas, (0, yc, image.width, image.height))
ax.scatter(xs, ys, zs)
sleep(5)
form = MessageAdminForm
plt.figure(figsize=(6 * 1.618, 6))
c = Counter(x for x, y in ranks)
resp = conn.getresponse()
x_coords, y_coords = zip(*points)
thumb = Image.open(new_file.img.path)
data = cur.fetchall()
woman = WomenNativePassport.objects.get(pk=pk)
False
index[axis] = indices[tuple(index)]
C = B.reshape((20, 20, 2, 2, 18, 5))
datetime.date(2002, 11, 28), datetime.date(2002, 12, 25), datetime.date
v[i] += 1
issubclass(WindowsError, OSError)
session = requests.Session()
companytypeserializer = typebase_serializer_factory(CompanyType)
img = Image.open(sys.argv[1])
original.show()
x = x + y
length = len(s)
sha1.update(data)
tag = _lookup_string(child.tag, strmap)
ax.set_aspect(1)
print(mime_type)
pl.colorbar()
token = response.read()
bar(dvals)
res.status_code == 204
main = objectify.fromstring(xml)
arg = sys.argv[1]
dis.dis(bar)
production.py
pprint(A_inv)
f = open(filename)
strio.seek(0)
print([sph_kn(floor(v), x)[0][-1] for x in X])
ax = plt.figure(fig)
self.data - other.data
heapq.nlargest(2, el)
d = {x: df.columns[df.columns.str.contains(x)].tolist() for x in cols}
consumer.start()
MyObject().id
print(repr(x))
hs.place(x=5, y=5, width=150)
content = cleaner.clean_html(content)
html_theme_path = [customized_readable_theme.get_html_theme_path()]
curses.init_pair(i + 1, i, -1)
d = collections.defaultdict(list)
telnr
next(end)
item_names = list(item_dict.keys())
plt.show()
print(x)
polygons.append(Polygon(square))
existing_category = Category(key_name=category_keyname)
print(col.text)
my_func_called_inside_a_task()
cert.serial_number
queue.put((tag, line.rstrip()))
get_lerp_factor(0, 9, 16)
self.handleError(record)
0,
self.assertFalse(w and str(w[-1]))
ss.bind((host, int(port)))
raise CustomException(42)
top_left = true_points.min(axis=0)
hello.main()
orig_hasattr(o, a)
queryset
n = nx.shortest_path_length(G, 1, 4)
days_since_last_fail = arange(len(is_fail))
plt.subplot(1, 1, 1)
sel = Selector(response)
base_cls_name = obj.__class__.__name__
start = time.time()
s = base64.b64encode(t)
fig = bp.figure()
bn.T.flags
spl[-1] = int(spl[-1])
res = []
cs + np.sum(a)
X_train_to_add
first_row_min = df.loc[(first[0]), first[1]:].min()
c += 1
self._min_y = min(self._min_y, y)
self._add(key[1:], children[-1].children)
print(floor(d * m) / m)
verts = [(0.0, 0.0), (1.0, 0.0), (1.0, 1.0), (0.0, 0.0)]
self.f = f
out_data = []
outer_result = pool.apply_async(setouter, (Q, G, n))
widemapOP = dict((ord(x[0]), x[1]) for x in zip(normal, wide))
f(x=4)
m.group()
session = trans.open_session()
textwrap.indent(text, amount * ch)
local_tz = get_localzone()
stream.read()
xstep = np.concatenate((xstep, -xstep))
app = Flask(__name__)
findex[0] = -1
db_field.formfield(**kwargs)
b = []
s
train_features = np.array(train_features)
cPickle.load(f)
df2
a.sort()
gray = cv2.cvtColor(image, cv2.CV_LOAD_IMAGE_GRAYSCALE)
it.send(StopIteration)
locator.sub(_doreplace, s)
1
client.load_system_host_keys()
[1, 1]
result = celery.AsyncResult(tid)
commands[command]()
w = MyWidget()
result = []
1
tree(size - random.randint(10, 20), myTurtle)
answer = 0
a = a.strip()
ucs4[n] = fill_char
random_genes_dict[x] = genes_dict[x]
loop.run_forever()
find_intersection(m_list)
print(i)
t = threading.Thread(target=tornado.ioloop.IOLoop.instance().start)
content = thefile.read()
non_blank_count += 1
app = Flask(__name__)
os.rename(tempi, filepath)
cos = np.cos
Gcc = nx.connected_component_subgraphs(G)[0]
p += 1
sum([(i * w) for i, w in zip([1] + inputs, self.weights)])
tmpfile_name = tempfile.mktemp()
rdd1.leftOuterJoin(rdd2)
result_names = np.unique(names)
i
__repr__ = __str__
d = {}
d = {}
declaration = doc.toxml()
self.enforce_required_fields(attrs)
print([k for k, v in enumerate(linesB) if not v in linesA])
new_name
methodReference.methodReference.__self__.__class__
mean.shape = mean.shape[0], 1
fig.subplots_adjust(top=0.88)
1
print(df1)
print(i, time.time())
dic[k].append(v)
context.paint()
lst
plt.xticks(list(range(len(corr.columns))), corr.columns)
a * np.sin(2.0 * np.pi * f * t + p)
t.interval(0.95, 10, loc=1, scale=2)
w[1][0]
heights = pd.Series(np.random.normal(size=100))
rooted_paths.append([root] + path)
getkey.get_key(D, 5)
main(**vars(args))
thrlist.append(t)
cross_val_score(LinearRegression(), X, y, cv=threefold)
ax.xaxis.set_minor_locator(ticker.LogLocator(subs=subs))
S.remove([])
print(j)
xlApp.ActiveWorkbook.Close(SaveChanges=0)
self.buffer.append(line)
id(df2.columns)
test_suite.addTest(unittest.makeSuite(Invoice))
i = 0
y = rand(2, 2)
consumer = oauth.Consumer(consumer_key, consumer_secret)
e.args[0].reason.errno
mysets = (set(x.items()) for x in MyList)
np.set_printoptions(precision=4)
a.fromstring(s)
bow
bestfit
np.random.seed(0)
-1
print(max(wn.lch_similarity(good, great), wn.lch_similarity(great, good)))
n * 2
lst.extend(words)
stdout = StringIO.StringIO()
value = getdict(value)
line[-1]
known = set(i for i, j in mylist if j not in other)
self.Show()
a[0] - b[1]
dom.insertBefore(pi, root)
i = 0
start = np.random.randint(0, xmax - 10, nsubarray)
count = len(self.leftover)
False
ar[0] = np.arctan2(vect[0], vect[2])
fig = matplotlib.pyplot.figure()
sys.stdin.name
paths.append([])
infinity
[my_alphabet.index(c) for c in word]
self.delete(seq_num)
setattr(self, key, execdict[key])
subplot(2, 1, 2)
np.trapz(arr)
self.obj_type = obj_type
fp.close()
j == i + 1
f()
cols.append(x)
fcs.pszIconFile = iconpath
n = int(h.hexdigest(), base=16)
recvSock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, True)
id = sa.Column(sa.Integer, primary_key=True, autoincrement=True)
work.append((nx, ny))
data.update({item: set() for item in extra_items_in_deps})
min(best_results, key=distance)
zipstream = StringIO.StringIO()
d if d.day >= 15 else d + timedelta(weeks=1)
all_point_sets.append(curr_points)
OrderedDict(obj)
theta_mid = 0.5 * (theta_edges[:-1] + theta_edges[1:])
select = np.in1d(list(range(data.shape[0])), sample_indexes)
_set_match(matches[-1])
raise NotImplementedError
a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2
newFile = self.window.new_file()
print(cell.value)
thread.start()
print(sum(lst))
n
x = x[x != 0]
[h for h in hay if not set(h) - needle]
a = np.arange(100)
wordpx = []
palette = np.arange(8)
m_list.append(x)
Y = poly.fit_transform(X)
lens = []
a = A.values.reshape(-1, 10)
ndb.delete_multi_async(Shard.query().fetch(keys_only=True))
start = datetime(2012, 1, 1)
email.save()
mymodule.myfunc()
winsound.Beep(600, 250)
true
self.byName = collections.defaultdict(list)
group_consecutives(a)
a, b = b, a + b
(8, [2, 2, 2]),
r = bisect.bisect_left(indices, a)
sock = urllib.request.urlopen(request)
assert x == y
print(elevation.shape)
PLT.draw()
self.draw_confints(ax, offpos, confint, errcolors, self.errwidth, self.capsize)
self._jrdd = rdd._jrdd
self.partitioner = rdd.partitioner
print(resp.headers)
priority_list[i[1]] = 1
object_list = object_list.filter(user=request.user)
tloc = threading.local()
d = {}
yflat = np.full_like(y, max(ax.get_ylim()))
session = Session()
processes = [Process(target=print_head, args=(i,)) for i in range(1, 10)]
check(v1, v2)
plt.plot(x1, y1)
args = parser.parse_args()
grouped.indices[group] = list(range(0, len(index)))
cov = np.cov(a, b)
A = [d.date() for d in drg]
False
xx = np.array([[[1, 2], [5, 6]], [[7, 8], [9, 0]]])
self.monochrome = self.cmap.monochrome
m = a.reshape((a.shape[0], -1))
do_one()
sumBefore.append(sumBefore[-1] + x)
r.append(idx)
func_proto = ctypes.WINFUNCTYPE(HRESULT, HWND)
b = a.copy()
date_dict[date_value.date()].append(date_value)
np.not_equal(c[1:], c[:-1], out=flag[1:])
clientId = serializers.Field()
boundmethod
callerframerecord = inspect.stack()[1]
sample = xy.take(np.random.choice(xy.shape[0], 100, replace=False), axis=0)
app_name.context_processors.date_now
color = np.random.rand(N)
datastore.put(updates)
_PyUnicode_COMPACT_DATA(op)
pytest.fail(exc, pytrace=True)
0
dictionary = read_dictionary_from_file()
allbytes = [chr(i) for i in range(256)]
self.SetCellValue(rowstart + y, colstart + x, c)
cnum = 1
print((args, leftovers))
plt.grid()
self.arg1 = arg1
parts = urlparse.urlsplit(url)
digest = hashlib.sha1(hashcontents).digest()
functor.arity = arity
chrome_options = webdriver.ChromeOptions()
tracefunc
rows = cursor.fetchall()[:10]
print(args)
print(d)
timeit(lambda : list(emptydict.keys()))
print(data)
print(df)
colors = [cmap(i) for i in np.linspace(0, 1, number)]
x.append(int(_x))
self.b = b
df
foo = Foo()
link.allow_tags = True
transitions[msg[0]]()
line[1] = line[1][:5]
a = np.random.randn(1000)
b = B(e)
iter(List)
d = np.diag(C)
description = db.TextProperty()
print(output)
self.client = webtest.TestApp(app)
NULL
self.get(key)
y.pack(side=BOTTOM)
glClearColor(1.0, 1.0, 1.0, 1.0)
cov[(1), :] = 1
time.time() - start_time
T(x + y for x, y in zip(self, other))
miny, maxy = (y1, y2) if y1 < y2 else (y2, y1)
r = np.any(img, axis=(1, 2))
print(myset)
hex(200 - (1 << 16))
new_element = lxml.etree.fromstring(lxml.etree.tostring(elem))
inner.click()
handlers = []
count += 1
obj + 1
sample = random.sample(idx, p)
minimum = random.randrange(0, max_line, 6)
i += 1
cat(toJSON(response))
b = int(sys.argv[2])
reversed_words(s)
setattr(namespace, self.dest, attr)
post_syncdb.connect(add_view_permissions)
self.context = context
parsed_args.func()
myFunction(x, y)
post_env = env.copy()
data = [random.randrange(100) for _ in range(20)]
lines = []
{5, 5}
DEBUGGING = False
expression_if_true if condition else expression_if_false
node = ET.Element(tag)
1
results
user = request.user
data = [False, False, False]
json.dump(testarr, test_file)
y = math.cos(x)
bind_layers(PPPoE_Tag, PPPoE_Tag)
self.c = c
df[cols]
print(is_perfect_cube(-64))
example = np.ones((4, 2, 100))
df = pd.read_csv(files[0])
key = f.read()
ani = animation.FuncAnimation(fig, lambda : next(game))
indented[0] = lines[0]
vals = []
[self.x - 1, self.y], [self.x + 1, self.y]
result_feed = gd_client.ExecuteBatch(request_feed)
positive = array + np.amin(array)
stop_event = threading.Event()
fs1 = frozenset([42, 666])
result = dialog.exec_()
conn.close()
b = [1, 0, 1, 1, 0, 1, 1]
value = map(lambda x: power(r, x), funcs)
select_rows(*items)
print((key.__name__, items))
edgey1 = region1 ^ np.roll(nregion1, shift=shift, axis=1)
kth_order_statistic2(A, k)
print(stdout[-1])
assert np.allclose(orig, decoded)
min_x, max_y, minloc, maxloc = cv2.minMaxLoc(result)
q, r = divide(22, 7)
X = [map(int, row[0:6]) for row in A]
dims = np.fromfile(f, dim_dtype, array_ndim)
s = pd.Series(np.random.rand(100))
post_delete.connect(update_b_count, sender=B)
os.times()
obj.func1
d2 = decimal.Decimal(2)
wait_for_finishing_subprocess()
arr[1:].imag = arr[0].real
cax = fig.add_axes([0.15, 0.15, 0.05, 0.4])
param = dist.fit(y)
WSGIApplicationGroup % {GLOBAL}
start = argc.value - len(sys.argv)
i = np.argmax(A != 0)
print(timeit.timeit(list_comprehension))
a = copy(data)
pyo = ctypes.py_object(o)
s[:last_index]
draw = ImageDraw.Draw(im)
site = sys.argv[1]
current = match.group()
self.updateIcon()
raise ValueError
y.shape
wrapper
_defaultdict(CountTree)
_, filename = os.path.split(latest_file)
count += bytechunk
outer.inner()()
[p.join() for p in proc]
data = iris.data
x = np.array([0.5, 2.2, -1.8, -0.1])
df1.plot(ax=ax)
A2 = np.hstack([A, A])
fit_alpha, fit_loc, fit_beta = stats.gamma.fit(data)
real += 1
fly.rect.x += fly.hspeed
foo = Foo(settings)
ind1, ind2
connection.ops.value_to_db_datetime(value)
base = argparse.ArgumentParser(add_help=False)
print(vardata.something_else)
self._deletes.add(key)
[map_level(f, i, level - 1) for i in item]
runUntil(start.Add(time.Millisecond * 100))
max_y = np.nanmax(rot_points[:, (1)], axis=1)
connection = some_connection_pool.get_connection()
index = np.arange(len(cols))
print(res.ready, res.value)
print(result)
directive += signature
f = tempfile.NamedTemporaryFile(delete=False)
print(s.title())
0
auth_uri = flow.step1_get_authorize_url()
os.chdir(PATH)
line = line.strip()
sum
now = datetime.datetime.utcnow()
min(S)
title = models.CharField(max_length=100)
shelf.close()
rtn = True
plt.vlines(x_intersect[negatives], -20, 20)
init_from_map(self, locals())
tree.getPayload()
print(char, count)
c = np.random.normal(size=1000)
self.canvas = FigureCanvas(self, -1, self.figure)
argparse.ArgumentParser.set_default_subparser = set_default_subparser
help(isinstance)
new.__class__ = old.__class__
(d - 1) * d / 2 == len(condensed_matrix)
ex2 = QtGui.QWidget()
opening = cv2.morphologyEx(img_thresholded, cv2.MORPH_OPEN, kernel)
{{balance.amount | abs}}
print(minified)
value = list1[0][i]
bs = BeautifulSoup(t)
df[df.col1 == tf.col1]
drops = df.index[df.index < df.index.max() - keep]
a = []
self.dict[key]
seq = [(x, key(x)) for x in seq_in]
res
skin_ycrcb = cv2.inRange(im_ycrcb, skin_ycrcb_mint, skin_ycrcb_maxt)
s, self.get_environ(s)
numpy.median(vars)
dx = x[1] - x[0]
original = np.get_printoptions()
i = 0
print(a.shape)
w = Window()
s.asfreq(BDay())
myclient = Client(url, transport=mytransport_instance)
group = models.ForeignKey(Group)
Tree.fromstring(s)
tfile.close()
y = numpy.array([0.5, 0.75, 1, 0.5])
b = unhexlify(myhexstr)
a = np.arange(20).reshape((5, 4))
len(res)
counts = collections.Counter(a)
dRA = uniform(-0.0001, 0.0001)
optimizer = tf.train.AdaGradOptimizer(0.01)
S = dok_matrix((10000, 10000), dtype=bool)
ind = pd.Index([(e[0] + e[1]) for e in mi.tolist()])
sess.run(tf.global_variables_initializer())
desired_value = __builtins__.next(value_iterator)
b = map(tuple, list(d.values()))
model1 = models.ForeignKey(Model1)
print(serialize(data))
self.channel = self.connection.channel()
allix = set(range(len(elements)))
parameter1 + parameter2
name = db.Column(db.String(50))
list2 = map(itemgetter(1), origlist)
list(zip(alist, blist))
print(a)
self.kill(signal.SIGKILL)
managed = False
min(lists, key=len)
int(x)
self.grid()
labels = np.linspace(m0, m1, num_ticks)
plt.imshow(data)
set_ids = []
dlg.Destroy()
self.factory.startedConnecting(self)
pairs = zip(mylist[::2], mylist[1::2])
entry_split = entry_regex.split(row, 1)
previous_value = doing_fd.read()
handler = logging.StreamHandler()
shelf.clear()
init_op.run()
np.array(l) ** np.arange(len(l))
foo(node, p)
print(page)
i1 = Interval(10, 15)
printItems(v, indent + 1)
df1
result
np.log10(1 + 100 * a, b)
print(my_string.zfill(2))
TerminateProcess(hProcess, 1)
p = np.asfarray(p)
pclt.set_transform(mtransforms.IdentityTransform())
fd = sys.stdin.fileno()
result = ssh.stdout.readlines()
is_duplicate = df.apply(pd.Series.duplicated, axis=1)
a ** 2
Matrix(df.as_matrix())
f
print(larray)
minval = a[i]
chain += [primes[secnum]]
x = 5
type(Foo.bar)
usleep = lambda x: time.sleep(x / 1000000.0)
N = 100
multiply(S, P)
lst2 = [1, 2]
self.value = value
s.read(len(expected))
print(dict)
dt_delta = dt_delta.days * 60 * 60 * 24 + dt_delta.seconds
self.array.append([item, priority])
print(string.value)
logger.addHandler(console)
entries.add(key)
os.path.join is posixpath.join
self
rand_num = np.random.choice((0, 1), p=[1 - p, p])
comp = compiler.SQLCompiler(dialect, statement)
item.setCheckState(QtCore.Qt.Checked)
df2.columns
nonmatching = object()
print(pat.findall(data))
scores[name] += int(score)
canvas.print_png(response)
authentication_classes = TokenAuthentication,
allocate(rowData(nC))
sys.exit(qApp.exec_())
r = lambda x, y: np.sqrt(max(0, 1 - x ** 2 - y ** 2))
msg = handle_pyerror()
x = list(enumerate(l))
args = [(square, a[i], x[i]) for i in range(10)]
self.sock = sock
toss2[edges] = dsteps
res = opener.open(req)
Py_Initialize()
qbbbb
bbbb
qaaaa
val
c = SimpleCV.Camera(1)
self.z = z
map(tdgi, filter(tdin, theList))
fields = [line[column].strip() for column in columns]
foo(node, copy.deepcopy(p))
EMAIL_PORT = 25
rhost = socket.gethostbyaddr(host)
sys.float_info.epsilon
something = protorpc.messages.StringField(1, required=True),
print(list(people.keys()))
create_frequency_list(df)
milepost += len(data) // 10
b = [4, 5, 6]
results = []
children
w.writeheader()
result.append((ChartItem(rule[0][0], Ir), ((x + z, z), (Ih,))))
data = f.read().split()
ogl.CGLGetCurrentContext.argtypes = []
sys.stdout = _stdout
print(self.value)
expressions = []
L = list(range(100))
BOOST_PYTHON_MODULE(example)
result = _SHGetFolderPath(0, CSIDL_APPDATA, 0, 0, path_buf)
z = list(zip(t, t2))
xys_top.append(((x.max() - x.min()) / 2.0, zone))
num += s[0]
demo01()
layer.paste(mark, (x, y))
print(urlunparse(u))
what_i_want = [i for i in combinations(stuff, len(stuff) / 2)]
keylist.append(lkey_annotated)
a = np.random.randn(10, 10)
plt.gca().add_artist(self.line)
print(lst)
dists.shape
fig = plt.figure()
out = np.ravel(np.zeros(shape=(n, n)))
[(j, is_odd(j)) for j in range(10)]
fromstring_tree = etree.fromstring(xml_str).getroottree()
your_subprocess.py
retries = 0
[]
link.allow_tags = True
aaaaa
[tox]
tree = et.fromstring(xmltext)
sqrt_n = int(math.floor(math.sqrt(n)))
self.x = x
feature_group.add_child(folium.Marker(location=[lat, lon], popup=name))
L = ax.legend()
print(easygui.fileopenbox())
mmapped_file_as_string.close()
print(recursion(a))
print(i, j)
divider = make_axes_locatable(ax)
x = np.random.normal(1 + i, 0.04, size=len(y))
stdin.flush()
print(len(A))
self.value
text.rfind(pattern, 0, text.rfind(pattern))
post_data = request.POST.dict()
log(p(a, b) / (p(a) * p(b)))
MANAGERS = ADMINS
convert_list = label_list[:-1]
result += self.buf.read(size - len(result))
t = Thread(target=processData, args=(some_data,))
AppHelper.runEventLoop()
loader = unittest.TestLoader()
unew = np.arange(0, 1.01, 0.01)
f.name
doc = parseString(html_string)
r
result = list(product(*lists))
m if m else 12
filepath = sys.argv[1]
form = OrganismForm()
queryset = self.model._default_manager.all()
MyClass.some_method(mock_object)
[4, 8, 12],
a_test.method_three()
result = thirdparty.go()
lstnans = [np.nan] * (len(Weight) - len(Quota))
vals_array[lat_idx, lon_idx] = vals
sys.stdin = _stdin
columns[k].append(v)
cbar_ax = fig.add_axes(fig_coord)
s.startswith(tag)
cr = csv.reader(response)
parser = ArgumentParser()
lats.append(float(row[1]))
_foo()
print(json.dumps(x))
a[:] = numpy.NAN
edges = [(i, j) for i, j in permutations(replace, 2) if i[1].has(j[0])]
1
platform.release()
type(Sub1)
y = np.array(y)
json.dump(testarr, test_file)
print(sqlStr)
action = webdriver.common.action_chains.ActionChains(driver)
i = (n + 1) / 2
d = datetime.datetime(*tup[0:6])
x = np.linspace(0, 2 * np.pi)
coords = np.array([yy, xx, np.zeros(im.shape[:2])])
sftp.get(filepath, localpath)
print(list_index)
repmask = np.logical_and(~flag[slcs2], flag[slcs1])
s = list(input_str)
print(df.index.hour)
params.append(escape(v, conversions))
fallback
root = Tk()
data = self._get_numeric_data()
tree = ahocorasick.KeywordTree()
filerecords.remove(selection)
sent = self.sock.send(msg[totalsent:])
MULT(table[i - 1], a, table[i])
data = Counter(your_list_in_here)
f(*args, **kwargs)
ret1, frame1 = cap1.read()
s = requests.session()
len(self._d)
z = np.any(img, axis=(0, 1))
result += num_subsequences(seq[1:], sub[1:])
len(self._dict)
magdir = np.rad2deg(np.arctan2(u, v))
test_case.assertEqual(len(expected), len(actual))
M = [[0, 1, 2], [1, 0, 1], [2, 1, 0]]
b.wait()
messages.sort(key=lambda m: m.lineno)
print(integer, exponent)
row = session.query(Table)[rand]
print(mystring.format(**locals()))
process.kill()
f.seek(f.tell() - overlap)
color = models.CharField(max_length=50)
shutil.copytree(source, destination, ignore=ignored_files)
cmap4 = CustomCmap([1.0, 0.42, 0.04], [0.5, 0.5, 0.5])
my_img = tf.image.decode_png(value)
cache.incr(self.COUNTER_CACHE_KEY)
list(iterate_strings(5))
edge_list.append((i, j))
myNewMassage.extend(myMassage)
a = np.zeros(100000, int)
pprint.pprint(x)
w = gtk.gdk.get_default_root_window()
xlim(0, 1000)
proxy.config.debug = 1
newfile.close()
lazy(help_SHOP_CHOICES, list)()
pylab.plot(x, y)
loop.call_later(5, stop)
app
x11, x21 = np.meshgrid(A[:-1, (0)], B[:-1, (0)])
X = np.arange(N * N).reshape(N, N)
blank_image.save(out)
ax = fig.add_subplot(111)
lines = [line] + list(itertools.islice(f, 6))
print(min((cost(shots), shots) for shots in shot_sequences))
start = time.time()
data = np.random.multivariate_normal(mu, sigma, 1000)
self.buffer = []
string = string.rstrip().lstrip()
yaml.add_representer(literal_unicode, literal_unicode_representer)
b = [l[i] for i, flag in enumerate(flags) if not flag]
points = np.empty([50, 100])
print(a)
AND_ANOTHER_CONSTANT = 4
x = np.linspace(min(sample), max(sample))
time.sleep(0.5)
files = zip_file.namelist()
list(parse_to_argv_gen(instring))
B = p2[0] - p1[0]
text = tk.Text(root, wrap=tk.WORD, height=5)
self.set_data(x, y)
master = Tk()
logA, alpha, B = np.linalg.lstsq(M, np.log(ydata))[0]
xml
print(a[j[k]])
xlsx = pd.ExcelWriter(output_path)
item in self.__dict__
x_std = (x - x.mean()) / x.std()
arr = np.array([([1] * 10) for _ in range(5)])
self.file.seek(position)
a = np.asarray(a)
mail = line[1].strip()
eval(equation)
z = x * np.exp(-x ** 2 - y ** 2)
func = lambda : requests.post(full_url, json.dumps(data))
narr = np.asanyarray(source)
nom_plan_label = QtGui.QLabel()
time = (end - start) / 1000
cursor = connection.cursor()
race = models.ForeignKey(YourRaceModel, index_db=True)
content_type = mimetypes.guess_type(name)[0]
session = requests.session()
popt, pcov = curve_fit(func, xdata, ydata, p0)
newTuple = tuple(oldTuple[x:x + 4] for x in range(0, len(oldTuple), 4))
mask1 = np.hstack((False, arr[1:] < arr[:-1], False))
parser.print_help()
B = np.zeros_like(A)
print(x)
current_dict = current_dict[letter]
results = map(f, list(range(50)))
form = UsersForms.UserImage()
fd.writelines(rows[n:])
x + y
out[::-1]
cv2.destroyAllWindows()
person.put()
rt.clock_getres(CLOCK_REALTIME, byref(res))
pickle.dump(ibm, fout)
result = []
v = defaultdict(list)
X, Y = meshgrid(x, y)
x
cols = [(np.ones_like(a) * i) for i, a in enumerate(data)]
idxes = [idx for idx, val in enumerate(s) if val in letters]
x = random.gauss(-200, 150)
ax1 = f1.add_subplot(111)
term_appearance.update(x)
stdscr.addstr(len(lines), 0, s)
a.append(0)
lg = lua.globals()
url_values = urllib.parse.urlencode(data)
soup = BeautifulSoup(f)
deleteseq[pos:]
self.doIt = myFunc
self.length = n
t[rows]
running = True
h5_store = h5open(file_input, fileop)
signal.signal(SIGHUP, SIG_DFL)
inbox = outlook.GetDefaultFolder(6)
out = np.zeros(A.shape[0], np.bool)
f.truncate()
f.seek(999999999)
gridpoints = np.array([xx.ravel(), yy.ravel()])
print(df)
y = np.random.rand(20)
func(elem, level)
result.append(math.pow(y, 2.0))
utc_dt = utc.normalize(dt.astimezone(utc))
ax = plt.gca()
a = QApplication([])
originalList = [0] * len(myList)
upper_bound = np.array([255, 255, upper_val])
vars(X())
wrapper
answer.save()
l2 = l[split:]
a, b = list(range(10000)), list(range(10000))
manager.resize(*manager.window.maxsize())
sys.exit()
title = title.strip()
buf = bytearray(bufsize)
word1_set = word1_synonyms[best_match[0]].lemma_names
d[5] = 1
sc = SparkContext(conf=conf)
p.close()
self._cond.acquire()
t = Thread(target=some_task)
spark.range(10).rdd.map(map_sth).count()
cmpfunc = lambda a, b: cmp(b, a)
self.name = tempfile.mkdtemp()
json.dumps(dict_obj)
deg, mnt, sec
choice = localrandom.randrange(num_choices)
found = True
len(self.buffer) > 0
self.first_name
x = x.flatten()
cols = [mapping[i] for i in y]
d = Dave()
origin[0], origin[1] - 1
min_d, max_d = 50, 200
assert len(self.weights) == len(self.chars)
self.data
x
sys.stdout.flush()
deletex
root = Node(element)
j = np.arange(N)
a[:, (1), :] = [[8, 8, 8], [8, 8, 8]]
section.append(line)
bar.fizz()
task.add_done_callback(self.handle_go_result)
num[i, j] = np.where(t[i] <= t[j], t[i], t[j]).sum()
hold(True)
count = 0
lyrics = m.group(1)
x2_Kaxs_2[j] = [random.randint(0, 9) for k in range(2)]
fn = fileinput.filename()
f2.write(b)
self.window_list = []
delta += 1
cn = Counter(l).most_common(2)
value.__index__()
print(parser.parse_args())
env = os.environ.copy()
union.match(word)
count, sum
test1.put()
count = 0
result = []
len(self.alist)
d_view.sort(reverse=True)
c = calendar.Calendar(firstweekday=calendar.SUNDAY)
s = f.read(bufsize)
someList = []
print(curve_fit(f, xdata, ydata, p0=(0.1, 0.5, 0.1, 150)))
next([x for x in test if x % 5 == 0])
a.insert_node(a.root, 4)
t.start()
f = Foo()
xlen = wlen
ranked = sorted(timings, key=lambda t: t[1])
B[::2] += 0.1
msg = EmailMessage(subject, html_content, from_email, [to])
dumps(rv)
True
top = sorted(freq_dict, key=freq_dict.get, reverse=True)
id = Column(Integer, primary_key=True)
im[ylo:yhi, xlo:xhi] += gauss2d(imx, imy, amp, x0, y0, sx, sy)
z = x + y
total += int(col)
f = interp1d(x, y)
self.end_states.append(name)
print(df)
sd.play(data, fs)
do_something_to_display_them()
pvt = pvt[pvt.columns[1:].tolist() + pvt.columns[:1].tolist()]
GENERATE_LATEX = NO
dl = Downloader()
y.visit(t)
result = dict(zip(columns, result))
prime_divisors = [d for d in divisors if isprime(d)]
results = [], []
d = np.diff(b)
fig.draw(fig.canvas.get_renderer())
fig, ax = plt.subplots()
ret[line.strip()] = {}
result = self.cursor.fetchall()
defaultdict(recursive_defaultdict)
result = []
threads[-1].start()
idx = np.arange(iszero.shape[0])
c()
_foobar(m, n, xpp, ypp)
print(list_A, list_B)
s = b.session()
d2 = datetime.date(2008, 9, 15)
data = np.reshape(np, random.randn(20), (10, 2))
a[0, 0, 1] * b[0, 1, 2]
s = set(range(10))
netscape = True
mask = df.eq(df.max(axis=1), axis=0)
new_sequences.add((val + 1, count + 1))
answer.append([i])
tasks = [blocking1(), blocking2()]
nrows = B.shape[0]
inner_fn()
arr[i] = -1 * arr[i]
eventLoop.exit()
p_as_list.append(node)
arr2 = [[(i + j) for i in range(5)] for j in range(5)]
z = list(zip(t, t2))
y = y.reshape(numRows, 1)
counts = {k: v for k, v in list(Counter(mylist).items()) if v > 1}
cursor = connection.cursor()
fullPath = os.path.join(dirpath, filename)
lmarshalledClosureValues.append([pickle.dumps(litem)])
print(element)
self.connect()
c0 = np.array([1.0, 0.0, 2.0])
len(self.arr)
AC, 150.0
data = obj.__getattribute__(field)
alphabet = string.ascii_letters + string.digits
od = OrderedDict()
non_blanks = (line for line in fin if line.strip())
the_table.update(giveHereYourDictionary)
self.create_receiver()
self.x = x
B /= B.std()
inner()
start_index = np.argmin(np.abs(ts - start_point))
job.join()
d, c, b, a = a, b, c, d
amap.append([r(), r(), r(), r(), r(), r()])
EnumProcesses.restype = ctypes.wintypes.BOOL
{(9): 9}
awscli
print(result)
postvars = cgi.parse_multipart(self.rfile, pdict)
ax.clabel(cset, inline=1, fontsize=10)
configure(config)
list(indices(5, 2))
bucket = conn.get_bucket(BUCKET_NAME)
s = set([4, 5, 6])
user.is_staff = True
vset(args)
c_array[:] = points
x = datetime.now()
trimmed.append(line[indent:].rstrip())
img = cam.get_image()
out = x[unq_idx[np.bincount(tag_idx) == 1]]
data.extend(x)
print(new_list)
df_null = df.isnull().unstack()
fascent, fdescent, fheight, fxadvance, fyadvance = ctx.font_extents()
clump_mask = label == biggest_label
rng = list(range(6, 9))
finish_time = datetime.datetime.now() + datetime.timedelta(hours=6)
columns = list(someitem.keys())
myvalue = eval(my_data[name])
item
simplejson.loads(s1)
l = [0, 1, 2, 4, 5]
print(data)
True
id = Column(Integer, primary_key=True)
id(os1) != id(os2)
print(b.weekday())
first_ten = pd.DataFrame()
a = copy.deepcopy(a)
print(x.pop(-1))
b[b == 255] = 1
sys.stdout = self.sys_stdout
v = ctypes.c_int(1)
plt.subplots_adjust(top=0.85)
after.replace(sub, wanted, 1)
block_list
delta_time = (time2 - time1).total_seconds()
plotter2 = Plotter(ui)
termios.tcsetattr(fd, termios.TCSAFLUSH, old_term)
ecdf = sm.distributions.ECDF(sample)
x = sin(i)
res = []
field.document_type(**value)
file_writer = csv.writer(test_file)
G.add_edges_from(list(data.items()))
df_count = df_count.reset_index()
b = np.eye(2)
1 + self._foo
app.exec_()
r.clipboard_clear()
item = date_to_datetime(item)
yi = np.linspace(min(y), max(y))
app.logger.info(region2.id)
print(len(img.split()))
[pypi]
dict.__init__(self, *kwargs)
state = self.__dict__.copy()
datetime.timedelta(475)
title = models.CharField(max_length=255)
i = 1
[0.80000001, 0.40000001]
TestApp().run()
n = np.array([-t[1], t[0]])
client_socket.send(k)
next(self.__iterPerson(**kwargs))
index = self.dictionary[key][0]
ax.scatter(x, y, z, c=density)
ax1 = plt.subplot(121)
num_consumers = mp.cpu_count() * 2
config = config.reindex(new_index)
data = s.recv(1024)
driver = webdriver.Firefox()
fun(arg)
x = y + x
print(pretty.date(yesterday, short=True))
ConfusedRaster = arcpy.sa.Con(arcpy.sa.IsNull(ras1) == 0, 1, 0)
print(list(cells)[1:])
self.__disconnect__()
tools.c.do_something()
plt.show()
message
tokens = re.split(pat, text)
window = QtGui.QWidget()
client = pm.SSHClient()
soup = BeautifulSoup(value)
output = df.communicate()[0]
assert y.shape[:2] == new_x.shape and x.shape == y.shape[2:]
p
self._odict[key] = val
df = pd.DataFrame()
bytereader = lambda : fobj.read(1)
gc.collect()
f.write(content)
pb = gtk.gdk.Pixbuf(gtk.gdk.COLORSPACE_RGB, True, 8, w, h)
funcs = funcs[:]
foo = models.Foo()
type(a)
prime = True
a.d
tup[0] = a
listvals = []
wrapper
v1 = np.random.randn(100)
wrapped.__module__ = tgt_func.__module__
x = np.append(np.nan, np.append(x, np.nan))
output = {}
img.set_data(haha)
zip(*([iter(List)] * 2))
p.join()
plt.tight_layout()
assert mac.isalnum()
print(df)
L = [(x[0], x[1]) for x in list(tmp.items())]
pos = pygame.mouse.get_pos()
a = 10
fNewList = list(fL)
entries.append(attrib)
lookup = collections.defaultdict(list)
ax = f.add_subplot(111)
df
df = pd.DataFrame(dict(observation=np.random.uniform(50, 60, 200)), idx)
graph[-1].append(line)
convert_list(v)
elementwiseApply(mul, list1, list2)
x = numpy.arange(10)
outputlist.append(y)
grp1.parent_id,
a[(b), :]
ids = set(i for i, j in mylist)
1
sat = np.cumsum(np.cumsum(sat, axis=0), axis=1)
item_set = set([item for sublist in s for item in sublist])
day += DELTA / 60 / 60 / 24
print(a)
self.foo = foo
x.start()
self.NEWATTRS.append(attrs)
self.cookies = []
count_Trues(b_List)
s.discard(line.strip())
lookup_list = []
result.append(set(sublst))
newY = y[:]
values = numpy.random.randint(0, 20, 10)
table = Gtk.Table(1, 1, False)
baz.bar(1)
finder.run_script(source_name)
self.a
self.count = start - 1
print(k)
frame.pack()
print(word)
s[:-amount] + substring
total
total_length += dereference(it).second.size()
user = request.user
msg_out[i + j] ^= gf_exp[lcoef + lgen[j]]
False
Py_DECREF(POP())
d.append(c)
ch = logging.StreamHandler(sys.stdout)
driver = webdriver.Chrome()
GC.SuppressFinalize(this)
sys.stdout = code_out
{{x}} - {{y}}
Union(self, other)
l2.remove(m)
out.write(u)
result[x, y] = grid.cells[x, y]
c = np.concatenate((a, b))
response = requests.get(slug)
events += [(t, value, i) for t, value in l]
g.sum()
stream.attach(screen)
print(issubclass(Foo, Mixin))
fout.close()
r_[a2d(a0), a2d(a1)]
beg_ts = time.time()
actions.perform()
self.data[key]
file_contents_values = list(file_contents.values())
mytimer = FakeTime()
sys.exit()
do_something_with(request)
self.ax = self.axes[0]
p = select.poll()
e.tags = self.tags.all()
title = title.strip()
df = df.copy()
source_unique = [v1 for v1 in source_list if v1 not in set(diff_list)]
crsr = cnxn.cursor()
new_hexbin = self.ax.hexbin(self.xData, self.yData)
fig = plt.figure()
now = datetime.now(tz)
print(number)
G = nx.DiGraph()
interp(256, [1, 512], [5, 10])
df = pd.read_csv(content, header=0)
root = Tk()
_new_foo, (self.__class__, coltypes, rows)
a.insert(0, self.__adb_path)
self.sum += item
os.chdir(moveTo)
serializer_class = UserSerializer
f_ab = np.empty((len(a), len(b)), dtype=np.array(f(a[0], b[0])).dtype)
np.allclose(loopy_cdist(seed, data), vectorized_indexing_maxat(seed, data))
MOUSE_LEFTDOWN = 2
clf = XGBClassifier()
myUdf = udf(myFunc, StringType())
yaml.dump(test2)
df_from_each_file = (pd.read_csv(f) for f in all_files)
print(x)
print(x)
a = a + 5
_method(parameter, _user_data)
d = defaultdict(list)
opener = urllib.request.build_opener(proxy_support)
reverse_d = collections.defaultdict(list)
imshow(blue)
mg = numpy.meshgrid(x, y)
self.GoaldID = -1
print(a)
a = A()
plt.scatter(list(range(len(results[0]))), results[0])
self._real_executor.shutdown()
stream_handler = logging.StreamHandler()
server.handle_request()
x.myAttr
path
l[0] if len(l) else []
np.all(a == b)
low = np.array([-10, -10])
s0 = s[0]
packetcount = 0
math.sqrt(numpy.sum((circle1.pos - self.pos) ** 2))
magdir
df
print(strs)
sys.stdout, sys.stderr = orig_std
self.value = value
sprocket = PySprocket(widget)
print(text)
print(len(rgbData))
password_mgr = urllib.request.HTTPPasswordMgrWithDefaultRealm()
c.index(a[index])
cords_set = set()
create_app().app_context().push()
ses.listen_on(6881, 6891)
d_sum[topkey][key] = dic2[topkey][key]
PyObject * weakreflist
action = pipe.readline()[:-1]
response
deletecities[key]
variables
rgb_values = []
adjlist = [set(graph.neighbors(node)) for node in range(graph.vcount())]
i -= 1
root = Tk()
e.args[0].reason
df
W = nmf_model.fit_transform(A)
self.connection.add_on_close_callback(self.on_closed)
inf.close()
self._value = value
db.reset_queries()
makedirs(mypath)
Product.objects.get(part_no=self.product.part_no)
fib_lru(n - 1) + fib_lru(n - 2)
urls.append(self.view.substr(selection))
s = str(n)
f(args)
list_container = [ast.literal_eval(line.strip()) for line in lists]
col = ax1.scatter(x, y, 100 * s, c, picker=True)
winreg.SetValueEx(INTERNET_SETTINGS, name, 0, reg_type, value)
filters = []
cv2.line(vis, (x1 - r, y1 - r), (x1 + r, y1 + r), col, thickness)
sorted_index = numpy.argsort(xs)
mat_f = np.column_stack((mat_xc, mat_yc))
config.write(cf)
print(n)
self.temperature = 1
threading.Timer(next_call - time.time(), foo).start()
event = Event()
parser.set_defaults(method=a)
print(res)
self._obj = obj
handler = urllib.request.HTTPBasicAuthHandler(manager)
self.move(self.old_pos)
L = L[:start] + L[end:]
x = sin(phi) + 2 * sin(2 * phi)
print(np.sqrt(xa ** 2 + ya ** 2))
f(**example)
instance = self.get_object()
tables = iengine.get_table_names()
rev = (len(d) - idx for idx, item in enumerate(reversed(d), 1) if item)
tot = gllhs
lst.clear()
convolution.real
extent = [yedges[0], yedges[-1], xedges[-1], xedges[0]]
next(b)
contents = text_file.read().rstrip()
ax1 = plt.subplot2grid((m, n), (row_1, col_1), colspan=width)
end = time.time()
treeview.append_column(treeviewcolumn)
squared_list_iter = [(value ** 2) for value in my_array]
self.mps_in_process.append(id)
zip_code = models.ForeignKey(ZipCode)
output = random.choice([sys.stdout, sys.stderr])
d[key] = x
page.close()
type(seq)([val])
dict.__delitem__(self, k)
el.clear()
self._n_weights += neuron.n_inputs + 1
self.factory.doStart()
t = timespec()
nameserver = default.nameservers[0]
test1()
mutation.append(choice([0, 1]))
sample_ix = np.random.randint(low=0, high=500, size=100)
rect(ax, x, y2, dx, y1 - y2, color, **kwargs)
arr = np.array([[255, 255, 255, 255], [255, 0, 0, 255], [255, 255, 255, 255]])
print(split[1])
wxImage.SetData(frame.tostring())
foo.num += 1
y = ytrue + np.random.normal(size=len(x))
text
inf.seek(offset)
factor * f(*args, **kwargs)
True
urls_d = Counter(list_of_urls)
[x[1], u(t)]
end = start + timedelta(days=6)
QModelIndex()
last_stop = split_points[i - 1][1] + 1 if i > 0 else 0
whiteness = w / (y + w)
out[k].append(item)
s = stringio.read(1)
A, Y
B = np.random.rand(N, N, N)
print(series_data)
_repr(o)
print(newString)
yf = scipy.fftpack.fft(y)
Py_Initialize()
length = len(text) - 1
print(texter.create_text())
subset = [x for ind, x in enumerate(lists) if ind != 1]
b = -2 * (zfront * zback) / (zfront - zback)
reporter = ExceptionReporter(request, is_email=True, *exc_info)
next = self.queue.dequeue()
deleteself.thisptr
L = list(range(10))
hist = serie.hist()
word2_synonyms = wordnet.synsets(word2)
subset1 = data[data[:, (0)] == 100002]
print(lst)
I = speye(A.shape[0], A.shape[1], dtype=A.dtype, format=A.format)
data = input()
ax2.set_ylim(scale * (miny + dy), scale * (maxy + dy))
rowsum = A.sum(axis=1)
write(n, pos + 1, op + 1, cl)
main.py
self.sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
messages = [parser.Parser().parsestr(mssg) for mssg in messages]
klass = getattr(module, c)
self.value = value
A * x ** alpha * np.exp(B * x)
newlist = []
root = Tk()
print(type(tf))
print(a)
x = np.linspace(0, 1, 10)
self.causes = {n: [] for n in self.fnames}
iv.append((left, right))
queue.append((node, end, path))
grouped.JobNos.sum()
type(converted.iloc[1])
hi.bye = 5
b, c
Dup = {}
hosp_info = {}
images = []
len(self._data)
b = [8, 1, 5, 4]
d = defaultdict(list)
df
print(legend.get_window_extent().height)
s = bitstring.pack(fmt, **d)
count = Counter(word)
cv2.line(vis, (x1 - r, y1 + r), (x1 + r, y1 - r), col, thickness)
t, v, tb = sys.exc_info()
i += 1
ax = plt.gca()
shifts = [1] * (len(pattern) + 1)
len(buffer.getvalue())
record = self.queue.get()
value = request.POST[key]
print(mystring)
result = []
x[i], y[i] = polygon[i]
pdraw = ImageDraw.Draw(poly)
vstart = vspell[1]
inp = sys.stdin.read(1)
self.long_thread.thread_finished.connect(self.reply2_finished)
xnew = np.linspace(x.min(), x.max(), num=npts, endpoint=False)
self.name = name
w, h = table.wrap(width, height)
np.frombuffer(mp_arr.get_obj())
p = Pool(5)
pg_n_genotypes = models.TextField()
browser = QtWebKit.QWebView()
print(os.__file__)
mapping[u]
cv2.line(view, pt1, pt2, color)
F = R[1] ** 2 * R[2] * R.x - R[0] * R[1] * R.y + R[2] ** 2 * R.z
pmb = p - b
idx = a[R, C].argsort()[:4]
x + 10
print(resp.status)
y = np.sin(x)
win.refresh()
axmatrix.set_xticks([])
print(a.x, a.y)
tkpi = ImageTk.PhotoImage(image1)
print((inst.x, inst.y, inst.z, x))
X.append(x)
eval(str(a))
text = StringField(required=True)
app = Flask(__name__)
api = Api(app)
batch = tf.Variable(0)
grp.count()
transform = lambda x: x.id
pyximport.install()
print(df)
fv = numpy.vectorize(F)
result = [do_something(x) for x in list if list]
image = plt.imread(image)
less.append(x)
parts, rest = divmod(len(lst), n)
t.append(main_list[i])
final.show()
minm = np.insert(minm, 0, i)
arr[arr < 0] = 0
draw = ImageDraw.Draw(img)
ax = fig.add_subplot(1, 2, 1)
print(sorted(Counter(d).elements()))
my_func(1, 2)
df.iloc[5:8, (2)] = np.nan
a[:, (0)] * c0 + a[:, (1)] * c1 + a[:, (2)] * c2
vec_lda = lda[vec_bow]
bottom_right = true_points.max(axis=0)
df_test.groupby(group_hours).apply(insert_missing_hours).reset_index(drop=1)
[[]]
print(lines)
model.fit(Xtrain, Ytrain)
[] == False
numbers = [int(n) for n in line.split()]
image_data = cPickle.loads(str(s))
zlib.decompress(base64.b64decode(_))
print(eq2.eq_run)
opener = urllib.request.build_opener(proxy_support)
id = Column(Integer(), primary_key=True)
q_in = multiprocessing.Queue(1)
markers = []
deletedirs[:]
d = fd.read()
xl.Visible = 1
bins = NP.array([0.0, 20.0, 50.0, 75.0])
colnames = [i[0] for i in cursor.description]
df
rmtags = soup.findAll(tag)
print(i, first_month(i))
state = models.CharField(max_length=50, blank=True)
self.frame.Iconize(False)
cls._metadata_value = get_class_metadata(cls)
f2(X)
area_hist = ((bin_edges[1:] - bin_edges[:-1]) * counts).sum()
sum += float(e)
requests.old_post(url, data, json, kwargs)
l = math.floor(math.log10(abs(x)))
indices[j] = indices[j - 1] + 1
out = np.zeros(mask.shape, dtype=int)
smtp_conn.set_debuglevel(True)
pid = os.fork()
print(option_expiration(datetime.today()))
ax = fig.add_subplot(111)
app.queue.put(request)
pylab.ion()
app.debug = True
False
gouda = Cheese()
regr = linear_model.LinearRegression()
input_header = next(reader)
self.canvas = Canvas(frame, width=900, height=900)
False
result = json.parse(data)
df.update(df_large)
b[0]
player = operator.itemgetter(0)
win.show()
res(environ, start_response)
list(izip_short(b, a))
removed_indices.sort()
pyversion
get_keys(v, target)
d = datetime.datetime(2010, 12, 25, 18, 25)
dingo
df = {}
count(dict_test)
line[1] = line[1][:6]
int(s)
user = models.OneToOneField(User, on_delete=models.CASCADE)
init = tf.initialize_all_variables()
divide(arr[i], depth + 1, m)
asyncore.loop(count=1)
type(-maxint - 1)
id(lst)
self.sck.connect(url)
some_other()
set(main_array) & set(second_array)
x = x ^ y
em_width = view.em_width()
objects = MyModel.all().fetch(1000)
binary_data = w.readframes(w.getnframes())
txtcurl = StringIO.StringIO()
c = a + b
index.append(bisect.bisect(b, item))
siz = (p2 - 1) / 2
a, b = 1, 1
print(perm_list)
n = c_int(n)
plot1 = plt.subplot(111)
option.append((dept, number))
self.dictionary = {}
net.addModule(bias)
150.17
print(fib(1, 0, 10))
errfunc = lambda p, x, y: y - fitfunc(p, x)
print(df.describe())
view_func(request, *view_args, **view_kwargs)
args = ()
user = UniversityDetails.objects.get(email=email)
ar = np.array([0.0, 0.0, 0.0])
encoded_chars.append(encoded_c)
item.setFont(font)
sum = 0
ax.axis(ymin=-1, ymax=2)
tripled + squared
kernel_r = np.array([[0] + [1] * ksize], dtype=np.int16)
self.master.destroy()
sim2.run(configFactory.ConfigForSim2())
X = df.values[:, ([0])]
client = paramiko.SSHClient()
admin.site.unregister(User)
sent_at = models.DateTimeField(auto_now_add=True)
numpy.__version__
ws.isspace()
a = np.arange(2, 22).reshape(4, 5)
print(word, item)
rows[10:40, 10:40] = [0, 255, 255, 255]
x12, x22 = np.meshgrid(A[1:, (0)], B[1:, (0)])
y = []
diffs.append(nextone - current)
self.author_name == other.author_name and self.title == other.title
listing = os.listdir(path)
dictionary = {k: as_row(v) for k, v in list(obj.items())}
text
qs = User.objects.filter(email=email)
counts = g.transform(lambda x: len(x.unique()))
print(rng.random_long())
self.positions.insert(0, self.latest)
self.master.columnconfigure(c, weight=1)
cb.locator = tick_locator
float_image = tf.image.per_image_withening(reshaped_image)
r = np.roll(a, -i, axis=1)
sort_idx = np.argsort(reference)
print(tn.read_eager())
outer_data = StringField()
self.f
before = this_array[prev_i] if prev_i != -1 else this_array[next_i]
prettify(main_dict)
trans.kill()
value[:(elen - tlen) // 2] + elidetxt + value[-(elen - tlen) // 2:]
kernel_base = np.ones(shape=5)
rootLogger.addHandler(consoleHandler)
file_path = os.path.join(path, filename)
int(hex(200 - (1 << 16))[-2:], 16)
teardown_func(*args, **kwargs)
df_ret
query = gdata.spreadsheet.service.CellQuery()
date_today = datetime.datetime.today()
l = list(l)
print(u, v)
hash(self.data)
signal.signal(signal.SIGINT, signal.SIG_DFL)
self.file
workers = [worker(queue) for _ in range(MAX)]
(datetime.datetime.min + obj).time().isoformat()
getattr(conf, self.name)
print(np.transpose(np.matrix(data)).shape)
server.stop()
value = self[key] = type(self)()
tree = ET.parse(StringIO(DATA))
a = np.array([-1, -1, 1, 1, 1, 1, 1, -1, -1, -1, 1, 1, -1, -1, -1, -1])
M[i] += N[j]
Exception.__init__(self)
print(data)
key, value = line.split()
name, email, phone_numbers = unpack_three(*user_record)
processed_data
cs = pd.concat([cs, same_grp], axis=1)
df = df.reset_index(drop=True)
boundaries[counts == 9] = 0
print(args)
to_zone = tz.tzlocal()
f, a = plt.subplots(2, 1, figsize=[8, 10])
parser.setContentHandler(handler)
result
first_match(nouns, tables)
elements = []
result = MagicMock.__call__(self, *args, **kwargs)
print(simplejson.dumps(songs_as_dict))
f.seek(0, os.SEEK_SET)
partition_binary(partition(X, rank), my_relation)
req = urllib.request.Request(url, post, headers)
match = matcher.find_longest_match(0, len(matcher.a), 0, len(matcher.b))
client_socket.send(fname)
cmp(a.foo, b.foo) or cmp(b.bar, a.bar)
x()
f(i, 20)
fizzbuzz1(20)
current_level = current_level[part]
[line_processor(line) for line in lines]
dis.dis(b[2])
p[0].set_data(xn, yn)
l = Checkbutton(root, text=users[x][0], variable=users[x])
obj = self.wref()
self._data = data
d2 = {value: key for key in d1 for value in d1[key]}
disk_basedir = os.path.dirname(os.path.dirname(pytz.__file__))
keyname
funcs.append(lambda : x)
aa.indices[aa.indptr[1]:aa.indptr[2]]
self.rules[0].link_extractor.allow_domains.remove(hostname)
avg_cor = rollingcor.dropna().to_frame().apply(tril_sum) / ((n ** 2 - n) / 2)
m[i][j] = m1[i][j] * m2[i][j]
user = User.objects.get(username__exact=self.username)
rfc2109 = False
name = models.CharField(max_length=50)
5 > x > 1
print(get_res(Fruits))
typed_text[-1].append(keyname(event.key))
images[idx]
np.percentile(S, 100)
print(json.dumps(r.json(), indent=1))
offset = [1, 0, 0]
True
Variance(X + z)
seen, result = set(), []
records = Entrez.read(handle)
cv2.watershed(cv2.cvtColor(img, cv2.COLOR_GRAY2BGR), lbl)
log = logging.getLogger()
pytz.utc.normalize(pdtnow2)
app = Flask(__name__)
jsonpickle.decode(jsonpickle.encode(Goal()))
response
print(element)
self.layout.addWidget(self.button)
okay = [0, 1, 1, 0]
wid = termf.winfo_id()
[root.val] + argmax(print_path(root.right), print_path(root.left))
myObj = {}
seq.append(name)
numloss = 0
t.start()
PyObject * pyname
value = request.GET.get(key)
print(astr.translate(deleter).split())
b.T
pyautogui.moveTo(100, 150)
cbar.locator = MaxNLocator(nbins=6)
d1 = dt.now()
df
row[0]
sorted_strings(L)
print(msg.Attachments.Item(item + 1).Filename)
cpplib.call_callback(callback)
deletesys.path[0]
pC[1] = 100
seindex += 1
ax2 = fig.add_subplot(gs[0, 1], sharex=ax1, sharey=ax1)
out[i] = [row[j] for j in range(len(columns))]
print(word)
sys.settrace(self)
items = list(od.items())
count += f(v, i + 1, S - v[i])
f = lambda *args, **kwds: self.fn(cls, *args, **kwds)
d2 = D.mean(axis=0)
tmp += nhat[i, k] * m[j, k]
ret_val = np.zeros((arr.shape[0], maxlen))
cur = conn.cursor()
u = random.uniform(x[0], x[-1])
slab = parts[1]
tuple((m, m) for m in calendar.month_abbr[1:])
file = BytesIO(data.read())
now()
html = urlopen(url).read()
d[key] = x, newy, z
derivative = np.dot(2, np.dot(feature, errors))
fig = plt.figure(j)
handler.setLevel(loglevel)
setupcon.setup_console()
queryset = queryset.order_by(Lower(ordering[1:])).reverse()
line = p.stdout.readline()
seq_pow2(16)
f.a()
new_dict[key] = value[key]
0
rad = (atom_shape[0] - 1) / 2
lock = multiprocessing.Manager().Lock()
user2 = tokens[2]
self.arg1 = arg1
adjusted_dom = dom + first_day.weekday()
items[0]
start_date = start_date.replace(hour=0, minute=0, second=0, microsecond=0)
NTP_DELTA = 2208988800
the_next_line_of_code()
new_dict = {}
big_nda = numpy.arange(10000).reshape(100, 100) > 5000
print(tag)
hash_string
m = matrix[0].copy()
id = np.where(fdata[1] == fdata[1].max())[0][0]
app = wx.App(True)
offsets = np.cumsum(histogram[:-1])
output = [(dct[i] if i in dct else i) for i in text.split()]
self.text
comp = compiler.SQLCompiler(dialect, statement)
self.roots = [et.parse(f).getroot() for f in filenames]
the_page = response.read()
matches[0]
end = datetime.now()
results = dict.fromkeys(inputs)
ini_path = os.path.join(base_dir, some_subdir, some_file)
anyFunc(*args, **kwargs)
True
r.insert(0, i)
random_list = random.sample(list(genes_dict.items()), int(length))
self.assertEqual(widget_in.size, expected_tuple)
install(darwin)
False
datetime.date(2008, 11, 27), datetime.date(2008, 12, 25), datetime.date
result = []
RNA_integers = []
keyword.kwlist
Z.append([i, j, float(len(subtree[n])), len(z)])
list1 = [(list1[i] * list2[i]) for i in range(len(list1))]
out.append((key, elems, word))
opener = urllib.request.build_opener(proxy_support, urllib.request.HTTPHandler(debuglevel=1))
shape2, loc2, scale2 = rv2.dist._parse_args(*rv2.args, **rv2.kwds)
ax = plt.subplot(10, 10, i)
self.serversocket.listen(5)
x_coords = x[..., (np.newaxis)] * size + base
freq2char[freq].add(char)
text = item.text
result = cur.fetchone()
word_set = set(list_of_words)
Bar(income_df).show()
float.__add__(1.22, b)
p.wait()
print(model.summary())
inst.__init__(*coltypes)
axs[0, 0].imshow(im)
plt.plot(x - 1, y)
crc1 == crc2
json.loads(*args, **kwargs)
neighbors.append((rr, cc))
ctx.eval(js)
root = Tree()
thickness = 0.5 * np.abs(np.sin(x) * np.cos(x))
inds = np.where(np.isnan(a))
xi = np.linspace(min(x), max(x))
df
False
pp.imshow(detected_peaks)
heroes = set()
process([line for line in tmp_lines])
foo(2)
print(Add.make_args(expr))
list_of_tuples.append((x, y))
matrices[:, (1), (1)] = c
end = numpy.array([2, 10, 9], numpy.int16)
dic1.keys() == dic2.keys()
event.canvas.draw()
PDF = PDFFileReader(source)
scipy.io.numpyio.fwrite(fd, data.size, data)
position = position[:-1]
data = self.cleaned_data
print(result.message)
f = Foo(m=5)
()()
os_encoding = locale.getpreferredencoding()
a = int(yourstring)
rest = df[10:]
asyncio.set_event_loop(self.loop)
self.prediction
plt.plot(x_axis, y_axis)
[[x] for x in a]
tf_bias = tf.Variable(tf.zeros([B]))
Fc = 40
p = itertools.combinations(data, i)
df = pandas.DataFrame(formula)
self.ses = requests.session()
input_dim = X_train.shape[2]
x * x
df = pd.DataFrame(1, index=[0], columns=mi)
self.h
opener = urllib.request.build_opener(proxy_support)
info = {path: filename, name: path.basename(filename)}
a.real *= factarr
html = _.read()
b = a
[(x + sx, y + sy) for sx, sy in zip(dx, dy)]
cur = conn.cur()
a = np.array(x)
dims = X.max(axis=0) + 1
parser = argparse.ArgumentParser()
[-0.66666667, -1.0, -1.0],
CallMe().variable()
math.sqrt(sum(diff * diff))
self.wfile.write(self.t1.show())
norm = A.shape[1] - 1.0
groups = match.groups()
[0] * 0
plt.hist(mix, bins=20)
credentials = storage.get()
plotgauss2(histdist[1])
pprint.pprint(data1)
p.daemon = True
print(list(bookmark_collection.keys()))
root_path = os.path.abspath(os.path.split(__file__)[0])
a[:k] = np.random.randn(k)
next(self)
cnt[c] += 1
c.some.method(x=1, y=2)
new.shape
task_1 = a_long_process.delay(x, y)
r, c = np.triu_indices_from(B.T)
saver.save(sess, checkpoint.model_checkpoint_path)
beta = np.array([0, 1.0], dtype=np.float64)
Image(filename=fn)
curses.echo()
axis.set_major_formatter(formatter)
numbers = []
recall = np.linspace(0.0, 1.0, num=42)
the_method_in_modeladmin.allow_tags = True
cls.getMe()
tc = tender_data.values[:, 1:5]
tree = random(n)
vals[i] += abs(np.dot(u, v))
data = urllib.request.urlopen(target_url)
hashlib.md5(stdout).hexdigest()
self.cleaned_data
a, b, c, d, e = l
new_nums = []
block_end_byte = f.tell()
fromstring_element = etree.fromstring(xml_str)
vars(x)
plt.scatter(t.date.dt.to_pydatetime(), t.sample_data)
FORMAT = pyaudio.paInt16
iterator_mergesort((next(iterator) for _ in range(size / 2)), size / 2),
input_thread.start()
s.union([o])
d = d[p]
args = parser().parse_args()
self.add(row, col, val)
loop.create_task(receive_log())
cet_eur = pacific.astimezone(cet)
True
resp
g = lambda x: 2 * x
li = [s[i:i + n] for i in range(len(s) - n + 1)]
social_data = UserSocialAuth.get_social_auth_for_user(request.user)
im = Image.open(infile)
ix, iy = np.argwhere((Ax == Bxmin) & (Ay == Bymin))[0]
dt = date(2008, 11, 10)
result = [x for x in result if x not in string.whitespace]
dirname = os.path.normpath(dirname)
raise KeyError(key)
print(s1.value_counts(sort=False))
net.layers
Tops1 = [1156, 1250, 1156, 1187, 1187, 1187, 1156, 1156]
res
cr.fill()
application = linkedin.LinkedInApplication(authentication)
p1 = interpolate.PiecewisePolynomial(x1, y1[:, (np.newaxis)])
bool(0.0)
print(sample1.count(True))
mapper(Player, players_table)
i += 1
a.flags.owndata
frame = Frame(root, bd=2, relief=SUNKEN)
prevnode.left == node.left
print(e.pgerror)
print(plusOne(y[:]), y)
parts.reverse()
print(p)
norm_factor = np.linalg.det(norm_factor)
tb.deactivate()
f = plt.figure()
endif
imp.fit(train)
index += 1
list2 = [1, 0, 0, 0, 0, 0]
fuzzeBinSearch(L[:mid], x)
self.x = x
events = []
self.cache[key]
result = self.queue.get()
l = []
pool.release(connection)
True
cache[:] = [v]
c = np.bitwise_xor(a, b)
seen = set(y)
power = int(math.log(num, base) + 0.5)
a = result
x[()]
count += 1
print(b)
lo, hi = min(x, lo), max(x, hi)
s.commit()
cots = aliased(TextString)
cits = aliased(TextString)
self.__dict__ = db_to_frames_dict(engine)
b = splinter.Browser()
self.ax.set_ylim(min(newy), max(newy))
t = buf.read(1048576)
coord = list(product(list(range(8)), list(range(8))))
lst = list(t)
VENUS = Body(mass=4.869e+24, radius=6051800.0)
my_data = NP.random.random_integers(0, 9, 16).reshape(4, 4)
contents = f.read()
i += 1
second_list = []
estimated_mu = np.log(scale)
unigrams[token] += 1
n = len(list)
request.GET.update(options)
redistributed_points = []
y = np.trunc(x)
data = urllib.request.urlopen(url).read()
w = excel.Workbooks.Open(f)
(2 < arr) & (arr < 6)
im1 = cam1.getImage()
codeproc = subprocess.Popen(code, stdout=subprocess.PIPE)
x = [1] + [1]
foo = Foo()
sendcounter += 1
ctxt.xpathFreeContext()
tf.getnames()
app.debug = True
ax = plt.subplot(1, 1, 1)
main()
data += self.request.recv()
self.Fit()
f.truncate()
cmd = nil
raise_exception()
name = models.CharField(max_length=255)
print((k, len(v)))
data.shape
x = HtmlXPathSelector(response)
()
self.treestore = gtk.TreeStore(str)
pprint(res)
files_in_dir = os.listdir(path_to_dir)
subprocess.check_output(arglist)
h.update(chunk)
ax.patches.pop(0)
results = [r[1] for r in results]
stdscr.move(y, x)
i += 1
cursor = connection.cursor()
df1
sys.path.append(os.path.abspath(dir_above_top_level))
da = dict(zip(listanum, lista))
diff = np.sum((points - median) ** 2, axis=-1)
assert isinstance(d, dict) and len(d) == 1
i = True
l = len(string)
_post_import_hooks[name].append(func)
row_id,
df = pandas.DataFrame(mydata)
text = pystring.lower(pytext)
self.dependency = dependency
sendSock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, True)
self._y
self.y = y
self.data.seek(offset)
plt.plot(x, f2(x))
ax2.bar(list(range(l)), One)
atom = tables.Atom.from_dtype(x.dtype)
l2 = [1, 2]
X = [random.randint(0, 10) for _ in range(10 ** 7)]
all(map(same_structure, a, b))
app.add_window(newWindow)
csv_file.seek(0)
d[sub[0]] = sub
write_output([process.stdout, process.stderr], outmap)
today - DD
new_bitmap = wx.EmptyBitmap(size, size)
f.seek(savepos)
matches = [val for key, val in d.items() if key.startswith(partial)]
yrat = height / float(MAXSIZEY)
loop = asyncio.get_event_loop()
counts[i] = len([x for x in list(vals.values()) if x == i])
root = int(math.ceil(start ** 0.5))
result = [[]]
c = Field()
_GetShortPathNameW.restype = wintypes.DWORD
False
r = random.random()
df = pd.DataFrame(data)
h = hmac.new(key, msg, hashlib.sha1).digest()
self.assertEqual(forty_two, 42)
global_randstate.seed(42)
mod = imp.new_module(name)
set(myprocess(pattern, text))
axis = [i for i in range(ndarray.ndim)][axis]
print(key, dict[key])
print(column.name)
time.sleep(1)
self.arg1 = arg1
action(*actionargs)
B = np.random.rand(N, D, R)
self.__name__ = name
r[r > 0]
count += 1
domain = request.get_host()
ax2 = plt.subplot(122)
pl.show()
cov.erase()
[] > -1
trans.commit()
g = 1 / (1 + exp(c * (b - t)))
print(par1)
self.sample.save(self.name, django_file, False)
cur_num += 1
True
print(self.server.arg2)
res = holt_predict(Y_observed, epoch_in, fcast_days)
hi = len(a)
self.d = {}
data = Column(String)
print(intersection)
self.Inc()
first, itertools.chain([first], iterable)
df
self.queue = set()
outertype = ctypes.ARRAY(ctypes.POINTER(ctypes.c_float), 2)
nextmonthdate = x.replace(year=x.year + 1, month=1)
False
a.__setitem__(y, a[x][0])
j, i = np.unravel_index(k, image_temp.shape)
plt.plot(series.index, series.values)
abbrev = abbrev.lower()
x0 = numpy.array([0.0, 0.0])
a[i] = i
x = np.linspace(0, 1, 100)
mult = lambda x_y: x_y[0] * x_y[1]
self.request.user = Mock()
fig, axs = plt.subplots(2)
self.meth = meth
y = data[:, (1)]
lines_needed = zip(tri, (tri[1], tri[2], tri[0]))
print(x)
deci_x = Decimal(1)
output = tf.gather(input, [0, 2])
Py_XDECREF(pValue)
pathname = os.path.dirname(file)
style_context = window.get_style_context()
current_item, next_item = the_list[i], the_list[i + 1]
print(b)
mat.numRows()
self.data = []
matches = input == indices[:, (np.newaxis)]
deleteArtofWarCounter[word]
N = int(sys.argv[1])
i = numpy.arange(len(r)).repeat(r)
print(goodkeys)
user = models.OneToOneField(settings.AUTH_USER_MODEL)
username = User.objects.get(email=username).username
t = np.linspace(0, 1, 5)
template = lookup.get_template(uri)
self.index = 0
console.log(JSON.stringify(chg))
ax[i].imshow(yourimage)
prices = [match.group(1) for match in rx.finditer(teststring)]
self.buf.seek(current_read_fp)
a = np.zeros((new_rows, new_cols))
print(round(root, -int(math.log(eps, 10))))
d = Deleted()
session = requests.Session()
self.layout.addWidget(self.btn_cancel)
known_good.add((predecessor, successor))
xs = [1, 2, 5, 6]
sess.run(tf.global_variables_initializer())
Foo()[42:81:7]
remote_ip = x_real_ip or self.request.remote_ip
smbus_read_byte.restype = c_int
assert composite_actuator.get_position() == (0, 0)
n = [bool(i) for i in n]
b = str(num)
tremove(L, M)
tries += 1
print(raw_string_with_quotes)
r = NP.random.randint(0, 10, 4)
g = np.random.rand(m)
soup = BeautifulSoup(source)
df.index.month
reordered = []
data = Column(String)
idx = df_ctrl.index.intersection(df_test.index).sort_values(ascending=False)
subseq_id_to_intervals_dict,
print(msg)
tmpdir
value = vars()[varname]
result = re.match(identifier, test)
self.a = A()
metadata = MetaData()
evals, evecs = np.linalg.eig(C)
self.password = password
country = models.CharField(max_length=128)
x = list(this_will_work())
cosang, sinang = cos(theta), sin(theta)
b_hidden = tf.Variable(tf.zeros([HIDDEN_NODES]))
a.pop(5)
menu.append(item_joke)
signers = smime_object.get0_signers(X509.X509_Stack())
grand = os.path.join(agrandie, infile)
val[0]
reshape = pd.concat(tmp, axis=1)
hyp = (h.split() for h in hypfin)
func.code
file.write(xm)
outputter.write(s, len(s))
cropped = img[y1:y2, x1:x2]
[rep_len(seq) for seq in seq_l]
filename = filename[:-1]
nsecs = dt.minute * 60 + dt.second + dt.microsecond * 1e-06
PREPEND_WWW = False
activity_date = db.DateProperty()
plt.boxplot(X)
base_pic.save(file=stream_out)
mmc.serial.baudrate = baudrate
qPlg = QPolygonF()
print(data)
allocationList[numBytes] = allocationList.get(numBytes, 0) + 1
newVec = CountVectorizer(vocabulary=vec.vocabulary_)
other_terms = find_terms(words[1:], max_words_per_term)
f.write(chunk)
cb = plt.colorbar(im, cax=cax)
some_list = [True, False, True, False, False]
self._sessions = sessionmaker(bind=self._conn)
topkeys = set(sum([list(dic.keys()) for dic in dicts], []))
plt.figure()
instance = MyClass()
print(a[:2, :2])
config = ConfigParser.ConfigParser()
fig = plt.figure(figsize=(12, 6))
a.get(0)
initial
r, t = np.meshgrid(r, t)
net.addConnection(FullConnection(hidden1, output))
len_ab = len(a) + len(b)
X - a
birthplace = models.ForeignKey(Birthplace)
self.a_fun = lambda : 1
a * x ** 2 + self.b
p = Point(x=11, y=22)
email.send()
compare(key1, key2)
randomRange = list(range(len(listOfItems)))
result = self.process(path)
self.id == other.id
a == 0
print(response_two.content)
0
img.save(outfilename)
err2 = r2 - r4
True
subset = data[(col1 == val1) & (col2 == val2)]
data
file.seek(sequence_end, 0)
p = Person()
np.subtract.outer(x, x)[np.tril_indices(x.shape[0], k=-1)]
cache = {}
s1.commit()
intersect_with_key(fs1, fs2, key=str.lower)
cxns.remove(node)
sock.bind((dev_id,))
data.astype(int16)
self.initUI()
y = np.arange(100)
mx.mask = ma.nomask
True
response = {}
self.func = func
_R = np.random.uniform(-1, 1, n * (n - 1) / 2)
Point.ORIGIN = Point()
os.system(osCommandString)
data = np.random.normal(0, 1, (10, 10))
plt.spy(M)
m.sort()
fieldnames = [f[0] for f in c.description]
Function(lambda x: self(x) / other(x))
0
Base.metadata.drop_all(engine)
c = C()
mask = binary_matrix[idx[:, (0)], idx[:, (1)]] == 1
x + y
dt = naive_dt.replace(tzinfo=FixedOffset(offset))
_chord = self.Chord
Thread(target=foo)
hash(self.args)
i = random.randint(1, 5)
self.initial_value = 1
L2 = [1, 2]
buttons.pop(2)
Done
print(next_friday)
self.setLayout(layout)
f.close()
result = []
window.refresh()
barbarfoobarmoopmoop
True
h, w = im_th.shape[:2]
response.url = req.url
uniqList = list({x.tag: x for x in myList}.values())
mlo, mhi = map.min(), map.max()
self.ctr += 1
print(len(a) - index - 1)
numpy.array(A)[2] = 2
print(key)
a = math.radians(angle)
name = Column(String(50))
application.pc.connect()
bool(set(fruit_dict1).intersection(fruits))
printable = set(string.printable)
self.wfile.write(result)
plt.show()
value = event.widget.get()
value
arr_x = arr[:, :, (np.newaxis), (np.newaxis), :]
browser = webdriver.Firefox(firefox_binary=binary, proxy=proxy)
my_diff = np.diff(my_array) > 1
self._n = 0
self.buf.write(*args, **kwargs)
nextlevel.append(n.left)
0 * F - 10 * C
outdatav[i] = indatav[i] * 2.0
browser.close()
push((2 ** 2, 2, 2))
task_data = input_q.get()
fixed_comments.append(fixed_text)
cursor.execute(sql)
line.set_color(colorArray[i])
sys.argv = sys._argv
mask = np.sign(X)
prod = tree.productions()
self.stackVals.append(listTuple)
raise
result = _get_date(region)
print(is_new_style(int))
model = Waypoint
sys.getsizeof(foo1)
print(a)
bts = l[x][:1024]
print(list(find_with_dupe(l)))
print(name)
dic = dict.fromkeys(lis, [])
width = horizontal[i + 1][1] - h[1]
api = twitter_api()
b.build_scripts
output
fmt.format(self)
args = vars(parser.parse_args())
saver.restore(sess, path.model_checkpoint_path)
self.foo = foo
lists = [[x[0] for x in tup] for tup in lists]
box = cv2.boundingRect(curve)
verify(good_cert, sig, content, digest)
newip = str(request.remote_addr)
subprocess_call = Popen([call], shell=True, stdout=PIPE, stderr=PIPE)
c = numpy.random.random((1000, 1000)).astype(numpy.float96)
print(product)
author = models.ForeingKey(Author, required=True)
rng.freqstr
ax.broken_barh([(midpoint - 0.01, 0.02)], (perc[5], perc[6] - perc[5]))
object.__setattr__(self, _d, (x, y))
x = y
obj = get_obj()
y = y.flatten()
plt.grid(True)
self._foo
print(z)
self.subdomains = domain_parts[:-1]
_decorator
self.file_size
artists.append(ax.add_artist(ab))
Session = scoped_session(sessionmaker())
t.join()
a.some.__self__
-b.py
_key = list(self.keys())[key]
dd2here.min()
self._ethernet = copy.deepcopy(pbuffer)
sums.append(a * b)
[(u.value, u.meta) for u in set([a, c, e]).intersection(set([b, d, f]))]
status = MPI.Status()
reactor.callLater(1, self.sendHello)
print(repr(L))
print(asking)
temp = np.cumsum(np.random.random(num) - 0.5)
(ser > 0).mean()
s = a.shape
rows[::int(1 / proportion)]
my_classification = sess.run(tf.argmax(y, 1), feed_dict={x: [images[0]]})
func(self, *(args + parameters), **kw)
range_prod(lo, mid) * range_prod(mid + 1, hi)
t2 = np.linspace(1e-10, 1e-05, 1000000)
C[::2, :] = A
print(f.__class__)
axes = np.arange(N)
t[0][0] = 5
sys.stdin = os.fdopen(fd)
keys[1], keys[2] = keys[2], keys[1]
cppcode.init(address, port)
self._data = []
num = num / base
copen.errcheck = errcheck
p.close()
t = ET.parse(sio(raw_text))
df
x[..., (False)]
thresh = cv2.adaptiveThreshold(gray, 255, 1, 1, 11, 2)
code = marshal.load(file)
match = True
filename = sys.argv[1]
self.wheel.delete()
df2,
passman = urllib.request.HTTPPasswordMgrWithDefaultRealm()
dt_now = datetime.now()
recurse(a, b, rest)
d.foo
self.canvas.SetMinSize((self.canvas.w, self.canvas.h))
x + x
gray = cv.cvtColor(image, cv.COLOR_BGR2GRAY)
init = tf.initialize_all_variables()
start_time = time.time()
1
label_set = set([category[0] for category in in_list])
sys.getwindowsversion()
df
next(it)
self.fingerprints.add(fp)
xes.append(x)
labels = vectorizer.get_feature_names()
cess_sents = cess.tagged_sents()
small_range = list(range(10 ** 5))
path = request.get_full_path()
print(firstMatch.start())
metadata.reflect(bind=db)
self._write(file, self._root, encoding, {})
self._taskqueue = Queue.Queue()
print(list1, list2, p)
raise AppropriateError
moo = np.zeros((size, size), dtype=np.float)
cls
local_port = serv.socket.getsockname()[1]
dumps(js)
filename, file_ext = splitext(basename(disassembled.path))
y = np.arange(10)
timeit.timeit(lambda : var1 == var2, number=10 ** 4)
file.seek(0)
plt.show()
serialized_str = base64.b64encode(pickle.dumps(mydict))
r[4::2] = [False] * len(r[4::2])
st[ind:] * int(st[:ind])
icondata = base64.b64decode(icon)
__instance = []
age = StringField()
cv2.waitKey(0)
get_user_model().objects.filter(id=user.id)
print(df)
phone = serializers.PrimaryKeyRelatedField(many=True, read_only=True)
mask = cv2.morphologyEx(img_bw, cv2.MORPH_CLOSE, se1)
pencolor(colour)
print(df)
some_list[0] = False
ax1 = subplot(211)
list1 = list1[:max_size]
cursor = dbapi_con.cursor()
d[col] = line[-1]
num2word.to_card(1555)
x = {i: set(range(1, 7)) for i in range(1, 7)}
channel.shutdown_write()
make_plot()
self.myobj = origobj
driver = webdriver.Firefox(capabilities=d)
DEBUG = False
r = s.post(url, data=payload)
crnt[k] = {}
classification = sess.run(tf.argmax(y, 1), feed_dict={x: [img]})
jsonify(**course)
id = Column(Integer, primary_key=True)
a = RecursiveDict()
values.append(value)
dis.dis(g)
a[0] = 1
file.close()
print(line.project(p))
peer = serial.Serial()
dis.dis(myFunc)
accumulationList
it = iter(s)
self.clear()
resp = opener.open(url)
loop = asyncio.get_event_loop()
exit(2)
x, y, z
zf.close()
dict_x = collections.defaultdict(list)
profile = request.user.get_profile()
new_data2 = np.array(data)
dct[x]
work.append(nope)
context = etree.iterparse(reader, events=events)
list_of_list = []
someblock = d.popleft()
last_number = 0
average = sum_of_grades / len(my_list)
self.cond.notify()
self.start = start
lines = fin.readlines()
SE_Lat = [Lat[x] for x, y in enumerate(Lon) if y == min(Lon)]
df
allocationList[numBytes] = allocationList.get(numBytes, 0) + 1
coords[2] += 1
ratio = 2 * (value - minimum) / (maximum - minimum)
t1.start()
page = f.read()
iter_mystate = iter(getstate, object())
getattr(obj, proxy.value_attr)
0
pprint.pprint(cluster_facts)
s.append(string[i:i + 1])
PREPEND_WWW = True
self.queue = queue
dims = np.maximum(array_2d.max(0), row) + 1
mock_redis_set.side_effect = set
sample2 = []
wk = dt.isocalendar()[1]
confint.append([np.nan, np.nan])
z = theano.tensor.zeros((idx.shape[0], n_val))
d[tup[0]] += tup[1],
sorted_idx = np.lexsort(Ar.T)
True
print(cleaned_email_list)
median()
print(output)
column = np.asarray(a.getcol(2).todense()).reshape(-1)
tree.pop(nodes[0])
output_ws.write(rindex, cindex, input_cell.value, red_background)
next(b)
x1 = np.random.randn(100)
combobox = QtGui.QComboBox()
name = name.lower()
row = np.array([[0.1, 0.2]])
Serial.flush()
ManufacturerId = wo
giter = groupby(sorted(L, key=keyfunc), keyfunc)
ds = [vec_distance(p1, p2) for p1, p2 in it.combinations(s, r=2)]
list1 = [1, 0, 1, 0, 0, 0]
func()
self.cbar.set_clim(self.zmin, self.zmax)
df.new_group.iat[n] = df.new_group.iat[n - 1] + 1
result = eval(s)
csvfile = StringIO.StringIO()
jsonify(dict(data=[no1, no2]))
obj = getattr(module, name)
loads(j, object_hook=as_python_object)
request.url
a[0]
ax4 = plt.axes([left, 0.1, width, 0.09], sharex=ax2)
r = requests.post(url, files=files)
print(type(b))
hh, locx, locy = scipy.histogram2d(xdat, ydat, range=xyrange, bins=bins)
ConvexHull = cv2.convexHull(c)
data = np.random.randint(10, size=(5, 10))
self.add(node1, node2)
inline = p.stdout.readline()
df2 = pd.DataFrame()
sns.set()
newarr, revchoice = tmp[:cut], tmp[cut:]
y.cumsum(axis=0, out=y)
self.level += 1
lines.distance(point).min()
pipe = Popen(path, stdout=PIPE)
print(row)
(x < 8) & (x > 2)
rest = list(set(a) - set(c))
old_window[0].focus(0)
n = n - weight
window.show()
im = cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY)
full = str.maketrans(west, east)
title.translate(title_unicode_trans)
demo(root)
m.group(0).capitalize()
seen.add(f)
msg = email.message_from_string(data[0][1])
data = zip_file.read(f)
point_tree = spatial.cKDTree(points)
b.append(x)
form = BarForm
total += y
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
x = np.hstack((np.ones((n, 1)), np.matrix(x)))
s.strip(string.punctuation)
s
new_list = []
indptr = np.concatenate(([0], np.cumsum(label_features)))
processHeader(next(f))
pydoc.pager(text)
c += D.min()
s[4:-4]
y = func(x)
simplest_fraction_in_interval(x - e, x + e)
V = np.random.rand(n, p)
print(result)
on_draw()
args = [iter(iterable)] * n
next10k = list(islice(f, 10000))
df[~df.eq(df.max(axis=1), axis=0)] = -1
program = sys.argv[1]
pylab.show()
xs = np.random.randn(100, 5)
test_set = [flatten_image(matrix_image(image)) for image in test_images]
print(df)
axcb = fig.colorbar(lc)
colors = dict([(k, (random(), random(), random())) for k in list(data.keys())])
bind_layers(PPPoED, PPPoE_Tag, type=1)
df1 = df1.swaplevel(0, 1, axis=1).sort_index(axis=1)
x = a[1]
len(values)
kidshair[mypath]
df
self.name = name
ax1 = df.cumsum().plot()
my_list = []
X = np.matrix([[0, 1, 4, 0]]).T
b = random.random((5, 10, 2))
cargs = [deepcopy(arg) for arg in args]
array_of_strings[0, 0]
groups = collections.defaultdict(list)
pil_im = Image.open(img)
x += 1
YSIZE = 2
total_seconds = int(turnaround.total_seconds())
cimg = np.zeros_like(img)
b2 = np.all(frame > PSigma2, axis=-1)
out = groupCoords[(col0_mask & col1_mask).any(1)]
plt.scatter(X, Y, s=data)
S = np.random.randn(N, N)
a = np.zeroes(shape=(5, 5), dtype=float)
graph = dict((v, list()) for v in list(vertices.keys()))
1 == 1
r = random.normalvariate(a, sigma)
count += 1
i = bisect.bisect_right(a, x)
plt.xticks(x, time)
interpreter.setOut(out)
cursor.execute(sql)
t.join()
pattern.search(s)
print(i)
logging.basicConfig(level=logging.INFO)
p_values = 1 - scipy.special.ndtr(z_scores)
4294967295
points = []
it = re.finditer(regex, s)
time.sleep(0.2)
json.dump(*args, **kwargs)
fig = gcf()
PyErr_SetObject(PyExc_IndexError, indexerr)
ModelMemo = Column(Unicode(255), nullable=True)
pill2kill.set()
n.write(i)
im = ax.matshow(C, cmap=cm.gray_r, norm=LogNorm(vmin=0.01, vmax=1))
cxml2 = xml_string_io2.getvalue()
server_sock.listen(4)
zf.write(path)
self.__fn(*args, **kwargs)
field = self.fields.get(field_name)
f = pyplot.figure()
print(p.primes_dict[i])
{(i ** 2) for i in range(5)}
x = set(range(10))
z = np.zeros_like(x)
a.pop()
M = np.random.randint(2, size=(h * iters, n))
False
axe_x.extend(time_list[np.arange(j + n, j + (time_interval - n))])
self._float_eq(a, b)
curl.setopt(curl.WRITEFUNCTION, response_buffer.write)
prevnl = nextnl
ax.set_xticklabels(xlabels)
[1.0, 1.0, 1.0, 1.0, 1.0, 1.0],
ar[0] = np.arctan2(vect[1], vect[2])
f
y_formatter = matplotlib.ticker.ScalarFormatter(useOffset=False)
c1 = plt.contour(X, Y, abs(np.angle(Z) * 180 / np.pi), levels=levels)
t = threading.Thread(target=process, args=(fname,))
self
print(post.user.email)
stack.append(c)
jv(n, z) + 1j * yv_imcut(n, z)
data_stream = Popen(mycmd, stdout=PIPE)
smallerThan = lambda x, y: [i for i in x if i < y]
frame.append(162)
pip - sync
cub_right.append(points[0])
object.__new__(cls)
df = DataFrame(columns=list(range(10)), index=list(range(10)))
best_without = best_score_for(items, segments[1:], subtotal)
x - 1, y - 1
signal.signal(signal.SIGALRM, got_alarm)
print(r.reason)
slither / slither / impl.py
n = parser.parse_args(extra)
x = copy.copy(y)
request = mechanize.Request(loginURL)
content = val.group(1).strip()
args = parser.parse_args()
indices = [(q * i + min(i, r)) for i in range(n + 1)]
self.meth = meth
x0, y0, x1, y1 = min(X), min(Y), max(X), max(Y)
max_chunk_size = 1000000
os.umask(2)
100
candidates_indexes = [(0) for _ in bases]
mod
self.after(100, lambda angle=angle + 10: self.rotate(angle))
app.processEvents()
deltaY = P2_y - P1_y
df
pl.figure(figsize=(10, 5))
b1.append(lines[0])
dis.dis(g)
self.oldtrace = sys.gettrace()
pop_conn.quit()
records[key] = 0
and_also_this()
self.input_queue = input_queue
data = np.ones(n_samples * n_features)
s = a.argsort()
CyABase(PyObject * obj)
[x for x in tup if x]
df_Quota = df_Quota.append(FinalDataframe)
heapq._heapify_max(listForTree)
self.m = [[(row + col / 10.0) for col in range(4)] for row in range(4)]
out.append((key, elems, i))
host = MYSERVER
len(self._result_cache)
plt.plot(X, Y)
len(self._s)
F0 = F(x0, a, b)
plt.plot(tiempo, senial)
arguments = cgi.FieldStorage()
len(self.list)
data = trends1[0]
mask = np.all(np.abs(r) < 1e-06, axis=1)
data2 = np.ma.zeros((num_rows, num_columns, num_datasets))
column_indices = (X + indices[:-1]).ravel()
db = engine.connect()
parser = etree.XMLParser(remove_blank_text=True)
bit.append(x % 2)
rectangle(res, box, color, 5)
ring = 0
driver = webdriver.Chrome(desired_capabilities=caps)
a = object()
b, g, r, a = image.T
print(update_doc(a))
serializer = TimelineSerializer(queryset, many=True)
df.replace(to_replace=sorted(list(set(letter))), value=sorted(list(set(num))))
page = document.get_page(i)
input = input()
a = os.urandom(64)
data = self._get_bool_data()
ax1 = plt.axes([left, 0.5, width, 0.45])
settings = get_project_settings()
minutes += 1
C = np.dot(np.exp(A - max_A), np.exp(B - max_B))
self.sendata(d)
self.omega_m = omega_m
self.id
box2 = [2, 2]
date = datetime.date(start.year, start.month + j, 1)
mpl.xkcd()
inv_cov = np.linalg.inv(cov * scotts_factor ** 2)
False
matches.append(pattern)
app = App(root)
MyClass.x = x
plt.savefig(plot_file_name)
self.connected = True
f, ax = plt.subplots(1, 1)
ctx.rotate(theta)
takefrom = allix.copy()
print(fp.read())
data = np.random.random((N, 4))
sigma = np.dot(inputs, inputs.T) / inputs.shape[1]
pd.__version__
mail1.config()
a[20:] = [(0) for aa in a[20:]]
ws.fit_to_pages(pages_horz, pages_vert)
print(x)
list.__getitem__(self, index % len(self))
console_client.connect_to_console()
about = About.objects.get(id=1)
p.feed(data)
d = DictConditional(lambda x: x != 0)
l = []
b = collections.OrderedDict.fromkeys([6, 20, 1])
s = []
parser.parse_args()
wait.until(ExpectedConditions.numberOfWindowsToBe(2))
df.Date = pd.to_datetime(df.Date)
random.choice(self.primes[ai:ai + bi])
startindex = 0
c = sum((Counter(**{k: v}) for k, v in lst), Counter())
process_data(piece)
loop = asyncio.get_event_loop()
func
self.X.append(i)
relation = lambda x, y: (x - y) % 4 == 0
attachment = MIMEImage(fp.read(), _subtype=subtype)
id = int(s[1])
xygood = np.array((x[~a.mask], y[~a.mask])).T
a = (ctypes.c_ulong * (len(ba) / 8)).from_buffer(ba)
self._pixmap = QtGui.QPixmap(self.label.pixmap())
shortset.add(longstring[i:i + length_shortstring])
lst[-1]
1
True
mentions = api.mentions_timeline(count=1)
cb.update_ticks()
a[a[k]] = k
list_
self.another_field
dirname = os.path.dirname(name)
bins = pd.cut(df.x, bin_edges, right=False)
s = list(range(100))
x_field = forms.CharField()
raise self._exc_info[1].with_traceback(self._exc_info[2])
interior_id = canvas.create_window(0, 0, window=interior, anchor=NW)
x = np.random.normal(0, 1, 100).cumsum()
myTests.py
p // math.factorial(k)
query = dict(urlparse.parse_qsl(url_parts[4]))
result = Result(5, 6)
rows = iter(table)
platform.processor()
poller = zmq.Poller()
{}
self.inverse = {}
xmax = data.max()
nb = np.where(y > 200)
seen = set()
outer = gridspec.GridSpec(2, 1, height_ratios=[1, 6])
renderPDF.draw(d, p, 1, 1)
d[1][0] = d
[words[n] for n in list_out]
mantissas, binaryExponents = np.frexp(absx)
[sum(values) for values in zip(*items)]
traverse(bfs(g, start_node), process)
lengs = numpy.array([0] + [len(l) for l in polys])
c.fetchall()
viewer.terminate()
res = [f for f in os.listdir(path) if not m.search(f)]
increment()
numbers = list(range(2, 100))
print(line)
0
work.append(nope)
X = np.asanyarray(X)
Y = np.zeros_like(Z)
df
df
N = 20
print(to_case(input_str_lower, case_map))
print(len(list(combs(elts))))
Count_Col = df.shape[1]
nwords = len(wordslist)
p.start()
args = docopt.docopt(__doc__)
lis = []
f.close()
PyEval_InitThreads()
self.cache = {}
a, b, c
items_list = list(Items.objects.all())
imputed = df[mask]
4.56006002426
prevnl = -1
[easy_install]
pypreprocessor.parse()
self.arrays[j][i + shift] = v
session = Session()
self._paths.extend([child] + path for path in child.paths)
out = np.zeros(shape)
pd.Panel(d).to_frame().reset_index()
json.dump(db, fh)
base_file, ext = os.path.splitext(filename)
ipdb.set_trace(context=21)
self.timer = threading.Timer(timeout, timer_callback)
wb = Workbook()
bool(self.outbox)
A[n]
max_idx = np.argmax(l)
pid = os.fork()
self.key
link.parent.insert(index + 1, br)
html_source = driver.page_source
response = urllib.request.urlopen(request, encoded_params)
o.setCallback(foo)
print(b)
print(msg)
SYSTEM_HZ = round(1 / (res.tv_sec + res.tv_nsec / 10.0 ** 9))
getcontext().prec = 6
val = self._get_val_from_obj(obj)
new_a.append(sorted(group))
textwrap.indent
all_chars = (chr(i) for i in range(1114112))
[nosetests]
canvas[start_pt[1]:end_pt[1] + 1, start_pt[0]:end_pt[0] + 1] = 1
logger = logging.getLogger(__name__)
mu2 = 1
cherrypy.server.socket_port = 80
kind1 = params.get(cls._KIND1_PARAM)
melt_second_half = pd.melt(second_half)
df1 = df1.astype(bool)
(sortedLst[index] + sortedLst[index + 1]) / 2.0
a = {}
other_weirder_list = [list(line) for line in first_list]
calendar = defaultdict(list)
y = numpy.outer(numpy.sin(u), numpy.sin(v))
False
conn = adodbapi.connect(connstring)
self.rules[1].link_extractor.allow_domains.remove(hostname)
mx = ma.masked_array(a, mask=(a < -100) | (a > 100))
fig = figure()
newmodule = __import__(key)
print(df.columns)
d = defaultdict(int)
int.__get__
split(bezier_points, len(bezier_points) / desired_multiplicity, axis=0)
array([22, 106, 100])
lens = [len(x) for x in args]
deleterender_window, iren
print(elem.text)
tform = blended_transform_factory(ax.transData, ax.transAxes)
removed_KP.append(item)
gain / denominator
link.next_sibling
d.update(abc)
distance = calculateDistance(2, 4, 6, 8)
kernel.timer = QtCore.QTimer()
slice2 = tuple(slice2)
---a / python / pyspark / daemon.py
{{location}}
reversel
models.py
b = calc_b(a, d1)
self.a1a2_edit.setText(str(product))
hashes = [hash(o) for o in olist]
step = min(step, df.shape[1])
combs = 5165700
x = np.bincount(a, weights=b)
print(inspect.stack()[0][0].f_code.co_name)
photo = deferred(Column(Binary))
sy = arr.shape[1]
self.parent = parent
print(df)
n = sum(divmod(n, 10))
d_sum = {}
USE_L10N = True
trie = make_trie(list(dictionary.keys()))
invf._update(record[name][ftmp], val)
endpos = 0
prevLine = line
print(x)
self.traceback.append(self.col_seq[j - 1])
user_store.complete()
hello()
8, 1, 8, 1
squareroot = math.sqrt(self.start)
tree
self.search_box.send_keys(query)
perms = (permutations(given_word, i) for i in range(4, len(given_word) + 1))
var_a = 2
utc_time = datetime.utcfromtimestamp(epoch_time)
[[array2 for _ in row] for row in array1.tolist()]
not self == other
plt.imshow(spectrum_matrix)
MyFancyNumber(5) + 2
transaction.savepoint(True)
flips += 1
asyncore.loop()
Segments[2]
first_name = models.CharField(max_length=50)
PIPE, stdout = subprocess.PIPE, stderr = subprocess.PIPE, cwd = os.curdir,
fast_real(56.0)
sys.stdout = MyClass()
classifications = []
mylist = cpickle.loads(string_from_file)
a[-mask]
8, 8, 1, 8
os.linesep
ax = subplot(111)
print((tree, nodes[0]))
do_stuff()
Py_INCREF(array_wrapper)
d[k] = d.get(k, 0) + v
xmlOutput += self.dirToXML(os.path.join(directory, item))
fh = logging.FileHandler(logf)
rank
arr.nbytes
dy_cell = max(abs(lattice_vectors[0][1]), abs(lattice_vectors[1][1]))
df
arg = sys.argv.pop(0)
a = numpy.zeros(5)
print((unique_neighbors, neighbor_counts / neighbor_counts.sum() * 100))
i = int(i)
zip(shapes, colors)
the_page = response.read()
[line.rstrip() for line in c if not line.isspace()]
it1 = iter(lis)
b = tf.shape(a)
r, c = np.where((df1 > s).T)
numpy.iinfo(numpy.uint64).max
h.close()
is_sub(B, A)
gg = g.groupby(0)
value
myOutput.close()
R, C = np.triu_indices(arr.shape[0], 1)
chosen_lists.append(stg)
a
fig = pl.figure(1)
f.write(mystruct)
b = [5, 6, 7, 8, 9]
columns = [c.key for c in class_mapper(model.__class__).columns]
b = [4, 5, 6]
item.append(field)
counts = np.bincount(pos)
root = __import__(modulename)
df = df.stack()
logOutput = QTextEdit(parent)
other_fd.write(read_slice)
not relative.startswith(os.pardir + os.sep)
time_shift = argmax(abs(c))
group = parser.add_mutually_exclusive_group()
app = Klein()
clean_array = [element for element in my_array if value_to_remove != element]
ctx.select_font_face(face, cairo.FONT_SLANT_NORMAL, cairo.FONT_WEIGHT_NORMAL)
d = c.CastToDerived(b)
print(result)
print(time.time() - t, end.shape)
self._x = value
np.random.seed(1)
x = np.arange(12, dtype=float)
x = list(range(N))
print(get_ax_size(ax))
o.stop()
a = Object()
print(globalVariable)
kernel.execute(command)
(row + [v] for row in subtable for v in [0, 1])
lock.release()
type.__new__(cls, name, bases, dct)
middle_name = models.CharField(max_length=80, blank=True, null=True)
stdio.StandardIO(FileReader(filename))
deletedf[1]
tag = etree.fromstring(XML, parser)
print(line)
Model.objects.count() == 1
deletechunk[:]
message.getHeader().getField(qfSendingTime)
simplify(abs(exp(I)).expand(complex=True))
null_ptr[5]
combinations = [c for c in itertools.combinations(axis_labels, i)]
curl.setopt(pycurl.WRITEFUNCTION, output.write)
inspect.ismethod(Foo.baz)
title.getparent().remove(title)
all = N.ma.zeros((maxLen,) + dSets[0].shape[1:] + (len(dSets),), dtype=float)
print(i)
monday_my_date = my_date - timedelta(days=dow)
self.z = z
print(f(4))
next_item = resultList[i + 1][0]
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM, 0)
start = a + 1
im /= len(files) * 0.25
suds.client.SoapClient = TestClient
f, args = q.get()
[buildout]
bp = plt.boxplot(data, whis=[5, 95], showfliers=False)
ret == 0
ury = np.flipud(ury)
self.buttonLogin.clicked.connect(self.handleLogin)
connectivity = 4
params = urllib.parse.urlencode(parameters)
print(x)
sequence[9]
rendered_content = response.content
summary_writer.add_summary(image_summary)
Child().parent_prop()
slope, intercept
ans
print(a)
points.set_data(new_x, new_y)
result.fill(np.nan)
isinstance(False, int)
t[k] += v
json_block.append(line)
client.connect(ip, username=un, password=pw)
D = csr_matrix((10, 10), dtype=int)
paths.insert(0, DIR_NAME)
A = np.array(A)
functools.update_wrapper(d(fn), fn)
demo()
val, weight = zip(*[(k, v) for k, v in list(counted_data.items())])
process(mv[i:j])
instance.__dict__[self.prop].__set__(instance, value)
options, args = parser.parse_args()
plt.pcolor(df)
html.tostring(t)
raise Http404
i = iter(lst)
ts = pd.DatetimeIndex([t])
platform.machine()
print(df.shape)
delta = bins[1] - bins[0]
maxlabel = np.max(A) + 1
count = 1
trimmed = [lines[0].strip()]
a / 2.0
idx = np.searchsorted(haystack, needle)
stdscr = curses.initscr()
gbl = globals()
ipaddress.ip_address(16909060).__str__()
setattr(self.instance, name, value)
Py_XDECREF(pModule)
list(missing)
new_pdf = PdfFileReader(packet)
n_to_N = spdiags([n * diag, -nrange[-1:0:-1]], [0, 1], n - 1, n - 1)
data = loader.get_single_data()
group = parser.add_mutually_exclusive_group()
process(cache2.value)
f = urllib.request.urlopen(url, data)
a[4:]
formula = lambda b, m, p, q: np.sum((b - m) ** 2 * p) / q
s.split()
decorator
treeoid = bld.write()
p = field.objects.create(**kwargs)
result[field] = value
label = label_names.index(label_name)
years_dict = dict()
C = [0] * len(matrix)
self._convert * self._swapu
chain.from_iterable(listOfLists)
args = parser.parse_args()
raise wsgiserver.NoSSLError
cal = calendar.Calendar(0)
print(sorted((minval, value, maxval))[1])
tmp.close()
log.write(warnings.formatwarning(message, category, filename, lineno, line))
1,
b[1, 0] = 100
x = [random.random() for r in range(1000)]
raise URLError(err)
gram_matrix = np.zeros((X1.shape[0], X2.shape[0]))
iter(iterparse)
print(pattern % tuple(_u(t) for t in line))
allcols = list(range(0, len(l1)))
self.assertTrue(row[0] == counts[index_row][0])
row_headers = list(df.index)
statvfs.f_frsize * statvfs.f_bavail
groupdxs = [i for i, group in enumerate(groups) for j in range(len(group))]
jpgs = [s for s in files if jpgre.match(s)]
u = x * np.sin(5) + y * np.cos(5)
f_poly = np.poly1d(pfit)
t.start()
du.py
r2 = Range(start=date(2016, 1, 28), end=date(2016, 2, 28))
height = 100 * np.random.random(numcurves)
consonantsremoved = noay[:len(noay) - (len(firstconsonants) + 1)]
top = 1
parser = OptionParser()
indices = [0, 5, 12, 17]
[1, 1, 0, 0, 0, 0],
m = email.message_from_string(email_body)
cluster_0 = np.where(clusters == 0)
list1 = [2, 4, 6, 8, 10]
b = np.sqrt(np.sum(np.square(xs), axis=1))
ftps = ftplib.FTP_TLS()
dt_delta = values[1][1] - values[0][1]
d = {}
max_range = np.asarray(max_range, dtype=int).ravel()
t = 1 - np.abs(np.linspace(-1, 1, 21))
df = shuffle(df)
self._log_ = []
l.append((i[0][11:-1], i[1]))
df = df.applymap(int)
new_string, enc = output[-1][1]
self.x = x
colorama.init()
before_task_publish.connect(self.task_add)
fig, ax = plt.subplots(1)
self._db._adapter.insert(self, self._listify(fields))
a = np.ma.compress_cols(np.ma.masked_invalid(a))
pb = pb.get_from_drawable(w, w.get_colormap(), 0, 0, 0, 0, sz[0], sz[1])
perm_list.append(temp)
t = np.linspace(-10.0, 10.0, 100)
final.append(b)
is_capital = models.BooleanField()
print(themessage)
np.insert(a, 1, 5)
count
psutil.pid_exists(pid)
self.path = request.path
func = self.func_options[func_name]
result
np.apply_along_axis(nGauss, -1, xx, mu, cov)
C1[:, :, (i)] = np.dot(A[:, :, (i)], B[:, :, (i)])
methodReference.__self__.__class__
list_of_lists.append(titles)
img_str = fd.read()
q2 = session.query(TName.calc_column).order_by(TName.calc_column)
(d.A + d.B) / d.C
user = userform.save(commit=False)
progname = sys.argv[0]
raw_email = data[0][1]
f.flush()
count, x, y = np.histogram2d(x_axis, y_axis, bins=numbins)
nplons = numpy.array(lons)
form = DjForm()
ndict, nsearch = benchmark_fuzzy_match(wordslist)
a_sorted = numpy.sorted(a)
False
nones = series.values == n
event.widget.insert(10, old - 1)
this_session = cherrypy.session[SESSION_KEY]
s.getvalue()
headers, resp = client.request(query)
print(QMouseEvent.pos())
page = existing_pdf.getPage(0)
colMean = a.sum(0) / (a != 0).sum(0)
c2 = csv.reader(f2)
numpy.add.reduceat(a, [0, 2])
ax.right_ax(False)
colsmask = np.array([True, True, False])
tf.mul(X, w)
s.shutdown(SHUT_RDWR)
name = models.CharField(max_length=200)
df
x = Decimal(2)
print(getSubStrings(a, 0))
factor = A[j, i]
X = lab[:, :, :1]
loc = seq.index(item, start_at + 1)
key, self[key]
i -= 1
z, y, x = np.indices(A.shape)
count = 0
summation = summation + int(i)
dayDelta = timedelta(days=1)
ys = np.array([[0, 1], [1, 1]]) * 1.0
numpy.nextafter(0.1, 1)
s
c = pycurl.Curl()
print(i)
col_names.append(group)
assert solution(vals) == your_solution(vals)
montreal_json = pd.DataFrame.from_dict(many_jsons[0])
floor(2, 1)
grid = mlab.pipeline.scalar_field(data)
tree = ast.parse(yoursource)
record_bytes = tf.decode_raw(value, tf.uint8)
res = t[-1]
curr.children.append(node)
iris = datasets.load_iris()
matcher(l2, l1)
cleaner.cleanFile(sys.argv[1])
print(repr(y))
result = s.execute()
print(typefunc[type(param)](param))
result.append((n, n))
sortedA = np.array(sorted_a)
p = Pool(4)
s.logout()
m = exp.findall(text)
points = zip(X, Y)
visited.add(s)
df2
root = Tkinter.Tk()
mlcValue = -1.86
self
sys.exit(0)
reverse_dict = {}
b = datastream.read(1)
val -= timedelta(days=diff)
df
data_chunk = data_chunk[-n_overlap:]
loop.call_soon(user_func)
self.data = data
x, y
sess = tf.Session()
quadro.quadro()
print(a.queue)
soup = bsoup(r.text)
time_struct = time.gmtime(time_epoch)
index = random.randrange(len(sequence))
x = asarray(x)
[(s, b) for b in B for i, res in t.iter(b) for s in res]
tuple((str(n), str(n)) for n in range(1995, datetime.now().year + 1))
os.close(2)
request = urllib.request.Request(url, headers=headers)
expr_topl = ZeroOrMore(pths_or_str | anything_topl)
image_summary_t = tf.image_summary(images.name, images, max_images=1)
socket.setdefaulttimeout(2)
row.append(10)
trace = pm.sample(2000, n_init=100000)
dict(items)
stack[-1].append(current)
node.children.add(start_node)
a = [1, 2]
self[key] = NestedDict()
s = sum(i == j for i, j in zip(a[x:], b[:-x]))
xdat, ydat = np.random.normal(size=N), np.random.normal(1, 0.6, size=N)
marked_text
df
pd.isnull(x)
figure(1)
newArray[theArray == k] = v
path
self.awareness_status = self.max_val, -1
line = remove_chars(line)
node = queue.pop(0)
f = Foo(1, 2)
j += 1
p.pprint(obj)
view.setModel(model)
x = np.random.random(N)
print(dt)
dict((v, k) for k, v in enumerate(calendar.month_abbr))
action = QtGui.QAction(text, self)
x
f.close()
invertedDict[value].append(key)
print(lines)
color.setNamedColor(string_with_color)
path = os.path.join(dirpath, filename)
sp.diff(ntot, n[5])
s = requests.session()
some_words = OneOrMore(~JUMPS + Word(alphas))
Base = declarative_base()
y = np.random.rand(1000)
struct.unpack(new_fmt, dat)
a.set(round(5.494949, 2))
args = parser.parse_args()
phi = list(phi)
QuoteFormSet = modelformset_factory(Quote, form=QuoteForm, extra=2)
current = sum(negatedEven[i:i + d])
array_ = array_.reshape(-1)
print(temp)
f()
cPickle.dump(rf, f)
example = Example()
pdb.gimp_item_get_children(c)
self.conn.commit()
taken_at = models.DateTimeField(default=date, auto_now_add=True)
print(name)
sleep(1)
[(val,)] = t2
x > -2 and x < 2
reshaped_data = data.reshape((4, -1))
print(html)
create_all(app)
ss = str(request.form)
dic[k].extend([v] + dic[v])
y = np.empty_like(x)
self.domain = domain
list.__init__(self)
classification = np.zeros(len(data))
out = np.empty((9, 9))
x = []
W = np.cumsum(W) * np.sqrt(dt)
X = np.outer(A[:, (n)], rowb)
print(L)
g = a()
Requirements
infoObject = pygame.display.Info()
add2 = functools.partial(add, 2)
i2 = Interval(0, oo)
result
self.client = gconf.client_get_default()
print(decorated_argspec)
2 * val
fig, ax = plt.subplots()
temp_file = make_a_file_in_a_dir(temp_dir)
dlist.append(d)
total += (math.log(scale) + x / scale) * count
a = gen()
k = list(d1.keys())
login_view = KeyAuthLoginView.as_view()
query |= Q(lft__lt=node.lft, rght__gt=node.rght, tree_id=node.tree_id)
print(d)
threads = []
data = re.sub(REGEX, escape, data)
print(determinant)
pipeline.get_state()
d.rotate()
arr_win = np.empty((rows, cols - n + 1), dtype=np.intp)
foo = timeit(lexicon, number=nloops)
foo = timeit(comprehension, number=nloops)
callback(size, file_size)
line = result.stdout.readline()
result_list = regex.findall(line)
result = value_if_true
num_str = str(n)
l.append(uimg[i])
False
transposed_l = zip(*l)
eval(method_name1)
dx = np.linspace(0, 1, 20)
A[0, 2, 6, 7, 16, 20]
forms = [Foo(prefix=i) for i in range(x)]
len(self.d)
time.sleep(0.4)
test_df[test_df < 4] = np.nan
self.buffer[n]
transaction.commit(sid)
f = lambda a, b: a.append(b) or a if b not in a else a
element.attrib[key]
file_parser = argparse.ArgumentParser()
self.val = val
select.order_by(func.rand())
grid, np.linspace(xmin, xmax, nx), np.linspace(ymin, ymax, ny)
voltage = [1, -1, 1.1, -0.9, 1, -1, 0.9, -1.2, 0.95, -1.1, 1.11]
lamp_object.select = True
[[a - z] - -[aeiou]]
laplacian2 = nx.spectrum.laplacian_spectrum(graph2)
app = App(root)
connection = op.get_bind()
print(result)
next(b)
traceback.print_exc(file=sys.stdout)
pprint.pprint(dict(result))
instances = []
data = mmap.mmap(f.fileno(), size, access=mmap.ACCESS_READ)
(d.days * 24 * 60 * 60 + d.seconds) * 1000 + d.microseconds
s[10:]
tokens = wordpunct_tokenize(text2)
self.update(json.load(fh))
istart.append(i)
time.sleep(0.1)
c = camelcase()
x = int(x)
files
int(string)
f(5)
list_
data = np.empty((sizes[-1],), dtype=csc_mat.dtype)
tty.setraw(sys.stdin.fileno())
page = html.parse(url).getroot()
result = dot(total, unit_normal(poly[0], poly[1], poly[2]))
arg.join(value)
c.connect()
type(m)
serializers.get(type(ob), repr)(ob)
authors.allow_tags = True
[[i[o] for i in a if len(i) > o] for o in range(max_len)]
engine = create_engine(dbname, echo=False)
Features
file.write(insert)
c = getch()
counter = 1
myobjs = [Foo() for _ in range(1000000)]
gzip.wait()
print(note.id_item, note.name, note.value)
img = Image(image_path)
print(sf.to_string())
mask = mask.resize(image.size, Image.LANCZOS)
model.add(LSTM(4, input_dim=input_dim, input_length=input_length))
parameters.append(int(tokens.popleft()))
client_socket.send(strng)
ax.autoscale_view(True, False, False)
mydict
reader = csv.reader(input_file)
os.remove(self.filename)
logger.addHandler(fh)
self.y = y
passing, failing
dict(zip(p[:100], p[100:]))
search_button.click()
keys = list(d.keys())
target_date = base_datetime + delta
self.nested_json
cache[jid].add(resource)
print(t.sTitle)
1.0 - 0.5 * erfcc(x / 2 ** 0.5)
STOCK_GO_BACK
STOCK_GO_FORWARD
STOCK_JUSTIFY_FILL
STOCK_LEAVE_FULLSCREEN
STOCK_ORIENTATION_LANDSCAPE
STOCK_ORIENTATION_PORTRAIT
STOCK_SPELL_CHECK
STOCK_ZOOM_FIT
startTime = datetime.now()
c = b.view()
s
readline.read_history_file(histfile)
d[key] = value
api = tweepy.API(auth)
summary = Column(String(2000))
s = x.argsort()
self.books[i]
q.put(test_w)
s = requests.Session()
main()
p.y = y
B()
[0, [0, [0, values, 2], 2], 2]
csv_contents = []
1, 2, 0
slug = models.SlugField()
False
deleteself.lines[:]
datetime.timedelta(seconds=seconds, microseconds=microseconds)
rm = np.hstack([ind[i] for i in mylist])
Options + ExecCGI
columns = line.split(separator)
rdd.__class__ = RDDWithSquares
print(b)
dic[7]
a + b
line.set_data([], [])
int_n = int(abs(n))
j = ttk.Treeview(self.parent)
current = (current + incrementor) % modulo
a[indices] += x
filename_queue = tf.train.string_input_producer(filenames)
atom_shape = np.shape(atom_proj[values[1][0]])
s = set(l)
self.search_entry = gtk.Entry()
Series(mapped, index=self.index, name=self.name)
window = collections.deque(sorted(window), maxlen=window_size)
c.py
d[k] = f(v)
list(l)
[arg_line]
lens = np.array(map(len, arr))
a, b, c = uniform_result(*do_something5())
print(i, da[i], db[i])
traceback.print_exception(*exc_info)
sns.heatmap(data=df1, annot=False)
table.setCellWidget(0, 0, combobox)
p.terminate()
href = href.strip()
BOOST_PYTHON_MODULE(hello)
self.verticalLayout.setSizeConstraint(QtGui.QLayout.SetFixedSize)
True
print(b.y)
step = len(array) - 1
objects = SomeManagerSet.as_manager()
current_time = datetime.now()
old_file_position = f.tell()
print(multi_dict.get(key))
box = BoxLayout()
poss = lookup_mapping[text[:2].lower().lstrip()]
data = final_list
cols = np.any(img, axis=0)
SNIP
lag_seq = np.int64(np.random.normal(lag_mean, lag_sd, n_iter))
ser = pd.Series(data=np.random.randn(len(idx)), index=idx)
self.comboBox.currentIndexChanged.connect(self.on_comboBox_currentIndexChanged)
1
ipython = IPython.core.ipapi.get()
Session = sessionmaker(bind=engine)
liPos = [(2, 5), (8, 9), (18, 22)]
dis.dis(foo)
print((Session.is_active, Session.is_modified(mylst)))
datetime.datetime.today().ctime(),
feed.etag
X, Y, Z = generatedata()
browser = webdriver.PhantomJS()
f.read()
self.read(rc)
utc = datetime.datetime.utcnow()
x += 1
fills = np.zeros(nu)
new_remaining = []
next(dtg0)
foundColors[color].add(key)
Base.metadata.create_all(e)
cursor = conn.cursor()
dicto = defaultdict(list)
b = iter(a)
lons, lats = zip(*verts[ring])
total = cursor.scalar()
[easy_install]
list(set([str(rng.randint(60000, 80000)) for _ in range(n)]))
b = a[2:9]
frob()
bar_obj = Bar()
column[h].append(v)
available_tickets = [fulltime, parttime, daytime]
memv = memoryview(a)
reversed_edge_list.append((j, i))
sys.stdout = mystdout
self.sendLine(request)
xmldoc = xml.dom.minidom.parse(file)
X, Y, Z
header.seek(0)
data = str(data, coding).encode(new_coding)
label.show()
__metaclass__ = fancytype
fib(400)
pool.map(func_star, zip(a_args, itertools.repeat(second_arg)))
response
0
assert pickle.loads(pickle.dumps(C(1), -1)).i == 1
str(50) is str(50)
data = np.random.normal(0, 1, (10, 100))
tic = time.clock()
s = self.makeDefaultS()
transaction.commit_unless_managed(using=self.db)
[x, y, z] = v
parser.clean()
self.file_pointer.read(self.record_size)
add(1)
self.count[0] += 1
form.show()
sort_by = lambda x: x[0].lower()
pkg.mark_install()
cols = set(chain(*list(d.values())))
q.set_array(np.random.rand(np.prod(x.shape)))
pylab.arrow(4, 6, x, y, alpha=0.8, **opt)
primefactors.append(p)
print(leastsq(optm, [0.5, 0.5, 0.5], (x,)))
X = np.concatenate((X, X))
x = np.linspace(100, 100.1, 100)
self.mapping[key] = value
lookuptable >> i & 1 != 0
print(x ** 5)
print(type(n))
logging_thread.join()
add(x=x, y=y)
idx = np.abs(a - a0).argmin()
currentSongURI = self.GetSongURI()
df2 = pd.DataFrame({col: vals[column] for col, vals in df.groupby(by)})
idx[0]
edges = np.zeros((len(hull_points) - 1, 2))
playerList = []
b = a[:, :, (newaxis)]
ie.Visible = 0
conman.found()
cls = type(c_uint).__new__(metacls, name, bases, dict)
l2 = list(range(5))
print(a is b)
id = serializers.Field()
b = a
cur = db.cursor()
browser = Browser()
c[0].append(c)
iterator = iter(iterable)
d[nkey] = newvals[nvalue]
self.buffer.pop(0)
True
session = DBSession()
totalscore = sum(t)
log_observer.start()
possible_shuffles(initial_state)
result
text1 = open(file1).read()
sleep(1)
resp(status, headers, *args)
tb = sys.exc_info()[2]
l2 = f2.readline()
InterfaceClass(iface.__name__, iface.__bases__, fields)
x = 42
a = np.array([True, False, False, True, True, False, False, True, False])
df.columns = columns
cv.WaitKey(0)
colormap = window.get_screen().get_rgb_colormap()
self.Layout()
[model_solve(100) for x in results]
mkdict = lambda row: dict((col, row[col]) for col in cols)
self[key] = key
text = infile.read()
transpositions(splits),
replacements1(splits),
s = -1.0 / (2 * sigma * sigma)
id(tup)
r = csv.DictReader(i)
H, xs, ys = np.histogram2d(x, y, weights=z, bins=bins, range=rng)
related_obj = getattr(obj, name)
dense = np.asarray(a.todense())
sessionOptions = blpapi.SessionOptions()
self.members = []
plot_durations(starts, stops, ax, facecolor=color, alpha=0.5)
rows = [x for x in cursor]
cache = apt.cache.Cache()
event.widget.insert(10, old + 1)
MAX_EMAILS_IN_PERIOD = 1
raise ReturnValue(value)
Sx = Sy = Sxx = Syy = Sxy = 0.0
x += y
print(number)
root = Tkinter.Tk()
print(model.eval({select_test: True}))
window = gtk.Window(gtk.WINDOW_TOPLEVEL)
qs = MyModel.objects.all()
new_state = self._as_dict()
x = np.linspace(0, 10, 10)
x = np.linspace(0, 10, 100)
y_onehot = [0] * len(y)
zip_longest(it1, it2)
ticklab = ax.xaxis.get_ticklabels()[0]
keys.append(k)
X = X[(indices), :]
x = np.linspace(xmin, xmax, 100)
items = list(this_v.items())
directions = array([[1, 1], [-1, 1], [1, -1], [-1, -1]])
numbers = set(range(10))
axes_col.set_title(col.strip())
my_list
images.append(image)
num_items = (num_bits + BITS_PER_ITEM - 1) // BITS_PER_ITEM
self.domains[key].remove(color)
sel = Selector(response)
entnum = int(hex, 16)
mu = np.array([1, 10, 20])
line.isspace()
data = np.random.random((10, 10))
axes[0].plot(list(range(50)))
output.write(texts)
manager = mp.Manager()
Pool(processes, initializer, initargs)
dx = dALLdt(X[-1], i)
class_a_inst = get_my_inst(5)
updated_fixtures
file = sys.argv[1]
something = protorpc.messages.IntegerField(1, required=True),
distance_km = haversine(points_1[0], points_1[1], points_2[0], points_2[1])
w.wcs.crval = [crvalX, crvalY]
False
json_obj = requests.get(url).json()
x.turn()
main()
recv1 = recv1.decode()
ax2.set_xticks(ax2Ticks)
new_dict
lats = [0.0, 41.0, 19.0, 51.0]
zipped = zip(x, y)
name = Column(Unicode(256))
combination[r - 1] = combination[r - 2] + 2
HoughLines(dst, lines, 1, CV_PI / 180, 100, 0, 0)
my_worksheet.protect = True
_draw_point(i, j, MAX_OPAQUE - fade_amount_i)
mask = cv2.bitwise_not(mask)
id_ = build_id(pub_key)
solve(a, b)
print(df2)
os.makedirs(build_temp)
__debug__
np.array_equal(accumulate_based(A2), cython_based(A2c))
result = []
pairs[(J == 1), ...]
assert PyUnicode_KIND(u) == PyUnicode_KIND(str)
x.append(pt[0])
content = myfile.read()
gen2, gen2_copy = tee(gen2)
data = request.DATA, files = request.FILES
raise Timeout()
s.snoodidle()
head - 1
[0]
s.close()
print(proc.stdout)
job = pool.apply_async(worker, (i, q))
instances = [i for r in res for i in r.instances]
type(D)
a(locals())
doc = parseString(s)
plot(t, s)
congruent.stack(dropna=False)[same].dropna()
pivots = zeros(n_eq, np.intc)
num_lines += 1
list_of_dct
temp[parts[-1]] = 1
img = im_clear[:, idx * split_point:(idx + 1) * split_point]
indefinite_integral(end_time) - indefinite_integral(start_time)
root = int(math.ceil(lo ** 0.5))
addToList(myList)
w = Tk()
newbuf = file.read(bufsize)
_r = r.request.response
b_padded.shape
f = sympy.Sum(x, (n, 0, 10))
resultqueue = Queue.Queue()
pathqueue = Queue.Queue()
is_type(df, np.integer)
[string[start:end] for start, end in zip(starts, ends)]
mat_inv /= det[..., (np.newaxis), (np.newaxis)]
x.y = 1
length = len(elements)
result = small_number * A
lConnection.close()
print(observer.radec_of(az, el))
result = np.array(nearest_neigbours, dtype=np.uint8)
data
self.sources_list.append(source)
output.writerows(rows)
i = 0
paths = os.listdir(path)
app = QtGui.QApplication(sys.argv)
func_wrapper
plot(x)
vulture - -help
filename = os.path.join(root, basename)
second_list = [2, 5, 7, 9]
c[0][0]
Property1 = 1
type(0) is int
espec = urllib.parse.unquote(espec)
self.yaxis.set_zorder(2.5)
values = tuple((company.id, company.max_price) for company in companies)
p.start()
csvin = csv.reader(fin)
self.count += 1
httplib.HTTPMessage(filehandle).getdate_tz(headername)
y = cos(angle) * self.radius.imag + self.center.imag
type(c)
deleteconnection
type(size2_col), size2_col.index
ascend_list = []
self.kill_now = True
self._do_request(action)
np.allclose(original_app(x, idx), reshape_based(x, idx))
time.sleep(0.1)
ys = [(i + x + (i * x) ** 2) for i in range(10)]
plt.colorbar(im)
myfunc()
all = set(range(1, 101))
Y_int = np.round(Y * 10).astype(int)
l = []
indices = np.where(tmp)[0]
self.after(100 * name_changes, finish_spinning)
B().f()
data[word[i:i + 1]] = [word[i + 1:], {}]
b2 = [4, 5, 6, 7, 8]
code = json.dumps(data)
mu, std = norm.fit(data)
c = char[0]
number
ax = fig.add_subplot(111)
raise ArgumentError(action, msg % (name, arg_string))
clf.partial_fit(X, Y)
dis.dis(f2)
subclass1.bar()
{(0): 1}.get(0, getter())
print(j)
v.sort()
c.showPage()
plot = plt.figure()
print(x, c)
x, y = np.mgrid[0:h:500j, 0:w:500j]
dll._sin.argtypes = [ctypes.c_double]
fd.write(string_conditioned(row))
diam = np.empty(N)
n_estimators = 10
[], 2
deletehand[key]
print(find_centroid(im, 20))
my_plot_1(ax1)
sys.exit(1)
initial = tf.truncated_normal(shape, stddev=0.1)
ceil(datetime.datetime(2012, 10, 25, 17, 45, 1))
self.zipinfo = zipinfo
blah[i] += merp
result = []
res = 0
print(total)
vend = vspell[2]
print(csr_matrix(np.vstack([line for line in dense if line[2] == 0])))
pubsub = redis_instance.pubsub()
ax.set_ylim(height_of_im, 0.0)
px = ImageGrab.grab().load()
i = seq.index(subseq[0], i + 1, n - m + 1)
dict_of_strings.close()
code = x86_env.InstructionStream()
my_data[i] = line
session.run(tf.assign(embedding, embeddings_that_you_want_to_use))
print(result)
gen = myfunct()
callback(copied)
x = [10.01, 5.001, 4.89, 5.1, 9.9, 10.1, 5.05, 4.99]
Contacts.all_contacts.append(self)
test([1, 0])
thread.join()
math.floor(x)
self.seconds %= 86400
parts = re.findall(pat, sentence)
d = dict((i, i) for i in range(10))
f(b=44, a=12)
data = self.request.recv(1024)
self.array.pop(0)
self.leftover = data[size:]
self.my_member_fun(data)
logger = logging.getLogger()
x, y = np.mgrid[0:size, 0:size]
self._sendRequest(queued_d, request)
stopindex = 2
r_ndegen = gen.randn(1000).astype(np.float)
type(self)(self.x + other.x, self.y + other.y)
to_response(request, response, myobject)
w.writerows(r)
seen_titles.add(obj.title)
id(a), id(b)
alan2
Gtk.main_quit()
a = np.asanyarray(a)
match = patt.match(line)
self.feature_indices_ = indices
hash(new_key) % 8 <= hash(old_key) % 8
browser = webdriver.Firefox()
pet = Dog()
app_log.addHandler(my_handler)
j = jinja2.Jinja2(app)
1
w1, w2 = [], []
inspector
topic_bundles = []
edges = set()
print(so[-4470:-4460])
y = np.concatenate((y_a, y_b, y_c, y_d))
w.write(code)
tty.tcsetattr(stdin_fileno, tty.TCSANOW, raw_ta)
dt
df
wholeList = list(range(0, 10))
col_list = list(df)
sys.stdout = sys.__stdout__
row = cursor.fetchone()
end_date = end_date.replace(hour=0, minute=0, second=0, microsecond=0)
dates.append(dates[i] + timedelta(0, delta))
myLib.RegisterNofityCallback(45454, 0, func)
loop.run_until_complete(asyncio.wait(tasks))
statistics.median(map(float, items))
b = a.T
deleteself.inverse[self[key]]
image_profile = QtGui.QImage(image_path)
tree.write(s)
u = uuid.uuid4()
self.curoffs += len(data)
zip_ref.extractall(directory_to_extract_to)
txt = txt.replace(sep, default_sep)
p = bokeh.plotting.figure(plot_width=400, plot_height=400)
self
print(tree)
_ProcQueue(q)
print(a[:4, 1:6])
ipdb > new_post.update(request.GET)
a = np.zeros((10, 2))
open(fname)
get_items(coo, 2, 5)
a, b = {}, 5
window.set_titlebar(header_bar)
df = pd.DataFrame(array)
app.run()
b = numpy.empty(a.shape, dtype=a.dtype.descr + descr)
DOT11_CIPHER_ALGO_NONE = 0
coord = np.array(atom[6])
last_day_of_previous_month = first_day_of_current_month - timedelta(days=1)
print(f)
X if not isinstance(X, pd.DataFrame) else X.as_matrix()
b = np.random.normal(size=1000)
rows, cols = img.shape
main()
d[a] = a
b = a + 2
i += 2
print(newlist)
a[rows, cols] += np.ones((rows.size, cols.size))
myfoo.d = myfoo.c + 1
d = {k: (lambda k, s: s * A[k]).__get__(k) for k in range(n)}
session = requests.Session()
max_val = max(my_list)
module = __import__(module_name)
sy2, _ = np.histogram(x, bins=xbins, weights=y * y)
B = np.empty_like(A)
f = lambda x, y: x * x * x + y * y
andalso = Infix(lambda x, y: x.and_impl(y))
result = np.zeros((9, 12))
xyi = np.column_stack([x.ravel(), y.ravel()])
fig = plt.figure()
dis.dis(foo)
method(self, *args, **kwargs)
print((first, second))
self.disconnect_from_server()
PROJECT_DIR = os.path.dirname(__file__)
root.update()
s = pd.DataFrame(data[1:], columns=data[0])
logits = model.inference(batched_train_x)
assert is_palindrome(s_fail)
relate(inp, cut)
print(LCM(99, 12))
self._x
sched.start()
print(f())
self.camera.child.join()
x = pd.rolling_min(arr, window)
self.dummyy[i] = nm.NaN
self.dummyz[i] = nm.NaN
extension
fitfunc = lambda p, x: p[0] + p[1] * x
str(self.val)
output = io.StringIO()
{{name}}
v = A[position:position + length]
dems < -readHTMLTable(demdir)[[1]]
sc = scorm.objects.get(pk=someid)
self._locals = {}
result
clf.train(samples, y_train)
__round__()
print(parser.feed(content))
__init__.py(blank)
xvalues = line2d[0].get_xdata()
list
d.__repr__()
rightmax = 0
a = argparse.ArgumentParser()
f1.write(line)
sys.stdout = f
parser.parse_args()
df.columns = ind
writer.save()
fd = StringIO()
y = np.zeros(n)
l = list(range(10))
model = Post
queue.join()
base = sum(np.array([(p[m] * A[m]) for m in range(M)]))
fig = plt.figure()
todays_files = []
tagged.sort(lambda x, y: cmp(x[1], y[1]))
tally = Counter(chain(*map(set, data)))
[(u.value, u.meta) for u in set([b, d]).intersection(set([a, c, e]))]
end_date = dt.datetime.now().date()
print(e)
new_from_slices(a, slices)
count[i] += 1
nltk.pos_tag(text)
x = np.arange(10)
x = np.linspace(0, 1, 10)
compressor.write(chunk)
sunaudiodev
d[letter] += 1
vals = words.split()
T = zlib.decompress(S)
yet_to_run = 0
alpha.paste(circle.crop((0, rad, rad, rad * 2)), (0, h - rad))
plt.colorbar()
x_values = data.columns.values
0.0010009999275207519
dict_reader = csv.DictReader(fin)
cur = l[i]
df = pd.DataFrame(data=d)
np.nextafter(1.0, 0.0)
self.dict[key] = value
http_server = tornado.httpserver.HTTPServer(Application())
xlApp.Quit()
self.upload_file(filename)
d[key]
tokens = f.read().split()
files_py.append(fff)
res.append(S[pos])
data_y = [1.5, 1.0, 0.7, 2.5, 1, 1.5]
self
a_ma = np.ma.masked_where(a > 0, a)
d = defaultdict(list)
GradeNum.B == Suit.spade
clock = pygame.time.Clock()
doSomethingElse()
root = Tk()
axarr[0, 0].plot(x, y)
s.get_subnet(28, count=10)
c.remove(x)
df
res = np.flatnonzero(d_slice >= thresh_d)
self.constant = constant
order.sort()
model._meta.app_label == self.app_label
weekday = current_date.weekday()
print(index, item)
print(driver.current_url)
istart = 0
process(dir)
result[0] = len(result) - 1
ax_img.set_axis_off()
image, label = read_my_file_format(input_queue.dequeue())
self._latency = latency
print(i, m)
TASKS1 = [(mul, (i, 7)) for i in range(20)]
self.assertTrue(user.username == testuser.upper())
main.test
setup_environ(settings)
self.accounts.signup(userName, password)
x = time.time() - 1000
lons = np.linspace(-180, 180, bm.shape[1]) * np.pi / 180
pkcs11 = PyKCS11Lib()
a(myfoo)
print(out)
objects = PersonManager()
a = np.array([np.nan], dtype=object)
obj.get_decoded()
gtk.main()
hex(s.start)
enable_numpy_scalar_converter()
self._may_close = False
numpy.dot(numpy.array([-d[1], d[0]]), p - v1) < 0
do_something(blah)
Nfeval = 1
self.workers.acquire()
print(text.translate(trans))
irb
your_tableview.setModel(model)
imx = np.tile(np.arange(xlo, xhi, 1), ny).reshape((ny, nx))
update_list_energy(list_of_proteins, 1)
objs = []
rows = []
a = []
row[0:4]
im_array = np.array(im_grey)
a = A()
[(a, B[k]) for a in A for k in d[a]]
p(sys.path)
self.connections.add(self)
offset = 4 * (self.width * int(round(y)) + int(round(x)))
visit.Launch()
self.start_urls = [url]
contents = my_file.read()
l1.append(elem)
d = defaultdict(list)
el.text
app = web.Application(loop=loop)
d = dict(enumerate([str(random.randint(0, 10)) for _ in range(100)]))
points = np.column_stack((x, y, z))
templateString = ftemp.read()
sfile = ctx.open(suri, os.O_RDONLY)
output[:-len(self.sentinel)]
out = np.array([[np.dot(matrix, np.array([x, y, 1])) for x in xs] for y in ys])
2, 4, 6
0
Foo.arg0
self.request = request
dif = set(bigd.items()) - set(bigd2.items())
browser.switch_to.window(newWindow)
start += step
data = next(line_iter)
password = forms.CharField(widget=PasswordInput())
lens = len(s)
l = []
df
dir_path = os.path.join(self.feed, self.address)
c = ctypes.create_string_buffer(mlen.value + 16)
sqc[i], sqc[j] = sqc[j], sqc[i]
count = 0
imputed_array[hole] = most_frequent
print(example())
sess.run(init)
temperatureRaisedSignal = QtCore.pyqtSignal()
cmd.append(run_as_root_path)
print(text)
cls_attr = class_.__dict__
perms.append(result)
df2
user = auth_by_token(request, backend)
instance = object.__new__(cls)
Q.appen(task)
ser_cdf = pd.Series(cum_dist, index=ser)
p = Process(target=self._crawl, args=[domain_pk])
handler.dispatch()
[T(val, params) for val in array]
i, j = 0, len(x) - 1
data = data[4:]
data = f.read()
cat / tmp / kernel.json
Model.aggregate(*pipeline)
min_value = min(sentiment_dict.values())
parser = argparse.ArgumentParser()
self._callback = callback
data
results.append((i, r))
self.name
s.sendmail(From, To, msg.as_string())
self.input.SetValue(value)
updating = True
ret
type(x)
thresh = cv2.adaptiveThreshold(blur, 255, 1, 1, 11, 2)
self.marked = {}
formula = [(x, s.index(x)) for x in s if x in string.digits + symbols]
rf = r[np.triu_indices(r.shape[0], 1)]
train_as_dicts
height = im.size[1]
inGroup.append(n)
print(df)
cesttime.isoformat()
vocabs.append(dict(zip(vals, list(range(len(vals))))))
emitted = []
n - x // 2
print(csr_matrix(np.vstack([line for line in dense if line[2] == 1])))
[(o >> shift & 1) for o in ords for shift in shifts]
result = pool.apply_async(f, [10])
51251080
x2to = x1to + x2fr - x1fr
y2to = y1to + y2fr - y1fr
print(table_name.parseString(test).dump())
r = np.sqrt(x ** 2 + y ** 2)
print(x[0])
print(type(a), len(a), a)
processes[i].join()
s == s[0] * len(s)
self.database[name] = value
show()
print(a)
index = lambda self, *args: self._tuple.index(*args)
logger = logging.getLogger(name)
self[key] = value = self.default_factory()
pygame.draw.rect(Surface, (150, 0, 0), particle.rectangle, 0)
count = 0
primes = [2]
output_img = input_img.crop(box)
M[0, 2]
data = data[order]
f_order[0, 1, 2]
end = datetime(end_year, end_month, 1)
deleteddd[k]
session.delete(x)
H = nmf_model.components_.T
http_server = tornado.httpserver.HTTPServer(Application())
z[x, y] = np.dot(transformation_matrix, rgb_image[(x), (y), :])
df
dict(zip(self.column_names, row))
print(jez(df))
blocks = np.array(blocks)
dx = pxi - pos[j, 0]
sess.add(user)
rank = {v: i for i, v in enumerate(sorted(a))}
x = np.linspace(0.0, N * T, N)
coeff_mat = hstack((vstack((n_to_M, n_to_N)), vstack((m_to_M, m_to_N))))
jsonString = json.dumps(data)
S = np.minimum(max_sum - P.sum(axis=1), max_range[0])
quit()
x + y
print(im.size)
insert_locations = sample(range(len(lst) + len(seq)), len(seq))
self._lookup = {}
channel.set_combine_stderr(True)
f.close()
m = max(map(hello.count, hello))
key, value = d.popitem()
menubar = tkinter.Menu(root)
x, y = spstereo(lons, lats)
df
self.Blist = [B(True), B(False), B(True)]
disown
L[start:end + 1] = sorted(L[start:end + 1], key=g)
net.ipv6.conf.all.forwarding = 1
iph = IP(import_hexcap())
print(value)
wrapper
rows = cursor.fetchall()
f0 = round(len(index) * RATE / (2 * np.prod(len(signal))))
df1.join(broadcast(df2))
p = np.stack([p, p]).flatten()
np.sum(A ** 2, axis=1)
c_list.append(c)
color = max(iter(histogram.items()), key=operator.itemgetter(1))[0]
foo(1, 4)
aclass
False
f = urllib.request.urlopen(req)
auc = np.trapz(y, x)
final = [word_list[0].capitalize()]
print(field.name)
outfile.write(calculation_result)
ts = datetime.datetime.fromtimestamp(time.mktime(nofrag_dt))
a = x.y
A2c2 = A2.copy()
sizes.append(len(i[1]))
cut_idx = np.append(0, map(len, I))[:-1].cumsum()
R = (T - y) * Dinvs
keystate = pygame.key.get_pressed()
l = string.split()
movement.normalize()
print(mystuff.average(a, b, c))
P = mpp.Pool(mpp.cpu_count())
print(stripTags(match.body))
tuple(repeat() for i in range(n))
assert (f1(data, d) == res).all()
x = 5
main()
results
client = Client()
vals[half - i - 1]
self.transport.setOutgoingInterface(src_ip)
c = p.cumsum()
reply = json.dumps(info)
the_choice = items[choice]
_cache[key] = f(*args, **kwargs)
dt1start <= dt2end and dt1end >= dt2start
dict(form=form)
new_loop = asyncio.new_event_loop()
http = httplib2.Http()
dfy.plot()
l = list(x)
numpy_default_rng = numpy.random.random.__self__
request = requests.get(url)
print(df)
c = np.vectorize(d.get)(a)
a = np.random.randint(10, size=10)
p.join()
pool.map(find_inter, product(ent.shape, collidable.shape))
print(i + -+i)
instance.__dict__[self.prop].__get__(instance, owner)
f.write(z.read(icon[1]))
l1 = f1.readline()
a = [1, 1, 1, 2, 2]
self._stream = BytesIO(self._body)
f2 = pl.figure(2)
df[[0]]
descend_list = []
self.current += node.id
result.add(path)
next_item = self.queue.get(timeout=15)
symbolList = map(Dummy, range(numEquations))
C = np.empty(A.shape[0] * 2, dtype=A.dtype)
groups = []
pl.plot(xd, piecewise_linear(xd, *p))
print(A.dtype)
d4.setdefault(k, 0)
doc.remove(e)
print(NewList[0]._data)
len(r)
strip_list = map(str.strip, lines)
encoded = json.dumps(obj)
log4j.logger.org.eclipse.jetty = WARN
sck.send(next(locker))
True
self.hide()
pairs += recursion(value, new_base)
f.truncate()
G = (list(x) for _, x in groupby(L, lambda x, c=count(): next(c) - x))
app
c1 = pycurl.Curl()
total = 0
sm.ratio()
main()
result.add(k)
assert False
X_ = poly.fit_transform(X)
c_float_p = ctypes.POINTER(ctypes.c_float)
Y = np.array([2, 0, 1, 1])
A = np.dot(X0.T, Y0)
main()
x = np.random.randint(xmin, xmax, ndata)
d = pickle.load(filehandler)
dictionary.setdefault(realName, {})[falseName] = position
g = Graph.Lattice([10, 10], circular=False)
bbbb
hildonize_window = _null_hildonize_window
player.play()
e = Entry(root)
print(message)
result = str(time.time())
loop.run_until_complete(my_app())
CustomerAddress.objects.filter(customer_id=self.id)
array = [1, 2, 4, 5, 4, 5, 6, 7, 2, 6, -9, 6, 4, 2, 7, 8]
s = f.read(100)
bins = np.linspace(-2, 2, 101)
block = f.read(4096)
min_y = np.nanmin(rot_points[:, (1)], axis=1)
f_line = next(f)
request = urllib.request.Request(url)
two = models.CharField(max_length=255)
yaml.add_representer(OrderedDict, ordered_dict_presenter)
x + 5
self.correct_response = correct_response
test(a)
fp = open(filename)
self._listener.stopListening()
sys.exit(1)
code_out = StringIO.StringIO()
signals.post_syncdb.connect(init_data)
tocrawl.add(link)
self.width = event.width
code.interact(local=locals())
print(A.index(l))
next(cr)
out = np.empty((len(x_lattice), 2), dtype=float)
print(highscores)
attr
original_rows = np.asarray([[1, 0, 1], [0, 0, 0], [1, 0, 0]])
self.write(value)
ax = fig.add_subplot(111)
img_hsv = color.rgb2hsv(img_color)
linecache.cache[L.__code__.co_filename]
reactor.listenTCP(PORT, factory)
SL = sorted((x, i) for i, x in enumerate(L))
ys = np.random.rand(20)
tree = QtGui.QTreeView()
screen.blit(user_text, text_rect)
df1.shape
results = p.imap(f, jobs)
label = tk.Label(window, text=id)
show(block=False)
queryset = Subscription.objects.all()
foo = _bar.__enter__()
roots = set()
f, ax = plt.subplots(figsize=(8, 6))
nb.index(nb.select())
dataDict = json.loads(data)
values = json.load(jsonFile)
print(doc.xml.web.total.string)
np.array(list(fread(fname, cond)), dtype=np.float64)
lst = [(data[i], data[i + 1]) for i in range(0, len(data), 2)]
default()
stefan = []
self._data.pop(value)
warnings.showwarning = warn_with_traceback
df
b_set = set(b)
passthrough
print(car)
B_r = B.ravel()
self.uniqueProps(lambda song: song.album)
iterator = gen(10)
is_invertible(a)
print(rows[idx])
oldfig = plt.figure
line = lines[i]
_vim(fname, globals())
fout.close()
z[-1]
[8, 1, 5, 9]
ind = np.argmax(counts)
j = np.arange(len(new_x))
fig = pyplot.figure()
observer.start()
print(soup)
n = len(pd.read_csv(filename)) + 1
np.linalg.norm(xyz - roi, axis=1) < radius
print(line)
z_scattered_smooth = fun_smooth(x_scattered, y_scattered)
RGB = [0, 0, 0]
queryset = UserProfile.objects.all(),
P1Sum = P1Channels.sum(axis=1)
c = CurrencyRates()
sorted_permissions = sorted(permissions, key=permissions_key)
ans.append(k)
d = {}
store.close()
Base = declarative_base()
x + y
np.random.seed()
d[b] = a[:, (i)]
new.__dict__.update(old.__dict__)
ser = serial.Serial(SERIAL_PORT, 9600)
list.__init__(self, *args)
d = keybased_defaultdict(lambda x: len(x))
area.show()
password.send_keys(Keys.RETURN)
dw, dh = wx.DisplaySize()
query = parse_qs(u.query)
prev_item = resultList[i - 1][-1]
print(millis)
newlist = list(filter(filtah, test_list))
self._cond.release()
f.close()
flipper.pack()
rdata.append(sock.recv(MAX_PACKET))
char = ascii_lowercase[ascii_lowercase.index(char) + 1]
image
serve(request, path, settings.PRIVATE_MEDIA_ROOT)
a = iter(iterable)
name = models.CharField(max_length=50)
A = np.random.randint(2, size=(n, n)).astype(np.int8)
self.setTopLevelWindow()
tot = str(int(pri) + int(sec))
p.start()
bucket_list = bucket.list()
readdir.argtypes = [c_dir_p]
self.count = 0
args.push_back(arg)
process(lines)
new_o = copy.deepcopy(o)
deleteL[write_i:]
print()
threadA.join()
neighbors = get_neighbors(x, y, img)
0
d = float(requests.get(realtime_url).text)
g = Foo.Instance()
self.depth += 1
counter = 0
a_test = Test()
next(c)
plt.plot(dist_space, kde(dist_space))
num_converted[0] += 1
(),
amap = []
conv = locale.localeconv()
sd.SetSecurityDescriptorDacl(1, dacl, 0)
answer = set()
upper_red = np.array([180, 255, 255])
request.user = user
con = psycopg2.connect(conn_string)
a = SomeClass()
offset = df1.values[:, (-1)]
s = np.zeros(p.size, p.dtype)
data = stream.read(CHUNK2)
os.close(fd)
app = QApplication(sys.argv)
axF = plt.subplot(gs1[(0), :])
sys.stdout.name
imp.acquire_lock()
i = i + 1
U.append(temp)
self.output_queue = output_queue
mean, sigma = np.mean(a), np.std(a)
firstzero = (FS[:, (0)] == 0).sum()
lst.append(el)
df_bad_idea
y - x if y > x else 0
x.shape = x.shape[0], -1
d, f = os.path.split(os.path.abspath(__file__))
b = list(b)
c.append(i)
self.trd.start()
os.chdir(curpath)
line(5, 10, 20, finish=True).take(inf)
count = count + 1
m4 = deepcopy(mat)
test
a(0, 5)(0, 1)
base ** power == num
root = tree.getroot()
True
self.__ntrue += 1
f[4:10, ::-1, ...]
serving_url = models.URLField()
{0},
iters = [list(range(i, 5)) for i in range(4)]
v = self.value // 2
self.zip.close()
tornado.autoreload.start()
word = word.Documents.Open(doc_path)
output_dict.setdefault(key, []).append(value)
adate
app = Flask(__name__)
fields.GenericRelation(Faves)
print(cur.description)
index[s_word] = index.get(s_word, []) + [word]
print(test)
result = []
mats.append(mat)
session = tf.InteractiveSession()
infile.seek(chunk_end)
m_text = ndb.TextProperty()
print(df)
print(result)
self.con.connect()
endings = [v[len(root):] for v in hablar.values()]
it = iter(items)
DictAdditionalValueWrapper(d, self.specialKey, self.specialValue)
df.iloc[0, 0] = 99
array_crator(a, (9, 17))
values = {k: item[k] for k in sum_value_keys}
response.set_data(minify(response.get_data(as_text=True)))
cap = cv2.VideoCapture(input_rtsp)
pickle.dumps(d)
columns = (a != 0).sum(0)
sorted(set(fill(m)))
x = A(1)
emp.user_permissions.add(permission)
p = c.getparent()
t = t[::-1]
clf.fit(data)
arr = np.delete(arr, 0, axis=0)
signals.post_save.connect(Revision().send_email, sender=Revision)
x = np.linspace(0, 4 * np.pi, 100)
raise DistributionNotFound(req)
thread.put_message(message)
hcpv = np.array([[cpt_hcpv(p, s, poro, sw) for p, s in r] for r in g_arr])
frame.pack()
bool({})
print(df_resampled)
result = Markup(result)
X_centered = X - np.mean(X, axis=0)
print(words)
stringValue = lst[1]
th.start()
out.append(cust + sub[0])
p = set(x + y for x, y in combinations_with_replacement(listgen(), 2))
indices = [list1.index(c) for c in list2b]
offset_y = lambda xy: (xy[0], xy[1] - 0.5)
sum(x) / l, sum(y) / l
surface.write_to_png(buffer)
run_thread = Thread(target=run, args=(args.arg1, args.arg2))
do_stuff(e)
os.execv(path_to_executable, args)
out = []
BadRows.add(rowID)
dirname, filename = os.path.split(filename)
dtype = data.dtype
test_module_n.py
excluded_numbers.add(a[j])
ts = time_uuid.TimeUUID(bytes=my_uuid.bytes).get_timestamp()
k, v = line.split()
logger.addHandler(handler)
self.listOfVideo = []
p, k = Phi.shape
sorted(data, key=len, reverse=True)
deleteSOME_VARIABLE[:]
np.array([ax2_cid[axs] for axs in x2_Kaxs_1.flat], dtype=object).shape
alpha.paste(circle.crop((rad, 0, rad * 2, rad)), (w - rad, 0))
final_str
plt.axvline(mode)
print(df)
self.event.wait(1)
print(out)
dist.append(d)
socket.send(txt)
page_obj
relationships = docx.relationshiplist()
start_time = time.time()
lens = np.array([len(item) for item in v])
r = [False, True] * (n // 2) + [True]
n, d = expr.as_numer_denom()
locale.nl_langinfo(locale.DAY_1 + x)
newfiles = check_for_new_files()
f.write(data)
print(i)
ch.setLevel(logging.ERROR)
sys.exit(1)
self.insert(len(self), value)
states = [0, 2]
self[k] = data[k]
print(min(s), min(s, key=str.lower))
output
bins.values.codes
reply = error.fp.read()
inactive_objects = models.Manager()
elapsed_time = time.time() - start_time
parser.parse(input, tokenfunc=get_token, debug=0)
results[-1] = letter, results[-1][1] + 1
self.choice
result
main_group = parser.add_mutually_exclusive_group()
ordered = [h for h in tails if h not in num_heads]
max(t for t in sorted(hours) if t <= now)
a = Foo()
population.difference_update(some_list)
module_ok = True
downloaded += q.get()
idxs = (rising | falling).nonzero()[0]
print(df)
A + ones((4, 1))
print(res)
a.y = 2
http = credentials.authorize(http)
d = {}
os.write(fd, someStuff)
p.join()
iargs = iter(args)
proc = Process(target=make_flaky_call, args=(q,))
cursor = connection.cursor()
cls._osx_get_modes()
self.callback()
c = np.array((-1, -1))
time = 0
logging_handler_err = logging.StreamHandler(sys.stderr)
x2 = max(x_normalised) + 1
sys.stdout.write(frm.tostring())
self.data = self.default_data() if data is SENTINEL else data
print(b)
False
A[1] = previous_A[0]
rlappend(theDict[listItem])
a = 0.0
diff = len(list1) - len(list2)
row = []
arr2 = array[split_idx:, :]
answer[pk][sk] = L[i][1]
cursor.execute(query)
print(var1 + var2)
self.trayIcon.show()
csv_writer = csv.writer(output)
()
keys = random.sample(list(d), 10)
Y = np.array([2, 0, 1, 1])
self.verify()
hist = pd.Series(y, x)
results = {}
email = db.Column(db.String(120), unique=True)
vertices = numpy.empty(1000, dtype=vertex_dtype)
stdout = StdOut()
json_posts = json.dumps(list(posts))
Z = X.copy()
last_line = get_last_lineprocessed()
todayDate = datetime.date.today()
100 * self.h
item.pk, item.__unicode__()
b = a.reshape((5, 10))
h
basename = os.path.basename(pathname)
threading.Thread(target=input_func, args=(p, lq)).start()
numpy.lib.stride_tricks.as_strided(stacked, shape, strides)
mat = ax.matshow(a, cmap=cmap, vmin=-1, vmax=N - 1)
bot = ttk.Treeview(Tkinter.Tk())
points_left = np.copy(points_center)
self.assertEqual(mocked.yeah_im_not_going_to_run.call_count, 1)
trglen = len(trgtext)
temp.append((v[2],))
outproj = osr.SpatialReference()
random.shuffle(start)
url_dict
self.x = x
last = item[1]
cache[hash] = object_to_cache
location = models.ForeignKey(Location)
index += 1
strcpy(greeting, hello)
COMMENT
frame = previous_trace[0]
answer.add(r)
print(avgs)
i += 1
new_x = new_x.ravel()
r.__init__(cols)
numbers = iter(list(range(10)))
id(True)
counter = Counter(s)
key = max(scores, key=scores.get)
fn, fext = os.path.splitext(f)
b = a[np.lexsort(a.T)]
config = ConfigParser.ConfigParser()
seconds = (now - midnight).seconds
ic = ic.filter(ImageFilter.BLUR)
zs = np.array([f(x, y) for x, y in zip(np.ravel(X), np.ravel(Y))])
start += 1
conn.close()
print ()
assert not p.poll()
results = Pool.map(do_work2, arglist)
pos = np.where(np.diff(mask))[0] + 1
print(module_name)
sp = nx.shortest_path(G, (0, 0), (9, 9))
method_to_be_executed_in_case_of_exception_or_pk_is_false()
value = models.FloatField()
[]
ff.seek(-7, 1)
b if a else c
cls._threadmap[thread.get_ident()]
response
args = parser.parse_args()
S = pd.to_datetime(df.dt)
a = A()
r_avg = sum(r_vals) / len(r_vals)
namespace.clear()
self.data = data
count += 1
insert_ids = []
print((test, lookup[test]))
horse
gopher
np.__version__
stdout_output = proc.communicate(script)[0]
original_save(self, *a, **kw)
tmpdir = tempfile.mkdtemp()
shift += len(result) - sigfig
pl.figure(figsize=(7, 7))
dicC = dicA.copy()
obj = A.__new__(cls, data)
crypts.append(mask)
x, y = y, x + y
text2html(self.description)
pid = os.fork()
s = np.vstack([np.zeros((1, v.shape[1])), v.cumsum(0)])
sys.path = oldpath
db.session.add(admin)
header = my_dataframe[[i]].astype(str).columns.values
start = a.index(item, start + 1)
next(line_iter)
min_dist[i] = np.min([point.distance(line) for line in lines])
pos_a, pos_b, size = s.find_longest_match(0, len(s1), 0, len(s2))
1 + 2
my_func()
y = tf.nn.softmax(tf.matmul(x, W) + b)
z = exp(x)
axs[1].plot(days, np.random.random(len(days)))
file2freq[c, d] += 1
cout[:, (-1)] = 0
out = numpy.empty(rows * cols, dtype=broadcasted[0].dtype)
res = res.reset_index()
subtree = dict((n, [n]) for n in leaves)
files = os.listdir(dir)
print(list(literal_eval(line)))
gmm.delta += 1
word[start:stop:step]
buf = in_file.readlines()
rect(names, names, 0.9, 0.9, color=some_colors, x_range=names, y_range=names)
executor.submit(call, cmd, stdout=outputfile, stderr=STDOUT)
clf.tree_.children_right
v.f2()
top.mainloop
writer.newLine()
clf.tree_.children_left
sorted_records_array = records_array[idx_sort]
distance = [[[0] * n] * n] * n
firefox = webdriver.Firefox()
init_logging()
a = gen()
mov_avg = np.bincount(_, weights=avg_val.ravel())
seconds, minutes = math.modf(item[2])
full_arr = full_arr[sort_idx]
a = [1, 9, 12]
lines = []
_cache[key]
buffer = StringIO.StringIO()
app = Flask(__name__)
learner.train(features, labels)
out
item = L[i]
fig = pylab.figure()
fig = plt.figure()
c = np.concatenate((a, b))
y.byteswap()
grp = (isone != idx.to_series().diff().eq(1)).cumsum()
smudge_filter_openssl
readline.read_history_file(historyPath)
net.reset()
os.read(self.STDIN_FILENO, 4096)
print(inner)
rotatedRect.points(rect_points)
ax1 = fig.add_subplot(111)
objects = SoftDeleteManager()
iter(self._s)
results = []
raise StopIteration
my_dict = dict(zip(b, list(range(len(b)))))
value
ipython
yertle.goto(point)
print(time.ctime(future))
count = count + 1
bucket_list = bucket.list()
digits = [int(i) for i in str(input)]
print(n)
my_app = Flask(__name__)
value
last_name = CharField()
i += 1
Depends(test, main)
print(s.recvfrom(65565))
synsets.append(wn.synsets(lemma, pos=wn_tag)[0])
self.treeview = gtk.TreeView(self.tree_filter)
[0, 1] < 2
app = QApplication(sys.argv)
U[U < 2] = np.nan
url_rule = request_ctx.request.url_rule
extra_compile_args = []
r = requests.get(source)
a_map[A_object.string] = A_object
draw()
optionN
print(clf.components_[(1), :])
print(sheet_rect.height, sheet_rect.width)
abs(area / 2.0)
donecounter = 0
[]
x = A.tocoo()
container[index]
dyncodes = query.fetch(1)
keys.extend(key_list)
[]
tar.add(full_dir)
SystemTime = SYSTEMTIME()
profile = webdriver.FirefoxProfile()
show()
rows.loc[rows.time > first_purchase_time]
print(np.allclose(original(a), mean_around(a)))
r[4::2] = [False] * ((n + 1) / 2 - 2)
sleep(5)
lon2 = loc2[0]
v2 = np.concatenate((v, v))
x = x - f(x) / fprime(x)
t.create()
ans = network.receive()
grouped = frame.groupby(frame.columns[0])
__repr__ = lambda self: self._tuple.__repr__()
x, y = m(lons, lats)
long_path_name = buffer.value
plt.gca().add_artist(self)
frame.pack()
styles = getSampleStyleSheet()
array[np.arange(N), index]
d = d[col]
modules.append(imp.load_module(m, f, filename, desc))
setup.py
content_json = json.loads(r.content)
rows = csv.reader(infile)
get_user_model().objects.none()
idxInf = np.isnan(a[item]).nonzero()
out.release()
Gvalue = someoperation(Gnodes)
exit(2)
n, m = np.meshgrid(x, y)
tmp = tempfile.NamedTemporaryFile(delete=False)
len(solns7)
reader = avro.datafile.DataFileReader(input, avro.io.DatumReader())
eval(expr)
r2 = list(range(0, end_day + 1))
self.do_template_based_capitalization(mapping)
locs, labels = mpl.xticks(xt, vWidth, fontsize=9)
g[a == 0] = 255
p.map(walk, [0] * 10)
id = serializers.UUIDField()
histogram()
type(pdsDF)
pub_dict = {}
res_females = pool.map_async(fun_f, females)
creative_url = models.URLField(max_length=200)
l2.sort()
obj = {}
m[np.isnan(m)] = m.T[np.isnan(m)]
np.r_[1:10, (15), (17), 50:100]
[tox]
fs, in_data = wavf.read(in_wav)
decoded
f = open(filename)
output = []
self._lock.release()
pix = QtGui.QPixmap.fromImage(img)
(14, [2, 7]),
ws = wb.active
https_request = http_request
topic_bundles.append(bundle)
something_awesome()
q, r
plaintext
arr = img.load()
ranked = []
keys = list(dict.keys())
output, err = process.communicate()
len(bytes)
message = e.args[0]
map(accumulate, list(range(20)))
merged.append(x)
d = collections.defaultdict(int)
file_list.append([i, time.ctime(a.st_atime), time.ctime(a.st_ctime)])
+webapps
_iterencode(o, 0)
pager(ofh.read())
fd = msvcrt.open_osfhandle(handle.value, 0)
False
Main()
a = np.arange(100)
self.items.append(item)
self._val
q75, q25 = np.percentile(x, [75, 25])
qs_sorted = list()
fig, ax = plt.subplots()
myserializer
newdata = obfuscate(data).decode()
root = Tk()
rf.fit(X, y)
print(d)
zipfile1.writestr(zipi, filedata)
idx = b.index.union(a.index)
g = gen()
x = sum_list[:i + 1]
new_stepListA.append(pathList[n][0])
d = hashlib.md5()
img_thresholded = cv2.inRange(img, (60, 60, 60), (140, 140, 140))
sizer.Add(btn, 0, wx.ALL | wx.CENTER, 5)
bar()
typeB = acc.accounttypeB
client = MongoClient()
im
getattr(self.original, name)
indc = np.where(np.all(arr == 0, axis=0))[0]
asyncio.set_event_loop(loop)
json.JSONEncoder.default(self, obj)
print(output)
self.x_values = np.asarray(list(xdict.keys()))
cols = list(df.columns)
self.my_enter()
queryset = User.objects.all()
value = self._variable
vscrollbar.config(command=canvas.yview)
plt.title(title)
print(list(split_text(c)))
args.sort()
OriginalShared(target, source, env)
divider = make_axes_locatable(ax)
x = NP.linspace(0, 1, n)
t2 = lambda : list(map(str.strip, hello))
b, c = (a,), (a,)
brown_count = len(set(list_of_brown_items).difference(list_of_all_items))
i = next(matches, 0)
key = self._redis_key()
lis = list(range(1, 11))
a[ix] += values[i]
k.tap_key(k.tab_key)
self.download_image(self.creative_url)
node.parents.add(prev_node)
dataset_array.append(item)
prevMatrix = matrixDict[thisC.index(max(thisC))]
prevMatrix = matrixDict[thisR.index(max(thisR))]
self.queue = queue
results = list(pool.imap_unordered(foo_pool, list(range(10))))
2 * x
pygame.init()
my_class = example.MyClass()
narrow = wide
lists = [list_a, list_b, list_c, list_d, list_e]
s = pd.Series(np.arange(len(df)), index=df.time)
__setattr__ = dict.__setitem__
analyzer = vect.build_analyzer()
c = SomeClass(5)
x = np.random.random(50)
data = np.asarray(img.getdata()).reshape(img.size)
fp.close()
attr = getattr(cls, name)
ax = plt.gca()
port = 8080
B = 2
self.n = n
d = np.diag(a.A1)
ret, frame = cap.read()
Xtest = vect.transform(new_documents)
object.__le__(self, other)
Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
{{set_foo_is_true(local_vars)}}
bad.getparent().remove(bad)
set(string) >= set(substring)
app = Flask(__name__)
print(data)
do_something(obj)
list(find_consecutive(my_list, 1.0))
handler = logging.StreamHandler(log)
current = time.time()
my_data = []
show(pie_chart)
args = self.__build_command__(cmd)
C[:] = np.dot(A, B)
data = yaml.safe_load(f)
fn()
df
df[df.C > df.C.mean()]
result
self.send_header(k, v)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
g.ax_marg_y.legend_.remove()
wx.EVT_BUTTON(self, b.GetId(), self.OnDaemonize)
circle(res, center, radius, color, 5)
str(num) == str(num)[::-1]
{{usercontent.thing_b}}
output = [0] * len(x)
self.queue.put_nowait(result)
notifier.loop()
letters = list(string.ascii_letters)
data_cluster = KMeans(n_clusters=5)
print(new_grammar.productions()[2091])
on_done()
row[8] = row[8][:-1]
X, Y = np.meshgrid(xi, yi)
print(i)
put = deepcopy(tup)
len(brown_tagged_sents)
dict.update({cut2: x})
print(len(path), len(path_ext))
clientSocket.noTcpDelay(true)
data = urllib.parse.urlencode(values)
httpretty.enable()
len(self.getData())
i += 1
body = doc.xpath(path)[0]
clf.fit(yourdata)
cmath.sqrt(0j) == 0j
length = len(sublist)
asciiz_start = struct.calcsize(format[:pos])
self.keep_interrupt = True
id | name
xy = 50 * np.random.random((num, 2))
end = len(array) - 1
n = n - 1
r = s.send(p)
i += 1
self.format(*other)
result_df
PAGE_HEIGHT = defaultPageSize[1]
print(line)
rowconvol = a[1:-1, :] + a[:-2, :] + a[2:, :]
x = math.radians(i) * math.cos(math.radians(i))
page2 = input2.getPage(0).rotateCounterClockwise(90)
np.prod(x.shape) * x.itemsize
result = set(elements)
info = os.stat(filename)
res = scipy.integrate.quad(integrand, 0.0, math.pi, [w, p])
printByLine(countsSortedAlphabetically(words, reverse=True))
HELP, DESK - IT - Support
area = SelectField(coerce=int)
dict
csv_writer = csv.writer(testfile)
5, 6, 7
D[n, s, x]
p = abs(scipy.stats.norm.ppf((1 - pred_error_level) / 2))
r = random.uniform(r1, r2)
result = list(flatten(data))
wr = w.rowsBetween(-sys.maxsize, -1)
expr.integrate((x, -s.pi, s.pi), (y, -s.pi, s.pi))
time = time.strftime(DATETIME_FORMAT)
mysocket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
base = get_datetime(base_date)
answer = [[(2 * el) for el in sublist] for sublist in L]
ins = example.insert().values(expire=tomorrow)
len(self.m)
t = time()
seen.add(t)
reversed = line[::-1]
widemap = dict((ord(x[0]), x[1]) for x in zip(normal, wide))
value = get_array(value)
print(dwarf)
b = b[~np.isnan(a)].astype(int)
obj = SomeClass()
f.__name__
print(t)
BOOST_PYTHON_MODULE(hello)
http = credentials.authorize(httplib2.Http())
n, bins = [], []
write(n, pos + 1, op, cl + 1)
print(2, time.time())
_tester
self._od = collections.OrderedDict().fromkeys(values)
bp = plt.boxplot(data, whis=[5, 95], showfliers=True)
avg_dists = numpy.average(dists)
sio.seek(0)
height = t.winfo_height()
collatz(number)
l = len(rearranged_data)
t /= np.linalg.norm(t)
print(config_root.server.port)
start_urls, extra_domains, regexes
exceptionArchive.write(newData)
print(config[0].expiration)
aa = json.loads(j, object_hook=Struct)
set_success()
a = b
B = np.random.randint(M, size=N)
print(item_due.item.ref_id)
some_node = tree.getroot().getchildren()[1]
dialog.destroy()
print(mytext.capitalize())
fig, axs = plt.subplots(len(areas), 1, figsize=(5, 45))
h.funcA()
library.remove(self)
Session = sessionmaker(bind=engine)
self.active_writer_lock.release()
frameH = 256
combination[p:] = list(range(combination[p] + 1, combination[p] + 2 * (r - p), 2))
p = len(prefix)
d[1] = c
num = sorted([int(eval(input())) for i in range(0, n)])
successed = 0
unique_.append(sub.tolist())
frames.append(data)
y = scipy.real(scipy.ifft(Y))
counter = collections.Counter()
traceLock.Unlock()
locest = optimize.fmin(pareto_ks, rvsmin * 0.7, (rvs,))
print(id(item))
self.q.put(item, block=True)
queryset = User.objects.all()
UserList.UserList.__getitem__(self, idx)
logging.setLoggerClass(MyLogger)
connection = pool.get_connection(command_name, **options)
deletemyResult[:]
r, g, b
self.record = {}
axis = [4, 4, 1]
self.database[name] = old_value
sentence = f.readline()
views.py
self.p *= 1 - regularization
layout = bokeh.layouts.gridplot([[p], [color_select]])
cur.close()
i += 4
mod1 = load_module(name, *foundmod)
dis.dis(Binary)
pygame.display.set_mode.__doc__
a = MyClass(7)
reader = csv.reader(lines.splitlines())
main.object1[1]
Excel.Quit()
p = psutil.Process(os.getpid())
counts[x] += 1
takefrom.difference_update(s)
item = yourList[i]
order_expressions = [(Company.id == i).desc() for i in company_ids]
a_sum = np.sum(a, axis=0)
C = C.reshape(-1, 4)
process_request()
order = np.abs(np.int(order))
args[key] = value
print(row)
name = name.strip()
form.process()
ukol1.SummaryFormula(someSummaryFormula)
background_label = Label(top, image=filename)
x, y = np.random.random((2, 1000))
print(module.__file__)
nonZeroRows = (ANOVAInputMatrixValuesArray != 0).sum(1)
token
-sum(map(sum, self.a))
root.mainloop()
size = struct.calcsize(fmt)
subjects = dict()
znylpx
c.foo
bytes = map(ord, reversed(value))
form = TeamForm(request.POST, obj=team)
ml.append(i)
levels = np.array([p10, p50, p90])
n = 10
pickle.loads(pickled_value)
keys = []
LR.fit(X2[:half], y2[:half])
deleteself.obj_
root, infodict, ier, mesg = optimize.fsolve(pdiff, val, full_output=True)
options, args = parser.parse_args()
line = process.stdout.readline()
resized_file.save(file_bytes, **save_opts)
tunnel._lport
[(a + d) for a, _, _, d, _ in fiveTuples]
a * 2
{k: [convert(i) for i in v]}
Py_INCREF(pMyException)
i, i + len(small) - 1
os.makedirs(dir)
out.close()
make_random(someArr)
multiply(a.ravel()[:, (newaxis)], b.ravel()[(newaxis), :], out)
[head] + novowel(tail)
outputmapping
d2_dict = defaultdict(dict)
foo = pickle.load(f)
print(deriv_list)
print(un[cnt == cnt.max()])
r = [True] * n
dirname(parse_object.path)
myvalue = eval(name)
map(alpha_getter, image.getdata())
r
value1, value2
print(len(G))
(self.end or datetime.now()) - self.start
confirmation_message = _(msg_template).format(order)
pool.close()
m = re.match(p1, statement)
Wrapper()
my_list.sort()
temp.paste(image)
result = []
level += 1
l = [0] * 4
self.listWidget.addItem(item)
self._n_weights
[5, 6, 7, 8, 9],
children.append(node.kwargs)
print(x / y)
x = 255
pd.concat(retLst)
form = ItemAddForm
c.perform()
sys.argv[-1:] = glob.glob(sys.argv[-1])
dfnum = df._get_numeric_data()
align_arrays(b)
parent.remove(child)
array(a, dtype, copy=False, order=order)
windows = []
print(magicList)
output = []
d = np.zeros(N)
i = len(a) - 2
C()[1] = 0
self.reporter.on_close(self.stats, previous_stats)
sum(x, dtype=float64)
path = path.replace(os.altsep, os.sep)
time.sleep(5)
atexit.register(self._exit)
input[mask]
dis.dis(a)
c.method_a()
self.var_a = 2
f(*args, **kwargs)
appstats_LOCK_TIMEOUT = 1
x = arange(0, 2 * pi, 0.01)
{{my_json}}
print(name)
self.__dict__[decorator.name]
drops = (N == np.diag(N)).sum(axis=0) > 1
print(canvas.max())
columns = [column[0] for column in cursor.description]
df
True
fraction.setParseAction(lambda t: t.numerator / t.denominator)
reducedQs = self.get_query_set()
pickle.dumps(d, -1)
frm.Show()
names.append(row[0])
d = datetime.date.today()
len(results) == len(letter_pattern)
closedir.argtypes = [c_dir_p]
arr
[-0.5, 0.0, 0.5, 0.0],
fig = plt.figure()
self._normalized
cols = []
default()
nd = numpy.array([-d[1], d[0]])
hs.close()
self.combo()
wx.ListCtrl.__init__(self, parent, style=wx.LC_REPORT)
np.dot(inv_A, b)
line = f.readline()
ax.plot(xvals, yvals)
print()
seconds += 1
n = int(round(error / 0.01))
plot(draw, img, xpxl1, ypxl1, rfpart(yend) * xgap, col, steep, dash_interval)
self.args = kwargs
wrapped
event.widget.config(bg=color)
immutable = frozenset(list(mutabledict.items()))
counts = np.sin(np.linspace(0, np.pi, dates.size))
pdf_contents = get_pdf_contents()
False
browser = selenium.webdriver.Firefox(profile)
print(root.height())
print(foo.T)
result_array = result[0]
date_tuple = email.utils.parsedate_tz(date_str)
A = np.expand_dims(A, x)
temp_n += 1
description = db.StringProperty(multiline=True)
result.append(current[:markerpos])
img = ImageGrab.grab()
dir(builtins)
a.binaries,
attributes = [n for n in directory if not callable(getattr(cls, n))]
self.obj[frozenset((idx,))] = value
y_data = x_data.dot(w).reshape((-1, 1))
text
m = np.exp(mu + sigma ** 2 / 2.0)
add_job_callback()
assert m[1, 0, 2] == 100
items.append(item)
df1.columns = df1.columns.format()
weekday = current_date.weekday()
d = np.diff(a.flat[i])
-1
self.fileTextCtrl.SetInsertionPointEnd()
bin_ += 1
a = set()
message.send()
searchB.update()
[4.0],
t1 = time.clock()
next(filter(my_criteria, e))
result = expression.subs(symbols_vals)
f = opener.open(req)
xybad = np.array((x[a.mask], y[a.mask])).T
mp.freeze_support()
time.sleep(5)
raise je
queue.put(result)
client = Client(url)
print(path_list)
(forms.BaseForm,),
raw.append(str(mod.__dict__[key]))
mandel_surface.set_at((x, y), color)
parentclass.__init__(self, *args, **kw)
fig = plt.figure()
temp = []
M = V.reshape(n, 1, p) * V.reshape(1, n, p) * F.reshape(n, n, 1)
size = os.fstat(f.fileno()).st_size
has_unknown_fields = set(attrs.keys()) - set(self.fields.keys())
socket.setdefaulttimeout(5.0)
profile = cProfile.Profile()
word, count = line.split()
print(data)
r = f(i)
self.name = name
wts = (c_double * n)(1, 1, 1)
item
reader = csv.reader(open(parameters_file), dialect)
mean = cv2.mean(roi, mask=mask)
B[1:2] = C
output_list.append(list(record.values())[0])
self.start()
null_ptr[0]
self = cls()
0, subset1, subset2
old_stdout = sys.stdout
n = 0
file_ptr.close()
print(testclass_instance.name)
character = myscene.GetCharacter(i)
x = np.linspace(0, 1000, fs * 1000)
_NestedClassGetter(), (ParentClass, self.__class__.__name__), state
x = np.ma.array(x, mask=y == 0)
unittest.main()
course_id = forms.IntegerField()
patches[0]
spot_id = c.lastrowid
print(self.size)
print(result)
print(self.obj.name)
colidx, colslice = slice(colidx, colidx + 1), False
signed_url
rowidx, rowslice = slice(rowidx, rowidx + 1), False
5
z.write(absfn, zfn)
a / b
menu = QtGui.QMenu(parent)
foo = True
sleep(1.0 / 25)
df
od = OrderedDict(items)
reversed = line[::-1]
application.manager.run()
5 - +-+-+2
name = sa.Column(sa.String(50))
xv, yv = np.meshgrid(x, y)
logger = logging.getLogger(__name__)
op1, op2 = int(op1), int(op2)
testtest
embedded_func()
raise StopIteration
assert n > 0
UNION
form = ModelForm(request.POST, request.FILES)
req = urllib.request.Request(url)
print(sys.maxsize)
dump_cell(sheet, rowx, colx)
line_number = traceback.extract_tb(tb)[-1][1]
my_RDD_strings = sc.textFile(path_to_dir_with_JSON_files)
setattr(related_item, fk_field, obj)
redirect_to_login(path, login_url, redirect_field_name)
druhy = col[1].string.strip()
attrs
self.rules = {}
axs[1, 1].imshow(im)
list(slot_combinations(A, B))
abe
q.join()
method(self, *args, **kwargs)
ostream.write(*another_objects_list)
src.load()
exit(-1)
loop.run_until_complete(run())
Foo()
resultset = [dict(row) for row in res]
img = img_as_float(data.camera())
print(a)
sys.exit(1)
cython_module2.pyx
path = chg.path.slice()
integer = int(totPrimes)
preverifyOK
any(map(sb.__contains__, a))
service_id, monday, tuesday, wednesday, thursday, friday, saturday, sunday, start_date, end_date
original = Image.open(original_path)
curve = np.zeros((num, 2))
end_of_leader = s.index(leader) + len(leader)
hell
loy
ow
owe
ye
x = np.linspace(F_values_2[0], F_values_2[-1], 100)
n = len(L) - 1
result = cursor.fetchone()
ast.literal_eval(s)
start = pyqtSignal(str)
ctypes.memset(id(a) + offset, 0, bufsize)
trace_call()
asyncio.run_until_complete(mock())
i = 5
print(df1)
objworkbook.SaveAs(os.path.join(conv_scripts_dir, file_name))
ax = plt.gca()
parent[:] = sorted(parent, key=lambda x: x.tag)
self.mainLayout = QtGui.QVBoxLayout(self)
a.py
child = sp.Popen(openRTSP + opts.split(), stdout=sp.PIPE)
today - margin <= datetime.date(2011, 1, 15) <= today + margin
fr1.index = fr1.index.droplevel(0)
a, b = tee(iterable)
atexit.register(readline.write_history_file, histfile)
f(*args, **kw)
bar()
ax.add_line(line)
a, b = [1, 2]
self.flush()
horizonPlot(xx, yy)
grid.Add(self.figure, flag=wx.EXPAND)
str.__init__(self, s)
p = cs.collections[0].get_paths()[0]
repo.heads[branch].checkout()
row.delete()
n_b = a.shape[0] + len(index)
[t for t in tokens if t.lower() not in stopwords]
print(lcl)
print(results)
main(sys.argv)
pid = getmypid()
hrow = next(reader)
a = wait.until(EC.text_to_be_present_in_element(By.YourBy))
plt.xlim(0, 20)
a.keys() & b
the_data = request.get_json()
d[2] = c
self.totalsize = os.path.getsize(filename)
tally[elem] += 1
size = self.GetSize()
fis = np.concatenate((np.linspace(-np.pi, np.pi, 100), [np.nan]))
p = Process(target=func, args=args, kwargs=kwargs)
times = arange(0, 4, sample_rate)
today = pd.datetime.today().date()
z2 = tf.add(rand_var_1, rand_var_2)
help(math.ceil)
a.method()
print(t._size())
p.setColor(w.backgroundRole(), Qt.red)
26.0
g_filter = np.exp(-grid) / (2 * np.pi * sigma ** 2)
OPTION_B = 2
self.assertTrue(isinstance(user.username, iunicode))
df > 16
cond_im[1:-1, 1:-1] = cond
eq = Eq(Derivative(p(t), t), -a * p(t) + exp(-(a + b) * t))
c = Cheese()
self.stdout = stdout
True
out.append(x)
exp(1e-05) - 1
score = 0
print(max_times)
r2 = range(1, len(r) + 1)
print(mult.multiply_(byref(a), byref(b)))
time_in_miliseconds = int(time_in_seconds * 1000)
QtGui.QDirModel.data(self, index, role)
req = QtNetwork.QNetworkRequest()
result[I] = v1[I]
0
A /= A.std()
[time.ctime(float(x)) for x in string_list]
h = httplib.HTTPConnection(parsed.netloc)
consumed += i
max(new)
f4 = bytes_to_int(f4)
stuff()
length = arr_view.shape[0]
p = mp.Process(target=count, kwargs=d)
a = 5
c = np.any(img, axis=(0, 2))
exit(0)
i = random.choice(index)
L.append(L.popleft())
df
a = p.abspath(somepath)
queryset = User.objects.all()
print(i)
set(nltk.wordpunct_tokenize(strin)).difference(sw)
r.text
ax.stackplot(x, percent)
self._instance = instance
loop = asyncio.new_event_loop()
self.save()
results_q.put(ip)
sidx = a.argsort()
columns_to_keep.append(i)
JM2[(ii), (ii), :] = 0
dstdraw.polygon(dst_tri, fill=(255, 255, 255))
words = set(fp.read().split())
filler = string2[-1] if len(string1) > len(string2) else string1[-1]
instance.type = fkey
print(cursor.description)
time.sleep(5)
rows = []
results.append(obj[0])
c.append(f)
newEl = random.choice(l)
DELIMITER
groups = itertools.groupby(lst, lambda i: i[0])
xx = np.hstack([-1 * x[::-1], x])
result_s += to_len
der = f.read()
set.union(*list(dd.values()))
result[i, j] = data
x[k] = multi_level_dict(*args[1:])
self.weights = weights
screenshot.show()
line = pipe.readline()
foobar(p, x - y, baz())
x[nonzero] /= norms[nonzero]
dom.append(label)
end_date = start_date + relativedelta(days=1)
timeout_handler()
id_ = sqlalchemy.Column(sqlalchemy.Integer, primary_key=True)
filenames.sort(key=os.path.normcase)
df.drop(list_of_values)
self.documents[i].setDocumentMargin(0)
url = unquote(url)
L = L[:start] + L[end:]
ar.append(value)
False
x
a = Decimal(2)
A.method()
replacement.join(source.rsplit(target, replacements))
atexit.register(save_history)
t.trundle()
lst = [A, B, C]
xchunk_gen = (x[i:i + chunk_size] for i in range(0, len(x), chunk_size))
sgn * math.floor(abs(n) * factor) / factor
st = inspect.stack()[1]
solution_sets.append(set(new_solution))
birdsRemain -= 1
serializer_class = SubscriptionSerializer
xaxis = np.linspace(0, 4, 10)
arr = np.array(img)
line = fin.readline()
print(df2)
doSomething()
image1 = models.ImageField(upload_to=images)
dns_server = sys.argv[2]
i
old_modules[name] = sys.modules.pop(name)
maskleft = np.where(np.isnan(a))[0]
output = id_arr.cumsum()
decorator
dictonary[k] = [i]
rows.append(row)
mommy + daddy
x = x.reshape(1, numCols)
p1 = perm1[loc]
sys.stdout = flushfile(sys.stdout)
pool.close()
out += arr[1:-1, 2:]
b = random.randint(0, 255)
FACTORY_FOR = Post
extractDefines(TEST1)
deleteself.thisptr
conmut = (a, b), (b, a)
result = set()
minimum + (maximum - minimum) * random.random()
data = np.hstack((xData, yData))
y_test
arr_win[:, (0)] = arr_cum[:, (n - 1)]
index
train_op = control_flow_ops.with_dependencies([train_op], total_loss)
print(l)
[item for item in l if not set(item).difference(s)]
application = webapp2.WSGIApplication(routes, config=_config, debug=DEBUG)
func
B = np.random.rand(N, N, N)
plt.plot(new_x, new_y)
blob_info = blobstore.get(blob_key)
print(entry.title.text, entry.GetSelfLink().href)
previous_value = value
print(self.x)
df = df.stack().to_frame()
int(value) / int(arg)
choices = tuple(User.objects.all().values_list())
print(a)
BUFFER_SIZE = 500
new_array = map(lambda x: abs(x - some_value), my_array)
res
stack = []
B = np.arange(N)
points.update()
data = np.exp(-(X / 80.0) ** 2 - (Y / 80.0) ** 2)
a % 1
spotify.stop()
print(s, file=p.stdin)
r, w = os.pipe()
x[k] = v
idx = np.hstack((0, diff_idx, b.shape[0]))
assert desired.issubset(superset)
poly = Polygon([(0, 0), (2, 8), (14, 10), (6, 1)])
setup(install_requires=install_requires)
line = line.strip()
current_time = timezone.now()
df
start = time.time()
max_key = max(max_key, key)
without_punctuation = map(strip_punctuation, input_data)
plt.text(4, 400 - 80 * il, l)
t.join()
self._x = self.x = x
assert new_result, same_a_different_b
df
memdb.brpop(self.finished_prop)
new_df = pd.concat([df, another_df], axis=1)
ext_modules = []
args = parser.parse_args()
xi = np.array([0.2, 0.5, 0.7, 0.9])
c.insert(c.end(), a.begin(), a.end())
d[key] = list(group)
textplot(x ** 2, 0, 5)
shape = total_length / size, size
to_remove = list(d.keys())[500:]
testing = data[5:]
print(l)
addr = ctypes.addressof(Data.contents)
assert np.all(answer == result)
endif
stream.stop_stream()
labeled = [classify(model, features_for(u)) for u in unlabeled]
conn.executescript(script)
gcs_file_name = gcs_data.gcs_write_blob(dyn, field_storage.file.read())
print(x)
self.ax = ax
buffer.append(line)
OverlayImporter()
True
objs = []
d[t] = 11
print(powercheck(lst))
lines = lines[19:52]
list(reversed(a[2:4]))
print(s.recv(8192))
self.assertTrue(filecmp.cmp(path1, path2))
0
result = []
comb(a, b)
fly.rect.right = hit.rect.left
[term_appearance.update(x) for x in l]
count = random.randrange(1, 5)
out = seq[0:1]
n = randint(0, 2 ** (j - i))
z[ind] = (x + y)[ind]
testObj.quicktest(sys.argv)
p = bisect.bisect_left(fpr, thresh)
print(sizeof(mystruct))
new_list1 += [list1[i]]
f.seek(l, 1)
Global = global_injector()
server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
max(enumerate(accumulate(it), 1))
i += 1
newf
foo, bar = cur.fetchone()
mydict = {}
i_max = len(lst)
onerror(os.listdir, path, sys.exc_info())
time.sleep(threading.currentThread().mytimeout)
index = slice(0, 2)
db.put(DB_TempTestModel(data=lots_of_data))
d = {}
time.sleep(random.randint(0, 50) / 10.0)
576
110011
111000
date(2015, 10, 7) - date(1, 1, 1)
quit()
l = list(a.values())
batcher_loop(queue)
handle = urllib.request.urlopen(req)
self.finditemprop = finditemprop
b = list(reversed(a[1:])) + a
print(A.todense())
print(value)
x = v()
loop = asyncio.get_event_loop()
q_out.put(val)
m.Test()
cluster.labels_
generating_random = true
image = pdb.gimp_file_load(file, file)
mpmath.exp(-1200)
print(response.read())
writer = csv.writer(outfile, quoting=False)
a = a + 1
x * x + x
rows = []
reactor.listenTCP(8000, factory)
img[:, :] = 128
df.d
resp
cursor2 = db.cursor()
self.signal = True
nodes.add(e)
plt.subplot(221)
settings = self.webview.getSettings()
np.random.seed(101)
sys.stdout = old
item.setCheckable(True)
pet_list
processes_to_kill.extend(subps)
tracefunc
d = defaultdict(list)
current[1] += 1
a.insert_node(a.root, 45)
s = list(s)
etree = ElementTree.ElementTree()
b = defaultdict(list)
hosts = sorted(set(list(scan0.keys()) + list(scan1.keys())))
edgePoint.x += self.bounds.size.width / 2.0 - self.center.x
cols = np.zeros((w, maxlabel), np.bool)
mainData_sheet = mainData_book.sheet_by_index(0)
args = [iter(iterable)] * n
x
iterator = IT.chain([item], iterator)
False or []
itteration = itteration + 1
flask.jsonify(exception=traceback.format_exc())
threads.append(threading.Thread(target=listen_to_audio))
pyplot.show()
samples_avg = [((s1 + s2) / 2) for s1, s2 in zip(samples1, samples2)]
sqs1 = sqs.filter(title_auto=q)
self.observer = Observer()
url[2] = urllib.parse.quote(url[2])
freq = collections.Counter()
tokens = [token.lower() for token in tokens if len(token) > 1]
df = pd.DataFrame(np.random.randn(100, 5))
()()()
count[x] -= 1
img[y][x][0] = r
mod_name, file_ext = os.path.splitext(os.path.split(filepath)[-1])
w = POP()
serializer_class = EstablecimientoSerializer
ax = plt.gca()
print(is_perfect_cube(-65))
y = np.random.randn(10, 1)
TestApp / LICENSE
-W15 - -ignore
dis.dis(f)
sets = (set(d.items()) for d in dicts)
result
self.null = True
t.join()
current.append(line)
Thread(target=self).start()
i.relationships
coord(self.x + c.x, self.y + c.y)
countup(n - 1)
cbegin() + size()
matches[0].ruleId, matches[0].replacements
view.openGLContext().makeCurrentContext()
keys.sort(key=StrictVersion)
result = {}
self.cursor.execute(arg1 if arg1 else arg0)
group_sizes = pd.Series(group_sizes)
cv2.waitKey(0)
Response(serializer.data, status=status.HTTP_201_CREATED)
new_user = authenticate(username=username, password=password)
x2.sort()
str2_list = list(str2)
current_user = word[:-1]
numpy.multiply(255.0 / (display_max - display_min), image_data, out=datab)
dirs[:] = []
ba.extend(writtenbytes)
b = b.ravel().view((np.str, b.itemsize * b.shape[1]))
plt.colorbar(sm)
ax = fig.add_subplot(111)
file_bytes = io.BytesIO()
type.__init__(cls, name, bases, cls_dict)
capitals_dict
self.__setattr__(name, value)
Jobs = pool.map_async(args)
d = OrderedDict()
d = defaultdict(int)
raise argparse.ArgumentTypeError(msg.format(arg, choices))
x[np.isinf(x)] = np.nan
diff = ImageChops.difference(a, b)
jsonObj = MessageToJson(org)
assert q.count()
line = sys.stdin.readline()
o1.one()
a[:] = b
counts = collections.Counter(x)
print(my_lst_str)
cr.move_to(x, y)
startDate = datetime(2011, 7, 7)
result = [[]]
result
l = len(min(dictionary[i], key=len))
118.9404
azel = np.asarray(azel)
rows_to_zero = np.random.choice(np.arange(rows), size=10000, replace=False)
self.output = asyncio.Queue()
_translation.gettext(s) % dict
pathA if sum(pathA) < sum(pathB) else pathB
stream.close()
elt.findall(get_tag_with_ns(tag_name, ns=ns))
arr_1[1::5] = 100
val
data_file.readline()
wall(0, 1)
self.optionmenu_a = tk.OptionMenu(self, self.variable_a, *list(self.dict.keys()))
a = np.random.normal(size=100)
process_thing(thing)
[tuple(lis[j] for lis in data) for j in range(min(len(l) for l in data))]
print(func.__doc__)
cursor.execute(query)
print(Foo.setUp.__code__.co_varnames)
i & 4294967295
shutil.rmtree(path_to_temporary_directory)
parent.remove(prop)
PYTHONUNBUFFERED = true
zeta = random.uniform(-1, 1, size=2 ** 24)
iN = mX.shape[0]
print(i)
seconds = 0
readline.read_history_file(histfile)
A[1][2][0].simplify()
-r[0][0], r[0][1], r[0][2]
[y for z in [([x] * x) for x in range(1, num + 1)] for y in z]
now = datetime.datetime.now()
self.lsi[self.tfidf[bow]]
set(literal_eval(lis))
tree.body[0].names[0].name
print(max_len)
print(a.help)
tt.listen()
address = models.CharField(max_length=1000)
m.captures
task_prerun.connect(_precalc_numbers, sender=tasks[PowerOfTwo.name])
out = vals.prod(1).reshape([gn] * n_dims)
self.loop = loop or asyncio.get_event_loop()
fig = plt.figure(1)
count = 0
print(args)
h.Write(buf.Bytes())
self._x = self.x
delta = timedelta(days=7)
print((sizeof(p), repr(p.raw)))
PeakDetection(map[string, string])
num_zeros = len(X) - np.sum(nonzeros)
method_to_be_executed_in_case_of_exception_or_pk_is_false()
locale - a
df = pd.DataFrame(tweet_sample)
file_handler.setLevel(logging.WARNING)
nbytes = (nbits + 7) // 8
result = data[is_ok[b_vals]]
n += 1
all_pairs = []
model._meta.db_table
input_thread.join()
N = 10
a = {}
c = Counter(x for x, c in lst for _ in range(c))
C[x, y, z] += A[x1, y1, z1] * B[x2, y2, z2]
myfunc(1, callback=callback)
PyMODINIT_FUNC
masklength = np.sum(mask)
t.plus(1)
line = next(p.stdout)
result = {}
df2 = df1.ix[4:8]
aspect = models.ForeignKey(Aspect)
et.tostring(self.roots[0])
incomment = True
idx_range = np.arange(data.shape[0])
o.insert(o.begin(), begin, end)
sf.close()
print(df)
totals[k] = totals.get(k, 0) + v
h = t[i] - t[i - 1]
main()
L[i + 1] = L[i]
cols = [ele.text.strip() for ele in cells]
d = dict.fromkeys(range(n))
pyth_module = PyImport_Import(module_name)
t_component = np.array([d2s_dt2] * 2).transpose()
print(a + b)
allkey = set(allkey)
System.out.println(s)
branch = root.setdefault(path[0], [{}, []])
json = f.read()
{}
self.args = args
x = scipy.linspace(-2, 2, 1000)
os.remove(f.name)
i = 0
u = urllib.request.urlopen(URL)
print(filename)
current = threading.current_thread()
data = self._get_property_data()
l = len(iterable)
b = 1
last_etag = feed.etag
CustomerAddress.objects.filter(customer_id=self.id)
Obj.jsonable()
solar_time = datetime.combine(dt.date(), time(12)) + td
a = 1
axes = fig.add_subplot(111)
REPORTLAB22 = _reportlab_version >= (2, 2)
post.tags.add(tag)
sublist.sort(reverse=True)
[0.0],
print(parser.format_help())
df.show()
verifier.verify(data, sig)
m.connect()
len(set(p1.boundary.coords).intersection(p2.boundary.coords)) >= x
indr = np.where(np.all(arr == 0, axis=1))[0]
s.sendall(content.encode())
fullpath = os.path.join(path, paths)
isinstance(open, types.FunctionType)
filename = _get_filename(loader, mod_name)
self._attr = value
inv_data = l.split()
[1, 2, 9, 0],
print(do_add(s, 1))
print(k, list(g))
p = plt.pie(a, colors=cs)
array.data()
self.request.send(foo.lower())
parser.exit()
y = np.sin(u) * np.sin(v)
it = iter(iterable)
extent = [xbins.min(), xbins.max(), ybins.min(), ybins.max()]
round(f)
target = target[index + len(key):]
t = iter(s)
m1[1, 2]
x = np.arange(1, 15.1, 0.1)
wall(2, 1)
ws.append(cols)
VBD.create(connection, vbdrecord)
glMatrixMode(GL_PROJECTION)
min_pair = min(itertools.combinations(fList, 2), key=distance)
num_smudges = len(smudged_numbers)
a1[a2 > 0] = a2[a2.nonzero()]
min_value = min(dict.values())
d = ImageDraw.Draw(img)
numpy.clip(image_data, display_min, display_max, out=image_data)
True
angle = getAngleBetweenPoints(-1, -1, -1, 2)
pypi
loaded = imp.load_module(module, f, fn, d)
print(list)
self.is_started = False
turtle.forward(n * 4)
res[i, j] = ndarr_dot_product(A[i], A[j])
ax = fig.add_subplot(111)
x.cumsum(axis=0, out=x)
print(list(split_text(a)))
jobs = u.userjob_set.all()
q.append(next(gen))
init = tf.initialize_all_variables()
passman = urllib.request.HTTPPasswordMgrWithDefaultRealm()
inspect.getargspec(foobar)
x + 1
tv = gtk.TextView()
x = []
dq = collections.deque(maxlen=50000)
data = sorted(data)
coeff_mat = scipy.sparse.coo_matrix((data, (row, col))).tocsc()
find_intersect_vec(x_down, y_down, x_up, y_up)
t1 = datetime.now()
new_contact = Contact.put_from_message(request)
match = match.group()
crawler.configure()
func = lambdify(v, Matrix([v[1], 2 * v[2]]))
11856
self.authName
x_normed = x / x.max(axis=0)
saved_args = locals()
request.db_session = settings.Session()
last_row = df.index[-1]
poly_verts = [(2, 2), (5, 2.5), (6, 8), (2, 2)]
print(foo.bar)
dir_p = opendir(path)
newfile.close()
self.value == other
GGC
GCC
CCA
seq.append((n, 0))
s = requests.Session()
parser = HTMLParser()
d = defaultdict(list)
snowflakebranch(n)
MultiConditionalTest(values, testIterations)
self.output = tf.nn.relu(linarg)
self.connection = redis.Redis()
df = pd.DataFrame(data)
word = models.TextField()
frq = k / T
Counter(data[1])
self.exec_()
mydict = recursivedict()
c = stack.enter_context(Dummy())
self.density_water = 1000.0
print(a.nbytes / 1024 ** 2)
-1
curl = pycurl.Curl()
s = str(rng[0][1])
NULL
cls = getattr(module, cls_name)
parser = argparse.ArgumentParser()
xlApp.Quit()
gevent.sleep(IDLE_PERIOD)
sum_list = map(operator.add, sum_list, li)
tBI[item] = value
A.get_instances()
http_server = tornado.httpserver.HTTPServer(application)
print(oodict[results_key] + line)
Xs = np.average(X)
portshort = int(port)
soup = BeautifulSoup(self._open(request))
print(pts[idx], idx.sum())
img = img.reshape(planes, rows, cols)
soup = BeautifulSoup(d)
assert n(21) == set([16, 17, 20, 22, 45, 46])
initargs = [sys.stdin.fileno()]
two.shape
myObject.doMoreStuf()
mode = os.fstat(0).st_mode
Arrays.sort(nums)
train_features = train_dataframe.iloc[:, 1:]
q = Q()
original_string = soup.p.contents[0]
strncpy(d, _d, sizeof(d) - 1)
zeros_and_ones[coord[0], coord[1]] = 1
a + b
txt = inp.read()
my_array[0, 0] = 1
keep_default = True
lock = threading.Lock()
1, 2, []
self.scroll.setWidgetResizable(True)
sendSock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)
img.fillColor(color)
s = (i for i in range(100))
buffer_string = lines[-1]
self._handler.setFormatter(fmt)
test.readFrom(inf)
tokens.assign(token_list.begin(), token_list.end())
xmax, ymax = fig.transFigure.inverted().transform((xmax, ymax))
print(parser.parse_args([]))
print((len(argv), repr(argv)))
TRUE
XYZ = np.vstack([x, y, z])
patch = subimage(im, (110, 125), np.pi / 6.0, 100, 200)
dictrepr = dict.__repr__(self)
connection.setblocking(0)
json.dump(o[i:i + chunkSize], outfile)
{articles: {{articles | safe}}}
ip = ether.data
something.y = something.x
D = np.ones((dim,))
first_el = mylist.pop(0)
a = Animal()
classifier = pickle.load(f)
f = foo()
manhole.Manhole(namespace)
word_len_dict = defaultdict(list)
result = [tuple([key] + value) for key, value in key2value.items()]
{4, 5, 6}(maximal)
s.listen(5)
int(p)
conf.check_python_headers()
session = sessionmaker(engine)(twophase=True)
cur = con.cursor()
ctype = ContentType.objects.get_for_model(self.__class__)
f = scipy.linspace(0, fs, len(Xdb))
value = value[slice(*sindices)]
result
exit(1)
print(p.x)
tmp.append(item)
print(i)
print(files)
self.data.append(data)
worklist.extend(graph[node])
stdin, stdout, ssh_stderr = ssh.exec_command(cmd)
c = a
x = np.arange(-5, 5, 10.0 / (2 * N))
ufunclike
id(a)
sys.settrace(mytrace)
y = np.linspace(1.0, 10.0, 20)
field.formfield()
main()
rect_start = coordinates[0][0] - i, coordinates[0][1] - i
pwd.getpwuid(os.getuid()).pw_dir
sess = tf.InteractiveSession()
y_val = clf.predict(samples)
tt.tm_yday
seg = a[col_index[i:i + snip]]
PyArray_Return(meanX)
s1 = set([5, 7, 8, 2, 1, 9, 0])
a = A()
print(lasthash)
c = a.ravel()
main()
res = requests.get(*args, **kwargs)
resultlist = []
plt.subplot(2, 1, 1)
print(c)
a = f()[1]
True
a
a = pair_freq - d1[0][base1] * d1[1][base2]
mlab.figure(bgcolor=white)
DOT11_CIPHER_ALGO_WEP = 257
_ROOT = os.path.abspath(os.path.dirname(__file__))
out_ar[i] = pd.Timestamp(datetime.datetime.combine(date, time))
df
proc_id = str(multiprocessing.current_process())
self.v_c / self.H0
print(d)
listener = serial.Serial(com_port1, baudrate)
cls(page=page)
matrix[tuple(reversed(pair))]
gcm_device = models.OneToOneField(GCMDevice)
t = s.execute()
self.solve()
a[1]
m = a != 0
r = np.zeros((rows, rows))
bus = dbus.SystemBus()
db.store(serial_str)
Employee.manager_id = Column(Integer, ForeignKey(Employee.id))
msg.attach(img)
vec_tfidf = tfidf[vec_bow]
cache = {}
[compressrange(map(long2ip, rng)) for rng in ranges]
CloseKey(key)
print(word_list)
print(d)
ax.relim()
l1.index(20)
fi = np.arange(k)
seen = set()
ft = a.get_level_values(1)
app.run(debug=True)
splash.Show()
dataE = [sorted(x) for x in zip(geometry, geometry[1:] + geometry[:1])]
2, 7, 8, 9, 18
root = Tk()
print(config_root.licence_file)
line.set_data([], [])
self.owned = owned
deleteself.thisptr
node_count = sum(1 for _ in db.nodes)
logger_a.setLevel(logging.DEBUG)
print(i)
-499999999999999999999999999999999999999999
summed[key] = summed.get(key, 0) + value
okBtn = wx.Button(self, wx.ID_OK)
str(self.view)
l = list(range(20))
0
a = np.random.randn(1000)
count = 0
deleteobj.data[field_name]
user = username(request.user)
saved = []
ndb.delete_multi_async(Counter.query().fetch(keys_only=True))
kmer2count[kmer1] += initcount[kmer2]
gc.collect()
df
pd.Panel(d).transpose(2, 0, 1).to_frame().reset_index()
report = models.ForeignKey(Report)
a * (1 - np.exp(b * x))
affprop.fit(similarity)
groups = [list(g) for n, g in groupby(sorted(cols, key=fnc), key=fnc)]
self.pushButtonSimulate = QtGui.QPushButton(self)
self.a = 1
s = textwrap.wrap(text, width=10)
show(p)
date_wise_stats[i[0]] += 1
a = datetime.now()
MyImplementation.do_stuff(request.something)
V = np.sqrt(np.mat(np.diag(C)).T * np.mat(np.diag(C)))
row = next(csvDict)
ret = np.empty(len(input))
x = y = np.arange(-5, 5, 0.05)
zi = np.array([[0.0, 1.0, 2.0], [0.0, 1.0, 2.0], [-0.1, 1.0, 2.0]])
b[i] = 0
self.squares[row * 8 + col]
painter.end()
a = str(num)
x + y
positions[a] < positions[b]
d = {}
new = []
start = time.time()
self.x = x
register_treebuilders_from(_lxml)
tangent_y = tangent[:, (1)]
field_names = [v[1] for v in string.Formatter().parse(s)]
result = tuple(islice(it, n))
echo.serve_forever()
inputElement = driver.find_element_by_name(key)
np.put(canvas, linear_index, 1.0)
d = c * (c < 255) + 255 * np.ones(np.shape(c)) * (c > 255)
page.mergePage(new_pdf.getPage(0))
share_memory(a, b)
q = Queue()
l = s[i + 1]
upper_white = np.array([255, sensitivity, 255])
mod.__file__ = filename
ordered_dump(data, Dumper=yaml.SafeDumper)
zip_code = models.CharField(max_length=20)
client = paramiko.SSHClient()
A.foo.__func__(y)
timerThread.start()
print(nextdate)
out = timeobj.replace(tzinfo=pytz.utc)
do_something(c_temp)
Z = np.log2(np.arange(Y.size) + 100) * 0.001
newlist[i] += str(counts[item])
y.append(int(_y))
print(str(clause))
print(commands.formfile.__doc__)
a[list(indices)] = -1
df2[df1.columns[0]] = df1.iloc[:, (0)]
1
self.parser.quote_mode()
self.z = z
result = []
HTHflips = HTTflips = 0
sum1 = row1.sum()
workbook = xlwt.Workbook()
num
get_platform()
redis_client.delete(key)
colors.append(cmap(n / float(N)))
55247
55248
55249
ax.plot_trisurf(tri, z)
runner.run(suite)
print(df)
another_pet.say()
p = IP() / TCP(flags=18)
text
groups = OrderedDict()
mocked_zipfile.namelist()
B = A[:]
fig = plt.figure(0)
is_new_style_class(New)
print(months[2])
value_to_key
print(solution(x))
self.a1a2_edit.setText(str(product))
func_names = [f.__name__ for f in func_list]
b.shape = 2 * len(a[0]), 2
use(block)
data = someFunc(*arg, **kw)
glMatrixMode(GL_MODELVIEW)
match_cache[m]
id_arr[idx[:-1]] = -a[:-1] + 1
df_list = []
names.append(name)
print(location.address)
id(c)
points = sorted(points)
plt.plot(np.sort(heights), vF(x=np.sort(heights), data=heights))
{{usercontent.thing_a}}
vstart = vspell[1]
mins.pop()
y += 1
foo(arr)
x
self.get_value(field_name, args, kwargs), field_name
pool.close()
y = det([[a[0], 1, a[2]], [b[0], 1, b[2]], [c[0], 1, c[2]]])
A = [[1, 1], [1, 1]]
X.T[:1, :] = x
x = datetime(2011, 1, 5)
max_x = np.nanmax(rot_points[:, (0)], axis=1)
np.array(train_idxs), np.array(val_idxs)
[]
csvdata_old.set_index(mergecols, inplace=True, drop=False)
matcher = re.compile(pattern, re.X)
labels = skimage.morphology.label(img)
getattr(ImportedLib, string1 + string2)()
intersect = dict1.keys() & dict2.keys()
node = Node()
log.msg(nicklist)
print(msg.SenderEmailAddress)
index = int(w.curselection()[0])
task = AsyncResult(task_id)
sys.exit(app.exec_())
print(x & z)
v = in_.get(k)
l = [x, y, z]
col = column_index_from_string(xy[0])
k = 0
canvas.blit(ax.bbox)
fp.close()
django.middleware.csrf.CsrfResponseMiddleware
myjson = json.load(sys.stdin)
self._box._ipython_display_()
sorted_keys = sorted(stealth_check.keys())
tri = qhull.Delaunay(xy)
parts = line.strip().split()
df
Title = a.childNodes[0].nodeValue
first_num = int(next(d))
v.visit(node)
print(i, c)
packet = f.read(blocksize)
result.update(diffs)
new_result.extend(combo + [word] for word in words)
new_lis = [list(v) for k, v in groupby(lis, key=itemgetter(1))]
keyed_dict[i, e].append(tup)
window = Gtk.Window
b[s]
self.extend([self._gen()] * (index - len(self) + 1))
mymap.__code__
result = getattr(dataImage, method)
df = pd.DataFrame(d)
print(response.url)
wait_process.start()
fig = plt.figure()
s = set()
func.__code__
recvSock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)
axes.bar(x1, y, facecolor=getCycledColor())
new_vertices = vor.vertices.tolist()
lst.sort(key=len)
name = list(p.keys())
log_handle.setLevel(logging.WARNING)
x.iloc[4]
last_i_elements = url_elements[i:]
my_decoded_str = str.decode(bytes)
student_tuples.sort(key=itemgetter(0))
setattr(self, countname, getattr(self, countname, 0) + 1)
est = stats.pareto.fit_fr(rvs, 1.0, frozen=[np.nan, loc, np.nan])
Base = sqlalchemy.ext.declarative.declarative_base()
raise StopIteration
filename = part.get_filename()
print(s.recv.__doc__)
popen(cmd)
even_numbers = (n for n in numbers if not n % 2)
self.layoutAboutToBeChanged.emit()
my_dict = defaultdict(dict)
options, args = parser.parse_args()
letter = letters.get(self.rank, str(self.rank))
fig = plt.figure()
Y = linalg.lstsq(A, X)[0]
X = np.random.rand(nNew, 2)
profile = selenium.webdriver.FirefoxProfile()
getter[0]()
k = datetime.date(2010, 5, 26) - datetime.date(2010, 2, 10)
results.append(file)
result.append(current)
ret
chunk_size = 1024 * 1024
this()
input = sys.stdin.readline()
p.peek()
pred = types.FunctionType(marshal.loads(pred), globals())
L = [1, 2, 45, 55, 5, 4, 4, 4, 4, 4, 4, 5456, 56, 6, 7, 67]
s = s.rstrip()
models / __init__.py
self.ui.comboBox.view().pressed.connect(self.handleItemPressed)
search_offset + m.start(), search_offset + m.end()
exclude = set(string.punctuation)
axmatrix.set_yticks([])
dest = PDFFileWriter()
raiz.mainloop()
cond_im = np.zeros_like(im, dtype=bool)
L.remove(c)
porter.stem(greatest)
2 + 2 == 5
fig = plt.figure()
indices = np.dstack(np.indices(im.shape[:2]))
delay = time.time() - start
self[key]
ax.plot(xf, 2.0 / N * np.abs(yf[:N // 2]))
requests_session = requests.session()
a = sheet.cell(row=i, column=j)
b()
print(clean.clean_html(html))
raise TypeError
result = list(unpack(x))
True
k = ord(s[i])
names = [x.name for x in triggers]
input = input.lower()
print(curated_text)
nges = summation(n[i], [i, 1, numSpecies])
answer = my_value / divisor
c.prerequisites.add(b)
pythons_tasklist = []
dfWeeks.assign(target_hit=dfWeeks.apply(find_match, 1))
sleep(1)
file_content = f.read()
args = [iter(iterable)] * n
subquery = session.query(table_c.id)
b = pd.Series(np.random.randn(200) / 100 + 0.001)
a + 1
y in x
random.shuffle(chars)
root.instance.related_set.all()
units = models.TextField(max_length=500)
zipfile.write(filename, dest_path)
plt.scatter(dat[:, (0)], dat[:, (1)], c=fit.labels_)
rv.append(x)
c = app.test_client()
im = im.point(lambda p: p > threshold and 255)
doStuff(item)
red, green, blue
bytes([first, random.choice(trailing_values)])
row = []
new_dic[1][2] = 5
filter_summary = tf.image_summary(filter)
server = loop.run_until_complete(coro)
programming / index
results.append(model_solve(100))
MakeHeptagonalPrism()
time_created = Column(DateTime(timezone=True), server_default=func.now())
sys.exec_prefix
test = pd.DataFrame(np.random.random((4, 4)))
print(dir_name)
a = sys.executable
print(e)
x_subplot = fig.add_subplot(2, 2, i)
output = []
self.other_field_name = other_field_name
n = len(users)
collection.set_array(np.array(colors))
s.dummy()
x
x.append(1)
i = next(i for i, v in enumerate(list_) if v)
f.write(line)
d = {}
outdata[i] = (ctypes.c_double * 6)()
previous_df_no += 1
ax.autoscale_view(True, True, True)
sys.stdout.flush()
df = grp.mean()
signature = base64.b64decode(signature.encode())
print(rofile[a])
np.loads(zlib.decompress(value))
q = lambda x, y: -np.sqrt(max(0, 1 - x ** 2 - y ** 2))
doc = nlp(text)
random.shuffle(self.name_list)
x = np.arange(i - size, i + size)
self.var1 = var1
print(i, e)
stat2[k] = v
solutions = get_possible_solutions()
item = prio_queue.get()
print(self.__bar)
idx = np.sort(np.array(list(product(np.arange(gn), repeat=n_dims))), axis=1)
unpickled.foo
f.add_done_callback(submit_if_success)
self.master.bell()
uid = StringField(required=True)
logging.getLevelName(15)
[uwsgi]
theList = list(range(20))
f2(X, list_obj_array)
atexit.register(self.delpid)
lastsum += addval - subval
cumulative_fails = is_fail.cumsum()
a = 10
self.copy_constructor(orig)
g += f * f
base_parser_50 = argparse.ArgumentParser(add_help=False)
i += 1
print(sequence1)
print(match(to_words(a), to_words(b)))
r_dataframe = pandas2ri.py2ri(df)
ax1 = fig.add_axes([0.09, 0.1, 0.2, 0.6])
start_new_thread(gentask, ())
(any(isColor(*pixel)) for pixel in im.iterpixels())
M[:, (j)]
count = np.sum(mask)
groups = collections.defaultdict(set)
a = numpy.zeros(10, numpy.uint8)
count = 0
points = sorted(list(set([(i % bound) for i in points])))
color = im.cmap(im.norm(value))
od[name] = rpy2.robjects.conversion.py2ri(values)
self.parent = parent
print(urlparse(u).netloc)
a = numpy.arange(10)
bigmat
self.color_cycle = itertools.cycle(clist)
sub_df
quit = True
print([co for co in c if not st1.issubset(co) and not st2.issubset(co)])
start, stop, step
np.in1d(aView, bView)
print(get_diagonal(m, 1, 1, 1))
y = a[len(y):] + b[len(y):] + y
persons = Person.objects.all()
arr[sl]
data = urllib.parse.urlencode(values)
query_d = urlparse.parse_qs(parse_result.query)
instance, created = Book.objects.get_or_create(slug=slug, defaults=d)
p.stdin.close()
df * weight[0]
result
a = {x, y}
x * x
-_prereq
fd.inc(word)
coro
item
print(a[:, (0)])
popt, pcov = curve_fit(func, x, y, p0=(1, 1e-06, 1))
blueprint.add_app_template_filter(filter2)
self._items[regex]
value
libfoo.pi
dur1 = 1
lis = [x.split() for x in f]
a.get(1)
first_row = df.index.get_loc(first[0])
MyModelSerializer
f = bar
MyClass.decorated_method
process.poll()
0
2 * li
id(s)
self._stdout.seek(0)
list.__setitem__(self, key, value)
chain.append(item)
comment.replace_with(fixed_text)
dectest
e_str = binascii.hexlify(n_bytes)
os.replace(outfile.name, input_file.name)
factor5 = sum
self.sleep_func(10)
print ()
Py_DECREF(m)
d = np.array([dx, dy])
loop.add_reader(self._fd, self.handle_read)
df * weight
u = urllib.request.urlopen(req)
reconnect_to_database()
App.run()
df
axis = np.asarray(axis)
f_handle.close()
x = np.sin(2 * np.pi * t)
l = map(timesTwo, l)
urls.put(attr[1])
fig.add_layout(myToolTip)
len(list(c.elements()))
dist = np.sqrt(x ** 2 + y ** 2)
chessgame.apply_move(chessgame.get_moves()[1])
self.wfile.write(html.encode())
value = 0
print(base.foo(), base.fooBase())
some_objects = MyClass.objects.all()
new = large_array[(large_array >= min_val) & (large_array <= max_val)]
context.update(csrf(request))
[set([x for i in s for x in lis[i]]) for s in disjoint_indices(lis)]
existing_user = auth_models.User.get_by_auth_id(email)
ax1.set_xticks([])
intermed_func = functools.partial(magic_map, str.split)
setattr(cls, k, getattr(a, k).__func__)
smtp_conn.ehlo()
date_after_month = datetime.now() + relativedelta(day=1)
x2[x2 < q].shape[0]
myCounter += 2
input_size = len(input)
clauses = (Q(address__icontains=p) for p in postcodes)
get(d[key], rest)
chan.exec_command(cmd)
trayIcon.show()
fh = urlopen(url)
oldHeight = image.shape[0]
fr.Show()
c()
weekdays._days_cache = {}
gray = cv2.blur(gray, (15, 1))
names = []
n = sum(1 for line in open(filename)) - 1
old_handler = signal.signal(signal.SIGALRM, timeout_handler)
df < 1
self._my_numpies
y = c / (1 + np.exp(-k * (x - x0))) + y0
counts[i] += 1
self._name
proposal = uniform(low, high)
big_table[nchunks] = {}
im = Image.open(thefile)
__builtin__.profile = profile
y.squeeze()
ulist.append(utest)
myA[truncate_mask(myA > val, n)] = 0
foobar.__name__
summary_merge = tf.merge_all_summaries()
list1 = list1[:-max_size]
http = httplib2.Http()
pool.close()
new_data.append(triple)
items = set([-1, 0, 1, 2])
clusters = km.fit_predict(X_train_tfidf)
print(recognised_tags[tag_id])
print(mindiff, x2sort[mindiff], x1sort[mindiff], x1sort[mindiff - 1])
sort - Vu | head - 1
res_arr = sparseness2(express_df.values)
X = np.arange(dk, 0.4, dk)
div.removeChild(div.firstChild)
start()
x, y = np.random.random((2, N, 2))
ax.plot(*coords.T)
a = numpy.arange(n1)
d1 = {}
ptr.close()
list(it)
configure_uploads(app, (csvfiles,))
Builder.load_string(kv)
y
1.66666666667
70.6666666667
temp = str(integer)
Yr = int(current_date[7:11])
d = OrderedDict()
ac.append((wx.ACCEL_NORMAL, key, _id))
output[strD] = outData
e.sort()
output = ob_get_clean()
print(stack[len(stack) - 1][2])
loader.close()
optimize_result = scipy.optimize.minimize(neg_log_likelihood, [1.0])
l.append(Point(1.0, 0.0, 0.0))
reactor.listenTCP(7080, server.Site(Math()))
test_string
print(predresult)
result = self.cursor.fetchone()
zxcvb
setattr(instance, self.name, value)
map(threading.Thread.join, threads)
min_key, min_value = k, v
idx = (A > 2) * (A < 8)
arr[:, (-1)] = np.where(np.arange(M) <= min(max_range[-1], max_sum), 1, 0)
m = max(len(x) for x in a)
base_parser_20 = argparse.ArgumentParser(add_help=False)
new_obj = pickle.loads(pickle_str)
pickle.load(s)
a1_rows.difference(a2_rows)
measured.append(tuple(float(x) for x in (ampl, phase, speed)))
open_db()
i += 1
point = np.array([0.0, 0.0, c])
img_hsv[..., (0)] = color_mask_hsv[..., (0)]
dis.dis(bar)
x
deleteself.keyToId[key]
f = lambda x: x == 0
q.put(res)
type(obj)(namedtuple_asdict(item) for item in obj)
D[C[1][i]].add(C[0][i])
df2
edges = cv2.Canny(gray, 10, 100)
dir(pyudt.pyudt_socket)
dfs({Sequence1: [Translate], Translate: [Sequence1]}, Sequence1)
unknown_compressed_data[:10]
sys.stdout = EatLog()
app.Quit()
sheet.cell(row=1, column=c + 2).value = col_name
signer.update(message)
new_list_of_pixels = pool.map(update_pixel, list_of_pixels)
foo.MyClass()
attract_to_closest(points, attractors, f)
im1 = np.vstack((im[x:], im[:x]))
keep_names = [name for name in dt.names if name not in names]
self.empty()
d = [0] * (max(lst) + 1)
query.offset(offset).limit(limit).all()
dec_lat = random.random() / 100
handlers = [(re.compile(x.re), x) for x in [message, warning, foo, bar, baz]]
print(np.outer(w[i], v[i]))
trg[k] = v
main()
data_2 = np.random.randn(len(categories))
ws = wb.Worksheets[1]
self.votes.size()
print(fab.env.roles)
setattr(namespace, self.dest, items)
warpPerspective(src, transformed, transmtx, transformed.size())
buf = in_file.read(block_size)
X[0:1, (4)]
df.a.values
s = frozenset((2, 1))
a = 10 ** np.array(np.linspace(-10, 10, 51), dtype=np.float64)
S = set([0, 2, 6, 8])
output[day] += 1
f = outer_func(5)
page = urllib.request.urlopen(access.get_imdbURL(movie))
result = int(n)
print(strings.customer_name)
timeit.timeit(f, number=100000000)
m, n = np.meshgrid(z, z)
0, 1, 1
repr(node)
print(y)
System.out.println(line)
materials = [0, 0, 47, 0, 2, 2, 47]
datum = caffe.proto.caffe_pb2.Datum()
maxp = max(maxp, len(str(item.price)))
x
z = array([cat((t, rep(9999, k))) for t, k in zip(s[:-1], j)])
config = tf.ConfigProto(log_device_placement=True)
list_[index] *= 2
key in dictionary and valid(dictionary[key])
print(l)
self.transport.start_client()
M = nx.MultiGraph()
print(bitmath.Byte(bytes=4026).best_prefix())
new_list = []
D = 2
vector = np.array([10, 20])
arr2 = array[i + 1:]
x = sparse.lil_matrix((N, N))
Pdb
list_b = ModelB.objects.all()
j += 1
names[host] = nick
mat[h, k] = mat[h, k] + 1
self.word_type
file_sample_rdd = sc.emptyRDD()
mime_image.set_payload(file_upload.read())
unique(a)
data[0, 0] = 1, 2
self.xaxis.set_zorder(2.5)
this_method = getattr(self, method)
self._pixmap = QtGui.QPixmap(self.pixmap())
self.x = v
self.hide()
form_instance = form.save()
repo.modified_files
stop = start + np.random.randint(1, 10, nsubarray)
self.map[hash(item)]
print((c, d))
img[y][x][2] = b
tag = soup.div
a = [np.arange(1, k + 1) for k in ua]
(df > 0).all(1)
plt.figure()
image.getpixel()
[codeintel]
list[0] = 42
pil_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
label.pack()
PersonQuerySet(self.model)
yd = [float(row[1]) for row in data]
contents = dir(module_code)
[]
glDrawElements(GL_TRIANGLE_STRIP, count, GL_UNSIGNED_SHORT, buf + 14)
amps = 100 + 100 * np.random.random(ng)
x = np.random.randn(1000)
root.after(5000, lambda : root.focus_force())
br.click_link(l)
print(numpy.array(list(range(10))))
BytesIO.__init__(self, buf)
self.exprStack.append(toks[0])
a = np.random.random(100) * 0.5
help(int.__add__)
sys.stdout = out
mask = np.ones((8, 8))
source = cv2.imread()
p2.wait()
win.getMouse()
jobs.append(p)
print((next(I1), next(I1), next(I1)))
print(s)
arr[i] = (c_short * len(numpy_arr[i]))()
method = getattr(cls, n)
df
fh.setLevel(logging.DEBUG)
out = pairs[((p0 == 0) | (p1 == 0)).sum(1) != 2]
r = {}
gconf_root_key = applet.get_preferences_key()
self.Splash = True
seen.add(x)
loop.run_forever()
self.SetSizerAndFit(self.windowSizer)
ref = (r.split() for r in reffin)
self.fig = ax.figure
y = x[:, (np.newaxis)]
score = models.IntegerField()
conn = MongoClient(host, port)
os.close(fd)
shutil.move(tmp.name, filename)
print(str(e))
print([f() for f in funcs])
a2 = list(s)
score += 1
get_ipython().Completer.limit_to__all__ = True
total.start()
result
data = task.result()
qr = qrtools.QR()
print(save_match.match.group(1))
res = []
kernel[mask] = 1
func()
self._value = 1
now = str(datetime.datetime.now())
f = fft(x)
Gdk.cairo_set_source_pixbuf(context, self.pixbuf, 0, 0)
print(text)
self._pid = os.getpid()
response = urllib.request.urlopen(request)
{}
[2, 1],
density = np.concatenate(results).reshape(xi.shape)
main()
app
print(p.map(numpy.sqrt, x))
merged[item[key]] = item
0
self.complete(decisions=decisions)
content = pickle.dumps(somedata)
l, d
taskindex = available.pop(random.randrange(0, len(available)))
a = (c_char * 4 * 2)()
self.q *= 1 - regularization
NotImplemented
print(outputfile[0])
prog = ast.parse(sys.stdin.read())
axarr[2].plot(x, cut_signal)
name = StringField()
func(repeat(string_iterable))
result[k] = dmerge(x[k], y[k])
y = r * math.cos(theta)
omega = 2 * pi / wavelength
r = np.random.rand(prob_matrix.shape[1])
t1, t2 = tee(iterable)
a = np.array([4.0, 5.0])
c = Counter(a)
print(df_a.merge(df_b))
df = pd.DataFrame(data)
d = defaultdict(list)
self.name = name
print(a)
diffthis
testme = np.array(alist)
func(L)
A = 2 * np.arange(10)
ret = self.func(obj, *args, **kwargs)
list_of_strings = b.tolist()
r(argv[1])
seen = set()
le = preprocessing.LabelEncoder()
c.start()
treebank.tagged_words()
timeout = self._timeout
self.list = list()
newWord
bananas(x)
print(globals.value)
p = np.column_stack((x_down, y_down))
window = MainWindow()
self.md5 = hashlib.md5()
df
resultList.append(a[index:index + length])
self.view = QtGui.QGraphicsView(self.scene)
s = StringIO.StringIO()
list(closed_range(1, 10))
plt.show()
shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)
[i, j], [i2, j2]
[]
cols = mask.all(axis=0)
t[::2], t[1::2] = t[1::2], t[::2]
True
sum(nrs)
y = np.random.rand(5)
unquote(value)
h2, w2 = img1.shape[:2]
_.isoweekday()
sys.exit(main())
values = [tuple(dd[k][0] for k in list(dd.keys()))]
train_imp = imp.transform(train)
my_field = Models.IntegerField(choices=MY_CHOICES)
0, 1, 1
install.initialize_options(self)
x = arange(0, 10)
transport.open()
process(item)
points = np.ones(len(user_item), int)
g[0] = x[0] ** 2 - x[1] + 1
result = np.arange(a.shape[0])[mask][arg]
inputready, outputready, exceptready = select.select(input, [], [])
dic = dic.setdefault(key, {})
pymongo.has_c()
encoded
myarray = np.arange(20)
print(yaml.dump(test2))
v = v[:, (np.newaxis)]
win = GraphWin(width=200, height=200)
print(formattedList)
solve_linear_system(A, x, y, z)
d = a.flat
goto(1)
self._queryset = qs
eachpwd = line.strip()
x = chr(a | b << 1 | c << 2 | d << 5)
self.name = name
sock.close()
x = np.arange(100)
stdscr.move(y, x - 1)
df = psql.frame_query(sql, cnxn)
m = alsaaudio.Mixer()
con = np.concatenate((c, b))
B = numpy.ones((2, 2)) / 4
sum_x = np.sum(arr[:, (0)])
print(x)
k = random.choice(list(x.keys()))
print(x)
server.start()
t.timeit()
nums[i] = int(Math.random() * (Math.random() * 2001 - 1000))
rows, cols = arr.shape
self.parser.bracket_mode()
p.start()
categories = [animal.categories.all() for animal in all_animals]
ctsquarelib.mysumsquares.restype = ctypes.c_float
socket.setdefaulttimeout(original_timeout)
print(result)
f2()
f(d)
a.__code__.co_varnames
web = QWebView()
block_list.extend(sequences[:])
query = Foo()
n = len(sublist)
t.join()
shutil.copy(filepath, destpath)
average[i, j] += kernel[ii, jj] * matriz[i + ii, j + jj]
sum(item if i % 2 else -1 * item for i, item in enumerate(mylist, 1))
PROPERTIES
-rrequirements.txt
txt.close()
x = numpy.linspace(0, 10, 100)
print(finder.nbest(bigram_measures.likelihood_ratio, 10))
y = np.empty(x.size, dtype=np.int64)
t = time.time()
listview.list()
a = A()
self.params = dict(list(request.GET.items()))
self.age = 21
date = line[0].split()
a = A(1)
Y[..., (1)] = 1
print(repr(item))
assert f.read() == DATA
cout[1:-1, 1:-1] = out
endDate = datetime(2011, 10, 7)
s.index = [s.groupby(level=0).cumcount(), s.index]
secret = models.TextField(max_length=255)
chunkfile.write(line)
print((k, hddict[k]))
wb = xl.Workbooks.Open(yourExcelFile)
nbytes /= 1024.0
self.attributes_string()
process_line(line)
print(answer)
macro.request.formatter.text(code_out.getvalue())
d[p[1]] += 1
queryset._raw_delete(queryset.db)
print(value)
K, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0
node = destination.setdefault(key, {})
ldlt_np(A)
print(res)
priority_list[i[1]] += 1
d = {(1): var1, (2): var2}
p.drawImage(image)
zip_longest(fillvalue=fillvalue, *([it] * size))
print(df2[~df2.isin(df1).all(1)])
nbors.append(i + A + p * W + (r - p) / 2)
func()
axs[1, 1].plot(rand(100))
self.subject = msg.Subject
[4, 4, 5, 5, 6, 6],
result
decimal.getcontext().prec = 100
y_fit2 = Func(x, *popt2)
G = nx.from_numpy_matrix(A)
print(dingo)
print(mytext.title())
print(df)
train_likes_df = pd.read_csv(io.StringIO(temp))
G = nx.Graph(edgelist)
user = authenticate(username=email, password=submit_pwd)
arr1inds = arr1.argsort()
a + b
self.memo[id(obj)] = 1
mro = cls.mro()[1]
id = Column(Integer, primary_key=True)
f.write(bin)
f.close()
item = singlet_list[0] if singlet_list else False
groups = itertools.groupby(allLines, lambda x: x[1])
counter
result = result.subs(old, new)
triples = []
cd / opt / local / Library / Frameworks / Python.framework / Versions / 2.6
new_dict = {}
threefold = list(KFold(len(y)))
app = MyCelery()
suite = unittest.TestLoader().loadTestsFromTestCase(TestEffortFormula)
widget = treeview_column.get_widget()
stylesheet_file.close()
rtn
lasagne.layers.set_all_param_values(network_output, param_values)
matches = []
cdata = s[0].contents[0]
results = {}
tmp = self.head
pipeline.start()
r = resolve(request.path)
endpoints = sorted(list(set([r[0] for r in ranges] + [r[1] for r in ranges])))
ct.char_test.print_strings(strings, strings.shape[1])
self.apachereq.write(data)
a = df.values[:, (0)].copy()
x = np.linspace(0, 2 * np.pi, n)
Y[..., (0)] = np.angle(X) / (2 * pi) % 1
self.searching = True
print(node)
x = np.random.random((5, 5))
self.slopes = [((y2 - y1) / (x2 - x1)) for x1, x2, y1, y2 in intervals]
plt.semilogx(w, phase)
idx = df.groupby([df.customer, df.invoice_nr, df.date, df.amount.abs()])
swap(i, 0)
print(sum(1 for i in numbers if i % k == 0))
print(type(img_np))
coefficients = np.polyfit(x, y, 1)
register_wrapper
python - -version
data = str(data)
X, Y = np.meshgrid(x, x)
print(tree2)
self.contained = df
data = f.read()
lines.update()
new_loop.append(S + str(i))
j += 1
zindex += 1
GetWindowText(hwnd, win_name, win_len + 1)
x = np.reshape(n, (N, 1))
DF = [pd.DataFrame()] * 5
print(r)
out = np.zeros(mask.shape, dtype=data.dtype)
col1 = df.col1.values.repeat([len(c) for c in c2.tolist()])
t = time.monotonic()
self.finished = -1 if error else 1
anchor_layout.add_widget(label)
worksheet1.set_column(1, 1, width)
seq_pow2(4)
httplib.responses[404]
outfile.write(a)
i = iter(list_of_strings)
sql = sqldb.get_session()
sys.stdout = NullIO()
green = np.random.hypergeometric(ngreen, nblue, m - red)
print((n, repr(readline(int(n), f, findex))))
regexes.append(build_compiled(r, p, re.DOTALL, code))
merged
json_obj = json.dumps(some_dictionary, sort_keys=True, indent=4)
w0 = np.ones_like(x0)
area = 460.0
new_start_date = localtime(self.start_date) + add_days
plt.show()
plt.plot(spect)
self[0] = value
print(supersets)
self.__parent__ = parent
self.assertTrue(testuser.upper() == user.username)
help()
rect_end = coordinates[1][0] + i, coordinates[1][1] + i
gen = func(*args, **kw)
RNG = random.Random()
str = PyString_FromStringAndSize(s, size)
lambda y: x
frame = inspect.stack()[1][0]
list(range(1, i, 2))
m = Mock()
Case(When(created__month=0, then=1), output_field=IntegerField())
soup = BeautifulSoup(html)
print ()
NotImplemented
True
a1.binaries,
string = string[first_full_stop + 1:last_full_stop + 1]
list = []
category = random.choice(list(lists.keys()))
self.created = datetime.today()
m = my_regex.findall(string)
shape1, loc1, scale1 = rv1.dist._parse_args(*rv1.args, **rv1.kwds)
tmp_arr.append(float(j) / float(a))
listC[1][1] = 100
f = norm.cdf(x, mu, sigma)
Progname = erl
p = find_key(v, value)
form.Show()
km.load_connection_file()
prefixed = []
a = np.random.rand(5, 4)
out, err = capsys.readouterr()
result.append(board)
b = test.keys()
sock.bind((sourceIP, 0))
shape[:arr.ndim] -= window - 1
str(stepNode.childNodes[0].nodeValue)
product = np.dot(M, F)
arr_1 = np.array(multidim_list)
result
gs.tight_layout(fig, rect=[0, 0, 1, 0.97])
invf._update(record[name], record)
a = iter(l)
b & 1 == 0
np.save(f, data)
numpy.asarray([my_list])
a.x2 = a.x2.shift(1)
self.parent.weaponDestroyed()
synonyms = wordnet.synsets(text)
pyplot.plot(xnew, heights_smooth)
udp_port.socket.setsockopt(socket.SOL_SOCKET, IN.SO_BINDTODEVICE, dev)
my_saved_data = json.loads(string_from_file)
arr[j:, (i)] += arr[:M - j, (i + 1)]
html = bs4.BeautifulSoup(r.text)
print(dataf.to_string)
node.end()
bases = set(inspect.getmro(type(next(iseq))))
raw_data = u.read()
label = encodings.idna.nameprep(str(label))
True
[nested]
self[key] = self.factory(key)
instance = request.user
next(c)
loop = asyncio.get_event_loop()
s = pd.Series(test)
queryset
Py_TPFLAGS_CHECKTYPES = 1 << 4
exec_globals.update(copy_globals)
inspect.ismethod(Foo.bar)
self.write(data.decode())
pylab.plot(X[list(range(1024, 2048)) + list(range(0, 1024))])
Y = pdist(X, f)
plot(xdata, ydata)
x[:] = (value for value in x if value != 2)
line[:7] + [line7] + line[8:]
mod = inspect.getmodule(frm[0])
self.age = age
foo = e.module
edid = get_regval(regkey)
new_seasonal_indices.set_shape(seasonal_indices.get_shape())
df
c = OSC.OSCClient()
lambda x: f(g(x))
ruamel.yaml.round_trip_dump(data, fo)
result
T = 0
ar[1] = np.arctan2(vect[1], vect[2])
time.sleep(1)
next(build_generator(a, v * 2 + 1, mid + 1, end))
some_node = some_node.getchildren()[0]
tree = ET.parse(io.BytesIO(content))
callable(c)
file_like_io.tell()
word1[1:] == word2[1:]
data = []
self.L.remove(k)
y = np.matrix([0, 1, 1, 0]).transpose()
print(b.Pear)
args = sys.argv[1:]
x = np.random.randn(500, 500, 500)
self.actions[cond_1, cond_2]()
time.sleep(sleep_time)
print(attr)
len(u.bytes)
im2 = cv2.bitwise_and(destination, destination, mask=mask_inv)
nL[i] = 1
0, 0, 0, 0, 0
new, = new.nonzero()
paths.append(child_path)
V = np.zeros((n // BSZ, BSZ))
print(factorization)
re.compile = lambda pattern, flags: re.my_compile(pattern, flags | re.DOTALL)
x = np.arange(0, 100, 1e-05)
line_list = line.split(delimiter)
self.rows.append(self.cells)
layout = QtGui.QVBoxLayout()
print(x)
x = f(x)
a = ABC(func)
owner = db.ReferenceProperty(Human, required=True)
cnt = np.bincount(a)
sys.stdin = os.fdopen(fileno)
new_time = now + datetime.timedelta(seconds=time_in_seconds)
self.name = Name
r = cv2.boundingRect(pts)
raise MyConfigError(e.message)
self.parent.notifyChange(self.id, strChange)
bytes_in_file = self.tell()
date_cand = datetime.date(*map(int, date))
job = Job.objects.filter(client__id=pk)
G.add_edges_from(removed)
lmaorofllolwtfpwned
_check_something
sum(1 for v in r if v % divNumber == 0)
count = Counter(fragments())
o.append([x])
params = [c1, mu1, sigma1, c2, mu2, sigma2]
window.append(line)
predictions = model.predict(X)
wall(2, 5)
count(char, text, spot + 1)
Base = declarative_base()
lines = []
print(useful_word)
req = urllib.request.Request(url)
items = []
self.unregister(user)
i += 1
fscale = freq_scale.lower()
data_1 = np.random.randn(len(categories))
host = socket.gethostname()
ButtonsApp().run()
axes_2.add_patch(Ellipse1.art())
height = rect.get_height()
self._instance
0
cols = df.columns
target = NP.empty(shape=s.shape, dtype=NP.float)
glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_WRAP_T, GL_CLAMP)
d.append(e)
file.write(x)
self.trayIcon.hide()
print(df)
self.key = key
self.form_valid(form)
x = arima_mod.aic
crypts = []
sorted_ids = ids[sidx]
x = np.zeros(10)
constructors = set(_shared_tasks)
print(density)
counts[value[1]] = counts.get(value[1], 0) + 1
merger.merge(position=0, fileobj=path)
port = 1219
form = ProductAdminForm
di_str = dict((str(x), y) for x, y in zip(list(di.keys()), list(di.values())))
p = Process(target=func)
output = dict(zip(year, file_contents_values_grouped_by_year))
m = v.shape[0]
L[i] = L[i + length]
binary_data = xmlrpclib.Binary(handle.read())
df_b = df_a + np.random.randn(5, 7)
dll.get_buf.restype = c_char_p
fig = plt.figure()
self.remove_edge_by_id(edge.id)
s.write(datum.data)
print_data(data)
t.start()
print(args)
response
start = (len(A) - 2) / 2
print(d)
self.host = host
cd = os.getcwd()
[[]]
self.add_child(child)
ax0.imshow(image, cmap=plt.cm.gray)
closed.append(name)
PyObject * dict
last.append(val)
get_stems_recursive(remaining, partial + [stems[i][0]], result)
formats.py
9.99
s = pd.Series([[col] for col in df.columns])
element
o = A()
f = lambda t: len(t[1])
help(cv2.xfeatures2d)
form = EmployeeForm()
fedora
response = profile.runcall(app, environ, start_response)
cyts = aliased(TextString)
denom = [c10 * 10, c20 * 20, c50 * 50, e1 * 100, e2 * 200, e5 * 500]
a, b = tee(iterable)
answer = []
OrderedDict(fields)
assert a[0] == 2
self.rows = []
bool(parsed_url.scheme)
print(logging.getLogger().handlers)
x, y = inv.transform([(event.x, event.y)]).ravel()
print(e)
parsed_output.write(window[0])
pygame.display.update(pygame.draw.circle(srf, color, (x, y), radius))
fig, ax = plt.subplots()
mail = Mail()
x = csv.reader(a)
np.linalg.norm(v)
self._str.upper()
[account1]
L1 = [a, b, c], [d, e, f], [g, h, i]
self._save(saved_name, ContentFile(saved_source))
q = {tdk: []}
lines.append(line)
raise ValueError
email = models.EmailField(max_length=100)
self.__str__()
body
start = time.clock()
df1.Moves = g.sum()
pickle.compatible_formats
validation_images = images[~mask]
total_count = Content.objects.count()
to_self.close()
len(train)
print(r_dataframe)
fig, ax1 = plt.subplots()
s = [[str(e) for e in row] for row in matrix]
self.index = 0
src = mlab.pipeline.scalar_field(s)
L1.sort(reverse=True)
instance = Test()
patcher = patch(module_name, **kwargs)
f.close()
newlist = mylist[n:]
WORKDIR / code
norm = np.linalg.norm(v, ord=1)
n = 0
A1 = ((A1 + offsets) / norms).T * priorita
t = np.linspace(start.value, end.value, 100)
[False, True, False, True, True],
fig.subplots_adjust(bottom=bottom + textHeightFig, hspace=newHspace)
NULL
date_time = datetime.now()
axmatrix.set_xticks([])
dv = list(d.values())
{0, 4, 5, 6, 0, 0, 0},
a = [l[i] for i, flag in enumerate(flags) if flag]
self.app = QApplication(sys.argv)
y_train = Xy_train[:, (0)]
print(a)
root.mainloop()
bar.bar()
example[1:5]
attr = getattr(obj, name)
l, extend(r)
o, e = process.communicate()
farming_details = {}
print(dateobj)
self._x
MyFancyNumber(5) / 4
method_code = inspect.currentframe().f_code
v = tf.Variable(0)
x - x
data = np.array(img)
dtype = PyArray_DTYPE(arr)
mdd, start, end
print(sum(asDigits(2 ** 1000)))
folders.append(path)
m & (np.cumsum(m) <= stop)
sigma = sum(y * (x - mean) ** 2) / n
df
print(result)
fdir, fname = os.path.split(fpath)
newfoo
share_memory(a, f)
test_data = np.delete(data, indices)
panel.SetSizer(sizer)
file = vacation.jpg
nexts = cycle(islice(nexts, pending))
print(item)
bar()
textarea.replaceWith(contents)
print(repr(encoded))
doc4.txt, PROBABLY
a = np.exp(a) / np.sum(np.exp(a))
beam.io.fileio.TextFileReader.__iter__ = _TextFileReader__iter
sys.excepthook = custom_excepthook
self._handle = hwnd
killasgroup = true
full_arr.nbytes = 20854577808
axmatrix.set_xticks([])
cython >= 0.2
print(t2.extractfile(name).read())
print(variable)
print(link)
print(dt)
count
list(uniq.keys())
print(serial_out)
scope.GetVariable(variable)
pyplot.ion()
img = np.frompyfunc(calc_pixel, 2, 1).outer(np.arange(100), np.arange(100))
print(n)
ym_end = 12 * end_year + end_month - 1
b.pack()
df2
a[-2] = 5
obj = MyIter()
a + 1
print(r)
widget = QWidget()
print(np.column_stack((roots, p1(roots), p2(roots))))
print(concatd(a, b))
dt = dt.date()
model.add(Dense(output_dim=10))
vectorizer = DictVectorizer()
numline = len(file.readlines())
os.symlink(src, dst)
txt = [getPageText(url) for url in urls]
high = max(freq_count.values())
model = Sequential()
head, tail = os.path.split(p)
file.close()
df
b = Field()
x = 1, 2
result = a * b
array1 = np.array([10, 65, 200])
d = {}
spam = with_connection(spam)
next(incsv)
ips = [each[0] for each in re.findall(pattern, fileContent)]
intervaly = ysize / ysegment
print(repr(time_tuple))
ntype = type(n)
average[i, j] = 1.0 / 9 * matriz[i:i + X, j:j + Y].sum()
i += 1
print(lu_obj.solve(b))
remaining_items.append((item, dependencies))
args.func(args)
JM2[i, j, k] = jmat[k, i] - jmat[k, j]
print(c)
self.args = args
self.parent().unsetCursor()
q = nfqueue.queue()
i = 0
net.addLink(s1, s2)
_, exception, tb = sys.exc_info()
1
app = Flask(__name__)
a.as_integer_ratio()
id_arr[idx[:-1]] = -a[:-1] + 1
colors = matplotlib.cm.rainbow(np.linspace(0, 1, len(Ys)))
hp -= punch
saver.restore(sess, ckpt.model_checkpoint_path)
cur = db.query(sql)
np.cumsum(rng, out=rng)
x, y = randint(m, n), randint(m, n)
temp = np.arange(10)
fg.clf()
trp([], 4)
[e for sub in tgt if sub for e in sub][-5:]
edge_tuple1[0] == edge_tuple2[1][0] and edge_tuple2[0] == edge_t
matrix = np.array([[0, 0, 1], [1, 0, 1], [0, 1, 1]], dtype=bool)
basemetaclasses = []
print(hash)
count[0] = not count[0]
zi = griddata(x, y, z, xi, yi)
x = list(filter(n, x))
JM1[i, j, k] = jmat[k, i] + jmat[k, j]
counts = numpy.logical_not(a.mask).sum(axis=axis)
lst += [4, 5]
print(df)
m[x + int(y - 1) * N] = 1
cursor = db.cursor()
pyop_frame = frame.get_pyop()
print([x for x in funs()])
values = np.random.uniform(low=0, high=1, size=ages.shape)
sess.run(eval_op, feed_dict={data: some_testing})
JSONEncoder.default(self, obj)
maxscr = max(scores.values())
X = numpy.random.rand(9, 4)
os.path.normpath(string)
pendown()
N = 100
b = word in words
NEWLIST = []
value = parser.get(section, option)
data
print(crossover(f1, f2))
soup = BeautifulSoup(response.get_data())
p2x = tx2 * cosang + ty2 * sinang + cx
posts = session.query(visible_blog_posts).all()
p = pd.MultiIndex.from_product(df1.index.levels, names=df1.index.names)
test_equivalence_partition()
f = d(f)
count += 1
rgb = scipy.misc.toimage(cube)
atan_in_degress(1)
files = parser.parse_args().file
plt.semilogx(w, mag)
title = db.Column(db.String(80))
y = np.linalg.det([[a[0], 1, a[2]], [b[0], 1, b[2]], [c[0], 1, c[2]]])
endfun
allvars_good()
result = result[1:] + (elem,)
centerLat = sum(x[0] for x in self._points) / len(self._points)
yertle.penup()
obj = A(data)
A = np.random.rand(rows, latent_features)
self.max_val = 50000
kthsmallest(A[i:], B[:j], k - i)
rest = np.mean(arr[toslice:])
NULL
print(repr(y))
new_list = []
mplfig_to_npimage(fig)
dataDict = dataDict[k]
i = ord(x)
api.update_with_media(filename, status=message)
PyString_FromString(buf)
ascends[-1][0] = i + 1
arr
partition = []
app.url_rule_class = TranslateCorrelationRule
start <= x or x <= end
colors = np.empty(X.shape, dtype=str)
result
l = df.values.tolist()
hog = cv2.HOGDescriptor()
thread.start_new_thread(runserver, ())
root = Tkinter.Tk()
x2_Kcids_1[0, 0]
c = Counter(text)
sf.where(q1).show()
writer.write(x)
ofiles[fn].write(l)
cursor = conn.cursor()
[]
ET.tostring(y)
ax = fig.add_subplot(111)
deletea[:]
new_size = sys.getsizeof(d)
otherFunc()
print((graph, current_vertex))
2 + 2 == 5
rt.stop()
result = []
[g(x, fx) for x, fx in ((x, f(x)) for x in l) if fx]
can.save()
pl.plot(F_values_2, S_values_2 - width_S)
r = np.ones(shape=(rows, rows))
df
p = psutil.Process(os.getpid())
z.extend(y)
v = np.concatenate((v, v2))
resp = requests.get(baseUrl)
signals.request_started.connect(close_connection)
print(list(running_avg(nums)))
CrawlSpider.__init__(self, **kwargs)
False
list.__setitem__(self, index % len(self), value)
tmp = tmp.__next__
my_table = tables[0]
elem[i] += 1
a = bn.partsort(a, i)
thelen = len(trailing)
lr1 = LogisticRegression()
module = __import__(importModule)
out.append([typ(val) for typ, val in zip(castings, line)])
x = np.random.rand(1, ROW_SIZE)
gauss(x, amp, cen, sig)
inner = c[n, m] * math.cos(m * lam) + s[n, m] * math.sin(m * lam)
z1.writestr(n, zf.open(n).read())
factorial(n) / factorial(k) / factorial(n - k)
(d * w).sum() / w.sum()
self.y = y
std = np.std(stats)
[]
loop = asyncio.get_event_loop()
c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))
y = foobar(x)
foo(22, 42)
window = s.root.create_window(0, 0, 1, 1, 1, s.root_depth)
a, _, b = myTuple
result2 = np.reshape(result, result.shape[0] * result.shape[1])
self.title
model = Word2Vec(sentences, size=100, window=5, min_count=5, workers=4)
b_test.method_three()
im = cvLoadImage(filename, CV_LOAD_IMAGE_GRAYSCALE)
bundle.obj.save(update_fields=field_to_update)
print(l)
uncorrelated = np.random.standard_normal((2, N))
[w for t in taglist for w in words if w.startswith(t)]
modelinstance.picture.save(filename, file_contents, True)
keyRegex = re.compile(key, re.IGNORECASE)
f2 = plt.figure()
user = authenticate(username=username, password=password)
self.im.putpalette(*self.palette.getdata())
c.release()
username = self.SessionObj.settings.key().name()
arr1d = np.array(some_sequence)
self.list = lst
first_name = models.CharField(max_length=40, blank=False, null=False)
MOUSE_LEFTUP = 4
new = orig + datetime.timedelta(days=90)
_fork()
sys.stdout = MyStream(sys.stdout)
url
print(result)
ew.save()
print(result)
ax1.imshow(color_mask)
data = txtcurl.getvalue()
df_a = pd.DataFrame(a)
random_sample_input = random.sample(words, 100)
y = np.asarray(x.getdata(), dtype=np.float64).reshape((x.size[1], x.size[0]))
np.ndarray.__array_prepare__(self, output, context)
new_data.append(row)
a.join()
a_line, = ax.plot(*zip(*points))
D = euclidean_distances(X_cluster_0.getrow(0), km.cluster_centers_[0])
t = now.time()
print(df)
fmt_values = [formatter(x) for x in self.values]
pValue = PyObject_CallObject(pFunc, NULL)
np.diag(s)
df2 = pd.DataFrame(-np.ones(df.shape))
rdd = rdd.map(list_to_csv_str)
b = B()
translation.activate(request.LANG)
x, y = np.meshgrid(lin, lin)
order.append(item)
cor = df.corr()
results = [pool.apply(cube, args=(x,)) for x in range(1, 7)]
memmove(s.getData(), data)
print(make_hash([func.__code__, func.__dict__]))
_MyClass.instance = _MyClass()
x = next(it)
data = [container[key] for key in container]
pdffilename = sys.argv[1]
X, Y = meshgrid(xi, yi)
n = 0
evaluate(tagger, sentences)
print(gram)
self.server.stop()
f = tempfile.NamedTemporaryFile(delete=False)
block_number -= 1
p.ParseFile(f)
rtn
print(s.shape)
scipy.stats.stats
p = re.compile(pLu)
mydata = json.loads(output)
b(1, 6)(1, 2)
{{blog_form.as_p}}
alotoffunc.klm(self, x, y)
t_end = time.time() + 60 * 15
classifier = NaiveBayesClassifier(train, feature_extractor=my_extractor_func)
eval(equation)
pygui(true)
print(something.bar(12, 14))
sidx = lid.argsort()
args.output.write(text)
x = np.linspace(0, 10)
self.should_run = threading.Event()
u = pickle._Unpickler(f)
position = models.CharField(max_length=120, choices=POSITION_DESCRIPTORS)
d.pop()
readline.set_completion_display_matches_hook(print_suggestions)
c1 - c2
method_decorator.__init__
json.dumps(list(somecollection.find(expr)), default=newEncoder)
newlstTwo.append(lstTwo[i])
update = csr_matrix((N, m_ind, [0, len(N)])).toarray()
numpy_array == 0
p = ctypes.cast(names, ctypes.POINTER(ctypes.c_size_t))
df2
print(a.get_value() == b.get_value())
tuple(mydata)
spyder - -new - instance
threading.Thread.__init__(self)
round(2.5)
data_matrix
Mn
X, Y = map(list, zip(*R))
next(songiter)
raise ValueError
__call__ = lambda x: x
[dna_seq for dna_seq in DNA_list if len(dna_seq) > threshold]
print(jsonstring)
f.write(datatowrite)
handle = ExPASy.get_sprot_raw(accession)
date1 = datetime.date(year=2012, day=2, month=2)
MyFunc()
now = time.mktime(time.localtime())
self.items = []
m = np.dot(m, uad)
x = linspace(-10, 10, n)
outbuf = ByteTriplet()
app(environ, start_response)
lst[i] = e
d.update(frame.f_locals)
cursor = query.cursor()
list1
update_model(model, item_model)
mu = data.mean(axis=0)
self.root = tk.Tk()
print(Nickname)
m_to_M[1:, (0)] = -np.arange(1, n - 1)
lenc = a.shape[1] / c
int_div = a // b
v = c_uint16()
boxes.append(x)
ret[prevline.strip()] = {}
target.write(line)
a = 0
optimizer = tf.train.GradientDescentOptimizer(learning_rate)
server_url = models.TextField(max_length=2047)
five_lines = list(itertools.islice(sys.stdin, 5))
a = set(a)
y_int = np.polyval(poly, x_val)
otherStuff()
estimate = arima(data, order=c(p, d, q))
paks = rdpcap(INFILE)
text = wx.StaticText(self, -1, caption)
cell.font = cell.font.copy(bold=True, italic=True)
soup = BeautifulSoup(html)
t = numpy.array([0.22])
dstBB = ax2.get_position()
sigma = 100 * np.random.random(numcurves) + 0.1
[u.path() for u in urls]
g.series((x, 0), (y, 0))
False
x = x + 1
print(result)
mapper = class_mapper(obj.__class__)
size = sum(1 for _ in f)
a.append([])
work_list.append(new_item)
row = cur.fetchone()
b[0] - a[1]
ax.patches.remove(patch)
m.method()
radii = max_height * np.random.rand(N)
mask0 = numpy.sign(F_mid) == numpy.sign(F0)
key = lambda i: i % 2 == 0
hackedsyntax() - uglybuiltinsyntax()
hcumsum = np.sumsum(hravel)
result_list = []
pidfile.acquire()
globals()[someclass.__name__] = someclass
Ml[:, (i)] = sparse.coo_matrix(Ml[:, (i)].A + v)
m = multiprocessing.Manager()
aDict[name] = [(startTime, endTime)]
foo = forms.ChoiceField(widget=forms.Select, initial=self.foo_queryset)
train_op = optimizer.minimize(loss, colocate_gradients_with_ops=True)
self.draw_page_number(num_pages)
sys.stdin.read(1)
c.method_b()
executor = ThreadPoolExecutor(max_workers=2)
tmp = mydict[mykey] = myfunc()
force_proxy = connection.cursor()
names.append(field.name)
opener = urllib.request.URLopener()
b = [x for x in a]
struct = time.struct_time((2015, 6, 18))
self._secret_file
ax = plt.gca()
H, theta_edges, r_edges = np.histogram2d(theta2, r2)
print((row.id, row.val))
newstr
minT, maxT = theoryX.min(), theoryX.max()
A = [1, 1, 1, 1, 1]
app = wx.PySimpleApp()
p = pd.Series(np.random.randn(200) / 100 + 0.001)
df
list(filter(letter_set.__contains__, s)).lower()
finalResult = rdd1.mapValues(lambda v: v[0] / v[1]).collect()
response.status
list(d.items())
main()
a = some_string
primes = list(range(2, 20))
fcs.cchIconFile = 0
f(self, key, *args, **kwargs)
output.close()
pdb.runcall(foo.bar, x)
result.append(left[i])
i = 0
plt.ylim(0, 1.4)
lst[:position]
but.destroy()
equiv2 = dict((k.lower(), v) for k, v in list(equiv.items()))
cdll.msvcrt.memcpy(byref(v), byref(mystruct), sizeof(v))
show(layout)
exp_diag = np.exp(scale * diag_T)
1 + (max(map(depth, list(d.values()))) if d else 0)
bytes += len(line)
l.append(A())
comb = list(product(df.X.unique(), df.Y.unique()))
total += 1
Total = Total + int(Numbers)
print(page)
cofactors = transposeMatrix(cofactors)
intersections = []
new_array = new_array.T
quarter = pd.Timestamp(dt.date(2016, 2, 29)).quarter
result.reshape(nx, ny)
print(df)
c = numpy.diag(b)
df
os.mkdir(destination[0:len(destination) - 1] + path)
sorted(l)[-k:]
__add__ = check_shape(np.ndarray.__add__)
server.user(user)
x[0] = fractions.Fraction(1, 1)
names.append(data.read(len_name))
im = np.column_stack((im[:, 1:], im[:, (0)]))
pandas.core.series.Series
plt.xlim(vor.min_bound[0] - 0.1, vor.max_bound[0] + 0.1)
file.open(QIODevice.ReadOnly)
sample_dictionary[words].add(word)
print(time_between_two_dates_except_weekends(start_date, end_date))
db = CustomAlchemy()
document = Document()
reader = csv.reader(infile)
y_norm = y - y_mean
proposal
arr_win[:, 1:] = arr_cum[:, n:] - arr_cum[:, :-n]
self.c = c
print(myString, myList1, myList2)
print(x)
book.authors.add(george)
my_list = []
print(now, add_month(now))
p = Process(target=run_simulation, args=(simulations_to_run, results))
f10(5)
print(html2text.html2text(h2))
print(strc)
newdate = date.replace(hour=11, minute=59)
tmp.write(line)
new_instance
datetime(2009, 10, 1, 7, 0), datetime(2009, 10, 1, 7, 0)
echo(foo=foo)
data = numpy.concatenate((data, data_tmp))
self.setContextMenu(menu)
y = random.random()
f.close()
psycopg2.extensions.register_type(psycopg2.extensions.UNICODE)
b = g
g = [x[1] for x in g]
[f.name for f in matplotlib.font_manager.fontManager.ttflist]
fig = plt.figure()
q = queue.Queue()
list_result = [entry for entry in result]
args, unk = parser.parse_known_args()
r = np.random.rand(2)
data = np.random.normal(-200, 15, size=1000)
idces = df.index.intersection(df.columns)
max_x, max_y = numpy.max(iterable[0], axis=0)
e2 = str(e)
stack.pop()
x = 0
CO = np.cov(X_.T)
velcro.penup()
out.append(float(value))
zi = np.zeros((len(tim), len(jj)))
w, v = q[0], q[1:]
k = line.split()[0]
d.feeds[100].tags
x = list[indexInlist]
_format(format_string, args, ChainMap(kwargs, caller_locals))
logger = logging.getLogger(__name__)
self.parent = parent
a = arange(1, 20)
hours, minutes = divmod(minutes, 60)
rtn += message.get_payload()
w.set_visible(False)
sys.stdout = old_stdout
sort_slice = np.lexsort([dates.values, dates.notnull().values])
turtle.left(90)
source = ColumnDataSource(data=dict(x=x, y=y))
ax1.bar(dates, col1)
date = datetime.datetime.fromtimestamp(email.utils.mktime_tz(date_tuple))
elements = heapq.nsmallest(4, my_list, key=f)
l[0]
next(reader)
print(val)
self.timer.start()
BadSubClass.convert(anotherbase, 2)
self.vtkCells.InsertNextCell(1)
exit()
final_list = []
manager = urllib.request.HTTPPasswordMgrWithDefaultRealm()
[SomeDB]
self.clip = gtk.clipboard_get(gtk.gdk.SELECTION_CLIPBOARD)
v = list(range(n))
func(*(literalargs + arglist))
fig = plt.figure(1)
my_task.delay(target.value)
fig.scatter(df.index, df.icol(0))
i = np.argsort(a.flat)
path.insert(0, c)
P = np.zeros((n, n))
df
appstats_MAX_LOCALS = 10
err.printDetailedTraceback()
p = multiprocessing.Process(target=processWorker, args=(input, result))
print(x)
func = CALLBACK(wrapper)
self.kwargs = kwargs
file_str = f.read()
number += 1
print(row_format.format(name, *row))
model = MCMC(timesteps)
my_bytes.append(125)
args = argparser.parse_args(argv)
flows[maks], maks
foo()
most_popular({el: (0) for el in list(range(1000000))})
data = f.readlines()
res = AsyncResult(id)
code.py
m_to_N = lil_matrix((n - 1, n - 1))
label.pack()
pprint(Integral(x ** 2, x))
x + kth_comb(remove(x, elems), m - 1, k)
Base * get_base()
importModule = os.path.basename(path)
do_long_code()
output_lines = diskpart_output.decode().split(os.linesep)
print(cookie)
plot_clipped(data, center_x, center_y, radius)
print(self.crawled_urls)
x = np.empty((p.size, nIterates))
result.append(current)
GL.glMatrixMode(GL.GL_PROJECTION)
deserialized_user = User.load(serialized_user)
tf.reciprocal(y) * grad, -tf.div(tf.div(x, y), y) * grad
c.start(container, publish_all_ports=True)
array = df.values
print(dict_reborn[1])
source_image = pyexiv2.Image(source_path)
fp.seek(0, os.SEEK_END)
key = uuid.uuid4().hex
signal.alarm(2)
p = argparse.ArgumentParser()
df
Case(When(created__month=10, then=1), output_field=IntegerField())
frequencies[i] = frequencies.get(i, 0) + 1
print(tb1.head())
self.x ** 2 + self.y ** 2
a, b = json.dumps(a, sort_keys=True), json.dumps(b, sort_keys=True)
self._key_to_index[key] = len(self._values) - 1
self.finished.wait(self.interval)
max_len = max([len(col) for col in section])
int((x * 100).quantize(1, rounding=ROUND_HALF_EVEN))
ax = fig.add_subplot(111)
self._timeout = timeout
z[np.arange(5), np.arange(5)] = 1
cub_left, cub_right
_data = {}
result = cmp(fn(left), fn(right))
word_counts = Counter(cap_words)
np.log(scale), shape
url = self.queue.dequeue()
thetas += 2 * pi * np.random.random(thetas.shape)
print(sf.text)
starring = [name for name in starring if name.strip()]
cnt[word] += 1
self._read(fp, filename)
cur = dbconn.cursor()
init_op = tf.initialize_all_variables()
print(r)
i = 0
list(_f(seq, idfun))
word = word[-1]
print(best_f, best_state, map(sum, a))
nodes[-1].notes.append(body)
arr = np.zeros(shape=(M, N), dtype=int)
df2.loc[-2] = [14, 15, 16, 17]
result = pool.apply_async(fill_array, [val])
ip = IPDB()
ret
x = np.random.rand(n, 10)
next(gen)
k2 = a.__class__
arg = np.argmin(a[mask][:, (0)])
filters.append(Q(mailbagstats__num_letters2__gt=int(cut)))
freakExtractor = cv2.xfeatures2d.FREAK_create()
+c * sin(u)
b = arr.reshape((n, m))
list_index += 1
use_production = True
rows = mask.all(axis=1)
pipe(list(range(4)), mapcat(lambda i: repeat(i, i + 1)), list)
plt.fill(thetabox, rbox, facecolor=my_cmap(colorv))
d.update(100)
df.plot(subplots=True, layout=(2, 2), **opt)
d_sum[topkey][key] = new_val
run(host=socket.gethostname(), port=8000)
something
foo(1)
RSI1.plot()
req.setRawHeader(headerKey, headerValue)
print(domain)
self.output_file = new_output_file
c = db.cursor()
args.insert(0, name)
mask = np.isnan(df.values)
a[10:18]
x.translate(xtd)
f = random.choice(files)
self.belltimer = wx.Timer(self)
__init__.py
rest, tail = os.path.split(s)
chart.Activate()
cosetCoding.cosetCoding(10, 11, 8, arr, 0)
number, rep = (input().split() + [1])[:2]
self.send_error(400)
arr_cum = np.cumsum(arr == search, axis=1)
w = wcs.WCS(f[0].header)
digits.append(n % 10)
self.p.terminate()
df
self.is_expired = True
[(int(g) if g.isdigit() else g) for g in re.split(pattern, x)]
out = np.zeros((nr - 1 + nrows, nr))
client.close()
formatter = self.formatter
is_valid = True
a = df.values[:, (b_c_idx_locs)]
idel = len(L)
n = len(l)
sct.norm.sf(x=50, loc=60, scale=40)
pais, lats, lons = [], [], []
count = np.zeros(data.shape + (N,), dtype=int)
_shortcircuitmiddleware
p.__code__.co_varnames
print(s)
y = eval(input(x))
y = y[0].rstrip()
actions = ActionChains(driver)
self._data.pop(index)
lines = chunk.splitlines()
thebytes = pickle.dumps(myObj)
data = []
vid = Column(Integer)
b()
pdf = stats.beta.pdf(x, *params)
count += 1
parser.write(configfile)
l2 = [([x] if isinstance(x, str) else x) for x in l]
out = abs(m - n)
n, bins, patches = ax1.hist(y, bins=50)
seen = set()
smoke_test()
data = scipy.misc.imread(fname)
keep = ~numpy.isnan(w)
k_map = Korean()
ax.add_patch(patch)
df
trends1 = api.trends_place(1)
print(args)
{}
self.errors = errors
self.bark = bark
l = list(range(1, 100))
muproc.current_process()._identity[0]
zipfile = ZipFile(StringIO(zipdata))
arr[i]
points = []
is_new_style_class(1)
True
d = Path(__file__).resolve().parents[1]
msg = ctypes.wintypes.MSG()
new_list.append(list2[0])
response_value = response_buffer.getvalue()
type(D)
a[0] = X()
condition = [True, True, True, False, False, True, True, False, True]
theta = np.random.uniform(low=0, high=2 * np.pi, size=n)
xs = np.arange(X)
root.right = self.insert_node(root.right, element)
Z = np.exp(-((X - 1) ** 2 + Y ** 2))
matrices[:, (2), (1)] = s
print(line)
xf = np.linspace(0.0, 1.0 / (2.0 * T), N / 2)
user = User.query.get(id)
np.exp(x)
match = re_hostinfo.search(host)
d.columns = list(range(d.shape[1]))
bob.hideturtle()
acls
X = np.zeros((len(x), c))
soup = BeautifulSoup(htmlstr)
len(vow_found), c.most_common()
plotted = ax.imshow(rand(250, 250))
48.6057858287
supersets = [listOfSets[0]]
result[i][j] = col_data
df[new_col] = [int(a != 0) for a in df[col]]
opendir.restype = c_dir_p
a = A()
t = list(t)
self.update(active=False)
data = s.recv(4096)
result.tolist()
print(line_text, file=sys.stderr)
print(item)
accounts = defaultdict(attributes.copy)
method2(method1)
running = False
2
x = np.linspace(0, 2 * np.pi)
a = A()
atexit.register(shutdown_logger)
self._paths = [x.filename for x in self.zfile.filelist]
False
processed_data = target.throw(FINISH_PROCESSING_SIGNAL)
cur = conn.cursor()
parser.print_help()
d[id(a)] = a
ascii_num += chr(integer % 1000)
d = PyModule_GetDict(m)
deck.append(item)
print(string[0:5] is string[-10:-5])
arr[1] = b
pir1(x, d)
spl = inputText.split()
not bool(self._errors)
store.add_cert(x509)
dict(mydict=code_to_generate_dict())
line1, = ax.plot(x1, np.sin(x1))
print(res)
ExitAndDestroy(sys.argv[0])
assert text.find(field_key) == field_value
self.graph.update_from(new_hexbin)
handlers.append((re.compile(regexp), f))
list_words
db.put(entities)
5.25
9.75
9.7
9.8
print(p.dfsh(2))
print(identified_range[0].start, identified_range[0].stop)
Z = np.array([1.0, 1.0, 1.0, 1.0])
args[0].__round__(*args[1:])
recur(n - 1)
text = nltk.Text(nltk.tokenize.word_tokenize(input_text))
ncol, nrow = len(df.columns), len(df)
propagate = 0
list1 = list(range(x1, x2 + 1))
y = math.radians(i) * math.sin(math.radians(i))
dyn = gcs_data.Dynamics(id=file_name, filename=file_name)
k = list(self.keys())[-1]
printinstance(dict)
hxs = HtmlXPathSelector(response)
lst[0][0] = 5
gdb.stop_event_loop
df = pd.concat([df_current, future])
s.sendall(sys.argv[1])
REVERSE_MAPPING[val] = key
logdata = np.log10(data)
print(stdout)
p = subprocess.Popen(cmdstring, stdin=subprocess.PIPE)
tvalues.sort()
result = schema.dump(obj)
item in self._inner
lcms = ctypes.windll.lcms2
new_data = data[mask]
root = Tk()
f = os.path.splitext(f)[0]
multiprocessing.freeze_support()
()
0 in a
grid.append([])
binds.update(dict.fromkeys(staff_metadata.sorted_tables, staff_engine))
conn = TimeoutHTTP(host)
997
lookup_mapping[k[:2].lower().lstrip()].append(k)
mydata = urllib.parse.urlencode(mydata)
p.haslayer(UDP)
max_val = seq[0]
things = [list(s) for s in raw]
False
sum_by_key[sum_key] = value
print(list(split_text(b)))
on_exception()
subform.initial = data
helper(old_stack, new_stack)
(0.1).hex()
g = sns.JointGrid(x, y, ratio=100)
df
make_adder.__code__.co_consts
slast = slast.split()
mutable[0] = int(mutable[0])
PLT.subplot(111)
myclass = MyClass()
labels = [str(x) for x in values]
display.start()
user.save(using=self._db)
bitbuf = bitdata.bytes()
recall
__all__.append(obj.__name__)
rows = data[0]
BrotliCompression.Compress(input, output)
System.err.println(i.tmp())
input.append(client)
data[:, 1:-1] = 0
self.value
val = int(foo)
wordbank[word] = 1
my_code = eval(code)
self.vtkPolyData.SetVerts(self.vtkCells)
self._test
bar.txt
yticks[::int(len(yticks) / 10)] = keptticks
{0, 0, 0, 0} // sentinel
lock = threading.Lock()
y = np.random.uniform(0.0, 10.0, 15)
indptr = np.append(indptr, nnz)
k.__name__
ax = fig.add_subplot(1, 1, 1)
False
print(modname)
R = 1.5 + (0.1 * np.random.random(15) - 0.05)
print(ans)
i = input()
leng(isChar(s), 0)
paths.extend(find_all_paths_aux(adjlist, node, end, path))
config, ind, bsi = load_yaml_guess_indent(open(file_name))
unique_idx[mov_avg > 0.5]
print(sys.path)
movie_dict[actor].append(movie_name)
data = [int(x) for row in sys.stdin for x in row.split()]
fflush(stdout)
response
list(long_dna)
df
rtn
seen = set()
this_module = sys.modules[__name__]
students = list(map(Student, reader))
api = tweepy.API(auth)
user = models.OneToOneField(User)
parser = etree.XMLParser(remove_comments=False)
buf = f.read(chunksize)
xf = np.linspace(0.0, 1.0 / (2.0 * T), N / 2)
Z2 = np.array([0, 1, 0.5, 0])
mat = sps.lil_matrix((len(df), len(vocabs[i])))
df.equals(expected)
ipcounter = 0
main()
fh_out.write(i)
total += 1
c.NotebookApp.enable_mathjax = True
l.extend(f(i))
introspector = request.registry.introspector
pmat.__doc__ = parser.format_help()
result[0].content
gc.enable()
n, r = divmod(n, BASE)
lists[item[:5]].append(item)
flip_stack_helper(s, Stack())
Derived.my_fun(Derived)
self.parent = ParentClass(1)
tokens = re.findall(command_pattern, f.read())
dic[key] = dic1[key] + dic2[key]
myframe.pack(fill=BOTH, expand=YES)
d1 = dict(itertools.islice(i, n))
h - prtns.tolist()
i = i + 1
t2.start()
temp.append(t)
line = line.upper()
self._ref1 = ref1
fd.write(a[(i), ...].tobytes())
weights[i] -= step_size * derivative
print(really_really_long_variable_name)
tform = ori2cent.dot(rmat_z).dot(rmat_y).dot(rmat_x).dot(cent2ori)
print(lists_dict[key])
0
result = self.apply(f, reduce=False)
actions
file_contents = tf.read_file(filename)
colors = sns.diverging_palette(20, 220, n=4)
l.index(X(is_odd))
response = opener.open(url)
top.after(100, on_after_elapsed)
logger.addFilter(NoParsingFilter())
song = Song.objects.get(id=song_id)
0
message
a = models.IntegerField()
roi = im[y1:y2, x1:x2]
q = Company.query.filter(Company.id.in_(company_ids_page))
total_sum = sum(lst)
y = sig(x)
opt_fun = lambda x, a: f(x, a, user_b, user_c)
last = next(it)
result = [dict1[k] for k in set_operation_result]
alpha = 0.0025
s = s.reindex(idx, fill_value=0)
numpy.iinfo(numpy.uint64).min
fragments = self.getDiffFragments()
parser = argparse.ArgumentParser()
r.instance_b_placeholder.save()
print(do_add(s, 2))
foo = [[]] * 4
item = stack.pop()
print(c_range_obj.start, c_range_obj.step, c_range_obj.len)
setattr(Search, option, make_set_condition(option))
df
self.update_prop(image, orig_handle, legend)
noclubs = list(suits)
f = Foo()
r = np.linspace(0, 1, 100)
l.pop()
annotated_films.append(film)
df = pd.DataFrame(a)
authinfo = urllib.request.HTTPBasicAuthHandler()
screen = pygame.display.set_mode((200, 200))
endif
sl.insert(0, i)
utc_time = datetime.utcnow()
fig = plt.figure()
print(i)
empty_shared_array(ndarray.size, ndarray.dtype, lock)
AppHelper.runConsoleEventLoop()
False
f, line = lookahead_line(f)
pred = pipe.predict(test)
node
p = abs(d.as_tuple().exponent)
run = True
W = np.arange(N * N).reshape(N, N)
Py_INCREF(x)
self.name = name
a = 1
minimum, maximum = float(minimum), float(maximum)
fd = open(f)
slices.append(slice(0, 1))
do_something(result)
get_pixels.restype = ctypes.POINTER(ctypes.c_char)
fd.close()
print(trends)
fb_ = np.zeros_like(zeta)
sum_prods = arr1.dot(arr1_weights)
torfile = libtorrent.create_torrent(fs)
mock.assert_called_once_with(n=40)
df2 = df2[meds.index]
seq1 = list(range(1, 11))
args = parser.parse_args()
freq = collections.Counter(xs)
loop.run_until_complete(coro())
print(request.LANGUAGE_CODE)
i = np.arange(N)
q = model.all()
print(list(truncated_range20))
root = tk.Tk()
print(field)
idx = np.array(list(range(len(xhash))))
rex = re.compile(file_name)
csv_writer = csv.writer(fou)
c = b
d.append(b)
box.pack(side=tk.TOP)
m.start()
P = np.matrix(np.eye(4)) * 1000
plt.plot(data)
parser = create_pmat_options()
False
n = npseq.shape[0]
self.v = v
df
self.crawler.configure()
Var1 - 1
django.VERSION < (1, 7)
print(a.result())
yesterday = now + datetime.timedelta(days=-1)
plt.figure()
driver = webdriver.PhantomJS(desired_capabilities=dcap)
data = f.read(4000)
thistime = time.time()
games_won = winners.sum(0)
print(table)
min_x, min_y = numpy.min(iterable[0], axis=0)
samples.index = samples.index.get_level_values(1)
a = np.zeros(10, dtype=str)
item = self.queue.get()
ax2.imshow(img_masked)
n = len(S)
a = [True, True, False]
fd.truncate()
L = []
pixel_shape = box(llx, lly, urx, ury)
c = [C[k] for k in range(len(C)) if k not in (i, j)]
c = canvas.Canvas(filename)
ret += line.split()
l.append(e)
self.assertEqual(common, subset)
result[I] = func1[zeta[I]]
print(word)
instance.created_by = user
maxEl = max(element[0] for element in elements)
doStuff(e)
uuid_generator = (line.split(SPLIT_CHAR)[UUID_FIELD] for line in file)
ygen = (y[i:i + 10] for i in range(0, 1000, 10))
buffer_string = buffer_string + ser.read(ser.inWaiting())
normal = np.array([1 / length_dT_dt] * 2).transpose() * dT_dt
x = 1
c = Castro()
D = where(K, A, B)
n.parentNode.removeChild(n)
b = int(split_text[1])
d = {}
stripped_code = output.getvalue()
b[a < 40] = funcA(a[a < 40])
grouper = mi_df.index.get_level_values(0)
pos = haystack.find(char, pos + 1)
g.a.append(5)
client
df.Knownvalue // 10
ax2 = fig2.add_subplot(111)
do_something_else_1()
print(procd)
g = df.groupby(group_col)[condition_col]
result_item.append(l)
your_dict = {}
lowdimtest = mat(testX) * pcmat
plt.figure()
httplib.__file__
pylab.plot(bins[:-1], n)
Counter(more_itertools.windowed(s, 2))
app.register_blueprint(child.child)
comm.Probe(source=0, tag=22, status=status)
hits.append(word)
print(obs_values[0].firstChild.nodeValue)
answer = [s[idxes[i] + 1:idxes[i + 1] + 1] for i in range(len(idxes[:-1]))]
func(*a, **ka)
t.day
print(cake)
finalMessage += chr(ord(value[x]) + 1)
t.start()
final_file.writerow(current_user)
error_out()
screen, px = setup(sys.argv[1])
articles.extend(parser.parse_articles())
pairLambs.append(closure(p))
company, was_created = Company.objects.get_or_create(name=info)
es = Elasticsearch()
self.vtkCells.Modified()
formatter.format_help()
my_dict = {}
t.set_position((shift, 0))
ret = []
timers.append(t)
print([(sum_table[i + w] - sum_table[i]) for i in range(len(a))])
temp.close()
comparative
dd = defaultdict(list)
worker.setDaemon(True)
print(s)
timeit.timeit(lc)
fit = double_gaussian(x, params)
fig, ax
out = np.zeros((Y_idx.max() + 1, X_idx.max() + 1))
c.accept(list.get(i), i)
ts = int(time.time())
t.cancel()
nots = set(range(n)) - set1
zeta0_ = zeta[i]
figure()
res = ec2.get_all_instances()
hangflg = 0
d[word] += count
print(data)
pip - -version
driver = webdriver.Firefox(proxy=proxy)
a, b = itertools.tee(iterable)
len(defaults) >= len(arguments)
nplats = numpy.array(lats)
b2j.setdefault(word, []).append(j)
lowest_values = []
indices = list(range(len(source)))
df
aList = []
self.data = data
recur(n - 1)
candidate = remaining[0]
df = pd.DataFrame(randn(15, 20))
pdfStorage.put()
ipython = IPython.ipapi.get()
mapping = [header.index(x) for x in columns]
stream.stop_stream()
self.msgs = set()
accumulated = {}
c = Counter(s)
cxy
doc = webview.page().mainFrame().documentElement()
start = datetime.datetime.now()
print(df1)
coeffs, matcov = curve_fit(func, x, y, p0)
print(l_out)
reader = csv.reader(f)
out = np.zeros_like(skel)
print(ar + 2)
indexMatching(self.mylist, lambda x: x.name == name)
final_list.insert(0, lowest)
deck = powerpoint.Presentations.Open(inputFileName)
doc = LH.fromstring(content)
M = np.vstack([np.ones(len(xdata)), np.log(xdata), xdata]).T
d[tx, code].append(value)
node.isleaf = process(node)
x.run()
remove_all_subclasses(type, old_bases)
time.sleep(0.5)
x * 100
val
dtd.freeDtd()
cj = cookielib.LWPCookieJar(cookie_file)
output = np.column_stack((arrA.flatten(), arrB.flatten(), arrC.flatten()))
self.stream = self._open()
ax2 = ax1.twiny()
colors = 100 * np.random.rand(len(patches))
root = tree.getroot()
print(f(a))
players = sorted(enumerate(players), key=level)
run_ends, = numpy.where(difs < 0)
done += 1
file_contents = tf.read_file(input_queue[0])
step += inc
fig = swarm_plot.get_figure()
(d.day + 6) // 7
indata = in_file.read()
requests.__version__
self.flush()
seen = set()
foo.foobar
result = []
self.create_widget()
fcst_serie = pd.Series(data=pred1[0], index=fcst_index)
zap = lambda self, x: x + self.bar(x)
self.name = name
sys.exit(main())
temp = map(str, L[j:])
ok = False
accum_min_lst.append(val - max(x))
df
print(sds)
l = list(range(5))
AddressFactory.create_batch(4)
pool.map_async(func_worker, func_args).get(9999999)
day_of_year = (dt - datetime(dt.year, 1, 1)) // DAY + 1
a[1]
var1 = np.arange(1, 10, 2)
train_idxs = []
monkey.patch_all()
checkLower = check.lower()
help(cvxopt.msk.qp)
r * np.arccos(cos_lat_d - cos_lat1 * cos_lat2 * (1 - cos_lon_d))
sys.exit(1)
threading._format_exc = traceback.format_exc
b[b > 0] = 255
a - b
test.d = test.d + 1
workingObj.methodName()
b, c, d = -axis * math.sin(theta / 2.0)
request.url
writetoafile(file.strpath)
y = int(a, 2) ^ int(b, 2)
sub_comm.Disconnect()
root_logger = logging.getLogger()
fin.readline()
pyautogui.dragRel(0, 10)
output = io.BytesIO()
it1 = double_ints(map(itemgetter(0), it1))
linetext = QtGui.QLineEdit(window)
fList.append(fil)
cv2.line(vis, (x2 - r, y2 - r), (x2 + r, y2 + r), col, thickness)
shape[axis] += 2
next(gen)
item.setCheckState(check)
b.pack(padx=5, pady=5)
new_index = sorted(config.index)
new_buf.write(self.buf.read())
main()
stacked = dfs.stack(0).reset_index(level=1)
margs = [x.__repr__() for x in args]
print(int(x, 16), file=g)
data = np.random.random(N)
heapq._siftup_max(heap, 0)
channel_session_user_from_http
PrettyPrinter.__init__(self, *args, **kwargs)
last_idx = A2.shape[1] - 1 - np.argmax(A2[:, ::-1] < 0, axis=1)
python - -version
np.linalg.eigvals(A)
alpha.paste(circle.crop((rad, rad, rad * 2, rad * 2)), (w - rad, h - rad))
__builtins__
composed
o = []
ef
my_data = NP.random.randint(10, 100, 10000).reshape(1000, 10)
Frame.__init__(self, master)
df_b = pd.DataFrame(b)
res = {}
end.append(pop_dict[ind.mate])
hdfs = pydoop.hdfs.hdfs()
x, y = inv.transform([(event.x, event.y)]).ravel()
obj.Test()
data_from_django = {{my_data | safe}}
d[col] = {}
False
python - O
print(myCity.lower())
self.stopped = False
[TYPECHECK]
globals()[k] = self.monad[k]
NSScreen.mainScreen().frame().width
integer = int(hexadecimal, 16)
unfrozen_indices = [i for i, e in enumerate(lst) if not e.freeze]
self.it = it
self.b = b
a = list(range(100))
metadata = MetaData(bind=engine)
mapping[keyword.lower()] = mapping[keyword.lower()].upper()
profiling_wrapper
self.engine.createElement((0, 0), TriFader(SelectFileState), -240)
new_dict[pair[1]] = []
func_alias = mat.group(1)
time.sleep(sleep)
coords = np.vstack([item.ravel() for item in [xi, yi, zi]])
count = 1
record = Record.objects.get(pk=record_id)
sample_width = wave_file.getsampwidth()
a = iter(iterable)
deleteself
t1 = time.time()
instance.row.name
a = np.array([1 + 1e-10j])
pool = mp.Pool()
self.data = data
ax2 = ax1.twinx()
result
print(info_extract(soup))
b = traceTA * normX / normY
print(future.result(timeout=1))
table[-1][-1]
result = pool.apply_async(f, [10])
consoleHandler = logging.StreamHandler()
neis = g.neighbors(v)
dud_ = dud[:]
raise MemoryError()
bins = np.logspace(-2, 2, 20)
display.display(plt.gcf())
now_tz = now.astimezone(tz1)
list_keys = list_query.fetch(keys_only=True)
plt.xlabel(x)
len(x)
transformer = FunctionTransformer(drop_nans, validate=False)
batch.submit()
print(result)
func, args, kwargs = resolve(url)
html = clean_html(html)
wx.TheClipboard.SetData(clipboard)
print(value)
__builtin__.object = metaobject
line = next(irofile)
print(unpickledlist)
print(result)
print(test.vec())
setattr(local_module, key, getattr(module, key))
t = (k - 1) * s + n // pow(s, k - 1)
result.append(tree.pop())
mymetadata = sa.MetaData()
register = template.Library()
min_distance = distance(fList[0], fList[1])
start_subquery(lexer, lexer.lexpos)
out = sess.run(inference_net, feed_dict={inputs: batch[0]})
n_int = int(n)
a = Auction.new()
consumer_secret, access_token_key = access_token_key, access_token_secret
string
_int = int(string, base=16)
sys.stdir = sys.__stdin__
ax = fig.add_subplot(111)
s.replace(sep, sep + p).split(p)
Class1
ofh = sys.stdout
self.connected = False
anothername = myname
print(f.url)
last_row = df.index.get_loc(last[0])
words = nltk.tokenize.word_tokenize(p)
wallet = kwallet_example.open_wallet()
[x for x in Foo.__dict__ if isinstance(Foo.__dict__[x], property)]
d = defaultdict(list)
portfolio, err, errid, errmsg = ibm.get_account_update()
-1
media.write(recordbuf)
self.filter(age__gte=min, age__lt=max)
SOUTH = False
project = sys.argv[2]
IDs = sidx[np.searchsorted(cols, query_cols, sorter=sidx)]
b, c = next(gen), next(gen)
parser.unescape(text)
data = tf.cond(select_test, lambda : test_data, lambda : train_data)
desired_date = stored_date + tz.utcoffset(stored_date)
x = np.linspace(0, 600)
A.flags.maskna = True
False
page = urllib.request.urlopen(fish_url)
N = len(s)
name = Column(String(20))
evt.Skip()
panel = wx.Panel(self)
s = set()
run_number += 1
figure(0)
all_found = []
line = line.strip()
self.window = self.engine.rootObjects()[0]
d.update(buf)
self._maxlen
sum(it)
run()
r, w = select.select([A], [B], [])
data = [strace, mtrace]
average = sum(grades) / len(grades)
g.gremlin.execute(script, params)
coordinates = np.column_stack([x, y]) + 0.04 * np.random.rand(len(x), 2)
a[a != 999] = a[a != 999] > 5
f.write(word)
max_cnt = max(freq_list)
y = np.exp(-0.5 * x) * np.sin(x)
overall
fig = figure()
self.animal_set[0]
replaces = [(a + c + b[1:]) for a, b in splits for c in alphabet if b]
mylist.append(x)
hold(True)
out = np.dot(m, prior_reci) + np.dot(1 - m, 0.1 * prior_reci)
matches[1].ruleId, matches[1].replacements
sample = Column(postgresql.ARRAY(Integer))
func.__code__
True
AB = np.hstack((B, A))
self.__error = str(e)
EquivDiameter = np.sqrt(4 * Area / np.pi)
rsa_key = RSA.importKey(subjectPublicKeyInfo)
list1 = [1, 5, 8, 10, 50]
data = compressor.compress(inputfile.read())
w = b.widget()
PyErr_Print()
(matr for matr in matrix_g(n, m) if halfrank(matr, maxrank))
tran = ssh.get_transport()
colors_seen.remove(color)
some_iterable = list(range(1000))
pagenos = set()
body = extract_body(payload)
mybytes.append(x)
self.name = name
print(line)
a, b
intersect(cone, box.faces[0])
sink.write(input)
df
fig = plt.figure()
Fruit[6]
b = [6, 1, 0]
connection = Connection()
ws.set_horz_split_pos(1)
fig, ax1 = subplots(1, 1)
black = 0, 0, 0
pdfdoc = PDFDocument.alloc().initWithURL_(url)
self._min_x = min(self._min_x, x)
a = ndarray((5,), int)
B.__init__(self)
next(self.g)
password
values = ast.literal_eval(values)
out_csv.writerow((filename,) + row)
master_book = load_workbook(master_file_path)
stream.close()
args = parser.parse_args(argv)
checkForNonUnicodeHelper(parser.suite(codeString).tolist())
handle.write(block)
difference_in_days = abs((end_date - start_date).days)
resul += i
self.available_moves + self.get_squares(player)
open(URL, data)
a[key] = value
final = []
b = df.Bolean_condition.values
tree = scipy.spatial.KDTree(numpy.array(points))
r = requests.get(url)
s_y = center[1] - v_x[1] * (width / 2) - v_y[1] * (height / 2)
new_D[k.isoformat()] = v
digit_count = int(log(abs(n + 1), 10)) + 1
self.assertIn(k, d2, msg)
pc = prov_data.values[:, 1:5]
print(df)
exec(user_code)
list.extend(self, x)
sock.connect((ip, port))
A = np.empty((10, 10))
x
groups = defaultdict(list)
self.attrb1, self.attrb2
p = re.compile(reg)
N = A01.max()
interactive_legend().show()
w0[:len(x0) / 2] = 0.5
Foo.spam
lines = (line for line in stripped if line)
client = Client.objects.get(id=id)
cls._counter += 1
sig_keys[obj.signature()].add(k)
self.x + self.y
tvalues = np.zeros(n)
stacktrace = traceback.format_exc()
print(y)
c = count()
numpy.power(-1 + 0j, 0.5)
xvals, yvals = gca().axes.get_xlim(), gca().axes.get_ylim()
string = inspect.getframeinfo(frame[0]).code_context[0].strip()
self.gpa = 0
self.buf.seek(read_fp)
ax1 = fig.add_subplot(111)
value = next(it)
deq.append(i)
dst = np.zeros(template.shape, dtype=template.dtype)
foo(1)
failed_items.append(q.get())
img[y][x][1] = g
dask - scheduler
sum(map(pred, seq))
elements = []
print(ranks[a], ranks[b], count, file=file)
newvals[value] += int(value)
False
effectslist = []
Image.open(fout.name).show()
step = -1 if b < a else 1
traceback.print_exception(exc_type, exc_value, tb, limit=limit, chain=False)
WlanEnumInterfaces = wlanapi.WlanEnumInterfaces
b, c = arange(a.sum()), ones((m, n), dtype=int) * 999
print(type(vector_b))
deleteform.name
x < 2
sys.modules[__name__] = FutureMagic()
f_i = interp1d(x, y)
print([proj.a.text for proj in project_titles])
dec_lon = random.random() / 100
data_inside = cur.fetchone()[0]
img_tf = tf.Variable(img)
C_list = [5, 6, 7, 8, 9, 10]
main()
arrayTest.append(i)
logging.basicConfig(level=logging.INFO)
nsmap = dict((k, v) for k, v in list(tree.nsmap.items()) if k)
print(s)
y = [1, 2]
b = copy.copy(a)
meth(self, *args)
layout.removeWidget(widgetToRemove)
happy_array = np.random.randn(28, 28)
workers[0].name
0.00851202011108
0.00508499145508
raise MyError(100)
a = [1, 0, 1, 1, 0, 0, 1]
c = C()
deepReduce(f, deepReduce(f, y, xs[0]), xs[1:])
value = f(*args, **kwargs)
i += 1
update_hash(keys=keys, args=args, client=pipe)
recurse(v)
asyncio.set_event_loop(loop)
x = np.linalg.det([[1, a[1], a[2]], [1, b[1], b[2]], [1, c[1], c[2]]])
A.x
self.recording += 1
combined = Counter([1, 2, 2, 5]) | Counter([2, 5, 5, 5, 9])
rawdata = [(1, 0.4, 4), (1, 0.6, 6), (2, 2.6, 6)]
d = a.copy()
form.set_step(2)
print(cur_date)
x_b = points[..., 1:][..., (mask)]
next(iter([]))
maks_length = len(value)
np.logical_or.at(is_ok, b_vals, d_vals)
width, height = pb.get_width(), pb.get_height()
f = Foo()
ids = []
bar()
im = plt.imshow(data)
self._locked = True
col_mean = stats.nanmean(a, axis=0)
response_data = r.read()
result = unittest.TextTestRunner(verbosity=2).run(suite())
R = numpy.linalg.cholesky(V).transpose()
child.setText(0, str(val))
bytes += stream.read(1024)
v[i] = set((i,))
sA = A.sum(0)
x = [0, 5, 10, 15, 20]
response.status_code = 404
System.out.println(map.keySet())
p._pool[0]
red_float.convertTo(red, CV_8U)
ct_datetime = utc + datetime.timedelta(hours=current_ct_offset)
u, s, v = np.linalg.svd(a)
q = multiprocessing.Queue()
i = 0
print(begin.lower() + text.upper() + end.lower())
val = obj.__getattribute__(field)
win = Window()
df = pd.DataFrame(BSI, columns=Book._fields)
a - b
ncols = xl.book.sheet_by_index(0).ncols
url
float.__init__(value)
self.queryset = Resources.objects.filter(user=request.user.username)
xyi = np.floor(xyi, xyi).T
NEWLIST[j], NEWLIST[k] = NEWLIST[k], NEWLIST[j]
mat_inv[..., (1), (1)] = mat[..., (0), (0)]
client = pymongo.MongoClient()
ani = animation.FuncAnimation(fig, update_loc, 2500, interval=50, blit=True)
y = asarray(y)
tmp.append(i)
self.first_name
print(msg)
sub_category = [sub[1:] for sub in in_list if sub[0] == label and len(sub) > 1]
words = sentences.split()
Gui().run()
it = iter(list(range(10)))
lock = Lock()
x = datetime.date.today()
logger.addHandler(syslog)
main()
register = template.Library()
model = Clergy
self.c = c
np.unique(_25.index.get_level_values(1).minute)
ls - l / usr / local / bin / python
approximate_fraction(math.pi, 1e-05)
print(mat_sp[(idxs), :].todense())
False
_called_by_deffered2()
fh.seek(start)
ipython < file
l[index] = 0
obj.someforeignkey = another_obj.id
outcsv.writerow(list(result.keys()))
ax.set_title(col)
new_matrix = np.ones((len(matrix1), len(matrix2[0])))
unique_hash1 == unique_hash2
id(x1), id(x2)
seq.append((n, is_prime(n)))
start = cols[1].a.string
errThread.start()
print(np.sum(pdf * np.diff(bins)))
print(d2.sqrt(dot100))
tree = etree.fromstring(html, parser=etree.HTMLParser())
a.x = b
0, 0, 0
args = np.atleast_1d(*xi)
100, 0.217721, 0.218544
seq = [1, 0, 0, 2, 0]
objects = PersonManager()
spam.append(bar)
winner = np.argwhere(list == np.amax(list))
l = list(g)
p1 = list(range(N))
results = []
-------------Minute(0 - 59)
data = s.recv(1000000)
urls_d[url] += 1
modList = []
WSGI = WSGIResource(reactor, reactor.getThreadPool(), app)
attr(*args, **kw)
g = (x for x in range(10))
bar = []
k, self[k]
fig1 = figure()
sys.excepthook = print_traceback
df
print(docopt.docopt(__doc__))
1,
df
ticket
y = list(range(8, 20))
d = dict()
b = [-1, a, -100, a[2], -1]
np.random.seed(seed)
x0 = mu + sigma * P.randn(10000)
src = os.path.abspath(src)
install_data.run(self)
a = A(1)
c_ulong_type.tp_flags |= Py_TPFLAGS_CHECKTYPES
event = Event.query.get_or_404(id)
df.loc[tup] = 0, 0
mod = __import__(name)
y = np.arange(j - size, j + size)
f
interpreter = cpy
result = conn.search_s(some_dn, ldap.SCOPE_SUBTREE, some_lookup)
n_to_M = -2.0 * np.eye(n - 1)
clusters = [(p ** e) for p, e in list(collections.Counter(prime_factors).items())]
row_sums = a.sum(axis=1)
objects = list(Contest.objects.get(pk=id).image_set)
lines = file.read()
output = StringIO.StringIO()
x += 2 * p
f(p) + normal(0, 0.1, len(x))
jobForm.is_valid()
start = s.index(first) + len(first)
f.write(proto_graph.SerializeToString())
net.addConnection(FullConnection(bias, hidden0))
p = os.path.join(root, file)
6000000
dist_mat = np.zeros((data.shape[0], n_clusters))
True
func1d = lambda y, *args: optimize.curve_fit(f, xdata=x, ydata=y, *args)[0]
ret + 1 if (ret + 1) ** n == val else ret
matches = tuple(matches)
result = cx.eval_script(whatyoupostedabove)
self.mainFrame().load(url)
wynik[i] = 1
OLD_STDERR = sys.stderr
ip_addr = Column(String)
t = Timer(10.0, timeout)
clientsocket.close()
assert expected == actual
print(order_form.order_entries)
d0 = p[0] - b[0]
len(inspect.getargspec(add)[0])
l = l.split()
sum_ = sum_digit(n)
key = m.hexdigest()
a = np.random.uniform(10, 150)
dummy = [int(variable in search) for variable in variables]
aa = theClass()
rng = list(range(len(text)))
animal = form.save(commit=false)
Case(When(created__month=11, then=1), output_field=IntegerField())
primes.append(i)
last_run_at = self.maybe_make_aware(last_run_at)
arr = line.split()
ggknot < -data.frame(x, y, z, dcol)
print(hex(item))
a = [5, 7, 11, 4, 5]
deserialized_user = yaml.safe_load(serialized_user)
print((c.i, c.j))
dir(o0)
self.name = name
t0 = datetime.datetime.now()
next(randomLst)
match = False
print(row)
dists = numpy.sum((x - y) ** 2, 1)
clientImage = np.array(list(bitmapBits), np.uint8).reshape(height, width, 4)
def_ = Column(String(50))
s
vec < -numeric(0)
self.n += 1
r = pd.Series(index=s.index)
s = mat.shape[0]
localtrace
key.verify_init()
first = 0, 0, 0, 0, 0, 0, 0
self._test_fit([-1, 2], [4, 5], [[1, 2], [4, 5]], [1, 1])
self._lock = threading.Lock()
newarray[i] = oldarray[i]
x += y.A
thincows
tags = db.ListProperty(str, required=True)
assert numpy.all(data == reference[indexes])
0
lum_img = img[:, :, (0)]
conn.close()
a += 10
self._content.write(content)
print(logger.handlers)
y = np.array([20, 5, 4, 9, 11, 7, 25])
a = 1
fig.colorbar(cs, ax=axs[1])
query = query.filter(**{m2m_field: _id})
w0[:len(x2) / 2] = 0.5
random_tasks = random_lines(files)
output = []
g(5)
items[i + 1] = items[i]
full_backtrace = NULL
self[key] = value = self.default_factory()
response = urlopen(url)
loglevel = logging.INFO
path = os.path.join(dirpath, filename)
20000000000.0
xnew = np.linspace(0, 15)
xx, yy = np.meshgrid(x, y)
getpid()
obj = MyClass()
app = _force_https(app)
app.MainLoop()
cursor = query.cursor()
values.ensure_value(dest, []).append(value)
self.vmax = im.max()
self._method
4, 667
d = {}
a = np.array([True, False])
s = s.replace(f, r)
args[0].warned = True
image_path = os.path.join(drive, folder, image)
base_path = sys._MEIPASS
ranges.sort(key=lambda r: r.start)
s = tuple(iterable)
M = sparse.dok_matrix((6, 5), dtype=int)
exit(1)
c.listsquare
counter += 1
lud_bitmask = 0
content = response.read()
y = x[0]
name = StringField()
answer = []
c = stdscr.getch()
exit(1)
numpy_array = df.as_matrix()
a = np.outer(np.arange(0, 1, 0.01), np.ones(10))
tornado.options.parse_command_line()
print(x, y, x)
np.array(feature_names)[support]
args = list(args)
img = cv2.medianBlur(img, 5)
time = datetime.now()
list(p.map(partial(foo, depth=depth - 1), list(range(x + 1))))
table.add_row(row[1:])
print(type(res))
setattr(oTest, key, dic[key])
_PSID = _ctypes.POINTER(_wintypes.BYTE)
e1 = Entry(root)
max_rows -= len(chunk)
GLOBALLOCK = multiprocessing.Lock()
protocol = uwsgi
sess = tf.Session()
table.wrapOn(c, width, height)
img1 = np.uint8(np.random.randint(0, 255, (480, 640)))
a = A(6)
xvals, yvals = gca().axes.get_xlim(), gca().axes.get_ylim()
torun = np.array_split(sample, cores, axis=1)
queue1 = Queue()
print(newer_grammar.productions()[2091])
atof(str, int)
key.Close()
a = a.flatten()
mask = np.ones(len(x), dtype=np.bool)
jobs = [multiprocessing.Process(mc) for mc in montecarlos]
G = Graph()
result = (v for t in zip(data, tweets) for v in t)
debug(a=a, b=b)
g()
[51, 52]
array
time.sleep(5)
print(y[1])
exit(0)
df.index = index
Y[..., (2)] = 1
100
l
os.chdir(pf[0])
start = time.time()
klm = alotoffunc.klm
f = pickle.loads(s)
line = line.strip()
print(d)
row_y, col_y = meshgrid(list(range(y.shape[0])), list(range(y.shape[1])))
g.insert(gg, ggtrafos)
d.a
getsizeof(my_dictionary)
max_len = max(max_len, len(current))
run_once(loop)
d = defaultdict(list)
html_doc = urlopen(url).read()
self._real_add_job(job, jobstore, replace_existing, True)
np.array([ax2_cid[axs] for axs in x2_Kaxs.flat], dtype=object).shape
self.keep_interrupt = False
p.x
td.delta * 1e-09 / 60
ash
tstdata._convertToOneOfMany()
start += step
glVertex2f(0.1, 0.1)
main = http_message.maintype
show()
a
AC[j] = n
lst.append(triple)
pool = Pool(processes=num_processes, initializer=init, initargs=(tests,))
plt.hlines(0, 0, 2)
selfVar.__dict__.update(argDict)
args.extend(rest[index:])
results = service.data().ga().get(**params).execute()
dotprod / (magA * magB)
print(cmp(now, INF))
1
frame = cv.RetrieveFrame(cap)
coords[1::2, :, :] = coords[1::2, ::-1, :]
b[:9]
root_id = hex(Display().screen().root.id)
x[name] = np.random.randn(m, n, p)
assertDeepAlmostEqual(self, dict_1, dict_2)
print(data)
x + 5
Py_DECREF(args)
meta.save()
print(authed)
myDict = {}
nodes[1] = tuple()
action2.long_press(x=xx, y=yy).move_to(x=0, y=-50).wait(500).release()
resp
start = tpl[0][0]
i, j = numpy.nonzero(fpInput == True)
modulenames = set(sys.modules) & set(globals())
self.__dict__ = self
sys.exit(2)
bigd2 = dict([(x, random.randint(0, 1024)) for x in range(90000)])
names_list
self._cmd = cmd
session.add(model.SomeObj())
form = EquipmentModelForm
common_keys = set(next(keys)).intersection(*keys)
x, y = numpy.meshgrid(a, b)
w = CustomItemWidget()
di[pos][1][:] = listb[i]
response
found.append(pattern_list)
ssh = paramiko.SSHClient()
datetime(2009, 10, 1, 7, 0), datetime(2009, 10, 1, 5, 0)
func(1, 2)
first, rest = sub[0], sub[1:]
run = False
ea.Tags()
datetime.timedelta(someSeconds / 86400)
print(len(list(filter(is_div_two, r))))
lst_2d[0][0] = 5
size = os.fstat(f.fileno()).st_size
deletebar
formset = WorkoutInlineFormSet(request.POST, instance=workout)
seconds = np.arange(int(t[0]), int(t[-1]) + 1)
C = A * B
b = bytearray()
self.transaction = []
good_emails.append(email)
p.renderers.extend([vline, hline])
result = cache[self] = method_to_cache(self, *args, **kwargs)
x = SomeObject()
cache[args]
BLUE = 2
tmp[(1), :, :] = (1.2 - 0.8) * np.random.random_sample((sy, sz)) + 0.8
db = MongoClient().database
a = [1, 5, 9, 7]
visit_status = Field()
form = EditProfile(obj=user, website=user.site)
f = Foo()
print(byte & 1)
each.getFriends(degree - 1, friendList)
list(combined.elements())
unittest.main()
m = mmap.mmap(fd, 0, access=mmap.ACCESS_READ)
True
print((abbrev, text, result, answer))
item = q.get()
fh.seek(end)
main()
(lambda d=d: lambda : self.root.change_directory(d))()
print(a)
ys = np.linspace(ylim[0], ylim[1], resolution)
proc = psutil.Process(process.pid)
Py_DECREF(pArgs)
say_hello()
output_list.append(data_type)
nperms = factorial(nballs)
epoch = int(time.mktime(mydate.timetuple()) * 1000)
do_all(c.send(val) for val in generator1())
print(cell)
new_dict = abclass.__dict__.copy()
bin((1 << 5) - 1)
npmask = np.triu(np.ones((n, n), dtype=np.bool_), 1)
self.path = list(filename)
self.ig.add(self.rect)
F418c5c1
savimp(name, *x)
values = [(next(i) if v == smallest else v) for i, v in zip(iterators, values)]
print(get_diagonal(m, 1, 1, -1))
rec(16)
Unipath.Path(mypath).split_root()[0]
deletey
pos.update((n, (i, 1)) for i, n in enumerate(X))
print(libadd.Add(42, 1))
gs = gridspec.GridSpec(1, 2)
y = A(2)
os.remove(SECRETSDB_FILE)
self.wfile.close()
glClear(GL_COLOR_BUFFER_BIT)
self.write(params)
y = [4, 5, 6]
p.join()
A = 0.5 * ((1 - s) * np.cos(a - b) + (1 + s) * np.cos(a + b))
a[1, 0]
data = wf.readframes(chunk)
node_list = list(range(n))
image_y = np.zeros(image_yuv.shape[0:2], np.uint8)
out = np.zeros(dims, dtype=vals.dtype)
filenames = [os.path.join(root, filename) for filename in filenames]
dest = values_list[0]
np.s_[:540]
df
print(x)
float(1) / 2
variablename = new_value
0.00285911560059
matplotlib.rcParams.update(pgf_with_latex)
print(label)
sidx = count.argsort()[-N:][::-1]
env = os.environ.copy()
form.process()
self.__offset
p1.show()
self.panel = wx.Panel(self, size=self.GetSize())
all_objects = list(Animal.objects.all()) + list(Dog.objects.all())
words = line.split()
print(x_input, sess.run(y, feed_dict={x: [x_input]}))
check = np.ones((len(array_list), array1.shape[0]), dtype=bool)
Table(name, metadata, *(cols + constraints))
MAX_ITEMS_TO_HANDLE = 500
s
self.file_name = out_file
dict((p.key, p.value) for p in object_)
siftDown(A, 0, end - 1)
desktop_path = shell.SHGetFolderPath(0, shellcon.CSIDL_DESKTOP, 0, 0)
new_values = A[j], A[k], A[i]
first_reps = pd.concat([first_half] * repeats, ignore_index=True)
cnt = masks.sum(axis=1)
key, value = items[0]
result.append(child.strip())
i += 1
extractor.extractImages(args)
print(calc_tax(m))
length = int(mat.next().split()[-1])
size += sum(map(getsizeof, iter(d.values()))) + sum(map(getsizeof, iter(d.keys())))
rand1.seed(0)
print(d.quack)
pos = f.tell()
city = models.TextField()
pix[x, y] = value
print(new_string)
z[~np.isnan(a)] = zscore(a[~np.isnan(a)])
sub_foo(*args, **kwargs)
count -= 1
sArr = np.cross(np.array([1, 0, 0]), np.array(normal))
answer = sentence[0]
a = a + i
Popen(shlex.split(cmd), stdin=streams[i])
l.sort(lambda x, y: cmp(x[1], y[1]))
seen = set()
rebuilt_to_plot.append(np.int(num))
df
vol = m.getvolume()
decorator
text_to_number = {a: 1}
root_logger.setLevel(logging.WARNING)
bpy.ops.object.editmode_toggle()
label = Column(String)
sorted(list(s1))
f.close()
print(row)
points[:, (1)] = np.take(y_p, yi)
mpl.plot(x_vals, y_vals)
a.addHandler(h)
self.obj.my_attr.__hash__()
w = tk.Tk()
PlayerRole.objects.get(player=self).team
print(k, v)
pyximport.install(reload_support=True)
pool = Pool(processes=cpu_count)
source / etc / bash_completion.d / virtualenvwrapper
a = [5, 7, 11, 4, 5]
print(format_delta(self.begin, now()))
password.send_keys(password)
py_compile.compile(your_py_file, doraise=True)
f = lambda x: dgs[x.index].mean()
C.spreadsort(begin, arr.size)
rtranslation = [[1, 0, 0], [0, 1, 0], [tx, ty, 1]]
a[:, (c)] = np.inf
plot(a)
print((a, b))
x.seconds
print(find_joined_path(p1, p2))
self.queue.put(text)
time.sleep(5)
phone = UserProfileSerializer(many=True, read_only=True)
pprint.pprint(l)
print(f)
newList = []
l = [a, b]
fg = cv2.bitwise_or(img, img, mask=mask)
LOCALIZED = False
print(rec.title)
0, 0
self.w = w
out = np.zeros((m * n, n * (n + 1)), dtype=pts.dtype)
bar()
y = np.where(row)[0]
message[i] = (digest[i] ^ digest[i - 1]) * 129 % 256
now = imaplib.Time2Internaldate(time.time())
y = [0.5, 1.5, 2.5]
previous_values = {k: getattr(something, k) for k in kwargs}
print(r.status_code)
global_dict[key][value] += 1
s = listview(L, 2, 5)
data = []
print(p.map(f, list(range(6))))
print(d)
myvalue = eval(name)
index_list = []
the_dict = json.load(response)
df_ = df.stack().unstack(fill_value=tuple([np.nan] * 2))
telnetlib.Telnet.__init__(self, host, port, timeout)
list(i2)
x, y, dx, dy = geom.getRect()
numprocs = 1
ax2.add_artist(arrow2)
print(data.shape)
print(r1.status, r1.reason)
self.__class__(obj)
con = cql.connect(host, port, keyspace)
bin_string += bin(last_decimal)[2:].zfill(last_chunk_length)
text = text.replace(key, wordDict[key])
lines = []
sum = sum - 4 / (x * (x + 1) * (x + 2))
print(x)
FONT_HERSHEY_PLAIN
FONT_HERSHEY_TRIPLEX
mymetadata = MetaData()
max_freq = max(frequencies.values())
pitch = 60
pd.factorize(df.b)
left = 10 - len(lst[-1])
tok_format(node)
m.click(x, y)
conf.readfp(fd)
foo.bar = partial(foo.bar, qux=1)
SubClassWithoutDocstring.__doc__
print(getPointTotal([1, 14]))
f.truncate()
is_even_nozero(0)
token_uri = GOOGLE_TOKEN_URI
gdef_2 = g_2.as_graph_def()
label.set_line_wrap(True)
sys.exit(1)
bn = a[:, :, (0)]
lisdic = []
c = self.process.stdout.read(1)
bins_mean = [(0.5 * (bins[i] + bins[i + 1])) for i in range(len(n))]
df = d.copy()
groups = {}
customer_name = models.CharField(max_length=60)
self.other_data = [4, 5, 6]
strides = np.array(arr.strides * 2)
result = fn(*args, **kwargs)
directory = os.getcwd()
retval += traverse(node[1][2]) * node[1][0]
[0] * numColumns
apples()
id(x), id(y.x)
dis(foo)
fig = mlab.figure(1, bgcolor=(1, 0.7, 1), fgcolor=(0.5, 0.5, 0.5))
ctx.enter()
bytes = f.read()
print(me.__doc__)
False
somenamedtuple.box
x = cls()
output = []
q = Queue(maxsize=1)
index_name = df.index.name
print(img.shape)
g.get_all_shortest_paths(0)
ax1 = fig.add_subplot(111)
print(type(pickled))
res, counter
jinja2.Markup(loader.get_source(env, name)[0])
self.centralwidget = QtGui.QWidget(self)
df
unflattened = group(group(data, 2), 2)
cls(suds_data)
print(max_x, max_y)
m[mask] = a[mask]
10
avrg_count(phrase)
fl = fcntl.fcntl(fd, fcntl.F_GETFL)
timestamp
x1, y1, x2, y2 = np.random.uniform(-1, 1, 4)
b += 1
print(imp.reload.__doc__)
ownPid = os.getpid()
dt = utc_dt.astimezone(timezone(timedelta(hours=hours, minutes=minutes)))
arr = (ctypes.c_int * 8)(0, 0, 0, 0, 0, 0, 0, 0)
median = sorted(last_thirty)[15]
p.append(x)
pickle.dump(dict, file)
results.append(r)
sys.stdout = Out()
num != num
json_util.dumps(data)
user = backend.get_user(user_id) or AnonymousUser()
X_train = vectorizer.fit_transform(train_data1)
result.headers
words[word] = []
column_list = column_series.tolist()
[np.nan] * l
print(x)
type(uni)
outpath = os.path.join(out_folder, filename)
words[i] = word.capitalize()
result = str(os.getpid())
line = p.stdout.readline()
k[:] = U[(ind), :]
tap = dpkt.radiotap.Radiotap(rawdata)
class1()
df = {}
type(a)
result
a = a + 1
rowcount = results.rowcount
print(i.text)
parser = ET.XMLParser(recover=True)
ax1 = fig1.add_subplot(111)
items[i + 1:] = sorted(items[i + 1:], key=counter.get, reverse=True)
list.__setslice__(self, *args)
fig = plt.figure(figsize=(10, 6))
arg4
wrapper
pre_save.connect(default_subject, sender=Subject)
self.raw_tweets.insert(self.tweet_list)
bio_tagged_sent = []
mask = (a > 0) & (a < N)
count = Counter()
arr[x.index] = x
atmp = np.sort_complex(a[:, (0)] + a[:, (1)] * 1j)
self.__ntrue -= 1
print(a, b, c, d)
b = B()
plt.xticks(x_nums, xs)
res = capture.group(1)
print(k, list(v))
setting1 = 0
n = len(s)
met()
Gives - x + y - z < 5
all_points = numpy.fromiter(values, float)
modules = {}
Wizard.Button2.Click()
a.close()
self.flush()
result += new[i + 1:].upper()
job_id = uuid.uuid4().hex
prices / prices.shift(1) - 1
bus = dbus.SessionBus()
print(type(p).__name__)
ord(bytecode[i + 1])
backup = copy.deepcopy(a)
self.port = port
pid = os.fork()
min_mask = np.ones_like(pdf)
print(response_one.content)
r = np.linspace(0, 1, M.shape[0])
print(len(train_set))
_cell.style.font.size = 8
sftp.put(localpath, remotepath)
self.channel = channel
self.lower()
themsg = MIMEMultipart()
print(set(b) <= set(a))
self.b = 2
values.apply(reduce)
proxy = SOAPProxy(url, namespace=namespace, soapaction=soapaction)
int(item)
contour.append(numbers)
ax.yaxis.offsetText.set_visible(False)
map(next, map(itemgetter(1), groupby(iterable, key)))
bits = random.getrandbits(N)
c = [np.random.choice(np.flatnonzero(b == b.max())) for i in range(100000)]
img[img > 0] = 255
logOutput.setCurrentFont(font)
l.insert(lo, e)
out, err = proc.communicate()
c = a + b
rgb = map(lambda x: int(x * 255), colorsys.hsv_to_rgb(*rgb))
dir(a)
element.clear()
result = []
sum_of_two = other1 + other2
lst = []
a + b
column[h].append(v)
mat_inv[..., (0), (0)] = mat[..., (1), (1)]
outputhash.write(sha_1.hexdigest())
ax
t2.start()
a = [[(0) for _ in range(rows)] for _ in range(cols)]
columns = len(next(data))
frame = sys._getframe(back + 1)
cost = tf.square(Y - y_model)
Ciri
queue = asyncio.Queue()
points_right = np.copy(points_center)
x2 = 4 * np.random.randn(100)
v = eval(r[0])
root = tree.getroot().tag
root.append(child)
index = {}
self._data == other._data
p = argparse.ArgumentParser()
res = f(value, *args, **kwargs)
fig, ax = plt.subplots()
image = gkt.Image()
ctx = app.app_context()
out = np.empty(shape=(sz + S.sum(), P.shape[1] + 1), dtype=int)
j = [0, 2, 2, 0, 1, 2] + 1
print(self.a)
__builtin__.profile
line_indices = list(range(lines))
result.strip()
y - weib(x, p[0], p[1]) + penalization
sbuf = StringIO.StringIO(buf)
__getitem__ = xtend(list.__getitem__)
real_decorator
nested[outkey] = dict()
a.a = functor(a.a)
Server.Users.Get(username)
r += buf
b = ma.masked_values(a, error_value)
barycoords = np.dot(barytransform, grid)
childrenScores[box[1]] += 1
False
H5Tset_strpad(tid, H5T_STR_NULLPAD)
clientsocket, address = serversocket.accept()
line_offset = []
(_host, _ssh_port),
wn.NOUN
Point(-self.x, self.y)
sound = sound.set_channels(1)
False
print(tests.test_001.test_001_func)
thread.join()
seq = sys.argv[2]
myfile = StringIO.StringIO()
rect.set_transform(t_end)
f.close()
result = [func(group) for group in np.split(grouped, offsets)]
sum(1 for _ in islice(elements, n + 1)) <= n
0
g.WLPer.rank(pct=True, ascending=False)
x + 1
no_bonus = not (A and not (B and C))
x_vals = linspace(0, 10, 100)
seconds = dt.timedelta(seconds=int(date_string[7:]))
raise e_reraise
default_tagger = nltk.data.load(nltk.tag._POS_TAGGER)
(group_size, op), grest = groups[0], groups[1:]
z = np.linalg.det([[a[0], a[1], 1], [b[0], b[1], 1], [c[0], c[1], 1]])
Other().access_eclipsed()
aaa
1
matches = [m.group(0) for m in matches if m]
df = pd.DataFrame(all_dicts).T
conn.search(s)
summons = cells[1].find(text=True)
self.approved = True
print(list)
sess.delete(self)
s.add(obj)
Py_DECREF(res)
dis.dis(compiled_code)
alist.append(4)
first_line = msg[:pos]
B()
data = caffe.io.datum_to_array(datum)
rs = conn.execute(s, id_list=tuple(id_list)).fetchall()
index_pos = numpy.where(cond2)
tplFinal2, success = leastsq(ErrorFunc, tplInitial2[:], args=(x, y))
clf = NaiveBayesClassifier.train(list(make_training_data(reader)))
cp = nltk.ChartParser(grammar)
l = [1, 0, -2, 0, 0, 4, 5, 0]
self.func()
ope, clo
i -= 1
versions.sort(key=StrictVersion)
resp = conn.getresponse()
match = value_regex.search(strJunk)
pool.join()
rest = lists[1:]
arr[0] = a
Y = np.vstack(df.values[:, (-1)])
False
response = self.client.get(reverse(url.name))
all[:-1000] = []
output = output[:, :-1] + output[:, 1:]
drop_keys(recursive_dict[key], keep_list)
getattr(self.module, item)
print(strip_tags(html))
print(n, count[n] / 10000.0)
print(new)
s.item() == 1
self.register(user)
copyfileobj(input, output)
canonical_url(u1) == canonical_url(u2)
read(**kwargs)
runtime.LockOSThread()
self._a = a
__builtin__.object
country = models.ForeignKey(Country)
foo = Foo()
list_query = List.query()
a = c_ulong(16)
text = json.dumps(original)
client = Client(url)
print(powd)
self.lock = Lock()
stdout
result
p = Process(target=processData, args=(some_data,))
tf.seek(0)
newds = [d for d in self.ds if self._key in d]
indices.append(i)
self.localtrace
fft_axes = fig.add_subplot(212)
self.pt_plot.set_ydata(y)
np.ndarray.__array_wrap__(self, out_arr, context)
next(idxs)
real(int(r * 1000000.0 + 1) / 1000000.0, REAL_KIND)
r.get(fpKey)
draw.save()
chrCounter += len(line)
sk = lambda vi: (name_lambda(vi), vi.group, vi.tab)
self.hlayout = QHBoxLayout()
random.sample(possible_rolls, count)
this_week = []
rmat_x = np.eye(4)
total += 1
a = next(it)
l = []
main()
text = fobj.read()
mat_ds = np.random.rand(50000, 50)
self.data = data
result = regex.search(line)
uniq = np.unique(arr)
self.content_type = content_type
m = re.search(pattern, text)
X = np.hstack(X)
argmaxD = F[a, b, c, d, X].argmax(axis=-1)
sum(1 for _ in iter)
sub_face = image[y:y + h, x:x + w]
s.seek(0)
screen.force_update()
result = pool.map_async(worker, list(range(15)))
themod = new.module(themodname)
bb = a.view(float).reshape(a.shape + (-1,))[:, :2]
dd = defaultdict(list)
require(plyr)
self.__delattr__(key)
self.INITIALIZE = JOBSTATE_INITIALIZE
header = next(reader)
fig = pl.figure()
self._popup.show_all()
res += 1
print(a)
print(a.y_int(b))
self.im.seek(self.old)
d = {}
args = p.parse_args()
print(s)
toutput = defaultdict(set)
nums = [2, 1, 0]
file_data = blobstore.BlobInfo.get(str(the_document.blobstore_key))
a[0] = Register()
req.add_data(urllib.parse.urlencode(data))
self._bar
False
new[str(k)] = v
cpy_list.append(d2)
self._requests.append((request, queued_d))
data = models.TextField()
[self.delete_object(item) for item in related._deleted]
readable[fd].flush()
print(format_date_time(stamp))
messages = db.ListField(db.EmbeddedDocumentField(Message))
l.append(X)
tree = compiler.parse(x)
dir(test)
filtered = (i for i in a if i == 1)
np.maximum.accumulate(x, axis=0, out=x)
request.response.status_code = 400
foo
ip = job_q.get()
page = opener.open(httpReq)
EXIT / B > NUL
glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR)
id = child.GetValueAsUnsigned(lldb.LLDB_INVALID_ADDRESS)
2011 - 1 - 24, NaN, NaN
print(results)
can = tkinter.Canvas(tk)
svg_size_width = 900
print(tostring(tr))
hh, ee = np.histogram(xx, density=True, bins=logbins)
m_norm, z_norm
coords[1::2] = coords[1::2, ::-1]
gen_func(*self.__args, **self.__kwargs)
current_chunk.append((word, pos))
ip = ipapi.get()
xx = np.linspace(0, 5, 100)
col_rank = np.argsort(col_order, axis=0)
L[j] = R[i]
blah.append({k: i})
global_learning_table
print(list(it))
self.conditions[i] = json.dumps(condition_loaded)
numpy.ma.MaskedArray(data=sums * 1.0 / counts, mask=mask, copy=False)
text = article.cleaned_text
sent_tokenize(train_text[11])
max_length = max(len(elem) for elem in inputs)
print(s)
testlib.myprint()
plot_roc(label_every=5, *roc_data)
intersections.append(point)
attr = zipfile.ZipInfo(filePath)
self.wfile.write(response)
modded
r = np.corrcoef(matrix)
2
self.get_queryset().not_in_group(group)
handle.write(buffer=xml_data)
print(pdf)
nameArray.append(int(i))
s = socket.socket()
graph = plt.plot(X, Y)[0]
res = cr.dictfetchall()
True
(ser[ser.notnull()] > 0).mean()
self.with_case = list(sorted(iterable, key=lambda s: s.lower()))
[]
six.next(six.itervalues(dict))
pprint(result.data)
location = settings.MEDIAFILES_LOCATION
ax2 = ax1.twinx()
displayImage(screen, px, topleft)
argv = sys.argv[1:]
m_to_M[1:, (0)] = -nrange[1:-1].reshape((n - 2, 1))
b = np.arange(N) - N / 2
x, P
cnt[word] += 1
unpad = lambda s: s[:-ord(s[len(s) - 1:])]
clo = []
root = Tk()
res[k].extend(v)
t = linspace(0, 10, 1000.0)
ax = plt.subplot(1, 1, 1)
d
fact1 = n0 * math.tan(phi1) / r0
monitor_user.assert_called_once_with(user.key)
X_int = np.round(X * 10).astype(int)
setattr(cls, name, cls.DecorateMethod(meth))
tf.write(data)
assert desired <= set(superset)
func = types.FunctionType(*(args[:-1] + [closure]))
spdf = pd.DataFrame(np.zeros((nrow, ncol)), columns=cols, index=rows)
module = getattr(pkg, m)
print(i)
elapsed = time() - start
x = create1k()
True
result = []
sys.meta_path[0] = DummyLoader()
s = yaml.dump(x)
config.update(patch)
[14, 24, 1.0],
yp = R[1] + np.sin(razim) * np.cos(relev) * (self.dist + zoom_out)
value + 2
it.chain.from_iterable(glob.glob(pattern) for pattern in patterns)
self.it
uchar * pCurr
uchar * pBelow
uchar * pDst
count = count - 1
erased = False
list
print(m.coef_)
next(x for x in test if x % 5 == 0)
b = models.CharField(max_length=42)
partial1, inner_c1 = catalan_rec_count(i)
cdll.msvcrt._tzset()
label = Column(String)
setp(subplot.get_yticklabels(), rotation=y_rotation)
a.colour = numpy.arange(num_stars)
tee.communicate()
sf_client.login(sf_username, password)
data
self.y = 0
dodgy = []
result
print(line, file=sys.stderr)
f2.read()
ind = ind.argsort(axis=1)
self.id = next(self.last_id)
self.a.sort()
socket.setdefaulttimeout(10)
pos = nx.spring_layout(G, pos=fixed_positions, fixed=fixed_nodes)
df = []
si_pixels = list(subimg.getdata())
profiler = Profiler()
a = np.arange(10)
aaa
df2
print(mapping[char])
plt.plot(time, cut_signal)
hourdiff = (now - epoch).days * 24
print(B().my_list)
data = np.random.rand(5, 4)
q = Comment.query.filter(Comment.path[1] == 11)
item[name] = value
screen.fill((255, 255, 255))
p.start()
print(CHUNK1, CHUNK2)
False
pars2 = st.norm.fit(data[classification == 0])
new_a[(i), :] = map(d.get, row)
temp_file.writelines(download.content)
wv.show()
high = lambda x: isinstance(x, (int, float)) and x > 10
namespace = main_parser.parse_args(namespace=namespace)
console = logging.StreamHandler()
print(data)
n = (next_day - d.weekday()) % 7
server.listen(backlog)
output = StringIO.StringIO()
cov.start()
assert len(Index) == 5
areas = (max_x - min_x) * (max_y - min_y)
clang.cindex.Config.set_library_file(path)
dis.disassemble(code)
sorted(iter(x_c.items()), key=second, reverse=True)[0][0]
rgba_img = cmap(img)
instance_count = 0
signal.alarm(0)
rs = pd.Series(list(range(10)))
width, height
type(f)
nums = [ord(x) for x in lst]
threads.append(thread)
first, second = bar()
low_results = run_pool(process_items, items, 2, low_par)
g = (x ** 2 for x in range(10))
losses = tf.reshape(tf.concat(1, losses), [-1, seq_len])
num_cols = len(grid[0])
np.array(y.tolist())
print(True)
self.member_names = []
fig, ax = plt.subplots()
y = scipy.sin(x) + (0.0 + scipy.rand(len(x)) * 0.4)
Sr1.add(Sr2, fill_value=0)
result.append(x)
a == b
startDate = models.DateField()
freqs = list(line(samples, min_freq, max_freq, finish=True))
fs.sync()
x ^= y
dist = dist.distribution(partial(f, 1.0), other_variables)
self.config = ConfigParser.ConfigParser()
tag = TagSerializer(read_only=True, many=True)
x_axis = np.linspace(0, 500, 100)
p.join()
draw()
origin_time = time.time()
date
newFile.writerow(firstNames)
br = mechanize.Browser()
v
self._stdout.read()
config.add_route(*args, **kwargs)
lines = list(reader)
prevnode.left = node.right
widget = QTreeWidget()
key = lambda l: l[0]
OPTION_C = 4
x = 10
lookup = {(1): 0}
output
good_objects = [True, False, False, True]
print(find_lt(R, x))
np.version.version
spDF.show()
self.x = x or MyClass.x
self.layoutHorizontal.addWidget(self.pushButtonSimulate)
t = threading.Thread(target=animate)
xdict = dict(enumerate(x))
dfs.append(df)
self.redirect(redirectTo)
rpmdevtools
print(result)
test = grouped.aggregate(np.sum)
res = []
n * n
1 - y | 1 - y | 1 - y | 2 - y
a = a.insert(root, 4)
html.append(df_html_output)
d = Decimal(str(f))
print(num)
result = []
srcname = os.path.join(src, x)
a = np.random.randint(10, size=1000)
plt.subplot(2, 1, 2)
self.button = QtGui.QPushButton(self)
d = month, day
process_data(mylist[:17])
average = mahotas.gaussian_filter(average, 24)
g = df.groupby(0)
lst = sorted(lst)
res = result.get(block=True, timeout=10)
fileHandler.setFormatter(formatter)
self.on_close = on_close
request_params = dict(urlparse.parse_qsl(split_result.query))
store.close()
a
r1.append(e1)
features = [feature_names[i] for i in tree.tree_.feature]
center = vor.points.mean(axis=0)
itertools.cycle.next(self)
ids.add(id(ob))
clf.predict(iris.data[25])
newarr = arr[mask]
queryset = self.get_queryset()
self.linelocs.extend(x + self.curoffs for x in linends)
plot(freq, abs(spectrum))
print(a)
dictrows = [dict(row) for row in cur]
total = func(total, element)
a = int(split_text[0])
delta = np.array([-1, 0, 1])
L[i] = 0
console.setFormatter(formatter)
sets = (indices[field][key] for field, key in factors)
data
foo[foo == 0] = m
key
getattr(self.person, attr)
[i.__class__() for i in lst]
client = tornado.httpclient.AsyncHTTPClient()
image = ImageReader(StringIO.StringIO(user.photo))
spinBtn.configure(adj, 1, 0)
df.head()
masked_data = np.random.random((100, 100))
views.py
mock_response(req)
print(path_buf.value)
self.name
bins = np.bincount(data[:, (0)])
self._graph[node1].add(node2)
self.cmd = cmd
xmin, ymin, zmin = x.min(), y.min(), z.min()
x + y
tst = dt.hour * 60 + dt.minute + dt.second / 60 + time_offset
cpixel = pixels[x, y]
print(word)
delete__bootstrap__, __loader__
print(str(ioe))
fut.add_done_callback(sleep_done)
decoder = json.JSONDecoder()
proc = subprocess.Popen(cmd)
s.ioctl(socket.SIO_RCVALL, socket.RCVALL_ON)
array = []
a = attrdict(x=1, y=2)
buf.value
a[:, (0)] = a[:, (0)].astype(int)
M is iter(M)
d = data(foo=1, bar=2)
f.readlines()
u, created = User.objects.get_or_create(userName, userMail)
main()
page_content = f.read()
fpath = os.path.join(dname, fname)
new_row.append(item)
x = random.randint(-500, 500)
fig, ax = plt.subplots(figsize=(8, 6))
print(args)
print(x)
a.ques_type
y = datetime(2011, 1, 9)
self.cumweights[-1]
True if month >= 1 and month <= 5 else False
s[:amount]
xml1.getroottree().write_c14n(xml_string_io1)
self.getName(node)
self.stream.seek(0, 2)
temp = lib.make_array()
assert isinstance(dumper, ruamel.yaml.RoundTripDumper)
Q_UNUSED(child)
QPushButton.__init__(self, text, parent)
False
word1, word2 = random.sample(WORDS, 2)
{{x.location_id.name}}
filename = askopenfilename()
select_obj.select_by_visible_text(dict[key])
a, new_a = itertools.tee(a, 2)
sum += item
apps.get_model(model_identifier)
app = QtGui.QApplication([])
self.directive.result.append(self.indent + line, source, *lineno)
fig, ax = plt.subplots()
deserialized_output = simplejson.load(f)
x1 = x * cos(theta) - y * sin(theta)
newdata[name] = row[2:]
[s for s in strs if s.isalpha()]
index = (index + 1) % n
field_to_update.append(field_name)
bananas(result)
flatten_iter = itertools.chain.from_iterable
cleaned_email_list = list(set(cleaned_email_list))
cd / Library / Frameworks / Python.framework / Versions / 2.7 / bin
lChannel.close()
page = opener.open(httpReq)
newlist = []
data
urls.py
opener = urllib.request.build_opener(keepalive_handler)
ret
m.create_xref()
parts = parse.urlparse(url)
update_wrapper(f, self.fn)
lc = lambda : [element for tupl in tupleOfTuples for element in tupl]
print(row.user_id, row.user_name)
subs.extend(getSubsFromConjunctions(subs))
py.test - -reuse - db
tstart = time.time()
cls.asUTCDate(date)
print((a, b, c, d, e))
do_reload(name)
self.view.title = self.post.name
object.__setattr__(self, key, value)
root.append(Tree(token[2], [(token[0], token[1])]))
my_array = numpy.empty(predict_length())
re1_matches = re.findall(re1, text)
t = np.zeros((n,)) + v
name = models.CharField(max_length=40)
quad_pts.push_back(Q2)
quad_pts.push_back(Q4)
start_of_trailer = s.index(trailer, end_of_leader)
x = x - 0.5
time0 = time.time()
self.listsquare = [(x ** 2) for x in self.list]
plt.plot(xl, yl, c, alpha=alpha)
self.write_c.notify()
result = htql.query(page, query)
a.remove(i)
out = [[]]
count = check_string.count(char)
(x + y).subs(100 * reps)
db = connection[self.db_name]
alnREFseq = aln[1]
stringify_children(node)
a_bins = []
outputfile.close()
f = q.get()
data = data.reshape(720, 1440)
6 - 1
print(freq[12, 6])
is_creator(f, impostor)
callback = subtask(callback)
x1 = series.index.values[idxs]
D.x
value[arg]
my_instance.store_dataframe(df)
100 ** 100
padded[0:m.shape[0], 0:m.shape[1]] = m
datenow
g, x - b // a * y, y
dataFT = fft(dataPadded, axis=1)
datetime.datetime(y, m, d, hh, mm, ss, us)
svg_size_height = 4500
S = csr_matrix((values, [digitized, np.arange(N)]), shape=(nbins, N))
m.a
cnt = np.bincount(_)
plt.show()
model.add(Dense(1))
print(self.combo.GetValue())
sorted_pairs = sorted((i, j) for i, j in zip(x, y))
f = operator.itemgetter(1)
df.set_index(times, inplace=True)
b = [2, 6]
x = Foo(2)
x[-45]
numpy.array(data)
x = numpy.array([0, 0, 1, 1])
self.client.listen(self.on_chan_message)
success = True
ncols = data.shape[1]
byte_array.insert(0, long_num & 255)
deleteanother_class, descriptive_name
fl.write(data)
res[i] += to_add
ransport = random.choice(list(sportDict.keys()))
r.groups()
timeStamp = datetime.utcnow()
exc_type, exc_value, tb = sys.exc_info()
lambda : callback(x)
True
configParser = ConfigParser.RawConfigParser()
meta[k][tag] = value
(X.toarray() > 0).astype(int)
pkg_resources.declare_namespace(__name__)
os.waitpid(self._pid, 0)
group_hours = (df.hour <= df.hour.shift()).cumsum()
bx = fig.add_subplot(1, 2, 2)
Testing(5 / 5)
node
x = np.dstack([r, g, b, a])
os.path.exists(mypath)
chr = binascii.unhexlify(match.group()[2:])
result.append(nxt)
self._x
Foo_Base2.fun()
print(2)
doctest.OutputChecker = AEOutputChecker
print(item)
c.internal()
pipe.fit(train, train.Label)
adic = defaultdict(int)
res += u[min_len:] + l[min_len:]
nread = _getdents(__NR_getdents, fd, buf, len(buf))
rlist2 = list2[::-1]
this_row.append(str(s.cell_value(row, col)))
b = [1, 2]
d[k] = {}
gmpy2.invert(0, 5)
n.addModule(bias)
npc[i, j] += row[0, j]
m.start()
a = np.array([1, 2, 4])
A.partition(4, axis=1)
obj = [obj]
decode_header(a)
df.groupby(grps).agg(funcs)
iterator = iter(data)
visit.Launch()
result.append(obj)
procs = []
source = bkm.ColumnDataSource(data=your_frame)
d1 = [get_base_freq(seq) for seq in seq_pair]
data = Counter(lst)
count += 1
sift(0, count)
m = max(a)
shutil.rmtree(tmpdir)
args = [iter(iterable)] * n
_suitability(node, word, mx)
result.append(word)
text
sheet = wb.ActiveSheet
sorted_s = sorted(s, key=lambda v: v[1], reverse=True)
L2 = [next(g[1]) for g in giter]
name = n.id if isinstance(n, ast.Name) else n.func.id
wb = Workbook()
lol(x, 4)
du - h / usr / share / dict / american - english
print(newstring[0:6])
app = Flask(__name__)
pc = pcap.pcap()
application_readable
some_command()
words = ch.strip().split()
DF_corr = DF.T.corr()
genes_dict = {}
readfile.close()
data.append([ele for ele in cols if ele])
int(cr[1]), int(cr[0])
handle.close()
print(s)
star_count = 0
list((x - y).elements())
assert b.day == d.day and b.hour == d.hour and b.minute == d.minute and b.second == d.second
results.append(proc)
print(func(False))
len(list(nicematrices(m, n))) * factorial(m) * 2 ** m, 2 ** (m * n)
j = s.index(c, i)
print(arr[(1), :])
green = make_norm_dist(x, 50, 10)
do_something(conn, addr)
self.last_img = self.canvas.create_image(16, 24, image=self.images[sprite])
a = np.zeros(dim, dtype=int)
A.sort()
print(f.x)
df2
wrapper
res = set()
node_key = dumper.represent_data(item_key)
True
items = np.unique(A[:, (1)])
CGIHandler().run(app)
ay1
ay2
bx1
bx2
by1
by2
cy1
cy2
cx1
fd[word] = 1
vWidth = list(range(0, int(STEP_PART * width), 1))
c = collections.Counter(input)
self.arrays[j][i - shift] = v
columns = df.columns.tolist()
post_save.connect(update_b_count, sender=B)
results = re.findall(search_pattern, pattern_string)
a = zeros((2, 2))
tree = etree.parse(StringIO.StringIO(broken_html), parser=parser)
writer.save()
chunked[-1] += word_pos
counter[name] += 1
print(catalan(5))
lineage
b = 2
firefox_profile = webdriver.FirefoxProfile()
a, b = np.meshgrid(list(range(ydim)), list(range(xdim)))
pprint(list(textAndElement(doc)))
t.timeit(57662556)
current_seq_len += 1
fig = plt.figure()
Py_DECREF(sys)
spider_count = 0
X, Y = np.meshgrid(np.arange(others.shape[0]), b)
skip = sorted(random.sample(range(n), n - s))
print(output)
it = iter(iterable)
df
dis.dis(swap2)
sys.exit(0)
L1 = {tuple(row): i for i, row in enumerate(L1)}
array1[i][j] = array2
start_iter = textbuffer.get_start_iter()
ts_clip = ts.iloc[np.argwhere(ts.index.hour.__eq__(17)).ravel()[0]:]
n = int(n_str, 16)
dudette = User()
aplusb(100, -100)
DG = 1
print(word)
platform.node()
data_dict[el[0]].append(el[1])
args.extend(rest[:index])
common_items[key] = value
type({}) is dict
L = [1, 2, 45, 55, 5, 4, 4, 4, 4, 4, 4, 5456, 56, 6, 7, 67]
context = ssl.SSLContext(ssl.PROTOCOL_TLSv1)
step = tf.train.AdamOptimizer(learning_rate=0.01).minimize(cost)
map_clear()
h = HTMLParser.HTMLParser()
show()
random.shuffle(indices)
code = line[:2]
list.append(number)
things = [getattr(module, x) for x in dir(module)]
Session_1 = sessionmaker(bind=some_engine_1)
pipe.close()
result = method(*args)
assert isinstance(value, str)
root = logging.getLogger()
print(point_tree.data[point_tree.query_ball_point([1.5, 2.5], 1)])
conditions.append(User.name == term)
p = psutil.Process(os.getpid())
fg1 = bg1.apply(frame, learningRate=0.001)
retval += traverse(node[1][1][0])
sess.run(train_op, feed_dict={data: some_training})
perms = []
other_data = pd.concat([pd.read_csv(path_1 + f) for f in os.listdir(path_1)])
self.menubarMenu.addItem_(self.menuItem)
pos = w / 2, h / 2
results = q.fetch(10)
G = matrix([[-1, 0, 0, 0], [1, 0, 0, 0]])
help(operator.add)
sc.close()
print(Counter(map(frozenset, y)))
zs = np.random.random((101, 101))
twisted.protocols.basic.NetstringReceiver,
[i for i in eq1.atoms(Pow) if i.base == a]
print(df)
build_libpython(n)
record[key] = smarter_nestify(l, record.get(key, {}))
self._waitable.add(signal)
obj.owner = self.request.user
results = processPool.map(worker, list(range(15)))
src_text = src.read()
print(ranking)
field_help.get(self.name) or self.help
a[1] = 2
emp = Employer.objects.create(blablabla)
axs[1, 0].imshow(region2)
a = np.random.randn(128)
app.debug = True
logging.info(new_contact.key.id())
self.networkAccessManager().setCookieJar(qcookiejar)
ax2 = f2.add_subplot(111)
y = np.array([4, 5, 6])
temp_data.remove(data[count])
ax = plt.subplot(111, frame_on=False)
connection.ioloop.poller.open = False
indices = np.unique(np.random.randint(200000000.0, size=(12000,)))
isinteger(1.5)
diff.htmlDiff(a, b)
self._convert * self._swapf
minutes, second = divmod(seconds, 60)
shifted = df.copy().shift(2, axis=1)
rmat_y = np.eye(4)
request
print(obj[key])
h = plt.bar(range(len(country_list)), heights, label=country_list)
False
rnd.shuffle(wordslist)
frequency_list[l] += 1
a, b = b, a * b * n
obj = queue.pop()
SOX_EXEC
fun(B())
print(composite_list)
R = dot(u, vh)
N = db.collection.count(condition)
d[i] = l.count(i)
section.text
f = logging.currentframe().f_back
anyTrue = any(map(predicate, iterable))
dict.update(eval(func.__code__.co_consts[2]))
os.symlink(target, tmpLink)
ALLWAYS = 1
my_object = MyObject()
label = fuse_classifications(classifications)
modname = os.path.splitext(testcase)[0]
A()
db.add(word, index)
text = ax.yaxis.label
self._get_patches_for_fill.set_color_cycle(clist)
list_2_sorted
stdout = fin.read()
[myvars]
writer.writerow(d)
0
print(sys.path)
L.sort(key=make_lazy(f1, g))
self.children = []
a.T.ravel()
argand(a)
bodylist.append({edge[0], edge[1]})
sum_row = {col: df[col].sum() for col in df}
stream = cStringIO.StringIO()
func = lambda x, y, args: (x, y, {})
repr(math.fsum(self) / len(self))
db_crsr = _cxn.cursor()
self.add_connection(edge)
content = urllib.request.urlopen(url).read().lower()
middle = len(L) / 2
tot += A[i, k] * A[j, k]
cs = ax.contour(X, Y, Z)
bool_indices = numpy.logical_or.reduce(bools_2d)
new_y.append(y[i])
self.handleError(record)
df_90 = df.drop(rows)
thread1.start()
print(word)
label.append(race)
lst[i] = new_element
loss = my_normal_loss + reg_constant * sum(reg_losses)
fn(s)
f(*args, **kw)
sql.add(customer1)
text.translate(D())
indices = defaultdict(list)
x = tf.decode_raw(x, tf.uint8)
Example.Variable = 5
load()
res.seasonal
result
out_file.write(x)
t = t.lower()
nic = nic_configs[0]
last = input[0][1]
b = [[1, 1, 1, 1], [2, 2, 2, 2], [4, 4, 4, 4][8, 8, 8, 8]]
count_deals = get_stored_deals(dbconn, userID)
self._x = x
day = int(argdate % 100)
pool = Pool(processes=4)
dict = OrderedDict(sorted(list(dict.items()), key=lambda t: t[0]))
self.do_not_run = False
pool += itertools.islice(gen, poolSize - len(pool))
self.instance = instance
data = self.stream.read(1024 * 16)
sep.join(x for x in spl if x)
tagger = nltk.UnigramTagger(nltk.corpus.brown.tagged_sents())
process.join()
pprint.pprint(data2)
request.session = {}
frame = cv.QueryFrame(camcapture)
executor = concurrent.futures.ProcessPoolExecutor(10)
x = NP.arange(10)
func()
A = sorted(A, key=lambda x: x[0])
current_job = get_current_job(conn)
+-gmod.py
cols_via_apply(df)
module = imp.new_module(name)
task.deferLater(reactor, 1, self._called_by_deffered2)
np.set_array_base(a, new)
print(test)
items = interleave()
autoCov += (X[i + delta] - Xs) * (X[i] - Xs)
f_.z
res_list
Py_Initialize()
self.b = True
[actor] = [actor for actor in self.actors if actor.name == actorName]
percentiles = (np.arange(n) + 0.5) / n
s.a = 10
m = min(i for i in a if i > 0)
f00
name = meta.CharField(maxlength=100)
a = a.T
Mock()
any(map(my_dict.__contains__, my_list))
res = defaultdict(list)
Counter(x) - Counter(y)
print((x1, x))
rows = np.zeros((h, maxlabel), np.bool)
name = fields.Str()
self.url = url
t = np.linspace(0, T, T * rate, endpoint=False)
first_array = array(FFnetlayer[0::2])
print(item)
df
s1 = random.random()
data = {}
results.append(numpy.argwhere(indices).flatten())
decimal.getcontext().prec = 28
self.trayIcon.contextMenu().show()
values[sum(1 for key in keys if query > key)]
yaml.add_representer(folded_str, represent_folded_str)
char = char.upper()
DBSession2 = scoped_session(sessionmaker(extension=ZopeTransactionExtension()))
DBSession4 = scoped_session(sessionmaker(extension=ZopeTransactionExtension()))
im_data_base = multiprocessing.Array(ctypes.c_float, im_size[0] * im_size[1])
excel.Application.Run(myMacroName)
db = boto.connect_dynamodb()
plugin.other_plugin_stuff()
m, e = math.frexp(x)
val = int(pct * total / 100.0)
print((args, bar))
suite.addTests(loadedtests)
Decimal(1.1)._isinteger()
print(seq, distance(*seq))
ax = fig.add_subplot(111)
jbound = list(range(n - k + 1, n + 1))
output = pd.concat([input, pd.DataFrame(index=newIndex)], axis=1)
log.setFormatter(logformatter)
mylog.setLevel(level)
print(x + y)
print(output)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
outer()
m1()
apply_argsort(a, 0)
wrapper
a_set
self.__int__ = lambda : 1
form = CustomerInfoForm()
rgbint // 256 // 256 % 256, rgbint // 256 % 256, rgbint % 256
y = np.sin(t)
exc = subprocess.check_output(exargs, startupinfo=startupinfo).split()
PyArray_SimpleNewFromData(2, dims, NPY_FLOAT, obj.m_data)
curl = pycurl.Curl()
initialTimeStamp = time.time() + time.clock()
d[el.tag] = el.text
par_plot.set_ydata(y_data)
bytearray(10 ** 9)
isReplaceable = Field()
np.testing.assert_equal(using_quadratic_loop(data), using_filters(data))
max_bin = np.max(list(counted_data.keys()))
main()
df = pd.read_excel(inData)
self.values = {}
_type_ = ctypes.c_byte
keypoints = detector.detect(frame)
image_data = fin.read()
sums = partial_sums(int(line) for line in f_in)
_reload_builtin(module)
a = np.random.randint(0, 5, (50, 50))
-1
loop = asyncio.new_event_loop()
list_dump = json.dumps(list_org)
roots.add(root[0])
args = parser.parse_args()
opt = tf.train.GradientDescentOptimizer(learning_rate)
hashed_password = bcrypt.hashpw(combo_password, salt)
print(new)
writer.writerow(list(range(i, i + 10)))
means = v.mean(0, keepdims=True)
print(savedtweets_datetime[0])
something_complicated(self._whatever)
x += x
p
file_ptr.write(old_content)
print(arg)
print(key)
reqs = conn.get_all_spot_instance_requests()
word_dict = {}
date = Column(DateTime)
valid
self.src_defaults = src_func.__defaults__
x0 = np.array([1.1, 1.1, 1.1], dtype=np.double)
saver.save()
print(a)
p[1]
Print[value]
fig = sns_plot.fig
tree = ET.fromstring(Text)
str(value)
background.show()
self._locked = False
pivot = array[0]
foo = Foo()
lines = text.splitlines()
engine.Operations.InvokeMember(pythonClass, method, arguments)
l = len(s2) - len(s1)
thing.__dict__
args = [a, b, d, c]
mod = import_module(p)
rect = plt.Rectangle((x, y), w, h, color=c, ec=c, **kwargs)
d = {}
usage()
fig.canvas.manager.window.raise_()
PygameHelper.__init__(self, size=(self.w, self.h), fill=(255, 255, 255))
F = np.cumsum(fsorted)
print(dfs(0))
GoodSubClass.convert(anotherbase, 2)
c = [2, 12, 10, 10, 2]
ax2.add_collection(C[0])
optimizer = tf.GradientDescentOptimizer(0.01)
first_valid = s[s.notnull()].index[0]
np.in1d(a1, b1)
some_queryset[:length] if length else some_queryset
data = sock.recv(1024)
child_mock2._mock_new_parent is parent_mock
my_dict
metalist.sort(reverse=True)
axes.add_artist(acc_arrow)
count = collections.Counter(text)
email_admins(w[0].message)
graph_db = neo4j.GraphDatabaseService()
g.init()
current_child = Node.objects.get(id=child.id)
print(row[0])
last_number
totoss = set((v, k) for k, v in myDict.items())
Parent().parent_prop()
hh = [[82.5], [168.5]]
indices = sorted(list(range(len(a))), key=a.__getitem__)
sys.meta_path.append(DummyLoader())
self.frames = [ImageTk.PhotoImage(first)]
self.__class__ = sex
signals.pre_save.connect(update_timestamp, sender=User)
date_of_birth = DateField(input_formats=settings.DATE_INPUT_FORMATS)
pos += d.d_reclen
data = s.recv(1024)
byte_array[mask] = 0
print(f)
listdrivesout, err = listdrives.communicate()
group_consecutives(a, step=47)
r = random.random
res = key.get_contents_to_filename(key.name)
base.from_param(obj)
lines[-1] = new_last_line
self.table.setItem(row, 0, item1)
lst = list(range(1, 4))
retval
prt(i, b)
im_mask |= hitmiss(im_binary, np.fliplr(kernel))
result = type.__new__(cls, name, bases, dict(classdict))
s2.is_valid()
self.Show()
False
builder.toString()
self.collection_dict = dict()
rand_elt_num = random.randint(0, len(cells) - 1)
2 * x ^ 2 + 6 * x ^ 2 * y
do_stuff
args = parser.parse_args()
d[i] = d.setdefault(i, 0) + 1
le = QtGui.QLineEdit(w)
foo.bar = 1
self
cache[key] = value
d[item] += 1
self.b = False
plt.hist(a, **common_params)
set(itertools.product(the_set, repeat=n))
swidth = wf.getsampwidth()
D = r - 2 * tf.matmul(A, tf.transpose(A)) + tf.transpose(r)
name, extension = splitext(basename(pathname))
board.read()
fig = plt.figure()
yvals = (arange(len(sorted)) + 0.5) / len(sorted)
ax = PLT.subplot(111)
r = random.randint(0, i)
bodylist[index].append(edge[0])
der[begin:end]
c.save()
lid_open()
pd.rolling_apply(values, window=1, func=reduce)
sys.getrefcount(a[2])
a = numpy.array([200, 2e-26], dtype=numpy.longdouble)
print(guess_seq_len(list_c))
x = np.arange(len(df.date.unique()))
sns.palplot(colors)
self.exit = False
1111011
1011001
100010101111
start = n * (n - 1) // 2 + 1
user = database.get(user_id)
tree = ET.parse(metadata)
self.factory = RequestFactory()
matrices[:, (1), (2)] = -s
set(v)
ptchs = []
ch.setFormatter(chformatter)
fig = plt.figure()
blocking_future.cancel()
curdir = os.getcwd()
pkey = x509.get_pubkey()
thing.run()
obj = SubClass()
validlist.append(valids)
et = etree.ElementTree(e)
data
groups = OrderedDict()
__library.initialize()
Testing(9 / 9)
indices[j] = indices[j - 1] + 1
pl.figure(figsize=(70, 70))
print(inspect.getsource(re.compile))
y = f(x)
os.rename(old, new)
children.sort(key=lambda x: (x.lineno, x.col_offset))
f = x ** 2 + 1
x = [1, 2]
i += 1
p = pyaudio.PyAudio()
df
deleteancestor.getparent()[0]
stmts = []
without_reset = (a == 1).cumsum()
c = NP.random.randint(0, 10, 5)
cursor = conn.cursor()
freq_list = list(count.values())
v = numpy.linspace(0, numpy.pi, 100)
1
pcolor(data, cmap=cm.YlOrRd)
gen = it.izip(indices, reversed(li))
addlist = alllists.pop()
__tracebackhide__ = True
opener = urllib.request.build_opener(proxy)
print(der.foo(), der.fooBase())
z = np.random.random(x.shape)
stream.write(data)
self.dfjson = dataframe.to_json()
l.set_option(ldap.OPT_DEBUG_LEVEL, 255)
self.test(*self.arg)
y = np.asanyarray(y, dtype=float)
root.wm_minsize(maxwidth, root.winfo_reqheight())
baz_from_bar(self.bar(x))
form = ClientForm(instance=client)
pprint.pprint(list(make_combos(6, 12, 4)))
iK = mX.shape[1]
fig.figimage(im, 0, fig.bbox.ymax - height)
crawl(url)
root_nodes = {x for x in parents if x not in children}
path = queue.pop(0)
foo(x + 1, limit)
times_2 = [pd.Timestamp(t) for t in times_2]
p.append(i + 1)
results.append(next(iterator))
s.feed(html)
print(begin.lower() + begin.upper() + end.lower())
resultList = []
decorator_factory
n = np.max(partitions)
linesmask = np.array([True, True])
xp = np.linspace(0, 1.1, 1500)
print(row)
storage = FileSystemStorage(settings.STATIC_ROOT, settings.STATIC_URL)
sublime.set_timeout(self._destroy, 5000)
new_dic_defaultdict
rand = np.random.rand(5)
print(zip.__doc__)
x = [1, 1, 2, 2, 17]
out.append(i)
fig, ax = plt.subplots(2, 1)
tmp.MyEnum.C
self._jstext = jstext
a = [([0] * cols) for _ in [0] * rows]
d = dict.fromkeys(keys)
pygame.surfarray.blit(temp_surf, scan)
wrapper
result = rex.search(f)
used_legends.add(label)
cache = {}
str = []
words = phrase.split()
print(str(condition))
try_one(troublesome, 2)
deletefoo
base64.decodestring(encoded_str)
print(new_data)
c[0, 0, 1, 2]
auth_token = get_auth_token()
print(self.arg1)
console.log(msg)
wx.PostEvent(self._notify_window, ResultEvent(result))
i = a[0]
print(self.data)
a == b
result
A2 = np.random.randint(-4, 10, (100000, 100))
os.makedirs()
self.children = []
Wnck.shutdown()
dialog.setFileMode(QtGui.QFileDialog.Directory)
a = np.arange(rows_a * cols).reshape(rows_a, cols)
adjacents = list(_adjacents)
g.add_edge(key, val)
content = request.json
g = np.array(grid)
num = next(nums)
dis.dis(f)
row = [5, 5, 5]
id = Column(Integer, primary_key=True)
ip = IPRoute()
remaining.append(x)
False
var2 = [5, 6, 7]
sys.modules = old_modules
freq = lambda n: int(440 * math.pow(2, 1 / 12) ** n)
pool = Pool(processes=4)
c = Counter(lst)
pool.apply_async(compute, args=(j,), callback=write)
PyModule_GetDict(main_module)
b.sort()
t1 = t.timetuple()
self.fp2 = open(self.file_2[0], self.file_2[1])
opener = urllib.request.build_opener(proxy_handler)
header = next(ifin)
o.__dict__
tris = mtri.Triangulation(zen, azi)
soup = bs4.BeautifulSoup(r.text, from_encoding=encodings_to_try)
stuff.sort()
turtle.right(90)
Hence
list(islice(gen_weird_sequence(count(), count()), 16))
airport - h
conn.commit()
page = opener.open(url)
tries += 1
ax.set_xticklabels(ticks)
t, p = ttest_ind(a, b, equal_var=False)
start = time.time()
foo = {a, b, c}
plot(b)
helpers.bulk(es, actions)
h.sqlContext.sparkContext.union(dfs.map(_.rdd)),
input = input.lower()
a[1, 1]
print(username)
cols = array.shape[1]
wmark = Image.open(watermark)
lambda bound_d=d: self.root.change_directory(bound_d)
inst1.i = 2
csvFile = os.path.join(resultDir, fname)
right_endpoints = name_list[N - 1::N]
ln - s / opt / application / env / bin / phone_home / usr / local / bin / phone_home
lst
(new_x[i, j] - x[k - 1]) / (x[k] - x[k - 1]) + y[i, j, k - 1]
list(range(n))
python
client = api.get_client(api.API_DOMAIN)
basename(parse_object.path)
st = os.statvfs(path)
0
grams = [sentence[i:i + N] for i in range(len(sentence) - N + 1)]
s = a.shape[:2]
N = len(poly)
syllables = [(word, syl) for word, syl in entries if word == inp]
logger.warning(my_custom_command)
print(test_Dict[obj2].name)
managers = [stack.enter_context(my_context(arg)) for arg in items]
4, 4, 4, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 7, 7, 8, 8, 8, 8, 8, 9, 9, 9
s.commit()
map[x][y] = tmp[x][y]
print(a)
data += buf
L = map(int, L.split())
y = 0
calls.append(c)
myfx.datadex = {f: (42) for f in foo}
kana = [a, k, g, s, z, t, d, n, h, b, p, m, y, n]
print(cmd_resp.read())
df
calc_harmonic(20)
self.p = 2 * (1 - stats.t.cdf(np.abs(self.t), y.shape[0] - X.shape[1]))
x = SimpleClass()
data.global_wealth = 1.0
x = np.array(img)
self.sock = sockssocket()
axs[0, 1].imshow(region1)
last_digit + sum_digits(rest)
in_queue.put(file)
n = np.npv(0.01, cashflow)
df = matrix.shape[1] - 2
self._x
DEBUG = False
keys = [[entry[0] for entry in unique_items]]
app = Bottle()
df[df.Phrase.astype(bool)]
n, m = len(a), len(b)
y = np.random.random(num)
session.close()
print(Test.x, Test.y)
val = self.queue.get()
crawler_process.crawl(spider_cls)
0
byId[masterDict[k].id].append(masterDict[k])
dt = dt.replace(year=dt_now.year, month=dt_now.month, day=dt_now.day)
results.append(procs.pop(0).communicate())
value = self.default_factory(key)
x2 = (x2 - min(x2)) / (max(x2) - min(x2))
items = sorted(list(d.items()), key=lambda item: item[0])
subcats = []
checkbox_id = self.clear_checkbox_id(checkbox_name)
swap(i, max)
R, C = np.triu_indices(a.shape[1], 1)
print(name, str(high_salary))
func(self, x - 1, func)
Sx = Sx + x
print(c, x)
timer(stateDSM, 5)
chunks = split_on_silence(sound, min_silence_len=500, silence_thresh=-16)
res.append(part)
a = 1
print(len(user_timeline))
arr[xyz]
Mtl.T
abs(a - b) < 0.01
out[..., (1)] = np.arange(n)
col_list = list(df)
111111
y = np.roll(x, 1, axis=1)
temp = set(tf.all_variables())
stored_date = Training.objects.first().start_date
diff = difflib.ndiff(f1, f2)
tree = ET.fromstring(Text)
ridx = idx[::-1]
med = np.random.randint(-10, 10, size=100000)
x = np.arange(N)
merger = PdfFileMerger()
dateSet = set(dateList)
search_offset = f.tell() - len(line) - 1
df.columns = [(int(col) if type(col) == float else col) for col in df.columns]
s[1]
lines = groupby(sorted(lines), lambda x: x[0])
df.loc[df.name].reset_index(drop=True)
n += 1
scrolled_window = Gtk.ScrolledWindow()
QList()
self.name = name
loop.run_until_complete(aio_readline(loop))
app.queue = Queue.Queue()
a = OP[op](a, b)
id = serializers.CharField()
print(s[i])
npreds = [-1] * n
headers = dict(headers)
time.sleep(0.2)
ax.plot_surface(T * T, sqrt2 * T * S, S * S, cmap=cm.jet, rstride=1, cstride=1)
line = proc.stdout.readline()
f1 = lambdify((a, b), a + cos(b))
d[col[0]] = row[idx]
delta = timedelta(days=1)
[OUTPUT]
color = forms.MultipleChoiceField(choices=COLORS)
x + 1
stack[-1][-1][-1] = v
c = C()
sheet2 = xls.parse(1)
all(l1 in sLines for l1 in dataE)
partners[i] = potentialClosest[i]
clf = SVC()
self.args = args
a.registerCallback(listener1)
C = [[(0) for row in range(cols_B)] for col in range(rows_A)]
response = f.read()
recipe = Recipe.objects.create(**validated_data)
c = int(k[1][1:])
data = opener.open(request).read()
print(args)
self.name = name
raise KeyError
time = np.linspace(0, 10, num)
self.__dict__ = self
x = (radii * np.cos(angles)).flatten()
self.name = name
m.assert_has_calls([call.m1(), call.m0()])
user = ThreadLocal.get_current_user()
auc_from_fpr_tpr(fpr, tpr), auc_from_fpr_tpr(fpr, tpr, True)
y = np.random.normal(0, 0.5, 100).cumsum()
outcsv.write(ProcessLine(line))
get_token = re.compile(tok_regex).match
html = f.read()
print(sum(1 for i in map(int, file) if i % k == 0))
data = []
filedata.sort(key=lambda a: a[2], reverse=True)
h5py.__version__
baseName, ext = os.path.splitext(f)
ca.key = ctypes.pointer(ctypes.c_wchar_p(key))
debug = True
types = data.apply(lambda x: pd.lib.infer_dtype(x.values))
delta = dt.timedelta(seconds=hex_to_int(string))
a(1, 0)(1, 5)
dictionary.update(line.split())
text_parts = soup.findAll(text=True)
client = MongoClient()
y = [4, 5, 6]
self.clear()
levels[-1] = State.Done
all_nodes = Gh.nodes()
slcs1 = slcs[:]
quit()
[rotatePoint(point, angle) for point in points]
sys.version
wordpx.append(pixels[start:start + new_width * 4])
X = np.random.random(size=N) * 10
diffs = [abs(i[0] - i[1]) for i in zip(a, a[1:])]
indices = np.arange(1, max_value)
mapper(Customer, customers_table)
i = [0, 0, 1, 2, 2, 2] + 1
self._foo = val * 2
logger = self.get_logger(**kwargs)
data = ctypes.ARRAY(ctypes.c_float, 100)()
name = Column(String)
ns = list(range(1, len(words)))
full_sql = f.read()
res.append(capitalize_nested(s))
print(seq)
buf[idx % BUF_SIZE]
x = np.array(list(range(0, 6)))
plt.spy(a)
numcount = defaultdict(int)
mydict[mykey] = myfunc()
array = [i, j, k, l, m]
people = Person.objects.all()
True
my_dict[k][v1] = v2
p, cov = polyfit(x, y, 2, cov=True)
print(np.all(clf.feature_count_ == X + X2))
ws = wb.Worksheets[index - 1]
b, 0, 1
print(list(dic.keys())[0])
[1.5, 1.49999]
self.collector.dump_to_file(self.output_file)
self.clients = []
e, o = partition([1, 1, 1, 2, 2, 2, 1, 2], even)
stemmed_tokens = [st.stem(i) for i in stopped_tokens]
semilogy_to_bottom(X, Y)
print(node.type.kind, node.get_tokens().next().spelling)
s = np.sin(np.pi * t) * np.exp(-t * 0.0001)
t = t.__base__
zip = zipfile.ZipFile(f)
print(proc_stdout)
init = tf.initialize_all_variables()
handler.setFormatter(logging.Formatter(FORMAT))
sys.exit(1)
x[0] = 2
display = StringVar()
y = [25, 18, 17, 9, 8, 5, 8]
str(n.n)
allfiles = os.listdir(os.getcwd())
[(row + [v]) for row in subtable for v in [0, 1]]
x, y = np.where(a == i)
combs.pop(comb_index)
width, height = r.winfo_screenwidth(), r.winfo_screenheight()
a(7)
buff = cStringIO.StringIO()
os.rename(tmpLink, linkName)
result
fig, ax = plt.subplots()
client_socket.sendall(out)
url = urljoin(response.url, link)
shutdown_server()
new_strs.append(new_strs[new_strs.index(x)])
os.kill(pid, 9)
a.count(1)
arr[2] * 100000 + arr[1] * 1000 + arr[0]
print(gray_image.shape)
set(needed) & set(combination)
item = item.append(10)
a = np.array([False, True, True, True, True])
writer.writeheader()
ax[0].bar(dates, list(range(10, 20)))
print(word)
[]
rfc822.parsedate_tz(datestr)
ntimes = 0 if len(ntimes) == 0 else int(ntimes)
1
mycoord = SpatialReference(22186)
U = np.empty((0,), dtype=y.dtype)
binds.update(dict.fromkeys(finance_metadata.sorted_tables, finance_engine))
text = elt.text_content()
aprilFirst = datetime.datetime(2012, 4, 1, 0, 0)
4, 5, 6
qproc = Process(target=sub_proc)
ratio = (float(limit) / result[-1]) ** (1.0 / (n - len(result)))
flag1_enabled = flags & FLAG1
self.layout.addWidget(self.textedit)
value = map(float, value.split())
all_vars = dict(vars())
n += 1
self.start = time.time()
line = line.strip()
print(repr(Fraction(25, 5)))
seq.append(val)
f.close()
res = gcd(res, x)
print(spam, tomato)
current_dict = current_dict.setdefault(_end, _end)
itertools.product(L, L)
s
print(data[:, (idx)])
s.index = [s.groupby(level=0).cumcount(), s.index]
timeit(lambda : T(20, 12, 10, 70), number=1)
insertionsort(c)
recv = conn.recv(2048)
print(a, b)
print(a[100])
print(get_subclass_methods(SubClass))
obj = self.get_object(request, obj_id)
resource.AddSubclassFactory(scf)
source.python / bin / activate
result = np.empty_like(scores)
image_samples = []
smtp.login(username, password)
x == y
name = Column(String)
t = threading.Thread(target=doit, args=(pill2kill, task))
time_end = time.time()
termdocumentmatrix_example()
root = Tk()
not self.__eq__(other)
print(migrant)
[[1]]
s = bitstring.BitString(hex=hex(i))
False
print(result)
new_url
p.wait()
it = iter(seq)
float(item)
x.append(row[1])
count = len(line) + 1
session = aiohttp.ClientSession()
df.addCallback(results, name)
print(p1err)
arr.reverse()
sum += (u[i] - v[i]) ** 2
value = messages.IntegerField(1)
mat.sum_duplicates()
proc = subprocess.Popen(cmd, cwd=child_cwd, shell=True, close_fds=True)
start, stop, step = 4, -(len(a) + 1), -1
print(self.printstring, line.rstrip())
newlist = [([0] + i) for i in temp]
df2
CHANNELS = [1, 2]
c = db.cursor()
myfunc(input, myfuncFUNCTYPE(lambda x: mycb(x, userdata)))
file = open(filename).readlines()
eval(x, globals=namespace)
image = vid.get_data(num)
n = int(sys.argv[1])
m[k] += empirical[o, k]
plt.hist(b, **common_params)
result
pickle.dump(classifier, f)
n = int(sys.argv[1])
order_dict = dict(zip(b, list(range(len(b)))))
m, max_list
session.configure(bind=engine)
d, 1, 0, 1, 0
boo.asd
ax1.plot(list(range(10, 1, -1)))
result[t[1]:h1 + t[1], t[0]:w1 + t[0]] = img1
print(result)
fd = nltk.FreqDist()
self.append(n)
yummain.user_main(sys.argv[1:], exit_code=True)
children = el.getchildren()
numpy.longfloat
t1 = time.gmtime()
x * x
g = np.floor(np.random.random((100, 100)) + 0.5)
accumPatientData[1].append(match.gleason)
res = ndimage.mean(ar, labels=regions, index=np.arange(regions.max() + 1))
result.join()
timeit(fX, number=100)
centerLon = sum(x[1] for x in self._points) / len(self._points)
server.start(4)
print(X.shape)
_ + 1
Weekday, Week = np.mgrid[:df2.shape[0] + 1, :df2.shape[1] + 1]
self.time = datetime.now()
imgdata.seek(0)
output = t.render(c)
i += 1
self.vtkDepth.InsertNextValue(point[2])
s = s.lstrip()
h.shape
rowDict = OrderedDict(rowDict)
s = ast.literal_eval(s)
counter_lock = Lock()
nbors.append(i - A + p * W + (r - p) / 2)
print(result)
Root(request)
is_even
bin(1 << 8)
df.columns = cols
glPixelStorei(GL_UNPACK_ALIGNMENT, 1)
flatten(v, a)
self.window.SetInsertionPointEnd()
g, y, x = egcd(b % a, a)
cipher = AES.new(key)
GPS_EPOCH = datetime.datetime(1980, 1, 6)
root = Tk()
samples2 = [bin_to_int(s) for s in samples2]
System.out.println(m.group(1))
some_condition = True
A[6:12]
self.timer.timeout.connect(self.on_idle)
yhist, xhist = np.histogram(x, bins, weights=mass)
intersect = r.intersection(c)
max_indices = [i]
data_f = np.concatenate(data)
inv_len = 1.0 / math.sqrt(sum(coord * coord for coord in v))
one_week = datetime.timedelta(weeks=1)
key, sum_ = [], []
row = R.getrow(i)
MRWordCounter.run()
ret += to_json(v, level + 1)
pageData = sock.read()
str(signature(example))
processes[i].start()
content = f.read()
now = time.time()
print(df)
p = pyaudio.PyAudio()
result_dict[x.key] = []
app = wx.App()
False
myproducer = myqserver.producer()
myid = IntField(required=True, unique=True, primary_key=True)
foo()
p[np.tril_indices(p.shape[0], -1)] = pf
mx = x.mean()
extension
print(conjoined_endings)
y = q[0] + q[1] * xprime ** q[2]
data = [1, 4, 5, 6, 10, 15, 16, 17, 18, 22, 25, 26, 27, 28]
completed_tasks.append(task)
write_samples(output_wave_file, samples, sampwidth)
self.curve.setData(self.data)
ioff()
z = np.in1d(xhash, yhash)
0
str(o)
self.update(parm.copy())
wait = WebDriverWait(driver, 10)
shutil.rmtree(outdir)
d.isocalendar()[1], d.weekday()
val = redis.get(key)
c.executescript(query)
x = 2
start += 1
step = rrdMetric[0][2]
sys.exit(2)
PyObject * func_from_other_module(PyObject * self, PyObject * args)
self.__class__ = type(self.__class__.__name__, (self.__class__,), {})
cam = pygame.camera.Camera(pygame.camera.list_cameras()[0])
dfA.reset_index()
foo
b = a[:]
x /= sum(x)
string.Formatter.get_value(self, key, args, kwargs)
print(output)
globaltimes_randomnode = []
a = [(lambda i=i: i) for i in range(5)]
zB = math.cos(x + phaseB)
count = len(data)
labels = np.arange(0, 10) % 2
foobar = Derived()
joined_event_df = joined_event_df.swaplevel(0, 1)
dateData.append(start)
to_type(val)
Plot.init()
theta = np.random.rand(N) * np.pi * 2
response = requests.get(someurl)
y = np.random.randint(ymin, ymax, ndata)
xi, yi = (int(round(n)) for n in (event.xdata, event.ydata))
pylab.close(int(close_plot))
s = s[:start] + content + s[end:]
B.Update(self)
list.insert(self, *args)
result[old_arena] += old_timestamp - int(timestamp)
api / resources.py
cnv_text = lambda s: s.rstrip()
turtle.left(90)
--------views.py
CDN(app)
ax.scatter(x, np.minimum(y, ymax))
print(n)
logging_handler_out = logging.StreamHandler(sys.stdout)
result = a2[index]
I.append(np.arange(volume.size - INTERVAL_LENGTH))
print(MyZip.read(4))
self.stream = self.open_mic_stream()
bit_array[item_index] >> bit_index & 1
query.with_cursor(cursor)
x1 = v1[0]
y = np.vstack([x[i::M] for i in range(N)]).T.ravel()
b.do_something()
bagoftricks.geofind()
assert 1
print(arg01)
t2 = a[:, (0), (0)]
filename = sys.argv[4]
wrapper
cls
app.task(upload_done)
doc = etree.parse(valid)
update(a, (2,))
_ = lambda x: x
p2 = p1 + np.array([1, 0])
print(foo.timetuple())
zeroMatrix[i] = zeroArray[:]
mcastsock
rev += x & 1
closing_tags = list()
Xfit_mono_ind = zeros(Xfit.size)
self.get_model().objects.all()
t.update()
x, y = pair[0], pair[1]
xflat = np.full_like(x, min(ax.get_xlim()))
copy = dict(d)
fileHandler.setLevel(logging.INFO)
processes = []
delt = (w - a) * 60 + (x - b) + (y - c) / 60.0 + (z - d) / 60000000.0
f = Foo()
_send_refresh_request(user_social)
print(f.id.get_access_plist().get_cache())
pprint(inspect.getclasstree(inspect.getmro(Protocol)))
zip(*(islice(l, i) for i in range(n)))
print(parse_contents_href(url))
myData = JSON.parse(myDjangoList)
associate_address_with_sid(address, request.sid)
fig = plt.figure()
x0 = np.array([1, 0, 0])
one = models.CharField(max_length=255)
print(df1)
fnew_v[j, k] += f[i, j, k, l] * b[i, l]
print(randSolve())
fig = plt.figure()
g.db.execute(sql, (limit_offset, limit_count))
p.communicate(input=sequence)
print(len(lengthy_thingy))
sku_dict = defaultdict(list)
m = np.isnan(a)
df2 = df.copy()
mx = ma.masked_array(x, mask=[0, 0, 0, 1, 0, 0, 0])
packedIP = socket.inet_aton(ip)
a, b = list(d.keys()), list(d.values())
sieve = [True] * (n + 1)
width, height = image.size
r = int(k[0][1:])
hxs = HtmlXPathSelector(response)
ch = logging.StreamHandler()
finance_engine = create_engine(url1)
count = defaultdict(int)
frz = frozenset(f.readlines())
self.r = r
print(row)
t.join()
print(set(results) == set(results2))
splitmaptime
sub1 = subplot(211)
filesize = os.path.getsize(filename)
t += res[-1].duration
4004
5005
rename_dup(df, 1, pd.DataFrame())
type(thing)(pformat(value) for value in thing)
f = lambda x: x * 5
started = ndb.DateTimeProperty(auto_now=True)
words = content.split()
s1 = datetime.now()
print(output)
ch = s[0]
test2 = MyModel()
a = A()
[4, 0, 0],
744884
ctsquarelib.mysumsquares.argtypes = [c_float_p, ctypes.c_size_t]
self.fr.Show(True)
monday2 = d2 - timedelta(days=d2.weekday())
c.save()
atexit.register(save_cache)
x = 1
a[0] == True
setattr(self.inner, name, value)
true_points = np.argwhere(dat)
config.make_wsgi_app()
nextNode = nextNode.nextSibling
C = (np.random.random_sample(10000.0) + 20) * 40
x = np.concatenate((A, B)).reshape(2, 2, 2)
other.value < self.value
df1 = pd.DataFrame(randn(10, 5))
Response(serializer.data, status=status.HTTP_201_CREATED)
w = QtGui.QComboBox()
summary_op = tf.merge_all_summaries()
row += 1
plot(X, Y)
lenu = len(u)
ax.set_ylim(0, 1 / large)
dill.dump(rf, f)
thread = threading.Thread(target=cvloop)
y = np.sin(t)
value = Training.objects.first().date
logmod = linear_model.LinearRegression()
scr = curses.initscr()
self.application = application
loop.run_until_complete(main())
velcro.forward(150)
handler = urllib.request.HTTPBasicAuthHandler(password_mgr)
result += new[i].upper()
self.fn = fn
v2 = np.random.rand(N)
sums = numpy.bincount(x, weights=z)
M[0, col] = 1.0
toc = time.clock()
e.extract(x)
y = y ^ x
digits.append(d)
False
True, np.ma.where(ma == ma.min())[0][0]
logger = logging.getLogger(name)
df
f.close()
new_df = df.groupby(m % how_many_groups).apply(reset)
os.read(master, 1000)
[byteify(element) for element in input]
print(list(first_found(l)))
np.log(C, out=C)
L.sort(key=make_lazy(f2, g))
text_content = strip_tags(html_content)
push(*args)
array1 = array1[:-1] + array2
{NULL}
self.image = self.images[self.index]
closedir(dir_p)
True.__cmp__(2)
idx = df.index[df.Dependents.isnull()]
pprint(list1)
self.sum = value
today = now.replace(hour=16, minute=0, second=0, microsecond=0)
sio.write(v)
keyname = gtk.gdk.keyval_name(event.keyval)
statistics.median(map(Decimal, items))
dfA.dot(dfB.T)
output2HTML = widgets.HTML()
width, height = data.shape
jac[1:] = np.diff(jac)
min(commons, key=lambda v: max(L.index(v) for L in paths))
txt
yscale = float(y) / svg.props.height
q = Queue(maxsize=1)
p = f.tell()
y_proc = np.copy(y)
new_list.append(list1[0])
np.linalg.norm(A1[1:] - A1[:-1], axis=1)
a if not p else [sub_k_list(a[:p], k), sub_k_list(a[p:], k)]
sopot = [228481, 164126, 922891]
Text.__init__(self, x=x_pos, y=y_pos, *args, **kwargs)
d = {}
last_el = mylist.pop(-1)
x0, y0 = next(iter(sol))
thisM, thisC, thisR = self.score_cell(i, j, chars)
condition = pp.Group(expr + operator + expr)
print()
b = ones((2,))
self.stop()
p.join()
b = dfb.values.flatten()
numpy.all(numpy.abs(numpy.diff(numpy.sign(a))) == 2)
y = [max(g[1]) for g in groups]
self.cursor = cursor
a + b + c
soup4.body.__next__
[(pattern % s) for s in list_]
t = -math.log(x)
frame = cv2.flip(frame, 0)
ind = np.digitize(vals, bins)
result
(yes if pred(d) else no).append(d)
dfy = pd.DataFrame([row.T[0] for row in df2.y])
self._count -= 1
pfit = np.polyfit(x_range, y_range, 10)
bigstring.append(buffer)
QQ.old_poly_ring(x).quotient_ring([x ** 2])
print(b)
sf.where(q2).show()
df_c = df_a + np.random.randn(5, 7)
pos = np.where(np.diff(sorted_A))[0] + 1
x1, x2 = rootsearch(f, a, b, eps)
b = SomeClass()
foo_noniterable(iterable)
a = np.tile(A, 2)
result = HTMLParser.HTMLParser().unescape(urllib.parse.unquote(markup))
max_distanace_list = list(max_distances.values())
self.attachement = attachement
i, card = select_choice()
Foo.bar.__self__
arg = arg[2:]
y, x = np.mgrid[0:a.shape[0] / size, 0:a.shape[1] / size]
self.create_test_data()
application = get_wsgi_application()
fmt.dump()
msg = response.read()
get_thread = threading.Thread(target=getter, args=(q,))
stuff[0] += 1
x = 0
os.setuid(user_uid)
mask = np.full((img.shape[0], img.shape[1]), 0, dtype=np.uint8)
page = urllib.request.urlopen(req)
vals = np.concatenate(listvalues)
x = []
pycvex_Stitcher_Type.tp_getset = pycvex_Stitcher_getseters
print(p.introduce_self())
finder.nbest(bigram_measures.pmi, 5)
deletebatch[:]
I = [2, 4, 5]
[number] * int(rep)
wall(2 * (N - i), 1 + 4 * i)
data = list(string)
defaultValues = tf.zeros(a.get_shape(), dtype=a.dtype)
print(catalan_1(2))
g = g.map_offdiag(sns.kdeplot, lw=1)
b[(a > 40) & (a <= 80)] = funcB(a[(a > 40) & (a <= 80)])
print(n)
line += c
p.join()
values = [c.text.strip() for c in cells]
thisrow[len(seq2) - 1]
found = True
response = client.get(some_url)
mn, mx = ax2.get_ylim()
type(1j)
reduced_data = np.dot(evecs.T, data.T).T
ind = np.arange(self.n)
b = np.random.rand(D) + 1
posx = np.digitize(xdat, locx)
n_classes = 2
a_as_str = k
power = int(e[1])
endwhile
memdb.decr(self.count_prop)
element_counts = Counter(chain.from_iterable(allsets))
posts = bundle.obj.posts.all()
z[0]
data = np.transpose(data)
height, width, channels = arr.shape
print(item[-1])
print(f.read())
title = Column(String(100), nullable=False)
numbers = map(int, f.readlines())
c9sdk / scripts / install - sdk.sh
majorlocs = self.axis.get_majorticklocs()
a[:] = b
user = models.OneToOneField(User)
d = datetime(2012, 2, 10)
item = QListWidgetItem()
sys.path.append(app_roots[hostname])
r_dataframe = com.convert_to_r_dataframe(df)
path_list = path_list[1:]
d = dict.fromkeys(keys, [])
mask |= ar1 == a
self.clients = []
print(pi_gauss_legendre())
print(e)
d = {t.tag: map(etree_to_dict, t.iterchildren())}
d[i] = m[0, i]
win.show()
self._hash
raw_answer = input()
0
self.etElem.get(name)
a.extend(da)
self.gen.throw(type, value, traceback)
print(n)
R = int(round(B * 255))
fout.writelines(f.readlines())
prune(y, x)
rslt = pd.DataFrame([dict((x, r.count(x)) for x in r) for r in d]).fillna(0)
message, error = p1.communicate(certificate)
x = [6, 8, 7, 9, 6]
self.assertEqual([], self.verificationErrors)
ax1.set_ylim(100.0, 1000.0)
x[0:2]
date = datetime.utcnow()
config = IPython.get_ipython().config
block_number = -1
glMatrixMode(GL_PROJECTION)
Case(When(created__month=6, then=1), output_field=IntegerField())
fmt.Println(c)
result.append((x * n, y * n))
c1.append(1)
valuesi = valuesi.reshape(Xi.shape[0], Xi.shape[1])
res = timespec()
pars1 = st.norm.fit(data[classification == 1])
y * y
item = _decode_dict(item)
Bx = np.arange(Bxmin, Bxmax + dx, dx)
context = ssl.SSLContext(ssl.PROTOCOL_TLSv1_2)
txt = soup.body.getText()
print(Base)
ax = fig.add_subplot(111)
arr
known_links.add(link)
self.name = func.__name__
self.draw_segment(point)
collection = db.collection_name
y = y_train.as_matrix()
start = haystack.find(needle, start + len(needle))
v = QVariant((data,))
str(sum)
self.create_main_panel()
image = Image.open(infile)
serialized = UserSerializer(data=request.DATA)
r = session.get(url, params=params)
db.comment_post.post.default = request.vars.post_id
fixed_shuffle(lst)
n, _ = np.histogram(x, bins, normed=True)
p.nice(10)
nodes.append(n.func)
second_length = len(second) + 1
parser = etree.XMLParser(remove_blank_text=True)
flattened = [item for l in subset for item in l]
somewhereelse / reference_diff_page_001.pdf
pretty(d[key], indent + 1)
X[0, t] = u ** 2 - v ** 2 + a * u + b * v
IntStream.range(0, myList.size())
appstats_MAX_REPR = 100
dict1 == dict2
bar = args.two
x.group()
show(p)
n = ups + downs
sub(a)[:] = np.zeros((2, 2))
points.append([xi, yi, zi])
srt1 = sorted(s[::-1] for s in l2)
mat = np.empty((len(p0), len(q0), 2, 2))
split_names.index = split_names.index.get_level_values(0)
it1, it2 = tee(iter(it))
opener = urllib.request.build_opener()
f0 = (lambda val1: lambda val2: callback(val1, val2))(i)
filename = get_filename(path)
meta = defaultdict(defaultdict)
dt = datetime(2014, 7, 2, 16, 10, 54, 442585)
people_map = defaultdict(int)
print(substituted_str)
x, y
primfac
input = iter(lst)
image[idx, 0] = threshold
test_dict[key] = random.random()
self.attr2 = attr2
setup_environ(project)
result.append((v, k))
inc_type_md_col, cnt_col, ctr_dt_col = tuple(subq_xyz.c)
ys = np.arange(Y)
url = urlparse(url)
c.wait(timeout=100)
key_prefix = request.path
print(li)
c.accept(it.nextIndex(), next(it))
groups = itertools.groupby(SL, key=operator.itemgetter(0))
x = list(x)
type(a[0])
min_bin = np.min(list(counted_data.keys()))
scoreA += 1
print(simplejson.dumps(pyStruct))
_state, a, b, c
QtGui.QWidget.__init__(self, parent)
sync_low_level()
FG(1e-05).g()
fly.rect.y += fly.vspeed
ucd.name(u2[0])
default = compiler.get_column_default_string(column)
s = s[1:]
cNorm = matplotlib.colors.Normalize(vmin=min(cs), vmax=max(cs))
widget.resize(640, 480)
input_stream = sys.stdin
name
lines = f.readlines()
job.hour.on(12)
str(qstr_password)
mdd = dd.min()
filename = sys.argv[1]
root = ET.fromstring(response.content)
name, ext = os.path.splitext(file.name)
l.append(key)
width, height = original.size
expected = df[df.Name.isin(names)]
val = literal_eval(s)
b = numpy.array([4, 5, 6])
cur = cnx.cursor()
obj = np.asarray(input_array).view(cls)
True
test_suite = unittest.TestSuite()
get_num(x)
a = lambda x: x * 2
zvals = np.ones((100, 100))
res = []
print(ser.portstr)
self.cache[args]
self.readsofar = 0
[[get_bbox(x) for x in str]]
m = pattern.search(s)
d = json.loads(dd)
menu = gtk.Menu()
NULL
content = s[start:end]
data = np.array(data)
counter = Counter(data)
df
jobs = pool.map_async(Check, list(range(10)))
gp.fit(X=np.column_stack([rr[vals], cc[vals]]), y=M[vals])
client = MongoClient()
X.fillna(self.fill)
label.set_text(label.get_text() + non_block_read(sub_proc.stdout))
assert all(lst[i][1] == lst[i + 1][1] - 1 for i in range(len(lst) - 1))
callback = self.print_callback.__func__
plt.hist(vals, bins=100)
kivy.resources.resource_add_path(resourcePath())
output = os.read(fd, 1024)
b.setText(a)
count = 0
__metaclass__ = add_mixins(Mixin1, Mixin2)
i += 1
b = a[1:]
size = sys.getsizeof(d)
counts[i] += len(dice)
n = 24
event.widget.delete(0, END)
Tracer()()
_get_dict.argtypes = [c.py_object]
resp = request.invoke_subrequest(req)
points = mask.nonzero()
X = (y + np.random.randn(200)).reshape(-1, 1)
book_scores = {}
primeind += 1
unittest.main(testRunner=runner)
os.remove(temp_handle.name)
setattr(cls, name, getattr(self, name))
print(df1)
ret = np.zeros(csr_mat.shape[0])
e = np.vstack(d)
M = matrix(n, n)
timezone = dtz.gettz(name)
C = np.dstack([A, B])
modi_list(some_list)
adjacency = [(i, j) for i in (-1, 0, 1) for j in (-1, 0, 1) if not i == j == 0]
fun = dork1
data = json.load(open(json_url))
dct = {}
Foo().number
print(f.name)
mu, sigma = 0, 0.1
build_info = {}
amqp_connector = Connector()
print(newcorpus.words())
self.func = func
p = mp.Process(target=run_child, kwargs=d)
True
pn = df.to_panel()
base64.urlsafe_b64encode(md5bytes)
assert test_list[-8] == 5
inst.__dict__[self.name] = value
result_image = image.copy()
B = [0] * len(matrix)
r.resize(r.size() - 1)
x = 1
extend(l)
mydict.update(tmp)
MSE = NP.sqrt(NP.sum((y_pred - y) ** 2) / 10)
input = input.split()
existing = set(self.fields.keys())
upperCorner = ax.transData.transform((1.2, TICKYPOS + 0.2))
argvalues = inspect.getargvalues(frames[0][0])
ind = np.digitize(vals, bins)
b = np.array([[np.real(x), np.imag(x)] for x in atmp])
blogger_html
values = tuple(new_values)
fig = figure(1)
start = 0 if last < 1 else sorted_keys[last - 1]
gp2 = []
x = npct.as_array(x, (n,))
self.valid_template = False
sys.exit(0)
print(line)
row = {name_map[name]: val for name, val in row.items()}
params = {}
cgitb.enable()
soup = BeautifulSoup(content)
manager = multiprocessing.Manager()
f = Foo()
min_x = np.nanmin(rot_points[:, (0)], axis=1)
obj
pic = cStringIO.StringIO()
AI2 = 0
p.set_array(np.array(colors))
mylumpofdodgyhtml
image[:] = color
index = list(range(1, max(df.index) + 1))
yn = y + 0.2 * np.random.normal(size=len(x))
info = pat.match(s)
y = np.random.random(N)
r = {}
args_copy = copy.deepcopy(args)
print(self.data)
elem = minidom.parseString(s).firstChild
d.x = 0
self.button.draw()
printset = set(string.printable)
base.get(id=id)
strategy = operationFuncs.get(operation(), DefaultObject())
[MASTER]
f.close()
False
ss.shutdown()
self.runable = True
obj[1] = False
zip(a, b)
list(range(first, last + 1))
n
print(pfoo[i].id, pfoo[i].name)
id(self)
incr = np.ones(counts.sum(), dtype=int)
screen = curses.initscr()
chunk = decompressor.read(8192)
shutil.copy(dll, cdir)
res = cv2.bitwise_and(frame, frame, mask=mask)
n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)
print(datetime.datetime.now())
print(result)
map(int, x)
mapping = {u: i for i, u in enumerate(labels)}
result += 1
height = self.parent().height()
j += 1
self.mainloop.quit()
req = urllib.request.Request(url, post, headers)
y = [tuple(sorted(q)) for q in y]
self.s = s
l = len(key)
activation = task.activate()
outfile.close()
a = 1,
cr.show_text(yourtext)
sprite = pyglet.sprite.Sprite(img)
year = tempdata[:, (0)]
unique = [item for item in lst1 if item[:2] not in remove_keys]
id_arr[idx[:-1]] = -a[:-1] + 1
a = df.columns[arr1[:, :k]]
s.sendall(content)
btdtri = scipy.btdtri
rows = np.isnan(g).all(axis=1)
np.array([[C_x, C_y]])
log.put()
glist.append((newgr, pos))
self.seek(0)
cleaner = Cleaner(**args)
self.children = []
self.specialValue
splitup[1], splitup[0]
in_f = cStringIO.StringIO(out_f.getvalue())
c[:i] + (c[i] + 1,) + tuple(range(len(c) - 2 - i, -1, -1))
i, j, k = np.ogrid[:2, :2, :2]
random_48_bits = random.randint(0, 2 ** 48 - 1)
result.append((x * n, y * n))
d = [1, 1, 1, 1, 1]
ax = fig.axes[0]
len(chunk)
f = Foo()
parent_mock = MagicMock()
sum_vals = [10, 9, 7]
Xret = np.ones((rowcount, width), dtype=np.uint16)
args = [iter(iterable)] * page_size
z = h0 * np.ones(len(x))
g = igraph.Graph.Adjacency((A > 0).tolist())
order_form = OrderForm()
print(it[10])
colors = np.empty([colors.shape[0], colors.shape[1], 4])
print(gram)
styles = getSampleStyleSheet()
self.file = open(name, mode)
fields = model_instance._meta.get_all_field_names()
mostfreq = freq.most_common()
doc = parse_html_string(htmldocstr)
print(clrscrn)
cluster_idxs[c].append(int(i))
[(x ** 2) for x in self.mylist]
render()._repr_html_()
db.put(to_put)
d = defaultdict(int)
parts = [to.join(split_subparts) for split_subparts in split_parts]
dialog.exec_()
x = q + 2 * p
weights = []
numC = random.randint(lowerLimit, upperLimit)
blocks = np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)
color = line.get_color()
c[letter] += 1
x[0] = 5
print(os.pathsep)
1 / 0
ranks = literal_eval(line)
object.clickCheck(event.pos)
False
z[0][:] = 0
angles[:, 1::2] += math.pi / n_angles
streetno = {}
b = C()
data = []
id = sqAl.Column(sqAl.Integer, primary_key=True)
func.coalesce(cls.end, func.current_timestamp()) - cls.start
[x for x in things if type(x) == type]
string = string.replace(i, j)
hex((ord(hex1) + ord(hex2)) / 2)
ndb.put_multi(entities)
target_index = l1.index(target_element) + 1
raise ValueError
c = C()
dict2 = {(5): 6, (7): 8, (1): 1, (2): 2}
loop = asyncio.get_event_loop()
query = select([users], and_(*terms))
b = [(lambda : i) for i in range(10)]
inv_transform = axis.transAxes.inverted()
self.name = name
y_means = np.array([np.mean(y[x == u]) for u in x_unique])
t1.start()
clf.fit(gaussianKernelGramMatrix(X, X), y)
a = abspath(somepath)
full_arr[sort_idx]
y[:] = 1000
int(hexlify(s[::-1]), 16)
result = cv2.warpAffine(image, rot_mat, image.shape, flags=cv2.INTER_LINEAR)
print(bytes_to_num(num_to_bytes(n)))
True
up = Vector((0, 0, 1))
x = Z[:, (np.r_[:49, 50:100])]
sys.modules.pop(fullname)
B = list(reduce(lambda a, n: a[n[0]].append(n) or a, A, defaultdict(list)).values())
n = length(s)
self.func = func
self.queue.task_done()
split_commas = set(all_commas) - set(special_commas)
store.close()
res = conn.getresponse()
OUTPUTS = 4
sys.exit()
cache = foo()
r.append(1.0)
print(response.get_data())
False
encoded = encrypt(key, text)
style = xlwt.XFStyle()
bar = etree.XML(foo, parser)
array2 = np.array([14, 70, 204])
ret -= timedelta(days=7)
N = len(tables[0])
it = iter(iterable)
b = a.tolist()
f = lambda x: x ** 2
path / to / jar2.jar
random.randrange(1, secret_number_range + 1)
ThickLine(img, p0, p, color, thickness, line_type, flags, shift)
offset = random.randint(0, sum(d.values()) - 1)
blockLengthX = np.argmin(a[0] == a[0, 0])
api = Api(app)
timezone.make_aware(naive, timezone.get_current_timezone())
lis = lis[20:]
module_a.foo()
M[np.unique(m_ind)] += update.ravel()
fig = plt.figure()
print(fixed_str)
setattr(args, self.dest, values)
fieldDataList = [fieldDataArray.getValueAsElement(i) for i in range(0, size)]
user = models.ForeignKey(User)
print(metrics.average_precision_score(tstlbl, prob))
a.x
browser = spynner.Browser()
foo(next(prng))
chars.append(c)
is_coherent(l1)
self._key
ceil(datetime.datetime(2012, 10, 25, 17, 45))
a
config = ConfigParser.ConfigParser()
p = psutil.Process()
axes(frameon=0, aspect=1, polar=1)
proxy = urllib.request.ProxyHandler({})
output.write(resource.read())
r = r.reshape(shape)
self.lock = threading.Lock()
assert np.all(z[(0), (0), :] == z_)
count2 = 0
print(Meta.authentication)
self.vdisplay.stop()
line = line.rstrip()
b = a[1:]
scores = np.where(played, v, -1)
ll = list(zip(*(v.ravel() for v in m)))
Ol[i] = Ol[l]
y = a * np.abs(x - x0) + b * x + c
d = {}
myList = [(i ** 2) for i in range(10) if i != 2]
1, 1
n = len(data)
solution.append(character)
msg += e.what()
print(hist)
field.populate_obj(obj, name)
result = []
report.close()
a.reverse()
self._job = next(job_counter)
session = DBSession()
bcrypt.checkpw(plain_text_password, hashed_password)
a[:4]
skype.Attach()
ps = PSDraw.PSDraw(myf)
print(u.hostname)
a = Point(1, 2)
segment_scores = {(A, B, C, D): 0.99, (A, B, C, E): 0.77}
ret.append(b)
2 * f(*xs, **kws)
s = sorted(lst)
s.setsockopt(socket.SOL_IP, IP_MTU_DISCOVER, IP_PMTUDISC_DONT)
view = QListView()
results = sm.OLS(data.endog, data.exog).fit()
vector = [109.85, 155.72]
diag = np.ones(n - 1)
[tuple(item) for item in second_step]
f
fit = stats.norm.pdf(h, np.mean(h), np.std(h))
h, wB = len(rows), int(mult8(w) / 8)
curve += np.outer(Bernstein(N - 1, ii)(t), points[ii])
self[:] = state
print(min(li))
X, Y = np.meshgrid(x, y)
math.ceil(x)
foo == 1.5
self.n = n
f.write(text)
val = worksheet.cell(2, 1).value
qs.delete()
dis.dis(use_int)
echo.shutdown()
self._data = data
total = 0
pivot = next(i)
random_float(5, 10)
threads = tf.train.start_queue_runners(coord=coord)
img1_k.append(1)
h = defaultdict(list)
gc.is_tracked(t1), gc.is_tracked(t2)
compdb = CompilationDatabase.fromDirectory(compilation_database_path)
example_dict = dict(zip(list(range(10)), list(range(10))))
value = user_input.get()
my_loc(df, idx)
map.drawcoastlines(linewidth=0.25)
0
arg_names = func.__code__.co_varnames[:func.__code__.co_argcount]
bar.x = 42
distance = m.sqrt((y - Ro) * (y - Ro) + (x - Ro) * (x - Ro))
self.base.someMethodOfBase(*(args ** kw))
con.Close
app.Open.Open.Click()
raise Timeout()
values = [tuple(dd[k][i] for k in list(dd.keys()))]
xs.insert(0, xs)
points = zip(xs, ys)
foo(line)
sum(range(49999951, 50000000))
sys.__excepthook__(type, value, tb)
f
tmp[(0), :, :] = (1.2 - 0.8) * np.random.random_sample((sy, sz)) + 0.8
parser = bibtex.Parser()
interp = sp.interpolate.interp2d(x, y, image)
conn, addr = sock.accept()
print(diagonal(arr, corner1, corner2))
Xfit_mono = Xfit_mono[:len_mono + 1]
mod2.pxd
filter_parser = argparse.ArgumentParser(add_help=False)
v, i = min((v, i) for i, v in enumerate(n) if v is not done)
shorter_id = base64.urlsafe_b64encode(hashlib.md5(orig_id).digest())[:11]
self.x = 0
crnt = stck.pop()
a[0] = a
randIndex = random.sample(list(range(len(mylist))), sample_size)
birthday = datetime(1988, 2, 19, 12, 0, 0)
df
self.cancelled = True
l = Label(textvariable=a)
type_char_p = ctypes.POINTER(ctypes.c_char_p)
l.extend([partition[:start], partition[start + k:]])
results[full_name] = importlib.import_module(full_name)
series_name = [i[0] for i in series]
Z9PTUqQLh5keX / IRJ6JxaQkVBIy / iyoCIx2Y0zy5F5tll8CRydGzFDjXMLWEG425
barytransform = np.linalg.inv([[ax, bx, cx], [ay, by, cy], [1, 1, 1]])
params = params.copy()
o, e = process.communicate(timeout=10)
theta = np.linspace(0, 2 * np.pi, 50)
clf = svm.SVC(verbose=2)
list.append(e)
my_args = sys.argv[1:]
self._jstext
n = len(keys)
myfunc.argtypes = [POINTER(c_char), callbackFUNCTYPE]
sigma = sum(y * (x - m) ** 2)
total = -total
datafilter = datafilter | Q(publish_date__day=i)
b = numpy.sum(x[6 - i:4 + i, 6 - i:4 + i])
flds = tuple(zip_longest(pads, (0,) + cuts, cuts))[:-1]
_
f, ax = plt.subplots(1, 5)
normalized = array / np.amax(a)
print(str(infile))
main()
out[mask] = np.concatenate(v)
self[key]
g(4)
q[1][1] = 4
setattr(cls, name, self)
hm = pyHook.HookManager()
x = np.linspace(0, 2, 1000)
self._n
mylibrary.config
s.send(data)
np.arange(5).dtype
x % sql % y
ax = f.add_subplot(1, 1, 1)
data = [4, 5, 6]
apply_along_axis(func1d, -1, arr2d)
[f(fixed, x) for x in thelist]
line = thefile.readline()
lst = [i[1] for i in F if (i[1].year == year) & (i[1].month == month)]
local_time = now.astimezone(la)
self.addContentToSpelling(writer, item.content)
y = 2
HttpTransport.__init__(self, *args, **kwargs)
sys.exit()
print(i, x)
t = np.linspace(0, 100, 1000)
myattr = myattr()
self.factory.clientConnectionMade(self)
ar = np.array([0.0, 0.0])
main()
branch[parts[-1]] = 1 + branch.get(parts[-1], 0)
roundTo = dateDelta.total_seconds()
J = np.nonzero(row)[0].tolist()
i = 0
x = np.arange(8.0)
result = {}
result += sortBy(sublist, keyChain[1:])
p.join()
out = A[:, (colmask)]
self.properties[property] = self.properties.get(property, 0) + amount
a
setattr(self._obj, item, value)
raise ValueError
a = A.__new__(A)
sum(q) / len(q)
print(line)
not isinstance(x, str) and True
print(image_entropy(img))
call_method_that_does_not_exist()
x = np.linspace(0, 2 * np.pi, 10)
results = p.imap(f, jobs)
b.py
err_xs.append((x, x))
p[0] = tmp
d = addresses_table.delete(addresses_table.c.retired == 1)
print((line[0], date, line[count]))
total += len(files)
data = json.loads(request.data)
M.select()
variables = vars()
objid_to_idx = {id(obj): idx for idx, obj in enumerate(lst)}
actions.append(obj())
igd = gupnp.igd.Simple()
max_indices = np.argmax(n, axis=1)
arg = math.atan2(y, x)
degrees(acos(distance)) * 69.09
response = urllib.request.urlopen(certificate_url)
res = sys.stdin.readline()
d = (i[2] - i[2] // 1) * 100
instance.categories.add(category)
adder_w(2)
plt.xlim(0, 100)
self.update(*args, **kwargs)
y = y * sin(theta)
False
items.append(item)
soup = BeautifulSoup.BeautifulSoup(urllib.request.urlopen(url))
len(self.valid_keys)
result = f(number, sigfig)
mean_params, std_params
model, resid = np.linalg.lstsq(A, y)[:2]
print(df)
dict_time[0.1]
doctree - resolved(app, doctree, docname)
print(img_url)
shin, shout, sherr
out.seek(1024 * 1024 * 1024 - 1)
cache[int(key)] = value
a = pipe.readline()
dis.dis(t1)
print(x)
l2 = [l, l, l]
print(f(v, 0, sum, memo))
result = result[1:] + [elem]
print(dictionary)
self._doQuery(query)
signx = sign((x - pi / 2) % (2 * pi) - pi)
raise StopIteration()
p = psutil.Process(os.getpid())
+repr(data)
browser.submit_form(signin)
loop.close()
U, S, V = np.linalg.svd(sigma)
out_shp = [ID_arr.max() + 1, vals.max() + 1]
dc = wx.MemoryDC(new_bitmap)
t.interval(0.99, 10, loc=1, scale=2)
tweet_sample = json.load(f)
cmd.append(param)
parser._actions
a = numpy.empty(shape, dtype)
print(now)
unpad(aes.decrypt(encrypted[16:]))
notFound = list(set(all_vals.keys()).difference(list(newDict.keys())))
line_columns = [p1a, p2a, (p1a, p1b), (p2a, p2b), (p1a, p1c), (p2a, p2c)]
factor = int(round(float(rec[-1]), 0))
created = models.DateTimeField(auto_now_add=True)
k(**d)
s = requests.Session()
current_process = psutil.Process(os.getpid())
key.upper()
pos = self.lc.ScreenToClient(wx.GetMousePosition())
b = np.random.randn(1000)
whisker = 1.5 * iqd
print(self._A__name)
X = odeint(dALLdt, ic, t)
fig.colorbar(im)
[] - [] - [] - []
dtype = []
some.staging.host
print(hex(i))
k += 1
base, ext = os.path.splitext(filename)
ax = plt.gca()
z = []
deferred.resolve(response, status, headers, config)
df.status.mul(df.type).sum(1)
response = urllib.request.urlopen(req)
x = r * cos(theta) * sin(phi)
field = model_class._meta.get_field(key)
r, g, b
name = db.Column(db.String(255))
b = sorted(a)
self.normalized == other.normalized
deletespr
d[el.tag] = {}
print(profiler.output_text())
{name}
first, second
B = view_as_blocks(A, block_shape=(2, 2))
k.read(10)
response = service.methodName(parameters).execute()
print(i)
folder = fso.GetFolder(folderPath)
content_typeA = ContentType.objects.get_for_model(ModelA)
dfa = np.diff(np.hstack((-1, a, -1)))
print(item)
__metaclass__ = BooType
self.__dict__[property] = amount
pdf_queue = multiprocessing.Queue()
PyErr_Print()
elements = selobj(documenttree)
attr = getattr(attr, elem)
last = df.irow(i)
dict = request.form
t = ET.tostring(tree)
self.a
a = np.eye(5, 5)
found_vals[line[0]] = line[1]
Func(lambda x: self(x) + other(x))
now.dtype
False
grid = np.random.random((6, 6)) * 10
self.mock_assertions()
True
t1 = Process(target=f, args=(x,))
vfunc = np.vectorize(func)
f = lambda x: x ** 2
b = 1
print(event.ind)
data = json.load(response)
wb = Workbook()
reloader(locals())
raise template.TemplateSyntaxError(msg)
hc_scaled = (hc - hc.min()) / (hc.max() - hc.min())
lst.remove(n)
c.setPageSize((700, 500))
text_cell_runlist = first_sheet.rich_text_runlist_map.get((row_idx, COL_IDX))
print(f(1000, 500, 0.5))
row = dict(zip(columns, row))
cnx.disconnect()
qs[0].author
an = (a + b) / 2
c.accept(i, list.get(i))
L.extend(l * i for l in LL)
sys.getwindowsversion()[0] == 6
path = k.to_path()
print(str(s))
print(mydict[b])
MyClassUnderTest().main_method()
my_shelf = shelve.open(filename)
f.close()
[] or False
self._d[key]
dwg = svgwrite.Drawing(name, (svg_size_width, svg_size_height), debug=True)
output = StringIO.StringIO()
x = numpy.arange(n)
res = dict(collections.Counter(L).most_common()[:2])
tasks.monitor_all.delay()
xml = dict2xml.dict2xml(r.json)
find_min(l[1:], smallest, assigned)
tangent = math.atan2(dy, dx)
image = np.array(image, copy=True)
df2.columns = df2.columns.droplevel(0)
sorter_a = np.argsort(a)
line = infile.readline()
labels.append(label)
display = Display(visible=0, size=(800, 600))
a.a = 1
results = [tester.timeit(times) for i in range(rounds)]
outputFile.save(sourceFilePath)
hash(self.id) ^ hash(self.area)
[]
[p for p in database if type(p.data) == Foo]
fig, axes = plt.subplots(nrows=20, ncols=2, sharex=True, figsize=(6, 10))
loop.close()
s.close()
mantissa = floor(mantissa * 10 ** (sigfigs - 1)) / 10 ** (sigfigs - 1)
iterable = list(iterable)
allfiles = glob.glob(path)
print(repr(my_class))
list2 = list1[:]
referrer = []
m.drawmeridians(np.arange(-180.0, 181.0, 60.0))
df
print(response.reason)
l = list(range(10000))
self.lock = lock
self.A[self.box_slice(j, k)]
item
adic
lr.bind_callables(pinfo.pdict)
-np.sum(template == image)
full_key_name = os.path.join(path, key_name)
b[-1] *= 2
br = mechanize.Browser()
my_point_list = [Point(p[0], p[1]) for p in my_tuples_list]
allow_reuse_address = True
user
module = sys.modules[module]
py_warnings_logger.addHandler(console_handler)
m = np.concatenate(([True], np.isnan(a), [True]))
text = db.Column(db.Text)
idx[axis] = slice(start, end)
k = 2
headers = self.tv.horizontalHeader()
listbox.config(selectmode=EXTENDED)
wraps(func)(wrapper)
next(csvfile)
n = 0
self.filename = filename
self.fn = fn
lower_blue = np.array([110, 50, 50], dtype=np.uint8)
title = db.Column(db.Text)
s.index = pd.to_datetime(s.index)
img = wx.Image(fn, wx.BITMAP_TYPE_ANY)
print(xlrd.xldate_as_tuple(a1, 1))
self.username
x16 = []
prefixes[prefix].add(key)
(7, [7]),
p(convert(ambiguous_dt, east_tz, pytz.utc, is_dst=True))
num_years - 1
Y = np.array([[1.0], [0.0]])
result = re.search(expr, template)
print(ans)
upper = string.ascii_uppercase
print(findall_replace(ch, pat, rep))
next(t)
document = next(cursor)
self._request = request
sidebarView.html
foo(line)
self.method = method
out = []
db(query).select()
repo.commitctx = updatectx
l = [a.text for a in l]
i = 1
s, c = math.sin(angle), math.cos(angle)
self.start <= num <= self.end
frequencies[value] += 1
args = parser.parse_args()
globals()[module] = module_obj
total = a + b + c + d
s += float(i[:-1])
base_url = page_url
self.generator
match.group()
self.connection_pool = redis.ConnectionPool()
show_topics(num_topics=10, num_words=10, log=False, formatted=True)
x, y = [], []
False
X -= X.mean(axis=0)
o.add(value)
first_gt10 = next(itertools.ifilter(lambda x: x > 10, [10, 2, 20, 5, 50]))
r = requests.get(url)
end = len(seq)
my_counter = Counter(my_list)
g_filter /= np.sum(g_filter)
sift = cv2.SIFT()
os.rename(fout.name, fname)
b.finalize_options()
print(messageExpr.parseString(testStr))
a2.ravel()[:] = np.array(ll).tolist()
gash
fig = plt.figure()
pprint(params)
score = score + a[i] * b[i]
remote_bind_address = (_remote_bind_address, _remote_mysql_port),
x * 2
l2.append(np.sum(l1))
response = urllib.request.urlopen(request)
columns = [x.name for x in cursor.description]
sum
[]
ch = regex.findall(f.read().lower())[0]
servicemanager.StartServiceCtrlDispatcher()
l.setLevel(logging.INFO)
divs[j][0] += 1
print(l2)
_g[key] = getattr(settings, key, value)
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
print(out)
L_a = len(a)
test(result)
iplot(fig)
newImage = Image.new(mode, (canvas_width, canvas_height), new_background)
insert_after(element, new_element)
dis.dis(foo)
print(A.indices)
n = 0
obj = round(obj, 4)
circular_primes = [p for p in primes if is_circular(p)]
(C.y - A.y) * (B.x - A.x) > (B.y - A.y) * (C.x - A.x)
glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_WRAP_S, GL_CLAMP)
df
[i] + prime_factors(n / i)
index = np.digitize(a.ravel(), palette, right=True)
convergence = abs(dist[i] - dist[i - 2]) < 0.1
current = multiprocessing.current_process()
args.remove(self_arg)
print(jez(df))
points.append(origin)
print(add(1, 2))
sys.stdout = where
data = json.loads(response.body)
B
temp = tempfile.NamedTemporaryFile(prefix=basename, dir=dirname)
root = tk.Tk()
t0 = time.time()
next(comp)
ax._orig_position = ax.get_position()
all(recursively_empty(c) for c in e.iterchildren())
self.cursor.execute(sql)
fly.rect.bottom = hit.rect.top
counts = Counter(data)
box = tuple(x / 8 for x in a.shape)
fig, axarr = plt.subplots(2, 2)
g = globals()
existing_provider.rssfeed = form.rssfeed.data
f(target)
df
dic1.keys() - dic2.keys()
alltests.addTest(unittest.findTestCases(module))
55.0
result = result.iloc[0]
w, z = gw, gz
setattr(MyFancyNumber, name, make_func(name))
cursor = connection.cursor()
p = numpy.poly1d([2, 4, 6])
print(args)
mi = np.max(ii.nonzero())
self
s.close()
z_series = hstack((z_series, record_z))
porter = PorterStemmer()
output
obj
self.fed = []
gray = rgb2gray(img)
self.do_open(self.getConnection, req)
np.multiply(tr1, tr2, out=pr)
result_values[i] = np.mean(values[names == name])
sec = gllhs[2]
b = asarray(b)
width, height = image.size
f2 = (f2 - np.min(f2)) / (np.max(f2) - np.min(f2))
stackSize + 1
row = sheet1.irow(0).real
print(i + 1, len(pub_dict))
dict(k)
buff = bytearray(os.path.getsize(file_path))
combs = []
f(*args)
image = image.rotate(90)
col2 = data[:, (1)]
print(L)
result_dict[len(word)] = {word}
self.trayIcon.set_from_stock(icon)
ClassB.ClassB(theirnumber)
offset / 60 / 60 * -1
inserts = [(a + c + b) for a, b in splits for c in alphabet]
min_val = a.min()
element = ET.fromstring(data)
trunk[FILE_MARKER].append(parts[0])
[map(ip2long, rng) for rng in map(expandrange, ranges)]
im[x, y] = max(im_a[x, y], im_b[x, y])
print(closest(X, p))
s.listen(backlog)
1
particles.append(Particle(150, 150))
bv = surface.get_buffer()
self._n ** 2
confint[i].append([np.nan, np.nan])
entry_point.add_command(group2.version)
DataFrame(self.model.predict_proba(X))
a
import_array()
quit()
a[idx]
out2 = a.reshape(-1, np.prod(a.shape[-2:]))[:, ::-1].reshape(a.shape)
raise ValueError
primefactors
match[i] = i - start + 1 + match[start - 1]
score = score + 1
fly.rect.top = hit.rect.bottom
list(filter(isPrime, collatz(n)))
print(stop - start)
fig = plt.figure(figsize=(12, 4))
days_ahead = weekday - d.weekday()
value = node.get_data()
x += 1
index2wordcollection = doc2vecmodel.index2word
df.div(df2)
z = rz * np.outer(np.ones_like(u), np.cos(v))
self.hidude = hidude
fun(obj, *things)
fig, ax = subplots()
np_labels = set([nsubj, nsubjpass, dobj, iobj, pobj])
words = []
counter = collections.defaultdict(int)
items.append(q.get_nowait())
print ()
self.value = value
Py_SetProgramName(argv[0])
out[1]
dt = pd.DataFrame(rand(len(dr), 2), dr)
pairs = zip(lst, lst[1:])
login_required(active_required(my_view))
config.solar.azimuth_angle
self._list.append(item.row())
print(matches)
other_option = False if len(options) != 2 else options[(oindex + 1) % 2]
df = read_frame(qs)
result = chr(n & 255) + result
l = []
myentry = Entry(myGui, textvariable=B).grid(row=1, column=0)
G.set_axes_range(0, 20, 0, 20)
self.base = numpy.zeros(6)
B, drops = drop_strict(A)
request = urllib.request.Request(genuwine_url, data, headers)
stop(my_log, logging.handlers.RotatingFileHandler)
self.check(v)
randval = min + (max - min) * oldval
self.b = 2
ax = subplot(111)
columns = df.columns,
EuuRDQrBgQnmVtlZ2t42QfIRBSvfJheZVh8k27g / tH5wpchZ47gxxatUKsVJ84P8
x = [randint(1, 9999) for _ in range(randint(50, 200))]
a, b, c = b, c, next(gen)
1048
sorted_s = sorted(s, key=lambda v: v[2], reverse=True)
print(longest_nan_run([1, 2]))
sys.exit(application.exec_())
partial_duplicate_destroyer(mydict, 2)
main()
yHat = np.matrix(self.predict(x)).T
print(a[dim])
response
row.name
fig = plt.figure()
my_config_value = 42
self.my_text = my_text
results.append(dict(item))
weatherData = json.loads(jf.read())
listAA = [listA[x:x + 10] for x in range(0, len(listA), 10)]
zA = math.cos(x + phaseA)
C.foo
print(test_utf8)
print(mylist)
print(sum1(1))
self._register()
row = mycursor.fetchall()
j = j + 1
print(datetime_as_iso_ms(d), test)
a = numpy.arange(1, 15)
result.append(known[-1][0])
p = Popen(cmd, stdout=iofile, stderr=iofile)
spectrum = numpy.fft.fft(signal)
self._cards[card_ID]
df
x = X()
request.notifyFinish().addBoth(lambda _: lc.stop())
problem = sys.argv[1]
r = np.random.randint(n_data - 1000)
query = PersonalPost.all()
clipboard = wx.TextDataObject()
ch = stream.read(1)
utc_time = eastern_time.astimezone(utc)
wx.RAISED_BORDER
template_path, view_params = view_method(request, *args, **kwargs)
df[col] = numpy.roll(df[col], nb_iterations)
print(list(files))
C().f(1, 2)
xi = numpy.abs(x - x0).argmin()
assert to_camelcase(test) == expected
leftShuffle.extend(rightShuffle)
set(d2.items()) - set(d.items())
entities.append(entity)
sparsity += spars
fit = leastsq(func, [10, 10, 10], args=(xs, yn), Dfun=dfunc, col_deriv=1)
d.addSample([1.0, 1.0], [0.0])
mu = np.log(scale)
plt.subplot(1, 2, 2)
repr(path)
self.lineEdit = QtGui.QLineEdit(self)
readFile(filename)
S2 = set(L2)
ptr = ctypes.cast(x, ctypes.POINTER(ctypes.c_ulong * 5))
auth_resp = urllib.request.urlopen(auth_req)
idx = (idx + 1) % len(li)
lake = labels == idx
chunk = [1] * 400 * slot_duration
result = a + b + c
parent_indent, parent_tree = stack[-1]
test > x
password_hashed = bcrypt.hashpw(password, salt)
list(set(list1) & set(list2))
A = (M.sum(0).sum(0) - D) / 2.0 + D
bin / pypy
ax = fig.add_subplot(len(yn), 1, i + 1)
CommunicationFormSet = inlineformset_factory(Contact, Communication)
row = cursor.fetchone()
True
ff.quit()
rs = p.map_async(do_work, range(num_tasks))
foo()
driver = webdriver.Firefox(firefox_binary=binary)
sum_key = key[0], key[-1]
workers = []
catalogue = tree.getroot()
objarray(alist, 4)
s = str(cell_value)
db.rollback()
source_name = os.path.join(java_path, name)
wei = s.weibull_min(2, 0, 2)
data.append(curRow)
date_from, date_to = [to_date(lit(s)).cast(TimestampType()) for s in dates]
form.order_entries.append_entry()
encoded = base64.b64encode(ciphertext)
digits.reverse()
d1_ts = time.mktime(d1.timetuple())
ax2.set_yticks([])
cursor = dbapi_connection.cursor()
A[end], A[0] = A[0], A[end]
xbnds = np.array([-20.0, 20.0])
length.sort()
locals()
b[0]
column[h].append(conv(v))
unittest.main()
r = tracer.results()
myTurtle.pensize(size / 20)
os.close(fd)
task_1_result = task_1.get(timeout=1)
x = np.random.uniform(0, 1, [seq_len, batch_size, input_size])
sorted_values = sorted(list(values.items()), key=lambda val: val[0])
s.index = s.index.droplevel(-1)
selection.add(int(i))
print(findall_replace(ch, pat, rep))
root = tk.Tk()
raise NotImplementedError
pool.join()
Lo - -other
[18, 2, 6, 14],
rhymes = []
tok = string_tokens.pop(0)
c.shape = 20
print(result)
ips = list(ips_data.keys())
address = models.TextField(unique=True)
r.search(p)
assert len(c) == 2
request
print(type(a))
combined_meta_data = MetaData()
piecew(2.1)
getattr(handler.request, method).add()
arm_number = arm_number + 1
np.percentile(S, 0)
a * x ** b + c
den = np.array([1.0, -alpha])
print(ACK)
allowed_domains = []
self.rcon.connection_pool.disconnect()
host = m.group()
-Alice
random.seed(seed)
res
self._sendRequest(d, request)
app = Flask(__name__)
sensor_row = models.PositiveIntegerField()
s.shutdown(socket.SHUT_WR)
r.set_data(html)
Values = map(f, list(range(0, 1000)))
self.changed()
c.clipPath(p, stroke=0)
d.append(p)
df = df.append(df_try)
self.header = data[0]
cPickle.dump(myBigList, savefile)
print(p.parse_args([]))
c = {x: (A.get(x, 0) + B.get(x, 0)) for x in set(A).union(B)}
zscore = lambda x: (x - x.mean()) / x.std()
self.method_called = True
output[day][start.hour] += 1
{B} < ---epsilon - -----{D}
plt.scatter(x, y, c=label_dict.get(label), label=legend_dict.get(label))
y.append(pt[1])
my_func = my_decorator(old_my_func)
N = 10
a()
assert F() < fractions.Fraction(0, 1) < G()
qty * unit_price
f.truncate(size)
client.sendInitPresence()
values.get(value, value)
file_on_disk.seek(0)
desired_output[idx_func] = func(abcissa_array[idx_func])
pool.close()
python - V
bytesize = serial.EIGHTBITS,
r = a - b * q
B = np.zeros(A.shape, dtype=np.float)
print(self)
images.append((line,))
_ranks = []
db = dict(zip(listbnum, listb))
a.swapcase()
win = Gtk.Window()
self.stdout = stdout
fly.rect.y += fly.hspeed
l = []
result = self.__eq__(other)
R = np.arange(-K, K + 1)
objs = list(bucket.objects.filter(Prefix=key))
tid = tender_data.values[:, (0)]
Queue._init(self, maxsize)
result[k] = i - rank_a.get(k)
draw()
type(X), type(Y), type(Z)
2
buffer = s.recv(4096)
p.map(copier, file_list)
lastnode = nextnode
retval
dbservers_get_facts = runner.run()
print(count.most_common(10))
print(filename)
os.makedirs(attdir)
x = np.linspace(0.0, N * T, N)
m.sin(x / 2.0) + m.sin(x * m.pi)
items.append(item)
dimmDates = sorted([(date, idx) for idx, date in enumerate(dimmDates)])
index = random.randrange(len(MY_LIST))
[min(x for x in a if x >= best[1]) for a in aa]
signal = wav_to_floats(sys.argv[1])
resultString.strip()
d[name] = max(d.get(name, 0), score)
runstart = 0
runend = 0
plt.hist(sample)
2 / w * pdf(t) * cdf(a * t)
add_miniconda_to_path
zipped = zip(x, y)
logger = logging.getLogger()
start = time.time()
int(__builtin__.round(number))
df_num = df.select_dtypes(include=[np.float])
sampwidth = input_wave_files[0].getsampwidth()
im = max0 * np.random.random((10, 10))
dtype = tid.dtype
index1 = randrange(0, len(a_list) - 1)
ax = cf.add_axes((0, 0, 1, 1))
script_path = os.path.dirname(__file__)
a = Foo(a=1, b=2)
map_nested_dicts_modify(v, func)
print(d)
1
aResponse.addCookie(cookie)
print(m)
sheets = map(str, list(range(1, 6)))
root = {}
arr[:] = np.random.uniform(size=N)
rrset = response.answer[0]
width, height = bbox.width * fig.dpi, bbox.height * fig.dpi
A_new = x_new.reshape(A.shape)
print(A, B, X - (A + B))
_success = True
app = wx.PySimpleApp()
d[cust].append(cust + sub[0])
outer_sum = 0
self._decoratee.f1()
bins = numpy.diff(indices, axis=axis)
self.rank == other.rank and self.suit == other.suit
myfoo = foo()
main()
ch2 = stackless.channel()
df.assign(g=df.ID.ne(df.ID.shift()).cumsum()).pivot_table(*args)
plot(ffty)
ydata = line.get_ydata()
sock.close()
fig, ax = plt.subplots()
self.document().contentsChanged.connect(self.sizeChange)
re.sub(pattern, replacer, text)
x[idx] = np.unravel_index(full.argmax(), full.shape)[0]
x = np.linspace(-2, 2, 6)
tuple([(x + y) for x, y in zip(self, other)])
file = open(location, mode)
search_sequence = [1, 2]
foo = bar
a, b = json.loads(a), json.loads(b)
logger.exception(err)
movie_dict[movie].append(actor)
c.this_method_must_be_overridden()
potentials = graph[woman]
self._i
all_deps.add(dependance)
s.connect((HOST, PORT))
coeff = Stream([1, -1, 1, -1, 1, -1, 1, -1, 1, -1])
[1, 10, 1],
sourceSession.commit()
results[key] = item
offset = time.timezone if time.localtime().tm_isdst == 0 else time.altzone
p.join()
doc.addPageTemplates([])
1 < x < 5
bufsize = fin.tell()
result = []
defn = c.get_definition()
event.append(line)
name = models.CharField(max_length=80)
df_points = gpd.GeoDataFrame(np.array([points, np.random.randn(n)]).T)
f.read(8)
print([x.captures(2) for x in rx.finditer(s)])
self.popMenu.exec_(self.button.mapToGlobal(point))
factor = float(dt_delta) / float(ts_delta)
result[old_arena] += int(timestamp) - old_timestamp
kw.update(kparms)
print(x)
rollBy(d.ToRoll, d.RollBasis, 5, sum)
self.server = Flask(__name__)
inputStream.reset()
cv.SetImageROI(imag, rect)
TestApp / testapp / __init__.py
file.close()
locations = Location.objects.filter(locations_bewertung__in=ratings)
f1 = sigma * (y - x)
root = lxml.html.fromstring(ud.unicode_markup)
r = 1.0 / (i % 2)
float(sx)
arr[:] = alist
print(l)
A = A.tocsc()
data = np.random.normal(size=10000)
Case(When(created__month=1, then=1), output_field=IntegerField())
dist = lognorm([stddev], loc=mean)
l1.append(i)
print(arduino.readline())
x_norm = x - x_mean
tornado.web.Application.__init__(self, handlers, **settings)
b.remove(b[0])
step_2 = 2 * np.arctan2(np.sqrt(step_1), np.sqrt(1 - step_1))
deletenumpy_surface
a = c
ans = []
mpt
print(x[0].a)
NULL
answer.append(sub_answer)
self._append_to_buf(contents)
ss = Sth()
atexit.register(save_history)
greyscale_map = list(im.getdata())
next = l[i + 1]
listToFill = list(range(1, n + 1))
True
print((sign, count))
f(*args, **kwargs)
wrapping
magic_index = [np.arange(i) for i in indices.shape]
add_to_observation_log(lines)
x = np.where(col)[0]
(11, [11]),
cur = col.find()
print(df)
array([4.0, 6.0])
text = indexes.CharField(document=True, use_template=True)
1, 2, 4, 5
df
_clients[name] = Client(url_for_name)
m.squeeze()
draw = ImageDraw.Draw(foreground)
Hello.show()
res = transform(doc)
putch(c)
dic[slast[-1]] = x
print(self.a)
main()
G = nx.Graph()
b = [6, 1, 0]
data = []
shifted_words = [words[-1]] + words[:-1]
fout.writelines(set(fin))
print(factorizations)
app = MyApp(0)
a = A(**params)
form = MyForm(request.form, obj=my_obj)
os.path.normpath(home_dir)
x = float(str(w)[:-1])
print(j)
torfile.set_hash(i, hash)
str(sys.exc_info()[2].tb_frame.f_back.f_lineno)
text
c = Counter(hello)
L1_sums = np.zeros(len(L1[0]))
y = np.sin(x)
mock_save.assert_called_once_with(side_fx.self, data)
pairs = {}
dr = webdriver.Firefox()
copy[alert_status].loc[alert_read_criteria] = 1
lst = list(itertools.chain(*tp))
cur_set = []
a += [1]
pylab.plot(freq, numpy.angle(Y))
tuple(ans)
Pyro / ext / daemonizer.py
session = self.sessionmaker()
answer[L[0][0]] = L[0][1]
qs = self.get_searched_queryset(qs)
init_new_vars_op = tf.initialize_variables([v_6, v_7, v_8])
data = OrderedDict()
print(list(hack(source)))
N = A.shape[1] / 2
palette = np.array(palette, np.uint8)
False
net.ipv4.conf.default.rp_filter = 0
dependants
dist = sum([abs(x) for x in hist_sel - hist])
fig = plt.figure()
num = num[::-1]
a[mask]
i()()()()
os.utime(fname, times)
plt.imshow(jpeg_image)
c = C()
numpy.diff(mat_row.indptr)
page.append(item)
root = logging.getLogger()
print(student.user.username)
do_whatever_with(x)
print(y_interp(5.0))
self.data
dx = dxs.mean()
d1 + relativedelta(months=1)
path = os.getcwd()
print(cls)
self.vmin = im.min()
x - math.floor(x)
out = [(pop * [allele]) for pop, allele in zip(pops, alleles)]
{0, 2, 6, 7}
print(affprop.labels_)
application = Flask(__name__)
x_ticks = ax.get_xticks()
fpOutput[indexI, indexJ + 1] = True
list(evens)
print(dictOfStuff[x])
Nprime = np.transpose(N[:, :9])
first_list = [1, 2, 2, 5]
t.set_y(y)
self._data[self._keys[key]] = val
db = conn.test
set(result)
print(row)
p.wait()
file_path = File.join(file_dir, file_name)
aifc
chi2 = np.sum(w * (y - (a + b * x)) ** 2)
input_cell = input_ws.cell(rindex, cindex)
node_value = dumper.represent_data(item_value)
author = ModelMultipleChoiceField(queryset=Author.objects.all())
fig.canvas.print_pdf(io.BytesIO())
i += 1
gateway = JavaGateway()
res.append(s.capitalize())
pred_T = (y[1] - y[0]) / (t[1] - t[0])
app = QApplication(sys.argv)
lsb_release - a
self.nodes.append(n.exc)
val[0] += 1
self.evt.set()
thread = threading.Thread(target=current_post.post)
labels_img = labels.reshape(data.shape)
stderr_thread.daemon = True
True
suggested
baz()
print(name)
labels = [item.get_text() for item in ax2.get_yticklabels()]
x[i:len(x) - i] = x[i:len(x) - i][::-1]
count = 1
self._stop = True
all_points[:, (0)] *= 0.5
grokster = d.groan()
index = index + 1
q = np.column_stack((x_up, y_up))
accumulated[length] = total
j == len(a2)
firstLine = readFile.readline()
autostart = true
autorestart = true
y = np.sin(x)
cf = csv.reader(f)
result[key] = val
p = figure(plot_width=400, plot_height=400)
temp.remove(v)
self.stdout = stdout
B = (np.random.random_sample(10000.0) + 10) * 20
selections = listbox.curselection()
i += 1
f = lambda x: lambda y: x
my_array[x + y * m] = c
d = {}
ret = subprocess.call(command)
mythread.daemon = True
lock = Lock()
reshaped = reshaped.reshape(-1, 2)
cat > tmpf.py
i += 1
lines = buf.split(delimiter)
raise self.retry()
page = paginator.page(page_number)
file_extension
pts = []
z_norm = norm(diff.ravel(), 0)
stringArr = models.TextField()
print(i, j, k)
b = B()
plot(times, sin(2 * pi * freq * times + phase_correction))
int[index[2, overlaps]]
rslt.set_index(pd.Index(n), inplace=True)
area_of_triangle(triangle) + area_of_polygon(polygon)
a = OuterTest()
hash1 = hash1.hexdigest()
W = sparse.spdiags(w, 0, L, L)
model.add(Dense(nNeurons))
foo = Foo()
instance = instances[0]
y_test = Y[test_indices]
temp = [sort_tuple(tuple) for tuple in items]
combs = []
print(a)
indices = [2, 4, 0]
cj = cookielib.CookieJar()
m = (y2 - y1) / (x2 - x1)
app = QtGui.QApplication(sys.argv)
request = Request(url, urlencode(post_fields).encode())
root = etree.fromstring(CONTENT)
main()
mat_lil = mat_csr.tolil()
time1 = datetime.datetime.now()
output, errors = p.communicate()
qnetworkcookie_list.append(tmp_cookiejar)
flatten(_getPermutations(string))
dict = to_dict_dropna(data)
lines = img.findLines(threshold=25, minlinelength=20, maxlinegap=20)
ranges = np.empty(counts.sum(), dtype=int)
digest.update(s)
n = a.strides[0]
img_temp.flush()
a[v] = k
line
title = soup.title
pill2kill = threading.Event()
print(item)
treeview.set_model(listStore)
res = acalc(10)
email_message = email.message_from_bytes(data[0][1])
nesting = 0
x = linspace(0, 10 * pi, 1000)
img = Image.frombytes(mode, size, data)
pprint.pprint(distance)
im = im.copy()
raise StopIteration
self.i = i
_f_array[(a), :]
self.cursor.find(data.key)
pylab.figure()
vmidi_out.send_message([176, 7, 100])
n * fact(n - 1)
encoded_data = json.dumps(not_encoded)
assert stdout.read()
c = dict(c)
x = itertools.islice(list(d.items()), 0, 4)
i = randint(0, 15)
a = list(range(10))
j & 1
currcount = 0
task = asyncio.Task(periodic())
a = sqrt(a ** 2 + arr[i] ** 2)
display.stop()
V = np.sin(Y)
self + 1
v1 = forloop()
uid = pw.pw_uid
X = np.array([[-1.0], [1.0]])
LPTSTR = LPWSTR
a = np.array([list(range(1000)), list(range(1000)), list(range(1000))])
your_subprocess
func_count = 0
getcontext().prec = 28
[4, 5, 6],
R = float(np.sum(r)) / ttl
fclose(f)
handler = urllib.request.HTTPBasicAuthHandler(password_mgr)
f = np.median(np.diff(aapl.index.values))
all_subclasses.append(subclass)
m = re.match(alternates, tc)
array.flat[step:-step:step]
plt.minorticks_on()
df
d[4] += 1
main()
System.out.println(Math.toDegrees(Math.atan2(-1, -1)))
b = [(ctr[frozenset(x)] == 1) for x in a]
print(excel.Cells(1, 1).Value)
print(s)
print(k)
print(result.screen_name)
df = df.loc[:, (df.apply(pd.Series.nunique) != 1)]
x_curve = np.linspace(1, 5, 100)
root_logger = logging.getLogger()
sparse[(indices), :]
YY += y
average = sum(max_ratios.values()) / float(len(max_ratios))
id(self)
isinteger(1.0)
r = requests.get(hist_url)
drec = dict()
result = defaultdict(list)
col_names = list(df)
test = test - 1
fig = event.canvas.figure
code = _mangle_template.format(cls=source.__name__, attr=attr)
np.eye(n_values)[values]
circle(radius)
sns.despine(left=True)
results.reverse()
b_vals = data[:, (1)]
c_type = part.get_content_type()
_dec
print(len(xdata), len(ydata))
mainThreadState = PyEval_SaveThread()
funcs = [lambda x: x ** 2, lambda y: y * 2, lambda z: z.upper()]
count
do_loop_body(i)
flat = tf.reshape(output, [-1, num_neurons])
width, height = bitmap.GetSize()
y = np.sin(x)
df
self.name = name
0
lines = set()
f
A4D = A.reshape(-1, 2, N, 2).swapaxes(1, 2)
value, False
deleteancestor.getparent()[0]
get_single_item_data(item_url)
[nosetests]
self._val = 0
labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))
cursor = mydb.cursor()
loads(response)
map(next, iters)
listunique = [unique_element(i, elements.count(i)) for i in eset]
-cmp(self.score, other.score)
c.insert(c.end(), b.begin(), b.end())
val += int(item)
value.filter(distance__lte=meters).count()
self.simulThread = QThread()
original = sys.argv[1]
posy = np.digitize(ydat, locy)
IOLoop.instance().start()
file_stat = os.stat(path)
wsgi_handler = MyWSGIHandler(req)
self.a = a
decorator
all(x == s[0] for x in s)
print(data)
f1.close()
self.parser.mode.handle_word(word[1:])
Observer.__init__(self)
np.isnan(data)[np.isnan(data) == False].size
term_appearance = Counter()
sys.stdout = self
obj = TestClass(*args, **kwargs)
np.random.seed(1)
abstract = True
d = []
configure_logging()
idx = np.r_[0, idx]
Session_2 = sessionmaker(bind=some_engine_2)
A[mask] = np.nan
axis1 = fig.add_subplot(211)
tag.string = comment.strip()
print(len(hashes))
done = True
itertools.chain(iterable, raising_iter(i))
n = len(points)
found.symmetric_difference(expected)
out.write(line)
module_loader
out_list = []
win.getMouse()
pass_to_other_process(RecordData(record))
plot(wrong_order)
current_path = os.getcwd()
aab
aac
aba
abb
aca
acb
baa
bab
bac
bba
bbc
bca
bcb
caa
print(name)
pdsDF = sparkDF.toPandas
np.sum((x - y) ** 2)
test_case.assertAlmostEqual(expected, actual, *args, **kwargs)
document = etree.fromstring(xmlcontent)
format_to_year_to_value_dict = {}
num1 = int(argv[1])
next(self.gen)
dirname = os.path.basename(dirname)
stream.attach(screen)
[R, G, B]
y + 5 * self.foo(x)
response = requests.get(url, auth=(user, password))
exit(parser.print_usage())
result += new[i + 1:].lower()
indent = match.group(1)
result = f(*args, **kwds)
print(sess.run(y_))
distup = zip(dists, Ytrainvec)
webbrowser.open_new(self.url_to_load)
value = self._base_dict[key]
fig, ax = plt.subplots(1, 1, figsize=(6, 6))
anagrams[frozenset(list(Counter(s).items()))].append(s)
n.pool2 = L.Pooling(n.conv2, kernel_size=2, stride=2, pool=P.Pooling.MAX)
n.pool4 = L.Pooling(n.conv4, kernel_size=2, stride=2, pool=P.Pooling.MAX)
shutil.rmtree(DOC_DIR)
self.wordList = []
htmlparser.feed(xml)
wrapped_field = Column(CastToFloatType, nullable=True)
self.b_isset = 1
end = int(args[0])
[letter for freq, letter in frequency_list]
N = 100
lly = np.flipud(lly)
ax = fig.add_subplot(2, 1, 1)
wrapper
repeat_count = [b[i] for i in stream_index]
s = response.read(content_length - len(data))
lenr = a.shape[0] / r
bc = Counter(b)
a.append(i - 1)
selections = self.view.sel()
deletelst[i]
s.group(0)
res = []
eval(code)
IMember.names()
print(k)
print(n)
print(link)
print(nltk.pos_tag(text))
chan.get_pty()
print(i)
older_books = []
recipe = corneti.recipes.codeintel
url_adapter.match(parsed_url.path, method)
self.on_error = on_error
print(Test.attr2)
key = item[group_by_key]
fig = PLT.gcf()
print(nums)
False
combined
dir, name = os.path.split(path)
l = np.random.random(20000, 20000)
decorator
count += 1
pixels
purge_old_data.py
log_handle.setFormatter(log_format)
a[key] = data_merge(a[key], b[key])
star_count = 1
answer = True
self._getrow(rowidx)[colidx]
0
cur_seq.append(data[-1])
S = np.dot(S, S.T)
expr << ZeroOrMore(pths_or_str | anything)
self.a = 5
series = pd.Series(np.random.normal(0, 100, 1000))
car = OneToOneField(Car)
d = AttrDict()
p_as_list = p_as_list[-1].copy()
PythonEngine.Shutdown()
type(t[1])
f.__code__.co_consts
n_lst = list(str(n))
win_copy_files(files_to_copy, dest_folder)
t.testOnData(verbose=True)
print(i, word)
numerical_bids = [int(bid) for bid in bids]
d.update(frame.f_globals)
val = float(s)
line
hildonize_window = _hildon_hildonize_window
item = eggs, count = 7
print(x_tag[:50])
meta[0]
x = np.linspace(1.0, 10.0, 20)
a.__doc__
self.rwlock.acquire_read()
data = [row for row in reader]
c._params
bincounts.append(0)
endlineno, endcolno = linecol(doc, end)
self = self.replace(key, value)
tree = etree.parse(xmldoc, parser)
seen = set()
w.wcs.crpix = [len(glon) / 2, len(glat) / 2]
locstm = LocatingWrapper(stm)
t = list(s)
[6, 7, 8],
request.py
record.user_id = request.user.id
print(path)
conn = smtplib.SMTP(url, 587)
a = [4, 8, 0, 1, 5]
table[tup] += 1
i = np.concatenate((i, i2))
print(dok[10, 20])
inner()
app.MainLoop()
stem_sets = list(all_stems.values())
data = pd.Series(list(range(1, 9)))
print(list(x))
alist = list(range(2, n))
i = iter(iterable)
normal = np.array(cross([1, 0, a], [0, 1, b]))
self.stackVals.append(dictTuple)
xy = geometric_matrix_multiplication(x, y)
(self.comovingdist(z2) - self.comovingdist(z)) / (1 + z2)
first_index = -1
counter[el] += 1
tck = interpolate.splrep(x, y)
k
str_base(d, base) + digit_to_char(m)
pympler.asizeof.asizeof(n)
s1 = sin(2 * pi * 100 * t)
filter_params = {}
labels = np.random.randint(2, size=10)
d.append((start, length + 1))
b = list(set(a))
result
plt.show()
ax2 = f2.add_axes([0.1, 0.1, 0.8, 0.8])
root = tk.Tk()
context
new_stack = type(self)()
c.sort(kind=kind)
output.append(line)
module = app
c = []
X.foo
self.char_count = tk.Label(self)
columns_data.append((n, el))
c = np.array(c)
a.foo
paths.Add(dir)
pubsub = r.pubsub()
z = np.cos(v)
arr = np.zeros((2,), object)
objects = models.Manager()
timedelta.max
d = a.shape[1]
file_handles = []
8, 8, 8, 1
print(parent_conn.recv())
Bar()
output
books = r.json()
ridx = np.random.random(size=n)
AI1 += 1
entry[1]
wid = termf.winfo_id()
AC_CHECK_HEADER_STDBOOL
Py_DECREF(iterable)
c = np.kron(a, b)
new_path.append(adjacent)
X[idx] = np.maximum(X[idx].A, Y[idx].A)
model = ThirdModel
coords.fk5
self = instance.activity_set.all()[0]
ax = plt.subplot()
self.axes.xy_dataLim.intervaly
print(random_sample_input)
arr
d = str(decimal.Decimal(value) / decimal.Decimal(1000000))
line = []
sigma = np.linspace(0.01, 0.5, n)
self.b_list = []
compare_dict = {}
self.name_list.pop(index)
area2 = 0.5 * np.abs(np.dot(x[1:], y[:-1]) - np.dot(y[1:], x[:-1]))
decorator
t = np.arange(0.0, 40, dt) + i * dt
QtCore.QCoreApplication.postEvent(self, mouseReleaseEvent)
content = driver.page_source
a_out[:] = 100
g.user = user
a.ndim
self.regex = self.text[1:]
xy = resize(arange(10), (2, 10)).T
print(i)
settings.CONFIG
filepath = os.path.join(DATA_DIR, file)
self.model
imp.acquire_lock()
x = np.ones((25, 25, 25, 25))
g = (df.url != df.url.shift()).cumsum()
headline = article.headline_set.all()[0].headline
y[b]
print(q.introduce_self())
OPTIMIZE_OUTPUT_JAVA = YES
grid = gridspec.GridSpec(1, 1)
list.append(i[2])
z = zipfile.ZipFile(fname)
start = len(word) - 1 if step < 0 else 0
self.b
lines = file(config_path).readlines()
c.StoreMagic.autorestore = True
t0 = time.time()
view_traceback()
run_simulation(0.06, 0.2, 250, 10)
a = sys._getframe(1)
t = extend(t)
FILE = theFile.readlines()
print(m.groups())
my_item = item
f = np.random.rand(m)
cls.__instance__
print(string.Template(my_path).substitute(os.environ))
ref_keys = [prop.get_value_for_datastore(x) for x, prop in fields]
n = old_dict.copy()
points += [new_point]
y = np.vstack([x[0::5], x[1::5]]).T.ravel()
im = np.arange(81).reshape(9, 9)
empty_method_field = serializers.SerializerMethodField()
img = mgimg.imread(fname)[-1::-1]
a = np.arange(1, 26)
a = max([n for n in list2 if n < i])
shared_dict = {}
r.append(i)
int(string, 16)
self.name = name
b = sparse.csr_matrix(a)
False
bar.delay = foo.delay
self.defaultorder() < other.defaultorder()
a = numpy.arange(24).reshape(6, 4)
parent_mock._kids[0][2] is child_mock1
L
EXC_IF_CURS_CLOSED(self)
qresult = numpy.array(qresult)
notifier.stop()
print(b.build_lib)
self.b_set.remove(b)
x1 = np.interp(width_S, S_values_2[:idx + 1], F_values_2[:idx + 1])
uniques = np.unique(arr)
dtypedict.update({i: sqlalchemy.types.INT()})
do_something(value)
output.sort()
opener = urllib.request.build_opener(hh, hsh)
Brewfile
print(link)
rnd_str = f.read(4)
UserModel.objects.get(pk=username)
data = np.random.choice(np.random.random(K), N, replace=True)
hex(self)
deletemodule
i += 1
x is y
new_list = [round(x) for x in list_num]
ts1 = [0, 1, np.nan, np.nan, np.nan, np.nan]
u[j] += 1
server.start()
cls
classifier = pickle.load(f)
clust = pc.kcluster(darray, 2)
kls
a.insert(0, img)
seq = (x for x in range(10))
pattern = re.compile(regexp)
----views.py
plt.plot(W, f_signal)
action_form = XForm
print(msg)
outputqueue = Queue.Queue(50)
session = requests.Session()
y(aVariable, bVariable)
lst, type(lst)
x_1 = odeint(sis, [0, 0], t, args=(acel,))
test_corrcoef()
printItems(list)
[0, 1][False]
print(frequency_list)
Qt / QtCore / __init__.py
print(tag.getTitle())
matches = []
self._mark_failed(str(e))
res[i] = zip(list(x), list(y))
nexts = cycle(iter(it).__next__ for it in iterables)
app.Quit()
df2 = DataFrame(data=np.random.randn(10, 10), index=arange(10))
self.index = 0
age = Column(Integer, nullable=True)
set1 = [np.array([1, 0, 0]), np.array([-1, 0, 0]), np.array([0, 1, 0])]
obj = next(li)
xx, yy = np.meshgrid([-5, 10], [-5, 10])
date_uploaded = db.DateTimeProperty(auto_now_add=True)
Xf[0]
Xi[0]
subparsers = parser.add_subparsers()
module = imp.load_module(custom_name, f, pathname, desc)
L1.__init__(self)
print(e)
a = k()
out[A01[:, (0)] - 1, A01[:, (1)] - 1] = A[:, (2)]
i if i == f else f
y = (x + numpy.pi / 2) % numpy.pi - numpy.pi / 2
phi = np.linspace(0, 7.0 * pi, 2000)
b = Bar()
m = int(len(x) / 2)
test
result[real_name][false_name].append(location)
l = lambda : defaultdict(l)
yaxis = plt.gca().yaxis
a = MyClass.__new__(MyClass)
Z = normX * traceTA * np.dot(Y0, T) + muX
print(index_li)
d = defaultdict(data_structure)
print({el: (0) for el in list(range(10))})
logger = logging.getLogger(__name__)
B2[:, :, (r), (c)] = B2[:, :, (r), (r - c)]
server, client_addr = listener.accept()
gmpy.is_square(x ** 7)
False
Xtrain = vect.fit_transform(documents)
data
x, square(x)
ids = [0, 0, 1, 2, 2, 1]
print(i)
out = strings[bool_arr.astype(int)]
ax.draw_artist(im)
B = np.sum(num / den, 1)
now = datetime.now(get_localzone())
big_array[chosen_slice]
default = dns.resolver.get_default_resolver()
bin_assignments = NP.argmin(dist_matrix, axis=0)
reader.fieldnames = [name.lower() for name in reader.fieldnames]
PyList_Check(op)
end = self.startDateTime + timedelta(minutes=24 * 60)
list = [0]
skew(x, l[0], l[1], l[2]) - fzz
env.from_string(template_string, template_class=cls)
str(self.events)
T
exec(s)
authentication = CustomApiKeyAuthentication()
l.extend([i] * i)
a = numpy.array([x[1] for x in results])
x = numpy.arange(0, xstop, step).astype(int)
U = SVD.fit_transform(X)
right.put(elt)
False
traverse(t)
e2 = Entry(root)
label.winfo_exists()
element_text = element.text
image = np.asarray(image[:, :])
f_ = dill.loads(_f)
print(k)
d = datetime(year, month, day, hour, minute, second, microsecond)
sio.close()
tokens = iter(s)
print(datetime.datetime.utcfromtimestamp(ts - num_secs + 1))
print(xml)
s = s.lower()
False
wrapped_user()
func(elem, *args, **kwargs)
dx, dy = lrx - ulx, uly - lry
new_list
aList = [Entry(headline=val) for val in values]
rho = df.corr()
a = np.frombuffer(a, dtype=np.dtype(type_sig))
f.close()
s = inspect.stack()
self.func = func
module_filetype in EXTENSION_SUFFIXES
lastKnownSizeOfFile += amountToRead
numpairs
0.816
yd = np.diff(y)
x = x.rename_axis(lambda x: calendar.day_abbr[x].capitalize())
groups = [list(it) for k, it in groupby(sorted(L))]
w, v = self._val[0], self._val[1:]
thumbnail_buf_string = StringIO.StringIO()
arr = np.chararray((seqlen,), buffer=seq)
[4, 5, 6, 7],
stored_hash = something_that_gets_this_from_the_db()
print(row.name, i)
sys.stdout = self.stdout
kern_nx, kern_ny = np.round(scotts_factor * 2 * np.pi * std_devs)
names, passw = zip(*cursor.fetchall())
print(upload.filename)
grouper[(indexer < 20) & (indexer.cumsum() > 50)] = 2
thread.join()
a = Test(1, z=2)
y = block_list.pop(x)
norm = 1.0 / sum
eq1 = c * b * a + b * a + a + c * d
[FreeTDS]
i += 1
fig = pl.figure()
GST_PLUGIN_PATH
element.text = text
random.seed = myseed
d[key] = {}
query_stat = str(session.query(User))
w = ward_tree(X)
MON, TUE, WED, THU, FRI, SAT, SUN = list(range(7))
e.insert(0, text)
axes.set_xticks(list(range(10)))
data_to_write = data[:]
right_min + (value - left_min) * scaleFactor
u.append(u_end)
x = {row.SITE_NAME: row.LOOKUP_TABLE for row in cursor}
assert len(c) == 0
df
self.id = id
print(d)
zip(*([it] * size))
ws = wb.create_sheet()
print(results)
m.start_of_track()
exeName, stdout = subprocess.PIPE, stderr = subprocess.PIPE,
words = []
x[4]
self.location = location
L.append(str(s))
[tox]
field.validate(form, extra_validators=self.extra_validators)
values = numpy.array(values)
dataPoints = np.random.random((5000, 256 * 256)).astype(T.config.floatX)
dist_min = numpy.inf
transport = proxy_client.get_transport()
sys.stdout = fileconcord
m = getattr(a, methodname)
0.229
self.a = a
t = MyClass(a=1, b=2)
action1.long_press(x=xx, y=yy).move_to(x=0, y=50).wait(500).release()
weights
0
BOOST_PYTHON_MODULE(mymodule)
i += 1
some_criterium = do_something(line)
pool.close()
raise self.failureException(msg)
x = obj[keyX]
{input_column: tf.reshape(predictions[-10:], [1, 10])}, {}
ax.add_table(tb)
normed = (dist ** 2).sum(axis=2) ** 0.5
print(df)
-jdcal == 1.0
assoc.save()
[-1, 0, 1, 0, -1],
grid = pad_to_square(grid[:, (~np.all(g, axis=0))][~np.all(g, axis=1)])
[2, 6, 10],
data
main()
zip.write(the_file)
new_dim = np.prod(A.shape[2:])
repr(d)
imagedata.image = blob_info.key()
self.neurons = [Neuron(n_inputs) for _ in range(0, self.n_neurons)]
mode = lambda ts: ts.value_counts(sort=True).index[0]
i = 0
ip = socket.gethostbyname(socket.gethostname())
print(li)
s = h.status()
queryset
main()
min_ = ranges[0][0]
np.floor([5.99999999, 6.0])
instance
os.mkdir(newpath)
maxima[diff == 0] = 0
self.connected = False
self.instances.append(weakref.ref(self, self._cleanup_ref))
prof.dump_stats(datafn)
newFile = csv.writer(fileobj)
args = s.split()
combinations = (dict(zip(kwargs, vs)) for vs in product(*list(kwargs.values())))
COOKIES_DEBUG = True
gmpy2.isqrt((10 ** 100 + 1) ** 2)
last = line[0]
list(filter(str.isalpha, strs))
patcher.is_local = True
count
mask = np.all(np.isnan(arr), axis=1) | np.all(arr == 0, axis=1)
myapp.foo.doSomething()
ax2 = plt.subplot(gs[(1), :-1])
p(convert(ambiguous_dt, east_tz, pytz.utc, is_dst=False))
intvals[bisect.bisect(intvals, 8000)]
unpack.append(item)
print(c)
lst = [partial(f, z=i) for i in range(5)]
self._inner = list(it)
data = np.random.randn(20, 40)
data = urlopen(url).read()
False
df_swap.columns = df_swap.columns.get_level_values(1)
a = arange(0, 1024)
f = urllib.request.urlopen(url)
root = e.getroot()
numpy.searchsorted(a, v, side=SIDE.RIGHT)
xml.normalize()
c = [1, 7, 2, 4, 1, 9, 9, 2] * 1000000
lookup[item.parent].children.append(item)
task_2 = another_long_process.delay(x, y)
avgs = []
ar.fromfile(fp, sz)
i = np.arange(1, len(m) + 1)
funcs = []
print(f)
ax.view_init(elev=10.0, azim=i)
frac_part = abs(x) - int_part
cv2.ellipse(image, center, axes, angle, startAngle, endAngle, WHITE, thickness)
self.z = z
hash(test(10)) == hash(test(20))
it = iter(a)
models.base.ModelBase.__new__(cls, name, bases, attrs)
result = []
hue = hue_from_rgb(r, g, b)
book = pyExcelerator.parse_xls(filename)
cookiejar = cookielib.LWPCookieJar()
files = os.listdir(working_folder)
infile = StringIO.StringIO(corpus)
len(char_string) - char_string[::-1].index(char) - 1
basket.update(basket_two)
sys.meta_path.append(self.collector)
sortBy(part, keyChain[1:])
k.press_key(k.alt_key)
p.feed(page)
sliceable[cut]
but.pack()
1, 1, 5, 5
magic_index = np.ogrid[tuple(slice(i) for i in indices.shape)]
p1 = Player.objects.get(id=1)
C[z, B[z, y, x], x] = A[z, y, x]
a, b = tee(seq)
r, c = np.tril_indices_from(B)
s = df.stack()
root.mainloop()
try_match
a = np.random.normal(0.0, 0.5, size=(5000, 10)) ** 2
json.dump(self.memo, f)
processed_rows = zip(*processed_columns)
text = db.TextProperty()
a[:] += da
digs = string.digits + string.letters
timeout_start = time.time()
c[2]
index1, index2 = np.ix_(index, index)
self.name = name
app.listen(9000)
result.stop()
output[item] = {next_word: 1}
t = linspace(-4, 40, 1000)
x = tab.scan()
self.bigdict = build_big_dict()
seen.add(x)
out[i] = out[i] + f[j] * cexp(-1j * x[j] * y[i])
main()
0
print(link)
copy_reg.pickle(type(sys), savemodule)
something_else = False
a_s = np.random.uniform(0, 1, size=100)
exec_locals.update(frame.f_locals)
{{page}}
i += 1
kpca = PCA().fit_transform(X)
session.close()
cj = cookielib.CookieJar()
aws_access_key_id = AxxxA
Draw(particles1, circles1)
frontier = []
is_active = models.BooleanField()
print(df.shape)
yPoints = np.arange(0, ylen + 1, 1)
offset_x = lambda xy: (xy[0] + 0.1, xy[1])
plt.show()
Handle = OpenProcess(PROCESS_ALL_ACCESS, False, TaskID)
print(np.multiply(r, b.T))
ax = plt.subplot(111)
a.fromstring(binary_string)
a[1] = 42
words.sort(key=len, reverse=True)
canvas.print_png(png_output)
s1, s2 = set(source_list), set(diff_list)
rows, cols = np.nonzero(idx)
result[0] = next_third_friday(result[0])
json_util.dumps(objects._collection_obj.find(objects._query))
df
sparseness
_post_import_hooks = collections.defaultdict(list)
hdlr.setFormatter(formatter)
do_huge_computation()
10
A_upper_triangular = tf.boolean_mask(A, mask)
process.extractOne(row, data, score_cutoff=60)
query.with_cursor(start_cursor)
outer()
np.bincount(a.flat, weights=b.flat)
p.map_async(test, evaluations)
Y = X + np.random.rand(100) * 0.1
Pdb
v1 = [2, 5]
p, code = raw_compile(r, re.DOTALL)
d = {}
countdown(n - 1)
outer[pos:pos] = inner
result.append((entry, data.count(entry)))
openHeap.append((0, current))
plt.subplot(2, 1, 1)
duplicate_columns = unique_columns[:, (column_count > 1)]
a
op.basename(urlparse.urlsplit(url).path)
md5sum
average(arr, -1)
company = models.ForeignKey(Company, on_delete=models.CASCADE, null=True)
print(df.head())
x = numpy.arange(2 * 4).reshape(2, 4)
result = [parts[0]] + b
seconds = (dt - dt.min).seconds
list
training_images = images[mask]
queryset = queryset.order_by(Lower(ordering))
root = self.root = tkinter.Tk()
result.append(type(item))
sys.stderr = codeErr
type(o) == type
a2 = np.empty(m.shape[1:], dtype=object)
st.st_size
bpy.utils.register_class(HelloWorldPanel)
True
url
print(n)
x = rand(10)
type(X)
json.load(*args, **kwargs)
valuesProcessed = pool.map(someFunction, valuesToProcess)
include_files.append((os.path.join(include_dll_path, dll), dll))
B[n] = np.random.randn(N)
d = decimal.Decimal(number)
Bar(self, key)
dict.__init__(self, *p_arg, **n_arg)
result.add(rot)
d1 = datetime.strptime(from_date, fmt)
lis[1]()
str()
rpipe, wpipe = os.pipe()
Country = warlock.model_factory(schema)
globalValue += 1
idx = numpy.array([2, 1, 0])
assert timestamp.hour == 0
True == 1
dset_X.append(X_chunk)
X, Y, Z = np.meshgrid(xv, yv, zv)
history = model.fit(X, y, nb_epoch=10000, batch_size=4, show_accuracy=True)
doc = func.__doc__
num_samples = 1000
index = numpy.index_exp[:] * increase_axis
assignments = list()
BEGIN
cookie.load(cookie_string)
df = pd.read_csv(io.BytesIO(data), delim_whitespace=True)
cnxn = pyodbc.connect(connection_info)
out = [[next(it)]]
l = [0, 1, 1, 2, 2]
a.strides
x = c0.dot(c1 * L) / (np.linalg.norm(c0) * np.linalg.norm(c1))
__builtin__.object = newobject
sys.getsizeof(d)
timer(stateDSM, 100)
df
img = cv2.cvtColor(cv2.imread(sys.argv[1]), cv2.COLOR_BGR2GRAY)
password_mgr = urllib.request.HTTPPasswordMgrWithDefaultRealm()
number = 0
loop = asyncio.get_event_loop()
math.atan(slope)
print(result)
overlaps = numpy.where(c == max_peak)
primelist.append(p)
db.echo = False
ix = np.unravel_index(ix, ax.shape)
byte = ord(byte)
j = len(a) - 1
remote.chmod(stat.S_IRWXU | stats.S_IRGRP | stats.S_IXGRP | stats.IROTH)
lst
logger = logging.getLogger()
p = np.poly1d(coeffs)
data = sorted(data)
FP = confusion_mat[:, (i)].sum() - TP
test_orig(port=int(sys.argv[1]) if len(sys.argv) > 1 else 8000, *args)
req = requests.get(url_csv)
b = np.random.random(a.size)
re.escape(motif)
arr[1, 7, 2]
rowsums = sum(A[I] for I in np.tril_indices(n, -1))
t_squared = r ** 2 * (df / ((1.0 - r) * (1.0 + r)))
frames
child_end += width + 1
bmax = numpy.max(databack[:, :, (2)])
thread.start_new(extract_bigrams2, (cpnt, cpnt + iterator + 1, a))
rs = [grequests.get(url) for url in urls]
l = set()
line = line.strip().split()
y.myAttr
rows = re.findall(rowfinder, html)
a - b
frontier.append(i)
event.ignore()
obj = pickle.load(sys.stdin)
tmp = lambda x: sin(x) + cos(x)
print(sorted(subs(s, vowels)))
main()
label.pack()
xc = (numpy.roll(sig1, shift) * sig2).sum()
mech.select_form(nr=0)
self.myList[key]
print(row)
data
costheta = random(-1, 1)
False
X = scipy.randn(100, 2)
pprint_off()
MyRelatedModel.objects.none()
l = [1, 2, True, False]
self.webview.setWebViewClient(wvc)
logger.debug(e)
x, y = map(lons, lats)
im_data[:] = data
SparkContext.stop(sc)
files = glob.glob(path)
print(cruncher.hexdigest())
D = defaultdict(dict)
df
editor.setBackSpaceUnIndents(True)
list(testgen(2))
__metaclass__ = type
780758
ret
value = parser.parse_expression()
possibleFactors = list(range(1, int(numpy.floor(numpy.sqrt(numToFactor))) + 1))
curpiece.shift(-1, 0)
model2 = models.ForeignKey(Model2)
print(bar.foo)
group_max = dict()
o = urllib.request.build_opener(h)
[[e for e in all_eq_elms(lst, elm)] for elm in set(lst)]
B = np.random.randn(N, M)
order = np.lexsort(a.T)
md5 = hashlib.md5()
new_stepListB.append(pathList[n][1])
query = Members.objects.all().query
m = imp.load_source(modname, fname)
chain.from_iterable(map(get_inner_lists, xs))
min_window = normed.mean(axis=1).argmin()
text = f.read()
a1 = np.tile(a, (7, 1))
seen = set()
gist = models.CharField(max_length=50)
is_company_admin = models.BooleanField(default=False, null=False)
label = ttk.Label(frames[treatment[1] - 1], text=treatment[0])
alllinks = page.findAll(tag, href=True)
inds[-2]
L = list(s)
B = ind[A[ind] == value]
self.canvas = FigureCanvas(self, wx.ID_ANY, self.figure)
new
cos = np.cos(angles)
line7
f.toggle(random.randint(0, 4))
xp = np.packbits(x)
print(eat(list))
slc[axis] = slice(start, end)
thing2 = thing.get()
format = workbook.add_format()
INSERT_INTO_HOMEFEED_BATCH = 10000
dol = collections.defaultdict(list)
plt.xlim(-2, 2)
fastload_fifo.write(line)
LU
0.0099989
connection.close()
foo = FooObject(**foo_data)
type(root.sides[1])
decimal.Decimal((sign, digits + (0,) * exponent, 0))
a.parse_args()
X = np.linspace(0, 10, 100)
t = np.linspace(-2, 2, 100)
self.servers[server].get_message(name, message)
ind[ind < 0] = -1
u, v, w = gradients.T
i, j
True
s = numpy.isnan(a)
consume(iterator, 4)
params.update({})
rate = lambda T: 200 * exp(-T) if T > 200 else 400 * exp(-T)
txt = f.read()
out = np.where(left_idx != right_idx)[0]
train_set = treebank_tagged_sents[:train_len]
chunks = itertools.groupby(reader, keyfunc)
f.close()
plt.xticks([]), plt.yticks([])
parse = lambda line: tuple(s.decode() for s in unpack(line.encode()))
self.this_obj = FooBar(O, P, Q)
False
x = np.ravel(np.tile(np.arange(nx), (ny, 1))).reshape((nx * ny, 1))
stdoutHandler = logging.StreamHandler(sys.stdout)
M = np.arange(2, 6)
response = requests.get(url)
description = models.TextField()
new_url = urlunsplit(url)
grammar.add_rule(ExampleRule())
a = np.array([1, 1, 1, 1, 1, -1, -1, -1, 1, 1])
row = df_result.irow(0)
y1, y2 = Y.T
s2 = datetime.now()
allsets = [{1, 2, 4}, {4, 5, 6}, {4, 5, 7}]
f = tuple(sorted(f))
nbors.append(i + 1)
start_date -= datetime.timedelta(days=1)
charBlank = models.CharField(max_length=10, blank=True)
data = np.ma.masked_where(distance > radius, data)
lst2 = line.strip()
self.lnameLabel.grid()
ts = pd.Series(pd.np.random.randn(len(time)), index=time)
install.run(self)
cmp(a, b)
astr = w.readframes(w.getnframes())
result.append(array[i] * array[j])
chunk.append(i)
print(a)
ttl = re_img1.size[0]
[x - y - x * (x ** 2 + 5 * y ** 2), x + y - y * (x ** 2 + y ** 2)]
my_rmdd = rolling_max_dd(s.values, window_length, min_periods=1)
g = globals().copy()
fig = mlab.figure(bgcolor=(0, 0, 0))
dic = {}
count += len(v)
color
logFile.write(text)
arr = numpy_all_the_way(5000)
ww.setparams((1, sampwidth, framerate, nframes, comptype, compname))
print(sing)
digits.append(digs[x % base])
cax.patch.set_alpha(0)
rand_num = random.random()
linends = (m.start() for m in relinend.finditer(data))
a & b
num_silent += 1
ws = wb.create_sheet()
products = [(x1 * x2) for x1, x2 in combinations(xs, 2)]
self.search_box.submit()
raise StopIteration
print(p(0))
words = line.split()
args = parser.parse_args()
OK(SKIP=1)
plt.tight_layout()
d = {}
x = stats.norm.rvs(size=100)
win.add(btn)
init = tf.initialize_all_variables()
writer.writerow(row)
a = c_int(2)
self._get_lines.set_color_cycle(clist)
embed = MapField(EmbeddedDocumentField(Inner))
text = text.replace(k, d[k])
df
print(fn())
text = input(prompt)
s = MLStripper()
lots_list = [x[1] for x in decorated]
self.scat.changed()
d = {A: B, B: A}
batched_x, batched_y
data.remove(val + 1)
pos[label] = construct_projection(label)
name = tempfile.mkdtemp()
print(k, v)
scipy.linalg.fractional_matrix_power(m, 2.5)
f = StringIO()
s2 = s.drop([5]).reset_index().ix[:, (1)]
result[cols] = result[cols].apply(lambda row: row / row.sum(axis=1), axis=1)
math.pi * self.radius ** 2
print(C)
results = balancer.map(lambda i: (i, my_func(i)), id)
b_in_a = b_in_a[i:]
image = Image.open(b.cover_pic.path)
user = User.objects.get(**kwargs)
table_name = table_name[0]
bchr(10)
print(path)
self.draw()
name = Column(String)
result = t[-1]
x
print(a)
reactor.listenMulticast(1520, MyProtocol())
book.py
1 < [1]
PyObject_INIT(op, tp)
d = OrderedDict()
c = np.array([(1, 0, 0, 1), (0, 1, 0, 1), (0, 0, 1, 1)])
x = 5
li = df.product(axis=1)
a()
sorted_indexes = np.lexsort(tuple([rnd_data[:, (col)] for col in cols]))
self.mqConn.heartbeat_tick()
print(found_str)
i = set(range(10000))
display.start()
187976.61
gen = glob.glob(path.join(dirpath, how_to_find_files))
child = QTreeWidgetItem()
c.accept(next(it), it.previousIndex())
inner = []
f.zoo(2)
text = ~any_section_header + everything_up_to_the_end_of_the_line
print(getattr(a, fld))
kdist
X[idx, i] = 1
handle = urllib.request.urlopen(req)
degrees = int(decdegrees)
sem.acquire()
crackup
bodylist[index].append(edge[1])
id(df1._data)
p.wait()
repeated_row_indexes = np.repeat(np.arange(df.shape[0]), 4)
a[key] = b[key]
main()
dist
data = f.read()
words = text.split()
r = pd.qcut(a, 10)
self.text = text
B()
meta = sqlalchemy.MetaData()
any(map(my_dict.__contains__, my_list))
unique_groups = np.unique(groups)
s = pd.Series([True, True, False, True, np.NaN])
y = np.mean(X, 1)
self.list = []
p = img.getpixel((x, y))
self.value += 2
answer = {}
d = dt.now()
shpsegs.append(zip(x, y))
print(driver.title)
serializer = self.validation_serializer(data=request.data, *args, **kwargs)
[0] * numColumns
W = np.exp(-2 * math.pi * i * np.dot(f.reshape(N, 1), t.reshape(1, N)))
output.getvalue().strip()
value
rows = [0, 1]
pycallback
cast(v.vendorName, c_char_p).value
p.insert(0, instrument.Violin())
net = buildNetwork(10, 20, 11, outclass=LinearLayer, bias=True, recurrent=True)
DF_Filtered = pd.DataFrame()
n += 1
l2.sort()
Z = normY * np.dot(Y0, T) + muX
print(data.transform(replace))
print(obj)
value = ser.read()
f = Foo()
pubsub.subscribe(chan)
x, y = generalizedEuclidianAlgorithm(p, a % p)
test = [copy.deepcopy(it) for it in l for _ in range(2)]
lines = f.readlines()[1:]
a1 = A()
sumh = h.sum()
text = index.model().data(index, QtCore.Qt.DisplayRole).toString()
print(MyClass.my_member)
d2 = d.copy()
print(ch)
start = time.clock()
M2Dr = M4D.swapaxes(1, 2).reshape(-1, dim ** 2)
R = int(sqrt(float(N)))
array
some_number % some_other_number
result = []
args = [iter(iterable)] * n
print(myclass.stdout)
doc = SimpleDocTemplate(pdf, pagesize=letter)
print(result)
readline.set_startup_hook(lambda : readline.insert_text(prefill))
scale_width = screen_res[0] / img.shape[1]
str(b)
a()
df
cursor2 = connection.cursor()
y = sp.sparse.spdiags(x, 0, x.size, x.size)
panel = wx.Panel(self, wx.ID_ANY)
objects = MemberManager()
databasefile
wantspec
Squash
Persistency
D = np.diff(np.sort(product.T, axis=1), axis=0) == 0
d.popleft()
self.j = random.randint(1, 10)
test(unicode_string)
n = len(x)
data
group = n.get_group_symbol()
self._event.cancel()
self.host = host
pos.update((n, (i + 0.5, 2)) for i, n in enumerate(Y))
TWOPLACES = Decimal(10) ** -2
print(df.dtypes)
f = float(s)
end = np.sort(np.concatenate(out))
c1 = csv.reader(f1)
np.percentile([0, 1, np.inf], 50)
MySQLdb.connect(_host, _user, _pass, _base)
print(old_url)
QApplication.processEvents()
H6 = pd.rolling_mean(H5, 4)
f.write(s)
f = StringIO()
Hx = np.eye(dim - n + 1) - 2.0 * np.outer(x, x) / (x * x).sum()
get_monotonic_nums(6)
cls._osx_set(width, height, depth)
b1 = B[..., (1)]
data = concatenate((normal(1, 0.2, 5000), normal(2, 0.2, 2500)))
pyplot.show()
a = []
closest_point = find_hull_intersection(h, [1, -1])
f(s)
print(f == 1.0)
sys.stderr = sys.__stderr__
print(repr(actual))
self.tin2 = wx.StaticText(self.test_panel)
precision = np.random.rand(42) * (1.0 - recall)
fig = plt.figure()
f = StringIO()
False
FETCHED = 200
session.commit()
print(nums)
orelse = Infix(lambda x, y: x.or_impl(y))
corm < -cor(x)
sizer = wx.BoxSizer(wx.VERTICAL)
AM_INIT_AUTOMAKE
self.name = tname
ue = NP.unique(x)
termf = Frame(root, width=400, height=200)
assert isinstance(self.test_user, User)
sio_buf = StringIO(buf)
item
size = sum(1 for _ in g)
test2.main(args)
y = np.sin(x) + (0.0 + np.random.rand(len(x)) * 0.4)
print(p)
self.text = self.text.upper()
index = []
sqla.session.commit()
self.match = match
2 - 0.469774
context.open()
searchtab = notebook.get_nth_page(0)
rslt.columns = [(t[1] if t[1] else t[0]) for t in rslt.columns]
json.dumps(dict, cls=DatetimeEncoder)
image
timestamp1 = calendar.timegm(utc_date.timetuple())
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
a = (c_byte * 4)()
_HTTPSConnection.connect(self)
a, b = tee(iterable)
generate_random_data(latitude, longitude, 600, file_n)
soup = BS(text)
help(datetime)
member.name
found = []
content = http_client.get_content(url)
print(line)
total_messages, total_discussion_approval_votes, total_message_approval_votes
x1, x2 = x2, x1
l.__setitem__(i, Y)
self._value + rhs_value_func()
os._exit(os.EX_OK)
cgitb.enable()
self.val += int(val)
new[key] = transform(value)
x[(0), :, ([0, 2])]
text
sum = 0
True
localtime.tzname(insummer)
visited.add(new_state)
self.write(kk)
color2elts[color].append(elt)
self.device = self
install(fs)
M[~M]
max_peak = numpy.prod(b.shape)
info_hash = match[0][1]
unique_columns = npi.unique(a, axis=1)
colors_seen.add(color)
values = [5, 10, 15, 20]
recursive_lambda = lambda func: lambda *args: func(func, *args)
print((getpid(), n))
rz = 0.0
main()
df
relDir = os.path.relpath(dir_, rootDir)
result += dict_1[key] * dict_2[key]
x = collections.Counter(IT.product(A, B, C))
python - continuation - line - p
quicksort(array, left, pivot - 1)
output, unused_err = process.communicate()
protocol = MyProxy
f2.close()
root = Tkinter.Tk()
S += P_i[:, (j)]
stay_on_path = cheapest_path(path_list, path, history + [step[path]])
g = np.sin(np.arange(0, 10, 0.01) * 2) * 1000
install.do_egg_install(self)
[], [], []
print(i)
subplot2 = fig.add_subplot(122)
termios.tcsetattr(fd, termios.TCSAFLUSH, new_term)
layout = QtGui.QHBoxLayout()
byte = 0
print(getAbstract(text, lines=7))
out
y = x
self.object_class = self._meta.module_name
type(a)
print(info)
STOCK_ORIENTATION_REVERSE_LANDSCAPE
df
prop_list[0] = something
setattr(lr, k, v)
nested = dict()
n.append(n[-1] + n[-2])
self.url = url
benchmark(100)
points[:, (0)] = np.take(x_p, xi)
ax = plt.subplot(111)
destSession.commit()
print(foo.i)
print(get_diagonal(m, 1, 2, 1))
fnf = fn[:num_plot].ravel()
+--__init__.py
l = [0]
stack.pop()
logger = mp.log_to_stderr(logging.DEBUG)
new_style = []
X[idx][:, (idx)]
x.append(int(row[1]))
lst = []
util._run_after_forkers()
ipynb = read(ipynb_file)
ob[k] = func(v)
data = wf.readframes(chunk)
recipients.append(comment.user)
cls.web.set_window_size(1280, 1024)
infourl = urllib.addinfourl(fp, headers, req.get_full_url())
print(l1, l2)
df.sum(1)
y[:] = x
f([1, 1, 4, 5])
doc2vecmodel.syn0[i] = wordvectorfromlda
child += 1
n = numbers[(i + start) % length]
x = np.random.random(num)
[0, x1]
print(M)
o.x = IAddProp.__get__(TestObj2.x, o, TestObj2).__iadd__(5)
k += 1
cur_type = self.obj_type.__mro__[i]
arr_y = arr
bus = dbus.SystemBus()
params
pid = os.fork()
pool.apply(job, [l, i])
self.fd = next(self.fditer)
self._buf += line
d = self._asdict()
bigd = dict([(x, random.randint(0, 1024)) for x in range(90000)])
x.remove(1)
hour = int(hour)
list_[1::2] = map(double, list_[1::2])
current_line = line
first_time = time.time()
x = 1
response = urlopen(request)
res_combine1st = df2.combine_first(df1)
shell = IPython.core.interactiveshell.InteractiveShell.instance()
pdb.gimp_image_flip(image, ORIENTATION_HORIZONTAL)
ar[:i + 1]
fn(*new_args, **new_kwargs)
args = p.parse_args()
self.__modifier_pressed = True
img = np.invert(img > 0)
_get_key(db[k], key[1:], path + [k])
i, j = len(a) - 1, 0
col = int(cell_entry.cell.col)
data = np.array(np.random.rand(1000))
self.value = value
print(d_keys)
this_dir, this_filename = os.path.split(__file__)
f.close()
fmyM = smyM.subs(fcoefs)
algo(x[1:], op, nums)
Base = declarative_base()
response = conn.getresponse()
arr_1[2::5] = 100
raise Http404()
qs = self.model._default_manager.filter(year=year)
_replace_csv_headers(output_files[row[0]], [r[0] for r in cur.description])
chan.exec_command(command)
count == 0
datas = img.getdata()
type(p)
module = sys.modules.get(fullname)
X_channels_first = np.transpose(X, (2, 0, 1))
print(1)
self.app.quit()
collection = defaultdict(list)
self.do_AUTHHEAD()
self._exc_info = sys.exc_info()
Case(When(created__month=2, then=1), output_field=IntegerField())
decrypted = cipher.decrypt(encrypted_value)
fig = plt.figure(figsize=(12, 4))
type(bar)
app = Bottle()
cols = np.isnan(g).all(axis=0)
v = node_list.pop(0)
map(lambda x: toDict(h, x), data.asList())
columns = zip(*rows)
bla.bar(4)
x = GFKmodel.objects.create(pk=789, content_type=ct, object_id=y.pk)
df
fig.tight_layout()
new_bases.add(dependence)
link_locations.append([match.span(), match.group()])
self.a = a
data = np.empty(N, dtype=float)
response
product *= int(x)
index.pop(i)
j = np.argmax(xs[:i])
birth_years[n] = years[index]
dx = [0.5, 0.5, 0.5]
t = d * sin(bearing)
igrp += len(g)
waffle_plot_width = 20
df = df1.join(df2)
dist
L_in.pop(idx)
booklet
ax = plt.axes([0, 0, 0.1, 0.2])
raise TimeoutError(error_message)
d = SurrealDuck()
numberofrows = ysize - y
key.get_file(fp)
print(msg.BCC)
k2 = np.c_[k[:, (0)] - 1, k[:, (1)] + 1]
subArray.append(newRow)
-DogID(PK)
-ChildID(FK)
result = tuple(islice(it, n))
z1 = tf.add(rand_var_1, rand_var_2)
self.__dict__.update(kwargs)
loop = asyncio.get_event_loop()
line_num = 0
print(intf_ip)
shared = np.arange(n)
root = Tk()
dict(cm)
my = y.mean()
print(line.strip())
o.x += 5
bytesToRead = ser.inWaiting()
DD, EE, FF
dis.dis(f)
result, index
max_score, max_player = max((max(a, b), player) for player, a, b in players)
screen.blit(player.image, player.rect)
posts = Post.objects.filter(owner=owner)
width = 25
readline.set_history_length(200)
d = pd.DataFrame(dict(Time=pd.unique(df.index.date) + Hour(16)))
empty_lines += 1
DataFrameDict[key] = data[:][data.Names == key]
result = ast.literal_eval(s)
a = np.stack([d.values.flatten() for d in dfs], axis=1)
extra_dims = np.random.randint(0, 10, (1, 1, 5, 7))
tables = cursor.fetchall()
count = 0
sys.exit(-1)
item
os.execlp(program, *argv)
condition &= Q(full_name__icontains=string)
str(self.name)
engine = django.utils.importlib.import_module(settings.SESSION_ENGINE)
clusters_separation = [0, 1, 2]
file = self.get_selection()
root = Tk()
runing_with_root_privileges()
console = logging.StreamHandler()
my_dict = defaultdict(int)
b = [4, 5, 6]
output[funcname] = paramcount
plt.pcolor(m)
ax.grid(True)
print(state)
filename = tkFileDialog.asksaveasfilename(**self.file_opt)
PlayerRole.objects.get(team=self).player
UserModel().set_password(password)
a[0, 1]
data[:, (1)] = np.cos(data[:, (1)])
False
y_model = model(X, w)
exexA1 = exA1
y = [2, 4, 1]
vector = matutils.unitvec(matutils.sparse2full(vector, num_features))
xf = np.linspace(0, 1, 50)
loop.run_forever()
f = plt.figure()
output.write(resp.content)
dataframe.loc[(1), :]
i += 1
p = MyParser()
u = list(set(x))
np.percentile(rdd.collect(), 25), quantile(rdd, 0.25)
df.iloc[i] = row
string
res.append(record.id, record.name)
print(a[n1, n2])
{}
run_wsgi_app(application)
ds1 = set([tuple(values) for values in df1.values.tolist()])
df2.y[0]
__builtins__ = 0
theLayout.addWidget(logOutput)
beep()
print(items)
l1 = inp.split()
open(file_path, mode)
N(h, 2)
{{form.name(disabled=True)}}
d[std::make_pair(1, 2)] = 1
items = sorted(items, key=counter.get, reverse=True)
self.ser = serial.Serial(port, baud, timeout=timeout)
Base = declarative_base()
print(args.aggregation)
split_string.append(identifier[previous:])
rslt.reset_index(inplace=True, drop=False)
request = Request(url=url)
item = _finditem(v, key)
xy = np.multiply(x, y)
repr(dict(foo=self.foo, bar=self.bar, baz=self.baz))
Py_Initialize()
not unmatched
xt = ax.get_xticks()
zdata = np.sin(8 * X) * np.sin(8 * Y)
delta = np.random.normal(size=N)
num = len(s1.intersection(s2))
[yes, no]
values = list(x.values())
df
childListStack.remove(childListStack.size() - 1)
i = 0
L = list(ascii_lowercase)
new_idx = np.nonzero(pdf.ravel())[0][new_idx]
font.setPointSize(10)
module1.py
wx.Frame.__init__(self, parent, id, title=filepath)
path.append(target)
buffer = buffer()
counter[key] = 1
args = items[1:]
zout.close()
main()
self.attname = self.name = name
-extproc
fout.close()
assert_array_equal(b, c)
decoder = json.JSONDecoder(object_pairs_hook=collections.OrderedDict)
print(m)
b[0] = 12
awt.Canvas.__init__(self, size=(newSize, newSize))
[namedtuplify(item) for item in mapping]
wn.ADJ
n = np.ndarray(a.shape)
old_settings = termios.tcgetattr(fd)
rddX + (h - floor(h)) * (rddXPlusOne - rddX)
c = Counter(r.category for r in results)
start += step
B[-1].append(list)
m, n = x.shape
engine = sa.create_engine(url)
d.append((start, length))
t2.timeit(number=1000)
root = tk.Tk()
to_tz.normalize(from_dt.astimezone(to_tz))
self.call_count += 1
app = Tk()
100
data.update(obj.__dict__)
y = [int(t[4:]) for t in x]
x_sorted
y = 1 / mu * np.exp(-x / mu)
managed = False
ips[parts[0]] = 0
jsonify(success=1)
dec
t = json.dumps(s)
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
inkey = get_key()
a = [0, 0, 0, 0, 0]
num_zeros = (y == 0).sum()
r[a == 0] = 255
d[l2] = len(s1 & s2)
salt = bcrypt.gensalt()
time.sleep(0.1)
pygame.draw.circle(screen, color, e.pos, radius)
pg.QtGui.QGraphicsItem.shape(self)
in_file_length = in_file.tell()
line = next(afile)
print(magicInput[1])
line = line.lstrip(BOM)
parser = argparse.ArgumentParser()
word.Activate()
plt.ylim(0, 100)
X = X.toarray()
l1 = [(t, value, 1) for t, value in a]
result = [5, 6, [4, 5]]
x -= 1
print(len(all_rosters))
thread2.start()
eval(scripts[0])
setattr(obj, k, v)
df = pd.DataFrame(np.random.randn(5, 4))
getattr(self, item)
foo(x)
sum += i
self._closed = True
ax = plt.subplot(111)
f(**relevant_args)
a = np.array((0, 1))
x2, y2 = np.random.rand(2, N)
dt = data.dtype
quicksort(Array, 0, len(Array) - 1)
update_db_here()
False
paramcount = len(inspect.signature(f).parameters)
values = list()
matches = np.empty((rows, cols, cols, 2), dtype=str)
plt.scatter(x, y, c=color, s=200)
True
i = 5
type(a)
print(tasks[1].result())
print(df1)
browser.select_form(nr=0)
g()
kp1 = detector.detect(img1)
self.given_client_connection()
func2.__name__ = name
cam = scv.Camera(0)
cmd[arg] = sys.argv.pop(0), sys.argv.pop(0)
print(H[-1, i])
test2.put()
my_list = eval(json_format_string)
up.insert(i, up[i - 1])
r.findall(s1)
names = load_names()
f.close()
info = {}
response
dir(Foo)
a = np.arange(25).reshape(5, 5)
print(dok)
a = np.zeros(dim[0], dtype=int)
[l[0] - 1] + recurseDecrMap(l[1:])
frame = Frame(root, width=100, height=100)
cbax = fig.add_axes([0.85, 0.12, 0.05, 0.78])
conn = engine.connect()
exitstatus, signum = status & 255, (status & 65280) >> 8
self._format(object.bar, stream, indent, allowance + 1, context, level)
self._x = x
pickled = pickle.dumps(session)
thing = MyFactory(object=object, related__param=object)
openedfile = open(filename)
{NULL, NULL, 0, NULL}
M = a_copy.shape[1]
i += 1
chars.append(random.choice(ALPHABET))
data = loadtxt(os.getcwd() + txtfl[0], skiprows=1)
eval(input())
print((d1, d2))
count
item.append(default)
AC_OUTPUT
Apple, Orange, Pear = list(range(4, 6))
dirnames[:] = []
df_ret[dcol] = grouped.apply(wavg_f)
d = datetime.datetime.fromtimestamp(sec)
inp.setformat(alsaaudio.PCM_FORMAT_S16_LE)
date = models.DateField()
results_dict.update(my_list)
expr = Delayed()
recarr[:] = prepare
index = self.selectedIndexes()[0]
vars(othermodule)[k] = my_decorator(v)
n.blabla()
c = a[(check), :]
is_coherent(l2)
xbar = ravel(data).mean()
root.append((token[0], token[1]))
self.allowed_domains = allowed_domains
print(data.dtype.names)
cgitb.enable()
old_flags = fcntl.fcntl(w, fcntl.F_GETFL)
res
FigureCanvas(fig)
process(row)
t.join()
self.fire(connect(self.path))
obj_1.double_x()
n -= 1
big_array.append(arr)
True
deletepak[TCP].chksum
last_row_min = df.loc[(last[0]), :last[1]].min()
args.pop(0)
fig = plt.figure()
sdata = data[data[:, (0)].argsort()]
declaration_type = child.string.split()[0]
foo()
f = int(f)
steps = (toss.cumsum() * toss).diff()
to_date = from_date + datetime.timedelta(days=1)
core.wait(0.05)
firstVal = MyTuple[0]
colors = iter(cm.rainbow(np.linspace(0, 1, len(ys))))
print(get())
p - 1
sizer.Add(okBtn, 0, wx.ALL | wx.CENTER, 5)
visited = set()
self.ids.myimage
print(result)
show(layout)
self.uri = uri
x = np.arange(0, 10, 0.005)
config = ConfigParser.ConfigParser(allow_no_value=True)
_ranks[i + 1][k] = a
s[s == s.max()]
fig = Figure()
self.numSquared = self.square(num)
x = 1
config.read(CONFIG_FILENAME)
tree.addi(0, 10, 5)
a = a + 1
output.append([]) if val == valueToSplit else output[-1].append(val)
s.bind((HOST, 0))
defaultBases = PLONE_FIXTURE,
it = iter(d.items())
result
t = Test()
np.linalg.norm(fromdeg(90) - fromdeg(270))
c = random.choice(list(choices - set(last_choices)))
self.children = []
post.tags = Tag.objects.all()
SetValue(reg, installkey, REG_SZ, installpath)
print((a, b, c, d, e, f))
0.1 + 0.1 + 0.1
self.a = Foo.objects.get(id=1)
f.write(page.mainFrame().toHtml())
subplot(212)
date = datetime.date(start.year + i, j, 1)
TP, FP, TN, FN
quarters[month]
tri.triplot(ax, triang)
result = func(*args, **kwargs)
self._original_state = self._as_dict()
worker_thread.run_event.set()
result = true_stacked.index.tolist()
n = a.shape[0]
last_valid = df[col_name].last_valid_index()
data = np.zeros((W, H), dtype=np.ubyte)
self.assertEqual(expected, isEven(num))
aaaa
df[missing] = shifted
root = Tk()
t.capitalize()
y = x * sin(90) + y * cos(90)
plt.show()
tokens.append(x)
StartupWMClass = myscript
proxy.Proxy.dataReceived(self, data)
ul[a]
locals()
self[attr]
clean = dirty.translate(nukemap)
a = A()
d
lst[unfrozen_indices] = unfrozen_set
M.append(e)
w, h = img.size
user = ForeignKey(User)
f.seek(readLoc)
wall(0, 4 * N + 1)
value = fn(*args)
o.update(self.recursiveDecode(v))
True
print(b[0, 0])
-1
phase(complex(-1.0, -0.0))
testsite_array = list(f)
self.button = gtk.Button()
start_pos = np.ones(6) * (1 / 6.0)
sys.exit(-1)
positionsList.sort(key=partial(howCentric, boardSideLength))
round(2.5)
lSongs
-1 / 2
0, 1, 0
trueList.append(item)
print(signchange)
app.yaml
y = i + x * (b + x + 2) / 2 + 1
print_student(std)
SOCKS_PORT = 9150
os.unlink(file)
ax.loglog(x, y, basex=np.e, basey=np.e)
ndictionary, nwords - ndictionary
_stdout = sys.stdout
args = [iter(iterable)] * n
tdgi = theDict.__getitem__
startmax = max(startmax, endmax)
browser.get(urls_map.get(resource))
main()
out = {}
oracle_subprocess.wait()
scipy.inf
os.makedirs(root)
setattr(self._mockclass_wrapper, name, value)
nexts = cycle(islice(nexts, pending))
c = C()
non_empty.sort()
idx = np.argwhere(np.diff(np.sign(f - g)) != 0).reshape(-1) + 0
local_dt = datetime.fromtimestamp(ts, get_localzone())
s_x = center[0] - v_x[0] * (width / 2) - v_y[0] * (height / 2)
x = np.random.rand(1000)
q.put(job_done)
url = request.url
field = forms.Charfield()
idx = np.mod(np.arange(df.shape[0]) - 1, df.shape[0])
fp.flush()
nges
print(a)
cc = ctx.default_ccache()
statinfo = os.stat(path)
l, = ax.plot(x, y)
globals()[input()] = 42
print(pdf_file)
size = sum(range(1, r.shape[0] + 1))
after_setup_task_logger.connect(initialize_logstash)
f = next(g)
dest_file.write(chunk)
raise AttributeError
fields[field] = obj.__getattribute__(field)
lots_of_defaults(**different_than_defaults)
persons = Person.all()
logging.error(item)
self.data = list(zip(*data))
nt = tuple(list(tup))
t - len(np.unique(np.random.randint(0, N, size=t)))
RDF = rdflib.namespace.RDF
line_segments.append([f[0], f[0] + s * f[1]])
Head.delete(new_remote_branch.repo, new_remote_branch)
clone.foo()
a[0, 0]
bool([])
True
DEBUG = False
img = Image.open(file_in)
print(x, y)
df2
f2.write(line)
marker2 = plt.scatter([], [], s=a2.max())
module2
Y.sum(0).sum()
arr[1]
print(type(self.decorated_method))
text = text.replace(i, j)
fn()
b = bytearray(vals)
cola = [True, False, True, False, False, False, False, True, True, True] * 1000
rows = result.fetchall()
fpr, tpr, thresholds = roc_curve(y_test, prob)
x.append(4)
ack = client_socket.recv(1024)
outThread = Thread(target=enqueue_output, args=(p.stdout, outQueue))
ID = unqID_mask.cumsum() - 1
data_frame = pd.read_csv(file_path, index_col=False)
lower_limit = dt.date.today()
tasks.append(power.delay(i, 2))
np.arange(5.0).dtype
product = np.multiply(M[:9, :], Nprime)
5
ps = np.abs(np.fft.fft(data)) ** 2
v
new = all[:2] + all[4:]
0, 1, 0
denomb = sum(bvalue ** 2 for bvalue in b)
diffyears = end_date.year - start_date.year
self.button.set_sensitive(True)
session.commit()
a[1] = 100
FG(nstep=20).g()
parentdir = os.path.dirname(currentdir)
inserts.append(pythonified)
self.b = b
self.name = name
print([a() for a in b])
M = np.column_stack((x ** 2,))
path_result
j += 1
ipList = []
1
MyClass.my_member
request2.add_data(data)
fmap = {}
contents.insert(index, value)
game_score / max_score * 0.7 + game_score / total_hits * 0.2
xml = ElementTree.fromstring(result)
[self.mapping[c] for c in astring]
auth_url = auth.get_auth_url(redirect_uri)
False
setattr(cls, name, VerifyTokenMethod(meth))
print(df)
ind = np.fromiter(list(d.keys()), int) - 1
thumb.set_from_file(file_path)
8, 8, 1, 1
fig = pl.figure()
actionChains.context_click(your_link).perform()
out = np.zeros(idx.max() + N, dtype=regular_sequence.dtype)
file = self.files.pop(spider)
runs_scored, runs_allowed = map(float, runs)
self.connection = imaplib.IMAP4_SSL(mail_server)
ax.plot(i * x)
current = []
dict.__getitem__(self, self._keylist[index])
i -= 1
max(ranks, key=lambda key: ranks[key])
fig = plt.figure()
self.od = OrderedDict(zip(keys, values))
x = y
timer(stateDSM, 50)
condition = Q(full_name__icontains=s[0])
url_adapter.match(parsed_url.path, method)
self._loop.call_soon(self._step)
self.method_called = False
print(_hex)
dirs.append(item)
params = dict()
last_state = tf.nn.embedding_lookup(output_rs, last_index)
err.write(data)
rows = []
test = SomeClass()
ax = plt.gcf().axes[0]
itempath = os.path.join(folder, item)
x[(j), :, (i)]
logging.basicConfig()
[1.0]
connection.login(username, password)
valid_indices = i[(i >= 0) & (i < len(d))]
1 * y
df
{x: ([x] * 125) for x in range(0, 100000)}
m[k]
Eccentricity = np.sqrt(1 - (axes[MIN] / axes[MAJ]) ** 2)
PyErr_SetObject(PyExc_IndexError, indexerr)
tgt_argspec = inspect.getargspec(tgt_func)
app2 = Flask(__name__)
APNS_SERVER_PORT = 2195
r, b = len(lst1), len(lst2)
hdlr_2.setFormatter(formatter)
b = np.random.uniform(10, 150)
DEVELOPMENT = False
cache_key = m.hexdigest()
self.f.setframerate(framerate)
result.uint8image = tf.transpose(depth_major, [1, 2, 0])
creation_date = mongo.DateTimeField()
df.assign(new=pd.factorize(df.marks.apply(tuple))[0] + 1)
root = logging.getLogger()
s1 = SonsItem()
b = np.diag(x).cumsum(1) - x
resp = conn.getresponse()
t = (t & 255) + ((t & 16711680) >> 16)
n
df
channel.confirm_delivery()
counter[p] += 1
self.createWidgets()
print(node.value)
self._stop = False
setup_environ(settings)
options, args = parser.parse_args()
Inbox.drop_collection()
ckattr = session._template2ckattrlist(template)
print(x)
s.listen(1)
dfx[c] = df_parms.loc[0, c]
http_message = res.info()
e.appendChild(t)
df.addErrback(lambda err: err.printTraceback())
isinstance(instance, self)
rle.values.as_mut_ptr()
saved_column = df.column_name
pyudev.Context()
x = np.arange(-100, 100)
pre = np.sum(npseq[:i]) / i
os.close(f)
CF = ax1.contourf(X, Y, Z, norm=LogNorm(), levels=lvls)
all_permutations_no_dupes = set(all_permutations_substrings(a_str))
df = pd.DataFrame(np.ones(nrows), index=index)
chunk = req.read(CHUNK)
self.tickcount += 1
values = [t[1] for t in ans]
sys.stdout = orig
self.save(cxx_buf, size)
r.raw
Pxx.shape
edge = get_edge_from_id(edge)
filechecker()
self.finalizeInitialization()
product = []
soup = BeautifulSoup(docTxt)
k = min(k1, k2)
p.start()
func = lambda x: [(line[x], i) for i, line in enumerate(lst) if len(line) > x]
tree = lambda : defaultdict(tree)
console.settext(text)
conn.send(packet)
owner = self.get_object()
restored
print(i)
list(group_runs(my_list))
loop.stop()
a = A()
print(airportCode)
self.log[name] = self.log.get(name, 0) + 1
maxcount
subG = G.subgraph(subnodes)
result = parse_aYbM(test)
dumped = pickle.dumps(fake_suds)
sum_.append(deref(it).second)
value
AC_CONFIG_MACRO_DIR(m4)
temp_surf = pygame.Surface((w, h))
myimages = []
show()
indef = Integral(x)
i1, i2 = len(sorted_list) - 1, 0
lat = points[:, (0)]
lookfor = set(word.lower() for word in words_to_find)
print(soup)
Y = np.concatenate((Y, Y))
DII,
operator.le
b = form.save()
y = y.A
ctypes_arrays = [np.ctypeslib.as_ctypes(array) for array in arrays]
False
r.append((False, text[pos:]))
sleep(1.0)
self.Close()
row = cursor.fetchmany(size=1)
app.exec_()
arr[2]
shard_keys = []
itemfreq(x)
tmp = tmp.reshape((-1, 1000))
start, end = unravel_index(V.argmin(), V.shape), (40, 4)
coord = tf.train.Coordinator()
sqs2 = sqs.filter(body_auto=q)
assert isinstance(x_, q.X)
a = np.array(elements, dtype=int)
ycorners = y[0, 0], y[0, -1], y[-1, 0], y[-1, -1]
numpy.asarray(A)[2] = 2
toaddrs = recipients
l = re.findall(r, x)
countPaths(0, 0)
idr = np.column_stack(np.unravel_index(R, (dim, dim)))
print(r.ticket_id, r.cause_code.cause_code)
tokens = [i for i in tokens if i not in string.punctuation]
my_distance
[-1.0, -0.2, 0.75],
loop = asyncio.get_event_loop()
thread = MyThread()
app = QtGui.QApplication(sys.argv)
0.55
[0.0, 0.0, 0.0, 0.0],
best = count + 1, val + 1, key
avg = len(seq) / float(num)
args = parser.parse_args()
a = [7, 5, 5, 4]
start = 0
sectorsPerCluster = ctypes.c_ulonglong(0)
stdout.channel.close()
denoma = sum(avalue ** 2 for avalue in a)
strides = A.itemsize * np.array([8, 2, 4, 1])
B = np.random.rand(5, 4)
test_df = test_df[test_df >= 4]
t = Thread(target=background_task)
setattr(e, k, v)
value = dotdictify(value)
vars(a)
a = [1, 0.1, 0.5]
print(output)
size += item[1]
it_A = iter(A)
tb.tb_frame = tb.tb_frame.f_back
X_mean = np.average(X, axis=1)
points = np.where(ref != 0)
field2 = models.FooField()
emp.greet(ceo)
Fraction(0)
P = partition2(max_range[1:], max_sum)
raise ValueError
sortidx = np.lexsort(coo.T)
group[0][1]
config.set_request_factory(request_factory)
resource.setrlimit(type, (limit, hard_limit))
Column(jc(_to_seq(sc, [], _to_java_column)))
one.rst
self._cache[idx]
print(df)
col = get_column_letter(col_idx)
self.x = x
True
self._kids = []
k = j + 1
C = confusion_matrix(y_true, y_pred)
browser = sys.argv[1]
self.deflt_func = deflt_func
dt = parser.parse(dt_str, default=DEFAULT_DATE).date()
execute(op, operand1, operand2)
new_d = dict((k, []) for k in old_d)
menu.popup(event)
x = y = []
final.paste(im, (int(x * largura), int(y * altura)))
x
session = requests.Session()
result = etree.tostring(parse_tree, xml_declaration=True, encoding=encoding)
res += INCREMENT
-anaconda
parser.disable_interspersed_args()
opts, args = op.parse_args()
self.response.write(json.dumps(rows))
key[0]
path = urllib.parse.unquote(urlparse.urlparse(i).path)
kwargs = {}
print(staininfo_attrb_value)
d = np.ma.array(d, mask=d < 0.2)
fig, ax = plt.subplots(figsize=(8, 4))
q2 = Models.object.filter(field2=f2)
running_results = accumulate(chain(val, funcs), lambda res, f: f(res))
file_2.write(file_1.read())
print(k)
foo(a=2)
mod.foo
0
ydata = list(range(10))
self.__dict__ = d
elem = [0] * len(bounds)
upper_red = np.array([10, 255, 255])
item2node = {T: root}
print(x)
ip = results.get()
args = [iter(iterable)] * n
head = urllib.request.urlopen(HeadRequest(url))
converged = False
print(word)
a = [1]
product = [x for x in itertools.product(*list(options.values()))]
x = [a for a, b in Counter(data).most_common()]
fly.rect.x += fly.vspeed
x = np.arange(0, xmax, 0.1)
getattr(self.widget, name)
d2 = dict((i, i) for i in range(1, 11))
nx, ny = img.shape
tgt = T.reshape(tgt, newshape)
raise NoSectionError(section)
f(self)
print(df_long.sort())
f = gen_f()
simplified = [(word, simplify_wsj_tag(tag)) for word, tag in tagged_sent]
not (bad_rows or bad_cols or bad_squares)
completedFiles.append(fileName)
0
outf.truncate()
d = defaultdict(int)
angle = -angle
X[:, (j)] = np.interp(X[:, (j)], map, np.arange(len(map)))
re.sub(pattern, replace, str2)
D[n - 1] = np.sign(x[0])
lineage.append((parent, split, threshold[parent], features[parent]))
s = set()
self.redirect(exception.uri, exception.permanent)
print(has_pairs_of_pairs(A))
d = json.loads(s)
args_name = inspect.getargspec(f)[0]
py_mod = imp.load_source(mod_name, filepath)
dis.dis(f)
content_typeB = ContentType.objects.get_for_model(ModelB)
python - Qnew
output[k] = sum(x[1] for x in g)
session.ehlo()
profile = FirefoxProfile(profile_diretory)
stderr_thread.join()
bar
1 - n | 2 - n
newy.append(i)
plt.figure(1)
packet = packet / inet.Padding(myString)
self
a = np.ascontiguousarray(a)
data_files
zipped_file = StringIO.StringIO()
print(type(a) is bytes)
value7_set, value8_set, base_value
sys.stderr = _stderr
result = some_module.bar(x, y, z)
img.setPixel(x, y, QtGui.QColor(*data[x][y]).rgb())
_get_key(db, key, [])
_zips = random.sample(zip(list_1, list_2), 5)
sum += distance(str1, str2)
a += 2
g(arr, a, 0)
self.memo = {}
Base = declarative_base()
row = dict(row)
c.append(i)
c = a[-1]
list_of_decorators = [foo, bar]
G = nx.Graph()
distance = models.IntegerField()
fvec(vec, *args, **kwargs)
proxy = SOAPProxy(url, namespace)
cov.start()
self.data = OrderedDict(*args)
j1 = json.loads(data)
x = touch.x - self.center[0]
__all__ = []
distToB -= distToA
D[i, j] = abs(x[i] - x[j])
face_color = [0.5, 0.5, 1]
it1, it2 = itertools.tee(it)
stdout_value = proc.communicate()[0]
df2 = df2.groupby(df2.index).apply(lambda x: x.B.reset_index(drop=True).T)
print(key)
gray = CreateImage(GetSize(img), 8, 1)
se2 = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
self._data = [(key(item), item) for item in initial]
b2 = B.objects.create(ref_a=a2)
soup = BS(html)
raise Http404
elem.tail = i
print(fridays)
output = parser.parse_args()
scene.camera.data.angle = fov * (pi / 180.0)
STOCK_MEDIA_NEXT
STOCK_MEDIA_PAUSE
STOCK_MEDIA_PLAY
STOCK_MEDIA_PREVIOUS
STOCK_MEDIA_REWIND
status = excelProcess.wait()
print(args)
invert_im = np.where(im == 0, 1, 0)
lst = range(1, 4)
max_A = np.max(A)
False
print(os.getresuid())
xmlparser = etree.XMLParser(schema=schema)
random.shuffle(english_words)
sys.exit()
worker_thread.run_event.clear()
main()
idx = index.Index()
np.random.seed(1)
print(data)
self.sizer.Fit(self)
print(s.cookies)
print ()
ref = sorted(seq)
kernel = stats.gaussian_kde(data)
month = a[:7]
self._namescallback = {}
cls.foo = lambda self, x: foo_from_bar(self.bar(x))
print(x)
interpreter = PDFPageInterpreter(rsrcmgr, device)
assert type(result) is list
df2
datetime_object = datetime.strptime(your_date_string, format_string).date()
self.menubarMenu.addItem_(self.quit)
ixlo = set()
b = np.append(b, 0)
lst = foo()
second = first[:]
M[-10:, -10:].mean()
painter.select_color(color)
dis.dis(test)
lmdb_cursor = lmdb_txn.cursor()
as_strided = numpy.lib.stride_tricks.as_strided
print(match)
test.make_cache_key = make_cache_key
end = []
A[k - 1]
s
build.run(self)
dict(parser.items(parser.sections()[0]))
res2.append(i)
result = [entry for tag in tags for entry in entries if tag in entry]
new_tree[dependence].add(key)
self.specific()
merged.append(y)
a = numpy.array([11, 2, 10])
p = np.zeros(tot_vec)
min(y)
user.save()
options = ctypes.c_longlong(0)
dictionary[key] = setItem
np.take(data.values.T, ind_to_take)
n += 1
master.maxsize(width=666, height=666)
print(b_result)
x.theFunction()
threads.append(t)
df
s = np.random.normal(size=N)
rank_b = enumerate(b)
constant(4)
_f = dill.dumps(f)
self.save_work()
count += 1
MyIter(self)
model = Model.objects.filter(pk=pk)
self.plot(next(dataloop))
loop.run_until_complete(go())
G2.add_edges_from(special_edges)
r, w = csv.reader(oldcsv), csv.writer(newcsv)
thing.num_ratings += 1
key = [4, 5, 6]
num_rows = df.shape[0]
logging.log(self.level, data)
wrtr.writerow(row)
angle = 0
uwsgi.atexit = will_invoked_after_reload_or_shutdown
setattr(self, key, execdict[key])
ldm.SetInputConnection(ids.GetOutputPort())
linewidth = 1
c = params[2]
user.set_password(data)
fig = plt.figure()
x = numpy.random.rand(10)
line = pipe.stdout.readline()
cardValue = cardMap.get(card[0]) or int(card[0])
self.y += self.vy
g()
data = []
foo = FooImplements()
dst = distance.euclidean(a, b)
print(jn(v, X))
conn.close()
MASK = 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0
ratings[np.where(ratings == 0)] = np.nan
y = np.sin(x) ** 2
l2.sort(key=natsort_key2)
lines = []
axes[1].imshow(rot_img)
True
row_nonzeros = np.diff(m.indptr)
n = b.shape[0]
MyDatasetObj.cases.append(i)
print(w1back)
col1 = data[:, (0)]
count = collections.defaultdict(int)
key0 = 0
item
dict(format_price=format_price)
first_mask = np.concatenate(([True], ref_sort[:-1] != ref_sort[1:]))
soup = bs(urllib.request.urlopen(url))
dt = pd.DatetimeIndex(df.dates)
current = [item for item in iter_rec([], F, B)]
pos = x, y
next(f)
args = parser.parse_args()
newstdout = os.dup(1)
xNew = (x - x0) * cos(theta) - (h - y - y0) * sin(theta) + x0
ran = [int(n * random.random()) for i in range(n)]
Response(stream_with_context(generate()))
readRequest += chr(self.transactionID % 256)
setattr(cls, name, field)
mask = NP.random.random_integers(0, 1, 48).reshape(8, 6)
res = requests.get(url)
x = df.a / df.b
result
y = xy[:, 1:]
os.kill(pidfile.read_pid(), 0)
yloc = plt.MaxNLocator(max_yticks)
ObjModel.the_callable_on_object.__func__.allow_tags = True
mask[mask] = haystack[idx[mask]] == needle[mask]
x[z.nonzero()] = z[z.nonzero()]
self.filter(width__lte=1200)
pylab.plot(X)
count += 1
query = [self.corpus[i] for i in query]
g = lambda x, f=f: f(x)
combined = list(zip(a, b))
requestObj = urllib.request.urlopen(url, data)
sms_notification_task.delay(payload)
settings = crawler.settings
print(k, v)
out.shape
list_AlignMatrix.append(list(list_AlignMatrixRow))
beaker.session.type = redis
self.AssertSomeStuff()
ndata
x = n
f.readinto(data)
dtx = d1.replace(hour=0, minute=0, second=0, microsecond=0)
self.c * self.config.a
file_2.write(file_1.read())
matches.loc[deltas.idxmin()]
data = {key: value for key, value in data.items()}
JoxApi.writePixelsRect(c, x, y, 10, 20)
p = PyAudio()
list(result)
passing, failing = [], []
ans = pool.map(functools.partial(f, n=20), list(range(100000)))
self._variable = 6
imgarray = np.asarray(image[:, :])
print(b.build_temp)
a, b = x[:, :-1], x[:, 1:]
solution[-1] += character
sys.stdout = sys.stderr = null
app = default_app()
p1y = -tx1 * sinang + ty1 * cosang + cy
_dir = os.getcwd()
queue.append((node, end, path))
infolist.append(len(i))
self.d.pop(self.d.pop(k))
type(a)
perm1[loc], perm1[sloc] = perm1[sloc], perm1[loc]
parent.SetSize((width, height))
logger.addHandler(logger_handler)
cmdlist
httplib.HTTPConnection.connect(self)
mypad_refresh()
escapeInvalidXML(s)
aClk.start(), c[:, :] ** 2, aClk.stop()
maps.Maps.add_animal(rbt)
data = {}
utest = [str(i) for i in nums]
this.insert_after(text_link)
image.save(absolute_path)
atexit.register(cleanup)
gl.glVertexPointer(2, gl.GL_FLOAT, 0, vertPoints.ctypes.data)
f.levels
name = Column(String)
s1.index = s1.index.droplevel(-1)
y[:, ::2] = 0
self.data_structure.custom_sort()
tot += A[i]
not bool(self.data[int_n] & 1 << bit_n)
counter += 1
fig = plt.figure()
next_pending.append(entry)
actual_numpy_array = a._array
sols = solve(sin(z + 2 * pi * n) - 2, z)
frequency = np.array(map(len, neighbors))
grammar_dict[key] = val.setResultsName(key)
fresult.col1 = pd.to_numeric(fresult.col1).replace(np.inf, 100)
print(res)
user_result_str = subprocess.check_output([PYTHON_PATH, USER_CODE_FILE])
w = Workbook()
indata = Serial.read()
value = _decode_dict(value)
Base, DeclarativeTestModel
sift = cv2.xfeatures2d.SIFT_create()
self.Refresh()
output_dict = {}
bar()
print(a[blo:bhi + 1])
log_handle = logging.getLogger(__name__)
self.broken = False
V[:, (-1)] *= -1
idx, dest[idx]
self.__database, self.__query.__code__, self.__name_changes
wordlist = list(s)
zip = ZipFile(args[0])
self.visit(node.left)
d1 = dict()
frame_size = cv.GetSize(frame)
display_in_garden_show(big_sh)
i += 1
matches = [url for url in urllist if url.startswith(search)]
dims = np.array([10000, 100, 1])
c = np.linspace(0, 1, M.shape[1])
print(line)
print(val)
tick.set_pad(8.0)
a_list[i] = elem * 2
data2 = np.random.randn(N)
print([ele for ind, ele in enumerate(i) if ele not in i[:ind]])
f.set_figheight(15)
truthtable(1)
intersect_indices(x, y)
wipe
badchar = not badchar
sorted_rows = defaultdict(list)
print(i)
assert_equal(s.randint(1000), 419)
data = np.random.randn(10, 12)
spud = Potato()
x[(0), :, (0)]
df1 = data[mask]
department = sc.parallelize(department).map(lambda d: (d, 0))
A.data[:] = 1
print(f2(**kwargs))
[[0], [1]]
MOUSE_RIGHTDOWN = 8
result[pattern] = [idx]
t.join()
coro_add = add()
result
s = m.group(0)
write_to_log(mydict)
x + 5
total += float(i) / j
in20 = ctr2 + in2[0]
my_eni_sg_ids.append(add_sg)
__tablename__ = table_name
G2.add_edges_from(edges)
self.p = subprocess.Popen(cmdstring, stdin=subprocess.PIPE, shell=False)
combs_per_set = ncombs(len(elems) - 1, m - 1)
root = ET.fromstring(content)
test(i)
sizer.Add(btn)
sorted_xml_files.sort(key=os.path.getmtime)
self._dict[key]
existing_item = Item(parent=existing_category, name=item_name)
i += 1
args.append(rhs[argSplits[i] + 1:argSplits[i + 1]])
width, height
match = re.match(regex, thestr, re.X)
1114111
cur = con.cursor()
col_names = [desc[0] for desc in cursor.description]
game = GameConnection.objects.all()[:1].select_for_update()
1, 4, 7
print([co for co in c if not st.issubset(co)])
a = np.array([100, 10, 1])
os.makedirs(checkpoint_dir)
g = foo(10)
helloFunc = hello_func
count += countnodes(ele.right, 0)
processed_files = set(line.strip() for line in open(processed_files_file))
c = args[0]
c = np.copy(a)
id(self) == id(arg)
size = wcwidth.wcswidth(s)
form = PersonForm
print(ud.name(combined_astr))
i = ord(c)
zeroArray = [0] * Np
[4, 8]
pivot
ts[i] = ts[i][:-1]
c.perform()
stdout, stderr = processes[0].communicate()
badchar = True
res.resid
cB = pd.cut(B, 9)
a[0] is False
new_editor
m_1 == m_2
BOOST_PYTHON_MODULE(ModuleTestBoost)
np.array([month_id[datum] for datum in data])
dis.dis(string_iterate)
len(self.data)
output.seek(0)
1 / 0
sum((getRecipe(item, quantity) for item in subitems), Counter())
self.__offset = timedelta(minutes=offset)
dealer = Dealer.objects.get(id=dealer_id)
levels = os.path.split(path)
print(data)
out = []
val &= ~(1 << 1)
reflected = [e[::-1] for e in rotated] if len(x) > 2 else []
item = q.get()
pp(data)
x1, x2
CA.d
YourWidget()
im = numpy.where(im > 0.5, 1, 0)
indexes(LB, UB - 1)(0, 4)(5, 8)(9, 11)
m, n = A.shape
opener = urllib.request.build_opener(proxies)
raise
p1 + p2[size:]
window.move(x, y)
1 << n
string.translate(s, tab, deletions)
url_queue.task_done()
table[m - 1][n - 1]
nlist = [x for sub_l in map(split_or_not, blist) for x in sub_l]
processes = []
ij_1d = np.linalg.norm(delta, axis=2).argmin()
setattr(copy, attr, getattr(el, attr))
root = tk.Tk()
datass = np.sqrt(scipy.stats.ss(datam, axis=1))
id(x)
[s]
print(aList)
b = a
h = _Foo_()
x = np.arange(0, 2, 0.008)
x1 = np.linspace(-1, 1, 100)
s = sign.groupby((sign != sign.shift()).cumsum()).cumsum()
loop = asyncio.get_event_loop()
i_idx_y = u_idx_y[np.in1d(u_y, i_xy, assume_unique=True)]
j += 1
------views.py
api = restful.Api(app, decorators=[csrf_protect.exempt])
self.SetSizer(grid)
text
window.raise_()
d = defaultdict(int)
num_years
w.set_default_size(640, 480)
foo(FOO)
parsedval = tokens[0]
out[:, (i)] = np.max(mult, axis=1)
sys.argv[1:] = args.unittest_args
b1 = np.array([1.0, np.NAN, 2.0, np.NAN])
new_request = Request(link, callback=self.parse_file_page)
print(users)
bstream = blob_info.open()
isstatement = True
list_of_pixels = list(img.getdata())
2
l2 = np.array([1, 2, 5, 10])
platform.mac_ver()
print(shape)
out.ravel()[idx1 + 4] = cosv
print(x, field)
test.columns
frame.Show()
Mtl = mat.T.tolil()
True
print(get_uuid())
res = np.zeros((len(seqs), CHARS_COUNT * maxlen), dtype=np.uint8)
Decimal(2).sqrt()
x = next(generator)
print(df)
M[i - cols, i] = M[i, i - cols] = 1
to_delete = []
print(np.divide.outer(i, j).sum())
g = list(g)
dated_files.sort()
prevnode.right == node.left
line(img, vertices[i], vertices[(i + 1) % 4], Scalar(0, 255, 0))
d = dict()
Py_DECREF(v)
counts[key] = 0
f
a - b
woman = int(woman)
df_ = df.stack().unstack(fill_value=tuple([np.nan] * 2))
word = numeration + word[0:]
b += len(line)
list(r)
NumericOperand(int(as_float))
exec(script)
a[r[:, (0)]] = r[:, (1)]
item
d = np.linalg.norm(r)
deadline = time.time() + timeout
print(listForm[pos + 1])
print((item, row, col + 1))
queryset = MyModel.objects.all()
say(my_chr)
data = struct.unpack(fmt, f.read(size))
df
text is line[begidx:endidx]
b[np.where(mymask)[0]] = c
self._hal.dbus_error_init(ctypes.byref(self._dbus_error))
this_team = Team.objects.get(pk=team_id)
A = 5
a, b, c
httpretty.reset()
otest = list(utest)
newFunction
isinstance(2.5, float)
print(numpy.__path__)
n, bins = np.histogram(x, bins, normed=True)
b[b.searchsorted(a)] = np.nan
init(strip=not sys.stdout.isatty())
iter(self.pairs)
a = sum(i, 0)
unordered = set(unordered)
print(type(e))
count += 1
size = 0
print(enumerator)
cur = connection.cursor()
self.pubsub = self.rcon.pubsub()
print(msg.as_string(unixfrom=True))
s = s.replace(char * 2, char)
lst = list
it = iter(map(int, [_f for _f in row[1:] if _f]))
uniques = pd.unique(vals_1d)
self
print(Foo.number)
width = len(df.columns) / 7 * 10
2, 7, 15
fly.rect.bottom = hit.rect.top + 1
p = numpy.poly1d(z)
result += 2
stop_event.set()
l.append(m)
df
print(reconstituted.arg1)
b.x = a
myfile.close()
engine2.process()
partition[random.randrange(s)] += 1
m = memoryview(buf)
data.append(x)
i = l.index(x, i) + 1
self.v_c = v_c
sums = list(partial_sums(nums))
value += array[i] >> shift
Case(When(created__month=7, then=1), output_field=IntegerField())
docText = MSWord.Documents[0].Content
newList = insertElements(oldList)
self.value = self.e.get()
s = u ** 2 / (2 * g)
result = service.data().ga().get(**params).execute()
max_elements[item[1]] = item
fig, axes = plt.subplots(nrows=2)
self.flip()
cursor = conn.cursor()
pool.close()
True
d = {x: d1[x] for x in d1 if x in d2}
1,
re.search(regex, s)
S = set(range(10))
ax2 = ax1.twiny()
a = numpy.diag(diag) + numpy.diag(lowdiag, -1) + numpy.diag(updiag, 2)
r, g, b = convert_to_rgb(minval, maxval, val, colors)
cv2.ellipse(image, center, axes, angle, startAngle, endAngle, BLACK, thickness)
abort(500)
b[:] = 7
result.groupdict() if result else {}
i_out.append(i)
t0 = time.time()
logfile.write(output)
ClassManager.__init__(self, class_)
my_join([])
top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])
ticks = ticks[::2]
ax.add_collection(coll)
rows = fd.readlines()
r = _chord(**kwargs)
result
print(df)
l2 = l[:]
elem = etree.SubElement(root, name)
x = [[4], [6, 4, 9], [4, 6], [0], []]
array[start], array[i - 1] = array[i - 1], array[start]
mimetype
mask = np.isnan(a)
print(self.arg)
results.append(numbers[0])
array([0.5, 0.0, 1.0, 1.0]),
tclsh = Tkinter.Tcl()
height = images.Image(image_data=profile.avatar).height
pr = cProfile.Profile()
choices[i] = np.random.choice(items, p=prob_matrix[:, (i)])
form = StopAdminForm
num_cols = len(f.readline().split())
func_proto = ctypes.WINFUNCTYPE(HRESULT, c_long, HWND)
df = df.assign(Quartile=quartiles.values)
element = lst.pop()
icpa = IncrementalPCA(n_components=10, batch_size=16)
totalsent = 0
currentarg[0]
index.exposed = True
mask = pd.isnull(df)
it = iter(seq)
vals1, vals2 = zip(*[(dict1[k], v) for k, v in list(dict2.items()) if k in dict1])
print(i)
value = int(value)
1
x.pack()
datam[i] = data[i] - ms[i]
value = int(value)
print(cert.get_subject())
fmt.Println(e)
plt.plot(Y)
d = defaultdict(set)
otherdata = Column(String)
df.dtypes == object
first_num
node = node.setdefault(part, {})
b = fig.add_axes((0.05, 0.5, 0.4, 0.4))
status = _get_status(greenlets)
hash2.update(text2)
wpa_migmode = 1 << 19
a2 = np.arange(101, 111)
new_tokens = []
A = nx.to_agraph(G)
rects1 = ax.bar(ind, menMeans, width, color=my_colors, label=lab)
j = 0
funcs.append(f)
params = urllib.parse.urlencode(payload, doseq=True)
newIntersections.extend(tailIntersections)
b = [1, 4, 7]
y = x[1:4:2, 1:4:2]
folder = os.path.dirname(file)
(passing if pred(item) else failing).append(item)
226
input.put(command)
print(self.name)
qslkjqskqsdhf
print(m)
myCounter = itertools.count(5)
l = tuple([x for x in l if x == i or x % i != 0])
iter(lambda : tuple(islice(it, size)), ())
l = random.choice(lines)
my_slider.bind(value=OnSliderValueChange)
lum_img = np.flipud(img[:, :, (0)])
g(*args[0])
dat = np.array(d)
print(value)
[jekyl]
by_week = numpy.reshape(visitors, (7, -1))
ticks = axes.get_xticks()
t.load(_t)
app = web.application(urls, globals())
a |= set(l)
my_own_id()
rule_list = []
m.print_map()
exit()
pprint(foo_good(), width=50)
subprocess.check_call(ffmpeg_command)
print(x)
ex.show()
Xfit_mono_ind = Xfit_mono_ind[:len_mono + 1]
row_ind = [211147]
m[key]
df.write
mat = [([0] * n) for x in range(m)]
RSA_key = RSA.generate(2048, randfunc=my_rand)
xy = numpy.roll(numpy.swapaxes(yx, 0, 1), 1, 2)
z2[index]
c1.donor_id = c2.donor_id
shp = 2 * np.ones(np.log2(N), dtype=int)
i = 0
handle_error()
self.value = value
stack = [[number_list[0]]]
False
tmp = []
__pycache__
grids = np.bincount(lin_idx, minlength=U ** 2).reshape(U, U)
getattr(self.fn, item)
results = []
pkey.bits()
l[-n:]
c = StringIO()
d[2] = d
profile.update_preferences()
os.setpgrp()
d[1](1)
outputTbl.close()
inst1 = Test(2)
worker.start(True)
t = dill.load(f)
subject, body, obj.is_html
self.selectedFiles = files
x = [1]
response = my_server.get(variable_name)
remainder = []
cols_via_concat(df)
options, files = parser.parse_args()
loop.run_until_complete(test())
x & 4 != 0
__delattr__ = dict.__delitem__
li2 = []
b = [1, 1, 2, 2, 2]
writer = csv.writer(tmp)
z_surface = numpy.real(z_surface)
p.add(L[i] + L[j])
c = [b.index(x) for x in a]
authentication = complete(request, backend, *args, **kwargs)
line2d = plt.plot(xnew, heights_smooth)
naligned = nbytes - nbytes % nletters
im = ax.imshow(np.random.random((10, 10)))
self.scat,
0
ld2 = ld(m.group(0), s)
[list() for _ in range(n)]
a = Product1()
main(s)
N = len(values)
pubkey = EVP.PKey()
forced_yeses = set()
libc._write(1, s, len(s))
list_ = [line[2]]
amass.delay(results, tasks, countdown=1)
print(subtraction)
tt = np.linspace(-1, 1, n)
img = cv2.resize(img, (1700, 700))
cls.plugins.append(instance)
self.replacements[mo.group()]
range1 = [date(2016, 6, 1), date(2016, 6, 20)]
print(df.Tm)
cmd(cmd_run)
size, start = max(starmap(lcp_item, pairwise(sa)), key=lambda x: x[0])
print(new_period)
x, y, z = np.ogrid[0:m, 0:n, 0:r] - roi
selfclass(**properties)
results.append(mapping[datatype](val_string))
writer = csv.writer(file)
curses.noecho()
x1, x2, y1, y2 = min(x), max(x), min(y), max(y)
print(get_long(b, 1) == 2 ** 64 - 1)
b = [n & 1] + b
yr = rnd.rand(100000) * nrm + stats.logistic.cdf(0)
Base = declarative_base()
res += catalan(i) * catalan(n - i - 1)
ch = port.read()
f = Foo()
tol = [1, 2, 10]
BEGIN
start = haystack.find(needle, start + 1)
with_divisible(1, 1, 1, lambda x: x)
print(find_weights(40))
U = np.cos(X)
print(get_value(*argv[1:]))
y = np.array(data)
some_session = Session()
A, B, op = B, A, lambda x, y: opT(y, x)
id6, Tool, moreinfo6
False
d = euclidean(X_cluster_0.A[0], km.cluster_centers_[0])
kwargs_copy = copy.deepcopy(kwargs)
8128
8191
8589869056
524287
a[min_ind:min_ind + K]
end_date = end_date.replace(hour=19, minute=0, second=0, microsecond=0)
points = np.array([x, y]).T.reshape(-1, 1, 2)
a * x + b * y + c
DF = pd.DataFrame(Data)
Node._field_types
arr = arr.copy()
self._data[key] = val
len(self.store)
print(df)
cv2.imwrite(sys.argv[2], ws_color)
d = baset.replace(microsecond=i)
com.baudrate = baud
session.save(user)
counts = my_series.value_counts()
next(fin)
SOCIAL_AUTH_GOOGLE_PLUS_IGNORE_DEFAULT_SCOPE = True
ax.autoscale_view()
web.Response()
DBsession = sqlalchemy.orm.sessionmaker(bind=engine)
dupes = df.columns.get_duplicates()
0, 0, 0, 0
d = OrderedDict()
idc = np.column_stack(np.unravel_index(C, (dim, dim)))
x = linspace(-15, 15, 4000)
y
t = set([7, 8, 9])
copy.copy(d)
vector[cython.int]
print(operator.index(item))
self.name = name
a.append(decr_recursive(i))
print(data)
response.append([scope, term])
img2 = to_grayscale(imread(file2).astype(float))
elements = []
ip_packet = ip.Packet()
self.name = name
ret, binary = cv2.threshold(M, 10, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
ns = {}
self.SetIcon(plane.GetIcon())
ans.extend(list(g2))
fig = plt.figure()
print(stdout.readlines())
print(results.groups())
p = Process(target=self.socket_to_process, args=(self.server.q,))
seq[pivot], seq[end - 1] = seq[end - 1], seq[pivot]
data.append([keyd, elem])
i, value = randomElement(list(range(10 ** 15)))
prof = cProfile.Profile()
diff = (end - start) / intv
x.fill_mail_data(5)
sns.clustermap(DF_dism, row_linkage=linkage, col_linkage=linkage)
axis = 0
self.__dict__.update(fields)
GMaxI = values.max()
out, err = ret.communicate()
manager = MyManager()
counts(value[1])
self.o = self._q.get()
cache[lookup_value] = arg(*args)
i -= 1
[28, 15, 16, 17, 4, 19, 20],
bar.MergeFrom(foo)
plot.append(axRes)
partial(func, accuracy=accuracy, nstep=nstep)
secret_key = os.urandom(16)
pa.may
commQueue = Queue.Queue()
olist, ulist = [], []
ipdb.set_trace()
fg.canvas.draw()
X, Y = [], []
son
b in (0, 1)
f.read(how_many_bytes_you_want_each_time)
coord(self.x - c.x, self.y - c.y)
common = len(set(summary[xvalue]) & set(summary[yvalue]))
print(upper_by_index(my_string, i))
records = self.query.filter(Record.dirty == True)
count_list.remove(a)
t.start()
time.sleep(1.0)
checkInput(okay)
image.file = open(image.file.name)
duration = 1
user = qs[0]
raise CannotSimplify
max_arrays = np.array(p.map(process, chunks))
profile = webdriver.FirefoxProfile()
ladd.append(deco(addx))
np.abs(diff)
fig.patch.set_facecolor(bg_colour)
v = list(d1.values())
x[i] = f(v)
bob.width(2)
x = h(x)
intersect = set(new.keys()).intersection(set(old.keys()))
cursor.execute(updateSQL)
d(10) ** d(10) ** d(8)
[10.0, 5.0, 2.0, 0.5, 0.2, 0.05, 0.02, 0.02]
my_array[1, 1] = -1
b = [1, 9, 1]
seen.add(key)
self.logger.log(self.level, message)
A = np.zeros(R, C)
j = arange(cum_a[-1]) - cum_a[:-1].repeat(a)
out.append(first)
d = OrderedDict()
torfile.set_comment(torinfo.comment())
sensor_col = models.PositiveIntegerField()
root[-1].append((token[0], token[1]))
__initialized = False
x = [1]
exec(s, globals())
(out.ravel() == manual).all()
pairLambs[0]()
print(comm_seq(arr_1, arr_2))
self.shell.ast_transformers.append(MyTransformer())
print(content)
I, J = [], []
test_f.count
self.obj = obj
vis0 = cv.fromarray(vis)
g = 1 / (1 + exp(c * b - c * t))
times_1 = [pd.Timestamp(t) for t in times_1]
id = Column(Integer, primary_key=True)
mylist = json.loads(myvalue)
result = [list(v) for k, v in groupby(a, np.isfinite) if k]
s.get(url_0)
root = tree.parse(xmlf, OrderedXMLTreeBuilder())
parser = csv.reader(input)
RE_D.search(string)
objects = [myClass() for _ in range(10)]
out = np.zeros_like(B)
self.minSlider.Bind(wx.EVT_SCROLL, self.respondSliderChange())
result.append(next_value)
self.barrier.release()
python27 - apple
assert len(salt) == 8, len(salt)
then = datetime(year, month, day, hour, minute, second)
updated_obj = mock.updates.pop()
data = f.read()
fnames.discard(invf.name)
np.allclose(xy, xy2)
oldpath = sys.path
execute_from_command_line(sys.argv)
arr *= (upper - lower) / arr.max()
thislevel = [rootnode]
self
distToA = startA
index[:-1] = groups[1:] != groups[:-1]
level += 1
cls.get_or_insert(cls.__singleton_keyname, count=0)
xs = list(range(xs))
start = s.rindex(first) + len(first)
it = stoppable_iter(list(range(10)))
n10 = (np.sum(counts_a ** 2) - n) // 2 - n11
249
result.append(stem_intersect)
x, y = list(sort(x)), list(sort(y))
session.add(User(name=tmp_name))
s = set(replace_list)
time_waited = 0
data_df = np.array([5, 6, 7, 8])
files = output.split()
nx, ny = x + dx, y + dy
p = mp.Pool(8)
argc = c_int(0)
hours, minutes = divmod(n, 60)
im_b = b.load()
[process(x) for x in stuff]
fig.colorbar(coll, ax=ax)
io_loop = IOLoop.current()
start_time = time.time()
clean_data.account_id, amount, tax, deposit, clean_data.pos_id
data = request.form
dG = nx.DiGraph()
self.sound.play()
self.set_useOffset(useOffset)
mask = np.zeros((h + 2, w + 2), np.uint8)
os.remove(self._lock)
c += 1
c = np.cos(x_axis_rotations)
value - base if signed and value.bit_length() == bits else value
print(instance2 in set([instance1]))
self.id = uuid4().hex
list(map(int.__sub__, a, b))
q.put(a)
cur = conn.cursor()
blit_mask(text, windowSurface, (a, 0), green, (0, 0, 800, 600))
pylab.savefig(output, dpi=75)
result = False
format_name = clp.GetClipboardFormatName(rc)
url = sys.argv[1]
self.__slots__
x = [1, 1, 1, 2, 2, 2, 5, 25, 1, 1]
pygame.time.set_timer(TIMER_EVENT, 10)
y_median = y[nearest_05]
lons = np.arange(-180, 180, 0.5)
clen = len(T1)
log.addHandler(ch)
print(i)
print(html)
[bdist_wininst]
my_list = []
shelve.Shelf(gdbm.open(filename, flag))
trimmed = defaultdict(float)
len(list) - 1
results.append(board)
x[0] = 5
r = []
self.bar = backup.bar
module1.cool()
coupons = [as_coupon(c) for c in cfs[:-1]]
gtk.main_quit()
i = 0
print((y.param, sys.getsizeof(y.param)))
setattr(cls, method_name, remember(m))
letter_counts = collections.Counter(the_text)
y[yindex] = z[zindex]
dialect = csv.Sniffer().sniff(csv_fileh.read(1024))
matches = [value for value in values if text.upper() in value.upper()]
retcode = subprocess.call(cmd)
data
firefoxProfile = webdriver.FirefoxProfile()
not (A and not (B and C))
sel = select.select([self.fp.fileno()], [], [], 0)
t.year
a.append((float(k), float(j)))
self.domain = domain_parts[-1]
output2HTML.value = plot_to_html()
deltas[deltas > 100] = 0
globals()
errorcount = 0
dic = {}
obj
func(funcself, **kwargs)
files.append(item)
errno_ = ctypes.get_errno()
integer = int(list_d[0] + list_d[1])
unique = defaultdict(lambda : (0, 0))
Decimal(local.timestamp())
1 in l
inds[rng[:-1]] = start[1:] - stop[:-1] + 1
show(layout)
samples1 = [samples1[i:i + 2] for i in range(0, len(samples1), 2)]
self.response = session.get(url, headers=httpHeaders)
self.t1 = t1
b = np.arange(n_b_rows * n_b_cols).reshape(n_b_rows, n_b_cols)
linecycler = cycle(lines)
display.start()
fig, ax = plt.subplots(figsize=(9, 5))
print(A.data)
print(p.output)
dt = dt.replace(year=dt.year - 100)
div.append(a)
print_something()
im = Image.fromarray(np.dstack([item.T for item in (r, g, b, a)]))
print(c)
newword = random.choice(table[w1, w2])
o.write(b)
tag = models.ForeignKey(Tag)
r[i * i::2 * i] = [False] * ((n + 2 * i - 1 - i * i) / (2 * i))
dates = []
file_buffer = file_buffer[pos + 1:]
f = udf(test_in, pyspark.sql.types.BooleanType())
qValue += probability * (reward + self.discount * self.values[successor])
xscale = float(x) / svg.props.width
df1
i = 0
input_file = StringIO(urllib.request.urlopen(url).read())
weights = np.ones(x.size)
self.shape = array.shape
xs = list(range(N))
httpd.handle_request()
G = nx.empty_graph()
p_surplus -= 1
x = sum(similarity(i, j) for i in a for j in b)
max = 0
tree = etree.fromstring(XML)
form = authentication_form(request, data=request.POST)
plt.plot()
SITE_ROOT = os.path.realpath(os.path.dirname(__file__))
worksheet = workbook.add_worksheet()
cand = [0] * length
a = 2
data.append((1 - t[0], t[2], t[1]))
creation_date = Column(DateTime, default=datetime.datetime.now())
print(item)
time.sleep(pause)
h.update(text)
crawler.signals.connect(spider_finished, signal=signals.spider_closed)
Counter(dict(zip(vocab, counts)))
multi_dict = request.args
self.mapping = {}
print(p.dfsh(1))
self.inches = 0
my_pets = [pet, another_pet]
t.sleep(2)
absdists.argsort()[:n]
queue = toro.Queue()
conn.setopt(pycurl.SSL_VERIFYHOST, False)
mark_safe(new_html)
km = KMeans(n_clusters=num_clusters)
i += 1
j = quaternion(0, 0, 1, 0)
cols = [cols[-1]] + cols[:-1]
plt.imshow(labeled)
a, b = divmod(len(li), n)
out[j * m:(j + 1) * m, 1:] = out[0:m, 1:]
p = Process(target=count_sheeps, args=(5,))
pos = np.arange(len(data)) + 0.5
source / usr / local / bin / virtualenvwrapper.sh
result = []
ln - s / usr / bin / pythonX.X / usr / bin / python
mostCommon = list(allWordDist.most_common(10).keys())
{y, x, 0}
make_transient(inst)
a = f()
legend_padding, legend_spacing, legends, name, orientation
print(point_tree.query_ball_point([1.5, 2.5], 1))
conf_int_b = stats.norm.interval(0.68, loc=0, scale=1 / np.sqrt(M))
seen = set()
x, y, z = colors[:, (0)], colors[:, (1)], colors[:, (2)]
bar()
val >> n if val >= 0 else val + 4294967296 >> n
r, w, x = select([dev], [], [])
dir(Foo())
res = (A == B).all()
self.hostbase = hostbase
r = np.cos(theta * 2) + np.random.randn(N) * 0.1
sieve[m] = s
it = iter(lst)
setattr(cls, name, field)
self.rfile.read(length),
pr = profile.Profile()
blue = sns.color_palette()[0]
len(self.children)
self.value = value
deletedictionary[path[-1]]
mail = email.message_from_string(str)
A, B = unify(iterableA), unify(iterableB)
tree = clf.fit(iris.data, iris.target)
res = NULL
ax = df.plot()
zip_longest(l, [o], fillvalue=o)
ofile.write(data)
True
b = numpy.zeros((6, 5), object)
text.append(line)
location_code = Column(Unicode(10), nullable=False)
self.x = x
d[l[i][0]], d[l[i - 1][0]] = divmod(d[l[i - 1][0]], l[i][1])
print(SystemTime.wHour, SystemTime.wMinute)
ltextvals = set(textvals)
_set_match(re_.match(pattern, string, flags))
i = 1
cov = np.dot(x, y.T) - n * np.dot(mu_x[:, (np.newaxis)], mu_y[(np.newaxis), :])
image_absolute_url = urlparse.urljoin(response.url, image_relative_url.strip())
deleteiterables[i]
cv2.circle(img, (x, y), rad, (0, 0, 255))
plt.scatter(x, y, c=label_dict.get(label))
result = pool.map(func, ind)
d[0], d[-1] = d[-1], d[0]
SYS_gettid = 186
b = np.array(b)
round_up_to_even(1.25)
loop.run_until_complete(do_checks())
self.x = np.uint64(x)
n = np.array([-t[1], t[0]])
h, t, u = int(numStr[i]), int(numStr[i + 1]), int(numStr[i + 2])
django - photologue
sess.run(model.train_step)
dpi = png_formatter.for_type(Image.Image, display_pil_image)
self.handle[idx]
self.inner(*args, **kwargs)
print(arr[(4), :])
self.f.flush()
self.bar(n)
records = session.query(MyModel).all()
vals[:, 1:][idx[:, 1:] == idx[:, :-1]] = 1
d = pd.DataFrame(a).T
another_command()
SHAhash = hashlib.md5()
qrystr = qrystr[:-2]
main.py
mod = __import__(modname)
d2 = datetime.strptime(to_date, fmt)
df1
x, y = points.T
a.A
A[1, 2]
_sdist.run(self)
True
fly.rect.x += fly.hspeed
sum
variable[0]
root.mainloop()
original(a).strip() == new2
audio = MIMEAudio(file.read())
right_depth = self.right.depth() if self.right else 0
scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=cmap)
y_onehot[i] = [0] * (y.max() + 1)
res = sm.tsa.seasonal_decompose(dta.co2)
each.remove(choice)
df.Cat1 = df.Cat1.fillna(value=df.Cat2)
at_most_five_words = words[:5]
counts = bins[tuple(index)].reshape(location.shape)
results = []
name, int(score)
metadata = MetaData(bind=e)
db = MongoClient()
print(line)
group_dict[name].append((dte, time))
a >> 2
x = 1
p = os.path
w = QtGui.QWidget()
D = nx.DiGraph()
res = math.exp(420000)
--Project
text = file.read()
~numpy.array(mylist)
r = [i for i, v in enumerate(m, 0) if v]
input_filename = sys.argv[1]
self.lock = threading.Lock()
model = OLS(labels[:half], data[:half])
endif
c = tuple(range(len(c), -1, -1))
print(p.getChildren()[0].getParentId())
area_2 = area_2.union(create_tube(-1, h))
ostart = max(ustart, vstart)
results = res.fetchall()
height = font.getsize(text)[1]
True
x * x + x
new_strs = []
assert func.isidentifier()
frags
print(qs.query)
adjs.extend([right for right in tok.rights if tok.dep_ in ADJECTIVES])
Ndy = np.array([np.arange(grid_size[1])]) * dy
posts = Post.all()
msg = MIMEMultipart()
data = pd.concat([df, decomp.trend, decomp.seasonal, decomp.resid], axis=1)
session_key = random.randrange(1, 256)
socket.inet_ntoa(unpacked)
result = r / (variance * np.arange(n, 0, -1))
im_mask = np.zeros(im_binary.shape, np.uint8)
print(cet_eur)
result += char
object = pickle.load(f)
out.insert(index, elem)
arr = test.bar()
ac = Counter(a)
opd1, opd2 = int(nums.pop()), int(nums.pop())
sent.put()
fxn()
loop = asyncio.get_event_loop()
im = PythonMagick.Image()
2009 - 1 - 1
func(self, *args)
gray_lap = cv2.Laplacian(gray_blur, cv2.CV_8UC1, ksize=5)
xym = np.vstack((sidx[inidx.nonzero()], sidx[1:][inidx.nonzero()])).T.flatten()
next(t)
keys, values = zip(*list(upLocals.items()))
print(tuple(vars))
True
line = f.readline()
old_action = signal.signal(signal.SIGINT, signal.SIG_IGN)
axs[0].plot(hours, np.random.random(len(hours)))
a.dtype.num == np.dtype(dt).num
False
weights = np.array(initial_weights)
l_no_v.remove(v)
x
l
int(read_int(stream))
a.__array_priority__
item = Item.objects.get(pk=1)
tid.set_size(64)
mlab.axes()
print(b)
False
time_loop(iterator, 1)
False
table = [([0] * n) for i in range(m)]
distribute_overrun(groups, train_length, 1)
assert False
k = a.index(b)
good.append(m)
plt.subplot(222)
f
fmyM
self._x
vals = np.ones_like(rows)
1 in [1, 2]
submission = user_agent.get_submission(link)
time = DateTimeField()
db = connection.my_database
x = np.random.normal(size=100)
data = np.ma.masked_equal(data, 0)
popt, pcov = curve_fit(func, xdata, ydata, bounds=param_bounds)
print(y)
test = Test()
i = j + 1
vertexAttribute.extend([uvCoord[0], 1 - uvCoord[1]])
s_len = len(s)
assert issubclass(cls, A)
a = self.z
lexer.input(lexer.lexdata)
--enable - multibyte
nan = np.nan
f.write(str(mm_addr))
DOUBLE = np.float64
ref_entities = dict((x.key(), x) for x in db.get(set(ref_keys)))
result += new[i].lower()
i += 1
signal.alarm(0)
filter.children
args = request.args
Py_DECREF(stop)
links = re.findall(link_regex, text)
self.threads.append(downloader)
testRunner.run(get_test_data_suite())
raise NotImplementedError(msg)
renderer_classes = EmberJSONRenderer,
init_anykey()
library(dplyr)
x, y = np.meshgrid(np.linspace(-2, 2, 21), np.linspace(-2, 2, 21))
subsub
print(numpy.power.__doc__)
npreds = defaultdict(int)
count += 1
lst = list(gen)
d = Data()
weight_matrices.append(weight_matrix)
destination = bucket.new_key()
count(4)
db.fit_predict(distance_matrix)
counter = itertools.count()
a = pickle.loads(received_string)
a[ii] = val
datastream = ReseekFile.ReseekFile(datastream)
print(i)
model = pca.fit(df)
key = self._get_key(response.request)
728
points = zip(x, y)
results = pool.map(foo_pool, list(range(10)))
print(x / 10)
prev_node.children.add(node)
print(df1)
data_dict = json.loads(data)
res = []
poly2 = apart(poly, x)
start_cursor = query.cursor()
self.sum += self.foo(thing)
s.astype(bool)
print(seq[0])
S.add(e)
df1 = df1.div(df1.sum(axis=1), axis=0)
print(proc.connections())
parent.children.add(this)
AKLMNOPQRS
me = os.getpid()
sel2 = sel1
print(order_form.name)
d
arr = [(a + b) for a, b in l]
xs[1]
broadcasted = numpy.broadcast_arrays(*broadcastable)
__metaclass__ = models.SubfieldBase
2 - 0.209096
result = full_union(L)
serializer = self.get_serializer(instance, data=request.data, partial=partial)
stations = OrderedDict()
invert(*args)
15662901497824584782
canvas = event.widget
cmap = sns.diverging_palette(20, 220, as_cmap=True)
request = urllib.request.Request(authentication_url, data, headers)
print(((r, r + 10), count))
test1.timestamp = datetime.datetime.now() - datetime.timedelta(hours=2)
total_sum = 0
var1 = 1
prange = list(range(2, 6))
{{form.category}}
obj_list = []
response1, sw1, sw2 = self.cardservice.connection.transmit(apdu)
stdout_thread.daemon = True
print(repr(encoded_d))
e_values, e_vectors = sp.linalg.eigh(CO)
threading.Thread.__init__(self)
x = C()
xp = v1.x * v2.y - v1.y * v2.x
x
plot_masked(data, center_x, center_y, radius)
df
count2 += 1
count1 += 1
d = datetime(1, 1, 1) + sec
Ndx = np.array([np.arange(grid_size[0])]) * dx
distLDAModel.topicDistributions
bpy.ops.transform.rotate(value=(rot.angle,), axis=rot.axis)
values[np.digitize(random_sample(size), bins)]
iendswith
default
images = tf.image.resize_images(images, 256, 256)
xl = list(x)
frm = inspect.trace()[-1]
pwd()
add_clipboard_to_figures()
pattern, filename = sys.argv[1:]
deactivate
print(count)
it.iternext()
nodetype = type(node).__name__
content_raw = response.read()
x % 2 == 0 and x != 0
testing()
print(row)
window = Gtk.ApplicationWindow()
print(msg.format(**info))
X[unique_nonzero_indice]
int.__m
vbdrecord.VDI = null
print(df)
s = set(range(4000000))
password = Column(String(64), nullable=True)
x * x
db.close()
False
x = 0
file = path.resolve(dir, file)
frame.cause_error()
c = np.array([7, 8, 9])
max_value = a.max()
process_name = sys.argv[1]
plt.figure()
client.put_object(bucket_name, object_name, object_data, size)
rad = points[:, (2)]
bar = Foo()
a = fig.add_axes((0.05, 0.05, 0.4, 0.4))
zipstream.seek(0)
frob_some_more()
fill_from(size, random.choice(on_locs))
rise = np.diff(log_y)
result = a + b + c
start = []
_decorator
lr.fit(X, y)
clock.tick(FRAMERATE)
myList.append(brightness(image_name))
serializer_class = QuestionSerializer
self.counter += 1
inp.close()
download_file()
lowest_values = [x]
idx += 1
c = a + b
df
word_dict = dict()
cls
config = tf.ConfigProto()
alpha * binary[:, :, (c)] * overlaycolour[c]
partition = iter([])
c2 = pycurl.Curl()
ix_i = np.random.sample(x.shape).argsort(axis=0)
lcd.clear()
data = f_in.read(size)
self._waitable = set()
processor.process()
bytes.append(choice(allbytes))
df
i, d = divmod(s, 1)
ipython - -no - confirm - exit
the_date = datetime.fromtimestamp(unix_timestamp)
groups.last()
hwidth = len(max(row._fields, key=lambda x: len(x)))
end_date = datetime.date.today()
sequence += [padding] * (group_length - len(sequence) % group_length)
stderr_events_enabled = true
r[k] = int(v)
xys_bot.append(((x.max() - x.min()) / 2.0, 15))
cimage = cStringIO.StringIO(cimage.getvalue())
print(WEEKDAYS.get_selected_values(52))
env[k].append(v)
fig = pl.gcf()
self.loaders[key]
fig = figure(1, figsize=(6.5, 6))
pwalk(np.zeros(10))
df1
my_date = date.today()
fig.colorbar(cax)
pyplot.show()
X_neg.A
text.splitlines()
s = yaml.dump(f)
d.bar()
new_method
pool.close()
form = SupplierAdminForm
f2 = np.vectorize(curry_f(P))
gexpr = (bar() for i in range(10))
q.put_nowait(firstkey)
datalist.append(chunk[:i + 1])
self.name = name
self._def.addCallback(self._finish, toc)
b_reshaped = b.reshape(dim_array)
instance.__class__ = _
int_arr
len(self.point)
print(element)
deletedf
print(coords)
self.a2_edit.setValidator(self.int_validator)
corr = corr[corr.index.get_level_values(0) != corr.index.get_level_values(1)]
zeroArray = [0] * Np
s = response.content
dict(zip(symbols, map(partial(getattr, module), symbols)))
result = {}
prev = next(it)
self.vec = numpy.array(vector)
getattr(handler.request, method).add()
deletesys.modules[random_name]
session.get(base_url)
bitrate = f.info.bitrate / 1000
isinstance(e, bs4.Comment)
slope, intercept = np.polyfit(np.log(length), np.log(time), 1)
self._x = value
distance_matrix = zeros((N, N))
is_activated.boolean = True
df = pd.DataFrame(columns=df[0], data=df.ix[:, 1:].values)
id(S)
y = np.linspace(-1, 1, N)
partition_between.append((i + 1) * len(a) / k)
client.connect(your_hostname, username=user, password=passwd)
m_istr.close()
num_nonzeros = np.diff(M.indptr)
statistic.append(np.nan)
self.expandfor(index)
True == 1
False
self._array = numpy_array
file.write(line2)
trans = Word(unicodePrintables)
variable = f(5)
plt.scatter(x, y)
A[i]
self.insert(**self._filter_fields(value))
lines = [ax.plot([], [])[0] for _ in range(N)]
splits = np.split(arr, argrelmax(arr)[0] + 1)
result = HttpAuthenticated.send(self, request)
trans = {x[0]: x for x in lol[1:]}
0
sys.excepthook = log_exception
new_tree[dep_module].add(module)
X, Y = np.meshgrid(X, Y)
imap.login(username, password)
data_files.append((to_dir, [os.path.join(root, fl) for fl in file_iter]))
value | 1 << bit
str(select)
True
y = y[indices]
counter = str(int(f.read().strip()) + 1)
diags = []
_render_template = flask.render_template
target = urlparse.urlparse(target)
e = matlab.engine.start_matlab()
w = wcs.WCS(f[1].header)
max_x = x[y_av.index(max_y)]
mask = (arr == arr[0]).all(axis=0)
l[0] += nasty()
print(letter)
conn[db]
freq = Counter(data)
self.name = ParentClass.constant_pool[idx]
workbook = xlrd.open_workbook(excel_file)
args = [iter(iterable)] * n
column_letter = _get_column_letter(column)
path = []
self._data = base64.encodestring(data)
Py_DECREF(pygame_module)
msg.String()
speech = Pygsr()
sum_of_seen += item
line4, = ax4.plot(line2.get_data()[0], line2.get_data()[1])
style.rules.append(rule)
ceo.greet(emp)
vbox = QtGui.QVBoxLayout()
loop = asyncio.get_event_loop()
network.updateWeights()
4 - 1.982109 - 0.770861
y_train = np.random.randn(N)
item = models.ForeignKey(Supplier)
b = [4, 5]
th, im_th = cv2.threshold(im_in, 200, 255, cv2.THRESH_BINARY_INV)
key = pickle.dumps((args, kwargs))
string
draw.text((0, 0), ShowText, font=font)
instance = MyModel.objects.get(myargs)
drives = []
vcurve = numpy.vectorize(curve, excluded=set([1]))
df2
n += 1
y = yaml.load(fString)
keys = self.get_index_keys()
nosetests - h
print(len(lines))
results[l] = [p for p in product(range(1, min(l), 1), repeat=10)]
i += 5
server_cert = self.sock.getpeercert()
words = {}
print(item)
current_locale = locale.getlocale()
print(foo)
date = matches[0]
out.append(count)
OC = doctest.OutputChecker
val[key, value] = 1
db.drop_all()
df = df[df.runs == 0]
indata[i][j] = 1.0
serialized = pickle.dumps(a, protocol=0)
back[:] = 255, 255, 255
self.cache[args] = self.func(*args)
leg = plt.legend()
Py_DECREF(pValue)
data = np.random.random((50, 50))
backends_dir = os.path.dirname(matplotlib.backends.__file__)
VAR1 = config.CONF_VAR1
args = p.parse_args()
trans_neg = df.amount < 0
m_to_N[:, (0)] = -np.arange(1, n)
abs(left - rite)
uniq = np.unique(struct)
print(list(filterlines(prefixes, lines)))
net.ipv4.conf.all.rp_filter = 0
t = numpy.linspace(0, 4 * numpy.pi, 20)
mystring = mystring.strip()
p.join()
y1 = data[:, (1)]
plt.ylim(-2, 2)
node.add_child(tree_builder(child, level=level + 1))
2 * asin(min(1, sqrt(a))) * radius
random.shuffle(sequences)
list = yaml.load(string)
b = temporary_expr_result
surf = ax.contourf(X, Y, Z, 8, cmap=plt.cm.jet)
f
process = subprocess.Popen(stdout=pipe, stderr=pipe, *popenargs, **kwargs)
b = np.random.randn(K, K)
op_groups = itertools.product(operators, repeat=groups - 1)
sign(x) * math.sqrt(math.sqrt(a2 * a2 - a1 / a) - a2)
all_lists
r, c = np.where(games_played != 0)
make_nested(values[l[0]], l[1:])
plt.imshow(data)
print(i)
RespDict = json.loads(JSON_Datalist.content)
next(c)
print(K[-N:])
conf = config.current_conf()
a.f_locals.update(kw)
dirpath = os.path.abspath(sys.argv[0])
plot = []
L = list(range(10, 21))
plt.show()
fit = df.apply(lambda x: d[x.name].fit_transform(x))
db = flask.ext.sqlalchemy.SQLAlchemy(app)
a = list(range(20))
new_t = np.linspace(min(t), max(t), 80)
mail_admins()
line1.set_data(x, y1)
getLogger = loggerDecorator(getLogger)
d.addCallbacks(result, fail)
convertFile(filename)
x = SimpleClass
flann = FLANN()
self.readonly = True
start = i - 1 - match[i - 1]
x1, x2
self.__values.insert(index, value)
print(res.x)
process_list = get_list.s(10) | dmap.s(process_item.s())
point_in_plane = np.array([a, b, c]) / vector_norm
u, s, v = svds(hstack([A, b]), k)
print(errors)
c = []
solve(equations)
data = ListField(StringField())
n = b.shape[0]
width = (pos[1, 0] - pos[0, 0]) * scale_x
x = 0
md5 = hashlib.md5()
probs = df.as_matrix()
previous_line = current_line
plt.xticks(y_pos + width / 2, titles)
array[i] = int(Math.random() * N * N)
df = df[df.v1.ne(df.v2)].reset_index(drop=True)
st = np.sqrt(s)
a + b
l.append(i)
e_len = np.sqrt(e_x ** 2 + e_y ** 2)
all(c in allowed for c in mystring)
func(dom)
self._values[key] = value
result = []
assert type() is xxxx
downs.append(translated[chars.index(elem.strip())])
z = bar(x)
name = ndb.StringProperty()
yes, no = [], []
main()
curdoc().add_root(layout)
value_set = str(item[0:])
fig.add_axes(ax)
insp = reflection.Inspector.from_engine(db)
cache[lookup_value]
cache.clear()
new = []
y = vor.vertices[index, 1]
user = pwd.getpwuid(uid)[0]
arg = {a: 1, b: 2}
velcro.pendown()
start = time.time()
pbar.update(self.bytes)
Foo.bar = bar
document.mozCancelFullScreen()
start = time.time()
output = set()
result = sum(map(Counter, dictList), Counter())
A = np.zeros(10, dtype=np.int64)
upload_proc.join()
proc.stdin.write(ByteBuffer)
print(book.price)
widget.bind(event, callback, add)
a
data = [1, 4, 5, 6, 10, 15, 16, 17, 18, 22, 25, 26, 27, 28]
sleep(1)
self.setMinimumHeight(docHeight)
arr[i] = 1
n = len(args)
table = {}
sess = self.session_store.get_session()
arr = np.array(a)
connection.select()
results = []
cm.ax_heatmap.set_position([hm.x0, hm.y0, hm.width * 0.25, hm.height])
filtered_data = list(filter(filter_func, data)).lower()
print(myModule is myPackage.myModule)
CGWarpMouseCursorPosition((x, y))
cv2.line(frame, meas[i], meas[i + 1], (0, 100, 0))
win = gtk.Window()
abspath = os.path.abspath
title = db.StringProperty(required=True)
+game_score / total_hits * 0.2 + game_score_per_life / hits_per_life * 0.1
root = ast.parse(code)
shom_im(cir)
rows = []
parser.print_help()
page = urllib.request.urlopen(url)
b = a[np.mod(ii, a.size)]
Base.__sa_instrumentation_manager__ = ReadonlyClassManager
a & 1 == 0
t = scipy.acos(z / r)
self.remove_pt((event.xdata, event.ydata))
something
flag, frame = cap.read()
new_text = list(text)
print(regex_test.timeit(100))
Point(-self.x, -self.y)
s.starttls()
display.stop()
df1.columns
ranked.append(sorted.searchsorted(item))
i += 1
t = requests.get(url2, cookies=r)
main()
objects = MyModelManager()
line = source.readline()
column_editable_list = column_list
print(i, j, list_str1[i])
minList = []
r = np.random.uniform(low=0, high=1, size=n)
btns = self.findChildren(QtGui.QPushButton)
y = Decimal(10) ** (x - deci_x + Decimal(n) - Decimal(1))
min, max = max, min
item[j] = prev_item + float(j + 1) / item_length * difference
renderWindowInteractor.Start()
ca = CA()
func = validate_inp(func)
self.button.clicked.connect(self.on_button_clicked)
total = -total
print(processed_rows)
f2(a)
groups = df.groupby(pandas.cut(df.a, 10))
points[:, (2)] = np.take(z_p, zi)
out = [next(it)]
zipped = zip(*list2)
x = math.sqrt(-2.0 * math.log(y))
(sum(np.diff(sorted(l)) == 1) >= n) & all(pd.Series(l).value_counts() == 1)
a.print_x.__func__(b)
filtered = [(h, col) for h, col in zip(original_header, row_major) if any(col)]
True if month >= 8 and month <= 12 else False
deletelistener1
coef = pca.transform(i)
preferred_name = models.CharField(max_lengths=100)
yum(v)
shift = max([t.get_window_extent(renderer).width for t in legend.get_texts()])
fake_csv = StringIO.StringIO()
poll.register(p1.stdout)
lattice[:, :] = vSite(init_arry)
_create_unverified_https_context = ssl._create_unverified_context
L2.sort(reverse=True)
attr = Desc()
f()
r = git.Repo.init(repo_dir)
res.flat[idx] = np.repeat(arr, rep.flat)
print(newhash)
list(testgen(1))
group = parser.add_mutually_exclusive_group()
A = numpy.array([[1, 2, 0, 1], [1, 0, 1, 2], [0, 1, 2, 1], [1, 2, 1, 0]])
True
lookuplist[k] = v
category = models.IntegerField(choices=CATEGORY, blank=True, null=True)
index = d * (d - 1) / 2 - (d - i) * (d - i - 1) / 2 + i + 1 - i - 1
self.body = msg.Body
a.iloc[:, (0)]
__metaclass__ = M1
final_file = csv.writer(output_file)
res_list = [[] for _ in header]
not self.is_alive() and self._queue.empty()
print(overlaps)
np.random.seed(100)
Y = hdfpivot.index.values
q[:maxrows] if maxrows else q.all()
value += 1
dbConnection = MySQLdb.connect(**kwds)
df
([lower(x) for x in tuple],) + tuple
names = collections.defaultdict(counter)
res
int(idstr[2:])
segments = np.concatenate([points[:-1], points[1:]], axis=1)
executor = ThreadPoolExecutor(max_workers=4)
print(x)
a[start:stop:step]
controller.signal(Signal.NEWNYM)
yi = np.arange(0, len(grid[:, (0)]), 1)
hypline, refline = next(z)
dict_obj = model_to_dict(obj)
df.formatted_dt.dt.date.map(str) + df.time.map(str).str.rjust(9)
max_term_len = min(len(words), max_words_per_term)
gcs_data.gcs_serving_url(dyn)
y_idxs = [(1, 1), (0, 1), (1, 0), (0, 0)]
string_dict[letter] = test_string.count(letter)
a = Dog()
f = window.GetFont()
recall_accumulator.append(precision_recall_fscore_support(y_true, y_pred))
print_nested(v, indent + 1)
new_root = etree.Element(root.tag, nsmap=nsmap)
print(result)
new_lines = []
results = json.loads(search_results)
needed_value = value_array[first_ungrouped_idx]
out.append(q.get(timeout=0.2))
print(parse_qs(s[2:]))
x = np.concatenate([x1, x2])
ex = text.get_window_extent()
col_lenth = len(x)
self.value = value
s = Session()
wrapper
self.name = name
adder_w = partial(adder, y=5, z=10)
R_ = R1.copy()
x, y, z = pts.T
fcs = SHFOLDERCUSTOMSETTINGS()
printer.pprint(object)
x = np.random.rand(5)
b = [4, 5, 6]
server.close()
groups = []
t = t + (1,)
pl.imshow(z0 - z1, extent=[-5, 5, -5, 5])
x = np.zeros(size)
options, _ = parser.parse_args()
last = bins[-1]
data = JsonData()
dst = cv2.inRange(img, BLUE_MIN, BLUE_MAX)
composed = lambda x: x
query
e.preventDefault()
parent_mock = MyMock()
Test.A = []
tempj = empty(M, dtype=int)
output = []
levels = 90 * (0.5 + (np.arange(N) + 0.5) / N)
new_products.add(x)
False
idx = np.nonzero([(type(i).__module__ == np.__name__) for i in list1])[0]
copy_list = org_list[:]
simplejson.dumps(value)
self.map = {}
plot(draw, img, x, ipart(intery) + 1, fpart(intery), col, steep, dash_interval)
THREE
temp_dir = tempfile.mkdtemp()
self.list[i] = v
df1 = df.ix[:date, :]
True
isinteger(foo)
print(ham)
path = [tuple(e) for e in path]
distance = sin(lat_a) * sin(lat_b) + cos(lat_a) * cos(lat_b) * cos(long_diff)
1 - 0.051282
a1, a2 = a1 + (a2 if 9 < int(s[i - 1:i + 1]) < 27 else 0), a1
l.setLevel(loglevel)
q = Queue()
a.extend(sorted_s)
img = plt.imshow(haha)
name = models.BooleanField(default=False)
x.pack(anchor=W)
around(1.5)
menMeans = 8092, 812, 2221, 1000, 562
fcntl.lockf(fp, fcntl.LOCK_EX | fcntl.LOCK_NB)
cnct.index = idx
i = j - 1
pruned_d = get_pruned_dict(d, exclude)
not bool(set(sympy.factorint(d, limit=10).keys()) - {2, 5})
url,
True
result = pool.map(read_file2, files)
pygame.draw.line(s, (0, 0, 0, i * 4), (0, i), (64, i))
pid = int(stdout.readline())
self.thread = QThread()
rtn_words = []
np.text
c = [random.randint(0, 20) for x in range(100)]
a = foo()
json.dumps(j.__dict__)
procs = []
shift += 8
cursor = dbapi_conn.cursor()
entry.pack(padx=5, pady=5)
MyFancyNumber(5) * 0.5
pnt = geometry.Point(*map(float, i))
x.remove(item)
model = Game
h.open(1118, 2048)
mask = (a[:, (np.arange(1, a.shape[1], 2))] < 0).all(axis=1)
ar = np.random.rand(20000).reshape((100, 200))
print(a, b)
print(item)
corpus[pos_left:pos_right].strip(), match_value
print(my_dict[map])
s = Series([True, True, True, False])
a.view(float)
iterables = {i: [next(it), i, it] for i, it in enumerate(iterables)}
df2 = pd.DataFrame(np.random.rand(10, 8))
Found(array([45.21292244]), array([101.85151772]))
formats = [dt.fields[name][0] for name in names]
packet = rand(100, 100)
collection = db[self.question_collection]
r = src_session.query(src_class).all()
L2 = [i for i in L if i in L2]
x = random.choice(l)
ca_list.append(ca)
output = [[]]
start = datetime.datetime.now()
self.__class__, args
LOGGER = log4jLogger.LogManager.getLogger(__name__)
print(str(now.replace(microsecond=0)))
convert(values)
reader = csv.reader(csvfh)
parse_object.path
print(d)
result
PyErr_Print()
K = float(k) / (n - 1)
res = {}
fullSuite = unittest.TestSuite([suite1, suite2])
s = StringIO()
loop_bool = False
iris_df = pd.DataFrame(iris.data, columns=names)
keys = list(a.keys())
df_ = df.apply(threshold).astype(int)
False
rs = p.imap_unordered(do_work, range(num_tasks))
print(df)
new = {}
print(list(filter(str.istitle, l)))
print(da_y.T)
print(redirected_output.getvalue())
plt.figure = newfig
df7 = df.ix[:, 72:84]
node_data[key] = node_to_dict(node[key], {})
simulation.mocked_update = MethodType(make_mocked_method(), simulation)
words = [s.strip() for s in f.readlines()]
x = np.arange(0, 10, 0.01)
route.handler_adapter(request, response)
processRecursive(ftp, name)
cv2.rectangle(image, best_fit_point, bottom_right, (255, 255, 255))
self.clients = []
x1 = data[:, (0)]
result = a[::blockLengthX, ::blockLengthY]
pickle.dump(model, fout, protocol=pickle.HIGHEST_PROTOCOL)
a[ix_(Xinds, Y2inds - 1)]
counts = df[col].value_counts(normalize=True)
scores.update({key: int(score)})
testB.py
B = Y.imag
new_names
self.maxidx
num1 = int(num1)
id(b)
len(p.__code__.co_varnames)
local_datetime = datetime.datetime.now()
raise
old_open(fname, *args, **kwargs)
print(url1)
naughty.sort(key=lambda x: x[0])
writer = csv.DictWriter(f, fieldnames=fieldnames)
label_name = s[0]
self.check_migrations()
url = sys.argv[-1]
exec(execlist)
root.append(make.to_element())
users = list(q1) + list(q2)
fig = plt.figure()
clf.score(digits.data, digits.target)
blockbounds = tuple(c[j][idxs[j]] for j in range(bpa.size))
df.drop(col_dict[col_n_to_drop], 1)
r = {}
timeout_obj = mymethod()
ret, frame = cap.read()
splited_list.append([])
raise e
f.write(res)
fly.rect.left = hit.rect.right
some_long_process()
answer0 < -vapply(split(answer0, names(answer0)), sum, integer(1))
start = datetime.datetime(2010, 1, 1)
p.nice(psutil.HIGH_PRIORITY_CLASS)
screen = display.screen()
out.append(custnumstr + df[0])
category = defaultdict(list)
f.fp._sock.fp._sock.shutdown(socket.SHUT_RDWR)
fa.append(g)
db = client.database_name
local_tz = utctime.astimezone(eastern)
pid = 4044
pcolor(arange(20).reshape(4, 5))
deleteout[-1]
ser = Series(arr)
val = set(df1.Name).intersection(set(df2.Name))
dispatcher_thread.start()
t = t + (2,)
send_to_rabbitMQ(items)
least_common_values(data, 2)
d = keybased_defaultdict(lambda x: x)
total = []
print(df, type(df))
max_distances = {}
deadline = datetime.datetime.now() - t
batch_request.AddUpdate(cell_entry)
yaml.load(s, Loader=yaml.BaseLoader)
realconn.set_isolation_level(0)
Blah()
distances[clust[i].id, clust[j].id] = distance(clust[i].vec, clust[j].vec)
points = np.random.random((numlines, numpoints, 2))
groups = groupby(sorted(iter(d.items()), key=key_fu), key_fu)
cls.x
i = 0
c = a - b
a, b, c
subset.isin(myList)
i1 = iter(a)
app = Flask(__name__)
plt.imshow(c)
output.write(outputStream)
type1 = mime_type(blob_info.filename)
0
t = dt.datetime.strptime(e, fmt)
getrefcount(h)
HSV = np.dstack((H, S, V))
data2[idx]
queryset.filter(isClosed=True)
original_x = self.x
tree = ast.parse(src)
temp
output = p.map(getLocalResults, [(x, i, j) for x in range(i, j)])
dd = np.diff(ii)
-gophers
d[i] = []
hash(object())
self.f.setnchannels(nchannels)
self.mapping = {}
id = db.Column(db.Integer, primary_key=True)
colors[i], colors[-1] = colors[-1], colors[i]
filedescriptor = urllib.request.urlopen(req)
self.set(value)
phone
self.log = {}
self.callback = callback
table2 = pd.read_csv(f)
a = b[:]
tot = []
vectors / norms
obj = obj.b or obj.c or obj
self.md5.update(str(type(v)))
title = models.CharField(max_length=64)
x & 1, x >> 1 & 1, x >> 2 & 7, x >> 5 & 7
print(collector.data)
fig2 = plt.figure(figsize=plt.figaspect(0.75))
sess = tf.Session()
StopAdminForm
sys.exit(main(sys.argv))
y0 = [f0(x) for x in xs]
b = np.random.rand(2)
CGEventSetType(eventRef, kCGEventMouseMoved)
print(2 + a)
L.append(a)
BOOST_PYTHON_MODULE(example)
self.delete(saved_name)
print(lst[index])
print(a, b, c)
scipy.special.btdtri = my_btdtri
test_Dict[obj] = obj
fig, ax = subplots(1, 1)
arr = np.array(ptr).reshape(height, width, 4)
axis2 = fig.add_subplot(212)
+message_text
req = mech.click_link(next_link)
c = conn.cursor()
print(diff)
idx = i + j
self.windows.append(ChildWindow())
thefile.seek(x, 1)
index = len(line) - len(line.lstrip())
args = [list(range(0, 11))] * i
body = models.TextField(max_length=100)
result = m.group(1) + m.group(2)
inspect.getmembers(cols)
f.save()
lastgroup = match.lastgroup
loop.call_soon(loop.stop)
items = map(make_some, dl)
x_da = np.arange(0, 5 * barwidth, barwidth)
yaml.add_representer(literal, literal_presenter)
surf.downloadKeypoints(keypoints2GPU, keypoints2)
surf.downloadDescriptors(descriptors1GPU, descriptors1)
surf.downloadDescriptors(descriptors2GPU, descriptors2)
strategy()
result.append(strings[prefix])
arr = []
dtype = chunk.dtype
result
seq = [(k, len(list(g)) >= 2) for k, g in grp]
mean_list.append(sum(filtered_list) / (len(filtered_list) * 1.0))
total += count(o)
X[np.ix_(mask1, mask2)]
unicode_result_unchanged(str)
grps = df[s].gt(df[e].cummax().shift()).cumsum()
precision_score(y_true, y_pred, **kwargs)
len(h)
sleep(delay)
integer_number = int(integer_number)
CONSOLE_ARGUMENTS = parser.parse_args()
rows = cursor.fetchall()
print((list_number1, list_number2, inters))
pool = Pool(processes=4)
a = 1e-21
print(line.translate(full))
c.invert()
paths = []
result = [dict(zip(desc, line)) for line in curs]
column_names = [desc[0] for desc in cursor.description]
q1 = session.query(Baz.foo, Quux.bar).join(Quux.bar)
print(thing.otherstuff)
sleep(0.1)
interpolated_x = np.linspace(x.min(), x.max(), new_length - len(x) + 2)
sum(y, dtype=float64)
test = json.dumps(test)
d[k] = str(v)
repr(thestring)
df
a, b, c, (d, (e, f)) = v
table.create(dest_engine)
fig = plt.figure()
curses.wrapper(Main)
print(dict)
print(y.eval())
z = 1
list(map(unshared_copy, inList))
not_prime = [False] * limitn
print(t)
plt.legend(loc=0)
memostirling1[n, k] = (n - 1) * stirling1(n - 1, k) + stirling1(n - 1, k - 1)
arr = [0, False, False, 0, False]
sys.exit(1)
x, y = np.mgrid[-2:2:0.1, -2:2:0.1]
print(result)
sum(map(lambda xy: xy[0] == xy[1], zip(a, b))) >= 2
result = next(nums)
IMC.important_global_constant = 1
r = follow_redirections(s.get(url), s)
current_node = current_node.children[letter]
ax = plt.axes(xlim=(0, 2), ylim=(-2, 2))
f = -2 * x ** 2 + 4 * x
gradient = cmap(np.linspace(0.0, 1.0, 100))
s = s.lower()
plot(x, p)
o1.two()
d.replace(year=d.year + years)
[unicodedata.name(c) for c in a]
output
False
myfruits = {}
False
already_in.update(set(perfect_corr))
print(repr(line))
up.rstrip()
print(os.fstat(0) == os.fstat(1))
today = datetime.datetime.today()
s = list(iterable)
t.stop()
args.foo
self.view[0] += 1
print(df)
upper_red_1 = np.array([180, 255, 255])
vals = df.values
ikey, keyv = specifiers[0]
obj_list
print(l)
print(i)
func_I_want()
print(df_a)
agencies = Agency.query.all()
name, ext = os.path.splitext(upload.filename)
REBUILD = True
result
cliques = [clique for clique in nx.find_cliques(G) if len(clique) > 2]
newID = c.lastrowid
time.sleep(0.1)
ModuleName.sdrts_reverse_burst_ff()
bytes([first])
self._dictionary[key] = item
idx = [g[0] for g in grp]
self.length
scale = 10 ** (-np.floor(np.log10(np.max(f1))) + 4)
key.verify_final(b64decode(signature)) == 1
writer.add_summary(valid_summ, step)
print(myModule.variableY)
max_score = 0
setattr(args, self.dest, values)
prev = word[idx - 1]
d = self.__dict__.copy()
self.results.put(self.items)
substring + s[:-amount]
line = self.file.readline()
y = sin(t)
rw, gw, bw
s.upper()
drawContours(im, imContours, i, color, 2, 8, hierarchy, 0, Point())
user = request.user
data.append([ele for ele in cols if ele])
loc = df1.index.get_loc(t)
WriteInts(a, filename)
func()
b = numpy.arange(n2)
buf = fp.read(1024 * 8)
data.shape = shape
new_d = []
url_lists = [get_urls_from_response(response) for response in responses]
numbers_in_nxn = random.sample(list(range(n * n)), k)
s
serializer.serialize(queryset, fields=fields)
list_1 = list(range(1, 11))
d.update(frame.f_locals)
api = Api(app)
group.members.all()
data = iter(data)
max_only.append([name, group.occurences.max()])
sys.exit(0)
c
widget.setLayout(QVBoxLayout())
func(args[0], request, args[1:], **kwargs)
label = StringField(required=True)
bins = []
colors = 100 * np.random.random(N)
response = session.get(download_link)
archivename = sys.argv[2]
a[1, i[(1), :]]
y = np.arange(100)
show(s1)
s
show(p)
proxy.supervisor.getState()
MetaClass(cls.__name__, cls.__bases__, cls.__dict__)
v2 = {x2 - xA, y2 - yA}
batch_size = 1000
zip(prevs, items, nexts)
{{language.name_local}}({{language.code}})
s = socket.socket(family=socket.AF_INET6)
ldawordindex = {}
w = world.World()
is_efficient
d[el.tag] = map(xml_to_dict, children)
ypxl1 = ipart(yend)
tree = et.fromstring(xmltext)
bins = [-1, 0, 1, 5, 10, 15, 100]
poller.register(work_receiver, zmq.POLLIN)
print(getsource(f.bar))
new_text = []
print(record.alignments[0].hsps[0].score)
bill = models.BooleanField(db_index=True, default=False)
np.concatenate(([False], a[1:] == a[:-1]))
grp = data.groupby(by=[data.datetime_col.map(lambda x: (x.hour, x.minute))])
df
shop_name = models.CharField(max_length=200)
num
y = np.linspace(-1.0, 1.0, 100)
readline.write_history_file(historyPath)
dW[:, (jj)] += XX[(ii), (jj), (ii), :].transpose((2, 0, 1))
inner()
base64_encoded = base64.b64encode(data)
y = map(len, a)
diagonal = np.diagonal(view, axis1=0, axis2=1)
strides = sz * np.array([w * bh, bw, w, 1])
bool(self.rematch)
channel, views
ValidateFileButton.ng - click()
ignore_list
ac = [(wx.ACCEL_NORMAL, wx.WXK_LEFT, widget.GetId())]
w = csv.writer(outfile)
args[0]._copy_attrs(self)
result = {}
sequence[1:len(sequence):1] == sequence[1:len(sequence)] == sequence[1:]
album_names = set({song.album for song in self.allSongs})
Py_DECREF(pModule)
num
print(Foo.get_counter())
u = uuid.uuid1()
test.sin_2_.argtypes = [POINTER(c_float)]
count = defaultdict(int)
d = tempfile.mkdtemp(*args, **kwargs)
descr = line[1:].rstrip()
marker_type._marker_type_key
my_dict = dict.fromkeys(keys, [])
df
install.finalize_options(self)
t = nested_find(x, e)
foo.bars.add(target_pk)
N(h, 1)
self.items.__repr__()
fd = _multiprocessing.recvfd(self.child_pipe.fileno())
a = Zd()
d[lastKey].append(i)
allow_null = True
z = clip_z_data(z)
name()
cred.refresh(http)
a == b or isnan(a) and isnan(b)
d[1].append(4)
path = sum(hypot(*d) for d in diffs)
print(list(iter_longest(origin, known_words, 5)))
lock = Lock()
self.path = [(0, 0)]
1
self.point.remove(p)
alllists = []
x_big = np.linspace(1, 1800, 2000)
fly.rect.top = hit.rect.bottom - 1
counts = numpy.bincount(a)
self.NUMBER_OF_PROCESSES = 5
s = int(s)
self.simulRunner.stepIncreased.connect(self.currentStep.setValue)
parameter = argv[1]
params_list = re_param.findall(url)
cropped.save(filePath)
self.name = name
(datetime(1992, 8, 27, 8, 0, 48), 28.2),
x = []
processes = [Process(target=child) for _ in range(10)]
identify, 1
id(10 + 4j)
suite
val1 / val2
A = 2 / (r_max * r_max - r_min * r_min)
X = scipy.randn(10, 2)
result_utc_datetime = local_datetime - datetime.timedelta(hours=UTC_OFFSET)
watchdog.stop()
df[df == 0] = np.random.choice(np.arange(2, 100), replace=False, size=df.shape)
idx = list(range(len(s)))
self.gridLayout = QtGui.QGridLayout(self.centralwidget)
SpectralClustering(n_clusters).fit_predict(lena)
doc = LH.fromstring(htmlData)
tree = etree.parse(StringIO(s))
d[0] = d[0][1:]
x = np.arange(-2 * np.pi, 2 * np.pi, 0.1)
zip_longest(iterable, it_ahead, fillvalue=sentinel)
self.fp.write(generated)
trainX = numpy.reshape(train, (train.shape[0], 1, train.shape[1]))
print(p.value)
Line2
ind_vals = np.array([0, 2])
i = randrange(len(s))
itemBank = []
dx = [0, 0, -1, -1, -1, 1, 1, 1]
True
td_reconstructed = reconstruct_timedelta(str(td))
i = np.arange(nrows).reshape(-1, 1)
last_index = tf.shape(output)[1]
nmake
user.username = hash(user.email)
token = g.github_token
fig1 = plt.figure()
wep = 1 << 1
4806
new_shape.insert(axis, length)
dis.dis(a[2])
unq_idx = np.split(sort_idx, np.cumsum(unq_count))
True
iter(self.vals)
l2 = [(t, value, 2) for t, value in b]
print(set_of_sets)
res
list1
root = tree.getroot()
interpreter = PDFPageInterpreter(rsrcmgr, device)
cleaned_data
c = np.array([6.0, 7.0])
image._restrictSize(1 * inch, 2 * inch)
MyWidget()
x + y
client = paramiko.SSHClient()
run(flow, storage)
out = out.reshape(X.shape)
a = df.x.values
circular = []
ax.set_xticklabels(genres, rotation=80)
mix_wave_files(output_wave_file, input_wave_files, args.buffer_size)
y = np.linspace(1, 10, ndata)
self._pixels = [(x, y)]
to_neuron.inputWeights.append(self)
cls._count += 1
DataList = []
last_friday_at_16 += one_week
common_settings.py
res = sm.OLS(y, X).fit()
magnitude += 1
ax = fig.gca()
print ()
pid, master_fd = pty.fork()
print(frame.f_back.f_locals)
b = []
an = ax.annotate(s, xy, alpha=0.0, xytext=(0, 0), textcoords=an, **d)
abs_path = os.path.join(dir, name + suffix)
NotImplemented
Xf[0] = Yf[0]
print(output)
cnt = Counter(mywords)
table = [(str(x), str(f(x))) for x in mylist]
lastMonth = today.month - 1 if today.month != 1 else 12
xpxl1 = xend
block = a[base[:, (np.newaxis)] + row * size, base + col * size]
x1 = numpy.ones(N) * 1000.0
sock.settimeout(self.timeout)
extracted_values = defaultdict(list)
user = ReferenceField(User)
start = date(2012, 12, 11)
__all__ = []
foo = Foo()
last_index = 0
mean, variance = tf.nn.moments(x, [0, 1, 2])
cursor = realconn.cursor()
p.join()
a[i, i] = 1.0
scores = model_selection.cross_val_score(clf, X, y)
retries -= 1
y = sum(x + 1j for x in z)
[value]
get_ = datetime.timedelta(int(worksheet.cell_value(row - 1, i)))
print(user.name)
WSGIPythonHome / opt / python / run / baselinenv
files_grabbed = []
df = pd.DataFrame(X)
s[i:i + 4] = []
django_request = Dummy()
instance.save(request=request)
_, im_binary = cv2.threshold(im, 50, 255, cv2.THRESH_BINARY)
stream_index = []
False
m = max(d1.values())
in_db = dbf.Dbf(filename)
next(build_generator(a, v * 2, start, mid))
l.sort(reverse=True)
dicto
self.long_running_thing.moveToThread(self.thread)
self._foo = value
fig = plt.figure()
self.est = est
popt, pcov = curve_fit(func, x, yn)
Syy = Syy + y * y
C = A.dot(A.T.conjugate()) / norm
print(arr.flags)
datetime.utcfromtimestamp(local.timestamp())
points_up = np.copy(points_center)
b2.append(lines[1])
a + str(foo * bar)
numbers.append(i)
process_mock.configure_mock(**attrs)
it = iter(iterable)
Counter(str1) == Counter(str2)
conn = condb()
via_cc(df1)
self.coords += np.random.random(self.coords.shape) - 0.5
circle_exp2imp_2d
circle_imp2exp_2d
circle_llr2imp_2d
ext.domain
x.data = np.log(x.data)
print(l)
N = int(eval(input()))
df = DataFrame(randn(10, 4))
sel.open(response.url)
a[r[:, (0)], 0] = r[:, (1)]
print(sum)
self.srv.serve_forever()
file_string = file_.read()
c = BitArray(hex=input_str)
amplitude = numpy.fft.rfft(signal.astype(numpy.float))
q = Session.object_session(self).query(Collection)
mask = np.all(np.isnan(arr) | arr == 0, axis=1)
mybytes = bytearray()
bin_widths = bins[1:] - bins[:-1]
c[:, :, (2)] = 255
list(filter(type(seq).isdigit, seq))
print(basis[0](1))
math.pi * self._x * self._b
self.end_headers()
7 - Dec - 2016
r2 = np.random.rand(4)
print(err)
PyEval_SaveThread()
tbl[seq.length()][subseq.length()]
self.is_running = True
indices = defaultdict(list)
g.series(y, 0)
print((option, value, type(value)))
first, second = item, first
t = TriangleButton()
axRes = plt.subplot(gs1[(7), :], sharex=axF)
self.br = br
number = 1
a, b = 1, 2
a[[1, 4, 8]]
show(p)
asyncio.ensure_future(self.update())
a = A()
run_starts, = numpy.where(difs > 0)
digit_product()
SUDO_USER = martin
tb.send_photo(message.chat.id, img, reply_to_message_id=message.message_id)
l = {}
bad_request(error.message)
dx = (b ** 2 - hc ** 2) ** 0.5
self.item_to_position[item] = len(self.items) - 1
sample_weight = numpy.ones(len(values))
appengine_config.py
R = np.sqrt(X ** 2 + Y ** 2)
n_to_N = spdiags([n * diag, -nrange[-1:0:-1]], [0, 1], n - 1, n - 1)
c = values.cumsum() - ALLOWANCE
count = 0
data = conn.recv(100000)
pb = pb.get_from_drawable(w, w.get_colormap(), 0, 0, 0, 0, sz[0], sz[1])
content = f.readlines()
self.tree = ttk.Treeview()
a = IntVar()
max_char = sentence[-1]
tmp = tmp.reshape((1000, -1))
response_or_exc
myDict = {}
max_index = row.indices[row.data.argmax()] if row.nnz else 0
config.read(location)
sz = len(s)
shift(reverse(sentence))
object_values.append([])
l.popleft()
fig, ax = plt.subplots(1, 1, figsize=(9, 5))
instance = []
xy_source = np.mgrid[xmin:xmax + xres:xres, ymax + yres:ymin:yres]
values = sum(weights * features) + bias * weights.size
plt.plot(arange(0, 100, 10) + 1000, arange(0, 100, 10))
code = inspect.getsource(L)
lineNum = 0
d = defaultdict(list)
line = line.strip()
ast.NodeVisitor.generic_visit(self, node)
cls
output.read()
id(y)
smtp = smtplib.SMTP(server, port)
f.namelist()
idx = dist.idxmin(axis=1)
L = np.polynomial.legendre.legval(x, np.identity(deg))
resize(400, 400)
install_xxx()
local_time = datetime.now(timezone.utc).astimezone()
frame.Show(True)
fr[:nrow - 1]
self.first_name = first_name
bincounts[b] += 1
group = []
confint[i].append((np.nan, np.nan))
_1 + _2
bike = session.query(Bike).filter_by(bike_id=pk).first()
self.primes.append(self.candidate)
w.grid()
fig.tight_layout()
plt.title(titles[i])
timedelta(0)
ch += chr(int(b, 2))
f = FunctionDefinition(2, 4)
my_datetime = timezone.make_aware(my_datetime, timezone.get_current_timezone())
logits
bar = foo()
product = max(product, product * x, key=abs)
l = l + [1] * size
x_new, xi_new = normalize_x(x), normalize_x(xi)
self.connection_pool.disconnect()
a >> 2.0
nthreads = 2
st.t.interval(0.95, len(a) - 1, loc=np.mean(a), scale=st.sem(a))
chars.append(chr(x))
nums = split_odd_even(string_to_ints(numbers))
py2ri_orig = rpy2.robjects.conversion.py2ri
print(value)
buff = ctypes.create_string_buffer(length + 1)
id(df.columns)
result
x, y, w, h = cv2.boundingRect(cnt)
sys.excepthook = my_excepthook
d[field] = default_factory()
end = len(lst)
ax2 = ax.twinx()
print(partial_derivative(f, input))
self.image_data = read_png(image_path)
x = 10
X().wrong
self.count = 0
True
self.engine.createElement((0, 0), TriFader(states.SelectFileState), -240)
self.__d[attr]
print(marshal.dumps(a))
body = json.loads(body_unicode)
i = 1
print(a)
conn, addr = s.accept()
response = _real_view(request.user)
x, y, z
df2
inst2 = Test(5)
y_pandas.dtypes
candidates_to_remove.add(c[0])
BOOST_PYTHON_MODULE(A)
db_engine = create_engine(sql_url)
rule = app.url_map._rules[-1]
list(round_robin_odd(d, n))
myApp.run()
Counter(words)
totals = df.sum(1)
x.set(a)
delta(i) in {0, 1}
MAIN_SURF.blit(cl_surf, my_position_2)
x = 7
b = s.loc[s.notnull()].astype(int).astype(str)
C.__mro__
print(mm_obj[:20, :])
modules = []
output.close()
pdf.closed
print(data)
self._min_y = y
start_time = datetime.now()
print(kwargs)
tmp_dir = tempfile.mkdtemp()
self.confint = np.array(confint)
string_buffers = [ctypes.create_string_buffer(8) for i in range(4)]
df_w_ftr = temp_rdd.toDF(schema)
result = self.func(obj)
print(number // 2)
self.send(self.process_f(self.last_value))
print(mindiff, x2sort[mindiff], x1sort[mindiff])
result = [item] * (len(lst) * 2 - 1)
d = dict(zip(sorted(set(a)), sorted(set(a), reverse=True)))
result_length = 1 + sum(len(array) - 1 for array in arrays)
B = list(groups.values())
send_value = process(n)
l[0] += x
factory = protocol.ServerFactory()
self.stop_serving = True
n.hexdigest()
pts = Profile_Tag.objects.all()
add_subclass(PyTypeObject * base, PyTypeObject * type)
self.omega_l = omega_l
words = nltk.tokenize.word_tokenize(p)
a = arange(16).reshape(2, 2, 2, 2)
dc = wx.WindowDC(self)
radii = np.linspace(min_radius, 0.95, n_radii)
M.A
name = models.CharField(max_length=128)
border_elems(a, 2)
f = Foo(**d)
SOUTH = True
print(next(f))
falseList.append(item)
response
lis = str(list(s))
True
date = dt.datetime(1970, 1, 1, 12)
timesteps = np.empty(N, dtype=object)
val = np.intersect1d(df1.Name, df2.Name)
timeit.Timer(update).timeit(10000)
print(text)
path = os.path.dirname(os.path.realpath(__file__))
p2.wait()
df_b
f = random.choice([sys.stdout, sys.stderr])
ins = InsertFromSelect(temp, t.select().where(t.c.id > 5))
xmlResults = urllib.request.urlopen(MY_APP_PATH, urllib.parse.urlencode(params)).read()
strc_view = strc.view(int).reshape(len(strc), -1)
echo_func
tojoin = []
aQ = Queue.Queue()
type = blob_info.content_type
match = regexp.match(url)
user, ts = User.get_by_auth_token(user_id, token)
raise StopIteration
f = pylab.figure()
raise KeyError(str(key))
ZCAMatrix = zca_whitening_matrix(X)
ti = np.linspace(0, 1, num, endpoint=True)
legend = ax.legend()
head, tail = os.path.split(path)
fd = sys.stdin.fileno()
a = {key: a[key].item() for key in a}
p.join()
raise StopIteration
querier = connection.cursor()
new_data
k = n - k
p = np.array(p)
shared_queue = Queue()
print(i)
host = urlparse(self.url).hostname
trap - p
d2 = dict()
id(var2)
PyArray_ITER_RESET(it2)
c2.wait()
self.__storage = []
self.initialized()
n += 1
print(gcs_url)
queryset.filter(isClosed=False)
echo - n / path / goes / here | xclip
deletekwargs[key]
p, x = np.histogram(s, bins=n)
q = u.query
baz = models.CharField()
tot += a[i] * b[i]
h = ax.bar(ind, height, width, bottom=prevBar, color=color, label=label)
cmd.Cmd.__init__(self)
A = 1
prices.shift(1) / prices - 1
vals = np.zeros(max_bin - min_bin + 1)
grp1.head,
r.headers.get_content_charset()
A = 0
p = norm.pdf(x, mu, std)
n = 2
complement = [x for x in a if not b_count.decrement(x)]
b = 4 * np.random.randn(50)
plt.xticks(np.arange(0.5, 10.5), list(range(0, 10)))
request_token
print(mandatory_arg, optional_arg)
i += 1
print(a)
result = collections.defaultdict(list)
a = Foo(2)
self ^ other == 0
action_df.where(timestamp_parsed > cut_off).show()
print(nfp)
print(body())
shift_data[0] = shift
result.append(self.format_epilog(formatter))
raise IgnoreRequest()
pstack = []
obj = self.cb.GetClientData(self.cb.GetSelection())
x = Hal()
list(x)
hash(b)
DnaID = 1
sampleframe = im[j - w:j + w, i - w:i + w]
origin.push()
length = len(alist)
pid, status = os.waitpid(-1, 0)
self._whatever = whatever
stdout, stderr = p.communicate(data)
True
{6, 2, 0, 1}(maximal)
pymax
data = zip(list_one, list_two)
t_interp = linspace(0, 20, 2000.0)
span1, span2 = b - a, c - b
print(is_perfect_cube(65))
self.world
max_length = 10
self.timeout = timeout
i += 1
new_dictionary
vf = np.random.normal(size=N)
d = defaultdict(int)
cols_A = len(A[0])
result = 0
gss = gss_client.open(SPREADSHEET_NAME)
t = Thread(target=server.serve_forever())
h = scipy.signal.firwin(numtaps=N, cutoff=40, nyq=Fs / 2)
addresses.delete(synchronize_session=False)
results = pool.map(calc_kernel, torun)
many_vars.__code__.co_stacksize
b64 = base64.b64encode(output_s)
db2 = SQLAlchemy(app2)
user = current_user()
df[df < 0] = np.nan
train_as_dicts = [dict(iter(r.items())) for _, r in train.iterrows()]
s = socket.socket(socket.AF_PACKET, socket.SOCK_RAW)
google_dict = dict()
m = numpy.ones_like(V) * numpy.inf
i + 1
newY
df_nodupe = df[~df.duplicated()]
add_vector_to_vectors(b, a)
j = is_match.group(2)
output_array = np.array(data[output])
print(len(pairs))
a = np.linspace(c1, c2, 8)
time.sleep(0.005)
result = zip(probabilities, zip(*pairs)[1])
G = np.asmatrix(np.arange(N)).T
buffer.seek(0)
a.a = 2
count
prev = line
tocompare = datetime.time(tocompare.hour, tocompare.minute, tocompare.second)
json_dict
counts = dict()
q = given_q.union(received_q).order_by(Thank.date_registered)
get_func.__func__ is Client.get
print(x)
fileName = os.path.join(path, file)
c_ulong(i).value
app = current_app._get_current_object()
res = np.zeros_like(a)
datass = scipy.stats.ss(datam, axis=1)
qs.model = my_class
print(urlInUrl)
cache.set(key, result, timeout)
d = {}
submitButton.click()
source_image.readMetadata()
root = dealer.to_element()
fn()
w, x, y, z = end.hour, end.minute, end.second, end.microsecond
z = np.random.random(ndata)
pairwise = functools.partial(grouper, 2)
bb = np.load(f)
r = np.random.rand(20)
seqs.append(value[int(start):int(end)])
self.file = file
a = numpy.sum(x[5 - i:5 + i, 5 - i:5 + i])
setattr(random, f, our_decorator(getattr(random, f)))
hashed_passwd = bcrypt.hashpw(passwd, salt)
counts = Counter(ref)
self.__name = name
now = time.mktime(time.localtime())
skel_coords = []
zp = np.array([0.0])
fil = [True, False, True, False]
root.addHandler(fh)
x = np.linspace(0, 5, N)
range(min2, max2, step2),
counter.value += 1
remove = set()
p.get_lines()[0].get_xdata()
query = query.limit(page_size)
zone = models.ForeignKey(Zone)
self.b.go(self.url)
xx, yy = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]
tab2 = tk.Frame(root)
output[key] = value
connection.creation.create_test_db(verbosity, autoclobber=not interactive)
[pol(5) for pol in polynoms]
print(repr(sl[1:2]))
blahblah
head = list(islice(myfile, N))
count += 1
third = list(set(first) | set(second))
credentials = storage.get()
time.sleep(2)
proto = ClientFactory.buildProtocol(self, address)
list(range(start_val, start_val + 10))
img_hsv[..., (1)] = color_mask_hsv[..., (1)] * alpha
print(obs_val.firstChild.nodeValue)
letters = [a, b, c, d, e]
q_main_to_s1.put(POISON_PILL)
rv
B_s = scipy.sparse.lil_matrix(B)
[1.5, 5.5],
assert len(kwargs) == 1
self.__database = database
dfs = []
print(output.getvalue())
start += 1
print(df)
mask[thismask] = True
sess.run(accuracy, feed_dict={am_testing: True})
board = []
d[std::make_pair(0, 0)] = 0
dates_dict = defaultdict(list)
n = 4
order_dict = {color: index for index, color in enumerate(listOne)}
x = 1
allergies.append(d)
last = len(d) - 1
p2.drop()
page += 1
t1[0][0] = t1
logger = add.get_logger()
1, 10, 7
modified = models.DateTimeField(auto_now=True)
x = numpy.linspace(0, 20, 10000)
print(time.time() - timei)
print(s)
print(linenum)
raw_data = strip_ANSI_escape_sequences(formatted_data)
test_features = np.array(test_features)
y = [0, 0, 0, 0, 1, 1, 2]
result = []
stack = [[]]
chars[i] += 1
t1 = time.time()
ds.addSample((x,), (y,))
model = Article
result = Counter()
self._qnx
seed(42 if sys.version_info.major == 2 else 299)
output
fig, (ax1, ax2) = plt.subplots(nrows=2, sharex=True)
self.fp1.close()
c = np.empty((vals.shape[0], 2 * k), dtype=a.dtype)
next(self.gen)
st = set(b[0])
p1 = argparse.ArgumentParser()
wsbin = numpy.zeros((height, width), dtype=numpy.uint8)
{{login_form}}
result = []
[i, j], [i2, j2]
xmin, ymin = fig.transFigure.inverted().transform((xmin, ymin))
self.assertEqual(FooCycle.query.count(), 1)
Py_DECREF(key)
modified_since = os.path.getmtime(filename)
f.write(c.dump())
test = Test()
self.value = value
new_set = [[2, 7], [0, 1]]
worksheet = workbook.worksheets[0]
result = []
document.append(ul)
mask = np.diff(g) != 0
assert np.all(x[:, (0), (0)] == x_)
writer = csv.writer(string_buffer)
print(x + 10)
file_toload.readline()
consumer = oauth2.Consumer(CONSUMER_KEY, CONSUMER_SECRET)
platform.processor()
os.mkdir(outfile, perm)
n = int(n)
c.set_cipher_list(ciphers)
self.logger.debug(message)
a = np.random.rand(m, n, N)
irofile = iter(rofile)
mn1, mn2
writer.writerow(row)
d_slice = dists[:, (1)]
DateTimeEncoder().encode(object)
print(synsets)
q = q.filter(~Collection.accounts.any(id=self.id))
app.json_encoder = MyJSONEncoder
t1 = datetime.datetime.now() - t0
locale.nl_langinfo(locale.DAY_7)
self.text
idx = scipy.spatial.distance.cdist(lonlat, points).argmin(0)
currentStr
sine_list = []
print(datalines)
start_date += relativedelta(weekday=MO(1))
print(d)
lineage = defaultdict(list)
plt.plot(x_curve, f(x_curve, *popt))
z = np.vstack(np.hsplit(x.T, r / c))
a = []
sys.path.append(cwd)
next_ns = [x for x in next_ns if x >= 0]
m = a.shape[0]
request = urllib.request.Request(BASE_URL, headers=HEADERS)
self.do_open(self.getConnection, req)
wrapper
all(brute(n) == easy(n) for n in nums)
dfg.unstack()
print(a)
months = np.asarray(months) - 1
arr[i] = 0
ht = defaultdict(lambda : 0, ht)
self.data[slice]
dev.capabilities()[ecodes.EV_LED]
tree = html.fromstring(page.content)
response
df2.loc[0:1] = [list(s1), list(s2)]
module_under_test.do_something()
2 | A | ARG
a = np.random.rand(4, 4)
stdout = subprocess.PIPE,
RGB = hsv_to_rgb(HSV)
results = QuerySet(query=query, model=Members)
sys.modules = old_modules.copy()
od = OrderedDict()
False
mydocs_path = shell.SHGetFolderPath(0, shellcon.CSIDL_PERSONAL, 0, 0)
tornado.options.parse_command_line()
False
toolbar.insert(self.fileOpen, -1)
a = np.zeros(size)
plt.subplot(2, 1, 2)
subprocess.call(*popenargs, **kwargs)
f = math.sin(theta)
self.trace_lines
a.max()
x.discard(k * p)
dt.item()
print(len(repr(0.1)))
a = itertools.starmap(lambda x, y: x + y, zip(itertools.repeat(x), y))
imgstr.reset()
o.x = -2
self.x = x
print(result)
line = q.get_nowait()
pValue = myModule.doSomething()
sane_variable = variable.lower()
compute_and_plot(ax, alpha)
self.kernel.start()
p90 = np.percentile(a, 90)
a[1][0] = 4
remain *= 10
print((n, main(n)))
total += n
print(item)
print(kwargs)
l = [str(i) for i in list(range(10))]
x = child.expect(pexpect.EOF)
df
dump = simplejson.dumps(oldAnnotations)
x0 = x - math.log(x) / x
f(*tup)
freq = fft.fftfreq(len(spectrum))
json_dict[self._KIND1_PARAM] = self._reader1.to_json()
print(i)
remotezip = urllib.request.urlopen(url)
ladder = [x for x in range(5)] + [x for x in range(5, -1, -1)]
time.sleep(self._poll)
formatter.add_text(self.description)
y, x = np.mgrid[-2:2:21j, -2:2:21j]
outq = mp.Queue()
savepos = f.tell()
print(current)
avgDists = np.array([1, 8, 6, 9, 4])
a.append(n & mask)
l_y.append(s[k])
list_of_int[0] + list_of_int[1]
math.pi
chrome_options = Options()
y = tf.add(x, x)
d = {}
dayno, dayclock = divmod(ntp_time, 86400)
c1 = MyClass()
W
True
parser = argparse.ArgumentParser(add_help=False)
mask = ~np.logical_or(np.isnan(distancesArray), np.isnan(intensitiesArray))
d = c.fetchone()[0]
app.config_from_object(my_client_config_module)
snift = csv.Sniffer().sniff(afile.readline())
self.c = [C()]
array1 = np.array([10, 11, 200])
nick(df1).equals(jez(df1))
not_prime.add(f)
self.append(i)
table1 = pd.read_csv(f)
print(repr(data))
bottom = np.cumsum(data, axis=0)
d = {x[i]: i for i in x.index}
a = 0
matrix = [([WATER] * len(heights)) for _ in range(max(heights))]
l_1 = [1, 1, 1, 0, 0, 2, 6]
d[key(x)].append(x)
print(arr)
os.system(pathtowk.format(args_str, in_html_file, out_pdf_file))
print ()
d[x] -= 1
all_uniques = {elem for elem, count in list(element_counts.items()) if count == 1}
result = datetime.strptime(date, format)
fileobj.stream.seek(0)
x, y, _ = line.split(parse, 2)
event = QtCore.QEvent(QtCore.QEvent.Clipboard)
main()
mod_name, loader, code, fname = _get_module_details(mod_name)
year, month, day, hour, min, sec
print(result.eval())
multimedia = Multimedia.objects.filter(user_profiles_avatares__pk=pk)
S_ISDIR(ftp.stat(path).st_mode)
shutil.copystat(filename, tmp_file.name)
ret = f___(input)
assert isinstance(obj, MyClass)
lines[0]
kr += 1
out.close()
fig.colorbar(scat)
s.dropna().plot()
a.append(i)
dnf = list(itertools.product(*filters))
print(line)
local_port = int(local_port, 16)
data = norm.rvs(10.0, 2.5, size=500)
foo_2 = relationship(Foo, foreign_keys=[foo_2_id_1, foo_2_id_2])
a1, a2 = np.indices(ind.shape)
size = np.shape(inp)[0]
min = x
list_of_substrings = {}
b = np.random.rand(n, m, N)
ctxt = doc.xpathNewContext()
result_list = []
counts = collections.Counter(array)
foo = list(range(100))
lib = CDLL(lib_path)
callback()
abort(500)
parent = Node.objects.get(id=parent.id)
data = data.astype(np.float)
high = len(input) - 1
print(file_list.filename)
i = 2
ax = gca()
seq_len = len(seq)
b = [4, 5, 6]
integers_list = [4, 6, 1, 99, 45, 76, 12]
count += x
tmp_file.write(pattern_compiled.sub(repl, line))
image = Image.open(Image_Location)
s = Sound()
ops = [-1, 0, +1]
cwd = os.getcwd()
val
print(h[ds].value)
args = str(hash(frozenset(list(request.args.items()))))
print(change_in_memory())
p.append(procs)
s.close()
author_lastName = Column(String(20))
c = dot(u, v) / norm(u) / norm(v)
imgarr[0, 1] = 4278190086
total_months = lambda dt: dt.month + 12 * dt.year
parser.parse(tokens)
phase = np.exp(1j * np.dot(kpt, rpt_list.T)) / r_ndegen
F = (y.flatten() * x.flatten().reshape((y.size, -1))).flatten()
new_lists[index] = new_lists[index][:maxLength]
simplex = np.asarray(simplex)
info = lt.torrent_info(sys.argv[1])
foo(11)
y_sorted
wrapper
file.seek(file.tell() - removedLinesLength)
total = 0
print(URLless_string)
print(df1)
1
colors_array = list(matplotlib.colors.cnames.keys())
wxImage = wx.ImageFromStream(stream)
indexing_with_clipping(arr, indices, clipping_value=1)
print(a)
self.canvas = tk.Canvas(self, width=400, height=400)
paths.append(path)
plt.scatter(Xd[:, (0)], Xd[:, (1)], c=y)
ret, frame = cap.read()
lmdb_txn = lmdb_env.begin()
zelib.multiplier.restype = ctypes.c_float
response = make_response(data)
self.y = 1
br = mechanize.Browser()
result = []
enabled = yes
print(date)
model = Sequential()
item
map = {}
1
K = 1 / sqrt(N) / (sqrt(N) - 1)
thread.daemon = True
m.release(x, y)
next(new)
table.stack()
timezone(dep_dt[19:]).localize(dt)
list(range(start_val, start_val + 10))
kwargs = {}
activations.append(a)
p.dump(d)
test_ordered_dict[key] = random.random()
peak_type(index, *args, **kw)
self.visit(node.func)
img2 = numpy.asarray(img2)
cls.x
df
result.append(source[0:end])
total = float(sum(C.values()))
send_mail(self.email, error)
n
(sorts[length / 2] + sorts[length / 2 - 1]) / 2.0
prefix = os.path.dirname(os.path.abspath(__file__))
print(credentials.to_json())
jwt_encode_handler = api_settings.JWT_ENCODE_HANDLER
self._create_network()
writer = csv.writer(destination)
sms.DescrStatsW(a).tconfint_mean()
first_bigger_than_threshold1 = np.zeros_like(signal, dtype=np.bool)
setattr(namespace, self.dest, array_out)
sys.stdin = current_stdin
bothzero = (FS == 0).all(1).sum()
d
all_in_slices.append(slice(0, self.shape[dim]))
l = l + [0] * size
result
text = retstr.getvalue()
first_arrangement = [[int(x) for x in l.split()] for l in islice(d, 4)]
print(partial_k(f, 1, [0, 1])(10))
notifier.process_events()
primes.add(i)
foo(line)
print(common_to_all)
mask = dist[:, (0)] / dist[:, (1)] < r_threshold
cmd.stdin.write(kB)
True
array = QtCore.QByteArray()
lowest_weight = func(x)
s.update(words)
save_chat_id(message.chat.id, username)
Base = declarative_base(bind=engine)
Variance(X).var_expansion()
term.daemon = True
len({song.artist for song in self.allSongs})
starmap(Product, product(*list(items.values())))
serializer_class = UserDetailSerializer
os.chdir(new_dir)
os.path is not found
shard_ids = []
message = queue.get()
next(a)
ccompv = bwlabel(regmxv, 8)
candidates = []
index = mask.argmin(axis=1)
K.set_session(sess)
reader = csv.DictReader(open(thecsvfilename))
print(len(contours))
-sys.maxsize
print(tree[4])
self.mock_obj = MockObj()
b = a.astype(bool)
dataQ.put(v)
print(data.key)
s = string.lowercase + string.digits
stream.close()
clip_weights = tf.assign(weights, clipped, name=name)
authorization = DjangoAuthorization()
store.add_cert(value)
s.add(string)
self._waiters = []
time.time()
pctx = layout.get_context()
dall = {}
expr = Forward()
IRI = gateway.jvm.org.semanticweb.owlapi.model.IRI
f = foo
usec = 2748
cc.get_chart()
merge_dict(trg[k], v)
line = line.split()
files[linenum].write(line)
d[2](1)
count = Counter(a)
gs1 = GrandsonsItem()
line.set_dashes([8, 4, 2, 4, 2, 4])
index += 1
-python - dev
p = scipy.atan2(y, x)
f = np.arange(0, 1000)
print()
(a > 10).tostring()
m = np.max(n)
count += 1
spectrum = fft.fft(data)
reset_queries()
c.shape
y = np.empty(s.size, dtype=np.int64)
mock_response.status_code = 200
self._intersections[a][b] = 1
n, h, w, c = im_in.shape
deck.SaveAs(outputFileName, formatType)
fig = glumpy.figure((512, 512))
print(lst)
self.input
print(hex2(17))
x = x * sin(theta)
shop()
print((dest.is_default, dest.name))
df.timestamp = df.timestamp.factorize()[0]
b = Foo(a)
self.received_buffer.tell() != 0
Py_DECREF(func_name)
df.POINTS = df.DATA.rolling(4).max().shift(-1)
docs = [row.doc for row in rows]
print(i)
self.run_event.wait()
demo.load()
prefixes[w[1::-1]].append(w)
exec(code, execdict)
my_list.append(2)
input = PdfFileReader()
ys = np.array([np.nan])
list1_copy = list1[:]
t, p = ttest_ind(data[list1], data[list2])
input[i] = 2 ** i
copy_graph = graph.copy()
my_click = QtCore.pyqtSignal(QObject)
self.__class__.class_setup_called = True
timeit.timeit(lambda : f(*args), number=1000000)
image_center = tuple(np.array(image.shape) / 2)
re.append(key_to_items[k].pop())
line = line.rstrip()
q.Field1
rs.add(c.delay(a))
job_count += 1
km.start_channels()
example = sess.run([image])
form = MyModelForm
img.set_data(dat)
back.paste(poly, mask=poly)
-np.inf
modules_copy = sys.modules.copy()
points_down = np.copy(points_center)
self.x = x
reactor.callLater(1.0, d.callback, x)
plt.imshow(labeled)
poly
old_width, old_height = im.size
my_module.get_url = fake_get_url
print(text)
count = np.zeros(len(unique), np.int)
data = stream.read(chunk)
memo[n][arr][end]
t.stop()
print(dct)
plt.scatter(X[:, (0)], X[:, (1)], c=y)
data = StringIO.StringIO(zfile.read(csv_file))
result.workHardForAMoment(something)
print(index)
iterator = iter(input)
args
obj.isoformat()
values = values.reshape(arr.shape[0], arr.shape[1])
min_value = sab
x = np.arange(5 * 5, dtype=np.long).reshape(5, 5)
dialect = query.session.bind.dialect
is_email_validated = models.BooleanField(default=False, null=False)
len_seq = len(seq)
ID = ID + 18
p = np.random.rand(2000, 4)
cookie_jar = cookielib.LWPCookieJar()
next(i2)
tmap.append((r(), r(), r(), r(), r(), r()))
fig, ax = plt.subplots()
max_y = max(y_av)
sns.set()
result = soup.findAll(something)
t1 = time()
session = sessionmaker(bind=engine)()
REQUIRES = django
os.remove(result_image_path)
True.__cmp__(-1)
os.setgroups([])
seconds = pytimeparse.parse(td_string)
hook(self._client_cls, *args, **kwargs)
inp = [dict(x) for x in (a, b, c)]
type(sub2)
d.update(d2)
automobile
y6 = x.astype(float_)
expect = set(x for x in range(1, N * N + 1))
self.obj = obj
app = App()
sum(abs(permutations_1[key] - permutations_2[key]) for key in keys)
x = x + (x >> 8)
nprect = np.vectorize(rect)
a = np.array(64).reshape(8, 8)
ret[i, k] = m[k] / n[k] - 1.0
x
phi = list()
{id: (first, last) for id, first, last in name}
data_items.append((index, data_value))
float(m(400))
account.refresh()
mllib_linalg.SparseVector(v.size, v.indices, v.values)
str(self) + other
found = next(i for i in mylist if predicate(i))
self.azimuth_angle
inRange(red, Scalar(129), Scalar(255), mask_red)
self.pt_plot.set_visible(visible)
my_dict = {}
l = locals()
r_test_fast = reshape_vector(r_test)
p = math.exp(DeltaE / ktemp)
res.append((phrase[i], phrase[i + 1]))
show()
result = [0] * n
1 - 0.411741
self.sample.save(self.name, ContentFile(content), False)
self.value = value
self.worker_count = worker_count
my_dict
p.join()
print(c())
A1 = A[:, (new_order)][new_order]
lists = []
x = total - x
str(personId)
self.arr
CATCGATCAGCATCGACATGCGGCA - ACG
label = QLabel()
y_data = y_data.flatten()
metadata = bencode.bdecode(torrent)
mail.settings.tls = True or False
train_set_x = numpy.arange(100.0).reshape([20, 5])
text = html2text(newhtml)
print(partners)
print(self.anyfontname.measure(text))
foo_list = []
print(f(x))
self.runable = False
lab = convert_color(sRGB, LabColor)
self.start_urls[i] = request.url
not any(map(any, x))
stream.sample()
text = match.group(4)
xy = NNN.mean(axis=2)
idx_pivot = random.randint(start, end)
retval = _orig_db_model_put(self, *args, **kwargs)
qs = Room.objects.filter(name=self.name)
body = json.loads(message.body)
next(Odd())
x = np.random.uniform(0.0, 10.0, 15)
day = 1
mytemp = db.get(MyDocId)
tk.iconbitmap(default=ICON_PATH)
sols = solve(sin(z) - 2, z)
lambda : nodes[i].value() == nodes[j].value()
self.__ordered_fields__.append(attr)
line = self.fo.readline()
add_user(user)
B = np.tile(A, (6, 20, 1))
d_sum
l = [combinations(pieces, i) for i in range(2, 4)]
path_list = your_path.split(os.sep)
i = 2
request.method,
nth_largest(a, 2)
element
pool.map(test, [(proc_id, i) for i in range(4)])
x.nbytes
np.random.seed(0)
conn.select(readonly=1)
http_server.listen(tornado.options.options.port)
cols = df.columns
dict((column.name, column.id) for column in dataset.column_set.all())
np.bincount(IDs, vals) / np.bincount(IDs)
len(l)
graphemes == graphemes[::-1]
result = []
pos = f.tell()
print(line)
result = result[1:] + (elem,)
bin(1 << 8 | 2)
t = chr(t)
circle_first_y = Circles[0].y - circle_spacing_y / 2
np.int64
b = b0 + (b1 - b0) * (x - x0) / (x1 - x0)
self.x == c.x and self.y == c.y
scores[username] = 1
sess = tf.Session()
r = np.linspace(0, 100, 200)
webdriver_assume_untrusted_issuer = TRUE,
support.build()
index = 0
msg = ard.read(ard.inWaiting())
df2 = np.ceil(gp.count() * stratfraction)
stm = cStringIO.StringIO(txt)
response = urllib.request.urlopen(request)
a.first()
actions = JSONField()
collections.OrderedDict(loader.construct_pairs(node))
A = np.vstack(arrays)
time.sleep(60)
getattr(self._obj, item)
allow_domains = allow_domains, deny_domains = deny_domains,
plot_coords(ax, tube.exterior)
g = g[1:]
result.append([hours.iat[0], values.iat[0]])
print(maxchange)
max_tm = max(tms)
l = tup[0]
target.append(start.pop())
test.bar()[1].member
indices.append(a_index)
timedelta(hours=1)
id = db.Column(db.Integer, primary_key=True)
module = (div - 1) % 26
l
result = parser.parse(inp, tokenfunc=get_token, debug=0)
sys.stdout.write(self.read_from_console())
multiset = collections.Counter()
widget = item.widget()
tomorrow = today + datetime.timedelta(days=1)
self.data.write(line)
thisPath < -thisPath - thisPath.end
bit7 = bool(x & 64)
add(x=5, y=10)
2 - y | 2 - n | 1 - n | 1 - n
d = {ni: indi for indi, ni in enumerate(set(names))}
xl.Visible = True
dispatcher_thread.join()
shutil.copy(tmp_filename, filename)
print(mydll.test(10))
self.table.append(row)
a = collections.OrderedDict.fromkeys([1, 2, 20, 6, 210])
dict_obj = model_to_dict(obj)
isinstance(aobj, a.A)
decp = n.get_decimal_symbol()
config = configparser.ConfigParser(defaults=defaults)
d = pq(data)
delete_key_list.append(key)
dispatcher.connect(self.spider_closed, signals.spider_closed)
print(obs_values[1].firstChild.nodeValue)
raise DuplicateKeyError(k)
b_set = set(b)
self.context.enter()
a = {}
xlApp.Visible = 1
next(fin)
Session = sessionmaker(bind=engine)
myfoo = Foo(1, 2)
self.forest = []
tmp.append(tmp2)
testCase.assertAlmostEqual(first, second, *args, **kwargs)
n = 2000000
x = np.random.randn(10, 1)
x, y = point_to_xy(50, 50)
all_contacts = []
big_letters = set(string.ascii_uppercase)
headers = response.headers
g = f(1)
self.num = num
n = 6
a[il1] = np.nan
file.append(buf)
data = zfile.read(filename)
x2_Kaxs_1[j] = [random.randint(0, 9)]
x.remove(i)
a = [0, 1]
result.append(table[tup])
idx, = d.nonzero()
c.listsquare = [(x ** 2) for x in range(0, 10)]
files.sort()
cols = map(len, input)
min = round((UT - int(UT)) * 60, 0)
another_row = result.fetchone()
ax.add_collection(coll)
print(A.I)
output = StringIO.StringIO()
labels.append(int(label))
n = a.shape[-1]
QSyntaxHighlighter.__init__(self, document)
parser = OptionParser()
ax1 = f1.add_axes([0.1, 0.1, 0.8, 0.8])
urls.py
self.number = self.store.customer_set.count() + 1
mask = np.repeat(mask, nnz_per_row)
min_value = np.iinfo(im.dtype).min
df.columns = [cols % 2, cols // 2]
rmtree(tmp, ignore_errors=True)
self.objtype = objtype
t.substitute(**d)
Server.__call__(self, app, *args, **kwargs)
a < b
articles = db.get(keys)
a = list(range(1, 10))
np.array(ds)
appstats_DEBUG = False
res = add_all_subclasses(type, new_bases)
count = CountVectorizer(vocabulary=myvocab)
data_chunk.append(vals)
inf = sys.stdin
m_to_N[:, (0)] = -nrange[1:].reshape((n - 1, 1))
args = parser.parse_args()
wb = Workbook()
imshow(gray, cmap=cm.gray)
l = numpy.linalg.norm(d)
yaml.safe_load(list_dump)
p.search(s)
_d_xor2[a, b]
counts[value[1]]
print(result)
myfunc(a, b)
setup_crawler(spider_name)
foo = Foo()
field = self.fields[field_name]
written_cell_data = self.written_cells[sheet_name].get(cell)
matches.append(alignedAt)
file = urllib.request.urlopen(uri)
add5 = make_adder(5)
print(df1)
df1.c = df1.c.astype(int)
assert len(attr.columns) == 1
green_list, green_on, green_start
nameArray = inputText.split()
image.show()
angle = arccos(clip(c, -1, 1))
self.y = y
stokes_list.append(stokes_line)
textwrap.wrap(s, 15)
self.LastJson = json.loads(response.text)
value = self._align_series(indexer, value)
nodes_nummpy_array[:, (1)],
type(answer)
mynumbers = []
result
print(names)
d = defaultdict(int)
old_out.write(x)
original_handler = signal.signal(signal.SIGALRM, timeout_handler)
fig = plt.figure()
b = np.array([4, 5, 6])
jbest = ffinal.argmin()
nexts = cycle(islice(nexts, pending))
RSI2 = 100.0 - 100.0 / (1.0 + RS2)
temp = []
list_a[filter]
line, = ax.plot(x, y)
args, kwargs = self.parse_args(parser)
field.required = False
channel_session_user
data.result = capturer.getvalue()
ob = A()
args[-1] += 1
num_fields = len(cursor.description)
killed
print(+x)
list(gen)
{}
results[value] = [value]
head, tail = os.path.split(head)
lin, = ax.plot(th, y, lw=5)
self.data[key] = value
x += y
lats = np.arange(-90, 90.5, 0.5)
badcfehgjilknmporqtsvuxwzy
model.add(Reshape((1, 80)))
print(doc)
next_ns = map(lambda x: n - x, legal_moves)
f_ = dill.loads(_f)
print(item.title, item.isbn, item.price_and_currency)
1 < {0}
c = [int(e) for e in b]
b = A(2)
new_dict[abstractmethod] = lambda x, *args, **kw: (x, args, kw)
a.some
r = v % 20
stats.pearsonr(Y, Z)
self._n_weights = 0
obj = Photobox.objects.get(user=request.user.id)
cVerts[i] = verts[i]
print(result[0])
self._old_stdout = sys.stdout
a, b = b, min(a, b) + v
type.tp_dict = PyDict_New()
shift = 0
print(time.ctime())
dx = radius * math.cos(angle)
points = np.array(points) / [mult, mult * int_w / (2 * np.pi * r)]
Comment1
new_time = current_time - timedelta(seconds=10)
print(F.evalf(subs={d: dist}))
print(poly.powers_)
dis.dis(Test.calc_x)
sort_idx = np.argsort(full_arr[:, (index)])
l
k = n.bit_length()
d = {(0): [0.1, 0.2, 0.1], (1): [1.1, 1.2, 0.1], (2): [2.1, 2.2, 0.1]}
parser._parse_known_args(sys.argv[1:], argparse.Namespace())
print(new_l)
sqs = SearchQuerySet()
glClear(GL_DEPTH_BUFFER_BIT | GL_STENCIL_BUFFER_BIT)
a1 = A[0], a2 = A[A.length - 1], L = a1.length, i = 0
10 * ((x + 5) // 10)
panel = wx.Panel(self, wx.ID_ANY)
print(df)
state = Column(Integer, default=0)
neighbors.remove(parent)
smallest = l[0][1]
rng = Random.new().read
NotImplemented
m.drawcountries()
xy = np.empty(tr.shape, np.float_)
True
s = match.group(0)
self.write_c.wait()
count += 1
f._x = 5
first16 = sio_buf.read(16)
ret, foo.x = x * x + foo.x, foo.x + 1
tree.remove(street[r])
print(axarr[0].get_xticks())
f.close()
factors.append(n)
datetime = models.DateTimeField(default=datetime.now)
print(id(ch))
arg2 = bool(strtobool(arg2))
result[word] += 1
cls.name_map[name]
pickle.dump(favorite_color, f_myfile)
b = sc.array([4, 5, 6])
values = []
z = zip(str(a), str(b))
g = lambda x: x.groupby(x).apply(f)
request.start_time = time.time()
c = [5, 15, 25]
elevations = response.read()
match.a
rand = random.randrange(0, session.query(Table).count())
functools.reduce(np.logical_and, conditions)
self.fh = open(filename, *args, **kwargs)
ofp.write(findata)
path, file = os.path.split(path)
self._dict == other._dict
fig, ax = plt.subplots()
self.loadInstManagers()
nextran = random.random()
i = math.floor(x / binsize)
str(pi)[:n + 2]
h = fromstring(xml, parser=parser)
w = WED.WikEdDiff(config)
roismall = cv2.resize(roi, (10, 10))
numbers = list(x >> i & 255 for i in range(0, 64, 8))
result = f(result)
register = template.Library()
file_date_tuple_list.append(file_date_tuple)
FORMAT = pyaudio.paInt16
convert = lambda text: int(text) if text.isdigit() else text
id_arr[shift_idx] = shift_vals
bytes2delete = bytearray(list(range(naligned, nbytes)))
self.x = x
82514145
brlxusd = usdbrl.text
samples = read_samples(input_wave_file, buffer_size)
print(x)
count += 1
proc = subprocess.Popen(test_cmd, stdout=cmd_out, stderr=cmd_out)
q = p[:]
round(o, 4)
list_b = [67, 4, 67, 4, 67, 4, 67, 4, 2, 9, 0]
obj.macAddresses.all()
B[5, 5, 4]
random.choice(min_keys)
soup.b.string
print(np.mean(sample_signal(5000, 0.5, mu=2)))
delta = dt.timedelta(seconds=secs)
x = np.linspace(0, 10)
data[index], data[new_index] = data[new_index], data[index]
application2
country_reverse = dict((v, k) for k, v in COUNTRY_CHOICES)
date_conv = datetime.date(1900, 1, 1) + datetime.timedelta(int(date_value))
zn = griddata(xr.ravel(), yr.ravel(), z.ravel(), x, y)
shape = list(x.shape)
aa = list(assignments(n - 1, m, used))
X.flatten(), Y.flatten(), Z.flatten()
vc.gotoVersion(bookmark)
index.append(i)
np.transpose(X), info
axcolor = fig.add_axes([0.94, 0.1, 0.02, 0.6])
a[blo:bhi + 1] += bbins
Base = declarative_base()
Model.column.ST_AsText()
it = iter([0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0])
pickle.dumps(state[i], protocol=2)
size, p.image.size
result_values = np.empty(result_names.shape)
path = self.path
clock.tick(60)
c = repo.commits(path=i[0], max_count=1)
font = ImageFont.truetype(font_location, adjusted_points)
y = (x for i in range(10))
self.vcmd = self.master.register(self.count)
login_form._errors.setdefault(NON_FIELD_ERRORS, ErrorList())
x + y
0, x
x = XClass()
last_name = CharField(max_length=50, blank=True)
result = future.result()
dfy += np.matrix([[0] * 10, list(range(10))]).T
+gopher
count = 0
request = urllib.request.Request(add_component_url, data, headers=headers)
list1 = [2, 7, 8, 5]
setofcols = np.unique(np.dot(X, product).A1)
c = [0]
longest = max(len(t[0]) for t in timings)
f.read(length)
serv = Server(duplex=1).boot()
element.location_once_scrolled_into_view
loop.close()
[1, 1, 1],
list(set(leftList[:leftN]) & set(rightList[rightN:]))
child_or_parent()
piped = row.pop()
ngroups = (d.shape[0] - (consec + (nsub - 1) * offset - 1)) // pace
voronoi_plot_2d(vor)
rgx = regex.compile(p, regex.VERBOSE | regex.MULTILINE)
country = models.CharField(max_length=2, blank=False, null=False)
len(self._dict)
end = date(2012, 12, 18)
pool = mp.Pool(processes=mp.cpu_count() - 1)
var1 = 10
response(environ, start_response)
people[name] = User(name)
fb_auth_token = SocialToken(app=app, token=auth_token)
start_time = Column(Integer)
rd[0:10] = 5
STOCK_DIALOG_QUESTION
v = print_dict(v)
ret += math.pow(a / r, n) * inner
sst_contour = ax.contourf(lons, lats, sst, 60, transform=ccrs.PlateCarree())
features = vectorizer.get_feature_names()
rowsums.columns = colsums.columns
out.shape = 6 * N, 6 * N
zip(before, items, after)
assert (z == z2).all()
self._x = value * 2
map(next, iters)
st.update(words)
0
print(b.shape)
shape = [i for i in dif.shape]
ski.view_as_blocks(a, (2, 2))
old_window = [Gdk.Screen.get_default().get_active_window()]
funcs_dict = dict(zip(func_names, func_list))
response
i = iter(iterable)
dict(item1=self.item1)
next_item = queue.get(timeout=0.5)
a = [1, 2]
self._instance_setitem(k, v)
path = os.getcwd()
other_street = tree.next(other_street)
tree[child.name] = {}
parser = ArgumentParser()
getter, setter
user.is_staff = True
s = np.sum(t, axis=1)
decorated
myenums.Sequential.B.succ().succ().pred()
0
thefile = foobar.FileParser(sys.argv[1])
authorize_url = twitter.get_authorize_url(request_token)
toys = alice.toys[:]
md = module.__dict__
self.my_table = db[table_name]
self.lChild.makeList() + [self.data] + self.rChild.makeList()
scatterHs = []
title = StringField()
1
not W.groupby(level=0, axis=0).filter(filterer).empty
df = pd.concat([df_ for _ in range(10000)], ignore_index=True)
y // 100 * 5 + x // 100
print(value)
ramp = 1.0 / (1 + exp(-6.0 * (times - t_change)))
int()
connection = opener.open(request)
Afactsolve = factorized(A)
ID_arr = np.repeat(np.arange(len(lens)), lens)
prediction = clf.predict(test_features)
IP, username = line.split()[:2]
res = scipy.optimize.minimize(fun, params0)
deleteself._fwd[key]
expiration_utc_ts = (d - datetime(1970, 1, 1, tzinfo=utc)).total_seconds()
dtype = np.uint8
print(a)
response = h.getresponse()
count += 1
cax.set_ticklabels(list(range(-1, N)))
s1 + x + s2 == y
data = [str(random.randint(0, 100000)) for i in range(100)]
value = []
first_purchase_time = purchase_times.min()
EncodeAES = lambda c, s: base64.b64encode(c.encrypt(pad(s)))
stdout.flush()
r = np.array([random.randrange(1, 1000) for _ in range(0, 1000)], dtype=float)
print(a)
curs = con.cursor()
seekpoints[infilenum] = infile.tell()
cp = ConfigParser.ConfigParser()
self.__dict__[name] = value
n[0]
num = int(next(data_file))
i = Image.open(f)
axdendro = fig.add_axes([0.09, 0.1, 0.2, 0.8])
thumb.erase()
view_link.allow_tags = True
temp = []
wall(4, 1)
delta = datetime.timedelta(seconds=duration / gst.SECOND)
self.decorator = dec
y = 2 * x
self.exns = set()
run_test.click()
ohc.active_features_
session = Session()
self._waiters.append(waiter)
d = datetime.datetime(2012, 5, 25)
tf = df.Phrase.apply(pd.value_counts).fillna(0)
t = Tk()
type = models.ForeignKey(Type, default=mydefault)
a = 1, 2
print(DNAseq)
a, b = 0, 1
code.InteractiveConsole(locals=globals()).interact()
self._W = w
where = numpy.hstack((inVs, outVs)).astype(int)
data = base64.decodestring(key_string)
_, img = capture.read()
ax = g.plot()
self.file.write(fp + os.linesep)
myWB.Close
grid_x, grid_y = np.mgrid[0:im.shape[0], 0:im.shape[1]]
fig = pylab.figure()
nnz_per_row = np.diff(a.indptr)
node.middle()
1, counter
print(0 % p)
[0, 1, 4, 9, 16, 25]
a = 5
boolean = Column(Boolean)
retval.put()
schedule.append([[d[j], d[-j - 1]] for j in range(n / 2)])
result = [(0) for i in range(len(numbers))]
split_word[0] + split_word[1]
item = self.spider.parse(response)
deriv_list.append(df_i)
sum
input_thread.start()
CHUNK = 1024
root
blurred_halo = halo.filter(ImageFilter.BLUR)
drops = np.tril((N == D) & (N == D.T), -1).any(axis=1)
BIT7 = 2 ** 7
conn.close()
alen = len(astr)
termcolors = coloransi.TermColors()
print(test.num)
seconds = int(round(frac * 86400.0))
l = []
writtenbytes = buffer(buf, 0, bufsize - len(m))
np.concatenate((theta, r), 1)
recipe = models.ForeignKey(Recipe)
mask = np.zeros(len(a), dtype=bool)
symptoms = [s.strip() for s in symptom_pat.split(astr)]
endTime = datetime.datetime.now() + datetime.timedelta(minutes=15)
X = squareform(np.array(distance_vectors))
min_time = datetime(2015, 9, 29)
a * maxB + b
p1(x) - p2(x)
dt, success = calendar.parseDT(date_string)
student.py
handle = ssh.SSHClient()
new_lst = copy.copy(lst)
res
s.listen(BACKLOG)
index = bisect(b, a)
foo(10)
list_of_tuples = zip(FFnetlayer0[0::2], FFnetlayer0[1::2])
paths.append(path)
x = p.Series()
jobname = sys.argv[1]
print(ydata[i])
p = Pool(processes=np)
ds2Cursor.commit()
z = np.array([[complex(c.m_x, c.m_y) for c in cells]])
matplotlib.backends.backendbackend_agg.FigureCanvasAgg(fig)
self.lock.release()
user = User.objects.get(id=2)
suffixes = sorted(data[i:] for i in range(len(data)))
err2 = np.sqrt(errfunc2(optim2, data[:, (0)], data[:, (1)])).sum()
ax = fig.axes[i]
print(mr_parse(params))
val = next(it)
self.name = name
QQ.old_poly_ring(x).ideal(x ** 2 + 1)
unique_users.sort()
exif = image._getexif()
arr[i] = i
self.size = size
self.filter(alive=True)
inverted_dict
strided = np.lib.stride_tricks.as_strided
print(list(y[1]))
PyObject * pydict
b = 5.2 * a[:, (1)]
arrow.now().datetime
frame1.axes.xaxis.set_ticklabels([])
file_like = cStringIO.StringIO(data)
SOCIAL_AUTH_GOOGLE_OAUTH2_USE_DEPRECATED_API = True
True
sessionOptions.setServerHost(host)
il1 = np.tril_indices(4)
main()
y = exp(-x * x)
f.close()
temp_list = []
finalMessage += chr((ord(value[x]) - 96) % 26 + 97)
d.append(Distance(_, unit=u.kpc).kpc)
xml = f.read()
data = data.drop(item[0])
errno = ctypes.get_errno()
b = BitArray(bitlist)
parser = nltk.ChartParser(grammar)
form.test_field.default = some_default_id
print(output)
README
yappi.stop()
result = defaultdict(int)
order_centroids = model.cluster_centers_.argsort()[:, ::-1]
result = fftconvolve_1d(data, Gauss)
win.setContentView_(view)
[openblas]
assert len(x) == width
self.foo = 1
dest_name = os.path.join(install_path, name)
stream.write(data)
gobject.timeout_add(1000, self.checkStatus)
xx = pylab.linspace(-5, 5, 100)
a = arr.tostring()
selectors = (len(s) == 2 for s in x)
axis = axis / sqrt(np.dot(axis, axis))
res = list(itertools.product(L, L))
result.append(data_c.pop(0) - data_c.pop(0))
mbstowcs(buffer, tmp, buflen)
link = mainData_sheet.hyperlink_map.get((row, 0))
ls2 = list(set2)
my_keys.append(i)
mats = []
vocabs = []
fullresults = []
z = a.view(dtype=numpy.uint8)
writer = FFMpegWriter(fps=15, bitrate=1000, metadata=metadata)
i += 1
app.debug = True
filtered = all(i in line for i in black_list)
counts_matrix[from_, to] += list(counts.values())
smtp.sendmail(fromaddr, toaddrs, msg)
self._d[key] = value
n = n + 1
R = eye(k)
print(header_data)
caps = word.upper()
l = sorted(numbers)
processPool = multiprocessing.Pool(5)
totalLen = int(sys.argv[2])
not rex_nomatch and re1_matches
type(_)
as_part = np.argsort(partitions, axis=1)
y[s] = np.arange(s.size)
list(one_duplicate(2))
conset = set(map(tuple, map(sorted, consarray)))
temp.append(strg)
[i.rewrite(log) for i in sols]
start = int(args[0])
istartswith
deck[i].insert(0, x) if i != len(deck) else deck.append(newDeck)
my_value = 0
sampwidth = 2
FFT_FREQS = numpy.fft.nfftfreq(CHUNCK, DT)
print(data)
startOfNextYear = dt(year=year + 1, month=1, day=1)
callback, arg = callback_ref[0](), callback_ref[1]
slugify(unidecode(value))
axsliderC = axes([0.74, 0.85, 0.16, 0.075])
ET.dump(parent)
abs(date2 - date1).days
do_more_things()
raise ValueError()
v = self.value * 2
content_type = ContentType.objects.get_for_model(self.__class__)
m.a()
set_ranlet = set(ranlet)
l = [0]
reader = vtk.vtkXMLUnstructuredGridReader()
old_cs.ImportFromWkt(ds.GetProjectionRef())
t = np.linspace(0, 1, num_t)
df.loc[:, (msk)] = np.round(df.loc[:, (msk)], 2)
self.__double
iter(obj) is obj
num_vowels = num_vowels + 1
y[j, i] = x[idx[j, i], j, i]
sz = w.get_size()
ii = [int(x) for x in arange(0, df.shape[0] - N + 1, nn)]
changedir = {envtmpdir}
c = 2.0 * arctan2(sqrt(a), sqrt(1.0 - a))
height = 25
self._fp = open(self._to_do.pop(0))
db = SQLAlchemy(app)
ws.set_vert_split_pos(1)
Case(When(created__month=5, then=1), output_field=IntegerField())
t = sparse.coo_matrix(t)
group = match.group(0)
True
assert 1 <= a <= b <= n, (n, a, b)
test.foo()
tkip = 1 << 5
self._closing = False
(self.map(x) for x in other if self.filter(x))
fOX
Fox
FoX
combination[r - 2] += 1
datasets.append([])
self._i = value
_ranks[-1][k] = a
doSomethingWithFile(f)
self.level -= 1
b = numpy.array((xb, yb, zb))
clients -= 1
data = np.random.random_sample((25, 25))
deleteself.self
g = Graph()
(datetime(1992, 8, 27, 7, 46, 48), 28.0),
y_offset = np.median(y_offsets)
self.min_set[value].add(key)
self.value = value
l = l[0]
zs = np.cos(U)
max_len
yi = np.linspace(ymin, ymax, ny)
m.set_array(Z)
print(count(PeopleList, lambda p: p.Age < 20))
writer = csv.writer(outfile)
pandas2ri.activate()
glClearDepth(1)
obj = cPickle.load(dump)
key = cv2.waitKey(0)
a + b
result = tuple(islice(it, n))
qs = urlparse.parse_qs(tmp)
file_path = os.path.join(responses_dir, file_name)
l = [5, 2, 6, 7, 9, 8]
one_I_want = full_doc.get_worksheet(0)
dictionary = aggregate_names(previousFunction(string))
resp = req.read()
i = 0
a = dfa.values.flatten()
print(body)
self.y = y
transformer = TfidfTransformer()
Test() + 4
print(data_obj.calculate(10))
res = list(itertools.islice(i, 0, n))
endif
init_op = tf.initialize_all_variables()
print(data)
jobForm = JobForm(request.POST)
df.fillna(0.0).values
Z2 = ML.bivariate_normal(X, Y, 4, 1, 1, 1)
x, y = np.meshgrid(np.linspace(-1, 1, 100), np.linspace(-1, 1, 100))
comment_re.sub(comment_replacer, text)
self.name = name
data_tmp = numpy.array(values, dtype=dtype)
result[:, :] = scipy.outer(A, B)
new_val = [x[0]]
print(self.a)
qdate = QDateTime(2012, 12, 20, 11, 59, 59)
Case(When(created__month=8, then=1), output_field=IntegerField())
True
gef_kanji = zahl.find(key)
list(testgen(0))
paulj(C)
y[0, 0, 0]
crawler.configure()
m.fillcontinents()
info = zipfile.ZipInfo(filename)
Py_DECREF(op)
XYZ[0] = float(XYZ[0]) / 95.047
data = collections.defaultdict(list)
str(form.data)
Task(process_image, im)
match &= a[i:i - n]
print(x)
print(repr(seq_record.seq))
B = [12, 5]
form_class = UserPhoneNumberForm
np.sqrt(u * u + v * v)
x[-1]
items.extend(list(flatten(v, new_key).items()))
sign = np.sign(df[col])
new_driver = webdriver.PhantomJS()
print(l[5])
self.i += 1
print(ch)
sorted(lists[0])
print(Fraction(0.5))
queryset = queryset._clone()
open(self.fname)
zip_cities = {i: tsk.result() for i, tsk in enumerate(tasks)}
y
k(a=10, b=20)
me = Object()
orig_stdout = sys.stdout
R, C = np.triu_indices(a.shape[1], 1)
file_sample_rdd = file_sample_rdd.union(sc.textFile(f))
all_combinations = list(combinations(points, m))
arr = np.array([[int(bin) for bin in line] for line in f])
x
str(value)
result = (on_false, on_true)[condition]
dirname = os.path.dirname
Y_observed.append(y)
a = pool.submit(fibonacci, n - 1)
k = np.zeros(N)
corners = (xlim[0], ylim[0]), (xlim[1], ylim[1])
sQ = mod1.modulate(sB)
app.Documents.Open(tmpFile)
laplacian1 = nx.spectrum.laplacian_spectrum(graph1)
{self.name: d}
d = {}
name = m.group(1)
doc = ET.parse(file)
out.show()
r.fill(255)
df
a_as_vector = tf.reshape(a, [-1])
qs = list(qs)
strlen = len(string)
all_data = {}
y = np.apply_over_axes(np.mean, x, (1, 2))
A().f(5)
sample = np.random.binomial(1, frac, size=10000)
month = self.event_date.month
array = (ctypes.c_double * len(floatlist))(*floatlist)
df
t /= np.linalg.norm(t)
print()
[].x = 0
type(self), self.name
print(t)
state = np.tile(ic[:, (np.newaxis)], (1, p.size))
e.pack(side=LEFT, fill=X, expand=1)
s[1][1][1] = 2
_textwrap.wrap(text, width)
set(d2.items()) ^ set(d.items())
print(result)
df
string.find(keyword)
p = Pear()
m = diag(list(range(1, 11)))
x2, y2 = polygon[-1]
REVERSE_MAPPING = {}
cmath.atan
self.omega_r = omega_r
width = 10
df
theta = np.where(y < 0, 2 * np.pi - theta, theta)
r.imag = copysign(d, z.imag)
reactor.callInThread(d.callback, 1)
id(x)
setup()
udf(_parse, TimestampType())
polys = [numpy.random.random((n, 2)).tolist() for n in [5, 7, 12, 6]]
self.arg += arg
files = list(filter(os.path.isfile, os.listdir(os.getcwd())))
print(line)
reshape(lat_len, -1)
config = ConfigParser.ConfigParser()
getattr(instance, self.name)
first_row_index = 124 - 1
wx.SIMPLE_BORDER
other = pd.DataFrame(dict(a=1), index=ix_use)
max_index = len(colors) - 1
row = l.split()
i = np.floor(t)
h.setLevel(DEBUG)
r = [x.sum() for x in ygen]
self.value[i] < other.value[i]
stack.append(iterator)
gp = np.array(goodPix, np.float)
rx = [(x ** 2 + y ** 2 < 9 and 1 or 0) for x, y in Data]
some_stuff()
distance = plane[-1]
a_foo = Foo(bar=5)
self._description
delattr(instance, attr)
randomArray = np.random.rand(2, 2)
token = self.trell[i][1][k][1]
i = i - 1
logger.addHandler(logging_handler_err)
idx = [((x,) + y) for x in df.index.levels[0] for y in other.index.values]
pandas2ri.activate()
my_pandas_frame = pandas.DataFrame(vec_dict)
mtime = os.path.getmtime(path)
a = [id(row) for row in r]
r = list(generate_less_than(5))
x > 5 and x < 20
pos = numpy.digitize(values, bins)
items = list(elem.items())
False
next_emitted = []
arrayList = []
add_months(otherdate, 1)
np.save(outfile, weights)
easy_install / your / file / location / pack.tar.gz
benchmark(checkio_andreysabitov)
benchmark(checkio_andredaniel)
wrapper
func()
tablize(n - 1, truths + [i])
utc_offset = lambda offset: timezone(timedelta(seconds=offset))
fig2 = plt.figure()
x if condition1 else y
day = 21 - (calendar.weekday(date.year, date.month, 1) + 2) % 7
True
args = parser.parse_args()
benchmark = timeit.Timer(splitsearch, prepare)
raise Hell(n)
plt.xticks(list(range(10)), indices)
fig = plt.figure()
rx.search(value).group(0)
ndimage.rotate(array, 45)
eratosthenes(100)
value = []
print(c.two())
i = 0
sysname = platform.system()
weights = np.random.randint(1, 4, size=20)
os = ds.open_array(input_array, 44100)
show(therest)
left.put(elt)
window.setLayout(vbox)
last -= 1
server, key
self.subject_init = self.subject_initials()
print(tweet)
f = lambda : f
mf.rowconfigure(0, weight=1)
len(singleton)
set2.add(item)
k = np.argmax(image_temp)
register = template.Library()
base_method = getattr(base, name)
start = start + timedelta(minutes=60)
point = np.radians([lon, lat])
tearDown()
970
index = -1
main.show()
se1 = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
x = [5, 10, 15, 20, 25]
random.random() * 500
myInstance = myClass()
NPY_BEGIN_THREADS_DESCR(PyArray_DESCR(ap2))
self.chunk_count = 0
r < len(indices) and indices[r] < b
response
parm = {}
files = []
axmatrix.set_yticks([])
f.a()
formatter = logging.Formatter(logging.BASIC_FORMAT)
print(i)
flist = matplotlib.font_manager.get_fontconfig_fonts()
sub_obj = json_obj[tag_name]
denom = pd.DataFrame(denom.values, columns=df.columns, index=df.index)
nb_frames = input_wave_file.getnframes()
x[..., (0)]
unrooted_paths = []
string = StringIO.StringIO()
link.url = proxy_url(link.url)
Segments[0]
qnetworkcookie_list = []
asdouble = ctypes.c_double(x)
print(something.foo(10))
x
print(firstNlines)
s = pid.communicate()[0]
colors = np.random.random(len(lines))
self.path = sub_path
X = np.random.randn(10000)
row.append(comments)
ds.open(path, mode)
print(keys[0], keys[1], z)
c.bar
print(monday_my_date)
net.addConnection(FullConnection(bias, output))
all(earlier >= later for earlier, later in zip(first, second))
q.put(c)
x, y = list(range(0, 10)), list(range(0, -10, -1))
stream = urllib.request.urlopen(url)
omags[fixmsk] -= 1.0
main()
toret
arrays = [[(i, item) for i, item in enumerate(arr)] for arr in arrays]
metadata = sa.MetaData()
raise TypeError(msg + mthd_list)
amount = models.DecimalField()
raise Exception()
source = sys.stdin.readline().strip()
it = iter(iterable)
data[1] = 1.0
input = input_variable(1)
inner
print(request.version)
getFoosMatchingCriteria(someCriteria)
self.subject = subject
jane, 6, F
d = {x: (0) for x, _ in p}
classes.append(klass)
sorted_indexes = np.lexsort(tuple([rnd_data[:, (col)] for col in sort_by]))
axes = [], []
s.equals(s2)
encoded_params = urllib.parse.urlencode(params)
train_labels = train_df.values[:, (0)]
model.add(Dense(output_dim=64, input_dim=100))
colors[:, (-1)] = 255
seq = sys.stdin.readline()
date = datetime.utcnow().date()
points = map(lambda x: tuple(x[0]), contour)
print(f)
self.conditions = {}
y = x + 1
print(Y[ind, a1, a2])
cov.save()
k.set_contents_from_file(fp)
y = x[:]
Parent2.on_start(self)
x_unique = np.unique(x)
current = next(it)
a.setall(False)
0
removed_indices.append(i)
cleaned_data = self._cleaned_data()
hours, minutes = divmod(offset, 60)
np.all(row1 == row2)
queryset = User.objects.all()
self.votes = []
X_proj = Q.T.dot(X)
argparse.HelpFormatter._split_lines(self, text, width)
y1 = np.cumsum(np.random.random(time.size) - 0.5)
pre, ext = os.path.splitext(name)
Base = declarative_base()
H5T_C_S1_64 = h5py.Datatype(tid)
structured_data = json.loads(raw_data)
assert nextnode in bg.neighbors(lastnode)
f.tell() - (len(buffer) - pos)
self.ewma_trainer.apply([self.mean, self.variance])
spect = abs(np.fft.fft(signal))
im = np.zeros((df.shape[0], df.shape[1], 4))
whatever()
matches = list(datefinder.find_dates(input_string))
indices = (scores > 0).astype(np.int)
[server]
foos = dict()
print(x)
FONT_ITALIC
web.internalerror(render.site.e500())
ax.yaxis_date()
y[idx] = np.unravel_index(full.argmax(), full.shape)[1]
A1 = A.reshape(-1, 1)
q = q_key.get()
idx = np.argsort(X)
print(f.readlines())
d = {}
people = PersonQuerySet.as_manager()
p = ceiling(sqrt(n))
_min = int(floor(float(n) / float(s)))
myxml = fromstring(text)
ws = websocket.create_connection(socket_io_url)
self.set = dict((item, True) for item in items)
True
now + datetime.timedelta((_FRI - now.weekday()) % 7)
filename = askopenfilename(parent=root)
data = f.read(BUFSIZE)
time.__dict__
data
doc.addPageTemplates([template])
df
YY = Y.reshape((1, Y.size))
_t1 = _timer()
drvs = []
a, b, c = start, start + length, pos
result.insert(index, elem)
instance.raw()
getattr(self.file, name)
self.i = random.randint(1, 10)
self.lynx = lynx
scale = int(math.log10(frac_digits))
convolution = numpy.fft.ifft(fft_of_convolution)
lstiter = iter(lst)
list
y1fr = max(0, y1)
self.b = B(z)
fig, ax = plt.subplots(nrows=1, ncols=1)
ElementTree.tostring(tree1)
headers = [col.text for col in next(rows)]
bars[2].close
obj = MyClass()
result.writelines(rows)
idx = np.argsort(evals)[::-1]
j = 0
k1 = list(od1.keys())
scene.addItem(node)
p0 = [1.0, 0.0, 1.0]
changes = {}
fields.sort(key=lambda x: x[1]._creation_counter)
dist = calc_distance(point)
crawler.signals.connect(spider.idle, signal=scrapy.signals.spider_idle)
SliceEverything(source, count)
result = method(*args, **kw)
temp = test.ix[i::4]
encoded_params = urllib.parse.urlencode(params)
pprint.pprint(result)
a = MyClass()
bool(set(fruits).intersection(fruit_dict1))
model = Event
b = a ^ (a & -a) << 1
print(int(f1))
True
random.seed()
N = [1, 2, 5, 5, 4, 6]
tk.Frame.__init__(self, master)
outlist.append(indexlist[index2])
some_enum = some_protobuf_object.SOME_ENUM
s = set(L)
x = 0.57
klist = list(d.keys())
rng.to_pydatetime()
plt.show()
jsonify(success=1)
m.source_of_module
dbconf = ConfigParser()
Mx[x] = x - n / 2
print(col_list[2:5])
a += 0
prime = [True] * (number + 1)
name = sqlalchemy.Column(sqlalchemy.String(20))
ts = np.interp(ts_rng.asi8, data.index.asi8, data[0])
ImageDraw.Draw(im).text((10, ys), sometext, 254, fh)
item = QtGui.QListWidgetItem(self.listWidget)
y[start:stop] = f(x[start:stop])
r = random.uniform(0.0, 1.0)
app_label / change_list.html
keyList = sorted(d.keys())
qslkjqskqsdhf
t.daemon = True
ax_img.imshow(img, cmap=plt.cm.gray)
thing = json.dumps(data, cls=MyJSONEncoder)
current_depth = max(current_depth, self.left.depth())
self.weights = [w[0] for w in W.tolist()]
normalized if exponent <= 0 else normalized.quantize(1)
second_array = set(second_array)
loop = asyncio.get_event_loop()
display.clear_output(wait=True)
print(big_df.shape)
print(url)
im_orange = im.copy()
values_size = lib.rle_values_size(self.obj)
self.maxidx += 1
result = []
make_map(ss) == make_map(reversed(ss))
matches[0] if len(matches) > 0 else np.nan
counts[k] = counts[k] + 1
checked = [False] * len(words)
youtube_regex_match = re.match(youtube_regex, url)
result = find_name(submodule, name)
result.append(qresult)
dirty_data[key] = cleanup(value)
format_float(buf, 100, v, PREC_REPR)
A * exp(-(x - x0) ** 2 / (2.0 * sig ** 2))
1 / 0
i, datei = next(pdates)
True
align_array = np.array([record.seq for record in records], np.character)
d2 = pickle.load(fp)
string
fake_writer = csv.writer(fake_csv)
Case(When(created__month=4, then=1), output_field=IntegerField())
l.append(x[start:i + 1])
ipywidgets.interact(create_plot, swapp_axis=swapp_axis)
DECLARE
cursor = connection.cursor()
result
to_be_serialized
self.items.append(item)
i = i - len(words[i])
plt.colorbar(im[i, 1], cax=ax[i, 2])
tag = list1[i + 1]
Ar = A.reshape(-1, A.shape[2])
cli()
fig, (ax1, ax2) = plt.subplots(nrows=2)
num2word.to_card(55)
S = [x for x in range(1000000)]
args = shlex.split(command)
q.mutex.release()
dfEmpty = pd.DataFrame([(c, b, 0) for b in Eperson for c in ets])
os.remove(f)
print(name)
p = next(ps)
history = self.poll()
self.max_number = max_number
s += float(i[:-1]) / 12
reencoded
s = pd.Series(np.random.randint(10, size=100), index=rng)
finalList = []
Z = sparsemax(X, Y)
res = defaultdict(list)
prime = False
parent_map = dict((c, p) for p in et.getiterator() for c in p)
sum_
self.listWidget = QtGui.QListWidget(self)
df
print(entry)
binary_insert(r, Node(1))
(value for value, dummy in n_apart(iterable, n))
widget = MainWidget()
bins = np.arange(0, 110, 10)
rollback()
domain_crawl(domain_pk)
self.factory.clientConnectionLost(self)
background_task.cancelled = True
grid = np.random.rand(4, 4)
print(pickled.var1)
print([p.energy for p in list_of_proteins])
print(sess.run(using_tensor_test))
x
xarr = np.array(xlist, dtype=dt)
f = Foo.Instance()
hash(x)
c = Counter(lst)
self.port = port
sum += distance(str1, str2)
KludgeDumper.add_representer(str, SafeRepresenter.represent_unicode)
longs = (np.random.rand(60, 1) + np.linspace(-np.pi, np.pi, 80000)).reshape(-1)
listOfSets = supersets
iterable = iter(iterable)
next_nearest_diff = pd.to_timedelta(next_nearest.values - dates.values).days
squares.append(x * x)
unicodedata.name(s[2])
result
tokens = [word for sent in sent_tokenize(text) for word in word_tokenize(sent)]
df
BOOST_PYTHON_MODULE(meta)
print(x[i][j])
a, b = np.arange(10).reshape((5, 2)), list(range(5))
context = ssl.create_default_context()
rand_bytes = rand_iter(0, 256)
heapq.heapify(openList)
w.show()
self._size = zipinfo.file_size
print(path, qs)
date.year
print(output)
draw.text(img.width / 2, 40 + i * 60, artext)
deletetime.sleep
canvas.drawString(15, i, linea.strip())
dqok = self._dqpush(request)
n = g.vcount()
main.show()
X = np.r_[X, np.random.uniform(low=-6, high=6, size=(n_outliers, 2))]
L1[0:1] = L2
myInput.close()
x_grad = np.gradient(x)
first_job_id = current_job.dependencies[0].id
degree_sequence = sorted(list(nx.degree(G).values()), reverse=True)
Hsub
numpy.genfromtxt(fname, **karg)
dk = list(d.keys())
length = len(str(int(last)))
mode = im.mode
item = _decode_list(item)
wordlist = f.read().split()
os.kill(pid, signal.SIGKILL)
Y /= (dx * Y).sum()
pool = Pool(4)
TRUE
ind = bisect.bisect(lis2, x)
s.strip()
self.children
property = db.StringProperty()
publisher = models.ForeignKey(Publisher)
year = week[:-2]
print(key, name)
optimize_result.x[0]
Session = sessionmaker(bind=engine)
nbors.append(i - 1)
uni2 = _decode_uXXXX(s, end + 1)
p = psutil.Process(pid)
assert chunk_length == int(chunk_length)
http_server.listen(8888)
newx.append(i)
self.grip = ttk.Sizegrip(self)
formatted(4.797)
formatted(4.001)
max_ = np.zeros((4000, 4000))
evens.append(number)
output_datetime = output_datetime + offset_delta
year_month_pairs = [(i.year, i.month) for i in formated_dates]
errors.append((srcname, dstname, str(why)))
a = np.random.rand(129, 129)
print(a.mul(d).astype(int))
new_arr = []
avg = Image.open(imlist[0])
list(map(auxparse, l))
input = sorted(chain(a, b, c), key=lambda x: x[0])
b = tf.Variable(tf.zeros([NUM_CLASS_BINS]))
bgs = nltk.bigrams(tokens)
youtube.NO_PREVIEW
handler(*args)
map(m.update, margs + mkwargs)
yc = m[0, 1] / m[0, 0]
textwrap.dedent(string)
axarr[1, 0].plot(x, y ** 2)
options, args = parser.parse_args()
print(dill.source.getsource(t.__class__))
print(c.base is a)
print(r)
suite = unittest.TestLoader().loadTestsFromTestCase(TestChronology)
midpoint = vor_.points[pointidx].mean(axis=0)
out = np.zeros(shape=(n_part[0], max_range.size), dtype=int)
d += 1
a if flag else b
s = f.read()
unq_count = np.diff(np.concatenate(np.nonzero(unq_first) + ([a.size],)))
np.log(scale), shape
cdir = os.getcwd()
process = processing.Process(target=func)
out = StringIO.StringIO()
out += str[bit].lower()
ch_set.append(ord(ch[0]))
file_data = f.read()
it1, it2 = iter(lst), iter(lst)
start = time.time()
N = 5
tag = audioFile.getTag()
False
print(node)
cppcode.init(address)
X_train = vect.fit_transform(features(d) for d in documents)
b, new_b = itertools.tee(b, 2)
count = lambda self, *args: self._tuple.count(*args)
r = circle_r * random.random()
m = csr_matrix(a)
url = sys.argv[1]
x1.sort()
self.__keys.insert(index, key)
K = np.ones(WSZ, dtype=int)
True
df
fp.write(part.get_payload(decode=True))
patches[1]
norm = cm.colors.Normalize(vmax=abs(Z).max(), vmin=-abs(Z).max())
print(x)
w = cos(theta)
input_array = np.random.random((rows, columns))
size = x.shape[0]
line_iter = iter(someFile)
result
df
fig.window.hide()
new_list.append(ch)
d = np.r_[d, [0] * k]
self.left = left
self.vals.append(new_val)
self.path = path
print(data)
Base = declarative_base()
memfile.seek(0)
print(s)
params = self._get_params(_data, kwds)
time.sleep(next_call - time.time())
print(obj.key)
value = map(lambda x, r=r: power(r, x), funcs)
width, height = picture.size()
result[k].append(word)
data = clipboard.GetText()
A * B
ac - ropemacs - setup
meth = web.ctx.method
end, date
print(x.get_string(border=False))
mappingsp[func](a, b)
c = np.vstack((fwd, bwd[::-1]))
root = Tkinter.Tk()
counts = Counter(words).most_common(100)
register = template.Library()
query = Person.all()
result
parents = inspect.getmro(child_cls)[1:]
top_row = 0
response_type, client_id = client_id, redirect_uri = redirect_uri,
ax = plt.gca(xlim=(-pi, pi))
chunk_end = chunk_start + chunk_size
total
names_previous[key].appendleft(val)
B()
counter[key] += 1
bar._high
root = Tk()
r.groupdict()
image_temp = copy.deepcopy(image)
fp.write(some_bytes)
loop = asyncio.get_event_loop()
ckpt = tf.train.get_checkpoint_state(FLAGS.checkpoint_dir)
True
categories = np.array([0, 2, 1, 1, 1, 2, 0, 0])
self.card = card
ns.b
b * d
description = models.TextField()
last = len(sorted_keys) - 1
stop_event.wait(1.0)
length = int(cap.get(cv2.cv.CV_CAP_PROP_FRAME_COUNT))
x, y = worldpoint
indices = list(range(len(s)))
print(row)
inclusive = i == len(binlims) - 1
print(result)
b[i] = min(b[i - 1], a[i - 1]) + 2
my_rhs
a.append(42)
text
level = 0
value = True
cumsum_vec = numpy.cumsum(numpy.insert(data, 0, 0))
xl = np.array([minxd, maxxd])
_secret_file = models.FileField()
a + b
vt = vt[:numDimensions, :]
it = iter(seq)
cookies = cookielib.CookieJar()
0
builtins = [getattr(__builtins__, s) for s in dir(__builtins__)]
d[k] = max(d[k], v)
action4.long_press(x=xx, y=yy + 50).move_to(x=0, y=-50).wait(500).release()
print(o)
+some_project_name
max_similarity = s.ratio() if s.ratio() < max_similarity else max_similarity
df_ctrl.loc[idx]
b = [1, 2]
unsw_mid_year_end_date = datetime.date(2015, 7, 12)
King.repress.__annotations__
print(x * y)
instance
MyFancyNumber(5)
self.__clean__()
print(prms)
user.username = testuser.upper()
d_keys
diff = difflib.unified_diff(expected, actual)
abstract = True
__STR__()
data = r.json()
sequence[index]
print(len(plus))
output
c = []
name = f.readline()
d1, d2 = a
axcoords = ax.transAxes.inverted().transform(coords)
sorted(items_list, key=score)
_setmode(fileno(stdin), O_BINARY)
painter = Qt.QPainter()
a[i + 1:] = reversed(a[i + 1:])
xml_result = tokens.asXML()
numerator = df.sum(1).mul(row.sum(0))
com.timeout = 1
tf.seek(0)
kwargs.setdefault(param, value)
x ^= len(string)
a = Foo()
row_tab = [str(row[0]).ljust(col_paddings[0])]
vset(args, val)
a, b, c = pos, start, start + length
lineArr.tofile(fileObj)
print(fmt(num))
obj.select()
p.parts[2:]
qtls = np.linspace(0.0, 1.0, num=numin, endpoint=False)
self.random_number = str(random.randint(1, 100))
object.__lt__(self, other)
example = tf.image.decode_png(file_contents)
length = len(d[6::2])
l.__reduce__()
{}
isint = lambda x: all([(ord(i) >= 48 and ord(i) < 58) for i in str(x)])
mag_func(s)
out
now = datetime.datetime.now()
divide(2, 7, 70)
rec = self.con.recv(1024)
F = [0] * (len(f) + 1)
print(std[i])
data1 = np.random.randn(N)
type(b)
formulae = []
fig, ax = plt.subplots()
blocks[i:j + 1]
log.addHandler(console_handler)
new_background = 255, 255, 255, 255
tokenizer = nltk.tokenize.punkt.PunktSentenceTokenizer()
app.debug = True
pd.__version__
p.feed(n)
center_window(500, 400)
setattr(copy, attr, getattr(self, attr))
str(int(x))
signum = getattr(signal, i)
print(director.allClasses)
job = Job.objects.get(client__id=1)
[noun.leaves()[0] for nouns in NNs_inside_NPs for noun in nouns]
indexing_with_clipping(arr, indices, clipping_value=0)
v.reserve(10)
mysocket.close()
lon = points[:, (1)]
key
rpt2 = lambda lst: len(lst) != len(set(lst))
sub = os.path.join(dir_path, directory)
nums.append(ans)
EMAIL_PORT = 587
index = np.argsort(tmp)
Y = lb.fit_transform(y_train_text)
map(term_importance, list(word_freq.keys()))
kill_proc_tree(me)
p.join()
meam = sum(x * y)
X = np.random.rand(9, 4)
Pdb
print(config.x)
K = npi.intersection(K, f(K))
something7
something8
change(item)
mux_fn = mux41(0, 1, 1, 0)
y = float(str(w)[:-2])
c = models.IntegerField()
modify_Person_to_be_friendly()
struct.unpack(fmt, string)
word_map[w] += 1
words = []
codecs.BOM
randIndex = indices.pop(np.random.randint(0, high=len(indices)))
hf1.flush()
s2.values.append(4)
process_file(fn)
print(lat, int)
d = KeyDict()
self._target.start(tag, attrib)
url = str(url)
self.method = method
s = io.StringIO()
threading.Thread.__init__ = init
print(line)
print(mydocs)
print(row)
t = (t & 15) + ((t & 240) >> 4)
Shell_NotifyIcon(NIM_DELETE, nid)
layout.addWidget(self.led, 0, 0)
bv << 6
axarr[1].plot(xf, 2.0 / N * np.abs(yf[:N // 2]))
most_similar_words = model.most_similar([model_word_vector], [], topn)
self.value_ + rhs.value()
out.append(current)
0.54, 0.57, 0.51, 0.605, 0.57, 0.65, 0.642, 0.6, 0.66, 0.7, 0.688, 0.69
res[index_i] = roll(a[index_i], -i * strength, shift_axis)
plt.show()
response = HttpResponse(wrapper, mimetype=mimetypes.guess_type(filename)[0])
noduplicates = []
print(json.dumps(user, default=json_util.default))
rules = Rule2
invert[value].append(key)
count += 1
x.m(1)
2 * i
demean = lambda x: x - x.mean()
print(df)
w_h = tf.Variable(tf.random_normal([n_in, n_out], mean=0.0, stddev=0.05))
p = mp.Pool()
an_instance.g()
hash(self.val)
self._pool.append(close)
getattr(self.wrapped, name)
print(dis.dis(testMethod1))
digits.reverse()
print(string)
my_array
setuplogger()
m.iloc[1] = np.nan
p_func = frame.f_back.f_code.co_name
count
s.add(line)
leglines.extend(legline)
new_data = json.loads(json.dumps(np_data))
current_line_no - previous_zoro_ind
self._uniqueid
self.feed = 0
newimg = imresize(img, (6, 5))
platform.linux_distribution()
float(_)
module._shutdown()
unittest.main()
redistributed_points.append(p + t / n)
o = getattr(module, name)
self.right.insert(othernode)
length, i, item = len(lst1), 0, lst1[0]
start, end = 0, len(seq_in)
BOOST_PYTHON_MODULE(foo)
df
ET._Element.__init__(self, tag, dict(attrib, **extra))
dict = {(2): 5, (6): 2}
t = np.linspace(0, 1, 500)
y = np.ravel(np.tile(np.arange(ny), (nx, 1))).reshape((nx * ny, 1))
outputs = [result[0] for result in results]
SomeObject.objects.create()
k, v = next(iter(list(d.items())))
fig = plt.figure()
words.append(word)
pc.extend([c, c, c])
A = [0] * len(matrix)
module_1.py
d = (c[1:-1 - k] - c[:-2 - k]) * k / dt
self._bandwidth = bandwidth
[0, 1, 2]
False
idx1 = np.argwhere(flag.T > 0)
ns = ns[2:]
a = myarray[i][j]
d = {}
sort_idx = np.argsort(full_arr[:, (idx)])
driver = self.selenium[browser]
f = SomeFilter(request.GET, queryset=f.qs)
write_list(MyList)
scene.camera.rotation_euler[2] = rz * (pi / 180.0)
max_len = max(max_len, len_current)
pos = nx.spring_layout(G_pc, pos=pos, fixed=fixed_nodes)
labels = [c for c in string.uppercase if c not in exclude]
COMMIT
plt.figure()
x = A.__class__(b.shape)
df = pd.DataFrame(np.random.random((10, 10)))
fo.seek(0)
current_count = query.count()
cv.drawContours(im_bw_inv, [cnt], 0, 255, -1)
list(b.keys())
cleanup_stop_thread()
b = np.array((2, 1))
r = list(range(N))
x[idx, J, I]
dropped.axes[axis_].set_names(axis.names, inplace=True)
answer0 < -unlist(answer0)
values = data.values
b = a[t, J, y, x]
print(k)
line = 1
string.uppercase[5:] + string.uppercase[:5]
accum = np.ones((na, nb), dtype=bool)
have_reflection = np.linalg.det(T) < 0
cursor = db.col.find()
apply_vectorized = numpy.vectorize(lambda f, x: f(x), otypes=[object])
l = s.split()
s = mapnik.Style()
field = name, desks
remainingStr = pattern.sub(subst, remainingStr, 1)
df
img = tk.PhotoImage(data=icon)
prms = [i for i in p]
last_match.group(*indices)
d2 = date(2008, 9, 15)
print(x)
sign * 2.0 ** -24 * prec
dates = pd.to_datetime(dates.values).date
b = np.array([9, 8])
sequence[0:5:1] == sequence[0:5] == sequence[:5]
table.create(schema=table_schema, overwrite=True)
df = pd.DataFrame(df)
print(re.sub(expr, replace_by, mystr1))
l1.extend(l2)
self.finish()
foobar2000 = False
print(df)
y = np.array([np.pi * np.sin(X).ravel(), np.pi * np.cos(X).ravel()]).T
type(p.fields)
C()
False
xfx(exampleIterable)
imp = int(eval(input(prompt)))
df1 = eventsDf.comment.str.extract(regex, expand=True)
f = lambda x: x ** (1.0 / 2)
print(time.time(), msg)
columns = {c: c.strip() for c in df.columns}
pickle.dump(tokenizer, out)
q.put(c)
links.append(self.re_encode(href))
filename = mod.__file__
names = [record[0] for record in records]
new_position = file.tell()
True
f.write(session.get(full_link).content)
axis.set_minor_formatter(NullFormatter())
db = connection.mydatabase
cmp(ai, bi)
shuffle = np.random.shuffle(all_nodes)
Ham1 == Ham2
lang.clear()
fig, ax = plt.subplots()
sin(pi * x) / (pi * x) if x != 0 else 1.0
a = list(range(100, 400, 100))
form = ModelForm()
batched_inputs, batched_labels = model.batch_data(array_input, array_labels)
xml.etree.ElementTree.parse(f)
args = locals().copy()
cr.stroke()
n = mat.shape[0]
a = np.random.randn(40)
g = lambda x: f(x)
handle = urllib.request.urlopen(request)
ranges.append(group[0])
a = C()
self.total = 0
req1 = urllib.request.Request(url1)
SubjectLocation(1295, 967, 699, 696)
f.close()
foo(4)
main()
non_list_items = []
PID = os.getpid()
dummy_wrapper
stdin = subprocess.PIPE
Editor.with_box(ffmpeg=int, box=2)
print(np.allclose(gpu_out2, cpu_out2))
for_df
count = 0
scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=cm)
DTYPE = np.int
b = sum(li[:2])
myfile.write(data)
screen = pygame.display.set_mode(size)
a - b
buffer = StringIO.StringIO(json_to_write)
DIRECTIVES = {}
L = list(range(100))
now = datetime.now()
sides = [a, b, c]
application = tornado.web.Application(handlers, **settings)
killtime = time.time() + timeout
Point(self.x, -self.y)
print(err)
sftp.put(localfile, remotefile)
urljoin(url1, url2)
JM2 = np.zeros((N, N, N))
JM1 = np.zeros((N, N, N))
dir(e.args[0].reason)
innerFunc(2)
print(final_list)
correct_pred = tf.equal(tf.argmax(out, 1), tf.argmax(y, 1))
shutil.copyfileobj(req, fp, length)
print(a, b, c)
new_wb.save(dest_filename)
print(val)
ax_local.set_axis_off()
a = np.arange(h * w, dtype=np.uint8).reshape((h, w))
print(data.verb_list)
5
self.free = []
My = np.zeros((n, n))
self._tunnel()
writer = csv.DictWriter(csv_file, fieldnames=fieldnames)
self.extend([self.default] * (index - max_index))
thiselem = li[idx]
df.skew()
c = a.copy()
s = backend.session()
pickle.Pickler.save(self, obj)
arr2 = arr.reshape((arr.shape[0] * arr.shape[1], arr.shape[2]))
win()
image = cv2.cvtColor(image, cv2.cv.CV_BGR2RGBA)
False
key = x.lower()
-infinity
print(dataAC)
d[i] += 1
y = np.random.random(numdata)
id = s.Column(s.Integer, primary_key=True)
dictList = []
answer = []
min_freq = 0.0
node = self.parser._end(tag)
dic = {}
loop = aio.get_event_loop()
self.obj[frozenset(idx)] = value
print(response.read())
True
a = etree.tostring(a)
i = int_gen(4)
intersection = keys_a & keys_b
0
k += 2
result = [func(group) for group in np.split(vals, inds)]
L1 = [1, 6]
args = parser.parse_args()
c = [(r[i], r[j]) for i in range(len(r) - 2) for j in range(i + 2, len(r))]
print(dir(Test))
amoServer.Connect(serverName)
SPN.shape
print(i)
inner
self.vsb.config(command=self.text.yview)
str(td)
pixelcount = img.size[0] * img.size[1]
intervals = [1, 2, 5, 10, 100, 1000, 10000]
print(schema)
buffer_from_memory.restype = ctypes.py_object
end = int(args[1])
scaler = make_interpolater(1, 512, 5, 10)
result.append(right[j])
{key, [origin_2, values]}
dom = lxml.html.fromstring(connection.read())
fpconst
False
df
sample = np.exp(logsample)
there = re.compile(pattern)
st = set(b[1])
result
file_obj.seek(my_offset)
{{gallery}}
cm.print_stats()
dtrange = pd.date_range(begin, end)
db = SQLAlchemy(metadata=metadata)
corpus = [dictionary.doc2bow(i) for i in tdm]
content = template.render(context)
endy = obj.ax.y(d[1])
[0.0, 2.0, inf],
print(bid)
print(self.server_address)
i = arr.searchsorted(total - t)
currentAxis = plt.gca()
True
self.swallow = swallow
results.update(import_submodules(full_name))
build(trailneg)
doSomethingWithFile(f)
records.sort(key=lambda x: x.code)
[]
writer.writeheader()
r, c = np.tril_indices_from(B2[0, 0])
print(a)
canvas = Canvas()
str_now = now.date().isoformat()
tree = ET.fromstring(xml_data, parser)
method_name = method_code.co_name
output_img = img.copy()
W = numpy.random.random((L_out, L_in + 1))
t -= 2208988800
df.eq(df.max(1), 0).sub(df.lt(0).mul(9999))
x + a
data = f.read(data_len)
res += chr(27) + chr(idx)
print(a)
print(line)
print(df)
actions = []
png_output = StringIO()
console.setLevel(logging.ERROR)
cls.__doc__ = base.__doc__
writer = csv.writer(outfile)
M[(i), :] *= s
pubkey = get_pub_key_from_crx(crx_file)
b.sort()
prevnode.right == node.right
config = cp.ConfigParser()
z.append(pt[2])
print(link.attrs, link.contents)
data, addr = s.recvfrom(1024)
System.out.println(testObj)
relFile = os.path.join(relDir, fileName)
print(j.name(), j.antonyms()[0].name())
print(nth_root(1, 100))
self._items.add(item)
anArray[h][w] = getRGB(p)
func(self, *args)
foldl(add, 0, xs)
assert pubkey.verify_final(signature) == 1
deleteself._weapon
k = N / (sigma * math.sqrt(2 * math.pi))
shutil.copyfileobj(header_file, new_file)
characteristic = Characteristic()
config.scan()
Xi, Yi = np.meshgrid(X, Y)
obj = xmltramp.parse(xml_string)
a, a_copy = itertools.tee(a, 2)
line = f.readline()
2011 - 11 - 7
filename = path.join(dirname, filename)
records[l] += 1
id(a[0])
Model = scrapy.Field()
print((section, df2.std()))
y = np.asarray(y)
data_flat = np.ravel(data)
r, c = np.triu_indices(s.shape[0], 1)
TestApp / testapp / sub / testprinter.py
a = a + 1
partial(myfunc, arg2=1).keywords == partial(myfunc, arg2=1).keywords
print(str(result.query))
notebook = gtk.Notebook()
raise ValueError
self._name = value
r = Tk()
links
iterator = iter(iterable)
x = set(l1).union(l2)
print(dec_num)
s1.index = list(range(0, len(s1) * 2, 2))
not_seen = lambda x: not (x in seen or seen.add(x))
((A - Cmin) / dif + (B - Cmin) / dif + (C - Cmin) / dif + (D - Cmin) / dif) / 4
value = [val[5] for col, val in dictionary.items()]
f = urllib.request.urlopen(req)
print(map(fib, list(range(10))))
img = np.arange(256 * 256).reshape((256, 256))
[(topicid, topicvalue) for topicid, topicvalue in enumerate(topic_dist)]
df = df[df.State != df.RegionName]
self._parser = configparser.ConfigParser()
x = f(x)
a.additional_data = [b for b in list_b if b.modela_link_id == a.id]
iequal(4, 2)
_.shape
s.add(x <= x)
a = 1
L = list(word)
contents = f.read()
print(entry)
self.argv = self.argv[1:]
x = np.arange(20)
col_uni_val[i] = len(df[i].unique())
lib.DoSomething(np.ctypeslib.as_ctypes(row))
raw = nltk.clean_html(html)
list(common_entries(da, db))
i, j = 0, 0
last_row_name = df.index[-1]
packet = Ether() / IP(dst=host) / ICMP()
rows
self.name = name
dfd.addCallback(the_end)
F1 = np.cumsum(H) * dx
out.append(it)
google_dict[i] = item
basename = os.path.basename(dirname)
False, s
cities.append(cities)
a * t ** alpha + b
app = QtGui.QApplication([])
b = 2
rank = np.sum(s > 1e-10)
2
xml = template % (id, name, puid, version, mimetype)
prefix_len = len(a[0])
send_somewhere(traceback.format_exception(*sys.exc_info()))
fdata = fly.get_data()
rowlength = grouped.ngroups / 2
print(T(lambda : tree(PLIST)).repeat(number=100000))
args = tuple()
Func(lambda x: self(x) * other(x))
x = np.random.rand(4, 5)
cipher = AES.new(self.key, AES.MODE_CBC, iv)
consumer.daemon = True
p.daemon = True
df1
bitflag = 0
page = requests.get(url)
val
access_token = dict(urlparse.parse_qsl(content))
0, 0, 1
mask = mask[:, :, (NP.newaxis)]
groups = []
pprint(records)
subparsers.required = True
newshape = np.where(np.array(arr.strides) == 0, 1, arr.shape)
img.save(name)
new_module
a = foo()
Py_DECREF(item)
prefixed.append(candidate)
x_max = tf.reduce_max(x, reduction_indices=[1])
process.append(bench_map[bench_name])
print(example.py)
type(s)
contents = urlfetch.fetch(url).content
n = 10
print(x)
frame = models.IntegerField()
opener = urllib.request.build_opener(HTTPSudsPreprocessor)
all([fn(x) for fn in enabled]) and x % 2 == 0
self.test_panel.SetAutoLayout(1)
s = d.screen()
z2 = mlab.bivariate_normal(0, 2 * sigma, sigma, sigma, 0.0, 0.0)
root = dict()
self.id.__hash__()
self.size = 0
coolness = zip(lettered, plusone)
print(s)
self.fail(reason=str(error))
fcs.dwSize = sizeof(fcs)
print(t[1])
f.write(document)
z = zipfile.ZipFile(file=mock_file)
1
N = random.randrange(100)
A = User()
print(n)
dc_files.pop(index)
[1, -1, -1, -1, -1]
worker(cnt, res, len(l) - 1)
sorted_indices = np.argsort(values)
temp_list = []
id | date | user_id | product_id | amount
memsetObject(testObject)
1 / 0
y = np.random.randn(100)
myScaledPixmap = myPixmap.scaled(self.label.size(), Qt.KeepAspectRatio)
print(split(a, a < 5))
text
t2 = time.clock()
vector1 = matrix1[:, 0:1]
self.setCentralWidget(self.central_widget)
plt.figure(figsize=(800 / my_dpi, 800 / my_dpi), dpi=my_dpi)
m = int(m)
dis.dis(func1)
keylist.sort()
f.close()
self.data = list(data)
arr = [6, 4, 2, 1]
doStuffWithObj(obj)
cpy = copy.copy(self)
overflows = [[] for n in input_lists]
hex(decoded)
read_only = True
sheet = list(csv.reader(open(source_path)))
print(number)
self._b = b
copy_of_a = copy(a)
volume = 100
t = self.es.search(*args, **kwargs)
f = pandas.Factor.from_array(s)
func1.__name__ = name
polygon = points[:-1]
ConvexArea = cv2.contourArea(ConvexHull)
variable = int(stringToInt)
sign + alphabet[number]
dfs.append(dfm)
cache[args] = result = f(*args)
daemon_runner.do_action()
form = ResendActivationEmailForm(request.POST)
s = pd.Series(values, index=df.index)
filename = module.__file__
color_dict[v] = colors[idx]
fields[name] = attr
b1.append(x)
xscreen = ax.transData.transform(zip(x[-2::], y[-2::]))
testdata = [[5, 6, 8], [], list(range(8)), [42]]
config.x
print(newStudent.name)
results_key = line[0:7]
folders.reverse()
end = datetime(2012, 10, 6)
my_eni_sg_ids = [x.id for x in my_eni_groups]
i = p.integ()
jsonResponse = json.loads(decoded_response)
stdout, stderr = processes[1].communicate()
(2 < arr) | (arr < 6)
foo2(10)
A = [tuple(a) for a in A]
splitter.setWindowState(Qt.WindowMaximized)
print(list)
worker_threads.append(worker_thread)
data = []
input_str
parser = my_argparse.MyArgparse()
matrices = [np.random.randn(1000, 1000) for ii in range(10)]
d[k] = u[k]
a[i] = i * i
print(image2.shape)
AIsVCP = 0
form = authentication_form(request)
doc = LH.fromstring(tekst)
mpl.dates.num2date(starts), mpl.dates.num2date(stops)
prevnode.left = node.left
op, code = s[i:i + 2]
n = x.shape[1]
WW = sp.ndimage.gaussian_filter(W, sigma=2.0)
x + y
solutions
inv_A = np.linalg.inv(A)
next(it2)
item = CustomItem()
a = s.toarray()
Z = Z.reshape(xx.shape)
a = np.random.randint(0, 1000, 10000)
start_node.parents.add(node)
miny, maxy = ax2.get_ylim()
vote2 = votemil[:spaceindex]
path, filename = os.path.split(sourceFile)
strategy.BacktestingStrategy.__init__(self, feed)
code5
deviceid
b = pd.DataFrame(a)
count = 0
conn.close()
ret.append((item0, item1, terms[item0][item1]))
temp.extend([key, value])
c.insert(0, i)
item4
multi_line_word << (word ^ split_word + multi_line_word)
self._generate_conf()
pprint.pprint(make_combos(6, 12, 4))
print(self.path)
steep = abs(dx) < abs(dy)
int(21 / 5)
posix_timestamp_micros = (now - epoch) // timedelta(microseconds=1)
pick_0_2 = itemgetter(0, 2)
pdf = stats.norm.pdf(x, loc=estimated_mu, scale=estimated_sigma)
not any(chain(*x))
res = compress(xy, [(item[1] > 0) for item in xy])
label1, label2, edge = line.strip().split()
AX_SWIG_PYTHON
set.remove(list)
iter = xquery.iterator()
print(arg)
self.result = []
birth_years[name[i]] = year[i]
self.run(translated_name, kwargs)
self._swallow = swallow
ws._cells = new_cells
d = {}
soup = BeautifulSoup(unicodestring_containing_the_entire_htlm_doc)
euid = os.geteuid()
print(_int)
ET.tostring(x)
po.join()
arr = (c_short_p * len(numpy_arr))()
print(df)
s = set()
print(len(args))
gevent.sleep(0)
STD_OUTPUT_HANDLE_ID = c_ulong(4294967285)
data = pd.read_csv(filename)
transform = ET.XSLT(xslt)
repr([2])
self.path = pg.arrayToQPath(x.flatten(), y.flatten(), connect.flatten())
y = np.ravel(y)
unique0 = list(lines[0].keys()) - list(lines[1].keys())
fp.write(contents)
yi = numpy.abs(y - y0).argmin()
count[c] = count.setdefault(c, 0) + 1
infile.seek(start)
multiple_conv_out = [repeated_conv.flatten()] * np.prod(self.poolsize)
a = a + b
counts = [1] * 5
arr = arr[~(arr == 255).all(1)]
recursive_check(url, pat.urls, names, args)
mylist += [[circle.m[0] + circle.r, 1, i] for i, circle in enumerate(circles)]
box = ttk.Notebook(root, width=1000, height=650)
endif
res = conn.execute(select)
NotImplemented
word_len = len(SEARCH_WORD)
print(rand_num)
item
results[X[:, (0)] != 1] = self.kNN.predict(X[X[:, (0)] != 1])
deleteancestor.getparent()[0]
session.Logoff()
d = {}
p = bk.figure()
a2 = a1.reshape((2, 2))
num = 0
writer.book = book
print(list(reader))
CSS_SIZES = list(range(1, 7))
foo(1, optional=4)
myFunction()
noisy = False
p = Pool(now)
{(int_start(int1) <= int_end(int2)) & (int_start(int2) <= int_end(int1))}
list2 = list(range(0, 100))
resp = r.json()
exit()
2
app.MainLoop()
print_as_octave_bit_hex(x)
items = list(DATA.items())
divider = make_axes_locatable(ax)
config_no_auto.solar.zenith_angle
self._graph[node2].add(node1)
CLOCK_MONOTONIC_RAW = 4
100
d = dict()
deleteself._deletes
days_ahead += 7
OrderedDict(sorted(list(d.items()), key=lambda t: t[1]))
dategmt = gmt.localize(date)
entry = q.pop()
[mssql]
CS = plt.contourf(xi, yi, zi, 15, cmap=plt.cm.jet)
longest
print(d)
print(i)
sum(1 for x in takewhile(lambda x: x[0] == x[1], zip(self, other)))
self.bar(**inputs)
cars = query.fetch(limit)
DictEntry.objects.get(keyword=repr(something)).definition
time.sleep(0.015)
[1]
df
seen_add = seen.add
self.counter += 1
fig.autofmt_xdate()
k = len(point_list[0])
numpy.array(list(range(10))).__str__()
fig.colorbar(scalarMap)
driver.start()
gc = pygsheets.authorize()
result = max_value if result > max_value else result
FINDER_LABEL_NAMES[idx]
mockType = type(name, (), {})
convert = t.eye(n, n)[v]
addr = ctypes.addressof(num)
out[0] = out[0].getvalue()
image_data = get_page(pdf_path, page_number - 1)
print(i)
m = re.match(regexp, email_address)
y = x.map_overlap(derivative, depth=1, boundary=0)
args[arg]
send_mail(body, author, subject, to)
main()
init = tf.group(tf.initialize_all_variables(), tf.initialize_local_variables())
init_W = numpy.array([2.0] + [0.0] * numTeams)
server_thread = threading.Thread(target=server.serve_forever)
level_values = df.index.get_level_values
x = read_next_byte()
dis.dis(indict)
(100 * pq.degC).rescale(pq.degF)
getch()
delta = np.abs(lonlat - [x, y])
0
self.parent = parent
y_h, x_h = arr_h.shape[:2]
self.a = A(num, self)
copy.append(child.clone())
intBuffer.get(dst)
tick_gen = ScalesTickGenerator(scale=euro_scale_system)
rows = cursor.fetchall()
mySearchTree = fromstring(your_input_string)
string_to_write = json.dumps(my_list)
newPos.setX(qMin(rect.right(), qMax(newPos.x(), rect.left())))
testreader = csv.reader(testr)
a += a.T
a[10:20:2] = 1
Z.shape
x += 1
axes[1].plot(zi)
temp = random.randint(0, total)
print(full[x, y])
disps = disps[second_mask]
any(_has22_iter(it))
word_list = open(filename).read().lower().split()
print(row)
xl.sheet_names
crawler.signals.connect(instance.spider_error, signal=signals.spider_error)
test_labels = np.array([labels.index(x) for x in test_labels])
a = np.random.randn(10000, 1000)
x = [].append(1)
newGuess = (n / oldGuess + oldGuess) / 2.0
sio.seek(offset)
arr = numpy.ascontiguousarray(arr)
pool.close()
buf = [[], []]
venue = Event.objects.filter(venue__id=venue_id)
14285714285714285714285714285714285714285714285714
c.f = types.MethodType(C.f, c)
print(repr(B))
cython.char
_zfit = zfit * 1
fid = ContentFile(content)
muls = [mul(items) for items in numbers if len(items) > 1]
n, d = expr2.as_numer_denom()
obj
distrib.rvs(size=10)
vars = {}
np.vstack(np.unravel_index(idx, dims)).T
self.type = type
charlist[0]
self.all[self._key] = self
IeThread().start()
[-5]
assert answer([2, 2, 2, 2, 4, 4, 5, 6, 8, 8, 8]) == 90
self.right = right
data = self.clientSocket.recv(1024)
imshow(raw)
chromosome = [1, 2, 1]
1 - y | 2 - y
data[name] = text[:length].rstrip()
Cenia
p[0].set_data(xn, yn)
freduced.roots()
cs.head(10)
df_out = pd.DataFrame(out, index=index, columns=df1.columns)
newfile.write(str(packets[0]))
sys.excepthook = excepthook
pypy - -version
file_to_be_saved = ContentFile(pdf_contents)
weights = pd.Series(y_err)
main()
m[df.A]
clf.partial_fit(X2, y)
raise IOError()
pydir = sys.argv[1]
nsamples = A.size
df_a
c = a + b
idx = np.array([a, a]).T.flatten()[:len(a)]
count = 0
print(x)
np.random.seed(2015)
print(path[1])
[sp.Poly(num, x).all_coeffs(), sp.Poly(denom, x).all_coeffs()]
self.children = children
x[k] = x[kr]
DoGravity(Particle[i], Particle[j])
data = json.loads(JSON)
auth = tweepy.OAuthHandler(api_key, api_secret)
angle += 180
u = (x - xmin) * ((umax - umin) / (xmax - xmin)) + umin
now_d.callback(buffer)
recursive_del(d[k], keep)
out.seek(0)
b[s, s]
print(Player(1).uniqueid)
result.group(1)
ax = figsn.add_subplot(1, 1, 1)
player.play(filt(sig), rate=rate)
children = []
df[cols] = df[cols].applymap(np.int64)
MIDCAP
SMLCAP
GREENX
CARBON
INFRA
CPSE
rows, cols = im.shape
kls = cls.__items[ext]
widget.attach(self)
out = []
members = inspect.getmembers(Foo)
path = self.get_cookie_path(app)
answer
TestResult.addFailure(self, test, err)
self.slice = slice(-len(self.view) - 1, self.base.size)
result
LIVEHOST = False
cosine(pink, blue)
y = np.arange(5 * 5, 5 * 5 * 2, dtype=np.long).reshape(5, 5)
MemberQuerySet(self.model, using=self._db)
count = 0
color_mask_hsv = color.rgb2hsv(color_mask)
print(i)
self._inner[index] = value
lst = [-4, -2, 1, 2, 5, 0]
regexes = []
self.k = random.randint(1, 10)
coords = np.array([yy, xx])
two_d[1, 4]
title = db.StringProperty(required=True)
find_crossings(data, -1290)
result = list()
div_sum - num
CharField.register_lookup(SpaceRemovedValue)
self._apply_mocks()
Accnt.code
[tuple(u) for u in combos]
array = np.atleast_2d(array)
WORKDIR / opt / app
val ^= 1
result = pool.apply_async(f, [10])
metainfo = bencode.bdecode(torrent_file.read())
SOCIAL_AUTH_GOOGLE_OAUTH2_IGNORE_DEFAULT_SCOPE = True
Manufacturer = MagicIncorporated
am - 0.007 - 0.007
li = st.split()
print(int(args.square) ** 2)
html = requests.get(url, params=url_args)
sub_folders_list = glob.glob(sub_folder_pathname)
indices = []
s[:2]
True
b = B()
datei, i = next(pdates)
s = Session(e)
shutil.rmtree(outpath)
list(izip_short(a, b))
bfd.inc((w1, w2))
make - j8
rdf = com.convert_to_r_dataframe(df)
self.register_queue_hooks()
dir(B)
print(trainer.train())
ans
f = (F(n) + F(n + 1)) / F(n - 2)
i = 100
ind - ind2
bar = {}
utc_dt = tz.localize(dt, is_dst=True).astimezone(pytz.utc)
log.info(keys)
per = tota * 100.0 / 500
len(someitem) < 60
v = [0, 1, 0.5]
count = 0
filters = MyFilterSet(data)
mail = email.message_from_string(s[0][1])
twosidedtagger._train(train_sents)
str
mydict = {k: (0) for k in range(10)}
hello(data)
s1 = sum(x for x in samples)
batch.append_cypher(cypher_merge_user, params=dict(name=screen_name))
new_arr[idx] += 1
post_save.connect(save_mymodel1_count, sender=Mymodel1)
d1 = collections.OrderedDict(d)
print()
mock_retry.assert_called_with(exc=error)
countMap[v] = countMap.get(v, 0) + 1
cnts = np.diff(np.concatenate((first_idx, [ref_sort.size])))
counter += 1
linecount += 1
names, cumprobs = [], []
ss = np.flatnonzero(m[1:] != m[:-1]).reshape(-1, 2)
print(i())
type(my_pandas_frame)
L, F = powLF(n // 2)
G_pc = nx.Graph()
str(1.0)
sigma, scale = lognorm_params(mode, stddev)
counter += 1
l = len(x) - 1
res = {}
zipped = zip(*list2)
match = pattern.search(string, match.end())
word
with_groupby(df).equals(with_groupby(df))
Py_XDECREF(pFunc)
svm_y_train = numpy.array([(0) for i in range(2000)])
ostart = max(ustart, vstart)
key_result = {}
str(o)
result.append(name)
kernel.integrate_box_1d(-numpy.Inf, x)
with_idx = ((sum(v), i) for i, v in enumerate(x))
j += len(arr)
nameserver = default.query(authority).rrset[0].to_text()
x = defaultdict(lambda : defaultdict(Counter))
y0 = np.cos(x)
print(area.name, roles.name)
n = n % len(seq)
zp = R[2] + np.sin(relev) * (self.dist + zoom_out)
sum_arr = sum(arr)
choices = np.zeros((n,))
self.a = a
print(row[0])
result.append((x.v, x.t, x.c))
page_text = page.read()
Acut = Ap[np.ix_(np.arange(N) + x, np.arange(N) + y)]
pivoted = pivoted.sort_index()
postvars = cgi.parse_qs(self.rfile.read(length), keep_blank_values=1)
arr[jrow, jcol] = col
A = numpy.array([5, numpy.nan, numpy.nan, numpy.nan, numpy.nan, 10])
values.mean()
self.current
s = np.sin(x * y * z) / (x * y * z)
stat2 = {}
t1 = tz.localize(t1)
result = b[d > TOL]
med.sort()
loop = gobject.MainLoop()
sigh = 10
cause = e.__cause__
timeit(lambda : list(emptydict.keys()))
readnames = next(reader)
t = 0.24
context = etree.iterparse(xmlfile)
self.left = othernode
xx2 = xx1
self.word = random.choice(lists[category])
_memoizer
fig, axes = plt.subplots(nrows=2)
d
thread1.start()
p.data -= 1
self._val = np.array([w, x, y, z])
b = models.IntegerField()
bdata
ciphertext = base64.b64decode(encoded)
fesetround(FE_TONEAREST)
print(majorkey)
self._unique += 1
soup = BeautifulSoup.BeautifulSoup(html_data)
a = f()[2]
x1 = next(y)
Q = ureg.Quantity
orig_spam = spam.__closure__[0].cell_contents
grid, _, _ = np.histogram2d(x, y, bins=[gridx, gridy])
df = pd.DataFrame({name: mat[name][:, (1)] for name in mat})
print(mystuff.average())
arr = df.values
iter(self._myattrs())
ranges = []
assert datetime.timedelta(days=7) < then - now <= datetime.timedelta(days=14)
d = models.IntegerField()
self.logent[bow]
current = browser.window_handles[0]
configparser.RawConfigParser.__init__(self, defaults)
y = np.sin(t)
caseSensitivePath = f.read()[:-1]
env = Environment(**kwargs)
y = [0, 0, 1, 1]
print(stdout)
wnd = GetConsoleWindow()
dict_orig.update(dict_add)
swap(leftFork, rightFork)
foo_dom = parseString(xmlrpclib.dumps((json.loads(somejson),)))
summation
item = QTableWidgetItem(col)
f = StringIO(jstring)
f = MyModel()
a = Mynum(1)
button.on_click(add_button)
print(a)
a = np.zeros(500000)
p1 = np.array([1, 1])
wrapper.__name__ = func.__name__
distances[-1]
path = path.lstrip(os.sep)
pylab.ion()
(A, A)(A, B)(B, A)(C, C)
docs = []
cons_max(df, 5)
idx = sorted(range(len(U)), key=U.__getitem__)
constants.py
resp = self.get_detail(request, pk=pkval)
spec = inspect.getargspec(f)
0
errcolors = [self.errcolor] * len(offpos)
gg = graph.graphxy(width=0.2 * figwidth, x=xxaxis, y=yyaxis)
self
ktok = 1
cat / proc / bus / input / devices
sns.reset_orig()
runs_scored, runs_allowed = map(float, league[team])
C = A.copy()
print(a.data.as_ints[0])
TAG_REGEX = re.compile(TAG_EXP, re.UNICODE | re.IGNORECASE)
b = bf.save(commit=false)
A.f
sm.SendSMS(message)
tz = get_localzone()
rows = cur.execute(SQL).fetchall()
set_up()
v_abs = sqrt(v[0] ** 2 + v[1] ** 2)
double = lambda l: [(l[x] * 2 if x % 2 != 0 else l[x]) for x in range(len(l))]
dX = np.abs(XX - XX.T).reshape((1, X.size ** 2))
t = Thread(target=myfunc, args=(i, mutex))
print(meta_data)
results = expr.parseString(s)
out = []
CvtColor(input, output, CV_GRAY2BGR)
weights = weights / np.sum(weights[:])
app_infos = gio.gio.app_info_get_all_for_type(mime_type)
pl.spy(A, precision=0.01, markersize=1)
parent = psutil.Process(pid)
timer = timeit.Timer(calculation)
achievements = Achievement.objects.all()
content = page.read()
Pickler(file, 4).dump(obj)
print(s)
pydot_graph = G.to_pydot()
ylim = min(ylim[0], np.nanmin(yc)), max(ylim[1], np.nanmax(yc))
VV = sp.ndimage.gaussian_filter(V, sigma=2.0)
print(d[42])
self.data = list(data)
s = set(list1)
style = mapnik.Style()
foo2(1)
data = conn.recv(BUFFER_SIZE)
dirs.sort()
b.shape = 12,
iscell = True
prev_weekday(date.today())
foo2 = Foo()
digitized = (float(nbins) / (r1 - r0) * (x - r0)).astype(int)
os.close(slave)
data = zip(*data)
True
grid()
SECURE_SSL_REDIRECT = True
response = h.getresponse()
fib(a + b, a, n - 1)
max(paths(ranks), key=len)
arr_2 = [random.randrange(0, 5) for _ in range(10)]
b.name
new_list.extend(temp_list)
old_init(*args, **kwargs)
h = np.array([1.0, 0.5])
0
subs.append(s[0])
print(file_handler.readlines())
wintypes.LPWSTR(filename),
op(x, axis=axis, skipna=skipna, **kwds)
cos_lon_d = np.cos(pos1[..., (1)] - pos2[..., (1)])
x = 4
a_ = a[s]
self.home = home_func
bad_files.append(f)
self._kids.append((args, kwargs, result))
groups
charNull = models.CharField(max_length=10, null=True)
sums.append(sums[i] - a[i] + a[i + wlen - alen])
current < max
model = Media
Base = declarative_base()
vector = matrix.flatten(1)
scotts_factor = np.power(n, -1.0 / 6)
object_id = indexes.IntegerField()
imageBox = image.getbbox()
obj.thread.word_count = sum(c.word_count for c in obj.comments)
print(ans)
x = NP.random.randint(1, 10, 10)
ips.insert(location, ip)
current_color = picture.getpixel((x, y))
values = np.bincount(inverse)
main()
pylab.axis([0, max(x), 0, max(y)])
socket = context.socket(zmq.REQ)
f
f = urllib.request.urlopen(request)
clipboard.SetClipboardText(array_string)
x * x
close_connection()
col.insert(value)
fft_mag = numpy.abs(numpy.fft.fftshift(numpy.fft.fft2(im)))
p = Pool(initializer=init, initargs=(counter,))
queue.write(json.loads(data))
plt.subplot(224)
print_i2()
rsrcmgr = PDFResourceManager()
first = Popen(first_command, stdin=PIPE, stdout=PIPE)
print(t)
m_istr
msg1
type_name = fdm.GetDocumentation(index)[0]
x = y
field, value = list(kwargs.items())[0]
0 * F + 10 * C
func = type(func)(func.__code__, nowglobals)
height = (pos[1, 1] - pos[0, 1]) * scale_y
phis = [lambda x: x ** 2, lambda x: x]
last_value = column_1
q = Queue()
a + b + c
city = City.objects.get(geometry__contains=geomodel.location)
t = np.zeros_like(p)
sum_
Variance(X + z).var_expansion()
[g for k, g in list(grouped)]
endlocal
yes.append(d)
print(a)
output = np.zeros_like(M, dtype=np.uint8)
self.text = QtGui.QLineEdit()
client = MongoClient()
d.x = costy * (sintz * (a.y - c.y) + costz * (a.x - c.x)) - sinty * (a.z - c.z)
max
r_avg = 0
print(repr(e))
SWIG_exception(SWIG_RuntimeError, s.c_str())
choose(10000, 100)
p1[:i] + p2
test = Test()
self.getString
calculate(pt, ls)
reader = csv.reader(f)
df
count += 1
GMax_idx = values.argmax()
a = np.arange(9, -1, -1)
init = tf.initialize_all_variables()
self.app = app
self.timer = QtCore.QTimer()
hist, edges = np.histogramdd((delta, vf, dS), (xedges, yedges, zedges))
self.index += 1
result = lst1[:]
print(row)
-1 % 48
myplot = plt.imshow(img)
Pdb
mat_sp[(idxs), :] = 2.0
match = p.search(l)
client_cmd.settimeout(1.0)
self.foo = 2
func(*args)
arr = np.arange(1001)
x = np.linspace(-10, 50, 100)
driver.close()
data = self.recv(8192)
keys = [key for key in list(redis_client.keys()) if key.startswith(key_prefix)]
checksum = hashlib.md5(open(path).read()).hexdigest()
data = [1] * len(r)
x[y > x] = y[y > x]
do_stuff(element)
self._optcre = self.OPTCRE
index_type()
2986
print(element)
A[-1]
x, y = np.atleast_1d(x, y)
setattr(namespace, self.dest, value_dict.get(values))
y = [8, 5, 8, 9, 17, 18, 25]
response.status = 202
b.add(1)
page_count = pdf.getNumPages()
v2 = v1 ** 2
items = q.get()
shift = np.take(shift, np.argsort(axis))
d = {}
sys.settrace(self.old)
choices.append(rn)
X, Y = np.meshgrid(X, Y)
str(td)
soup.body.wrap(wrapper)
dill.dumps(self)
raise
OrderedDict(sorted(list(d.items()), key=lambda t: t[0]))
assert quarter == 1
push(1)
print(new_list)
result
serializer = AssetsSerializer(data=request.data)
b = np.frombuffer(b, dtype=np.dtype(type_sig))
movie_dict[actor] = key,
self.id = rec.id
self.lists = [[], []]
buffer.close()
raise AttributeError(name)
print(name, phone_number)
y = temp + y
b = datetime.datetime.fromtimestamp(ts + 2.5e-07)
sio.write(png_str)
view
counter += 1
extra_files = extra_dirs[:]
self.doc.appendChild(self.root)
logger.addHandler(logging_handler_out)
train_op
print(np.cov(xlong.T, bias=0))
z = np.sqrt(x ** 2 + y ** 2) + np.sin(x ** 2 + y ** 2)
self
check = set(List)
str(c)
--1
length = arr.shape[0]
df_type_lookup = df_type.applymap(lambda x: other_table.loc[x]).values
print(mat_csr[(idxs), :])
n = len(open(filename).readlines())
df
messages = {}
model = [invert(x, y) for y in data.T]
cluster1 = [j for i, j in zip(lda_corpus, documents) if i[0][1] > threshold]
args.append(F[n](args[-1]) - 1)
n_j_k[j][k] += 1
print(lst)
f_handle, f_path = tempfile.mkstemp()
mylib.do_something()
a = list(range(1, 401, 4))
print(b)
root = tk.Tk()
bucket.append(line)
list = []
dy = [-1, 1, -1, 0, 1, -1, 0, 1]
result
new_map
hildon.StackableWindow
df_bad_idea = df.T.reset_index().T
print(v)
map[item] = item_command(item)
text = irc.recv(2040)
l2 = np.atleast_1d(np.linalg.norm(a, order, axis))
{{form.example(disabled=True)}}
threads.append(w)
call_tailored_args(f, kwargs)
arr[1, 1]
data = self.clientSocket.recv(1024)
num_bytes = base64.b64decode(alpha)
print(is_alternating_signs([1, -1, 1, -1, -1]))
d[detached[0]] = detached[1:]
request = urllib.request.Request(url, mmapped_file_as_string)
BOOST_PYTHON_MODULE(hello_ext)
frames = []
raise StopIteration
subs.insert(0, selfclass)
fig = plt.figure(figsize=(20, 20))
print(d)
layout.set_wrap(pango.WRAP_WORD)
dstack = np.dstack((a, a, a))
shutil.move(tmp_file.name, filename)
ex = QtGui.QWidget()
a[0] is True
getcontext().prec = 2
t += i
1
covering_set = set()
client.load_system_host_keys()
a = SomeAbstractClass()
y = (radii * np.sin(angles)).flatten()
vol = volume[i + 1:i + INTERVAL_LENGTH].cumsum()
m.groups()
y = np.dstack(x)
out.close()
i += 1
doSwim(where, why)
result.append(date)
tree = lxml.html.fromstring(raw_html)
cell = cell.lower()
cls(a, b)
ax
data = [tuple(d.split()) for d in data]
s = json.dumps(d, indent=4)
lines = [line for line in sys.stdin]
self.future.cancel()
f.write(content)
c.execute(sq)
invoice_id = Column(Integer)
np.sign(np.linalg.det(np.c_[[a, b, c], [1, 1, 1]]))
a.extend(islice(b, 14, 20))
print(levenshtein_distance(argv[1], argv[2]))
print(merged)
df = df.replace(0, nan)
r = update(d.get(k, {}), v)
zAxis0 = [0, 0, 0, 0, 0, 0, 0, 0]
TCPServer.__init__(self, (host, port), self.RequstHandler)
logger.addHandler(h2)
endif
trainer_df = pd.read_csv(path, skiprows=some)
todo_items = todo_folder.Items
score = 0
string = json.dumps(values)
results.extend(result)
key = list(item.keys())[0]
now = datetime.datetime.today()
nprect = np.vectorize(rect)
new_matrix[i, j] *= matrix1[i, k] * matrix2[k, j]
z = det([[a[0], a[1], 1], [b[0], b[1], 1], [c[0], c[1], 1]])
newshape = T.shape(tgt)[0]
rs = conn.execute(s, id_list=tuple(id_list)).fetchall()
[myfunc(a, b) for a, b in zip(data[::2], data[1::2])]
mp.Pool().map(worker_search_fn, files_to_search(target))
self.close()
d = defaultdict(int)
b = [row for row in r]
dag
server += HelloWorld()
fp.write(decomp)
assert answer == result
model = Person
df.update(duplicated_cols)
b = list(range(100, 400, 100))
recursive_urls(urls)
draw.text((0, 0), text=unicode_char, font=font)
uniq = {d[1:]: d for d in data}
a, b = b, a
httpd.server_close()
c = itertools.count()
print(numberList)
bar = 10
summation
sum += list[i].foo
result
created = DateTimeField(default=datetime.now())
rate = 22050
a = [1, 1, 1, 1]
raw = open(filename).read()
I = np.eye(d, dtype=pts.dtype)
fouriery = fftpack.rfft(datay)
t0 = np.zeros((mat.shape[0],))
print(len(str(x)))
result
E[X ^ 2] - E[X] ^ 2
loop()
179218
command = os.path.splitext(os.path.basename(sys.argv[0]))[0]
user = request.user
Add(5)(10)(15) * 100
value = value[1:-1]
df2.columns = df.columns
plt.plot(X2, F2)
execute(self._argv[1:])
op = LinearOperator(A.shape, matvec=my_matvec)
myList = [key for key, _ in txn.cursor()]
j += 1
x = ((df > 16) & mask).values.nonzero()
df = df.to_sparse(fill_value=0)
print(row)
t = datetime.datetime.utcnow()
h = h / sumh
ss = subprocess.Popen(FileName, shell=True)
COMMIT
data = []
b = Counter([1, 1, 2, 5, 6])
[([current] + path) for path in below_paths]
print(lev(s, t))
s = Series(list(range(10)), index=[1, 2, 2, 2, 5, 6, 7, 7, 7, 8])
it1 = iter(lst)
show()
content = thefile.read()
combination = list(range(1, r * 2, 2))
print(self.__name)
parser = argparse.ArgumentParser()
self.course = Course.objects.get(pk=course_id)
rects = ax.bar(list(range(numBins)), np.ones(numBins) * 40)
OrderedDict.bar = lambda self: 42
b = np.sum([(arr1[i] * arr2[j]) for i in range(n) for j in range(i + 1, n)])
expr
a = A()
instance = get_object_or_404(Post, slug=slug)
s = Scriptable()
args_values = list(args_dict.values())
self.maxbytes = 0
L2 = ast.literal_eval(s)
print((alpha, loc, beta))
s = list(someset)
R
value
hash(o)
self.tagged = self.build_proxy(Tagged)
self._list = list(iterable)
location_serializer = LocationSerializer(locations, many=True)
Response(serializer.data)
print(libc.getpid())
sum = 0
df.dtypes
max_im = Image.fromarray(maxi)
settings = get_project_settings()
doc.set_parser(parser)
cap_words = [word.upper() for word in words]
gender = models.CharField(max_length=1, choices=genders)
lst.append(row[2].toPython())
daemon = False
ax.plot(x1, x2)
ll.addHandler(logging.StreamHandler())
d = collections.OrderedDict.fromkeys(zip(alist, blist))
(0.1 * 0.1).hex()
sess.run(tf.global_variables_initializer())
m()
sig = inspect.signature(test)
repr(0.1)
value = bstream.read()
print(a)
result = celery.AsyncResult(task_id)
x = np.sin(2 * np.pi * f_line * t) + np.random.randn(len(t))
print(newpayload)
count = 0
toplist = []
fills[:mku] = 1
mean = sum(x * y) / n
ar = map(apply_conditions, list(range(0, n)))
process.communicate()
wrapper.retry(exc=exc, args=args, kwargs=kwargs)
value = weak.get(key, notFound)
whatever
print(data)
linesA = f.readlines()
alphabet[0]
exit(1)
print(x)
dx = [x[1] - x[0]] * len(x)
data = extract_data_from_filename(filename)
ws.PageSetup.Zoom = False
value, T(self.error_message)
a = A()
first_it, second_it = tee(first_it)
0
temp_object = int(i)
self._listener = reactor.listenTCP(self.get_http_port(), self._app)
user_dict
jinja = jinja2.get_jinja2(app=self.app)
1 + count(char, text, spot + 1)
print(date)
print(l)
print(func)
magnitude = 1 if int_part == 0 else int(math.log10(int_part)) + 1
p1, p2 = (p1, p2) if p2i == 0 else (p2, p1)
[-1, -1, -1, -1, 1]
mask = (a == 0) & (other[serie_name] == 0)
out.append(v)
get_repeated_seq(seq, pos, size)
escaped_string = cgi.escape(original_string, True)
df
result = np.zeros((len(x), len(uniq)), dtype=int)
pygame.quit()
omit = set(omit)
box = [-71.4, 41, -70.2, 41.5]
plt.subplot(2, 1, 1)
n = max([dEdtheta1, dEdtheta1, dEdtheta2])
angle = degrees(atan2(y - center_y, x - center_x))
bop = tk.Frame()
instance = self.instance
ax = fig.gca()
parser = OptionParser()
v = n // 5
read_data = f.read()
print(p.parse_args([]))
self.comp.add(company)
X = np.array([next(vals) for _ in range(N)])
base = next(words)
0
wraps(func)(wrapper)
object_pairs_hook(loader.construct_pairs(node))
i = frame.index.searchsorted(date)
print(func(test))
game = mygame.MyGame(screen)
max_val = a[0]
datetime - timedelta
s.add(filename)
protocol = MyProtocol
l1 = set(l1)
Foo.x
result = pickle.load(pickle_handle)
hm = pyHook.HookManager()
target_fp.write(row + newline)
key * 2
old = int(event.widget.get())
o.__str__
max_ = np.maximum(max_, im_array)
Order = list(range(len(myList)))
parent = psutil.Process(parent_pid)
bigram_finder = BigramCollocationFinder.from_words(tokens)
out = np.empty(shape, dtype=complex)
result
port += 1
vc = df2.mi.value_counts()
[0.0, 6.0, 1.0, 6.0, 8.0],
spampwriter.writerrow((s1, item, i, list1[item - 1], er2))
type(sys.maxsize)
thing2
thing4
exit()
x, y = data.T
fmt_values
y = np.linspace(0, 11, 50)
serv.gui(locals())
raise NotImplementedError
PyErr_BadInternalCall()
request = urllib.request.Request(url)
df
new_im = im.swapaxes(0, 2).swapaxes(1, 2)
True
prev, current = next(input), next(input)
OutputLists.append(list(chain(*ZIPPED)))
fig = pl.figure()
Py_XDECREF(result)
rows, cols = np.triu_indices(M.shape[0], k=1)
zipi = zipfile.ZipInfo()
python / path / to / application.py
i = 0
red.publish(channel_label, message_data)
np.where(comparison_array == False)
test(combs2)
df
count += 1
obj[k] = make_str_unicode(obj[k])
d[x] = d.get(x, 0) + 1
mapping = {(0): [0, 4, 0, 4], (1): [0, 4, 4, 9], (2): [4, 9, 0, 4]}
f1 = plt.figure()
val = next(data)
handlebox.add_artist(title)
sys.getrefcount(os)
sound2.sound.play()
sound1.sound.play()
string
print(cPickle.loads(m[start:end]))
main()
console.log(m[0])
neighborhood = morphology.generate_binary_structure(len(arr.shape), 2)
A * x + constant_term * x.sum()
main.py
dis.dis(foo)
sp.add_parser(cmd)
t = arange(0, 6, 0.01)
print(train_likes_df.time.dt.time)
nx.is_valid_degree_sequence(z)
c = pycurl.Curl()
local_gamma = tf.identity(self.gamma)
it = iter(range(100, 200, 10))
temp = f.name
False
x, y = np.meshgrid(xarray, yarray, copy=False)
a = []
output.write(line.upper())
shape[arr.ndim:] = window
self.name == other.name and self.age == other.age
nums = double_list(nums)
self.__theme_variables
phyrule = dict()
self.arg2 = arg2
median_labels = [str(np.round(s, 2)) for s in medians]
FAILED(failures=1)
br.form = list(br.forms())[1]
a.itemsize
assert len(data) % 4 == 0
R1_ = R.copy()
a + b + c
user = models.ForeignKey(User)
d[obj.key] = obj
c1.wait()
start_daemon(pidf=args.pid_file, logf=args.log_file)
print(params)
res_list = []
sys.settrace(trace)
p.map(f, list(range(20)))
result = set()
m = len(a) + len(b)
supermanu
total_count = 0
N = int(N)
input_fd, output_fd = os.pipe()
a = list(range(65, 91))
(5.0).hex()
data = pandas.read_excel(infile)
name = CharField(max_length=50)
angle = radians(self.theta + self.delta * pos)
toSend.append(row)
method_2()
contentMD5,
o(*args, **kwargs)
self.Dict = _dict or {}
age_and_sex = numpy.logical_and(age_is_one, sex_is_one)
2
df
serial_str = pickle.dumps(your_rrule_object)
print(cls)
array = PyArray_SimpleNewFromDescr(2, dims, descr)
df
mean_params = mean(ps, 0)
assert self.is_file()
z + v
n = np.arange(1, len(X) + 1) / np.float(len(X))
now = time.time()
assert sum_gen0 == sum_list1
args = zip(itertools.repeat(x), data.T)
ch = s[i + 1]
s2 = inter.UnivariateSpline(x[::-1], y[::-1], s=0.1)
items.append(item)
r += (x[i, k] - xc[j, k]) ** 2
b_new = b[bi[aiinv]]
map(lambda x, y: y - x, flist, flist[1:] + [1.0])[:-1]
contents = client.GetResources(uri=folder.content.src)
errfunc = lambda p, x, y: gauss(x, p) - y
sparse_update = tf.scatter_update(data, indices, updated_data_subset)
result[key] = value
amp = 0.6 + 9.5 * np.random.rand()
par = urlparse.parse_qs(urlparse.urlparse(url).query)
n = int(N)
shutil.copyfile(source_name, dest_name)
print(index)
build_tree(tree_list)
new = []
center, radius = cv2.minEnclosingCircle(points)
print(message)
ipdb.post_mortem(tb)
Zm = ma.masked_where((abs(z_grid) < 1.02) & (abs(z_grid) > 0.98), z_surface)
final = FinalProcess(parsed.get(), pattern.get(), calc_res.get())
bbox = fig.get_window_extent().transformed(fig.dpi_scale_trans.inverted())
result.ToString()
print(p(42))
recipients.append(instance.content_object)
buf.value
ax1.legend()
p = multiprocessing.Pool(cpus)
a < b and b < c
model = MyModel
print(x[slicer])
x
1 / 0
indexing_with_clipping(arr, indices, clipping_value=2)
twisted.protocols.policies.ProtocolWrapper,
insert_section(root)
setUpClass = classmethod(setUpClass)
func()
outfile.seek(0)
0
a
c
print(r.date[0])
ids = [t[0] for t in ans]
content = urllib.request.urlopen(base_url + symbol).read()
num = float(num_str)
os.umask(UMASK)
t = threading.Thread(target=self.newThread)
net.ipv4.ip_forward = 1
print(scope.document.value)
obj.name1()
common = list(cls.__dict__.keys()) & list(obj.__class__.__dict__.keys())
head = [next(myfile) for x in range(N)]
raise StopIteration
start = time.perf_counter()
df
q[tdk] += tdv
li[li.index(ch, last_found)] = repl
stack = traceback.extract_stack()
show_missing = True
sys.version_info
paths.insert(0, value)
l1.sort(key=natsort_key1)
offsets.clip(0, max_dim, offsets)
type(f)
dt = (times[i] - times[0]) / i
cookie_jar = cookielib.CookieJar()
t2 = time.time()
print(p - 1)
self.tin.Bind(wx.EVT_TEXT, self.TextChange)
float_numbers = map(float, string_numbers)
keys_list = [key for key, value in globals().items() if value == x]
na = np.frombuffer(a, dtype=float).reshape(-1, 10)
print(a[inter])
e = len(str(n)) - 2
s = {}
merge_dict(result, sub_hdict)
rot = str_num[mid:] + str_num[:mid]
pprint.pprint(js)
0, 0, 1
differences.append(diff)
req = urllib.request.Request(add_note_url, encoded_data)
authResult = authenticator.authenticate(authToken)
idx, inputData[idx]
col += 1
city = db.StringProperty()
cut_signal = irfft(cut_f_signal)
display.stop()
X = np.linspace(0, 10, 1000)
yf = scipy.fftpack.fft(y)
print(CV_rfc.best_params_)
rec.levelno
d.append(c[j])
print(result)
regr.fit(input_X_vars, input_Y_vars)
clf.predict(iris.data[75])
K.clear_session()
moo = size * np.tensordot(bar, bar, axes=(0, 0))
+db_matrix[:, (option_vector[i, 0])] * bp_vector[j, 0]
print(result)
Cmd.cmd()
words = words[5:]
setattr(namespace, self.dest, values)
self[k] = v
fig = pylab.figure()
output_dict = json.loads(json.dumps(input_dict))
remote_name.value
conn = engine.connect()
b[2] = 10
scipy.stats
bool(i & 1)
config.b.x
odds = (x for x in inputs if x % 2)
vals = df.values
set_y = frozenset(y)
username = get_username_from_storage(unique_code)
ax = plt.figure().gca()
(dd * ww).sum() / ww.sum()
result = session.execute(s)
assert a[2] == 10
roots = set()
self.md5.update(v)
rbf.epsilon
b.extend([0] * (minlen - len(b)))
rad2deg = math.degrees
result.append(partition[start:start + k])
parameters = param4, param5, param6
student_detail = student_detail.filter(campus_id__name=pk2)
vers1 = (x + y) ** 2
resp = opener.open(DOC_URL)
clsdict[name] = value
color = next(colors)
queue = collections.deque(itertools.islice(it, at_end))
inds = np.searchsorted(vals, bins[1:-1])
dt = datetime.now()
print(A().my_list)
pdfdoc.setDocumentAttributes_(attrs)
print(element)
df
print(row.th.get_text())
up = list(itertools.takewhile(lambda x: x < down[-1], up))
df
x = np.linspace(0, 20, 100)
app = Flask(__name__)
transaction.rollback(_capture_exception=True)
self.n = n
counter[item] += 1
isinstance(im, Image.Image)
unmaskString(templateString, maskedList)
False
dset[:] = chunk
X = np.zeros_like(Z)
bcw = csv.writer(bc, csv.excel)
config.b.f
v = A[20:40:2]
root = tk.Tk()
down = list(itertools.dropwhile(lambda x: x < up[0], down))
print(mypolygon)
self.generic_visit(node)
profiler = Profile()
cos_lat_d = np.cos(pos1[..., (0)] - pos2[..., (0)])
self.conn.rollback()
j2len = {}
newj2len = {}
np.array(norm)
data = sockfile.readline()
version >= sys.version_info[0] + sys.version_info[1] / 10.0
new_loop.run_until_complete(low_level(loop=new_loop))
self.it = it
cls._metadata_value
weak[key] = value = factory(key)
sess = tf.Session()
print(active_app_name)
x = []
page = existing_pdf.getPage(0)
pointers = (ctypes.c_char_p * 4)(*map(ctypes.addressof, string_buffers))
os.setgid(user_gid)
readme = f.read()
a = b = np.arange(8).reshape([2, 4])
nextx = next(it)
f2 = lambdify((a, b), a + cos(b) * 2)
x[::2]
NO_OTHER_WRITING = ~stat.S_IWOTH
pcapnum += 1
results = classifier.predict(test_features)
tf.initialize_all_variables(), inputs, labels, output, optimizer, saver
print(astor.to_source(tree))
cache = apt.Cache()
f, ax = plt.subplots()
c.inc()
N_val = 2 ** np.arange(15)
queue = multiprocessing.Queue(1)
t *= i
a, b
index2count = dict((i, 0) for i in range(len(elements)))
nb.select()
assert ellipse.eccentricity == eccentricity
msg = OSC.OSCMessage()
print(n)
raise
numberList = [1, 2]
url = QUrl(url)
output_buf = ctypes.create_unicode_buffer(output_buf_size)
random.seed(randseed)
main()
c = np.zeros(len(a) + len(b), a.dtype)
message.ack()
marks = {}
setattr(self, name, f(*args, **kwargs))
process_a = multiprocessing.Process(target=get_a)
next(gen)
idx = idx[mask]
domain2synsets = defaultdict(list)
mlen = max(len(s) for s in snippets) * 2
Case(When(created__month=9, then=1), output_field=IntegerField())
model = cv2.KNearest()
a = A
df.gdp = df.gdp.shift(-1)
figure(1)
aplusb(100, -99)
grp1.name,
self.do_open(Connection, req)
oFig1 = plt.figure(1)
register = Library()
ans.append(((i, j), (ni, nj)))
y1 += 1
setattr(inst, self.name, result)
d1 = date(2008, 8, 15)
mylibrary.config = config
self.__proxy = proxytype, addr, port, rdns, username, password
idx = pd.IndexSlice
names = data.name.tolist()
5 == x > 4
a, b = tee(iterable)
thread.join()
print(i)
formatter.add_text(action_group.description)
serializers.PrimaryKeyRelatedField.to_internal_value(self, data)
c = Counter(a=4, b=2, c=0, d=-2)
zAxis1 = [1, 1, 1, 1, 1, 1, 1, 1]
n -= 1
print(spam_list)
x | y
print(elem)
+--salt
stream.stop_stream()
s = stdin.readline()
foo(x)
b = f1.read(1)
start_i = bisect.bisect_left(lst, start)
green_img = np.apply_along_axis(update_pixel, 2, img)
verify_if_payload_is_mine_and_assign_fields()
stty - a
session = orm.scoped_session(sm)
df, header
records = query1 | query2
module.input = input
x = x1 + (x2 - x1) * t
True
self.song1 = song1
a = sum(li[:1])
matching_key.append(key)
className = MyClass
output_list.append(group)
socket.setdefaulttimeout = 0.5
possible = [1] * len(criteria)
g_values = dict()
print(thelink)
res
sum(abs(n1 - n2) for (i1, n1), (i2, n2) in zip(birthday_1, birthday_2))
1 | 1
description = forms.CharField(widget=widgets.AdminWYMEditor)
res.show()
plt.colorbar()
MyClass(someNumber, someString)
cls.__str__ = __str__
assert len(index_groups) == len(args)
a = [1, 2]
f.truncate()
signal.signal(signal.SIGINT, stop_handler)
print(items)
fruits = FruitObject()
Serial.write(data, sizeof(arg))
dest.addPage(blank_page)
print(k, kwargs[k])
indices = sorted(random.sample(range(n), r))
print(car, price, mileage)
n = len(target)
self.fnames = []
print(new_size)
dbconn = pyodbc.connect(ConnectionString)
sublime.set_timeout_async(test_progress_bar, 1)
total = sum(map(int, list(filter(str.isdigit, input_string))))
y = r * sin(theta) * sin(phi)
opt = tf.GradientDescentOptimizer(learning_rate=0.1)
pathLink = os.path.join(desktopFolder, linkName)
sympy_exp = -x ** 2 + y + 1
g.drawEllipse(QPoint(20, 20), 10, 10)
main()
resp = current_app.make_default_options_response()
indents = line[:len(line) - len(line.lstrip())]
{}
c = con.cursor()
bash
a + b
x = np.linspace(-100, 100, 1000)
my_df = pd.DataFrame(a)
print(result)
svg.render_cairo(context)
result.append((ser.mean(), ser.std(), mask2.sum()))
im_a = a.load()
product = models.ForeignKey(Product)
x = x + (x >> 16)
log_to_file(err)
infected_users.close()
print(pt.profile_id)
print(list(my_gen(example, drop_condition=matchCondition)))
generated = random.randint(1, 10)
english_dict = dict()
next(g)
self.myConfig.setConfig(key, val)
print(constant.co_names)
print(x)
print(ex)
number.value += 1
re.compile = re.my_compile
rows = cursor.fetchall()
AsyncDraw(this, tmpinput)
new_point = np.array(np.unravel_index(new_idx, pdf.shape))
x = np.concatenate((pad, x))
self.default
f.close()
j += 1
n = 100
cell_type = worksheet.cell_type(row - 1, i)
setuptools.__version__
ifr = ifreq()
numbers = {2, 7, 8, 9}
d1 = defaultdict(list)
arr_2.sort()
model.setRootPath(QDir.rootPath())
A_yz = np.vstack((y, np.ones(len(y)))).T
self.y < other.y
pairings = [(y, x) for x, y in pairings]
a = numpy.array(l)
today = datetime.date.today()
fp = fopen(ptr, p)
sum(samples) // len(samples)
f
wsgiref.handlers.CGIHandler().run(application)
answer.append(resultify(elem, flatResults, []))
foo
Returns
form = AuthorForm(request.POST, instance=a)
env.Depends(target, source)
rolling_sum(df, n=6, k=4)
True
new = []
text.setMinimumHeight(50)
Baz.java
s[1] = n + 1
a.fill(7)
print(vars(options))
session = scoped_session(sessionmaker())
[rect.set_height(h) for rect, h in zip(rects, histogramSeries[(i), :])]
output = {}
assert aware == now_aware
sys.modules.pop(mod)
print(dir(Classic))
center = width / 2, height - 25
i += 1
print(i, j, families[i])
s.close()
foo = login_required(active_required(foo))
rounding_swig / Makefile
result = {}
MyFancyNumber(5) - 7
Thread(target=first.communicate, args=[simple]).start()
expr.extend((op, num))
centerPoint = QtGui.QApplication.desktop().screenGeometry(screen).center()
x = [0, 7, 2, 4, 6, 9, 5]
tuple(self._bar)
stokes_list = []
self.tweet = json.loads(buf)
i = 7
x = rk4(diff, x, dt)
CALLS = 0
_ ** 2
False
a = 0
app = QApplication(sys.argv)
toslice = arr.shape[0] - extra
print(R, R * 2)
len(r)
cls
columns = list(song.keys())
i.wait()
height = int(h)
print(s)
node = node.right
data
print(rs.get())
sum_of_seen = 0
screen_center = numpy.array([w / 2, h / 2, 0, 1])
result.append(tup)
tkinter._test()
df
f = Foo()
p2 = Player.objects.get(id=2)
stats.print_stats()
output = y[np.logical_and(x > 1, x < 5)]
original_get(*args, **kwargs)
ws = wb.create_sheet()
self.data = {}
client.on_connect = on_connect
plt.plot(tr, yr)
d2 = {}
line[:set_data](t, x)
wmiquery = _objSWbemServices.ExecQuery
key_to_items[k].append(i)
df_ctrl.reindex(idx)
keyed_a = ((n.real, n) for n in a)
delay(10)
data = [4, 5, 6]
self.x = x
formset = GroupeFormset(request.POST, instance=client)
s = item[0]
x += 1
zflat = np.full_like(z, min(ax.get_zlim()))
query_db()
blog = models.ForeignKey(Blog)
twitter_json = status._json
print(u5.all_friends)
ast.literal_eval(i)
the_time = datetime.now()
stty - a > stty - after
Base = declarative_base()
dirty_data
start, stop, step = 0, 42, 5
text = text[length:]
settings.DEBUG = True
x = vor.vertices[index, 0]
g = f.integral()
save_wrapper
print(r.text)
value
number_length = len(number)
hdlr.setFormatter(fmt)
value / float(total)
tackless.append(s[0:4] + s[5:7] + s[8:])
solution_set = sympy.solve(equations, P, Q, S, T, set=True)
l.addHandler(h)
global_namespace.clear()
a = numpy.array(a)
POOL = Pool(5)
worker_list.append(worker)
d = {v: i for i, v in enumerate(l)}
print(self)
print(numpy.linalg.norm(y - clf1.predict(X)))
dotplace = leftdigits
an = ax.annotate(s, xy_arr[0], *args, **kwargs)
my_dict = {}
new
print(a)
create_ranges(start, stop, 5)
[some_extention]
lines = [line.strip().split() for line in f]
True
ans = []
process(data_chunk)
I = plt.imread(tiff_file)
total = 0
words1, words2 = [], []
a, b = take2(*p)
A = np.linspace(xmin, xmax, 100)
app = QApplication(sys.argv)
sess.run(init)
n -= 1
rec = flatten(json.loads(data))
print(1 / 2)
encoded = EncodeAES(cipher, my_text_to_encode)
new_index = pd.Int64Index(np.arange(len(df))).difference(index)
perm_unique_helper(listunique, [0] * u, u - 1)
i -= 1
conn.sock.shutdown()
F /= F[-1]
fq[field][row[field]] += 1
[k for k, b in self._lookup.items() if b & selection]
print(comparison_df)
checktime = checktime.timetuple()
yticks = ax.get_yticks()[1:-1]
stream = cStringIO.StringIO()
item
options, args = parser.parse_args(values=v)
unsw_mid_year_end_date + timedelta(days=k)
queryset = models.UserProfile.objects.all()
main()
new_class
pos = fence(rng, n)
print(total_size(d, verbose=True))
[], 4
tokens = word_tokenize(i.lower())
self._swapf = int(lines[15].split()[1])
xs, ys = numpy.triu_indices(len(x), 1)
self.assertEqual(output, validated_output)
register = webapp.template.create_template_register()
dequefilter(deck, lambda x: x > 2)
root = Tk()
line = next(file)
print(line)
concatenation = []
oend = min(uend, vend)
image_tk = ImageTk.PhotoImage(image)
resp
print(my_dicts)
np.diff(data.value.values)
GET_print(packet)
root = ElementTree.fromstring(XML)
t = datetime.time(10, 22, 15)
class_ = getattr(module, class_name)
parser = etree.XMLParser(dtd_validation=True, load_dtd=True)
print(A.f)
False
[supervisor - cron]
intersection = set(vec1.keys()) & set(vec2.keys())
print(err)
all_same(property_list)
wrapper_func
self.empl_count = empl_count
shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)
BaseClass.__init__(self, self.specific)
pa_stream_peek(stream, null_ptr, ctypes.c_ulong(length))
config = ConfigParser.RawConfigParser()
listComps = (node for node in ast.walk(prog) if type(node) is ast.ListComp)
width = GetSystemMetrics(0)
hashed = hmac.new(key, raw, sha1)
myDict
result = []
_list = []
foo = blahblah
makeArrow(ax, 0, fun, +1)
self.popularity = (self.user_set.count() - 1) / (th + 2) ** 1.5
self.seek(0, os.SEEK_END)
self.var1 = var1
x += bits[i] * 2 ** i
ts = calendar.timegm(datetime(2010, 7, 1, tzinfo=pytz.utc).timetuple())
drug_field = vals[1].strip()
myDlg.Destroy()
majorstep = majorlocs[i] - majorlocs[i - 1]
data = []
view_func(request, *view_args, **view_kwargs)
fkey = some_method_that_gets_the_foreign_key()
node = node.left
self.source[key]
x = 4
print(temp_list)
text_col = 0, 255, 0
nums = [[] for x in range(n)]
result = comment.upper()
np.dtype(np.float64).num
tex = tk.Text(master=top)
User.objects.get(username=username)
schema.deserialize(not_list)
print(min(sub_lst))
self.thread.started.connect(self.long_running_thing.run)
data
str(value)
b.read(ike)
order_range = list(range(order + 1))
content_type = ContentType.objects.get_for_model(settings.AUTH_USER_MODEL)
brown.tagged_words()
exc_type, exc_info, tb = sys.exc_info()
data_rows = []
wep104 = 1 << 4
posts = ListField(EmbeddedDocumentField(Post))
args = func_args[:len(arg_names)]
parser = argparse.ArgumentParser()
c = C()
self._list.__getitem__(key)
p_len = np.linalg.norm(p)
word.Visible = True
main()
formset = AttributeFormSet(queryset=Attribute.objects.filter(product=product))
distutils.util.get_platform()
set_cond.__name__ = option
exec(zsh)
manager.refresh()
generating_random = false
extract_inner_zipfile(parent_zip, path)
minorstep = majorstep / ndivs
True
print(line.strip())
data[name].append(value)
source / tmp / eb_env
entries = [list(range(2)), list(range(2)), list(range(2 ** (d - 1))), list(range(d))]
list
suppressed_exc
idx = np.argmin(np.abs(ay - by))
x, y, z, value = np.random.random((4, 40))
in_second = set(second_list)
src = b.submit().read()
cel = Celery()
my_instance = MyModel()
result
stack = inspect.stack()
hs.write(name)
randomWalk(u, w)
nums.append(item)
tile_frame = Label(frame, text=rand)
cfd(brown.tagged_words())
42.0
checksums = []
mock(2)
g = application.get_profile()
data = []
setuid(geteuid())
name = path.basename(name)
translation.activate(self.new_lang)
nested_two_args = nested_two_parser.parse_args(req=root_args)
G.nodes(data=True)
self.__class__(lambda x: Function(self)(x) / Function(other)(x))
h = matplotlib.finance.candlestick(ax, quotes)
self._items.remove(item)
byId = collections.defaultdict(list)
value[0] = True
cnt = Counter()
fig, ax = plt.subplots(1)
main()
print(res.state)
activity = models.ForeignKey(Activity)
options = p.parse_args()
ones = np.ones((8, 8))
y = i[4]
fig = pylab.figure(figsize=(8, 8))
self.__data[k]
print(repr(dt_obj))
vol = ec2.get_all_volumes()
type(s)
numpy_array(shared_arr, peaks)
self.contentPane.add(self.canvas)
count += 1
D = np.sqrt(rows + cols)
pickle.dump(subl, fp)
isclose(100, 98.9, rel_tol=0.02)
digits.append(str(p))
_set_match(re_.search(pattern, string, flags))
df = df_in.copy()
k_means.fit(data[:, (np.newaxis)])
xy_index
dc = wx.BufferedPaintDC(self)
k = X[i]
1 + 2
X, Y = np.meshgrid(x, y)
yarray = np.linspace(0, 1, num=resolution)
s = pprint.pformat(aDict)
n11 = sizes2count(np.bincount(ab), n)
a[:, (i)] = c[:, (idx[i])]
False
engine = AnalyticEuropeanEngine(process)
self._update_existing(key, value)
print(s)
CC0 = np.dot(sq_CC0, sq_CC0.T)
i = (i & 15) + (i >> 4)
arr22.shape = N22, 2
print(d)
real_decorator
d = Device(conn)
deques = [collections.deque() for i in range(n)]
signal.alarm(self.seconds)
Relational(l, r, ineq.rel_op).canonical
words = lst2.split()
print(matplotlib.__file__)
f = dostuff()
G = nx.Graph(G)
path.exists(prettyfile)
f(s)
x = from_array(x, chunks=5)
print(cols)
existing_provider = Provider.query.get(1)
Tkinter.mainloop()
mydict = dict(mylist)
idx = diff.argmin()
value = 0
groups.append([val])
a0 = np.array([1.0, np.NAN, 2.0])
t_plus = cv2.cvtColor(cam.read()[1], cv2.COLOR_RGB2GRAY)
vertices = np.take(tri.simplices, simplex, axis=0)
kpt_data[:, :, (i)] = h_r.dot(phase)
a.extend(buffer(b, 14, 6))
print(row)
path = dest_dir
RoundToSigFigs(eglist, 1)
pols = [p1, p2]
col_names = [desc[0] for desc in cursor.description]
current[key] = dic[key][i]
y + 1, x + 1
result
print(err.filename)
C = np.zeros((n_cols, n_cols), int)
self.lookup_tables = defaultdict(lambda : defaultdict(list))
print(days_from_today)
model = Review
StringIO(f.read())
np.array(np.dstack((my_array[begins], my_array[ends])))
dll._sin.restype = ctypes.c_double
index = similarities.MatrixSimilarity(lda[corpus])
result = A.copy()
floor_key(d, 100)
dimB = B.shape[0]
uenc = str(enc)
ax = fig.add_subplot(111)
cmd = q.get()
frame.OnResult(ResultEvent(frame.worker.result))
tdata = s.read()
ws = wb.create_sheet()
sum_of_col = A.sum(0).tolist()
i += 1
f(xs)
print(df)
res = [re.compile(re.escape(a)) for a in A]
sum(isinstance(exp, ast.FunctionDef) for exp in tree.body)
q = Queue.Queue()
semester = models.CharField(max_length=10)
self.b = self.a.get_browser()
t.join()
flags = parser.parse_args()
1
dx = x2 - x1
loop = asyncio.get_event_loop()
self._name = name
environment = KEY1 = value1, KEY2 = value2
group = parser.add_mutually_exclusive_group()
session = requests.session()
full_real_path = os.path.realpath(sys.executable)
print(b.shape)
logger.addHandler(handler)
cub_right.append(points[n])
stuff(2)
mp.Process.__init__(self)
observed_y = true_y + 0.05 * np.random.random(N) * true_y
cmp(ensure_datetime(d1), ensure_datetime(d2))
main()
self.age = age
dshape = tuple(data.max(axis=0) + 1)
B = plt.boxplot(data)
data = build_data(_data, kwds)
deque(map(writer.writerow, data), maxlen=0)
modes = [k for k, v in frequencies.items() if v == max_freq]
self.access_token(user, self.assertEqual)
print(func, t.repeat(number=10 ** 5))
ones = np.ones(len(x[0]))
length -= chunk
wrapped.__dict__ = tgt_func.__dict__
self._sub_results = {}
li = s.rsplit(old, occurrence)
Ydict = dict(((i, j), v) for i, j, v in zip(Y.row, Y.col, Y.data))
self.address = Address
myList = []
self.textLayout = QtGui.QVBoxLayout(scrollContents)
stream = open(path)
start1, stop1, start2, stop2 = dice_random_mapping[dice]
b = ClassB()
thread.join()
s.ix[d1.merge(token).id.unique()]
key = b64encode(urandom(9))
filename = request.module.__file__
a, b = b, a + b
print(x, y, z)
i -= 1
size = 1525
x2 = series.index.values[idxs + 1]
False, np.nan
result = PyDict_SetItem(dict, key, newobj)
curr.append(i)
msg = Message(body=plain_body, html=html_body)
response
files = []
t = [{} for k in range(max_int)]
dot11_phy_type_fhss = 1
np.percentile(weight_array(ar, weights), 25)
frame = pandas.DataFrame()
a
self._bwd = {}
p = MyHTMLParser()
timer = wx.Timer(self)
proc = subprocess.Popen([cmd, dirname], stdout=subprocess.PIPE)
dim = data.GetDimensions()
c_array = (ctypes.c_char_p * len(list_to_send))(*list_to_send)
averages = data2.mean(axis=-1)
n.append(y1 - y0)
s = json.loads(j)
cls.instances.remove(ref)
d = Path().resolve().parent
mo = myre.search(line)
c.executemany(SQL, rows)
v1[0] = 10, 100
plt.imshow(wordcloud)
result = []
spider = MySpider()
sstot = np.sum((yd - ybar) ** 2)
a = urllib.request.urlopen(url)
a = A()
expr = Forward()
value = _decode_list(value)
remote = request.remote_addr
new_shape = list(arr.shape)
self.process = Process(target=self.main)
loop.stop()
print(scounttext)
scenario.mark_skipped()
d = sum(s)
[(f, multiplicity(n, f)) for f in factors]
a, b = 0, 1
self.NUMBER_OF_PROCESSES = cpu_count()
result = [dates[0]]
min(self) < other < max(self)
theta = np.degrees(np.arctan2(*vecs[:, (0)][::-1]))
a, b = b, a + b
l
cd / opt / portapy / virtenv
a = A()
new_values.extend(value)
lst = map(abs, lst)
dist(gen)
fclose(fid)
mask = [(2 ** i - 1) for i in range(N)]
ABCDEFGHIJKLMNOPQRSTUVWXYZ
print(key, value)
new_url = urlparse.urlunparse(url_lst)
lst = [min(data)]
inprogress = []
htext = h[0].text_content()
time.sleep(0.4)
suite
res
parent_node = name_to_node.get(parent)
print(round(monthlyPayments))
data = np.zeros((0, feature.size))
print(output)
col == random.randrange(1, MAX_INT)
first = data.pop(0)
self.connection = self.request
getattr(self.gen, attr)
print(dict(**t))
Gtk.Window.__init__(self)
comboBox.grid()
print(inspect_generator(list(filter(6))))
newattrs[name] = value
results = []
assert len(nvec) + len(mvec) == len(bits)
print(sqrt(2) * (a + b) / 2.0)
print(str(elm))
parent = parent.setdefault(n, {})
result[J] = fun1(zeta[J])
mysignal = pyqtSignal(int, list)
raise NameError(func_alias)
managed = False
logsum = 0
self._children = set()
n = len(l)
res[1::2] = l[:min_len]
h.itemset(i, j, 0, 255)
pub.bind(url)
print(text)
existing = dict()
Foo.sad.some_behavior = sad_behavior
storage.put(credentials)
jvdata = json.loads(visitordata)
logging.info(count)
err = execve(EXECFILE, arguments, NULL)
fn(12)
False
False
0
print(friend_list)
tz._utc_transition_times
self.im.seek(self.cur)
display.start()
wordlists[wordno].add(recno)
addlist = []
height = rect.get_height()
print(max_depth)
wintime = pywintypes.Time(newtime)
print(unicode_obj)
s = f.read()
widget = MyWidget()
column_index = 5
print(e.output)
s.setServiceParent(ret)
print(matches)
fn(e)
wxImage = wx.EmptyImage(frame.width, frame.height)
self.click = x, y
bbox = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())
self.setup_instance(instance, state)
proc_manager.wait()
pie_chart = Donut(data)
n[i] = 0
msg = Message()
self.__class__(lambda x: Function(other)(x) / Function(self)(x))
tuple([make_hash(e) for e in o])
real_preds = [marshal.dumps(pred.__code__) for pred in preds]
s[i], s[j] = s[j], s[i]
y = 2
d[tuple(t)] = 42
walk_around_the_filesystem()
fixup(adict[key], k, v)
self.start = start
cimg = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
print(k, v)
session_list = all_unexpired_sessions_for_user(user)
char = screen.getch()
y = np.cumsum(x, axis=0)
checkbox_name = self.clear_checkbox_name(name)
ret = test_method()
count = 1
D, V = linalg.eig(P)
tstamp = time.mktime(date2.timetuple())
len1 = max(len(el) for el in my_list)
temp = np.array(temp).reshape((len(temp), 1))
next(it)
files = sorted(searchedfile, key=lambda file: os.path.getctime(file))
list(gargs[self.max_gindex + 1:])
l = [self.browserStartCommand, self.browserURL, self.extensionJs]
new_obj = self.model.objects.create_from_existing(obj)
print(stderr)
key, value = item
sgmllib.endbracket = EndBracketMatch()
tokenized_sentences = [nltk.word_tokenize(sentence) for sentence in sentences]
print(x.is_bad())
X = numpy.random.random((npoints, ndims))
a = np.arange(100)
type(data[1])
dayno = int(dayno)
d = defaultdict(list)
d = np.random.rand(10, 10)
app = Flask(__name__)
direction = [0] * len(criteria)
pivot = array[start]
A = np.random.random(100)
http_server = tornado.httpserver.HTTPServer(application)
p.wait()
trimmed = {}
np.random.seed(0)
a = np.array([0, -2, -1, 0, 1, 2, 0])
day = days[start.weekday()]
HOST = socket.gethostbyname(socket.gethostname())
x.size
links.append(self.re_encode(href))
root = Tk()
result.append(subclass)
self._x = x
list(d.keys())
selenium.Start()
salt = base64.b64encode(os.urandom(12))
df_select = df.loc[ix]
style = getSampleStyleSheet()
root.change_text()
stack.extend(v for v in self.graph[vertex])
y_min = plt.gca().get_ylim()[0]
radii = 0.1 * np.random.random(N)
print(foo.bar)
p = pd.Panel(d)
f = open(fileName)
dimfac = np.prod(np.arange(1, dim + 1))
plt.figure(figsize=(15, 10))
n = min(len(self.index), len(self.columns))
optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)
classmethod(bar).__get__(foo)
tasks = list()
x ** 2 + y ** 2 + z ** 2 - 2.0 ** 2
book = pyExcelerator.parse_xls(filepath)
msg = email.message_from_file(open(file_name))
attrib = attrib.copy()
True
mask = (np.nan_to_num(arr) != 0).any(axis=1)
common = cylinder1.common(cylinder2)
map.__code__
0
dbus.mainloop.glib.DBusGMainLoop(set_as_default=True)
thisrow = list(range(1, len(seq2) + 1)) + [0]
capture = cv.CaptureFromCAM(camera_index)
[1500, 1780, 1780, 1670]
b = a.sum(axis=0) <= S
print(replace_verb(line))
p.a = 1
dd = defaultdict(list)
veclen = x.shape[1]
name, path, args, kwargs
sum = sum + 4 / (x * (x + 1) * (x + 2))
print(col.name, j)
myInterpolator(2.5, 4.0)
self.x = x
y2 = np.cumsum(np.random.random(time.size) - 0.5)
c = 5
new.paste(b, mask=diff)
inspect.getmodule(np.dot)
a = pd.Series(list(range(100)) + [0] * 20)
2
s = map(lambda x: map(int, x), s)
a = []
client = self.factory.clients.get(client_n)
print(a)
print(b)
callback(func(arg + i))
patches = all_patches[upper_left[0], upper_left[1]]
c = Counter()
x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]
print(x)
df[col][x] = func(x, *col_params[col])
i = 0
fixmsk = mantissas < 1.0
ax.plot(data[(i), (j), (k), :], color=color[j, k])
named_func[determine_types(args, kwargs)](*args, **kwargs)
map_.fit()
access_token, local_directory, dropbox_destination = sys.argv[1:4]
f.write(content % args.__dict__)
print(c.name)
lst = getattr(namespace, self.dest)
hours = int(hours)
bar.restype = c_char_p
x.xy
train_op = tf.train.GradientDescentOptimizer(0.2).minimize(loss)
b = next(self.l)
doTheSmartCancellationSoNobodyWouldCrash()
Prefixes(4)
self.serversocket.close()
[clown - college]
a = np.arange(1, 21)
keys = [key.lower() for key in next(reader)]
ss.close()
inner_zip.close()
n = len(entries)
self.raise_if_exceeds(np.array(minorlocs))
l = q.poll(0)
self.y = initY
env = jinja2.Environment(loader=loader)
sentences = []
od[key].append(i)
6 - 0.140995
min(lev(s[:-1], t) + 1, lev(s, t[:-1]) + 1, lev(s[:-1], t[:-1]) + cost)
self.x = x
self.b = b
perms.append(deepcopy(current_tables))
g = f.readlines()
indice = numpy.nonzero(y)
assert False
result[::2] = data
print(myapp.settings.FOO)
x * i
gs = stack.enter_context(get_stuff())
app = MyServer(__name__)
self.end_headers()
Row(**dictionary)
print(d)
city_type = db.StringProperty()
audio = AudioItem.objects.filter(user=user)
_ = get_localizer(request)
fd.close()
sys.exit(not result.wasSuccessful())
DEBUG = False
print(x)
d = []
total
fig.scene.camera.azimuth(215)
ip = q.get()
const_reverse_iterator(cbegin())
i = m.start()
result = pd.tools.tile._bins_to_cuts(arr, bins, include_lowest=True)
temp_file = StringIO.StringIO()
style = Style()
self.end_headers()
min_count = df.shape[0] * df.shape[1]
s = badjson
no.append(d)
test_func({{data | safe}})
a = 1
print(name)
today = datetime.today()
m, m - h, m + h
M = a.shape[0]
a / b / o / p / t / u
print(n.contents.nanoseconds)
result
defaultdict(tree)
_cell.style.fill.fill_type = Fill.FILL_SOLID
foo = 1
print(a)
self.ids.stack.add_widget(self.l[i])
print(__class__)
p = pyaudio.PyAudio()
glClear(GL_COLOR_BUFFER_BIT)
actions.append(action)
processLine(line)
idx = ts.shift(n).fillna(False)
b = a[:]
args = {}
ipshell(msg, stack_depth=2)
v.remove(a)
x = det([[1, a[1], a[2]], [1, b[1], b[2]], [1, c[1], c[2]]])
version = FloatField()
func_name = co.co_name
args = [iter(iterable)] * n
print(prices.pct_change(1))
test[6].append(5)
self.linthresh = linthresh
category.most_common()
y = sin(radians(i))
values = (np.random.random(dates.size) - 0.5).cumsum()
raise OSError(e)
self.__class__(lambda x: Function(self)(x) + Function(other)(x))
data = numpy.random.rand(10000, 1000)
lines = sys.stdin.readlines()
dis.dis(func2)
values = Simulation.sample(values)
f = myopener.open(url)
related = fields.ForeignKey(RelatedResource, full=True)
{k: dict(v) for k, v in list(output.items())}
top = Toplevel(root)
child.py
res.flat[idx] = sll
print(dt)
s = Series(1, index=i)
T(other * x for x in self)
print(al[:, 11:14])
f2 = produce_f(42.0)
l = []
Foo.number
d.addSample([0.0, 1.0], [1.0])
MGI = MGI[4:]
self.setDaemon(True)
result = []
self.view.username = self.post.author
ctypes.cast(addr, ctypes.POINTER(typ))
result = []
print(i)
dfJoin.score.fillna(0, inplace=True)
t1 = Thread(target=stdin_to_queue, args=(q12,))
i + 1
main = argparse.ArgumentParser()
x = 1.5 * 10 ** -2
txt = ip_file.read()
diff = df.c2.apply(lambda z: abs(x - z))
allTuplesRdd = sc.parallelize(dataset, 4)
sinplot()
LAMBDA = lambda : 0
0
print(lda.print_topics())
max_q = max(0.0, np.max(q))
r = f(*args, **kwargs)
data *= 255
pegs[target].append(pegs[start].pop())
d = dict(lst)
strip_list = map(lambda it: it.strip(), lines)
ncol = len(next(reader))
1
csvwriter = csv.writer(csvfile)
store.flush()
df
flist = []
ts = pd.Series(pd.np.random.randn(len(rng)), index=rng)
type(x.A.count())
inner
metadata.reflect(db.engine, only=list(tableNamesDict.values()))
death_day = death_data[4]
print(key, dict[key], dict[dict[key]])
i += 1
pd.value_counts(x)
print(x)
fileReader = csv.reader(csv_file.file)
file_list = []
[1.0],
load_readline_favorites()
MyFailureException
1
kNN1 = kNN.NeighborsClassifier()
c = sy.cos(wrf * t) * sy.cos(wlo * t)
l = chain.from_iterable(zip(*l))
x < x + x
self.con.register(handler, msgtype)
array = np.array(list)
root = lxml.html.fromstring(broken_html)
s
sum = 0
numofc = len(cnames)
yb.resolveDeps()
True
dir(o1)
vc = df.A.value_counts()
print(add1(10))
queue = Queue()
clubs = Club.objects.all()
alter_elements(sample, lambda x: -x)
head(dropwhile(pred, enumerate(accumulate(s), start=1)))[0]
lib.b.B()
total += i
uni = nx.MultiGraph()
python - -version
g[1] = 1 - x[0] + (x[1] - 4) ** 2
m, n = mat.shape
output = [x for x in input if x.name]
0
new_l = []
print(counts)
new = defaultdict(list)
Program_1.py | Program_2.py
window = Window()
print(response.status == 200)
[]
Location2 = motion_plan(increasor(0, -1), alternator(0, -1))
saver = tf.train.Saver()
config.write(cf)
s = np.sin(c - d)
k += 1
glVertexPointer(2, gl.GL_FLOAT, 0, vertices_gl)
buf = get_frame(sys.argv[1])
print(a().perform())
x_pos, y_pos
email_data = data[0][1]
exp <<= number | cstr | key_value | pp.Group(lbra + pp.ZeroOrMore(exp) + rbra)
x = np.empty(t.shape)
items.append(item)
df
sys.exit(2)
print(cube + (10, 100, 1000))
hdlr = logging.StreamHandler()
gen = ((c, ord(c) - 1) for c in s)
mpl.rcParams.update(inline_rc)
a = cos(theta / 2.0)
poller = zmq.Poller()
a, b = b, a + b
do_something()
--------urls.py
a = MyExtendableArray(np.arange(100))
slope(self.x, self.y)
d = {}
m0, m1 = Mock(), Mock()
400, 1.706914, 0.446965
b = as_strided(a, (11, 4), (4, 4))
printRecur(elem)
r, g, b, a = img.split()
mu, sigma = 100, 15
file / usr / local / bin / python
s = [[]]
self.best_res = res
t99 = scipy.stats.mstats.mquantiles(X.data, [0.99])[0]
by_row_index = df_concat.groupby(df_concat.index)
B[r, c] = B[r, r - c]
np.random.seed(2016)
getattr(instance, field.name).add(rel_instance)
primeList = [2]
reader = tf.TFRecordReader()
df.addCallback(lambda _: reactor.stop())
s = s - 1
freq_dict[token] += 1
qfSendingTime = fix.SendingTime()
d = PyModule_GetDict(m)
a, b = tuple(argList)
result = psxmlgen.wait()
exponent = len(list_d[0]) - len(str_dec)
x = POINT1[0] + p * math.cos(bearing)
sqlContext = HiveContext(sc)
c = type.__new__(cls, name, bases, clsdict)
axplot = fig.add_axes([0.07, 0.25, 0.9, 0.7])
c = conn.cursor()
async_list = []
ddd = [str(d1 + timedelta(days=x)) for x in range((d2 - d1).days + 1)]
cli()
x = string.printable
offs = haystack.find(needle, offs + 1)
pos += 1
find_seed(numprimes, start)
b = executor.submit(wait_on_a)
A.plot(xdat, y, color=cpick.to_rgba(t))
foo()
main_global1 = __main__.global1
total_area = np.sum(areas)
_plugins = [klass() for klass in _plugins]
imgs = []
num_warnings += 1
print(a)
a += 1
result = []
head(dropwhile(pred, count()))
out.append(s[i])
i = 0
print(i * 2)
print(sum_z, count_z)
module_n.py
b = 0
np.sum(res)
parse_object.scheme
cin2 = in2[ctr]
self.data[index]
start = datetime.time(start.hour, start.minute, start.second)
data = []
platform.python_version()
x, y = np.meshgrid(np.linspace(-5.0, 5.0, num), np.linspace(-5, 5, num))
final_df = assembler.transform(encoded_df_with_indexed_bar)
False
name, int(num)
lu = spsl.splu(A)
n = len(a)
self.run(translated_name, **kwargs)
True
expiration = datetime.utcnow() + timedelta(hours=2)
merged = list(itertools.chain.from_iterable(broken))
setup_nova(dummy_creds)
w, h = img.size
cls.rules = {}
video = cv2.VideoCapture(sys.argv[1])
print(x)
False
[]
self.value = value
writer.flush()
sys.stdout = log_file
b = example.get_base()
code.co_consts[2]
fallback_handler = logging.StreamHandler(stream=sys.stdout)
df = df.stack().reset_index()
mapping = dict((idx[i], idx[i - 1]) for i in range(n))
numwords[word] = 1, idx * 10
x if x is False else y
d = Nice()
iters = [i for i, j in ((iter(k), k) for k in map(list, args)) for _ in j]
child.stdout.pipe(process.stdout)
indices = random.sample(list(range(len(myList))), K)
a, b = (float(s) for s in line.split())
print(X.shape, Y.shape)
distance_matrix[j, i] = distance_matrix[i, j]
yy = slice(1, 5)
urlopen(url, data)
post_save.connect(update_attachment_count_on_save, subclass)
do_something(current)
data
np.diff(data.value)
ax = plt.gca()
content = enternum.get()
lo * hi
print(x)
dyn.put()
func = timeout(timeout=16)(MyModule.MyFunc)
output, err = p.communicate()
a = PriorityQueue()
data = csv.reader(file)
re.findall.__code__
parsed_values, meta_data = ast.literal_eval(repr(tokens))
college_list.sort(key=len)
readdir = c_lib.readdir
closedir = c_lib.closedir
True
img = LoadImage(file)
print(using_view(A, B, assume_unique=True))
n = [next(it, done) for it in iterators]
M[:, (1)] = [[0], [0]]
X_test_pca = estimator.transform(X_test)
x = 1.000001
every_hours_crontab.save()
top = destruct_directed_run(num_set, arbitrary_member + 1, 1)
original_request = request._request
t = [2, 4]
zoomMultipliers = np.array(tempShape) / np.array(inShape) + 1e-07
match_size = len(match)
data = np.vstack((data, feature))
ctx = Context(prec=20)
adj = self.scrolled_window.get_vadjustment()
i, j = np.ix_([0, 1, 2], [0, 2])
A.print_x.__func__(b)
print(s)
time.sleep(start - t)
new_arr = arr.reshape(5000, 25)
palette = []
os.path.splitext(os.path.basename(code.co_filename))[0],
y = y.reshape(x.shape)
nIterates = 100
stdoutHandler.setFormatter(logging.Formatter(LOG_FORMAT_WITH_TIME))
standard_c_lib = ctypes.cdll.LoadLibrary(get_libc_name())
province = db.StringProperty()
constraints = [c.copy() for c in table.constraints]
commands = Queue.Queue()
s = reactor.listenTCP(LOCALPORT, factory)
print(verboseResult())
y = float(maxwidth) / float(width) * height
b = [True, True, True]
i += 1
X = np.random.random_sample(n)
callback = software_updates.subtask()
res = dict.setdefault(key, {})
average = sum([a for a, b, c in values]) / float(len(values))
bf = int_to_bytes(int(b, 2), 8)
clientPort = 2181
window = glumpy.Window(512, 512)
print(len(matching))
assert b.x == 1
1
result = []
dict(enumerate(map.objects))
tc = tc.Elem()
t.start()
s
res = MD.map([(i,) for i in range(6)], sum_row, ordered=True)
p = subprocess.Popen(args)
total += count
HOTP(K, C, digits=digits)
os.dup2(devnull, 1)
frags.append(generate_sample, chosen_expansion)
df
print(tables[1].text.strip())
lowest_acceptable -= 1
t1 = time.time()
obj = cls()
groups[-1].append(val)
list = FoodsList()
m = mixture.MixtureModel(2, [0.5, 0.5], [n1, n2])
shuffle(l)
qt - devel
company = CompanySerializer(allow_null=False, required=True, write_only=True)
p.join()
numpy.array(trainX)
source / path / to / bin / virtualenvwrapper.sh
opener = urllib.request.build_opener(cert_handler)
json_obj_type = type(json_obj)
f
os.path.getctime(filePath)
reverse_linked_q.append((this_key_chain + [k], v))
epoch + timedelta(days=inDays - 1, seconds=inSecs)
self.RunFunctionIThinkIsSlow(param)
d_mva[10:20]
fig = plt.figure()
frag = frag[:5]
print(arr)
print(parse(s, fuzzy=True))
print(i.author)
print(a)
a, b = itertools.tee(L)
buffer.seek(0)
fig, ax = plt.subplots()
f.close()
next(m)
cosine(pink, red)
rs = [bisect(cdf, random()) for i in range(20)]
replace = [(x, y + 1), (y, x + 1)]
len(inspect.getfullargspec(add).args)
y[0, 0] = 100
letters = list(lt.keys())
[easy_install]
msg_id_list = msg_ids.split()
Schema.TYPE_MAPPING[ObjectId] = fields.String
main_set = set(list_of_all_items)
connection.creation.create_test_db(verbosity, autoclobber=not interactive)
False
os.makedirs(folder)
contents = file1.read()
y = fit_df[col].values
ext_modules = [mylibrary_module],
y = 0
self.history.append(statement)
y = xy[:, 1:2]
[k] + p
h = httplib2.Http()
pubkey = EVP.PKey()
exit_status = process.wait()
self[key] = value
N = a.shape[1]
bs_parse(html)
type(g.groups)
self.myGUIInit()
print(stdout)
subject = CharField(max_length=255)
strong = collections.deque(maxlen=maxlen)
image
auth_NTLM = HTTPNtlmAuthHandler.HTTPNtlmAuthHandler(passman)
self.__dict__[name] = value
join_neighbors = list(set(neighbors) & set(next_neighbors))
x
config = ConfigParser.ConfigParser()
atexit.register(code.interact)
t = np.arange(0.0, 10000.0, 10.0)
newlist = mylist[:]
print(i)
j += 1
G = float(np.sum(g)) / ttl
match = np.isnan(b)
time.sleep(int(1.0 / fps))
a = A()
sublist = [1]
obj.select()
num = 0
data2a = np.array(np.random.uniform(0, 1, batchSize))
-1
r = weakref.ref(o)
font.set_weight(pango.WEIGHT_BOLD)
t[0].join()
n0 = n + 1
print(to_range_list(diff))
M[1, 1] = 1
sys.__stderr__.write(altered_txt)
blah = poll()
isitIn(char, aStr)
strings, numbers = zip(*tuples)
find_first(8, a)
value1, value2 = foo(a, b)
p(east_dt)
ctypes.pythonapi.Py_IncRef(arrayobj)
table = document.add_table(rows=1, cols=len(col_names))
node1.children.append(self.buildnode(children))
b1 = np.all(frame < NSigma2, axis=-1)
print(node, link.mNode.GetName())
--version
(okays_append if success_condition(r) else errors_append)(r)
os.dup2(stdout, 1)
d = defaultdict(int)
a.resize(b.shape)
real_handle_exception(self, *args, **kwargs)
a = Person(1, 2)
dtype = x.dtype
redirect_to_login(path, resolved_login_url, redirect_field_name)
my_array = arange(10)
attachment.WriteToFile(FileName=filename)
self._norm = 1.0 / (2 * variance)
rcv = readlineCR(port)
o = SomeObject()
W, p = scipy.stats.shapiro(dataset)
help(s.value_counts)
self.number < other.number
c[j] = d[i == j].sum()
Console.Write(File.ReadLines(filename).ElementAt(linenumber - 1))
line += line_p[i]
inds = diff.index[:5]
(df_from_g == a).all().all()
getattr(self, attr)
DBSession = scoped_session(sessionmaker())
exit(ret)
fig = figure()
students = [lloyd, alice, tyler]
os.close(devnull)
zipped = zip(x, y)
main()
self.y = y
store = defaultdict(list)
working_slice = img.crop(bbox)
self.last_value = self.gen.send(arg)
x = width = svg.props.width
request = req.Request(url)
self.write(block)
j = np.arange(i + 1, i + INTERVAL_LENGTH)[filter]
0.0, 1.0
pct.append(float(idx) / self.n * 100.0)
counter += 1
p.x = x
os.remove(fileobj)
hanoi(pegs, start, aux, n - 1)
newlist = []
glVertex2f(0.1, 0.9)
setattr(ob, name, value)
res[v] = 1
intg = np.array([quad(f, 1e-09, xx)[0] for xx in x])
print(stack)
clf = MultinomialNB()
2 - 0.128205
l = len(str(s))
byvalue = defaultdict(list)
print(minm, maxm)
statistic[i].append(np.nan)
self.textedit.moveCursor(QTextCursor.End)
client.set_missing_host_key_policy(paramiko.WarningPolicy)
j_shift = np.interp(g[:, (0)], g[(0), :], np.arange(n))
s.append(((obj.votes - 1) / pow(obj.submision_age + 2, 1.5), obj))
result += 1
i += 1
time.sleep(0.1)
thread = Thread(target=http_server)
result = []
slice1.insert(axis, n)
i = b[1] - b[0] - k
y = np.concatenate((y, -y))
fl = fcntl.fcntl(fd, fcntl.F_GETFL)
m = mock.Mock()
mean_age = survey_data.Age.dropna().mean()
y = touch.y - self.center[1]
setattr(clone, slot, getattr(self, slot))
type(delta)
print(data)
s = set(a)
df
random()
MyClient(MyServer()).client_show()
new_grouper.append(key)
sample = [(v / sum(sample)) for v in sample]
query = make_query(start_cursor)
response
canvas = Tkinter.Canvas(window, width=image.size[0], height=image.size[1])
sys.stdout = backup
f[:] = numpy.random.randn(*f.shape)
align_lr(g1, g2)
print(self.answer)
points = np.arange(20).reshape((10, 2))
r.append(word)
result = regex.search(seq, pos)
unique1 = list(lines[1].keys()) - list(lines[0].keys())
coeff = Stream((1, -1, 1, -1, 1, -1, 1, -1, 1, -1))
sessionOptions.setServerPort(port)
node = candidates.pop()
print(hex1.neighbors())
out[k].append(recursive_asdict(item))
_d = Functions.motion.move().right
result
raise AttributeError
wnd.set_default_size(400, 400)
locals()
newrow.append(row[0])
collections.__file__
t = t.upper()
environment.handle_exception = handle_exception
args = parser.parse_args(sys.argv)
self._callback = callback
colors = {l.get_label(): l.get_color() for l in ax.lines}
r = np.empty((n, len(u)), dtype=c.dtype)
a = [(x / 10.0) for x in range(100000)]
loop = asyncio.get_event_loop()
os.dup2(silent, 1)
tuple(tbl[c] for c in color)
step(i + 1)
data = [d.split() for d in data]
a.hotel.id
app = Flask(__name__)
f = Foo()
a = next(self.l)
book.authors.remove(georfe)
print(float_numbers)
print(i)
print(audioop.max(data, 2))
ax = axs[x, y]
mutex.release()
f = h5py.File(fid)
a[i]
ranges.sort(0)
generate_app(options.environment)
pix = im.load()
confint = []
2.0 ** 2
table_1.columns = clean_label(table_1.columns, margins=True)
20.15
29.91
60.19
69.96
79.72
90.46
urllist = f.readlines()
Base = declarative_base()
buf = StringIO.StringIO()
print(line)
parser.print_help()
f.seek(offset, 1)
print(line)
lexer.lexpos = pos
r = random.randrange(c, d - 2 * b)
m, n, cache = len(seq), len(sub), {}
i = i % len(self)
L = s.split(delimiter)
a = math.sqrt(t)
stop_event.wait(time)
np.import_array()
Parkour_Character.move_ip(Parkour_Speed, 0)
subtask = task.s(*myargs, **mykwargs).set(queue=myqueue)
ncols = max(len(row) for row in a)
co = webdriver.ChromeOptions()
nums[0] = 2
y = 150 + 25 * plt.randn(1000)
autostart = true
autorestart = true
killasgroup = true
out.append(i)
p = subprocess.Popen(args)
print(kw)
list2.append(item)
r = []
dom = dt.day
value = type(self)(value)
png_output = StringIO.StringIO()
client
2, 2, 2, 6
x = 2592701575664680448
x2 = 1
2
length = len(email)
print((n, mv.tobytes()))
whole = wrapper % tuple(str)
G = nx.complete_graph(4)
print(x.my_property)
KDSETLED = 19250
ostream.write(*objects_list)
j = arange(255)
self.authorize()
data = np.random.rand(1, 4).tolist()[0]
new_dict[i] = temp
KDSETLED = 19250
print(a)
v = test_data[:, (-1)]
obj = A()
print(TestSuite.to_xml_string(ts, prettyprint=False))
raise ValueError(msg)
index = -1
some.sort()
Returns
self.length = len(self.zero_indices)
column_of_values = NP.random.randint(10, 99, 10)
code = df.stack()
json.dump(self, fh)
win.close()
b = b.strip()
data[key] = val
print(lt.tm_gmtoff / (60 * 60))
repr(self.arg)
fdata = fliers[i].get_data()
plt.ion()
result[match[0]] = True if not match[1] else match[1].strip()
self.m[idx]
changeGlobal()
list = list(range(20))
ax = plt.axes()
assert isclose(a, b, abs_tol=1e-08)
2 + 2
test = df[~msk]
data.append((ip, orginalName))
print(split_list(A, wanted_parts=8))
setattr(self, name, inject(attr))
source.Execute(scope)
to_bijective(from_bijective(s) + 1)
Py_Initialize()
nc = netCDF4.Dataset(url)
print(a)
BOOST_PYTHON_MODULE(MyModule)
yTrain = np.array([[1, 0], [0, 1], [0, 1], [1, 0]])
sd_sample2 = np.std(sample2, ddof=1)
row_scalar = np.ravel_multi_index(row, dims)
t = Timer(1, p.terminate)
self.b = 0.0
later = time.time()
path.insert(new_step_index, new_step)
1
res[::2] = u[:min_len]
round(2.6)
o = SubClass()
end_time = Column(Integer)
Y = np.arange(1, 10)
cov.report()
self.loaders = {}
parser = OptionParser()
doc = libxml2.parseDoc(DOC)
data = list()
self
name, seq = line, []
demo()
doStuff(i)
newlist.append(item)
__serialize(cls, d, rs)
print((ITEMS, CHUNKS, time.time() - t))
loop()
fclose(input)
response.write(t)
exog = np.vander(x, degree + 1)
xlApp.Visible = 0
+db_matrix[:, (option_vector[i, 1])] * bp_vector[j, 1]
out_str += char
self._in(wrapped.__get__(self, cls), *args, **kwargs)
pdf.footer()
self.name = name
buffer.read().strip()
new_size.scale(event.size(), QtCore.Qt.KeepAspectRatio)
self.pub_date = datetime.datetime.now()
root = Tkinter.Tk()
b = c_int(4)
quote = m.group(2)
ax = cb.ax
p = Test()
self._foo.x = value
self.f = open(fname, mode)
data = zip(ip1, packs)
vector = vector.toarray().flatten()
gcd = GCD(a, b)
customers = np.unique(A[:, (0)])
p.nice()
primes = list(range(2, max))
dists2 = abs(r[triu[1]] - r[triu[0]])
databack = scipy.misc.fromimage(pixback)
print(i)
data.query(qry)
results = arma.fit()
matches = np.concatenate(([0], np.equal(x, val).view(np.int8), [0]))
x = 42
frontier.append((vertex, -1))
vals.sort()
keycount += 1
result
starts = [0] + [i[1] for i in splits]
a[:len(a) // 5 * 5].reshape((-1, 5))[:, 1:4] = 100
verb_list = [x, y, z]
createTest(MyTestCase, somedata, index)
dingo = 2
file_path = os.path.join(dir, the_file)
G.add_edge(a, b)
Y.sum(0)
self.n = n
summary, _ = sess.run([img, train_step])
print(c)
x
path = os.getcwd()
False
string * times
args = args.copy()
print(result)
location.raw
c = mpmath.sqrt(b)
idf = np.log((len(df) + 1) / (tf.gt(0).sum() + 1))
print(tup)
colSize = [max(map(len, col)) for col in zip(*myList)]
1 in a
levls = np.linspace(1, 10, 10)
self.attr_name = attr_name
df
x1 = (x1 - min(x1)) / (max(x1) - min(x1))
rect = minrect[topLeft:] + minrect[:topLeft]
x = writecode(5, 1, 0, 4)
out = A.dot(B).tolil()
[0, values, 2]
os.environ[name] = value
print(node.get_data())
arr = np.random.rand(256, 256)
f_string = pickle.dumps(f)
print(x)
scrollbar.config(command=lb.yview)
fig, ax = plt.subplots()
print(result)
fringe.push(item)
c = [2, 1, 1, 1, 1]
self.draw_bars(ax, bar_kws)
entries = [line[2] for line in reader if int(line[1], 16) in hexvalues]
obj = getattr(A.objects.get(pk=int(pk)), attr)
instance
print(i, val)
c
solutions = []
sess.run(tf.global_variables_initializer())
self.files = []
fhandle.close()
self.width = width
[(s + fill) for s in wrap(string, length - len(fill))]
p = Child()
1
dt.iloc[index]
b_ma = np.ma.masked_where(b < 0, b)
_output_csv(row)
module.runCode(cl)
print(x, y)
all_occ[k] = [x for x in v if (x[0] > end) | (x[1] < start)]
now = start + datetime.timedelta(seconds=i)
s[1, 2]
list_A = []
x_out = NP.linspace(0, 2, 20)
a[a > 0] = 1
i = sys.stdin.read(1)
hcpv = np.array([[cpt_hcpv(p, s, poro, sw) for p, s in r] for r in g_arr])
print(dict(d))
dt_obj = datetime(*time_tuple[0:6])
self.redirect(redirect + username)
id = db.Column(db.Integer, primary_key=True)
newchunksize = len(indices) / newchunks
write_line(indiv, last_window + 10000, coverage, 0)
[U, s, V] = np.linalg.svd(A, full_matrices=False)
d.addSample([1.0, 0.0], [1.0])
print(mail.list())
self.length
resp
extend(l), r
r = a or b or c or default
exc.__cause__ = cause
self._stride_length = value
nums = collections.Counter(itemlist)
new_list = []
imgdata = StringIO.StringIO()
arr1[unequal_pos]
parser = create_main_parser()
y = POINT1[1] + p * math.sin(bearing)
fixed_positions = {(1): (0, 0), (2): (-1, 2)}
NULL
font_description.set_size(font_size)
out_file.close()
print(A)
MyArray({key: OrderedDict.__getitem__(self, key)})
args = sys.argv[:]
self.conn = get_connection()
value = result.get()
calls = cursor.fetchall()
self.assertTrue(t.iditit)
p.terminate()
current = next(seq)
print(foo)
ruby_question = p.stdout.readline()
self.values = values or dict()
self.n_neurons = n_neurons
plt.setp(patches, linewidth=0)
treebank_tagged_words[0]
wbk = xlwt.Workbook()
rpc = urlfetch.create_rpc()
x = np.linspace(-50, 50, 100)
set1 = set(list1[0])
queryset
r1 = conn.getresponse()
encrypted = base64.b64decode(encrypted)
z = 0
self.id = id
self.logger = logger
foo
Z = griddata(x, y, z, xi, yi)
put_into_locals(test.dependencies)
a = 5
Planet.EARTH.mass
RegisterPy()
a, b, c, d = start.hour, start.minute, start.second, start.microsecond
input_length = X_train.shape[1]
page = nf.read()
filename, chunk_number, number_of_chunks = params
H = np.eye(dim)
conn.execute(ins.values(cols))
figManager.window.showMaximized()
(50, 140), (50.1, 170)
rv = subprocess.check_output(cmds, stderr=subprocess.STDOUT).decode()
getattr(self._request, attr)
iter(self.L)
c = 0
self.oktypes = oktypes
arr_2 * 2
[9, 6, 1, 5],
myDll = ctypes.CDLL(dllabspath)
1
cnt[ch] -= 1
(seq[pos:pos + size] for pos in range(0, len(seq), size))
email = Column(String(64), nullable=True)
msg.ParseFromString(data[pos:pos + next_pos])
bootfile = p.communicate()[0]
encoding = sys.getfilesystemencoding()
my_slice(word, step)
i()
arr[~np.in1d(arr, valid).reshape(arr.shape)] = 0
t = int(input())
io.DEFAULT_BUFFER_SIZE
indices = defaultdict(list)
print(line)
self.tree_filter.set_visible_func(self.match_func)
visited.add(state)
self.host = host
print(str(foo))
list = []
result
secondes_dot_ = duration(filename)
x == 0
proto
sys.exit(1)
y[y.columns[0]].tolist()
order_form = OrderForm(obj=order)
delta_long = radians(long_a - long_b)
counter[0] += 1
N = np.size(Xi)
matched_data = list()
ends = [i[0] for i in splits] + [len(string)]
chunk.append(someFileId)
obj[key] = float(mod.__dict__[key])
http = self.oauth.credentials.authorize(http)
True
newlist = [[alist[0]]]
result_data = np.empty(zones.shape)
self.x = 100
status, output = commands.getstatusoutput(command)
ser.setRTS(True)
degs = [1] * size
r = glob.glob(test)
x = NestedDict(a={})
temp_p = PyTuple_GetItem(args, i)
a, b = 1, 2
self.elements[name] = KeepTogether(t)
solution
clientEndpoint.connect(factory)
sols
temp_array = [((i + 1) * 10) for i in range((129 - 1) // 10)]
out = numpy.zeros((c, d))
True
rv1 = stats.gamma(a, loc, scale)
a = A()
method.invoke(instance, args)
t = n.timetuple()
x.lhs().symbol()
draw = ImageDraw.Draw(im)
r = ran.random()
im_dst = im_binary & (1 - im_mask) * 255
ef21b9ad
combined_summary = tf.Summary()
pool = Pool(processes=4)
area1 = 0.5 * np.abs(np.dot(x, np.roll(y, 1)) - np.dot(y, np.roll(x, 1)))
groups.setdefault(trans.blog_id, {})[trans.field_name] = trans.translation
yx = zip(Y, X)
np.diff(data.value.index)
a + b
self.mainFrame().load(req)
root = tree.getroot()
stream.seek(0)
self._locked = False
something = B(x=1, page_num=2)
i, j = I.T
clean_up_in_a_hurry()
arr = df.as_matrix(cols)
c = numpy.array([[9, 10, 11], [12, 1, 2]])
pd.concat(retLst)
X2 = np.sort(Z)
unique_items = set(data)
q = session.query(ndticket_table, cause_code_table).join(cause_code_table)
cache[s1, s2]
raise ValueError
x, y = y, x + y
color = orig_handle.get_colors()[0]
w_o = tf.Variable(tf.random_normal([n_in, n_out], mean=0.0, stddev=0.05))
df1 = df.ix[date:, :]
id_arr.cumsum()
any(x[col] == val for x in self.d.items())
n = 2
mu, sigma = 100, 15
object.__getattribute__(self, attr_name)
fig.add_tools(bokeh.models.TapTool(callback=TapCallback))
f = lambda m, n: [(i * n // m + n // (2 * m)) for i in range(m)]
self.x + z
cron.get_next(datetime.datetime)
m = hashlib.sha256()
sport.check_all()
args = [iter(iterable)] * 2
scaled_features = mapper.fit_transform(df.copy(), 4)
k = list(i.keys())[0]
raise
C.pack()
out.append(cell)
f1 = lambdify([x], y_solsf1)
print(result.fetchone())
print(df)
buf = file.read(x.size)
data1, data2 = read_csv_file()
values_fmt = [value_format(val) for val in values]
access_token, access_token_secret = self.KNOWN_USERS[user]
self.weights[self.chars.index(char)]
gc.is_tracked(4)
MDD_duration = np.busday_count(MDD_start, MDD_end)
-0.0 == +0.0 == 0
current_set -= 1
pixels = list(im_gray.getdata())
self._setDefault(stopwords=set())
self.mustignore = dict(f.f_locals)
6
g2.drawRect(self.x, self.y, 10, 10)
center = [(0) for i in range(2)]
a = np.array([-2, -1, 0, 1, 2])
it_B = iter(B)
num_tokens = text.count(token)
s1 = np.random.uniform(0, a, n)
print(test.f)
dot11_phy_type_dsss = 2
s2 = pd.Series([True, True, False, True, np.NaN])
Include / etc / apache2 / vhosts.d / media.include
{fxn(song) for song in self.allSongs}
img = ImageChops.difference(img1, img2)
not any(st.issubset(data) for st in checker)
arr_1 = [random.randrange(0, 5) for _ in range(10)]
False
field[1].format(field[0])
n = np.logspace(2, 5, 4, base=2)
self[key]
self._y = y
encoders.encode_base64(msg)
sublime.set_timeout_async(self.test, 1)
user = models.ForeignKey(User, blank=True, null=True)
y = np.ravel(zip(y, y))
cipher = PKCS1_OAEP.new(key)
s = prob_matrix.cumsum(axis=0)
root.add_node(node)
82, 0.449198, 0.978571, 0.116202
self._table = table
data = stats.gamma.rvs(alpha, loc=loc, scale=beta, size=10000)
lines.append([(0, i), (1, j)])
canchangedriver = True
point(-2, -1)
plot(r_i, zlim=c(-10, 25))
deactivate
VARIABLE14
result = []
name = module[0]
it1, it2 = tee(iter(a))
ax = plt.gca()
result = FlakyClient.call()
self.write(initial)
self.axes.plot(x, y)
month = cal.monthdatescalendar(2010, 7)
df_dict = {cell.value: [] for cell in row}
ax.yaxis.get_minor_locator().subs([1.5])
c += z[i + 2]
new_items = {item: (item ** 2) for item in range(5, 7)}
print(repr(f.newlines))
pairLambs[1]()
fg = plt.figure(1)
decoded = decrypt(key, encoded)
fg.close()
Infix(partial(self.func, other))
y = y.flatten()
p = array_2
self.fed.append(d)
image = models.ImageField(upload_to=image_upload_to)
pango_context = editor_widget.create_pango_context()
author_firstName = Column(String(20))
b = np.arange(100, 200)
colors = QColor(c).getRgbF()
self.im = Image.open(pathname)
Window = Frame(root)
word
instance.save()
System.out.println(powerSet.get(i).size())
_numbers = list(range(0, 10))
FAILED(errors=1)
dictionary[word] += 1
result
rand_int += ord(c)
s = f.read()
id(y.x)
match_iterator = token_regex.finditer(match.group(1))
PyObject * p
rows, cols = X.shape
self.delete(name)
BZ_IN = Bz.copy()
results = Queue()
file_on_disk.read() == file_in_memory.read()
i = 1
num_df
x = x[1:] + x[0:1]
c = [[0], [0], [0], [0], [0], [0], [0], [0]]
bw = cv2.cvtColor(src, cv2.cv.CV_BGR2GRAY)
self.popMenu = QtGui.QMenu(self)
self.aws.__aenter__()
c
output
print(p.stdout.read())
grdevices.png(fn, width=width, height=height)
A.compute.__self__.__class__
fast_real(56.0, coerce=True)
print(notags)
[F(N + 1), F(N)]
shutil.copy(dll, dest_dir)
self._reqId = 1
source_bytes = source_image.read()
c = []
print(filename)
plot_selector.configure_traits()
upper_white = np.array([0, 0, 255], dtype=np.uint8)
nested_instance.__class__ = nested_class
t0 = datetime.datetime.now()
print(df)
omags -= 1.0
im_hsv = cv2.inRange(im_hsv, (7, 180, 180), (11, 255, 255))
new_stack
do_things_here()
max_mask = np.zeros_like(pdf)
__metaclass__ = classmaker()
c[i] = a[i] ^ b[i]
sList.append(stream.read())
userform = MyUserCreationForm(request.POST)
lines = partialLine.split(inputNewline)
id(me)
a.rotate(-1)
fig = plt.figure()
pa = argparse.ArgumentParser()
memo[n][arr][end] = (n - arr[..., (end)]) ** 2
bytes_read = ctypes.c_size_t()
p.findall(s)
numbers = []
dict(d)
g.series(x, 0, y, 0)
rdfrm = com.convert_to_r_dataframe(dfrm)
Py_XDECREF(arglist)
chunk = infile.read(1024)
dir(object)
old_set = [[0, 1], [4, 5]]
idx |= ts.shift(j).fillna(False)
temp = a[mask1]
x2 = 1,
current._set_ident()
nargs = len(args) + len(fargs)
A(0, 0)
a + b + c
new_lis = lis[:]
r = restartable(x)
subStr = word[idx - 2:idx + 1]
ax.bar(data, data)
print(i)
print(x[0])
self.signal_received = False
print(threading.activeCount())
self.factory = factory
type(data)
maxVal = max(map(max, l))
df
C_list = [5, 6, 7, 8]
traceTA = s.sum()
input_str_lower = input_str_lower.replace(replace_str, replacer_str, 1)
struct[0]
b.append(i)
Image.register_open(BmpAlphaImageFile.format, BmpAlphaImageFile)
pipeline.add(gtksink)
scipy.inf * 0
total = 0
path.moveTo(0, 0)
zfiledata = StringIO(zfile.read(name))
assert n(20) == set([15, 16, 21, 45])
r = [x.sum() for x in g]
a_index += 1
app.add_url_rule(rule, endpoint, f, **options)
(ajcr(a) == divakar(a)).all()
Bob, 0.085
u + v - z0, u * J + v * Jc - z0, u * Jc + v * J - z0
filename = os.path.basename(member)
pprint(myTree, stream=out)
name = list1[i]
obj = obj[:]
jar = cookielib.CookieJar()
self.username = username
PyErr_BadInternalCall()
triangle = tri.Triangulation(corners[:, (0)], corners[:, (1)])
word = docx.wordrelationships(relationships)
cycles.append(matching)
tempdict = {}
groupable = pd.concat([X[colname], y], axis=1)
cats.setDACValue(1, 4)
assert isinstance(to_translate, str)
list_dir = []
y = np.linspace(700.0, 900.0, 401)
LB[0, 5, 9, 12]
print(df)
True
Rtf_text = label.text()
self.currentWeight = self.weight
scriptable = Scriptable(my_script)
time.sleep(2)
Python
bigram_measures = collocations.BigramAssocMeasures()
obj.isoformat()
commands.put(command)
shell.mainloop()
map[x][y] = 4294967295
a + b
f.seek(80 * 100000)
Py_DECREF(start)
m.close()
frozenset([(source_node,)])
self.key = value
result
neighbors = G.neighbors(root)
idx.insert(pos, cell.bounds)
doctest.testmod()
yx = [y.size, x.size] + [1] * (f.ndim - axis - 1)
raise StopIteration
records.append(record1)
wrapper
action(*actionargs)
x = np.linspace(0, 500, numpoints)
print(list(SP.keys()), list(CP.keys()))
s = s.replace(i, o)
max_columns()
result.append([hour, value])
n
host.expect(newExpect)
grequests.map(rs)
result = dialog.exec_()
x_median = x[nearest_05]
pylab.show()
help(sys)
buffer.seek(0)
maxindex
f.e()
10
count = 1, 0, 0, 2, 0, 0, 1, 1, 1, 2
name = m.group(1)
urls[-1 - len(tlds)]
s = sql
more.append(item)
event.start = self.startDateTime
random_floats(0.5, 2.8, 5)
client = Cassandra.Client(protocol)
list(d.keys()), avg
print(e.message)
fmin = np.minimum(f1, f2)
i = n % 10
pd.to_datetime(x)
len(solutions)
all.mask[:len(set), ..., (i)] = False
b = numpy.array([4, 5])
s += i
matches = self.pattern.findall(self.orig_template)
plt.scatter(X_Train_embedded[:, (0)], X_Train_embedded[:, (1)], c=y)
INPUT = sys.stdin
files = os.listdir(os.getcwd())
value.append(p[:i] + [l[0]] + p[i:])
getsizeof(dict((n, 0) for n in range(5462))) / 5462.0
browser.get_screenshot_as_file(path_to_file)
model.removeRow(qIndex.row())
localizer = get_localizer(request)
pixdata = img.load()
j = np.complex(0, 1)
self._set_property_defaults()
match = re.match(pattern, string)
ch = logging.StreamHandler()
dt_matrix = pd.DataFrame()
bar(5)
t.replaceWith(t.strip())
print(a)
trainer.trainEpochs(100)
next(a)
n
emails = []
x = np.arange(10)
res += 1.0 - cos(val)
user = nobody
dis.dis(unpack_or_index)
self.update(d)
result
activations
item = lst1[i]
c = Child()
res = [x.hypernym_paths() for x in wn.synsets(word, pos)]
im.putalpha(alpha)
property = path.pop()
ax.add_artist(circle)
a_piece = pickle.load(sys.stdin)
cursor = fruitDB.cursor()
new_list = [types_dict[t] for t in types_found]
fut.result()
lon = np.arctan2(xyz[:, (1)], xyz[:, (0)])
logger_handler = logging.StreamHandler()
response.raise_for_status()
c.setopt(pycurl.URL, url)
curve = np.array([data[index] for index in class_members])
[0, 0, 0]
1
id_counter[2]
print(result)
absdiff = np.abs(np.diff(matches))
self._x * -1
Y = np.random.rand(1, 100) * 10
self.lastTextPos = QPoint(0, 0)
floor(xyFromCell(r, ii))
bytes(bytearray(getrandbits(8) for _ in range(n)))
med = df.median()
n = int(sys.argv[1])
request_queue.put(data)
intermediate_dict[line_number][key] = my_dict[entry]
draw.draw()
28.26
enc.feature_indices_
x = arange(5 * 5 * 5).reshape((5, 5, 5))
filelist = os.listdir(dir_path)
x = set()
plt.show()
offset = (bg_w - img_w) / 2, (bg_h - img_h) / 2
curpiece.shift(1, 0)
c = []
ops[relate](inp, cut)
self.dloadItems(event, outdir)
shift_axis = 0
raise StopIteration
counts = Counter(a)
self._optcre = self.OPTCRE_NV
mng.frame.Maximize(True)
S1, S2 = 0, 0
__buitlins__.open = my_open
a = [4, 5, 6, 7]
adjs = [left for left in tok.lefts if left.dep_ in ADJECTIVES]
row_x, col_x = meshgrid(list(range(x.shape[0])), list(range(x.shape[1])))
TestAbsoluteMove.Ssh(self)
A if condition else B
key_str = key.text.strip()
eigenvectors, eigenvalues, V = np.linalg.svd(data.T, full_matrices=False)
print(df2)
z = np.empty_like(rgb_image)
month_end = date
server = smtplib.SMTP(SERVER)
isinstance((), Mapping)
f = False
True, np.where(ma.mask == False)[0][0]
parser.print_usage()
Relational(all_on_left, new_rhs, op)
uexpr
out[name] = object_to_dict(related_obj, found)
x.tag.test_value = np.random.randint(100, size=(5, 5))
iter(self._dict)
raise KeyError
df
fig = plt.figure()
a()
Car.sorted.all()
collatz(number)
x += 1
print(s.recv(4096))
list_AlignMatrix.append(list(list_AlignMatrixRow))
n, i = divmod(n, 256)
result &= outmask
print(df.index.weekday_name)
print(df1)
file_size = os.fstat(fl.fileno()).st_size
cursor = connection.cursor()
[48, 54, 48, 55]
z = zlib.decompressobj()
fig, ax = plt.subplots(1, 2)
parsed = list(urlparse.urlparse(testurl))
w = wavefile.load(filename)
b = []
obj.download_fileobj(data)
factory = protocol.ClientFactory()
datum = (number[:, :, (0)] * 15).astype(int).reshape((64,))
setattr(instance, key, rel_instance)
arr = arr.reshape(-1, arr.shape[-1])
fallout.write(protein_line)
x += 1
f = record._fields[n]
milepost = len(data) // 10
x = zeros(data.GetNumberOfPoints())
print(prediction)
result
values = [song[column] for column in columns]
context = {}
self.updateGUIThread = Thread(target=self.updateGUI)
successors.add(node)
foo = bar
main()
x * x
sample_dictionary[len(word)].add(word)
idx.unique()
array = [abs(item) for item in array]
first.sql_ctx._sc.union([df.rdd for df in dfs]),
y = np.array([0.5, 0.75, 1, 0.5])
description = next(line_iter)
(index,) + path
bar(x)
output = StringIO()
source_unique = list(set(source_list) - set(diff_list))
f.writelines(lines[1:])
_id = wx.NewId()
True
mins = mins[:n]
renamed
out_data = pad_audio(in_data, fs, T)
ones = [np.ones(l) for l in run_lengths_1]
ips.remove(item)
p = pyaudio.PyAudio()
pickle.dump(NewNamedTuple(piece, more_data))
G = int(round(B * 255))
good_input = user_input
seta = seta.union(listb)
s.getvalue()
finalMessage += chr((ord(value[x]) - 64) % 26 + 65)
vector.shape
folders = os.walk(directory)
self.end_headers()
cards = dict(zip((str(x) for x in range(1, 11)), list(range(1, 11))))
print(text)
count = pd.value_counts(dummy_col) / len(dummy_col)
oscmsg = OSC.OSCMessage()
x == y
data
soup = bs4.BeautifulSoup(content)
filenames = [name for file in [files for _, _, files in os.walk(path)]]
df
a in [a]
d[0](1)
c1.do_something()
print(index[2])
root_logger.addHandler(handler)
id = sa.Column(sa.Integer, primary_key=True)
os.system(cmd)
value = self.get(name)
parsed_output.write(window[1])
operator.attrgetter(*field_list)(context)
words[line[0:split_idx]] = line[split_idx + 1:-1]
PyObject * item(NULL)
results = [f(i) for i in range(50)]
values.get(value)
startOfThisYear = dt(year=year, month=1, day=1)
ret_code = p.wait()
print(x)
GetSongs = GetSongs.new()
df1.Title = df1.Title.astype(int)
a = datetime.now()
self.item_name = item_name
f.write(aes.encrypt(data))
your_dictionary[node.string] = node.next_sibling.next_sibling.string
foo = Foo()
httpd = HTTPServer(server_address, HandlerClass)
l
db.session.add(Invite(email))
print(field.primary_key)
self._startPage()
diff_if_bigger(np.array([5.6, 7.0]), 8)
results.extend(result)
__len__
display(prgBar)
clf = LinearSVC(class_weight={(0): 1, (1): i})
dict_a = tupl[1]
diff_to_previous.cumsum()
parent.children.append(Node(parent, contents))
grid.Add(self.buttons, flag=wx.EXPAND)
test1 = MyModel()
epoch = datetime(1970, 1, 1, tzinfo=timezone.utc)
lat = math.radians(latitude_in_degrees)
x = np.arange(4)
t1.start()
result = defaultlist()
yv2 = np.arange(0, 1.5, 0.1)
agency_id, agency_name, agency_url, agency_timezone, agency_lang, agency_phone
Y = np.sqrt(X)
idx = (a * mask).argmax(0)
current += relativedelta(months=1)
imgdata = StringIO.StringIO()
new_str += x.lower()
data = json.loads(response.data)
Response(serializer.data)
i <<= 1
setattr(self, section, Section(section, self.__parser))
out = []
AAB
values.append(value)
conn = SSH2()
i, j, k = list(range(1, 4))
set(d1.items()) - set(d2.items())
data = json.load(f)
a[inds] = np.take(col_mean, inds[1])
self.app = app
callable(elt.keys)
N = len(elements)
--chdir / home / myuser / projects / myproj
d_mva.shape
screenshot = pyscreenshot.grab(bbox=(10, 10, 500, 500))
digits = str(number)
t.add(5)
C = np.empty((K, d, d))
self.port = port
children = get_children(node)
True
newx, bad, newy = [], [], []
counter = db.IntegerProperty(required=True)
l1.sort()
register = template.Library()
c2.say_my_name()
self.vtkCells.InsertCellPoint(pointId)
result[key(item)].append(item)
x = B if x == A else A
not all(ord(c) < 128 for c in str)
[]
str(uuid.uuid1())
setInterval(sendEmail, 10 * 1000)
terms = tfv.getTerms()
default_number = self.page_number
counts_copy[x] -= 1
print(row)
double * wts
fig1.get_size_inches()
x = []
b = a
days = np.asarray(days) - 1
n_rings = 20
instance.validate()
splited_list[-1].append(element)
rf.fit(X, y)
chmod + x / etc / init.d / celeryd
dll.DllGetClassObject(clsid_class, iclassfactory, byref(com_classfactory))
[Yi, Xi] = np.meshgrid(np.linspace(0, 1, ni), np.linspace(0, 2, mi))
ACK = 16
[]
results = mycursor.fetchall()
X = X.flatten()
a = 1
num = locale.atof(num_str)
output.strip()
math.sin(t * w) / t + p
item
df = df.fillna(df2)
input, output = process.stdin, process.stdout
curline += 4
print(len(cols))
iterator = zip(*((iter(pil_image.getdata()),) * pil_image.width))
order = dict(zip(spam_list, spam_order))
DestroyWindow(self.hwnd)
tree = lxml.html.parse(page)
print(train_features)
self.a = a
selection = random.choice(filerecords)
1
out = []
Week.thisweek().week
concat_tups(x, y1)
p.registerAuthenticator(x)
H = np.dot(H, mat)
res = expr.parseString(test)[0]
theta = np.random.rand(n, 10)
document = match.group(1)
x + y
self._calculate_keys()
self
self._lib.TessBaseAPIGetUTF8Text(self._api)
mutex = Lock()
data = json.loads(response)
WRITE_OWNER = 524288
s2 = np.random.uniform(0, a, n)
result = list(str(result))
var_hist = get_user_vars()
json.dumps(members)
x = 1
print(result)
dict_time[key] += value
print(line)
plt.figure()
samples = np.zeros((N, 1))
page_content = page.extractText()
text_file.write(result.summary)
cluster2 = [j for i, j in zip(lda_corpus, documents) if i[1][1] > threshold]
opener = urllib.request.build_opener(passwords)
self.is_running = False
df
resource.Resource.__init__(self)
round(x * 4) / 4
xd = [float(row[0]) for row in data]
x = [(2 * i) for i in aRange]
oneBits = int(sys.argv[1])
xdata = np.linspace(1, 10 ** 8, 1000)
print(f(1))
a[n] = 10
level += 1
RATES = [44100, 48000, 192000]
resp
func2 = lambda t, y: func(y, t)
gcd(2 ** 9048, 2 ** 248212)
c = list(tweepy.Cursor(api.search, q=search, include_entities=True).items())
loop.run_until_complete(client())
login_page = request.path.find(login_url) == 0
instances = [c() for c in classes]
df = pd.concat([df for _ in range(1000)])
idx += 1
connect()
x = DirAsXML(os.path.join(path, d))
df
self.filter(width__gte=1200)
a = df.values
df, columns = argv[-1], argv[:-1]
q.put(map.readlines(numbytes))
result
input_y = np.random.randn(100, 2)
print(x + x)
file.flush()
ssA = (A_mA ** 2).sum(1)
permuted_entries = [entries[px] for px in perm[::-1]]
raise TypeError
True, x
thread1 = threading.Thread(target=func1, args=(gen1,))
plt.hist(c, **common_params)
what_bson_type(1)
dictpsl
myjobs.MyJob().run()
value = next(cont)
input
print(x[0])
funcs = []
keystone.tenants.list()
outs[-1].append(x)
count = [0] * 5
nlp = English()
self._tuple = x, y
driver = init_phantomjs_driver(service_args=service_args)
bdict = dict((1 << i, i + 1) for i in range(6))
wr = csv.writer(out)
tree.make()
q
numwords[word] = 1, idx
ch = sys.stdin.read(1)
lastMonth = first - datetime.timedelta(days=1)
fd = sys.stdin.fileno()
colb = [False, True, True, True, False, True, True, False, False, True] * 1000
filehandle.close()
True
window = myXwindow.Window(self.parent().winId())
logger.addHandler(logging.StreamHandler(sys.stdout))
c = list(compress(a, a))
a = b
_NOTFOUND = object()
pd.Series(result)
caller = inspect.currentframe().f_back
app = App()
self.loadImageFromSRC(source)
result = []
new_password = getpass.getpass(password_prompt, stream)
sys.stdin = f1
a == c
oldstderr = os.dup(sys.stderr.fileno())
l
print(x & y)
user = {}
localt.replace(tzinfo=tz).astimezone(UTC())
nan = np.nan
g = Git(repo_path)
reverse_linked_q.append((list(), d))
num_neurons = int(output.get_shape()[2])
r = Record(foo=1, bar=False)
print(a.listsquare)
ix = np.where(accountList == i)[0][0]
y_vals = np.amax(y_vals, axis=0)
False
key, value = i, f.lower()
b = Browser()
output_csv.write(col1)
KeyDown(Base[Combs[Key][0]])
pickle_str = pickle.dumps(obj)
self.insert(index, element)
v = np.array([1.0, 1.0, 1.0, np.nan, 1.0, 1.0, 1.0, 1.0, np.nan, 1.0])
module = modules[module_name]
map(dict_lowercase_content, tweets)
q.enqueue(send_report, depends_on=report_job)
self.file.read(outputfilename)
string = string[:match.start()] + char + string[match.end():]
parser = argparse.ArgumentParser()
getCode()
comment = forms.CharField()
s2.index = s2.index.droplevel(-1)
upper = bisect.bisect_left(dates, datetime.datetime(2007, 1, 6))
queue_manager = Manager()
count += 1
final_list.append(string)
t2 = time.mktime(t1)
b = []
im_data[i] = np.array(pixels[head:tail], dtype=np.uint8)
im = p.close()
2010 - 7 - 26
print(div_result_int(a=25, b=5))
print((s, y == dot(A, s)))
v = [0] * len(predicates)
text
i = initlen
python2
self.allowed_domains = [urlparse(i).hostname.strip() for i in data]
cli()
colours = numpy.zeros_like(z_surface, dtype=object)
bases = cls.mro()[1:]
self.read_bytes()
print(get_diagonal(m, 1, 4, 1))
form.agency.choices = get_agencies()
data, address = client.recvfrom(1024)
infile.seek(seekpoints[infilenum])
Point(-6, 0).slopeFromPoint(origin)
stack.push(event)
ones = match.group(0)
endIndex = index if index == len(str) else index + 1
my_list = []
(a + b + 1) / b
self.max_length = max_length
factors = list(primefac.primefac(n))
self.execute_python_code(line)
sets = iter(map(set, d))
values = list(align_values(iters, values, max_tm))
a[-100:1000]
s = set()
curs = conn.cursor(oursql.DictCursor)
importances = clf.feature_importances_
new_bar = bar.copy()
self.output = tf.nn.sigmoid(linarg)
r = random.uniform(0, 1)
num = ctypes.c_int(42)
l = [X(), X(), X()]
collect(zip(s, drop(s, 1)))
byte = bits[index:index + 8][::-1]
a = np.asanyarray(s)
lis = []
df = pd.read_csv(url, parse_dates=True, index_col=0)
print(EvaluatorCompiler().process(int_clause)(a_foo))
int(unix_time(dt) * 1000.0)
new
modelclass = ndb.Model._kind_map[self._kind]
style.bg[gtk.STATE_NORMAL] = color
main()
print(total)
fig, ax = plt.subplots()
day = min(sourcedate.day, calendar.monthrange(year, month)[1])
value
u = a.union(b)
request = HttpRequest()
dic[g] = defaultdict(dict)
fakeglobals = {}
n = max_idx - len(self.already_computed) + 1
img = ndimage.gaussian_filter(img, sigma=(5, 5, 0), order=0)
driver
0 in r
list2.remove(list2[0])
marker1 = plt.scatter([], [], s=a2.min())
_dict = {}
s[:-ord(s[len(s) - 1:])]
f = Foo()
xx = x[:, (np.newaxis)]
ssh_rsa += modulus
-1
unique_a
cascade = cv2.CascadeClassifier(cascade_fn)
pos = file.tell() - 1
g = g0 + (g1 - g0) * (x - x0) / (x1 - x0)
updated = Feed.objects(posts__uid=post.uid).update_one(set__posts__S=post)
slope, intercept = np.polyfit(x, y, 1)
z_sparse_evil = fun_evil(x_sparse, y_sparse)
result = re.search(your_stuff_here)
df
post_delete.connect(delete_mymodel1_count, sender=Mymodel1)
self.f = math.sqrt(self.a ** 2 - self.b ** 2)
key_count += 1
X, Y, Z, N = 1, 1, 1, 2
sums.update(data_dict)
walkDict(myDict, builder)
bin_edges = np.arange(A[0].min(), A[0].max() + 2, dtype=np.int)
predicted = classifier.predict(X_test)
print(datetime64Obj.astype(object).day)
three_letter_code = lang.terminology
mid = (lo + hi) // 2
minv = min(lastvalues.values())
d1[0] = 0
summary[entry[0]] = entry[1:]
p.swapaxes()
self._filename = filename
unqs = data[np.sort(ind)]
json_dict = {}
p = Process(target=begin, args=(child_queue,))
br = Browser()
modules = []
pairs = sorted(_get_pairs(t, cat), key=lambda x: x[0])
self.data = []
last = w
temp = datetime.date(2012, 8, 21)
tuple(pool[i] for i in indices)
newRow = []
res = conn.getresponse()
calc(0, 0, mat)
t2.start()
InvertedLogPolarTransform(self._axis, self._use_rmin)
new_wb = Workbook()
res[person].append(message)
queue_empty = queue_state.method.message_count == 0
print(res)
soup = BeautifulSoup(source)
numberofrows = intervaly if y + intervaly * 2 < ysize else ysize - y
e0 = models.Ellipse2D(amplitude=1.0, x_0=0.0, y_0=0.0, a=2, b=1, theta=0.0)
date2 = datetime.datetime.combine(date1, datetime.time())
i += 1
output_csv.write(col2)
primebytes.tofile(f)
[(ord(char) ^ key) for char in message]
raise
params.update(view_params)
axplot.plot(scipy.randn(100))
call(args)
f.x
fd.read()
Logger.redirect_stdouts_to_logger(MyLogger())
xmin, ymin, xmax, ymax = 0, 0, 10, 10
ax.grid(True)
self._getrow(idx)
current.append(arg)
2
key = l.pop(0)
mng = plt.get_current_fig_manager()
math.sqrt(a * a + b * b)
recall_ratio
handle_line(prev.popleft())
site = Site.objects.get_current()
y[y[:, (-1)] == 1] = 1
row_f = np.concatenate(row)
self.data = data
fig = plt.figure(figsize=(paperwidth - 2 * margin, paperheight - 2 * margin))
print(item.Dependent.Caption)
self.name = name
n = len(l1)
print(result)
BZ_OUT = Bz.copy()
B[1, inverse[A[1] == 1]] = A[2, A[1] == 1]
print(sHeader.PID)
myFiles.append(file)
date = models.DateField(default=datetime.now().date())
count += 1
p.contents
move(10, 1)
solution = lcm_seq(range(1, 21))
pl.pcolor(data)
b[name] = a[name]
sb.append(m.group(1))
index_dict = dict((value, idx) for idx, value in enumerate(a))
self.connecting = True
print(hashes[newhash])
sys.stdout = self._old_stdout
r = []
account.save()
thread.stop()
child_widths = [block_width(s) for s in child_strs]
t = []
Wire.write(relay_status)
y.shape = len(y) // chunk_size, chunk_size
szr = wx.BoxSizer(wxVERTICAL)
overlap = df.groupby(df.s1.eq(df.s2)).duration.sum()
{{list2[loop.index0]}}
print(df.mask(df.notnull().cummax(), df.fillna(0)))
a = np.arange(1, 6 + 1)
buf.value
pid = fork()
self.builder.add_from_file(self.glade_file)
host = mssql_server_ip_or_domain_name
dfs = []
eset = set(elements)
r = base64.decodestring(s)
result = lxml.html.parse(lxml.html.submit_form(form, open_http=myopen_http))
output[animal] = max(prev_high, high), min(prev_low, low)
split_at_idx(string.ascii_letters, [])
data.append(feature)
ax = fig.add_axes([margin, margin, 1 - 2 * margin, 1 - 2 * margin])
print(y.x)
test_case.assertEqual(expected, actual)
initlen = 2
r, w, e = select.select([f], [], [], 0)
dicpos[k] = len(dicpos)
False
xlen, ylen = lens[0] + 1, lens[1] + 1
UpdateWindow(self.hwnd)
im = np.asarray(im)
Y = np.array([0, 0, 1, 1, 1, 0])
df.loc[index_list] = df.loc[index_list]
sin_seg = sin(seg * factor) + sin(seg * factor1)
print(i)
listset = set(l)
print(multiplicity.sum())
tets = dt.points[dt.simplices]
drive_list.append(drname)
value = 0
leftfile1rightfile1
y = np.random.randn(10, 1)
env = RelEnvironment()
dis.dis(code.co_consts[2])
HDFStore.__init__(self, *args, **kwargs)
threads.append(t)
rowid = 0
vec_data_ang = np.abs(np.arctan2(dy, dx))
x_coords = new_array[:, (0)]
v.set_stringvalue(value)
print(html)
idx_sort = argsort(records_array)
image = my_img.eval()
cookies = {}
db = SQLAlchemy()
state = ser.readline()
peek = next(gen)
t_in_seconds
print(process(line))
mythread.start()
fnx = lambda : set(RND.sample(string.ascii_uppercase, 7))
exception_hook.enable()
-libatlas - base - dev
mask = (mask - np.diag(np.ones(8))).astype(np.bool)
classesinmodule(modulename)
design / index
scene.camera.location.x = tx
middle = len(lst) / 2
my_id_strs = map(str, my_ids)
self.stdout = sys.stdout
print(s)
time.time()
__n = al.c_ptrint_t(n)
vals = list(d.values())
scores = model_selection.cross_val_score(clf, Xd, y)
shape = tf.shape(tensor)
d[date][area, time] = value
nstones = stones[1:]
last_photos = copy.deepcopy(photos)[5:]
mean_k(s, 2)
item
seq.decode(keyDER)
original_y = self.y
a.itemsize
w = QtGui.QMainWindow()
dt = datetime(2011, 7, 2)
lst2 = [2, 1]
queryset = queryset(self)
new_dictionary = {}
httplib.HTTPResponse.read = patch_http_response_read(httplib.HTTPResponse.read)
sample1 = np.random.randn(10, 1)
what_bson_type(True)
sentinel = {}
help(pandas.ols)
zip(a, b)
p.WaitForExit()
seq = difflib.SequenceMatcher()
lineage.reverse()
self.__class__(lambda x: Function(other)(x) + Function(self)(x))
i * i + 2 * n
n += 1
self.reactor = reactr
fft_axes.plot(abs(fft))
print(df)
html = response.read()
arr
f.read()
instance = model_class.objects.get(**get_or_create_kwargs)
maxm = np.append(maxm, i)
dnaf = ndimage.gaussian_filter(dna, 16)
width = len(myArr[0])
mesh = numpy.indices(bins.shape)
self.debug = 1
cls
[default]
b_index += 1
print(result)
html_google = urlopen(req_google).read()
memdb.rpush(self.finished_prop, 1)
reverse_d = {}
root = Tkinter.Tk()
deleteself.data_ki[key]
modified_date = mongo.DateTimeField(default=datetime.datetime.now)
[testenv]
file.write(data)
df1
False
ret = main()
TldMatcher.loadTlds()
l1.append(elem)
sum(sum(space(val)) for val in unique)
obj[k] = self.recursiveDecode(obj[k])
counter[c] += 1
date.year + fraction
train_length -= train_size
shape = data.shape
print(item)
gradsp = tf.pack(grads)
year = int(sourcedate.year + month / 12)
print(yaml.dump(a, allow_unicode=True))
abcab
keys = list(kwargs.keys())
logger = logging.getLogger()
print(divide_equally(50))
http_server = tornado.httpserver.HTTPServer(application)
individual_dict = defaultdict(list)
counts = collections.defaultdict(int)
data = client.recv(8192)
artist = ax.bar(start_days, durations, bottom=start_times, **kwargs)
self.fd = inotify.init()
chunks.append(current_chunk)
cmp(self.s, other.s)
partitions.append(a[index:div])
True
self._q = dQ
self._what
res = service.cse().list(q=search_term, cx=cse_id, **kwargs).execute()
result = set_list[0]
ctypes.resize(a, ctypes.sizeof(a) + align - 1)
request.invoke_subrequest(subrequest)
data[name] = data.get(name, {})
pv(x)
print(lista[1:])
A != 0
df2 = df1 + 1
data = f.read()
n = np.asarray(n)
idx_max_dict = np.max(list(dict_with_tuples_key.keys()), axis=0)
sns.set()
print(row)
df = pd.DataFrame(dict(Close=data), index)
11890400
form = GradesForm(request.POST, **data)
intro = intro[2:]
doc = fromstring(html)
myArray[2:5, (4)] = -4.0
diff_day = timedelta.days + float(timedelta.seconds) / 86400
ymin, ymax = y.min(), y.max()
all_shape = list(np.shape(x))
data = f.read()
pyplot.imshow(np.flipud(Pxx_dB[:, n1:n2]), extent=ex2)
bitmap = CreateCompatibleBitmap(screen, width, height)
df1
foo = list(range(100000))
str(arg) % value
next = self.queue.dequeue()
slides = [list(slide) for slide in zip(*lists)]
print(uc_hex)
method_1()
app = QtGui.QApplication(sys.argv)
basepath = os.path.dirname(__file__)
data = dict(zip(header, columns))
reactor.listenTCP(8080, web)
client.load_system_host_keys()
title, url, price, title2, keyword = row
print(df.mask(df.notnull().cumsum() != 0, df.fillna(0)))
lon = -lon
binds.update(dict.fromkeys([Employee, Customer, Invoice], finance_engine))
mask = x[yindex] != y
temp_df_no_na.logged_dt = temp_df_no_na.logged_dt.str.split().str[0]
axes[1, 0].set_title(2)
cs.set_clim(50, 210)
text = cgi.escape(text)
src_copy = src_img.copy()
s
self.b = b
UnivariateSpline._from_tck((t, copt, k))
html_string = response.read()
tid = h5py.h5t.C_S1.copy()
logger.propagate = False
ActualTableObject
test()
l = [0]
utc = pytz.utc
selections = [(int(x) + 1) for x in selections]
b = a[:, (0)]
print(thebigrams)
True
process_cm(confusion_matrix, i, to_print=True)
axes[2].set_xlim(left=0, right=d2.shape[1])
sdict = {}
key.append(deref(it).first)
signals.m2m_changed.connect(my_m2m_signal, sender=Person.car.through)
d.quantize(Decimal(1)) if d == d.to_integral() else d.normalize()
self.p = pyaudio.PyAudio()
BEGIN
assert r * group_length == len(all_combinations)
token = oneOf(list(alphas.upper()))
h, w = arr.shape
GuiMixin_FunctionalityA.__init__(self)
info = lt.torrent_info(torrent, len(torrent))
f = Foo()
j = np.diff(np.sorted(a))
self._iterable[self.index]
gc.disable()
begin()
False
False
self.Refresh()
self._run = True
contexts[i] = context
gotBytes = ctypes.c_ulong(0)
t = Timer()
server = HTTPServer((ip, port), MyHandler)
email.send_keys(login)
sql.commit()
scaled_data = map(scaler, data_list)
f = StringIO.StringIO()
it = iter(data)
print(s)
print(color_list)
input(prompt)
plt.subplot(2, 1, 2)
pprint(my_dict)
allcount += max(count)
x, y, z = tuple(request.args)
self._paths.append([child])
foo()
x.values
a, b, c2
idx = []
translation = [[1, 0, 0], [0, 1, 0], [-tx, -ty, 1]]
max_elements = collections.defaultdict(tuple)
value = f[value]
print(e)
self.cookie = Cookie.SimpleCookie()
source_file_path = args.source_file.name
params = []
os.rmdir(targetLink)
result
it = iter(word)
self.extend(values)
self.children[type].add_node(node)
item
string.decode(enc, errors)
nzvals = a[nz[0], nz[1]]
start, stop = ss[(ss[:, (1)] - ss[:, (0)]).argmax()]
cls(table_name)
prune(x, y)
a = 4
fig, ax = plt.subplots()
timer(stateDSM, 1000)
filterfalse(pred, t1), list(filter(pred, t2))
rr = range(1, 4, 2)
a[2] = m
f.pack(side=LEFT)
temp_rdd.toDF(schema).printSchema()
results = (c_char_p * 4)(s)
connection = Connection()
IP_PMTUDISC_WANT = 1
self.window = window
new_D = {}
train_treebank_tagged_words = cfd(chain(*train_set))
L
t = np.linspace(0, 1, num=num)
print(comment.transformString(code))
v1, v2 = [getattr(obj, attr, _NOTFOUND) for obj in [self, other]]
data = self.request.recv(1024)
column_2 = [(now - last) for now, last in zip(column_1, [0.0] + column_1[:-1])]
vector < Point2f > center(contours.size())
HAS_NUMPY = False
[a, b, c] = [5, 10, -1.5]
print(index_of_last_nonzero(lst=a))
left = max - ((1 << j + 1) - 1)
mratings = np.ma.masked_array(ratings, mask=ratings == 0)
c = c + sum([len(word) for word in words])
largest = max(self.store.values())
AwesomeStatusBarApp().run()
schema_root = etree.XML(f.read())
compl_tree = {}
fig.show()
self.json_str = json.dumps(json_data)
list = zip(list1, list2)
split2(s, v)
file_rst.append(line.strip())
aux(x, y)
self.song1.setVolume(fadevalue)
self.song2.setVolume(fadefalue)
print(df)
start
y = y[index]
turtle.forward(25)
sub_compunds.append(sub)
self.evt.clear()
min_similarity = s.ratio() if s.ratio() > min_similarity else min_similarity
result = list(json_objects_from_file(f, chunk_size=_MB))
print(overlap(-5, 5, -2, 10))
f1 = Foo()
pal = img.getpalette()
dx = NP.ones(10)
area = models.ForeignKey(Area)
cs = np.zeros((nx + 1, nz))
new_page = {}
f.close()
numpy.lib._datasource.open = openm
form = SurveyInstanceForm(request.form)
x = np.random.rand(n)
im_data_lock = Lock()
self.assert_once()
register_adapter(Point, adapt_point)
char = chr(ordinal)
self.d[k]
self.fditer = self._fditer()
deleteself.data[key]
a &= b
()
handler.setFormatter(formatter)
print(x)
x = np.arange(0, 10, 1)
app = docx.appproperties()
print(eval(Choose_Item))
a = 2,
setCentralWidget(view)
obj
ui.write(e.EV_REL, e.REL_X, 10)
print(foo.to_string())
py > ast.body[1].value.args[0]
pool_result = pool.map(fill_array, list_start_vals)
self.year
print(lst)
init_op = tf.initialize_all_variables()
sum(map(get_inner, nested), [])
print(ind.shape)
ys = np.append(ys, curcen[1] + currad * np.sin(fis))
widget.can_add_related = False
wines_query = db.Query(Wine).ancestor(origin_key)
loopcount = int(somestring)
self.valid_subword = valid_subword
arr = numpy.array(list(range(10)))
d[offset:offset + len(text)] = list(text)
ctr = zip(*([iter(ctr)] * len(contour)))
[loggers]
y_min, y_max = X[:, (1)].min() - 0.1, X[:, (1)].max() + 0.1
x = (ctypes.c_ulong * 5)()
keys = list(x.keys())
print(name)
flags = os.O_WRONLY | os.O_CREAT | os.O_EXCL
pairs.sort(key=lambda p: p[0])
item.instance
sys.exit()
source / usr / local / bin / virtualenvwrapper.sh
res = cmat1 * cmat2
deletelst[i]
isstatement = False
l = sorted((random.random() * x[0], x[1]) for x in l)
cdf = np.cumsum(prob_matrix.T, axis=1)
ftpc.abort()
a[8, 8] = fill_value
PyObject_HEAD
nan in [nan]
self._replacement_map[key] = o.get_jstext()
self.grid()
main(sys.argv[1:])
n = 2
print(letter, repetitions)
writer = csv.writer(f, quoting=csv.QUOTE_NONNUMERIC)
p = s.index(delim, p + 1)
print(url)
stack.append(n)
found = False
y = x.flat.copy()
x = models.Field()
ignores = frozenset(ignores)
sample_dictionary[words].append(word)
_diff = end_date - start_date
DD514C
self.output_cookie = Cookie.SimpleCookie()
print(Int, type(Int), obj, type(obj))
curr_id = lst[0][0]
math.floor(x)
belly_id = models.AutoField(primary_key=True)
decimal.Decimal(value)
self.arr
ret = a.y < b.y
gb.apply(a1)
-1
x, y
l = []
exit()
Ol[j] = Ol[l]
memo[x] = f(x)
output[key] = to_dict(value)
a = map(chr, list(range(65, 70)))
temp.append(5)
max_item
H = nmf_model.components_
df_cross
POST / session / id / phantom / execute
isinstance(other, Symbol) and other.value == self.value
result = result[:sigfig]
data.ages[bool_indices]
cb.update_ticks()
path = os.path.dirname(_file)
scale_height = screen_res[1] / img.shape[0]
a
col_f = np.concatenate(col)
value = a / b
A.toarray()
self.statusitem.setImage_(self.icon)
self.lefttoright = False
A = logm(M) * x
letters += 1
A.func1
sess.run(init)
_connection
stream.flush()
deleteself._flg[key]
list = list + format_tb(tb, limit)
difference = int(later - now)
min_key = {value: key for key, value in list(sentiment_dict.items())}[min_value]
x = 0
log.startLogging(sys.stdout)
pandas.DataFrame(data, teams_list, teams_list)
to_json(self, self.__class__)
n_int = int(n_str)
sys.maxsize
cvtColor(img, gray, COLOR_BGR2GRAY)
inNumberint = int(inNumber)
mySocket = socket(AF_INET, SOCK_DGRAM)
M = np.matrix(np.eye(5, dtype=bool))
y.strides = y.strides[::-1]
MyParametrizedSpider(name, start_urls, extra_domain_names, regexes)
type(Foo)
x[:5]
print(a.__code__.co_filename)
is_found
start = time.time()
path.setElementPositionAt(index, pos.x(), pos.y())
print(item)
host = sys.argv[2]
fname = os.path.join(r, fname)
l = list(random.randint(0, 10) for _ in range(10))
inargs = parser.parse_args()
func1()
button = wx.Button(parent, -1, name)
s = ssl.wrap_socket(sock, certfile=sys.argv[1])
v_axis[i][0] = v_axis[j][0]
g_line = next(f)
s = list(iterable)
f_ab = f(a[:, (np.newaxis)], b)
c.save()
lap_blur = cv2.bilateralFilter(dilate_lap, 5, 9, 9)
freqs_label = list(line(samples, min_freq / Hz, max_freq / Hz, finish=True))
ax.set_ylim(0, 10000)
ipdb > exp_diag[k].shape
self.now += delay
4 - 0.958774
kernel = [1, 0, -1]
x1sort = np.sort(x1)
d[nan1]
os.remove(oldfile)
fields_keys = set(self.fields.keys())
conn = redis.from_url(redis_url)
self.setGeometry(self.geometry() - hack)
type(df.values)
merger.merge(position=0, fileobj=path2)
run_wsgi_app(application)
keys = set(list(a.keys()) + list(b.keys()))
L = lambda x: x + 1
rectangle = rect(x, y, width, height)
print(each_key)
raise ndb.Return(bed_info)
ser2 = pd.Series(y2, index=new_t2)
get_new_candles2(clock_tick, previous_tick)
f.write(img)
plugin_path = os.path.join(plugin_dir, plugin)
second_sample = s[-10:]
print(stdout_output, type(proc))
d.callback(7)
tmp2.append(X[i, j])
data = json.dumps(payload)
imgstr = StringIO()
widget.init(data_from_django)
data = np.random.random((10, 10))
minutes, milliseconds = divmod(miliseconds, 60000)
print(np.max(np.abs(iv_u - predict_ci_upp)))
seq.reverse()
view_fn
Domenesider.append(side)
output = StringIO.StringIO()
bar._state = Mock()
Category, Year = [], []
final_subnets.append(s)
print(s)
GetWindowText(hwnd, buff, length + 1)
i = 2
[run]
outfp = StringIO()
__metaclass__ = Meta
w = PEEK(i)
client = Client(svc_url, doctor=doctor, transport=MyTransport())
print(foo.__annotations__)
print(row_number)
self._run = False
text = fpin.read()
whatever()
m[lenM:] |= k[:-lenM]
utcmorning = timestring[182:187]
aaf
data1 == data
index = 0
data = np.array(im)
reader.setContentHandler(handler)
g[:, :, (0)] * x + g[:, :, (1)] * y
ivalue = int(value)
X = data.data[:100, 0:1]
count = 1, 0, 0, 2, 0
output.append(line)
UW_duration = np.busday_count(MDD_end, NOW)
first = next(i)
oldtrace = [frame.f_trace]
writer = csv.writer(f)
timeit(lambda : list(emptydict.keys()))
handler(**kwargs)
df[6] = df[0]
diff[:-1] = positions[1:] != positions[:-1]
x = arr[4:10, 9:15, ::-1]
response = browser.submit()
do_something_with(attempt.challenge)
startLogging(stdout)
number_of_dups = 1000
id = sa.Column(sa.Integer, primary_key=True)
corruption_failure()
1, [deep_annotate(i) for i in item]
1 - inv
new_list = list(range(101, 6284))
GBP
USD
p1 = Polygon(ring.coords)
np.mod(x, 1, out=x)
attribute = getattr(obj, name)
tables.append(list(range(x, x + N)))
mx = ma.masked_array(data, mask)
os.path.exists(arg)
a[b]
query = self.search_entry.get_buffer().get_text()
_DECODER = json.JSONDecoder()
workbook.close()
legend_markers = [marker1, marker2]
res = resubmit(batch, res)
compressor = zlib.compressobj()
seq[:pos], seq[pos:]
res = sps.hstack(mats)
base_method = getattr(BaseClass, method)
frames += 1
sf2 = f2[L4:-L4]
scaled = float(d * math.pow(1000, -degree))
loaded_mm.seek(0)
print(i)
p + coord_polar()
mask = values.isin(counts[counts > 1].index)
form = re.sub(expre, lambda x: subexpr(x.group(0)), form)
print(reverse(array))
a = 1
inNumberfloat = float(inNumber)
metadata = MetaData(bind=some_engine)
period += 1
py > ast.body[1].value
self.n / 10 ** i % 10
current = datetime.datetime(mydate.year, mydate.month, 1)
print(order.customer)
len(m[i])
Nrows = max([len(Quota), len(Weight), len(price)])
parser = OptionParser()
df
print(counter)
exponent = int(math.log10(number))
cv.SetData(foo_cv, foo_np_view.tostring(), w * d * foo_np_view.dtype.itemsize)
old_sys_exit(value)
d.P_VALUE.sort()
self.data = data
self.val = init_val
print(li.tolist())
b = bytes()
mat = np.eye(dim)
doc = etree.fromstring(svg)
score = 10
fit_residual = np.sqrt(np.sum(err ** 2))
n = 0
seen = set()
os.chdir(old_dir)
callPython()
ob.serialize()
executable = stat.S_IEXEC | stat.S_IXGRP | stat.S_IXOTH
clf = YourClassifiers()
[sum(x in y for y in list1) for x in list2]
array_str(M)
path = tf.train.get_checkpoint_state(checkpoint_dir)
print(l)
vectorized_sparse
JSONEncoder.default = _default
dd = today - timedelta(days=90)
reactor.run(installSignalHandlers=0)
counts = {}
len_value = len(value)
ret.append(close[start:end])
output_list = []
FGHIJKLMNOP
y = np.random.randint(100, size=x.shape)
msvcrt.setmode(sys.stdout.fileno(), os.O_BINARY)
a = np.array(list(range(size)))
DATABASE_COFLICT_ERRORS = []
distance = euclidean(X_cluster_0[0], km.cluster_centers_[0])
daemon.stop()
M[:10, :10].mean()
ax.plot(data.index, data.A)
assert_almost_equal(a, b)
g.checkout(version_tag)
pool.map(fbstatus, list(range(1000)))
last_frame = inspect.stack()[1]
arr1_weights = arr2[::-1].cumsum()[::-1] - arr2
my_sum += pow(fabs(expect_r[i] - val), 2)
h, w = arr.shape
lastplus = q.get()
i = j + 1
dx = x[1:] - x[:-1]
gzip_fname = os.path.basename(gzip_path)
frequency_list = [(freq, letter) for letter, freq in frequencies.items()]
y = bins[1:]
redis_instance = redis.Redis()
print(type(opts.some_option), opts.some_option)
self.wfile.write(self.t1.show())
print(c)
figure = Figure()
print(copy_foo)
desired = np.empty((10, 20))
a_copy = a.copy()
curr = old_d[sort_key][i]
s
print(line[7])
mydictionary[Col2].append(row[1])
dealloc_callback * dealloc_cb_p,
date
x1, y1 = polygon[0]
encoded_data = urllib.parse.urlencode(data)
values = sum(weights * features + bias)
print(a)
self.without_case = [s.lower() for s in self.with_case]
ss.kstest(A, ss.randint.cdf, args=(0, 10))
[foo.test]
d = list(range(10))
result = 255 - (im_norm * 255).astype(numpy.uint8)
dis.dis(test)
0
n = next(nums)
print(degrees, minutes, seconds)
doc = lh.fromstring(html)
since = datetime(1970, 8, 15, 6, 0, 0)
ixlo = set(sample(lo, M - len(ixhi)))
frame = np.asarray(cam.grab_next_frame_blocking())
lists
n, bins, rectangles = ax.hist(x, 50, normed=True)
length = len(sorted(x, key=len, reverse=True)[0])
{{(iterable2 | index): forloop.counter0}}
url_adapter = appctx.url_adapter
[stream.popleft() for i in range(n)]
b = np.random.randint(len(a), size=size)
x = NewList([0, 1])
d[key] = val
z1 = mlab.bivariate_normal(0, 1 * sigma, sigma, sigma, 0.0, 0.0)
x = np.random.rand(M, L)
self._conn = create_engine(src)
ipython - -classic
group_size = len(names) / num_pages
graph(my_formula, list(range(-10, 11)))
X = pygame.sprite.spritecollide(fly, current_level.object_list, False)
bytearray(reversed(b))
resp.content
y = x[arr]
x = list(range(10))
v = cPickle.load(f)
queryset = User.objects.all()
B()
authenticated, headers = who_api.login(creds)
trell = []
lvls = np.logspace(0, 4, 20)
stiff = stiff.subs({(2 * nuxz ** 2): 1 - nuxy - m})
obj = StringIO(str(obj))
aiinv[ai] = np.arange(a.size)
[future] = c.scatter([x], broadcast=True)
FAILED(errors=1)
wordlist.append(word)
logChannel = logging.StreamHandler()
data.shape[0],
value2 = locale.atof(value_s[1:])
print(data.shape, data)
odd_numbers = [y for x, y in enumerate(items) if x % 2 != 0]
print(col_values)
stream.stop_stream()
TypeStringID(tid)
circle = plt.Circle((x0, y0), r)
image.write2file(name)
g = nx.dodecahedral_graph()
print(triples)
L2 = [(0) for i in range(len(L1) - len(L2))] + L2
A = A_embedded[:, 2:-2]
rest = my_sum - i
im_color = cv2.applyColorMap(img, cv2.COLORMAP_HSV)
deleteglobals()[reduce.__name__]
a = a ^ b
list_obj_array = np.ndarray((1,), dtype=object)
upx = True,
func
data = pd.read_csv(filename)
np.random.RandomState().seed(42)
print(x)
a = np.ones((inputs.shape[0], inputs.shape[1] + 1))
ind = np.argsort(data)
xs = set(data)
application = Flask(__name__)
r = sum((Counter({frozenset(k): v}) for k, v in list(d.items())), Counter())
subquery = session.query(table_c.id)
orig_dict[key] = orig_dict.get(key, []) + val
li = list(range(1, 15))
PyNumber_ToBase(v, 2)
A() is A()
data = file.read()
y = np.bincount(x)
sess = tf.InteractiveSession()
done = False
print(child.before)
tdm.add_doc(doc2)
i
f, path, info = imp.find_module(name, path)
source_vec = NP.random.rand(10)
ping_data = retval.strip()
cmd = lambda value, func=self.test: func(value)
print(processed_numbers)
venues = profile.venue_set.all()
print_as_octave_native_bit_hex(x)
solution = []
dateTime = models.IntegerField(db_index=True)
total += i
hereary, herearx = herear.shape[:2]
bigary, bigarx = bigar.shape[:2]
pip - -version
ranges = []
self.rwlock.acquire_write()
1
ssl._create_verified_https_context = _create_verified_https_context
self.properties = {}
length = float(len(text))
degree(eq1, d)
d = dictlist.Dictlist()
[]
vertexAttribute.extend(list(mesh.data.vertices[vertex].normal))
method = getattr(itertools, name)
c = Counter()
best_idx = np.argmin(areas)
print(dis.dis(f))
html = BeautifulSoup(sample)
query.update(params)
c[:, 1::2] = b
sys.maxsize
print(myproject.__version__)
B[key][key2] += value
od = OrderedDict()
result = []
2, 2, 4, 4
form_overrides = dict(text=forms.CustomTextAreaField)
ncols = df.values.shape[1]
self.match = self.ok(l)
t = np.linspace(1e-15, 1e-10, 1000000)
self.betasPValue = 1 - t.cdf(abs(self.betasTStat), df)
resultify(inputList, flatResults)
client = suds.client.Client(wsdl_file)
arr = line.split()
xi = np.arange(0, len(grid[(0), :]), 1)
id = serializers.ReadOnlyField()
types.FunctionType
records
foo_np_view.copy().strides[0] == w * d * foo_np_view.dtype.itemsize
[-1, -1, -1, 1, -1]
last_name = TextField()
args = [iter(iterable)] * n
unit_ray = normalize(ray_point)
wsqrmean - wmean * wmean
colNames = str(desc[0])
img[groupCoords[:, (0)], groupCoords[:, (1)]] = 1
self.floater = FloatingWindow(self)
user = facebook.get_user_from_cookie(self.request.cookies, key, secret)
x = df[pd.isnull(df[col])].index.astype(float).values
data = web.data()
groups = df1.groupby(level=df1.index.names)
last_found = li.index(ch, last_found + 1)
b[i] = b[i - 1] + 1
prob_pos = (prob_pos - prob_pos.min()) / (prob_pos.max() - prob_pos.min())
len(list([x for x in t if x <= 2]))
t = np.linspace(0.0, np.pi, nt)
newFunc
neighbours = faces[1]
shortname, ext = os.path.splitext(plugin)
item = self.tree.selection()[0]
start = datetime(2012, 1, 1)
readdir.restype = c_dirent_p
meth = getattr(obj, key)
new_str
ax2 = ax.twinx()
next(i)
print(result)
recursivedict = lambda : defaultdict(recursivedict)
data = (datatype(row[column]) for row in incsv)
value = v.stringvalue()
db_connection = engine.connect()
actor = next(actor for actor in self.actors if actor.name == actorName)
raise KeyError
count_inside[..., (k)] += k == labels_img[2:, 1:-1]
df.Period = df.Period.bfill()
print(entry.d_name)
seenstrings = set()
shell_table = Table(data, colWidths=[t1_w, t2_w])
object_list = pool[:100]
sio.write(c)
frontier.append((neighbor, repeat_count))
y += t * Ly[k]
self.sessionmaker = scoped_session(sessionmaker(bind=self.engine))
sum(nums) / float(len(nums)) if nums else default
ctypes.POINTER(Vertex),
self.magnetic_permeability = 1.0
repo.__class__ = myrepo
format(-0.0)
validGrades[np.argmin((grade - validGrades) ** 2)]
cls(**dct)
customer = stripe.Customer.retrieve(cuid)
window = window.query_tree().parent
wrapped
X[(a), :][:, (b)]
self._buff = int(lines[2].split()[1])
saver = tf.train.Saver([W, b])
s.send(args.text)
print(shootnum)
max_depth = max(max_depth, depth)
root = ast.parse(source)
secondVal = MyTuple[1]
hash(self.lower())
print(result)
data = self.body
root = tk.Tk()
lidx = np.ravel_multi_index(a.T, a.max(0) + 1)
upper = len(array)
cities = []
cut_f_signal = f_signal.copy()
found = []
MyDF
x2 = np.linspace(0, 10, 200)
test_list
yaml.add_representer(quoted, quoted_presenter)
modules = []
i = len(self.data) - 1
array[j], array[i] = array[i], array[j]
py_mod = imp.load_compiled(mod_name, filepath)
Location1 = motion_plan(alternator(0, 1), increasor(0, 1))
queryset = self.queryset
lines = file.readlines()
l[i + 1] = key
custom_thing()
out_list.append(result)
print(result)
response = conn.getresponse()
res = result.get(block=True)
inner.click()
ucontent.find(x)
model = PCAmllib(2).fit(rdd)
self.received_buffer = StringIO.StringIO()
changedir = tests
str(table)
self.exhausted = False
L = deque(list(range(100)))
l = []
node.update(**data)
parsed = json.load(page)
apns_string = json.dumps(apns_dict, ensure_ascii=False)
format_float(buf, 100, v, PREC_STR)
framerate = int(frate)
[cython]
False
sorteddata = {}
list(islice(tuesdays_of_february), 5)
y + x
l, z = tee(z)
self.a = a
associations[-1][1]
t = threading.Thread(target=worker)
d = list(range(l))
print(polygon(5))
b = webdriver.Firefox()
config = WED.WikEdDiffConfig()
imshow(x)
main()
print(list(e))
data[:, (1000)] += data[:, (2000)]
newl.append(i)
text_out = FMT_SAY_TEXT % text_escaped
self
s = list(iterable)
S = {(i + x) for i in L for x in range(-5, 6)}
deletetime[d]
self.nodes = {}
data_file.seek(last_pound_pos)
expr_topl_text = originalTextFor(expr_topl)
nodes.append(Node(body, indent))
key = f.read()
corpus = [dictionary.doc2bow(text) for text in texts]
a == b
seconds = int(value)
output_image
print(i, base_decode(base_encode(i)), base_encode(i))
tail
wrapper
Gtk.Button
newmoves = {}
match = matches[0]
hexlify(os.urandom(16))
print(line)
ret_val[mask] = np.repeat(arr.ravel(), rep.ravel())
grammar = PCFG.fromstring(wsjp)
TWOPLACES = Decimal(10) ** -2
type(pix_array)
signals.py
tmp = 0
z = np.zeros(list(a.shape) + [4])
sorted(list(counter.items()), **kw)
pystr = PyObject_Str(pyth_val)
u = urlparse.urlparse(url)
condition = tf.not_equal(a, target)
gpx = gpxpy.parse(gpx_file)
y = np.concatenate([y1, y2])
out.write(valid_xmlstring)
bom
self._map_to_uniform_grid(X)
arr
l2_copy = list(l2)
ext = splitext(path)[1].lower()
raise KeyError(key, _val)
x = np.random.randn(50, 25)
sigma = np.array([0.025, 0.025])
ms = data.mean(axis=1)
assert idx >= 2 and idx % 2 != 0
readLoc = f.tell()
indexgroup[i] = k
ptr = ctypes.cast(addr, INTP)
o = BillingSystem.query.get(1)
sleep(0.1)
572
partial_duplicate_destroyer(mydict, 20)
v = np.arange(rows_v * cols).reshape(rows_v, cols)
sentinel = object()
bar = traits.api.Range(low=1, high=10)
a + b + self._value
final_result.add(final_str)
id, nm, lat, lon, countryCode = txt.split()
nextmonthdate = x.replace(month=x.month + 1)
assert ret0
new_array[:, (0)] = uinqPos
I = np.matrix(np.eye(F.shape[0]))
print(dom.toxml())
params = lasagne.layers.get_all_params(l1)
df
counts = np.asarray(counts)
print(test2_eastern.astimezone(utc))
sent_pos_tags = [pos for token, pos in pos_tag(sent_tokens)]
results[func] = pool.apply_async(func)
data = np.arange(25).reshape((5, 5))
b.append(dict(id=id, desc=desc if len(desc) > 1 else desc[0]))
sys.stdout = fd
i = bisect.bisect(self.store, (key, self.empty))
print(self.__dict__)
a = b
self.exit.set()
__metaclass__ = abc.ABCMeta
print(np.max(np.abs(re.fittedvalues - fittedvalues)))
shutil.rmtree(build_temp)
tasks.append(p)
d -= 1
axes[0, 0].set_title(0)
y -= y.min()
p = chr(ord(max(s)) + 1)
[-1, -1, 1, -1, -1]
logger = logging.getLogger()
lists = []
ymax = max([t.get_window_extent().ymax for t in textobjs])
map(lambda x: WHATEVER(x), key)
modals = srt[tuple(index)].reshape(location.shape)
step(0)
i = 0
ans[c] = abs(r[i] - r[j])
print(out)
ord(char) - 64
info.ui.dispose()
pixdata = img.load()
[line1] = plt.plot(list(range(10)))
reversedEnumerate(list(range(10)))
result = etree.tostring(fromstring_element, xml_declaration=True)
self.param = param
csrf_protect(CustomLoginView.as_view())(request)
p = mp.Process(target=display)
myA
[self[ii] for ii in range(*key.indices(m + 1))]
img = img.resize((width, height), I.ANTIALIAS)
a[i], a[j] = a[j], a[i]
cache = {}
fig = pylab.figure()
allfound = sorted(map(itemgetter(1), auto.iter(astr)))
pdraw = ImageDraw.Draw(poly)
result
C_s[A_s.nonzero()] = A_s[A_s.nonzero()]
cloud.mp.join(cloud.mp.map(process_all, pathfile))
dat.corr().applymap(Pearson)
datetime.datetime = datetime
meta = mutagen.File(filePath, easy=True)
root.append(new_entry)
self[key]
a == b == c == d == e
a, b, c, [d, [e, f]] = v
keycount = 0
result
outfile.write(output)
print(file)
print(train_likes_df.head())
x * y
print(row)
print(func2.__code__.co_varnames)
x.append(5)
p2 = Rectangle((0, 0), 1, 1, fc=pl2.get_color())
args = sys.argv[1:]
G.add_edges_from(to_edges(part))
self._fip = fip
asset = Asset.objects.get(id=self.id)
has_header = csv.Sniffer().has_header(inf.read(1024))
d2d = Delaunay(p2d)
x = 2
string
getRelativeTime(x)
result = subprocess.check_output(cm)
data = b64decode(list(request.form.keys())[0])
d = defaultdict(list)
sum = arrlist[0].copy()
f = chr(f)
map_level(double, data, 1)
time.sleep(0.5)
a = []
mf = matplotlib.ticker.FuncFormatter(tmp_f)
f = lambda x: x * x
autocorr_plot1, ax1 = plt.subplots(figsize=(6, 5))
outq.put(sentinel)
X = np.linspace(xmin, xmax, N)
parser = test2.get_parser()
myTurtle.down()
headers = {}
json.last_error_position = json.decoder.linecol(doc, pos)
size = f.tell()
key
regex.findall(OUTPUT)
out.index = df.index[N - 1::nn]
iterations = list(range(2, len(t) / 2 + 1))
self.sock = sock
L.sort(key=make_lazy(memo(f1), memo(g)))
task1.join()
n.show()
e.value
print(name)
r.add((e, v))
os.strerror(errno.ENOENT)
raise TimeoutError(self.error_message)
print(final)
print(sheet)
self.dialog.installEventFilter(self)
dir(x)
A = list(range(10))
self.context.__exit__(*args)
document = db.test_collection.find_one()
Run > Configure
all_pixels = []
result = dfs[0]
session = Session()
200
maxCols = ubound(pyvalue(0))
opts = docopt(__doc__)
print(df)
register = template.Library()
list(DynamicEnum)
app.MainLoop()
type(treebank.tagged_words())
file_menu = Menu(menu_bar, tearoff=False)
event_count = IntegerProperty()
p = argparse.ArgumentParser()
d2 = dict(i)
theta_i = np.linspace(theta.min(), theta.max(), ny)
Y = X.repeat(4096, 2)
d[x] = y
reactor.listenTCP(5050, server.Site(root))
d[name] += num
assert count == count2
s = a.strides[0]
s = s[s != 1]
Count_Row = df.shape[0]
log_file = self._find_logger_basefilename(parent)
grp.Remove(usr)
print(df)
self.end_headers()
target = sys.argv[1]
os.makedirs(dest_dir)
2
C = 1.0 / (2 * pi)
event.set()
tokens = text.split()
y = np.random.random(num) - 0.5
shifts_arr[np.arange(m - 1, 1, -1).cumsum()] = 1
c.appendleft(i)
i = 0
help(send)
mymodels.py
result = prog.match(mystr)
x.append(1.1)
self._dict = set(self.__dict__.items())
c1.close()
response = make_response(image_binary)
User.__unicode__ = user_new_unicode
count
i = iter(l)
tree = et.fromstring(xmltext)
user_func(args)
i = 0
a = np.array([list(range(11, 21)), list(range(11, 21))]).reshape(20)
li.append(chr(n))
tail = itertools.chain([i], it)
p = 20 * np.log10(np.abs(np.fft.rfft(x)))
text
rolling_window(a, 5)
memcache.add(cooldown_key, True, 1800)
self[1] = 10
t = numpy.linspace(0, 4 * numpy.pi, 20)
UTF - 8
xx, yy = np.mgrid[:height, :width]
frontier.append((start, start.num_repeats))
xdata = [(log2(x) * (10 / log2(10))) for x in range(1, 11)]
[]
total += item
print(1.0 / 2)
zip_cities.update({idx: [zipcode, city, state]})
assert s >= t[0]
0
canned_example()
width, height = d.shape
1
input.remove(s)
center_y = (y1 + y2) / 2
post_one_update.delay(post.id)
regex = re.compile(chunk_type)
x0, y0 = 200, 200
sys.modules[self._subModules[attrname]]
idx = pd.IndexSlice
free(self.handle)
t = np.random.rand(N, L).T
pad.append((0, 0))
print(s.aggregations.by_house.doc_count)
local_tz = get_localzone()
print(a)
b_start, b_stop, b_step = b.indices(a_length)
a[0, 0] = 1
uniques = np.delete(np.unique(M), 0)
x_sorted
type(a)
print(f.closed)
split = (line.split() for line in lines)
unborn = sorted(population, key=lambda x: -x[0])
CustomModel
found = re.findall(regex, text[s:])
a.sort()
cell = tf.nn.rnn_cell.LSTMCell(state_size, state_is_tuple=True)
row[:] = np.r_[row[row == 0], row[row != 0]]
item
measure.update_idletasks()
self.scene = QtGui.QGraphicsScene()
header, rows = zip(*filtered)
games_list = list(itertools.product(*permuted_entries))
folders.append(folder)
b, g, r = cv2.split(img)
c.send(oscmsg)
ctx.show_text(string)
[]
pp.show()
print(bigclass.__bases__)
decorator_apply(origtask, func)
sapi = tweepy.streaming.Stream(auth, CustomStreamListener())
signal = np.cos(thetas)
b = randint(0, len(a) - 1)
x = 0
inprof = lcms.cmsCreateLab4Profile(0)
cmp(normalize(version1), normalize(version2))
st = test[0][0]
test_suite = unittest.TestSuite()
loop.close()
h.itemset(i, j, 0, 0)
y = exp(x / 2.0)
c = C()
value
k_exog = res.k_exog
f.place(x=x, y=y)
reader.fieldnames
app = Celery()
all(x in allowed_set for x in s)
v2, col2 = d2[0], d2[1]
f.write(credentials.to_json())
df
array = numpy.zeros((querysize, querysize, tilebands), numpy.uint8)
print(subimg(small, big))
test.flush()
content = page.read()
action = models.CharField(max_length=64)
id(a)
new_x, new_y = zip(*L)
y += (y2 - y) * 0.1
segments = np.concatenate([points[:-1], points[1:]], axis=1)
d2 = {x[0:2]: x for x in lst2}
fmt_values = [formatter(x) for x in self.values]
arr[l:u]
process_my_captcha()
bv.write(myarr.tostring(), 0)
print(x - 10)
cities.remove(cities[0])
mail = email.message_from_string(email_body)
getCamera.main(arg1, arg2)
cnt = np.cumsum(lo_or_hi)
{0}
update.save()
new_img = Image.blend(background, overlay, 0.5)
activity.approved = true
a = np.indices(max_range + 1)
dbCursor = conn.cursor()
pygame.mixer.pre_init(44100, -16, 2, 2048)
262152
self._fsb_controllers = []
df = concat(list_of_dfs)
d[k] = v
f1 = partial(f, 12.0)
func(a)
d[1]
print(c() or a())
desired_size, index
Ver2(folder)
self.file.write(data)
mySquare.draw(win)
fig = plt.figure(frameon=False)
pool = multiprocessing.Pool()
p2 = argparse.ArgumentParser()
d1 = 0.5 * (p2.x - p0.x)
print(a)
print(mp.pi)
songs.append(song)
r.append(b[0])
halt_thread = threading.Timer(duration, self.halt_event.set)
{{form1.as_p}}
np.array([A2[(0), :-1], A2[(1), 1:], A2[(2), :-1]])
out[idx] = A
min_diff = min(abs(v - target) for v in list(d.values()))
iequal(2, 2)
result
getRelativeTime(x, accuracy=2)
x = 1 / u * np.cos(phi)
n = len(df.columns)
self.__parser.write(f)
df
szr.Add(self.button_1, 0, wx.TOP, vgap)
nextword = iter(words)
bs = BeautifulSoup(t)
True
d = float_to_decimal(float(number))
product = np.dot(M, F)
mat.A
new_strs = []
start - stop - daemon - -start
1
elem = input[0][0]
f
bytes(x)
y[window_len:-window_len + 1]
sort_by_score(identity_scoring, foo)
frame = DataFrame()
dis.dis(foo)
cows.append(line)
deletekwargs2[key]
x = np.arange(10)
app = wx.App(False)
res1 = landed(input)
idxs = np.random.randint(50000 - 1, size=1000)
X = np.random.rand(1, 100)
application = tornado.web.Application(handlers, **settings)
ignoreList.append(name)
x = 1
False
sendSock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL, 24)
l1 = list(range(10))
application = webapp.WSGIApplication(url_mapping, debug=True)
mean = np.load(mean_file)
d.as_tuple().exponent
op(x, threshold)
p1m0[k] = -p0m1[k]
smaller_list = list(range(2500))
frames = []
pattern = pattern.replace(os.altsep, os.sep)
m.shape
matrix = np.random.random((100, 100)) * 100
cipher = PKCS1_OAP.new(key)
area_1 = area_1.union(create_tube(2, h))
xml.dom.ext.PrettyPrint(doc)
df1 = df1[~df1.dropData]
client, clientAddress = self.server.accept()
lines = []
counter = [len(args) - 1]
root.right = Tree()
main()
parser.feed(content[:idx])
setups = []
print(1, time.time())
unpickled = pickle.loads(pickled)
answer = round(n)
DOT11_AUTH_ALGO_WPA_PSK = 4
j = r.json()
line
i2 = draw_text_with_halo(i, (20, 20), txt, font, text_col, halo_col)
date_of_birth = datetime.date(1990, 1, 1)
iter(((),))
lookup[n]
f = c.makefile()
not A or not (B and C)
d[key] = preserve_path(list(flatten_group(value)))
url = list(url)
deleteself.__class__.matcher
print(len(a), sys.getsizeof(a))
new_len
array
SMinY = 0
_r.history.append(r)
count = 0
new_sequences.add((v, 1))
col_width = [max(len(x) for x in col) for col in zip(*table)]
na = np.setdiff1d(np.arange(len(df_a)), ia)
Bar()
n = len(sys.argv)
1, 2
Model.query
print(event.Ascii)
smoothed = signal.convolve2d(B, kernel)
False
the_class_
print(sys.prefix)
arr_1.sort()
t = t * ((X - Lx[j]) / (Lx[k] - Lx[j]))
type(a).__module__
ROCK = 1
cur.execute(sql)
result = self.buf.read(size)
X = 1
http_server = httpserver.HTTPServer(application1)
d
retval = prof.runcall(func, *args, **kwargs)
d = {}
True
__str__ = silently
value
print(cookie)
notifier = pyinotify.Notifier(wm)
generate_numbers()
xmlstr = tree.tostring(xml_content, pretty_print=True)
s[::-1].upper()
schema.deserialize(valid_data)
prime = True
done = True
map(int, [_f for _f in columns if _f])
result += 1
print()
proxy_url = QUrl(proxy)
datalist.append(chunk)
sides.sort()
lm.save(strict=True)
[1.0, 1.0],
array2 = [nan, nan, 2, 1, 1, nan, nan, nan, nan, 0.101, nan, 0.16]
cos_norm_impl(a, b)
self.__foo.x
str.rindex(str[-1]) + 1
event.widget.tag_click = True
reportlab_pil_img = ImageReader(pil_img)
n10 = sizes2count(np.bincount(a), n) - n11
i = 0
ret = sys.stdin.read(1)
et.setMousePosition(200, 200)
parser = ArgumentParser()
print(lines[i])
result
done = True
Fruit[4]
plot = sns.pairplot(df)
-0.12
-0.11
-0.0900000000001
-0.0800000000001
-0.0700000000001
-0.0600000000001
difference = sum(new_arr) - sum_to
print(v())
print(connection.queries)
cert = DerSequence()
a = OrderedDict()
Fader.instances.append(self)
ln((x - loc) / scale)
a, b = b, a + b
big = np.random.randint(-10, 10, size=10000000)
rgba = cmap(0.5)
tmp = []
ans = pool.map(lambda x: f(x, 20), range(1000))
2
d = dict(enumerate(a))
False
LinearSVC1 = LinearSVC(tol=0.0001, C=0.1)
result = np.zeros([len(lst), inner_max_len], dtype)
result = 1j * Data[..., (1)]
print(stdin.channel.eof_received)
strcpy(file_name, argv[1])
self.nodes[node] = sorted(self.nodes[node])
my_bytes = bytearray()
i = i + 1
M[i - 1, i] = M[i, i - 1] = 1
root.left = Tree()
y[it.multi_index] = data[xindex].sum()
respawn
[1] * x
PyList_SetItem(list, 1, PyInt_FromLong(0))
l = self.lens[j]
x0 = np.min(x)
A = B.get()
False
False
d
rr, cc = np.meshgrid(r, c)
print(name)
assert isinstance(m, np.ndarray)
item
loop = asyncio.get_event_loop()
env[k].extend(v)
shortcut = shell.CreateShortCut(path)
sent = self.send(self.buffer)
entry = input.readline()
c.A0
zut = Column()
menfin = Column()
it = iter(iterable)
pkey.type() == OpenSSL.crypto.TYPE_RSA
config.x = 1
count = 1
12.25
repr(self.results)
firstkey, firstvalue = next(iterdict)
push_item = int(i)
limit = 2000
(279, 401, 170)(279.002, 401.824, 169.992)
rectified_linear_activation = lambda x: T.maximum(0.0, x)
m = list(range(1, 21))
result = copy.deepcopy(list1)
libc.fesetround(FE_UPWARD)
data = numpy.array([[e[1] for e in x], [e[2] for e in x]])
raise CompileError(msg)
[k][k][k - 1],
geo_r = requests.get(freegeoip)
unistr.rindex(unistr[-1]) + 1
start_color = 1, 0, 0
resp = requests.get(dls)
print(i)
nodes[node_id] = node
self.fields[field_name] = field_value
lambda x: j * x
type(y)
i = np.searchsorted(old_val, a)
print ()
count = lengths.get(length, 0)
stop = min(size or len(segment), len(segment))
mkin = open(sys.argv[1])
s = x.tostring()
n = n - 1
fcntl.ioctl(console_fd, KDSETLED, all_on)
model = models.Bloop
a(A, B)
type(name, bases, atts)
self.annotate_axes(ax)
version
sqs = SearchQuerySet().models(Post)
dense1 = gensim.matutils.sparse2full(lda_vec1, lda.num_topics)
ICON_STOP = 16
levls = np.concatenate((levls[:-1], np.linspace(10, 100, 10)))
title = forms.CharField(max_length=50)
display_as_text(result)
index_file.write(output)
val = worksheet.cell(1, 2).value
add1 = make_adder(1)
out, err = proc.communicate()
n01 = (np.sum(counts_b ** 2) - n) // 2 - n11
self._make_node(self._tuples, set())
data
value_index = -1
data = urllib.parse.urlencode(values)
instring_iter = iter(instring)
l.append(self._left[:i + 1])
float(dirty_data)
myglobals.data = []
a = (),
cur = connection.cursor()
data = stream.read(CHUNK)
year = int(date[0:2])
stack.append(current)
count += 1
i / 9 == j / 9
pil_im = Image.open(imageFilePath)
fly.rect.right = hit.rect.left
stem2 - 0.5
directory_list = list()
bar = Foo()
b = c
xy = np.zeros([X.shape[0] * X.shape[1], 2])
foo_max_time_q.foo_id = foo.id
contents = buff.getvalue()
thawLazy = strictToLazyST.Vector.thaw
days[inp]
print(mylst)
self.dict = {}
print(dt)
sig_objs[obj.signature()].append(obj)
score(1)
b = list()
f = mahotas.imread(imagename, as_grey=True)
new.join(li)
plt.yticks(list(range(height)), alphabet[:height])
np.min(alpha[alpha > 0]) * U
np.random.shuffle(X_t[:, (i)])
print(page.extractText())
gifmaker.makedelta(fp, frames)
z = w + ct
arr[i] = [arr[i], complement - arr[i]]
item.not_an_attribute
self.__dict__ = db_to_frames_dict(engine)
squre_pts.push_back(R1)
0
data = pd.DataFrame(np.random.normal(size=40 * 40).reshape(40, 40))
Py_MEMCPY(p, sep, seplen)
print(res)
print(mytmp)
imin = min(bins.keys())
df
arr[:] = 0
result = scipy.zeros(A.shape + B.shape[-1:], dtype=A.dtype)
chars[i] = chars[i].upper()
self.render_to_json_response(form.errors, status=400)
m, n = [((ss - 1.0) / 2.0) for ss in shape]
DictWrap(self.__d[attr])
recurse(0, 1)
foo = Foo()
self.set_intercept(X_mean, y_mean, X_std)
intermediate, result = myfunc()
matched = set1.intersection(set2)
data = concatenate((spread, center, flier_high, flier_low), 0)
reference_index = dict((value, index) for index, value in enumerate(reference))
x += 1
user_id = line_data[0]
nosetests - vv - -collect - only
y_mean = np.average(y, axis=1)
ii = itertools.count(X.shape[0])
[0]
orig = fd.read()
self.assertTrue(handler.request.recv.called)
grouper = (v != v.shift()).cumsum()
self.imp(name, *args)
b.print_a()
toret[pstack.pop()] = i
print(b.eval())
extra = 0
parser = MyConfigParser()
outputList.add(item)
_attr = getattr(cls, _cls.name)
sum(minutes_mul)
d2 = dt.now()
sys.exit()
final = []
size, (format, version, compression), (width, height)
self._stop
d = defaultdict2(noisy_default_with_key)
X = cv.fit_transform(preproc)
self._obj is other._obj
print(Lagrange(Lx, Ly))
glClearDepth(1.0)
source / path / to / current / bin / activate
sine_wave = np.sin(2 * np.pi * 440 * t) + np.sin(2 * np.pi * 1020 * t)
map(str, range(1, 4))
foo(x)
lst1.extend(lst2)
result = int(significate_d) * 10 ** int(times)
son[key] = decode_custom(value)
path = os.getcwd()
model.appendRow(item)
r = Tkinter.Tk()
self.pid = os.fork()
obj
response = HTTPBadRequest()
6
q = array_2
scr.keypad(True)
Xcum = np.empty((T - H + 1, k))
-x ** 2 - y ** 2 + z ** 2 - 1
title = r.search(page).group(2)
arr_1 & arr_2
f.append(self.target([candidate], args)[0])
theta = np.arctan2(x - cx, y - cy) - tmin
print(dt)
to_select = set([to_select])
log4j.appender.console = org.apache.log4j.ConsoleAppender
a = np.random.randint(-5, 5, 100)
prev = next(itercars)
c.Update(useA=False)
grads = [tf.gradients(yle, x)[0] for yle in yl]
x += counter
b = np.cumsum(a)
x = 50
writer.writerow(output_header)
L4 = int(len(f2) / 8)
handler.setFormatter(formatter)
collResv.rejectCompletely()
yaml.dump(test2)
exit()
filecmp.cmp(Compressed_new_file, Compressed_old_file, shallow=True)
permutations.append(list(cards))
login2 = urllib.request.urlopen(request2).read()
numbers = []
a.Field1
results[existing].append(value)
index = 0
link_list.append(link)
self.cb = wx.ComboBox(panel, size=wx.DefaultSize, choices=sampleList)
print(p)
mask = groups == unique(groups).reshape(-1, 1)
j = numpy.arange(j_max)
print(enum_list)
result
list(split_at(0, myIntList))
w = p * (y > z) + (1 - p) * (y < z)
abs(a - b)
place = models.OneToOneField(Place, primary_key=True)
next = __next__
it = iter(iterable)
print(answer)
cursor.execute(query)
phone_book = defaultdict(list)
handler(event)
integer + dec + decimal
frate = 44100.0
t0 = time.time()
student_detail = student_detail.filter(last_name=pk)
obj_.save()
times = np.random.randint(1, 24 * 60 - 1, numtimes)
name = path.basename(urllib.parse.unquote(urlparse(url).path))
pool = Pool(4)
val[1].append(k)
S - UnicodeStrings
id(a), id(b)
inneropt, partition, x = inner_result.get()
train_op = tf.train.AdamOptimizer(0.0001).minimize(cross_entropy)
n = len(arr)
step = 2 if n % 2 else 1
cd / Users / YourName / Downloads / boost_1_48_0 / libs / python / example / tutorial
callback = lambda pat: pat.group(1).lower()
col_num = workbook.worksheets[0].max_column
print(MySubClass().property)
li = []
MOUSE_MIDDLEUP = 64
l.append(8)
result
res += count_rec(cursum + i, level + 1)
work_duration = time.clock() - start
util._finalizer_registry.clear()
np.power(r, -6, out=r)
j, i = np.unravel_index(k, image_temp.shape)
fmin = Decimal(N) / Decimal(f2)
bot.reply_to(message, reply)
self.father.write(self.buffer)
content = f.read()
serializer_class = OCompraDetalleSerializer
m * c
print(solve(start, end, data))
xldays += 1
self.authorize(user, action)
X = np.arange(1, 10)
myfile.write(output)
hsv_color = rgb_to_hsv(*normalized_color)
print([a_i.sexpr() for a_i in a])
time = datetime.datetime.today()
x, y, z = np.ogrid[0:s, 0:s, 0:s / 2]
conn = SMTP(SMTPserver)
items = query.limit(per_page).offset((page - 1) * per_page).all()
xcorners = x[0, 0], x[0, -1], x[-1, 0], x[-1, -1]
cat.buildpacks
c = [[0], [0], [0], [1], [2], [1], [2], [1]]
dtype = arrays[0].dtype
print(timeit(lambda : map(mmul, matrices), number=20))
crawlerProcess.start()
True
print(user_social_auth.tokens)
func_type = CFUNCTYPE(c_double, c_double, c_double)
results
this.runCommand({dbstats: 1, scale: scale})
tot += float(a[0])
eventdata = npdata[npdata.event_id == 1]
i += 1
a += 1
from_naive_dt = datetime(2011, 11, 1, 8, 11, 22)
node_sizes.append(size)
param1.method(self, params)
cycle.next().append((sensor, value))
l.pop(i)
Y, X = stdscr.getmaxyx()
print(variables)
wrapper
t = test()
self.html_content = html_content
guiFrame.mainloop()
cols = list(set(result.columns).intersection(df.columns))
delta_sample = random.sample(delta, 1000)
dr = 1.0 / np.sqrt(dx * dx + dy * dy + dz * dz)
100000100, 100000200
self.b = 5
base_class = ParentA
make_async(process.stderr)
x0 = np.min(x)
g(**kwargs)
abcIRi = fewf
print(result)
rx_megabits = int(rx_bytes) * 8 / 1024 / 1024
abs(a) / abs(b) * sign
X = scipy.fft(x)
args = parser.parse_args(sys.argv[1:])
histo[1] = histo.astype(np.float) / len(g)
l2 = list(l)
print((One, Two, Three))
overflows[index].append(new_lists[index].pop())
self.wait_for_prompt()
x + y - z
data = self.f.read(*a)
csv_reader = csv.DictReader(f, fieldnames)
norms = np.sqrt((x ** 2).sum(axis=1, keepdims=True))
thunk(callback)
browser = mechanize.Browser()
pd.__version__
root = logging.getLogger()
cv.Flip(orig, flipMode=-1)
b()
new_string, 0, enc
z = [x]
max_scores = defaultdict(int)
a = np.array(lst)
L[i + 1] = L[i]
bin(88)
all_ = itertools.zip_longest(ones, zeros, fillvalue=np.array([]))
print(list)
N = A.T.dot(A)
cur = todb.cursor()
deleteself._namescallback[channel]
PyList_SET_ITEM(l, i, PyInt_FromLong(array[i]))
df
x = np.zeros(10, dtype=np.object)
h.itemset(i, j, 1, 255)
a.x = 5
H = sparse.lil_matrix((num, num))
f(mydict)
raise e
mw.dockWdg2 = QtGui.QDockWidget(mw)
b, c = [1, 2], [1, 9]
cpick = cm.ScalarMappable(norm=cnorm, cmap=cm1)
l.sort(key=key)
post_url = reverse(route, args=(new_obj.pk,))
stats = dict()
(5, [5]),
per = 100.0 * tota / 500
data2.flush()
verified_domains.add(domain)
y & 1 << x and 1
object().x = 0
test()
content = rsp.read()
df.Col2
spawn_process_that_runs_main(level - 1)
playProcess.wait()
new_row = []
elements.append(table)
py.test - c / dev / null
headlines = [headline.headline for headline in article.headlines.all()]
self.last_value = next(self.gen)
randstr()
a, sep, b
new_cs.ImportFromWkt(wgs84_wkt)
d = shelve.open(filename)
no_zeroes = [(r[:i] + r[i + 1:]) for i, r in enumerate(a)]
raise StopIteration
app.testing = True
predict = fit.predict(df)
f
sound.play()
prior_reci = 1 / np.asarray(prior)
raise KeyError(key)
foo = Dog()
cluster.append(j)
Point.ORIGIN = Point()
lock = threading.Lock()
paths.extend(walk(v, child_path))
print(i * m)
count
outsider_to_swap = np.random.randint(N - k)
data = open(file).readlines()
doStuff()
p.feed(s)
sieve = [1] * size
pa_stream_peek(stream, ctypes.byref(vdata), ctypes.byref(length))
encodedFields = urllib.parse.urlencode(formData)
sy.init_printing()
s.index = df.columns
ax = plt.gca()
common &= set(l)
res = 0
inner
localized_time = system_tz.localize(time_of_meeting)
HOST = socket.gethostbyname(socket.gethostname())
canvas = ax.figure.canvas
out.shape
numbers = list(range(a, b)) + list(range(c, d))
out
len(set([x for x in t if x >= 9]))
fig_coords = fig.transFigure.inverted().transform(disp_coords)
str(jinja2.escape(s))
BEGIN
ax = plt.gca()
sampwidth = 2
test = test + 1
output = p2.communicate()[0]
naughty.append((nr, name))
with_statement.getMandatoryRelease()
board = [[(0) for x in range(s)] for y in range(s)]
print(data)
xml_string_io2 = StringIO()
description = db.Column(db.Unicode(140), nullable=False)
n = x2.shape[0]
allrows = list(range(0, len(mat)))
overlap_lens = (i + 1 for i, e in enumerate(addition) if e == master[-1])
name = input()
process.send_signal(sig)
cvCircle(rgbcanny, center, radius + 1, CV_RGB(0, 0, 255), 2, 8, 0)
serializer_class = UserSerializer
sorted_a[insertion_points]
print(value)
getkey.get_key(D, 2)
countings = numpy.bincount(x)
results = []
saved_source = Template(original_source).render(c)
print(d)
x, y = params
g = Lambda(x, diff(f(x), x))
vars(Example)
print(list(outbuf))
print(expr.parseString(t).dump())
print((account.db, account.host, account.user, account.password))
weight = func(x)
anim = animation.FuncAnimation(fig, animate, frames=list(range(2, 155)), blit=False)
continent = models.ForeignKey(Continent)
http = credentials.authorize(httplib2.Http())
primebytes.fromfile(f, filesize)
supermanutd
np.testing.assert_equal(using_eight_shifts(data), using_filters(data))
L[next(n)] = item
index = similarities.SparseMatrixSimilarity(tfidf[corpus], num_features=12)
e = self.model - np.dot(self.p, self.q.T)
os.setgid(running_gid)
tmp_sources.write(line[2:])
value -= 1
f.close()
event.widget.tag_click = False
eq1 = TestableEq()
alotoffunc.efg(self, x)
output = model.eval(arguments)
list = []
result = []
method2 = tmp[:, :, (0)] & tmp[:, :, (1)] & tmp[:, :, (2)]
a0 = A[..., (0)]
gr = P.Group(key_equal + val)
X = np.linspace(-5, 105, 2000, endpoint=True)
end = s.index(last, start)
res.is_integer()
tornado.auth.GoogleMixin.get_authenticated_user(self)
num = num ^ 1 << k
True
r[i, j] = min(r_num / r_den, 1.0)
w, v = np.linalg.eig(corr)
installpath = sys.prefix
timeit.Timer(f2).timeit()
0,
client = suds.client.Client(wsurl, plugins=[payload_interceptor])
child._parents.add(self.name)
data = np.random.uniform(low=-1600, high=-550, size=(50,))
user.topics.all()
Point(num * self.x, num * self.y)
Players = int(Players)
n = len(a)
True
data = self.wf.readframes(self.chunk)
new_list2 = []
weights += lrate * (CD / nCases - opts_arr.dot(weights))
True
csvfile.close()
print(m.span(), m[0])
W = fftfreq(y.size, d=x[1] - x[0])
glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT | GL_STENCIL_BUFFER_BIT)
dT.T.dot(dT)
plot(t, x)
print(device_lib.list_local_devices())
it = zip(*([a] + [itertools.cycle(b) for b in bs]))
pylab.ion()
init_db()
X[(I), :]
sqr.data **= 2
s.script()
FWHM = 2 * np.sqrt(2 * np.log(2)) * fit_stdev
d1 = {}
payload = {}
compute(2, 4)
abort(400)
old_sys_exit = sys.exit
do_stuff_to(thing)
rnd = np.random.randint(100)
randomized_list
oct = str(resp[0])
dis.dis(test1)
c.b
s = set()
print(s[start:end + int(s[start + 1:end])])
b = a
first_name = TextField()
print(tree[6])
dicts = [d1, d2]
test(no_deco=True)
IP_PMTUDISC_DONT = 0
y = [0, 0, 1, 0]
partial_duplicate_destroyer(mydict, 200)
new_obj.info
t = ET.parse(sio(fixed_text))
_ref, _sys.modules[__name__] = _sys.modules[__name__], _DynamicModule()
float(s)
x + 5
assert len(A.instances) == i
dis.dis(bar)
vals = np.random.random(10000.0)
r, g, b = im_rgb.getpixel((x, y))
r.status_code
result_dict
result = [[word] for word in words]
mean_list = []
self.myConfig.getConfig(key)
parts = line.split()
height = shape[0]
item = PyList_GetItem(list, 0)
self.timeout = 20
idata = iter(data)
found = issubclass(type(spam_loader), importlib.machinery.SourceFileLoader)
joined = joined.sort_index(axis=1)
foldl(cons, [], xs)
y, x = np.mgrid[:12, :12]
plt.plot(xrng, yrng)
jmax = jj.max()
fit = model.fit()
dd = defaultdict(set)
install_requires = []
next_time = datetime.now() + period
n = a.strides[0]
h /= sumh
self.folders += 1
newf = f.f_locals[n]
r[4::2] = [False] * len(r[4::2])
O(nlogn) + O(k)
result[:] = fillval
task_2_result = task_2.get(timeout=1)
-(0)
df.genres.apply(unique_items.update)
writer.writerow(columns)
do_something_else
value = mc.get(key)
count = db.IntegerProperty()
res = 0
wrapper
s_lower = s.lower()
query = NDB_Model.query(NDB_Model.some_property == some_value)
print(template.format(pid, uid, pname))
add(1)
oend = min(uend, vend)
c = a + b
[9.0, 0.0, 6.0, 9.0, 4.0],
idmap = dict((id, pos) for pos, id in enumerate(ids))
_counter_lock = threading.Lock()
sample_sizes = (np.ones(nu) * mpb + fills).astype(int)
i1, i2 = int(v), min(int(v) + 1, max_index)
pickled = pickle.dumps(a)
width, height = bbox.width, bbox.height
logger.addHandler(fh)
sum_
df1
desc = cursor.description[i]
tag_weight = {k: int(v) for k, v in list(tag_weight.items())}
m = m.astype(bool, copy=False)
nodes = set()
line.set_data(x, y)
k[j], k[j - 1] = k[j - 1], k[j]
seen = set()
velcro.forward(75)
print(inputready, outputready, exceptready)
delta_days = d.isoweekday() - 1
permutation_list = set(permutations(x * y))
delta = timedelta(days=7)
standard_c_lib.__error.restype = ctypes.POINTER(ctypes.c_int)
innertype = ctypes.ARRAY(ctypes.c_float, 10)
True
value = my_dicts[0][key]
df.columns = levels[1][labels[1]]
zip[j] = lists[j][i]
set_printoptions(threshold=nan)
spotifyPlaying = spotify.isPlaying()
column_dict.update(col)
cnx.close()
c = C()
connect = engine.connect()
merger(*wrapper_tuple)
[Y, X] = np.meshgrid(np.linspace(0, 1, n), np.linspace(0, 2, m))
my_set = {1}
indices = sorted(random.sample(list(range(n)), r))
sparse.csr_matrix((d, (r, c)), shape=A.shape)
right = [4]
id(y)
x, y = 0, 0
norm_rows = np.sqrt(np.add.reduceat(a.data * a.data, a.indptr[:-1]))
logging.basicConfig(level=logging.INFO)
x = np.linspace(1, 10, ndata)
a.desc = 2
tuples = [ab for ab in group2(tuple)]
copier = functools.partial(copy_file, target_dir=target_dir)
c = conn.cursor()
N = 2
sys.stdout = s
item.add_done_callback(self._remove)
uniquekeys = []
__import__(name, globals, locals, fromlist, level)
pp(x)
x, y = 7, 0
plt.figure()
result
browser.set_cookiejar()
key = _winreg.OpenKey(hkey, keypath, 0, _winreg.KEY_READ)
out[mask] = np.concatenate(data)
mask = cv.resize(unbordered, (image.shape[1], image.shape[0]))
args = func_args[:len(arg_names)]
tuple.__new__(tuple)
val = [0.1 + 0.1j, 0.1 - 0.2j, 0.1 - 0.4j]
Counter(string)
result_pic = io.BytesIO()
scrapy_settings = get_project_settings()
self.trayIcon.hide()
print(df1)
particle = table.row
ssh_con(ip, un, pw)
t = Timer(lambda : superMegaIntenseFunction(10))
tree
print(tuple(l))
python27(active)
Normalize.__init__(self, vmin, vmax, clip)
wrapper
time = fields.Str()
data = np.random.multivariate_normal((0, 0), [[0.8, 0.05], [0.05, 0.7]], 100)
name = models.CharField(max_length=200)
sigma = a / a_sigma
ws = wb.active
x1 = np.max(x) + 1
self.urls_seen = set()
print(a)
xmax = [11.0, 11.0]
msg = mailserver.retr(i + 1)
x = np.random.randint(1000000, size=i)
z.close()
newList
factory = lambda : defaultdict(factory)
print(g.todense())
y = np.arange(0, 1, 0.2)
data = json.dumps(data)
c = a * b[ss]
min_a, max_a = min(a), max(a)
self.assertAlmostEqual(val1, val2, 5)
id(c.d) == id(CA.d)
print(res.weekdays)
print(fooaction.default)
xsort_idx = x.argsort()
df
after_request_check_something(response1)
left = self.reindex(columns=common, copy=False)
htmlcolor(127, 14, 54)
app.merge(confdict)
i = 0
y = np.zeros(len(x))
use(block)
retcode = process.poll()
rpc.weblogUpdates.ping(instance.title, instance.get_absolute_url())
print(get_closest_point((a_bound, a_val), dist_to_valid_b_points))
this_method = getattr(self, method).__func__
time.sleep(0.2)
print(df)
action.dest.upper()
print(link)
Foo.bar is foo
ucs2[n] = fill_char
email_notification_task.delay(payload)
sum0
renamed.__name__ = name
print(peek_line(f))
Console.WriteLine(output)
out = np.empty((arr1.size, arr2.size))
tot_vec = embed_vec.shape[0]
dis.dis(f)
out_sen.append([word, str(idx)])
bootstrapped_scores.append(score)
figsn = matplotlib.pyplot.figure()
test1.test()
False
memoryview(a0) == memoryview(c0)
mid + 1
sys.stderr.write(error.message)
last_edit = models.DateTimeField(auto_now=True)
attrs
parser = ArgumentParser()
self.arr = arr
repr(result)
t * 2
string_from_file = f.read()
KeyDown(Base[Combs[Key][1]])
10 ** 100
x = math.pow(pos1[0] - pos2[0], 2)
print(even, odd)
divisibleBySeven = list(filter(meetsCondition, inputList))
rsi_series
print(datetime.now() - startTime)
x = bins[:-1] + 0.5 * np.diff(bins)
int_data = unpack(formatstr, rawdata)
tmp = cm.hsv(x)
serializer_class = MySerializer
len_data = len(packets)
1, 2
r.get_response(app)(environ, start_response)
login_html = self.ses.get(url_login)
extras = list(t for t in st1 if t not in list2titles)
ipdb > pylab.show()
label.set_size_request(250, -1)
delta_weeks -= 1
u = self.create_user(email, password, **extra_fields)
seen = set()
temp = a.__getitem__(slice(0, 1))
print(line)
raise ex
h[-1].append(d[n / 2])
self.failed_urls = []
certs = response.read()
L = list(range(10))[::-1]
ftp = ssh.open_sftp()
server_sock = BluetoothSocket(RFCOMM)
self.roots = [et.parse(f).getroot() for f in filenames]
runner = unittest.TextTestRunner()
next_neighbors = get_neighbors(next_step, V, visited_nodes)
err, mid, msg = self.q.get(block=True, timeout=self.timeout)
revnums.reverse()
list2 = list1[:max_size]
[-1, 1, -1, -1, -1]
datei = next(pdates)
d2 = {}
print(counts)
elements = []
cv_custom = [(list(range(0, N)), list(range(0, N)))]
user.date_joined = datetime.now()
bio_tagged_sent
modules
self._iterable_len = len(self._iterable)
a
df2
ws.start()
self.owned = False if self.owned else True
Y = df.index.values
roi = im[y:y + h, x:x + w]
seen_keys.add(key)
x2 = lerp(n01, n11, u)
print(p.Name)
maxcol = A.col[I]
groups = [(k, g) for k, g in evens_odds_grouped]
module
h = [((h + d) % 1) for d in (-d, d)]
norm = mpl.colors.Normalize(parameterToColorBy[0], parameterToColorBy[-1])
result += c
detail = err.args[0]
j += 1
new_kwargs = dict([(k, kwargs[k](v)) for k, v in list(fn_kwargs.items())])
print(distances_as_2d_matrix)
x.tofile(f)
firstItem = rs.first()
NavigableString.clone = lambda self: type(self)(self)
print(string)
n = len(l)
valid_file = True
sample = [random.gammavariate(a, 1) for a in params]
d = {}
log.start()
DBSession.configure(bind=engine, autoflush=False, expire_on_commit=False)
new_list2 += [list2[j]]
1, 1, 4, 6
plot_implicit(hyp_part1, bbox=(-100.0, 100.0))
raise TypeError
random.shuffle(items)
sock = socket(AF_BLUETOOTH, SOCK_RAW, BTPROTO_HCI)
False
postal_code = db.PostalAddressProperty()
s = set()
number_of_tries = 0
rtn = []
result = collections.defaultdict(int)
im.crop(bbox)
z = y - x
show(bar)
print(d)
x
lta = [int(s) for s in a.split() if s.isdigit()]
aDict = {}
out[k] = []
{{inner()}}
obj
self.collection = self.db.block_chain
TRAVIS = true
ax.grid(True)
arr1 = array[:split_idx, :]
value = choice.get(choice.curselection()[0])
node = node.children[path.pop(0)]
execute_manager(settings_local)
0 - 0.247187
mydf.rx(True, c)
self.menu = NSMenu.alloc().init()
print(map(list, result))
process_the_stuff()
line = plt.plot(x, y)
False
distances = np.zeros((n, n))
wd = Tk()
item = defaultvalue
myclass = MyClass()
vals = np.random.random(100000000.0)
{{f.get_follow_count}}
li = []
sh = logging.StreamHandler(sys.stdout)
line = f.readline()
last = sets.copy()
ysort_idx = y.argsort()
sleep(0.2)
m = hashlib.md5()
numpy.bitwise_xor(numpy.frombuffer(aa, dtype=numpy.uint64), b, b)
Concate = dict()
X = X[(indices), :]
ID = ID + 1
seen = set()
derivative
unittest.main()
legline.set_dashes(dashes[1])
print(response2.text)
result = cmp(key_func(t1), key_func(t2))
main()
updating = False
run_wsgi_app(application)
results = []
self._exceptions.append(formated_exc)
created = models.DateTimeField(default=datetime.now())
self.name = name
x = Flatten()(x)
tpl = Template(tpl_xml)
parity = serial.PARITY_NONE,
random.random() * (high - low) + low
toks = tokenizer.tokenize(text)
m.group()
trainer = deepbelief.DeepBeliefTrainer(net1, dataset=ds)
new_dictionary[key] = value
res += partial1 * partial2
json.dumps(result)
self.check(value[0], value[1])
sysd_ss = scipy.signal.cont2discrete(sys_ss, 1.0 / 10)
np.random.seed(101)
g = sns.clustermap(flights, row_linkage=row_linkage, col_linkage=col_linkage)
y = np.ma.masked_where(y == 0, y)
slc = np.array(list(big_diff(df.y)))
res[n], err[n] = integ.quad(G, 0, 1, args=(n,))
n -= 1
w1 = Weight(-0.79, neurons[0], neurons[2])
a.write(filename + os.linesep)
last_key = key
self._scale[j] = (n - 1) / (h - l)
print(avg_cor.head())
results = Queue()
rindex = np.array(sample(range(len(df)), 10))
self.d[k] = v
masterList = []
sums[p[0]] += int(p[1])
prime_slices[n]
lowest_values
randomRow = query.offset(int(rowCount * random.random())).first()
a = get_weights_array(5)
x ** 2
p.first_name
fig, ax = plt.subplots()
a += 1
np.int64(self.x)
trace.text = s.getvalue()
foo = Foo()
a = df.values
ts
self.canv.saveState()
print(r.text)
self.parent()
strrepr = repr(eval(tokstr))
print(html[:50])
ax
hanoi(pegs, start, target, 1)
index = cindex.Index.create()
self.data = dict(*args, **kwargs)
setdefault_(x, []).append(i)
classmethod(_w)
end_time = time.time()
hits_count = np.histogram(hits, bins=n_centers.shape[0])[0]
b = 8, 1, 0, 0
axes[1].imshow(my_image2, clim=clim)
serializer_class = self.get_serializer_class()
ax1 = plt.subplot(gs[(0), :])
cam.release()
test_m = np.asarray([[] for s in range(size)])
print(p.A)
print(group.name)
regmxv = zeros(size(di2))
self._index += 1
bad_lines = []
Py_INCREF(elem)
root = path[:path.index(os.sep)] if os.sep in path else path
formatter = logging.Formatter(fmt=self.subject)
seqsamples = random.sample(range(0, int(seqs)), int(args.n))
word = words.next().strip()
x = gmpy.mpf(10 ** 1000)
+db_matrix[:, (option_vector[i, 2])] * bp_vector[j, 2]
correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels, 1))
a = m[2, 0] / m[0, 0] - xc ** 2
do_something_with(record)
compilation_database_path = args.compilation_database.name
print(ismethod)
b = values.copy()
print(original_string)
iter(lambda : list(IT.islice(iterable, n)), [])
sound2.sound.set_volume(0)
func
ncalls += 1
a = np.diff(w).argmax()
file_list = list_files(path)
infile.close()
attr
self.f.write(x)
r = sr.Recognizer()
all_sequences = [list(range(x)) for x in range(10)]
lastRow = ubound(pyvalue)
TEST_RUNNER = unittest.TextTestRunner()
curses.use_default_colors()
VENUS = Body(mass=4.869e+24, radius=6051800.0)
screen.refresh()
self.name = name
sample = df.loc[(sample_multi_ix), :]
i, j = int(i), int(j)
response = view_with_request(request)
results = sm.OLS(y, X).fit()
caller.assert_called_with(Any(int), Any(int), Any(int), arg=False)
x1 = np.max(x) + 1
zip_longest(fillvalue=fillvalue, *args)
[20, 22, 24, 26],
url, headers, body, status = self.create_token_response(request)
fast_iter(context, process_element)
content = socket.read()
np.arctan2(np.power(lon_dif, 0.5), np.power(1 - lon_dif, 0.5), out=lon_dif)
f_signal = rfft(signal)
C = np.intersect1d(A.view(dtype), B.view(dtype))
noise = 5 * (np.random.random(data.shape) - 0.5)
table.insert(0, x_axis)
action.move_to_element_with_offset(el, 5, 5)
i = 0
x, y = p.get_lines()[0].get_data()
n = max(1, n)
x
bool2 = True
y = f(4)
c.dump()
itempath = os.path.join(path, item)
N = 100
child_id = os.getpid()
aa = np.array(a)
sourceFilePath = os.path.join(targetPath, image)
n = len(self.coef) - 1
res = []
now = datetime.datetime.utcnow()
root = tree.getroot()
xs = np.linspace(xlim[0], xlim[1], resolution)
values = []
a = phyawall()
y2 = np.random.randn(100)
splitS
ok = -np.isnan(A)
print(pid)
r = r[:-1]
clf = RandomForestClassifier(max_features=5)
A = PG.AGraph(directed=True, strict=True)
raw_data = stream.readframes(num_frames)
check_api_key
mode = os.fstat(fd.fileno()).st_mode
print(hash(str(self)))
inputList = [0, 0.25, 0.5, 0.75, 0.99, 1]
zip(*d)
not result
merged_list = list()
self._read_bitmap(offset)
word = self.trell[i][0]
raise RuntimeError(error)
list(i1)
new_sql.append(new_statement.to_unicode())
line
crawler.start()
groupCoords[(cdist(groupCoords, Arr) < 1.5).any(1)]
ax2.set_xlim(min(dates), max(dates))
n = n // 2
Xfit_mono[len_mono] = Xfit[0]
a is b[1]
paragraph = Paragraph(header_string, styleH)
entry.pack()
wpa = 1 << 6
seen.add(x)
num = 1
print(df2)
sorted_li = sorted(li, key=itemgetter(1), reverse=True)
split_mounts = [s.split() for s in mounts.read().splitlines()]
j = r.json()
args = p.parse_args()
m.update_time(0)
Y = np.array([[0.0]])
tenth_column = get_column(a, 9)
dict((k, pretty_floats(v)) for k, v in list(obj.items()))
signal.alarm(seconds)
xy_pairs = xy_pairs.reshape(X.shape)
image_new
raise NotImplementedError
value = cgi.escape(value)
wrapper
print(x)
self.text = text
dom2 = parse(datasource)
print(u[ank][uri])
0
chain.from_iterable(map(acc_f, seq))
first = lists[0]
serializer_class = PlaylistVideoSerializer
print(obj.testclass1())
distToB = startB
deletemydll
points[(i), :] = np.random.normal(loc=medians[i], scale=disps[i], size=100)
self.sock.bind((self.source_ip, 0))
loop.run_until_complete(asyncio.wait(tasks))
self.pts.append(p)
retval = _func()
inner
jwt_payload_handler = api_settings.JWT_PAYLOAD_HANDLER
is_train = True if len(sys.argv) > 1 else False
astring[:-len(trailing)]
FakeModule.World = CoolModule.World
self.figure = Figure(facecolor=(0, 0, 0))
s1 = strip_ANSI(s)
a + b / 12.0
mylist[mylist.index(s)] = s + str(suffix)
et.ElementTree(self.roots[0])
io.imshow(newimg)
y = numpy.arange(0, ystop, step).astype(int)
print(keys_list)
bigar = numpy.asarray(big)
mock(1)
print(a)
sxs = 100.0 * np.random.random(ng)
mask = int(n.netmask)
Returns
f = Foo()
res = []
jsonify(res)
q1 = Cat.objects.all()
child = div.contents[0]
print(result)
self.a1_edit = QtGui.QLineEdit()
it = iter(obj)
xs = ax.transData.transform(zip(x[-2::], y[-2::]))
s.append(item)
stack = []
xmap[:] = x[:]
deletexl
self.terminate_all()
metadata = MetaData(bind=dest_engine)
False
i = 0
car1 = pygame.transform.rotate(car1, 10)
data_list.append(data_dict)
df = DataFrame(abs(np.random.randn(5, 4)), index=Index, columns=Cols)
self.weight = 5
x, y
Foo.dict_init()
V_next = numpy.concatenate((V[1:], V[:1]))
a[mask]
ctx.push()
numpy.log10(mat)
new_len += min(2, count)
id(a)
result = []
self.items = list(items)
figure, imshow(label2rgb(ccomph), [])
m = aStr[len(aStr) // 2]
zip(a, b)
utc_time = mexico_time.astimezone(pytz.utc)
f = partial(func, x=xv, y=yv, z=zv)
out_curs = con.cursor()
objectify.deannotate(root, xsi_nil=True)
f.close()
[1, -1, -1, -1, 1]
i = 0
register_treebuilders_from(_html5lib)
print(convert_tuple([f, f2]))
piold = pi
transposed = [list(i) for i in zip(*table_data)]
common.py
print(result)
dup2(father2child_pipefd[0], 0)
scipy.sparse.linalg.lsqr(A, b)[0]
True
l.append(n / pi * (x * 0.1 + 1) ** 2 - pi * (x * 0.1) ** 2)
data
exp = int(math.floor(math.log10(abs(x))))
y = cos(phi) - 2 * cos(2 * phi)
angle = np.math.atan2(np.linalg.det([v0, v1]), np.dot(v0, v1))
self.func
print(df1)
lst = manager.list()
count += 1
targets.push(target)
Session = sessionmaker(bind=sa.engine)
print(repr(r))
a = N.arange(0, 5, 0.5)
points = np.random.uniform(size=(npt, dim))
_col = prop.columns[0]
t = np.arange(0, 1, Ts)
reactor.callLater(1, self.tick)
sample_bucket.create()
z = math.sin(i)
ibm = IbManager(clientId=5001)
pais.append(str(row[0]))
dirs.remove(skip)
module_name = os.path.basename(program_filepath)
res1 = slice_array(arr, 4, 2)
string = string.replace(d, divs[0])
print(filesContainString)
content_length = len(fp.read())
all_perm = np.array(list(itertools.permutations(list(range(ncols)))))
a == b
out = np.zeros(im.shape, np.uint8)
t1 = time.clock()
self._parser.Parse(data, 0)
self.rcon = rcon_or_url
val += 1
self.flip()
col, rem = divmod(col - 1, 26)
print(sys.version)
results = [x for x in results if x.dist <= DISTANCE]
1
field_class, kwargs
x = []
primelist = []
mean = 0.418749176686875
dis.dis(code)
autostart = true
a = n % len(seq)
name = element.contents[0]
THE_ANSWER = 42
c = (~p).cumsum()
key
mean = np.load(mean_file).mean(1).mean(1)
es_formats.DECIMAL_SEPARATOR
False
show()
y = x * x
d = etree.HTML(data)
seen = set()
r = slice(1, 4)
patches, labels = ax.get_legend_handles_labels()
ret
print(penguin)
lengths = [len(item) for item in l]
data = [4, 5, 6]
print(file)
pl.plot(data)
alphas = string.lowercase + string.uppercase
True
data = base64.standard_b64decode(encoded)
list1 = [2, 4, 6, 8, 10]
A1 = np.zeros_like(A)
value
str(path)
minval + Decimal(rangelen) * random.randrange(denom) / denom
data = []
pair = [i.strip() for i in pair]
cmd_resp.sendline(password)
os.chdir(getScriptPath())
-value if x < 0 else value
print(x)
cluster = point_tree.data[group]
self.x += 1
_num = 1
pl.plot(conv)
arr = (c_double * N)()
bottom_row = 0
print(root)
skip = q + int(bool(r))
out[np.triu_indices(a.shape[0], 1)] = dists
root = node
f2 = f2 * (np.max(f1) - np.min(f1)) + np.min(f1)
mydf_cp2 = mydf.copy()
web = QWebView()
rf = RegistrationForm(request.POST)
df.index += index_start
self.handle_data(chr(name2codepoint[name]))
t.daemon = True
n
Child().self_prop()
aaa.port
request.user = AnonymousUser()
logT = np.log(T)
count = start - 1
users = defaultdict(list)
tmp = tmp * dy * ax.get_figure().get_dpi()
ws.send_str(hello.text)
converged = True
print(x)
writeln(intArray)
self.ctx.invoke(subcommand)
font = CONSOLE_FONT_INFOEX()
self._property = 12
print(d)
values = [200, -140, 400, -260]
print(x)
self.color = color,
main()
parser._parser.EndElementHandler = end_tag_event
ec2 = boto.connect_ec2(*AWS_ACCESS_GENERIC)
tree.setModel(model)
config = configparser.ConfigParser()
incomment = False
load_environment(conf.global_conf, conf.local_conf)
print(result.sort_index())
i.union(j)
a_char = random.choice(keylist)
n, bins, patches = plt.hist(array, 50, normed=1)
data = write_png(buf, 64, 64)
draw = aggdraw.Draw(im)
print(index[1])
pink = make_norm_dist(x, 60, 10)
seq = [str(x) for x in seq]
p = psutil.Process(os.getpid())
count = mylist[:i].count(v)
registered_plugins = []
m = hashlib.md5()
n & mask | m << i & ~mask
tries.append(numC)
os.close(fd)
self._meta = new_meta
item
f = np.arange(1, 9) * 2000
Foo(1)
result
context = {}
x
xor_.cython_xor_vectorised(aa, bb)
my_date_format = udf(lambda d, fmt: d.strftime(fmt))
sequence1 = record1.seq
rows = numpy.zeros((len(arrays), result_length))
assert value is False
py > ast.body[1].value.args[0]._fields
result = []
print(msg)
print(ctypes.windll.cprog.square(4))
message_types.VoidMessage,
files_grabbed
e = soup.find(text=right_comment)
j += 1
m = MetaData()
A.add_word(w, (i, w))
idx = mro.index(__class__)
EMAIL_PORT = 465
norm_vals = np.random.normal(0, 1, size=(nm,))
func()
group_max
c = m[0, 2] / m[0, 0] - yc ** 2
scale = max_norm * tf.minimum(l2norm_inv, tf.constant(1.0 / max_norm))
last_row = df.tail(1).index[0]
t = TestClass(1)
print(i)
DUT = Class()
mixins.RetrieveModelMixin,
py > ast.body[1].value.args[0].s
Counter({name: quantity})
idx = np.zeros(n, dtype=int)
print(int(answer))
System.out.println()
size
D.shape
main.hide()
surface.fill((255, 255, 255))
image_list = []
print(max(map(len, invRegex.invert(data))))
grokster = s.snoodidle()
L_in_columns = zip(*L_in_rows)
fs = [executor.submit(process_file, file) for file in files]
print(d)
widget = self.dvbox.takeAt(cnt).widget()
unique_labels = set(labels)
bit_array[item_index] &= ~(1 << bit_index)
D = (np.random.random_sample(10000.0) + 80) * 80
b = np.array([67.5, 60])
instance = targetClass()
assert len(a) == len(b)
self
_ranks[i][k] = a
x, y, z
x[0] += 1
root = Tk()
x = x.T
sql = sqlparse.parse(stmt)[0]
d = dict(abspath=os.path.abspath, dirname=os.path.dirname)
{}
chrome_options = Options()
newfile.write(str(packets[1]))
self.panel.SetSizer(self.vbox)
self.key = key
Set2 = set(List2)
na = a.shape[0]
cess_sents = cess.tagged_sents()
logging.info(time.time() - started_at)
default_encoding = locale.getpreferredencoding()
path = request.get_full_path()
successor.send(cust)
print(results)
pos = df.index.get_loc(idx)
month_aggregate[date].append(v)
n = len(letters)
handler_map = legend.get_legend_handler_map()
serv_resp_body = serv_resp.read()
print(ai[ai_move][player_move])
desired_result = img[y1:h - y2, x1:w - x2]
pace = 2
y = X.dot(w) + numpy.random.random(npoints) * 0.1
settings = list(propfaid.get_cache())
ldaModel = lda.fit(corpus)
data = os.read(fd, 1024)
s = next(s, 5)
self._min_x = x
print(f.x, f.y, f.z)
cleaned_email_list = list()
print(scan.request.id)
list = getattr(namespace, self.dest)
y_pred = svc.predict(X_test)
ltex.set_rotation(rot)
self.array = []
x, fs, nbits = scikits.audiolab.wavread(filename)
s.push(n)
Sy = Sy + y
element.tag
e1 = lst[-1]
rgbArray[..., (2)] = b * 256
False
test_sent_features
sio = cStringIO.StringIO()
res = self.opener.open(req)
args = parser.parse_args()
parser.setContentHandler(MyHandler())
cPickle.dump(self.object, file, protocol=cPickle.HIGHEST_PROTOCOL)
self._func(*args)
available_translations = ndb.StringProperty(repeated=True)
RSAkey = RSA.generate(1024)
arr = numpy.array(im)
left, right = seq[0], seq[1:]
ax = fig.gca()
x = np.random.randn(100)
all_ = list(get_all(s, A, to_load))
i = i + prim
toks[0][2], toks[0][1] = toks[0][1], toks[0][2]
t = Test()
f.write(r.content)
N = len(max_range)
Y = np.arange(dk, 20, dk)
x = int(myStr, 2)
fs_enc = sys.getfilesystemencoding()
popt, pcov = optimize.curve_fit(func, xdata, ydata)
dec = yad(list_of_decorators)
binds.update(dict.fromkeys([Project, Hour], staff_engine))
arr
f = manhole_ssh.ConchFactory(p)
ipython
upper_red_0 = np.array([sensitivity, 255, 255])
(f for f in zip(*my_iters) if all(x > threshold for x in f))
__iter__ = int_iter
user.avatar = url
x + 1
df[~mask] = -1
p[0] * c - p[1] * s, p[0] * s + p[1] * c
print(pid, status)
error = get_error(Q, X, Y, W)
j = s.index(t, i)
traceback.print_exception = custom_print_exception
next(i)
content = browser.response().read()
tree.add(street[l])
self.content = content
output = list(filter(not_empty_except_first, input))
dictionary = BOW.cluster()
b = b0 + (b1 - b0) * (y - y0) / (y1 - y0)
PARSE_ERROR, ER.NO_SUCH_TABLE, ER.WRONG_DB_NAME, ER.WRONG_TABLE_NAME
mat = globpat.search(line)
result = {}
mu = np.mean(samples)
etype, value, tb = sys.exc_info()
f = I0 * (2 * sy.besselj(1, x) / x) ** 2
b = example.get_other_base()
standard_c_lib._errno.restype = ctypes.POINTER(ctypes.c_int)
sim1.run(configFactory.ConfigForSim1())
skeleton = morph_laplace_img < morph_laplace_img.min() / 2
print(find_parent(A, class_set))
rs = mySession.query(Items)
bool(-0.1)
print(obj.xyz)
mask = (np.abs(arr[R] - arr[C]) < th).all(-1)
bv.write(myarr.tostring())
griddata._convertToOneOfMany()
tree.body[1].module
succ = [create_successive_items(lst, i) for lst in lists]
self.mass, self.radius, self.moons
bin = struct.pack(myfmt, *mydata)
out = out.argmax(axis=1)
arr = [1, 2]
isinteger(bar)
print([f() for f in funcs])
ch0 = s[0]
samples = [gammavariate(1, 1) for _ in range(n)]
modified = {o: (d1[o], d2[o]) for o in intersect_keys if d1[o] != d2[o]}
result = doSomething()
[i] + t
print(t, fractExpr.parseString(t))
type(a.get_value)
idx = np.argmax(a, axis=axis)
fo.writelines(outlist)
deletedata
d
print(len(line))
f = interp1d(x[indice], y[indice])
rng = np.random.RandomState(rng_seed)
print(len(l))
previous = my_date + relativedelta(weekday=MO(-1))
t = 1.0 / (1.0 + 0.5 * z)
eq_dy = eq_y.diff(x)
self._bytesSent += len(bytes)
pir(a)
url = request.url().toString()
gen1, gen2 = itertools.tee(gen)
hook()
help
hb = hashlib.sha256(json.dumps(b)).hexdigest()
True
ccg
x > 10
print(self.__class__, new_arg)
palette = [1, 2]
line = next(line for line in out.splitlines())
stdout_capture = False
ordered_funcs = sorted(funcs, key=lambda f: f.__code__.co_firstlineno)
Py_Initialize()
_get_dict.restype = c.POINTER(c.py_object)
self.items = paginatable[(page - 1) * per_page:page * per_page]
std = np.std(clf.feature_importances_, axis=0)
code = event.GetKeyCode()
np.lib.stride_tricks.as_strided(a, shape, strides)
HTTPFound(location=url)
defaultdict(tree)
[1.0, 0.0, 4.0],
x[:] = x + y
m[20, 25, 60]
x * 2
xlib.XOpenDisplay.argtypes = [c_char_p]
PyString_FromString(str)
b = []
remote_client.load_host_keys(hosts_file)
not any(map(any, x))
self.overrideredirect(True)
decimal.getcontext().prec = 4
buf = f.read(blocksize)
first_array = batch_xs[0]
print(a)
theme.post_plot_callback(ax)
json_text
requestSucceeded = True
dT.T.dot(dT).A
_PackageBoundObject.__init__(self, import_name, template_folder)
d[ele[0]].append(ele)
n = 10
readable = {masters[0]: sys.stdout.buffer, masters[1]: sys.stderr.buffer}
pairs = []
connector = aiohttp.ProxyConnector(proxy_url)
expressions
intermediate_dict = {}
pdf = stats.norm.pdf(h, hmean, hstd)
X_train = v.fit_transform(X_train_raw)
match = re.search(regex, l)
request.param
grid = grid[first_row:last_row + 1, first_col:last_col + 1]
data_id = dict(zip(unqs, np.arange(data.size)))
uniquify(symbols)
{} == False
print(html_string)
coords = sorted(coords)
result = f(data.values)
self.op = op
euclidean_distance(self.pos, pos)
l = len(Ol)
a.union(b)
a = 0
p.xaxis.major_label_orientation = np.pi / 4
ic = np.random.uniform(0.1, 0.9, L)
self.__class__(self.transform_key, self.data)
insertion_points = numpy.searchsorted(sorted_a[:, (0)], b).ravel()
socket.socket = socks.socksocket
stripped = line.lstrip()
out.append((x, tup[0] - 1))
line = map(lambda i: parts[i][index[i]], list(range(len(parts))))
parts = list(partlst(list(range(1, 15)), 5))
my_dict = defaultdict(list)
count_inside[..., (k)] += k == labels_img[:-2, 1:-1]
print(self.x)
a = 5
new_set = set()
layout.add(everything)
[0, 1, 2]
S = np.split(I, (2, 4, 5))
normalized_map = plt.cm.Blues(h / h.max())
session = scoped_session(sessionmaker(bind=engine, autoflush=False))
drives.append(letter)
df.power200c[6]
ds = sorted(d.items())
samples_fit = stats.lognorm.pdf(x_fit, shape, loc=loc, scale=scale)
ordinal = int(escapesequence, 16)
amp = 8000.0
sorted_taglist = sorted(tag_list)
empty = socket.recv()
lamb.write_lamb(outfile)
in_fd, out_fd = os.pipe()
y_fft = np.fft.fftshift(np.abs(np.fft.fft(y))) / np.sqrt(2 * N)
user
b = np.tile(B, 2)
con.login()
dates.append(row[0])
flipped[value] = [key]
DTYPE = np.int
y = list(x)
i += 1
sys.stderr = RedisFileObject(self.request.id)
b = self.file.read(1)
fig = plt.figure()
data.compress_type = zipfile.ZIP_DEFLATED
k.set_contents_from_stream(buff)
False
b = (a[:, :, (0)] == 255) * (a[:, :, (1)] == 0) * (a[:, :, (2)] == 0) * 1
h
M = cv2.addWeighted(Dx, 1, Dy, 1, 0)
print(letter.substitute(vars()))
print(s)
body
coeffs = C / np.sqrt(np.outer(d, d))
d[(1), :] = numpy.asarray(my_list)
print(df1)
item = queue.get(True)
p = figure()
U = gen.randn(ni, nj, nk)
result[0]
k_arr = np.zeros((10000, 2))
False
delta = len(string2) - len(string1)
10.212458187001175
w = Widget()
factory = XMLInputFactory.newInstance()
x = np.linspace(-1.0, 1.0, 100)
g = np.meshgrid(poro, sw)
sparse_out.todense()
angle_trunc(atan2(deltaY, deltaX))
y[0][0] = 6
rval, frame = vc.read()
mro = type(cls).__mro__
print(output)
autorestart = false
main()
notifications
False
dir(yaml)
new_t = np.arctan2(X, Y)
res *= n - i
mnu1 == mnu2
ars == mnu1
pr.enable()
fn(src, *args, **kwargs)
ceiling -= 1
col.set_array(colors)
sock
self.func = func
utcnow = datetime.utcnow()
cython_my_module
(x for cond, x in l1 if cond), (x for cond, x in l2 if not cond)
newlayer = arcpy.mapping.Layer(theShape)
print(df)
app.logger.exception(exc)
surf(img1, GpuMat(), keypoints1GPU, descriptors1GPU)
interval = 1
mail = Mail()
vpath.pop(0)
A = data.shape[1] - 1
channel = transport.open_session()
err_type, err_value, err_traceback = sys.exc_info()
res = {}
result = instance.Addition()
new_s += chr(n)
quoted_values = cursor.fetchone()
stems
print(-x)
maximum = sum(negatedEven[:d])
nic.SetGateways(DefaultIPGateway=[gateway])
convert = lambda text: int(text) if text.isdigit() else text
mean_norm_sq += np.sum(s ** 2)
reAssessmentTeam = models.OneToOneField(Group)
state = models.IntegerField()
xlim(0.01, 5.0)
A += [nx.bipartite.eppstein_matching(G)]
http_server2 = httpserver.HTTPServer(application2)
results = []
result_list[i].append(item)
scheduler = Scheduler(connection=Redis())
assert number >= 0
the_callable.allow_tags = True
c = [7, 8, 9]
a, b = tee(iterable)
ca_list = []
keptticks = xticks[::int(len(xticks) / 10)]
list(final_result)
self.iditit = True
time.sleep(0.4)
x = 1
weather.check_all(**kwargs)
z[np.arange(4), np.arange(4) + 1] = 2
train_idxs.append(X_train_0[i_1 * stride:(i_1 + 1) * stride].index)
r[(r.imag == 0) & (r.real >= 0)].real.min()
[0.0, 80.0, 0.0],
app = SampleApp()
stuff()
v2 = np.random.randn(200)
op(x[col], n)
x = hi()
max_data1 = max(enumerate(data1), key=itemgetter(1))[1]
api_method(*args, **kwargs)
DELIMITER
self.cert = cert
raise IOError
res.append(C)
model = MyModel
print(a.get_value == b.get_value)
[52], [97], [64], [82], [11], [71], [27], [75], [60], [85], [42], [40]
sp1.add_collection(sympy_p1._backend.ax.get_children()[appropriate_index])
a[4] = -np.inf
doc.appendChild(a)
x = np.random.randn(25, 25, 25)
content_type = ContentType.objects.get_for_model(Employer)
sum2 = sum([(vec2[x] ** 2) for x in list(vec2.keys())])
labels = [c for c in string.ascii_uppercase if c not in exclude]
print(t.overlap_point(-5))
d2[HashableDict(a=1, b=2)]
DUT.should_raise()
job_instance_id = sir.instance_id
args.command(subparsers, args)
r = csv.DictReader(infile, dialect=csv.Sniffer().sniff(infile.read(1000)))
filename = dialog.selectedFiles()[0]
sensors.sort(key=lambda item: item[1], reverse=True)
i = 0
name = db.StringProperty(required=True)
os.makedirs(inner_extract_path)
all_dict.update(dict(zip(ks, k)))
add_it_to_regular_dict
g = g0 + (g1 - g0) * (y - y0) / (y1 - y0)
b_id = [id(row) for row in b]
grps = pd.cut(randint(1, 5, n_rows), arange(1, 5))
shuffle(b)
my_list = my_list[:-1]
updated_fixtures.append(fixture_file)
deletea
self.data[index] = value
cur_seq.append(data[i])
Py_InitializeEx(0)
shutil.rmtree(path, ignore_errors=True)
size -= len(data)
main()()
memodict(f)
x = 200 + 25 * plt.randn(1000)
max_rows = max(1, max_elements / shape[1])
opener = urllib.request.build_opener()
c = w.map(len)
1 * x
raise KeyError(k)
current_size += 1
result = response.read()
result
print(new_word)
project = __import__(os.path.basename(fullpath))
temp.flush()
g = gen()
ssl._create_default_https_context = _create_unverified_https_context
number
inner_str = m.group(1)
TagFactory.create_batch(5, **kwargs)
template = Template(t)
l1 = empty((2,) + a1.shape, dtype=a1.dtype)
out[ix] = f(array[ix])
row_thresh = (nzm[:, 1:] & zm[:, :-1]).sum(1)
print(x.mode)
next(ravg)
dosomethingwithfile(path)
num_images = Image.all().count()
result = []
queryset
result = json.dumps(content)
blah = 1
ROLLBACK
randomized = random.sample(some_set_of_stuff, len(some_set_of_stuff))
ser1 = pd.Series(y1, index=t1)
obj == unpacked_object
klass = type(name, bases, body)
loan = float(loan)
t2 = time.time()
smalls = b[np.isfinite(b)][n:]
Name = str(sys.argv[1])
best = np.inf
conn.quit()
reverse_lookup[v].append(k)
x
win.show_all()
fatcows, thincows = {}, {}
prevnode.right = node.left
c = Child()
result = mp.Queue()
newPos.setY(qMin(rect.bottom(), qMax(newPos.y(), rect.top())))
walkDict(aDict[k], visitor, path + (k,))
decimals.push(last_chunk_length)
my_func(4)
tid = h5t.py_create(dtype, logical=1)
szr.Add(self.button_2, 0, wx.TOP, vgap)
request = Request({})
tree_iter = model.get_iter(path)
image = Picture()
Y, X = gray.shape
numbers = list(range(10, 16))
self.setOperation(operation)
picked.append(random.choice(filtered))
x_list = {key: value for key, value in zip(inputs, x)}
content = contents[0]
t0 = time.time()
chunk = infile.read(chunk_size)
results = [x for x in mem_test()]
a1.substring(0, i)
f = pd.factorize(v)
main()
magnitude = 1 if int_part == 0 else int(math.log10(int_part)) + 1
cell = xl.ActiveSheet.Cells(1, 2)
window.fullscreen()
xs = np.linspace(0, 4, 50)
self.counterclass = self.__class__.jMenuNumber
sys.stdout = self
mm = mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)
gs1 = gridspec.GridSpec(8, 4)
d = defaultdict(list)
window = df.iloc[x]
ret[i] = j
sftp = ssh.open_sftp()
print(dicts)
l = len(x)
intersect_indices_unique(x, y)
1
print(sorted(p))
reply = response.read()
dfs = []
c = a + b
ind = np.argpartition(arr, k)[:k]
transport = client.get_transport()
b.frob(1)
df
BT
print(df.corr())
foo.mock.assert_called_once_with(n=40)
num = np.array([data_id[datum] for datum in data])
process_name = myproj - uwsgi
app = MyApp.sharedApplication()
list_B = []
next(f)
img = cam.getImage()
next(xr)
classed_classes_first = np.transpose(classed_pixels_first, (1, 0))
(row.word,) + tuple(float(x) for x in row.vector.values)
G = nx.DiGraph(d)
cycleobject * lz
model = Sequential()
fr.set_pipelined(True)
num_from_new_number
db.put_async(DB_TempTestModel(data=lots_of_data))
item = bax, count = 2
parts.append([part])
c = (a ** 2 + b ** 2) ** 0.5
A = make_A()
curl.perform()
distance_img = ndimage.distance_transform_edt(threshold)
some = 1
broadcastable = numpy.ix_(*arrays)
-setuptools
X = np.linspace(x.min(), x.max(), len(x) * 10)
fullpath = os.path.join(path, file)
notebook.append_page(child, gtk.Label(label))
print(item)
zip(*[(a, 1, 2), (b, 1, 2)])
foobar()
path.pop()
print(i)
eq_y = P * x + Q + x * x * (S * x + T)
layout.addWidget(button)
result = []
s.rules.append(r)
xmlHttp.send(JSON.stringify(dat))
False
LinkForm(post_data)
print(line)
print(row)
df1
txt
spider = from_crawler(crawler, *args, **kwargs)
func
palette = lcd.palette()
stmt = res[0]
urllib.parse.quote_plus(md5bytes)
w, h = P.wrap(doc.width, doc.bottomMargin)
True
xi = np.linspace(-2.1, 2.1, 100)
procs.append(proc)
d = Week(2011, 40).monday()
pool = Pool()
x = np.linspace(0, 2, 10)
findCount = lambda s, v: len(findSubs(s, v))
df
nums = []
func(elem, *args, **kwargs)
_methC(parm1, params)
a += 1
total
self.clear()
width = stringWidth(string, font, size)
rcode = fh.read()
raise Http404()
fig = plt.figure()
y = np.linspace(0, 10)
print(data)
self.mode = mode
inds = [(x, y) for x in range(nRows) for y in range(nCols)]
func(e)
group = []
self.name
e_reraise = Exception(e_msg)
pp.show()
time = np.arange(8)
match.expand(replace)
result = {}
print(row)
obj = conn.recv()
curl = pycurl.Curl()
job = Job(self, **job_kwargs)
words = list(itertools.chain.from_iterable(w.values))
self.setFormat(index, length, format)
frame = inspect.currentframe()
posts = Post.objects.filter(owner=pk)
self.table.setColumnCount(2)
Foo.bar = foo
xmin = X.min(axis=0)
ch = logging.StreamHandler()
confint = [[] for _ in self.plot_data]
month_dates = list(cal.itermonthdates(year, month))
line
mask = a1 == a2
suite = unittest.TestLoader().loadTestsFromTestCase(MyTester)
_test(len(self.dataDict), lengths)
insert(array[i])
L.append(x)
post_save.connect(MyModel.post_save, sender=MyModel)
ipython
data = request.get_json(silent=True)
self.b = b
translate_table = dict(zip(tabin, tabout))
wb._save(f)
df = sqlc.read
coords = [self.lists[i].index(c) for i, c in enumerate(word)]
u = x.copy()
print(int(tmp, 16))
f = self.queue.get()
writer.writerow(next(cr))
drec
b = Mynum(2)
norm = colors.normalize()
fig2 = plt.figure(figsize=(7, 5))
x, y = p
dfstacked = dfstacked.reset_index(drop=True)
m.__getitem__.side_effect = d.__getitem__
file = file.lower()
members = inspect.getmembers(parent, predicate=inspect.ismethod)
bd = [parse(i, fuzzy=True) for i in bd]
st = set(B)
print(np.may_share_memory(x, xNewView))
self.args = args
t.replaceWith(text)
copy_list = list(org_list)
False
src = values_list[1:]
NULL
complements = []
self.timer.fire()
course_name = StringField()
frame.add(label)
b = a[(-100 <= a) & (a <= 100)]
errorcodes.lookup(e.pgcode[:2])
solve(eq)
hp = hpy()
a = c or b
hist = pd.cut(b, bins, right=True).labels
use_cython = True
z.writestr(info, bytes.read())
linkto = os.readlink(src)
_complicated = dill.loads(dill.dumps(complicated))
numPages = input1.getNumPages()
A = np.append(1, A)
STOCK_APPLY
STOCK_BOLD
STOCK_CLEAR
counter = Counter(yourdictionary)
self.usage_rate_strm = npr.RandomState().seed(seed=self.seed)
childListStack.add(children)
tag.setTitle(item_title)
diff(t, x)
dataframe[inds]
request.remote_addr,
myIterator = cycle(list(range(2)))
True
a.append(b)
PyObject * m
dpkg - S / usr / share / pyshared / numpy / __init__.py
s = origs[:]
print(a)
x2, y2 = [rand_data() for i in range(2)]
min(266, 255)
raise StopIteration
ret[k] = scrub(v)
s1 = float(s)
obj
prstd, iv_l, iv_u = wls_prediction_std(results)
print(res.status, res.reason)
ca_array = (CA * len(ca_list))(*ca_list)
consumer.map(process, producer.imap_unordered(download, urls))
9.625216960906982
11.450419902801514
times.append(trunc)
selected_choices.remove(option_value)
deleteself._x
headers = next(r)
print(array)
i = 0
X, y = make_blobs(n_samples=10000, n_features=10, centers=100, random_state=0)
roll_dice(count=5, allow_repeats=True)
x[()] = y
first_line = f.readline()
day = dateString.day
seq = np.zeros(lag_lens.sum(), dtype=np.int)
funcs = []
col[col.isnull()] = s[col.isnull()]
embed()
classifier = svm.SVC()
s = s[:formula[0][1]] + str(result) + s[formula[-1][1] + 1:]
shout.pop(0)
mySlice = slice(1, 2)
mt = MyTuple([1, 2])
self.layout().takeAt(1)
s.loc[:] = [4, 5, 6]
dic[mk, rgk, nv, ik, ek]
win = MyDialog()
m = mmap.mmap(infile.fileno(), 0, access=mmap.ACCESS_READ)
print(results)
rating = models.RatingField()
group[mask] = group[~mask].mean()
time.resize((n + 1, 2))
runner.run(suite)
c = 1, 2
item_keys = q.fetch(2000)
b.title()
x
recursive_check(url, patterns, names, args)
[choice[:i]] + get_seq_in_tree(tree[choice[:i]], choice[i:])
aws_access_key_id = aws_access_key_id,
self.n_neurons_to_hl = n_neurons_to_hl
today + relativedelta.relativedelta(weekday=1)
m, max_list = key(a[0]), []
co_filename, fname, c.co_firstlineno, c.co_lnotab, c.co_freevars, c
e1 = cv2.erode(im, k1, borderType=cv2.BORDER_CONSTANT)
self.connection = connection
fullname = os.path.join(dirname, f)
draw.ellipse((x - radius, y - radius, x + radius, y + radius), fill=dark_color)
number
self.widget.choices = self.choices
hash_string = myhash(filename)
deque(f(*args, **kwargs))
make_response((body, headers))
self.seconds = seconds
request_token = get_request_token()
Pxx = Pxx[(freqs >= minfreq) & (freqs <= maxfreq)]
w = gtk.gdk.window_foreign_new(id)
i = 1
new_func
velcro = Turtle()
x = [tuple(element) for element in x]
file.write(s)
out[1] = out[1].getvalue()
yesterday = (now - timedelta(day=1)).date()
Root.iconify()
print(li)
print(b)
next(it2)
low, high = [], []
ReturnDict(ret, serializer=self)
new_func
f.baz()
args = parser.parse_args()
s, c = math.sin(theta), math.cos(theta)
M[(1), :] = [2, 2, 2]
print(empty.add(1))
numbers = []
consecutive(a)
num_vowels = 0
self.slug,
dict(review=my_new_review)
xticklabels_example()
chunk.append(line)
legend_handles.append(mpatches.Patch(color=color_val, label=lable_str))
formatter = string.Formatter()
all_lines = f.readlines()
k = j
print()
n01 = sizes2count(np.bincount(b), n) - n11
Particles.remove(particle)
inspect.getmembers(Test, predicate=inspect.ismethod)
X = scipy.rand(9, 4, 1)
y = r * np.sin(theta)
foo.bar = bar.__get__(foo)
[]
e = 1.0
x = (lon2 - lon1) * cos(0.5 * (lat2 + lat1))
pool = Pool(initializer=initProcess, initargs=(toShare,))
test
currentList = []
df
c2 = conn.cursor()
cache.delete(key)
print(table2.columns.intersection(table1.columns))
tt = time.time()
raise ValueError
w, v = self.get_axisangle()
unpad(cipher.decrypt(enc))
w = a.translate(widemap)
lookup_table = dict((k, sorted(d, key=d.get)) for k, d in list(domain_keys.items()))
y = 0
uppercase_attr = dict((name.upper(), value) for name, value in attrs)
result = [(x + [y]) for x in result for y in pool]
utc_dt = datetime.datetime(2002, 10, 27, 6, 0, 0, tzinfo=utc)
temp_df_no_na.logged_dt = pd.to_datetime(temp_df_no_na.logged_dt)
aClk.start(), c * c, aClk.stop()
data = [-1, +1, -1]
print(head)
res_male = pool.map_async(func_m, males)
num = ls.pop()
count = np.zeros_like(unique)
Foo(s)
last_names = [x.surname for x in people]
lambda : tf.constant(0),
library(ggplot2)
elements = a[mask]
fig, ax = plt.subplots()
print(foo, bar)
year = date.year
col_ind = sp_matrix.col
argparse.Namespace.__init__(self, **kwargs)
notes = {name(n): freq(n) for n in range(-42, 60)}
nonrv = []
console_handler = logging.StreamHandler()
print(d)
cert = x509.load_pem_x509_certificate(pem_data, default_backend())
zorder = 1
self._it = iterable
request_queue = Queue()
s
frame.pack()
container[:] = [item[-1] for item in data]
my_dict = tree()
b = np.zeros_like(a)
tck = interpolate.bisplrep(x, y, z, s=0, kx=1, ky=1)
r = s.get(url_2)
c = 2 * asin(sqrt(a))
xmlrpclib.ServerProxy.__init__(self, uri, *l, **kw)
prob_weights = np.random.rand(m, n)
print(type(loc))
cookie = urllib.request.HTTPCookieProcessor(jar)
print(time.time() - current_time)
entering
df
m_to_M = lil_matrix(n_to_N)
self.get_key(user, api_key)
x = data[:, (0)]
meta = MetaData()
print_tree(tree)
jobs = list(range(1, 6))
N = np.linspace(0, 1, 2000)
YEAR = df.YEAR.values.repeat(len(df.columns) - 1),
c = C()
2 * x
keylist.sort()
solve_poly_system([y - x, x - 5], x, y)
painter.save()
raw_value = eval(input())
out = []
argspec = self.argspec
formatter = parser._get_formatter()
print_lock = threading.Lock()
PYSCRIPT
mask = [(True if x else False) for x in df.index if x not in blacklist]
raise InvalidSelector()
request.prepath.pop()
str(buf)
print(txt)
exacts = [user for user in query if user.first == token]
sorted_with_zeroes
response = si.query(expr[:-1])
end = time.clock()
self._app = self.get_app()
result
self.__dict__ = state
i += 1
sum(amino_weight[a] * n for a, n in list(combo.items()))
print(d)
index = 0
a.reverse()
[l[i:i + n] for i in range(0, len(l), n)]
print(astr.translate(deleter))
tform = view.scene.transform
js = [t[1] for t in sorted((v, i) for i, v in enumerate(list1))]
phases[constituentNumber] = constituentEpoch + equilibrium
t = time.gmtime()
t2 = Timer(method2, setupstr).timeit(nl)
__metaclass__ = stringer
print(r)
self.recv_buf_i += sz
round_format % a == str(b)
i += 2
file_str = f.read()
plt.gca().lines.remove(P)
process(ln)
MyArray([(key, self.data[key])])
print([l.strip() for l in list])
self.weapon = weapon
self.done = False
sig_keys = collections.defaultdict(set)
True, self.seconds
self.initial = initial or {}
True
mylist = [1, 2]
wrapped_py_func = CWRAPPER(pyfn)
func_argsort = func_indices.argsort()
g.Category.apply(pd.value_counts)
self._instance = self._decorated()
self._stop = False
wordgen = words(wordfile)
a[b < 100] = 255
x = gamma.rvs(2.5, loc=0, scale=4, size=1000)
enc.encode(doc)
merged
window = display.get_input_focus().focus
p = np.poly1d(z)
search(6000)
self.flag = True
self.get_object = get_object
lst = [a, b, c]
df = shell.SHGetDesktopFolder()
copy_list = list(org_list)
line = f.readline()
convert()
merger.append(filename)
messageName = ident.setParseAction(pushMsgName)
width, height = console.getTerminalSize()
venues = list(Venue.objects.filter())
print(len(solutions))
True
self.servers = {}
i = bisect_left(B, a)
wf.setsampwidth(p.get_sample_size(FORMAT))
count += 1
raise gen.Return(result)
c = sheet.cell(rowx, colx)
t2 = mt.now()
line.append(s)
self.iter = iter
main_doc = html.render()
d = defaultdict(int)
A[:, (second), (third)].shape
indices = [0] + indices + [len(list_)]
df1
self.files[spider] = file
response = get_url(request, encoded_params)
sums = [sum(t) for t in zip(a, a_one, a_two)]
x = f.readlines()
df
quote1.text
baz + blab
2 == False
print(parse_dms_string(INPUT))
self.seconds = seconds
text = _lookup_string(child.text, strmap)
name = Column(Unicode(200, convert_unicode=False))
dlg = tkFileDialog.asksaveasfilename(confirmoverwrite=False)
print((25.4 / 10.0 * 1.0 / 2.54).__repr__())
intersection = required.intersection(set(request.json.keys()))
nexts = cycle(islice(nexts, pending))
writer.add_document(title=title, content=nltk.clean_html(content))
red = _cubic(r, y0, y1)
sim_df
a = 47
SimpleHTTPServer.test(HandlerClass=MyHTTPRequestHandler)
sas.get_denomsas(qs, x, cp, cs, n_comp)
self.pool.submit(self.process_request_thread, request, client_address)
mlist = m.list([m.dict() for i in range(pnum)])
x1, x2 = x2, x1
response
fileObject = FileObject(os.path.join(MEDIA_ROOT, f.Audio.path))
os.kill(self.p.pid, 15)
x0, y0 = handlebox.xdescent, handlebox.ydescent
n_min = max(0, smin // coef1[0] + 1)
t.cancel()
[r(0, lstLen) for i in range(lstLen)]
new_time = new_time.time()
im_mask |= hitmiss(im_binary, kernel)
l_d_n = [[(0) for _ in range(len(d))] for d in docs]
index = triangular(row) + column
pylab.subplot(2, 2, 1)
print(d)
pdf_reader.getDocumentInfo().title
x
a = list(range(-7, 259))
env = Environment()
nodes = set()
company = CharField()
ids = np.ravel_multi_index(a.astype(int), a.max(1).astype(int) + 1)
deleted[-1]
worksheet.write(r, c, x)
wx.App(False)
getDriveMappings()[drive.upper()]
nonzero(t == 8)
colors[x, y] = colortuple[(x + y) % len(colortuple)]
cmp(self.arr, other.arr)
Base.metadata.bind = engine
start_response(status, response_headers)
pairs = zip(p1, pK)
i = 0
cv2.drawContours(ws_bincolor, [rect], 0, color, 2)
to_remove = []
temp = myDict.get(i)
obj = create_new_object(the_key)
end = seq.index(min_value, start)
info = DEF(first_name, last_name)
self.trayIcon = QSystemTrayIcon(QIcon(), self)
mod
x = [1, 1, 0, 1]
bokeh.plotting.curplot().plot_height = 400
model = SecendModel
standardized_data = StandardScaler().fit_transform(data)
a[k] = np.sort(a[k])
fast.addTests(TestFastThat)
clf = SGDClassifier().fit(digits.data, digits.target)
defult_tmp_dir = tempfile._get_default_tempdir()
crawledLinks.add(url)
oldmods = set(sys.modules.keys())
input_char = msvcrt.getch()
most_popular({el: (0) for el in list(range(10))})
A.flags
wrapper.__name__ = func.__name__
result = int(l[1])
values = dlg.getValues()
items.rotate(-1)
col2 = [1.1, 0.5, 2, 7.45]
all(n % j for j in range(2, n))
errors.extend((src, dst, str(why)))
image_new = Image.composite(foreground, image, foreground)
colors = [inferno_t(i) for i in np.linspace(0, 1, parameterToColorBy.shape[0])]
Silly(_fibCache(i - 1).v + _fibCache(i - 2).v)
rt = json.load(f)
page = input1.getPage(i)
transf_pca = sklearn_pca.fit_transform(transf_lda)
user_means = np.nanmean(ratings, axis=1)
cell.alignment = alignment_obj
pat = match.re
n = max(len(master) - len(addition), 1)
y = [4, 5, 6]
form_class = BookForm
user_sessions = []
region_dict = defaultdict(list)
print(result)
data = data.ravel()
urls[url] = urls.get(url, 0) + 1
output_encoding = sys.stdout.encoding
sort_articles_by_date(articles)
print(popt)
parse_layout(layout)
somelist.append(item)
main.html
customer2 = sqldb.system.CustomerUser()
lamb.write_lamb(outfile_path)
app = Flask(__name__)
b = {a: 1}
ratio = 2 / 5
array_repr(M)
stderr_thread.start()
prevnode.right = node.right
x = np.array([0.0, -0.75])
ordering = models.IntegerField()
self.price = price
list(filter(str.isalpha, mylist))
d.addCallbacks(result, error)
foo(a, b)
self.parent = parent
[Icons]
injector
charNullBlank = models.CharField(max_length=10, null=True, blank=True)
D = nx.Graph()
Foo().spam
spider.crawler.engine.crawl(Request(url, dont_filter=True), spider)
_lock = threading.Lock()
list(group.users.keys())
elements[1].click()
True
eggs = db.List
process.start()
in_memory_blocks[:blocks_per_flush].tofile(f)
print(line)
msglist = []
repos.index.add([submodule])
print(url)
args = []
self.cnt = 0
obj
print(sorted(self.names))
inst.append(row)
[n - d - c]
a.join()
users[name] = User(name)
workflows
a = sorted(a, key=lambda a_entry: a_entry[1])
FCS_FORCEWRITE = 2
b = Bar()
two_days_ago = datetime.now() - timedelta(days=2)
a, b = x[:-1, :], x[1:, :]
False
maxcoord = np.amax(coord, axis=0)
self._set_headers()
lines = os.read(fd, 4096).splitlines()
np.random.shuffle(labels)
mask[start:stop] = False
factorise(4998)
df
raise Exception
sess.run(train_op, feed_dict={am_testing: False})
after_buf.append(after)
irows, icols = np.indices(a.shape)
labels = [0] * len(negatives) + [1] * len(positives)
user = User.objects.get(email=email)
cur = con.cursor(mdb.cursors.DictCursor)
a = sheet.write(row, 5, L[:-1])
tests.addTests(doctest.DocTestSuite(my_module_with_doctests))
num = 1
c_len[elt[0]] += 1
print(myList)
all_ = itertools.zip_longest(zeros, ones, fillvalue=np.array([]))
print(orfs(Seq))
f2 = Foo()
res += chr(idx)
article4
article5
article6
var_dic = {}
num_vowels
fig.colorbar(im)
model = models.Photo
data = QueryDict(stream.read(), encoding=encoding)
cr = bitmap.cairo_create()
self.y = y
print(i, 2 ** i, int(2 ** i / 1.5))
PythonEngine.Initialize()
foo_arg = 4
re_multiline_macros = re.compile(start + continuation + lastline, re.MULTILINE)
array[i] = i
self.store.number += 1
ide.append([])
self
xy = np.random.random(2 * num).reshape(num, 2) - 0.5
items = []
instance.MyMethod()
num_tests = 10 ** 5
handle_line(previous)
2 - test12.txt
xldays = int(xldate)
print(smults)
(l for l in open(path)) if opath.exists(path) else ()
bar = map(float, foo)
objects.popitem(last=False)
attrnames = []
manager.addMarkers(m, 10)
(2)()
self.scroll.setWidget(scrollContents)
choice = self.choices[idx]
result = []
null_ptr = POINTER(c_float)()
string_view_iterator()
id(a) == id(b)
x = -1
print(reshape(validate(data, length)))
item = item_q.get()
True
self.path.updateElement(self.index, value.toPointF())
getrandbits = random.getrandbits
text
pprint(p.contents)
order = db.IntegerProperty()
con = httplib.HTTPConnection(proxyHost, proxyPort)
self.serialWrite.connect(self.serialc.writeData)
twrite = threading.Thread(target=write_output, args=(q.get,))
rebuilt_to_plot = []
df
fig.colorbar(heatmap, cax=cax)
lines = StringIO(buffer)
self.assertEqual(path_to_text_base, wc.get_pristine_copy_path(path_to_file))
b = [1, 2]
data
new_int = hex_int + 512
ndims = len(start)
b = params[1]
raise NotImplementedError
item = tuple(item)
im2 = im.resize((500, 100), Image.NEAREST)
token.user, token
y_crossings = np.zeros(x_crossings.shape)
result = []
s1 = set((0, 1))
job.minute.on(2)
0.18181818181818182
first_sample = s[-10:]
traceback.print_exc(file=sys.stderr)
sum(col * col)
reader = csv.reader(csvfile)
itp = interpolate.SmoothBivariateSpline(X_table, Y_table, Z_table)
defl = cls.default
anf = self.mustignore[n]
obj
first = next(iterable)
host = fig.add_subplot(111)
numbers.add(0)
obj = __new__(cls, *arg, **kwarg)
s = socks.socksocket()
df_multi_col = df.T.reset_index()
print(xml)
chunk.append(line)
f.close.assert_any_call()
name = CharField(max_length=20)
keypress(control_f4_sequence)
btn.my_click.connect(btnclick)
self.left = self.right = 0
staff_engine = create_engine(url2)
lx = SgmlLinkExtractor()
code = loader.get_code(mod_name)
total = 0
cryptography_distribution = CryptographyDistribution()
trueList = []
[foo], {}
self._func(x)
np.sin(t)
res = []
a = 1
do_other_stuff_not_in_the_daemon()
self.form.admin_site = admin_site
convert = lambda text: int(text) if text.isdigit() else text.lower()
self.fp1 = open(self.file_1[0], self.file_1[1])
_stdout = sys.stdout
d0 = date(2008, 8, 18)
even = list(end_of_loop() if n == 412 else n for n in numbers if 0 == n % 2)
r[1], r[2] = False, True
out = []
pkg.b
print(sub_tree.children)
self.a = 10
5
process.stdout.write(data)
print(i, len(i))
df
m.update(str(fn_src))
x + y
result[index] += d[index]
total = y_vals[0] + y_vals[-1]
intersect_AC = A.intersection(C)
clf2.score(digits.data, digits.target)
_cache[args] = f(*args)
False
nextbase += 1
a[i - imin] = bins[i]
volume_norm = np.linalg.norm(indata) * 10
c = a + b
self.mps_in_process = []
0.4 / 100.0
False, stderr
predictions = my_inference(images_batch)
[obj for obj in gc.get_objects() if id(obj) == 91056560]
seq = np.convolve(seq, regular_sequence)
POOL.map(f, list(range(10)))
arr = np.random.random((N, 2)) * np.logspace(-2, 2, N)[:, (np.newaxis)]
self.done = []
entries = []
g_arr = g_arr.swapaxes(0, 1).swapaxes(1, 2)
fig = plt.figure()
random.shuffle(A)
result = result.replace(upper_match, corrected_link)
x.append(j)
p = Process(target=worker)
g = Learn(X, y).guess(X)
print(ceil(d * m) / m)
name, score = ast.literal_eval(s)
a_colors = cmap(norm(a))
studentform.student_id = student_id
count += i
header = f.readline()
cur
posts = []
y_series = hstack((y_series, record_y))
myList = list(range(1, 101))
coords = np.column_stack(nz)
d = defaultdict(list)
user = User.select().dicts().get()
st.f_bavail * st.f_frsize / 1024 / 1024
fig, ax = plt.subplots()
conjunction = np.logical_and.reduce(same_mask)
james.lastName
counts = {k: (0) for k in names}
root = Tkinter.Tk()
x = 1
s = sched.scheduler(time.time, time.sleep)
assertDeepAlmostEqual(test_case, v1, v2, __trace=repr(index), *args, **kwargs)
A = A.view(A.dtype[0].base)
[-1, -1, -1, 1, 1]
r
raise CertificateValidationError(repr(server_cert))
z = np.array([0, 0.5, 1, 0])
__iter__
pdf[x] += y
list(accumulate(seq, lambda x, y: y if y else x))
current = []
print(y)
b.prerequisites.add(a)
tmp_dir = tempfile.mkdtemp()
main()
dev.detach_kernel_driver(intf)
stuff, word = m.groups()
links = line.split()
self.rules = {}
self.a2_edit = QtGui.QLineEdit()
N = [x for x in T if x in S]
digits = list(filter(str.isdigit, input_string))
lonlat = np.dstack([lon, lat])
result, shard_iterator
to_process.append(n - 1)
walk_dict(v, depth + 1)
my_dict[v].append(k)
print(a)
my_age = int(eval(input()))
self._norm = 1.0
print(mastercard_percent)
a
d = match.groupdict()
beingimported = set()
darray[key[0], key[1]] = value
print(find_prev_next(list(range(10)), 10))
x = Point(1, 2)
new_rhs = sympy.sympify(0)
app.autodiscover_tasks(lambda : settings.INSTALLED_APPS)
key[1] = 255
print(sample)
print((name, size))
lens.append(len(t))
sum(bool(key(x)) for x in iter)
new_dict = dict()
wx.Panel.__init__(self, parent, -1)
x = firstguess
-10
df
model = Settings
ip = c_int(0)
info = parse_currency(v, c)
driver = webdriver.Chrome()
mc = MyClass()
self.name = name
optval = optval.strip()
mask = x < 0
output_sent = extract_chunks(tagged_sent)
jira = JIRA(options)
print(param1)
first = df.index.min()
sstring = sstring.lower()
id = db.IntegerProperty()
query = haystack.backends.simple_backend.SimpleSearchQuery
grid = wx.BoxSizer(wx.VERTICAL)
c = ConfigManager()
self.last_match = re.search(pattern, text)
msglist = []
actions = [obj() for obj in Action.__subclasses__()]
session = Session()
node.set_next(Node(node.get_data() + sum_of_digits))
sock.connect(address)
samples = np.empty((0, 100))
bar = {b, a, c}
h[6]
lsi = models.lsimodel.LsiModel(corpus=corp, id2word=dictionary, num_topics=400)
header_id += 1
l.append(B())
k -= 1
prefix[s] = 1 << (i + 1) * 10
os.dup2(stdout, 1)
h5.close()
record.tid = tid
session = self.session_factory()
iter(self.data.values())
df
args = parser.parse_args()
self.q += learning_rate * np.dot(e.T, self.p)
sys.stdout = old_stdout
common_neis[u, w] += 1
result
logp = -0.5 * (df + d) * np.log(1 + np.sum(np.dot(Xm, V_inv) * Xm, axis=1))
self
print(user.post.genre)
sum_ += 1
console.log(conn.parameters.From)
Python - IPython
t[a[k][0]][a[k][1]] = 42
x = BO
Base = declarative_base()
ax = fgrid.axes[0][0]
print(np.allclose(A1, A2))
plt.bar(i, val, bottom=y, color=colors[key])
radix = len(alphabet)
dfm = df.mask(np.triu(np.ones(df.shape)).astype(np.bool))
print(df)
point = geom.Point(0.8, 10.5)
bonds
x = [0]
tuple(result)
obj
max_e = math.log10(max)
m = 2.2 * n / np.log(n)
print(reorder_copyright(line))
mask = [1] * len(arr)
mydata = fh.read()
threading.Timer(1, lambda : os._exit(0)).start()
print(a)
x = list(range(7))
print(find_prev_next(list(range(10)), 1))
print(var_one)
ipshell = IPShellEmbed()
request.data,
self[index]
requestSucceeded = False
response.content, file_name
connection = pika.BlockingConnection(pika_conn_params)
mylist = cityIndex[cityName] if cityName in cityIndex else []
HttpResponse(t.render(c))
norm = MidpointNormalize(midpoint=0.5, vmin=0, vmax=1)
self.quitting = True
self.e_isset = 1
model = MyModel
obj = tuple(obj)
self.target = target
{}
y = np.sin(x)
on_locs = list(filter(is_valid, combinations(list(range(size)), num_on)))
[b]
maxrowind.append(r.indices[r.data.argmax()] if r.nnz else 0)
print(item)
raise KeyError
res = A[:, (B)]
rsa = RSA.load_pub_key_bio(bio)
screen = Screen()
do_something_else()
similar(a, b)
sent = sent.split()
temp[c] = a[k][c]
self.iterable = iterable
D = scipy.zeros([40, 40])
print(sd.convert_tree(str(nltk_tree)))
t1 = timeit.Timer(stmt=stmt1)
AClass.__instance.append(self)
Session = sessionmaker(bind=engine, autoflush=True)
d.b == s2
char_counts = defaultdict(int)
combos.append((x,))
tag.setArtist(artist)
config = ConfigParser.ConfigParser()
data = stream.read(CHUNK)
start = geo2cart(latrand, lonrand)
sock.setblocking(0)
user[k] = merge(user[k], v)
keys = list(mydictionary.keys())
invoker.invoke(func, *args)
parser = etree.XMLParser(remove_blank_text=True)
pool.apply(example_main)
self.x * self.y * z
idx = diff.argmax()
binary_insert(r, Node(7))
self._deletes = set()
logger.addHandler(log)
c_sum[elt[0]] += elt[1]
pipeline = set([pipelines.Save, pipelines.Validate])
x = linspace(0.01, 20, 1000)
dumps(f)
rootLogger.addHandler(fileHandler)
type.__new__(uniquemcl, *a, **k)
eval(conditions)
t = threading.Thread(target=run, args=(fd, q))
fig, ax = plt.subplots()
cls._from_ldap(ldap_data)
minimize(objective, fit_params, args=(x, data))
rows = ws.range(cell_range)
marginal_cost = sum(not tutorial.issubset(s1) for tutorial in tutorials)
header.write(data)
leglines
b.shape
evens_odds = sorted(list(range(10)), key=even_odd_key)
new_end = end + datetime.timedelta(days=1)
t1 = tuple(sorted([42, 666]))
response = flask.make_response(something)
new_lst
print(j)
words_found
hash(self.parts)
-1
doc.poll()
it = iter(L)
a < -b
1, 2, 2
client_mod = form.save()
print(files)
write_samples(output_wave_file, mixed_samples, sampwidth)
int(_hexlify(bytestr), 16) if len(bytestr) > 0 else 0
fileobj.write(response.read())
start = time.clock()
proc_num = os.fork()
input_x = np.random.randn(100, 2)
hi = len(a)
rects = find_face_from_img(frame)
coll.save(doc)
obj = MyContainer()
test.test
value = row[0]
m.end_of_track()
1 + 6
exit()
colsums.index = rowsums.index
response = h.getresponse()
_plugins.extend(valid_plugins)
self.y = y
results = [res for res in cursor]
__metaclass__ = Meta
pipeline.set_state(Gst.State.PLAYING)
ruamel.yaml.round_trip_dump(d, sys.stdout)
get_info(Foo.__init__)
getting_text()
dtype = numpy.dtype(dtype)
listA[1]
count_inside[..., (k)] += k == labels_img[:-2, :-2]
print(sheet.title.text)
max_width, max_height = surface.get_size()
n = 56789
indices = np.argsort(importances)[::-1]
xTrain = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
h = exp(arg)
results
word_list = []
line = line[0]
mc.set(key, value, 60)
v1 = 0.00582811585976
plt.grid(True)
v -= 1
data
sel = scrapy.selector.Selector(response)
df2[~df2.key.isin(df1.key.tolist())]
urllib.parse.urlencode(params)
config = {}
data = json.load(f)
print(db_list)
d()
train_writer.add_summary(summary)
lcm = 2520
suite = unittest.TestLoader().loadTestsFromModule(test.test_prog)
ys = [np.array([i, i + 1, i, i + 1]) for i in range(N)]
z = 1.0 / x
Descr = Application.ActiveDocument.Tables(2).Cell(n, 2).Range.Text
b = np.random.randint(4, size=1000)
ranges = []
nums[nums[0]], nums[0] = nums[0], nums[nums[0]]
areasum = 0
buf = File.read(1048576)
self.count
prev = self.getInitial()
rec = line.strip().split()
random.random()
full = [i for i in lst1 if i[:2] not in second]
print(msg)
theta = np.arctan2(y, x)
locals.update(frame.f_locals)
n = a.size
x = x + 1
a.flatten()[5] = 77
data = []
countec[thisec] = thiscount
True
start = (n + size - 1) // size
results = pool.map(calc_dist2, grp_lst_args)
self
q = PPool(4)
cuml.append((total_weight, item))
perfect_corr.append(col)
seen.add(w)
mo = self.OPTCRE.match(line)
things = get_things_for_processing()
G = nx.Graph()
print(someDict)
c = C()
distance
print(x & y)
pprint.pprint(groupedData)
count = 0
A = np.random.randint(0, 255, (sizeOfArray, sizeOfArray))
wrapped_f.count += 1
colormap.SetVectorModeToMagnitude()
deleteiterable_map[key]
df_starts = df_starts.reindex(full_index, fill_value=0)
unmarked = []
pyplot.subplots_adjust(hspace=0.4)
glMatrixMode(GL_MODELVIEW)
hex(id(stream.getvalue()))
float(number_as_str[:end_of_number])
et = ET.fromstring(magic + html)
res[1::2] = l
Serial.println(d, BYTE)
output.writerow(dict((fn, fn) for fn in headers))
points = np.where(filled_grid != 0)
int(f)
print(y)
cache[to_calc] = np.linalg.norm(to_calc)
width = 1
test_suite.addTest(unittest.makeSuite(ConfigTestCase))
s = f.read(1024)
deepest_list = tmp_deepest_list
a[k]
benchmark(checkio_shashank_impure_regex)
x[invert(small_indices)] *= 10
i -= 1
password_input.send_keys(password)
m = min([a for a in map(sum, perms) if a >= half_sum])
print(i)
lst = []
df.Phrase.str.len() == 0
op = sess.graph.get_operations()
c = a + b
ex = c_double(0)
obj = myobject()
self._defaults[self.optionxform(key)] = value
new_idx = np.random.randint(available_locs)
s = a.read()
bound_f = partial(f, 1)
ind[ind >= array_shape[0] * array_shape[1]] = -1
pd.Panel(d)
print(mystring)
reader = csv.reader(f)
n = int(sys.argv[1])
xy = np.column_stack([xcorners, ycorners])
self.updated_on
df1
print(df)
x.set_diag(0)
setattr(self, arg, kwargs.get(arg))
dates, vals = IT.izip(*data)
img.floodFillColor(geo, color)
set_of_sets = set([a_set, b_set, a_set_copy])
df
self.name = name
r = circle_r * (2 - u if u > 1 else u)
last_chunk_length = len(chunks[-1])
h.get_starttag_text()
print(name)
jsonify(response)
print(x)
b = [6, 7, 8, 9, 10]
mkl_set_num_threads(4)
i = next(it)
self.visited_ids.add(id(self.current))
numer = ((df == df.shift(-1)) & df.notnull()).sum(axis=1)
i -= 1
update_b = tf.assign(b, c + a.read_value())
llslice = ll[1:-1]
conv -= conv.min()
foo = Foo()
self.serialc = SerialCon()
groups = [list(g) for k, g in groupby(a_ints, key=lambda x: x // 10)]
print(i)
green_list = []
x = pd.rolling_min(arr, window)
rw = gtk.gdk.get_default_root_window()
obj = MyClass()
first = itemgetter(0)
histogram = np.bincount(digitized)
aa = sps.csc_matrix(a)
image = image.crop((l, 0, l + nw, nh))
d = np.zeros(N)
print(args.positionals)
-constants.py
{{form.id.as_hidden}}
player = get_player_input()
gen = JSONEncoder._iterencode(self, obj, markers)
print(s2_out)
nges_uneval = Sum(n[i], [i, 1, numSpecies])
items = list(range(n))
reps = 2
snake.update(UP)
print(tests.test_001)
smtp = smtplib.SMTP(mailhost, port)
nums[0], nums[nums[0]] = nums[nums[0]], nums[0]
datalines_int.info()
print(name)
fid.close()
sha = hashlib.sha1()
merge(r1, r2, lambda a, b: a or b)
sum(x)
B = A.copy()
self.x = x
ltb = [int(s) for s in b.split() if s.isdigit()]
edgePoint.y += yFactor * (aa / 2.0) * tanTheta
self.value == other.value
foo_1 = relationship(Foo, foreign_keys=[foo_1_id_1, foo_2_id_2])
tweet = next(c)
ax = cum_edits.plot()
out = child.stderr.read(1)
f.readline()
teacher.save()
f = StringIO.StringIO(scsv)
image_center = tuple(np.array((image.width / 2, image.height / 2)))
print(powers_finder(14))
pip - V
print(c.base is b)
edge_list = set()
data = p.stdout.read(1024)
manager = Manager()
filtered_array
print(path)
master = pd.read_csv(path_2)
print(total)
print(transformer.transform(trainVectorizerArray).toarray())
partialLine = lines.pop()
node_list += d[v]
sigs[0] = 2 ** (signal.SIGINT - 1)
foo = ExtendedFoo(1, 2)
user = self.get_current_user(info=info)
a = 0
tmp = L[a:b]
encoded_data = base64.b64encode(data)
result = []
mytest
index = T.lscalar()
y1 = int(math.floor((canvas_height - old_height) / 2))
cls._baseclass_.__init__(a)
not_self.negate()
y_vals = lam_x(x_vals)
f1 = sigma * (y - x)
print(res)
self.x = x
o = c()
s2 = set([9, 0, 5, 1, 8, 2, 7])
next(iterator)
xsgn * np.around(mantissas, decimals=sigfigs - 1) * 10.0 ** intParts
raise ArgumentError(action, msg % type_func)
all.append(randnum)
qr_loader.add_data(data)
first = lambda x: lambda y: x
parser = optparse.OptionParser()
r.json
st = os.stat(path)
TailCall(factorial)(n - 1, n * prev)
allcount += max(counts)
circle_surface = pygame.draw.circle(COLOR, RADIUS, WIDTH)
1 / 2
rf = cPickle.load(f)
4
self.user = user_obj
a_shifted = np.roll(a_copy, shift=hor_shift, axis=1)
self.panel = wx.Panel(self)
self.result = result
lines.plot()
nextline = next(f)
print(root.foo)
size = 128, 128
fp = a.get_level_values(0)
index = {}
formatter.add_usage(self.usage, self._actions, self._mutually_exclusive_groups)
ret = {}
number_of_weekends = (end_date - start_date).days / 7
mydoc = zipfile.ZipFile(file)
vi / usr / lib / systemd / system / ipython - notebook.service
point_symbolizer.allow_overlap = True
form = AddClientForm()
sid = transaction.savepoint()
print(V[near(D, 1.0)])
t = np.arange(0.0, 2.0, 0.01)
l_pnt2 = [(-x, -y), (x, -y), (x, y), (-x, y), (-x, -y)]
helpers.bulk(es, k)
collection_entity = Collection.objects.filter(identifier=identifier).get()
self.store[self.__keytransform__(key)]
+(K - 1) * 1 * d[K - 1]
htmlText = page.read()
V = np.zeros(n)
np.random.seed(42)
result.write(form.format(*map(str.rstrip, lines)))
matches(PATTERN.search(text))
self.write(s)
self.bytes = 0
data = numpy.random.randn(10000)
self.gen = func(*args, **kwds)
auth.authenticate(code, redirect_uri, client_secret, resource=resource)
filtered = [last_str]
params = np.asarray(params).flatten()
lmap = lambda func, *iterable: list(__global_map(func, *iterable))
filters = pt.Filters(complevel=complevel, complib=complib)
[]
self[self.find(self.namespace) + len(self.namespace):]
time_obj = parse(time_str)
ret = {}
J = nx.gnp_random_graph(n, p)
uuid = Column(String(128))
np.nanmin(v), md - whisker, md, md + whisker, np.nanmax(v)
m
tuple_list
self.setGeometry(self.geometry() + hack)
position = [0]
rv
rand = np.random.randint(0, N, size=(t, iters))
a = list(range(100))
s = gmpy2.mpz(4)
im = Image.open(imname)
temp_dict = {}
print(split[0])
i += step
b_new[1][index] = value
self.interval = settings.POLLING_INTERVAL
proxy = True
i4 = [1, 6, 7, 8]
w = w + len(words)
text = index.data(QtCore.Qt.DisplayRole)
count_inside[..., (k)] += k == labels_img[1:-1, :-2]
self.widget = widget
arr.shape
enc = MyEncoder()
{}[key]
pending = len(iterables)
-simplest_fraction_in_interval(-y, -x)
server = SocketServer.ThreadingTCPServer((HOST, PORT), MyTCPHandler)
X
scale = int(-math.floor(math.log10(abs(n))))
print(result)
print(v)
l = [True, True, True]
posargs = (next((ifargs, iargs)[i in list_of_index]) for i in range(nargs))
assert_frame_equal(csvdata, csvdata_old)
db.close()
self.w = w
decoded_data == data
df
bins_log_len = np.r_[bin_edges[1:] - bin_edges[:-1], 0]
distances[i][j] = sumsquares
self.left = left
valid_combinations = [(i, x) for i, x in enumerate(PROD) if x == M]
son[key] = encode_custom(value)
print(frame)
retcode = process.poll()
counts = asarray([date_dict.get(d.date(), 0) for d in dates]).cumsum()
sun = Sun()
print(a._shape._dims[1]._value)
keys = list(to_sort[0][1].keys())
key = lambda x: x
print(temp.name)
df.columns = df.columns + 1
c = -0.0
result.append(port)
axes[0, 1].set_title(1)
s = set()
string_copy[step], string_copy[i] = string_copy[i], string_copy[step]
group_length = len(all_combinations) // r
root = lxml.hmtl.fromstring(the_html_above)
oldMethod(self, **kwargs)
out_view[i] = in_view[i] + i % 10
getcontext().prec = len(x)
txtarr.extend(random.randrange(256) for x in range(len(txtdata) - pixelcount))
im = im.resize((16, 16), Image.ANTIALIAS)
tx_megabits = int(tx_bytes) * 8 / 1024 / 1024
x = method.delay(1, 2)
populations[k] = np.random.normal(loc, scale, n)
True
self.name = name
mutable_list.append(item)
alpha2Scaled = alpha2 / 255
decoded = base64.b64decode(plain)
bounds = [-6, -2, 2, 6]
d = {}
h.itemset(i, j, 1, 0)
q = Queue()
1 << n & x ^ x
arr = arr + imarr / N
new_d = defaultdict(int)
self.mate = mate
rsrcmgr = PDFResourceManager()
print(sys.version)
id2 = csv.reader(open(os.path.join(perf_dir, id_files[1])))
d = {}
ylen = 16
set_x(x * 2)
set_mode()
env = {}
n = 2
y
slice2 = slices[:]
result = multiprocessing.Queue()
x_tag = get_next_permutation(starts_with_zero, zeros, ones)
content = Column(Text, nullable=False)
p, k = Phi.shape
x is np.nan
diff[diff < 0] = np.inf
circlePoints.append(point)
recall_accumulator = []
printcounter += 1
net.addConnection(FullConnection(inp, hidden0))
std2 = g.std(0)
nested = defaultdict(dict)
str
self.string = string
d[k] = sub
realconn.set_isolation_level(old_isolation_level)
a[i] = s.strip()
[www.domain.com]
os.remove(outfile_path)
vc = s.value_counts()
request.token = token
linecount += 1
a = choice(count_list)
a = list(range(100))
self.runner.readyReadStandardError.connect(self.newErrInfo)
instance = YourModel.objects.get(pk=pk)
srctext = srctext.split()
t2 = timeit.Timer(stmt=stmt2)
counter[name] -= 1
FAILED(failures=1)
dDec = uniform(-0.0001, 0.0001)
[A for A in x if A not in y]
counts = arange(0, len(list_of_dates))
row = next(reader)
jsonify.is_safe = True
chrCounter += len(line)
False
nowstring
a[:[(x[0] == x[1]) for x in zip(a, b)].index(0)]
c = Counter(list(mydict.values()))
counts[i][crit_view[j]] += vals_view[j]
np.random.seed(42)
self.y = y
self._instances
pool = mp.Pool(n_cores)
cj = CookieJar()
self.goodFood.append(food)
second_largest([1])
print(binary_info_hash)
tree = ast.parse(source)
phi = [lambda x: x ** 2, lambda x: x]
c = secret_number(4)
data = np.fft.irfft(data)
pool.join()
wand.sequence.append(two)
codecs.open(fullname, mode, encoding)
infourl
themax = value
native.strftime(format)
result[-1] = m
my_day = datetime.date(2014, 7, 15)
t = xs.sum()
a1, a2 = 1, 1
self.impl.length = 16
a = np.random.randn(i, j)
rgt = list(reversed(lft))
self.name = name
cd / usr / src
val % 4294967296 >> n
{{caller()}}
typical_aces[mask]
res[::2] = seq
is_type(df, np.float)
arr[0][1] = True
estimated_sigma = s
dom.childNodes[0].childNodes
data = data[tuple(ind)]
args = parser.parse_args()
month = integer.copy().addParseAction(rangeCheck(1, 12))
memo[x]
a = parray[0]
logger.addHandler(memHandler)
mpl.imshow(e)
somethingUseful
es.indices.create(index=config.elastic_urls_index, ignore=400, body=settings)
ld = list()
links
obj = A()
D[-1] = 2
lerp(x1, x2, v)
sig1, sig2 = gaussian_filter(sig1, sigma), gaussian_filter(sig2, sigma)
lst.extend([(i + 1) for i, v in enumerate(repeat_values)])
b = 1
print(df)
result
foo.delay = 1
xml1 = etree.fromstring(xml_string1, parser)
1,
sys.stdout = f
glEnable(GL_DEPTH_TEST)
final_subnets.extend(list(s.subnet(24)))
result
my_related_object = RelatedObject.objects.get(egg__pk=1)
x / y
print(nltk.ne_chunk(sent))
len(str(num))
times.map(lambda x: x + Minute(59 - x.minute) + Second(59 - x.second))
connection = Connection()
day = relativedelta(days=+1)
not is_odd(i)
listing = db.session.query(Listing).get(listing_id)
c = pl.scatter(x, y, s=r, c=color, alpha=0.5, animated=True)
next(self._generator)
data_batch = tf.batch([data_node_debug], batch_size=2)
i += 1
print(perm_list_gen)
response
ABW.csv
[_ for _ in x if _ not in y]
args = request.args
api = gcs.provider.get_api()
c[:1048576]
FACTORY_FOR = Post
print(args)
__items = {}
g = _chkarg(g)
q = tf.FIFOQueue([tf.uint8, tf.uint8], shapes=[[], [22500]])
tuple(map(S, x))
start(root)
uni.add_node(u)
159584844
c[i]
content = models.OneToOneField(Content, primary_key=True)
upper_limit = lower_limit + dt.timedelta(days=num_days)
__metaclass__ == suitable_metaclass
suite1 = unittest.TestSuite(testCases)
objects = collections.OrderedDict()
data[school] = []
conn.setopt(pycurl.POSTFIELDS, post_body)
new_result = []
bl1.append(eval(bstr))
sys.stdout = UTF8Writer(sys.stdout)
namespace.update(frame.f_locals)
df_out
non_unique = {kk: vv for kk, vv in list(indices.items()) if len(vv) != 1}
{protocol, _, internal_port, foreign_ip, foreign_port}
self._hash
self.queue = deque([])
outdata[i][j] = indata[i][j] * 4
i = 0
C = ((A.T * A - sum(A).T * sum(A) / N) / (N - 1)).todense()
hello
-db
print(count)
1
http = httplib2.Http(cache=custCache)
time.sleep(5)
_wrapped_view
B.append([list])
y = ecdf(x)
buffer = create_string_buffer(bytes)
images = tf.expand_dims(float_image, 0)
web.input(*list)
pathname = os.path.join(srcdir, basename)
test(largestpossible)
False
point = wkb.loads(bytes(lake.point.data))
fname, _ = os.path.splitext(zip_name)
self.get_section_links(response)
np.take(lut, image)
most_popular({el: (0) for el in list(range(100))})
print(cj)
idx = aapl.index.values
sender._meta._field_name_cache[:] = sender._meta._field_name_cache[:-1]
kernel_1d = kernel_1d / np.sum(kernel_1d)
trials = [2, 2, 2, 8, 8, 4]
params = []
myList
pixmap2 = pixmap.scaledToWidth(64)
form = TwitterUserForm
ret = []
deletesubprocesses[self.pid]
axes.add_artist(vel_arrow)
DNAseq[current_4mer] += 1
myFloat = float(floatAsStr)
asyncio.set_event_loop_policy(gbulb.GtkEventLoopPolicy())
l1(2)
total = X.shape[1]
orig_dict
np.unravel_index(52, (m * n, l * k))
time_d_min = time_d / datetime.timedelta(minutes=1)
response = br.open(url_index)
rwa = 1
res = res.sort_index(axis=1, level=1)
x = len(word)
formattedJson = json.dumps(results, indent=4)
what_bson_type(sys.maxsize)
print(hrefText)
print(grouper(4, t))
sourceiter = iter(iterable)
value = getattr(model, key)
inner
lt = operator.gt if reverse else operator.lt
c2 = dict(c)
worker.deleteLater()
divide(arr, 0, m)
bla.login()
ren = Gtk.CellRendererText()
a = pd.DataFrame(a)
request_repr = filter.get_request_repr(request)
ARRAY_TO_LIST(int, V)
amount = int(float(amount) * 100)
masses = np.arange(N)
factory = ProxyFactory()
b = A()
new_a
seen = set()
self.exhausted = True
categories[bisect.bisect(points, 50)]
host_base
position = 0
unique_idx, mov_avg
rv2 = stats.gamma(a, loc=loc, scale=scale)
110000
585
111100
101111
111101
4681
spoofed_ip = sys.argv[2]
self.name
m[k] = empirical[o, k]
all(brute(n) == easy(n) for n in range(10 ** 6))
x = np.zeros(m[0].shape, m[0].dtype)
b = a.T
request = Request(link, callback=self.parse_resp)
cell_value = worksheet1.cell_value(row, col)
cettime = datetime.datetime(2010, 1, 1, 12, 57, tzinfo=cet)
obj[x] = make_str_unicode(obj[x])
m = m.astype(bool, copy=True)
previous = match.start()
img = ImageChops.difference(img1, img1)
foo.insert(2.5)
self.text = self.text.replace(value, label)
output_s = output.read()
engines = []
self.fields[key] = {}
peekables = [peekable(it) for it in iters]
z = x, y
categoryNumber.append(label)
size += len(data)
frames = []
it = iter(seq)
x, y, yerr = np.rollaxis(data, axis=1)
s
parentMap[child] = parent
sys.exit(1)
AlwaysBuild(test)
registered_plugins
my_filtered_fruit = [x for x in my_filtered_fruit if pred(x[1])]
True
w = Window.partitionBy(df.k).orderBy(df.v)
s_sum = 1
print(form)
Py_DECREF(w)
N = int(n)
start_date = datetime.datetime(2015, 8, 22, 14, 24, 29, 894810)
etree.tostring(et, encoding=str)
assert desired <= set(subset)
words_ngrams = []
base64.b64encode(iv + cipher.encrypt(raw))
sorted_required_fields
div_tag = temp_soup.html.body.contents[0]
pub_dict = {}
authors_sorted = sorted(list_triples, key=lambda x: int(x[1][44:]))
id(_my_own_id)
print(primes_sieve(1000000))
self._mkdir(os.path.dirname(absolute_path), info)
intbids = []
m = partL + str(E1.get()) + partM + str(E2.get()) + partR
[tox]
b = 2 * (m[1, 1] / m[0, 0] - xc * yc)
next(self.stream)
result_tags = models.TextField(max_length=500)
t2 = tuple(sorted([666, 42]))
dis.dis(def_func)
1, 100, 1000
event = eventqueue.pop()
obj = NumberSymbol.__new__(self)
x = np.array(list(range(100)))
[1, 0, -1],
fhan = logging.FileHandler(fname)
funcs = []
diff = np.subtract.outer(A, B)
a.d()
counts_matrix.flat = np.bincount(flat_coords, minlength=counts_matrix.size)
self.layers[0][i].value = entries[i]
all = list(range(10000))
push((value, base, power))
print({m._marker_key: m.marker_type.name for m in result})
a = list(range(10))
driver.getCapabilities()
MyClass().ff
self.x1 = x1
dv = df.values
print(sess.run(data_batch_debug))
child_pipe, parent_pipe = multiprocessing.Pipe(duplex=True)
setattr(json.encoder, name, encode)
trainer.trainEpochs(100)
structure = parsePDB(pdbname)
print(new_lists)
type = redis.type(key)
test(SP, CP)
new_lst = []
idx[outer_slice[0]][inner_slice[0]]
assert value > self.store[key]
CgmSJomT8ixkARkWBGNvcnAxFzAVBgoJkiaJk / IsZAEZFgdyZWRtb25kMSowKAYD
print(max_number(999))
source / usr / local / bin / virtualenvwrapper.sh
zi2 = np.zeros((len(tim), len(jj)))
result.extend([item for item in group_items])
DF_Filtered = pd.concat([DF[DF[col] == i], DF_Filtered])
root = dom.firstChild
row_iterator = df.iterrows()
out.getvalue()
sys.displayhook = display_as_hex
wrapped_func = wrapped_func.__func__
id(d)
pThread = Thread(x, args=())
c = a
func = getattr(tc, method_name)
pylab.show()
count_zeros = iszero.sum()
MyNumber(other - self.x)
token.save()
time_it(two_largest, seq)
enumList = Group(ZeroOrMore(enumValue + COMMA) + Optional(enumValue))
out = os.open(fifo, os.O_NONBLOCK | os.O_WRONLY)
b = etree.tostring(b)
book_scores[book] = moving_av(reader_list, 5)
list1.remove(list1[0])
a |= set(b)
retval = func(*args, **kwargs)
Counter[key] /= value
t.add_word(a, a)
dud_.remove(d1)
1
observer.join()
X[([0]), :]
response
print(df)
serialized = module.dumps(data, protocol=-1)
cur_str
print(r.json())
self.rules[attr] = value
fst, snd = zip(*data)
print(a)
patch, labels = ax.get_legend_handels_labels()
h = HTMLParser()
df = DataFrame(randn(10, len(cols)), columns=cols)
lon = math.radians(longitude_in_degrees)
_meta = MetaMock()
r = numpy.roots(p)
value.astimezone(tzutc())
nexts = cycle(iter(it).__next__ for it in iterables)
map_level(double, data, 0)
ax.xaxis.get_ticklines(minor=True)
matrix1 = numpy.ones((5, 10))
filtered_word_list = word_list[:]
icu.UNICODE_VERSION
bar_width = 0.4,
QTimer.singleShot(25, showWidget)
app = App()
main_colors.add(tuple(component >> 6 for component in color))
example_list = [20, 5, 5, -10]
settings.setAttribute(QWebSettings.DeveloperExtrasEnabled, True)
raise NotImplementedError()
zorder = 0
dt = cv2.threshold(dt, 100, 255, cv2.THRESH_BINARY)[1]
ax2 = fig.add_subplot(212)
a += pi * 2
buf.close()
self.classes_[indices]
y = models.Field()
print(item)
stream.stop_stream()
a = [(0) for x in range(N)]
completed_subsection = models.ForeignKey(SubSection)
vc = vc.sort_index()
print(d)
self.rwlock.release_read()
encoding = m.buffer(blob)
r = np.recfromcsv(csv_file, case_sensitive=True)
dispatcher.connect(add_item, signal=signals.item_passed)
8
res
self.apachereq = apachereq
login.token = fb_auth_token
dictionary.words[whatever]
plt.legend()
print(json.dumps(lst))
FACTORY_FOR = Post
M.T * M
s = sum(r)
bit_index = offset % BITS_PER_ITEM
getitem_rlist(s, 2)
subdirectories = [x for x in p.iterdir() if x.is_dir()]
testwriter = csv.writer(testw)
val = random.randrange(0, 10000)
print(ab)
print(json_graph.dumps(DG))
bellset = set(bell)
math.pi * r * r * h
result_list
foo = Foo()
power = 0
dot100 = decimal.Context(prec=100)
my_dictionary = {}
i, j = np.unravel_index(ij_1d, lon.shape)
self._subs_dict(sequence)
nodes = {}
root.config()
result = []
dy = POINT2[1] - POINT1[1]
wrappedSocket.connect((HOST, PORT))
names = os.listdir(path)
subparser1._actions[1] is subparser2._actions[1]
idx = np.digitize(X, bins)
strg
A = M.eigenvects()
matches[0]
kernel = np.full((2, 2), 0.25)
clf = GradientBoostingClassifier(n_estimators=num_estimators, random_state=0)
self.lists[i].append(c)
g = gencoordinates(1, 100)
test = test.ix[NewIndex]
length = len(L)
R = np.sqrt(X ** 2 + Y ** 2)
sim = np.exp(-np.sum(np.power(x1 - x2, 2)) / float(2 * sigma ** 2))
s = df2.stack()
[frags[0]]
chars = []
scatter = plot.scatter(x_range, y_range)
age_index = defaultdict(list)
fig2 = plt.figure()
figure = matplotlib.figure.Figure()
primebytes
dict(zip(ptest.id, ptest.value))
mySer = pd.Series(np.random.normal(0, 100, 1000))
print(line)
b[1] - b[0]
self.sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
list1.remove(m1)
test_b
getcontext().prec = 200
b.stop()
fontsize = textobj.get_size()
fd = self.f.fileno()
xmlrpclib.Transport.__init__(self, *l, **kw)
d[d[:, (c)] == v]
4.0 * (r ** -12 - r ** -6)
m = MyModel()
wordslist = wordslist[4:]
print(data)
add_item(i)
x = np.hstack((1, np.arange(1, N2 + 1), np.arange(N2 - 1, 0, -1)))
controller.signal(Signal.NEWNYM)
overall = np.tile(unit, (len(data), 1, 1)).astype(np.int)
model = MyModel
self.eyes = 1
parsed = p.findall(pageData)
data = data.join(vecData)
list(chain(*args))
WebElement.sendKeys(Keys.DELETE)
meta = MetaData()
print(pickle.loads(data))
res = list(yield_length())
idx = np.r_[0:7, m:m + 9]
a = [0]
r.append(s)
wd = webdriver_connection.connection
ar[1] = np.arcsin(-vect[0] / np.linalg.norm(vect))
count += 1
sum(args)
A1 = A.multiply(U.dot(V))
out = pool.map(func, (item for item in items if item[0] in check_set))
env = os.environ
pos = pygame.mouse.get_pos()
raise
self.construct_scalar(node)
self.func = func
self._namescallback[channel] = [], []
suite.addTest(unittest.makeSuite(Class2))
sum(value)
anchored_box.x0, anchored_box.y0
parse_object.netloc
BAUD = 9600
my_pdf = gaussian_kde(osservazioni, h)
self.thread = threading.Thread(target=self._flusher)
org.python.Python.PythonDocumentation - 2.7
True
style = xlwt.XFStyle()
sh = list(rescaled.shape)
()
fix_path()
(sp.j1(r) / r) ** 2
print(data)
name = Status(1).name
2015 - 7 - 16 - 1.7595 - 1.7647 - 1.0622
pool.map(func, iterable)
len(dir(aBytearrayOfINTs))
dct_counts[item] += 1
print(type(mydf_sub))
hh = urllib.request.HTTPHandler()
text
headers = []
pdb.pm()
tremove(L, M)
firefoxProfile = FirefoxProfile()
n, nrows, ncols = arr.shape
x = 4.12121212
command = supervisor_stdout
i = list(np.ogrid[[slice(x) for x in a.shape]])
outputData = []
val = 0
self.id == other.id and self.name == other.name
lines.append(s)
print(e)
x, y = np.random.random((2, 500))
updated.urlencode()
integer = 65066066065
up.user = request.user
fr.write(data)
1 - test10.txt
r = redis.StrictRedis(host=YOUR_HOST, port=YOUR_PORT, db=YOUR_DB)
a = 1 / 1221759
pixel_array = pb.get_pixels_array()
line = mm.readline()
selfclazz.create_subclass_translator(cls, install=name)
results = []
assert result.equals(df_final)
14.198169080002117
print(A[:5])
value[int(arg)]
doc = word.Documents.Open(infile)
assert [str(n) for n in tree] == expected
buttons.rejected.connect(self.reject)
content = response.read()
serializer = ImaginaryUserInputSerializer(data=request.DATA)
dat[0] = np.arange(5)
db.account.insert_one(account_dict)
res.append(key)
data.write(buf.decode(encoding, errors))
baz = fie(fum)
R = np.sqrt(X ** 2 + Y ** 2)
longest = len(max(l))
message = self.name + self.count
i1, i2 = itertools.tee(i)
mdays = monthrange(d1.year, d1.month)[1]
MSWord.Visible = 0
clf()
d = {}
ch2 = screen.getch()
[row, column]
print(item)
print(b)
ax1 = f.add_axes([0.1, 0.1, 0.8, 0.8], zorder=2)
print(val)
cmp(self.intAttribute, other.intAttribute)
inspect.getfullargspec(add)
json.dump(o[i:i + chunkSize], outfile)
x_sq = np.arange(-nx, nx, dtype=float)
self.lines.append(line)
triangle = [points[0], points[-1], points[-2]]
sum
foo()
iters = [iter(list1), iter(list2)]
fig = plt.figure()
data = recurddict()
listBB = [listB[x:x + 10] for x in range(0, len(listB), 10)]
f.write(str(content))
[1, 21],
np.linalg.norm(D1 - D2)
y_list = self.y_list = map(float, y_list)
json.dumps(loaded)
i = 0
x = 5
print(m)
key = lambda x: x
out = np.zeros((m1, m2, n1 + n2), dtype=A.dtype)
flips = [flip(0.2) for i in range(N)]
plt.plot(X1[1:], F1)
constructor = globals()[id]
df[col][x] = func(x, *col_params[col])
print(stream.read())
site = models.CharField(max_length=50)
imgA = numpy.array(imgA)
T = np.sum(W * X[nonzeros], 0)
self.object_id = object_id
numpy.set_printoptions(threshold=2)
self.listOfVideo.append(videoToAdd)
lines = f.readlines()
print(shortest, longest)
ratio = float(width) / float(height)
f(collection, 0, 1)
self = Foo.sad
sorted(list(range(len(args))), key=args.__getitem__)[0]
MAIL_PORT = 465
a = 1
m.update(str(arg))
n_min = max(0, smin // c0 + 1)
i = 0
good_array = np.copy(bad_array)
libc.fopen.errcheck = errcheck
B = A[:]
print(i, v)
x = np.random.randn(100000)
{{value.record.name}} - {{value.key.name}} - {{value.value}}
self.assertEqual(expected, io.getvalue())
tuple_list = []
chg = changeLog[version]
t /= t[-1]
magicJsonData = json.loads(io.StringIO(str(youMagicData)))
u = 15185600.0
p = psutil.Process(the_pid_you_want)
HTMLString(html % (params, escape(field.label.text)))
pb = pb.get_from_drawable(w, w.get_colormap(), 0, 0, 0, 0, sz[0], sz[1])
n *= 2
parameterizedSwap(s, 5)
self.linkActivated.emit(anchor)
line = loader.line
myint = 12
raise NotImplementedError()
d = defaultdict(list)
bmp.drawSquare(x * PIXEL_SIZE, y * PIXEL_SIZE, PIXEL_SIZE, fill=True)
self.mainloop.run()
f(collection, 2, 250)
parent = psutil.Process(parent_pid)
ans, (s, p)
binned_values = NP.digitize(column_of_values, bins)
_complete_path(text, line)
print(simOneSet(0.5, 0.5))
self.setSizePolicy(policy)
d = []
ws.cell(row=j + 2, column=i + 1).value = val
sys.stdout.buffer.write(shell.recv(10000))
cache = defaultdict(float)
print(fun(some_arg))
state = self.__dict__.copy()
print(words[i].strip())
START = set()
b is a
self.x = x
index = initial_list.index(item1)
c = np.empty(i_max + 1)
wiringpi2.pinMode(4, 0)
x * x
x = 1
ax1 = fig.add_subplot(2, 1, 1)
stack[0]
x = np.arange(y.size)
print(y)
output = y[np.all([x > 1, x < 5], axis=0)]
g.a_clear()
self.calls += 1
self.parent.scene.addItem(test)
sr[(sr - median).abs() <= iqr]
end = Quarter.from_date(date.today())
self.d = d
X2_shared = theano.shared(X2)
True
np.asarray(Imcol).T
unmappend = unmarked.append
treeaslist
mapper = DataFrameMapper([(df.columns, StandardScaler())])
{STDERR: sys.stderr, STDOUT: sys.stdout}[fd].flush()
G = nx.DiGraph()
df
found = True
encoded_c = chr(ord(string[i]) + ord(key_c) % 256)
df
True
False
psutil.pids()
natsorted(x, alg=ns.IGNORECASE)
grouped = grouped.unstack().T.fillna(0)
v = NP.r_[(0.2), 1:10, (60.8)]
g = lambda x, n: n > 0 and g(x, n - 1) ** 2 or x
settings.overrides.update(mySettings)
Y = Y[list(range(n / 2))]
self.error_message = error_message
df2
filename = script1.run(sys.args)
params.update(zip(names, args))
q.join()
resize_canvas()
src.load()
dps = []
dir = []
corpus = Corpus(map(Document, l))
y = zeros(data.GetNumberOfPoints())
__next__ = next
sample2 = 1 + np.random.randn(15, 1)
digits = t[1]
max_val = rdd[0][2]
print(pat % tuple(a) % tuple(b))
directories = list(filter(os.path.isdir, children))
offset = 0
t[0]
vals = np.zeros(N)
scale = int(math.log10(frac_digits))
ind_max = tf.argmax(x, dimension=1)
res = gcd(*lis[:2])
report_exception(exc_type, exc_value, exc_tb)
self._memo[name]
result = count.unstack(fill_value=0)
x = ntplib.NTPClient()
sol = solve([x - I * y, im(y), im(x)])
err = np.ones(10)
rotated_square = np.rot90(im[x_slice, y_slice].copy())
groups.groups
print(b)
_diff = diff(zfit, axis=1)
PyObject * set_py_callback(PyObject * callable)
zvals = np.random.rand(100, 100) * 10
abs(result / 2)
decorator.name = func.__name__
b = 1 + 2 * a
indicies_zero.append(index)
map(str.__add__, si, si)
l = []
source / usr / local / bin / virtualenvwrapper.sh
t.daemon = True
dst_session.add(j)
BIT2 = 2 ** 2
cls(my_setting)
query = DBSession.query(Table)
main()
file_list = []
d[5] = 1
bv = BitVector(size=len(input_li))
url, host = self.q.get()
print(idx1.equals(idx2))
train_writer.add_summary(summary, i)
print(dir(e))
True
~x
robot_dict = {}
vec_bow = dictionary.doc2bow(doc.lower().split())
args = est[0], locest[0], est[1]
shape, loc, scale = stats.lognorm.fit(sample, floc=0)
n = 0
cw = csv.writer(fw)
print(str(row))
i2 = [0, 2]
main()
ds = audiere.open_device()
df
custom_form.author = request.user
n_count = dict((n, math.pow(n, dice - top)) for n in range(1, sides + 1, 1))
f()
do_work_and_notify(send_email_on_completion)
print(s)
deleteself.store[self.__keytransform__(key)]
password = Column(String)
mylist = slice(2, 4), slice(15, 19)
method_cls = _getclass(method)
list(odds)
twill.shell.main()
queryset = queryset.order_by(Lower(ordering[1:])).reverse()
result = [color for color in colors if search in color]
output = grep_process.communicate()[0]
self.data = data
self.fd = fd
my_view
pd.Series(dict(val1=f1(r.a, r.b), val2=f2(r.c, r.d)))
total = next(it)
my_n_node = my_node_list[0]
r
a = np.array([-1.0, -0.0, 0.0, 1.0])
x[0] = 1
i = p + 1
x = np.random.rand(4, 5)
value = index
Y = exp(-X ** 2)
right_now = datetime.datetime.now()
fake_server.shutdown()
path = urlparse(url_string).path
_number
print(index, item)
s = set(next(ip))
matchall[i:i - n] |= match
f.close()
yData = yTrue + np.random.normal(0, 100, N)
2 - g | 1 - y | 2 - y | 2 - n
lang.Thread.sleep(100)
print(m.start(), m.end())
flow = flow_from_clientsecrets(CLIENT_SECRETS_FILE, scope=OAUTH_SCOPE)
kw_lengths.append((v[0][1] - v[0][0], k))
bool(getNumericTail(str))
params = {}
module = filename
c1.remove(y)
l = m.groups()
to_process.append(n)
idx = np.where(abs(W) > threshold)[0][-1]
myfiles.append(l)
body = payload.get_payload(decode=True)
n = max(1, n)
axis(a)
print(sentence_reverse(str1))
mealPrice = float(mealPrice)
self._my_attribute
xxx.connect(path, port)
job = job_queue.get(block=False)
i = arange(255)
results = [pool.apply_async(my_func, ([c], {})) for c in candidates]
colconsec = (df1[col] != df1[col].shift()).cumsum()
post_install()
items.rotate(1)
result = q1.union(q2).all()
array = make_array()
theta += twoPI
pdf = beta.pdf(data, a, b, loc=0, scale=1)
clf.max_depth
end -= 1
cum_counts = numpy.cumsum(counts)
p_as_list.append(node)
args_dict = dict(zip(args_name, args))
f = foo()
prefix + chr(cb)
hover = ActionChains(firefox).move_to_element(element_to_hover_over)
another_b = b_cls()
uuid.uuid1().int >> 64
cli()
False
item.setCheckState(QtCore.Qt.Unchecked)
print(df)
sax.parseString(src, builder)
df_ = pd.concat([df] * 10 ** 5, ignore_index=True)
n_k_d = numpy.zeros((S, D))
self.assertEqual(self.table, spread_sheet.table)
data = f.read()
indexers
contents += self.fileobj.read(size - len(contents))
mcmc.sample(50000, 40000)
y = ax + b
y = 4
print(button_obj.create_button(b).get_html())
a = []
inputs = []
offset = sys.getsizeof(a) - bufsize
fig = figure()
a = A()
a = tf.constant(1)
print(s.setblocking.__doc__)
cell.PAD
offset_arr = np.cumsum(lag_seq)
print(port)
map_parameters.append((chunk, counter))
app = TestApp(main({}))
result = percentile_7(df_flat)
responses = grequests.map(rs)
saver = tf.train.Saver(new_vars)
Yf[0] = 1.90897e-14
self._id = id
driver = webdriver.Chrome()
result
n = 2
required_list.extend(word.split())
x = np.hstack([(r0 * (1 - h) * np.cos(u)) for h in linspace(0, 1, num_levels)])
print(word)
sum_ = 0
dst_img.paste(transformed, mask=mask)
entry.authors.add(john, paul, george, ringo)
display.display(plt.gcf())
ipython - -no - pprint
x = np.arange(i - size, i + size)
writer.close()
Py_MEMCPY(result_s, to_s, to_len)
z = z.reshape(N, N)
data = ruamel.yaml.round_trip_load(fp)
resulting_list = list(first_list)
i += 1
P[np.tril_indices(n, -1)] = P.T[np.tril_indices(n, -1)]
final_list = []
self.setUseAdjustedValues(True)
plt.grid()
turtle.right(72 - angle)
self.d, self.key = d, key
out = StringIO.StringIO()
int(year_as_string)
to_be_removed.append(value2)
{5, 6, 2, 0}(maximal)
print(datetime.datetime.now() - t0)
cols = zip(*body)
worksheet.write(item, i, value)
sub = lambda x, y: x - y
opener = urllib.request.build_opener(HTTPRangeHandler)
num *= 2
nosegae_user = True
md5.update(data)
word, count = line.split()
i.append(10)
input.iloc[i]
x1[zeros1 & flanked_by_positives1] = 50
self.depth = 0
print(json_list(part_nums))
d = dict(zip(keys, vals))
windll.GetUserDefaultUILanguage()
data_array = np.array(data_2d)
ex.show()
plot = scatter_plot(zip(x_series, y_series))
f.close()
print(word)
argSplits.append(i)
func.value = func(self)
pr.disable()
ar.result.result
x = np.random.random(numdata)
image.save(thumb_buffer, format=image.format)
s.commit()
fp.close()
pyplot.hist(a, 100)
testing.py
{{(myVariable | cut): myFilter}}
self._socket.sendto(data, known_server)
im_mask |= hitmiss(im_binary, np.flipud(kernel.T))
print(my_text)
raise StopIteration
no = Cliente.objects.count()
model = combo.model()
myInt = 10
list_of_delayed_values = df.to_delayed()
data = np.vstack((data.T, np.ones(data.shape[0]) * num)).T
ttkcal.set_day(16)
rs = temp / (datass[i:] * datass[i])
original_hook = sys.excepthook
self.server = server
reconnect_to_database()
dfs = [df, df1, df2]
test = this_friday
created = multiprocessing.Process()
sieve[j] = 1
db_connection = DatabaseConnection()
PyCFunction_Call(PyObject * func, PyObject * arg, PyObject * kw)
chan = transport.open_session()
scroll_element_into_view(driver, element)
tldextract.extract(url).registered_domain
binary_data = (ctypes.c_ubyte * size)()
result = serial.readline()
self._picked_indices = []
pid = os.fork()
strmap = {}
self.config(bg=color)
--recursive
neighbors = [e for e in neighbors if not visit_mask[e]]
new_url
lon2 = lon2 * pi / 180.0
y = linspace(-5, 5, 200)
NULL
{Py_tp_new, BrownNoddy_new},
a[i] = np.pi / 4 * np.sinc(t / Tsymbol)
read_ok.append(filename)
intersections.update(moreIntersections)
email = fields.Str()
link = ftp_connect(path)
[buildout]
taskqueue_stub._root_path = dircontainingqueuedotyaml
mu + math.sqrt(sigma2) * normcdfi(p)
list(obj)
apps.set_installed_apps(new_installed_apps)
result.extend([0] * group_length)
loop = asyncio.get_event_loop()
p.terminate()
pprint(data)
lambda : callback(m)
a[6, 7] == a.max()
self.interested_threads.append(thread)
result = sess.run(apply_transform_op, feed_dict={b: b_val})
dateForm.index = pd.to_datetime(poorList)
lexer.level += 1
tkSimpleDialog.mainloop(0)
mins = items[:n]
n_j_k = numpy.zeros((T, S))
l = []
print(b)
bottom = 1
self.tree.addTopLevelItem(i)
tempList = []
_xrc.XmlResource_AddSubclassFactory(*args, **kwargs)
soup = BeautifulSoup(html)
new = {}
print(arr)
data = json.dumps({})
d.version
values = np.array(listB)
df = pd.DataFrame(np.random.randn(100, 5))
variables = json.load(f)
all_numbers = set(range(numbers[0], numbers[-1]))
values_at_bottom_right = get_values_at_coordinates(I, bottom_right)
dt.year + days_from_jan1.days * size_of_day + days_from_jan1.seconds * size_of_second
self.pack(expand=YES, fill=BOTH)
[m[0] for m in child_only_methods]
warnings._show_warning = my_warning_wrapper
Console.ReadKey()
tid = dtype.id
reader = csv.reader(incsv)
k = str(i[0])
count = iter(list(range(20)))
col, start, end, skip_footer
only_names = [entry[0] for entry in first_six]
output_array
print(row)
b = [1, 10, 10, 1]
self.b = 100
ruamel.yaml.RoundTripDumper.add_representer(MyObj, MyObj.yaml_representer)
double_encode = json.dumps(encoded_data)
x = -2
selected_alternates = alternatedata.take(required_idcs)
self.daemon = True
print(words)
moduli = [0] * len(lists)
oplog = c.local.oplog.rs
widget.connect_kernel(connection_file=kernelapp.get_connection_file())
diamond = Jewel()
self.pool = self.prng.random_sample(size=self.batch_size)
real_part = a.real * b.real - a.imag * b.imag
key = lambda x: x
indicies_to_remove = zip(np.nonzero(nan_rows)[0], np.nonzero(nan_cols)[0])
start_response(status, response_headers)
indices = list(np.ndindex(d.shape))
sums = a.filled(0).sum(axis=axis)
rot_sprite.get_rect().center = loc
client = mqtt.Client()
inputs = cgi.FieldStorage()
django.core.mail.EmailMessage = newmailer.WrappedEmailMessage
list4 = [1, 4, 5, 9, 12]
graph.add(triple)
print(i, val)
idx = random.sample(list(range(N)), 1000)
chain(*(a + b for a, b in zip(left, right)))
start.focus_force()
data = self.data.copy()
c.disconnect_from_server()
kmers = [genome[i:i + k] for i in range(len(genome) - k + 1)]
zipstream = StringIO.StringIO()
e_bytes = bytearray(reversed(b[-4:]))
proc.cpu_affinity(affinity)
distances = {start: 0}
self.index = len(self.data)
get_col = int(cell_value)
self.__class__(self.year, self.quarter + 1)
novo = textwrap.wrap(texto, width=20)
a, b, c, d, e = list(range(5))
fy = np.fft.rfft(y)
primes.append(current)
i = 5
table.add_row(row)
self.quoted[key] = m.group(2)
x = mu + sigma * P.randn(10000)
print(id(x))
self.connections.remove(self)
retcode = p.poll()
inspector = VariableInspectorWindow(get_ipython())
number = number // base
data = np.random.rand(row.size)
NULL
tasks.append(task)
count[s] = 1
_cache = {}
rel = EventRelation.objects.create_relation(event, self)
p = mp.Process(target=App.run)
self.x = x
ltc = [int(s) for s in c.split() if s.isdigit()]
self.file_obj = file_obj
zip(df.index, *df.values.T)
getcontext().prec = 40
5
names, ages = [], []
self.execdirect(query_string)
red, green, blue, alpha = data.T
matches = []
s = set(sample(takefrom, n))
second_largest([])
source_iterable = (random.choice(list(range(100))) for c in range(20))
price = models.DecimalField(max_digits=10, decimal_places=2)
self._entry
properties = [9, 26]
self.data = {}
s.sendall(data)
lst = list(tup)
materials = [0, 0, 47, 0, 2, 2, 47]
num = 2
data = np.zeros((n, u.shape[0]), dtype=np.uint8)
self.trell[i][1][token][1] = guess
print(latest_rows)
-lib
output_csv.write(now)
A[spatial.KDTree(A).query(pt)[1]]
new_p = poly(sum(c * x ** i[0] for i, c in p.terms() if i[0] > n))
r.append(fd)
self.classifiers = classifiers
x = foo(1, 2)
errThread = Thread(target=enqueue_output, args=(p.stderr, errQueue))
w2.present()
npercell = 1
print(e)
send_email_notification(payload)
macros = Macros()
df = df.fillna(0)
d[i] = 1
lonlat = np.column_stack((lon.ravel(), lat.ravel()))
self.ranges = collections.defaultdict(int)
markup = fix.sub(m, markup)
a = Foo()
corner1Copy = (len(arr) - 1) * numpy.array(corner1)
lens = rep.sum(axis=1)
the_keys = set(the_keys)
username = ndb.StringProperty(required=True)
True
() + 1
dot = np.dot(x[:length - i], x[i:])
serialized_data = {c.key: getattr(obj, c.key) for c in obj.__table__.columns}
combinations = []
f = file(filename)
print(s)
fig = plt.gcf()
startupinfo.wShowWindow = _subprocess.SW_HIDE
alist = []
dup2(child2father_pipefd[1], 1)
my_debug.db()
api_result = user_list.create_new_user(request.data)
incr_num(num)
number
max_length = int(output.get_shape()[1])
taskbar.HrInit()
process.crawl(MySpider, start_urls=start_urls)
book.close()
ax = sns.heatmap(uniform_data)
x = np.linspace(0, 10)
int(year), int(month), int(day)
a, b = next(i), tuple(i)
print(overlap(5, 10, 15, 20))
n = self.n
PAPER = 2
print(e.errors)
rc = sel_cur.execute(sql_statement)
self._myList = [len(modList)]
__metaclass__ = Meta
word = models.StringField()
values.sort()
linarg = tf.matmul(self.input, self.w) + self.b
track = 0
out.append(b + start)
tc2
self.thread.finished.disconnect(cleanup)
parsed_url = urlparse(URL)
res
self.value[i] > other.value[i]
b = list(range(-7, 259))
id = models.AutoField(primary_key=True)
(x - self.mu) / self.sigma
print(time1)
c[4]
gens = []
print(rule.ip_protocol, rule.from_port, rule.to_port, rule.grants)
msg = s.read().decode()
all(onelevelok(p, t) for p, t in zip(top + levels, levels))
selected_pts = a[~np.in1d(np.arange(m), idx1[distance.pdist(a) < d])]
rows, cols = np.where(labels == section)
multiplier.get(units, -1) * fn(*args, **kwds)
positions.append(word.find(match_string, positions[-1] + 1))
codeErr = StringIO.StringIO()
ax = pylab.subplot(1, 2, 1)
value = self.get_prep_value(value)
reactor.spawnProcess(HsProtocol(content), prog, [prog])
100
print(x)
context = zmq.Context()
iterable_map[key][0] = next(it)
console.setFormatter(formatter)
j = i + 1
self.grip.lift(self.label)
out = x[np.ix_(np.arange(x.shape[0]), x_range, y_range)]
outList.append(1)
__metaclass__ = MetaA
lists.append(sl)
ch = f.read()
array_1d = np.ravel_multi_index(array_2d.T, dims)
interpreter = python
str(o)
pix = Photo.objects.filter(gallery_id=self.id).all()
allow_interrupt = False
rec[k] = v / denom
print(fruits)
inputLines = f.readlines()
print(wrapper.fill(message))
weights = W_conv1.eval()
x = iter([range(0, 5), range(5, 10)])
data = wf.readframes(chunk)
self.lens = [len(arg) for arg in args]
sorted_index = np.searchsorted(sorted_x, y)
reg = CreateKey(HKEY_LOCAL_MACHINE, regpath)
target
lo, hi = 0, len(myList)
output = make_response(si.getvalue())
plt.contourf(grid_x, grid_y, grid_z)
args = vars(parser.parse_args())
helper((), r, s)
on_disk = json.dumps(list(data.items()))
l_index += 1
print(a)
spread_sheet = SpreadSheet(temp_csv.name)
graph = GraphAPI(token)
overlap = (earliest_end - latest_start).days + 1
b = np.array([12, 17, 20])
model = Sequential()
stmt.tokens
indices = [m.start(0) for m in iter]
wfd, wildfd, bfd, tfd = (FreqDist(),) * 4
cleantext
url = lis[0]
self.assertEqual(t, copy.deepcopy(t))
value = value.groups()[0]
print(id(spam), sys.getrefcount(spam))
title = TextField()
pyplot.hist(b, 100)
crawler = index.model().itemFromIndex(index)
i = -1
iter(self._dict)
r = urllib.request.urlopen(request, timeout=15)
index = 0
out[first_idx] = True
current_solution.append(number[:i])
resolution = dt.timedelta(seconds=10)
Spam().egg(_Spam__a=1)
dir(Foo)
xticks[::int(len(xticks) / 10)] = keptticks
data = loads(obj.stringArr)
kwargs[arg] = default_args[arg]
sys.stdout.write(text)
out_f = cStringIO.StringIO()
xps.pop(index)
b(A, B)
d = collections.defaultdict(set)
last_valid_row_number = idx.index(last_valid)
s = socket.socket()
cache = [-1] * (n + 1)
print(data)
False
parts = re.split(RE_VOWEL, word)
name = str(name)
dat[1] = np.arange(5)
funparams = inspect.getargspec(func).args
x, y = np.random.rand(2, N)
cv2.drawContours(im_col, [lines], 0, (255, 0, 0), 1)
499999999999999999999999999999999999999999
self.name = name
y_predicted = clf.predict(X_test)
abs(three_years - ten_years) == 2 * three_years + year
value = float(n) / prefix[symbol]
self._observables = {}
c = matrix([float(c1), -5.0])
http_server.listen(8888)
self.remaining = self.stop - self.count
toolbar = tk.Frame(master)
counter += 1
sums = {i: (0) for i in range(n)}
response
seen = defaultdict(count().__next__)
X, Y = sp.meshgrid(sp.arange(data.shape[0]), sp.arange(data.shape[1]))
aes = AES.new(key, AES.MODE_CBC, iv)
completeset1 = megalist[0:4]
print(A)
token = self.trell[i][1][token][1]
dc.DrawBitmap(self.bmp, 0, 0)
0
data = np.repeat(2.7, len(rows))
b = []
prices_json = json.dumps(list(prices), cls=DjangoJSONEncoder)
list(samples1)
_d
myNetworkAccessManager = MyNetworkAccessManager()
xdot
data = createObject()
t = [0.01, 0.1, 0.2, 0.4, 0.6, 0.8, 1.0]
l1 = []
x = ham
print(j, len(j))
res2 = blockwise_dot(A, B, max_elements=max_elements)
w.update_idletasks()
g.send(10)
setattr(type(self), name, stub)
m()
controller.signal(Signal.NEWNYM)
self.cancel = self.after(self.delay, self.play)
it = iter(lis)
g.plot_joint(sns.regplot)
utmless_url = urlunparse(parsed_url)
b = datetime.now()
y
ctm = utils.matrixMultiply(ctm, rtranslation)
plt.scatter(xv, yv, 100, values)
pri_d.append(i[pri_m])
call_python
app.routes.js
name = models.CharField(max_length=50)
window.add(entry)
current_date = from_date
print(i, val)
im = ax2.scatter(list(range(10)), list(range(10)), c=list(range(10)), alpha=1.0)
app = Flask(__name__)
print(config[0].prefix)
model = Word2Vec(arr_str)
r = FE_UPWARD
data = fileObj.read(chunkSize)
n_vecs = 20
a.set_xlim(xlim, emit=False)
first = dict()
cur = con.cursor()
self.children = []
d[k.lower(), j] = v
filename = posixpath.normpath(filename)
IPython.embed()
self.btn.text = text
res = obj.lookup_rws()
y1 = np.max(y) + 1
activate
path = request.build_absolute_uri()
mask = C > A[0][B]
styles = getSampleStyleSheet()
t = t[0]
wtsses[j] = i + j
assert iscoroutine(coro), repr(coro)
p = pcap.pcapObject()
ps.append(p)
wait = WebDriverWait(browser, 10)
MyClass.x
out.append(ele)
df
event.description = self.description
g_loop.start()
result = my_num * 2
repo.auth(pkey=key_file)
r.after(500, tk.destroy)
editor_widget.override_font(font_description)
other_stuff()
True
True
root, _ = os.path.splitext(f)
df.mul(v2)
print(any(lst))
Ver1(folder)
[classes][students][grades]
width = pos[1, 0] - pos[0, 0]
cell = chr(ord(cell[0]) + 1) + str(cell[1])
point_symbolizer.opacity = 0.5
tokens = tokenizer.tokenize(myString)
sp2.add_collection(sympy_p2._backend.ax.get_children()[appropriate_index])
a = b
inf.close()
ids_by_data_len = defaultdict(list)
cols_arr = np.arange(cols)
image = image.crop((0, t, nw, t + nh))
video.close()
source = inspect.getsource(foo)
count += 1
retcode = ctypes.windll.Ntdll.RtlGetVersion(ctypes.byref(os_version))
response = rs.client_list()
j = randint(i, 16)
lists = [list_key.get() for list_key in list_keys]
variables = [x, y, z]
p.wrapOn(self.canv, 2 * inch, 2 * inch)
configdir = os.path.join(confighome, app_name)
smallestCars = collections.OrderedDict(key_value_pairs)
bar.set_facecolor(plt.cm.jet(r / 10.0))
print(self.picked_points())
A.a.__set__(self, val)
self.a1_edit.setValidator(self.int_validator)
train_step = tf.train.AdamOptimizer(0.0001).minimize(cross_entropy)
s.push(t)
color_indices = (values - np.min(values)) / (np.max(values) - np.min(values))
startsecs = 10
data.compute()
XYZ[1] = float(XYZ[1]) / 100.0
x = msvcrt.kbhit()
F = 1
my_a = A(**options)
k.set_contents_from_filename(filename, cb=percent_cb, num_cb=10)
PrintExtra = True
a = [1]
data_stack = np.tile(data, (unique_groups.size, 1))
print(r.dimnames(rf[8]))
self.obj_.xmin()
self.template = response.resolve_template(response.template_name).name
hex(119)
in_res = op(in_a, in_b)
b
p = sp.Popen(args, stdin=sp.PIPE, stdout=sp.PIPE, stderr=sp.PIPE)
request.is_json = True
suite = unittest.TestLoader().loadTestsFromTestCase(TestSequenceFunctions)
-views.py
platform.node()
array[ii][jj] *= 2
print(dist.sample_one())
print(i)
dfs = outer_parts(df, df2)
stopwaitsecs = 60
collections.defaultdict(recursively_default_dict)
bravo
c = [a + 1] * b + [a] * (n - b)
num = models.CharField(max_length=10)
self.target = target
x = 1
b = a.create_b()
signal.alarm(self.sec)
print(match)
im1_gray -= np.mean(im1_gray)
self.OneHelper.blah()
admin.autodiscover()
but.pack()
funcs = [lambdify(xs + ks, f) for f in syms]
res = []
self.threads.append(t)
(value,), = t
plt.xticks(np.arange(len(cats)) + 0.4, cats)
hashed = bcrypt.hashpw(password, bcrypt.gensalt())
self._init_kernel_manager()
i = i + 1
hull = cv2.convexHull(cnt)
ntot = sum(n)
array
params[args_name] = args[basic_arg_count:]
1 - 0.002666
hourOfDay = np.mod(list(range(0, 100)), 24, dtype=np.float)
CY = np.cumsum(Y * dx)
parser = nltk.parse.EarleyChartParser(mini_grammar)
updated_fixtures = []
rows, cols = A.shape
process_b = multiprocessing.Process(target=get_b)
a[mask] = b[mask]
head_inner()
self.addcredentials(request)
Image.merge(*merge_args).point(luts)
parallel = True
assert rescaled.shape == finalShape
raise ValueError
retrieve_job = vault.get_job(job_id)
name = fields.Str()
cv2.drawContours(im_col, [lines], 0, (0, 0, 255), 1)
persontable[self.personid]
request.write(result)
sll = np.hstack(ll)
x, y, z = self._seed
position.seek(0)
big_range = list(range(10 ** 7))
complete_social_login(original_request, login)
self.y = y
mean = np.mean(stats)
restrictedItems = appointments.Restrict(restriction)
list2 = [1, 0, 1, 0, 0, 0]
array([nan, nan])
xl = numpy.mgrid[0:256, 0:256, 0:256]
+code / speed.py
possible = list(range(1, int(numpy.floor(numpy.sqrt(numToFactor))) + 1))
d = Derived()
stdscr.addch(c)
print(clust)
x1, y
codes.append(codeblock)
assert hasattr(d, Comment.attrib)
self.trayIcon.setContextMenu(menu)
clipboard = QtGui.QApplication.clipboard()
print(country, count, sales_count)
[a - z]
post_text = Column(String)
[]
self.errwidth = errwidth
xdiff = np.diff(x)
A = 0
index = pd.date_range(pd.datetime(2008, 1, 1), pd.datetime(2008, 1, 5)),
ws[column_letter + str(row)] = counter
[udot, -u + sqrt(u)]
self.yData = np.append(self.yData, yData)
group = parser.add_mutually_exclusive_group(required=True)
print(lst)
lines = f.readlines()
ws.append([str(cell) for cell in row])
r_den = np.sqrt(datass[i] * datass[j])
func(**kargs)
form = ResendActivationEmailForm()
self.fName = fName
self.obj
sys.coinit_flags = 0
image = gtk.Image()
prior_reci = 1 / np.asarray(prior)
out[mask] = np.concatenate(v)
n = len(colors)
(l1 if pat == 1 else l2).append(fac)
cr.arc(100, 100, 80, 0, 2 * math.pi)
f(accuracy, nstep)
pyrodaemon.handleRequests(timeout=1.0)
-myproject.wsgi
preresult = collections.OrderedDict(zip(list(range(200)), list(range(200))))
threads[i].join()
inv_col(palette())
d2_ts = time.mktime(d2.timetuple())
u_y.append(s[k])
p.feed(s)
clientsocket, address = self.serversocket.accept()
ls = len(s)
wintypes.HANDLE(0)
keep_mask[slice] = False
print(type(mydf))
results = OLS(labels[:half], data[:half]).fit()
best_index = i
line_cnt += 1
tb1.reset_index(drop=True, inplace=True)
sp.distance.pdist(a)
combo[num_full_cells] += target_sum - sum(combo)
fd = sys.stdin.fileno()
loader.write(contents)
input = [a, b, c]
y = np.random.rand(N)
d[b].append(i)
items = get_items(request)
repr(A()) + repr(B())
midnight = datetime.datetime.combine(now.date(), datetime.time())
line12 = text.splitlines()[11]
print(result)
example.set_thing(b, 0, 999)
realData = pandas.Series(data=realData.Borough.values, index=realData.City)
x = np.random.randn(5)
foo(uids)
sample_dictionary[words] = [word]
deletenode
b
n = 2 * s ** 2 * (zp + z) ** 2 / d ** 2
print(result)
self.members[idx] = item
alphaDict = dict.fromkeys(s, 0)
distance = np.sqrt(E * E + x * x)
server = SocketServer.TCPServer((HOST, PORT), InteractiveServer)
aList[0]
path = _append_slash_if_dir(path)
seen.add(x)
deltas.append(t2 - t1)
driver.Navigate()
create_plane(board)
r + m.group(2)
object_values[-1].append(getattr(object, field))
population = set(range(1, 100000))
inverted[v] = max(inverted.get(v, k), k)
retcode = process.poll()
[t.join() for t in tasks]
newfile = tempfile.mkdtemp()
print(parsed_json)
df
xmlStr = xmlFH.read()
print(comment_entry.content.text)
change_in_memory = gen_change_in_memory().__next__
1
module = imp.load_module(random_name, f, pathname, desc)
sentinel = max(a_endpoints[-1], b_endpoints[-1]) + 1
recur(100)
xZCAMatrix = np.dot(ZCAMatrix, X)
x = 0
a = input()
dc.DrawBitmap(bitmap, dx, dy)
polygon_positions = numpy.cumsum(numpy.fromiter(polygon_positions, int))
result, candidates = list(), [self]
hello.bla()
request.is_json = False
200, 1.02461, 0.486549
questions = query.fetch(10)
a_start, a_stop, a_step = a.indices(length)
tmp = list(yielding(x))
d = MyDict()
rule = request.url_rule
0
plt.plot(line)
FP = CM[0][1]
myOrdDic = OrderedDict(sorted_list)
output = []
n = []
wrapper
perm1 = list(perm1)
n = 1000
max_len = max(len(i) for i in a)
response
print(max(wn.wup_similarity(good, great), wn.wup_similarity(great, good)))
PyObject * obj
y1 = y0 + r * math.sin(a)
current.pdf
context = {}
_.shape
target[property] = chg[val]
False
a = np.zeros(n)
autoargs(locals())
y1 = np.max(y) + 1
True
settings = QSettings()
p.close()
data_sd = np.array([11, 12, 12, 14])
pyframe = PyEval_GetFrame()
flags = os.O_CREAT | os.O_APPEND
data = args[0]
self.index
nodes = [set(L) for L in paths]
z = zlib.decompressobj(15 + 16)
currentDate += delta
df
queryset = Establecimiento.objects
var2 = np.arange(1, 10, 2)
converted_value = convert(value)
print(text_in_clipboard)
reg = OpenKey(HKEY_LOCAL_MACHINE, regpath)
make_nested(mp, l[1:])
figure.scene.disable_render = False
pool.map(somethinglong, jobs, chunksize=1)
predictions.append(prediction[0])
newdt = currentdt - datetime.delta(seconds=10)
self.y = 15
w = A[A % 2 == 0]
results
uuid = Required(uuid.UUID, unique=True, default=uuid.uuid4)
fee_gst = models.DecimalField()
scores.ffill()
I, J = len(E1), len(E2)
gen = np.random.RandomState(0)
kf = cross_validation.KFold(4, n_folds=2)
options, args = parser.parse_args(command_args)
idx = [idx]
serverEndpoint = StandardIOEndpoint(reactor)
A = np.random.randn(M, N)
print(find_prev_next(list(range(1)), 10))
im_out
x = input()
print(findSVAOs(parse))
fpr, tpr
self._weapon
print(a, b, c, explicit_params)
y = [x] * 4
a = a.mask(~a).stack().index
print(text.strip())
dictpsl = {}
plt.imshow(WordCloud().fit_words(lda.show_topic(t, 200)))
print(c)
ranking.append(ranks)
p = Semaphore(5)
dateHelp.communicate()
v = Series([1, 1, 1, nan, 1, 1, 1, 1, nan, 1], dtype=float)
rozza = Person._get_collection().find_one()
x0 = center[0]
do_something_else
result
print(logit_val)
session.visit(url)
ani = animation.FuncAnimation(fig, game.plot_step)
ret.append(c)
op = (ord(c) for c in code.co_code)
self._tuples = set(tuples)
Meta(name, bases, dct)
True
tmp = x[0] + x[1]
divide_equally(n + 1)
out = p.stdout.read().strip()
WSGIScriptAlias / app1 / app1 / app1.wsgi
2, 5, 8
figure = io.BytesIO()
print(total)
x2 = mu + sigma * np.random.randn(980, 1)
dt = DecisionTreeClassifier(max_depth=5, min_samples_leaf=1)
formset = MyFormSet
name = db.StringProperty()
run(1)
AB = map(sum, zip(A, B))
query
action = Action1.object.get(id=1)
aes = AES.new(key, AES.MODE_ECB)
nodes.update([child, par])
self._date = self._date - self.timedelta(days=1)
c = np.concatenate(a, b)
f[0] = 1
result = []
clusterLabels.append(labels[row.indices[arrayIndex]])
lol
n = data.shape[0]
{y, 0, x}
self._func(*args) + other(*args)
selector = [0, 1, 0, 0, 1]
feed_update = feedparser.parse(url, etag=last_etag, modified=last_modified)
blabla
self.mean += self.delta / self.n
form.agency.choices = getAgencyList()
partitions_new.insert(n, total)
X2 = cv2.fit_transform(preproc)
original(*args, **kwargs)
vfunc = vectorize(func)
p = p.filter(Post.date <= end_date)
price = 10
b = lambda m, n: a(m, 1, n)
f.update(e)
xtile, ytile
que.put(fff(*theArgs))
phrase.title()
self.id = msg.EntryID
cls
s.read(html)
count_inside[..., (k)] += k == labels_img[1:-1:, 2:]
df.A.iloc[pos:pos + 2] = 0
initial = self.initial.get(name, field.initial)
index = max(enumerate(new_lists), key=lambda tup: len(tup[1]))[0]
Inside
yy = pylab.linspace(-5, 5, 100)
cyts = aliased(TextString)
cots = aliased(TextString)
print(base.foo())
tick_size = 9
sum |= tup[i] << 8 * i
ms = [[Chem.MolFromSmiles(x[0]), x[1]] for x in ms_smis]
self.name = name
normal_vector = np.array([a, b, c]) / np.sqrt(vector_norm)
n = 1004
self.len = len(seq)
-P2
self._password
l2 = l[:]
fp.write(thumb_buffer.getvalue())
l.append(digits)
M[idx]
False
next_chunk = input_file.read(1000)
encoding = m.from_buffer(blob)
print(result)
[0 - 9]
idx = np.where(~np.isnan(x[tuple(axis_slice)]))[0]
w, h = img.size
s = StringIO.StringIO()
self.log = open(logfile)
x = 500 + r * math.cos(theta)
hashes = hashlib.md5(), hashlib.sha1()
2
a1 = a.copy()
foo.spam
print(os.times.__doc__)
methodReference.__self__
ssh = connect()
L + 5 * F >> 1, L + F >> 1
done = False
file_like_io = StringIO(txt)
klmno
pqrst
uvwxy
self.threads = []
lst1 = [(i, i, i) for i in range(10 ** 4 + 100)]
update(o, new_tuple)
transf1d(f, x, y, out, Nx, Ny)
delay_channel = connection.channel()
x = X()
dst_img.show()
print(xt)
print(info.filename)
bits = bitstring.BitArray(bitstream)
retries = 5
v2 = [4, 5]
xml = etree.fromstring(x)
instance
value, empty = is_empty(value)
buf = buffer(data, 0, len(data))
r = tracer.results()
print(zero_crossings)
wb = np.bincount(b)
data
incr()
df
print ()
parts_dict
result = next(i)
density = kde(coords).reshape(xi.shape)
arr[..., (i)] = a
self.myfunc = lambda x: x
myShelve.update(bigd)
main.js
df_means = by_row_index.mean()
res1.append(i)
DeleteDC(screen)
start = time.Now()
a.escape()
listOfDf.append(df[i * chunkSize:(i + 1) * chunkSize])
cb = fig.colorbar(res)
x = np.linspace(0, 1, 10)
check_infile(datafile, savefile)
running_max_y = np.maximum.accumulate(y, axis=1)
print(prefix(9e-06, 2))
fileNo = frame.f_lineno
today = datetime.today()
(t1, p1),
resolution = dt.timedelta(minutes=10)
axis = 1
m.materials[0].rgbCol = [random(), random(), random()]
config.make_wsgi_app()
scanned += 1
plt.imshow(WordCloud().fit_words(ldamodel.show_topic(t, 200)))
im[x, y] = color
arg_number += 1
df
con = MySQLdb.Connect()
page = requests.get(u)
files = [path]
l.acquire()
-10 * -1
[random.random() for i in x]
model = MyThrough
attrName = attr[0]
min_pub_date_time = datetime.combine(pub_date, time.min)
exit_status, stdout, stderr
self.notifications = []
df1
image = ImageReader(user.photo)
table = h5file.root.detector.readout
B = np.random.randint(0, 255, (sizeOfArray, sizeOfArray))
Field.register_lookup(Any)
q = session.query(NDTicket)
[4, 5, 6],
b_List.extend([T, T])
memset = ctypes.cdll.msvcrt.memset
dict = dict[key]
path.append(k.kind())
constrained_sum_sample_pos(4, 40)
tomorrow = datetime.now() + timedelta(days=1)
sums = [sum(t) for t in zip(a, *a_rotations)]
idnumber = tables.Int64Col()
addopts = --nomigrations
df2
compounded_iter = ((foo.value, bar.value(foo)) for foo in foos)
key = tuple(the_dict.items())
np.linalg.norm(fromdeg(1) - fromdeg(180))
print(t)
setattr(self, attr, profile[attr])
outfile.write(text)
V, W = np.meshgrid(v, w)
pred(2)
writer.write(bytes(1))
f4 = z - w
schema = etree.XMLSchema(schema_root)
start = 0
last_name = indexes.CharField()
longest = max(len(timing[0]) for timing in timings)
ymap[:] = y[:]
self.data = cStringIO.StringIO()
y = np.matrix(y).T
e.append(fd)
d
self.destinations(goingTo, passingBy)
best_run = []
colmask = ~np.triu(mask2D, 1).any(0)
l.get_contents_to_filename(d)
s.bind((HOST, PORT))
row_out = ((nzm[:, 1:] & (a[:, 1:] != a[:, :-1])).sum(1) > row_thresh).any()
ctypes.pythonapi.PyCell_Set(cell, new_value)
df
func(elem, *args, **kwargs)
distance = dx * dx + dy * dy
now = datetime.now(tz=pytz.utc)
KeyUp(Base[Combs[Key][0]])
color_red()
out_vec = np.exp(out_vec - logsumexp(out_vec))
output, exitstatus = pexpect.runu(command, withexitstatus=1)
print(x + 2)
self._set.add(item)
top = Tkinter.Tk()
code2
Z = np.random.random((10, 10))
img = next(self.L)
astring = sys.argv[1]
command = ser.read(1)
graphs_panel.SetSizer(graphs_sizer)
x + 5
zsum, areasum = sumtriangles(points, z, triangles)
print(line)
mySocket.bind((hostName, PORT_NUMBER))
print(np.sqrt(np.pi / (2 * X)) * iv(v + 0.5, X))
msg = resp.content
MAIN_SURF.blit(action_surf, my_position_1)
maxpos = counts.argmax()
self.client = brukva.Client()
stdout, stderr = p.communicate()
item
print(df)
seen.add(remainder)
x_lattice += center_pix[0]
myScript.py
self.func = func
a = np.array([1, 0, 0, 1])
print(loaded_mm.readline())
b = 1, 2
a.call_me()
game_score / max_score * 0.7
print(cmd)
yb.processTransaction()
x1 = x0 + r * math.cos(a)
d = numpy.array([a, b, c])
res = 1
print([f() for f in funcs])
full.sort(reverse=True)
num = num * n
templist.append(y)
i = FirstIndex(a, val, tol)
get_col = str(cell_value)
1, 11, 7
self.inches = value
gzopen64
idx = pd.IndexSlice
k = np.searchsorted(x, new_x).clip(1, len(x) - 1)
self.name = name
print(word_meaning.definition)
print(arg)
df = df.fillna(-9999)
results = regex.findall(expr)
date_info.columns = date_info.columns.droplevel()
dict(sample_dictionary)
html = res.read()
print(choice(all_maxes))
config.parse(config_file)
get_num(orange)
d
a1 = a > 1
self.fire(sendfile(self.filename, bufsize=self.bufsize))
y.strides
a = 2
vals[m] = avg_vals[ids[m]]
hamming_sets = [set(), set(), set(), set(), set(), set()]
[RpcCall]
rat = min(xrat, yrat)
data = map(np.array, data)
angles = np.arctan2(edges[:, (1)], edges[:, (0)])
low = min(row[:-1])
self.index = self.index - 1
width = GetSystemMetrics[0]
gggg = np.outer(gg, gg).reshape(4 * g.shape)
print(encoded_data)
page.close()
m1.as_string()
dc.Clear()
self.data.pop(0)
ml.reverse()
params.update(zip(names[:], args))
parsed_args = parser.parse_args()
increase_axis = 1
zip(*args)
handler1.addFilter(MyFilter(logging.INFO))
xyz = [np.array(p) for p in itertools.product(list(range(volume.shape[0])), list(range(volume.shape[1])), list(range(volume.shape[2])))]
y = data[i]
response = request.get_response(app)
t1.timeit()
data = str(source[0])
R_mean1 = list()
self.start()
results = innerre.findall(inner_str)
o = json.load(infile)
response = session.body()
qux is __main__
np.cumsum(c * rho, axis=0, out=cs[1:])
print(new_time)
my_list = []
newData = file.read(amountToRead)
i = 0
x = data[:, (0)]
f = open(args.filename).read()
sel.start()
ordered_merge(quotes, trades)
D[-1] = (-1) ** (1 - dim % 2) * D.prod()
result = [set(T[0])]
struct.unpack(fmt, dat)
list_of_tuples = []
fortress = 1 << 16
mass, pos, vel, f = 0, 0, 0, 0
result = []
mbox_index = list(build_index(fname))
lexer.level += 1
name = getUniqueFileName(prefix, image.getSuffix())
dataGrid = dataGrid.reindex(columns=numpy.append(dataGrid.columns.values, y))
self.setCurrentBlockState(0)
test_list = [0]
content = content.lower()
mask = (a > 0) & (a < N)
line_count += 1
test.sin_2_.restype = c_float
bar1 = Bar()
D = np.empty(shape=[0, 0], dtype=X.dtype)
demo(n + 1)
self.pipe = pipe
console = EmbeddedConsole(locals())
x = [5e-05, 5e-06, 5e-07, 5e-08, 5e-09, 5e-10]
sub(foo, bar)
csv_headings = next(csv_reader)
month, year = start_month, start_year
mu = 200 * np.random.random(numcurves) + 200
start = randint(0, len(numbers))
0, out
print(line)
self.app = QApplication(sys.argv)
prettify(value, indent + 1)
res = logger.get_trendy()
Dial()
not_really_a_file.close()
frame[name] = close
pipe((repeat(i, i + 1) for i in range(4)), chain.from_iterable, list)
count[pick_random(prob_list)] += 1
c = data.cursor()
archive.close()
d = {}
print(location_out)
1 - myEpsilon
mlg = MontyLingua.MontyNLGenerator.MontyNLGenerator()
data = data.drop(cols, axis=1)
resultArray.append([rowNr, result])
result
SYN = 2
fsolve(func, x0)
tz = get_current_timezone()
ws = wb.active
l = line.split()
print((x, rd[x]))
df.office_id = df.office_id.astype(str)
NPERSONS = 10000
print(xrange, yrange, zrange)
x = np.arange(61).astype(np.float)
outlist = [x for i in zip_longest(*prefix_match) for x in i if x]
s = m.group(1) + str(count)
7, 8, 9
index = i - 1
today = datetime.today()
exec(myMod)
json_object
join_overlapping_path(p2, p1)
print(hello)
max_len = 0
test_obj = Test.objects.get(id=to)
len(self.ary)
writer.write(x)
parser.stream.skip(2)
df[df < df.max().max() * np.finfo(float).eps] = 0
b = np.array(list(range(size)))
old_raw_input(*args)
print(cur.description)
instance = reservations[0].instances[0]
h.itemset(i, j, 2, 255)
ret.wait()
output, err = p.communicate()
n = 0
self._server = server
i += 10
myFoo._Foo__bar
useable, unueseable = paths(subtree)
match = match_pattern.search(text)
_count += 1
lst.append(d)
digitized = (nbins * vals).astype(int)
-cr.dictfetchone()
Z = np.random.rand(1, 100)
numpy.sinc(retval)
a_sum += ai * ai
io_loop.remove_handler(stream.socket)
decimal.getcontext().prec = 60
raise
l.append(Point(x, y, 0.0))
tb1 = tables[0]
ax = fig.add_subplot(111)
result = find_key(v, key)
sort_by_comparison(list_to_compare)
print(a % 1)
y = y.squeeze()
df2.comb
black = 0, 0, 0
Y = []
FLAG8 = 2
auth_req = urllib.request.Request(auth_uri, data=authreq_data)
print(p)
new_jec = interpolate.interp1d(t, jec, kind=kind)(new_t)
plot(xx, yy)
values = []
json_data
print(1)
func(TempLake[0], Z)
total = 0
print(type(a))
resultQueue = mp.Queue()
0, 0, 0
print(x)
col_out = ((nzm[1:] & (a[1:] != a[:-1])).sum(0) > col_thresh).any()
self._key_to_index = {}
opfunc(self, arr)
palette = plt.cm.jet
arr = np.arange(1, 10)
a_list.append(new_item)
i += 1
v1 = get_a_value()
cdf = np.cumsum(ydata) / sum(ydata)
f.write(data)
old_stdout = sys.stdout
fi = f.readlines()
print(floor(f1))
rs = c.get_all_buckets()
b = parray[1]
self.maxidx -= 1
dict_handler = lambda d: chain.from_iterable(list(d.items()))
print(type(bw))
a
res = list(mapper(f, arg))
User.__unicode__ = user_unicode_patch
exist = True
fin
d.addSample([0.0, 0.0], [0.0])
matching = [key for key in keys if re.match(query, key)]
date = Column(DateTime)
print(args.files)
allfriends = []
next(f)
quantity = models.IntegerField(default=0)
files = [f for f in os.listdir(sdists_dir) if f.startswith(name)]
print(find_prev_next(list(range(10)), 0))
dis.dis(test1)
T2
lambda y: x
unique = True
python2
x.add_row([e[0], e[1]])
entities = os.listdir(dirpath)
newuser.save()
ret = int(val ** (1.0 / n))
print(pd.DataFrame(tbl_d, columns=header))
v1[0] = 10, 100
print(mac_date)
asset_id = models.AutoField(primary_key=True)
processes = 4
self.fields = self.normaluser_fields
a = np.random.randint(4, size=1000)
wordvectorfromlda = [ldatopics[j][wordindex][0] for j in range(100)]
b = a.copy()
idx |= idx.shift(-1) | idx.shift(-2)
ax = gca()
iranges = iter(nums[0:1] + ranges + nums[-1:])
y = sin(x)
list1 = [2, 4, 6, 8, 10]
url = sys.argv[-2]
_data = ndarray.copy(self, ndarray)
False
G = np.zeros((x.size, ncols))
plt.yticks(list(range(height)), alphabet[:height])
Console.WriteLine(BitConverter.ToString(hash))
pixelcount = width * height
dict[letter]
print(s)
labels, levels = pd.factorize(s)
memostirling1[n, k]
assert i() < 0 < j()
val <<= 1
z_d_n = [[(0) for _ in range(len(d))] for d in docs]
node = queryset.filter(self.model.id == node_id).first_or_404()
1 - y | 2 - g | 2 - y
execute(render, [])
x, y = np.random.rand(2, 1000)
rows_arr = np.arange(rows)
print(len(overlap))
href = href.strip()
logger.addHandler(ch)
d[t[1]] = t
Newlist = []
resource.close()
x = np.arange(100)
AX_SWIG_ENABLE_CXX
self.handle(syntaxtree, **nameditems)
numbits = order * int(round(log(decimation_factor) / log(2))) + ibits
word = line.strip().upper()
CI = true
logger = logging.getLogger()
data = json.loads(response.text)
expensive_db_operation()
self.set[item] = True
assert myFixture in (2, 5)
l1.add(element)
self.file.write(fp + os.linesep)
2 < x < 4
self.c = 42
N = B.shape[0]
frame = cv.QueryFrame(self.cam)
self.memo[args]
GRANT
pp(c)
q.append((t, v))
datafile = os.path.join(os.path.dirname(__file__), datafile)
user = User()
menu.append(item_quit)
bar.argtypes = [c_char_p]
seq_numba = jit(seq_python)
atexit.register(Test.__cleanup__)
len(t) and t or True
clock = pygame.time.Clock()
flow = np.cumsum(np.random.random(num) - 0.5)
dists = Distance(np.arange(10), unit=u.kpc)
b = tk.Button(bop, text=tv, command=cbc(k, tex))
print(get_mirrored(TARGET))
print(b)
y = y.strip()
negative = posneg_calcsums([item for item in items if item < 0])
list_file.write(f_content)
CloseHandle(process_handle)
numpy.std(theta_hist)
motif = s[i:i + 2]
a[2] = 7
dt = dt.descr
count
decimal.getcontext().prec = 100
prediction = model.predict(np.array(tk.texts_to_sequences(text)))
d
lines = []
post_date = DateTimeField()
x = np.arange(-2 * np.pi, 2 * np.pi, 0.1)
one = models.TextField()
piperows.append(row)
path_ext = numpy.asarray(path_ext)
all(ord(char) <= 255 for char in valueFromSqlColumn)
utc_now
count = 0
C = np.array([1, 1, 1, 1, 2, 1, 1])
parser = argparse.ArgumentParser()
y = defaultdict(int)
result.append(new_value)
total = 0
self = float.__new__(cls, value)
current_dir = []
od.popitem()
formset = RecipeFormset()
list1 = [1, 0, 0, 1, 0, 0]
lo if x <= lo else hi if x >= hi else x
x = np.linspace(0.0, 1.0, len(color_list))
x, y = np.random.random((2, 10))
d = datetime.now().date()
b = 1 - a
debug(a, b)
response = queue.get()
cnt[k] = cnt[k] + 1
M[:, (j)] = l
x = x - x.mean()
raw = pd.read_csv(filepath)
current_date = from_date
sel2 = get_selection()
stream = StringIO.StringIO(b_data)
line.set_ydata(a1)
print(0 == False)
log_handler1.flush()
spec.loader.exec_module(module)
w = len(str(max_t))
a[(-1), :5]
print(c)
print(label, url)
y = np.sin(x)
(bins[pos - 1] == values).all()
original_hook(type, value, tb)
rows = []
cax.set_frame_on(False)
seconds2time(res)
fig1 = plt.figure()
swelling
wrapper
iris = datasets.load_iris()
self.entries.append(entry)
[1]
UW_duration = np.busday_count(MDD_end, UW_dt)
session = request.db_session
hours, minutes = divmod(abs(offset), 100)
print(repr(item))
using_ones_cumsum(array1, array2)
print(message)
modules[current] = __import__(current)
stop = np.append(stop, A.size - 1)
[1, -1, -1, 1, -1]
recalc_hour.delay(prev_hour)
listmix.ListCtrlAutoWidthMixin.__init__(self)
index1 = random.randint(0, last)
s = {1, 2, 4, 5, 6}
diffed.iloc[(0), :] = grouped.iloc[(0), :]
retval.value
web.input(**keyword_args)
print(list(info))
np.import_array()
Total = Total + int(Number)
parts = (format % MarkPlaceholders()).split(UNIQ)
df
s = json.dumps(a, default=encoder)
7 * A.f(self, num)
885216
744552
744724
745520
cairosvg.svg2png(bytestring=svg_code, write_to=fout)
unflatten(res)
minorticks = p.norm(np.arange(1, 10, 2))
print(Apple, Pear, Orange)
response.raw.decode_content = True
wines_query = db.Query(Wine).ancestor(winery_key)
assert self.field_one != value
lasagne.layers.set_all_param_values(network, param_values)
counts[current] += 1
n_j_k[j][k] -= 1
po.apply_async(sort_fn, (any_args,), callback=save_data)
0
actual_f = f(x)
content = content_file.read()
self.start = self.timer()
negatedEven.append(v)
n.close()
print(res)
do_things(f)
a = int(0)
print((probs_y2.dimshuffle(0, 2, 1) - probs_y).eval())
line, = ax.plot([], [], lw=2)
instance.attribute = value
c = collections.Counter()
x = np.random.rand(N)
cls.entries = db.relationship(Entry, viewonly=True)
image = MIMEImage(img_data, name=os.path.basename(ImgFileName))
string_types = str,
print(result)
self.view.uri = self.post.uri
layout = device.get_result()
response = urllib.request.urlopen(url)
out, err = p.communicate()
pool = Pool(8)
df
pkts.append(x)
num1 = 20 if someBoolValue else num1
g
smallestInt = min(numbers)
p = genprimes(100)
i += 1
a = np.random.normal(size=(5000, 1000))
c = len(u)
cv.EqualizeHist(smallImage, smallImage)
in_side(p, v1, p1, n - 1) or in_side(p, p1, p2, n - 1)
X2 = np.array([0, 0, 1, 1])
FAILED(failures=2)
np.power(lat_dif, 2, out=lat_dif)
nx.draw_networkx(G, pos=nx.spring_layout(G), node_size=node_sizes)
r.load_memory()
result = []
g = parser.add_mutually_exclusive_group()
data[..., :-1][white_areas.T] = 255, 0, 0
app.autodiscover_tasks(lambda : settings.INSTALLED_APPS)
names_fmt = [name_format(name) for name in names]
B
sampwidth = 2
original(a).strip() == new
spud.foo(n=n)
writer.writerows(result)
print(reversed)
pylab.subplot(2, 2, 2)
self.words[word.rstrip()] = key
totals = {(p + t) for p in getPoints(i) for t in totals}
int
cols = df.select_dtypes(include=[np.object]).columns
time = [(0) for i in tup]
request.GET._mutable = True
lst = list(x)
False
row_col = point_grid_id(float(x), float(y), minx, maxy, size)
z = x[1]
index.put(document)
self.ui.dragDataEdit = myDumpBox(self.ui.centralwidget)
start = i * chunk_length
False
l = l[current_size:]
A = rand(1)
rescue
binding.pry
flag = np.ones(len(c), dtype=bool)
nbors.append(i - A)
1
f({(0): 0})
lasagne.layers.set_all_param_values(network, all_params)
signal.alarm(5)
p.join()
tmp[:, (i)] = np.sum((window - pattern) ** 2, axis=1)
which = random.randrange(1, total + 1)
scn = Blender.Scene.GetCurrent()
print(n)
print(x * y)
p = point(x=1, y=2)
print(s.strip_inner())
os.mkdir(__cache_dir__)
pyplot.colorbar(img, cmap=cmap, norm=norm, boundaries=bounds, ticks=[-5, 0, 5])
Person(*[person_args[x] for x in Person._fields])
df
B()
dirs = []
tdm.append(stopped_tokens)
content = f_opener.read()
Delta = 20
res = []
print(args, kwargs)
array = np.asarray(array)
menubar = tk.Menu(parent)
t, frac = divmod(t, 1.0)
fig.line(x, [(i ** 2) for i in x], color=color, line_width=2)
page = etree.HTML(res.text)
NEL
y = [0, 1, 4, 0]
b = [1, 2]
now = datetime.datetime.now()
i.join()
Y = matplotlib.colors.hsv_to_rgb(Y)
zip(s2.index, s2.values)
print(args)
n, _ = np.histogram(x, bins, normed=True)
register = template.Library()
yn = y + np.cos(2 * np.pi * time[i] / 8.0)
line = line.strip()
raise Http404
substring in tokens
g_(5)
vote = Vote.objects.get(answer=answer, user=request.user)
dx, dy = self._transform.transform((self._dx, self._dy))
item
handler = open(file).read()
resultMD5, filename = p.communicate()[0].split()
sf = df.filter(sf.time > date_from).filter(sf.time < date_to)
out = np.fft.irfft(tr1 * tr2, n)
i = 0
px = im.load()
time.sleep(0.2)
logfile = blah2.log
dataGrid = dataGrid.sort_index(axis=1)
print(result.summary())
last_score = [0] * (np.max(page_id) + 1)
exist = False
positive = posneg_calcsums([item for item in items if item > 0])
user = nobody
out[:, (j)] = a_lu.solve(b[:, (j)])
hildonize_window = _fremantle_hildonize_window
bins[i] = 1
newlist[dicpos[k]].extend(val)
start = time()
rv
print(s, type(s))
Xcum = np.zeros((T - H + 1, k))
file_length = fp.tell()
print(key)
coup_sum += sin(theta[j] - theta[i])
f.show()
ax = fig.gca()
y_reshaped = np.reshape(y, (y_rows * y_columns, y_channels))
list.append(item)
only_names.append(entry[0])
self.queue = Queue()
self.vmin = 0
l = leg.legendHandles[1]
fillvalue = object()
1
choldowndate(R_, u.copy())
result = set()
secret_data_X2 = np.linspace(1, 2, 100)
1 / 0
box.config(state=tk.NORMAL)
s1 = s.strip()
n = len(a)
G.remove_edge(*edges[x])
tsite.protocol.producer = producer
crawlerProcess.install()
date = fields.Str()
data = file.read(SIZE)
logging_handler_out.addFilter(LessThanFilter(logging.WARNING))
clf = DecisionTreeClassifier().fit(X, y)
dir(__future__)
open_tags = open_tags[i + 1:]
process_the_file(f)
set2 = set(list2)
INFINITE = 4294967295
SYNCHRONIZE = 1048576
cv_im = pil2cv(pil_im)
data = np.array(vector, dtype=types)
L = []
ctx
command_line = shlex.split(command)
[self.map[hash(token)] for token in s]
values[l[0]] = dict()
print(a)
indices_bigger_than_threshold = np.where(signal > threshold)[0]
compiled = source.Compile()
print(i + ++i)
df
max_exp = sys.float_info.max_exp
path_to_script = get_main_dir()
lR = RAWR
img.point_data.scalars = s.astype(float).ravel()
i = int(floor(-log10(max(errplus, errmin)) + 2))
ans = network.receive()
column_set = set(columns)
dx = width / len(neighbors)
b = [set(range(i, i + j)) for i, j in a]
editor = models.ManyToManyField(User)
centers = np.mean(extents, axis=1)
val = fooArray.frompointer(val)
match_indices = np.arange(result.size)[(result > confidence).flatten()]
bitbucket.org
x = 0
self.write(result)
chunk_length = len(result) / channels
dict(items())
print(invertdict(invertdict(canonical)))
age.get_group(21)
acts.append(make_lambda(i))
head = np.zeros((11, 101))
data = data.reshape(len(data) / 2, 2)
output = tf.gather(input, 0)
print(i)
compiled_regex.match(m)
io.truncate()
f = Lambda(x, x ** 2)
size_line = match.group(1)
146
c.cursor(0)
l += l
docs = list(cursor)
st = os.stat(somefile)
ax1.set(yticks=dat.index.values, yticklabels=dat.Labels.values)
y_list = {key: value for key, value in zip(result, y)}
dfWeeks
sum(times) * 1.0 / len(times)
counts[value[1]] = counts.get(value[1], 0) + 1
ans = sum(1 for a in A if a - k in H)
print(e)
calc_plane(x, y, z)
tst.result_id = result.id
outprof = lcms.cmsCreate_sRGBProfile()
self.stream.close()
n_max = (smax - 1) // coef2[0]
X_train = vectorizer.fit_transform(train_data1 + train_data2)
y = a - b * np.cos(phi)
td.start()
myclass = MyClass()
self.es = Elasticsearch(hosts=hosts, **kwargs)
V = 5 * NP.random.rand(2000000.0).reshape(-1, 2)
result
_NestedClassGetter(), (factory, ParentClass), state
subprocess.PIPE, stderr = subprocess.PIPE, cwd = self.cwd,
temp.create()
fig = plt.figure()
form
df
http.server.test(HandlerClass=MyHTTPRequestHandler)
buf = bytestream.read(rows * cols * num_images)
result = np.zeros((sampleSize, 2), dtype=np.int64)
INPUT = pyexample.py
s_obj.ob_shash = -1
result = []
no_rep = set(letters)
grokster = t.trundle()
dt = 2
print(name)
model = models.Category
line = stderr_queue.get()
next = random.choice(list(x[last]))
BitsInteger(1)
ans.append([[arr[i]], [arr[i + 1]]])
i = 0
IP_PMTUDISC_DO = 2
print(Levenshtein.distance(string1, string2))
na_free = df.dropna()
output = []
kdev = np.minimum(kde_val, 1 - kde_val)
A = np.random.randn(10)
mn2 = min(i for i in list1 if i != mn)
xmldoc = minidom.parse(filepath)
mysql_time_epoch = calendar.timegm(mysql_time_struct)
0.208, 0.2, 0.21, 0.25, 0.2, 0.19, 0.216, 0.22, 0.224, 0.26, 0.229
clean_table_grouped = clean_table_grouped.head()
self.password = password
arima_mod = sm.tsa.ARIMA(df, (p, d, q)).fit(transparams=True)
newList = [item, commaItems[i + 1]]
v = PyString_AsDecodedString(str, encoding, errors)
a = b = 1
s
api = tweepy.API(auth)
print(formatter.vformat(s, (), mapping))
num_lock = 2
total.update(i)
print(x * y)
name = orginalName.strip()
sys.exit(-1)
obj[prop] = getattr(myinstance, prop)
resultlist.append(l)
{M for M in E for N in K if dist(M, N) <= 1}
begin = datetime.date(2001, 1, 1)
root = os.path.realpath(root)
p = argparse.ArgumentParser()
factor = (1.1 - 0.9) * np.random.random_sample((sy, sz, sx)) + 0.9
self.store[i] = key, value
self.tickcount = 0
sys.stdout = f
a = np.ones(10000000, dtype=np.int64) * 500
indices = [0, 5, 12, 17]
_format.setFontItalic(True)
cmap2 = CustomCmap([1.0, 1.0, 1.0], [0.02, 0.75, 1.0])
number_of_processes = 5
1
print(p.ne(p.shift()))
item = L[x]
name2index = dict((name, index) for index, name in enumerate(readnames))
final_subnets[:20]
print(type(node).__name__)
editor.setUseTabs(use_tab)
user = get_user_num()
self.position += len(string)
canvas = FigureCanvas(fig)
stop = min(limit, n - size + 1) + 1
m = len(df)
outcsv = csv.writer(outfile)
2
parsed.append((e, fmt, t))
rad = np.power(np.sum(np.power(centers - target, 2), axis=1), 0.5)
h()
array
print(a is b)
last_choices.append(c)
absmax = rmax or np.abs(X).max()
b = wx.EmptyBitmap(w, h)
xtile, ytile
div_sum = sum(x for x in range(1, num) if num % x == 0)
format_float(buf, sizeof(buf), v, PREC_REPR)
primfac.append(d)
icon_theme = Gtk.IconTheme.get_default()
arr = np.random.rand(samples)
r.fillna(0)
print(find_parent(B, class_set))
plt.minorticks_on()
display.blit(mandel_surface, (0, 0))
bytes.append(chr(num % 256))
N = 4
item2node[ch_node] = ch
client = bigquery.Client.from_service_account_json(path_to_key.json)
total = total + len(d[key])
cos(x) + cos(y) + cos(z)
Base = declarative_base()
self.count += 1
r, g, b = np.array(im).T
x = 2
plt.plot(W, cut_f_signal)
df_10 = df.ix[rows]
self.salary = salary
conn.authenticate(url, consumer, token)
view_2_noblock.block = False
SelectFileForValidation.click()
result = set()
raise IndexError
clf = SVM()
attr_val = urljoin(base_url, attr_val.strip())
self.get(section, key)
HttpResponseRedirect(passwords_url)
walk(tree, this)
g1 = nx.petersen_graph()
s = StringIO.StringIO()
retval += traverse(node[1][1])
dx = x[..., (np.newaxis)] - x[(np.newaxis), ...]
silent = os.open(os.devnull, os.O_WRONLY)
params[key] = value
lats = np.sin(longs) + np.random.rand(len(longs)) * 0.1
parser = htmlparser.HTMLParser()
self[out[0]] = out[1]
id2token[token2id[onemap]] = onemap
self.figure = Figure()
models = Customer.objects.filter(id=id, user=user)
d.shape
mlg.conjugate_verb(verb, mode)
t(value)
plt.margins(0.05)
result = flag.value or bool(o.name)
print(s)
map = mmap.mmap(f.fileno(), 0)
self.sc = iter(self.scenario)
s = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_RAW)
h = fromstring(html)
df2.iat[row, col] = df.iat[row, col]
df.values
i = 1
self.name = name
[1.0]
instances = session.query(model.SomeObj).all()
today + DD
bins = np.arange(0, 100, 10)
flags_save = fcntl.fcntl(fd, fcntl.F_GETFL)
rx = re.compile(numeric_const_pattern, re.VERBOSE)
fmt
src / src / org / renpy / android / PythonActivity.java
self._callback(self._total, len(data), *self._args)
iterer = iter(iterable)
old_f = sys.stdout
content = fp.read()
d = defaultdict(list)
print(prune(counts))
self.instant = False
years = [point[0] for point in group]
exc_type, exc_value, exc_traceback = sys.exc_info()
n_data = len(x)
total = 0
bins_log_cntr = bin_edges[1:] - bin_edges[:-1]
cache = [v]
data[slc[:, (0)], slc[:, (1)]] = 1
dis.dis(debug)
count += 1
t = YourThreadClass()
n
False
sys.stdin = Tee(input_handle=sys.stdin, output_handle=sys.stdout)
u, s, vh = numpy.linalg.svd(A)
[1, -1, -1, 1, 1]
x = np.arange(xmin, xmax + dx, dx)
table = zip(*transpose)
marked_text
posts = []
corr = df.corr()
my_cmap
x.nodeValue = x.nodeValue.strip()
subset1, subset2 = divide_data(data, column, cut_point)
bucket = f.read(500)
plt.figure()
readme_link
self.delays = self.l[0]
print(df)
x[0] = fractions.Fraction(1, 1)
e = q.get()
path.pop()
root = et.parse(filename)
z_dense_smooth_rbf = zfun_smooth_rbf(x_dense, y_dense)
model, created = get_or_create(item_model)
Py_DECREF(iterator)
UNION
HexDumpWidth()
print(repr(1))
data_array[i] = color
start = length - 1 if step < 0 else 0
result
s.send(data)
print(key, value)
root = Tix.Tk()
os.remove(self.get_old_thumbnail_path(old_path))
perms = np.array(list(IT.permutations(list(range(ncols)))))
idx_batch = set(sample(list(range(len(my_deque))), batch_size))
data = json.loads(string)
update_a = tf.assign(a, b + c)
row = pd.Series([5, 6])
self._d[0]
amqp = celery.bin.amqp.amqp(app=celery_app)
y[Ai[p]] += Ax[p] * x[j]
d1_filtered == d2_filtered
ix, iy = event.xdata, event.ydata
print(dic[list(dic.keys())[0]])
iptc.Rule.__init__(self)
flatten_fieldsets(self.declared_fieldsets)
result[file1[key]] = file2[key]
x
temp = str(i)
app = Flask(__name__)
dates.sort()
ax = gca()
obj.update()
mask = np.asarray(np.invert(np.tri(R, R, dtype=bool)), dtype=float)
d = {x.firstname: x for x in mylist}
d = data_t[start_idx:start_idx + timesteps]
i[0] = 5
self.model = model
unittest.main()
line = line.strip()
s = Session(e)
s.close()
d.dt = datetime.datetime.now()
print(arr[0:2])
self.method = method
self.content = decruft(self.content)
pts = np.where(cimg == 255)
putstr(data)
n = int(s, 2)
assert isinstance(line, bytes)
new_values = []
outer_slice[1]
self.x = 1
[hint_tuples(e) for e in item]
i_list = [0, 0, 1, 2, 2]
code.py
print(dict(t))
bdevi.GetAllProperties()
Base = declarative_base()
response = requestOpener.open(request)
self.scroll = QtGui.QScrollArea()
part = math.floor(part)
index = 0
install(linux)
Tom
cols, dtypes = zip(*((c, t) for c, t in df.dtypes if c not in by))
printItems(z, 0)
x = x.copy()
herear = numpy.asarray(here)
result[len(result) - 2:]
print(seq[2, 4])
HTTPMovedPermanently(request.route_url(name))
results = []
NotMn = set([])
print(x)
prefix_len = min(prefix_len, len(x))
set_a == set_b
root = tkinter.Tk()
diff = end - current
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
a = numpy.array(a)
r = fce()
ids = [z for k in volumesinstance for z in k.instances]
h = np.flipud(h)
agency_list.append((a.id, a.name))
factors2[k] /= f1
model, pathlist = tree_selection.get_selected_rows()
self.send_blob(k)
e = pygame.event.wait()
pd.Series(l)
b[ds]
name = os.path.join(settings.PRIVATE_MEDIA_ROOT, path)
where(bitwise_and.outer(arange(2 ** n), 2 ** arange(n)) > 0, a, 1).prod(1)
pathname = os.path.normcase(os.path.realpath(pathname))
emitted = next_emitted
ave_score = np.mean(scores)
print()
movie_dict[actor] = key
n = len(s)
self._locked
results[i - 1]
result
map(max, abs(a[2] - a))
print(a.answer)
tweets = []
rot = np.rad2deg(np.arctan2(*np.abs(np.gradient(xscreen)[0][0][::-1])))
my_curve2 = np.interp(x2, x, my_curve)
Modar
tomorrow = d + timedelta(days=1)
k, v = old_dict.popitem()
print(c)
frame = sys._getframe(2)
ugrid.SetPoints(points)
inputFile = sys.stdin
final_step = twitter.get_authorized_tokens(oauth_verifier)
result = []
BW = orig[:, :, (2)] < 128
list1 = list()
contents = self.fileobj.read(size)
time.sleep(4)
self._callback = callback
dummy_event = threading.Event()
ser.setRTS(False)
print(foo)
python2 / Users / jakevdp / Library / Jupyter / kernels / python2
hc = hashlib.sha256(json.dumps(c)).hexdigest()
line_list = line.split()
x.dtype
plotgauss1(histdist[1])
ret = []
parsed_url = url_parse(url)
pc_dud_.remove(d2)
a[1] = 10
graph = defaultdict(list)
print(err)
self.assertTrue(special_eq_for_numpy_and_tuples(x, y))
A.c
y = 10 ** 9
{{item.name}}
res
-1
s = 0
data = np.random.rand(1000)
pv.append([0, 0])
print_pair(pair)
img = Image.fromarray(rgbArray)
mult.multiply(4, 5)
videos.append(video)
Base.metadata = metadata
a1, b1 = map(encode, (A.T, B.T))
wn.path_similarity(dog, car)
test(1)
self.n = n
noon
yesterday
data = scipy.misc.imread(fname)
sip.setapi(name, API_VERSION)
PyListObject * list
y, binEdges = np.histogram(data, bins=100)
results = []
y = np.arange(j - size, j + size)
fig = plt.figure()
W = fftfreq(signal.size, d=time[1] - time[0])
print(p.dfsh(6))
new_x = np.linspace(min(x1), max(x1), new_length)
print(str(response))
width = 1
new_same_a_different_b
cls()
print(i)
ws_index_list = [1, 4, 5]
s.add(d[i] == Concat(goal[2 * i + 1], goal[2 * i]))
pid = os.fork()
b64_data = base64.encodestring(raw_data)
SgmlLinkExtractor(process_value=delete_random_garbage_from_url)
print(a)
B = fftpack.fft(b)
os.remove(dll)
__metaclass__ = fancytype
self.store = dict()
data = np.random.randint(-1, 2, (10, 10))
s
9
q.d()
img = gimp.image_list()[0]
print(df.dtypes)
lis2 = list(strs) + list(strs.upper())
arr = np.asarray(variable)
value = Status.STATUS_ERR_NULL_POINTER
list_b = [5, 8]
x = float(xstr)
out_file.write(base64.b64decode(data))
a = A()
statinfo2 = os.stat(self.thumbnail.path)
request = Request(url, callback=lambda r: self.parse_url_contents(r))
dic = defaultdict(int)
doc.make_links_absolute(base_url=url)
np.array(out)
_decorator
transCount += 1
endDate = date(startDate.year + 1, startDate.month, startDate.day)
Rectplace = pygame.draw.rect(window, (255, 0, 0), (100, 100, 100, 100))
coords = fig.transFigure.transform((0.1, 0.5))
obj = list(obj)
listOdd = list1[1::2]
to_dir = os.path.relpath(root, prefix)
allSimplePaths(u, v, thisPath)
self.write(delim)
self.flag = asyncio.Event()
pc
app = moc.app
total += a
extension = Column(String(20))
test_date += one_day
x, y = work.pop()
multi_line_word << (split_word + multi_line_word | word)
pylab.subplot(2, 2, 4)
g = []
data = form_or_json()
bob.circle(radius)
partition.append(k)
dfasdict = to_dict_custom(df1)
output_from_parsed_template
print(OldList[0]._data)
new_tasks = []
print(mylist[i])
digits[x]
A = numpy.zeros((50000, 1000000), dtype=bool)
cls.__metaclass__.lineage
stack.push(child[0])
N = len(a)
y = np.linspace(0, 10, N)
is_efficient = np.ones(costs.shape[0], dtype=bool)
attachment = attachments.Item(i + 1)
x = np.linspace(0, 10, 501)
s = self.bitlist
subform.initial = data
array
SPRT_RECT_Y = 0
deletea, b, c
print(type(temp_rdd_dense), type(temp_rdd))
2009 - 1 - 2
k = 0
self.simulRunner.moveToThread(self.simulThread)
print(m)
points = [(random.random(), random.random()) for i in range(100)]
hours = int(time[:2])
minv = min(data)
output.write(outputStream)
print(latex(uexpr))
self.words = {}
f = Obj.objects.get(id=obj_id)
self.textPass = QtGui.QLineEdit(self)
conn.close()
rest.sort()
dcap = dict(webdriver.DesiredCapabilities.PHANTOMJS)
result, self.ix[labels]
num = np.zeros((word_count, word_count))
y1 = np.random.rand(10) * 20
c += i
nz = np.nonzero(a)
lists = files.readlines()
194
199
182
195
206
208
first, last = first_and_last(g)
response = datasets.list(projectId=PROJECT_NUMBER).execute(http)
time_val = self.time
a = 0
y = np.sin(x)
x * y
wave[t] = math.sin(2 * math.pi * index / sample_rate)
D2[w[0] + w[2]].add(w)
self.b = b
Y = iris.target[(iris.target == 0) | (iris.target == 1)]
x = sin(t)
x = 5
p += seplen
stream.Open(outfile, SpeechLib.SSFMCreateForWrite)
path = []
result = []
ls = (np.subtract.outer(item, item) ** 2).sum()
clean_chunked
[]
root.mainloop()
writer = csv.writer(dest)
true
time.sleep(0.2)
cleaned_html = cleaner.clean_html(html)
newParsed = eval(parsed[0])
st_birthtime
clipped = tf.clip_by_norm(weights, clip_norm=threshold, axes=axes)
exprs = [count_not_null(c) for c in df.columns]
f = lambda *args: args[0] + args[1]
newshuffle = random.shuffle
queryset = OCompraDetalle.objects.all()
a = array(A)
close(c)
as_strided(arr, shape=newshape)
x.extend(i[0])
mixins.UpdateModelMixin,
KeyUp(Base[Combs[Key][1]])
raise WinError(get_last_error())
self.contents.append(x)
self._config = config
new = []
parent_thread.join(interval)
it = iter(it)
output[col] = pd.Series(value, index=output.index)
pair = defaultdict(dict)
self.widget.update(blah)
results_dict[a] += b
S = zlib.compress(T)
p_as_list = p_as_list[-1]
dataDict
handle = rsvg.Handle()
replace_all(new_exp, permutation)
d.add(qrw)
glDrawElements(GL_QUADS, 1, GL_UNSIGNED_SHORT, indices)
print(width_format.format(word1, word2))
serializer_class = BookSerializer
content = f.readlines()
print(time.time() - t)
block_mean(ar, 5).shape
arr = np.arange(100000)
X, Y = meshgrid(x, y)
module = imp.load_source(modname, os.path.join(root, fname))
sum(x == key for x in iter)
0 < ----------------4
M[(i), :]
a = params[0]
max_group_id += 1
what()
obj = container.create_object(filename)
True
self.exception = exc_value
example.shape
loader.close()
hdu = pyfits.PrimaryHDU(H, header=header)
aplusb(97, -99)
tot += 1
largest_index
a = list(range(100))
raise
X = scipy.zeros((len(interests), len(allinterests)))
endif
indent_type = 0
words.append(tens[t])
total_n = t1 - t0
getattr(self, field.get_cache_name())
A = 5
mytz = tzlocal()
d = defaultdict(list)
print(answer)
style = btn.get_style().copy()
target = NP.empty_like(source_vec)
end = chunk_start + chunk_length
s.add(foo2)
serializer = PostSerializer(posts)
dated_files.reverse()
obj.name2()
print(item.doc_count)
line_counter += 1
data = book[0][1]
includesFile.close()
True
func
a = []
p.__dict__
value + value2
slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)
arr = arr.astype(np.complex)
total += number
K, A_log = np.polyfit(t, y, 1)
self.SetColumnWidth(colNum, wx.LIST_AUTOSIZE_USEHEADER)
date_as_string = str(date_in_some_format)
df1.user_id,
numStrLen = len(numStr)
new_file_hash, nchunks = hash_for_tile(new_file)
serial.serial_for_url(dev)
m.drawcountries()
hash = hashlib.md5(output.getvalue()).hexdigest()
rootLogger = logging.getLogger()
output_list.append(data_type)
xj = pos[j, 0]
propagate = 0
deletefoo[:]
dataset = bq.Dataset(bigquery_dataset_name)
print(df)
list_of_tuples
do_stuff_with(self, init_args)
connections.remove(connection)
today = now.date()
next(f)
lower_white = np.array([0, 0, 0], dtype=np.uint8)
subset[subset.isin(myList)].stack()
current = sum(negatedOdd[i:i + d])
self.hidude = hidude
label.set_alignment(0, 0)
transf1d(fdat, xdat, ydat, odat, Nx, Ny)
index = 0
capturer = StringIO.StringIO()
top_features = sorted(features, key=lambda x: x[1], reverse=True)[:top_n]
effectList = []
logger.setLevel(logging.INFO)
c = s.get(url, params=payload)
root
jpeg_image_buffer = cStringIO.StringIO()
row = int(cell_entry.cell.row) - 2
x = 2
letter_lookup[letter.upper()]()
obj = Int(42)
table[tuple(bool(int(x)) for x in inputs)] = bool(int(output))
expr = (a * b) ** n
id(a), id(b)
func = A.my_method
mod = importlib.import_module(testName)
sc.nextInt()
MyError()
bad_rows = [row for row in grid if not sudoku_ok(row)]
i = 0
raise SomeException()
im_floodfill = im_th.copy()
do_things_here()
args = func_args[len(arg_names):]
ca.Values = (c_float * 2)(v[0], v[1])
numbers = [[t[1] for t in items] for _, items in grouped]
vals = [12, 0, 0, 0, 0, 0, 0, 0, 7, 0, 10, 11]
print(fib(n, m))
maxx = gt[0] + width * gt[1] + height * gt[2]
arg = arg()
a.foo()
lat = np.deg2rad(lat)
abs(self.length) / 2
code = ord(unichar)
app.register_blueprint(child.child)
print(match)
-1
self.level += 1
key
NULL
y = 1 / u * np.sin(phi)
fig = ax.get_figure()
cluster_means = np.array([np.mean(data_flat[labels == k]) for k in range(N)])
out = (stop + start + 1) / 2.0
show()
file_contents = f.read()
field_info
company, was_created = Company.objects.get_or_create(name=info)
options, command = parser.parse_args()
dot = p.dot(A.reshape(A.shape[0], -1)).reshape(A.shape[1], -1)
id_arr[lens.cumsum()[:-1]] = -lens[:-1] + 1
print(item)
ticks = ax.get_xticks()
stdout = output[0]
(all_CMs == all_CMs2).all()
keyPos = 0
a[s] = 0.0
next(it2)
alert(tagbs[0].fields.ParentVideoFile)
im2 = Image.open(imagePath2)
print(df)
timer = fig.canvas.new_timer(interval=100)
current_time = datetime.utcnow()
color = cm(1.0 * i / NUM_COLORS)
out[i] = 1
substring = match.group()
insort_case_insensitive(myList, x)
bg.add_nodes(range(nnodes))
loop.run_until_complete(main(loop))
protocol.waitForWhatever()
assert answer([1, 1, 1, 1, 1, 1]) == 20
clf.tree_.feature
InputID
all_dict = dict(zip(xs, x))
denominator = log(factorial(8000)) + log(factorial(2000)) + 8000 * log(10)
i + 1
memdc = srcdc.CreateCompatibleDC()
schema.deserialize(mixed_type)
n, bins, patches = plt.hist(data, bins=x, normed=True)
myfunc()
nums = set(nums)
user = User.objects.get(username=username)
chain(iterable, repeat(padding))
0.0554857286941
obj = str.__new__(cls, value)
num += alphabet.index(char) * radix ** power
img = matlab.workspace.get_image(some_parameter)
key
print(x.player.name)
image = tf.squeeze(image, squeeze_dims=[0])
reader.ReadAllScalarsOn()
treat_str(agg[y])
lst = [sys.maxsize]
sys.exit(1)
raise StopIteration
result = []
Xgrid = Xgrid.reshape([DenseSize, 1])[:, (0)]
print(B().__dict__)
e = 5
string[index:]
first_name = models.CharField(max_length=255)
self.canvas = wxagg.FigureCanvasWxAgg(self.panel, -1, self.fig)
self.session = session
bufsize = len(a) + 1
ChildForum = aliased(Forum)
Foo.__hash__ = lambda self: hash(self.item1 * self.item2)
docs = yaml.load_all(stream)
v = dict(x)
print(row)
PROJECT_DIR = os.path.dirname(__file__)
index()
end = time.time()
True
corr = np.corrcoef(xs, rowvar=0)
n_cpus = psutil.cpu_count()
tries = 1
i = 0
deleteself._graph[node]
index = days.index(weekday)
traverse_registry_tree(_winreg.HKEY_LOCAL_MACHINE, keypath)
j = len(s)
count = 0
NOW = pd.to_datetime(str(DT[-1]))
x[1, 1, 2]
r[otherAch] = r.get(otherAch, 0) + 1
j += 1
type.__new__(cls, name, bases, dict_)
x2.sort()
track_1 = np.array([1, 2, 10000])
statinfo1 = os.stat(self.photo.path)
filename = proc.stdout.readline()
[7, 7, 8, 8, 9, 9],
lastCol = ubound(pyvalue(rowIndex))
pprint.PrettyPrinter._format(self, object, *args, **kwargs)
rsi_series[i] = 100
queue = {}
response.app_iter = f
s
test_dict = defaultdict(lambda : 1)
to_process.append(n - 2)
self.midpoint = midpoint
df = df.reset_index(drop=True)
layer
gradst
render_visitor(request)
end = len(A) - 1
unknown_compressed_data = response.content
proc.terminate()
print(all(prev <= cur for prev, cur in zip(prev_it, cur_it)))
self.number = self.new_number()
a = list(cmd)
m = interp1d([1, 512], [5, 10])
cythonize([ext])
a_list
ybins, xbins, _ = ax.hist(series, bins=nbins)
v = df[cols[i]].values
rolled_view[1::2, :] = rolled_view[1::2, ::-1]
print(myList)
prev = next(it)
u = zip(a, b)
x * x
idx = x_idx + (n - 1) + (y_idx + (m - 1)) * im.shape[1]
self._paragraphs.append(p)
result
skip - locking
newfunc.rightmost_args = tuple(args)
fmap[fid] = 1
wfd.inc(w1)
test.prnt_.argtypes = [c_char_p, c_long]
message = xmpp.Message(to, msg)
log(b)
main.show()
aa = a[:]
s = client.get_transport().open_session()
words = []
second_list = [2, 5, 7, 9]
output.seek(0)
myOpt = MyOptimizer()
node
degrees, rest = intfloatsplit(d)
2
mylist[i] += str(counts[item])
pandas.version.version
f = Foo.objects.create()
rdd[the_index]
_pc_wrap(iptr, resultCLSID=wrapas or clsid_class)
ce.setFormatter(formatter)
gps_epoch_as_gps = datetime(1980, 1, 6)
variances = Add(*map(Variance, rv))
index = find(np.diff(crossing))
df
ix.close()
date = qdate.toPython()
options, args = parser.parse_args()
sys.exit()
surf = mlab.pipeline.surface(source)
f.close()
ex = Exception(1, 2)
p = list()
plugins.add(cls)
print(row)
job.run()
sock.setsockopt(SOL_HCI, HCI_FILTER, hci_filter)
painter.begin(self)
zt, yt, xt = x.shape
Base = declarative_base()
print(sum(times2) / len(times2))
theArray.fromfile(f, 1000000000)
cr.rotate(r)
b = json.loads(s, object_pairs_hook=decoder)
func
t2start, t2end
b = np.random.normal(size=(5000, 1000))
abcd = np.sum(data1, axis=1)
d = parser.parse(yourstring)
total = total + value
q.task_done()
listQ = listQ[minimum:maximum]
print(s)
tot = glrhs
res.reshape(a.shape)
rows, cols = a.shape
screen.setup(width=SCREEN_WIDTH, height=SCREEN_HEIGHT)
d[b[i:j]].add(k)
train_data = data[indices]
value
count[w] = 1
results = list(sum(islice(zip(a, reversed(a)), 0, int(len(a) / 2)), ()))
--Package
self.func = func
config.read(file)
self.next_mode()
hit = a.ix[:, :-2].dropna()
reply = shell.get_msg()
d, c, h
ret = res[0]
wrapper
x = list()
[-1, -1, 1, -1, 1]
isSQLServer = False
self._d = OrderedDict(*args)
module
test(**argsDict)
pairs = []
split_parts = [replace(stack, part.split(from_)) for part in parts]
w.join()
original_errmsg(msg, doc, pos, end)
response
foo + 1
self.finished.connect(slotOnFinished)
pyximport.install()
mylist[j + 1] = 0
formatter = dates.DateFormatter(date_fmt)
PyEval_ReleaseLock()
zipobj.write(fn, fn[rootlen:])
dy = pyi - pos[j, 1]
print(str(x))
self.__dict__[name] = value
md = MungedData(somefoo)
venv = venv
request.param
c = nltk.RegexpParser(p)
B = deque(A)
chomped_uri = chomped_uri[len(prefix) - 1:]
x, y, z = nodes_nummpy_array[:, (0)],
self._hash = hash(frozenset(list(self._dict.items())))
self._spam
z = abs(x)
groups_no_a.append(group)
print(template.format(*map(str, l)))
height = len(df.index) / 7 * 10
lst.append(element)
ip = ipapi.get()
self.content.append(string)
column_2 = column_1 - last_value
current = settings.TEMPLATE_STRING_IF_INVALID
login.html
x.data[i] *= b[x.rows[i]]
tmp = update(orig_dict.get(key, {}), val)
cw = csv.writer(fw)
session.expunge(obj)
lists = []
parsed_item_info.add(parsed_item)
data = parse_qs(response)
exclusion = s ^ t
fig = myGridPlotObject.fig
res = list(cube_generator())
print(original_string)
assert answer([1, 1, 1, 1]) == 4
revsubBin.append(revB)
test_indices = list(range(40, 50)) + list(range(90, 100))
output = {}
positionsList.sort(key=make_howCentric(boardSideLength))
I = quad(f, -dist, dist, points=[0])
file_to_adverb_dict = {}
hello.py | thisscript.py
my_file.num_of_sections
run
ba = bytearray([255])
fcntl.ioctl(console_fd, KDSETLED, all_off)
self._unauthorized()
phone = models.BooleanField(default=False)
productname = models.CharField(max_length=1024)
DEBUGGING = True
monkey.patch_all()
PREVIOUS_JOB.get_endtime()
self.getslice(key)
time.sleep(1.5)
res = {}
iflag_ptr.contents.value != 0
self.connectionMade()
f = open(filename)
func_list = [a, b, c]
sameLevel[level].append(idx)
self.fee + self.fee_gst
variable += 2
QUIET = YES
is_even = generate_is_even()
bobby_id = c.lastrowid
Counter(j)
_dispatch[YourType.__repr__] = _pprint_yourtype
record = smarter_nestify(l, {})
X = np.matrix(X)
0
modded = []
[-1, 1, -1, -1, 1]
True
uuid.UUID(bytes=value)
ele = ET.Element(self.__class__.__name__)
padded = pad_value * np.ones(2 * [max(m.shape)], dtype=m.dtype)
print(perm_list)
parsed_date
response.write(pdf)
devnull.close()
map = lmap
depth, size = a.shape
retval = Settings.query(Settings.name == name).get()
pos = [(x[-2] + x[-1]) / 2.0, (y[-2] + y[-1]) / 2.0]
a, b = 1, 2
start_time = time.time()
set(string).issuperset(set(substring))
XmaxY = [max(Xdict.get((i, j), 0), Ydict.get((i, j), 0)) for i, j in keys]
aaa.hostname
Installation and Operations
m, n = M1.shape[0], M2.shape[1]
top[0].data[()] = self.phase
time_start = time.time()
odds = []
root = ET.fromstringlist(it)
list_lens = [len(lst) for lst in lists]
row_mask = y == 1
inter.B
rdd = sc.parallelize(data)
foo = Foo()
11 - 0.000155
english
iseq = iter(seq)
sLines = [tuple(sorted(l)) for l in line]
queryset = self.get_queryset()
float.__init__(value)
d[1]
T = f.ThreadPoolExecutor(1)
np.nan
[1, -1, 1, -1, -1]
b = parse(a)
print(new_a)
somedate = datetime.date.today()
type(True)
kernvals = RBFSampler(gamma=gamma1, random_state=0).fit_transform(X)
conn = libvirt.open(name)
subscriptions = filters.get(word)
globs.add(names[next(op) + next(op) * 256 + extarg])
self.config[name] = value
print(df)
bb = np.array(b)
threads = [Thread(target=worker, args=(q,)) for _ in range(limit)]
last_col += abs(delta_len)
assert type(result) is dict
print(x)
self.instant = True
zip(it, it)
df_normalized = pd.DataFrame(np_scaled)
articles = []
p = p.filter(Post.date >= start_date)
low = high / 2
num_set.remove(start)
print(evenly_spaced(*iterables))
True
img2.seek(0)
print(validate(id_value2))
user
hyp = (my_split(h) for h in hypfin)
pytz.all_timezones_set
datetime.datetime.strptime(line[1:20], lfmt)
uinit = np.array([1.49907, 0])
python_time = total_time - db_time
df
l
log_y = log(y)
print(s)
config = ConfigParser.ConfigParser()
left = find_max(L[:mid_index])
config.read(propertyFileName)
exif.save_file()
self.environment_is_clean()
connect = np.ones(x.shape, dtype=bool)
results = generate_file_data()
formatter.format_help()
dst = src.copy() / 255
answer.append(m - sum(answer))
output[col] = LabelEncoder().fit_transform(output[col])
observer.stop()
vals[i] = vals[i] / M
conmut = (a, b),
signal = [c + np.random.normal(0, sigma_e)]
out = interpolate.splev(unew, tck)
x < -matrix(rnorm(10000 * 1000), ncol=10000)
print(a)
print(eval(command)(*sys.argv[1:]))
self.subdirs = {}
print(x)
cvtColor(im, gr, CV_BGR2GRAY)
a = b = 1
y0 = x + 1
Foo.__init__.__defaults__
exit / b
screen.dirty.clear()
print(anc.getText())
print(uniqB, numpy.bincount(inverse, weights=A.ravel()))
df = pd.DataFrame(iris.data, columns=iris.feature_names)
doSomethingWithFile(trueFile)
self._locked = True
a = np.arange(-10, 10)
nice.sort(key=lambda x: x[0])
animals = Animal.objects.all()
result = result + [(y + [x]) for y in result]
np.degrees(np.arctan(normalY / normalX)) + 90
tree = spatial.KDTree(np.array(points))
leng = numpy.sqrt(grad_x ** 2 + grad_y ** 2 + 1.0)
self.store = []
LOAD_LIBRARY_SEARCH_APPLICATION_DIR = 512
n = buildNetwork(d.indim, 4, d.outdim, bias=True)
total = 0
n = 0
foobar.foo = bar
X_r = pca.fit(X).transform(X)
decorated_func
xx0.append(x0)
s = 0
sorted(list(kwargs.items()), key=first_item)
a[1, 4, 8]
d.d
result += amplitudes[-1] * sin(harmonic * x)
self.arg1 = arg1
result = StringIO.StringIO()
dot(matutils.unitvec(self[w1]), matutils.unitvec(self[w2]))
i2 = (i1 + 1) % len(sorted_list)
timestamp = DateTimeField(default=datetime.now)
h.itemset(i, j, 2, 0)
item_index = offset // BITS_PER_ITEM
plot(img50_nd[(50), :, (1)])
sorted(result)
loop = asyncio.get_event_loop()
MessageBox(text=str(e))
teams[self.team].append(self)
logger.disabled = False
h = HMAC.new(secret_key)
ps.print_stats()
title = models.CharField
[(x * mult_fact) for x in output]
data = models.TextField()
mag = np.fabs(array)
[(x, y) for x in lst for y in lst]
module.__file__ = filename
repetitions = 100
user = get_user_model().objects.get(**kwargs)
False
c0 = numpy.sum((data - mean) ** 2) / float(n)
it = (next(g)[0] for k, g in groupby(enumerate(x), itemgetter(1)))
parser = English()
print(stdout)
outStr += outQueue.get_nowait()
device = PDFPageAggregator(rsrcmgr, laparams=laparams)
corr = np.corrcoef(corr_x, rowvar=0, bias=True)
print(2)
C()
arr = [1, 5, 50, 500]
disown
kw.update(kwargs)
7.51020240784
res
image_center = tuple(np.array(image.shape) / 2)
output = second.communicate()[0]
bs4.element.Tag.select = bs4.element.select
func(myname)
line = [[(0, 0)]]
e = np.dot(e, D_inv)
dates, counts = grouped_dates.transpose()
bitmask >>= 1
((a - b) ** 2).sum()
fortnight(date)
i -= 1
red, green, blue, alpha = colour
model.add(Dense(nNeurons, input_dim=nFeatures))
to_remove -= 1
d[t2.key] = t2
runner = unittest.TextTestRunner()
a[y] = a[x][0]
pilImage = Image.open(StringIO(rawImage))
Service.remove(service_name)
second = queue.enqueue(second_job, depends_on=first)
print(lR)
connection.isolation_level
res = expr.parseString(test)
east_dt = convert(from_naive_dt, ph_tz, east_tz)
file.__init__(self, path, mode)
monty
action = argparse.ArgumentParser.add_argument(self, *args, **kwargs)
l1.extend(l2)
X[i, j, k, Y]
path.push(st)
[-1, -1, 1, 1, 1]
data = []
df2 = df.copy()
df_concat = pd.concat([melt_first_half, melt_second_half], axis=1)
mask = np.sqrt(X ** 2 + Z ** 2) < 1
x, y = numpy.array([[0.05, 0.1, 0.9], [0.05, 0.5, 0.9]])
print(output)
True
get_tree(child, dest_dict)
data = args[0]
engine.Operations.InvokeMember(pythonClass, method, arguments)
thread2 = threading.Thread(target=func2, args=(gen2,))
lowestsumsdict[groupkey] = minsum
np.percentile(rdd.collect(), 75), quantile(rdd, 0.75)
x + y
pool = mp.Pool(n_cores, initializer=pool_initializer)
Brenda
N(h, 6)
print(list2)
x + 5
values.read(fin, 1)
rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)
device = PDFPageAggregator(rsrcmgr, laparams=laparams)
result = MySchema.loads(request.json())
sys.platform
self.choice
d = dict.fromkeys(list(range(2)), empty)
alias()
indexes = [c for c in range(len(word)) if word[c] == letter]
r = ReadInts(filename)
ax.lines.pop(0)
reply = xbee.wait_read_frame()
ba = bytearray(list(range(100)))
translate_table = dict(zip(tabin, tabout))
t_step = Tsample * np.linspace(-n / 2, n / 2, n + 1)
pflat = scipy.array(phi_coord.flat)
c_points.cache()
unintialized_variables
doSomething()
connection_file_path = kernel.get_connection_file()
avatar = urlopen(url)
i_x = iter(x[1:])
N = 2
n += 2
NotImplemented
vals = list(vals)
Z = Z.reshape(xx.shape)
line = thefile.readline()
ss = numpy.array(decimal_s)
vander = vander.reshape((-1, vander.shape[-1]))
current_page = 1
data = np.zeros(10 ** 7)
self.console.write(msg)
self.element_tree = ET.parse(xml_file)
m.send(line)
d[(2), :] = numpy.asarray([my_list])
SimpleHTTPRequestHandler.end_headers(self)
t1.join()
d = {x: i for i, x in enumerate(OrderedDict(zip(a, a)).values())}
print(op[operation](num1, num2))
f(5, 20)
value2 = pickle.load(f)
self.queue = queue
dt = ts.replace(microsecond=int(frag))
A[i] = value
article_dates.write(l)
b1 = [False, True, True]
print(i)
mylist = [weakref.proxy(Foo())]
assert answer([1, 1, 1, 1, 1]) == 10
a, b = a * a - b * b + c[0], 2 * a * b + c[1]
L
tmpout = sys.stdout
buff.close()
[]
list(sub(word))
arr = np.asarray(image)
gpsp.start()
timeit.timeit(it)
match_hostname(sslsock.getpeercert(), hostname)
assert test_list[-8] == 1
print(mention.text)
wholeList = list(range(0, 10))
run_wsgi_app(application)
id_arr = np.ones(lens.sum(), dtype=int)
p2 = Point(0.5, 1)
backend.show()
x == y
self.nodes.append(node)
not self.__eq__(other)
something
__up_frame = inspect.currentframe().f_back
self.connecting = False
original_file.seek(0)
display.clear_output(wait=True)
authors = models.ManyToManyField(Author)
self.arg = arg
ArticleFormSet = formset_factory(ArticleForm, can_order=True)
y = [0, 0, 1, 1]
d = {}
result.append(B[section[idx]])
name = tables.StringCol(16)
ind = df2.user_id.isin(df1.user_id) & df1.user_id.isin(df2.user_id)
ns.close()
to_my_linking(s)
print(4 + 2)
_count = 0
self.script = types.MethodType(script, self)
screen = wx.ScreenDC()
result.insert(location, element)
event.setAccepted(True)
students = select(s for s in Student)[:]
chars = digits + ascii_uppercase + ascii_lowercase
False
lstopt = [str(item) for item in lstopt]
new_str
z = normcdfi(1 - 0.5 * (1 - c))
deleteself.data[key]
port = 50007
s = set()
unquote_to_bytes(s)
lib = importlib.import_module(lis[0])
output.append(name)
new_o[k] = make_hash(v)
[handler_logfile]
c.acquire()
x = 10
nperms = factorial(nballs)
consts.append(p.n)
result = result.replace(url.upper(), url)
df_grouped.name
m - v
title = db.StringProperty()
{{line.errors}}
rows, cols = a.shape
True
df_i = deriv_list[-1].diff(t).replace(sp.Derivative, lambda *args: f(x(t)))
run(2)
X_with_indicator_vars = [X, Indicator_cat, Indicator_dog]
fig.canvas.mpl_disconnect(cid)
now = pg.ptime.time()
Ygrid = Ygrid.reshape([BSizX * BSizY, 1])[:, (0)]
newScript.appendChild(newScriptText)
print(f)
print(args)
stack.append(obj)
y = list(range(8, 20))
sort_by = lambda x: x[1]
text = input(prompt)
print(s)
lag_lens = np.round(np.random.normal(lag_mean, lag_sd, n_iter)).astype(np.int)
sorted_arr = sort_arr()
frontier.append((vertex, -2))
self._handlers.append(handler)
ord(letter) - 97
data = urllib.parse.urlencode(forms)
imageComponents = image.split()
int(*func)(int)
str(5) is str(5)
y = 2
conn = Connection(max_pool_size=20)
df = df[df > 0.5]
screen = pygame.display.set_mode((1280, 1024), pygame.FULLSCREEN)
D = euclidean_distances(X_cluster_0, km.cluster_centers_)
d[std::make_pair(2, 1)] = 2
statvfs.f_frsize * statvfs.f_bfree
FT_02_LB = PyLint(full)
S = float(hsb[1] / 100.0)
difference = (later - now).total_seconds()
str(self.stuff)
quantity = models.IntegerField()
console = logging.StreamHandler()
bytecode.append(0)
ax = pylab.subplot(1, 2, 2)
print(single_remove(word, letter))
painter.translate(point)
s1[pos_a:pos_a + size]
xr = iter(range(100))
self._swapt = int(lines[14].split()[1])
label = Column(String)
enableEntryRadioButton.pack(anchor=W)
y2 = theano.clone(y, {A: temp[:-2], b: temp[-2], c: temp[-1]})
ret.extend(extrajars)
0
print(multi_dict.getlist(key))
schema = current_schema._get_current_object()
print(row)
print(hex(item))
strmap[string] = string
y = np.sin(x)
True
men.method_unique_to_women()
self.do_open(self.getConnection, req)
c.__call__
selector = XmlXPathSelector(response)
text
condition = expr + operator + expr
my_list = []
aaaaa
multi_dict[k] += 1
2
ps.add(a + b)
sequence[position]
c = textwrap.fill(b)
file2freq = defaultdict(int)
deferLater(reactor, 1.0, lambda : 20).addCallback(hello)
x = np.arange(N)
observer.stop()
df
line2.set_data(x, y2)
type(self), self._args, self.__getstate__()
get_plate() in licenses
new_list1 = []
om1, om2 = np.meshgrid(test_data, train_data[0])
form = CompetitorForm(request.POST)
seen = {}
dotplace = 1
resultList = List(set(first_list) | set(second_list))
item_model = item_to_model(item)
False
manager = Manager()
i += 1
z[0]
callback
date_key = curr_date.date.month, curr_date.date.year
df == 0
ydata = trueydata + 0.1 * numpy.random.randn(8)
print(z.uncertainty.array)
self.fake_namefile = tempfile.NamedTemporaryFile(delete=False)
self.linelocs = []
bars = ax.bar(theta, radii, width=width, bottom=bottom)
self._val = val
deltas_x = np.abs(array[1:, (0)] - array[:-1, (0)])
c[2] = 51794
df = DataFrame(1, index=s1.index, columns=s2.index)
transport and transport.is_active()
output_filename
defaults.insert(0, defltargs[func_arg])
root_dir = os.path.dirname(os.getcwd())
npa[:, (1)] = npa[:, (1)] * n
proxy.GetCursOnDate(input)
before_buf.append(line)
y = x[:50]
fd.write(myCsvRow)
x, y = np.random.multivariate_normal(mean, cov, N).T
alpha = max(alpha, score)
loop.start(0.1)
print(e[0], e[1])
aList
NL = [(R[I.index(x)] if x in I else L[x]) for x in range(len(L))]
True
a = A()
print(stdout.readlines())
local.timestamp()
print(y - x)
map(tuple, rotated + reflected)
ret = np.vstack(ret)
i, size = 1, 10
self.point[i]
v
x = string.ascii_uppercase + string.digits
sentinel = object()
m, n = arr.shape
sess = Session(engine)
int.__add__(self, other) * -1
mkdir / opt / portapy / virtenv
self.raw_tweets.insert(tweets)
batch_serialized_examples = tf.shuffle_batch([serialized_example], batch_size)
seta.union(listb)
[formatter_form01]
4, 5, 6
register = template.Library()
a[mySlice]
mapping[0]
answerlist.append(templist[d])
d = []
a.real[abs(a.real) < tol] = 0.0
outdeg = G.out_degree()
response = req.urlopen(request)
date_taken = db.DateTimeProperty()
data = np.random.rand(5, 100)
metadata = MetaData()
ts = ts.cumsum()
self.a = 0.0
outlist.append(n)
next(unique_num)
value = values.get(args.value)
objects = CustomManager()
r = Tk()
data = []
outpath = os.path.join(out_folder, filename)
result += sublist
x & 1 != 0
output_list.append(consumer_output)
rgbArray[..., (0)] = r * 256
s = s.strip()
x = np.arange(10)
movement *= zombie_speed
row = cur.fetchone()
msg.attach(audio)
ax = fig.add_subplot(111)
current_count = query.count()
[t.start() for t in tasks]
degreelist = list(range(100000))
current = 0
s = df.style.apply(highlight_last_row)
Mc[:, (i)] = sparse.csc_matrix(Mc[:, (i)].todense() + vec[0, i])
self.number = random.uniform(0.0, 10.0)
string_copy = [character for character in string]
print(fullname)
n = ord(c)
desc[2] == imp.C_BUILTIN
_error_msg = ctypes.c_char_p(0)
X = np.array([1, 0, 0])
y = np.asarray(y)
fkwargs = dict(self.pkwargs)
print(Foo.bar)
self.store[key] = value
query = session.query(table_a, table_b)
mainloop = gobject.MainLoop()
self.author
content = f.read()
a = sleepy(10, 0.001)
print(row)
word = word.lower()
mat_csr = csr_matrix((50000, 50))
msg = xmpp.protocol.Message(body=text)
b = 10 * np.random.rand(5, 5)
admin.autodiscover()
store = models.ForeignKey(Store)
type.mro(type(c))
max_seq_len = current_seq_len
self.set_y(-15)
asizeof.asizeof({})
marked = []
b = a[2:7 + 1]
f(2, 20)
self.dict[self.list[index]] = index
xPoints = np.arange(0, xlen + 1, 1)
self.stderr = stderr
b = example.B_t()
user.username = newusername
print(self)
goodrows = []
l[i + 1] = l[i]
writer.save()
self.coords = np.random.random((numpoints, 2))
test_client = yourapp.app.test_client()
result = subclass.get_all(session, result)
emails = []
out_file.write(cipher.encrypt(chunk))
b = set([6, 20, 1])
bytes = [170, 85, 0, 128]
users = User.objects.filter(email=email, is_active=0)
-1
self.sizer.Detach(self.log)
final_str
all(seq in s for seq in SEQUENCES)
line = thefile.readline()
im = np.where(im > 100, 0, 255).astype(np.uint8)
_, reg_type = winreg.QueryValueEx(INTERNET_SETTINGS, name)
text_len = len(text)
m_swapped = m.swapaxes(axis, -1)
style = self.default_style
print(local1)
processes = 4
buffer_df.iloc[0:-1, :] = buffer_df.iloc[1:, :].values
self.char_x += 10
h = hash(obj)
part = sock.recv(BUFF_SIZE)
handle(e)
pages = list(pdf.pages)
fh.setFormatter(formatter)
s.add(a1)
df1[2] = df1[2].str.zfill(2)
c.pack()
self._n * 0.5
mydict = OrderedDict()
height, width, depth = imcv.shape
print(getFactors(n, m))
http_request = request._request
child_methods = set(inspect.getmembers(child_cls, predicate=inspect.ismethod))
fig = g.draw()
X[outer_slice][inner_slice]
default_tagger = nltk.data.load(nltk.tag._POS_TAGGER)
readline.read_history_file(historyPath)
cdays = ds.cumsum()
fg.canvas.draw()
assert condition(a, b), ERR_MESSAGE_01
ExtractRequest().process_request(request)
normed = [(i / sum(raw)) for i in raw]
buf += os.read(fh, 1024)
setp(subplot.get_xticklabels(), rotation=x_rotation)
sub = stack.pop()
i.join()
[[0] * len(unit_list)]
mask = mask.reshape(Z.shape).T
indent[0] += 2
origs = list(s)
resultDate = todayDate.replace(day=1)
dst *= 255
atof(bigNumString)
newPhoto.image = file_mock
jobs.put(i)
presentation.Close()
self.w, self.h = self.im.size
allcities = self.country.city_set
iris = datasets.load_iris()
compiled = re.compile(pattern)
decorated
print(overlap(0, 100, 0, 20))
options = parser.parse_args()
copy2(srcname, dstname)
values = Parallel(n_jobs=NUM_CPUS)(delayed(f)(x) for x in range(1000))
key_list = split(key)
result = []
doc = etree.XML(data, etree.XMLParser(remove_blank_text=True))
sys.exit(1)
pid = os.fork()
GetLongPathName(tmp, buffer, len(buffer))
ax = dfstacked.plot()
print(probs_y.eval())
print(event.artist.get_gid())
data = []
n = int(math.floor(amount / cent))
dill.settings
weighted_quantiles -= weighted_quantiles[0]
4 - 0.006156
print(match)
keyed_b = ((n.imag, n) for n in b)
clf.fit(iris.data, iris.target)
a = ax.zaxis.label.get_rotation()
top_left = 50, 50
dir_p = opendir(path)
HOSTNAME = socket.gethostname()
mylog
result = OrderedDict()
qd = parse_qs(parsed.query, keep_blank_values=True)
new
credentials.refresh(httplib2.Http())
diffs = np.diff(mask.astype(int))
flat = ((d, id, t) for d in data for id in data[d] for t in data[d][id])
df.iat[i, i] = np.inf
sub.start()
retval
counter = 0
d = dirname(somepath)
AC_CONFIG_SRCDIR([rounding_swig / rnd_C.cpp])
ggpairs(difflib)
res.send(401)
print(d)
i += 1
print(width, height)
print(t.overlap_point(5))
retval = True
print(round(1.0 / NUM_BUCKETS, 2))
index = ser[ser.isnull()].index
aaa
do_blah_thing()
graph[v1].append(v2)
counter += 1
self.setFormat(start, length, style)
dfrm
start_time = 100
self.server.funcs[method](*params)
terms.append(lambda x, n=i: c[n] * x ** n)
open_smbus.argtypes = []
FACTORY_FOR = Tag
final_df
opts = urllib2.parse_keqv_list(items)
expiration = int(time.mktime(expiration.timetuple()))
ax2.add_collection(vc)
rows = []
pairwise.pairwise_distances(a)
close_files_exhaustively(fd_min, fd_max)
config.read(filename)
inverted_im.show()
numeroLinea += 1
print(line)
1, 2, 1
start = time.time()
df = pd.DataFrame(yournumpyarray)
a = graph.get_adjlist()
calc_plane_bis(x, y, z)
user_logged_in.connect(limit_sessions)
record = BloodTraitRecord(*clean_types(result))
c = df.corr().abs()
anything_else_that_seems_important()
data2_list = []
print(filename)
sourcefld = i
array_2 = numpy.array([dict_2[key] for key in keylist])
r_fd, w_fd = os.pipe()
a = DynamicList(iter(range(10)))
[15, 16, 17, 18, 19],
max = []
10 if x == 6 else 1
ip = IPDB()
row = 0
cache[param] = func(param)
groups = itertools.groupby(list(range(10)), lambda x: x < 5)
p = Point(5, 5)
groups = itertools.groupby(l1, lambda x: x[1][0])
worker = Thread(target=pinger, args=(i, queue))
print(d)
bins = 4
X = scipy.rand(9, 4)
f.counter
1
recur(5)
url = line.strip()
foo.bar.baz()
dy = y[..., (np.newaxis)] - y[(np.newaxis), ...]
fact(4)
p.join(0)
ax = fig.add_subplot(111)
comment.extract()
subs.append(s[x + 1])
model = Author
mat[i][j] = 1
n = 0
call = [sys.excecutable] + python_script + sys.argv
PYTHONPATH
values = np.vstack([x, y])
res = NP.where(mask == 0, chk, img)
a, b = A(), A()
i += 1
cam.start()
print(decoder.decode(json_string))
lines = urllib.request.urlopen(url).readlines()
expires = datetime.now() + timedelta(seconds=expire_seconds)
b = []
endfor
b = []
ha = hashlib.sha256(json.dumps(a)).hexdigest()
check_raise(test)
np.extract(1 - np.eye(5), M)
extend_enum(Index, name, value)
all_R.append(R)
288.0
normal_fn.__code__.co_flags
df1
lib = ctypes.cdll.TestDLL
self.prevfd = os.dup(self.fd)
line_number = err.lineno
zip_name = os.path.basename(download_url)
buffer = create_string_buffer(data)
chunk_length = len(sound) / 180
a = np.sum(X ** 2, axis=1)
0 == False
i += 1
subset[subset.isin(myList)]
ignored = False
result = self.input.readline()
x += 2
max_seq_len = 0
f1 = pl.figure(1)
parser.last_positional_values.append(values)
timeit(df == df2) | (df != df) & (df2 != df2)
arr = test.fooArray.frompointer(test.bar())
index.rst
print(find_prev_next(list(range(0)), 10))
resp, content = service._http.request(download_url)
assert answer([1, 1, 1]) == 1
n
parser = OptionParser()
appended_data = []
credentials = run(FLOW, storage)
g = sp.exp(-x * y)
f1(f2(x))
[(coord * inv_len) for coord in v]
-1
permission_classes = UserPermission,
self._cache = {}
a.shape = 5, 2
store = models.ForeignKey(Store)
TN = cm[1][1]
signal.alarm(timeout)
2011 - 2 - 1, NaN, NaN
sum += (4.0 if i & 2 == 2 else -4.0) / i / (i + 1) / (i + 2)
a.default_factory
cookieprocessor = urllib.request.HTTPCookieProcessor()
m = partL + str(E1.get()) + partR
result = predicate(y)
x = counter
x2_Kcids.ravel()[:] = [ax2_cid[axs] for axs in x2_Kaxs.flat]
[]
test_features = test_dataframe.iloc[:, 1:]
e8
1
open(filename, mode, 0)
sum
e = np.ascontiguousarray(e)
test_sequence(a)
obj = event.GetEventObject()
v.tzinfo == pytz.utc
i += 1
x = np.array(x_range)
arr = np.ndarray(tuple(shape[:]), dtype, buffer, order=order)
latitude = models.FloatField()
True
image_without_exif = Image.new(image.mode, image.size)
f.write(dataImg64)
PyList_Insert(sysPath, 0, PyString_FromString(workingDir.string().c_str()))
check = Qt.Checked if randint(0, 1) == 1 else Qt.Unchecked
self.__dict__[rule_name] = self.instancemethod(augmented_func, self)
counter = collections.Counter(names)
value = self.q.get(block=True)
print(person)
ANYTHING
[1, 1, -1, -1, -1]
mod = __import__(mod_name)
self.vtkPoints.SetPoint(r, point[:])
vars
uploadform = UploadForm()
ham
deleteself.min_set[self.store[key]]
print(e.message)
self.y = y
dictList.append(temp)
m.position()
stdout_logfile_maxbytes = 0
center[i] = (coords[a][i] + coords[b][i]) / 2
b.set_response(r)
X = np.array([[0.0]])
freq_list.sort(reverse=True)
companies = Company.objects.prefetch_related(prefetch)
csi * i
np.bincount(r.labels)
my_list.extend(b.my_list)
add_item(j)
transformed = model.transform(df)
d
print(a[0:x])
pdf = StringIO()
soup = BeautifulSoup(landingPage)
assert (x[mx] == np.intersect1d(x, y)).all()
s == s2
folders_dict.append(d)
self.var2 = par2
bezier_points = bezier_points[k:-k]
http = httplib2.Http()
shifts_arr = np.zeros(m * (m - 1) / 2, dtype=int)
register = template.Library()
result
ret[val].append(key)
Xfit_mono_ind[len_mono] = iX
type(dates), type(dates[0])
GMaxI = values.max()
raise D2XXException
p = psutil.Process(2549)
max
self.b = b
r.append(item)
print(NEWLIST)
print(aggregate_names(EXAMPLES))
buf = os.read(f, 1024)
count = 0
dic[dt] = max(dic.get(dt, 0), val)
ed = df.end_date.values
self
model = Person
p = flt[i]
func
version = find_version(sdists_dir, name)
df
OUTPUT_DIRECTORY = pyexample
user
df_normalized
getattr(self.inner, name)
mail.send(msg)
help(idx1.equals)
time_str
print(K[-N])
SWIG_fail
f = inspect.currentframe().f_back.f_back
output_ws = output_wb.get_sheet(0)
out = stdout.read()
Y = [y for x, y in data]
result = sorted(sub_lst)[0]
FT_00_LB = pep8
self.input_buff = self.input_buff[:-1]
myinstance = MyClass()
l = imap2(str, range(1, 4))
xx = np.frombuffer(buffer, dtype)
results = []
cron.minute().during(5, 50).every(5)
deleteos, histfile, readline, rlcompleter
variables = {}
uGrid.InsertNextCell(vtk.VTK_POLYHEDRON, heptagonalFacesIdList)
np.random.uniform(low=0.0, high=1.0, size=(100,))
index_list = list(reverse_binary_search(my_list, threshold))
print(ord(inp[0]))
n = len(c)
i += 1
pfo.CopyItem(src, dst)
print(v)
Varray = numpy.array([[0, 0], [0, 1], [1, 1], [1, 0]], numpy.float)
print(repr(out[:6]))
max_similarity = 1
offsets = 10 * (np.random.random((numverts, numpoly, 2)) - 0.5)
channels = [settings.EVENTS_PUBSUB_CHANNEL]
fig1 = plt.figure(figsize=plt.figaspect(0.75))
current_total = 0
y ^= x
B = B.astype(int)
updated.urlencode()
o = [4, 10, 8]
posts = client.database.posts.find()
self._attrs = OrderedDict()
a
disable = C, F, I, R, W
sin = np.sin
gzipper = gzip.GzipFile(fileobj=data)
df
newdata = [x for x in data if x[1][1:].isalpha()]
frame = inspect.currentframe().f_back
window = gtk.Window()
click.echo(_read_version())
mins = sorted(islice(it, n))
new_transform = ax.transData + offset
root = HKEY_LOCAL_MACHINE
Index.sort()
x = np.linspace(0, 20, 200)
i = numpy.arange(i_max)
dates2 = [pd.to_datetime(d) for d in dates2]
db.set_mapsize(new_limit)
self.len
out.append(b + end)
new
string = string[1:]
print(c1, c2)
bodylist = []
output
self.thread.start()
userChoices = model.CompUserChoices()
xlim = min(data[:, (0)]), max(data[:, (0)])
ax_local.imshow(img_local, cmap=plt.cm.gray)
df.update(d1.where(d1 < 1, 1))
[idx[freq * n:lookback + freq * n] for n in range(int(len(idx) / freq))]
str(mixed)
old_string = new_string
d[a].append(i)
n = 10
colList = list(list(myDict[0].keys()) if myDict else [])
print(trendsName)
user_ns = self.shell.user_ns
pending = [(name, set(deps)) for name, deps in source]
make_async(process.stdout)
s = slice(*a)
numbers = 1, 2
mills = votemil[spaceindex + 1:]
colors = list(colors)
comp_row = [complex(x) for x in row]
8.02
p = sparse.rand(10, 10, 0.1)
out.reshape(m1 * m2, -1)
t = type(obj)
t1 = time.time() - t0
self.variable_name
app.pyramid = config.make_wsgi_app()
f
by_parent = co.defaultdict(list)
form
templist = list(range(x, x + length))
outcsv.writerows(result)
cache = {}
self.num_tweets += 1
True
calendar[date].append(event)
self.cousinitt = weird
tags = instance.tags.distinct()
net = buildNetwork(21, 20, 21, outclass=LinearLayer, bias=True, recurrent=True)
i -= 1
np.random.seed(2015)
builder.append(line)
tag = db.StringProperty()
force[(iParticle), :] += ljdist.sum(axis=0)
l, data = inp.read()
foo.b_value = True
ts = datetime.datetime.timestamp(d)
self.root[0] = self.root[1] = self.root
m, n = g.shape
datetime = TextField()
password = something_that_gets_input()
response = f.read()
print(icon)
whatevs = property
self._task_handler.daemon = True
arg = NULL
N = len(Y)
s.to_frame().T
plt.colorbar()
not rex_nomatch and re2_matches
month = 1
b0 = np.array([1.0, np.NAN, 2.0])
self.selenium.start()
result += 1
combination_num = list(range(k + 1, n + 1))
out, err = process.communicate(commands)
X = np.dot(W, x.reshape(N, 1))
text_width = stringWidth(text)
self.auto_pseudoid = generate_random_alphanumeric(16)
outeropt = setouter(Q, G, n)
ccd = sparse.spdiags(1.0 / cc.sum(1).T, 0, *cc.shape)
y = shuffle(x)
y = f.readlines()
settings.TEMPLATE_STRING_IF_INVALID
epoch = dt.datetime(YYYY, MM, DD, HH, MM, SS)
id(me)
futures.append(asyncio.ensure_future(coro))
kw = copy.deepcopy(kw)
res = product(*list(a.values()))
sparseness = (nr - a / b) / (nr - 1)
print(L)
mock = MagicMock(side_effect=lst)
dt = parser.parse(a_datetime)
f_t = TimeLimited(f, t)
console.log(e.data)
response.status_code = status
hi_obj = hi()
outbox = pts[np.logical_not(inidx)]
askopenfilenames
deletea
out = pandas.Series(out)
serialized = module.dumps(data)
df_energy2.head()
p(42)
setattr(testcase, testname, testmethod)
map = Basemap()
x = rand(2, 2)
print(get_sql_table_data(sqldb.system.BaseUser))
word_offset = index(word, running_offset)
-1
count_inside[..., (k)] += k == labels_img[2:, 2:]
checked
stream = cv.CaptureFromFile(filename)
root = Tree()
gc0.restore()
raise MyException
set(self.__class__.all_nodes[name] for name in names)
self.image_data = read_png(sample)
a, b = b, a
print(row)
response_data
child.add(letters, n, index + 1)
next(self.iterator)
html
c
F = Var(X) / Var(Y)
mask_1 = cv2.inRange(hsv, lower_red_1, upper_red_1)
same_edge = graph.es[same_edge_id]
headers = next(reader)
x + y
f1()
distances[i][j] = np.sum(np.square(features[i] - features[j]))
self.urls_seen = set()
sum(e * x ** L.index(e) for e in L)
+-BB
newIntersections.extend(head & s for s in tailIntersections)
r = max(min(r, 1.0), -1.0)
seq = get_seq_in_tree(tree, number)
nexts = cycle(islice(nexts, pending))
ltd = [int(s) for s in d.split() if s.isdigit()]
print(unique)
Py_MEMCPY(to + done * char_size, to, n * char_size)
directory = os.path.dirname(fname)
a.SomeMethod()
velcro.home()
sum(1 for x in islice(a, 0, 900000) if x == 0)
invertedDict = defaultdict(list)
register = template.Library()
pos_higher[k] = v[0], v[1] + y_off
df
_decorated.append(obj)
hddict
index = slice(0, 2)
sequence_uniqueness(a.intersection(b)) / (a_uniq * b_uniq) ** 0.5
i2x = np.indices(i2.shape)
t = ()
Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
print(op, code)
os.close(saved_handle)
xr = (x - xm) * cos(a) - (y - ym) * sin(a) + xm,
stripped = line.strip()
func = lambda x: [line[x] for line in lst if len(line) > x]
vals = line.split()
image = tf.image.resize_bilinear(image, [HEIGHT, WIDTH], align_corners=False)
N = 2
angle * 180.0 / np.pi
rot = np.rad2deg(np.arctan2(*np.abs(np.gradient(xs)[0][0][::-1])))
s.anotherFunction()
abstract = True
intersect_keys = d1_keys.intersection(d2_keys)
somevariablename = focus_get()
print(f)
N = len(imlist)
[default]
possibly_a_re_object.match(thing_to_match_against)
f.seek(offset)
checkValue = self.classTest.checkConfiguration()
data[x, y + c] = 255
filepaths[i] = filepaths[i], os.path.getsize(filepaths[i])
sleep(0.025)
seq = []
default_to_regular(defdict)
row.append(r - 1)
crawler.signals.connect(ext.spider_error, signal=signals.spider_error)
tweets = json.load(string_buffer)
to_thread.join()
cosx = absolute((1 - sinx ** 2) ** 0.5)
t = stoppable_iter(list(range(10)))
m[0]
c = Counter(str1)
resource.setrlimit(type, (soft_limit, hard_limit))
do_stuff(row)
all_info = subprocess.check_output(command, shell=True).strip()
vals = np.concatenate(a)
context
n11 = (n11 - n) // 2
obj = RejectingDict()
z = r * np.sin(phi) * np.sin(theta)
eltid = Column(Integer, primary_key=True)
root = self._setup_repo(self.arguments[0])
PyObject * pname
my_hash
prev = split[-1]
m[50, 50]
hello
self.widget.detach(self)
body = urllib.request.urlopen(url).read()
q.put((filepath, params, destUrl))
arr.resize(im.height, im.width)
output_hsv[np.where(mask == 0)] = 0
a[where_are_NaNs] = 0
mail.send(msg)
1
MyObject().id
total_len = len(treebank_tagged_sents)
iterable = some_generator()
gobject.threads_init()
first = list(itertools.takewhile(str.isalpha, l))
func()
res = add.apply_async((2, 2), link=mul.s(16))
stemmer = Stemmer()
available_tables = q.fetchall()
d = defaultdict(list)
libc.prctl(PR_SET_PDEATHSIG, signal)
print(output)
some_func(i)
print(string_at(p, size=sz))
overlap[l1, l2] = len(s1 & s2)
width, height = im.size
b.argmax()
output_hsv = img_hsv.copy()
f, pathname, desc = imp.find_module(name, sys.path[1:])
sleep(0.005)
print(getPointTotal([1, 26, 12]))
print ()
degrees = 0
result_list
python_name
x.append(carry)
i = iter(l)
nested_list = [[0] * 2] * 5
height * np.exp(data)
foo = next(bar_iter)
actual_width += len(text)
total = int(t_end / t_step)
connectivity = 4
line2 = next(csv2)
first_name = indexes.CharField()
sizer = wx.BoxSizer(wx.VERTICAL)
el = self.selenium.find_element_by_name(name)
False
True
True
print(l)
self.inputWeights = []
s = str(td)
GEN_CREATED
1
inner
entries = []
it = iter(s)
data_f = np.concatenate(data)
self.x = x
print(toks)
circumference = cv2.arcLength(contour, True)
distances = tf.reduce_sum(tf.squared_difference(expanded_a, expanded_b), 2)
print(1 + my)
dictpsl = PSL_obj.readPSLpairs()
o.die()
seconds = (serial - 25569) * 86400.0
connection.creation.destroy_test_db(old_name, verbosity)
print(val1 / float(val2))
do_other_stuff
cls.register_plugin(cls)
table = table / table.sum(axis=1, keepdims=True)
acc = acc + number1
datafile = os.path.join(sys.prefix, datafile)
list.append(SomeElementResponse(value=i))
cert = request.getpeercert(True)
counts = np.bincount(idx)
p = int(log(x, 2))
all(l1 in sLines for l1 in dataE)
cc[0].capital
u, v, w = a[i], b[i], c[i]
c = Collection(collection)
gzf = gzip.GzipFile(fileobj=f)
notes = Notification.objects.filter(user=self.user)
val
p.destroy()
status = 200
min_obj_set = []
f
type(9) is int
my_numpy_fun(name_addrs)
MISSING = object()
[round_floats(item) for item in o]
v = p.vertices
chunk_names.append(chunk_name)
print(corpus[0])
frame = sys._getframe().f_back
content_type = ContentType.objects.get_for_model(self.__class__)
self.real == other
sums = np.add.reduceat(b, idx[:-1])
print(answer)
print(output)
M = sps.csr_matrix(A)
stat.f_bfree * stat.f_bsize
host.sendline(command)
self.iterable = iterable
w, x, y, z = self._val
not other < self
self.free_users += 1
print(pizza.toppings.veg_toppings)
response = f.read()
not set(mystring) - set(allowed)
solution[-1] = newValue
formatter.add_text(parser.description)
pair = the_map[i]
x = 0.05 * t + 0.2 / ((t - 5) ** 2 + 2)
org.python.Python.PythonApplications - 2.7
Foo.bar = newMethod
random.shuffle(l_idx)
self.__offset
end = time.time()
instance.user = self.user
prev_year = int(year) - 1
print(totalfreq)
pp.c.T
df1
self.textName = QtGui.QLineEdit(self)
ns = parser.parse_args([])
smallfileiter = (f for f in fileiter if os.path.getsize(f) < 200 * 1024)
vector = np.random.rand(262144)
t, v, full_tb
r, c = R[idx], C[idx]
passage = f.read()
classes = [foo.baa.a, foo.daa.c, foo.AA]
print(test_shortest_path(Graph.GRG(1000000, 0.002)))
ys = np.sin(U) * np.sin(V)
candidates.extend(node._get_child_candidates(distance, min_dist, max_dist))
extract_nested_zipfile(child_zip_path, parent_zip)
sub_seq = seq[start:end]
grids = np.zeros((U, U))
not issubclass(other, collections.Sequence) or NotImplemented
mask = (x_lattice < image_shape[0] / 2.0) & (x_lattice > -image_shape[0] / 2.0)
isinstance(c, A)
a = [y for y in a if y != r[-1]]
testSuite.addTest(configtest.suite())
result
text[:index]
print(id(L))
True
ax = fig.add_subplot(111)
depart /= math.factorial(idx)
self.root = root
cell = worksheet.cell(row - 1, i)
print(sklearn.__version__)
a.x = 5
twodays_ago = now - 60 * 60 * 24 * 2
print(len(rows))
a, b = bisect_iter_to_iter(str.isalpha, iter(l))
vals[i] /= M
m_from = db.ReferenceProperty(reference_class=UserModel)
laparams = LAParams()
transaction.get().join(RedirectDataManager(request, trial_url))
find_sublist(sub, bigger) >= 0
X.append(np.mean(ceps[int(num_ceps / 10):int(num_ceps * 9 / 10)], axis=0))
dom = parseString(data)
itineraryArray.item = [itinerary0]
r
b = [100, 200]
Decimal(other)
request.param
self.question
overriden.append(method)
g.ax_marg_x.legend_.remove()
xmax = max([t.get_window_extent().xmax for t in textobjs])
xticks_pos = [(0.65 * patch.get_width() + patch.get_xy()[0]) for patch in h]
orig_obj = models.User.objects.get(pk=obj.pk)
t1.timeit(number=1000)
print(timestamp)
info = dict(zip(column_names, row))
a += i
r = test_yield_task.apply_async()
count = 0
0
ds = DescrStatsW(x, weights=weights)
pos = hfile.tell()
c[:, 0::2] = a
desired_ages = set(desired_ages)
b == False
transport.write(message.encode())
TN = confusion_mat.sum().sum() - TP - FP - FN
m = MyClass()
print((i, info))
B = nx.Graph()
map(y.__contains__, x)
data.image = db.Blob(fp.getvalue())
print(choose(list_a))
print(get_permutation(l1, 1))
print(v)
replace = StatefulReplace(0)
currentRowCount = tableWidget.rowCount()
self.port = port
ms()
keyset = set()
print(name)
time.time() > self.die_after
mean = [0, 0]
df_long = df_wide.stack()
q = MyTable.select()
print(myclass.last_transaction)
item
httpReq = urllib.request.Request(url, pData)
dx_zero, dy_zero = self._transform.transform((0, 0))
selected = df.loc[idx]
x = np.linspace(0, 2 * np.pi, 100)
vals = line.split()
ax.margins(0, 0)
std = Lambda(lambda x: K.std(x, axis=1))(input_img)
my_set
True
username
self.update(set(parm))
results = []
y
my_mesh.AddPolygon(0)
self.assertLazyResultEqual(expected, s)
error = originalTotal - sum(myRoundedList)
z = sorted(y)
a[x] = a[x], a[y]
next_word = wordList2[i + 1]
vec_data_mag = np.abs(dx) + np.abs(dy)
(r for r in result or () if _filter(r))
split_at = A.searchsorted([10, 20])
c = a / b
driver.Navigate()
count += 1
self.a += other
data = load(filePath)
stems = stem_tokens(tokens, stemmer)
init = tf.initialize_all_variables()
assert eval(input) == expected
print(df)
print(Xnew)
dfs = pd.read_html(driver.page_source)
result = func(*args, **kwargs)
left = bisect.bisect_left(arr, [xmin])
doc = ET.fromstring(content)
self.setHeader(QNetworkRequest.ContentLengthHeader, len(self.content))
sentences = random.randrange(5, 20)
cls._deck = object.__new__(cls, *a, **k)
print(data[~select])
most_popular({el: (0) for el in list(range(10000))})
form = MyForm(obj=myDataRow)
shared_queue_list = []
self.combine_element(mapping[el.tag], el)
params = urllib.parse.urlencode(params)
someMethod = someDecorator(someMethod)
sum(1 / token2frequency(t) ** 0.5 for t in seq)
skipna = True
setattr(args, self.dest, values)
options, args = opts.parse_args()
self.__modifier_pressed = False
[1, 22, 4] in a
stringf[offset:limit]
template_globals = {}
print(type(html))
[-1, -1, 1, 1, -1]
tsk.add_done_callback(handle_result)
self.length = length
registerform = UserRegisterForm(request.POST, instance=user)
print(peek(f, 4))
h = httplib2.Http()
self.observers[o] = 1
html.tostring(page)
CookieJar.__init__(self, policy)
cursor_list.append(1)
sm[i] += 1
p = next(ps) and next(ps)
print(agent.extract())
c = a + b
f = lambda x: x.sort_values(ascending=True).reset_index(drop=True)
self
http = httplib2.Http()
list(filter(isCap, myStr))
idx += 1
fnc = lambda x: x[1:]
invoice_lines = []
word.lower()
responses[404]
Y
today + relativedelta.relativedelta(weekday=2)
self.task = asyncio.sleep(60)
set_of_result_paths
line = self.fp.readline()
main()
ctx = app.app_context()
y = np.hstack([(r0 * (1 - h) * np.sin(u)) for h in linspace(0, 1, num_levels)])
ix0 = i2x[0] * box[0] + i2
threads.append(t)
my_rand.counter += 1
Mokil
Moglar
Diglar
Famdar
realconn = connection.connection
deleteowner[key]
b[0] = list(range(4))
fields = []
session = aiohttp.ClientSession(connector=conn)
x = np.asarray(x)
st_new = pd.concat([(st.o + st.c) / 2, st.vol], axis=1, ignore_index=True)
dta = sm.datasets.co2.load_pandas().data
raise TypeError(msg)
files = os.listdir(path)
self._func(*args) * other(*args)
series = pandas.Series(np.random.normal(size=2000))
sort_b = np.argsort(b_view)
fig = plt.figure(figsize=plt.figaspect(0.75))
memdb = Redis.from_url(settings.REDIS_URL)
yaml.add_representer(literal_str, represent_literal_str)
context = zmq.Context()
os.close(fd)
idx = df.index[df.Dependents.isnull()]
iter(self.data.items())
skip = (total << 1) // surplus + 1 >> 1
column_indices = column_indices - r[:, (np.newaxis)]
deleteself.inverse[self[key]]
VER_NT_WORKSTATION = 1
module = imp.load_module(fullname, fp, filename, self._c_ext_tuple)
tree.addi(5, 15, 20)
true if condition else false
command = child_pipe.recv()
linkto = os.readlink(srcname)
hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())
self.buffer = []
self.file = sys.stdout = file
value = row[1].value
y = y * sin(theta / 2.0)
Base = declarative_base()
print(data)
self.fnameEntry.grid()
Foo.c += 1
WSGIScriptAlias / gallery / path / to / gallery / apache / gallery.wsgi
data = stream.read()
Yellow
model = ExtraTreesClassifier(n_estimators=10000, n_jobs=-1, random_state=0)
new_list = []
print(k)
[0.25, 0.5, 0.25]
print(i.hw_addr)
params = dict(kernel_type=cv2.SVM_LINEAR, svm_type=cv2.SVM_C_SVC, C=1)
PyEval_InitThreads()
y_vals = si.odeint(lambda y, x: f(x), 0, x_vals)
Mylist.append(numToLetters[number])
a = np.unique(df.A.values[cond1])
b[x - 1] = 1
out.str().c_str()
1, 2, 4, 8
x == y
WHERE_AM_I = abspath(dirname(__file__))
skel = skel.copy()
start = randint(0, length)
self.setDaemon(True)
out[k] = recursive_asdict(v)
d = example.get_base()
sum(zip(*data)[1], 0.0)
randset = set()
cipher.append(previous)
d1[key], d2[key] = v
ys_filtered = (y for y in ys_all if y < 5)
myCount = Counter(foo)
current_observation = tf.gather(values, current_index)
arr = list(range(1, 10))
self.f.setnframes(nframes)
print(a + 2)
s.send(data_to_send)
df
tree[i].root = tree[root_idx]
cssin = open(sys.argv[2])
False
run = np.diff(log_x)
User.__table__.drop(migrate_engine)
print(s)
np.math.atan2(np.linalg.det([v0, v1]), np.dot(v0, v1))
vals_list.index(min(vals_list))
X[:, (i)] = k.transform(X[:, (i)])
plt.subplot(rows, columns, n)
print(a)
result = resource.render(request)
restaurant.delete(keep_parents=True)
print(chr(b))
shape = x.shape
gz = itertools.chain(gx(), gy())
screen.exitonclick()
result
double * n
restaurant = Restaurant.objects.get(pk=1)
f.pack(fill=X, expand=1)
self.concurrency = concurrency
x.o.str.repeat(x.ones) + x.z.str.repeat(x.len - x.ones)
A[i] = full_array[0]
g
X = np.array(np.meshgrid(x, y))
length = [2, 2, 2]
child_list = []
n_m_j_k[m][j][k] += 1
font = ImageFont.truetype(path, fontsize)
shape, scale
pylab.gray()
self.settings = settings
y = norm_vals[ij] / np.sqrt(x + 1) + 1 / (x + 1)
module
i = iter(list_)
b2 = [4, 5, 6, 7, 8]
list(a.gen)
print(2 * (response[y, x] - min(response[y, x - 1], response[y, x + 1])))
tic = time.time()
args = parser.parse(request.query_string)
readline.read_history_file(histfile)
q.put(reduce_socket(self.request))
pValue = PyObject_CallObject(pFunc, pArgs)
total += array[idx] * array[idx]
dict2 = eval(str1)
mock1.side_effect = ctpMocks
value
newdata.append(item)
conn = httplib.HTTPConnection(host, port)
cd = os.path.dirname(os.path.abspath(__file__))
pubsub = red.pubsub()
m.reflect(engine)
buf[9] = 0
cls.name_map[name] = cls(name)
vec_bow = dictionary.doc2bow(doc.lower().split())
f = plt.figure()
count_inside[..., (k)] += k == labels_img[2:, :-2]
patches, texts = plt.pie(y, colors=colors, startangle=90, radius=1.2)
new_dict[len(nums)][name] = nums
path = inspect.getabsfile(get_script_dir)
mot, nomot = count_motifs(listoflists, 2)
2, 100, 1000
groups = defaultdict(list)
E(1, 1)
querylist = set()
False
row_ind = []
get_info(Foo().__init__)
dt = t[k + 1:-1] - t[1:-k - 1]
x = int(N ** (1 / k))
ybottom = max(ay, by, cy)
create_conda_environment
self._x
a = os.urandom(2 ** 20)
++i
print(array)
f.truncate(size - 1)
a, b = tee(iterable)
ascii_string
x = y = []
h = hash(o)
num = int((num - mod) / 26)
X = vectorizer.fit_transform(l)
d = datetime.utcnow()
window = a[:, i:i + PATLEN]
X_projected_mmap[batch] = X_batch_projected
duration = 228.200515
i = c.intersection(l)
ys.append(x)
pcnt = (1 - iq_range) / 2
ptime += time.time() - pt0
length = len(sorts)
df
elem.tag = elem.tag[nsl:]
print(cmp(INF, now))
pd.options.display.float_format = orig_float_format
A.f = f
div = n
size += 1
result = zeros(max(i_list) + 1)
unpack = packer.unpack(some_packed_code)
x_series = hstack((x_series, record_x))
v = []
twistedServer.start(MessageQueuer(queue))
self.pool = ProcessPoolExecutor(max_workers=workers)
print(latex(expr))
splitlist.append((p + 1, new))
r = np.sqrt(R[k, k] ** 2 + x[k] ** 2)
sys.stdout.fflush()
dt = dt.replace(year=dt_now.year, month=dt_now.month, day=dt_now.day)
x = arange(-10, 10, 0.01)
self.inserts.update(session.new)
print(i)
results = []
SaneEqualityArray(my_array.shape, my_array.dtype, my_array)
[random.gammavariate(alpha=2.0, beta=1.0) for i in range(100)]
all(validateBit(b) for b in vals)
cv_im = pil2cvGrey(pil_im)
asdf.title = str(i)
StringIO.read(self, *args, **kwargs)
FCSM_ICONFILE = 16
fig = plt.figure()
tar.extractall()
not_other.negate()
wnl = WordNetLemmatizer()
cofactors[r][c] = cofactors[r][c] / determinant
response += buffer
cout << y << endl
sample = someRDD.sample(0, 0.0001, 0)
producer.beginFileTransfer(file_to_send, tsite.protocol)
corpus = [dictionary.doc2bow(text) for text in final_text]
PyErr_BadInternalCall()
perm1[loc], perm1[sloc] = p0, p1
queued_d
i += 1
connect_to_DB()
id(NaN)
[A]
urls.py
manipulandum = str(longint)
l_no_v = l[:]
Inside = 1
client_secret = FACEBOOK_APP_SECRET,
True, rest[1:]
objects = models.Manager()
a[0:2] = [5, 6]
print(20000000000.0)
s.getvalue()
opts.usersChoice = wrapper(standardGenerator, param=4.0)
curl.close()
min(l_one + l_two)
list_of_substrings = my_dict
delta = timedelta(days=1)
args = [iter(iterable)] * n
dates, vals = zip(*data)
max_item, max_size = item, key(item)
self.children = children if children else {}
map(scheduler.cancel, [x for x in jobs if x.func == func])
data = zlib.decompress(data)
admin = Column(Boolean, default=False)
[a, [b, [c, [d, e]]]] = v
assert tree[0].tag == qn
self.votes.append(vote_value)
t = pandas.tslib.Timestamp.now()
print(con.version)
func = ctypes.cdll.TestDLL.func
print(accuracy_score(y_test, predicted))
angle = radians(self.delta + self.delta * pos)
result_list = [] * number_of_rows
b = OrderedDict()
print(twosidedtagger.evaluate(test_sents))
x = N.array(br_float)
print(timeit(stmt=np_stmt.format(str(10 ** e)), setup=setup, number=10))
r = urllib.request.urlopen(req)
centers = geo2cart(lat, lon)
s = df.isnull().sum()
integer_data = struct.unpack(fmt, raw_data)
process_data(infile, outfile)
rolled[:, (-1)] = False
paths = []
self.other_field_name = other_field_name
a = np.log(a) / temperature
ctx.translate(pos[0], pos[1])
a == b
procesed_l = np.array([item for l in procesed_l for item in l])
eventqueue.add(InitEvent())
a = nx.betweenness_centrality(G)
log = logger.getLogger()
s[t], s[j] = s[j], s[t]
MyArray((k, OrderedDict.__getitem__(self, k)) for k in key)
to_reverse
n, p = p, n
p = sre_parse.parse(p, flags)
print(combin)
fullText.append(para.text)
-1 * item
hdr.insert(new_hdr, 2)
obj
tokenized = tokenizer.tokenize(text)
get_operator_fn(operator)(op1, op2)
self.vmax = 1
mf = mmap.mmap(fin.fileno(), 0, access=mmap.ACCESS_READ)
2 * x
traceback.print_stack()
string = reduce_string(string)
wrapping_fun
zip(count(), s)
array_1 = numpy.array([dict_1[key] for key in keylist])
vars.update(locals())
print(x)
W = (X.transpose() * X).getI() * X.transpose() * y
r = requests.get(url, stream=True)
self.fields[key] = Field()
dx = 1
ax.legend_.remove()
u = u.lower()
exit
logger = logging.getLogger(__name__)
c = [(a_i ^ b) for a_i in a]
aux = np.concatenate((x, y))
args2[i] = fmt.Sprint(v)
raise ValueError(emsg)
new_dt = dt_string[:19]
handlers.append(print_event)
n = len(a) / 2
width = default_font.measure(text)
array_type = ctypes.c_char_p * 4
buffer = f.read(16)
shutil.move(tempfile.name, filename)
self.level = 0
n_j_k_d[j][k][d] += 1
n = len(operands)
xnew = np.arange(1, 5.1, 0.1)
one_row = result.fetchone()
sortidx = a.argsort()
noise = np.random.normal(0, 0.1, 250)
x = 12
f.write(data)
t1 = mt.now()
final_set.append(merge(input[:i], rec_set))
end_km = group.iloc[0, 5]
cvuint8 = cv2.convertScaleAbs(image)
len(list([x for x in t if x >= 9]))
len({song.artist for sing in self.allSongs})
msg += part
prange = [a for a in range(2, 6)]
groups = np.cumsum(np.hstack([False, continuous == False]))
offset = timecnt * 4 + timecnt * 1 + typecnt * 6 + charcnt * 1
it = iter(numbers)
print(Decryption)
xopt = optimize.fmin(rosen, x0, xtol=1e-08, disp=True)
print(Encryption)
A, B = curve_fit(f, x, y)[0]
self.addcredentials(request)
xn = x + sigma * np.random.randn(num_samples, n)
logText = lastStep.getLogs()[0].getText()
values = [n.s for n in node.values]
STD_OUTPUT_HANDLE = -11
c = numpy.copy(a)
bands.append(zi.reshape((nx, ny)))
p.apply_async(testFunc, args=(f,), callback=collect_results)
print(upperlist)
print(c)
b.append(lambda : foo)
A += B
ratings = Bewertung.objects.order_by(sortid)
redirect_to = resolve_url(settings.LOGIN_REDIRECT_URL)
log.debut(text)
p = peekable(range(2))
requests.post.assert_called_with(requests_arguments)
randText2 = getRandText(N)
result = something.awesome(-42)
ZCAMatrix = np.dot(U, np.dot(np.diag(1.0 / np.sqrt(S + epsilon)), U.T))
print(a.dtype)
EW_REGIONCOLLSITE
it = iter(iterable)
im1 = Image.open(imagePath1)
df
logging.error(e)
rank = (s > rtol * s[0]).sum()
d1 = numpy.subtract.outer(xy1[:, (1)], xy2[:, (1)])
print(c)
lst.append(values)
prodM.append(newRow)
my_uuid = uuid.uuid4()
main()
mylist = [myClass() for _ in range(10)]
print(foo[mask])
image_urls = scrapy.Field()
data_item = json.loads(line)
date = datetime.date(dt_ar[2], dt_ar[0], dt_ar[1])
lookup = collections.defaultdict(set)
BIT4 = 2 ** 4
arr1 = np.argsort(-vals, axis=1)
default
tryIt
done = set()
new.index = df.index
OpenProcess.restype = ctypes.wintypes.HANDLE
print(o.netloc)
print((ticker, session))
frame = self.page().mainFrame()
5127
inner_sum = 0
self.input_values[self.input_cursor - 1]
100.00000000001425
print(d)
self._stride_length
np.random.seed(1)
print(file)
float.hex(1.25)
x = s[i]
print(line)
_items
get_info(bar)
session.expunge_all()
print(result)
26 % 7
self.oauth.credentials.refresh(http)
extent = xmin, xmax, freqs[0], freqs[-1]
self._observers.append(self)
value
max_idx = i
testcsv = csv.reader(testdata, skipinitialspace=True)
print(cluster1)
print(a)
copy.append(clone(child))
newIntersections = [head]
rows = [0, 0, 0]
self.row
code = compile(tree, f.name)
print(split_find(word, search_words, max_length))
tot += A[i]
std_image = np.sqrt(cum_sum_of_squares / n - mean_image ** 2)
new_obj = pickle.loads(pickle_str)
xbin = [bin(i)[2:].zfill(8) for i in xdata]
org.python.Python.PythonUnixTools - 2.7
output = json.dumps(obj, indent=2)
color_code = models.CharField(max_length=6)
liststore.append([s])
get_monotonic_nums(2)
x
P_a = np.eye(9) * 50
result = defaultdict(list)
setattr(StreamHandler, StreamHandler.emit.__name__, customEmit)
contents.insert(0, d)
self.lst = []
segment, score = segments[0]
pcapnum = 0
x_min, x_max = X[:, (0)].min() - 0.1, X[:, (0)].max() + 0.1
self.__deque.pop()
G = nx.path_graph(4)
{{line}}
lists = collections.defaultdict(list)
print(Fraction(0.25))
func2(xy, 2)
a & b
~np.in1d(a1, b1)
print(output_line)
memoize[str(l)][i]
TESTING = False
f_cheb.roots()
locale.setlocale(locale.LC_ALL, l)
isinstance(unicode_literals, Feature)
obj.__dict__[self._key]
fit_df = df.dropna()
m[:prefix]
n_j_k_d = numpy.zeros((T, S, D))
download_url = download_url_fmt % (yt_code, res[0])
face_list = set()
data = self.ser.read()
c = numpy.sum(numpy.square(temp), 1) - self.radius * self.radius
color = int(round(255 * v))
tf.name
second = [1, 2]
d1 = {x[0:2]: x for x in lst1}
test.running_sum(test.SimpleArray(100))
fixture.close()
record = Record(*inspect.getouterframes(inspect.currentframe())[1])
cached_g = mem.cache(g)
feeds.append(entry)
io_bytes = io.BytesIO(byte_array)
new_d
duration = np.diff(idx)
r, s = random.random(), 0
len_best = len(bestmatches[i])
val
foo = spy_decorator(Potato.foo)
FAILED(failures=1)
d = drec
x = x.number
D = 2
_add(a, b)
groupdict[key] = [dict([(k, v)])]
print(get_step(note))
pointer_ar = (ctypes.POINTER(C.c_float) * count)(*ctypes_arrays)
ctx = PyV8.JSContext()
Base = declarative_base()
+newConcrete
a = numpy.zeros((rows, 5)).astype(object)
print(dateForm.index)
firstHeader = CEL_HEADER.from_buffer(map, 0)
0
inner = dict(result.get(outerKey, {}))
result = f(values)
alias1 in mydict
aPtr.contents.value += ctypes.sizeof(a._type_)
httpReq = urllib.request.Request(url, pData, self._headers)
_
print(cj)
length += 1
thing_that_might_fail()
transact_time = fix.TransactTime()
this_year = DT.date(DT.date.today().isocalendar()[0], 1, 1)
mask[choice] = True
print(server.sum(1, 2))
big.info()
iterable_map[key] = [next(it), key, it]
p.daemon = True
print(number)
x[i][j] = min(x[i][j - 1], x[i - 1][j], x[i - 1][j - 1]) + 1
assert test_list[0] == 1
filename = os.path.basename(ImageFileName.value)
query_string = request.query_string
item = in_queue.get()
value = getenv_system(sys.argv[1])
browser.download.folderList = 2,
assert answer([1, 1, 2, 2]) == 4
Foo(8).numSquared
np.where(img1 > img2, img1 - img2, img2 - img1)
struct = time.struct_time((2015, 6, 18, 0, 0, 0, 0, 0, 0))
[7][8][9]
myzipfile = zipfile.Zipfile(StringIO(get_zip_data()))
setCookie.exposed = True
b
a = myobject.id
partial_integrals = []
n_samples = X.shape[0]
narray.assign(N, NULL)
print(vals)
p = Person(name)
screen = pygame.display.set_mode(SIZE)
href = (domain_link + href).strip()
lines = f.read().splitlines()
total += 1
body_children = list(soup.body.children)
cls._deck
logger_b.setLevel(logging.WARN)
sheet1 = xls.parse(0)
{}[list()] = 1
lev(s, t)
s = StringIO()
print(s, heights_smooth[list(xnew).index(s)])
flush_data()
print(y)
print(a)
element.extract()
linwcs = lambda x, y, n: ((x - y) / n, (x + y) / 2)
self.statusitem.setMenu_(self.menubarMenu)
ddd00000
print(x)
os.makedirs(os.path.dirname(self.get_ext_fullpath(ext.name)))
year_hour_means
os.mkdir(DIR)
get_hist = list(cursor.execute(sql_select))
w, x, y, z = q
Segment1 = {(X1, Y1), (X2, Y2)}
list_eye = lambda n: numpy.eye(n).tolist()
M = A.shape[0]
index_name = index_name[1:]
type(brown.tagged_words())
l = lst.pop(0)
values = [val_map.get(node, 0.25) for node in G.nodes()]
df = pd.read_csv(io.BytesIO(txt), delim_whitespace=True, index_col=0)
x *= 2 ** 29
pprint.pprint(gg)
R = int(round(var_r * 255))
angle = 0.5 * math.pi + tangent
result[idx].update(subset)
print((i, f.flags()))
f = inspect.currentframe().f_back
f_ratio = (ssq0 - ssq1) / (ssq1 / df)
self._tunnel()
session.bulk_update_mappings(User, user_mappings)
main()
combinations[key] = combinations.setdefault(key, 0) + 1
ser = serial.Serial(0)
ml.append(5)
myfunc.restype = c_int
articletext += tag.text
max_flow = sum(res[e] for e in tgt.in_edges())
self.key = key
wraps(s, t)
self.func = func
persons_by_jobs = defaultdict(list)
s
tmaj = int(fields[0])
foo2.a
False
print(name, myNames[name])
m, b = fit_line2(x, y)
index -= 1
model = Article
b.bark()
(t2 - t1).seconds
r, g, b = picture.getpixel((0, 0))
user
data_chunk = []
model = User
droid = android.Android()
r(argv[1])
my_class._meta = my_options
raise
B = B * 1
columns = {}
x.update({(2): 200})
last = next(it)
plot(x, y)
(10 ** 0.5) ** 2
self.image = self.images[self.index]
arr
texts.append(stemmed_tokens)
mcmc = mc.MCMC(model)
sp.capture()
n = len(x)
sum1 = sum([(vec1[x] ** 2) for x in list(vec1.keys())])
n & mask | m << i
old_width, old_height = im.size
zip(*iterators)
plt.subplot(2, 2, i + 1)
reader_p.start()
pub.send(word)
result[key] = getattr(self, key)
x, y = np.meshgrid(groups, unique_groups)
rparen = next(it)
_, exception, tb = sys.exc_info()
diff = a - b
string.seek(0)
[needleID, haystack[needleID], score]
x, y, z = arr.shape
dumb_replace(Input)
b = numpy.linspace(-5, 5, 1000)
__setattr__ = __setitem__
context
end = s.rindex(last, start)
byte_array[pixel_array == paddingVal] = 0
has_content = True
xmldoc = minidom.parse(url_info)
D = nx.DiGraph()
assert len(w) > 1
mylist = list()
a = 1.0
batch.submit()
line[col]
print(getFirstDup(c, sys.argv[1]))
orig_getproxies = urllib2.getproxies
char = sentence[i]
print(item)
probability = np.exp(p_log)
total = freq_list.count(max_cnt)
fig.canvas.draw()
close_stream()
df.loc[rows, columns] = 99
0.0, []
close_files_with_procfs(fd_min, fd_max)
has_neighbor[:, 1:] = np.logical_or(has_neighbor[:, 1:], square[:, :-1] > 0)
x = np.empty((120, 20000))
f, pathname, desc = imp.find_module(name, sys.path[1:])
dt = datetime.combine(date, time).replace(tzinfo=pytz.utc)
writeLoc = f.tell()
self.queryset = Comment.objects.filter(recipient=user.id)
x = np.sin(t)
amountToRead = size(file) - lastKnownSizeOfFile
args = parser.parse_args(get_xyz_cmd_line(cmd_line))
request = Request(environ)
dst = socket.inet_ntoa(ip.dst)
i_xy = np.intersect1d(x, y, assume_unique=True)
f()
reversel = []
template.render
net.sortModules()
mph = MyProcessHandler()
c = np.dstack((b, b, b))
hash = md5.md5(hash).digest()
d = CA()
_standardGenerator(other)
print(A * x)
y = sin(x)
domain = self.get_cookie_domain(app)
avg_sum = []
integrand = i(1) - i(0)
traceback.print_stack(frame)
self.value
x, y, z = v
math.ceil(f)
False
df.ix[df.index[idx]] = 999
regex = re.compile(pattern)
items
obj.view(cls)
s = socket.socket(i[0], i[1], i[2])
L
values_pointer = lib.rle_values(self.obj)
numpy_loss_history = numpy.array(loss_history)
h1 = SigmoidLayer(2)
start = a_str.find(sub, start)
wn.path_similarity(dog, cat)
tmp = list(K)
title = Column(String(100), nullable=False)
dict_x = {}
self.task = asyncio.ensure_future(self.update())
result[i] = score_sum
Green = RGBint >> 8 & 255
dists
bloop + offset
cursor = connection.cursor()
norm_factor = n * dx * dy * np.sqrt(norm_factor)
theta = np.arange(0, 2, 1.0 / 180) * np.pi
result = 0
ax1 = fig.add_subplot(211)
parts = t[0:4], t[4:8], t[8:12], t[12:16]
dec_lat = random.random() / 100
doc.setDefaultFont(option.font)
rendered2 = Template(rendered1).render(var2=6)
ClassB(the_number)
print(np.max(np.abs(iv_l - predict_ci_low)))
assert d is d[1] is d[2][4]
f = lambda x: x if x % 2 else x * 2
cons = []
foo = request.context
form = response.form
print(df)
print(sqlalchemy.__file__)
largest_index = -1
t = iter(s)
find_line(target, lower_bound, position)
IP_MTU_DISCOVER = 10
s = [10, 14, 18, 20, 25]
in_buff += mbed.read(mbed.inWaiting())
self._callback = callback
continent = models.ForeignKey(Continent)
display = Display(visible=0, size=(1024, 768))
R.append(i)
sys.getsizeof(foo1.__code__)
output_array = np.zeros(rows)
minutes = int(minutes)
y * y
b.pack(side=LEFT)
formatter = string.Formatter()
parser.resolvers.add(DTDResolver())
inv = ax2.transData.inverted()
deltas = []
segment_text = text_cell[start:end]
timer.start()
autoreload.on = False
kwargs[update_this] = TagTraduit.objects.get(pk=int(pk_str))
lines = (line.strip().split() for line in f)
trueydata = vcurve(truexdata, 1.0)
my_data = {}
456789
tmp = []
x in self.contents
timeoutCall.cancel()
a[:, (0)] * c0 + a[:, (1)] * c1 + a[:, (2)] * c2
print(env.host)
testme(x)(a) * b
med = np.median(np.diff(ts.index.values))
query = Question.all()
2, 4
print(type(f))
L.append(a[i])
ex1 = bins[0], bins[-1], freqs[0], freqs[-1]
diag_elems = A.data[idx_begin:idx_end]
self._d[1]
end = time.time()
print(l)
writer.sheets = dict((ws.title, ws) for ws in book.worksheets)
messages_to_delete = []
r2 = pd.qcut(a, q)
flat_index = n_cols * np.arange(n_rows) + col_index
CGIHTTPServer.test()
print(r[58:])
complex()
has_wpa = magic_number & crypt_wpa == crypt_wpa
valid = [int(b) for b in host_bytes]
SPARK_HOME / bin / pyspark
dep_dict = {}
df
C = np.empty_like(B)
BEGIN
data = [7, 7, 7, 7]
a
plt.hold(True)
minutes, seconds = divmod(rem, 60)
result = np.add.accumulate(result)
start_date = end_date - pd.DateOffset(years=5)
d = MyDict(lambda x: -x)
heap = list(set(text.split()))
host = host.strip()
a
output = []
sim_list = []
Xdict = dict(((i, j), v) for i, j, v in zip(X.row, X.col, X.data))
backend = load_backend(backend_path)
xs = np.append(xs, curcen[0] + currad * np.cos(fis))
raise gen.Return(x + 1)
template = self.template_with_initial
PythonEngine.Initialize()
response = request.urlopen(req)
m = np.isnan(a)
weights = []
str_lst.append(t)
print(yaml.dump(a))
cents = [2000, 1000, 500, 200, 100, 50, 20, 10, 5, 2, 1]
temp -= temp.min() - 10
dll.call_callback()
x = x.strip()
all_possible_permutations = []
spider_finished_count.count += 1
category = random.choice(list(lists.keys()))
h.add_credentials(username, password)
parts = haystack.split(needle, n + 1)
visited.add(node)
string_withNoise.count(string_pattern)
plt.figure()
x = 1, 2
SHGFI_ICONLOCATION = 4096
ys = ys[sorted_index]
moo = np.zeros((size, size))
value = mydict[key]
my_data = dict()
lookup[keyfunc(item)].append(item)
tmp = string1.split()
html = df.to_html()
d[0], d[-1] = d[-1], d[0]
d[word] += 1
emp = EmployeeRecord._make(line)
url = urlparse.urlparse(crawling)
a = 1.0
self.goodFood = []
l[i][1] /= d
pygame.init()
original_tag = soup.b
self.ui = Ui_CalculatorForm()
a = mydict()
pDst[x] = 1
ghost = Ghost(wait_timeout=4)
print(value)
xlsx.save()
X = np.linspace(0, 2, 1000)
sys.stdout = LoggerWriter(log.debug)
self.size = size
register = template.Library()
indicies = np.arange(a.size)[mask]
find_line(target, position, upper_bound)
4 or 6
lag_obs = next(observation)
ns = copy.deepcopy(default)
print((c_char * sz).from_address(address).raw)
gen = (True for i in lst if i == x)
my_slice = myarray[idx]
self.f(self.g(*args, **kwargs), *self.pending, **self.kwargs)
logging.basicConfig(filename=LOG_FILENAME, level=logging.DEBUG, format=format)
assert sequence_in(b, a)
slice2.insert(axis, m)
main()
self.value = n
B[i] = full_array[1]
stars1 is stars2
ones = np.ones(N)
Your_Root_Node.writexml(file_handle)
print(elem)
posts = g.db.posts.find()
deleteself.masses[-1]
self.density_air = 1.29e-06
self.density_air = 1.29
p.join()
string
data = ObjDict()
sb.append(line)
im[m, n] = ax[m, n].imshow(np.random.rand(10, 10))
key_name = entity.KEY_NAME % kwargs
p.ray(x=[0], y=[0], length=0, angle=np.pi, line_width=1)
self.patches.append(patcher)
setattr(ob, name, True)
q.put(n)
m.mock_calls
idx_arrays = np.where(df.isnull())
assert answer([1, 1, 2]) == 1
plt.figure()
opener = urllib.request.build_opener(MyHTTPRedirectHandler, cookieprocessor)
out = np.zeros((data.shape[0], 1), dtype=np.double)
[6.5, 1.5],
G = networkx.Graph()
foo
y1 = int(math.floor((canvas_height - old_height) / 2))
True
ncomparisons = ndict * nsearch
print(Test, Test.foo)
file = driver.execute_async_script(js)
get_screenshot()
longitude = data.longitude.tolist()
df
print(v)
second = list(itertools.dropwhile(str.isalpha, l))
12 % 48
node = to_visit.pop()
i = next(it)
diff = set(list1) - set(list2)
new_df = df.reindex(new_index)
client_id = XXXXXX - your_client_id
fig, axes = plt.subplots(ncols=4, figsize=(10, 4))
d = OrderedDict()
numerator, denominator = decimal.Decimal(n), decimal.Decimal(d)
f([part for part in l if len(part) >= k], k, m, result)
print(map.readline())
text = str(url)
chars[i] -= 1
output_array[i] = square_sum(input_array[(i), :])
sp[0], sp[1]
Color(1)
assert os.path.exists(path)
1 & 1
text_counts = Counter(text)
model.sample(iter=5000)
cam = cv2.VideoCapture(0)
points.set_data(xy)
print(cmpFunc.__name__, time.time() - st)
db = client.mydbname
(data_cm == data_cm2).all()
short_set_union_rest | few_large_lists | 0.849
x = y
assert b() < False < c()
freq, power, alfa, beta
1
y = np.array([20, 5, 4, 9, 11, 7, 25])
result[match.start(index):match.end(index)] = str(data[key])
self.threads.append(ErrThread(target=t))
__setslice__ = modify_method(list.__setslice__, 2, takes_list=True)
inner.string
PyType_Ready(PyTypeObject * type)
print(size)
W = tf.Variable(tf.zeros([NUM_IMAGE_PIXELS, NUM_CLASS_BINS]))
sample2 = np.random.choice(pop, size=size_sample, replace=True)
parse.add_argument(arg, **kwargs)
a_b.x
p = Pool(nthreads)
linedate = datetime.fromtimestamp(float(elements[0]))
wv = QWebView()
required_fields = []
z[t] += delta * sum(dy.get(e, 0) for e in t)
s1 = s.replace(s.value_counts().index[2:], np.nan)
name = friend.user.name
right_column = 1
myoutput.flush()
A, B
reversed = np.empty(shape=initial_shape)
env.update(caller.f_locals)
nrow = fr.shape[0]
result = self.get_current_file().readline()
retries -= 1
dep_list = []
X = sm.add_constant(np.column_stack((x[0], ones)))
driver.quit()
cits = aliased(TextString)
test
assert Index.StatusWord.value == 24641
MyClass
print(output_line)
sorted_1 = sorted([repr(x) for x in sample_json1])
df = DataFrame(randn(100000, 20))
a
cb = im[-1].colorbar
tag.addImage(8, artwork_file_name)
decoded += chr(data[i] ^ ord(key[i % l]))
check_thread = threading.Thread(target=run_checker)
apps.app_configs = OrderedDict()
outfile.close()
N(h, 0)
kOUT[i] = func(TempLake[i], Z)
deletechar
result = []
print(intersect_AB, intersect_BC, intersect_AC)
communicate_error(process, line)
wordindex = ldawordindex[index2wordcollection[i]]
in_order_print(root.r_child)
df
x2 = np.random.rand(10)
STATUSMAILER_RECIPIENTS = []
pd.Series(conditions)
yi = linspace(min(y), max(y), resY)
self._rooms = d.clear()
tk.Tk.__init__(self)
key + 1
l = [random.randint(MIN_VALUE, MAX_VALUE) for i in range(ITEMS)]
title = titles[0]
ar = np.arange(10)
print(r_dataframe)
Telnet.__init__(self)
values = itertools.chain.from_iterable(points)
values = numpy.arange(10, dtype=int)
key = h.root()
y = x
rank = 0
coord = tf.train.Coordinator()
X, Y
loss = loss1 + loss2
database.execute_some_query(query)
microseconds = int(dt, 16) / 10
start = datetime.datetime(2010, 1, 1)
app2 = Celery()
help(sys.float_info)
expr = sym.sin(a) + sym.cos(b)
ti = np.linspace(0, 100, 100)
match_object = reobject.search(data2)
newlist2 = list()
key, value = queue.pop()
new_background = 255, 255, 255, 255
user
provider.rssfeed = form.rssfeed.data
Builder.load_string(kv)
ww = w(r, theta, phi, alpha, beta, gamma)
R, C = (A != 0).dot(B != 0).nonzero()
start_idx = np.random.randint(offset, len(stock) - timesteps)
print(uniq)
pch = fR.tell()
probs.resize((len(n_vocab), len(m_vocab)))
x = np.linspace(0, 10, 501)
register = template.Library()
psk = 1 << 7
[-1, 1, 1, -1, -1]
table = html.fragment_fromstring(text)
self.func = func
N = 10000
term = np.exp(logsumexp(v))
x = keypoints[i].pt[0]
t1.join()
order_array
c = wmi.WMI()
primefactors = []
finder = importlib.machinery.FileFinder(path, [(lazy_loader, suffixes)])
print(foo(w))
plaintext = decryptor.decrypt(ciphertext)
formatted_text = json.dumps(json.loads(r.text), indent=4, sort_keys=True)
elements = sorted(full_set)
df2.head()
len0 = len(s)
a = 1
4, 5
lF = ttk.LabelFrame(root, labelwidget=f, borderwidth=4)
npt = X.shape[0]
type(x) is list
t = np.arange(0.0, 2.0, 0.01)
timeit(lambda : emptydict.keys())
manager = Manager()
print(x)
list(self.data.keys())
mergedVersions.append([v])
hostname, out_path, in_string = sys.argv[1:]
exc = sys.exc_info()
a.do_something()
D.__eq__(5)
msg = msg.format(*self.args)
imageWidth, imageHeight = img.size
result = []
rest = pd.DataFrame()
self.localizer = localizer
print(len(A))
caller = sys._getframe(1)
pv(b)
bytes[1:].decode(CODE_TO_ENCODING[bytes[0]])
self.__values[:]
wordlists[wordno] = set([recno])
x = 10
handle = lt.add_magnet_uri(ses, link, params)
masterDict = {}
raise Exception(msg)
tmp
v = df.t.values
ItemNumber = List.index(Item)
python
self.factory = RequestFactory()
10 ** (a / 10)
print(repr(p))
cls.ORIGIN = cls()
w = Worker(i)
2 ** 48 - 1
b = []
show()
TestApp / testapp / testmsg.py
default_encoding = sys.stdout.encoding
angles = np.zeros(len(edges))
counter = 0
doc = DocFactory.create(user=user)
int_part = int(abs(x))
text_edit.show()
myinstance.myfunc()
pygame.init()
value_in_config = self._config.get(self._section, option)
wrapper
result = defaultdict(list)
l
print(id, name)
pool.map(decode, map_parameters)
ip = get_ipython()
image = Gtk.Image(stock=Gtk.STOCK_OPEN)
array(self.__wrapped)
root = ET.fromstring(content)
counter[x] += 1
labelled = np.empty(values[0].shape)
results.append((ind, ind + sll - 1))
num_dates = [date2num(d) for d in list_of_datetime_datetime_objects]
self.last_match = re.match(pattern, text)
a = defaultdict(lambda : 1)
source = source.__class__
udf(concat_, ArrayType(type))
obj_7 == obj_6
eye = np.eye(corr.shape[1])
has_neighbor[:, :-1] = np.logical_or(has_neighbor[:, :-1], square[:, 1:] > 0)
data = arange(A * N * M).reshape((A, N, M))
axis.set_ticklabels([])
OrigTrace.localtrace_trace(self, frame, why, arg)
b = a[a]
result
d = np.timedelta64(int(60000000000.0))
n.to_proto()
output += i[0]
palette.setColor(palette.WindowText, QtGui.QColor(85, 85, 255))
print(dirpath)
len(self.__keys)
print(serial_data)
endfun
code1
myfunc2_code = f2.__code__.co_consts[2]
source / path / to / venv / bin / activate
x = t[1]
someApp.py | something.pl | finalStep.py
params = fitdistr(x, dist)
print(a)
s = 1
print(limits.shrt_max)
test_set = treebank_tagged_sents[train_len:]
data = PickledObjectField()
r = np.random.rand() ** inv_d
edgar.database.create()
print(result)
op = str(curlstdout)
ff = LimitedRandDoubles(fLim, N)
temp_dir = mkdtemp()
y = np.sin(2 * np.pi * x)
a = A()
self.raise_()
proc = psutil.Process(pid)
outfile = os.path.join(outPath, filename)
{{item | quality}},
[1, -1, 1, 1, 1]
print(1.0 / 7)
df.loc[mask, k] = df[mp.get(k)]
r = []
root
print(html)
max(map(depth, expr)) + 1
Flask - Cache == 0.12
transferprojrc(repo.ui, repo, remote)
axis.set_major_locator(MultipleLocator(1))
pixel_array[y][x]
manager = plt.get_current_fig_manager()
value >= self.low and value < self.high
mylist[i] = mylist[i - 1]
debug = False
deleteelem.getparent()[0]
fill_item(widget.invisibleRootItem(), value)
pathlib.Path(mypath).parts[0]
line.set_data(plot_data[:, (0)], plot_data[:, (1)])
d = deferToThread(worker)
value = myVariant.toInt()
indptr[-1] = len(data)
ymax = max(d.values()) + 1
21.88
retval, image = cap.read()
w.close(html)
my_file.magic
Input(device_id, buffer_size)
lambda : self.doStuff(item)
print(test.g)
dill.dump(ibm, fout)
print(key)
n = nn.SpatialConvolution(1, 16, 12, 12)
fg, ax = plt.subplots(1, 1)
new_user = User.objects.create_user(username, email, passw)
data[key] = n * [val]
l = list([x for x in l if x == i or x % i != 0])
m = r.search(s)
i = (i & 255) + (i >> 8)
diags = numpy.lib.stride_tricks.as_strided(stacked, shape, strides)
coords.append((ix, iy))
execute(execute_deploy, command=command, hosts=hosts)
cons.append(lambda i=i: i)
right = find_max(L[mid_index:])
TestApp / testapp / sub / __init__.py
result = current = {}
record.MYVAR = MYVAR
-1
assert kind == PyUnicode_4BYTE_KIND
output
bye
start_date = datetime.now()
a = numpy.array(d)
pip - -version
w = np.ones(L)
pyplot.show()
to_visit.append(next_face)
sys.stdout = fsock
bins = [0, 0.15]
PERIOD_LENGTH_IN_SECONDS = 10
df
my_list = []
regmxh = zeros(size(di2))
self.on(i)
keys = list(object_dict.keys())
X_ext1 = X[idx1[:, (1)]]
vec = np.random.randn(ndim, npoints)
x = x.flatten()
gridcoords = np.meshgrid[:grid.shape(0), :grid.shape(1)]
matrix[x][y - 1]
Password = MYPASSWORD
self.total_steps += 1
headers = []
next = nearest_multiple_of_a_or_b_to_current(current, a, b)
print(i)
x, y, z = mgrid[-100:101:25.0, -100:101:25.0, -100:101:25.0]
node
Suppress(string_representing_where_you_want_the_regex_to_stop)
your_dictionary[node.string] = node.next_sibling
y = np.random.normal(5, size=1000)
p.join()
x
surf = ax.plot_surface(x, y, z, **plot_args)
MultiprocessingService().setServiceParent(application)
HavsServer, PiratServer, SvartServer, NattServer, SovServer
row = []
upper_key = key.upper()
columns = (x.name for x in cursor.description)
new_spam_user = SpamProfile.objects.create_user(spam_field)
media_body = MediaFileUpload(filename, mimetype=mime_type, resumable=True)
len(self.__flags)
f2 = lambda a, b: a + b
df = self._constructor_expanddim(self)
h()
objects = TaggedItemManager()
print(val)
draw_half_circle_rounded(image)
foo()
p = psutil.Process(os.getpid())
length = len(name_num[mykey])
req = get_username()
[(1 if v == value else 0) for v in in_array]
newWord += char
sub.finish()
child = Task(target=download, args=(status, filename))
sock.settimeout(timeout)
fig = plt.figure(figsize=plt.figaspect(0.5) * 1.5)
datetime(2000, 1, 1),
xy_undistorted = cv2.undistortPoints(test, camera_matrix, dist_coeffs)
clf = DecisionTreeClassifier(random_state=0)
f = f.bar()
n = float(n)
simple()
b = a.sort()
results.add(x)
curs.execute(copy_cmd_str)
r, g, b
_s[i] = _s[i] - 1
loop.run_until_complete(main())
arr
MAPVK_VK_TO_VSC = 0
path.isfile(uglyfile)
optval = optval.strip()
print(type(x))
min_length = len(sets)
parse = makeparser()
N = 100
status = r.status_code,
image_filesize = len(contents)
ret = []
x = np.nan
sample_rate = stream.getframerate()
mlist
fragments = html.fragments_fromstring(xml)
pts = numpy.random.random(N).reshape(N / dim, dim)
print(err)
c = Cluster(protocol_version=2, auth_provider=ap)
a = 0
val = urljoin(base_url, val)
color_numbers = list(values.values())
profiler.runcall(threading.Thread.run, self)
some_dict
fieldspecs.sort(key=lambda x: x[1])
mylist = [10, 2, 20, 5, 50]
m, v
scene.camera.rotation_euler[1] = ry * (pi / 180.0)
self._values[key] = value
binary_insert(root.r_child, node)
new_results = new(a, N)
phase = np.exp(1j * np.dot(rpt_list, kpt_list.T)) / r_ndegen_tile
i += 2
verifier.verify(h, signature)
session = db.create_scoped_session()
response = request.invoke_subrequest(subreq)
newdict = dict(defaults)
email_body = data[0][1]
i -= 1
ind & ind2
NodeDb.append(Node)
np.nanmean(stride(v, (n - 9, 10, m), (s1, s1, s2)), 1).round(),
contents.seek(0)
x = dec % 16
n = int(input().strip())
fum.__class__ = DerivedFum
self.c = 0.0
self.x = x
df.A.iloc[pos:pos + 5] = 0
chars = random.randrange(2, 10)
nc5 = nc4 + 1 if c4 == nc4 - 1 and nc4 != 4 else nc4
cofactors.append(cofactorRow)
dummies = pd.get_dummies(df.level)
cls, a, b = row[0], int(row[1]), int(row[2])
2
h[key]
print(args)
new_y = np.random.randint(10, size=5)
out = []
letters = list(ascii_letters)
-cr.dictfetchall()
dt = p.DataFrame(rand(len(dr), 2), dr)
dict.__init__(self, **kv)
d += 1
185, 195, 185, 195, 200
logger.addHandler(hdlr)
strio = cStringIO.StringIO()
simplify(vers1 + vers2) == 0
d[column.name] = str(getattr(row, column.name))
mat_row.todense()
2011 - 2 - 2, NaN, NaN
url_lst = list(urlparse.urlparse(old_url))
mat[n - 1:, n - 1:] = Hx
start_time = datetime.now()
obj = MyClass.objects.get(pk=id)
X = np.random.random((10, 50))
product *= x
0, 1, -image.rows / 2
print(out)
file_buffer = old_fb + file_buffer
n = 1
print(L)
print(string[0:5] == string[-10:-5])
fg.clf()
set_x = set(list_x)
y = x + np.random.normal(size=N)
nosetests
sum += i
self[x] -= 1
raise e
[future] = c.scatter([x])
orig_dict[key] = new_dict[key]
prev = line
i = len(s)
print(1)
print(visitor_print_prefix(expression))
some_fun(c)
X, y, X_mean, y_mean, X_std
main()
it = iter(seq)
rst = []
raise Return(1)
given.add(name)
deletea
self.cert = cert
y = 1.000002
digits = []
x = y
self.val = obj
theResult = pd.concat([theSum, theAverage, theProduct])
form = CarAdminForm
categories = []
c = a
results = match.groups()
x.strides
enum_list = list(map(int, Color))
func
grid.arrange(g1, g2)
f.close()
my_hello_world = _temp.level_one_a.level_two.hello_world
group = parser.add_mutually_exclusive_group(required=False)
start = datetime.datetime(2000, 1, 1)
True
self.low = low
arr[:, ([frm, to])] = arr[:, ([to, frm])]
lets = string.ascii_uppercase
self.available += len(data)
secache = {}
x = y
Student.idCounter += 1
array([True, False, False, True], dtype=bool)
list2 = list()
UW_dt = pd.to_datetime(str(UW_dt))
data = [randint(0, 100) for r in range(N)]
self._list = list_
df
content = conn.getresponse().read()
print(sentence.root)
cardValue = cards[card[0]]
my_django_shutdown_signal = django.dispatch.Signal()
grab_data(year, rc)
s = c.unstack()
to_ret[key] = deep_convert_dict(value)
y *= -1
response = {}
j = np.arange(1, num, dtype=np.float)
alive = models.BooleanField(default=True)
r = x
s = psum(n)
self.cache = {}
random.shuffle(nums)
numbers = [int(x) for x in t]
file_chars = set(file_string)
a[0] = -a[0]
f2(x) + s[0]
a = np.zeros(D)
true_found
ov = OnlineVariance(ddof=0)
a = randvec(1000, 20, 100, 1)
n = 0
exec(code, run_globals)
total_integral = sum(partial_integrals)
response = bytearray()
count_inside[..., (k)] += k == labels_img[:-2, 2:]
sieve[0] = 0
self.appendPlainText(str(txt))
self.remoteport = remoteport
self.localport = localport
print(a_foo.int_clause(10))
https_data = speed_test(True, 1000)
np.bincount(a.flat) * rand
pprint(B_rref)
r = np.arange(0, 1, 0.001)
self.app
logging = __init__.logging
movement = player - zombie
y = y - np.mean(y[:20])
lineArr = dataArray[(i), :]
tmp.MyEnum.A
hour = ts.index.hour
mysocket.setblocking(0)
stuff.append(blah)
op = next(it)
p = ast.parse(open(mod).read())
a = fig.add_subplot(1, number_of_files, i + 1)
corrected_list.append(y)
r = numeric(s)
y != y.shift()
path = []
channel.confirm_delivery()
delete_images.py - h
self.q = q
t = Table(data, style=style_)
df2[~f]
BOLD = lambda s: (1, s)
arrow(left, 0, right - left, 0, length_includes_head=True, head_width=0.15)
s = s.append(s2)
y[1:] = y[1:] + y[:-1]
arg_count = foo.__code__.co_argcount
img = cv2.threshold(img, 0, 255, cv2.THRESH_OTSU)[1]
cv = CountVectorizer(tokenizer=mytokenizer)
runaj(coord, x_dist, y_dist, z_dist, a)
print(i)
pi = gu_pinv(b)
heappop(h)
server_thread.start()
i[axis] = a.argsort(axis)
k = k.text
decomp = decompressor.decompress(chunk)
df2.key.isin(df1.key.tolist())
arr.insert(2, arr[2])
lis.append(res)
g = iter(l)
filtered = list(filter(yada, data))
model = MyModel.m2m.through
ll = np.array([bx1, by1])
secondNum = numberOfNumeral(ns[1]) if len(ns) > 1 else -1
width, height = 400, 400
print(time_cell.value.hour)
power = 1
content = f.readlines()
result = tuple(islice(it, n))
sum = 0
out[Y_idx, X_idx] = Z
self.api = api
uid = StringField(max_length=60, required=True)
ENDPYTHON
yl = twodtensor2list(y, shapey[0], shapey[1])
cv2.grabCut(imgo, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)
contexts = [stack.enter_context(frobnicate(i)) for i in range(2)]
pygame.mixer.pre_init(44100, -16, 1, 512)
kdtree = spatial.cKDTree(dataset, leafsize=10)
s = input()
x
stack = []
dests
order.reverse()
buf += newbuf
range(min1, max1, step1),
op.append(item)
M = len(x) + len(y) - 1
pi = (a + b) ** 2 / (4 * t)
cmd.append(param)
source
value = model.get_value(iterr, 0)
parser = PDFParser(fp)
stdout, stderr = process.communicate()
HTTPAdapter.build_response = new_HTTPAdapter_build_response
print(root.data)
tmp2 = tmp2[:, ::-1]
img = StringIO()
consumer.stop()
intf,
new_arr[idx] -= 1
td = datetime.timedelta(hours=10.505)
myParam2 = 2
vectorizer = TfidfVectorizer()
C = int(time.time() / window)
last_updated = last_updated.astimezone(settings_time_zone)
predict_mean_ci_low, predict_mean_ci_upp = data[:, 4:6].T
print(link.url)
sum, n = 0, 0
script.py
Counter(str_a) & Counter(str_b)
example.print_value_1(s)
pos = 0
assert app1.tasks[test.name]
Texts.append(TextArea(t, textprops=dict(color=c)))
2
fcntl.ioctl(console_fd, KDSETLED, 4)
figprops = dict(figsize=(10, 10), dpi=100)
next(count)
labels = seg.slic(color_image, n_segments=4, compactness=4)
pathname = os.path.dirname(pathname)
millis / 1000.0
data = d[key]
request.param
states_from_slugs[slug] = state_name
M = []
print(buffer.value)
vol = []
data = pipe.read(1024)
request.names = names
DataBase.execute_some_query(query)
reverse_dic[v] = reverse_dic.get(v, [])
out[:, :, n1:] = B
client = SpreadsheetsService()
stderr = str()
signal.signal(signal.SIGALRM, handler)
perms[k] = list(permutations(v.values))
wand.sequence.append(one)
b_List.extend([F])
df2 = DataFrame([[np.nan, 1], [np.nan, np.nan]])
axes = data.hist(sharey=True, sharex=True)
myobject.fobar
customer.default_source = newcardID
PyLong_FromSsize_t(res)
freq = Counter(zip(words, nextword))
argv = sys.argv
sleep(interval)
page = template.getPage(i)
j = j + 1
l = list(set(list1) - set(compSet))
buf = cast(p, POINTER(c_char * n))[0]
_g[char] = Variable(char)
d[key] = data
_can_do_it(x)
Mock(wraps=mock_coro)
data = []
grid = np.indices(data.shape)
theta = list()
werkzeug_logger.setLevel(DEBUG)
print(len(argv), repr(argv))
outData = [x.getElementAsFloat(strD) for x in fieldDataList]
n = str(n)
s = pd.series(d)
self.addCleanup(tb.deactivate)
self._a = self._a_compute()
cursor = self.collection.aggregate(pipeline=pipe)
rest2.append(r)
x = Series(linspace(0, 2 * pi, 10000))
v[i] += w_thing
Py_DECREF(it)
done = object()
run_my_stuff()
main()
rowcount
sum_of = 0
charlst = list(word)
parser
self.it, cpy = itertools.tee(self.it)
testResult = unittest.TestResult()
theA.methC(params)
theA.methA(params)
GLOBALLOCK.acquire()
t.daemon = True
b = np.fromstring(np.random.bytes(nb), np.uint8, nb)
a1[i] = i
---Comment
re_match(m)
l[:] = result
kwargs = dict(obj=obj, parent=event.oldParent)
self.sock.settimeout(self.timeout)
x = np.arange(16).reshape(2, 1, 8, 1)
self.num = num
sel = Selector(response)
ctran = ogr.osr.CoordinateTransformation(point_ref, geo_ref)
n = 1
frobnicate(comp)
print(np.matrix(A))
sys.displayhook = lambda x: sys.__displayhook__(True if x is False else x)
[now.day, now.month, now.year]
(p(x + h / 2) - p(x - h / 2)) / h
self.moduli = []
n = 4
split_size = 2
out = {}
testList = [False, False, True, True]
dis.dis(code)
HexDumpWidth()
print(body)
BIT1 = 2 ** 1
print(width_val, heights_smooth[list(xnew).index(width_val)])
dups = []
[0, 1, 1],
set1 = set(el[0] for el in list1)
percent(0.1565, 2)
df.columns
X = numpy.asarray(rng.uniform(low=-2.1, high=5.0, size=(batch_s, dims)))
allergies = []
vec[uid_rows] = 1
nameArray.append(spl)
sortedlist = sorted(data, key=operator.itemgetter(1), reverse=True)
t2 = time()
result = first_list + list(in_second_but_not_in_first)
ds = (dd / day).astype(int) + 1
raise DatabaseError(state, err_text)
rev += text[i - 1]
S = set()
oldWidth = image.shape[1]
nchannels = 1
self.b / 1024
a1 = 2
PriorityQueue.__init__(self)
-managed
delfile.write(os.urandom(length))
img = img.resize((w, h + height_needed + 5))
p.x
idx = np.repeat(c.index, c.values)
error = np.mean(a != b)
pylab.show()
x = np.random.randn(10, 1)
adj[i, 2] = x - 1
rnd = random.random() * sum(weights)
clean_table_grouped
sd = SortedDict((key, value) for key, value in data)
ret = ctsquarelib.mysumsquares(dataptr, datasize)
delta = datetime.timedelta(fourth_jan.isoweekday() - 1)
another_field = models.CharField(max_length=1000)
repr(t2)
singular = lambda m: numpy.linalg.det(m) == 0
moo
print(tst2)
e = [-1] + d + [len(a)]
self._paths = []
d = d.reshape((-1, 128))
align_arrays(a)
(errors, okays)[success_condition(r)].append(r)
solutions += rec_dubz(prev + seq[0][0] * 2, seq[1:], allowed=allowed)
title, url, price, title2, keyword = row
tokenize = CountVectorizer().build_tokenizer()
f.user = request.user
A[root], A[child] = A[child], A[root]
numprimes = int(sys.argv[1])
self.delta = 0.0
group.loc[idx, new_col_name] = fill_value
subparsers = parser.add_subparsers()
y.append(random.randint(0, 1000))
A = np.random.rand(1024, 1024, 5)
dat = np.swapaxes(dat, 0, i)
CACHE = {}
tb = testbed.Testbed()
client = pysvn.Client()
hc_expand_dims = np.expand_dims(hc_scaled, axis=0)
can = [[max(min(u, 10.0), 0.0) for u in yy] for yy in can]
ouf.write(converted)
activity.setContentView(self.webview)
destination.write(chunk)
g = QPainter(img)
show()
purchases = Purchase.query.all()
plot(equation.rhs, (t, 0, 10))
re.sub(pattern, replace, str1)
sys.exit(app.exec_())
stk = inspect.stack()[1]
vmax = np.max([A, B])
name = lambda n: labels[n % len(labels)] + str(int((n + (9 + 4 * 12)) / 12))
mysocket.settimeout(0.5)
cert = decoder.decode(substrate, asn1Spec=rfc2459.Certificate())[0]
n = a.shape[axis]
all.mask = True
print(ed(df1))
__metaclass__ = m1
c
i = j - 1
negatedEven.append(-v)
x = [5]
rightpath = []
grouped = data_file.groupBy(lambda r: r[0])
self.request = request
interactive(True)
queries.append(db.table.field == x)
d = [1, 2]
n -= 1
x, x * x
func = items[0]
recursivereverese(nestedList2)
A = df.values
print(i)
hits = [(a, b) for a, b in list(self.keys()) if a <= key < b]
print(bigrams)
autorestart = true
autostart = true
b_stop_i = min((b + 1) * b_chunk_size, nrows_b)
(b - a).elements()
o.lastName
i += step
copy = items[:]
n[0] = 10
rv.append(a)
gen = generator()
combined[::2] = neg
--2
nbits = n.bit_length() + (1 if n < 0 else 0)
dx = X1[1] - X1[0]
list(binomial_choice(list(range(100)), 0.05))
children = d[n]
y = [2, 4, 6, 8, 10]
decimal.getcontext().Emax = 1000000000000
mylist = [(25, 7), (26, 9), (55, 10)]
mask_outside_polygon(poly_verts)
xvals = np.arange(NPOINTS)
map(indexed.get, a)
True, True
is_tuple = True
data = np.random.normal(size=10000)
nf = urllib.request.urlopen(url)
a = 1.0 * np.array(data)
print(arduino.readline())
sum(abs(runs_1[key] - runs_2[key]) for key in keys)
vals = np.concatenate(arr)
cursor = connection.cursor()
valid_utf8 = True
k = min(i, K)
list(d)
x = -2
matches = []
print(plt.style.available)
K = np.array(K)
unique_rows = [sorted_arr[i] for i in diff_idx] + [sorted_arr[-1]]
x = x * math.pi / 180
True
a = np.zeros(4)
result = []
list(self.data.items())
matches = re_.findall(pattern, string, flags)
maxchain = []
deleteelem.attrib[entry]
True, 10
blah = False
list(round_robin_odd(d, n))
s = input()
index.parse(source_path)
host_status
out[:, (0), (0)] = 1
sys.__excepthook__(exception_type, value, tb)
hr = dr.map(lambda x: x.hour)
weighted_quantiles /= weighted_quantiles[-1]
GlobalGraphOperations.at(graphDatabaseService).getAllNodes()
start += Decimal(d_start) * width
array1[-1:] = array2
print(x)
mediaref = line[7:len(line) - 1]
df = n - 2
time_new, data_new
file2freq = Counter(zip(C, D))
total += 2 * y
email = TextField()
len1 = len2
length = len(LIST)
t2 = [4, 5]
log_x = numerator - denominator
b = [1, 2]
date - date
x = (np.random.uniform(size=10000) > 0.2).astype(int)
img.save(output)
buffer_size = 100
True
previous_df_no = 0
size() == 0
to_table, fn, AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, delim, quote, gzip
bigset = set(random.uniform(0, 10000) for x in range(10000))
REM_Value2 = Bar
flanked_by_positives1 = has_pos_1_to_left1 & has_pos_1_or_2_to_right1
Astars = list()
print(volume.GetVolumeRange())
_save = PyEval_SaveThread()
print(data)
ys = filter(lambda y: y < 5, map(expensive, xs))
pdb.gimp_image_undo_group_start(img)
dLock.release()
a = sum([(ord(b) * 2 ** (8 * n)) for b, n in zip(s, list(range(len(s)))[::-1])])
conn
remote_user = C.DEFAULT_REMOTE_USER,
home = os.path.realpath(home) + os.sep
using_filters(data)
self[item] = res
cardValue = card[0]
bob = brain.Markov()
pixels[i, j] = i, j, 100
splash.Destroy()
sys.version_info
autojit_func = numba.autojit()(increment_counts_in_matrix_from_chain)
lps = count / sec
B = float(np.sum(b)) / ttl
canvas.showPage()
logger.setLevel(logging.NOTSET)
r.url
val = y.values
orig_float_format = pd.options.display.float_format
a, b = b, a + b
imageSize = image.size
path = os.path.split(__file__)[0]
mean = numpy.mean(data)
self.q_filters.append(a_new_q_object)
p.join()
doc = c.getresponse().read()
cvZero(imaginaryInput)
(6.9).Signals
foo
plt.plot(data[:1004, (0)], data[:1004, (1)])
lis = list(range(20))
candidates = [[random.randint(0, 9) for _ in range(5)] for _ in range(10)]
calculated_chunks.append([someFileId])
last[i + 1] = next(iterators[i + 1])
win.disconnect(win.connection_id)
DeadlineExceededError
im_mask |= hitmiss(im_binary, kernel.T)
exchange.sendResponseHeaders(code, bytes.size)
new_txt = process(f.read())
sample_weight = numpy.array(sample_weight)
print(next(t for n in noun for t in tables if n in t))
haha = np.zeros((2, 2))
traceback.print_exc()
response.content = s
key
ax.set_ylim(ylim)
msg = msg.format(**self.args)
r = np.sqrt(R[k, k] ** 2 - x[k] ** 2)
group = Group.objects.get(name=group_name)
a = list(range(0, 10000000))
matplotlib.rc_context.__init__(self)
loop = loop or asyncio.get_event_loop()
s = get_session()
ybar = np.sum(yd) / len(yd)
svc.fit(svm_x_train, svm_y_train)
y = np.interp(percents, p, d)
output_notebook()
plt.autoscale(False)
list2 = list1[-max_size:]
it_l = iter(l)
result = f(somedata)
result = int(a, 16) ^ int(b, 16)
indices = m.indices
c = 0.0
self.coords[self.i, 1]
right = [2, 4]
ax[i, 2] = plt.subplot(gs[i, 2])
print_data(data)
sensor = models.IntegerField(db_index=True)
self.process_candidate()
self.d
self.tree_store.append(parent, [f, True])
word_cnts = dict(zip(word_list, itemgetter(*word_list)(cnts)))
attribute()
line = remove_non_ascii(line)
p.rect(0, 0, 5 * cm, 5 * cm)
dfrm
c = a + b
params[kwargs_name] = {}
f = gzip.GzipFile(fileobj=buf)
out += str[bit].upper()
T = 1.0
messages.append(message)
arr[..., (i)] *= 255.0 / (maxval - minval)
i = 0
ui.write(e.EV_REL, e.REL_Y, 10)
id(b)
print(self.name)
pkt = scapy.Ether(self.contents)
self.test_property = resource_1.some_func(), resource_2.some_func()
req = urllib.request.Request(url)
string += str(item)
lst1[0] = 5
self.canvas = ax.get_figure().canvas
points = np.random.randint(0, 90, size=(100000, 2))
unique_columns, column_count = npi.count(a, axis=1)
b = IRtest[mz, my, mx]
nsearch = len(search)
a = x + y
df2 = df[df.dte < lastyear].B.head(depth)
ax1Ticks = ax1.get_xticks()
cypher_merge_user.execute_one(name=screen_name)
sys.meta_path.remove(self.collector)
x = int(word)
pwd = Pwd()
b = []
data = np.c_[a, b, c]
score
index = [x for x in summary]
print(output)
args.func(args)
v = df.values
print(result)
deleteclusters[idx + 1]
EmptySearchQuerySet()
a = numpy.frombuffer(aa, dtype=numpy.uint64)
l2 = [5, 6, 7, 8, 9]
l_two = [4, 6, 9, 11, 4]
callgraph.add_subgraph(cluster_bar)
values = scipy.ones(col.size)
B = A[np.random.choice(m, n, replace=False)]
result[0] = 0
a.connect()
dict(form=auth.register())
ok
ones((4, 1))
wordMap[bigram].add(word)
handle_threshold_reached()
app.request_class = OrderedRequest
parser.set_document(doc)
m = [(d in l) for d in w]
j = i + len(keyword) + 5 + 1
total_price = 0
last = a[-1]
f
chain.insert_rule(rule)
iptr
arrayIndex = numpy.where(row.data == row.max())[0][0]
print(model.eval({select_test: False}))
output = sp_ls.communicate()[0]
httplib.HTTPConnection._http_vsn = 10
sintheta = np.sin(theta)
deletea
connection.allow_thread_sharing = True
self.taskMenu.addAction(menuItem_Task)
print(df.shape)
[k] * l
raise
result = []
bitexts = comtrans.aligned_sents()[:100]
x += [1]
request = Request(url)
x, y = np.where(a=a)
s.add(BObject)
G = nx.gnp_random_graph(n=7, p=0.6)
mock.clear()
args = parser.parse_args()
c = f(b)
sb.setValue(sb.maximum())
phi = seq(0, 2 * pi, length=1200) - 0.27
print(status.text)
number.num
j = [1, 1, 1, 2, 2, 2]
a.d.more_c = a.c
m = int(input())
y += i
int_matrix = np.random.randint(10, size=(7, 5))
print(s)
res or [p[-1:] for p in parts]
x = places.objects.insert(a)
test_data_A = XY
your_code()
print(i)
b(a, 10)
decorator
sess = imaplib.IMAP4()
print(aStruct.someName, aStruct.anotherName)
result
ctypes.get_errno = lambda : _where_is_errno().contents.value
arg = sys.argv[1]
order(self.initial_value)
FLASK_ENV = development
django.conf.settings = local_django.conf.settings
start = stop + 1
table[n - 1][s]
overlap = {}
testA.py
self.age = age
env = Environment()
win.refresh()
self.data = data
size = 0
result = arg
Table = Orange.data.Table(Domain)
S.append(tmp)
V1 = V + numpy.outer(u, u)
0, 1, 2
inner_nodes = [n for n in nodes if G.out_degree(n) > 0]
print(repr(sumVal))
results.append([(xa, ya), (xb, yb), ia, ia + ib])
out[i] = 1
y = r * sin(theta) * sin(phi)
mpz_mul(base, base, base)
subparsers = parser.add_subparsers()
Woman is [+HUMAN], [-MALE], [+ADULT]
reshape = pd.concat([product, prc], axis=1)
v = A[::2][10:20]
migrations[old_version] = {}
entries_grid = np.rollaxis(entries_grid, 0, n + 1)
print(filename)
x, temp = divmod(x, m)
B = int(round(B * 255))
nm = ~nm.fillna(0).astype(bool).values * 1
child = self.contents[0]
print(phone_number)
response
distances = list(range(len(s1) + 1))
{{field}}
print(count)
dataold = scip.misc.fromimage(pixold)
frontier_index = 0
sp_ls.stdin.close()
j = i + 1
y = 2
p0, p1 = p[0], p[1]
h = Handler()
alert(endx - startx)
lambda df: df.assign(closeScaled=df.close.div(df.open.iloc[0]).round(4))
request = event.request
result = list(match.string)
[1, 1, -1, -1, 1]
x = 5
cs = [numpy.sqrt(c[0][0]) for c in cl]
total = len(allpeople)
meta = sqlalchemy.MetaData()
TIMEOUT_IN_SECS = 10
print(first, second)
N = 5
reps = np.random.randint(1, 4, len(start_df))
D = date(day=int(datelist[0]), month=int(datelist[1]), year=int(datelist[2]))
z = w
d.feed.subtitle
context = dict_from_django_context(context)
stdoutHandler.setLevel(DEBUG)
blank = False,
value
tolerate
firstLine = readFile.readline()
x -= 987661
starts = [(p * 2 * pi) for p in percents[:-1]]
result_dict = {}
friendList
month += 1
loop = asyncio.get_event_loop()
from_list = list(range(100))
print(utc(dt, GMT1()))
django.db.backends.utils.CursorWrapper.execute = execute_wrapper
w = dict((x, i if i < to else i + 1) for x, i in w.items())
br = mechanize.Browser(factory=mechanize.RobustFactory())
print(xquery.printPlanAsXML())
request_map = {}
dest_dir = os.path.dirname(dest_name)
jan = Sum(Case(When(created__month=0, then=1), output_field=IntegerField())),
True
aplusb(1000, -500)
df2
img = cv2.cvtColor(np.uint8(source), cv2.cv.CV_BGR2RGB)
p2.shape
self.layoutHorizontal = QtGui.QHBoxLayout(self)
br = webdriver.PhantomJS()
X[1, 17] = 1
ridx = np.random.random(size=n)
print(item)
++rit
self.factory.unregister(self)
list1a = list[:5]
row.append(ix)
num = len(points)
bit = len(binary)
parser = PDFParser(fp)
scalars = numpy.zeros((colors.shape[0],))
e.args
xData = xTrue + np.random.normal(0, 100, N)
i
print(data)
self.x = initX
array_2D = np.zeros((20, 10))
look_up[n] = n * fact(n - 1)
probs_y = probs[:, (T.arange(targets.shape[1])[:, (np.newaxis)]), (targets.T)]
stack.reverse()
cb.formatter.set_powerlimits((0, 0))
ax = fig.add_subplot(111)
in_data = flattened[flattened.value.isin(data)]
variables = variables[:-1]
Bd = np.ascontiguousarray(B).view(dtype)
self.append(Point(*point_data))
sums.append(lastsum)
aa = []
install(line)
np.arctan2(y, x)
f, axarr = plt.subplots(2, 2, figsize=(10, 10))
Rsq = R ** 2
Fedora
print(error)
fields = MyModel._meta.fields
bi = np.argsort(b)
self.assertEqual(manager.getBlahs(), 0)
lines = s.splitlines(True)
user = AnonymousUser()
in_db.close()
print(_)
self.eyw_transactionref = str(uuid.uuid4())
firstStack.add(ast)
proposed_outsiders = current_outsiders.copy()
btree_container.setdefault(Gnodes, IOBTree())[i] = [Hnodes, score, -1]
find_errors(txt_lines)
0.10000000000000009
prevals = np.ones(cumsum[-1], dtype=int).cumsum()
raw_response = requests.get(url, auth=r)
hashed_pwd = base64.b64encode(kdf.derive(user_pwd))
painter.end()
params = {}
f.__name__ = name
d.sales[d.sales == 24] = 100
shutil.copy2(f, newf)
headrev = client.info(svn_url).revision.number
alert(variable)
monday = lastweek[0]
waitKey(0)
exit()
nbors.append(i + A)
line = json.dumps(item)
print(b)
sine_wave2 = np.sin(2 * np.pi * 880 * t) + np.sin(2 * np.pi * 1500 * t)
result
print(list2)
stripped = string[5:].strip()
pptp = 1 << 15
new_cmap
x = coordinates[:, (0)]
pts.glyph.glyph_source.glyph_source.center = [0, 0, 0]
Os = set(range(1000))
readRequest += chr(0)
readline.set_completer(rlcompleter.Completer(vars).complete)
it = iter(lst1)
vor = Voronoi(points)
status = models.CharField(max_length=200)
foo.bars.add(bar)
sum = 0
d[i[0]] = i[1]
l_two = [4, 6, 9, 11, 4]
rflat = scipy.array(r_coord.flat)
out[i, j] = np.linalg.norm(a[i] - a[j])
logger = logging.getLogger()
1
print(matcov)
self.__keys[:]
name = StringField()
len, str = test.foo()
output_img[np.where(mask == 0)] = 0
NIL
readFile = os.fdopen(readEnd)
self.old = sys.gettrace()
d = MultiProcessing.list([df])
compare_dicts(dict_1, dict_2)
string += name
answer += str(number)
print(r)
root = HKEY_CURRENT_USER
make_session()
print(repr((a, type(a))))
1 / (k * (k - 1)) > 1 / 4
path.append(c)
(r1, g1, b1), (r2, g2, b2) = colors[i1], colors[i2]
n = 2
newRow.append(y)
b_item.doSomething()
select = select([table1, table2]).where(all_filters)
operand2 = evalExpr(it)
R = [200, 400, 500]
a.fn = a.op1
math.trunc(-1.5)
list_1_sorted
output
do_something()
hack = QMargins(0, 0, 0, 1)
print(cellObj.value)
print(data_df)
item = list(item)
10 ** 9
dLock = Lock()
data_restored = dict(map(tuple, kv) for kv in json.loads(on_disk))
req = urllib.request.Request(uri, encodedFields, headers)
loc_dt.strftime(fmt)
posixpath.relpath(target, start=base_dir)
new_a[:, (j)] = np.dot(a[:, firstx:lastx + 1], scale_line) / scale_line.sum()
first_index = min(trees.values())
list(user.groups.keys())
m = MetaData(bind=e)
l = list()
a = set()
counts[:n % ngroup] += 1
main()
print(a)
parser = argparse.ArgumentParser()
result = pd.tools.tile._bins_to_cuts(ser, bins, include_lowest=True)
print(a + b)
warning()
padded_text += r.decrypt(ciphertext[start:start + BLOCK_SIZE])
images = []
pool = Pool(cpus)
print(sorted(file_list, key=getsize))
print(line)
im1 = PIL.open(image)
division = len(lst) / n
f0 = partial(callback, i)
self.results = list(self.__interleave())
generations = [1, 1]
method.arity = _arity
offset = np.random.randint(1, 10)
n = 10000
insert = db.execute(sql, msg=weird_string)
print(new_strs)
br = mechanize.Browser()
layout = layout([[button]])
print(elem)
g_arr = np.array(g)
print(df)
imp.release_lock()
stdscr.addstr(y, x, prompt)
j = 6 * i
l2 = []
gen = chain(elements, gen)
as_float = float(symbol)
DEBUG = True
x += 10
csv_output.writerow(next(csv_input))
tasks = Task.objects.all()
output = StringIO.StringIO()
module = importlib.util.module_from_spec(spec)
sys.path = [path for path in sys.path if path not in remove]
answer = True
fig.set_figheight(6)
n = 5
True
macAddresses = serializers.RelatedField(many=True)
time.sleep(probe_interval)
serialized = [get_user_serialized(item) for item in x]
now = datetime.datetime.now()
print(Covariance)
mlist = []
dec_lon = random.random() / 100
n -= 1
components.append([a, b])
n -= 1
foreign_dt = pytz.timezone(foreign_timezone).localize(foreign_naive)
_testme
complicated
links = []
d[100]
mean
mydict = {}
output_dict = {}
inputs, output = line.split()
js[key] = loads(value)
print(data)
unique = [kk for kk, vv in list(indices.items()) if len(vv) == 1]
n = 77.0 / 27.0
python = sys.executable
email = models.BooleanField(default=False)
module
b, g, r = cv2.split(re_img1)
x, y = np.meshgrid(X, Y)
max_val = a[i]
csvDict = csv.DictReader(lower_first(datafile))
real(total)
print(a)
p = figure(plot_width=400, plot_height=400)
self.httpListeningPort = self.reactor.listenTCP(2080, factory)
self.instance == other
cls.driver = Firefox(firefox_binary=cls.binary, firefox_profile=cls.profile)
ts.head()
pcolor(a[(ii), :])
body.insert(i, print_statement)
print(current_set, current_element)
df
self.content.append(string)
bldr = URLBuilder(someURL)
[a - z]
s
e.extra_link_args = lopt[c]
a = df.values
f = getattr(builtins, funcname)
app = Flask(__name__)
t = 1
queryset = api_models.Sample.objects.all()
self.coords[self.i, 0]
print_anagrams(word_source)
self._bar = []
dll.get_buf.argtypes = []
z = zeros(data.GetNumberOfPoints())
self.key = key
seq + t([val])
framenp.dtype = np.float
istart = []
index = 0
current_key = key
x = (x[1:] + x[:-1]) / 2
figure = plt.figure(1)
self.links = {}
1
closeDb(dbConnection)
idx = np.random.choice(perm.shape[0], nsamp, replace=False)
print(back_to_string)
xbins = [0, len(x)]
imgarray = asarray(image)
y.extend(i[1])
self.whatever = whatever
N = 100
first_date = datetime.date(2005, 1, 1)
y = np.lib.stride_tricks.as_strided(x, (len(x) - window + 1, window), (8, 8))
test_sequence = np.array(list(range(100)) * 2).reshape(100, 2)
(end - start) / reps
contents = f.read()
magicList = list(magicInput)
title, sequence = match.groups()
hash(str(self))
d, Z, tform
y1 = np.exp(0.1 * x)
a = np.abs(np.gradient(xscreen)[0][0])
round(x)
words = random.randrange(5, 15)
ax = plt.Axes(fig, [0.0, 0.0, 1.0, 1.0])
price = int(price)
pvtdf = pvtdf[[c for c in sorted(pvtdf.columns)]]
sess.run(init_op)
args = args[0]
type(BaseProtocol.transport)
doc_hash[doc.id] = doc
filename = part.get_filename()
owncode = f.readlines()
A *= B
model = Entry
inv = [0] * len(k2i)
link = mapping.get(key)
root = ElementTree.fromstring(CONTENT)
False
stack = list(stack)
self.label.setSizePolicy(self.label.sizePolicy)
foo().grok()
rand_choice(1, 1000, 10, 10, 20)
loaded = json.loads(condition)
weighted_quantiles /= numpy.sum(sample_weight)
newlist = [0.0, 0.04, 0.08, 0.12, 0.16, 0.2]
b = a
C.update(B)
dp = {i: my_eval(j) for i, j in list(d.items())}
orig = df.dtypes.to_dict()
fig = pylab.gcf()
setTimeout(sendEmail, 10 * 1000)
workbook.worksheets_objs.sort(key=lambda x: x.name)
l1 = []
out_file.write(base64.b64encode(data))
entryy = int(e2.get())
occurence_[unique_.index(sub.tolist())] += 1
item = self.data[key].pop(position)
print(ret)
b = a[n1, n2]
True
Z1 = matrix_multiply(X, Y)
sum_of ** (1 / 2)
robots.txt
a = [1000, 2000, [2], 4000]
to_child.close()
increment()
j += 1
[expr for i in iterable]
self.delete(original_name)
FinalList = []
location = db.session.query(Location).get(location_id)
t = time.time()
natsort_key1 = natsort_keygen(key=lambda y: y.lower())
end = time.time()
ds1 = set([tuple(line) for line in df1.values.tolist()])
e = int(e)
False
i /= 2
mX = data[:, 1:]
map(lambda x: prefix + x, flatten(tree))
file_name = tmp_file.name
dat0 = CS.allsegs[0][0]
before = myList[pos - 1]
itsdangerous == 0.24
days_from_jan1 = dt - datetime(dt.year, 1, 1)
py_myfunc(PyObject * self, PyObject * args)
ray_distance = distance / dot_product
result
pos = QPointF(event.pos() - self.lastTextPos)
print(result)
mat.set_data(data)
assert c() < 0 + 0j < d()
print(numToWords(0))
result = []
Stuff(key)
x = main()
root, c1, c2 = Node(), Node(), Node()
self.read_c.notify()
key_result[id_key] = key
y = [x[b:e] for b, e in zip(start, stop)]
unique[ref] = add(unique[ref], float(value))
x = np.arange(1, 11)
self._decr = not self._decr
actionChains = ActionChains(driver)
ml = []
im = im.crop(0, 0, width, int(width_count * height / height_count))
gauss = np.random.normal(size=d)
label255 = label * 255
op = ineq.rel_op
evens, odds = partition(lst, lambda x: x % 2 == 0)
arr_f[28]
nextlevel = list()
cache = {}
bin_centers = 0.5 * (bins[:-1] + bins[1:])
dtype = PyArray_DescrFromType(NPY_DOUBLE)
1, 100, 2000
num_terms = sum(1 for x in Formatter().parse(fmt))
abstract = True
coeff = int(e[0])
self.ready = asyncio.Condition()
number_of_lists = st.integers(min_value=1, max_value=50)
total = 0
db = my_test_db
cr.set_source_rgb(1.0, 1.0, 1.0)
startDate = date(2012, 12, 21)
print(foo.b)
print(args)
gateway.save()
proto = legacyProtocol()
result2 = np.bincount(c)
res = [[0]] + [[] for i in range(N)]
app = QApplication(sys.argv)
d = {}
shape = grid.shape[0]
d = numpy.array(a)
total
t.month
x = np.arange(0, 5, 0.1)
magnitude = np.hypot(edge_horizont, edge_vertical)
data = list(range(10))
capture = re.match(regex, str1)
tmpdir = tempfile.mkdtemp(prefix=prefix)
x_crossings = (cross - y1) * (x2 - x1) / (y2 - y1) + x1
self.engine = QQmlApplicationEngine(self)
python - V
raise ValueError
n = 0
fig = Figure(data=data, layout=layout)
GrowlApplicationBridge.setGrowlDelegate_(self)
cls.web.get_screenshot_as_file(screenshot_file)
recursive_parse(urlpatterns, paths)
field_names = [name for text, name, spec, conv in string.Formatter().parse(s)]
iter(self.data)
0
SWIG_fail
print(req.execute().response)
pr = profile.Profile()
self.x = x
inner_lst, depth = get_deepest_list(lst)
mobile = CharField()
x = np.linspace(0, 2 * np.pi)
plt.colorbar(mat)
cell = ctypes.py_object(thing.__init__.__func__.__closure__[0])
df_data = np.random.randint(0, 9, len(idx0))
2 + 2
root = Tkinter.Tk()
f.b
r = gmm.fit(a[:, (np.newaxis)])
m = Melon()
raise exc
y = np.sin(x)
self._dict = dict(somedict)
client.recv(1024)
dfx = df_all_but_parms.copy()
stuff = parser.add_mutually_exclusive_group(required=True)
results = np.zeros((l, l))
config = MyConfigParser()
l
b.sort()
list2 = []
col_dict[i] = [element[0] for element in sorted_s]
pt.SetPoint_2D(0, lon, lat)
required_arguments = 1
join_overlapping_path(p1, p2)
upload_proc.start()
show()
_mostNestedSubTree(tree[key], nodes)
new_failures = [t for t in test1_tuples if t not in test2_tuples]
swissseq = SwissProt.read(handle)
points = sorted(zip(order, distance, points))
self.vals = list(obj)
region = eu - west - 1
value = ws[valueLocation].value
inst = klass()
value = getattr(obj, get_the_value)()
y = x.stack().reset_index()
b = np.arange(n_b_rows * n_b_cols).reshape(n_b_rows, n_b_cols) * 1.0
result = eval(clause, dict(Decimal=decimal.Decimal))
i, f
x = r * np.sin(phi) * np.cos(theta)
_uimg[i] = i
l1 = [facs[-1]]
obj.__class__ = make_parameterized(param_value)
swap[[-2, -1]] = swap[[-1, -2]]
ws2 = new_wb.create_sheet(sheet)
np.power(np.sum(np.power(centers - point, 2), axis=1), 0.5) - rad
qs = qs.exclude(pk=self.pk)
intersected = set()
Y = Y.flatten()
draw_half_circle_no_round(image)
self.Add(self.buttonPanel1, 0, wxALL | wxALIGN_LEFT, 5)
randIndex.sort()
left - right
xextent = 0, np.amax(bins)
print(yesterday)
os.remove(path)
tag = soup.a
y_big = Ebfit(x_big, params[0], params[1])
v = Tk()
d = {(1): 2}
context = vars(sys.modules[context])
g = __gen(iter(list(range(10))))
c = conn.cursor()
a += [1]
ismethod = False
not any(mult % p for mult in ex[0:-1])
[[]]
print(args)
now = datetime.now()
ret = _install.run(self)
2011 - 2 - 6, NaN, NaN
dicts
[1, -1, 1, -1, 1]
r = scikits.timeseries.lib.reportlib.Report(*timeseries_list)
args = s.split()
bResult = list(pdf.values())
b.b
s = data.max()
a
colorof[hx]
test_dict[tup] = +1
result = class_feature_importance(X, Y, feature_importances)
t = np.linspace(-2, 2, 100)
xf = np.linspace(0, 1, 50)
evaluate(result)
self.im.putpalettealpha(trans, 0)
merge(r1, r2, lambda a, b: a and b)
surf.downloadKeypoints(keypoints1GPU, keypoints1)
rdelta = relativedelta(date_one, date_two)
True
setattr(this_module, char, Variable(char))
delta = datetime.timedelta(0, 0, 0, target_date_time_ms)
y = np.random.randn(100000) + 5
self.children = []
result
self.get_the_value = get_the_value
response = view_func(request, *view_args, **view_kwargs)
type.__new__(cls, classname, bases, classdict)
K = numpy.zeros(shape=(n, n))
dis(foo)
pool.map(preprocess, real_preds)
demo.py
screen = Wnck.Screen.get_default()
res = [(not x & 1) for x in t_f_list]
x1 = mu + sigma * np.random.randn(990, 1)
w = sys.stdout.write
x[:] = np.where(mask, np.nan, np.log(r) * np.cos(t))
degree(eq1, a)
M = np.arange(10000).reshape(100, 100)
manipulated
overcount = np.maximum.accumulate(without_reset * reset_at)
G = make_graph()
config.add_section(section)
grid = temp.reshape((nrows, ncols))
r = []
mimimize[0].accDoDefaultAction()
foo = []
plot = Figure(plot_width=400, plot_height=400)
print(m.start(0))
c_valid = formC.is_valid()
d2 = DictView(d, valid_keys)
indicator.set_menu(build_menu())
sum(x)
params, cov = curve_fit(bimodal, x, y, expected)
fig = plt.figure(figsize=(5, 5))
os.rmdir(cur_path)
height, width = gray.shape
count += 1
x, y = 10 * np.random.random((2, 20))
keys_df
work_list = work_list[1:]
state1 ^= state0
print(self._a)
process_child(child)
True
proxy = WSDL.Proxy(wsdl, namespace=namespace)
nonz
np.random.seed(784789)
r.text
b_cls = type(b)
self._logFileName = logFileName
possible_params = []
splited = map(list, delisted)
glob(pathname)
d = {}
b = Foo(a)
train_index = np.logical_not(test_index)
fig = figure()
sims = sorted(enumerate(sims), key=lambda item: -item[1])
self.walk(child)
last_chunk_length, last_decimal = decimals.pop(-1), decimals.pop(-1)
print(processed_header)
gcd = GCD(gcd, d)
result.bar = b
H /= count
t = test()
User.objects.get(pk=user_id)
vc = vc.Elem()
files_found += 1
most_popular({el: (0) for el in list(range(1000))})
info_fp = LoggerWriter(logger, logging.INFO)
k = np.array([17.0, 225000, 226000])
A1s[([0, 1, 2]), ([0, 1, 0]), :, ([0, 1, 1]), :] = 99
data = [time.time() - start, np.random.rand()]
somelist[:] = filterfalse(determine, somelist)
new_str += x.upper()
res
pool = mp.Pool(cpu_count)
text[2:].splitlines()
os.setgid(pwnam.pw_gid)
im_data = im_data.reshape(im_size[0], im_size[1])
int[index[1, overlaps]]
bytesRead = c_ulong(0)
mytrace
tasks = []
setup_logging(config_uri)
m.SelectObject(b)
df = pd.read_clipboard().iloc[1:]
value = value + [[]]
index_list = []
Z = np.sinc(np.sqrt(X * X + Y * Y))
shout.pop()
artist.add_reviews(review_ids)
True
a = np.array([1, 2])
msg = p.parsestr(raw_email)
this.nextLoc.add(result)
self.x, self.y, self.z = x, y, z
V_inv = np.linalg.inv(V)
self._display = Display()
p0 = sum(p[i]) / n // average
self.ready_to_get.get(block=True)
data_with_zeros
filelist = os.listdir(targetdir)
self.request = request
a = BitArray(22)
unqrows, counts = unique_rows_counts(a)
children = current_process.children(recursive=True)
deleteprevious[lastkey]
self.value = value
all = [a, b, c]
palette = sns.color_palette()
h = wx.SystemSettings.GetMetric(wx.SYS_SCREEN_Y)
j = 0
recursive_print(planets)
e.append(lineno, repr(line))
hashesToPoints.setdefault(hash(p), set()).add(p)
key = entry[1:].strip()
++rit
buffer = os.read(io, BUFFER_SIZE)
Combined = []
low_word = int(num1, 16)
BOOST_LIBS = -lboost_python
print(B)
tmp = []
out = set()
print(sum(counter.values()))
arbitrary_member = next(iter(num_set))
self.remove_avail_range(ip_network)
list2 = [1, 2]
sigma, y, x, rho, beta, z
np.PyArray_STRIDES(a)[i] = np.PyArray_STRIDES(new)[i]
x = -1
f.x += 1
cr = csv.reader(fr)
print(foo.name)
count = []
d = deque()
match_values = []
a = list(range(10))
[Request(url=start_url) for start_url in start_urls]
t1, t2 = itertools.tee(seq)
d[name].append(float(val))
bg.add_edge(edge)
start.UseShellExecute = false
ddd
elem = next(it)
Choice.objects.all()
F[i] + f[i] * minutes_in_ith_slot if i < len(f) else F[i]
last_item = self.items.pop()
lock.release()
token.sort()
Special.convert_to_class(b)
cls.singleton_object
assert 42 == example.test_specific_uint8(numpy.uint8(42))
myNewMassage = copy.copy(BeautifulSoup.MARKUP_MASSAGE)
copyFile(path, dest, relative + 1)
eggs += application1
stats_z = [((s - mean) / std) for s in stats]
result
m(abacus, 2)
thefile = os.path.join(dirname, filename)
frags = []
row, col = np.diag_indices_from(a)
print(row)
main()
pprint(lists.asList())
print(suba)
X = np.array(list_of_objects)
print(f(t))
self.remote_ip = ip
print(label_dict[event.artist][event.ind[0]])
x = [1, 2, 4]
Colors & Fonts
next_n_results = [table[k] for k in next_n]
ref = (my_split(r) for r in reffin)
script
CollectAttributes().visit(guts)
reconstructor(*((factory(cls),) + args))
a, n = array(l), len(l)
obj.actor.orientation = [0, 0, 0]
d = {(1): 2}
[20, 21],
a = Queue()
request.path = reverse(view_name, args=args)
line = line.strip()
self.paid_users += 1
subject_base64 = base64.encodestring(subject).strip()
self.b = B()
5
points_left, points_right
index = df.index,
i = mat.tocoo().row
f = sympy.exp(x - y)
index, data = row
cd / tmp / logwtf
True
f = figure()
score = sum(i * w(i) for i in x if i in y) / sum(i * w(i) for i in x)
s = pd.Series(val, idx)
header = list(tempsubtask.si(i) for i in range(n))
pygame.init()
[(w * 2) for w in range(10) if w < 4]
Session = sessionmaker(engine)
filename = sys.argv[1]
{0, x, y}
my_file.sections
console.log(util.inspect(dirTree(process.argv[2]), false, null))
temp = numpy.multiply.outer(A, B)
decomp = sm.tsa.seasonal_decompose(df)
self.time = pkt.time
print(arr)
result = [(True if mpat.search(x) else False) for x in spat.split(text)[1:]]
conset = set()
processed_numbers = [(1 if num < 1 else num) for num in float_numbers]
dotProductSet.clear()
temp[rule.selector.as_css()].append((dec.name, dec.value.as_css()))
pkts[_packet_num].load
df
print(text2_re)
popt, pcov = curve_fit(f, x, y, p0)
ephem.degrees(sat.sublong - target_long).znorm
image = imread(list_of_files[i])
new_lists = [list(l) for l in input_lists]
d, lst
R.append(vysis)
x = []
func(string)
nans = s.apply(np.isnan)
image = models.ImageField(upload_to=img_get_file_path)
value * 12
edgePoint.y += yFactor * (bb / 2.0)
myTuple
data = open(myfile).readlines()
at_most(2, range(5))
cmd, arg, line = self.parseline(line)
10
flag = True
sloc = perm1.index(perm0[loc])
sd = socket.socket(socket.AF_UNIX)
anIntOBJECT.__sizeof__()
cl = json.load(f)
view[0, 0]
pdb.pm()
print(s)
logger.removeHandler(handler)
sys.argv = argv
theta = random.uniform(0, 2 * PI)
subplot(221)
sleep(i)
destination_path = sysconfig.get_python_lib()
X = scipy.fft(x[:N])
new_spline_repr = t2, d, k - 1
ctx.set_options(OP_NO_SSLv2)
entropy = nwords * nbits
app.run()
print(df.data.mask(df.data.notnull().cumsum() != 0, df.data.fillna(0)))
myPairs.sort()
pdt.normalize(utcnow2)
files = []
p.contents
newGroup = LinkGrouping()
ls - ald / usr / bin / pdb
PrimaryKeyConstraint(*columns, **kw)
print(np.all(clf.feature_count_ == X))
out[0]
self.recipient_list = recipient_list
ngram_rev = defaultdict(lambda : defaultdict(int))
self.__cache[len(self.__cache)] = obj
self.update(str(v))
raise Http404
shutil.copyfileobj(main_file, new_file)
form = CreatePhotoForm(request.POST, i)
self.icon.setScalesWhenResized_(True)
buf = io.StringIO(msg)
text_in_clipboard = root.clipboard_get()
print(user.user_id, post.post_id)
num = float(Fraction(num_str))
0
painter = QPainter(image)
local_device_protos = device_lib.list_local_devices()
mode |= stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH
N = 100
d_max
fileh.setFormatter(formatter)
[1, 1]
l
print(stdout_value)
time_val.tm_hour, time_val.tm_min, time_val.tm_sec = 0, 0, 0
loc = Location.objects.get(pk=1)
header
days, cnts = durs(df)
x = x
self.progress += 10
self.data = list(items)
a = c.sub(c.mask(p).ffill(), fill_value=0).sub(1).abs()
pumpedThread = threading.Thread(target=pumpQt, args=())
X_masked = X_train[(row_mask), :]
count = count + 1
found
fronts[remaining[~dominated]] = frontier_index
print(chessgame)
thread_2()
CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5)
math.floor(f)
sys.modules[modname] = self
urls = review_pattern.findall(msg)[0]
ids.extend(page)
urllib.request._urlopener = MyURLopener
start_l = l[:]
ys = np.sin(xs)
csvout = csv.writer(csvout)
k = min(k, n - k)
c[2]
self.fh = filename
obj
ID = ID + 7
form.username.data = my_user.username
month_start = next(month_dates)
newsession = True
c = Canvas(root, height=600, width=600)
parsed = sre_parse.parse(regex)
raise datastore_errors.BadValueError(prop._name)
x[0, 0, 0]
inp.setperiodsize(160)
print(term)
AaBbCcDdEeFfGgHhIiJjKkLl
name.form().submit()
self.children = children
nz = np.nonzero(a[i][:])[0]
col_ind = [9]
base = datetime.datetime(2000, 1, 1)
sleep(1)
target = NP.fromiter(source_iterable, dtype=NP.int8, count=v.size)
prices.lookup(orders.Date, orders.ticker)
cos = numpy.cos
x = np.ones(10)
ans2 = new_vec(seed=0)
ATESTVARIABLE
character * 2
0
s2 = Series(randn(5), index=[1, 2, 4, 5, 6])
tmp = list(chain.from_iterable(longlist))
self.subs.append(s)
n = len(d) // 2
p += 1
list_powers = [(2 ** i) for i in range(n)]
job_start = time.time()
zipped = zip(list1, list2)
self.attrb1, self.attrb2
f, path = mkstemp()
localClosure = foo()
errors = [r for r in results if not success_condition(r)]
tor_process.terminate()
call_line = inspect.stack()[1][4][0].strip()
2
DataFrameDict = {elem: pd.DataFrame for elem in UniqueNames}
q1 = Models.object.filter(field1=f1)
gc = pygsheets.authorize()
False
items = list(object.items())
file = self.get_selection()
A = np.array([1, 1, 2, 4])
qs = MyObject.objects.all()
string = match.string
value8_set = byte & value8 == value8
r.resize(5)
pubkey.assign_rsa(rsa)
maxiddict = {}
_wrapper
mergedVersions[-1].append(versions[i])
item._request._addoutput_on_failure()
cl, exc, tb = sys.exc_info()
iter([])
myResult = []
print(rand_num_tens)
self.count = 0
set1 = set(list1)
print(sum(success_list))
th = np.linspace(0, 2 * np.pi, 64)
N = len(xs)
b[1:, 1:] = a
years[self.year].append(self)
1.0 / x
translate(coding_dna)
0, 10, 1
move(x, y)
raise StopIteration
x = chain(5, 409)
200
sameLevel = defaultdict(list)
cd / opt / python - dev
response = opener.open(request)
result = []
account = Account.objects.get(user=request.user)
False
PyErr_SetFromWindowsErr(0)
d = defaultdict(list)
formatter = self._get_formatter()
heapq.heappush(openHeap, (tile.H, tile))
U1 = U[(A.row), :]
self.a = A(x, y)
print(z.eval())
self.a += other.a
True
c = CurrencyCodes()
ll = [1, 2]
ser1 = df1.iloc[:, (0)]
d[i] = d.get(i, 0) + 1
alice, 5
self.number = num
print(k, exifdict[k])
print(alist)
C = [x for x in range(10) if x not in B1 + B2]
dialect.type_descriptor(UUID())
old_dir = os.getcwd()
mults = re.findall(multre, f)
x1 = int(math.floor((canvas_width - old_width) / 2))
rect = Rectangle(Point(0.5, 0.1), Point(2.5, 2.1))
num
cartesian = [stack_arrays((a, b), usemask=False) for a in A for b in B]
1
A = octave.balance(A)
attrib.update(extra)
fd.close()
moo = size * bar.T.dot(bar)
norm(V) / sqrt(V.size)
book_author.author = george
total = number_of_partitions(n, S)
min(seq)
idx |= idx.shift(1) | idx.shift(2)
np.multiply(m_dat[slice_], v_data[j], out=data[sizes[j]:sizes[j + 1]])
a[i == j] = 1.0
c.showPage()
result
csvfile.seek(0)
sorted_groceries[item.store] = [item]
f = x + y
A()
CONTAINS
width = shape[1]
count = 0
a = 2
mul = cols[0].join(cols[1:])
print(crack(plain))
0
tmp.sort()
[]
CUSTOM_LOADERS = [MyCustomLoader1, MyCustomLoader2]
fig, ax = plt.subplots(figsize=(8, 6))
IPython.embed()
pygame.draw.circle(screen, color, e.pos, radius)
False
getValue(9, musical_scale)
float(input(prompt))
chunk = struct.unpack_from(fmt, self.recv_buf, self.recv_buf_i)
weights = [layers[j].weights for j in range(self.n_layers)]
zz = pylab.zeros([len(xx), len(yy)])
self.vbox.Add(self.canvas, 1, wx.LEFT | wx.TOP | wx.GROW)
backlog = 5
rsrc = requests.get(urlsrc)
ax = plt.Axes(fig, [0.0, 0.0, 1.0, 1.0])
start_row = 1
units.insert(1, units.pop())
response = as_view_fn(request)
lis = [4, 6, 12]
print(response.status, response.reason)
id(df), id(df2)
ax = axes([0.2, 0.1, 0.4, 0.8])
m.ratio()
data.append(temp)
bias = BiasUnit()
copy_list = org_list
aList
add = lambda x, y: x + y
emails.append(msg)
mytest = Test(sys.argv[1])
__foo_priority__ = 0
name = str(name)
fun = lambda x: chr(ord(x) + 1)
the_facecolor = [(color_numbers[nshp] - 1) / (Nshp - 1), 0, 0]
x = 1
image = Image(absolute_path)
req = urllib.request.Request(url)
defaultdict(tree)
qcookiejar = QNetworkCookieJar()
result = p.poll(10)
show()
us1 = td1.microseconds + 1000000 * (td1.seconds + 86400 * td1.days)
a_len, b_len = len(A), len(B)
phone_no = models.CharField(max_length=15, unique=True)
[np.NaN, np.NaN, 2.0, np.NaN, 2.0],
df_t_shift = df_t_shift.append(df.iloc[-1], ignore_index=True)
some_str
sort_by_comparison(list2)
cdf = scipy.integrate.cumtrapz(y, x, initial=0)
max_spaces = -1
cursor = db[collection].find(query)
spss.StartDataStep()
df[2] = 2
i = i + 1
smallerdataset.write(line)
10011100101000100010001100100000100111001111011011000100101101101010101101011111
t_values.sort()
cvWriteFrame(w, frame)
new_row = [str(new_date)] + row[1:]
ababababCDabababab
print(H6.head())
mask[:, (im.shape[1] - 1)] = False
yourThread = threading.Timer(POOL_TIME, doStuff, ())
a.dtype.itemsize
val += cval
index.yaml
nums = (max(2 ** x + d, 0) for x in range(200) for d in range(-50, 50))
proc.join(timeout=5)
C.set(A)
x + y, z
s_len = len(seq)
imgStr += base64.b64encode(mybuffer)
print(result)
ID = ID + 6
result[widget_type] = result.get(widget_type, []) + [app]
array([[1, 2]])
fiahl = drive_api.files().create(body=body, media_body=media).execute()
self.from_neuron = from_neuron
page = []
2
u = UUT()
_, _, x = f()
context.update(extra_context)
context.verify_mode = ssl.CERT_REQUIRED
char = font.createChar(65)
print(argspec)
True
B2 = vstack((B, C))
x2.append(t)
test_it()
print(sum(t.repeat(repeat=reps, number=1)) / reps)
8 ** 8000 / 10 ** 8000
renderer = figure.canvas.get_renderer()
Linux | posix | Linux
res.append(line)
candidates = set(valid_strings.values())
entry_point.add_command(group1.command_group)
plt.plot(points, m * points + b)
1.0
check_name(v)
As = [1, 2, 5, 6]
value = getattr(rule, name)
m = len(a)
not_changed = [k for k in initials if initials[k] == totals[k]]
dct = magic_get_dict(file)
print(b)
ssreg = np.sum((p(xd) - ybar) ** 2)
print(df)
util.run_wsgi_app(application)
dictionary = dictionary.copy()
h = _sopen(filename, 0, _SH_DENYRW, 0)
in_order_print(root.l_child)
self._pub_wrapper(verb, obj_type, args[0])
os.execl(python, python, *sys.argv)
port = 9100
arr = {}
print(bar)
i = 0
tuples
assert answer([1, 1, 2, 2, 2]) == 10
lifecycle = Lifecycle()
inner
powers
TAA
vpath
df = pd.DataFrame(yourlist)
table_schema = bq.Schema.from_dataframe(simple_dataframe)
line = self.file.readline()
crawlerProcess.queue.append_spider(spider)
bigram_measures = nltk.collocations.BigramAssocMeasures()
answers = dns.resolver.query(args.host)
total += 1
items.append(item)
user = UserModel.objects.get(**kwargs)
unigramCount = sum(x.count(word) for x in copyText)
authorization = ThingAuthorization()
size = max(width, height)
f(a)
otherstuff
id = Column(BigInteger, id_seq, primary=True)
L
self._max_y = max(self._max_y, y)
folder = OSFS(FLAGS.test_dir)
mem = inferior.read_memory(addr, bytes)
motif_counts_by_down, nonmotif_counts_by_down
pprint(result.data)
Py_DECREF(co)
plt.plot(t, triangle)
print(berlin)
pixdata[x, y] = 0, 0, 0, 255
print(ips)
repeat_dims = np.divide(new_shape, arr.shape) + 1
x = all_leaf_treepositions.index(target_leafpos)
self.__class__ = make_parameterized(state[1])
print(i, j)
print(x)
myconf = MyConf()
A = MyClass()
raise AttributeError
a, b = zip(*bigsquare)
print(day_range)
date
language_check.correct(text, matches)
print(x)
vals = df.value.values
classes = [A, B, C]
print(j.serialize())
print(err.value)
d + delta
responseJSONpart = requestObj.read()
self.groups = self.possible_combinations(self.nodes)
self._calculated_value
shp = a.shape
handle.connect(hostname, username=user, password=pw)
x = 0
ps.append(fit(new_d))
called = []
x, y = point_to_xy(150, 150)
pi = np.pi
array_2D = np.array(pool.map(fill_array, list_start_vals))
st.pop()
module = import_module(module)
type(False)
pinocchio
new_id_num = int(new_id[0])
a2 = []
density = 10 / (dr * da)
exchange.close()
last = row
df
matrix = np.matrix(s)
f = data.copy()
Z = zs.reshape(X.shape)
num_pool_worker = 1
line = p.stdout.readline()
workbook2 = xlwt.Workbook()
s_jpg_files = s_jpg_list.map(resize_image)
print([x.captures(1) for x in rx.finditer(s)])
new_x = np.random.randint(10, size=5)
tdm.add_doc(doc1)
fname, ext = os.path.splitext(img)
summary_writer.add_summary(filter_summary, i)
mask_0 = cv2.inRange(hsv, lower_red_0, upper_red_0)
value / 12
ret
new_words
c = count()
basename = os.path.basename(url)
N = A.shape[0]
cols = np.minimum(np.abs(cols), cols % N)
standard_c_lib.__errno_location.restype = ctypes.POINTER(ctypes.c_int)
xy = 100 * np.random.random((2, 10))
self.die_after = time.time() + self.seconds
outarr
pairs
self.__name = self.cur_node.func.id
burger_king.open_restaurant()
os.mkfifo(fifo_path)
d = to_sort[0][1]
k = 0
display = pygame.display.set_mode((width, height))
a_list[i] = np.NaN
next(iGen)
x = np.ones((1000.0, 1000.0))
fd = f.fileno()
b = i >> 1 & 1
name = fields.Str()
dct = self.__dict__
b = a
lyr_in = ds_in.GetLayer(0)
res = res(*args, **kwargs)
1
d[nan1] = 1
partial(myfunc, arg2=1).func == partial(myfunc, arg2=1).func
batch.submit()
sftp = client.open_sftp()
text = args.file.read()
print(msg)
adj = np.zeros((n_entries, 4), dtype=int)
oct_len = len(oct)
q.put(i)
print(frame.f_back.f_locals)
model = Order
max_base = (base * num.arange(base_size)).sum()
time.sleep(0.1)
size = xy.shape[0] - 2 * s
q = v // 20
ssl_version = ssl.PROTOCOL_TLSv1
determinant = 0
print(superlists)
_cache = {}
isinstance(someFloat, numbers.Real)
x
ax.set_xlim(xlim)
gui = MyApp()
i = 5
sample = [(v / sum(sample)) for v in sample]
score = model.evaluate(X, y)
copy_list = org_list
dir(obj.foo)
labels, num_labels = scipy.ndimage.label(mask)
obj2 = yaml.load(yamlData)
np.bincount(a, weights=b)
X = np.arange(10)
query = urlparse(self.path).query
request.LANGUAGE_CODE = request.LANG
print(row)
main()
self.rank = rank
xi = linspace(min(x), max(x), resX)
begin() + size()
t = Template(template)
whatever(node.some_other_attribute)
b[0] = 1
request.current_app = current_app
chunk = req.read(CHUNK)
_a1 = True
sin(x)
conn, addr = s.accept()
x, y = [], []
y = np.sin(np.pi * x * n) / (np.pi * x * n)
x
module = os.path.splitext(os.path.basename(file))[0]
[x]
list(result)
date_aware_la = localtz.localize(naive_date)
next(with_open())
TEST_SUITE = suite()
doc, tag, text = Doc().tagtext()
b[i] = b1[i] ^ b2[i]
libc.memcpy(binary_data, mem_pointer, size)
predictions = classifier.predict(X_test)
b.GetMyVector()
print(time.time() - start)
parent1[idx1], parent2[idx2] = parent2[idx2], parent1[idx1]
retFiles.append((root, i))
rf.fit(Predx, Predy)
MyClass = getattr(importlib.import_module(module_name), class_name)
yaml.SafeLoader.yaml_constructors
int_i = int(i)
-models
line.append(c)
my_mesh.AddPolygon(n)
keystone.users.list()
all_vars = locals.copy()
deleteo[-1]
a.data[a < 2] = 999
c.join()
args = foo.__code__.co_varnames[:arg_count]
fatcows
print(foo.func(False))
j = mat.indices
1,
resp = s.recv(1024)
self.id = nid
lines = lines[1:]
profile_avatar = forms.ImageField()
path = []
x = 1, 2
print(value)
h = httplib2.Http()
result = result + item
total = tuple(a + b for a, b in zip(row1, row2))
a + b
F = min([i for i in largecoprime_divisors if i > R])
print(q[0].playertype__count)
row[rand_cols] = 1
m -= result[i]
is_new_style_class(Old)
fd, tmpname = tempfile.mkstemp()
v = 1
pData = urllib.parse.urlencode(postData)
b = 40 * a
0
fn = (~bt.bitarray(p) & bt.bitarray(g)).count()
c.lookup_by_first_element(1) == (1, 200, 9)
10
self.assertEqual(manager.getBlahs(), 1)
n = len(pattern)
b = b + 1
mod2.py
arr = []
assert len(sample_probabilities) == len(xs)
bar = Bar(a=1, b=2)
print(dateTest(date))
self.cache = {}
instance = MyModel()
inner
sqlstate = ex.args[0]
5
limit = datetime(2011, 1, 5, 17, 0, 0)
getattr(self.original, key)
key_parts = key.split()
print(prefix, rest)
P = np.array([Psat(molecule) for molecule in molecules])
posix_now = time.time()
func1
items = sorted(list(mapping.items()), key=lambda x: x[0])
date_time = date_from_webkit(timestamp)
print()
label_Image = QtGui.QLabel(frame)
english_words = [word.strip().lower() for word in wordbook]
lst = []
True
myTurtle.up()
dep_field[0].rel.to
sieve[n] = not sieve[n]
idx += 1
start_mask = np.append(True, diffs == 1)
im1 = Image.composite(im1, im0, im1)
TestSuite.to_file(lFile, ts, prettyprint=False)
btn.clicked.connect(self.create_window)
i += 1
f(*args, **kwargs)
spitches = sorted([(p % tones_in_octave) for p in pitches])
bin_density = bin_counts.astype(float) / np.dot(bin_widths, bin_counts)
idx = np.arange(offset_arr.size) * N + offset_arr
ratio = lambda x: x.value_counts(normalize=True)
BOOST_PYTHON_MODULE(foo)
previous_vals.add(minimum)
a.some.__self__
print(delta)
persons = Person.all()
outs.append([])
ax.margins(0.05)
cache[args]
parsed_result[name] = [value]
print(myList)
points = [(16, -16), (90, 90), (40, -40), (40, -95)]
py_compile.compile = doraise_py_compile
bzfile = bz2.BZ2File(filename)
profiler = cProfile.Profile()
sub_answer = []
tb_list = traceback.extract_tb(sys.exc_info()[2])
self._half * 2
statvfs.f_frsize * statvfs.f_blocks
0
y_sum += y
df.info()
self.arg = arg
rgbArray[..., (1)] = g * 256
filtertext = self.data_filter.get(option_value)
c.meta
target = sys.argv[1]
a + 10
p8 = ctypes.cast(id(tb), ctypes.POINTER(ctypes.c_ulong))
buf += chars_read
x1[x1 > q].shape[0]
PygmentsBridge.latex_formatter = CustomLatexFormatter
end = __datetime(end_date)
yearly_sales_qs = SaleRecord.objects.filter(param=value)
l = len(df.columns)
start_time = time.time()
parser.whitespace
result.append(n)
os.setuid(running_uid)
params = [[unquote(p[0]), unquote(p[1])] for p in params]
non_update_fields = set(self.fields) - set(self.opts.update_fields)
tree[i].left = tree[l_child_idx]
new_text[index] = letter
False
x * x * norm
content_type = models.ForeignKey(ContentType)
id(a)
_InitializeParameterized(), (self.PARAM,), self.__dict__
place = Place.objects.get(pk=1)
a
final_set.append([input[i:]])
r = p.apply(go)
print((index, left, right))
fig, ax = plt.subplots(1)
df
short_list, long_list = sorted((list1, list2), key=len)
counts_copy = counts.copy()
fileName = frame.f_code.co_filename
utc_now = datetime.now(utc)
nArray.flags.writeable = True
all_rosters = []
bar.py
bottom = pos[0, 1] * scale_y
logx = np.log(x)
self.icon.setSize_((20, 20))
pname = mp.current_process().name
print(line)
final_df
-((-x >> power2 - 1) + 1 >> 1)
n -= 1
x + y
dis.dis(f.__code__.co_consts[2])
print(trunc(some_float))
t = threading.Timer(INTERVAL, schedule)
deletefoo
CELERY_IGNORE_RESULT = True
gb = grouped_df.groups
self.name = name
random.seed(key)
my_first_egg = Egg.objects.get(pk=1)
fn(self, val)
print(f1(**kwargs))
prefix = []
unpad = lambda s: s[0:-ord(s[-1])]
self.params = kwargs
start_km = group.iloc[0, 4]
aFunction(**someDictWithKeys_a_b_c_d_e_f)
print(__test)
queries.append(db.table.otherfield == y)
card = Card(1, 1)
IFBIsFifoTar = 0
print(d)
proc = x86_env.Processor()
cache[key] = result
out.append(current)
[1, 2]
HttpResponse(username)
df
X_test_std = standard_scalerX.transform(X_test)
output = []
ICON_INFO = 64
xdot = [f(x1, x2, k1, k2) for f in funcs]
dd = [(d1 + timedelta(days=x)) for x in range((d2 - d1).days + 1)]
y = np.ones(10)
goto(0, radius)
iter(self.__values)
im.compressType(CompressionType.ZipCompression)
self.quitting = False
config = dict(baseConfig, overriddenValue=etc)
ld[1]
base64.b64encode(obj)
cond = len(s) == 1 and item in s
combs2 = deepcopy(combs)
print(test.TestName)
Table1 = pd.DataFrame()
indptr = np.arange(0, len(data) + 1, 2)
noisy_y = y + 0.5 * (np.random.random(num) - 0.5)
models.Model.to_element = to_element
area = cv2.contourArea(cnt)
x_new = np.empty(x.shape)
self.var1 = 1
matches = []
c.set_offsets(np.c_[x, y])
pp_pprint(object, **kwrds)
self.aliased *= 10
b = a.tocsr()
assets = Environment(app)
print(output)
copy_foo = foo[:]
m.setvolume(50)
a_dict = {}
right = min(arr.shape[0], x + N)
model = buildModel(X.shape[1], y.shape[1], nLayers, nNeurons)
deletea
im2.size
b = 4
self.task_queue = Queue()
last_item += items[-1]
rot_points = np.dot(rotations, hull_points.T)
x = q.get()
print(least_value)
init_printing()
f2 = Foo()
seen = set()
multi_dict[k] += 1
raise
print(len(count))
stdout, stderr = proc.communicate()
k = (s < r).sum(axis=0)
bbins = np.bincount(b - blo)
b = np.array([1, 0, 1, 0])
sys.exit(0)
is_type(df, np.number)
s, c = 100 * np.random.random(num), np.random.random(num)
print(D)
other.number - self.number
nbsumeq = autojit(pysumeq)
falseList = []
x = np.arange(10)
b = os.urandom(2 ** 20)
lowest_dirs = list()
forms = mechanize.ParseResponse(response, backwards_compat=False)
[(val,)] = t
f1()
od[name] = rpy2.robjects.vectors.StrVector(values)
print(y)
rsi_series = pd.Series(0.0, deltas.index)
r = sympy.Rational(str(i)).limit_denominator(1000)
x = r * math.sin(theta)
res = a + b
t_nought = time.time()
colored_name.allow_tags = True
True
print(DIGITS)
mymodule.point
da.append(response[0][1])
UDPSock.sendto(s.getvalue(), addr)
option.setPricingEngine(engine)
(c.X - a.X) * (b.Y - a.Y)
subparsers = parser.add_subparsers()
left = 1
count_list
a += z[i]
hosts[host] = rhost[0]
matched += 1
results = []
memory2 = Memory(cachedir=mkdtemp(), verbose=0)
count = 0
imagesList = []
hash.find(salt)
self.char_y -= 10
bv.write(myarray.tostring(), 0)
jobs.append((time, child))
kwargs = dict(self.kwargs, body=body, **kwargs)
cls.do_not_call_in_templates = True
sum += lookup_table[n & 255]
ax = axes.flatten()[i]
deleteprocesses[n]
v = {}
soup = BeautifulSoup.BeautifulSoup(data, fromEncoding=encoding)
i = np.identity(df.shape[1])
density = kde(values)
zero[indices] = 42
d = c.sub(c.mask(~p).ffill(), fill_value=0).sub(1).abs()
fast.addTests(TestFastThis)
process(data)
sm.ReadConfig()
[v] + permutation(l[:i] + l[i + 1:], index - acc)
self.check(display_num_errors=True)
n = col2.strides[0]
result
[z] = [0][2]
astr = int(astr)
g()
subjectlines.append(subject)
mean, std = im.mean(), im.std()
print(X_train_init.shape)
loop.close()
request.meta.update(start_request_index=i)
fig = plt.figure()
period = 0
a_ints = [e for e in a if isinstance(e, int)]
dict = args
log_file_name = sys.argv[2]
Gender
l
rgb = np.empty((h, w, dim), dtype=np.uint8)
alphas = string.ascii_lowercase + string.ascii_uppercase
connection.close()
file.seekg(0)
print(a() or b())
a = np.random.randint(0, 20, size=10)
kw = dict(list(ukwargs.items()) + list(self._kwargs.items()))
winsound.Beep(440, 250)
hist, bins, patches = plt.hist(alpha, bins=20)
w, h = s.Size.Get()
col = attr.columns[0]
make_person(1, 2)
x, y = np.array(x), np.array(y)
lst = [(A, B, 2), (A, C, 5), (C, A, 2)]
ret = d * (y[1:] + y[:-1]) / 2.0
nameArray.append(i)
d[k] = r
self.__d = d
x.name
factors = numpy.random.rand(6)
sRGB = sRGBColor(126, 126, 126, is_upscaled=True)
BaseModel = declarative_base()
y0 = np.array(y0, complex)
date_range = date_range.lower()
bytecode.append(ops[type(p.op)])
print(df2)
result = next(sets)
path / page.html
app = MyApp(args)
cols = max(map(len, list_of_list))
y = math.pow(pos1[1] - pos2[1], 2)
tmp.index = list(range(num))
self
thread, result
formatdate()
min_value = min(seq)
x = r * math.cos(alpha) + circle_x
z = norm.isf([sig / 2])
gateway = JavaGateway()
keylist.append(key)
read_fortran_array(a)
demo.dump()
seen.add(s)
actual_count += 1
a, b, args
A = np.maximum(A, eps)
distance = self.line.distance(point)
shape = list(repeat(np.asarray(term_dict_k).max() + 1, 2))
done.appen(task)
reslist.append(entrada)
i = 0
cxml1 = xml_string_io1.getvalue()
network = list(splitNet())
a
plt.ion()
_clinkgrammar.sentence_parse(sent, opts)
cNorm = colors.Normalize(vmin=np.min(DATA[:, (4)]), vmax=np.max(DATA[:, (4)]))
i, j = np.ix_([0, 2], [0])
r[k] = json.dumps(getattr(self, k))
f = f + e
input = iter(input)
lambda_func = lambda x: x == 2
d[2] = 20
b[..., (2), 1:] = a[..., 4:]
user.has_perm(custom_permission)
ax = plt.subplot(5, 2, i + 1)
root
N = len(distance_matrix)
lesk(sent, ambiguous).definition()
caller_locals = inspect.currentframe().f_back.f_locals
dict_[sublist[0]].add(sublist[1])
self.fp
data_frame.to_csv(output)
print(cookie)
milestone_index = milestones_list.index(milestone)
make_table(dictList)
assert count > 0
singles, less, more = [], [], []
print(frame)
xys_top = []
q += 1
l = array([l, l, l])
gen_2, gen_2_teed = tee(gen_2)
print(x)
output_buf.value
exponent = int(log10(y))
stop(my_log, logging.StreamHandler)
feed_url = StringField(required=True)
lambda x: LazyComparer(x)
elist = textwrap.wrap(encoded, width=ewidth)
current_page_row += 1
data.append(row + [to_append])
unittest.main()
a1 = a.A
r = []
s = pygame.Surface((64, 64), flags=pygame.SRCALPHA)
data = json.load(inFile)
A2, B2 = zip(*D)
head = arg[0]
offset = 0
z = y + 1
context.render_context[self] = itertools.cycle(names)
myfunc1_code = f1.__code__.co_consts[2]
columns_to_keep = []
lines.append(line)
s = np.array(speed)
greyscale_map = numpy.array(greyscale_map)
N = [x for x in T if x in S]
SITE = domain1,
FooForm = make_foo_form(request)
len(set(a))
pinocchio
button.on_click(update_data)
save_tf(tmp_filename)
self
print(buff.value)
npa
dest = dict(orig)
collection = mon_db[col].find()
v
r = envoy.run(cmd)
m = eval(input())
r.append(0)
match = re.search(reg, txt)
n < -10
print(item)
MyClassifier.load_models(config)
print(df)
True
print(np.sqrt(np.pi / (2 * X)) * kv(v + 0.5, X))
a = 4
clientsocket.close()
averages = sums / counts
data[header] = [value]
msg = msg.format(fromaddr=fromaddr, toaddr=toaddrs[0])
id(a)
a_length = len(range(a_start, a_stop, a_step))
print(tz._utc_transition_times)
sentences = nltk.sent_tokenize(sample)
subscriptions = filters[word]
add
flow = client.flow_from_clientsecrets(CLIENT_SECRET_FILE, SCOPES)
node = worklist.pop()
dictionary_from_class[key] = thing.__dict__[key]
z[row[1].month] in y
console.log(data.result)
filenames = []
True
indices = list(range(len(iterators) - 1))
a = numpy.random.randn(data_length)
all(r >= rc for r, rc in zip(row, rowCandidate))
print(s.value)
object_list
m = X.shape[1]
df1 = DataFrame([[np.nan, 1], [2, np.nan]])
self.cond = threading.Condition()
length_line = write_line(of, i, d)
TITLE = str(child.after)
doIt(i)
class_ = GNUTranslations
m = polyfit2d(x, y, z)
lowers = word.lower()
print(open(DATA_PATH).read())
reader = request.getReader()
arrays = [[(i, item - minval) for i, item in arr] for arr in arrays]
screen.fill(BLACK)
hello_args = TEST_STRUCT(1, name)
s.send(data)
test_udf = udf(udf_test, schema)
M2[-1, -1]
s.read(1)
answer = []
o = OtherGuysClass()
foreign_to_a = Column(UnicodeText)
x[1]
x_pos = math.floor(x_mouse / 100)
ClassyUsersView.register(app)
subset_of_A = set([6, 9, 12])
f = (x - d) / diff[:, (index)]
endif
j = int(random() * (i + 1))
m(abacus, 4)
timeout = 10
exit_status = ssh_stdout.channel.recv_exit_status()
render()
__new__ = _aligned__new__
[actor] = (actor for actor in self.actors if actor.name == actorName)
remote_refs = remote_repo.fetch(REMOTE_URL, local_repo)
mapping = np.array([[v_x[0], v_y[0], s_x], [v_x[1], v_y[1], s_y]])
s = slice(2, 5)
results = requests.get(url + query)
ThingFactory()
swap(box.size.width, box.size.height)
b = 1
n = 6
df
print(len(unread_msg_nums))
9
file_obj = StringIO()
words = rx.findall(string)
len2
self[k] = v
f1 = pl.figure()
ctx.options |= ssl.OP_NO_SSLv2
print(df == 0)
mode = max((v, k) for k, v in frequencies.items())[1]
d[s]
consoleHandler.setLevel(logging.INFO)
False
ans = []
False
read_bytes = local_p.stdout.read(buf_size)
test_length -= test_size
print(ftext)
s0 = sum(1 for x in samples)
s.insert(axis, 1)
numerator = log(factorial(10000)) + 8000 * log(8)
view1 = array1[1:]
reparsed = minidom.parseString(rough_string)
sieve.set()
sab = a + b
parse_with_stdlib()
self.count
s = x * (x > 0)
test_html = load_html_from_above()
include_files.append((glade_folder, glade_folder))
ab = a * b
context = ssl.create_default_context()
self.SetColumnWidth(colNum, self.__columnWidth[colNum])
df
NAMES = []
sq_inc = (x ** 2 + 1 for x in odds)
job_sir_id = req[0].id
ix, iy = np.meshgrid(np.arange(nx), np.arange(ny))
ans = pool.map(f, range(1000), repeat(20))
item
diagonal_entries = [sum(e[row]) for row in range(e.shape[0])]
i = 2 / lcm
writer = csv.writer(f)
words[w].add(key)
value
model
out.write(f2)
self.add(int(rev_or_revs[0]))
4 | C | SER
start = end
http.client
y = tf.nn.softmax(tf.matmul(x, W) + b)
self.n = float(len(self.a))
fig, ax = plt.subplots(1)
phi = c()
server.start()
new_pair = {}
setattr(SomeTests, test_name, test)
result = []
i = 1
sumOfDigits = sum(map(int, str(num)))
links_text = linkre.findall(response_text)
newGuess = (n / oldGuess + oldGuess) / 2.0
delta_microseconds = tempo * delta_ticks / ticks_per_beat
print(i, count, hi[0], len(lookup))
x
last_line = line
print(a)
ALPHA = string.ascii_letters
self.y = y
self.members = list()
moduli
self.barrier.acquire()
p = pkts[0]
y = logT[:, (i)]
print(my_site.id)
ModuleLevelDocumenter.add_directive_header(self, sig)
heap = []
isSubstring = first in theOther
obj = Foo()
f(1, 20)
h.itemset(i, j, 0, k)
y1, y2 = y2, y1
data = sock.recv(1024)
main_colors = set()
C.c = MyDescriptor(C.c)
yfit1 = model1(xdata, fit1[0], fit1[1], fit1[2])
id_sizes = np.array(ndimage.sum(array, id_regions, list(range(num_ids + 1))))
bitmasks = dict((v, 1 << i) for i, v in enumerate(prime_residues))
func
arr = []
mylab.show()
4 - 0.006156 - 2.028601 - 0.071448
n_m_j_k = numpy.zeros((V, T, S))
h.itemset(i, j, 2, 255 - k)
-x, --stop
print(inspect.getsource(mymodule.sayHello))
qdict.update(MultiValueDict(dictionary))
print(s)
ttls = 1 << 11
midnight = now.replace(hour=0, minute=0, second=0, microsecond=0)
bar(*zip(*zip(count(), list(prefixes.values()))))
tempurl = url.format(i)
link = FbxCharacterLink()
self.fire(close())
plt.plot(ffty)
os.unlink(filename)
fig = plt.figure(1, figsize=(10, 5))
dothing(thing)
deepReduce(min, math.inf, xs)
overflows = [[] for n in input_lists]
choices[i] = np.random.choice(items, p=prob_matrix[:, (i)])
interpolated = gp.predict(rr_cc_as_cols).reshape(M.shape)
[j for i in zip(list(x.index), list(x)) for j in i]
p + os.sep
[np.NaN, np.NaN, 5.0, np.NaN, 5.0],
cipher = AES.new(key, AES.MODE_CBC, iv)
a2[mask]
mask = pd.isnull(df)
self.thread.finished.connect(cleanup)
pval = stats.t.sf(np.abs(tt), n - 1) * 2
args = []
sum(1 for _ in uniseg.graphemecluster.grapheme_clusters(x))
redirect_stderr = true
n
self.read_c.wait()
resultScaled = 255 * (result / result.max())
loc_dt = utc_dt.astimezone(users_tz)
bordered = cv.morphologyEx(bordered, cv.MORPH_CLOSE, kernel)
out[i] = inp[i] * inp[i]
result = float(total) / (X.shape[0] - 1)
mask = np.asarray(A[R, C] == 0).ravel()
print(a.get_value() == b.get_value)
self.subMenu = Menu(self.menuBar)
j = 0
d = {}
cat.info()
l = list(range(14))
elem1, elem2 = pair
wordVector = model[word].reshape((1, size))
a_type = type(a)
skf = StratifiedKFold(y, 10)
cellObj.value = 1
r[j] = a.shape[0] - 1
c[1:] = a + 1
output.append(self.current_indent_str + self.encode(item))
intervals = [(values[i + 1] - values[i]) for i in range(len(values) - 1)]
data = [a, b]
t
stop_i = bisect.bisect_left(lst, stop)
True
myFile.write(img)
myThread = MyThread()
print(win)
childrenScores = [0] * 10
[id]
G = nx.Graph()
theSum = df1.A + df1.B
value = protojson.encode_message(message)
height = int(width / ratio)
arr[a]
self.q = q
environment[k] = v
length
print(files)
print(event.char)
5
client = Client()
self.d = d
perm, [n + 1]
h.setFormatter(f)
zeros_and_ones = numpy.zeros(maxcoord)
n.count(True) == 1
buf[not t].append(x)
params.update(kwargs)
{7, 2, 1}(maximal)
decimals.append(last_chunk_length)
w = 0.5 * np.ones(d)
print(coord_list)
p[:i]
expect_problems_some_day()
a = 0
ClassA.ClassA(theirnumber)
keep = []
Success = 1
windowed_mean = pd.Series(data).rolling(window=win_size, min_periods=1).mean()
root_path
print(x)
Py_MEMCPY(result_s, self_s, self_len - i)
B[i + j + k] = A
subject, body, obj.is_html
fromZone.localize(dte, is_dst=True).astimezone(toZone)
o2 = origin_of_camera * Pose2 // typically[0, 0, 0]
to_date = object.end_date
idx.shape = -1, 2
stopped = Event()
result
matches = p.findall(s)
np.tanh(1477.92 * distance) / distance
nonmotif_counts_by_down[down].update(motifs_not_seen)
colors = [cm.jet(i) for i in np.linspace(0, 1, 10)]
Parent2.on_start()
row = 0
pixels = x_data.flatten().reshape(1000, 12288)
event.accept()
task.apply_async(producer=producer)
~(1 << index)
to_select = [to_select]
result
temp_arr = np.arange(4)
self.__ntrue = 0
print(jez(df))
os.execl(*([sp[0]] + sp))
Currency
cars = numpy.arange(1.0, 5.0)
palin.append(num)
cities_light.signals.country_items_post_import.connect(process_country_import)
x = list(range(10))
setattr(self, name, addon(self))
f = Foo()
raise NotFound()
mytemp = db[MyDocId]
value
newhours = int(hours) * 60
City.id,
include / etc / nginx / fastcgi_params
iter(self._data)
qs_today = queryset.filter(date=today.date(), time__gte=today.time())
special_edges = []
X_ext2 = X[idx2[:, (1)]]
d[tag] = node
string = converter.convert(obj)
print(t)
Child()
credentials = Credentials.new_from_json(f.read())
current_index < tf.shape(times)[0]
a_test = test()
[outStream, errStream] = myProcess.communicate()
self.precompute_tanimoto()
N = 4 * fs
fast_real(56.07)
positions = np.sort(positions)
warnings.warn(e.message)
decoded_data
smth_with(path)
[Service]
foo = bar
f = A()
z = 1
exc.value
itemList = recordTypeClassname.all().fetch(1000)
res.append(prefix + [key])
root = etree.parse(xmlfile)
cols = np.array([100, 99, 1474])
color = JoxColor(0, 0, 1, 0)
tmp = A.reshape(-1)
max_ = data.Before.map(lambda x: len(x)).max()
notepad.clearCallbacks([NOTIFICATION.BUFFERACTIVATED])
der_map = [(p * c, p - 1) for c, p in eq_map[:-1]]
tree.chop(5, 15)
colour = colourselection[count]
session = True
np.power(lon_dif, 2, out=lon_dif)
b.shape = b.size, 1
print(file1.class_instance.stats)
b = 1
i < -i + 1
PangoCairo.context_set_font_options(pctx, fo)
sequence
string_from_file
self.name = name
K = P_a.dot(np.linalg.inv(P_a + P_b))
self.idx += 1
print(colToExcel(1))
1
cl = HierarchicalClustering(data, lambda x, y: abs(x - y))
self.address
diff = merge(r1, r2, lambda a, b: a and not b)
clb = colorbar(sc)
alpha1Scaled = alpha1 / 255
radius = int(radius)
l1 = []
inp = open(textfilename).readlines()
bar = Bar()
seq = int(seq[:-1])
r = np.array(rest)
y = 20
next(it1)
x.strides
string_to_write = cpickle.dumps(my_list)
n = 2 ** 10
messages = queue_in.get_messages(wait_time_seconds=20, num_messages=10)
df2 = df.drop(cols, axis=1)
print(row)
obj = np.asarray(input_array).view(cls)
layout.addWidget(self.textName)
arr = ts.index
interleaved = signal.flatten()
deleteos, atexit, readline, rlcompleter, save_history, historyPath
weird_cumsum
index_array = numpy.arange(your_array.size)
x = 1 / 2
True
map.drawcountries(linewidth=0.25)
register_plugin(plugin)
cache2 = Cache()
C = A
time.sleep(random.uniform(0.1, 1))
df
K = b.shape[1]
cmdclass = cmdclass,
print(null(A))
gen = self._iterencode_dict(obj._asdict(), markers)
code_here()
f.login()
print_time_range(train_likes_df.time)
model.add(Dense(nClasses))
fd_top = resource.getrlimit(resource.RLIMIT_NOFILE)[1] - 1
xx0 = []
main = glib.MainLoop()
list1
r = [s]
points.push_back(p)
processes = 6
result = []
env.forward_agent = True
list_of_results.append(result)
letter = letter.upper()
PUSH(w)
fapp = FileApp(filepath, headers=headers)
l = []
padded[0:m.shape[0], 0:m.shape[1]] = m
screenshot = pyscreenshot.grab()
vals = [1, 2, 594592888]
d[item] = 1
loop.close()
thing.getSecret()
1000
my_filtered_fruit = list(my_filtered_fruit)
args = parser.parse_args()
mult = lambda x, y: x * y
n = 10 - first
model = pipeline.fit(df)
os.remove(fpath)
print(dic)
lcms.cmsDeleteTransform(xform)
group_data = inventory.get_group(group).serialize()
Debug.Assert(count > 0)
k = str(k)
inner_zip.extractall(path=inner_extract_path)
num = 0
False
intersections += [(list(intersect(i1, i2)) + i2.data) for i2 in tree[i1]]
w.add(v)
[uwsgi]
platform = StringField(max_length=20, required=True)
address
request = mock.MagicMock()
final = []
print(value + 2)
self.target.write(text)
edge.index == same_edge_id
new_list_pickler = pickle.loads(pickled)
to_del.reverse()
gpu_out2[idx] - cpu_out2[idx]
self.match = self.failed(l)
text
readable = True
value = method(self._driver)
sess.run(tf.global_variables_initializer())
h.add(x)
minutes_mul = [(a * int(b)) for a, b in zip([60.0, 1.0, 1.0 / 60], pattern)]
r = set()
self.lineEditZ.setText(str(x + y))
dy = radius * math.sin(angle)
piece = f.read(1024)
session = object()
self.curl.setopt(pycurl.WRITEFUNCTION, self.received_buffer.write)
bits = token.contents.split()
pd.set_printoptions(precision=2)
vars(cm)
pst = pypff.file()
_cachedf
i = 0
S = QuoteHandle(SimpleQuote(100.0))
PARALLEL_FETCHES = 5
param = svm_parameter(C=10, nr_weight=2, weight_label=[1, 0], weight=[10, 1])
variance = round(sum(dataSample) / len(dataSample))
recurse()
freqs = freqs[(freqs >= 125) & (freqs <= 1000)]
print(p.dfsh(9))
recApply = lambda f, n: lambda x: x if n == 0 else recApply(f, n - 1)(f(x))
ten_weeks_ago = current_time - datetime.timedelta(weeks=10)
manager = plt.xkcd()
gen = lazy(df, formulas)
npt = len(x)
x = 1
self.closed = True
conn = engine.connect()
0
millisecs = int(jd[6:-2])
self.Start(0, oneShot=True)
new = fp.readline()
max_val = a.max()
n, mod = divmod(n - 1, len(digits))
uld
v = repr(mydict[key])
d1, d2 = {}, {}
value = np.compress(mask, value)
halo_col = 0, 0, 0
atexit.register(save_history)
nonzero = np.nonzero(xc[:, (0)])[0]
upperlist.append(u)
assert expected.sort_index().equals(result)
height = pos[1, 1] - pos[0, 1]
print(list(times))
pairs_to_drop.add((cols[i], cols[j]))
combos = itertools.combinations(list(range(52)), 5)
a_names.sort()
today + relativedelta.relativedelta(weekday=6)
last[v + value(i)][k] = i
A(n)
print(s)
app = myApp()
maskdraw.polygon(dst_tri, fill=255)
print(arg)
repo = git.Repo(search_parent_directories=True)
json_raw = raw.readlines()
request.response = Response()
basic_bundle = self.build_bundle(request=request)
cout << foo(5) << endl
do_stuff
pp(pairs, compact=True)
self._max_x = max(self._max_x, x)
firstline = True
True
result.append(i)
print(sh1.row_values(rownum))
current_date = start_date
x, y = (9,) * 2
p.daemon = True
model = Category
A, B = sorted([P, Q], key=len)
i.paths = paths[i.pos]
r, _, _ = select.select([self.clientSocket], [], [])
ruckford(param)
col = col[1:]
deleted[k]
sck.bind(url)
result_lists = [[] for n in input_lists]
normal = plane[:-1]
print(allfriends)
coords = [int((x + 1) * 75) for x in A + B + C]
self.index = 0
flattened = [(y, x) for x, y in np.ndenumerate(n)]
False, False
n = args[0]
kill.add(subcommand)
request_token, request_token_secret = twitter.get_request_token()
remote_repo = HttpGitClient(REMOTE_URL, username=USERNAME, password=PASSWORD)
result = [element for element in parentgen(c)]
S.max()
reversed[index] = np.fliplr(inner_array)
expected_result = {}
groups[begin, end] = group
Wizard.Install.Click()
FLAG1 = 1
c = 1
m.data *= m.data >= 10
self.flag.clear()
data = np.array(data0)
s = line[:6] + line[-6:]
earliest_end = min(r1.end, r2.end)
iter(self.store)
weight = -n / sum(v)
subsequences.append(cur_seq)
figure()
test
self[key] = value
self._index += 1
l = logging.getLogger(__name__)
request_payload = request.body,
matchobj = re.search(regexStr, emailStr)
queryString = urllib.parse.urlencode(dict_name_value_pairs)
res = x + (res,)
n_diff += 1
response_dict = RequestContext(request)
print(repr(s1))
x.forces
n = self._args[0]
results = []
xml2 = etree.fromstring(xml_string2, parser)
CGEventTapEnable(mouse_tap, True)
0
self.level -= 1
serv_args = {}
[], []
print(num)
count_2
ins = ins.format(tablename=widgets_table.name, markers=markers)
html_show_sourcelink = False
f1.__code__.co_consts
t = time.time()
1
model.apply(features)
lst = [18, 8]
line += 1
sorted(subject)[len(subject) / 2]
tx.setFont(*font)
weighted.append(i[0])
lexer.level -= 1
X = df.columns.values
F = [lambda x: x, lambda x: x * x, lambda x: x * 2 - 5]
me = socket.recv()
Ck2 = map(frozenset, Ck)
dd = {}
print(col_mean)
BooleanField(question.text)
x = ord(string[0]) << 7
value
raise Ex()
print(s)
begin_date = dateutil.parser.parse(begin)
ret = t[1]
rlcn.method1()
tens = number // 10
idx[i] = np.searchsorted(cdf[i], r)
foo = FooModule.Foo()
desired_result = numpy.diff(sums)
yourdict = {}
doStuffWithObj(obj)
max_age = survey_data.Age.dropna().max()
self.currentMovie = random.randint(0, 100)
Singleton._instance = object.__new__(cls, *args, **kwargs)
ax = df.plot()
Z = 10.0 * (Z2 - Z1)
a * b
char * buf
self.write(response)
factors.append(factor)
p = PatchCollection(patches, cmap=matplotlib.cm.jet, alpha=0.4)
store_uri = settings.IMAGES_STORE
a.replaceWith(p)
print(len(TEinTSS))
col_params[col] = params[0]
rd.sample(x, k)
CrawlSpider.__del__(self)
RATE = 96000
res.read()
excelDT = 42548.75001
db = dict(b)
widgets = []
data_you_need = data_you_need.append(data, ignore_index=True)
dfa, sa = df.align(s, axis=0)
self._prof.dump_stats(self._filename)
_max = n - S + 1
num
print(line)
print(str(fruit))
name, old_value = self.transaction.pop()
ones = tf.fill(n, 1)
self.__dict__.update(kw)
count += 1
self.already_computed.append(elt)
outerjoin((cyts, cy.text_strings)).outerjoin((co, City.county))
clf = svm.SVC(max_iter=1000)
Y = np.arange(10)
old_modules = sys.modules
logger.info(kwargs)
r = _chkarg(r)
numrows = len(list_table)
buffer = buf_from_mem(c_pointer, arr_size)
LOGGING = copy.deepcopy(DEFAULT_LOGGING)
sample_size = len(xs)
print(i)
y2d = y.reshape(100, 10)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
print(solution)
groups = [[1.04, 0.96], [1.69, 4.02]]
B = 4
locations_2 = np.random.rand(1000, 2)
nballs, nboxes = length(balls), length(boxes)
mybucket / files / pdf / abc2.pdf
tarinfo.name = tarinfo.name[offset:]
length = len(code)
mgc = get_ipython().magic
binNum = pd.cut(myList, bins, labels=False, include_lowest=True)
m = n / arrays[0].size
a = list(itertools.permutations([2, 2, 2 ** (d - 1), d], 4))
s
d[i] = i in d
s2 = s.lstrip()
rule.symbols.append(point_symbolizer)
buf.close()
request.addfinalizer(thing.delete)
result[0] + 2, result[1] * 2, result[2] - 2
a
a.append(next)
results = [0] * runs
scalar_field = scalar_field.reshape(n_y, n_x)
hn = logging.NullHandler()
d[x] = xx * xxx
x is pi
n_int
coltypes = [type(c) for c in rows[0]]
b = Bar()
memoryview(zp)[0]
users[users].index
x - y
pkt
minIndex = bisect.bisect(translatedList, pos[0] - maxDistance)
x ** 2
palette.reverse()
A.dot(C)
getcontext().prec = minprec
f.noisy = p.noisy = False
size += 1
address_2_html.allow_tags = True
l = list(range(2, 20))
instance = cls.all_instances.get(unique_id)
part1Cache = mainscript.part1()
numprocs = 1
l = [1, 1, 0, 1]
Img(message=value)
set(pattern.findall(dna) + pattern.findall(revcomp(dna)))
query = Q()
xi = (nx - 1) * (xi - xmin) / (xmax - xmin)
entry.update()
frame = stack[1][0]
serial = create_string_buffer(serial)
file = sys.argv[1]
a, b, c, d = mapping[0]
X = [[0.0, 0.0], [1.0, 1.0]]
FooBase.metadata.create_all(engine)
p[0] = tmp
newDict = d[i]
mask = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))
r.imag = a.real * b.imag + a.imag * b.real
utf8_bytes[:cut_index]
print(add)
newString = str(self.runner.readAllStandardError())
traceback.print_exception(type, value, tb)
data[word] = find_definition(word)
b = container.GetBase()
driver.close()
readdir = c_lib.readdir
closedir = c_lib.closedir
connect_global_done_signal_to_global_done_slot()
dataSource = getattr(self, source)
self._name = name
slice1 = tuple(slice1)
q1 = session.query(Baz.foo, Quux.bar).join(Quux.bar)
substring in string
headers = {}
func(cls, request, *args, **kwargs)
a = self.z
buffer = fo.read(4096)
saver = tf.train.Saver()
y = r * math.sin(alpha) + circle_y
child_mock1._mock_new_parent is parent_mock
form = ImportExcelForm()
print_table(table)
CAT = 2
combs = [itertools.combinations(l, i) for i in range(len(l) + 1)]
print(os_bits())
v_in = input(self.prompt)
int(math.ceil(len(l) / float(n)))
recursive_print(dic)
root.append(f)
jpeg_bin_tensor = tf.image.encode_jpeg(image_tensor)
username_input.send_keys(username)
check_name(key)
reverse = defaultdict(list)
rootlist.append(x)
nose.tools.assert_equal(foo, 10)
abstract = True
traceback.print_stack()
b[idx] = False
formatdate(ts, localtime=True)
group_hours = (df_test.hour <= df_test.hour.shift()).cumsum()
self.filter.qs
newsession = False
output.append(cname)
y = np.sin(x)
ngreen = 4
repr(s1)
AWS_QUERYSTRING_AUTH = False
xy = x[:, (newaxis), :, (newaxis)] * y[(newaxis), :, (newaxis), :]
y_n, x_n = arr_n.shape[:2]
args = inspect.getfullargspec(foo).args
words = line.split()
x = np.concatenate((x, x + x[-1] - x[0]))
self.filter = self.filter_class(self.request.GET, queryset=qs)
memory_file = BytesIO()
out[mask] = np.concatenate(v)
self.mock_sum = patcher.start()
output = process.communicate()[0]
mask[a <= 0] = np.ma.masked
sock = socket.socket(*a, **k)
deletex
snippets = [str(s) for s in snippets]
p, a = processes[n]
print(float(ii * 4 / n))
print(cert[begin:end])
res.fun
sys.exit()
key = m[0]
dist.name, dist.shapes
xy_sum += x * y
print(url_opener.open(url).headers)
year_as_string = date_in_some_format[-4:]
eqn = Eq(i_out, D_PWM * (A / Rsense))
next_page = response.urljoin(next_page)
previous = data[0], data[1], data[2]
self.source[key] = value
xstart = 0
self.level(message)
print(x)
True
fibs.append(fibs[-1] + fibs[-2])
True
jobs = []
s = len(b)
o.x = 10
d = {}
time_new = np.arange(np.max(time) + 1)
data = yaml.load(yaml_str, Loader=yaml.RoundTripLoader)
enemy1 -= kill
first_non_nan = nans[nans == False].index[0]
points.plot()
print(attrs)
closure()
d = np.diff(condition)
print(args)
match = pat.search(s, i)
show(s1)
m = c.df1[c.df1 == c.df2]
csv_output.writerows(empty)
complex = Filtration()
response.content = image_content_blob
length = len(lst2)
srv_service.do_something_super_important()
p + gp.geom_histogram(binwidth=10000) + gp.scale_y_log()
masked_array = np.ma.masked_where(a == -999, a)
df = []
counts[x] = 1
shape, loc, scale = stats.lognorm.fit(x, floc=0)
X = iris.data
print(combination)
settings.setAttribute(QWebSettings.JavaEnabled, True)
indent_type = 1
False
new_instance = MyModel(key=new_key)
driver = Firefox()
r = Tk()
c(A, B)
print(error)
time.sleep(120)
positionTmp
deque.clear()
t_minus = cv2.cvtColor(cam.read()[1], cv2.COLOR_RGB2GRAY)
root = tree.value
traces = np.transpose(traces)
then = time.mktime(last_updated.timetuple())
aDict = {}
ret
name = ndb.StringProperty(required=True)
self.datetime.setDateTime(QDateTime.currentDateTime())
number = int(tok)
print(df)
print(all_intersection)
fig.set_figwidth(8)
mask = data > 20
raise NotImplementedError
min_val = a.min()
print(result)
A = fftpack.fft(a)
iters = [iter(group) for group in groups]
p = 1
self.listTools = Gtk.Toolbar()
output = fin.read()
sat.compute(t)
mantissa = x / 10 ** exponent
print(data[obj_slice])
a_remote = Column(UnicodeText)
d
print(mail.stat())
resp = json.loads(r.text)
(t2, p2),
rawdata = stream.read()
c.noise
print((mn, mn2))
frame2 = i.crop((275, 0, 528, 250))
users = UserFactory.create_batch(10)
DeleteDC(screen_copy)
u, s, v = np.linalg.svd(A)
is_tuple = False
self.request = request
derived_
block = f.read(1)
datab = (255.0 / (display_max - display_min) * dataf).astype(numpy.uint8)
n = r2.match(m.group())
z = np.hstack([(np.ones(len(u)) * h * h0) for h in linspace(0, 1, num_levels)])
b = 1
fig = fg.Figure()
x = np.arange(-50, 51)
x = np.linspace(0, 1, N)
count = len(a[0])
input_thread.join()
cmath.exp(cmath.log(-1) / 2)
event.request.add_response_callback(cors_headers)
state = self.__dict__.copy()
worker_process_init.connect(install_pool_process_sighandlers)
a = chr(i)
self.buf.write(data[:written])
data = sin(2 * pi * freq * t) * amp
readIncoming(bytes)
next((True for elem in list_arrays if elem is myarr), False)
a.append(1)
a[s]
raise LockError(e[2])
zipi.compress_type = zipfile.ZIP_DEFLATED
shortcut.save()
green = (16751018 & 65280) >> 8
first = next(it)
self.name = name
text = []
Br = -B.conjugate()
list(self.data.values())
sp.distance.cdist(a, a)
H = np.unique(C)
x_scale = 7.15 * 0.78 / (rng[1] - rng[0])
dir(mr)
word2 = equivalence.lemmatize(word2)
1.0 if x ** 2 + y ** 2 + z ** 2 <= 1.0 else 0.0
print(A)
myOption_2 = models.CharField(max_length=20)
tag.setDate(localtime().tm_year)
line = sys.stdin.readline()
[needleID, haystack[needleID], max(scores)]
template = np.zeros_like(image)
print(results)
self.items = []
t.changed_banks([])
ts.append(ts[-1] + datetime.timedelta(microseconds=(f << 18) // 10))
n = 2
print(GetVersionEx())
obj
special = set(string.punctuation + string.whitespace)
insrt_stmnt = insert(table).values(insrt_vals)
Int = 1,
final = cv2.bitwise_or(fg, bk)
self.finish()
fftData = abs(np.fft.rfft(indata)) ** 2
first = random.choice(first_values)
y.strides
n = s * (zp + z) ** 2 / d ** 2
n = datetime.datetime.now()
url
self[key] = value
p = pickle.dumps(PickleableModuleWrapper(pickle))
nov = Sum(Case(When(created__month=10, then=1), output_field=IntegerField())),
mod = __import__(modname)
x
lst1.append(elem)
print(y)
self._children.add(child.name)
tmp = datetime.datetime(1904, 1, 1, 0, 0)
module_key, modules = getDeployList(jira_ticket)
Cython.Compiler.Options.docstrings = False
svm_y_train[i] = 1
seen.add(child)
min_index = argmin(path_distances)
err = PyErr_Occurred()
df
N = 10000
next(it2)
now
hits = a.ix[:, :-2].dropna()
defaultdict.__missing__(self, key)
column = 1
obj
val
x = x - 1
renWin.Render()
print(foo.T == foo)
yData = np.reshape(yData, (N, 1))
f.name
print(clf.alphas_.shape)
par, res = queue.get(block=True)
e.Skip(count).Concat(e.Take(count))
t += d.popleft()
1
a / b / i / j / k / l
result = [],
client = app.test_client()
self.update(dict.fromkeys(self.placeholders, self.default_value))
p = 0
15 - 1
sys.stdin = f
a = list(range(10))
print(value)
path = os.path.abspath(path)
gen_1, gen_1_teed = tee(gen_1)
assoc.pyo = Python.CompiledFile
t = datetime.now()
buffer.open(QIODevice.ReadWrite)
result.update({sub: ping})
max_num = 1
num[0]
scr.addstr(row, col, str[:offset])
transaction.rollback(sid)
import_array()
t = tempfile.NamedTemporaryFile()
js = loads(data)
name
ans
new_data[i, j] = codeTable.get(tuple(data[:, (i), (j)]), -9999)
True
pos = 0
buf = stream.read(1024)
line = fileIN.readline()
matImage = cv.fromarray(npImage)
print(tokens)
df
module = os.path.split(os.path.dirname(__file__))[-1]
lookup = {ref[:2]: ref[2] for ref in refs}
self.mylist = l
print(new_labels)
s = os.fstat(fl.fileno())
num = len(dists)
sys.exit()
new_result = func()
indices = []
i += 1
Pdb(def_colors).set_trace(sys._getframe().f_back)
print(s)
new_dict = SortedDict()
item
getcontext().prec = 100
print(p)
tn.close()
self.render()
True
self.request.response.redirect(self.url)
dest.write(src.read())
b2.append(x)
instances = []
pca = PCA(n_components=2)
args = parser.parse_args(astr.split())
file_sample = random.sample(file_list, int(len(file_list) * desired_pct / 100))
bcrypt.hashpw(plain_text_password, bcrypt.gensalt())
labels, handles = zip(*sorted(zip(labels, handles), key=lambda t: t[0]))
c = a + b
self._exceptions = []
self.end_headers()
match = LIBRARY_LDCONFIG_REGEX.search(line)
arr = []
JSON(simplejson.dumps(directions))
fig_1 = fig.add_subplot(2, 1, 1)
print(years)
retval = POP()
xs = np.zeros((2, 10))
m = MyClass(10)
self.xData = np.append(self.xData, xData)
ca.values = ctypes.pointer(ctypes.c_float(tmp[key][0]))
--enable - pythoninterp
True
foo = importlib.util.module_from_spec(spec)
env.update(caller.f_globals)
sleep(1)
self.images = []
m_list.append(formula[formula.index(x) - 1] + x)
Out[6] = 1
df
sel = vmatch(A)
fg = plt.figure(1)
obj.set_secret_key(secret_key)
tokens[name] = tokens[0]
set(first).union(*rest)
print(x)
newlist1 = list()
print(content)
fit = min(len(bytes), ctypes.sizeof(self))
p1 = Rectangle((0, 0), 1, 1, fc=pl1.get_color())
[1, 1],
x = np.linspace(0, 2, n)
assert expected_result == actual_result
height, width = template.shape[:-1]
SITE_ID = 2
d
maxwidth = max(map(lambda x: len(x), mylist))
c = fig.add_axes((0.5, 0.05, 0.4, 0.85))
row = G[(i), :]
excelModule = workbook.VBProject.VBComponents.Add(1)
year, week, day
convert_column(dic)
socket.setdeaulttimeout(60)
col_thresh = (nzm[1:] & zm[:-1]).sum(0)
deployment / load_test_results
False in a
instance_id, instance_name
ytop = min(ay, by, cy)
result = somecalc()
df1
app = Flask(__name__)
arr
user.last_login = time
sheet = book.sheet_by_name(sheet_name)
data = list(range(100))
output.write(buffer, 0, length)
res
links
print(p1out)
authToken = authHeader[7:]
diffs += 1
fp = StringIO.StringIO()
result
elem = etree.SubElement(root, text)
normed_data = (data - data.mean()) / data.std()
d = {}
print(rationalize_coeffs(expr))
print(lst)
idx2 = idx1[idx1[:, (1)].argsort()]
p[0], 50, p[2]
name = Column(String(50))
client = gdata.spreadsheet.service.SpreadsheetsService()
predict_ = poly.fit_transform(predict)
d = {}
c = Client()
self.d = defer.Deferred()
value = float(value)
root = etree.fromstring(xml)
api = Api(app)
1.0 * numerator / denominator
f_manager = pl.get_current_fig_manager()
self.current_file = current_file
beingimported.add(modulename)
WORKDIR / root
Y2 = np.array([0.5, 0.45, 1, 0.5])
_bdist_egg.run(self)
result
result = []
subprocess_cmd = shlex.split(shell_cmd)
[8, 9],
print(next(csv.reader([a], skipinitialspace=True)))
target, prereq = regex.match(l).groups()
ratio = float(num_rejects) / num_tests
instance
type(newImg1)
builtins.set
type.__new__(self, name, bases, dct)
n = int(n)
filenames = tkFileDialog.askopenfilenames(parent=root)
fig = Gcf.get_all_fig_managers()[-1].canvas.figure
values = list(models.values()).get()
thingys = []
scaled_node_size = lambda node: NX.degree(Gh, node) * 700
Xcum[1:] = temp[H:] - temp[:-H]
True.__cmp__(0)
self.progname = self.old_argv[1]
d[category].append(number)
b = a.copy()
print(kmeans.inertia_)
single_row = dict(zip(zip(*cursor.description)[0], cursor.fetchone()))
AltTab()
print(len(links))
THREE
sample_count = 5
folder = os.path.abspath(folder)
int(int1) + int(int2)
pairs = list(filter(nums.isdisjoint, pairs))
grid.spacing = [1.0, 1.0, 2.0]
first_name = CharField(max_length=50)
dsize = j + j / 8 + 8
x[combined]
tests.py
sub(pattern, repl, string, count=0, flags=0)
c = mu * (1 - corr)
not_prime[f] = True
result
g.series(x, 0)
actions = [set_x_on_objects]
a + b
print(puffup(c))
signal.SIGINT.value
5 - 14.666667
credentials = get_credentials()
lst1.append(elem)
week
k = []
udp_packet = udp.Packet()
L * F
alice.age = 8
weights_stretched[0][0] = 1
Factor(s)
keys = list(w.__dict__.keys())
a = np.arange(n_a_rows * n_a_cols).reshape(n_a_rows, n_a_cols)
somewhere / comparison_page_001.pdf
ids = []
res = []
[5, 6],
plt.setp(ax1.get_xticklabels(), visible=False)
game.wood += 1
True
document.body.appendChild(latDiv)
self._memo[name] = value
article = extractor.extract(raw_html=response.content)
writer.write(data)
html = r.read()
subs[i + 1][j + 1][k + 1] = subs[i][j][k] + 1
str(self.name)
print(blue(res))
it = iter(it)
result = list()
tagname = tagname.lower()
d = []
x = 10 ** 9
contours.set_value(0, 0.5)
dumps(l)
main()
noon
perm.append(n - 1)
s = s + 1
isinstance(0, bool)
char_counts[max_char] = 1
score = 0
print(use_var_declared_global)
print(find_weights(1000000))
mask = np.isfinite(grid)
print(df)
prod(where(mask * val, mask * val, 1), axis=1)
p[i:]
page = QWebPage()
Q.append(v)
w = 2 * pi / len(t) * arange(N)
actions = []
BOOST_PYTHON_MODULE(Spline)
p = scipy.stats.norm(0.5, 0.02).pdf(c)
y = [5, 6, 7, 8]
print(constant.MASTER_CLIENT_CONNECTED)
0.909090909091
t * t
i = 0
argnames, varargs, kwargs, defaults = inspect.getargspec(func)
sum(binomial(q + 5 - j, 5) * a[r + 20 * j] for j in range(5))
item = todo_items[i]
raise Escape()
stdout.write(clr)
nz_values = foo[foo > 0]
print(s)
other = [u for u in other if u.key() != user.key()]
circle = (xx - 100) ** 2 + (yy - 100) ** 2
X = np.array([[0, 0], [1, 1]])
h.setFormatter(f)
1
cam = cv2.VideoCapture(1)
upload = FileLimiter(file_obj, my_chunk_limit)
valid_marks = [str(n) for n in range(101)]
reactor.callLater(randrange(10), assign, jobs)
form
filenames = os.listdir(path)
dic = {}
common = c.most_common()
self.val = val
response = urllib.request.urlopen(req)
cls.web.quit()
response.status_code = 400
filteredKeys.append(key)
val = 0
numbers.remove(number + 1)
links = self._extract_links(body, response.url, response.encoding, base_url)
unit.rows[i].cols[j] = string.ascii_lowercase[i * 5 + j] * 5
obj = self.get_value(first, args, kwargs)
print(list(enumerate(sims)))
t = length(a) + 1
cols = len(a[0])
fout.write(my_picture)
762912
frame = callerframerecord[0]
alotoffunc.abc(self, x)
globals()[name] = count
cols = df.columns
new_buf.write(self.read())
setattr(self, attr, Section(attr, self.__parser))
B_set = set(B)
i = 0
req.add_common_vars()
field1 = models.BlahField()
render_window = iren.GetRenderWindow()
buf = []
factorial(5, 6, 7)
dict_ = {}
subgraphs
msg
my_set
print(cb.execute(n))
strlen(str)
print(i.leaves())
+game_score_per_life / hits_per_life * 0.1
rgb = raw.postprocess()
tight_layout()
print(tup)
register = template.Library()
parent2, idx2 = find_idx(tree2, pos_in_2)
y_chk = df.y.eq(df.y.shift())
myNewMassage.extend(myMassage)
file_size = os.path.getsize(filepath)
print(sub_lst)
left + right
profile
self.gravity = 9.82
self.mongo.insert(dict(item))
nodeType = lst[0]
print(units.convert(ls))
pprint(data)
memset(d, 0, sizeof(d))
np.random.seed(42)
same_grp = pd.Series(grp)
compile_opts.extend(self.compile_options)
print(truths)
queryset = queryset.order_by(Lower(ordering))
print(lib_file)
rel = f(Ol[i], Ol[j])
transform = ET.XSLT(xslt_doc)
ret[i] = PyString_AsString(list_str[i])
print(dll.path)
can = map(lambda x: map(lambda y: max(0.0, min(10.0, y)), x), can)
print(csv_file)
df
elements = list(take(2, gen))
a
True
print(folder)
mn, mx = ((x, y), (y, x))[x > y]
message = messages.BytesField(1)
bool(numFontsAdded)
handler = QtHandler()
self.ax = self.fig.add_subplot(111)
pid, status = os.wait()
childrenKeys = db.ListProperty(str, indexed=False, default=[])
modules
0
i = 0
df.empty
pool = self.connection_pool
rows = len(input)
arglist = [[X, param1, param2, n] for n in linspace(0.0, 1.0, 100)]
s = s.astype(np.float16)
proxy = True
CGEventPost(kCGHIDEventTap, theEvent)
ax1 = fig.add_subplot(2, 1, 1)
system = A, b = M[:, :-1], M[:, (-1)]
a = 2
gc.set_debug(gc.DEBUG_UNCOLLECTABLE | gc.DEBUG_COLLECTABLE | gc.DEBUG_OBJECTS)
myBigList = cPickle.load(savefile)
feature_names[support]
action()
curday = days_of_the_week[data.pop(0)]
maxrec -= 1
ind = np.random.randint(0, len(many_countries), 25)
grid.newpage()
d = etree.HTML(d)
self._flg[key]
x += m * y
cr = csv.reader(fr)
thelistforme = list(justLoopOn(input))
handler.setFormatter(formatter)
adj[i, 2] = x + 1
logOutput.setTextColor(color)
mask = np.diag(np.ones(25))
0.2881578675080012
d = list(range(10))
bytes += len(item)
schema.assertValid(tree)
moreIntersections = set(s & t for t in intersections)
http_server = tornado.httpserver.HTTPServer(application)
variance_retained = np.cumsum(evals) / np.sum(evals)
input = np.random.randint(1, max_value, 100)
serve(request, path, document_root)
painter.save()
system_tz = pytz.timezone(constants.TIME_ZONE)
ser_2 = pd.Series([False, True, False, True])
my_list
obj = unpickler.load()
self.obj = obj
print(resp)
optimizer = tf.train.GradientDescentOptimizer(0.01)
True
time.sleep(period(tempo))
cities = []
x, y, z = values
top_indices = sess.run([top_k_pred])
idx = mpl.dates.date2num(df.index)
x - y
ind = event.ind[0]
rs[rs.index.dayofweek < 5]
l = len(list)
paths = []
4, 4, 4
f = lambda x, y: x + y
mail == x.Spam
user_ids = []
magic_flush_mro_cache()
r1, c1 = Az.nonzero()
tz = pytz.timezone(account.timezone_name)
res = np.zeros(N)
exec(code)
self.addFilter(MyFilter())
u_ode = odeint(f, u_dft[0], t)[:, (0)]
cgitb.enable()
valid_mask = y * alpha < BY
print(k, v)
largest = max(nx.weakly_connected_component_subgraphs(G), key=len)
start = datetime(2015, 7, 22, 17, 58, 54, 746784)
Q.append(S)
self.data = it
print(a in set([b]))
cgitb.enable()
hello.hello1()
X_train = vectorizer.transform(train_data2)
ret = []
total_seconds = int(td.total_seconds())
unique = set()
x, y = i
a, p = an, 2 * p
root = tk.Tk()
y = np.cos(t)
plt.figure(1)
tree.mount(root, script_name, config)
assert token == keyword and len(keyword) == end - start
current_group = []
queryset = self.filter_queryset(queryset)
s = list(iterable)
foo = range(100000)
result = square(value)
c, r = labels.shape
perms = list(permutations(w))
session.add(myobject)
lines = mlab.pipeline.contour_surface(source)
counts = Counter(a)
z = z + 1
data
session = orm.sessionmaker(bind=engine)
in_module_contents = False
slope = par[0][0]
gateway = JavaGateway(start_callback_server=True)
rows = ((np.arange(pdf.shape[0]) - p[0]) / mult) ** 2
uGrid.SetPoints(points)
spss.EndDataStep()
next(song_iter)
wheel = [1, 2, 2, 4, 2, 4, 2, 4, 6, 2, 6]
game.Player.__init__(self, index)
images = ops.convert_to_tensor(image_list, dtype=dtypes.string)
s
self.scroll.setVerticalScrollBarPolicy(QtCore.Qt.ScrollBarAlwaysOn)
edge_horizont = ndimage.sobel(greyscale, 0)
array = band.ReadAsArray()
center = W * (0.5 + gz.polar2cart(0.1, angle))
print(a - b)
result = np.zeros((4, 4))
DBSession.configure(bind=engine)
getattr(obj, self.secretAttr)
rows = []
pcolormesh(mx, cmap=cm.YlOrRd)
mdd = drawdown.min()
sign = 1 if a > 0 and b > 0 or a < 0 and b < 0 else -1
p = poll()
print(messages[result])
print(i == 420)
self.data[key]
plt.xticks(index + bar_width, cols)
stream.write(bytes(bytearray(buf)))
f1 = np.round(f1 * scale) / scale
eigenvalues = pca.explained_variance_
x = fit_df.index.astype(float).values
s.extract()
base64.urlsafe_b64encode(hasher.digest()[0:10])
f = dec(f)
--without - x
mydata = myfile.read()
c1[x1] += 1
PARALLEL_PARSES = 10
num_of_sheets = word.ComputeStatistics(2)
roster[4] = shortstop
c = [1, 2]
test > 10000
cos_lat2 = np.cos(pos2[..., (0)])
next(f)
LoD
char * buf
one.append(el)
atexit.register(save_history)
D = decimal.Decimal
npt = len(x)
dict_ptr = ctypes.cast(dict_addr, ctypes.POINTER(ctypes.py_object))
args = parser.parse_args()
last_photos = photos[5:]
print(df1.mask(mask))
self.combine_element(mapping[el.tag, hashabledict(el.attrib)], el)
histo = hist(data, 200, normed=True)
config.add_route(name, pattern, **kw)
complexStructure = bytearray(a[0:6] + b[0:])
dict_
fig.add_subplot(1, 2, 2)
good_data = data[(0), :][data[(0), :] == 1.0]
df
image.save(path_to_image)
s1 = Series(randn(5), index=[1, 2, 4, 5, 6])
values = df.values
job = job_queue.get()
__metaclass__ = Meta
raise AttributeError
param = dist.fit(y)
print(len(tables))
largest = heapq.nsmallest(10, heap)
stderr_events_enabled = true
~s
f_ab[i, j] = f(a_, b_)
right = bisect.bisect_right(arr, [xmax])
plot(t, u_ode)
cursor = ret[1]
fd = os.open(DEVICE, os.O_WRONLY)
1
json_str = json.dumps(data)
reader = csv.DictReader(r.iter_lines())
fmt.Println(f(), f(), f(), f(), f())
answer = True
conn.login(USERNAME, PASSWORD)
polygon = Polygon(np.random.rand(N, 2), True)
aces
x = r * sin(theta) * cos(phi)
times += 1
x == n or x % n
z = spsolve(Z, w * y)
self.reporter.display_results(sect)
reprec
sum(stirling1(n - len(prefix), n - d - c) for d in dset)
udist = sparse.tril(tree_dist, k=-1)
body = urllib.request.urlopen(url).read()
pos += 1
n_k_d[k][d] += 1
print(c)
id(b)
tuples = filter(f, tuples)
root_idx = (i + 1) // 2
window.append(row)
results = [1]
line.set_data(plot_data[0:i + 1, (0)], plot_data[0:i + 1, (1)])
results = results.json()
self.get_current_file.seek(offset)
columns_non_unique = indices[1]
self.non_copy_constructor()
Sentra98
my_chr = chr(cid)
print(df)
2
-4
Rsqr
string_dict = dict()
ar = numpy.array(a)
raise
unlockpt(pt)
xedges = xedges[:-1] + 0.5 * (xedges[1] - xedges[0])
print(b)
bisect.insort_right(l, (250, 400))
reversed_word1 = word[-1::-1]
mymodule.l.append(x)
popt, pcov = scipy.optimize.curve_fit(opt_fun, xdata, ydata)
print(num)
level = NOTSET
a_strs = [e for e in a if isinstance(e, str)]
1 - sys.float_info.epsilon
company = models.EmailField(max_length=150)
old = self.value
real_next = next
num
code = r.read()
print(line_split[index_addr])
print(True)
n = np.isnan(v)
unfrozen_indices = list(unfrozen_indices)
__pyx_v_a = 2.5
data.append(df[col_name].sp_values)
counter.value += 1
quit()
raise ndb.Return(build_info)
ann.set_figure(fig)
idx[outer_slice[2]][inner_slice[1]]
exp.append(word)
key = i
b = np.array([1.1, 2.1, 4.1])
sizes = 0.4 * np.random.random(num)
new_products = set()
new_sql = []
stats[l] = pearsonr(dat.loc[(l[0]), :], dat.loc[(l[1]), :])
file_generator(buffer)
myList = list(range(5))
K = np.arange(1, 100, 2)
x = y = [0]
p2.awareness_status = p1.awareness_status
y_lattice = y_lattice[mask]
result = True
jc1p
self.width * self.height
data = [obj1, obj2]
a = a.astype(int)
l = bisect.bisect_left(arr, [lower])
y1 = 2 * np.cos(x)
raw_email = data[0][1]
self.retcode = 0
self.connections.remove(self)
sys.stdout = tempfile.TemporaryFile()
new_x = np.linspace(0.0, 1.0, N)
classgroup.sample(nSamples)
myarray = {}
self.y = A * numpy.outer(numpy.sin(u), numpy.sin(v))
do_something
ax = axes([0.2, 0.1, 0.7, 0.8])
realInput = cvCreateImage(cvGetSize(im), IPL_DEPTH_64F, 1)
ticklabels = dfstacked.index.tolist()
town_id = 5
dictionary[newkey] = dictionary[oldkey]
total += item
obj.isoformat()
print(x * res[0] + res[1])
a = numpy.random.randint(10, size=(8, 8))
marker = object()
f = lambda x: 1 if set.intersection(*map(set, x)) else 0
mask0 = 7
i = 1
inverted_dict = dict([[v, k] for k, v in list(counter.items())])
print(repr(line))
browser.setPage(page)
checkerboard = 1 - checkerboard
c = black_or_b(a, b)
xml = dict2xml(example)
self.sock = socket.socket()
od = OrderedDict()
by_bins_iter = itertools.groupby(sorted(data, key=pred), key=pred)
remove_keys = set([item[:2] for item in lst2])
date = datetime.now(tz).date()
Foo.java
method
valueScaled = float(value - leftMin) / float(leftSpan)
self.setRequest(request)
origin = stack[::-1][i + 1]
BMW, Mercedes = list(range(2))
b(6, 7, 8)
s = sieve.pop(c)
items
example.fact(5)
X = 10
age = models.IntegerField()
0
data_for_signal_handler += 1
count = start = 0
bg = Image.new(im.mode, im.size, im.getpixel((0, 0)))
output = proc.communicate()[0]
waiter = self._waiters.pop(0)
z = sorted(zip(str(a), str(b)))
self.f = f
-x
proc = psutil.Process()
add2virtualenv
print(output)
live(board)
start = date(2000, 1, 1)
dis.dis(sayHello)
self.result = do_this()
result = im.copy()
func(y, 4)
text_list = list(text)
myapp = MyAppClass(aspell_instance)
X = np.vstack([x1, x2]).T
indices = np.argsort(subarray)
clip_rows = tf.clip_by_norm(x, clip_norm=10, axes=1)
flann_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=4)
np.busday_count(A, B)
print(int(d2_ts - d1_ts) / 60)
total = x + y
False, True
print(df)
b = a.view(newdt)
deque.append(word)
skel[skel != 0] = 1
self._ssh
sw.set_border_width(50)
self.char_x -= 10
x = a
self.window = QtGui.QMainWindow(self)
line = fh.readline()
closedir.argtypes = [c_dir_p]
engine = Python.CreateEngine()
the_matrix = arange(64).reshape(4, 4, 4)
order = random_order(my_list)
1 / 0
df_ret = grouped.agg({weightscol: sum})
sampleRate = f.getframerate()
list2 = []
image
ax.set_ylabel(h.units)
self._data.keys() <= other._data.keys()
q.lists()
seq(b)
x = np.linspace(0.0, 100.0, nx)
new_ids = db.allocate_ids(handmade_key, 1)
True
diffed = grouped.diff()
magic_and_timestamp = f.read(8)
samples[k] = np.random.choice(populations[k], m, replace=False)
C = C.T
fill_alpha2D_complex(points, complex)
rate = np.array([x.rate for x in keys])
results = fn(*args, **kwargs)
df
v2 = 0.00582811608911
url_opener = get_proxy_opener(*sys.argv[1:4])
first_index = s.find(s1)
df2
M.update(d)
dout = ndarray.__getitem__(_data, indx)
child.setwinsize(400, 400)
leftpath = [root.val] + print_path(root.left)
t_assert.equal(expected, actual)
f2 = x * (rho - z) - y
y = data[i - 1]
handle.render_cairo(ctx)
sum = 0
bin / install_nltk_data
n = len(a)
s1[pos_a:pos_a + size]
self.elements.add(tag)
logi = [operator.lt, operator.gt, operator.eq]
f(*perm)
i = int(x)
diff_filter_openssl
print(a)
template_source = re.escape(template_source)
scr.refresh()
a[a.mask] = a[~a.mask][KDTree(xygood).query(xybad)[1]]
result.append(line)
t_squared = r * r * (df / ((1.0 - r) * (1.0 + r)))
iterobj = iter(mylist)
print(i)
buf = f.read(sz) + remainder
treat_numeric(agg[y])
f = someMethod(b)
summary_str = sess.run(summary_merge)
old_stdout = sys.stdout
JobAlert.objects.get(pk=pk)
df_c = df_ar.combine(df.br, combiner)
h = make_header(decode_header(subject))
x, y = np.mgrid[-5:5:0.1, -5:5:0.1]
Response(output_serializer.data)
signal.signal(signal.SIGINT, lambda signal, frame: watcher.join())
10.5 % 1
process_data(data, self.client_address)
rows = np.minimum(np.abs(rows), rows % N)
data[2:4, 2:4] = 1
x0, y0, r = params
x2 = floor(x * 100) / 100
predecessor = {}
t = inspect.trace()
do_stuff(last_line, line)
N = 100
di[i] = idx[0][0]
cache[param] = original_func(param)
data[flag] = np.nan
self.url = url
shared.pop(0)
output = io.BytesIO()
a = 2
endpoint = TCP4ServerEndpoint(reactor, 8007)
killed = 0
data = inbound_file.read()
q = p + sum(1 for i in g)
True
encoded_params = urllib.parse.urlencode(params)
s = repr(n)
y_lattice += center_pix[1]
raise
cr.executemany(insert, id2)
ind = arange(df.shape[0])
[(i - sig[i] / (sig[i + 1] - sig[i])) for i in indices]
result[key] = file2[value]
end_color = 0, 1, 0
some_criterium = do_something(line)
temp = 0
self.device = self.ctx.get_device()
buf.seek(0)
i += 1
justifyList = map(lambda x: x.ljust(maxwidth), mylist)
X = v.fit_transform(samples)
assert (rcount(b) == manual(b)).all()
users_tz = tz.tzlocal()
value = loader.construct_scalar(node)
c.uint
final_image[..., (1)] = arrImage[..., (1)]
main()
n.pool1 = L.Pooling(n.conv1, kernel_size=2, stride=2, pool=P.Pooling.MAX)
self.wtree.join()
abar = a.mean()
vertex_list[b - 1].connect(vertex_list[a - 1])
l = MultiIter(lambda : map(str, range(1, 4)))
self.__class__._all_tasks.add(self)
serv_req = urllib.request.Request(full_serv_uri)
nums[nums[0]] = nums[2] = 1
background = np.full(img.shape, 255, dtype=np.uint8)
line = self.data.readline()
Shift + v
z = round(y)
t = {}
r = redis.Redis()
pypreprocessor.parse()
dropped += 1
lngn = A.lngn.values[lats.match]
t == {}
df
self.key = s
dict_.update(dict_from_django_context(subcontext))
X = parse_numpy_array(filename)
p = partialAP(self.fget, func)
rgb = np.array(color_list).T
tb_output.close()
ret = []
jobs = [() for i in range(8)]
fclose(f)
result = [[]]
print(aliases - modnames)
D = test()
prev = add_vector(prev, k, vec)
data_x = np.random.random((50, 2))
clusters = [[]]
self.bytes += len(buf)
a, b, t, p = 1, 1 / D(2).sqrt(), 1 / D(4), 1
ts
xpos = NP.random.randint(1, 10, 10)
a = set([frozenset([2])])
x < threshold
self.signal = signal
loop = asyncio.get_event_loop()
pending = asyncio.Task.all_tasks()
homeView.html
False
k[n - lenM:] |= m[:-n + lenM]
do_long_code()
print(hc_scaled.max(), hc_scaled.min())
G_mean1 = list()
print(type(data_for_browser.json))
value
module = __import__(modname)
w = x
medals
resp = urllib.request.urlopen(req)
model * T
print(sm.stats.anova_lm(cw_lm, typ=2))
dots = np.random.randn(10, 10) * 255
self.thisptr.FooBar(O, P, Q)
base.query = _QueryProperty(self)
zipTest.printdir()
heappush(h, (0, node))
val = outq.get()
glViewport(0, 0, w, h)
self.args = args
example.translate(nohigh)
f = first(2)
expr.free_symbols
b = np.array([19, 24, 29])
simulations.task_done()
print(df)
expr1 if condition1 else expr2 if condition2 else expr
get_col = str(int(worksheet.cell_value(row - 1, i)))
group_dict = defaultdict(list)
input_key = int(input())
print(x)
nativelib.all_users()
xTrue = np.linspace(0, 1000, N)
FIN = 1
q2 = Dog.objects.all()
start = string.find(sub, start) + 1
self.write(message)
self.size = max(self.size, 1024) * 2
auth.login(request, user)
time.sleep(60)
found.append(pattern)
value_altered
path = op.join(CACHE, _file_from_url(url))
result = func(session)
y = coordinates[:, (1)]
self._init_connection(a)
web = WebDriver(PHANTOMJS)
paths
idx = np.random.choice(np.prod(dims), nsamp, replace=False)
str(D)
x, y
jsonify(results)
p2 = np.random.rand(len(dtrange)) + 10
exepath = os.path.join(d, executable + ext)
print(df)
print(ni.ifaddresses.__doc__)
f = ((px + dx, py + dy) for dx, dy in nonzero)
window_list = default.get_windows()
result
f(*args, **kwargs)
my_handler = MyLogHandler()
print(times_met[a, b])
command = {}
r[i] = 1.0
tstart = time.time()
numbers = accumulate(chain([start], deltas))
float(o)
print(member, line)
i += 1
n = 5
A() in [A()]
x = a
i, j = 0, 0
abstract = True
filesParser = argparse.ArgumentParser(add_help=False)
t[Mtl.rows[i]] += Mtl.data[i]
diag = numpy.diag_indices(mat.shape[1], ndim=2)
ffi = cffi.FFI()
outfile.write(line)
f.setMath(ast)
b
resultset = []
exclusions = set().union(*(set(range(t[0], t[1] + 1)) for t in liPos))
od = OrderedDict()
scr = screen.Screen()
data = model_to_dict(model)
idx = idx[5:] + idx[:5]
self.__parser.read(fileName)
[request]
intersect_BC = B.intersection(C)
q = p[(nz == 0), :]
UDPSock.close()
anythingSpecificToThisKindOfTasks()
now = datetime.now()
largest.edges()
self.buf.write(data[written:])
prefixes = defaultdict(list)
population = np.zeros(sum(A))
self.fig.canvas.draw()
weighted_quantiles = numpy.cumsum(sample_weight) - 0.5 * sample_weight
iterable[i] = value
n = len(sublst)
self._data.clear()
colors = [(0, 0, 0)] + [cm.YlOrRd(i) for i in range(1, 256)]
model = RDF.Model()
end = datetime.now()
self.cub1 = cub1
piv.columns = piv.columns.droplevel(0)
print(yourTimeStamp)
flag = True
print(2 * 10 ** 10)
diffs[i + 1] -= partitions[i]
sigma = np.sqrt(-1 / (2.0 * A))
src = socket.inet_ntoa(ip.src)
result = Series(result, index=self.index, name=self.name)
zn = polyfit(x, y, n)
SOME_VARIABLE = []
print(x, y)
data = N.array(binvalues, typecode=N.Float)
resampled_group.head(len(resampled_group.index)).fillna(0).head(20)
re1_matches and re2_matches and re1_matches + re2_matches
mymodule.x()
r = model_name.objects.get(report_name=r_name)
h1.insert_after(div)
self.name
my_old_sessions = Session.objects.all()
response
z = np.random.random((nr, nt))
mock(4)
arr = np.array([0] * K + [1] * (N - K))
compare_and_swap(taken[rigthFork], true, false)
a
X_Train_embedded = TSNE(n_components=2).fit_transform(X)
test.head(5)
kwargs.append(nodes.Keyword(key, value, lineno=value.lineno))
cnt += 1
lr = LineString(ls.coords[:] + ls.coords[0:1])
_d_xor2 = {(0, 0): 0, (0, 1): 1, (1, 0): 1, (1, 1): 0}
self.strings = strings
X_train = clf.fit_transform(ut)
foo.reload()
retval = False
sdays = ds.sum()
a
mat = mat.tocsc()
subnets = list(ip_network.subnet(prefix, count=count))
stopbits = serial.STOPBITS_ONE,
tar.add(name)
brand = db.StringProperty(required=True)
print(s)
result = []
result = parse(test)
l
sol = solvers.lp(c, G, h)
D[i] = True
cmd.kill()
l = String(r).length
it = iter(seq)
seas, year = x.split()
fio.readinto(ba)
pyodbc.version
self.section_level += 1
x = list(reader)
nr = np.sqrt(xs.shape[1])
f = np.linspace(0, rate / 2, len(p))
os.close(self._flock)
distances[i] = np.sum(np.square(features[i] - features), axis=1)
idx = np.lexsort([distances, my_arr])
loop = asyncio.get_event_loop()
debug = print
pl.plot(delta, x_values)
col.append(c - 1)
figure = plt.figure()
print(result)
TS
row = MyTest(value=n)
vtk_array = vtk_image.GetPointData().GetScalars()
doc_dict = author_attr.copy()
print(msg)
answer1 = result1.get(timeout=10)
unread_msg_nums = response[0].split()
x = 1
item = FlexibleItem()
fq = defaultdict(int)
c = b + 96
a, b, c1
print(len(x))
vals = map(string.strip, msqlrLines[0].split())
dog = Dog()
print(np.asarray(train).shape)
mySquare = Rectangle(Point(1, 1), Point(9, 9))
jobs.put(randrange(10))
sample = wei.rvs(1000)
value = parser.getint(section, option)
pprint.pprint(A1)
[-1 - 4]
self.cert = cert
myStrList
sha_1 = hashlib.sha1()
[24.5, 7.0],
self._defaults.update(kwargs)
print(result)
wrapper
squares.append(square)
type(Foo.bar)
mask = np.isnan(data)
0, 0, 0
i = n + 1
tmp = set()
process(chunk)
matcher = negative_re.search(sys.argv[1])
tmp = []
mean - m * sem, mean + m * sem
b = numpy.fromstring(bb, dtype=numpy.uint64)
frames = [frame.copy() for frame in ImageSequence.Iterator(im)]
sizeof(o)
time.sleep(60 * 15)
print(repr(A))
firefox_capabilities = DesiredCapabilities.FIREFOX
ids.flags
output
df1
count = 1
i = 2
L = listgen()
data_files = []
deletesprocket.widget
npImage = np.array(pilImage)
ContactForm = factory.make_contact_form()
result = np.split(r, pos)
x, y = [9] * 2
p2 = cast(p, POINTER(c_char))
rev_ref[to]
intInput = map(int, strInput)
form = EditUser(request.form, obj=user)
result[hit].append(user)
seq.append(a[i] if bit else b[j])
self.delta = datum - self.mean
dt_matrix = dt_matrix.append(dt_matrix_file)
count
right = (1 << i) - 1
out, err = p.communicate()
ts2
1 == n % 2
blah(y)
a = c()
0
B = []
Find(n1) == Find(n2)
t.microsecond
save_work()
tree = cElementTree.parse(filename)
_ = Infix(lambda x, y: bin(int(bin(int(x))[2:] + str(y), 2)))
False
database = result.path[1:]
pixdata[x, y] = 255, 255, 255, 0
print(AsciiTable(transposed).table)
y2 = np.cumsum(np.random.random(time.size) - 0.5)
indices = np.repeat(np.arange(cols), [1] + [2] * (cols - 2) + [1])
T.reindex(T.index.union(missing))
self.queryset = ModelName.objects.none()
self.data = []
first_five_and_stripped = string[:5], string[5:].strip()
print(df)
0 <= s <= 1.2
parameter = dict(zip(keys, cells))
print(compose(f, g)(5))
print(r1.content)
F = F[~(F == 0).all(1)][:iters * 2 ** (n + 1)]
5.565719
Console.WriteLine(dateNode.InnerText)
thevariable
str_terms = [(str_coeff(c) + str_power(p)) for c, p in eq_map]
sf2
begins = np.insert(my_diff, 0, 1)
f = numpy.float64(1.4)
postvars = parse_multipart(self.rfile, pdict)
height = int(math.ceil(img.size[1] * factor ** 0.5))
minballs = 0
distname, version, id = platform.linux_distribution()
contours.sort(key=lambda x: cv2.boundingRect(x)[0])
print(G.edges(data=True))
d = 1
out_col = self.getOutputCol()
celery.conf.ONE_DEFAULT_TIMEOUT = 60 * 60
name, age, weight, height
full = http_message.type
print(output)
remove.append(cols[j])
self.number = number
[tuple(component << 6 for component in color) for color in main_colors]
hello.hello.argtypes = ctypes.c_char_p,
name = models.CharField()
assert n(49) == set([24, 44, 48, 74])
arr
discussion.id,
x = len(item)
v1 = d1.get(k)
self.imap.select()
fname = crsr.fetchone()[0]
t = Tree()
deleteiph.chksum
int_or_float + 1.0
self.curoffs = 0
display = Display(visible=0, size=(800, 600))
timezone = -(time.altzone if localtime.tm_isdst else time.timezone)
view = Browser()
print(delta)
os.dup2(copied.fileno(), stdout_fd)
to_write = min(prod(size) - filesize, max_chunk_size)
print(max_so_far)
node
c.random_method()
nullCond = df.Email.isnull()
axs[1].plot(days, days_value)
postsort = []
curr_line += 1
print(int(f2))
BOOST_PYTHON_MODULE(MyModule)
0.42857142857142855
wp.major_xs(0)
a = A()
plt.plot(freq[:N / 2], abs(W[:N / 2]))
recip = 1 / f(x)
tst_ydata = [1, 1, 1, 1, 1, 1]
pet_list = []
b = np.array(a)
fig.add_subplot(1, 2, 1)
mask = j - i - k < 0
y = np.random.rand(1000)
a = np.random.rand(ROWS, COLS)
value = get_the_value()
print(p.map(f, list(range(5))))
user = User.register_fromJSON(request.json)
filterChain.doFilter(req, res)
self._address = reader.recv()
first_val = islice(dropwhile(lambda x: x <= threshold, seq), 0, 1)
print(list(group[1].B))
data[i] = data[i]._replace(has_close_neighbor=False)
l2 = [i]
TEMP[apply_after:] = myfunc_v(TEMP[apply_after:])
response
all_patches = extract_patches(x, patch_size)
labelpos = ((0, i) for i in y_pick)
a.rotate(1)
plt.title(title)
newWindow = hildon.StackableWindow()
fig = plt.figure()
process.crawl(MySpider)
cython.uint
nelements = np.prod(f.shape)
swap = np.arange(a.ndim)
somelist = [a for a in b if not a.criteria in otherlist]
text = indexes.CharField(document=True, use_template=True)
int.__s
sum0 = [x for x in perms if sum(x) == 0]
y = np.sin(2 * np.pi * x)
True
print(row)
msg_out[i + j] ^= gf_exp_c[lcoef + lgen[j]]
thread.join()
key, x
patt.findall(s)
result
__div__ = divtd
print(test_string)
j = i + 1
before, digits, after = match.groups()
randomWalk(t, w)
i += 1
print(format_help(parser, [parser._action_groups[2]]))
tweet_image(url)
app.test_client_class = TestClient
mime = magic.Magic(mime=True)
ba.extend(ar)
card_scores = [getPoints(card) for card in cards]
max_number = len(self.possibilities)
axes[2].set_ylim(bottom=0, top=d2.shape[0])
_, y2 = ax2.transData.transform((0, v2))
localClosure(0, 0)
engine = import_module(settings.SESSION_ENGINE)
ram.close()
s.cat.codes
snprintf(address.sun_path, UNIX_PATH_MAX, sockname)
start_token = re.escape(start_token)
print(text)
h = hout
y5 = x.astype(float64)
register = template.Library()
print(metrics.classification_report(y_test, y_predicted))
rset = set(resultlist[index])
[6.5, 2.0],
args = parse_args()
tups = zip(list(range(0, n, step)), list(range(step, n + step, step)))
pre_order_print(root.r_child)
ngram = defaultdict(lambda : defaultdict(int))
scope = engine.CreateScope()
type(self).d = self.d + 1
size = sum(1 for _ in g)
mscale = mag_scale.lower()
plt.triplot(triang)
sum_x / length, sum_y / length
STATUS_ERR_NULL_POINTER = 1
nombre = Column(String(248))
print(listForm[pos - 1])
reversed_dict[value] = []
lines = open(path).readlines()
closedir(folder)
{}
patches.append(polygon)
True
--enable - multibyte - -without - x
result
d.addCallback(result)
print(list1)
lst.insert(0, n // 2)
age = IntegerField()
format = sound.AFMT_S16_LE
api = tweepy.API(auth)
record
lock.release()
memo[x]
(point2[1] - point1[1]) / (point2[0] - point1[0])
main()
wlan = dpkt.ieee80211.IEEE80211(rawdata[t_len:])
self.rules = Rule(SgmlLinkExtractor(allow=(self.allow,))),
mask = b - a - k < 0
setattr(namespace, self.dest, values)
line_strings = []
add5 = add(5)
print(page_count)
sum
max_concurrent_requests = 100
self.y = y
print(min_num.number)
print(i)
x_list = self.x_list = map(float, x_list)
ax = gca()
items = items[:-1]
h2 = TanhLayer(2)
Py_BEGIN_ALLOW_THREADS
im_hsv = cv2.erode(im_hsv, element)
print(alist[(lags[i] <= angle) & (angle < lags[i + 1])])
t4.start()
mx = max(l, key=itemgetter(1))
email = ndb.StringProperty(validator=stringValidator)
s
status &= ~FLAG_THREE
f.tight_layout()
xp = R[0] + np.cos(razim) * np.cos(relev) * (self.dist + zoom_out)
PageAdmin.queryset = queryset
{hash: hash}
z = 1.0
seq = iter(seq)
words = words.split()
column = self.headers.logicalIndexAt(position)
print(words)
install_conda_if_needed
best_merit_yet = merit1
stack.append(child)
pairs.append(col1 + col2)
print(pat.findall(s))
ans = -1
ret
yv1 = np.arange(0, 4, 1)
x = np.linspace(0, 10, N)
child = self.__q.get()
1, 10, 99
self.module = module
pos = f.tell()
x, = s
newurl[i] = parsed[i]
poll = multiprocessing.dummy.Pool(5)
id(A[0]) == id(B[0])
keys = []
(c > W1) + 1 + (c > W2)
print(df1)
greyscale_map = greyscale_map.reshape((height, width))
produce(x, t)
conn < -h2o.init()
master = Tk()
yi = y.astype(int)
apply_after_index = acceptable_low_flow_indices[0]
chunk = f.read(16)
filename = str(self.photo.path)
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
d = zfit[:, (index)]
y = round((y - 1) / 2) * 2 + 1
app = QtGui.QApplication(sys.argv)
v1, c1 = d0[0], d0[1]
funcs = []
buffer = create_unicode_buffer(BUFFER_SIZE)
print(ctypes.windll.library.square(4))
id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
_pass_name
[image]
form = getattr(self, name)
n_j_k_d[j][k][d] -= 1
opener = urllib.request.build_opener(proxy)
dictionary[name] = 0
num, letter = pd.factorize(np.hstack(df.values))
d = Series(np.diff(np.hstack(([0.0], c[n]))), index=index)
driver.findElement(locator)
print(text)
sin_2 = sin(r) ** 2
left, right = right, left
logy = np.log(y)
data = [[dt, foo(dt)] for dt in data]
sum += x
ax2 = ax1.twiny()
query = np.sin(idx) + np.array(R.runif(100)) / 10
FAILED(failures=1)
conditionbuff.append(line)
npa[:, (0)] = npa[:, (0)] * n
False
data2[(idx[n]), :, (n)] = data[n][:, :]
ob = A()
textfield = Column(UnicodeText(convert_unicode=False))
pos = e.pos
nbors.append(i - A - p)
self.app_label
ID = ID + 16
result = []
self.quitButton.grid()
both_top_n = np.logical_and(row_top_n, col_top_n)
err = c.Start()
nbors.append(i + A - p)
d = 0
gen = generator()
walk(item)
end_time = time.time() + timeout
f.write(str(pid))
c = m1 ** 2 / (2 * std1 ** 2) - m2 ** 2 / (2 * std2 ** 2) - np.log(std2 / std1)
someMethod = someDecorator()(someMethod)
ygens = itertools.tee(ygen, 100)
index = bisect_left(sorted_list, value)
random.shuffle(pix)
model = Sequential()
start = time()
quoted_id = Column(Integer)
tempfile = NamedTemporaryFile(delete=False)
mygen = generator()
x = x[:-1] + (x[1] - x[0]) / 2
A()
-np.partition(-v, k)[k]
NullTranslations()
overflows.append(l[item_per_list:])
x.append(y)
newloc.y = y
y.tofile(f)
assert len(data) == width * height
toggle_item = (toggle + pp.OneOrMore(item)).setParseAction(toggle_item_action)
s[first_non_nan:]
default = wnck.screen_get_default()
N = 10
domain_keys = defaultdict(lambda : defaultdict(count().__next__))
tb.send_photo(chat_id, img, reply_to_message_id=msgid)
vertex_list[a - 1].connect(vertex_list[b - 1])
pixels = [tupleize(pixel) for pixel in pixels]
to_visit.append(ch_node)
known[n]
a = 2
xhash = [hashlib.sha1(row).digest() for row in x]
f = _
b = [4, 5, 6]
Base = declarative_base()
result
res = clisocket.recv(16)
distance = haversine_distance(lat1, long1, lat2, long2)
n = str(self._args[0])
ncols = B.max() + 1
abs(integer) % 10 ** digits * sign
obj = map_to_obj(v)
db = MongoClient().test
width = int(math.ceil(img.size[0] * factor ** 0.5))
register_treebuilders_from(_htmlparser)
print(start_date > now_utc)
PressKey(VK_MENU)
_patched_callable._old_func = mock._callable
resp = self.get_list(request)
s_A_approx = np.random.randint(0, 100, 100)
evals, evecs = np.linalg.eigh(cov_mat)
print(res)
process_client_connection(connection)
client = MongoClient()
total = 0.0
d.days
scatter(X, Y, c=c, s=150)
result
x = mpstat.readlines()
self.listWidget.setEnabled(enable)
b, a = scipy.signal.butter(2, 0.1)
set(-2)
y_real = norm(x, mean1, std1) + norm(x, mean2, std2)
print(df)
hist = hog.compute(image, winStride, padding, locations)
first_idx, = np.nonzero(first_mask)
result = result[1:] + (elem,)
imgOut = Image.fromarray(imgOut)
A = np.hstack([u, -v])
d = []
r = v % 20
cos_lat1 = np.cos(pos1[..., (0)])
current_seq_len = 0
shade = 20
p, s = precision_and_scale(f)
rpc.append(urlfetch.create_rpc())
f
last_line = parse_log(log_lines[last_line:])
self.value = value
inverted_dictionary = {}
index = np.where(mask == True)
I1 = [MIN(X1, X2), MAX(X1, X2)]
list = []
i.update(j)
x = np.linspace(0, np.pi, 100)
obj = vc.data
al[mask]
jul = Sum(Case(When(created__month=6, then=1), output_field=IntegerField())),
queue = sqs.get_queue_by_name(QueueName=queue_name)
request_map[threading.current_thread()] = request
i = 0
formatter.add_text(self.description)
n = 0
print(min(t.repeat(number=10000)))
k in self.__data
urls_d = defaultdict(int)
edges = hull_points[1:] - hull_points[:-1]
rooted_paths, unrooted_paths
list(partitions_original(s))
Y = np.arange(450)
val = np.concatenate([s.values, nan])
print(rssPR.modified)
nextChar = getNextChar()
result
d = timeit.timeit(DSM, setup=s, number=10)
list += [4]
self.num = tmp.__iadd__(1)
()
next(f)
print(doc.page)
H = (D * H.T).T
b = 1 - np.random.normal(size=100) * 0.1
cursor.callproc(stored_procedure_name, args)
bound_method = getattr(obj, attr)
szr.AddSpacer(10)
geolocator = Nominatim()
result = 1 - numerator / (sqrt(denoma) * sqrt(denomb))
SS % (w, x, y, z, a, b, c, d, hh, mm, ss, ms)
data = ruamel.yaml.round_trip_load(fi)
r(eturn)
wordorder
colNameList = []
f = o.open(url)
[command]
srcDir = os.path.dirname(pytz.__file__)
st.issubset(a)
recurse()
b = b[0]
s = np.sin(2 * np.pi * t)
mydict.close()
a = b = l[0]
x = glen
mypad = curses.newpad(mypad_height, width)
errnum = get_errno()
self.obj.__str__()
worker_list = []
hist, bin_edges = numpy.histogram(data, density=True)
command = supervisor_stdout
nlines = 0
j = json.loads(r.text)
next(iterable)
settings.setAttribute(QWebSettings.ZoomTextOnly, True)
self
posix_timestamp_millis = posix_timestamp_micros // 1000
str_cols = df.columns[df.dtypes == object]
divmod(-0.0, 100)
np.reshape(self.im.getdata(), self.im_sz)
index,
threads = []
val
z = defaultdict(int)
thing = yaml.load(doc, Loader=PrettySafeLoader)
numerator = sum(tup[0] * tup[1] for tup in zip(a, b))
callmyprogram
index_to_swap = np.random.randint(k)
request.url,
rbf.xi
i = np.argmax(np.maximum.accumulate(xs) - xs)
print(numToWords(1001000025))
co = aliased(Suit)
start = string.index(start_marker) + len(start_marker)
winsound.Beep(notes[note], int(period(tempo) * 1000))
line = next(self.f)
cond1 = np.logical_and(array[:, :, (0)] == 10, array[:, :, (1)] == 15)
data
join()
d[k] = v
file0 = f.read()
Py_RETURN_NONE
self.params = params
context = {}
addChild(image1)
response
p = imp.load_module(PACKAGE, mod[0], mod[1], mod[2])
template
print(inst.statement % inst.params)
scene.camera.rotation_euler[0] = rx * (pi / 180.0)
t += ephem.minute
score(-1)
file.write(omp_test)
self._intersections[a] = {b: 1}
print(value)
captcha_count = CaptchaStore.objects.count()
lookup_table = dict((g, inverse_indices(gi)) for g, gi in indices.items())
result.append(buf)
x = 1
t = Table(tableData)
print(cc.calls)
env = Environment()
c_numero.append(pais.count(p))
i += 1
groups = []
maks_key = key
f.auth_tls()
length -= 1
imaginaryInput = cvCreateImage(cvGetSize(im), IPL_DEPTH_64F, 1)
doctree = publish_doctree(source).asdom()
ax = result.ax_heatmap
d
writer.write(ex.SerializeToString())
x = list(range(nx))
zombie_speed = 50
last_region = iterate(x, last_region)
msg = [ord(char) for char in message]
im = Image.open(os.path.join(dirname, filename))
b = _chkarg(b)
x = data[:, (0)]
aList = aString.split()
self.value = value
decorated
a = b
B = lfilter([a], [1, -b], A)
--jane
result_a, result_b
data = [1, 2, 5, 10, -1]
object.__init__()
x = [0]
user_input
input = datetime.now()
n -= k
new_sock = sock.dup()
do_something(each)
DTYPE = np.float64
x = 9
ContentType.objects.get_for_model(model_object).pk, object_id = object.id,
_as_mpf_val = pi._as_mpf_val
[item for position, item in sorted(enumerate(items_list), key=score)]
mysum += (a - b) ** 2
state = models.TextField()
other_time = now + timedelta(hours=8)
max_length = data.Col1.map(len).max()
pred_y = smoothing(data_t, data_y, alpha=0.8, beta=0.5)
ind = np.column_stack([i - n, i])
print(foo.microsecond)
t = do_something()
ids.extend(page)
x = x * sin(theta / 2.0)
print(x in a, y in a)
serializer.save()
2,
x = 5
interact(update, idx=(0, 2))
i = 0
dist_matrix = NP.sqrt(NP.sum((data - bins) ** 2, axis=-1))
client = Client()
folderTree(folder.Folders, indent + 1)
dest.update(extra)
print(parse_code(secret_code))
nums = list(filter(lambda k, n=n: k % n != 0, nums))
self.positions[i:j]
longitude = models.FloatField()
double * weight
final_data = {}
y = lambda : z
result
resultlist.append(seq[result.start():result.end()])
client = app.test_client()
print(json.dumps(us))
sys.path.append(DIRECTORY_WHERE_YOUR_PACKAGE_IS_LOCATED)
data[i] = feature
print(b[b < p90][-1])
args = parser.parse_args()
random_state = np.random
daemon = False
document = PDDocument.load(pdfFile)
sender = self.sender()
count = Model.objects.all().count()
g(i)
r = val[0]
log = logging.getLogger(__name__)
chunk_end = infile.tell()
api.my_operation(item)
update(time_limit)
app_iter, status, headers = run_wsgi_app(http.app.wsgi_app, env)
some_code_need_extra_explanation()
print_path(grid, path)
count = sum = 0
b = a[1:7:2]
False
G = 2
m = np.maximum.accumulate(a)
prev_cwd = Path.cwd()
Pdb
ServerName = mssql
icon = gtk.STOCK_YES
val = (val - minval) / (maxval - minval)
print(str(foo.extra))
h = hid.device()
x[0, i, j]
results = response.read()
env = os.environ
count = {}
end_time = time.time() + self._timeout
{{(person.birthday | timesince): today}}
mult4 = lambda n: int(math.ceil(n / 4)) * 4
n_rings = 10.0
data[name][attr_name] = data[name].get(attr_name, {})
it = iter(l)
feb = Sum(Case(When(created__month=1, then=1), output_field=IntegerField())),
branch.commit = commit.parents[0]
count -= 1
keyword.kwlist
index2 = random.randint(0, last - 1)
d2 = OrderedDict(sorted(list(dict_2.items()), key=lambda t: t))
cls
do_stuff_that_depends_on_the_existence_of_the_file(f)
X_ext2 = X_ext2[sort_idx]
exec(data, my_scope)
inGroup, outGroup = [], []
view_func
a + x * (b - a)
coords.fk4
print(name)
z2 = np.array([ai.dot(bi) for ai, bi in zip(a, b)])
my_click.emit(self)
joint_names = set(joints) - set([from_joint])
start_time = time.clock()
self._bytesSent = 0
rendered_content = response.rendered_content
k, v = row[0], row[1:]
sin_d_lat = np.sin(lat_dif / 2.0)
sys.setrecursionlimit(100000)
table2.date = pd.to_datetime(table2.date)
x * 1000000.0 if type(x) in [int, float] else x
x = TestClass()
trainer = BackpropTrainer(net, ds, verbose=True)
data = driver.page_source
data[1]
slens = defaultdict(list)
df
m = 1
newlstOne.append(lstOne[i])
b = 2
buf = []
y = tf.nn.softmax(tf.matmul(w, x))
k, v = generate_pair()
itemLink = urlparse.urljoin(response.url, itemLink)
g.nth(0)
print(b.simple(1))
p = pyaudio.PyAudio()
errors
ch1 = s[1]
r1.pop(1)
f = d.copy()
y_sq = np.arange(-ny, nx, dtype=float)
stmt = stmt[-2:]
i *= j
cp.digitemprc / usr / local / etc / digitemp.conf
item = sieve[0]
R = eye(k)
generator = gen(5)
m = timeit.timeit(ophion, setup=s, number=10)
kwargs = []
lon, lat = w.wcs_pix2world(100.0, 100.0, 1)
norm_factor = 2 * np.pi * cov * scotts_factor ** 2
GeeElem(res)
data = dict.fromkeys(list(range(10)))
answer[pk] = []
6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8
response = SomeView.as_view()(request)
p *= Fraction(n - i + 1, i)
print(n_a, n_b, n_ab)
median_index = -1
xindex = list(it.multi_index)
unittest.main()
application2 = cidr_merge(list(network28s[14:16]))
print(text_len)
style.append(line)
status, x = ilp(c, G, h, A, b, I, B)
print(s)
print(obj.val)
self.b = color.b
werkzeug.serving.BaseWSGIServer.verify_request = verify_request
rowstride = mat.strides[0] // mat.itemsize
line = input_file.read(117)
y = 1.0 - y
y[j, i] = x[idx[j, i], j, i]
b = 2
self.c = c
mymodule = imp.load_module(name, file, pathname, description)
item_ids.append(item.shared_note)
ips = []
EnumWindows(EnumWindowsProc(foreach_window), 0)
ipdb > pylab.plot(x, y)
graph = [[]]
[(w * 2) for w in range(10)]
messages = session.Inbox.Messages
self.depth += 1
completed_subchapter = models.ForeignKey(SubChapter)
print(len(chunk))
d = datetime(2007, 4, 14, 11, 42, 50)
[logger_root]
print(s)
count = 0
a = -2
extract(value, dict_out)
cesttime = datetime.datetime(2010, 4, 1, 12, 57, tzinfo=cet)
tasks.remove(index)
key
y_fit = norm(x, m1, sd1) + norm(x, m2, sd2)
result = df.reset_index().groupby(0).index.apply(list).to_frame()
plot(**ChainMap(x_axis_params, y_axis_params, plot_params))
self.__dict__.update(kwargs)
length = len(iterable)
last_score = np.zeros(np.max(page_id) + 1, dtype=np.int64)
content = resp.content
start_urls = {}
sys.frozen = True
base_dt = datetime.datetime(2016, 1, 1)
lambda bound_x=x: bound_x
initcount = Counter(kmers)
fig = plt.figure(1)
w, x = f(x)
max_t, max_p = max(self.t2pos_ev.items())
nic.EnableStatic(IPAddress=[ip], SubnetMask=[subnetmask])
dx = -dx
time = datetime.time(time_ar[0], time_ar[1], time_ar[2])
b, c, ret = 0, 0, [a]
y = 1050
type(DynamicEnum)
float(obj)
deletex
next_month(some_date) - timedelta(days=1)
b.a = 1
index_counts, _ = np.histogram(A[0], bins=bin_edges)
foo.append(7)
ignore = set(ignore)
w.document.close()
c = 1
c = sorted(c)
players = collections.defaultdict(list)
print(ts)
val / abs(val)
[1, 1, 1],
s = ssdeep()
print(s)
print(result)
l2 = list(range(5, 15))
table1.date = pd.to_datetime(table1.date)
has_neighbor[:-1, :] = np.logical_or(has_neighbor[:-1, :], square[1:, :] > 0)
0
blocks = [mac[x:x + 2] for x in range(0, len(mac), 2)]
b_fc1 = bias_variable([1024])
b = []
week
col = LineCollection(lines, array=colors, cmap=plt.cm.gray)
self.key = key
sd = 1
graphs_sizer = wx.BoxSizer(wx.VERTICAL)
acquired = lock.acquire()
thing
mem = inferior.read_memory(addr, bytes)
d.writelines(list)
True
task = Q.pop(0)
x0_scale = 1 - (the_x_range[0] - int(the_x_range[0]))
print(a)
v = str(v)
m = int(ratio * n)
b
print(v)
lsi.print_topics(10)
self._hash
td.contents
step = NUTS(scaling=start)
a = [[0] * rows] * cols
nelements = np.prod(c.shape)
weights = np.array([(w * 1.0 / sum_weights) for w in weights])
print(stdout)
p = MyParser()
less = [1, 2]
password
detect = lambda url: chardet.detect(urllib.request.urlopen(url).read())
JSON.parse(atob(dataString))
node.__line__ = line + 1
2 * a
python26 - apple
counter += 1
case_0(param)
xmp_str = d[xmp_start:xmp_end + 12]
chan = conn.channel()
DEVICE_NOT_FOUND = 2
i_max, j_max = len(A), len(A[0])
c
middle = partM.join(str(field.get()) for field in fields[:S.get()])
STEP = MAX / len(CSS_SIZES)
pprint.pprint(col_uni_val)
self
args = p.parse_args()
zp = -1 * norm.isf([power])
sound.play()
inner_dec
item, = [1]
old = AccessToken.objects.get(user=user, application=app)
t = l1, l2
el = next(it)
fig_2 = fig.add_subplot(2, 1, 2)
dis.dis(bar)
self.all_tasks_done.notify_all()
i = 0
x = 10
context.load_verify_locations(self.root_certificate_path)
a == b
rgb = [np.interp(new_x, x, channel) for channel in rgb]
l.remove(partition)
pool.map(target, iterable)
volumesinstance = ec2.get_all_instances(filters=filter)
self.digits[self.zero_indices] = np.array(x)
c = get_config()
result = result + int(binary[bit - 1]) * 2 ** power
tokens = map(str.lower, nltk.word_tokenize(sentence))
ret, thresh = cv2.threshold(image, 245, 255, 0)
out[N - idx - rows:N - idx] += A[:, (idx)]
pp(dict(group_dict))
print(l, d)
args = [iter(iterable)] * n
path = self.in_queue.get()
self.builtin[name] = value
common_values = set(d1[common_key]) & set(d2[common_key])
print(True)
self.widget_layers.setContextMenuPolicy(Qt.ActionsContextMenu)
enqueue_op = q.enqueue([label_input, feature_input])
self.right = right
bufferFile.close()
myList
fig.append_trace(trace1, 2, 1)
F.shape = f.shape
FN = confusion_mat[(i), :].sum() - TP
w = Process(target=consumer, args=(x,))
cnt = Counter(l)
modAttr = []
val
d4[k] += v
print(x * y)
i, o, e = select.select([sys.stdin], [], [], 0.0001)
highest_values = []
v = x.ravel()
[response_body]
io_img = StringIO(data)
description = db.StringProperty(required=True)
add_three(4)
tests.py
c = Counter()
box.lon_max = rad2deg(lon_max)
r = requests.post(url, files=files)
np.s_[:] if k > 6 else np.s_[:k]
mic = Input(chnl=0)
m = email.message.Message()
fullname = Column(String)
res = {}
f + abs(f) / f * 0.5
df
sieve.update(list(range(i, upto + 1, i)))
set_4 = {1, 2}
2 ** p == x
[0]
max_count = 1
prefix = pdfFile.substring(0, pdfFile.length() - 4)
after_buf = []
False
setattr(namespace, self.dest, values)
round_trip = vectorToGeogr(sphericalToVector(point))
num_list = [a, b, c]
x_new
self.xlApp = xlApp
module.__file__ = filename
ctx.sign(plain, sign, gpgme.SIG_MODE_CLEAR)
a.shutdown()
connection = Connection(url, session)
PyObject * base
asdouble = ctypes.c_double(x)
result.append(e)
a2[mask] = 0
s[s].index
repr(t1)
count = P(n, S, k - 1)
numbers = [1, 75, 64, 80275, 2, 7]
CD2
padded_sliding_windows(a, split_size=4, pad_length=2, padnum=100)
counter += 1
app.setTimeout(15)
image_list, label_list = read_labeled_image_list(filename)
upto += w
repeats.append(element)
result = Rule.match(self, path)
cut_f_signal = f_signal.copy()
darwin = []
r = requests.get(url).text
up = lambda x: x if x > 0 else 0
set_printoptions(linewidth=terminal_width)
image = binarize_array(image, threshold)
pix
items = urllib2.parse_http_list(value)
do_stuff(element)
tuple(mapped)
c = [1, -1, 1, -1, -1]
src / src / org / renpy / android / PythonService.java
groups = [[] for i in range(12)]
known_things = sorted(set(a.keys()).intersection(xyz))
rolled[:, (0)] = False
ylim = min(data[:, (1)]), max(data[:, (1)])
count = count + 1
print(m)
r = Tkinter.Tcl()
sha1sum
height, width = 20, 20
self.x = A * numpy.outer(numpy.cos(u), numpy.sin(v))
vals = numpy.random.choice(choices, N, False)
self._x = value
file_handler.setFormatter(formatter)
dis.dis(Spam._egg)
file_size = link.size(filename)
context.load_default_certs()
t.append((self.a[i][j], (i, j)))
offset = split_timestamp[2]
primes.append(i)
key
dx = hull[i + 1][0] - hull[i][0]
Py_DECREF(keywords)
org_month_dict = collections.defaultdict(set)
21155000.0
self._file_cache = set(files)
df
birthday = born.replace(year=today.year, month=born.month + 1, day=1)
result.AppendLine()
print(t)
grouped = [(uniq, len(list(dups))) for uniq, dups in groupby(sorted(list1))]
2
print(results)
words = Counter()
m1 = m.tocsr()
self.tasks = self.getTasks()
matrix = np.random.random((20, 20))
index, a, b, c = row
os.dup2(pipe_in, 1)
deriv_list = [x(t), f(x(t))]
app = ScriptNameStripper(app)
node = node.get_next()
asc = [i]
False
datetime(2000, 1, 10),
N = len(all_nodes)
model = models.Article
XYZ = [0, 0, 0]
p.method
print(info.lineno)
a, b = 6, 2
d = i >> 5 & 7
obj = next(iter(objects.values()))
W, H = 128, 128
folder = nltk.data.find(dirpath)
dt_matrix_file = pd.DataFrame(cleaned_dict)
binary_insert(root.l_child, node)
a == c or b == d or abs(a - c) == abs(b - d)
rng = np.arange(n)
proxy = True
dict_ptr.contents.value
README.rst
hot_list = [get_hot_value(sublist) for sublist in my_list]
build_ui(root)
s2 = max(m)
df_.index = ix_
b = numpy.frombuffer(bb, dtype=numpy.uint64)
m.names
angle = getAngleBetweenPoints(1, 1, 2, 1)
clf.tree_.threshold
ucd.name(u1)
rows = [X[chunk][row] for chunk, row in indices[i:i + newchunksize]]
httplib.HTTPMessage(filehandle).getdate(headername)
output = getOutput(outQueue)
irc.connect((server, 6667))
q[-1] = 1.0
before_char = fmt[idx - 1]
df = pd.read_clipboard()
deployment / support
self.name
polygon_shape = Polygon(xy)
components.insert(0, tail)
result = {}
f2 = yaml.load(s)
770000
h = [[d[j], d[-j - 1]] for j in range(n / 2)]
args = [iter(iterable)] * n
unsorted.remove(item)
self.s.join(self.items)
products.remove(1)
print(primeList[999])
type(wells)
main()
raise NotImplementedError(msg)
len(set(doc1) & set(doc2))
mat[diag] = numpy.nan
df
writer.header_list = list(df.columns.values)
c = chr(i)
d = +0.0
density = frequency / radius ** 2
ap = PlainTextAuthProvider(username=foo, password=bar)
earliest_end = min(A_end, B_end)
InitializeComponent()
priority = 998
i1, i2 = i1 - 1, 0
df
txn.put(key, value)
print(cells)
MOUSEEVENTF_CLICK = MOUSEEVENTF_LEFTDOWN + MOUSEEVENTF_LEFTUP
com_instance.Visible = True
resp = c.get(somehow_get_the_url_from(req))
print(t.draw())
resp
min_max_scaler = preprocessing.MinMaxScaler()
sims = sorted(enumerate(sims), key=lambda item: -item[1])
N = len(X)
endif
args.pop()
print(con.session.headers)
info.size = data.len
l + r
f = ctypes.windll.dwmapi.DwmGetWindowAttribute
score = tpl[0][1]
self.count = 0
i -= 1
[s]
choices = randint(0, length, length)
obj = getattr(obj, i)
assert _PyUnicode_CheckConsistency(u, 1)
x
print(val)
xbee = XBee(ser)
arr.append(alphabet[num % radix])
r += step
print(mean(data))
True
l = [1, 1, 1, 1]
Py_MEMCPY(p, PyString_AS_STRING(item), n)
Base = declarative_base()
sys
i = 0
c = Counter()
B.ravel()[idx] = A[mask]
data = np.zeros((num_rows,), dtype=fields)
x = 0
a = (z << 16) + w
dataf = image_data.astype(float)
all_tokens = sum(texts, [])
self.interval = interval
column_letter = get_column_letter(column)
env.warn_only = True
pdfFile = args[i]
doc = SimpleDocTemplate(handler.response.out, pagesize=letter)
v = myVector(4)
kwargs.update(stdout=devnull_out, stderr=devnull_out)
i = open_tags.index(tagname)
outbuffer.resize(outbuffer_len)
partitions_new[n]
dir(e)
log.removeHandler(hdlr)
start = __datetime(start_date)
print(result)
callgraph.add_subgraph(cluster_foo)
self.lastPoint = event.pos()
img = base64.b64decode(value)
pts = np.array(points)
acknowledged = True
2011 - 2 - 5, NaN, NaN
obj = someobject
iter(shuffled)
A_dist = distance.squareform(DF_dism.as_matrix())
[1, 0, 1],
index[6]
chocolate = chips, milk = shape
is_abstract = True
user_paths = []
_GeneratorContextManager(func, *args, **kwds)
num1 = 20
s = L[:], L[:]
self
print()
M = numpy.zeros((m_rows, m_cols))
traffic_monitor_callback(p)
path = [path]
df
result = f(*args, **kwds)
OPTION_B = 1 << 1
number_of_files = len(list_of_files)
df
self._spam
no_microseconds_time = time.mktime(d.timetuple())
Temp_Obj.setText(Rtf_text)
x = 1 << n.bit_length() - 1
m = s.model()
Gcf.destroy_fig(fig)
d.rotate()
set_1 = set(repr(x) for x in sample_json1)
roman
yi = np.linspace(-2.1, 2.1, 100)
w = random.standard_cauchy(N)
time += 10
jinja2.nodes.CallBlock(node, [], [], [], lineno=lineno)
print(getattr(re, options.action)(re.escape(options.regexp), options.string))
gamma = random.uniform(0.0, 2.0 * math.pi)
data = dict(data)
tty.setraw(stdin_fileno)
split = files.split()
val = d.get(val, stop)
Expr.__new__(cls, arg)
Test(self.val - y.val)
easy(2 ** 50 - 1), easy(2 ** 50), easy(2 ** 50 + 1)
fp = StringIO.StringIO(file_object.read())
client = oauth.Client(consumer)
MyObject.ID
serverhash, key = key
conn = engine.connect()
check_raise(test_chain)
PyObject * _next()
x = as_strided(a, (r, b1, c, b2), (rs, 0, cs, 0))
self.thread.daemon = True
assert 42 == example.test_generic_uint8(numpy.uint8(42))
r
deleteself.observers[o]
generator = getstuff()
childJoins = childJoins.join(child)
weatherData = json.load(jf)
gobject.timeout_add(timeout * 1000, callback)
visit(curRoom.eastNeighbor, curX + 1, curY)
costheta = np.cos(theta)
color = screen.get_at(pos)
query = query.offset(page * page_size)
1
winsound.Beep(800, 100)
r = Ridge(random_state=241, alpha=1.0)
ns.recv(8192)
root = Tk()
driver = webdriver.Firefox()
Y = np.array([-1, -1, -2, 1, 1, 2])
values = a, b, c, d
primes = [x for x in primes if x == i or x % i]
active = models.BooleanField()
list.remove(self, element)
Tibet
Indonesia
Arkansas
4250.5589
y = 1
_s = s[:]
wage = models.FloatField()
res
results = []
innerzippath = os.path.join(tmpdir, name)
msg = email.message.Message()
startx = obj.ax.x(d[0])
endx = obj.ax.x(d[0])
res = n._forward(a)
win_height = win_geo.height()
arr = temp_result
shape = shape[:axis] + shape[axis + 1:]
ret = service.MultiService()
etree.strip_tags(tree, etree.Comment)
products.update(new_products)
x, y = m(*zip(*[hawaii, austin, washington, chicago, losangeles]))
fprime = f.diff(x)
n_chunks = h5_array.shape[0] / read_chunksize
unique_hash1 = pickle.dumps(c1)
False
vtk_image = vtk_win_im.GetOutput()
sub_shapes = map(list, itertools.combinations(list(range(m)), int(rowstochoose)))
current = heapq.heappop(openHeap)[1]
COL = [colorsys.hsv_to_rgb(x * 1.0 / N, 0.7, 0.5) for x in range(N)]
time = now.time()
d = defaultdict(list)
f_out.close()
clean_up()
items = set.union(*[set(prefs[u].keys()) for u in bestmatches[i]])
True
st.norm.ppf(0.95)
y = func(10)
list = []
numelements = int((stop - start) / float(step))
balancer = engines.load_balanced_view()
number = int(number) * 10
yr = (x - xm) * sin(a) + (y - ym) * cos(a) + ym
app_id = os.environ[APPLICATION_ID]
reactor.listenTCP(2222, getManholeFactory(globals()))
notepad.clearCallbacks([NOTIFICATION.BUFFERACTIVATED, NOTIFICATION.READY])
y, x = [1, -1], [[1, 0, 1], [-1, 0, -1]]
conn.assert_hostname = host
ui.write(e.EV_KEY, e.BTN_LEFT, 1)
response = urllib.request.urlopen(req, jsondatabytes)
print(myl)
mask = np.zeros((h + 2, w + 2), np.uint8)
median = len(point_list) // 2
BDF.PN = BDF.PN.str.strip()
result = defaultdict(set)
ii = np.arange(jmat.shape[0])
c.use_certificate_file(self.certificate)
stream = pyte.ByteStream()
data = sorted(personlist, key=keyfunc)
C.append(line_c)
model = MyModel
scorer = make_scorer(score_func)
result = []
NumericOperand(as_float)
first = 0
max_B = np.max(B)
soup = BeautifulSoup(text)
sieve[y] = False
overlapping_dates = [date.fromordinal(x) for x in overlapping_dates]
current_set.remove(symbol)
model_module = sys.modules[new_class.__module__]
df = results_panel[item_label]
print(int(Color.RED))
print(str(i))
c.perform
buffer.close()
pkg = cache[pkg_name]
im_data[im_rangey[0]:im_rangey[1], im_rangex[0]:im_rangex[1]] = 10
dic
first = next(iterable)
nums = set(data_set)
signum = getattr(signal, i)
counter = counter + 1
self.end_headers()
message_bodies.append(body)
m = multiprocessing.Manager()
self.wfile.write(data)
self.apply((), kwargs)
i = [m.start() for m in re.finditer(keyword, string)]
total = 0
bulk = hdd.initialize_ordered_bulk_op()
nameArray = [(int(x) if x.isdigit() else x) for x in nameArray]
sum_of += ans
HTTPCACHE_ENABLED = True
a[0] = 11
actions.drag_and_drop_by_offset(element, 50, 50)
grid()
x = np.linspace(0, 2, 1000)
truncatechars(self.description, 100)
obj[x] = self.recursiveDecode(obj[x])
counts = Counter(a)
l1 = list(range(10))
out = np.take(strings, bool_arr.astype(int))
my_db.commit()
plotdat = np.sum(density, axis=0)
max_queue_messages = 10
action
result += int(bit) * 2 ** power
year = models.CharField(max_length=4)
interpreter = py
s[0]
inputStream = url.openStream()
ofs.Minute(1) + (ofs.Second(1) - ofs.Second(1))
model = Bloop
m = interp1d([1, 128, 256, 512], [1, 10, 90, 100])
of.seek(n * length_line)
people = {}
fmt.Println(r.Replace(format))
decorated_view
print(line1.buffer(EPS).contains(pr))
decimals = [int(chunk, 2) for chunk in chunks]
temp_depth.append(dep)
mapping = loader.construct_mapping(node, deep=True)
cval = unicodedata.numeric(c)
counts_a = np.bincount(a)
base[0]
alist.append(adict)
idx_1d = a_1d.argsort()[-N:]
self.basic_auth = HTTPBasicAuth(*basic_up)
df1
result = Reply(resp.status_code, resp.headers, resp.content)
list = []
events = events.exclude(eventitem__rev1__isnull=True)
print(str(TITLE_P[-1]))
sz = os.fstat(fd).st_size
image
compareDir(path0, path0List, path1, path1List)
mpz_set(base, b)
deletebuf[0]
values = dict_x[key]
log = application.log
session.identity_map._mutable_attrs.discard(state)
F = plt.figure()
eijk[0, 1, 2] = eijk[1, 2, 0] = eijk[2, 0, 1] = 1
print(average)
y_list = [y for [x, y] in list_of_lists]
exit
a
uniqueCrossTabs = list(itertools.chain.from_iterable(uniqueCrossTabs))
val = int(time.time()) % 10
lasthash == thishash
dphi, dtheta = np.pi / 250.0, np.pi / 250.0
print(len(videos))
current = current.prev
b = x = x + 1
app.Visible = 0
G = sqrt(X ** 2 + Y ** 2)
names[char] = name + chr(0)
dirname = os.path.split(os.path.dirname(filename))[1]
a_copy = a.copy()
matrix[pair]
set_b = {2, 4, 4, 1}
savimp = __builtin__.__import__
list2 = []
prog = re.compile(pattern)
firstRun = False
[python]
count = 0
p, i = mvn.mvnun(low, upp, mu, S)
sys.stderr = error_stream
elapsed = time.time() - start
days, cnts
print(k)
PyEval_ReleaseThread(myThreadState)
nexts = cycle(iter(it).__next__ for it in iterables)
db = lmdb.open(path, map_size=int(1000000000000.0))
s = (s * s - 2) % M
x = [70, 80, 90, 100, 110]
j = n
print(eqs)
self.run = unittest.TestCase.run.__get__(self, self.__class__)
shift_data,
~2
all_dfs.append(this_snp)
raise ArgumentError(action, msg)
msg_printer()
print(ct[inv] == 1)
print(line.strip())
has_other = True
env = Environment(**options)
p.output_list
[self.x, self.y, self.z]
ibm = pickle.load(fin)
option1.pack()
even_odd_key = lambda x: x % 2
w1.plot(n)
data = future.result()
iv = df.index.values
locale.nl_langinfo(locale.DAY_6)
cxt = mnt.Context()
console.log(data)
HttpAuthenticated.__init__(self, **kwargs)
my_cmd = MyCmd()
dest_image.readMetadata()
full_name = models.CharField(max_length=25)
1, 2
out_data
a[inds] = np.take(col_mean, inds[1])
deref(id(4), ctypes.c_int)[6] = 5
date_time = np.empty(dt_array.shape[0], dtype=object)
set([xs])
n + 2
hexchars = s[i:i + 2]
r += 1
use_for_related_fields = True
grades = collections.Counter()
print(1 == True)
Foo_Base2 = template(Base2)
env = os.environ
1
to_idx += 1
main.show()
accum = next(iterer)
filters = []
s = list(f.shape)
part = math.ceil(part)
items = []
print(data)
c.first
cutoff = np.maximum.reduce(s, axis=-1, keepdims=True) * rcond
filter = {}
counter = start
node_list = list(d[u])
outputFileHandle.write(line)
self.model.load(fn)
buffered_events = self.rcon.lrange(self.buffer_key, 0, -1)
binascii.hexlify(os.urandom(20)).decode()
inspect.signature(foo).parameters
a2 = list(a)
dest[index] = value
output_dict
nblue = 18
d = c
newGuess = (n / oldGuess + oldGuess) / 2.0
i = 2
doc = xml.Document()
py > ast.body[1].value.args
arduino.setDTR(True)
mutable_query_dict = QueryDict(mutable=True)
now = datetime.datetime.now()
z = ((x + y) ** 2).expand()
EMAIL_PORT = 465
r, g, b = (int(hexrgb[i:i + 2], 16) / 255.0 for i in range(0, 5, 2))
values = list(advance_values(iters))
self.size, self.direction = -1, -1
split.sort()
groups = itertools.groupby(my_array)
py > ast.body[1]
formatted_list = format_exception(hexc, hval, htb)
title = db.Column(db.String(45), nullable=False)
MASTER_CLIENT_CONNECTED = 0
raise
df = pd.DataFrame(num, index=prices, columns=days)
use_this_as_an_input_to_new_tensorflow_op = tf.constant(last_outputs)
print(env.hosts)
0
logging.debug(*a, **kw)
self.duration = time.time() - request.start_time
new_sku[::-1]
coord = tf.train.Coordinator()
self.fh
not_other = other.clone()
print(s.settimeout.__doc__)
self.name = name
zf.writestr(filename_in_zip, file_contents)
flattend2 = [k for i in incoming for k in i]
c = lambda : b(a, 10)
nonz = NPY_TRUE
A.a.__get__(self)
bisect.bisect(offset_values, 1900)
nan = np.nan
sentenceList[count] = word
draw.text_antialias = True
log_wrap(mydict)
parser = YajlParser(ContentHandler())
warnings.warn(UNSUPPORTED_DATABASE, UserWarning, stacklevel=2)
addlist = set(AddList)
float(numerator) / denominator
python
System.Collections.IEnumerable.GetEnumerator()
False
DISPLAYSURF = pygame.display.set_mode((width, height), RESIZABLE)
xbin = [bin(i)[2:].zfill(8) for i in xdata[-1::-1]]
test_main()
ConvertToByteArray(this.LocalString)
self.json_str = json_data
d.shape
print(k, v)
od = OrderedDict(first_found(l))
self._position.set(pos)
res = []
maxrec = sys.getrecursionlimit()
result.append(line)
col.append(len(df[col_name].sp_values) * [i])
m = a.shape[0]
counter
clang = True
code = open(os.path.join(TOP, path)).read()
eroded_img = cv2.erode(binary, mask, iterations=1)
events = inotify.get_events(self.fd)
all_ids = babel.localedata.locale_identifiers()
a = np.expand_dims(ip[start:end], -1) == jp.T
ipshell(local_ns=locals())
data_t = list(range(15))
self.__position = []
hmean = np.mean(h)
shared_dict[user] = value
cols = [0, 4, 5]
lognorm.shapes
small, big = (old, new) if len(old) < len(new) else (new, old)
foo = 1
dx, dy = 0.5, 0.5
mx.DateTime.DateTime(1899)
request_queue.get()
has_neighbor[1:, :] = np.logical_or(has_neighbor[1:, :], square[:-1, :] > 0)
df.COL_NAME.apply(max_cat)
c = int(*a)
print(test_df.mask(test_df < 4))
fig.canvas.blit(ax.bbox)
inf = 1e1000
b[x] = 1
labeled, nr_objects = ndimage.label(imgf > threshold)
second_third_first_items = operator.itemgetter(1, 2, 0)
plt.imshow(img)
print(eval(CommandText))
self.x = x
matched / limit * 100
ax0.bar(list(range(l)), Two)
s = psum(raw)
server = Server(8000)
d_sum[topkey] = dic1[topkey]
app = App()
conn = db.open()
b
ugettext(msg) == msg
data.setValue(i, j, value / 4.0)
avg_round1 = float(sum(a for _, a, _ in players)) / len(players)
current_depth + 1
frequency * np.random.uniform(-timestamp_noise, timestamp_noise, len(track_1))
[0, 1],
conn.login(account)
url = url_test % i
plot_data = np.zeros((window, 2))
Instrument.external_method = to_import_from.external_method
counter = Counter.get_by_key_name(key_name)
xcoord
str(rr)
channel = params[1].lower()
L[begin], L[i] = L[i], L[begin]
_, _, name, _, _, city, _ = whatever
count = {}
self.email = email
path = [p for p in sys.path if p != os.path.dirname(__file__)]
key = produce_cache_key(fun, *args, **kwargs)
f.close()
value
x.timeit()
my_list = []
dTime = time.time()
p_vec = np.vstack((0.1 / p, 1.0 / p, 0.2 / p))
print(x)
list(locale.locale_alias.keys())[:5]
reference_diff_page_001.pdf
lf.seek(0)
foo
W.add_edge(m, n, rel=weights_dict[relation])
p.apply(lambda x: x, f)
corr = df.corr().stack()
newstate
parsed_url = url_parse(url)
{}
(i, j), (k, m) = pair_of_pairs
fig.savefig(fname)
value = blob_reader.read()
f1 = partial(callback, i)
visit.Version()
length = len(line)
open_tags = []
PURPOSE
serializer_class = UserSerializer
user_ajax_obj
type(-maxint)
print(n)
print(foo, bar)
len(self.__deque)
print(dt)
y = zeros(1, length(x))
A[:ph, pw:2 * pw]
syntaxtree = []
~1
a
df.ix[df.index < r[0], ix] = np.nan
btn2.Bind(wx.EVT_BUTTON, self.Onmsgbox)
condition[:-1] != condition[1:],
file = sys.stdin
_, ret = np.unique(b[c], False, True)
ax < -c(-10, 10)
frobnicate(foo + bar, baz * quux)
xy += np.random.random(xy.shape) - 0.5
a
R[k, k] = r
previous_vals = set()
flash(message)
MIN = 1 - MAJ
new
setattr(SurveyInstanceForm, question.backend_name, field)
gline = g.gi_code.co_firstlineno
print(data_mean)
-sum([(p * math.log(p, 2)) for p in samples_probability if p != 0])
a2 = cnp.PyArray_SimpleNewFromData(2, [2, 5], cnp.NPY_FLOAT64, a1)
print(date_time, url)
cookieValue
tim.userprofile.follows.all()
K = int(np.floor(patch_size / 2.0))
game = play_game(initial)
string_goodness
data = {}
(x ** m) ** n
caller.assert_called_with(Any(int, str), Any(int, str))
db.flush()
print(line)
[]
y = 2 >= x
indices = np.zeros(4, dtype=np.int)
file.name = slugify(myfile.filename)
exif = piexif.load(path)
socket.gethostbyname(i.strip())
T = A - B
0
x = p.lib.stride_tricks.as_strided(A, shape=(2, 2, 2, 2), strides=strides)
thread.join()
true
acted_on = act_on_array(a)
result = self._square_root(number)
0 - 0.548275
pygame.mixer.pre_init(44100, -bits, 2)
diff[diff > 0] = -np.inf
self.push = self.append
r + 2 * b
expr
web.cookies()
print(team([90, 200, 100]))
file_contents = eval(file.readlines().pop(0))
len(a)
merged_one = False
print(classify(data))
matches = []
recur(tree)
tf.logging.set_verbosity(tf.logging.INFO)
rolled
d[1]
receive_newsletter = model.BooleanField()
_servers.py
True
py > ast.body[1]._fields
end = datetime(2012, 10, 6)
create_connection(Protocol)
1
+1
proxy = ifstream_proxy()
x, xy = X(), XY()
min_num = 1
counter += 1
time[x] = time[x] + time[y]
reset()
lChannel = lConnection.channel()
my_options = copy.copy(my_class._meta)
ret = func(*args)
final_mask = mask2[1:] > mask2[:-1]
df
a, b, c2
user
df
a = a[:, k:]
Py_DECREF(fun_args)
start = time.time()
si(k, v)
print(loader.load_item())
timeit.timeit(code, number=1)
canceller = Canceller()
sub.connect(url)
files = glob.glob(archive)
print(database)
tmp = list(range(N))
datetime(2000, 2, 8),
dflist.append(group)
y2 = [1, 0.859, 0.812, 0.774, 0.746, 0.721, 0.718]
final_image[..., (2)] = arrImage[..., (2)]
q.all_tasks_done.notify_all()
Y = integrate.odeint(dY_dx, Y0, t)
self.set_status(400)
fields = bnf.searchString(tmpStr)
g.ax_joint.cla()
result = SomeComplexModel.objects.all()
Gtk.FileChooserAction.OPEN,
out = np.zeros(N, A.dtype)
s
print(res.getheaders())
type.__new__(cls, name, bases, dct)
logOutput.insertPlainText(text)
spot_instance_request_ids = [sir.id for sir in spot_instance_requests]
InstanceAttributeDocumenter.add_directive_header = iad_add_directive_header
a_inds, b_inds = map(list, zip(*product(list(range(len(a))), list(range(len(b))))))
new_body = response.text.encode(self.encoding)
images = []
getattr(self, fieldname, self._default)(value)
dict_[sublist[1]].add(sublist[0])
row[-1].style.borders.right.border_style = Border.BORDER_THIN
root = Tkinter.Tk()
a = []
x -= 1
total += array(row)
print(i)
SYNCHRONIZE = 1048576
s = df.to_html()
docinfo = tree.docinfo
root.mainloop()
y = int(number[i])
self.__dict__
print(user)
version = distutils.msvccompiler.get_build_version()
key = lambda x: x
tuple(decoded_secrets)
addtwo = a + b
pprint(di)
report_encoded = base64.b64encode(short_report.read())
0
self.ctx.detach()
myplot(x, y)
rows = df.values
ifargs = iter(fargs)
unequal_pos = np.where(arr1 != arr2)
obj._name = name
print(i, p)
scrapy < command > [options][args]
data = stream.read(chunk)
--delete_old_stuff_task.py
c = list(range(0, 10000000))
nsqrt = np.sqrt(A.shape[1])
x = list(range(1, 200))
print(id(x) == id(y))
print(month)
session.get_decoded()[SESSION_KEY]
is_sys_imported = False
offset = random.randrange(0, num_images)
grades = np.random.random((4, 2))
print(time.time() - n)
np.bincount(a.flat)
--foo_report.py
print(a.str)
file_ptr.write(your_new_line)
f.close()
repo.heads.master.checkout()
roundline(screen, color, e.pos, last_pos, radius)
values
print(s)
text
procs.append(p)
end_date = obj.end_date
angle = math.pi * 2 * k / N
print(len(W))
db = session()
base_url + str(method)
last_guess = guess
size = sys.getsizeof(obj, 0)
required = False
totalfreq[w] += 1
tooth
print(record.alignments[0].hsps[0].expect)
i = -n / 2
upper_bound = file.tell()
arr = np.column_stack((lat.ravel(), int.ravel(), val.ravel()))
7 - 0.509
per_row = []
assert golden.read() == trial.read()
myseries_two[0]
init_scheduler()
exec(cmd)
sheet[cell].font = fontStyle
print(all_mod)
print(time.clock() - t1)
loop.run_until_complete(asyncio.gather(*tasks))
---------------_
answer.append(low + rand(0, tot) * (high - low))
(length - cycles) % 2 == 0
t0, t1 = Test(1, 1), Test(1, 2)
results.append(cell_contents)
this.length / (this.point_count + 1)
x, y = ob.xy
stop = False
AmountInfo(name, symbol, value)
print(get_permutation(l1, 20))
print(t.timeit())
res
mean_confidence_interval(a)
crawledLinks = set()
root = Root()
transformblit(tri1, tri2, im100, im250)
shared_x = theano.shared(train_set_x)
default_permissions = ()
print(ord(currency))
width = len(text) * aspect_ratio * fontsize
n_m_j_k[m][j][k] -= 1
writer.save()
going = True
cd = form.cleaned_data
d
self.accept()
response = multiple_tries(func, 2, RequestException)
self.value = value
df2
Foo.CLASS_PROPERTY = 2
fileHandler.setFormatter(logFormatter)
proxy.GetCursOnDate(On_date=input)
result[d, h] += 1
ln = len(row1)
columns = cursor.description
a.f = lambda x: 2 * x
print(myObject.myVar)
print(i6.inf)
soln[midpoint, midpoint] = 1
parsed = tree.parseString(sample)
trueList, falseList
print(str_display)
numBins = 10
currentForm += 1
out[mask] = np.concatenate(v)
count = len(first) + len(rest)
df
logger
car = np.array([0.6, 0.9, 0.5])
network = [[0] * cnt] * cnt
file = []
eval(args)
txt.append(DIRECTIVES[name])
n = 2
lengths_ = data.Before.map(lambda x: len(x))
np.set_printoptions(linewidth=w - 5)
hash(y)
sample = lambda sub_df, i: sub_df.sample(sample_sizes[i], *args, **kwargs)
eq_y = (P * x + Q - y(x)) ** 2 + S * x + T
__builtin__.foo = 1
t - np.array([len(set(r)) for r in rand])
a = A(10).__enter__()
Http404
tip = self.lc.GetToolTip()
num
display = Display(visible=0, size=(1024, 768))
0
file_id = hashobj.digest(), os.path.getsize(full_path)
is_ok = np.zeros(np.max(b_vals) + 1, dtype=np.bool_)
inverted[v] = k
tree.write(sys.stdout, xml_declaration=True, encoding=tree.docinfo.encoding)
k.index(s)
print(line1.distance(pr) == 0.0)
new_image = cv2.warpAffine(image, rot_mat, (col, row))
result[count] = np.sum(part_data[mask]) / np.sum(mask)
result = job.apply_async()
delta = datetime.timedelta(microseconds=int(webkit_timestamp))
print(i)
r
r = abs(4 * np.sin(2 * theta))
self.date = date
application = redirect_from_appspot(application)
cntdiv += 1 + (i * i != x)
print(foo)
print(stdout.readlines())
cmdclass = {}
a = a[:]
print(str1)
print(entry)
buffer = StringIO.StringIO()
Third
log.msg(msg, level=log.DEBUG, spider=spider)
negative_case(param)
files = []
perms = []
FT_01_LB = PyLint(basic)
g.setBrush(QColor(img.pixel(20, 20)))
stop = -len(word) - 1 if step < 0 else len(word)
[run]
data2 = np.dot(L, uncorrelated) + np.array(mean).reshape(2, 1)
success = False
whatever()
res = {}
print(x.strides)
self.log_lines = log_lines
jquery.js
rows = [Y[chunk][row] for chunk, row in indices[i:i + newchunksize]]
traceback.print_exception(exception_type, value, tb)
decorated
cast(v.vendorName, c_char_p)
results = []
sum_
a = np.zeros(166400)
response = orig_HTTPAdapter_build_response(self, request, resp)
testfile.close()
k.get_file(f)
count = 0
appointments = someFolder.Items
self.state = self.celery_app.events.State()
False
myvars = {}
initialisers = [foo, bar, baz]
ret = a.x < b.x
self.age = age
merged_one = True
sB = B.sum(0)
matches_list = date_reg_exp.findall(test_str)
anydate = datetime.date(2001, 1, 1)
tst = TestExecution()
lineno, colno = linecol(doc, pos)
self.key = self.generate_key()
fig = plt.figure()
gw, gz = w, z
mask = binary[y:y + half, x:x + w]
current_set.add(symbol)
mylist = sorted(mylist, key=get_field_sub)
PAGER = True
obj = someobject
u = numpy.random.normal(size=R.shape[0])
maks_length = 0
library(gtable)
hot_list.append(0)
args[i + 1] = fmt.Sprint(v)
self.threads.append(ErrThread(**t))
os_handle = mkstemp()
zout.close()
scale_line = np.ones(lastx - firstx + 1)
readdir_r.argtypes = [c_dir_p, c_dirent_p, c_dirent_pp]
self.canning_machine.can(name, attrs)
x + y
print(res)
dt.timedelta(hours=word_to_int[num])
dateNullBlank = models.DateTimeField(null=True, blank=True)
str(self.object)
A[0][1] = 5
flat(d, out)
d[i] += j
objects = QuerysetMock()
print(b)
raise
X, Y, Z = grid(x, y, z)
field_class = forms.ModelChoiceField
d
b = []
choices = np.zeros((n,))
print(a)
angle = math.atan2(dec, ra)
query_point = X[0]
mydata.ParseFromString(lob)
8
code = pickle.dumps(foo.__code__)
self.pidfile_timeout = 5
st.isdisjoint(v)
l1[len(l1):] = [l2]
self.received_buffer.truncate(0)
[]
y = adj1 * np.power(x + adj2, pw)
cd / usr / local / bin
v = Cube(vp)
i = 0
ldawordindex[ldatopics[0][i][1]] = i
multiline_r = redistribute_vertices(multiline, 100)
rdata.update_one(pull__webpage__image_list=image)
fileobj = tf.extractfile(entry)
result
a[n] = False
print(d)
active = Column(Boolean, default=True)
poller.register(subproc.stdout, select.EPOLLHUP)
bins = np.insert(bins, 0, 0)
self.buf = StringIO()
parser.formatter.max_help_position = 50
pc = p[j]
foo
avg = datapoints[0:5, (0)].mean()
self.n = n
sorted_arr = arr[(np.lexsort(arr.T)), :]
master, slave = pty.openpty()
total -= 1
ret
B_mean1.append(B)
pause
buffer = buf_from_mem(c_pointer, arr_size, 256)
foo = Foo()
request.META = fake_meta
object.updated_date = now
False
doc = LH.fromstring(content)
print(recursively_apply(example, replace_chars))
user_lat > this_lat - phi and user_lat < this_lat + phi
intersect_AB = A.intersection(B)
lst2 = list(range(100))
dfdp = [1 - np.exp(b * x), -a * x * np.exp(b * x)]
d.addCallback(context.succeeded)
y = [math.sin(degToRad(theta)) for theta in thetaList]
idx = A.searchsorted(target)
start = timeit.default_timer()
ingredient_list = []
lst.append(row[0].toPython())
C = C[C[:, (2)] != 0]
self.number = self.store.customer_number
next_move(n)
alpha = random.uniform(0.0, 2.0 * math.pi)
print(f)
0, item
fig = pie[0].get_figure()
graph[v2].append(v1)
aff = proc.cpu_affinity()
a
mpz_mod(base, base, modulus)
print(x)
book = xlrd.open_workbook(path)
dset.resize(dset.shape[0] + 10 ** 4, axis=0)
-10
b = 2
text2, numReplacements = re.subn(pattern, repl, text1)
sender = self.sender()
print(params)
lat = -lat
distances_as_2d_matrix = squareform(distances)
s1 * s2
datanew = numpy.array((r, g, b))
src_set = set(src_seq)
visible_rect = textview.get_visible_rect()
province_code = db.StringProperty()
closing(inner())
axis = 1
x, y = y, x
full_index = df_starts.index.union(df_stops.index)
parentNode = element.parentNode
y = x + 1
regular_sequence = np.arange(n_reg, dtype=np.int)
outputFile.write(chunk)
flist = []
1.5 < a
x2_Kcids_1.shape = shape
w.writerows(row[1:12] for row in r)
aws_secret_access_key = Zxxxr
aws_secret_access_key = CxxxZ
(value + HALF_N) % N - HALF_N
sp1 = matplotlib_fig.add_subplot(121)
object_id = indexes.IntegerField()
millisecs = int(jd[6:-7])
load_put_and_files(request)
-flat_namespace
plot(X, Y, color=c)
goMiss = True
es_nginx_d = dict(zip(es_fields_keys, es_fields_vals))
fmt_values
GetDriveType.call(path)
data = base64.b64decode(base64_encoded)
print(template.format(*l))
model = Person
hm = cm.ax_heatmap.get_position()
sparsity = 1
print(fname)
data = [1, 4, 5, 6, 10, 15, 16, 17, 18, 22, 25, 26, 27, 28]
tuple_array = ctypes.cast(array.data, ctypes.POINTER(FFITuple))
results
m = n + 1
t_no_opt = min(timeit.repeat(f_no_opt, repeat=10, number=10))
self.env = EnvironmentVarGuard()
start = lst2.index(item, start) + 1
found
m.update(buf)
self.write(line)
request.param
False
records.remove(d)
pts = np.random.random((N, 2))
dt = datetime(1970, 1, 1) + timedelta(seconds=timegm(utc_time_tuple))
ConfigParser = configparser.ConfigParser
params = {}
f = inspect.currentframe(1)
file_list = []
min, sec = divmod(int(sec_past_hour), 60)
ccomph = bwlabel(regmxh, 8)
names = name_addrs.ctypes.data_as(ctypes.POINTER(ctypes.c_char_p))
x = 100
i = float(temp_string)
parser = ArgumentParser()
traceback.print_exception(ty, er, tb)
newWord += char if word1[s] == char else word2[s]
xy = x[:, :, (newaxis)] * y[:, (newaxis), :]
parser = optparse.OptionParser()
list_index = -1
self.X = []
b = utf8_byte_truncate(s, m)
ap = argparse.ArgumentParser()
self.cert = cert
print(time.time(), next(locker_cli))
6 - 1.404 - 0.907
pos = masterList.index(min(masterList))
plt.legend()
a != 0
x = 4
jb_hypernyms = jb_sense.hypernym_paths()[0]
xs, ys = itertools.tee(a)
ys = Y.reshape((nx * ny, 1))
plt.close(1)
self.create = lambda : f(*a, **k)
alphabets = [alphabet] * i
k = 1
found.append(pattern[:cursor])
font = logOutput.font()
e = 4, 5
i += 1
stat64.argtypes = [c_char_p, POINTER(struct_stat64)]
new_lists = []
b = qrw.getBounds()
self.trd.join()
a_list
peak_counter += 1
e = Example(1)
True
print(2 * p - p.ceil())
nb = b.shape[0]
Terminated
print(numsum)
output_buf_size = 0
putter(q)
startpos = 0
int(num * prefix[letter])
i, node = min(enumerate(child_nodes), key=itemgetter(1))
data_quantized = data / (1 << 8)
keys, values = zip(*list(machines.items()))
print(path)
workers = [mp.Process(target=f2, args=(inq, outq)) for i in range(2)]
args = []
r = [[int(float(i)) for i in l] for l in fread(fname, cond)]
ret
PROCESS_SUSPEND_RESUME = 2048
results = simplejson.load(response)
catalan_1 = make_catalan()
n = n + 1
-1
xlong = np.repeat(x, weights, axis=0)
simulations_to_run = Queue()
send_over(k, v)
self.vtkPolyData = vtk.vtkPolyData()
id(Out[7])
all.append(obj.__name__)
score, jac
d_max = {}
result = []
heapq.heappush(self.heap, item)
y = np.asarray(y)
n1, (n2, dist)
match_cache = {}
x[:] = np.where(mask, np.nan, r * np.cos(t))
ax2 = fig.add_subplot(2, 1, 2)
fi = fitting.LevMarLSQFitter()
result = job.apply_async()
assert_equal(s.randint(1000), 684)
a = -0.0
ts_delta = values[1][0] - values[0][0]
np.multiply.reduce(np.ix_(*vs))
readme = f.read()
eagles_first_parts = [eagle[0] for eagle in eagles]
shared[:] = numpy.random.rand(1, n)[0]
post_init.connect(MyModel.remember_state, sender=MyModel)
start = clock()
view.setViewport(QtOpenGL.QGLWidget())
5 / 6.0
obj
m = modulegraph.modulegraph.ModuleGraph()
quote
p.ray(x=[0], y=[0], length=0, angle=0, line_width=1)
pd.Series([row.A, row.A / 2])
t = struct.unpack(fmt_mapping[oct_len], oct)
action_df.where(action_df.timeStamp > cut_off_str).show()
set(more).issuperset(less)
print(ScreenRes.get_modes())
p.draw(g2)
raise ctypes.WinError(result)
hWnd = pythonapi.PyCObject_AsVoidPtr(self.videoWidget.winId())
args.update(inputs)
df = DataFrame(index=rows, columns=cols)
print(dd)
scan_generator = MyTable.scan(max_results=10, exclusive_start_key=esk)
event_base = ctypes.c_int()
lcmap = [cmap(i) for i in range(cmap.N)]
WRITE_DAC = 262144
False
self.left = left
new
Person.drop_collection()
client.on_message = on_message
wrapper
self.begin = now()
new_index = pd.MultiIndex.from_product(df.index.levels)
y_hat.append(pred_y)
l = lognorm(s=sigma, loc=0, scale=math.exp(mu))
self.events = collections.deque()
print(data.stuff)
text = usertext[2:-1]
parents.append((currentDict, level))
s = SequenceMatcher()
Builder.load_string(kv)
scheme = urlparse(self.url).scheme
groupings = create_groupings(5)
print(df)
pickled = pickle.dumps(list_pickler)
self.output_file = output_file
assert indata.size == outdata.size
has_other = False
name = cell.value
0
student = students[i]
i = L[mid]
total_size = os.path.getsize(filename)
indexes[x] = idx
(amp2, freq2, phs2), pcov = optimize.curve_fit(sineFit, tDat, sub1, guess2)
i1 += 1
ans.append([s[i:]])
self.pop_up.dismiss()
cols = mon_db.collection_names()
objects = gc.get_referrers(obj)
self.__visitName(node.node)
data = str(structure)
permute_columns(x)
yamlData = yaml.dump(obj)
instance.__class__ = Wrapper
a = A()
update_slot(type, name)
dict_intersection = dict(set.intersection(*sets))
print(Blues(1.0))
fn.ABS(cls.length) / 2
w.append(fd)
msg_printer()
message
stdout, _ = pipe.communicate()
rv = Sqrt(term)
print(group)
x, y = int(max_loc[0]), int(max_loc[1])
p *= 2
xmin, xmax, ymin, ymax = px.min(), px.max(), py.min(), py.max()
pl.subplots_adjust(0.04, 0.1, 0.96, 0.94, 0.1, 0.26)
cut_insignificant_digits(obj, places)
sys.stdout.write(part)
theta[i] = w[i] + K * coup_sum / float(N)
a1_edit = QtGui.QLineEdit()
current_depth = max(current_depth, self.right.depth())
print((a2.flags.owndata, a2.base))
n = d.shape[0]
d.feed.title
X = hdfpivot.columns.levels[1].values
div.appendChild(scriptNodes[i].cloneNode(true))
N = 100
f(2.1, sorted_list)
scalar_field = np.array([(x * y) for y in y_axis for x in x_axis])
pyplot.imshow(np.flipud(Pxx_dB), extent=ex1)
primes = []
sortedlist, splits = merge(left, right)
contents = f.read()
word
p
i = random.randint(0, 99999)
options = {}
arr
second_mask[mask] = np.random.rand(masklength) < prob
register = template.Library()
----urls.py
thing = values_pointer[:values_size]
final_image[..., (0)] = arrImage[..., (0)]
visitedUrls.Add(nextUrl)
n1 = n0 + 1
year2students = defaultdict(list)
Y[2] = C
excel = Excel.ApplicationClass()
self.data = key
num += 2
FOX
ws.PageSetup.FitToPagesWide = 1
freq_dict = defaultdict(int)
done.add(cname)
new_dc_files = list()
Source(text)
print(m_list)
cols = row.split()
counter = 0
instance.work.attachment_count += 1
M = max(p)
d[nan2] = 2
bp = P.boxplot(data)
ax = fig.add_subplot(111)
res = urlfetch.fetch(url, method=urlfetch.GET)
print(item.url)
v = 1 + x - y[:, (np.newaxis)] ** 2
w = x.map(weights)
win = gtk.Window()
Y = np.maximum(Y, eps)
model = PunktSentenceTokenizer(punkt.get_params())
d.sqrt()
a.append(word[i:i + j])
hello
aux = trainer.train()
count
OPTION_A = 1 << 0
DEBUG = True
keys = set(dict.keys())
t1 = time()
this_code_is_always_executed
print(x)
qImage.setPixel(x, y, qRgb(r, g, b))
a
font.cbSize = ctypes.sizeof(CONSOLE_FONT_INFOEX)
tokenizer.train(text)
a[ix_(Xinds + 1, Yinds)]
outmask = (1 << obits) - 1
theList = list(range(10))
rootlen = len(target_dir) + 1
pool = Pool(processes=fishes, initializer=init)
validity_check(value)
tf.gather(input_as_vector, coordinates_as_indices)
current_time = datetime.now()
a = arange(25).reshape(5, 5)
i += 1
perm_list = []
timer.start(1000)
result_dict
M[int(home), col] = 1.0
stdout, stderr = ps.communicate(input=pdf_content)
set2 = set(el[0] for el in list2)
al[mask] = 0
0, a, a, c
l = []
combined = [x for y in comb for x in trans.pop(y, [y])]
n.parent = Find(n.parent)
assert len(result) == n
self.vals = []
q, r = divmod(q, 10)
ymin, ymax = ax.get_ylim()
style = xlwt.XFStyle()
x = x[index]
data = pandas.read_excel(infile)
rsrcmgr = PDFResourceManager()
readdir.restype = c_dirent_p
get_name()
MB_OK = 0
lst = os.listdir(whatever_directory)
type(x)
DBSession1.configure(bind=engine[0])
ipshell = IPShellEmbed()
clone
data = resource.read()
self.speedTestForRecordType(Subscriber)
p = canvas.Canvas(response)
fourgrams
membership = clusters.membership
N = 100000
print(cls, cls.PARAM)
buf = StringIO.StringIO(msg)
2
print(item)
X = np.arange(len(d))
arr = np.asarray(image)
print(doc)
test = 0
a = -5
(amp2, freq2, phs2), pcov = optimize.curve_fit(sineFit, tDat, sub1, p0=guess2)
print(name)
df = pd.DataFrame(data_iterator(path))
stuff_obj.execute()
p90 = np.percentile(a, 90)
axis([0, 80, 0, 120])
-db
e.args
result[last] = []
print(list(y[0]))
rand = random.random()
fittedvalues = data[:, (2)]
mydatabase = dict()
t2.join()
a.desc
print(i)
canvas.tag_click = False
dc = DesiredCapabilities.HTMLUNIT
names
l = []
k_trend = res.k_trend
sidx = L.argsort()
open = codecs.open
index_name
df
p = Person()
options = [i for i in commands if i.startswith(text)]
self.update(keyvalues_iter)
x = x[x >= 0]
uniqWords = sorted(set(words))
s = np.sum(val, axis=0)
namespace = frame.f_globals.copy()
X = sm.add_constant(np.column_stack((ele, X)))
self._paramMap[self.stopwords] = value
bottom_right = 100, 100
self.f = f
self.__flags[:]
print(R.units)
testDict[key] += val
print(1 + a)
print(url)
self._session = session
print(parser.files)
login = os.getlogin()
field_names_go_here = models.TextField(max_length=70)
monoChannel = y1.mean(axis=1)
page0 = input1.getPage(0)
a = A()
self.canvas.particles = particles
serial_no = fields[10].strip()
data = numpy.random.gumbel(2 ** 20, 2 ** 19, (1000,))
count[i] += 1
plotdat = np.sum(density, axis=1)
GPIO.remove_event_detect(7)
--Comment
res.append(A)
u = -1 - x ** 2 + y[:, (np.newaxis)]
p_help.set_defaults(func=help, parser=parser)
[1, 1, 0],
sl.append(l.pop(l.index(min(l))))
5
paths = defaultdict(set)
m.optimize()
self.y = y
counter = 0
data_new[np.in1d(time_new, time)] = data
inf = Decimal(1) / Decimal(0)
print(columns)
[]
one_minute_ago = time.time() - 60
k = Key(bucket)
res = 0
print(data)
print(self.data)
stack = []
vars(X)
b = mylist
ret.resize(len(ret) + len(tmp))
stopwords = self.getStopwords()
results = []
x = math.e
next(chunks)
pdb.gimp_image_undo_group_end(img)
loop_ok = False
dictionary[section] = {}
cur_list = []
connection = Connection()
status_line = hdr.getvalue().splitlines()[0]
b = localClosure(1)
[x for x, k in zip(seq, key) if not (k in seen or seen_add(k))]
p1i, p2i, size = sm.get_matching_blocks()[0]
tid = H5Tcopy(H5T_C_S1)
raise Exception
print(df)
ex[::-1]
cppcode.init(address, port, en_msg, error)
dir(Protocol)
bit = []
hosts = {}
Plain_text
_.value
sys.stderr = NullWriter()
int(o)
self.label.setWordWrap(True)
args = iter(args)
to_my_linking(a)
context = 20
state = db.inspect(target)
new_variable += variable
args
band = dataset.GetRasterBand(x)
y = m * x[:, (np.newaxis)] + b
f()
self.whenChanged()
index = -1
tokens = Entry.parseString(my_string)
start, end, path = queue.pop()
self.configs = configs
sizes = []
fd = os.open(filename, os.O_RDONLY)
db_dict = {}
b = 1
cr.set_source_rgb(1.0, 0.0, 0.0)
p, q = submat_shape
B = np.expand_dims(B, x)
sorted_no_zeroes = [sorted(r, reverse=True) for r in no_zeroes]
df = df.append(df)
reduceF,
indices = [1, 2]
recursiveAssertAlmostEqual(testCase, a, b, *args, **kwargs)
id = threadlocals.get_current_product()
L = grow(K, E)
item = MyItem()
lines = statemachine.string2lines(data)
pixbuf = gtk.gdk.Pixbuf(gtk.gdk.COLORSPACE_RGB, False, 8, width, height)
False
retry = False
splitIndex = bisect.bisect(translatedList, pos[0])
parm = parm.strip()
exc_type, exc_value, exc_traceback = sys.exc_info()
c = 0
f = Foo()
item.pid, item.aisle, item.bay, item.hits
points.push_back(p)
y = x[:i] + c + x[i + 1:]
tb = Table(ax, bbox=[0, 0, 1, 1])
pname = PyString_FromString(name)
points = itertools.chain.from_iterable(points)
helloworld
closedir = c_lib.closedir
students = collections.defaultdict(list)
nav_b64 = base64.b64encode(nav_json)
stream = cv2.VideoCapture(filename)
driver = init_phantomjs_driver(service_args=service_args)
reps = 5
h, w, d = foo_np_view.shape
print(partial_k(f, 2, [0, 1])(10))
False
a
d1.shape
caller_frame = inspect.currentframe(1)
c = Constraint((x > 10) | andalso | (x < 19) | orelse | (y < 0))
jointProbs /= jointProbs.sum()
count += 1
header = rdd.first()
t = Template(template_source)
print(kwargs)
thread = threading.Thread(target=create_show)
B - 0.678886 - 0.094709 - 0.678886 - 0.094709 - 0.678886 - 0.094709
ax = fig.add_subplot(111)
pModule = PyImport_Import(pName)
module_init()
print(df)
p.communicate(input=cert_pem)
Session = scoped_session(session_factory)
v = node.get_data()
cur_pred = clf.predict(X.iloc[(valid_idx), :])
self._flags[key]
func_code.co_stacksize, func_code.co_flags, func_code.co_code
iter(self._d)
model = QFileSystemModel()
x % 2 != 0
zoomingBox(axs[1, 1], [40, 60, 0.1, 0.9], axs[0, 0])
print(cn2.wholeText)
new_name, old_name = line.split()
t.setProgress(x + 1)
foo.bark()
data = {}
tmp
y_pandas = pandas.DataFrame.from_records(y_np)
tokens = nltk.word_tokenize(f.read().lower())
a2_edit = QtGui.QLineEdit()
src = f.read()
print(max((space_sum(v), v) for v in permutations(L)))
a + b
orig_HTTPResponse__init__(self, *args, **kwargs)
summands.discard(x)
sc = scorm.objects.filter(Header__id=qp.id)
x = 0
choice = random.choice(N, N * percent)
ret[i] = nd.Derivative(fg)(input[i])
y = pickle.loads(s)
result = handler(dict(self._environ), self._StartResponse)
sqrDiff = (a[:-1] - a[1:]) ** 2
tableWidget = QTableWidget()
vote1 = x[1]
stuff = [this, that]
b, p, sum = [True] * (n + 1), 2, 0
0 % 48
loader.write(contents, len(contents))
inner
table.selectRow(row)
new_key = word_counter_dictionary[key]
axicon = fig.add_axes([0.07 + 0.11 * k, 0.05, 0.1, 0.1])
(date - start_date).days // 14
f(**data)
p = ArgumentParser()
sigma_e = np.sqrt(sigma ** 2 * (1 - corr ** 2))
nexts = cycle(iter(it).__next__ for it in iterables)
g2 = ((x, y, round(float(list1[x]) / list1[y], 2)) for x, y in g1)
values = np.array(values)
System.out.println(ast)
intersected = set(range(first, second + 1))
myShelve.update([(str(record.id), str(record.seq))])
getGreenFoos()
iters = map(iter, args)
self.queue.append(item)
f2 = np.round(f2 * scale) / scale
x += 1
zip_list.append(zip([i], [j])[0])
sockets = Sockets(app)
type(h)
df
menu_bar = Menu(root)
somList.append(chr(b))
a = Foo()
a is b
unit, value = next(iter(kwargs.items()))
--help
completion.set_text_column(0)
html = HTML(string=htmlstring)
self.fields = {}
server_side, cert_reqs = cert_reqs, ssl_version = ssl_version, ca_certs
mymodule.py
print(cows)
colors = cmap(np.linspace(0, 1, len(centers)))
colconvol
df[df < 1] = 0
C[0::2] = A
system_uptimes = execute(_get_uptime)
l.set_markerfacecolor((1, 1, 0, 0.5))
signal.SIGINT.name
dy = dys.mean()
df
json_data = request.get_json(force=True)
i += 1
data = [(random.random(), line) for line in source]
a == b
cntr = len([i for i in os.listdir(DIR) if image_type in i]) + 1
d_out = {}
Quartz.CGImageDestinationFinalize(dest)
length = len(frag)
creds = {}
x
self.value * self.multiplier
print(opt)
mydocs = shell.SHGetPathFromIDList(pidl)
stuff_i_dont_want_to_see()
log2(finfo(float64).resolution)
instrument(orig)
dims = np.asarray(list(itertools.permutations(list(range(4)))))
test_suite
same_list.append(4)
seq[i] = 0
spec.defaults
a = 4
handles = handles[1::2]
i = 2
list.add(2)
cb = Call.create()
newdict = defauldict(int, d)
assert_frame_equal(df, expected, check_names=False)
im_bw = cv.threshold(gray, thresh, 255, cv.THRESH_BINARY)[1]
t1 = lambda : map(str.strip, hello)
l = l + [1] * size
get_matrix.__doc__ = Affine2DBase.get_matrix.__doc__
fig = plt.figure()
shape = image.width, image.height
print(key.name)
memc.set(KEY, buff, TIME)
foo - (1.2).tar.gz
redis_pub = redis.StrictRedis()
palin.append(i)
df
results.extend(aux)
classform.students.append_entry(studentform)
s, i = capture.read()
dlen = len(data)
lst
Person
d[i] = str(i)
nodelist.append(node.cargo)
False
sampleCategory([0.1, 0.5, 0.4])
bin_string
print(value)
print((r.OneColumn, r.OtherColumn))
x % 2 == 0
a = 1
divmod(+0.0, 100)
num_words = max(num_words, 40)
i = a_len * (k - 1) // (a_len + b_len)
matches
wordPattern = re.compile(pattern, re.IGNORECASE)
print(f.__code__.co_consts)
result = []
memory_size = getsizeof(RF_model)
Table = []
heapq.heapify(listForTree)
doc = fromstring(data)
print(postsort)
credentials = get_credentials()
print(df2.mask(mask))
a = []
1
self.name = name
lower = string.ascii_lowercase
prefix = s[:prefix_len]
Foo()
counter = 0
b[x - 2] = 1
group = parser.add_mutually_exclusive_group()
self.retry(exc=exc, countdown=2 ** self.request.retries)
loader.write(contents)
d = MyDict(my_global_base)
W = scipy.optimize.leastsq(errorfn, init_W, args=(M, S))
plt.scatter(dates, values)
print(r.text)
xi = x.astype(int)
formatter.add_text(self.epilog)
json_update
x0 = max(0, x - r)
XX = X.reshape((1, X.size))
test.truncate(0)
df = df_try
engine.signal_handler.subscribe()
ba.extend(m)
paths.append(path)
data = mixture.DataSet()
movie.formats.append(format)
a = a + 1
G = nx.drawing.nx_agraph.to_agraph(G)
result.left.add(n1.accept(this))
first = today.replace(day=1)
valid = bool(found_s) and found_s[0] == s
ret, frame = video.read()
arr1[0].ctypes.data
volume_radius_10 = make_cylinder_volume_func(10)
it = iter(seq)
self.f = f
xvals = np.arange(199.9, 999.9, 0.1)
tf.add(path, arcname=arc_path)
aux
a = b
deletecmap[subcommand]
begin = 0
print(df)
maxnorm
unique = False
entities = EntitySerializer(many=True)
new_result[:, :, (d)] = ndimage.map_coordinates(im, coords, order=1)
database = db
a, b = 0, 1
urlunparse(parts._replace(path=new_path))
d
source_vertex_id = edge.source
pp = MyPP()
False
one = 1
sin = numpy.sin
it1, it2 = itertools.tee(iter(s))
self.value = value
excel.Workbooks.Add()
p = l[1:]
corpus = corpus.lower()
_, p_b = scipy.stats.ttest_ind(df_a.dropna(axis=0), df_b.dropna(axis=0))
to_ret = dict(layer)
digest = md5.new()
x = np.sqrt(r) * np.cos(theta)
msg = MIMEMultipart()
-max_depth
d[istart.pop()] = i
msg_id = shell.execute(code)
PROCESS_CREATE_THREAD = 2
tp.die()
gtk_container_add(GTK_CONTAINER(parent), new)
print_arg(**mydict)
m = int(sys.argv[2])
chunk.to_sql(con=engine, name=table_name, if_exists=if_exists_param)
df_indexed = indexer.transform(df)
encoded_df = encoder.transform(indexed_df)
10
method, properties, body = channel.basic_get(queue, no_ack=True)
dir(e.orig.diag)[15:]
Group = ipynb
dates = []
entities.append(newProd)
C
X[right_idx] - X[left_idx]
form.email.data,
cols = np.arange(N) - col
user1 = tokens[0]
pth = os.path.sep.join(sys.argv[0].split(os.path.sep)[0:-2])
n % 100
distToA -= distToB
self.d.get(idx, 0)
height, width, _ = vtk_image.GetDimensions()
spp = sp.add_parser(cmd)
s
inter = Interleave(A, B)
rs = cursor.fetchall()
a = list(range(17))
key = RSA.generate(2048)
f
first = False
sex_is_one = test_rec.sex == 1
ctx = ssl.create_default_context()
host_status = False
df.head(5)
c.close()
url = url_for(rule.endpoint, **(rule.defaults or {}))
utcnow2 = pytz.utc.localize(datetime(2014, 1, 1))
self.skip(require_not_executed=True)
movie_means = np.nanmean(ratings, axis=0)
fesetround(r)
testme = lambda x: lambda y: x
a.b.c
T = array([arctan2(*x) for x in R])
tempdir = tempfile.mkdtemp()
self.a = np.array(aList)
scr.addstr(row, col, str, attr)
dictionary[k] = np.array(map(float, v))
Tkinter.mainloop()
s = count(q + 2 * p, 2 * p)
font_width, font_height = font.getsize(text)
pool = eventlet.GreenPool()
my_own_method.boolean = True
letters = [a, b, c, d, e]
string_goodness += letterGoodness[letter]
nbors
n = shape[0]
A = []
compilled_rules[scope][term] = re.compile(rule)
context = request.context
pos = ax.transData.transform(corners)
seq = np.zeros(lag_seq.sum() + n_iter * n_reg, dtype=int)
contents = f.read()
s = Session()
defaultdict = collections.defaultdict
d_sum[topkey] = dic2[topkey]
batch = next(batch_gen)
toggler = FullscreenToggler(window)
_session_data.allow_tags = True
root.withdraw()
pred = lambda i: A[:, i:i + 1] == B[:, (i)]
theta0[i] = random.uniform(0, 2 * pi)
robot_dict[key] = location, line
time_header.append(description)
f.bar
QSettings.setDefaultFormat(QSettings.IniFormat)
print(myclass.last_transaction)
print(me.json())
x = y = 1.0
bins = np.argmax(np.random.multinomial(n=1, pvals=probs, size=(size,)), 1)
print(pdDF)
z = x * np.exp(-x ** 2 - y ** 2)
self
self.invalid_response = invalid_response
a / b / c / d
1 / 0
working_slice = img.crop(bbox)
data[yi, xi]
above_threshold = gaussian_filter(data, sigma=sigma) > threshold
self
format(0.0)
n = (x ** 2 + y ** 2) ** 0.5
i1 = bisect.bisect_left(friends, (px - maxdist, py))
assert isinstance(fact, int), type(fact)
fp2_reader = functools.partial(fp2.read, 4096)
a = [makeFun(i) for i in range(10)]
sat = ephem.readtle(line0, line1, line2)
response.sendError(404)
False
buffer = zin.read(item.filename)
match = stree.find_substring(search)
threshold.SetInputConnection(extractSlice.GetOutputPort())
ground_truth = np.ones(n_samples, dtype=int)
b = BinaryUnderscorifier()
form
cache[n]
self.assertEqual(1, fake_increment.call_count)
JM1 = JM1.transpose([1, 2, 0])
ax = plt.subplot(cell)
time_epoch = time.gmtime(0)
x = next(it)
filenames = fnmatch.filter(filenames, ignore)
it = iter(lis)
current_seq_len = 1
n += num_increasing(ndigits - 1, digit)
outlist = [indexlist[0]]
c.list = list(range(0, 6))
a = list(range(10))
filename_base, filename_ext = os.path.splitext(filename)
transport = client.get_transport()
print(al[:, (10)])
paths
fixed_sum_digits(6, 20)
start_indices = [list(range(sh - width + 1)) for sh in data_shape]
grp1.id,
B1 = sympy.exp(-alpha1 * (r1_x ** 2 + r1_y ** 2))
new_month += 1
response
context = decimal.getcontext()
y = 1
socket.setdefaulttimeout(tm)
angle = getAngleBetweenPoints(2, 1, 1, 1)
p.put(task)
answer.append(L[i])
log4j.rootCategory = WARN, console
plt.show(1)
f.truncate(0)
d = sum(s)
child.stdout.pipe(process.stdout)
self.assertEqual(output, validated_output)
T = to_tree(Z)
output = {}
print(i[0], c[0].author, c[0].authored_date, c[0].message)
f[2000000] = 51
self.webview = WebView(activity)
deactivate
time_next_run = func()
left_column = 0
print(A)
shell = False,
self._int
url_adapter = app.url_map.bind_to_environ(environ)
True
wd.fooi(7)
iter(self.__keys)
some_func(value=value)
n = 4
parent_id,
counts = counts.cumsum()
ret = {}
names = []
print(resp)
unwanted = set(keys) - set(your_dict)
ss = min(ss, 59)
args, kwargs
mylist[j + 2] = i
logp = logp - logz
desired_content_is_loaded = true
char * shapename
val
major_formatter = FuncFormatter(my_formatter)
sout = list(s)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
original_errmsg = json.decoder.errmsg
below_paths = all_paths(r + 1, c) + all_paths(r + 1, c + 1)
id = fields.Int()
sys.stdout = old_stdout
form = forms[0]
pythonX.X - V
print(dfasdict)
divs = lambda x, y: x / y
body = f.read()
rowcount = db_crsr.rowcount
last_row = df.tail(1).index
hash[word] = 1
writeindices = [name2index[name] for name in writenames]
areas[cat] = np.hstack((last[::-1], next))
cv.EqualizeHist(grayscale, grayscale)
print(foo.bar)
xdat = np.arange(0, 90.1)
makes = DealerMake.objects.filter(dealer=dealer)
src = os.path.join(instdir, d)
position = QtCore.QPointF(event.scenePos()) - item.rectF.center()
x1.sort()
i + 2
datareader = csv.reader(gcs_file)
score(0)
dis.dis(t2)
False
result_array = x * original_array + y * shifted_array
self.value = value
twisted.internet.endpoints._WrapIProtocol,
new_dict = {}
scheme, netloc, path, qs, anchor = urlparse.urlsplit(s)
demo = AddIDemo([1, 2])
axcolor = fig.add_axes([0.91, 0.1, 0.02, 0.8])
filenames = self.zipfile.namelist()
2
print(s)
h(a)
pt = [8, 7]
fruits = re.findall(fruitdef, inputstring)
proxy = True
v = NP.r_[(0.2), 1:25:7j, (60.8)]
cax = plt.colorbar(mat, ticks=np.linspace(-0.5, N - 1 - 0.5, N + 1))
zip(a, b)
findPath(graph, key, next, end)
ret = test_method()
z = 5
r.withdraw()
print(len(s))
direction = data[1] - data[0]
camera_pos = self.camera_position(matrix)
Y_idx = Y_int - Y_int.min()
self.nodes = []
list = 2
B_rref = B.rref(iszerofunc=lambda x: x % 5 == 0)
bb.order(ByteOrder.LITTLE_ENDIAN)
rval = np.zeros((4, 2))
current = 0
A_lidx = np.ravel_multi_index(A.T, A.max(0) + 1).reshape(-1, array1.shape[0])
funcList.append(callback_factory(m))
include(CPack)
m[np.triu_indices_from(m, k=1)] = m.T[np.triu_indices_from(m, k=1)]
self.directory = dir
table = defaultdict(int)
security
X_test = vectorizer.transform(X_test)
root = xmltree.getroot()
overlappers = canvas.find_overlapping(x1, y1, x2, y2)
caseset = dict()
child.stderr.pipe(process.stderr)
result
self.buffer.write(data)
x + 2
dependencies = []
hot_list.append(1)
print(s.ratio())
print(data)
y = [0, 0]
self.symbol = symbol
data = []
print(server.supervisor.getState())
item = foo_list(i)
value = json.loads(value_json)
sorted_groceries[item.store].append(item)
print(result)
LHS, RHS = [(lh - rh) for lh, rh in zip_longest(LHS, RHS, 0)], [0]
print(elt.text)
False
system(fortran_mod_comp)
ip_img._repr_png_()
df
b = bytearray(len(b1))
c
imp.reload(uut)
D[k_new] = D.pop(k)
_MonkeyEmbeddingColumn(sparse_id_column, dimension)
tripledict = partial(defaultdict, partial(defaultdict, dict))
self.view = View()
N = 1.0 / 5
data[x + c, y] = 255
pattern = tuple(base[0:2])
dll.set_callback(callback)
msg.append(self.depth_symbol * self.depth)
countdown(n - 1)
thread.start_new_thread(kill_me_please, (httpd,))
penguins = []
m = defaultdict(list)
pca = PCA()
found and (best, n1, n2)
ioloop.add_callback(_defered)
false
self
t_series = hstack((t_series, record_t))
to_del = []
args = sys.argv[1:]
active_window_name
json_obj = json.loads(html)
self.d[v] = k
l = l + [0] * size
data = [[player.name, player.penalty(), player.score()]]
b = MyNumber(2)
other = stuff[:]
1
small_number = mp.besseli(400, 2)
[MASTER]
elem.tail = i
yourdata
batch_gen = generator(data)
d = Counter()
5
pool = []
input_filename = sys.argv[1]
job
other.value == self.value
print(elt)
timeit.timeit(f)
start_date = DT.date(2008, 5, 5)
df
z_chk = df.z.eq(df.z.shift())
split(input_image, split_image)
a_stop_i = min((a + 1) * a_chunk_size, nrows_a)
i = 0
models.py
x = linspace(0, 10 * pi, 2 ** 10)
output = {}
rows = []
datatype = row[0]
self.build(tag, l)
self.is_checkpointed = rdd.is_checkpointed
print(df)
[f.get_name() for f in formats]
s = pd.Series(arr, index=np.arange(1000000.0))
sess.get(url)
[group_name]
a = 5
temp = hashofthem(firsthash, secondhash)
Chocolate
theta = np.linspace(0, 2 * np.pi, 100)
raise User.DoesNotExist
search = wordslist[ndictionary:]
print(line)
is_authenticated = request.user.is_authenticated()
s
self.data.append(data)
divisor *= factor
self._buffer.read(size)
7 - 0.576197
out.handle[0] = arr.handle[0]
sample = [random.gammavariate(a, 1) for a in params]
sio = StringIO()
strides[increase_axis] -= strides[shift_axis]
y1, x1 = np.unravel_index(sort[0], result.shape)
self.panel.SetCursor(myCursor)
a == True, b == True, c == True, d == True
0
obj
old_a = a
charG = getch()
data
ret, thresh = cv2.threshold(gray, 50, 255, 1)
gamma, _ = lda.inference([bow])
ret = bool(pari.isprime(pari.gp_read_str(str(n))))
z = [True for p in range(x, y + 1)]
prevMatrix = matrixDict[thisM.index(max(thisM))]
d = d / n
y2 = y0 + -r * math.sin(a)
200 * exp(-T)
text = text.replace(match, rep)
lines = traceback.format_exception(exc_type, exc_value, exc_traceback)
2 | Loblaw, Bob | 2015 - 4 - 7
xy_data.append(temp)
chomp(v)
host_status = True
to_current = lines[:current_line_no]
one_segment = math.pi * 2 / sides
content = pdf.getvalue()
line.get_parse()
print(datenow)
background.draw(drawer.drawer)
numpy.genfromtxt = patched_gen_from_text
string.uppercase
c = wmi.WMI()
print(L[2])
l1 = np.array([1.9, 2, 2.1])
current = [s[0], 1]
my_func = makePoly([6, 2])
a[90:110] = 7
auth.get_or_create_user(form.vars)
requests.post = post_new
mObject = mPattern.search(uri)
f
t_opt = min(timeit.repeat(f_opt, repeat=10, number=10))
path / to / jar1.jar
max_count = char_counts[char]
Singleton._instance
id(a)
stuff()
stockInformation.append(newList)
othercommand | flipcase > output.txt
collection = con.db_name.collection_name
numpy.allclose(list(d1.values()), list(d2.values()))
urls.put(url)
x_intersect = x[:-1] - dx / (z[1:] - z[:-1]) * z[:-1]
expr = Piecewise((x, Eq(i, 0)), (1, True))
inner
pyplot.subplot(211)
print(item)
rows[:] = 255
unserialized = module.loads(serialized)
process = []
palette = []
train_likes_df.columns = train_likes_df.columns.str.strip()
pixbuf = loader.get_pixbuf()
self.h = h
name, email, phone_numbers
price_company = cursor.fetchall()
mo = matcher.search(s)
root = conn.root()
fig = pl.figure()
print(d)
a = 1
app = wx.App(0)
ax_global.set_axis_off()
spider.close_down = True
callable(foo1)
self.target = target
repr(self)
Options + ExecCGI
fmt_values = [formatter(x) for x in self.values]
s = np.sin(c - d)
response = MyClassBasedView.as_view()(request)
addsf1 = 0
s,
c = map[x][y]
print(expr.parseString(string).dump())
print(C.todense())
i = 0
words_iter = iter(words)
float()
combination_log = np.log(combination_num).sum() - np.log(combination_den).sum()
B[0] = 1
init_nltk()
visited, worklist = set(), [start]
print(line)
result.append(fragment)
start = 1 + mo.start()
meta.reflect(bind=engine)
sum_table[x1] - sum_table[x0]
g_arr = g_arr.swapaxes(0, 1).swapaxes(1, 2)
substr = data[0][i:i + j]
rows = random.sample(df.index, 10)
dirnames.sort(key=os.path.normcase)
o = ord(h[19]) & 15
a
authenticated_by_ip = re.compile(ip).match(user_ip)
ret = defaultdict(list)
c = Decimal(5)
buf = ctypes.create_string_buffer(size)
highestIndex = i
ser_1 = pd.Series([False, False, True, True])
a[ix_(Xinds, Yinds)]
self._name = name
self.data = obj
list2 = list1[:]
handler.get(*groups)
print(get_version(version))
q = res.k_ma
data = obj.getData()
value = cgi.escape(value)
400 * exp(-T)
self.items = items
final_list
A = A
folder, file_name = os.path.split(file_path)
pa = argparse.ArgumentParser()
manager = Manager()
unittest.TestLoader.sortTestMethodsUsing = lncmp
source.bashrc
newshape = T.shape(tgt)[0],
vc.gotoLastVersion()
dumb_replace(item)
print(r)
VARIABLE2,
1
res = list(mapper(f, ngrams(rand_str, n)))
shape = list(a.shape) + [window]
nums = count(2)
fclose(fileID)
df
Type * c_item
d[1] = 10
s = hex(v)[2:]
(x, y), radius = cv2.minEnclosingCircle(contour)
proba = clf.predict_proba(X)
new_path
temp = []
print(ipList)
floor(nextafter(x, -1.0 / 0.0))
last_file = sorted_xml_files[-1]
CloseAfterFinishFrame1(root)
b = (z << 16) + w
print(notags)
assert expected == actual, msg
minval = a[0]
a = sum([(ord(b) * 2 ** (8 * n)) for b, n in zip(s, list(range(len(s))))])
big_table = ObtainTable()
b1 = b1.sqrt()
param_ref = np.empty((4, sy, sz, sx))
assert 0 <= p <= 1
result_dict = defaultdict(set)
cpus = multiprocessing.cpu_count()
k = cv2.waitKey(5) & 255
retracePath(current)
_checking = True
mi.tolist()
args = docopt(__doc__)
jsonify(u=un, p=pw)
self.seq.sort()
item = DmozItem()
2 ** 0.5
SumLine = []
float(0.97)
summands.add(x)
yaml.dump(x, output_stream, default_flow_style=False)
flag = False
v.fit_transform([doc]).toarray()
Installed / Users / jterrace / test / venv / src / easy - thumbnails
decorator
self.data = data
print(i, n, m)
length = 100
W = arr_1.shape[0]
b = old_a + b
to_exclude = [1, 4, 5]
serv._getPort()._realPortNumber
dup_filter = DuplicateFilter()
self._save()
dbus.mainloop.glib.DBusGMainLoop(set_as_default=True)
posts = db.ListProperty(db.Key)
X = sm.add_constant(x)
__metaclass__ = abc.ABCMeta
closest = difflib.get_close_matches(elem, list_2)
print(args)
currentDict = currentDict[key]
x_lattice = lattice_vectors[0][0] * x_sq + lattice_vectors[1][0] * y_sq
data
users = userDetails.objects.all()
buffer += line
grp2.append(str(ind))
votemil = x[2]
[s[offs:] for s in completions if s.startswith(mline)]
cut_off = datetime.datetime(2016, 6, 29, 15)
app = Application(root)
y_pos * array_0_width + x_pos
bad_emails = []
distance = distance * -1
self.func(self.module)
c = math.atan(x / y)
area = simps(y, dx=5)
h += sys.maxsize + 1
values = [{func(song) for song in self.allSongs} for getter in getters]
print(d)
retval = []
[]
sl = sorted(tuple(sorted(i)) for i in l)
federated_user = users.get_current_user()
R > na.omit(companynames)
expr = args[0][6:]
memoryview(zp) == memoryview(zm)
my_value = c.next()[0]
x = v[:, (0)]
diffs = []
results = list()
x1 = np.random.rand(10)
vect = DictVectorizer()
text = f.read()
serves_hot_dogs = models.BooleanField()
wo
serializer = ImaginaryUserOutputSerializer(User.objects.all())
k, v
valid = True
self.__values[index]
s = sum(gmpy2.unpack(s, p))
a = numpy.array((xa, ya, za))
libs_folder = kfm.GetFolder(shell.FOLDERID_Libraries)
pending = len(iterables)
dupes.add((y, x))
html = wx.html.HtmlWindow(self)
corr = dataframe.corr()
ftplib.FTP_TLS.ssl_version = ssl.PROTOCOL_TLSv1_2
default = 1
ftps.prot_p()
data = page.read()
N = 7
copy[alert_status] = copy[alert_status].map(alert_status_dict)
constructor(app)
set_death_signal(SIGINT)
x_minor_lct = matplotlib.dates.HourLocator(byhour=list(range(0, 25, 1)))
A = ax.get_children()
print(item.getStringValue())
kpt = kpt_list[(i), :]
d = 1.0
print(d1, d2)
a
lambda *x: a(b(*x))
code_line = linecache.getline(func_filename, func_line_no).rstrip()
author_name = y[2]
realy_added_pks = not_realy_added_pk_set - prev_groups_pk_set
self[k]
n.drop1 = L.Dropout(n.fc1, dropout_param=dict(dropout_ratio=0.5))
print(d)
tree = lxml.etree.parse(StringIO(html), parser)
print(i)
d = {}
it = iter(arg)
point_ref = ogr.osr.SpatialReference()
print(m.evaluate(x, model_completion=True))
list(round_robin_schedule(9))
size = file.read(4)
combined = sound1.overlay(sound2)
writer.add_summary(train_summ, step)
frame = sys.exc_info()[2].tb_frame.f_back
_d
ptree = Tree.fromstring(bracket_parse)
rt = Runtime()
i_max + i
zip(*els)
self.get(orig_section, key)
print(a.PARAM, b.PARAM, type(a) is type(b))
x = []
fsolve(f, x)
res = (c_double * mm)(0)
print(r)
w = Walker(doctree)
sequence = list(sequence)
value1, value2 = foo(a, b)
labels = []
print(p)
groups = array()
a = complex(0, 1)
md5.md5(init_str).hexdigest()
list_of_cols = list(range(10))
deletespam
copy + item
self.im = PIL.Image.open(fname)
search = set(data)
filesize = os.path.getsize(fname)
myTkObject = Tk()
nonzero_values = foo[0::] > 0
ny = M.shape[1]
needs_pressing = False,
ca = plt.gca()
self.disp = make_display(b)
and_(same_size, same_items)
d
total, sign, i = 0, 1, 1
opener1 = urllib.request.build_opener()
idx = (pts ** 2).sum(axis=1) < 1.0
print(uvw.x)
_groupConcat = sc._jvm.com.example.udaf.GroupConcat.apply
temp = [item, -item]
students = [lloyd, alice, tyler]
mult8 = lambda n: int(math.ceil(n / 8)) * 8
b < -b + 1
l_out = [tuple(g) for _, g in groupby(sorted(L), key=_group)]
draw(img)
c = app.test_client()
data
results.plot(rot=45)
unique = set(tuples)
e2 = cv2.erode(1 - im, k2, borderType=cv2.BORDER_CONSTANT)
kafka_client = kafka.KafkaClient(kafka_server_name)
arg1 = args.arg1
id = 0
people = [Person(1900, 2000), Person(1950, 1960), Person(1955, 1959)]
8.4
cells = starmap(lambda a, b: (x + a, y + b), product((0, -1, +1), (0, -1, +1)))
conn = EC2Connection()
occ_minocc = [k for k, v in list(occ.items()) if v >= minocc]
num /= 1024.0
pvt = pvt.stack().swaplevel(0, 1).sort_index()
startdate = date.today()
result = schema.load(event)
tx.textLine(line)
C(0, 2)
foo.fi()
False
print(distance)
ClassSender()
binary = lambda n: n > 0 and [n & 1] + binary(n >> 1) or []
mylogger.addHandler(handler1)
t.trainOnDataset(d, 1000)
BIT5 = 2 ** 5
self.wb = load_workbook(src)
self.include_dirs.append(numpy.get_include())
all_in_slices.append(slice(start, stop))
factors.append(i)
print(notags)
t = result.registers[0]
x1, y1
a_view = np.ascontiguousarray(a).view(dt).ravel()
print(union_find(l))
self.val = val
idx = np.argmax(np.abs(fftx))
self.treeview = treeview
raise StopIteration
field1 = serializers.ReadOnlyField()
boby = Dog()
ve = nssp.alloc().init()
rows, cols = A.shape
print(divide_equally(1))
a = S()
leftList = sorted(segments, key=lambda x: x[0])
d
print(a, b)
5576689664895
HTML(sound_tag)
retracePath(current)
np.random.seed(2015)
r
self._pool = []
self.buf.seek(self.write_fp)
col_headers = list(df.columns)
count = defaultdict(int)
rightpath = [root.val] + print_path(root.right)
frac_part = abs(x) - int_part
a_sigma = float(norm.ppf(P / 2 + 0.5))
PyObject * pyth_val
ts1
compile_messages(stderr=sys.stderr)
client_secrets = json.loads(f.read())
text = str(self.v.get_text(lambda *a: True).rstrip())
formsets_validated = all_valid(formsets)
result.append(c in this.d and this.d[c] or c)
s[2] = 14
temp_a = a
[n, 1]
t2.start()
years = dict()
row = df1.iloc[i]
m = LogisticRegression()
display.stop()
source = ColumnDataSource(data=dict(x=x, y=y))
count = 0
helloset = set(hello)
char = getch.getch()
print(processed(line))
maxrank = min(m // 2 + 1, n)
graph = rdflib.Graph()
socket.getaddrinfo = new_getaddrinfo
self.factory.out_dump.write(d)
s = requests.get(url).content
unicodedata.unidata_version
print(lower, n, upper)
self.logger = logger
width = width * 1000 / 6
func[0](arg)
10188470000.0
R = mean_data[:, (0)]
free(buffer)
EXIT_SUCCESS
{{form.category.errors}}
chrs = [chr(c) for c in range(1114111 + 1)]
result
width, height = im.size
chunk_size = len(s) / nrows
match = re.search(pattern, string)
items = []
new.__dict__ = old.__dict__
print(dfu)
getenv.restype = c_char_p
pos += end - start + 1
c = np.apply_along_axis(np.mean, 1, b)
MeanIntensity = np.mean(img[regionMask], axis=0)
data = pl.random((25, 25))
print(d)
q = T.submit(block5)
print(res)
H, xedges, yedges = np.histogram2d(M[:, (0)], M[:, (1)], [bins_x, bins_y])
all_points = all_points.reshape(all_points.size // 2, 2)
b = deepcopy(a)
samples = [dict(enumerate(sample)) for sample in train]
centroids[m] += row[m] / len_best
med.head()
print(result)
indices
2
csr.close()
ipath = input()
Py_DECREF(v)
answer[c] = []
B = []
self[name] = func
y = [f(t) for t in x]
x = numpy.random.rand(1000, 1000)
f = open(filename)
list(round_robin_even(d, n))
description = db.TextProperty()
center *= [1, -1]
np.version.version
dic = defaultdict(list)
testObj(aQ)
compareDir(path1, path1List, path0, path0List)
foo(parser)
ret += str(o)
j = j - 1
tpl = MarkupTemplate(tpl_xml)
totals[bucket_id] += data_point[1]
self._c = C()
degrees, minutes, seconds
[formatter_logfileformatter]
fd = socket(PF_INET, SOCK_DGRAM, IPPROTO_IP)
n = 4 * x ** 2 + y ** 2
colstride = mat.strides[1] // mat.itemsize
cw.writerows(cr)
met = getattr(mod, m)
print(i)
s = s * s
mpz_set(c, result)
extraSize = np.prod(finalShape) / np.prod(inShape)
some_group(datetime_value)
corrMatrix.loc[:, :] = np.tril(corrMatrix, k=-1)
print(d)
p.start()
hexadecimal = str(info_hash)
parser = nltk.ChartParser(grammar)
plt.imshow(np.asarray(a))
num = 0
dictionary = corpora.Dictionary(texts)
libc.memcpy.restype = ctypes.c_char_p
n_bins = 100 * np.ones(D)
tt
rangeList[beg - 1:beg + 1]
t = type(obj)
imp = DOMImplementation()
val = x.name
include / path / to / application / routes.conf
students2 = students.copy(deep=True)
row[0].style.borders.left.border_style = Border.BORDER_THIN
self._decr = False
self.memory.add(key)
s2 = s.copy()
mapping = {vals[1]: vals[0] for vals in map_df.values}
s = StringIO.StringIO()
print(L[0])
h = timeit.timeit(subnivean, setup=s, number=10)
vm_xml = domain_object.XMLDesc(0)
self.num_lines = 0
L = list(range(5))
arg_info = inspect.getargvalues(frame)
c = CA()
start = item[0]
b = sys.path
y_int = integrate.cumtrapz(y, x, initial=0)
mainMonitor.size.width, mainMonitor.size.height
1
pcolor(a)
print(primes)
self.data[:] = args
_ = m_list.pop(len(m_list) - 2)
exception_dict = e.__dict__
n
A + B
id(x)
df == 0
r
CONCURRENT_REQUESTS_PER_DOMAIN = 2
self.input = parse_input
ICON_EXLAIM = 48
con.executescript(script)
new_meta = copy.copy(self._meta)
__metaclass__ = ABCMeta
changeLog.push(change)
c = Cont()
m = np.mean(data)
subs = selfclass.__subclasses__()
X
length += 1
hostname = socket.gethostname()
i = t - 1
other_object = java_object.doThat()
es_formats.FIRST_DAY_OF_WEEK
Value_entries[key].extend([cell.value for cell in row])
exc.__cause__ = cause
e = np.ravel(b[:, (2)])
you_custom_queryset
assert isinstance(B)
True
s += self.A[i]
df
name, n1, n2
L
xRecovered, xRemainder = signal.deconvolve(y, h)
q
val = np.add.reduce(1.0 - np.cos(a - b))
q.mutex.acquire()
empty.append(1)
f = False
strings.append(testbuf)
app.json_encoder = MyJSONEncoder
row[inds[0]:inds[-1]] = 1
ax1 = fig.add_subplot(121)
countvec = CountVectorizer()
y1 = np.cumsum(np.random.random(time.size) - 0.5)
e.list
sentinel = []
seconds = 0
arr[j] = 0
install_data.run(self)
start_df = pd.DataFrame(dict(A=np.arange(len(tidx))), tidx)
s = list(iterable)
_d = Functions.motion.move().right
Python - 2.6 / Modules / datetimemodule.c
S.discard(10)
a1_rshifted = np.roll(a1, 1)
self.accounts.signup(userName, password)
text = str(t)
print(mystring)
s = string.lowercase + string.uppercase + string.digits + string.lowercase[:5]
r, c = x.shape
orig_displayhook = sys.displayhook
qdate
h = hashlib.sha1(view[idx]).hexdigest()
pdb = Pdb()
main()
self
self.order = order
self.f = f
cmd.Cmd.do_help(self, arg)
aListOfLoPRIOevents = LoPRIOpoller.poll(timeout=0)
print(my_value)
uad = np.array([u, a, d])
TimeLimited(cursor.execute, timeout)(query_string, *query_args)
cache[args] = result = f(*args)
result = []
output.append(p)
max(scoreA, scoreB) >= 21
print(d)
project.foobar
parser = argparse.ArgumentParser()
result = []
hexnode = hex(fctx.node())
results.append(candidate)
G = nx.fast_gnp_random_graph(n, 5.0 / n)
self.data = data
G = int(round(var_g * 255))
print(possilities[choice])
model = lda.LDA(n_topics=num, n_iter=500, random_state=1)
i = 0
my_text = my_child.data
s = s.encode(encoding)
tzoffset = tz.utcoffset(now)
self.sendMessage(payload, isBinary)
session = Session()
T_FUNCTION = 6
patch.stop_all()
cur_version = sys.version_info
build_ext.build_extensions(self)
pre, ext = os.path.splitext(renamee)
parsed_result = {}
command_args = shlex.split(command)
print(a, b, t.val, L, S, T)
y_rev = np.empty(x.size, dtype=np.int64)
raise exc_type
im = img_as_uint(im)
obj = Class2()
roundGrade = np.vectorize(roundGrade)
wrapper
instance_ids = [i.instance_id for i in group.instances]
size_t(-1)
index = StringField(max_length=80)
hexNum = hex(intNum).upper()
parser = argparse.ArgumentParser()
x.fill(8)
driver = webdriver.PhantomJS()
doc.setHtml(text)
r.symbols.append(lineSymbolizer)
scope.SetVariable(variable, value)
values = []
formatter.format_epilog(self.epilog)
print(capitalize_nested(t))
nameditems = {}
d = tempDict
fully_mapped = mapper[init_weights.get_level_values(0)]
r, c = np.where(df.values)
pdf.resolvedObjects
db_connection.find(filters)
[]
idx = zip(grid[0].ravel(), grid[1].ravel())
plaintext_length = (Crypto.Util.number.size(rsa.n) - 2) / 8
A = [2, 2, 2, 2, 2]
len(self.positions) + 1
Debug.Assert(decompressed == original)
later = time.time()
root = Tkinter.Tk()
ser = df.ToRoll[(df.RollBasis >= x) & (df.RollBasis < x + 5)]
context
print(variable)
loopUntilA(text, firstElement.next.__next__)
start = 0
sorted_2 = sorted([repr(x) for x in sample_json2])
result = default.copy()
yhash = [hashlib.sha1(row).digest() for row in y]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
distanceSquared = (distance ** 2).sum(axis=1)
negative.append(number)
head,
inputTbl.close()
paths.Add(Environment.CurrentDirectory)
histdist = matplotlib.pyplot.hist(yourdata, 100, normed=True)
re.sub(pattern, replaceNthWith(n, replacement), str2)
out = np.empty_like(a)
app = wx.App(False)
df_std = std_scale.transform(data.transpose())
lambdas_list = []
x = y = [0]
g1 = gen()
i = argmin(abs(x - item))
raise ValueError((state, token))
star_it = next(it)
ret
f = magic.Magic(mime=True)
usernametoken.insert(passwd)
result_as_tiles[:] = a[:, :, (np.newaxis), (np.newaxis)]
print(len(s))
toposort_wrap(data)
print(t.timeit(10))
wrapper
print(new)
toret = {}
user = getpass.getuser()
result
self._coro = iter(coro)
ks_lit = array(*[array(*[lit(k) for k in ks]) for ks in keyword_list])
doc = etree.parse(openfile)
v = A[20:40][::2]
free(cpy)
print(cdist(p, p))
hvals = dict((Hnodes, someoperation(Hnodes)) for Hnodes in H.nodes())
l = list()
readonly = Tkinter.Text(root)
~Derived()
d1 = OrderedDict(sorted(list(dict_1.items()), key=lambda t: t))
ani
print(divmod.__doc__)
x2_Kcids.shape = shape
data = []
rotated = ndimage.rotate(image_to_rotate, 45)
9498409
t2 = time.process_time() - t1
id_arr = np.ones(idx[-1], dtype=int)
p += NP.size(x[ndx]) / float(x.size)
size = n // 2
C[0] = 2
a = np.zeros_like(b)
print()
red = 255
subparser1.add_argument(default=50, *n_args, **n_kwargs)
skip = False
libraries = lapack, f77blas, cblas, atlas
print(result)
print(b)
array = np.random.rand(4, 10)
yfit0 = model0(xdata, fit0[0], fit0[1])
_complicated
context
mask0 = cv2.inRange(img_hsv, lower_red, upper_red)
a = X.flat
nan = np.repeat(np.nan, pad)
l -= 1
fig.subplots_adjust(bottom=fig.subplotpars.bottom + textHeightFig)
theta = np.sum(bidule, axis=1).T
countMap = {}
foo = a._num
5 + True
acts = []
cls.flag = False
view1
input_thread = threading.Thread(target=wait_input)
n + n
buf = StringIO(response.read())
sys.stdin = f1
samples = []
result = []
all_annots += 1
do_production_stuff()
logger.addHandler(h1)
assert not ixlo & ixhi
col_list
num_bytes = byte & 127
g.setRenderHint(QPainter.Antialiasing)
app = Flask(__name__)
df1
print(y.strides)
players[self.player].append(self)
d[x] /= 2
0.468999862671
course_name = StringField()
pad.append(tuple(this_pad))
merged = tf.merge_all_summaries()
half_max = xs[index_of_peak] / 2
is_even_nozero = generate_is_even(reject_zero=True)
view_1_block.block = True
mp.get_logger().info(index)
print(splited_list)
m = len(t) // (2 * len(t2))
dir(a.some)
field2 = serializers.ReadOnlyField()
sock = socks.socksocket()
xml = etree.fromstring(xml)
assert 0 <= i <= stirling1(n, k)
data = conn.read(4096)
maskborder[:] = 0
Y = RGB[0] * 0.2126 + RGB[1] * 0.7152 + RGB[2] * 0.0722
self.name = name
plt.subplot(211)
authentication = ApiKeyAuthentication()
print(d)
a += 1
pDict = request.POST.copy()
print(i + ++++i)
opt_fun(1, 2)
x = np.asarray(x)
print((luckynumbers + sieve)[wanted_n - 1])
self.parent = parent
line = input()
new_min = 0
now = time.time()
print(dir(NewStyle))
s = prompt_thing()
i = np.arange(num, dtype=np.float)
a_valid = formA.is_valid()
c.get_attr()
self.items = []
back.paste(poly, poly_offset, mask=poly)
current = mymap[current]
print(j)
full_backtrace = strdup(str)
pi = np.pi
labels = list(set(train_labels))
thisrow[y] = min(delcost, addcost, subcost)
x = x / 2.0
texts = [(span_i.text, span_vi.text) for span_i, span_vi in spans]
print(list(group[1].A))
counts[i] = 0
update_mandelbrot()
req_for_image = requests.get(internet_image_url, stream=True)
a_iter = iter(a)
mimetools.Message(filehandle).getdate()
[9, 10],
task = self.tasks.pop(0)
worksheet.write(item, i, float(value), style=style)
l
tok = []
response = dict(response_tupels)
print(data_for_signal_handler)
cron = CronTab(user=True)
field_name = x.children[0].rawsource
angle = getAngleBetweenPoints(1, 1, 2, 2)
ones = np.ones(b.shape, dtype=bool)
f(*args, **kwargs)
locale.nl_langinfo(locale.DAY_5)
a = a + [2]
self.image_stretch = image_stretch
df
self.my_reader = DictReader(source)
parsed = ast.parse(setup_file.read())
__metaclass__ = Meta
second = Popen(second_command, stdin=first.stdout, stdout=PIPE)
plot(r_[y[N:], y[:N]])
dict = {}
-4, 1
float(ii * 4 / n)
val = max(0, x - ALLOWANCE)
self.text = text
result = chardet.detect(rawdata)
print(a.colour)
req = socket.recv()
entity_re.subn(substitute_entity, string)[0]
c2 = gimp.Item.from_id(4)
lookup_list, lookup
entry.place(x=i * cellSize, y=j * cellSize, width=cellSize, height=cellSize)
result = []
theta = 0.5 * np.arctan2(b, a - c)
readline.get_completer_delims()
cache[args]
hh.set_http_debuglevel(1)
g = {partial_repeat(test_string[i:]) for i in range(len(test_string))}
print(phrase)
tokens = nltk.tokenize.word_tokenize(sent)
raise Exception(v1)
cls._linux_get_modes()
self.update_config()
VK_TAB = 9
n
most_common = count.most_common(total)
dct
results.val1.hist(bins=120, log=True)
self._loop = loop
bufferFile.seek(0)
results
x = np.arange(0, 100, 0.1)
uncompyle(2.7, f.__code__, s)
c = pc - p0
y = self.lastPoint.y()
window = collections.deque(first_window, maxlen=window_size)
e = get_network_event()
locale.nl_langinfo(locale.DAY_2)
wordcount[word] += 1
makeResponse()
splits = [0] + [rand(0, 1) for _ in range(0, n - 1)] + [1]
n_d[d] += 1
config.add_view(hello_world)
dis.dis(f)
int(500 + 0) is int(500 + 0)
masterList.append(1.0 * i / j)
transitions
n = 5
y = copy.deepcopy(x)
num_converted += 1
seen.add(label)
urlunparse(parts)
N = 5
self.callbacks.append(callback)
modname = os.path.splitext(fname)[0]
explore(path)
output = [name]
endTime = float(row[1])
x - 1
GPS_EPOCH = datetime(1980, 1, 6)
auth_resp_body = auth_resp.read()
True
result
loc(0)
ids = np.repeat(ids, list(map(len, col)))
qs
self.nargs = 0
self.run_event = threading.Event()
to_keep = [n for n in outdeg if outdeg[n] != 1]
note.delete()
sio = StringIO(my_string)
total_counts = DF[col].count()
m.send(4)
crazy_call()
x_crossings = []
blosum = MatrixInfo.blosum62
incrementInventory = str(int(lineSplit[-1]) + 1)
_, cv2_im = cap.read()
Story.append(pic)
a = login.make_user()
pairs = zip(numbers, list(range(len(numbers))))
print(std[0])
rows = cursor.fetchmany(size=10)
Pdb
self.flag.set()
out_vec[out_vec > 709] = 709
connections = []
xs = set(x)
userprefs < -c(squid=0.4)
inverted = collections.defaultdict(list)
lob = dataDB[0].read()
res.append([s] + sol)
col = pp.col(locn, strg)
wn = wordnet.wordnet
M = csc_matrix(np.random.rand(5, 5))
ret = max(dict_depth(newDict, depth + 1), ret)
1
social = backend.strategy.storage.user.get_social_auth(provider, uid)
client.set_signature_method = oauth.SignatureMethod_HMAC_SHA1()
prob = betai(0.5 * df, 0.5, df / (df + t_squared))
result = originalimport(modulename, *args, **kwargs)
args = [iter(iterable)] * n
print(a)
print(df)
s_buffer,
python - bcrypt
f = diff(x(t))
a.fill(numpy.nan)
a = numpy.ones(24)
True
data = json.loads(resp.content)
ignore_list = []
y is np.nan
0
vowels
True
next = math.exp(start) * (max - min) + min
wrapper.has_run = True
needleID, score = max(list(results.items()), key=operator.itemgetter(1))
print(float(val1) / val2)
pq = [(prob(x), x) for x in items]
kwds.get(key, self.default.format(key))
MyClassifier.clf = load_from_file(path)
self
p.data *= 2
self.inline_instances = [ItemInline(self.model, self.admin_site)]
self.c = c
x = np.array(list(range(1, 16)))
n * call(factorial, n - 1)
header = [add.subtask((i, i)) for i in range(100)]
countre = sum(1 for mat in regx.finditer(ch))
self._hal.libhal_ctx_set_dbus_connection(self._ctx, self._conn)
t0 = time()
grad_vals = sess.run([g for g, v in gv], feed_dict={b: b_val})
vals = random_state.rand(k).astype(dtype)
llx = llx.flatten()
stderr = output[1]
origin = Point(0, 0)
r_DF = com.convert_to_r_dataframe(DF)
unzipped = zip(*input)
X = the_input_of_send
0
iconSize = Gtk.IconSize.LARGE_TOOLBAR
i * i + 2 * n
print(x)
year = integer.copy().addParseAction(rangeCheck(2000))
endpos = match.endpos
old_ttyattr = tty.tcgetattr(stdin_fileno)
self.__deque[-1]
print(func(images))
rsa_url = rsa_distribution.create_signed_url(url, message, expire_time)
s
output.append(calc_stuff(self.param))
print(particle.mass)
shape.pop(axis)
datetime.fromtimestamp(timestamp, tz)
df.new_group.iat[0] = 1
paramiko.agent.AgentRequestHandler(s)
form.send(instance.site_email)
x = c_float(4.56)
resp = json.load(inp)
axes[0].pcolormesh(np.array(d1), cmap=plt.cm.coolwarm)
self.pid = self.transport.pid
False
df_test
d = {}
event_handler = LoggingEventHandler()
prefix(x, dimension) + unit
print(result)
items.sort()
scoring(num_items, entry[0])
Other().parent_prop()
drawMatches(image1, keypoints1, image2, keypoints2, matches, img_matches)
t.lower() == ftype
print(sum_columns(l))
x is pd.NaT
result = numpy.array(result)
_filters.append(cast(_attr, String).match(query))
decimal_s = [[decimal.Decimal(x) for x in y] for y in s]
AUTH_USER_MODEL = user_model,
upload_proc = multiprocessing.Process(upload, args=(pdf_queue,))
where_in_b = np.take(sort_b, where_in_b)
print(d)
a_list = []
a.setMainWidget(w)
SublimeLauncher()
root_logger.addHandler(handler)
key = md5(data).digest()
crawler.signals.connect(reactor.stop, signal=signals.spider_closed)
listen_port = 8081
bit_array[item_index] |= 1 << bit_index
errno.ENOENT
total_size = 0
lesk(sent, ambiguous)
print(a)
prefixmatch, rest = prefix.split(s)[-2:]
scores.append(score)
setlocal
sequenceDict[i] = []
surface = cairo.PDFSurface(file.name, m.width, m.height)
logRecord.levelno <= self.__level
CGEventPost(kCGHIDEventTap, theEvent)
local_timezone = tzlocal.get_localzone()
True == 1
maxval = count2[i]
w, h = 100, 100
i += 1
cluster2 = [j for i, j in zip(lda_corpus, documents) if i[1][1] > threshold]
self._replace(x=x, y=y)
[--sys - prefix]
field_names = [f.get_attname() for f in opts.concrete_fields]
pool_size = multiprocessing.cpu_count()
inner_zip = ZipFile(innerzippath)
pattern_compiled = re.compile(pattern)
self.target_dir = tgtdir
rightList = sorted(segments, key=lambda x: x[1])
print((birthday_compare(my_gen, target), birthday_compare(control, target)))
str(s)
line_split = i.split()
a = 0
self.time = time
print(elem.parent)
res[0]
todo_folder = ns.GetDefaultFolder(olFolderTodo)
print(user_num_tens)
person = Person()
self.vtkPoints.Modified()
Mc = mat.tocsc()
indices = list(range(n))
matched = next(subl for subl in mylist if a in subl)
handler = MyFileHandler(os.curdir, logger, logging.FileHandler)
line = infile.readline()
sheet[cell] = amounts[indexValue]
print(df1)
count = list(set([i for i in list(dict.values())]))
registry.register(FrenchLanguagePack)
exif.clear_xmp()
d
wordcount[word] += 1
a = random.normal(0, 1, 10000)
delta = n / 10
tests, t = zip(*test_and_t)
process(match)
coeffs1 = sparse_corrcoef(a, b)
a = b
ypos = NP.random.randint(1, 10, 10)
session = aiohttp.ClientSession()
t0 = time.time()
number_of_rows = 500000
file_path, file_name = os.path.split(script_file)
t1 = time.clock()
main = argparse.ArgumentParser(parents=[base])
i, n = i + 1, n / p
self.key = hashlib.sha256(key.encode()).digest()
print((b.m1(), s.m1()))
corrected = []
future = datetime.datetime(t.year, t.month, t.day, 2, 0)
ca_array = CAArray()
initial = [(0, 0), (0, 1), (0, 2)]
rows_list = []
SubList.on_pickling()
response = conn.getresponse()
print(indices_bigger_than_threshold)
red = red * 127 / 255 + 128
abs(exp(I)).expand(complex=True)
j += 1
primes = []
print(p - pow(n0, p - 2, p))
print(f.name)
writer = CreateWriter(writefile, r)
bitArray.len / 8.0 * len(sequence)
y = data[d]
fast = TestSuite()
line = unidecode(line)
minutes, seconds = divmod(seconds, 60)
figsize = (1 + margin) * ypixels / dpi, (1 + margin) * xpixels / dpi
items = np.arange(m)
urllib2.getproxies = orig_getproxies
old_string = input_string
new_x
print(f.selected_genders_labels())
result += char
print(calendar_local)
size_ = udf(lambda xs: len(xs), IntegerType())
print(prev.month)
self.factory = RequestFactory()
x = x + x[-1] * (len(y) - len(x))
channel = params[2].lower()
A, C, E, F
cell.figure
new_cs = osr.SpatialReference()
trace_debug
ventilator_send = context.socket(zmq.PUSH)
self.cyclevars = template.Variable(cyclevars)
G.add_nodes_from(part)
me == neighbour
gt = ds.GetGeoTransform()
func2()
8 / 7
results.append(sc)
r6i = r2i * r2i * r2i
stuff += 1
print(auth_uri)
self._graph = defaultdict(set)
byte = byte_s[0]
print(volume_in_use)
sum = 1
events = pygame.event.get()
stream = io.StringIO()
j = timeit.timeit(Jamie, setup=s, number=10)
np.asarray(coo)[idx]
d = {}
seed = self.getInitial()
self._content = StringIO()
parser = OptionParser()
i.save(out_path)
__metaclass__ = abc.ABCMeta
a = (_ for _ in range(20))
print(d)
self.assertEqual(0, fake_increment.call_count)
pks = [item.pk for item in list(sqs)]
z = np.float64(4.555555555555555)
perm = np.random.permutation(df.index)
all_in_slices.append(slice(item[dim], item[dim] + 1))
info = model_meta.get_field_info(ModelClass)
uid = StringProperty(unique_index=True)
i = iter(a)
it = interp1d(t, np.arange(len(t)))
pred_label = model.predict(samples[0])
np.nextafter(0, 1)
lines = f.readlines()
fr, to = map(int, line.split())
a
d2 = date(2008, 9, 15)
order = int(np.sqrt(len(m))) - 1
books[i] = books[i]._replace(price=books[i].price * 1.1)
boardFrame.place(x=50, y=50, width=497, height=497)
v = 0
arrow(0, low, 0, high - low, length_includes_head=True, head_width=0.15)
tuple is _tuple
tets = ch.points[simplices]
n[x] = n.get(x, 0) + y
writer = ExcelWriter(xls_path)
test(string[len(prefix):], prefixes, existing)
m.setMap()
print(stdout.read())
d
w_stop = w_y
tmpdir = tempfile.mkdtemp()
indices = sorted(random.sample(range(n), r))
a_list[i + 1] = np.NaN
row = model[rowiter]
b = distutils.command.build.build(Distribution())
csr.close()
result
hdlr.setFormatter(formatter)
source = tmp[start:]
x[:window - 1] = 0
self.d, self.key = d, key
print(mysql_time_struct)
y = list(FunctionWithYield())
filepaths[i] = filepaths[i][0]
plt.scatter(df.preTestScore, df.postTestScore, s=df.age, c=df.colors)
wb.WorkSheets(ws_index_list).Select()
fn(self)
j = np.arange(1, 9999)
deletedff[col]
[0, 1][True]
2,
a = (i for subiter in x for i in subiter)
companies = [companies_map[i] for i in company_ids_page]
self._value + rhs.value()
ret += a[deg] * np.cos((deg + 1) * np.pi / tau * x)
line = fp.readline()
print(type(variable))
raise api.OperationalError(e, message)
False
bar = Bar()
print(f)
r, w = os.pipe()
FE_TONEAREST = 0
deleteself.store[old]
sum2(*varList[0:n2])
v4 = np.random.randn(50)
orig.update(df2.dtypes.to_dict())
delay(20)
matches = map(re.compile(regex).match, lines)
maxepochs = 20
firstLine = next(iter(g))
outbuffer[outbuffer_len] = buffer[i]
controller.authenticate()
False
a = {1}
ax = fig.add_subplot(8, 8, j + 1)
maxIndex = bisect.bisect(translatedList, pos[0] + maxDistance)
win()
print_nested(nested)
hd = hashlib.sha256(json.dumps(d)).hexdigest()
midnight_utc = datetime.combine(utcnow.date(), time(0))
self.pt_lst.append((event.xdata, event.ydata))
self[name]
Y = lambda f: (lambda x: x(x))(lambda y: f(lambda *args: y(y)(*args)))
method(arg)
max_depth = {}
data = np.random.normal(size=shape)
res
self.pipeline = Gst.parse_launch(gcmd)
gen = filter(lambda x: x % 2 == 1, seq)
c = a.copy()
mu, sigma = 200, 25
df
print(L[1])
iterator_mergesort(iterator, size - size / 2)
params = res.params
S = []
Add(5)(10)(15)
a = 1, 2
deletesys, os
path
push(stack, node)
newData = sock.recv(size)
brew - -version
1, 1, 1
indexes = [reference_index[value] for value in data]
value = self[item] = type(self)()
5 < {}
fullText = []
counters = [wordcount(wordlst) for wordlst in search_data]
self.echoers = []
Parent().self_prop()
green_start = s[0]
p.sort
grid(True)
score += score_match(pair, matrix)
print(i)
g.r
5
result = [data[0] for data in accumulate(temp, func)]
strs
loop.run_until_complete(coro)
m_menus.size()
[]
instance.work.attachment_count += 1
tot = list(tot)
x1 = 1
df
seen.add(id(o))
visit_id = Field()
library(maptools)
record = smarter_nestify(l, record)
xx = set(x)
4
deletedata
a = b
UNSEEN
sorted_items = sorted(chain(list(dict1.items()), list(dict2.items())))
gen1, gen2 = tee(generator(), 2)
es_formats.THOUSAND_SEPARATOR
len(msg.split())
print(arg)
answer
width, height = im.size
d2 = cv2.absdiff(t1, t0)
noduplicates
gid = altera
result
self.obj = obj
deck.Close()
wrapper.has_run = False
print(t.text)
y0, y1, y2 = cardan(A, B, C, D)
print(sess.run(using_tensor_train))
compressor = zlib.compressobj()
lru_cache(maxsize=8096)
True
start = time.clock()
post_save.connect(my_post_save_handler, sender=Order)
arr
raise e
print(a)
list(rv)
grp_last_dt = pd.date_range(grp0_lastdate, periods=WL, freq=freq_str).values
print(price)
x = x[mask]
X = scipy.randn(100, 2)
deer
dictionary = {}
tot = np.bincount(zones.flat, weights=values.flat)
sio.seek(0)
not any(clashes(p, q) for p, q in itertools.combinations(queens, 2))
NUMBERS = [4, 8, 6, 2, 15, 50]
OPTION_E = 16
priority = 998
f.write(self.read())
bbar = b.mean()
run_old(*args, **kw)
ix = len(s) - len(s2)
threads = [threading.Thread(target=fetch_url, args=(url,)) for url in urls]
tmp = word[:-2]
start += 1
iGen = (i for i in range(0, 6))
new_image.putdata(list_image)
ixhi = set(sample(hi, M))
pool = mp.Pool(2)
all_handlers.update(handlers)
p2.__bases__
arr_n = np.asarray(needle)
w() == foo
keys = list(v.keys())
name_addrs = numpy.ctypeslib.as_array(p, shape=(num_strs,))
tflat = scipy.array(theta_coord.flat)
start_at = 5
doc_hash = {}
x -= y
fmt_values
cvtColor(rotated, result, COLOR_GRAY2BGR)
cols.sort(compare)
some_label.text = str(value)
self.id = MyObject.ID = MyObject.ID + 1
x, y, z = a.shape
cls._instance
bus = dbus.SystemBus()
a = list(range(2, b + 1))
valToInsert = L[j]
c = stack_arrays((a, b), asrecarray=True, usemask=False)
app = Flask(__name__)
f
chr(octet) != _QUOPRI_BODY_MAP[octet]
Serial.begin(57600)
system
Z = sin(X) + cos(Y)
self.represent_scalar(tag, data, style=style)
key_c = key[i % len(key)]
unfinished = self.unfinished_tasks - len(self.queue)
frame[frame.key1.isin(key1_dups) & frame.key2.isin(key2_dups)]
exec(src, module.__dict__)
dists = distance(a, 10, 11).astype(int)
i = 1
groups = itertools.groupby(A)
text.parent.replace_with(new_soup.p)
z = lambda i=dst, p=[]: p if p.append(i) or i == src else z(pre[i])
print(source_path + filename)
mkimap = lambda : map(str, range(1, 4))
restaurant.describe_restaurant()
dis.dis(test2)
print(i)
HttpAuthenticated.__init__(self, **kwargs)
df
number_to_text = {(1): a}
True
decoded = fin.read()
sign *= -1
nbors.append(i + W)
response.content.count(USER_FULL_NAME)
m0()
xfmt = ScalarFormatter()
4 - 18.0
idx = np.argsort(freqs)
fullNameArray.append(nameArray)
a = b
print(x)
number
date += resolution
a
DIR = os.path.join(DIR, query.split()[0])
tRow.append(m[r][c])
inner_test = InnerTest()
fig = plt.figure()
min_age = survey_data.Age.dropna().min()
n = [1, 1]
point(-1, -1)
next(api_rate_limiter)
self.procs.append(p)
a = ord(msvcrt.getch())
d = OrderedDict()
average_max, average_min
graph = facebook.GraphAPI(auth_tokens)
print(np.cov(xlong.T, bias=1))
self.symtab = {}
win()
fig = mlab.figure(bgcolor=(1, 1, 1))
outGroup = [n for n in items if not is_even(n)]
p = array([a, b, c, d, e])
average
entry_text
a = default
model = Wine
A = 1
a = np.random.normal(0, 2, 1000)
df = pd.read_clipboard()
transport = paramiko.Transport((host, port))
type(self)(deepcopy(self.bar, memo))
print(str(e))
n
strings.append(rake.run(line))
mask = abs(spectrum) > threshold
lambda : x
common_words.extend(inverted_dictionary[key])
x + point(1, 1)
people_alive[a:b] += 1
x = np.random.normal(0, 1, size=1000)
a = array((5, 2))
0
key = a, b, c, d
item = gimp.Item.from_id(index)
combined[key1] = []
artext = get_display(reshaped_text)
php - a
B = Z.flatten()
last_received = lines[-2]
Done = 2
left = max - ((1 << j + 1) - 1)
data = np.random.multivariate_normal(mean, cov, N)
bar_iter = iter(bar)
zip(*iters)
do_stuff(element)
fsolve(f, 0.5, args=(2,))
print(e.output)
pycmd,
s.append(9)
result = list(sliced)
dict.update(frame.f_locals)
form = cls()
euid = os.geteuid()
lines = f.readlines()
A = npr.randn(n, n)
l1[1] = b1
np.concatenate((l1_x1 - l2_x1, l1_x2 - l2_x2))
arduino.setDTR(False)
print(select([Sample.id, Sample.name]))
obj
gw = 51 * ((int(g) + 25) // 51)
g = rgb[1]
loop.run_until_complete(get_and_print())
os_version = OSVERSIONINFOEXW()
spam, eggs = eggs, spam
channel = transport.open_session()
then > now - timedelta(minutes=5)
certType = rfc2459.Certificate()
middle = len(lst) / 2
b = 4
1 / 0
Console.WriteLine(mod)
length = size
authreq = False
g
tz
list2 = list1[max_size:]
deactivate
print(num_overlap)
print(out)
plot = figure(plot_width=400, plot_height=400)
mapp = (match.group(1) for match in matches if match)
self._threads = []
print(page)
invert = lambda a: a[::-1]
greenlet.throw(Greenlet.GreenletExit)
time_test(loops, reps)
print(df_)
print(login2)
ui.write(e.EV_KEY, e.KEY_ENTER, 1)
widthscale = len(yvalues) / 4
src, key = top[0]
count = 0
result = add(a, b)
2, 2
iterator = iter(iterable)
sum += A[row, i] * b[i]
type, key_string, comment = openssh_pubkey.split()
delta = delta[1:]
n, k = map(int, next(file).split())
dialect = csv.Sniffer().sniff(csvfile.read(1024))
label.paragraph_format.keep_with_next = True
idx
m, n = len(lst), len(seq)
batch.add_batch(table, keys, attributes_to_get=attributes_to_get)
out_2.getvalue()
tokens = nltk.word_tokenize(raw)
layers = np.empty([50, 6])
head.appendChild(script)
t.fake_new_resources([])
z = 1
col = [a for item in col for a in item]
print(sentence)
cars.insert(car)
browser = get_default_browser_name()
yticks = data.index
one, two, three = alist
axis = 1,
bin = np.arange(N)
x, y = s
a = list(range(2, b + 1))
df_grouped = df_grouped.reset_index()
self._broadcast.unpersist()
cppcode.init(address, port, en_msg)
[0]
funcList = []
[7, 8],
ia = np.indices(a.shape)
colors.append(newColor)
n_val = 4
dummy_call = service.data().ga().get(**params).execute()
self._choices_actions.append(choice_action)
raise
sess = Session()
p[x] = l[a]
PyTuple_SetItem(pArgs, 0, pValue)
char = chr(uni)
d
model = listWidget.model()
w, vr = eig(L)
key = f.read()
database = DB_NAME
print(L)
UserName = MYUSER
self.count -= 1
__slots__ = ()
print(config_root.sites.mysite.owner.name)
print(word)
unique_num = unique_nums()
method1 = np.all(tmp, axis=-1)
self.__dict__[name] = value
df
delta = t2 - t1
Ax = np.arange(Axmin, Axmax + dx, dx)
print(token.refresh_token)
rec_split(rest) + (tail,)
worker = ctx.Process(target=_job2)
pprint(tree, stream=fout, **other_kwargs)
end = p(sys.argv[1], 0, feed)
print_leaps(leap_lst)
store = ctx.get_cert_store()
result = []
filter = Q(a=True)
mode = file_stat[ST_MODE]
print_callback = classmethod(apple_print)
f = loc_dt.strftime(fmt)
e = revnums.pop()
self.numberRequests += 1
tup[0], -tup[2], tup[1]
s[mask] = 1.0 / s[mask]
k = 1.0
cursor = connection.cursor()
self.email = email
new_x = np.sort(np.append(interpolated_x, x[1:-1]))
cluster_classes = {}
tree = scipy.spatial.KDTree(reshaped_array)
i = 0
print(d.groupby(grps).apply(group_process))
dtd = dtd.apply(pd.to_datetime)
content = q.get(timeout=TIMEOUT_IN_SECS)
lst2 = []
t.cancel()
a_lu = splu(a)
ws.PageSetup.FitToPagesTall = 1
self.children = children
Crome_betaversion
element = ElementTree.fromstring(self.response.body)
rot = im2.rotate(22.2, expand=1)
first = True
variable = MyClass.E
x1 = mu + sigma * P.randn(7000)
newres
m = PyImport_AddModule(name)
bg = urllib.request.urlopen(bg_url)
mode = stat.S_IRUSR | stat.S_IWUSR
X, Y = meshgrid(arange(N), arange(N))
request.method in permissions.SAFE_METHODS
partial(myfunc, arg2=1).args == partial(myfunc, arg2=1).args
order = []
process_list = []
True
dict_ = dict(factorseq_dict)
out
a
type(p1.intersection(p2)) is geometry.LineString
show()
self.format_commandline_results(results)
deletedict_[k]
card = customer.sources.create(source=token)
style = xlwt.XFStyle()
G.add_nodes_from(v)
Out.ar([0], sig * 0.6)
start_date = obj.start_date
votetype = x[4]
print(args)
print(res)
assert a > b
newdf = df[med.index]
myapp = SessionMiddleware(app, session_opts)
print(d[i[i < d.size]])
print(some_module)
a = {i: (i ** 2) for i in range(10)}
self.price = price
6 - 5 + 6
positive.append(number)
print(smallerThan(integers_list, 12))
minlen, maxlen = sre_parse.parse(regex).getwidth()
test_labels = test_df.values[:, (0)]
idx = np.r_[idx, condition.size]
5 + 10
df1 = rdd1.toDF()
MIN_VALUE = 0
sp2 = matplotlib_fig.add_subplot(122)
opster.dispatch()
allSimplePaths(n, v, thisPath)
rand = 14
sols
self.__class__(self.year + 1, 1)
iv = Random.new().read(AES.block_size)
q = Q()
q.put(adj[0])
paragraph = hdr_cells[idx].paragraphs[0]
dates.sort()
index_of_peak = maxes[np.argmin(np.abs(maxes - start_index))]
cluster = daydict[hour]
False
labelCount = np.bincount(labels.ravel())
webpage_text = webpage.read()
mod.__file__ = path
nx, ny = y.shape[:2]
django.db.connection.close = close
mku = n - mpb * nu
sp1.place(x=5, y=5)
a == b or int(a * 10 ** sig_fig) == int(b * 10 ** sig_fig)
b = str(*a)
group = myuser
dirn = [2, -2]
test.prnt_(s, len(s))
{{item.quality}},
diff.days
decoded
http = credentials.authorize(http)
t_full = np.linspace(0, 0.01, 2 ** 12, endpoint=False)
True
self._put(key, val, overwrite_key=True, overwrite_val=True)
next_pos, pos = 0, 0
A = B.get()
1, 10, 44
non_str_len = struct.calcsize(fmt[:-1])
d.extendleft(iterable)
lst = [random.random() for i in range(5000000)]
total = 1
my_dict = {}
pos_x = screen_width / 2 - window_width / 2
df_ret[dcol] = grouped.agg({dcol: min})
True
a, b = c = 1, 2
output = StringIO.StringIO()
x = xint(10)
C.copy(pa, pb, len(a))
raise NotImplementedError()
new_representer
print(text)
int(astr)
a, b = build(x)
exc_info = sys.exc_info()
warnings.warn = warn
print(a == b)
asdf
val = 0
n = 2
contour, _ = cv.findContours(im_bw_inv, cv.RETR_CCOMP, cv.CHAIN_APPROX_SIMPLE)
x
print(res.json())
df[df == 0] = np.arange(start=2, stop=min_count + 2).reshape(df.shape)
stations[p] = 1
obj = range(1, 11, 2)
app = wx.PySimpleApp()
user_id = session[SESSION_KEY]
maxlen = max(map(len, seqs))
a = 1
data.write()
laparams = LAParams()
mic = hmac.new(ptk[0:16], data)
area = measurements.sum(z2, lw, index=arange(lw.max() + 1))
yy, zz = np.meshgrid(yedges, zedges)
df
word2_set = word2_synonyms[best_match[1]].lemma_names
route_id, service_id, trip_id, trip_headsign, direction_id, block_id, shape_id
string_hash(PyStringObject * a)
d
dis.dis(test5)
b = bibdata.entries[bib_id].fields
print(counter.value)
print(df)
print(comment_entry.title.text)
k = 2
theta = list(-1 * theta)
filter[field] = self.kwargs[field]
is_cy_call
G = nx.Graph()
2 in r
print(src)
gauss(x, mu1, sigma1, A1) + gauss(x, mu2, sigma2, A2)
A[i] = b
dacl = sd.GetSecurityDescriptorDacl()
preprocess()
item
x
c = Counter()
ax = s.hist()
result = dict((source, []) for source in sources)
d
add_form = UserCreationForm
b.sum
self.dwLength = ctypes.sizeof(self)
k.set_contents_from_filename(file)
do_something_useful_with(row)
key = d.get
df.columns = columns
setattr(__main__, namedtupleClass.__name__, namedtupleClass)
href = href[:indx].strip()
iterable, it_ahead = itertools.tee(iterable)
pred = lambda x: x
file_contents = f.readlines()
self.parent = parent
authenticated_userid(self.request)
2
n
FlatPagesDBO()
t = df.b.abs()
lst.append((f, f.f_lineno))
self.model.save(fn)
conversion[10]
x_list = [x for [x, y] in list_of_lists]
os.setuid(pwnam.pw_uid)
int(5 + 0) is int(5 + 0)
acc += (i + 1) * (K - (i + 1)) * v
counter[item] += quantity
mask = df.date_of_last_hoorah_given.isnull()
blines = words_file.readlines()
p = len(a) // k
power = np.array(alfa) ** 2 + np.array(beta) ** 2
logger
glob = globals()
mask = zeros_like(arr, bool)
tensor_indices_tuples = zip(index_groups, args)
ret.p = p
ret = self.call(*args, **kwargs)
data_file
categories[bisect.bisect(points, 1)]
parent = gtk_widget_get_parent(old)
overall_structure.ignore(NL)
self.d = {}
0
nexts = cycle(islice(nexts, pending))
SocketServer.ForkingTCPServer.allow_reuse_address = 1
mySuit = suite()
l
a < -a + 1
increment(num)
total = 0
oldStdout = sys.stdout
cache = obj.cache = {}
print(catalan_2.counter)
count = 0
subplot.set_ylim((-7, 7))
result = PyString_FromStringAndSize(NULL, buffer.len)
y = np.array([2.1, 2.9, 4.15, 4.98, 5.5, 6])
val = x.appearance
actual = generate_correlation_map(x, y)
map(lambda age__: age__[0], [__person_id for __person_id in mylist if __person_id[1] == 10])
grouped_2Darray.fill(np.nan)
temp = set()
whatever()
pv.extend([m * v[0:2], m * v[2:4], m * v[4:6]])
hp.heap()
4 / 100
im = ax.imshow(np.arange(100).reshape((10, 10)), aspect=0.5)
self.last_region = name
print(json.loads(r.content))
arr
process(entry)
sys.displayhook = html_displayhook
df2
df_yes
1
NULL
pen.append((x, y + 1))
n < -nchar(w)
collResv.rejectCompletely()
a_shifted = np.roll(a, shift=shift, axis=axis)
match_ratio
merged_data = merged_data.fillna(0)
print(x)
utc = pytz.utc
BEST, UL, UR, LL, LR, R, CL, CR, LC, UC, C = list(range(11))
notFound = object()
a.d
G = nx.DiGraph()
type(el)(el)
stack += [v]
a = 1, 2
ranges = iter(sorted(ranges))
list1 = [18, 8]
sub_len = len(sb)
boxsum(img, w, h, 2)
len(word)
Grid[row].append(TempTile)
img.putalpha(ia)
send_thread = SendThread()
y = list(range(len(x)))
print(num_of_fs)
l1, l2 = tee((pred(e), e) for e in lst)
cm.jet(val)
clip = fullVideo.subclip(startTime, endTime)
isinstance(False, int)
U2_val = ((f1 + 1) / U0 ** 2) ** -1
current = mymap[start]
result_with_zeros = a.div(other[serie_name], fill_value=fill_value)
Example[types][1](a, b)
report_fit(params)
childrenScores = np.zeros(10, dtype=int)
c = C()
nchannels = 2
module = ast.parse(my_code)
1.0 / sqrt(2 * pi * v) * exp(-(x - m) ** 2 / (2 * v))
offsets.sort()
a = arange(10)
print(newlist)
end = text_cell_runlist[segment_idx + 1][0]
df = DataFrame(abs(np.random.randn(5, 4)), index=Index, columns=Cols)
True
Connected.add(res)
i = 0
requests.Session.send(self, *a, **kw)
vals.push_back(val)
result = expr.parseString(astring).asList()[0]
B = [[A[0]]]
ranges = [tuple(path[i:i + 2]) for i in range(len(path) - 1)]
counts_b = np.bincount(b)
b = 1
unseen < -setdiff(names(preds), seen)
Builder.load_string(kv)
thismodule = sys.modules[__name__]
5
print(my_tuple)
22,
print(xx0)
index = list(range(len(mylist)))
P
loop_ok = True
pprint.pprint(diff)
A = B.get()
dis.dis(unpacking)
url = urlopen(dirpath)
scraped_field_b = Field()
w = Gtk.Window()
z = x + I * y
print(a)
parser = optparse.OptionParser()
print(lt.tm_zone)
s = StringIO.StringIO()
n = 1
list_query = list_query.filter(List.counter > 5)
kill(b)
response.status = 400
shell.settimeout(0.25)
self.now = start
N = 20
Row
j += 1
B = A[:, (colset)]
next_pending = []
print(xy[10])
reduce(einsum_for_two, tensor_indices_tuples)[1]
output = []
pe = performance.now()
ws.remove_splits = True
sdict[k] = [list_schema(seqtype.document_type)]
start = 0
number ^= number << 4
endTime = time()
myCursor.fetchone()
file.name = name + ext
w.document.write(response.responseText)
print(find_needle(n, h))
deletea
shell.init_display_formatter()
wn_tag = penn_to_wn(token[1])
0
self.memo = {}
run.bold = True
False
line = line.strip()
update = ScheduledPost.objects.get(id=update_id)
lhs, rhs = map(ast.literal_eval, map(str.strip, expr.split(operator)))
frames = wr.readframes(wr.getnframes() - 1)
d = df.index.day - np.clip((df.index.day - 1) // 10, 0, 2) * 10 - 1
i2 = bisect.bisect_right(friends, (px + maxdist, py))
y_rows, y_columns, y_channels = y.shape
draw.line((x, y0, x, y1), fill=line_color, width=1)
type_iid = fdm.GetTypeInfo(index).GetTypeAttr().iid
source_image.copyMetadataTo(dest_image)
matrices = []
data0 = np.fix(4 * np.random.rand(1000000) - 2)
mymodel_url_index.create(bind=engine)
fuzzyBinSearch(L[mid + 1:], x)
graph = tf.Graph()
df = df.sample(frac=1.0, random_state=42)
ls / usr / local / bin
xy = [x, y]
True
p
run.call(2)
_min = min_max(n, S)
data = parse(f)
(x + 250) // 500 * 500
Serial.begin(9600)
filename = secure_filename(file.filename)
True
x >>= 1
logging.basicConfig(format=FORMAT)
num_overlap += 1
theta = c()
zfiledata = io.BytesIO(zfile.read(name))
object_list = object_list.filter(author=bundle.request.user)
print(b.eval())
final_list = []
unit.pmax(w1, w2)
doSomethingThatMightFail()
plt.pcolor(data, cmap=plt.cm.OrRd)
result
out = arr_1 * arr_2[idx]
items = defaultdict(list)
modname = mod.__name__ if mod else frm[1]
point = iter(data)
self.sum += int(p.before)
EXC_IF_ASYNC_IN_PROGRESS(self, callproc)
prec = intervals[0][1] + 1
min_latitude = Lat[min_index]
immutable_list = mutable_list
self.thread.started.disconnect(worker.process)
tb.tb_lasti, tb.tb_lineno = tb.tb_frame.f_lasti, tb.tb_frame.f_lineno
print(col)
cols_saved = df1.columns
set([2]) in a
b = item[0]
self.shared_arrays[i]
self.combine_element(self.roots[0], r)
tuple1 = 1, 2
f = Foo()
self.url = url
myconf = configparser.ConfigParser()
data = {}
y = (y + H(x) % H) % H
a + b
free(arg)
y = y + 1
-12 % 48
path = url.toLocalFile().toLocal8Bit().data()
5
page = data.read()
timeout_timer = Timer(timeout, thread.interrupt_main)
_, y_b, _, h_b = cv2.boundingRect(new_contours[1])
a2, b2, c2, d2 = a * a, b * b, c * c, d * d
norm = 1.0 / (2 * variance)
factory = MyFactory()
xd = line.get_xdata()
lat_b = radians(lat_b)
ok = False
[pair for pair in f if in_range(pair)]
x0 = cos(2 * pi * t)
PyErr_NoMemory()
j = 1
serializer_class = TimeLineSerializer
False == 0
_config_parser_get(fallback_environment, id)
year_dif = val[0:4] - first[0:4]
handler = logging.StreamHandler(sys.stdout)
False
dictrepr = dict.__repr__(self)
result[0::2] = lst
x = X()
neginf = Decimal(-1) / Decimal(0)
dump_anydict_as_map(Document)
session = Session()
print(f(a))
newArray = myArray / myInt
b = login.make_user()
create_cover_sheet(coversheet_path, user, user.performancereview_set.all())
buffer_from_memory = ctypes.pythonapi.PyBuffer_FromMemory
ukeys, index = np.unique(keys, True)
Base = declarative_base()
Database = MyDatabase
1, a, a, c
cache = {}
p.map(f, list(range(20)))
std_xs = (xs - xs.mean(axis=0)) / xs.std(axis=0)
table = list(range(N))
has_microseconds_time = time.mktime(d.timetuple()) + d.microsecond * 1e-06
i += 2
out = template.format(*l)
out = np.insert(arr, idx + 1, newvals, axis=0)
st = set(a)
u = bisect.bisect_right(arr, [upper])
end - start
foo.desc
n = f2.write(buf)
print(new_item in session2)
input.copyTo(maskedImage, mask2)
Fourth
btoa(JSON.stringify(dataObject))
self.get_choices(include_blank=False)
h = {}
data[int_len:int_len + str_len] == type
df.dtypes
Reader = f.read()
0
req_data = JSONRenderer().render(data)
n, m = X.shape
y = exp(x / 2.0)
self.preferred_nodes = [node for node in self.nodes]
content = StringField()
mylock = threading.RLock()
print(ii)
arr_size = np.prod(shape[:]) * np.dtype(dtype).itemsize
pid = os.fork()
init()
str(r)
y = y[indexes]
SQLAlchemy
require(gmaps)
lon1 = lon1 * pi / 180.0
scrollContents = QtGui.QWidget()
u = u[1:]
aplusb(-1000, 8000)
raise TypeError
n = len(lst)
l = [frozenset()] * 4
this.length / (this.point_count + 2)
addmap[:] = xmap + ymap
styles = getSampleStyleSheet()
G.add_edge(1, 2)
lon1 = loc1[0]
result = registerform.save(commit=False)
n = 6
high = max(row[:-1])
not_prime = set()
l[n] = recursively_apply(l[n], f)
pt = Point(2.5, 1.2)
loop = asyncio.get_event_loop()
mean = float(total) / X.shape[0]
d = np.sin(xx) * np.cos(yy)
str(CarManufacturers[self._mfc].value)
y_lattice = lattice_vectors[0][1] * x_sq + lattice_vectors[1][1] * y_sq
row += 1
p = canvas.Canvas(response)
j += 1
popt, pcov = curve_fit(func, x, y, [100, 400, 0.001, 0])
df_a = pd.read_clibpoard()
self.contents = bytes(pkt)
m[0][1] = 44
user = user.upper()
b
raise
print(result)
switch[case_variable]()
l = []
pbar = ProgressBar(widgets=widgets, maxval=size).start()
length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
mydict = {}
ind = []
images = ((i, np.full(shape, i)) for i in range(N))
__metaclass__ = inheritdocstring
params0 = [0, 0, 0]
skills = serializers.PrimaryKeyRelatedField(many=True, read_only=True)
xs = []
o = C()
childRNG.setSeed(next(masterRNG))
Arrays.sort(array)
initialcolor
datacols = [cc for cc in df.columns if cc not in [groupbycol, weightscol]]
rootName = str(list(structure.keys())[0])
print(new_path)
n = 10
app = xmlrpclib.ServerProxy(server_url)
self.y = y
out = Image.composite(rot, fff, rot)
lower_red_0 = np.array([0, 100, 100])
m.push(e)
x ** 2
response = h.getresponse()
df
x[i * Fs:(i + 1) * Fs] = np.cos(2 * np.pi * f[i] * t[i * Fs:(i + 1) * Fs])
pyximport.install()
sys.argv.pop()
ShowIndex()[0:5:2, ::-1]
a
config = SSHConfig()
install_developer_libraries_as_needed
6 * z * x ** 2
deletelogging
B2 = np.empty(len(A))
self.sleep_func = sleep_func
UDPSock = socket(AF_INET, SOCK_DGRAM)
list_yc = []
598799
DEBUG(0.0)
bins = np.arange(0, 1.0, 0.155)
snapshot = np.random.randn(1024, 1024)
b = scipy.stats.binom(n, p)
self.RAWR = new
M.logout()
cleanup()
A.c = 20
print(a.text)
self.__name
scores = zip(*data)[0]
vector_c = r_[vector_a, vector_b]
self.book = get(Book)
uniq = OrderedDict()
require_dir(directory)
cos, sin = numpy.cos, numpy.sin
print(status)
self.getData(key)
print(df1)
table = PrettyTable(list(df.columns))
kde_val = np.asarray([kde.integrate_box_1d(-np.inf, xx) for xx in x])
filenames.append(filename)
int(n / precision + correction) * precision
height = GetSystemMetrics(1)
--ignore - case
options.append(model.visibility == VISIBLE_GLOBAL)
subcommand = cli.commands.get(line)
x = collections.defaultdict(list)
ctx = gpgme.Context()
self.softspace = False
gplt.plot(xs, [f(Y, x, N) for x in xs])
print(w.fill(a))
result = lambda : instance
raise TypeError
type(y) is list
other = other.real
i += 1
time.sleep(duration)
x = pd.concat([ts, pd.TimeSeries(index=datetime_index)])
y[0] is y
x + xy
print((number1, number2))
st = RSLPStemmer()
inet_to_str(ip.src), inet_to_str(ip.dst), ip.len, ip.ttl
app = Flask()
r = split_chunks(l, CHUNKS)
print(url)
c = SaneEqualityArray((7, 7))
chunk_length = len(result) / CHANNELS
set2.add(s)
SVR().fit(X_train, y_train)
x = list(range(10))
[5, 4, 4, 5, 6, 6, 5],
step = math.pi / 20
_ref = sys.modules[__name__]
res.append((op, code))
_precalc_table[x]
y = 2
cursor = db.cursor()
gg = np.outer(g, g)
n, d = divmod(n, 10)
anotherFunction(word)
axis += len(shape)
namelist = zfile.namelist()
b_List = [T, T, T, F, F, F, F, T, T, T, F, F, T, F]
env
f2 = (lambda x: lambda self: x)(noise)
print(result.Result.CompanyName)
new_word
arrayTest.init(10)
resultslist = []
a = (x for x in [1, 2])
mostNestedDict.pop(list(mostNestedDict)[0])
deltas[deltas < 0] = 0
traffic = Counter()
print(args)
bool(set.intersection(*tup))
reveal
node = self.last_node(body)
test.port = self.current_port_name
lst = list(range(10))
delta.append(delta_val)
mid = len(L) / 2
MEM_L = [1]
lowDimensionalQuery = dot(inv(sigma), dot(u.T, queryVector))
sample = [random.gammavariate(a, 1) for a in params]
g.end()
is_even = (el for el in with_idx if el[1] % 2 == 0)
b = [7, 8, 9]
first = set(first)
x = 1
p = Process(target=test, args=(x,))
wm = pyinotify.WatchManager()
start = 0
import_re()
results = pool.map(processInput, inputs)
cluster = []
level = NOTSET
f2 = x * (rho - z) - y
out = 0
len(spectrum)
TestResult.addSuccess(self, test)
sampling = population[np.random.randint(0, len(population), N)]
ko5o
lineCharsList.add(lineChars)
A[:ph, :pw]
books = {}
sorted_scores.sort()
samplerate = wav.getframerate()
star_len = match.size
CATCGATCAGCATCGACAAACGGCATACG
properties = props(MyClass)
f, (ax1, ax2) = plt.subplots(2)
d = defaultdict(count(1).__next__)
print(len(groups))
print(value, unit)
res
p1 = DummyObj(t1, list1, d1)
cookieValue
builder.append(indent)
cluster1 = [j for i, j in zip(lda_corpus, documents) if i[0][1] > threshold]
failures, _ = testfile(filename, module_relative=False)
x = -2
x, y = np.vstack((center + val * vec, center, center - val * vec)).T
user = models.ForeignKey(User, unique=True)
b = IRtest[my, mx] * ~(mask_my | mask_mx)
print(tabulate(table))
self.callback = callback
root = Tree()
print(comment_entry.id.text)
Bar = library.func(byref(Foo))
id7, Video, moreinfo7
id8, Video, moreinfo8
PyImport_ExecCodeModuleEx(char * name, PyObject * co, char * pathname)
2 ** 10
subs = iter(substitutions)
do_stuff_to_each(elt)
B = float(hsb[2] / 100.0)
Bxmin, Bxmax = -5, 10
fig_size = [fig_width, fig_height]
all(axis, out)
size = int(num[-1]) * 50
idx = image[:, :, (0)] > threshold
freq_list = [(freq, word) for word, freq in list(freq_dic.items())]
print(nonzeroind)
list(b.gen)
ans += 1
search = search.lower()
sdict[k] = list_schema(v.document_type)
t = (x - e) / w
x1 = arr1.flat[0]
val_len = r.strlen(k)
paths[len(newCandidate)].add(newCandidate)
input.copyTo(maskedImage)
assert isinstance(sys.meta_path[0], HardenedModulesHook)
print(product)
obj.is_draft = True
result, text
a
condition_loaded = json.loads(condition)
print(b)
i = clrt.get_global_id(0)
set(bbox_map.values())
new_heap = list(heap)
ret = []
matrix = [[levenshtein(i1, i2) for i2 in l2] for i1 in l1]
ast = childStack.remove(0)
p.df
sentence_parse = _clinkgrammar.sentence_parse
procesed_l = [_ret_list(k, g) for k, g in groupby(l)]
a = np.random.randint(-1, N, size=(5, 5))
print(s)
LoggingCursor.execute(self, procname, vars)
form = UserChangeForm
dic = defaultdict(lambda : 1)
1
path1.append((x1, y1))
np.nan, np.nan
res[hash].append(word)
xxs = XmlXPathSelector(response)
layer = qgis.utils.iface.mapCanvas().currentLayer()
as_strided = numpy.lib.stride_tricks.as_strided
document
L
mm = mmap.mmap(fp.fileno(), file_length)
print(output)
seta
element.attrib
it = iter(seq)
print(evecs.T[(1), :])
q[1] = 1
sum2 = count2[i]
EmailField.__init__ = email_field_init
r.append(type(cell))
R = B * A.loc[B.index.droplevel(2)].set_index(B.index)
ciphertext = obj.encrypt(message)
video_folder_path = ctypes.create_string_buffer(260)
a_thing = example.get_thing(b, 0)
row_dict = row.to_dict()
show_hide()
file_nodes = get_nodes_in_file(translation_unit.cursor, source_file_path)
image.clip(display_min, display_max, out=image)
insort(alive, -unborn.pop()[1])
FAILED(failures=2)
conn = urllib.request.urlopen(xmlfeed)
Pxx, freqs, bins, im
self.method = method
p.communicate()
KludgeDumper.add_representer(str, SafeRepresenter.represent_str)
created = db.DateTimeProperty(required=True, auto_now_add=True)
position = models.ManyToManyField(Position)
set(full_log) & set(tc1)
Panel(dd)
model = models.FavoriteList
net.addLink(h1, s1)
c = logmod.intercept_
cents = 999
[do_things_on_iterable for item in iterable]
Ycart = Ycart.astype(int)
Xcart = Xcart.astype(int)
p.draw(win)
print(in_koch(L, V, 100))
print(member)
secrets = netrc.netrc()
hash(a) == hash(b)
[200, 220, 100]
mixins.RetrieveModelMixin,
frame = Frame(root, width=100, heigh=100, bd=11)
HttpProtocolParams.setContentCharset(params, HTTP.UTF_8)
self._x = x_
True
val = repr(val)
self._s
counter = Counter(str)
subject, verb, object_ = line.split()
print(binop.parseString(e)[0])
imported_modules = [module for module in imports() if module not in excludes]
extractor = parallelTestModule.ParallelExtractor()
x = np.sin(2 * np.pi * t)
print(np.column_stack([m, reduced]))
new_shapes += [[(list(rr.dot(p)) + [0]) for p in s]]
index = list(np.ix_(*[np.arange(n) for n in shape]))
print()
nth_largest(a, 1)
input_list
raise
print(os)
my_dict = json.loads(options.test)
l = [1]
self
extracted_data = self.backend.extract_file_contents(file_obj)
-celery
original = np.copy(image)
width = 1280
seen = set()
Lambda = dot(Phi, R)
maxkey = max(occ_minocc, key=len)
a, b = paths(tree)
pep8radius - -diff
format = {}
sleep(0.2)
domain_object = conn.lookupByName(VM)
xc = m[1, 0] / m[0, 0]
print(rh)
val_string = row[1]
l = list(z)
w = wx.SystemSettings.GetMetric(wx.SYS_SCREEN_X)
t = datetime.now() - start_time
figure, imshow(di, [])
h, w = img.shape[:2]
sumBefore = [0]
isinstance(True, int)
nameTbl in getTables(cpmm)
object.changeState()
first in letter
results += 1
prg = factory.LazyAttribute(lambda a: ProgrammeFactory())
display_as_text(result)
False
bytes = fp.read(8192)
list1
-m.end(), -m.start()
carIndex = [my_list_comprehension][1]
y = x
modBinarySearch(arr[mid:1], x)
current_4mer = readingFile[i:i + window]
fdist = nltk.FreqDist(bgs)
out = np.full(mask.shape, np.nan)
variable = MyClass.A
out
gateway = JavaGateway()
session = Session()
minutes = int(floor(seconds / 60))
amoServer = Server()
x, i, j = args
b & bitmasks[r]
t = linspace(0, 0.1, 1000)
ERROR_SUCCESS = 0
val = s.cell_value(row, col)
z = 0.5 + np.random.rand(len(x))
out1, out2 = R[mask], C[mask]
user.save()
x = np.linspace(0, 2 * np.pi)
response = urlopen(url)
id2, Taxis, moreinfo2
tag = tag[2:]
max_file = fname
someStateMemo.set(aValue)
items2
map_canvas.layers.append(layer)
settings = Settings()
self.input = input_handle
a2 = k2()
print(t)
A().f1
data
stty - a > stty - before
cache = load_from_file()
False
DEBUG = False
factor = l // (i - 1)
wy0 = cy - y0
savedLength = undefined
print(i)
child.py
row = row[0::2]
1
ret = copy.deepcopy(x)
PyObject_Print(array, stdout, 0)
self.p = Path(*pathsegs)
vars = []
centroids = defaultdict(float)
data = [[random.random() for i in range(1, 4)] for j in range(1, 8)]
df
list_of_g[to_idx] = g_current
loglogmod = linear_model.LinearRegression()
window.discard(lag_obs)
trav(listD) == outlist
i = 0
bar.CLASS_PROPERTY = 2
s1mask = np.isfinite(series1)
s2mask = np.isfinite(series2)
logger.removeHandler(memHandler)
PrintFrame()
crontab - e
month_dates = cal.itermonthdates(year, month)
_stderr = sys.stderr
parsed, args = parser.parse_known_args()
0
[9]
mydict = dict(a=1, b=2, c=2)
a = pd.np.array(s)
raise TimeLimitExpired
all_targets = set((start_point,))
alignment = R.dtw(query, template, keep=True)
node = Composer.compose_node(loader, parent, index)
tup = tuple(fin)
print(df)
ws2.append([c.value for c in row])
item2 = [a, b, c]
print(a)
memo[n, left]
numin = binnum
self.session_factory = session_factory
print(nx.is_connected(G))
img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
store_and_clear(_cache[key], key)
x + y
logp
results = []
B = points - points.T
instance.update()
g.a = []
p = pairs(coords, 5)
splrep(x, y, w, k=k, s=s)
col = cm.ax_col_dendrogram.get_position()
self._func = func
self.func = func
tag_list = [item.tag for item in root]
step = 1
output = p.communicate()[0]
c = a + b
notepad.callback(indent_auto_detect, [NOTIFICATION.READY])
statements
result
b = Erg[:n].flatten()
self._entry = value
sess = object_session(self)
f.eval()
query = NDB_Model.query(NDB_Model.some_property == some_value)
current = current[markerpos + len(marker):]
a.x = b
stat = tun.poll()
a = df.values
self.do_open(self.getConnection, req)
1.0 / maxComponent
my_stats = CustomAggregateStats()
compilled_rules = {}
res = randr.get_screen_resources(window)
pct_same = sum(is_same) * 100 / len(master)
print(config_root.sites.mysite.owner.phone)
1
wrapper
raw = b64decode(repad(enc))
C = Z
execute(pageFormat, [])
scatter(x, y)
opener = build_opener(HTTPCookieProcessor(CookieJar()))
title = models.CharField(max_length=500)
obj
self.read_limit = read_limit
birth_years = {}
1
result.append(flatten_dict(d))
print(max(wn.path_similarity(good, great), wn.path_similarity(great, good)))
astrd = 1
data
m = MyClass()
predict_mean_ci_low, predict_mean_ci_upp = data[:, 4:6].T
dev = usb.core.find(idVendor=1118, idProduct=1920)
ni.ifaddresses.__doc__
True
data.append(text)
datalines = []
2.0 * math.pi
product = 1
mean_params, std_params = bootstrap(data)
x = 2
pg_a_genotypes = models.TextField()
min_date = min(murders.index)
display(fig)
serializer.object.user_id = 15
fd, path = mkstemp()
self.code_to_run_when_match(position)
last = df.irow(0)
rval, frame = vc.read()
source_vertex.index == source_vertex_id
g = [0.0] * 2
result = []
logging.debug(hexs)
y = np.zeros([num_steps + 1, 2])
N = len(t) // 2 + 1
xedges[-1] += 1e-06
combos = {sorted(scores) for scores in itertools.product(*card_scores)}
__metaclass__ = abc.ABCMeta
PostMessage(hWnd, WM_RBUTTONUP, MK_RBUTTON, lParam)
[2, 22],
domainsize = math.pow(2 * math.pi, 4) * math.pi * 1
[Test]
myObject = MyClass()
strides = x.strides
df
ui.write(e.EV_KEY, e.KEY_ENTER, 0)
outfile.write(final)
grid(True)
files = itertools.islice(files, batch_size)
x is pi
Adjust(color=0.5)
_get.raise_for_status()
b += z[i + 1]
table = batch.layer2.get_table(table_name)
l = Checkbutton(self.root, text=machine, variable=enable[machine])
it = iter(l)
countries[country.name] = country.alpha2
x = sin(angle) * self.radius.real + self.center.real
eq_dy = eq_y.diff(x)
2.24587512016
ffty = fft(y)
reader = tf.TFRecordReader()
ALLOWANCE = max(0, ALLOWANCE - x)
start *= [1, -1]
tree = html.fromstring(page_detail.content)
FF
i = 0
a, b = x
[12.0, 5.0],
t = time.time()
net.addModule(h1)
board = [[(0) for x in range(s)] for y in range(s)]
xmin, xmax = x.min(), x.max()
r = words[:1]
output.append(next_item)
idx = arange(0, values.size, n)
print(16)
fake_restaurant = FakeRestaurant.objects.get(pk=1)
x = np.linspace(1, 4, 1000)
y = pd.NaT
someList = list(range(10))
print(y)
image = cv.QueryFrame(Capture)
artigo = convert_pdf_to_txt(lista[0])
img_id, width, height = input().split()
result.Add(list[i])
self.object_list
rank = np.sqrt(deserialized.size).astype(int)
driver.get(url)
r, g, b, a
fields = company.__dict__
app.Run()
page = urllib.request.urlopen(req)
dx = ndimage.convolve(gx, image)
target[:] = source
qs
_i
print(first)
v = x[1:4]
n2 = mixture.NormalDistribution(1, 1)
d = ImportDoctor(imp)
c[i] = li[s:s + j]
cls._registry = []
s
dialog.setOption(QtGui.QFileDialog.ShowDirsOnly, True)
converters = {i: str for i in range(col_num)}
D[Xs, Ys] = map(lambda x, y: A[(x), :].dot(B[:, (y)]), Xs, Ys)
ventilator_send.send(repr(i), zmq.NOBLOCK)
a[i] = r[i]
info = response.info()
x * y * 0.5
a ^ MAX_BIT_COMPLIMENT
PyObject_HEAD
df = pd.DataFrame(reshaped_data).T
id(a.data)
sorts[length / 2]
session_1 = Session_1()
done = True
box_prob = predict_fn(cropped_img)
selftype = type(self)
module = importlib.import_module(module)
response.status_code = 500
t2 = time.clock()
self.list2[i] = x2
current_set = []
print(script.airportCode)
random.shuffle(ls)
rsum = [(0, 0)]
AwfulHackToGetTheInternedDict = ctypes.py_object
x = []
bit = 1
foo is bar
pyz = PYZ(a.pure)
scr.addstr(row, max[1] - 2, str[offset + 1], attr)
memcpy(d, rhs.d, sizeof(d))
paths = []
__abstract__ = True
jointWeightsAttribute.append(0)
setlocal
_, err = buf.Write(p.b)
create_connection(Protocol(1))
[5, 25],
new_a = []
print(number, list(foundColors[number]))
print(global_data.foo)
priv_key = RSA.importKey(priv_key_data)
end = time.clock()
python
dict_[key].add(element)
parse_uri(uri)
self.patience = patience
request, client_address = self.get_request()
stop = time.time() + 10000
count += letter.isupper()
area = trapz(y, dx=5)
570
a = [1], [2]
prev = next(iterator)
words[i] = replacement[counter]
dist = []
row = np.tile(np.arange(10 * n / 2), (2, 1)).T.flatten()
a = 4
layout.addWidget(self.textPass)
d = collections.defaultdict(lambda : d)
sw = Tix.ScrolledWindow(root, scrollbar=Tix.AUTO)
yrng = stats.logistic.pdf(xrng)
prodM = []
p = (new_x - x[k - 1]) / (x[k] - x[k - 1])
wrapper
column_name = column.compile(dialect=engine.dialect)
n = a.shape[0]
value7_set = byte & value7 == value7
match
sympy_p2 = sympy.plot(bar)
origin = 0, 0
False, rem
print(warn_header, file=sys.stderr)
y_stack_pred = LR_Multi.predict(X_stack[:, half:])
original_mod = inspect.getmodule(getattr(mod, name))
bit <<= 1
elements = iter(inverted_dict.items())
t = threading.Thread(target=load_and_enqueue)
ans = (n - 1) * stirling1(n - 1, k) + stirling1(n - 1, k - 1)
print(template.format(pid, uid, pname))
s.commit()
re.sub(pattern, replaceNthWith(n, replacement), str1)
print(example)
np.random.seed(42)
close(c)
model = TreeModel(headers, file.readAll())
iter_cons(_)
print([j._tag for j in f])
print(char, value)
False
print(data)
example_sequence = tf.train.SequenceExample()
status = status_list[0]
APPHEIGHT = 600
vbdrecord.mode = Types.VbdMode.RO
user_options = []
Notes
screen = pygame.display.set_mode((640, 480))
pred = clf.predict(X_test)
s = self.fp.read(4)
json.load(f)
self.join()
doc = Document()
stuff = [thing[1] for thing in pkgutil.iter_modules()]
whenConnected = cc.connectTCP(host, port)
index = (numpy.s_[:],) + t
args = [iter(iterable)] * n
print(data[select])
hog = cv2.HOGDescriptor()
True and 1 / 0
a = np.arange(50)
total = t1 - t0
print(parent.__doc__)
mainwin = gtk.Window()
self.__class__.counter = self.counter + 1
print(datetime_with_microseconds.microsecond)
good_results = results.select(is_good_result)
dir(aStrOBJECT)
cursor1 = db.cursor(buffered=True)
Xfit_mono[len_mono] = x
x = os.read(master, 1026)
success = True
self
new_r = np.sqrt(X * X + Y * Y)
print(list_indexes_updated)
b = np.random.randint(14440, high=14449, size=(len(index), 1))
cl = MongoClient()
key
objects = MyDoc.objects()
a.write(f)
self.im_sz = [self.im.tag[257][0], self.im.tag[256][0]]
os.unlink(db_filename)
(grid_x - centre_x) ** 2 + (grid_y - centre_y) ** 2 < radius ** 2
arr
print(match)
System.out.println(Math.toDegrees(Math.atan2(1, -1)))
y
some(**args)
type_setattro(PyTypeObject * type, PyObject * name, PyObject * value)
compressed2
im2_gray -= np.mean(im2_gray)
SHA1Hash.update(buf)
print(b)
joke
mm.close()
print(content)
self.on_finish = on_finish
ac - ropemacs - require
n = 10 ** i + 1
myfunc(2)
str_value = connection.string_literal(tuple(provider))
y
bin_range = np.arange(-200, 1000 + step, step)
decompressed_data = zlib.decompress(gz_data, 16 + zlib.MAX_WBITS)
sys.stdout = UTF8Writer(sys.stdout)
print(json.loads(r.content))
x = 42
length = 0
key += len(self)
pressed = pygame.key.get_pressed()
tuple(pool[i] for i in indices)
self.cur = self.im.tell()
gateway = JavaGateway()
print(distance_matrix)
result
z.urlencode()
r_len = 1.0
s
print(novo)
x = np.linspace(0, 10, num)
max_so_far = t[1]
df
article1.put()
sort_legend = True
data = []
tokens = tokenize.generate_tokens(reader)
last_position = -1
deletelines[:]
response
print(xy_undistorted)
teacher.py
cells[random_index] = cpuletter
fprime
_, file_name = split(full_file_path)
pytz.utc.normalize(pdtnow1)
time_object = datetime(nine_tuple[:8])
model = Question
language = Language.query.filter_by(language_name=language_name).first()
preds = rf.predict(new_X)
fast_iter(context, process_element)
fp
links = self._process_links(links)
[local]
d2 + relativedelta(months=1)
dates = matplotlib.dates.datestr2num(x_values)
g = generator()
slens[l].append(t)
print(x)
self.var1 = someNumber
a = a[np.logical_not(np.isnan(a))].ravel()
l2 = Lambda((x, y), x * y + x)
shell.SHOpenFolderAndSelectItems(folder_pidl, to_show, 0)
out.write(chunk)
q
t = django.template.loader.select_template(template_choices)
main()
tid = libc.syscall(SYS_gettid)
action_with_arg = partial(action, arg)
result
global_list = []
self.pending = args[:]
self.closed = False
result = hog.detectMultiScale(frame, **hogParams)
Base = declarative_base()
pyglet.have_avbin = True
idx = [t_values.searchsorted(data[n][:, (0)]) for n in range(num_datasets)]
hashtags = []
t1 = b[:, (0), (0)]
s.close()
serialized_data
True
System.exit(1)
item = DropboxItem()
deletedemo
f = tempfile.TemporaryFile()
print(f)
z = iter(z)
d1[i] = i
first_scheduled_task = datetime(year=2012, month=1, day=2)
4
sum(while_equal(seq, other))
print(t)
include_files.append((os.path.join(include_dll_path, lib), lib))
k = 1e-09
callback = self.print_callback.__func__
FIELD1 = 61440
y_pred = K.cast(K.greater(K.clip(y_pred, 0, 1), threshold_value), K.floatx())
around(-0.5)
result[t[0]] += D_grpTagReport[t]
arr_1 * 2
some_list = sample(list(population), n)
chunk_length = len(sound) / img_width
[p for p in L if _in_koch(p, V, n)]
print(unicodedata.name(c))
D = defaultdict(int)
num_converted = [0]
print(i)
print(a)
normal_pdf(k, n * p, n * p * (1.0 - p))
Pygments - (1.5).tar.gz
phaseA = math.pi / 1.5
print(result)
province = db.StringProperty()
print(mm[24:])
infile = sock.makefile()
timeAdded = db.DateTimeProperty(auto_now_add=True)
os.close(pipe_r)
n += 1
seq = np.empty(lag_seq.sum() + n_iter * n_reg, dtype=int)
c = Counter()
ctx = Context(f, data=range(10000000))
scan_value(start, stop, step)
block = file.read(block_size)
processLine(line)
shift = [10, 15, 20]
splitNet()
credentials
day = udf(lambda date_time: date_time.day, IntegerType())
dropped = self.ix[labels]
writer.WriteAllTimeSteps = 1
conv = locale.localeconv()
cat / home / datafireball / anaconda / bin / pip
denominator = math.sqrt(sum1) * math.sqrt(sum2)
parser = my_argparse.MyArgparse
left + right
i = self.__getitem__(key)
parsed_args = a.parse_args()
A = sps.rand(10000, 10000, density=1e-05)
dstv[dstybase + yoff][dstxbase + xoff] = convert(srcv, yoff, xoff)
days = testDf.columns[1:]
gen = func(*args, **kw)
merged = []
print(locmem._caches)
blah(x)
storage.put(credentials)
n >>= 1
a = 5
words = text.split()
plt.show
__IPYTHON__
a = 5,
spl = line.split()
dir(datetime)
my_rand.counter = 0
iter = NpyIter_New(X, NPY_ITER_READONLY, NPY_KEEPORDER, NPY_NO_CASTING, dtype)
x = x * cos(90) - y * sin(90)
normalized
4
ds = SupervisedDataSet(1, 1)
B.setdiag(c)
formatter.end_section()
msvcrt.setmode(sys.stdout.fileno(), os.O_BINARY)
print(config[0])
self.spiffy_obj = spiffy_obj
ax = s.plot.bar(width=0.8)
entry = gtk.Entry()
C(n)
Boolean = true
updates_sgd = sgd(loss, params, learning_rate=0.0001)
powerOfSum()
logger = MyProcess()
int(val)
black = 0, 0, 0
cmdline.append(from_addr)
test, len(temp_line)
5
trace = sample(2000, step, start=start)
total += sign * partition_new(n - k)
a = 1
newWindow = hildon.Window()
main = qt.QWidget()
y = np.random.randn(1000)
self.baz
self.valid_value = valid_value
a = c - d
lines = shopping.readlines()
page = 0
y = p.Y(q.X())
N += 1
result
raise Http404
parser.parser.parse = parse
clusters[idx].remove(element)
startTime = float(row[0])
t.amount
print(x.val)
data = f.read()
x_a, y_a = A.shape
name = args.name
self.proc.stdin.write(data)
event = action.get_event
arr
baud_rate = 4800
numyears = x[6]
tolerate = np.all(narray[1:] - narray[0] < lev_tol)
b_conv1 = bias_variable([1])
[self[ii] for ii in range(*key.indices(len(self)))]
False
pl_sequence = powerlaw_sequence(1000, exponent=2.5)
command > file.data
self.image = image
l_o_l
1.0 / 2
items = list(repo.tree().items())
modulo = 87178291199
query_stmt = ibm_db.prepare(conn, query_str)
print(paths)
parentDict[key] = {}
pdb.post_mortem(tb)
pathbuf = create_string_buffer(fontpath)
word_freq = Counter()
out = out << 1 | bit
order = np.argsort(B[:, (0)])
ans = n
[51, 51],
logger2.handlers = []
self.d = d
epoch_start = datetime.datetime(1601, 1, 1)
labels
SourcesGenerator = env.Builder(action=my_action, emitter=my_emitter)
spider = crawler.spiders.create(spname, **opts.spargs)
raise
s
0, -1
self.d[i, -1] = i + 1
grids.ravel()[unq_lin_idx] = idx_counts
lines.sort(key=gettype)
+game_score / total_hits * 0.2
_items.append((option, self[option]))
z[0] = x
sorted_ips
d2_dict
result
indent(subelem, level + 1)
opendir.restype = c_dir_p
values[l[0]] = l[1]
true
rvsmin = rvs.min()
prepdf
HttpResponse.__setitem__ = __setitem__
slugify(self._meta.verbose_name),
5.257147789001465
register = template.Library()
deleteself[name]
consoleHandler.setFormatter(logFormatter)
keysShuffled = list(word_drills)
mid = (lo + hi) / 2
deps.difference_update(emitted)
val = 0
w = cos(theta / 2.0)
ret.dealloc_cb_arg = dealloc_cb_arg
thebigrams = []
users = {}
temp.append(item)
timeit(f2, number=100)
yaj = func(x, coeffs[0], coeffs[1], coeffs[2])
value = Ks.data
a = list(range(10))
o
commonNamesToConnections[client.get_peer_certificate().commonName] = client
m.drawmapboundary(fill_color=oceanColor)
raise StopIteration
regressor = RandomForestRegressor(n_estimators=150, min_samples_split=1)
unival_inds = [np.transpose(np.where(M == unival)) for unival in uniques]
X.todense()
in_network = a & mask == netw
self.sum = 0
overlapping_intervals = tree.overlap(result[-1])
print(t, sum(item[1] for item in q) / count, count)
func = deco(func)
e.args
ar = np.array([True, False, True, True, True])
print(repr(d))
ipshell = IPShellEmbed(user_ns=namespace, banner=banner)
print(1)
self.value = value
df[key[1]][key[0]] = value
done < requirements.pip
start = 0
L = []
X = np.random.rand(r, n, p)
jsonify(failure=0, errors=inputs.errors)
self.window.show()
w = u * v
ans = []
x = a * phi - b * np.sin(phi)
df
ListWrap(self.__d[attr])
result
print(s)
INNER_LOOP = 10000
_, p_c = scipy.stats.ttest_ind(df_a.dropna(axis=0), df_c.dropna(axis=0))
all_lines = f1.readlines()
out = {}
print(token.orth_, token.tag_, token.head.lemma_)
x.upper()
j = 0
values = np.array(values)
a_list
b = []
impfile = filename[:4]
a.save()
True
bar = foo.__enter__()
image = Images.get(key)
raise
discon = True
rows_list.append(dict1)
time_in_seconds = hours * 60 * 60 + minutes * 60 + seconds
40
dests_p = pointer(dests)
x
print(rendered2)
y = ytrue + np.random.normal(size=len(x))
notification.setUserInfo_(userInfo)
b = 1
console_handler = logging.StreamHandler()
lower_white = np.array([0, 0, 255 - sensitivity])
errno, strerror = e.args
current_time = tf.gather(times, current_index)
list(zip(df.index[r], df.columns[c]))
doc.rank = i
pair = [[remainder[0], remainder[i]]]
index = a.index(i)
data = pickle.loads(col.column.value)
a1 = np.asmatrix(a1)
self.inserts = set()
item = force_decode(item)
concat_tups(x, y2)
int(-0.5)
1
picked = []
waiter = asyncio.Future(loop=self._loop)
handlers = nullHandler
converter()
library(Rsolnp)
result
district = x[0]
path = find_recursive(needle, item)
-np.sum(prob * np.log2(prob))
df = s.to_frame()
self.q.task_done()
mypad_pos += 1
self._value = value
comm = MPI.COMM_WORLD
obj = ExampleObject()
tags = KEYWORD
years = np.asarray(years) - 1970
ID_unique, value_sums = group_by.sum(value.flatten())
draw = ImageDraw.Draw(image)
Pool(processes, initializer)
zsum += area * z[tri].mean(axis=0)
data_id = dict(zip(unqs, np.arange(data.size)))
1
dic[100]
da, db = pxdom.parseString(a), pxdom.parseString(a)
cols_via_iloc(df)
NPP_SAVE
b = 1 - 2 * d
back.show()
mean = lambda x: sum(x) / float(len(x))
bluez = CDLL(btlib, use_errno=True)
self.max_obj_num = max_obj_num
self.Centre()
args = parser.parse_args()
raise StopIteration
r = self.proxy_auth(r)
b
object_id = id_regex.findall(your_url)[0]
rootlist, decimal_point_index
table[0] = z
that()
item = int(item)
get_next_id = itertools.count().__next__
ax[m, n] = plt.subplot(gs[m, n])
print(a)
B[k - 1]
flag = False
a - 1.0
qs = {}
i += 1
boby.bark()
se = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (minThick, minThick))
shared_dict = {}
x1 = (y2 - y0) * 0.5 / (2 * y1 - y2 - y0)
raise Exception
list2 = list(list1)
listOfN.append(num)
self.xlApp.Visible = Visible
sumsquares = np.sum(diff)
PR_SET_PDEATHSIG = 1
toRemove = [0, 2]
entry = Dirent.from_address(p)
norms
myfoo
glViewport(0, 0, window.width, window.height)
p = libc.readdir64(dir_)
print(test_runs[test_runs.TestName.isin(tests.unique())])
theta = np.arccos(x / r)
f2 = (arctan(-x + 2) + pi / 2) / pi
c = i[2] // 1 * 60
tuple(map(_convert, node.elts))
result[counter, 0] = (helper < -7.55).sum()
print(content)
mf = modulefinder.ModuleFinder()
c = pymongo.Connection()
length = np.linalg.norm(gauss)
imageSmall = cv2.pyrDown(image)
u = random(0, 1)
mult_out = a * b_reshaped
print(Crypto.__file__)
DeleteValue(key, name)
py > ast.body[1].value._fields
options[state]
app.MainLoop()
a = 1, 2
new_rows = df[split_rows].copy()
cipher = PKCS1_PSS.new(key)
a().x
group = [line]
size = len(matrix)
items = items[1:]
configParser = ConfigParser.ConfigParser()
C = A * R
ret.setServiceParent(service.IServiceCollection(application))
combination_den = list(range(1, n - k + 1))
d = ClassificationDataSet(2)
ext_modules = ext_modules(),
mid = (low + high) // 2
count
print(x)
self.cycles += 1
k = KDTree(a)
node
1 - 0.478
r.insert(0, c)
result = Quaternion.from_value(np.array((w, x, y, z)))
n % 400
sum(x)
entry = entry.strip().lower()
dic = Counter(e)
idx = pd.IndexSlice
Y = list(range(size))
free_bytes = ctypes.c_ulonglong(0)
invalid_escape.sub(replace_with_byte, brokenjson)
print(shiftedarray)
threshold = 0.5 * max(abs(spectrum))
result
print(finder.report())
moon
y = [0, 9, 18]
message
foo = they.method.method.method()
right = units[count - half - 1 + 1:][::-1]
self.func(other)
X_est = dot(A, Y)
dLock.acquire()
mllib_linalg.DenseVector(v.values)
my_cmap_r
self.help += message
data_frame = data_frame.drop(column_name, axis=1)
14
print(i)
clf = PCA(var_per)
self.update(v[k])
asyncore.loop()
args = parser.parse_args()
newPos
flag = True
print(df1)
logging.captureWarnings(True)
k = k - 1
results = []
deletescipy
print(a == b)
self.__dict__.update(state)
sign = 1.0
buffer = StringIO.StringIO()
ans.load(bit)
conf_int_a = stats.norm.interval(0.68, loc=mean, scale=sigma)
assert START == pickle.loads(pickle.dumps(START))
handle_false()
deletemyclass
A_comp = A.view(dtype=np.complex128)
c = self.ws.cell(row=row_dest, column=column_dest)
obj
doctest.testmod()
wd.food(2.5)
link = soup.a
weights = rx.findall(email)
print(volumeNameBuffer.value)
False
close(4)
ans = []
mbuf_len = BIO_gets(fbio, mbuf, BUFSIZZ)
data = np.random.rand(50000000)
pypreprocessor.parse()
tag_dict[tag].append(word)
self.context.pop()
2 ** 2
self
p = multiprocessing.Process(write_pdf, args=(pdf, pdf_queue))
source_code = requests.get(url)
Y = fft(wolfer)
N = 2000000
i
print(l)
q = m.Queue()
starts = np.array([1, 4, 2])
get_cached_media(self, js, css)
False
True
2 & 1
model = Organism
ctr_left.depth + 1
t = asarray(t)
0
row1 = adj_matrix[:row]
_entry = __table__.c.entry
print(df)
it.remove(i + 1)
alias.update_points()
arr[mask]
server_thread.daemon = True
jsondata = json.dumps(body)
acc = accumulator(0)
Base = declarative_base()
b[np.invert(b.mask)] = 1000
int_w = int(np.rint(w))
pid = window.get_pid()
children = node.getchildren()
unique_mean = np.bincount(unq_inv, values) / unq_cnt
len(queryset_1)
20090224
theta = 2 * np.pi * r / 90
store.remove(file)
a * d
body = obj.body
i = 99
z = [0, 1, 0, 1]
a == b
a, b = p, i
s = Mtx.sum(0)
num = np.array([data_id[datum] for datum in data])
condition
plot = plotting.figure(tools=tools)
c = conn.cursor()
boundRect[i] = boundingRect(Mat(contours_poly[i]))
node = Node()
myfab = FabricSupport()
tt = np.linspace(0, 1, 200)
params = {}
chr(int(ent))
first = splitted[0]
K += w1 * numpy.exp(-mu * chi)
test1()
module = sys.modules[modulename]
x[0] = 8
x = np.arange(6)
b = a[np.where((a > -1) & (a < 1))]
tmp.MyEnum.B
err = PyDict_SetItem(map, key, value)
print(firstNumber)
d1 = numpy.array([0, 0, 1, 0])
a * np.exp(-b * x) + c
speed = models.SmallIntegerField()
d2 = dict(d1)
bad_files = []
deleteself._bwd[_val]
editor_list = models.ManyToManyField(EditorList)
ids = []
alpha = -0.750000000928
MyClass.ff[0]
print(EvaluatorCompiler().process(bool_clause)(a_foo))
hildon.Window
date.strftime(cls.getPythonDateFormatForCurrentLocale())
d = {}
sigma = sqrt(diag(cov))
tmp_filename = os.tempnam(tmp_dir)
x = x * s2pi
unq_sum = np.bincount(unq_idx, weights=A[1])
mock_object = Mock(MyClass)
total = sum(w for c, w in choices)
print(data)
_part(n, k, n)
ratio, word = max(_match(matcher, word.lower()) for word in headwords)
__builtins__._ = value
_pywrap_tensorflow = swig_import_helper()
b = [9, 10]
linear_regression = LinearRegression()
t = a % b
b = [-1, 1, -1, 1, -1]
MAX = 100
print(CURSOR_UP_ONE + ERASE_LINE)
A = np.zeros(p.shape[:1] + (n - 1, n - 1), float)
FooForm
downloaded = 0
magic_slice = slice(args[0], args[1])
print(token, lookahead_1)
Result[Result_position[i]:Result_position[i + 1]] = xx
fixedpos = {(1): (0, 0), (6): (1, 1), (11): (1, 0), (16): (0, 1)}
a, b = os.path.split(self.photo.name)
freq = np.fft.fftfreq(N, 1)
result = asarray(result)
encoded = jsonpickle.encode(Pizza())
res = []
s.title
zsum = np.zeros(z[0].shape)
od[k] = od[k] + ele[1:]
get_errno_loc.restype = POINTER(c_int)
exec(code, module.__dict__)
memory_file = StringIO.StringIO()
full_html
maxcount = Math.max(currcount, maxcount)
port = 1219
random_order = list(range(nStudents))
agency = int(bits[40:52], 2)
it = iter(seq)
segment = x[start:stop]
a[a_true] = 1e+20
session_factory = sessionmaker(bind=some_engine)
QTest.mouseRelease(widget_to_release, Qt.LeftButton)
c[next_item] -= 1
z = -1 + 0j
update_all_slots(type)
byte & mask2, byte & mask1, byte & mask0
a = lst[0]
pdb.set_trace()
self.get()
0 <= s <= 0.2
t = []
a = time2seconds(a)
flipped = {}
s += num
patient.bed.room.unit, patient.bed.room.order, patient.bed.order
print(modnames - aliases)
b = df.as_blocks(copy=False)
deser = TypeDeserializer()
value
env = builder.get_environ()
ArtofWarCounter = Counter(ArtofWarLIST)
result = []
total_time = time() - start
out = groupCoords[(cdist(groupCoords, Arr) < 1.5).any(1)]
main()
cleaner.clean()
a[:, (1), :] = [88, 88, 88]
self.queued_items = toro.Queue()
refresh()
pycvex_Stitcher_Type.tp_dealloc = pycvex_Stitcher_dealloc
my_uuid
i * i
t = np.arange(0.0, 1.0, 0.01)
points = []
cumprob = float(cumprob)
df
myfoo
modul not in mod_ignore and func not in func_ignore and clas not in clas_ignore
self.maxidx = max(idx, self.maxidx)
pos = 0
d = {}
input_lists, overflows
interest = json.loads(raw_response.content)
l = list()
self.filename = filename
readline.insert_text(indent)
result = self.obj.__getitem__(self.order[self.cnt])
defaultdict.__init__(self, default)
results[j, i] = (mask[i] & mask[j]).sum()
t2 = time.time()
g()
creds = store.get()
p = str(primes.pop())
label = QLabel()
socket.send(data)
timeout -= poll_period
diff = cal.parseDT(time_str, sourceTime=datetime.min)[0] - datetime.min
int(numlit)
bin_edges = np.arange(100)
splitS = []
rot = np.rad2deg(np.arctan2(*a)) - 90
pnt.transform(desired_srid)
a = 1 + 2
images = [im[s] for s in slices]
print(toeplitz(first_col, first_row))
conv2d = T.signal.conv.conv2d
q.join()
r = get_response(url)
A = np.ascontiguousarray(A)
print(d)
items[elem.tag].append(pt(context, elem))
args.append(trailing)
python
b = layout.takeAt(2)
width = GetSystemMetrics(0)
count = len(units)
type = mimetypes.guess_type(filename)
Acol_ext = np.concatenate(([0], (Acol == 0) + 0, [0]))
result = etree.tostring(obj2)
print(end - start)
e = len(repr(n)) - 2
nxt = next(self.it)
9
self.bar = backup.bar
a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2.0) ** 2
window = [-1, 0, 1]
end -= 1
vertexAttribute[6], vertexAttribute[7], vertexAttribute[8]
plot(xdata, ydata)
colormap.Build()
self.windows = []
n, m = len(seq), P - N + 1
listOfN.append(num)
json = simplejson.dumps(my_structure)
rotated_array = lh.dot(rot)
cache.append(v)
tdata += s.read(data_left)
cmap2._lut[:, (-1)] = alphas
it = foo()
rs.append(r)
self.__theme_name = name
print(data)
x1 = amplitudes[0]
client_secret, refresh_token, expires_at
waypointGeometries = lyr.get_geoms()
random.Random(4).shuffle(x)
inner *= P(n, m, math.sin(lam))
[next(it) for it in islice(iters, len(a))]
result += i
unique_idx = np.array(idx)[z][unique]
binary = []
row = [x.strip() for x in row]
my_thread = x.ExceptionRaiser()
nz_values = foo[nonzero_values]
filesContainString.append(file)
file_date_tuple_list = []
info = resource.getrusage(resource.RUSAGE_CHILDREN)
browserParms = sys.argv[2]
acceptance_prob = (proposal - low) / (mode - low)
s_part = np.sort(partitions, axis=1)
url = q.get()
d - 1
csvfile = cStringIO.StringIO()
argv[1:] = [int(x) for x in argv[1:]]
threads = [t for t in threads if t.isAlive()]
[client]
chunk = fp.read(n)
bw = 51 * ((int(b) + 25) // 51)
dataset = workflow[0]
result = f(*args, **kw)
self._pending_jobs.append((job, jobstore, replace_existing))
_str2dict = set
ac = a.copy()
f
main_timestamp = split_timestamp[0]
modifiedDirList.append(name)
x = [([j] * k) for j in range(n)]
E_F_delta = np.sum(A_f[maximum_ix]) / 2
print(earlyBound.ActiveCell())
df_ar = df_a.reindex(df_a.index | df_b.index)
print(i)
i = 0
sigstr + pstr
setattr(namespace, self.dest, values)
diff.update({id: new[id] for id in created})
out_beta.append(model_ols.coef_[0][0])
file_object = urllib.request.urlopen(url)
tic()
X_scaled = preprocessing.scale(X)
print(get_ind_num())
out
print(x)
[prev]
value = line.strip()
wrapper
p1 = func(p0, *args)
userhome = join(dirname(userhome), path[1:i])
elapsed = time.perf_counter() - start
count = dll.func(byref(pfoo))
separate(self, sep)
target.switch(code, watcher.switch)
add = partial(operator.mul, 2)
a = A()
data = callvim()
ab_sum, a_sum, b_sum = 0, 0, 0
index.exposed = True
haha[1, 1] += 1
positions[1:-1]
x + x
frac, whole = math.modf(2.5)
print(new)
farglocker = ArgLocker()
s1 = frozenset(s1_tuple)
instances = list(chain.from_iterable(map(lambda r: r.instances, reservations)))
someOtherFunction(newParam, result)
RATE = wf.getframerate()
status.put([filename, (i + 1.0) / count])
print(d)
[lon, lat, z] = ctran.TransformPoint(lon, lat)
Q = [7, 8]
shape = tuple(image.shape)
max_char
x = np.zeros([num_steps + 1, 2])
res = conn.getresponse()
counter += 1
Xdb = 20 * scipy.log10(scipy.absolute(X))
dict_a = tupl[1]
inv = fig.transFigure.inverted()
raise
n = (npa[:, (0)] ** 2 + npa[:, (1)] ** 2) ** -0.5
self.pipe[1]
lst[ix] = val
print()
ret[k] = scrub(v)
layout = PangoCairo.create_layout(ctx)
r = random.uniform(0, total)
x = np.linspace(0, amplitude, section + 1)
intersection = required.intersection(set(request.json.keys()))
fibs[n]
alldays.MAXTICKS = 2000
_get_node(node.nodelist, context, name)
n, m = len(a), len(b)
output.value
sid = transaction.savepoint()
lines = sources.readlines()
workgroup, settings.USERNAME, settings.PASSWORD
int = __builtin__.int
total = progressbar.ProgressBar(maxval=50)
arr = np.random.random((N, N))
self.document = document
col2 = list(cytoolz.concat(c2))
pids.remove(pid)
a_list[i + 2] = np.NaN
__setitem__ = xtend(list.__setitem__)
self._change += 1
data = sp.zeros((6, 6))
df
chars = []
approxPolyDP(Mat(contours[i]), contours_poly[i], 10, true)
x = X[-1] + dt * dx
self.x, self.y, self.z = x, y, z
True
m.assert_any_call(4)
dl = pc.datalink()
path
v += 255
print(np)
chunksize = 0
imgdata.seek(0)
1, 6
n, bins = np.histogram(data, nBins, rng)
skipped = dropwhile(lambda x: x != 4, cycled)
snake.update(RIGHT)
std_lib = sysconfig.get_python_lib(standard_lib=True)
is_max_found = True
rawbytes
print(res(st, sa))
probs.append(np.mean(np.logical_and(X == c1, Y == c2)))
nwords = int(argv[1])
recipe_list_json = json.dumps(list)
shape = a.shape[:-1] + (a.shape[-1] - step + 1, step)
print(stdin)
count = 0
a
key.verify_update(signedData)
index = 0
pacific = pac.localize(t1)
MyClass(index)
mx[1]
pygame.draw.ellipse(screen, BLUE, ball_rect)
person = p.Person()
0 & 1
col = x.strip().split()
g = (i for i in range(times))
create_connection(lambda : Protocol(1))
new_char, position + 1
my_handler.setFormatter(my_formatter)
fig = plt.figure()
pos_y = screen_height - window_height
player = OneToOneField(Player, primary_key=True)
N = len(board)
id(b)
mkl_set_num_threads(1)
your_app
kx = (w - 1) / (x1 - x0)
self.manager.app.stop()
y = np.linspace(-100.0, 100.0, ny)
gender = gender_from_name(name)
out, _ = p.communicate(s.encode())
width = int(np.log2(factors.max()) // 1 + 1)
samples[i] = np.random.exponential()
xyz = np.ogrid[0:x, 0:y] + [c]
g0 = Piecewise([(piece[0], piece[1] - g(0)) for piece in g.list()])
d = data[4:]
x = 0
mask[l:r] = True
t = len(dist)
print(match)
mydestination = localhost.server.com, localhost, example.com
palette = itertools.cycle(sns.color_palette())
result = temp1.add(temp2, fill_value=0)
temp = list()
d = {}
data.fromArray(mix)
options
print(c_char_p(cdll.msvcrt.ctime(addressof(intTime))).value)
list(range(x, y)) | sum | f[_ ** 2]
x, y = rh.x(t), rh.y(t)
list_contains(PyListObject * a, PyObject * el)
cwd = os.getcwd()
n % 4
config = ConfigParser.RawConfigParser()
head, sep_, tail = line.partition(sep)
s
p2d = np.vstack([X2, Y2]).T
rvs = stats.pareto.rvs(shape, loc=loc, scale=scale, size=1000)
max_mtime = 0
obj.text_size = max(obj._label.content_width, obj.parent.width), obj.height
status = db.Column(StatusType.db_type())
toRemove = set([0, 2])
session = Session.objects.get(session_key=my_key)
J, I = np.ogrid[:yt, :xt]
application.listen(port)
ret = self.qlist.get(self.index)
pickle_str = pickle.dumps(obj)
__repr__ = dict.__repr__
mod = __import__(testName)
array = []
assert isinstance(d, dict)
result
print(make_canonical([12, 8 | 1]))
mtime = 0
ret[-len(tmp):] = tmp
duplicates = set()
load_data_2()
[8][9]
print(is_alternating_signs([-1, 1, -1, 1, -1]))
self.url = url
self._db_recycles = 0
s = s - 1
jsonstring = args[i + 1]
myList = list(range(10))
type(future_class_name, future_class_parents, uppercase_attr)
key in self.store
segmentation = qt.QApplication(sys.argv)
new_time
sig_objs = collections.defaultdict(list)
guess_k = np.argmax(np.fft.rfft(Y))
a = 9876
end = time.clock()
value_when_true if condition else value_when_false
weight = lrate * (CD / nCases - cost)
self.val = val
n = len(b)
plt.hist(xr, normed=True)
tidx = np.random.choice(tidx, smp_n, False)
records.pop(idx)
ans = []
nextPageLink = urlparse.urljoin(response.url, nextPageLink)
self.scores_matrix[m - 1, n - 1]
ready_socks, _, _ = select.select(socks, [], [])
str = str
nrows, ncols = arr.shape
content = self.gzipencode(strcontent)
seen = set()
buf[idx % BUF_SIZE] = val
self.button.config(state=tk.DISABLED)
mat.polySphere(radius=5)
x ** 2
deleted
tasks = Task.objects.all()
i.update(add_to_set__parents=i2)
m[pd.isnull(m)] = m.T[pd.isnull(m)]
opener = urllib.request.build_opener(proxy)
currentid = ptest.iloc[x, 0]
reactor.callLater(0.1, follow, fObj)
GObject.type_register(GtkSource.View)
smart_unicode(obj)
print(result.summary())
index = len(s)
a > b
names = map(lambda table: table.Name, my_list)
sys.exit(2)
(a ** b ** 5) ** b ** 10
exc_name = type(e).__name__
print(counter)
user_ns = {}
app.initialize(argv=[])
rdd.squares = types.MethodType(squares, rdd)
s
output, err = p.communicate()
df
n = sample_power_probtest(0.1, 0.11, power=0.8, sig=0.05)
self.constants_dict = {}
obj.__name__ = key
listname.append(diction)
0
orig = np.sort(df.groups.unique())
func2()
flattened = [item for sublist in segments for item in sublist]
num_frames = stream.getnframes()
df.formatted_dt.astype(np.int64)
list(normfilter(a, 5.0))
dictionary
filters = dict(zip(split[::2], split[1::2]))
persons = []
id_chain.reverse()
x = 2,
airport
items.update(cur_elem.attrib)
register = template.Library()
original_text
it = itertools.product(*coords)
api = Api(app)
squared = lambda x: x ** 2
m.logout()
Add(5)(10)
filled = ndimage.morphology.binary_fill_holes(thresh)
fcond = threading.Condition()
d = sch.distance.pdist(X)
print(letter)
exc_info = sys.exc_info()
response = r.get_result()
x = r * np.cos(theta)
jinja2.Markup(self.template % str(csrf_token))
print(row)
resargs = docopt(__doc__)
print(np.asarray(target).shape)
print(p.parent.resolve() / p.name)
iter(self.ranges)
primfac = []
x
print(b)
_ = lambda x, y: x + y
mapping = dict(a)
4
df.new_group.iat[n] = df.new_group.iat[n - 1]
test_a
self.outd = outd
b = a - 1
pygame.init()
print(min_unfairness)
True
group.members.add(user)
stream = pyte.ByteStream()
zip(self.__keys, self.__values)
self.forget()
MIN_SHAPE = np.asarray((5, 5))
print(y[0])
out = []
df == 0
data = img.getImg()
ok = True
seen = set()
B = np.empty((10, 2))
window.add(lead_obs)
main = Tk()
res.append((op, arg))
group_dict[name, dte].append(time)
page = urllib.request.urlopen(pageurl)
conn = connect()
xd = pd.ExcelFile(socket)
end_col = col_slice.stop
x2_Kcids_1 = np.empty_like(x2_Kaxs_1).reshape(-1)
res = batch.submit()
this.point_count
output = str(op.stdout.read())
lookup = {}
b = Column(Integer)
print(variable_to_query)
use_cython = False
cart.name = book.name
ngram[token][next_token] += 1
max_time = min_time + slot_size * len(f)
lib.LoadLibraryFromItem(i, storagecon.STGM_READ)
form = EmployeeForm(pDict)
y = np.linspace(0, 1, 20)
data
[(l, u - 1)] if T else []
then = (now + relativedelta(months=2)).replace(day=1)
df_small
tree = root
print(c)
rows = [Row(row.title, row.created_on) for row in data]
ctypes.pythonapi.Py_DecRef(arrayobj)
object_list.none()
b = ones((10, 2))
current_page = paginator.page(1)
a
True
parts = remove_common_prefix(*(part[::-1] for part in parts))
h = (n - 1) * p
all_combos.append(current_combo)
string
SOMETHING_SPECIAL
good_emails = []
key = record.key()
r = sum(s > tol)
sqrt()
print(subkey, value)
100
_
stopped_tokens = [i for i in tokens if not i in en_stop]
my_set |= {2}
ts_cutoff = np.linspace(0, time_delta_in_hours[-1], n + 1)
[16, 17],
print(x)
closest_matches(d, [20, 60, 200])
cc_btm += new_connected_triplets + new_open_triplets
renderer.props.wrap_width = 100
i = -1
n = np.fromstring(data, np.uint16)
strings.map(println)
self.value = value
masked = numpy.ma.MaskedArray(weights_stretched, numpy.logical_not(values))
y = set(y)
num_silent = 0
print(error)
json_object = json.load(fh)
od = OrderedDict().fromkeys(zip(alist, blist))
final_q = final_q & Q(subthing_set__subproperty__in=sub_vals)
p = p0 - (p1 - p0) * (p1 - p0) / d
ssB = (B_mB ** 2).sum(1)
self.asList = False
print(list_of_tokens)
value
sol1 = sl.solve(a, b)
field_value = x.children[1].rawsource
x1 = z * polevl(z, P2) / polevl(z, Q2)
names = {}
win_len = GetWindowTextLengthW(hwnd)
lookup_dict = {}
env.password = env.passwords[env.host_string] = password
0
print(v.nodes)
standard_c_lib.__error()
update_progress_bar()
deletex
{key, [origin_1, values]}
b = null
False
transformed_file_contents = format(file_contents)
dir(cjson)
axes[1].pcolormesh(np.array(d2), cmap=plt.cm.coolwarm)
basemsg = MIMEText(body)
setattr(visit, key, loc[key])
result = (com for com in permutations(weights) if sum(com) == 0)
possible_hits = numpy.where(disc >= 0.0)
f = UnivariateSpline(height, temp)
self.our_baseclass_instance[key]
futures = []
print(infer_freq(aapl))
X
subset_b = (40 < a) & (a <= 80)
header = next(csv_file_object)
math.trunc(1.5)
local_minima_locations = detect_local_minima(arr)
n_k_d[k][d] -= 1
a = df.values
result = []
EMAIL_PORT = 465
user2_auto = forms.CharField()
foo = 100
soup4
1j * alpha * y
print(file2.SomeClass())
self.app = app
lst = eval(lst)
group.loc[idx, new_col_name] = time_avg
self.x = x
k = m.copy()
i = 10 * array(list(range(n / 10)))
[list(m.values()) for m in op][1]
particles = []
a2 = a.copy()
com.port = port
pt.SetPoint_2D(0, lon, lat)
cur_pred = clf.predict(X[valid_idx])
tuple
Scalar(self._val(*args, **kwargs))
set_columns(len, pos + 1)
print(a * 5)
pool_outputs = pool.map(compute_something, inputs)
names_and_values[:, 1::2] = values
myFunc(params)
boundField = forms.forms.BoundField(form, form.fields[key], key)
xx = arange(-2 * pi, 2 * pi, 0.2)
d = np.diff(np.concatenate(([0.0], c[n])))
arr_h = np.asarray(haystack)
plt.hist(samps, bins=20)
low[:i] + mid
running_procs.remove(proc)
startDatetime = datetime.datetime.now()
seq = data[start:stop]
a_end = a_start + chunk.shape[0]
salt = os.urandom(8)
df = (df > 0).replace(to_replace=column_dict)
x.__contains__ = lambda : True
X_transformed = pca.fit_transform(X)
t1_stop = threading.Event()
result.get(propagate=False)
1
0
deployme(decode_json)
y = data[:, (1)]
Listlinker = []
nums[nums[0]], nums[0] = nums[0], nums[nums[0]]
packet = eventList.read(24)
remote_name = (wintypes.WCHAR * length[0])()
h = SHA.new()
out_csv = csv.writer(csvfile)
modname = os.path.splitext(c)[0]
[output]
--vnc
results
tiff.seek(tiff.tell() + 1)
ID = 0
acells[x] = board[x[0]][x[1]]
df
16, 4
m.SelectObject(wx.NullBitmap)
inds[0] = start[0]
addItemToStorage(e.target)
y = np.log(y)
p
image = tf.image.decode_jpeg(image_str_tensor, channels=CHANNELS)
old_pos = in_.tell()
raise ctypes.WinError(ctypes.get_last_error())
x = [0, 1, 1, 0]
results = pd.concat((table1, table2[cols_in_table1]))
serverhash = serverHashFunction(str(serverhash) + str(i))
reversed_pos_min = np.argmin(reversed_row)
N = a.size
print(thresholded_edge_indices)
idx0
self.b_b = self.modela.a_b
rotated = [x] + (list(rotate_left(x)) if len(x) > 1 else [])
item = i, xyz_list.count(i)
v = d[k]
self._hash = hash((self.label, self.vec))
AA = pd.DataFrame(d)
pen.append((x, y - 1))
stops = np.array([6, 7, 8])
map_matrix_cv = cv.fromarray(mapping)
print(parser.last_link)
trainer = BackpropTrainer(net, ds)
self.connected = 1
coord = tf.train.Coordinator()
print(vars(ex))
place_id = places[0].id
time -= delta
comb(600 + 600, 600) == 1e1000
count = 0
signal = np.random.rand(1000000)
xs[0] is a and xs[1] is a
ord_dict = OrderedDict()
print(key)
subtraction = int(start_big) - int(start_small)
result = chrs[0]
formatter.add_text(action_group.description)
next_time += datetime.timedelta(minute=1)
writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
print(Q.dot(Q.T))
filters = {}
type(webcontent)
0
temp = []
cond = df2[col2].isin(df1[col1]).all()
ins = table.insert()
mpl.rcParams.update(theme.get_rcParams())
a[idx] = a_shifted[idx]
print(x)
data
result
self.pool[self.index - 1]
posts = cycle(list(range(NBUCKETS)))
result = []
Foo.c
d1 = cv2.absdiff(t2, t1)
net.randomize()
PyObject * array_like_to_numpy(ArrayLike & obj)
print(set_1 == set_2)
y = np.array([4, 11, 8, 5, 6, 4])
nums[0], nums[nums[0]] = nums[nums[0]], nums[0]
thread_1()
assert isinstance(D)
user = self.get_object()
tor_c = socket.create_connection((TOR_CTRL_HOST, TOR_CTRL_PORT))
x = 5
G = nx.MultiDiGraph()
maxdepth = self.domain_depths.get(domain, self.default_depth)
constants.py
maxval = max(a[0] for a in aa)
f(self, index, *args)
cumsum = v.cumsum()
v[1].xid
Items.add(Item)
n_errors = 0
server_thread = threading.Thread(target=fake_server.serve_forever)
data = self.request.recv(self.BUFFER_SIZE)
a = [1, -1, 1, -1, 1]
bigstring.reserve(10 * buffer.size())
tbsCertificate = DerSequence()
cars = db.cars
df[s.columns] = s
panel.SetFocus()
bool.__bases__
{0} == {1}
sys.stdout = r
d = HTMLDoc()
diff = []
buffer = StringIO()
m = 2
p = 44497
True
ya = np.random.rand(10)
m_swapped[1, 2, 0] = 100
cv.CvtColor(image, grayscale, cv.CV_BGR2GRAY)
letter = s.strip()
x = func_py(cppobj)
new_list[i] = l[i]
catalan_2 = make_catalan()
x = np.atleast_2d(x)
self.running = False
entities
x = X()
dis.dis(f)
queue = [(start, end, path)]
pen.append((x + 1, y))
a[unq_idx], counts
f = opener.open(url)
num_columns = len(column_names)
BIT0 = 2 ** 0
e.addnext(sibling)
c = True and a or b
output[0] = square_sum(input)
xy = xz = yx = yz = zx = zy = np.zeros_like(xx)
total_weight += weight
timestamp = DateTimeField(default=datetime.now)
name, value
[10, 11],
inline_instance = MyModelAdminInline(self.model, self.admin_site)
cols = []
buf.st_birthtimespec.tv_sec
dt = df.index.values
i = round(i, 2)
s += num[1]
print(val)
5
outputlist = []
sample_size = 4
sign_with_cryptography(message)
pThread = Thread(target=p.run, args=())
print(exc_type)
urls = []
nums[nums[0]], nums[0] = nums[0], nums[nums[0]]
self.__dict__[decorator.name] = value
self.portfolio = collections.defaultdict(list)
a_extm = np.hstack((True, a != 0, True))
worker2_result = worker1_result.get()
answer = eval(question)
print(A)
model = Parent
x2_Kcids = np.empty_like(x2_Kaxs)
sum -= i
_log_config_location = resource_stream(__name__, _log_config_file)
canvas = FigureCanvas(fig)
month_start = month_dates[0]
data_min = min(data)
ret = sps.csc_matrix((data, indices, indptr), shape=csc_vec.shape)
STDERR_FILENO = 2
openList.remove(current)
res = opener.open(req)
False
ax = month_series.plot.bar()
self[k]
loc, labels = plt.xticks()
request.response.headerlist = []
False
badlist = list(range(7))
alist = alist[:]
{{form2.as_p}}
float(a) / float(b)
sys.displayhook = display_as_hex
print(r)
blur.set_standard_deviation(1)
msg = self.format(record)
loop_rec(y, n - 1)
plt.subplot(211)
aes_engine = AES.new(secret_key, AES.MODE_CBC, iv)
format(1.1)
site.setId(site_listing.getId())
self.goodFood.append(food)
h.schema
cy = sum(sum(line.get_ydata()) for line in pl.lines) / n
size * 6 / 1000.0
filter = filter & Q(b=True)
print(numbers)
pythonClass = engine.Operations.Invoke(scope.GetVariable(className))
VARIABLE2
VARIABLE1
is_playbook = False,
df
app = Bottle()
RAND_BOUND = 50
self.Show()
df = pd.DataFrame(dict(A=[], test=[], another=[]), dtype=int)
res = empty(a.shape)
r, w, e = select.select([sys.stdin], [], [], 600)
1
foo2()
free(shift_data)
shapefile_record = next(fiona_collection)
help(str.istitle)
mylist
default
L.append(d)
_myext_la_SOURCES = myext.cpp
1 == True
res
result = []
X0[-1] = 0
print(x)
date1 > date2
j = len(path) - 1
fileobj.close()
writer = csv.DictWriter(csvfile, headers)
x = lower + (upper - lower) // 2
d1 = pd.get_dummies(df.stack()).groupby(level=0).sum()
print(a)
wvc = WebViewClient()
tree = hierarchy.to_tree(Z, False)
dictDemo[callid] = val
res[si][ii * seqlen:(ii + 1) * seqlen][arr == char] = 1
old_s = s
gpsp.start()
w = com.convert_robj(w)
task
sims = index[vec_lda]
conn = psycopg2.connect(dsn)
data.read()
cur = db.cursor()
e = pq(url=results_url)
conf = paramiko.SSHConfig()
regular_query_dict = QueryDict()
i = iter(x)
res, err
acc
vector[string]
dt = datetime.utcnow()
b = es.enter_context(context2)
most_expensive_cars = []
Row._make(A)
abortable_async_result = AbortableAsyncResult(myTaskId)
print(i)
d = {}
values.pop(key)
df
c = a[b]
s = hex(lnum)[2:]
block = data[:4096]
list_2 = [5, 2, 8]
folder = IO.Path.GetDirectoryName(__file__)
existing.append(string)
c = x >> 8 & 255
txt = tree.xpath(path)[0]
app_icon = QtGui.QIcon()
_wrapped_view
end = time.time()
y[2, 2] = 1000
dirs.remove(ignore)
result = self.received_buffer.getvalue()
screen - r
f = lambda t: func_m(t[0]) if t[1] else func_f(t[0])
second_largest = largest
y.__next__()
err = c_char_p()
tz._utc_transition_times
der_sig_in.decode(der_sig)
print(D)
authreq = True
labels[batch_index:batch_index + remaining_space] = data[data_index]
hash(c1) == hash(c2)
x = np.random.rand(1000)
parser = ET.iterparse(filename)
foobars.printSchema()
debug_hook(exception_type, exception, traceback)
ws_bincolor = cv2.cvtColor(255 - wsbin, cv2.COLOR_GRAY2BGR)
b = 2
df *= 100
num *= 2
self.close()
suite
labels = df.columns.labels
B(n)
settings = web.settings()
mean_sample2 = np.mean(sample2)
size = 0
c = Client()
python
x = cos(angle) * self.radius.real + self.center.real
count = 0
value
s = pd.read_csv(data, squeeze=True)
types.GeneratorType
account_dict = request.form.to_dict()
N, M = A.shape
process_images(filters.rotate, **rotate_options)
vectorizer.get_feature_names()
print(d)
f.subs(x, x * eps).subs(y, y * eps).series(eps).removeO().subs(eps, 1)
parsed_response = yaml.safe_load(response)
pwd_context = _get_pwd_context(app)
RSI1 = 100.0 - 100.0 / (1.0 + RS1)
lens = np.array([len(item) for item in V1])
scores = []
ST_AsText(Model.column)
measure_none()
num
x
print(intersected)
progbar = generic_utils.Progbar(X_train.shape[0])
doc = doc.lower()
df
result.reverse()
currentvalue = ptest.iloc[x, 1]
deleteself.code_map[co]
print(results)
value = []
print(token)
False
methodReference.__self__
[0, 0, 4, 5, 6, 0, 0],
X.compressed()
my_site.save()
res = getattr(v, op)(w)
i.set(1, v)
a_slice = a_slice_op.eval()
exc
to_calc = np.multiply(FTR_WEIGHTS, diff)
transformer.visit(tree)
params = urlparse.parse_qsl(parsed.query)
install_requires = [],
platform.processor()
middle_name = indexes.CharField()
limit = n
out, lookup_table
counts, firstidx = count_and_first_index(lst)
print(channel.closed)
comb_index = random.choice(list(range(len(combs))))
n = sample_power_difftest(0.1, 0.5, power=0.8, sig=0.05)
c = pd.cut(x, xedges)
words = {}
half, rem = divmod(len(s), 2)
M = np.arange(1000000).reshape(1000, 1000)
print(row_ids)
to_show = []
0
result.extend([item for item in group_items])
temps = line.split()
server = context.socket(zmq.PULL)
fn(param1_list[0])
large_array.shape
setlocal
do_work
application = DjangoWSGIApp()
m = input_meal()
a = 0, 1
new_link = new_list
layout = QtGui.QVBoxLayout(self)
newline = os.linesep
c.disconnect_from_server()
col = np.hstack(5 * [np.arange(10 * n / 5).reshape(n, 2)]).flatten()
result
img[labels != background] = 255
R = array(list(R))
pixel.py
total = sum(spectrum)
AES.key_size = 128
soup = BeautifulSoup(resultsPage)
out[i:n * n - i * n:n + 1] = cs
max_key = 0
__getslice__ = int_getslice
chunk = inputFile.read(8192)
id_chain.append(node.id)
print(a)
s
print(long_to_bytes(m))
phase(complex(-1.0, 0.0))
client = ec2.meta.client
len(iter)
stderr_events_enabled = true
self.addCleanup(patcher.stop)
X1 = X[X[:, (0)] == 1]
r2.pop(1)
cursor = lmdb.open(lmdb_file, readonly=True).begin().cursor()
out = {}
root_group = parser.add_mutually_exclusive_group()
log_teardown_error
k = []
session_2 = Session_2()
reporter = ExceptionReporter(request, is_email=True, *exc_info)
ev = pygame.event.get()
tree2 = cKDTree(Y)
n = 0.5
res
para2
target_pk = 5
bycount = sorted(index2count, key=index2count.get)
xc[m - 1, k] = x[i, k]
aiinv = np.empty(ai.shape, dtype=int)
stream = imagefield.open()
y = x
print(x == y)
self.request = HttpRequest()
z = x * np.exp(-x ** 2 - y ** 2)
tips = tips_grouped.mean()
instance_type, image_id = AMI_ID, availability_zone_group = region_name,
izmir = pd.read_excel(filepath)
int_in_place(mutable)
z0 = e0(x, y)
pValue = PyObject_CallObject(pFunc, pArgs)
dest_image = pyexiv2.Image(dest_path)
keys = account1, account2
print(c)
hashes = dict()
urlunsplit((scheme, netloc, path, new_query_string, fragment))
rows = [list(row) for row in self]
print(a)
not A or not B or not C
grp_sums = np.bincount(ids, np.where(m, 0, vals))
b = 0
d[obj.thing] = obj
y_pred_cls = classifier.predict_proba(Default[feats])[:, (1)] > 0.5
print()
alpha = math.radians(float(i) * angle)
contribution._clone()
someOtherFunction(newParam, *this)
PyObject * item
self.fig = pylab.figure()
deletefoo
pages = list(pdf.pages)
server_topics = kafka_client.topic_partitions
true_positives = K.round(K.sum(K.clip(y_true * y_pred, 0, 1)))
p = res.k_ar
print()
idx = theano.tensor.lvector()
c += char
clf = IncrementalPCA(copy=False)
self.xss_info.contents.idle / 1000
response = view_func(request)
cutoffs
model_db.updated = True
lin_idx = idx[:, (0)] * lat_len + idx[:, (1)]
omit = frozenset([99, 60, 98])
fg = cv.bitwise_and(image, image, mask=mask)
average_values = np.bincount(ID_array, A) / np.bincount(ID_array)
entryx, entryy = 0, 0
old_stderr_fileno = sys.stderr.fileno()
path = []
plt.ylim(0, 1)
tmp2 = xy[2 * s:size + 2 * s] - xy[s:size + s]
mx = np.ma.masked_equal(arr, 0, copy=True)
html = f.read()
zipped = zip(x, y)
df
type(d.month)
stack = gateway.entry_point.getStack()
len(self.view)
print(word_list2)
zi = z[row.astype(int), col.astype(int)]
arr = np.random.randint(1000, size=10 ** 6)
make_transient(product_obj)
nope = it[i]
self._init_display(b)
valid = False
categories = {}
user_db.put()
a = []
mypad_contents.append(mypad.instr(i, 0))
i += 1
e.extra_compile_args = copt[c]
print(matches)
buffer = x.data
authentication = SpecializedResource.Meta.authentication
print(p)
console.log(JSON.stringify(result))
exit(1)
DWMWA_EXTENDED_FRAME_BOUNDS,
result = Jobs.get()
_wrapped_view
node_id = int(div)
gevent.spawn(parse_async)
xx = np.arange(0, 20, 1)
print(two_largest(inlist))
self.img = reportlab.lib.utils.ImageReader(imgdata)
arg = line.split()[1:]
h_pool2 = max_pool_2x2(h_conv2)
response
a
fp = StringIO()
print(arr)
keys = list(d.keys())
df1.columns = df1.columns.values.astype(str)
Timestamp(datetime.replace(self, **kwds), offset=self.offset)
df.loc[substr_matches]
yrng = stats.logistic.pdf(xrng) / nrm
print(l)
b = 2, 1, 1, 1
student = Student(profile=new_user.get_profile(), user=new_user)
y = np.array([-50, 0, 0])
qs = np.tile(1100.0, n_comp)
params[kw] = value
done = True
print(line)
len(item)
{}
nan = np.nan
set_2 = set(repr(x) for x in sample_json2)
C.grad_foo + C.grad_bar + C.grad_baz
print(stderr)
result = f(*args)
run_producer(q)
a < b
last_output = state[1]
myR = store_RAWR
base_line, = ax.plot(x, y, **kwargs)
numberChunks = len(df) // chunkSize + 1
BOOST_PYTHON_MODULE(printnum)
df
nprocesses, nitems = int(sys.argv.pop(1)), int(sys.argv.pop(1))
r = 1.0 - (arr(i) ** 2.0 + cos(real(i * DPHI, REAL_KIND)) ** 2)
bld = repo.TreeBuilder()
m = magic.Magic(mime_encoding=True)
w = items[oparg]
b = a
self.z = A * numpy.outer(numpy.ones(numpy.size(u)), numpy.cos(v))
theta -= twoPI
print(config_root.sites.mysite.owner.address)
decorator
qt - webkit - devel
MAX_TRIES = 10
destinitions_list = []
result = f(*args, **kwargs)
assert abs(result * result - number) < 0.01
expSum += exp(x - maxValue)
hours, minutes = divmod(minutes, 60)
i = args[0]
number = eval(input())
rest2 = []
i = 0
params[kwargs_name][kw] = value
centers = 100 * (np.random.random((numpoly, 2)) - 0.5)
raise ValidationError()
level = len(getouterframes(currentframe(1)))
mydata = numpy.random.random(10)
i = 0
0
dbModel = Contact
dict(imd)
m_list = list()
maskdraw = ImageDraw.Draw(mask)
threads.append(current)
upto = 0
binarize_image(args.input, args.output, args.threshold)
user = {{obj.user}}
system / console.py
print(ind)
x, y = map(float, val)
result
self.schedule = sched.scheduler(time.time, time.sleep)
user_b, user_c = get_user_vals()
setOverlays(cVerts)
print(n)
depth(exp[1:])
keys = []
aNext = next(a, done)
temp = zip([start] + vecs, [1] + scalars)
lastweek = month[-1]
log(expSum)
resource = str(urllib.parse.unquote(resource))
X_pos = X[y_pos]
alpha_img = pygame.Surface(self.get_rect().size, pygame.SRCALPHA)
ShowIndex()[:, :]
self.path = path
func_code = attr.__code__
data
print(myList)
observations = len(l[-n:])
zout.writestr(item, buffer)
endobj
object_list = object_list.filter(author__id__in=patients)
list(range(4, 8))
x, y = np.random.random((2, 20))
value = update(value)
z = 2
seed(42)
sympy_p1 = sympy.plot(foo)
eijk[0, 2, 1] = eijk[2, 1, 0] = eijk[1, 0, 2] = -1
formatter = TerminalFormatter()
--pkg
i = 0
print(auc_table)
self.cur = self.im.tell() + 1
logger = mp.log_to_stderr(logging.DEBUG)
fpOutput[indexI - 1, indexJ] = True
obj = Obj()
f0 = 1.519e+21 * (-2 * k / T * (k - alpha / pi * (B + V)) * A)
clf = IncrementalPCA(n_components=50).fit(X_train_mmap)
pub_date = models.DateTimeField(auto_now_add=True)
cell = tf.nn.rnn_cell.MultiRNNCell([cell] * num_layers, state_is_tuple=True)
build(next())
lis = []
lst = [1, 2]
A = npr.randn(n)
SENSEX
-learn_rate
result = type_func(arg_string)
final_task = group(a_group) | notify_user.s()
print(list(eval(x) for x in set(str(x) for x in A)))
dt = 0.1
True
print(repr(sl[1]))
mid = (lo + hi) // 2
vol += list(volume.values())
h = f()
gl_current += distToA
assert response.status == 200
print(aapl)
baz = foo()
cls.ClassMethod()
fd.close()
column_type = column.type.compile(engine.dialect)
func = inspect.currentframe().f_back.f_code
new_value = (10000 - -16000) / (16000 - -16000) * (100 - 0) + 0
print(ThisValue)
print(dict(parse(raw)))
err.printStackTrace()
m.__iter__.side_effect = d.__iter__
img = read_png(fn)
container.append(i)
PyObject * initresult
results.append(sentenceIndex)
point = wkb.loads(binary)
SLOT(openNetworkTab())
print(buf)
projectpath = request.form.projectFilePath
predict_ci_low, predict_ci_upp = data[:, 6:8].T
self.LastResponse = response
info = p.get_host_api_info_by_index(0)
raise _generate_django_exception(e)
WSGIPythonHome / usr / local / bin
n_bytes = bytearray(reversed(b[8:256 + 8]))
0.894842
0.967889
0.919405
0.912941
0.889992
0.88894
pprint(list2)
print(output)
tagged = pos_tag(word_tokenize(sent))
y = [1, 4, 16, 4, 1]
2
layout.addWidget(self.buttonLogin)
499
Mc
gradients[gradients == 0] = epsilon
a = {}
10
out1 = a[:, :, ::-1, ::-1]
k
attributes = serializers.PrimaryKeyRelatedField(many=True, read_only=True)
corpus = tm_map(corpus, tolower)
a = 1
inline_rc = dict(mpl.rcParams)
print(DataList)
corpusfile, corpusfile_clone = itertools.tee(corpusfile)
False
nonzero = norms > 0
result
print(out)
l = len(max(a, key=len))
mapper.SetInput(uGrid)
roots = [digital_root(num) for num in nums]
subArray = []
print(isinstance(obj, collections.Mapping))
L.append(i)
b_valid = formB.is_valid()
sp_matrix = sp_matrix.to_coo()
InviteManager.INVITE_MESSAGE
nValue = ast.literal_eval(value)
M = imaplib.IMAP4()
background_process.start()
self.y = float(y)
old_addHandler = logging.root.addHandler
item
ai = bisect.bisect(self.primes, a)
1
pandas.read_json(self.json)
kwargs = dict(chunksize=int(sys.argv[2])) if len(sys.argv) > 2 else {}
number = number + 1
label, index, value
result = self.ix[tuple(slicer)]
print(primelist)
managed = False
myfoo = instance.foo
words = []
glDisable(GL_DEPTH_TEST)
output += os.linesep
today = DT.date.today()
value = line.strip()
main_stream()
X_train = X[:k * subset_size] + X[(k + 1) * subset_size:]
elapsedTime = time.time() - startTime
zsocket_set_xpub_verbose(publisher, 1)
np.floor_divide.outer(lengths, mins).sum(0)
matplotlib.pyplot.hist(group[1].N)
fresh_crawl(purls, nurls)
pyparsing.usePackrat = True
True
reduce(rotated, horProj, 1, CV_REDUCE_AVG)
[l] = v
celery = Celery(app.name, broker=broker_url)
ch.setFormatter(TreeFormatter())
v = s[start:end:] + repr(mydict[key])
chunk = 1024
data = []
np = line.interpolate(line.project(p))
assert enc1 == enc2
m = pattern.match(string)
A - B
rec.result = (time2 - time1).seconds / float(60 * 60)
ClassA(the_number)
__flag = True
content
cnt += 1
messages.success(request, message)
bazinga
xL, yL, iL = mostfar(iL, n, s, c, -1, 0)
a = [8, 8, 1, 1, 5, 8, 9]
main()
xarray = np.linspace(0, 0.25, num=resolution)
hale
date = pd.Series(df.index) - pd.Series([timedelta(int(i)) for i in d])
self.generic_visit(node)
store_in_db(dbconn, userinfo, question_IDs)
751
periods[period_end]
signature = base64.standard_b64decode(signature_base64)
families[i][j]
l = collections.defaultdict(list)
possible[index] = 0
a[a_start:a_end] = chunk
box.lat_min = rad2deg(lat_min)
iter(x) is x
ticks_restrict_to_integer(ax.xaxis)
self.__argparser.print_help(self)
+--common.py
matches = []
num_rows = data.shape[0]
print(next(g))
rules = [str(p) for p in ptree.productions()]
retval.append(new_peak)
mask = uint8(ones(gray.shape))
new_b = some_process(b)
i = 0
path = []
x1, x2
traceback.print_exc(file=your_open_log_file)
b_new
self.call_count = 0
d = seq.ratio() * 100
_perf()
msg = self.rfile.readline().strip()
args = sys.argv[1:]
X, Y = np.meshgrid(x, y)
ngram = tuple(str(w) for w in deque)
path = args[0]
bgBase64Data = outputBuffer.getvalue()
board[c[0]][c[1]] = acells[c]
id_arr[lens[:-1].cumsum()] = -lens[:-1] + 1
b = a
small_holes = [hole for hole in holes if 500 < im[hole].size < 1000]
seconds_passed = time.time() - t_nought
_, yt, xt = x.shape
mc.multinomial_like(x=np.array(list(count) + [0]), n=n, p=bin_probs)
demo = lambda *a: a
testRunner = unittest.TextTestRunner()
self._property = 67
p = re.compile(__searchtext__)
DBSession2.configure(bind=engine[1])
M1 = M.reshape(10, 10, 10, 10)
assert test.app is app1
b = 2
f = -(x + a) + b / (1 + sy.exp(-(x + c)))
last_bit = (b & 1) << i
wrapped_f.count = 0
end = datetime.datetime(2017, 2, 27)
result[ing_id] = set(r[0] for r in cursor.fetchall())
cout << sink(pipe2(pipe1(i))) << endl
self.on_open = on_open
SP = P * np.array(S)
a = [1, 2]
d2 = copy.deepcopy(li)
type(PyQt5)
batch, labels
true
path, filename = os.path.split(filepath)
ptk = customPRF512(pmk, A, B)
count = np.count_nonzero(bc == 1)
Database = MYDATABASE
im = ax.imshow(Z, cmap, extent=extent, **kwargs)
result = []
distribute_overrun(groups, test_length, 0)
tbl_d = {name: col for name, col in zip(header, cols)}
(result << factor2 - factor5) * 10 ** factor5
someTransformationFunction(a.data)
flattend1 = [k for i in outgoing for k in i]
l_pos = np.array(classif.classify_many(pos[100:]))
h.sort()
in_view = mmap.mmap(in_f.fileno(), 0)
print(english_words[:10])
x = r.dot(1 / r.T.copy()) - 1
main()
f(*args)
x, y = generate_data(num)
c = a + b
print(output)
result = GeneratorContainer(DBProcessor().get_listings(), length)
deletexl
hessian[(k), (l), :, :] = grad_kl
chart_toolbar.Realize()
AaaB
stripper = str.strip
result
A = np.sort(np.asarray(AList))
request = urllib.request.Request(myurl, encoded_dict)
i -= 1
rv = dict.__getitem__(self, key)
app.module.js
operator.lt
ids.SetInputConnection(ugrid.GetProducerPort())
name = record[1].strip()
i = psutil.get_pid_list()
line2 = next(f)
df
count
job = TaskSet([sometask.subtask((a,)) for a in b])
b = B()
cleaner = clean.Cleaner(safe_attrs_only=True, safe_attrs=frozenset())
channel = default_channel()
route_name = request.matched_route.name
-1
t = []
i
result = 1
count = 0
By = np.arange(Bymin, Bymax + dy, dy)
oldlist = set(List)
rslt = []
iterable
end = match.index(best)
numerator, denominator
print(i)
DNAseq = defaultdict(int)
hello
row[0] = len1 - half - 1
print(day)
qux
self.end_headers()
L = a.max()
a = Test()
rslt = numpy.empty((len(a),), dtype=a.dtype)
freqs = np.fft.fftfreq(data.size, time_step)
m, n, r = volume.shape
self.Value == other.Value
q.task_done()
xr = stats.logistic.ppf(yr)
y_pos = math.floor(y_mouse / 100)
P.append(p)
fh.setFormatter(frmt)
kw.update(dict(key_name=inverse_millisecond_str() + disambig_chars()))
print(ser.portstr)
head, tail = mylist[0], mylist[1:]
y = 2
items[key].append(val)
createRow
newObj.x, newObj.y = self.y, self.x
SomeEnum.VARIABLE7
this_dir = os.path.abspath(os.path.dirname(__file__))
A
num_ticks = 10
stdout = os.fdopen(master)
strab
print(s)
original_open = open
temp = temp[part]
TIMEOUT = 2
skype = Skype4Py.Skype()
node_sizes = []
5
n * recur_factorial(n - 1)
Py_INCREF(v)
box.lon_min = rad2deg(lon_min)
sp.weekday.value_counts()
result
roll_down2 = pandas.rolling_mean(down.abs(), window_length)
os.getenv(key, value)
a + 100
tmp
n = 4
self.preferred_nodes.remove(n)
data[cat] = np.random.randint(10, 100, size=N)
tokens_stripped = [token for token in tokens if token not in stopwords]
y_train = y[:k * subset_size] + y[(k + 1) * subset_size:]
print(t.elapsed)
setColor(leftPixel, color)
queue_in.delete_message(message)
True
counter = 0
C = array(B)
self._flags = {}
this.driver = driver
loc = recarray.dtype.fields[colname][1]
dialog = ChildDialog(self)
colors = json.load(inFile)
x[i] = s
value = my_dic[100]
item = getattr(item, a)
python
from_date = object.start_date
x
bit = num % 2
print(df_flat)
collections.deque(map(writer.writerow, data), 0)
a.raw
numbers[i] = float(numbers[i])
time_taken = min(times) / 1000
tokens = nltk.tokenize.wordpunct_tokenize(s)
index = line.index
x = iter([range(0, 5), range(5, 10)])
filetime = datetime.fromtimestamp(path.getctime(file))
myEpsilon
p.y_range = Range1d(0, 12)
guestFile.close()
new_list = []
pprint.pformat(data)
result.append(elt)
print((timestamp, list(group)))
col = df.columns
fig, axs = plt.subplots(figsize=(9, 4), nrows=2, ncols=rowlength)
m = np.isnan(vals)
element
Image(data=png_str)
point_on_line = line.interpolate(line.project(point))
R2 = LR_Multi.scores(y_stack_pred, y_stack[:, half:])
namespace = __import__(modulename)
node.n
summed = sum((Counter(d) for d in folds), Counter())
gl2 < -locate_guide(g2)
loggedin = True
indices.append(i)
val = dotted_notation.parseString(t)
c = 1
nicknames = [x.user.nickname for x in group.groupMembers]
p1 = Point(0.5, 0.5)
slices = [slice(*(x, next(it))) for x in it]
val
print(i, word)
data = {}
x = TestEllipsis()
x = list(range(1000))
_, topLeft = min([(p2abs(p), i) for p, i in zip(list(range(4)), minRect)])
ast.NodeVisitor.generic_visit(self, node)
print((iv(-v, X) - iv(v, X)) * (np.pi / (2 * sin(v * pi))))
end_token = re.escape(end_token)
rand = np.random.randint(10)
frameW = 256
font.nFont = 12
self.sock = sock
string.letters
yShift = np.fft.fftshift(y)
-pip
result = summed.unstack()
o = json.load(infile)
ctypes.pythonapi.PyTraceBack_Here.restype = ctypes.c_int
stop_words_pat
self.val = int(initial)
resp = func(request, *args, **kwargs)
i = 0
list(round_robin_even(d, n))
normalized = d.normalize()
dir(rec)
x
x2_Kcids = np.empty_like(x2_Kaxs).reshape(-1)
assert len(mock.updates) == 1
my_array = []
indices = np.arange(a.size)[mask]
coords_ext[..., (2)] = 1
self._find(tests, val, valname, module, source_lines, globs, seen)
z = str(y)
print(b)
num_words
tc = TestClass()
list_ = form.save(owner=self.request.user)
j += 1
big_array = []
print(ind)
compute_item(rangeobject * r, PyObject * i)
l = list(set(tagged))
ind_train, ind_valid = train_index, valid_index
SX = spline(t, sx, N, order=4)
indices_zero = []
start = time.time()
point_table = [0] + [255] * 255
mqttStream.count().pprint()
value[arg]
context
self.loop = LoopingCall(follow, open(filename), self._sendLogLine)
type(a1)
print(mtime)
data = json.dumps(struct[0])
print(result)
__builtins__.__NUMPY_SETUP__ = False
char_value = dict((c, v) for v, c in enumerate(alphabet))
res = peek(mysequence)
2
img = np.arange(20).reshape(5, 4)
print(p)
count = 1
float(val)
A.values[process(A, B)[:, (0)], 0]
X.__iter__ = lambda x: iter(list(range(10)))
model = DecisionTreeClassifier(random_state=0)
compiled.Execute(scope)
somewhere / reference_page_001.pdf
corrMatrix = df.corr()
signed_url = cf_signer.generate_signed_url(url, policy=my_policy)
config = ConfigParser()
res[k] = sortOD(v)
urllib.request.urlretrieve(cafile_remote, cafile_local)
jpeg_image = PIL.Image.open(jpeg_str)
x
DummyLoader()
ACK, address = mysocket.recvfrom(1024)
context = zmq.Context()
image_row[i % 2::2] = data_row
data = self.request.recv(4096)
result
[ele for ele in alist if 2 not in ele]
i = j
result = {}
car = models.ForeignKey(Car)
print(a)
cost = cost.split()
minutes, seconds = divmod(remainder, 60)
my_list
credentials = GoogleCredentials.get_application_default()
--batch_timeline.py
Py_DECREF(w)
print(res)
loop.add_reader(s, test_serial)
Introduction
full_arr[i:j, :] = np.column_stack(process_sub_arrs(arr))
loc_to_incl_sorted = locations_to_include.take(sorted_dist_idcs)
ctx.enter()
data.sort()
reordered.append(line)
w = -2 * y * z - y
print((mytuple, value))
handler = urllib.request.HTTPSHandler()
x.attr = count
self.value = value
exec_globals = nvl(globals, {})
whatever.write(x)
pprint.pprint(union(list_))
m = re.compile(exp)
print(people.query)
my_ip = YOUR_IP
string.lowercase
fig = pyplot.figure()
pandas.formats.format.IntArrayFormatter = _IntArrayFormatter
_, recall, _, _ = precision_recall_fscore_support(y_true, y_pred)
print(_)
plot(x, func(x, *popt))
print(hist.history)
x = [math.cos(degToRad(theta)) for theta in thetaList]
t = T(2)
a = numpy.array([200, 2e-26], dtype=numpy.longfloat)
print(events)
months = sorted(set(data.months))
basic_arg_count = len(names)
current_time = time.time()
marshal.dumps(d)
c = iter(a)
df
print([sph_in(floor(v), x)[0][-1] for x in X])
roles = area.role_set.all()
compile.__text_signature__
-5 // 2
pos_min = len(self.scores_matrix[i]) - (reversed_pos_min + 1)
r[k] = str(getattr(self, k))
a = 5
time.sleep(self.blinkDuration)
k = {p for p in range(a, b + 1)}
os = ds.open_array(input_array, sampling_frequency)
tasks = [print_sum(1, 2), dosomethingelse(), compute(2, 4)]
mn, curr = s[0], s[0]
self.set_foreground()
fullnameArray.append(sublist)
ind -= 1
print(timeout)
oindex = options.index(current_option)
self.diff = True
(x1 * x2).dtype
percentile_df
highest_values = highest_values[:count]
False
result = np.sqrt(tmp)
self.tree_store = gtk.TreeStore(gobject.TYPE_STRING, gobject.TYPE_BOOLEAN)
dayno -= YEARSIZE(year)
x % y
deleteself.min_set[self.min]
out.cat.categories = bins[:-1]
self.offset += len(line)
lastGuess = x / 2
ball.y -= math.cos(angle)
headers = {}
coro = asyncio.coroutine(fn)(*args, **kwargs)
values = dict_x[key] = []
magnitude + scale, scale
fo.set_antialias(cairo.ANTIALIAS_SUBPIXEL)
self.item_to_position[last_item] = position
self.content
options = {}
print(time.time() - t)
newest = dated_files[0][1]
corr_x = np.asarray(corr_x)
parser = OptionParser()
print(o.x)
mpr.WNetGetConnectionW.restype = wintypes.DWORD
print(df)
lo = 0
A2 = A.reshape(time_len, -1)
Browser.Ts
noindices = [4, 8, 9]
print(result)
path = ctypes.util.find_library(libname)
exception
j -= 1
outerjoin((co, City.county))
m.user_defined_func()
es_formats.DATETIME_INPUT_FORMATS
cols = zip(*rows)
tokens.push_back(string(token))
sys.stdout = self
S = {1}
cur = connection.cursor()
d = dict(zip(a, b.tolist()))
self[k] = v
b = np.ma.compress_rows(np.ma.fix_invalid(a))
semi_filtered.filter(custom) if custom else semi_filtered
oodict = {}
self.right = othernode
model
url_adapter = appctx.url_adapter
InviteManager.ALREADY_INVITED_MESSAGE
size = e.size
UNIXClient().register(self)
print(variable)
estimator = tf.contrib.learn.Estimator(model_fn=model_fn)
ret
model = CanonPerson
c = C()
size = len(samples)
value = str(value)
label_batch, feature_batch = q.dequeue_many(BATCH_SIZE)
f(x(t))
[v, v, v]
self.DoSomethingIDontCareAbout()
print(line, file=sys.stdout)
docs.append(analyzedDocument(words, tags))
APPLICATION = endpoints.api_server([HelloImgApi])
loop.run_until_complete(main(10))
plot(t, x)
out.reshape(a.shape[0] - W + 1, -1)
print(a)
done += n
regularization_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)
dis.dis(a2)
field1 = bits[0:4].int
sm.Init()
model = linear_model.Lasso(alpha=(1.0)(default))
PyGILState_Release(state)
print(i)
similarity = Levenshtein.jaro(pair[0], pair[1])
locale.nl_langinfo(locale.DAY_1)
x
C.base is A
c = get_config()
r = max(min(r, 1.0), -1.0)
pl.plot(line)
idx_after = np.searchsorted(df.index.values, rs.index.values)
f = math.factorial(len(seq) - 1)
xbins = [0, 100, 1000]
__metaclass__ = DecorateMeta
proxy.ProxyClient.handleResponseEnd(self)
hm.HookKeyboard()
_Py_ReleaseInternedStrings.argtypes = ()
m = max(key.start, key.stop)
d1, d2 = 0.0, 0.0
dateForm.index = pd.DatetimeIndex(poorList)
args = my_args[2:]
input
self.items = []
r = data.view(mrecords.mrecarray)
dfu = dfg.unstack()
d
salt = bcrypt.gensalt()
cv = df.columns.values
worker = Worker(map(Queue, listen))
standard_c_lib.__errno_location()
main()
a, b = b, a + b
rows = []
zip_safe = False,
max_depth = depth
count += n_count[min(l)]
print(a is b)
handler = SomeHandler(mock_applciation, payload_request)
a
r = x[0]
n = 10000
dic.default_factory = lambda : 2
execdict[key].__module__ = self._name
db = DBSCAN(eps=2, min_samples=5)
server = smtplib.SMTP(SERVER, 1025)
buffer = cStringIO.StringIO()
print(datetime64Obj.astype(object).year)
x = [7]
value
python
text_cell_xf = book.xf_list[first_sheet.cell_xf_index(row_idx, COL_IDX)]
df.info
xmlFile = minidom.parse(FILE_PATH)
processed_line = process_line(line)
seq = asn1.DerSequence()
formatstring = formatstring.replace(p, v)
nbits = int(argv[2])
self.value += increment
x_offset = np.median(x_offsets)
pmf = 1 / x ** a
sp.Popen.terminate(extProc)
xg, yg, zg = np.mgrid[0:1:50 * 1j, 0:1:50 * 1j, 0:1:50 * 1j]
tmp = s.order(ascending=False)[:num]
l.remove(lowest)
cache[args] = f(*args)
form = LoginForm(request.form)
print(out)
pkt.time = self.time
w.start()
serialized = dumps(query)
decorated_fn
PythonToPairConverter()
boardFrame = Frame(root, bd=1, relief=SUNKEN)
pixdata[x, y] = 0, 0, 0, 255
val & 1
low = min(y)
s = s - 2
frame = Frame(Window)
m = key_pat.match(item)
sets = []
log.Fatal(err)
myBigList = numpy.array(list(range(1000)))
toHex(rest) + digits[x]
os.system = realSystem
a
pprint(cartesian)
A = rand(5, 5)
nrows = a.size - N + 1
Z = griddata(x, y, z, xi, yi)
move(src, dest)
data[offset] = value
print(e)
station.id
model = RDF.Model()
indent[0] -= 2
closestN(X, 5)
s, found, end = s.rpartition(lookfor)
CreateNoWindow = true
final_result = sum([r.get() for r in results])
t.name
fp.close()
print(df2)
overflows = []
0
q, r = divmod(total, surplus)
p.add_tools(g1_hover)
a = list(range(1, 1001))
conn.send(buf)
memf = cStringIO.StringIO()
m = 2
matches = list(itertools.chain.from_iterable(matches))
1
self.c = initial_c
cleanup()
arglist[arg] = args.__dict__[arg]
b = nx.bipartite.eppstein_matching(G)
print(repr(s))
height = 200
print(length)
fig.colorbar(collection)
Temp_Obj = QtGui.QTextEdit()
y = i
print(result)
1 == 1.0
IntervalTree(A.h, left, right)
client = paramiko.SSHClient()
res = []
shuffle(lengths)
bitmasks = [(1 << j, (u - 1) // 2) for j, u in enumerate(prime_residues)]
inds = ages.argsort()
self._split_lines_from_chunks(chunks)
indent(elem, level + 1)
start, stop, step = adjust_slice(length, start, stop, step)
os.remove(s[0])
currentDict = parentDict[key]
i = 0
datastore.put(oldVenueUpdates)
False
-setattr(self, key, run)
hover = ActionChains(driver).move_to_element(element_to_hover_over)
shell = IPShellEmbed()
se1 = db1.Session()
print(tup)
print()
__metaclass__ = abc.ABCMeta
attrs = xattr(filename)
[A()]
newx = np.linspace(min(x), max(x))
other[player]
conf.lib.clang_Cursor_isAnonymous(self)
t = results(tables(connection))
self.namespace = {}
print(c)
start = s.asof(start)
maxlen = max(len(List1), len(List2)) + 1000
vec_row = vec.T
around(0.5)
a.value = 5
compounded_iter = ((foo.value, bar.value(foo)) for foo in foos)
keypoints = surfDetector.detect(im)
stat = os.fstat(fd)
a ** 2
multiply(item)
ar = np.array([True, False, True, True, True])
p = multiprocessing.Pool(2)
M, N, R = A.shape
model = Image
self.number = number
splits = np.array_split(vector, 512)
I[-1] = 0
text(bp, (ytop + ybot) / 2, LETTERS[seq(cats)])
gr2 = greenlet(test2)
r1 = p.line(x, y)
isanimated = False
y = np.sin(x ** 2)
aln.ParseFromString(data)
temp_list = [str(len(temp_list))]
print(zip(links, smalls))
stats.rv_discrete(values=(list(range(1, m + 1)), pmf))
print(result_list)
foo2 = foo(lambda : foo_arg)
buf[i] = str[i] ^ 55
d = dict(B)
m(2)
b_length = len(range(b_start, b_stop, b_step))
language_id.py
datum.ParseFromString(value)
lst[start_i]
True
has_more = True
Record(*tuplePi)
B = MyClass()
x = sin(i)
df = pandas.DataFrame(values, index=dates)
a = b = c = list(range(20))
results = [2]
w, h = P.wrap(letter[0] - 20, doc.bottomMargin)
tree = GeneralisedSuffixTree([data, revc(data)])
framenp = framenp * 1.0 / framenp.max()
grid[second_mask] = 100
tester(site.read(100000))
cmdline.append(to_addr)
score, best_move
b = a[:]
lower_red_1 = np.array([180 - sensitivity, 100, 100])
c = -1
fields = {}
res = heapq.nlargest(2, some_sequence)
img_temp = NamedTemporaryFile(delete=True)
2, 100, 2000
coord_trans_cache = {}
buffer = zin.read(item.filename)
[4, 5],
same_a_offset = np.cumsum(counts_a)
sign_with_rsa(message)
le = LabelEncoder()
print(body)
result
monitor.start()
fig, ax = plt.subplots()
False
extra = 5
spider()
obj.throttle = obj.template.throttle
x, y = B.shape
print(num)
kwargs = {}
prev = f(prev, i)
df[self.keys].values
counter = itertools.count(10, -2)
priv_cipher = PKCS1_PSS.new(priv_key)
print(1 + 1)
mtext = strJson.get()
MyTest
[build_ext]
chrome_options = Options()
html = BeautifulSoup(content)
value / arg
y = np.sin(x)
num_ceps = len(ceps)
self.fields = self.normaluser_fields + self.superuser_fields
ip = {{obj.ip}}
b
poll_result = poll_obj.poll(0)
c = a / b
SVD = TruncatedSVD(n_components=r)
out = sorted(out, key=lambda x: x[1])
url
foo = allow_kwargs(foo)
total
chunk = []
cdf_val = stats.norm.cdf(x, loc=loc, scale=scale)
b = 9
x[x > 0] = new_value_for_pos
x = np.linspace(0, 4, 50)
length = idx[1] - idx[0] + 1
x = np.linspace(0, 1, 11)
requests_logger.addHandler(handler)
startdate = datetime.today()
a
msg_out[:msg_in.shape[0]] = msg_in
procs = proc.children(recursive=True)
print(font.getoffset(text))
a = 0
Gd = fy[1:100:2] / fsq[1:100:2]
last, lastG = last + Lval, g
print(postdata)
[7, 10],
xi = np.linspace(data.Lon.min(), data.Lon.max(), numcols)
i = df.Interval.values
deleteqtls, ebins
mask1
DISPLAYSURF = pygame.display.set_mode((self.width, self.height), RESIZABLE)
Ax, Ay = np.meshgrid(Ax, Ay)
cities[new_key] = d[key]
fd[word] = fd[word] + 1
im = alpha.load()
result_list = []
print(parser.options(section))
_csv.__file__
1
map_keys = np.array(list(codeTable.keys()))
c.update(b)
a[b] = 1
b = ref(a)
10
largest = inlist[0]
end = s.asof(end)
l = len(plaintext)
ax.quiver(x[skip], y[skip], dx[skip].T, dy[skip].T)
d.feed.link
val = float(s)
xs = np.sin(U) * np.cos(V)
resp = requests.get(rss_feed, timeout=20.0)
allowed_set = set(allowed_list)
a2.ravel()[:] = ll
self.car = car
self.running = True
look_up[n]
de2bi_convarr
groups.append(tuple(g))
properties.append(kwargs[letter])
now = str(datetime.datetime.now())
round_down(19, 10)
flattened_records = [flatten(record) for record in results.rows]
pixl.close()
root_logger = logging.getLogger()
l, = v
ser = serial.Serial(0)
seconds = 0
False
arr
self.view = self.base[self.slice]
d2 = d.T.dot(d[:, k:l])
{url}
j = n - 1
locale.nl_langinfo(locale.DAY_4)
module = __import__(mod)
self.list_value = []
C, (B,), (D,)
df.dropna(thresh=new_thresh, inplace=True)
indent(elem, level + 1)
wb = xlrd.open_workbook(excel_name)
Z = tf.pow(Z, 2.0)
v1 = get_a_value()
csr = conn.cursor()
True
process_pk()
coins.append(i)
j = [1, 1, 1, 2, 2, 2]
figure = plt[:figure]()
idx = gsm.find(c)
print(df)
print(res)
not condition
print(map(fix_key, patch_json))
print(result.dump())
coord_list = []
window.send_event(event, propagate=True)
[o.reverse() for o in overflows]
qs = self.model._default_manager.filter(year=year, quarter=quarter)
fifth
R > irr < -uniroot(irrSearch, c(0.01, 5))
readRequest += chr(4)
year_start = iso_year_start(iso_year)
h = hog(resized)
cent = sum([p[0] for p in pp]) / len(pp), sum([p[1] for p in pp]) / len(pp)
col_widths = [max(len(value) for value in col) for col in cols]
chunked = ne_chunk(pos_tag(word_tokenize(sent2)))
to_dt = datetime.datetime.strptime(end_date, DATETIME_FORMAT)
do_it_inner()
self.status = self.formErrorsMessage
b = in_.read(BUF_SIZE)
i, size = 5, 9
arr[:len_] = seq
procs.append(p)
SIMULTANEOUS_CONNECTIONS = 25
heapq.heapify(flattened)
results = np.zeros(X.shape[0])
tun = subprocess.Popen(args)
print(grouped)
start, limit = 0, start
ld = pd.DataFrame(labeldict).T
indx = [Ellipsis] * myarray.ndim
lsh.index(x, extra_data=c)
self.valid_key = valid_key
s(cmdString)
self.fp_offset += len(line)
numberofrows = intervaly
print(is_alternating_signs([1, -1, 1, -1, 1]))
numbers
model = Contact
fn_2()
x, y = 10, 1
serialised_cycle = pickle.dumps(c)
print(db.connections.databases)
text_content = strip_tags(html_content)
table = 1
mean_estimate = lfilter(b, a, data)
pp.coeffs.T
df_expand
deleteself[key]
python
iterator = iter(iterable)
type(x) in (int, float, bool, str, str)
discussion.name,
seasonal_indices[:current_season], [updated_seasonal_index]
nx.draw(G)
float_size = float(total_length) / i
a = A()
map(result.update, result_list)
f = FaxMachine()
rv
items = match.group(0)
s += b[row, i]
self.threads = []
52.2
name = match.group(1)
dfnew, c = rename_dup(df)
tmp = {}
dimensions = [(list(range(dim)) + [colon]) for dim in a.shape]
d = defaultdict(int)
name = row[0].value
idset = procidset()
print(out)
frameGm = self.frameGeometry()
args = parser.parse_args()
cache = keys[0], b[keys[0]]
result = np.zeros(data.size)
root_tag_namespace = self.__root_tag_namespace(self.element_tree)
fullname = fields.CharField(readonly=True)
c = []
cycled = cycle(L)
DATA = [1]
vacuum = true
y = x * x
shrt_max = SHRT_MAX
pool = Pool(len(hostnames))
seconds = _js_parseInt(match[2]) if match[2] else 0
a
curline = 44
1 in d
idx1 = idx0.tz_localize(tz.tzutc())
A.answer + a + b
page.customHeaders = {}
data = {}
pylab.plot(t, sine_wave2)
font.FontWeight = 400
0
settings = list(fid.get_access_plist().get_cache())
minutes = int(temp)
print(tokens)
presentation1 = list(network28s[0:1])
okay_items = list(filter(isNotMonster, all_items))
csvfile = StringIO()
old_open = __builtins__.open
a[1], a[0] = a[0], a[1]
x2, y2 = int(max_loc[0]), int(max_loc[1])
i >>= 1
current_frame = sys._getframe(0)
g_arr = np.array(g)
title = match.group(1)
fileset = set(filelist)
True
response
plt.hist(x)
print(res.status, res.reason)
master_key = PBKDF2(password, salt, count=10000)
slides
self.item_to_position = {}
self.name = name
caller.assert_called_with(Any(int), Any(int), Any(int), arg=True)
fileobj.write(response.content)
S[i] = val / jmax
cursor = conn.cursor()
a.reverse()
-n
mgr.start()
a = next(tokens)
cbar = plt.colorbar(im)
right = randint(left, len(L))
compile_opts.extend(self.compile_options_debug)
a == b
response.elapsed
counter = 0
OSError(2).errno
c = c + 1
expr = sym.sin(a) + sym.cos(b)
y_series = []
geometryFilter.SetInput(ugrid)
self.preferred_nodes = [n for n in self.nodes]
resp = h.getresponse()
parsed_sent = str(output[0])
process_mock = mock.Mock()
SendMessage(hwnd, 256, 9, 1)
defers = []
self.target = target
print(np.arange(start=2, stop=min_count + 2).reshape(df.shape))
r = r[0:pos] + pinyinToneMarks[r[pos]][tone - 1] + r[pos + 1:]
result_filled = result_with_zeros.where(~mask, 0)
mstats.winsorize(s, limits=[0.05, 0.05])
paths.append(path)
clib.register_callback(o)
draw = ImageDraw.Draw(visual)
n_y = n[1]
print(dialect.delimiter)
other = test
globs[modname] = m
assert ha == hc
uni = _decode_uXXXX(s, end)
_pairs = {(1): [0, 1]}
-yourFile.py
pnt.transform(trans)
mapping = dict(enumerate(indexer.labels()))
page
i, j = 0, 5
BoxTime.foo()
assert False
RST = 4
test.second
h, w = data.shape
expr
offset = 0
spl = line.split()
trial_url = obj.__parent__.__parent__.absolute_url()
newNo = ar[-1]
engine.Sys.argv = argv
print(c, dict[c] / float(n))
q_idx = np.argmin(np.abs(np.concatenate((l1_x1 - l2_x1, l1_x2 - l2_x2))))
rightMin + valueScaled * rightSpan
hour = round_to_nearest_hour(ts)
img1StringIO.seek(0)
f(5.0, sorted_list)
x.strides
current_product = current_product / popped_item * push_item
doc = etree.XML(sample)
losses = [tf.nn.l2_loss(w) for w in weights]
repeatList = list(repeatSet)
cvScale(im, realInput, 1.0, 0.0)
num = num / 10
x, s = next(it.xs, s)
result = myfunc(data)
i5 = i1 + i2
reactor.callFromThread(twistedServer.sendResponse, response)
name = Column(Text)
c.list
self.diff = False
goodbye_world()
locale.locale_alias
df1
c = cmp(xs[0], ys[0])
retval.scriptResult = some_python_value
print(i)
timing = dict()
apps.populate(settings.INSTALLED_APPS)
expected[key] = response.data[key]
cls.instance = cls()
t = 1 if i & 8 else 0, 1 if i & 4 else 0, 1 if i & 2 else 0, i & 1
end = PyInt_FromSsize_t(istop)
print(soup)
chop = int(sys.argv[1])
txt = txt.strip()
0
i, j = map(int, spl)
whatever_you_want
prev = x
worksheet = workbook.add_worksheet()
self._originalPosition.set(pos)
s.get_spam()
raise self._undefined_exception(hint)
zipped = zip(x, y)
x = Foo()
print(d1[key])
dir(re.findall)
placemark.layer = Layer.objects.get(pk=8)
output[i], state = cell(input_data[i], state)
a[2] = 7
grouped.columns = grouped.columns.droplevel()
True
new_object = model()
_count = 0
rqst = self.request.resolve(context)
bit8 = bool(x & 128)
d[item1] = item1
pop_flat = chain.from_iterable(list(range(i, j + 1)) for i, j in pop)
value_list = pgroup[1]
h = httplib2.Http()
channels[bucket].append(value)
cj = cp.cookiejar
msg_str = email.message_from_string(msg)
dialect.type_descriptor(PG_UUID())
print(obj)
x + y
wxMessageBox(PyString_AsString(pyname))
print(e.asdict())
lens = rep.sum(axis=-1)
j = i
film.followed_actors = film.actors.filter(id__in=actor_ids)
print(s)
page_detail = requests.get(t)
sub_sizes[num_threads - 1] += size % num_threads
firstHalf = sequence[:int(len(sequence) / 2)]
self._what = MyValue(40)
obj = objects.pop(the_key)
messages = [pop_conn.retr(i) for i in range(1, len(pop_conn.list()[1]) + 1)]
print(frame.toHtml())
j += 1
head, tail = generators[0], generators[1:]
b
skip - name - resolve
a
oldGuess = n / 2.0
[6, 5, 4, 5, 6, 5, 4],
_ctypes.FreeLibrary(lib1._handle)
password_mgr = urllib.request.HTTPPasswordMgrWithDefaultRealm()
ret
0
deletemodule
rooted_paths = [[root]]
someList.append(chr(c))
print(f(2))
n = (x ** 2 + y ** 2) ** -0.5
d1 = eastern.normalize(d1 + td(hours=1))
new_index = df.index.max() + pd.offsets.Day()
c1 = random((10, 10, 10, 10))
result = []
[]
ret
slice1 = []
print(list_index)
self.year = year
assert result == expected
2
val = args & 4294967295
oScript = oMSP.getScript(sURL)
toAddr = socket.recv()
closed = []
monkey.patch_all(thread=False)
print(result)
peak_factory(peak_type, 1, 0, 1, 0.5, 10, **kw)
val.append(i)
dataset_array = []
D1[w[:2]].add(w)
q_key = ndb.Key(urlsafe=key)
sum += p
f0 = paste0
Z = np.flipud(Z)
divisor = 1
print(mat_row.todense())
direction = data[i + 1] - data[i]
bar
mergedVersions.append([versions[i]])
first_row = next(csvreader)
ret_index[0] = 1
Input(device_id)
selected = []
v -= 1
adiff = smallest_diff_key(A, B)
propdict = {}
queryset = auth_models.User.objects.all()
x = np.array(list(range(1, K + 1)))
{}
index = np.searchsorted(year_range, line[:, (0)])
traffic.update({tuple(sorted(map(atol, (pkt.src, pkt.dst)))): pkt.len})
scale_estimate = lfilter(b, a, abs(data - mean_estimate))
pyrodaemon = Pyro.core.Daemon()
editor.setUseTabs(use_tab)
data_files = []
True
vals = [max(a.get(n, 0), b.get(n, 0)) for n in keys]
c_list = []
True
self.notDone = False
library.MagickSetCompressionQuality(img.wand, 75)
ET.dump(a)
col = values[idx]
print(b)
text_angle = arrow_angle - 0.5 * np.pi
i = trees.find(parent)
a = list(range(10000))
poll_list = {}
urls[url] += 1
Py_DECREF(map)
result = value
results = set()
qs.filter(site__id__exact=settings.SITE_ID)
assert myFixture2 == 2
kwargs = dict()
print(i)
fps = cap.get(cv2.CAP_PROP_FPS)
modName = str(line)
length = 100
python
pygame.init()
sum = 0
chunk = []
base_in2 = in2[0]
k = 2
plt.semilogy(X2, Y2)
seen.append(state[i])
signal.signal(self.sig, handler)
d[str(hash(i))] = 0
print(len(line))
assert False
class_name = type(self).__name__
t1 = np.arange(0.0, 50.0, 0.1)
sum(two_three), one
[(t2 - t1) for t1, t2 in zip(timeList1, timeList2)]
total_words += 1
self.c = c
stack = traceback.extract_stack()
pred = fit2.forecast(steps=4)
is_direct = Column(Boolean)
df = weather
a_string = etree.tostring(child)
nx, xbins, ptchs = plt.hist(X, bins=20)
summands = set()
print(list)
shell = InteractiveConsole(env)
result = []
b[x - 4] = 1
font.dwFontSize.Y = 18
o if isinstance(o, RawJson) else _encode(o)
isinstance({}, Mapping)
start = 0
value = conversion[x]
0
model2 = build_model()
kw_lengths.sort()
old_stdout_fileno = sys.stdout.fileno()
print(show(itertools.islice(circle_around(5, 5, 11), 101)))
pickle.load(stream)
pending = len(iterables)
numColArr.tofile(fileObj)
r = f(V, values_dct=vals, eq_lst=[IDEAL_GAS_EQUATION])
fig, ax = plt.subplots(figsize=(size, size))
print(t)
print(list1)
ynew = f(xnew)
result >>= outshift
print(y)
resource = str(urllib.parse.unquote(resource))
encodings_to_try.insert(0, declared_encoding)
print(found)
d = {}
receiver = lambda film=film: self.onFilmSet(self, film)
pos
zero_crossings = np.where(np.diff(np.signbit(a)))[0]
moveTo, path = path.split(os.sep, 1)
load_source_module(char * name, char * pathname, FILE * fp)
Console.WriteLine(ret)
minLength = min(paths.keys())
print(hex(id(self.sample_method)))
dom = transform(dom)
B[-1]
code.index = code.index.droplevel(1)
self.d[i] = self.d[i - 1]
0
fc = FigureCanvasWxAgg(self, -1, figure)
self.instManagers = {}
img = mymodule.MyClass()
agg_dict = dict(zip(col_rder, agg_fnxs))
canvas = Canvas(figsn)
c = self.listener.accept()
assert data
stack = traceback.extract_stack()
m(1)
print(split(y))
j += 1
m = 16777215
width, height = A4
x_nums = np.arange(1, N + 1)
p = np.atleast_1d(p)
sequence = chain((pad_symbol,) * (n - 1), sequence)
a = stack.enter_context(Dummy())
dis.dis(test1)
orig = Image.open(sys.argv[1])
builtin_bin(PyObject * self, PyObject * v)
print(stats.binom_test.__doc__)
import_array()
self.roomManager = MucRoomManager(self.stream)
arr = array.clone(template, 127, False)
sample_one_mask = df.SAMPLE == 1
c = np.ma.masked_array(value, value == 1.0)
self.visibility_changed(True)
print(chunk)
a = Foo()
__table__ = tmpSelect
counter = counter + 1
ns = builder.build_classes()
terms = set(search_terms)
a = 1
self.data.clear()
print(p4.diff(z))
console.log(e)
bytereader = functools.partial(fobj.read, 1)
countUniques = len(uniqueDF.index)
counter = [0]
my_debug = True
test = Test()
n = 0
es.indices.delete(index=config.elastic_urls_index)
x = idfun(x)
markers_array = list(matplotlib.markers.MarkerStyle.markers.keys())
pairs = tree.query_pairs(50, p=2)
str_value = str(s.cell_value(row, col))
Tprime = T
0
X = [ic]
new_path.append(elem)
f = lambda y=y: y
cxy = np.fft.irfft(X * np.conj(Y))
n = htonl(n)
self.s = s
chunk, iterable = iterable[:size], iterable[size:]
output_width = 800
result
MyClass.ClassMethod()
iterators = [chain(it, sentinel(), fillgen) for it in args]
vertexAttributeList.append(vertexAttribute)
f(6.0, sorted_list)
seqtype = v.field
numprocs_start = 1
x.c = 1
print(elem)
Base.metadata.bind = engine
ps = []
process(d)
buckets[n / chunk_size].append(n)
self.data = data
xrng = np.arange(-10, 10, 0.1)
dt = datetime(year, month, day, 10)
X_train_data, Y_train_data = load_svmlight_file(svmlight_format_train_file)
num_pixels = clibblah.get_pixel_length()
draw1.text((0, 0), text=text, font=font, fill=(255, 128, 0))
bytes_to_shift = file_length - offset - len(some_bytes)
column += 1
print(y)
assert age in input_given
all_mod = []
newData = true
DisablePlugins = pnat
raise IndexError(message)
lib.test(pointers)
pattern = list(pattern)
t_end = 100.0
print(answer)
x = np.array(x_range)
a
shutdown / l
j.text
hithere
fileContent = myFile.read()
4
print(df)
toDict(d[l[0]], v)
print(i)
ignore = migrations, badapp
svm_model.predict = lambda self, x: svm_predict([0], [x], self)[0][0]
vector_norm = a * a + b * b + c * c
average_values
subreq = request.copy()
date_index = pd.DatetimeIndex(df.created_at)
print(ref.text, ref.a.href)
r[j] = 0
vertexAttributeList = []
asset.asset_image.delete(save=False)
hi = len(l2)
celery.conf.CELERY_RESULT_BACKEND = REDIS_URL
s
[1000, 1070, 900, 910]
p.map(merger_wrapper, mergelist)
6
register(B)
self.uuid = str(uuid.uuid4())
x = np.arange(-10, 10)
srcf = str(source[0])
ch = scr.getch()
l, data = inp.read()
new_background = 255, 255, 255
bs4.builder.builder_registry.builders
field_1 = m.group(1)
timezone = pytz.timezone(timezone_str)
l2(1)
screen.blit(ball, ballrect)
observer.schedule(event_handler, targetPath)
fake_server.server_activate()
assert timestamp1 == timestamp2
used_legends = set([])
app = NSApplication.sharedApplication()
concatenation
num += ord(byte)
theta = -1 * theta
PyObject_HEAD
A, B = np.meshgrid(a, a, copy=False)
self.exit = multiprocessing.Event()
module = getattr(root.addons, module_record.name)
elem = PyList_GetItem(list, i)
s = StringIO.StringIO()
inq = mp.Queue()
a * np.exp(b * x) + c
PyArray_ScalarAsCtype(object, storage)
i = 1
rows_count = cursor.execute(query_sql)
PyObject_HEAD
1
self.maxidx = -1
BOOST_PYTHON_MODULE(example)
id(a)
config = Configurator()
x += (x2 - x) * 0.1
print(x)
old_out = sys.stdout
d[k] = v
a += 1
out_view = mmap.mmap(out_f.fileno(), length)
count += 1
gen = (word[i] for word in words)
df
USE_I18N = True
print(TestWithGlobals.__name__)
assert len(self) == len(other)
event.Veto()
t1 = t - p * (a - a1) ** 2
1, 2
ABA
print(i, j)
t.timeit(number=1000)
i[0] = 5
i = i + 1
a
xlApp.Visible = 1
maxDensityValue = np.max(my_pdf(x))
myNewMassage = copy.copy(BeautifulSoup.MARKUP_MASSAGE)
match = haystack.index(needle)
readable = False
numbers = 1, 2
definition = models.StringField()
result = []
l = []
bar = np.random.rand(size, size)
newlist = []
result = data.count(element)
result = -result
Out[5] = {0, 0, 0, 0}
num = self.data
sum(1 for _ in while_equal(seq, other))
2 + 2 == five
items.append(item)
cdfv = np.minimum(cdf_val, 1 - cdf_val)
mapY[y, x] = y + 100.0 * (d.y - e.y) * (e.z / d.z)
my_project_tree,
result = value_if_false
excel.XlFormatConditionType.xlCellValue
Protocol(self.a)
True
cython.double
MouseButtonRelease, self.cursor().pos(), QtCore.Qt.LeftButton
a = 10
print(tuples_list)
mealPrice
relation(a, mapping)
tmp.append(val)
grid = np.mgrid[xleft:xright, ytop:ybottom].reshape(2, -1)
image = np.arange(100).reshape((10, 10))
_, f = c.read()
print(a is b)
new_root[:] = root[:]
cccc
window = Calculator()
http_server.listen(5000)
old_min = -16000
myArray[(2), 1:4] = 16.0
args = [A, B]
point(-1, 0)
dir = 1 if step > 0 else -1
batch_size = 16
rec_array
screen = pygame.display.set_mode([700, 500])
Image.fromarray(im).save(sys.argv[2])
w = 7195
list_yc.append(yc)
new_points = []
fmt = wb.xf_list[cell.xf_index]
x = [1, 2, 4]
self.last - self.first
logger
raise StopValidation()
b1.on_clicked(callback)
cool_func()
df = DataFrame(rand(10000000.0, 15))
sample2.append(rand2() >= 0.5)
pid = os.fork()
val += d_abs(tmp)
localize = True
cb = fig.colorbar(im)
byts = s.encode(encoding)
button_objects[typ]()
print(uniqueList)
ws.freeze_panes = c
myOption_1 = models.CharField(choice=OPTION_1_CHOICES, max_length=2)
n2 = choice(list(range(1, 100)))
assign_op = x.assign(1)
pending -= 1
fds.append(fd)
x = lambda : next(a)
multiples_of_2 = iter(range(0, 100, 2))
x[int(fno) - 5] = val[1]
x = 1
choices[idx]
set_of_related_nouns
current.add(a)
currentDict[key] = {}
ret, img = cam.read()
oracle_subprocess = subprocess.Popen(OUI_DATABASE_10GR2_SUBPROCESS)
abcdefg
pen.append((x - 1, y))
IMC.special = A.thingy()
desired = s.diff().fillna(s)
field_info
vals = request.args.getlist(key)
FF = (1.0 - f) ** 2
N = np.uint64(2 + 2 ** 10 + 2 ** 18 + 2 ** 26)
n_cols = L.shape[0]
self.fire(done())
myclass = MyClass()
b_item.doSomething()
suffixed_num = str(num) + suffixes[num % 100]
t = timeit.Timer(method2, setup)
checker = Validator()
d.a = 1
band0 = biglist[::nbands]
A = sorted(set(A))
a = ref(1.22)
B = set(B)
out = StringIO.StringIO()
str += alpha[num % base]
my_scope = {}
N = 2 ** int(np.ceil(np.log2(M)))
d[item] = dg(item, 0) + 1
sorted(result)
start = 0
Py_DECREF(myobject_method)
print(tempdir)
tup(A, B)(A, A)(A, C)(B, B)(B, A)(B, C)(C, B)(C, A)(C, C)
save - buffer
s = Solver()
magnetic_permeability = 1.0
a * np.exp(b * x) + c
indices = numpy.nonzero(age_and_sex)
lst[1]
print(position)
B = bytearray(N)
s.set_seq2(y)
prices = []
j = 0
mm_obj[:] = data[:]
w, h = im.size
db.to_dict(o)
cx = rt.new_context()
[formatter_form01]
ret
attr
print(found)
add_two(4)
line = data.readline()
print(fmt.format(i, name, grade))
class_inst = getattr(py_mod, expected_class)()
f(*new_args)
buffer_df.iloc[-1] = item
token != NULL
names_and_values[:, 0::2] = names
print(qry)
print()
ycoords.push_back(y / count)
s = Foo()
self.number = self.new_number()
cxy = np.hstack((cxy[:len(x)], cxy[N - len(y) + 1:]))
largest = i
mpz_mul(result, result, base)
[py]
self._dict = d
arr = np.concatenate((zs, rs))
dialog = QtGui.QFileDialog(self)
end = item[1]
cont = [map(itemgetter(1), g) for k, g in groupby(enumerate(full_list), lambda i_x: i_x[0] - i_x[1])]
data = stride(v, (v.shape[1], v.shape[0] - 4, 5), (sc, sr, sr))
y2 = np.cos(2 * np.pi * x)
httplib.HTTPSConnection.connect = connect
artigo = convert_pdf_to_txt(ele)
self.l = self.manager.list()
c = boto.sqs.connect_to_region()
to_range_list(T.left, l, T.h) + to_range_list(T.right, T.h, u)
print(C.todense())
a = A(1)
num = self.data
self__theme_variables = self.__read_theme_file(self.__theme_name)
row_mask
f = 4.55556
num_rows = len(t_values)
a = b
df.col1
100,
my_own_id = func
x = np.linspace(0, 20, 1000)
PyNumber_Power(PyObject * v, PyObject * w, PyObject * z)
testsite_array = []
cont = itertools.count()
_plugins = []
incr_list(list)
pyz = PYZ(a1.pure)
k = 5
weights = np.empty_like(x)
fmt = sum(zip(res, args), ())
n = numbers.pop()
print(plot_html)
b = a
tokenizer = nltk.tokenize.punkt.PunktSentenceTokenizer()
maybes, yeses
b = ord(msvcrt.getch())
destination[key] = value
chunk_start = 0
list(c.find())
queries = []
total = 0
a.getcode()
simple = test.SimpleArray(100)
print(app.testComplete())
glMatrixMode(GL_PROJECTION)
True
offset += len(b)
levels[-1] = State.Inside
ttime = Column(DateTime)
m = T.submit(block5)
0
prodM
[workspace]
new_dict = invert_dictionary(d)
print(distances)
masterList.extend(setA)
custom = Custom()
points.shape, (t1 - t0) * 1000, (t2 - t1) * 1000, len(triangles)
error_base = ctypes.c_int()
1.5 < a < 2.5
Instrument()
max += 1
net.activateOnDataset(ts)
substrings = [text[i:] for i in range(len(text))]
user_social.refresh_token(strategy)
dataptr = arr.ctypes.data_as(c_float_p)
level = NOTSET
timestamp, _, arena = line.split()
sqla.session.remove()
iterable = iter(iterable)
a = A()
arg = ngrams(rand_str, n)
new_list = []
ureg = pint.UnitRegistry()
list[place] = item
w, h = I.size
employees.append(employee)
print((nun, val, wrd, i))
print(names)
gl1 < -locate_guide(g1)
a = numpy.zeros(4)
Data = daqread(mydata.daq)
print(connection.queries)
Special.convert_to_special(b)
tmp_deepest_list, tmp_max_depth = get_deepest_list(li, depth + 1)
print(fail_url)
num = num ^ mask
self.y = int(grid_number[2:4])
traceback = traceback.format_exc()
array = np.random.random((2, 4))
m = getattr(module, l[0])
mat
message = sendgrid.Mail()
foo.prop
some - module.js
qs_tomorrow = queryset.filter(date=tomorrow.date(), time__lt=tomorrow.time())
print(a.i)
-models.py
geo_ref = lyr_in.GetSpatialRef()
assert expected == stefan
res = stats.linregress(x, y)
raise StopIteration
rows, cols = rows[idx], cols[idx]
bytes = -500
Parkour_Character.move_ip(-Parkour_Speed, 0)
rows = np.arange(N) - row
out = A.copy()
d = deque(numbers)
unique_items = set()
kFile.close()
register = template.Library()
image_data -= display_min
co.add_extension(pluginfile)
new_f
True
next_ = objects[index + 1]
object_id = models.PositiveIntegerField()
leftFork = philosopherId
CharField.register_lookup(CharacterLength)
ans.append([head] + tail)
help(randint)
sequence.append(new_num)
x_int = int(x)
count
filename = secure_filename(form.fileName.file.filename)
synsets = []
order = np.argsort(ff)
notification.setSubtitle_(subtitle)
k1, k2 = zip(*gen())
final_q = Q(subthing_set__main=True)
wb = load_workbook(workbookEx.xlsx)
2
y = np.sin(np.pi * x)
numin = numin - 1
ok
included[l[i]] = true
BEGIN
maxSize = contours.at(i).size()
zero = 1
new_types = [x for x in org_types].append(self.portal_type)
4
myintvariable = 1
django.VERSION
a == c
counts = np.bincount(g)
y = [p.y for p in points]
n = np.array(a)
memo_dict[source_node, sink_node] = result
print(asizeof(d))
max(matches, key=len)
polygonSymbolizer = mapnik.PolygonSymbolizer()
mask = np.array([False] * 2000)
width, height = a.size
t = loader.get_template(email_template_name)
print(val)
dictionary
result.parent = last_result
square = 2
sum_of_all_assignments
valid_strings = {}
register(A)
zq = polyfit(x, y, q)
resp, content = service._http.request(download_url)
Crawler._visit(attr[1])
pos = [left, bottom, width, height]
self.frame = frame
sum_of_all_assignments = grades.sum(axis=1)
batch = db.new_batch_list()
self.data[key] = value
0
keys, values = node.keys, node.values
sr.latch.set(lastLatch, cb)
config = Configurator()
PyGILState_Release(state)
max_w = root.winfo_rootx() + root.winfo_width() - 15
header_lines = list(itertools.islice(file_handle, header_len))
cur.execute(copy_cmd_str)
print(a_foo.bool_clause(10))
key
M, N = a.shape
https.urlopener = opener
self._paths
1
GO
it = list(range(10))
dist = getattr(scipy.stats, dist_name)
t = datetime.datetime.now()
some_utc_date = datetime.datetime(2002, 10, 27, 6, 0, 0).replace(tzinfo=utc)
q = []
sorted_groceries = {}
wb = Workbook(optimized_write=True)
why = WHY_YIELD
data = f.read()
summation = 0
1, 2, 2
ele.attrib[field.attname] = str(getattr(self, field.attname))
vertex_list = [vertex(ID) for ID in range(1, 6 + 1)]
s = Spam()
_config_parser_get(required_environment, id)
print(c)
temporary_expr_result = True
sig = sig0[1:]
ss = [a, b, c, d]
groupLen = len(list(group))
screen - r
new += a[x - 1] + a[x]
syn_set.append(item)
mock_nova_client.authenticate.side_effect = Unauthorized(401)
numericVariable % 10
r = f(V, values_dct=vals, eq_lst=[IDEAL_GAS_EQUATION, MY_EQ_2])
y[index] = REPLACE_WITH
print(s.sentences[0])
print(i)
sorteddates
th.start()
sum
hProc.Close()
cls.selenium.start()
credentials = run_flow(flow, STORAGE, flags, http=http)
comb(n, k) * p ** k * p ** (n - k)
-output / user / Abhi / MRExample / Output
previous = 0
results = []
key, value = mr_job.parse_output_line(line)
entries[key].append(entry)
y = x
first_day_of_the_month
s.name
y = T.sum(A) * b[0] * c[0]
raise StopIteration
flag.value = flag.value and bool(o.name)
users_table = User.__table__
spacer = {s: 0}
stack = list(stack)
l2 = []
df4 = grouped.last()
channel = client.get_transport().open_session()
boat
x = 1
s.image
total = total + (mean - x) ** 2
result = lm(formula=my_formula, data=DF)
Distinction
n = 1
lock = thread.allocate_lock()
b = bytearray(a)
1
indices
Handle(handle.value)
head[:, (0)] = 42.0
greeting
conn = op.get_bind()
partial = functools.partial(getter, noise=noise)
x = np.reshape(logn, (N, 1))
logx_bar = ravel(log(data)).mean()
logger = mp.log_to_stderr()
print(b[10:])
signer.finalize()
something = 4
a == b
diff = array[1:] != array[:-1]
print(sum)
memcached._SOCKET_TIMEOUT = whatever_you_want_it_to_be
ArrayType = c_double * 5
k = t1 + t
N, k = map(int, (N, k))
sock
s1, s2 = set(l1), set(l2)
frame = inspect.currentframe()
len(T.cache)
file_like_object = io.BytesIO(my_zip_data)
show()
d
startsecs = 5
restOfLine = line[12:]
sin(degrees(x))
fig.colorbar(cax)
host = host or fabric.api.env.host_string
print(pool.map(foo, buff))
print(repr(d.delimiter))
g.json
l
offs = -1
objects = CustomerManager()
name_map = {}
context.check_hostname = True
stretch = 2 * np.random.rand() + 0.1
print(record.status)
print(type(b))
OPTION_D = 8
_triple_file.write(triple_response)
_methA(parm1, params)
_methB(parm1, params)
nitems = libc.fwrite(c_uncompData_p, sizeof_item, c_uncompSize, file_p)
x = np.linspace(0, 2, 1000)
defdict
chomp
cview.callback_memory_free = free
num % val == 0
print(lowest_dirs)
Dt
a[100] = 55
target = blognodes.base62(b10)
data1 = data1.groupby(data1.index).sum()
multiplier = 10 ** (max_digits - magnitude)
slice1 = slice(indices[i], indices[j], steps[k])
sc = SparkContext._active_spark_context
h = ImageChops.difference(im1, im2).histogram()
self.view[0] = 1
m - v
matrix2 = numpy.identity(5)
print(conset)
currentAxis = plt.gca()
axis = list(range(x.ndim))
frm.for_type(float, thousands)
0
create_json_response
self._hash = hash(self.left) * hash(self.right)
event.set()
res, spars = _suitability(child, word, mx)
post
foo[idx] = a + 42
tfidf = TfidfVectorizer(preprocessor=lambda x: x, tokenizer=lambda x: x)
worksheet = workbook.add_worksheet()
connection = pyodbc.connect(connection_string, autocommit=True)
img = Photo(user=user)
ds = ds[ds.notnull()]
chunks = []
pickle.dumps(n1)
n = len(a)
ret = a[0] * np.cos(np.pi / tau * x)
t = np.arange(sx.size, dtype=float)
P[np.triu_indices(n, 1)] = _R
i
val = value_in_frame(tok, frame)
print(e)
n = -42
output
x86_64
wb = Workbook(optimized_write=True)
print(output)
summation = 0
reverse = lambda a: a[::-1]
lower <= x[column_name].sum() <= upper
max_height = 4
data = s.recv(1024)
thread_table = Thread.__table__
old_raw_input = raw_input
console.log(response)
exit()
X_test = vectorizer.transform(data_test)
notifier.read_events()
total = array([0] * width)
self.linelocs[loc.getLineNumber() - 1] + loc.getColumnNumber()
bins.append(bin)
df[ping]
self.variance = self.M2 / (self.n - self.ddof)
newListOfString = []
from_dt = datetime.datetime.strptime(start_date, DATETIME_FORMAT)
mylist = []
y[index] = REPLACE_WITH
increments = list(range(0, steps)) * np.array([delta] * steps)
in_data = (c_double * N)()
wrapper
print(output)
print(counts)
d(5) ** d(5) ** d(5)
max_value_len = max(len(x) for x in values_fmt)
a, m = 2, 10
os.dup2(to_file.fileno(), stdout_fd)
request.option = array
HADOOP_PREFIX / sbin / start - dfs.sh
26 % 7
pandas.DataFrame.filt_spec = filt_spec
pprint.pprint(m)
root = t.getroot()
self.wv = Wv()
Icon = gnome - info
[Out][6, 6, 6, 19]
lennardJones = 48.0 * r2i * r6i * (r6i - 0.5)
postvars = self.parse_POST()
start = next(iterator)
a.age
st.append(j)
arr[i] = v
A = [50, 60, 70]
nz = (p == 0).sum(1)
4 + 5
entry = Entry(frame, width=80)
window
clojure - csv.core / parse - csv
table = [fmt.format(*row) for row in s]
h = hashlib.new(x)
sample = [(v / sum(sample)) for v in sample]
2
graph_db = neo4j.GraphDatabaseService()
track.log()
i = 0
fpOutput[indexI, indexJ - 1] = True
doc2 = etree.parse(invalid)
self.__class__ = LLPoint
INVALID_HANDLE = 1
handler = urllib.request.HTTPHandler(debuglevel=1)
m = len(q) // 2
sessions = []
cats.setDACValue.argtypes = [c_uint8, c_double]
ctx = SSL.Context()
new_image
self.__q = q
nom_plan_label.setText(nom_plan_vignette)
schema = MySchema()
self.g = g
map(type, f.__closure__)
data = file_obj.read(size)
ind.clip(0, len(m) - 1, out=ind)
this_may_cause_an_exception()
mean, std, sterr, ci
f(args)
is_all_true = lambda *args: all(args)
y = [(i + random.gauss(0, 1)) for i, _ in enumerate(x)]
e.filename = path
t = Texttable()
o.x = 5
indices = np.triu_indices_from(A)
cont = plot_2d_probsurface(data_x)
a = [1]
logging.Formatter.format(self, record)
p = pdf.getPage(pg)
msg = self.format(record)
env
fig = pyplot.gcf()
print(pValue)
zona = l[0]
0
self.filter_name = filter_name
t = browser()
print(final_result)
yearcom = x[8]
xa1 = (xa != 0) + 0
console_handler.setFormatter(formatter)
a[:5, (-1)]
x = (x + H(y) % W) % W
self.count = 0
your_solution(v_iter)
reply = sr1(packet, timeout=TIMEOUT)
blue = 2
value = getattr(item, tag).string
stream = StringIO.StringIO(data)
theSum += (xi[k] - a[k]) / (b[k] - a[k])
v[1].sort(key=lambda x: len(x))
df = sqlc.read.options(catalog=catalog)
ax_global.imshow(img_global, cmap=plt.cm.gray)
data.date_time = time.localtime(time.time())[:6]
compiler.reserved_names = set()
0 / 0
d = dict(d)
le_end = df.time.values <= end.to_datetime64()
int_type &= int_type - 1
k, d = s.detect(gray, mask, False)
date_list = []
res
modules / recon / bing
sem = multiprocessing.Semaphore()
print(cmp(c1, c2))
match_list = [x.id for x in match_list]
__serialize(cls, d, ds)
j += 1
record_dtype = record_type.get_dtype()
image.alpha_channel = True
b = 4.4
c_array = c_float * len(points * 2)
print(res)
i = 0
print(resultset)
longest = 0
BOLD = 1
printItems(i)
str
1.01280212402e-05
1.16641521454e-05
print(d1)
d = b ** 2 - 4 * a * c
x[slice1], x[slice2] = x[slice2], x[slice1]
res = a0 * x[0] + a1 * x[1]
self.override = 0
res = exp(log_res)
n
response
stack = inspect.stack()[2:max_depth]
df2
item
self.min = min(self.min_set.keys())
srclen = len(srctext)
red = (16751018 & 16711680) >> 16
y
M = map(abs, (-1, 0, 1))
instance = plugin()
print(row_format.format(team, *row))
x2, y2 = 0.2, 50000
artist.reviews.extend(reviews)
results = [pool.apply_async(do_work) for n in range(20)]
node = stack.pop()
viewPydot(pdot)
self._cursor.execute(query)
x = x + 2
self.end_time
architecture / webservice_arch
col, start, end = -1, -1, sheet.nrows
prime[j] = False
G = nx.Graph(directed=False)
AwfulHackToGetTheInternedDict = ctypes.pythonapi.AwfulHackToGetTheInternedDict
body = {current_edge[0], current_edge[1]}
print(s)
s = lambda t: volume * math.sin(2 * math.pi * frequency * t / sample_rate)
matches = re.findall(regex, user_agent)
nth_largest(n, iter)
X = X.copy()
in_file.close()
sum += number / t
upperlist = []
assert number >= 0
sqlContext = SQLContext(sc)
last_indent = 0
result.append((tot_rtn, p_rtns_md))
K, L = L, grow(L, E)
lastInputInfo = LASTINPUTINFO()
out_put.append(coach_details)
x[0]
obj.get_profile().company
l = lognorm(s=2, loc=1)
sys.excepthook = excepthook
split
d2.shape
decoder.process_raw(buf, False, False)
item in self.set
locale.windows_locale[windll.GetUserDefaultUILanguage()]
w, h = mode.width, mode.height
ld[x, y] = r, g, b
start_date = datetime.date(2016, 11, 22)
result = False
temp = cooling_rate * temp
s2 = s.sub(0.5).rolling(2).sum()
self.when_client_connection_starts()
tam = len(contorno)
convert = true,
target_dict = {}
lst
dis.dis(Bar)
r, n = r + n % 10, n // 10
rule.match_compare_key = spoof.__get__(rule, type(rule))
i = TestItem()
x, y, z = zip(*list(data.values()))
k = deepcopy(d)
self.logFilePath.set(filename)
plt.xlim(0, 1)
doer.doSomething = MethodType(doItBetter, doer, Doer)
cryptogen = SystemRandom()
mergedVersions[-1].append(v)
L.append(b[j])
permission_classes = CustomPerm,
opener = urllib.request.build_opener(proxy_support)
print(result)
timep
settings.DEBUG = True
magic(f)
cd / tmp / my - test - env
cursor = connection.cursor()
not_full = np.diff(mat.indptr)[major_index] < N
rand = random.choice(tiles_letter)
current_element = 0
prediction = model.predict(samples[i])
l2 = MyList(l1)
memory = joblib.Memory(cachedir=tempfile.mkdtemp(), verbose=0)
ItemPage.objects.live().child_of(self)
val
vertexAttribute.extend(list(triangle.normal))
html = response.read()
flier_low = rand(10) * -100
print(config_root.sites.mysite.name)
new_shorter_edge = tf.constant(400)
aStrOBJECT.__sizeof__()
iterdict = iter(mydict.items())
encrypter = ECC.generate()
i += 1
print(new_p)
y = np.append(y, i ** 2)
merged_data
m = a < 1
x = Decimal(x)
py > ast.body
yesterday
hs = pd.Series(h[:, (station)], index=jd)
d_next = d + datetime.timedelta(weeks=4)
jpeg_bin = sess.run(jpeg_bin_tensor)
shipping = TestShipping
print(col)
fp = urllib.request.urlopen(url)
pp.pprint(x)
D(1, 0)
id_arr[clens[:-1]] = 1
result_dict = manager.dict({})
print(i)
a += 1
a = 7
scoring(num_items, next(index))
i
ws.panes_frozen = True
CoReleaseObject(iclassfactory2_ptr)
task = asyncio.ensure_future(asyncio.sleep(5))
y = f(x, *popt)
process_data(piece)
somelist = list(range(10))
previous_stats = config.load_results(self.file_state.base_name)
ax = plt.axes()
cdf_start = norm.cdf(a_s)
canvas = FigureCanvasTkAgg(fig, canvas_master)
rec(tf, inner_paths)
inlines = [UserProfileInline]
NO, YES, NO, NO, NO
winsound.Beep(800, 500)
print(queue_dic[p.pid].get())
f_in.close()
my_space = my_space.apply(PpmiWeighting())
print(keys)
grequests.map(rs)
do_stuff_in_transaction(conn)
rect = ctypes.wintypes.RECT()
sp = spline_neumann(x, y, k, s=n * std)
xP, yP, iP = mostfar(iP, n, s, c, 0, 1)
j = 4
result = 0
argtypename, argval = next(list(kwargs.items()))
iterator = iter(iterable)
pad, num = 8, 9
print(r)
X_sample = np.expand_dims(X_channels_first, axis=0)
rv = {}
copy_table(se1, db1.Book, se2, db2.Book)
folder = findFolder(folder.folders, searchPath, level + 1)
deletetuple
print(loc)
log(a) - special.digamma(a) - s
x = np.linspace(0.1, 1.1, 101)
indices = list(range(n - 1))
n = np.linspace(lo, hi, num=N)
QtGui.qRed(rgb), QtGui.qGreen(rgb), QtGui.qBlue(rgb)
ShowIndex()[..., :]
info = json.loads(urlopen(url).read())
d.extend(new_list)
Py_RETURN_TRUE
start, stop = indice[0], indice[-1] + 1
result[i][j] = val
register = template.Library()
output
f_c = CFUNCTYPE(c_int)(f)
self[new if old == k else k] = v
data = toplevel.parseString(testData)
values = values[::-1]
client = socket.create_connection(ADDR)
found_one = False
seen.add(y)
set_death_signal(SIGTERM)
s1 = Singleton()
self.box()
pathList = sorted(pathList, reverse=True)
region = eu - west - 1
producer.start()
user.no_of_logins += 1
engines[:].push(shared_dict)
self[0]
myformat(1.0)
i = 0
print(next_monday)
item_numbers = []
display(maximal_difference_reorder1(list(range(10))))
char * token
bsort = b1.argsort()
ret
gui.stop_signal.subscribe(thread.handle_gui_stop)
rd = REL.relativedelta(days=1, weekday=REL.FR)
self.method = method
self.theConfig = theConfig
result[parameter] = currentResult
1
result
array_lambda = np.vectorize(lambda x: x * x)
stat_table
D = array(A)
90
dict[op]
ts = time.time()
unique_columns = sorted(set(columns_non_unique))
s = csv.Sniffer()
p2 = Line_Point.Point(p1.x, p1.y)
start = text_cell_runlist[segment_idx][0]
count_votes_for(this_record)
firstname = CharField()
myl[idx] = 44
slopes = rise / run
cc = ClientCreator(reactor, MyProtocol)
self.d[row].get(col, default)
Returns
u = ((y_true - y_pred) ** 2).sum(axis=-1)
address.sun_family = AF_UNIX
c = comb(n, k)
map_values = np.array(list(codeTable.values()))
gdfJson = json.loads(guestData)
a[2:4] = []
im1 = m.pcolormesh(xx, yy, data[(0), :, :].T, cmap=plt.cm.jet)
ord(item)
values = array(1, 2)
print(sent)
d1, d2
assert sorted(keys) == keys
domain = dns.name.from_text(domain)
net.addModule(h2)
new_word += char
result.append(v - 1)
True
b = np.arange(1000)
data_dict = defaultdict(list)
d = defaultdict(tuple)
func
print(r)
cv_arg = sklearn.cross_validation.StratifiedKFold(y, n_folds)
print(comment_entry.author[0].name.text)
lg.string.lower
sniffer_timeout = 60
TEinTSS = list(itertools.chain.from_iterable(p.imap_unordered(f, b)))
iitt = 15
key = base64.b64encode(kdf.derive(user_pwd))
body = self.cur_node
inSecs = int(round(frac * 86400.0))
l = len(b)
n = 5
big_shuffle(file)
fmt.Println(err)
choices[idx]
rank = [0] * N
print(d)
myInt = 10
0, 1, 10
xlApp.Visible = 0
r = np.random.rand
xy = np.column_stack([x.flat, y.flat])
categories[bisect.bisect(points, 1000)]
include_files = []
pd.Series(a)
print(fix_space(strip_po(s)))
self.__id = id
shifter = numpy.arange(K * N).reshape((K, N))
dataset = map(algo, dataset)
bigNumString[i] = 0
s = str(type(mydict[key]))
self.name = name
integrate(expr, manual=True)
print(i)
p.xaxis.major_label_orientation = pi / 4
wrapped
print(a)
start = max(0, a_start + b_start * a_step)
print(A.method is A.method)
[10, 5]
m = self.axes.transData.get_matrix()
Salesman
soup
val2 = float(input())
print(response.additional)
l = []
b[1], b[0] = b[0], b[1]
header = fd.read(100)
IDs
print(x)
self._box = widgets.Box()
top_matrix[0, 1] = -1
gateway = JavaGateway()
xi = linspace(min(x), max(x))
length = -1
para1
slices = int(math.ceil(height / slice_size))
Task(it)
actual_width += len(temp) - 1
print(stuff)
modules
fnmatch.fnmatch(s, pat)
2, 1, 2
print(activeAppName)
DBSession1 = scoped_session(sessionmaker(extension=ZopeTransactionExtension()))
print(df_result)
messageSent
my_child = my_n_node.firstChild
8
der = asn1.DerSequence()
pip - V
print(a)
screen = Gdk.Screen.get_default()
s = difflib.SequenceMatcher()
district = x[0],
imgfile = StringIO(img.value)
print(id(x), id(y))
t = int(text)
a
top = textview.get_iter_at_location(visible_rect.x, visible_rect.y)
t.start()
bins
many_to_many[field_name] = validated_data.pop(field_name)
X[17, 17] = 1
running_sum
vertexAttribute[9], vertexAttribute[10], vertexAttribute[11]
a.appendChild(b)
print(text)
exit()
p = partialAP(func, self.fset)
ftype = type(v)
self
s[s == True].index
--Package
deletetuple
title = models.TextField()
len = arr[i].length
counter = Counter(key_name=key_name)
wrapper
ketvirtas_m = df_data[90:120].reset_index(drop=True)
item_id
myletters
transformtable(fieldname, value)
readRequest += chr(2 * nToRead)
arr[mask]
self.speedTestForRecordType(CustomLog)
self.c = toto(combis)
random.shuffle(thetaList)
x = 1.0 / 2
category = django_filters.CharFilter(action=filter_category)
t1 = time.process_time()
cax = ax.matshow(a - b, cmap=cm.jet, vmin=-8, vmax=24)
meth.__name__ = syncname
d.addCallback(lambda ignored: reactor.stop())
mlab.gcf().scene.disable_render = False
0
deletesys.modules[k]
l[0] = 17
it = iter(iterable_or_sequence)
groups[i] = self.getGroup(selected, header + i)
client.wsdl.url = host
memory_shuffle(file)
v = NP.r_[(0.2), 1:25:7, (60.8)]
cmap = cm.jet
yfinal = np.vstack((yfinal, y))
user_options = install.user_options[:]
readEnd, writeEnd = os.pipe()
dict_dates[date] = dict_dates.get(date, 0) + 1
print(Decimal(1.0 / NUM_BUCKETS))
django.db.connection._valid_connection = validConnection
out[(0), :pad_length] = padnum
show()
z = 4 * x + 5 * y + 7 + np.random.rand(1000) * 0.1
precision_ratio
vbdrecord.type = Types.VbdType.CD
unique, count = npi.count(m)
x, y = int(move[0]), int(move[-1])
outdict = {}
setattr(StreamHandler, StreamHandler.emit.__name__, customEmit)
print(err)
image -= display_min
the_subset = the_list[the_indices]
r = 2
yvalues = 5 * numpy.sin(xvalues)
ds = lambda d, cls, column_name: str(d[column_name])
a = []
globals()[generatedClass.__name__] = generatedClass
self.i = max(0, self.i - 1)
self._url = amqp_url
new_result = new_type(result)
parent.py
self.default = default
i = 0
times = np.arange(data.shape[-1])
tbl = tuple(51 * ((int(i) + 25) // 51) for i in range(256))
counter += 1
s = Solver()
self.list1[i] = x1
rc.append(node)
myInt = 10
xi[xi < xmin] = xmin
d2 = left_pos - np.append(0, diff_pos[:-1].cumsum())
r.raw.decode_content = True
xR, yR, iR = mostfar(iR, n, s, c, 1, 0)
font.set_style(pango.STYLE_NORMAL)
last_data = data
ws1 = wb[sheet]
bus = dbus.Bus(dbus.Bus.TYPE_SESSION)
print(df.data.notnull().cumsum())
adj[i, 0] = x
prompts = []
formatter.add_usage(self.usage, self._actions, self._mutually_exclusive_groups)
yi = linspace(min(y), max(y))
doc.build(elements)
post.tags = []
data = []
dt = ((dt - dt.min()) / (dt.max() - dt.min()) * 255).astype(numpy.uint8)
print(time / 1000)
t2 = t[1:-1]
x[i][j] = x[i - 1][j - 1]
tracer = trace.Trace()
first_line = xml_file.readline().strip()
pending = len(iterables)
iris = datasets.load_iris()
p(x)
not_found_vals = vals_set.difference(found_vals)
temp = list(range(27))
counter.value += 1
self.append(data)
s
mu_x = x.mean(1)
bar_iter = aiter(bar)
requestSuceeded = False
user.locale
model = MyModel
class_members = [index[0] for index in np.argwhere(labels == k)]
lst
print(c is d)
print(out)
older_books
C[np.arange(n_cols), L] = 1
dy = ndimage.convolve(gy, image)
b = [2]
n = n + 1
N > sys.maxsize
cases = unittest.defaultTestLoader.loadTestsFromModule(mod)
im[8:-8, 8:-8] = 1
False
B.flags
h
y_hat = [y[0], y[1]]
i
print(s)
keylist = list(dct.keys())
pTag.contents
games = np.take(games_list, sorter, axis=1)
assert_equal(expected, len(found_nodes))
process = MyProcess()
df
w.join()
num
B = [10, 15, 20, 5]
x = UpSampling2D((2, 2))(x)
self.id = id
ofs.Minute(1) + ofs.Second(1) - ofs.Second(1)
print(even)
i = 0
i = i + j
locs, labels = plt.xticks()
loader = self.app.jinja_loader
stack = list(pairs)
print()
x = gamma_vals[ij] / (y * y + 4)
gateway = JavaGateway()
list < -list + (thisPath + v)
border_line_join, border_line_width, glyph_height, glyph_width
mlab.gcf().scene.disable_render = True
x -= APPWIDTH / 2
NL = LineEnd().suppress()
self.response.out.write(finalFreq)
pushButton = QtGui.QPushButton()
diff = np.square(diff)
value
[12, 14],
z = np.nonzero(s.values)
i, j = np.indices((50, 100))
Yellow
s = p.add_subparsers()
sanity_check -= 1
assert myFixture1 == 5
mux = pd.MultiIndex.from_arrays(df_a.values.T, names=df_a.columns)
fontsize = renderer.points_to_pixels(self._fontsize)
myName = eval(input())
pwnam = pwd.getpwnam(user_name)
converted_files = MyConverter.convert(ipynb)
self.__iter__()
overlap = (earliest_end - latest_start).days + 1
False
self.has_params = True
height = int(h)
ntok *= n
self.subdir == other.subdir
rng = np.arange(start, end)
numeroLinea = 0
_reload_builtin(thing)
indexes = np.argsort(dist, axis=0)
end = time.time()
line = Line_Point.Line(p1, p2)
smaple = sum(args)
i = code.InteractiveConsole(d)
tree = OneOrMore(group)
h.setFormatter(_cplogging.logfmt)
-1
initModuleTestBoost()
grids = np.zeros((U, U))
draw_polygon(polygon)
Lo
xrng = np.arange(0, 1, 0.01)
top, bottom = max(start, end), min(start, end)
cols.append(cell)
settings.INSTALLED_APPS = self._original_installed_apps
drivelisto, err = drivelist.communicate()
[(self.somelist[i] * 5) for i in key.indices(self.length)]
doc.build(elements)
a[0, i[(0), :]]
bar = Mock(spec=models.Bar)
old = myfile.read()
PROJECT(dbookpy)
print(get_interval(5500))
LGGR.info(traceback.format_exc([10]))
array = [name]
plot(img50_order0[(50), :, (1)])
datetime.datetime.replace.__code__
A = rand(10, 10) < 0.5
df.index = l
Record._make(tuplePi)
ngram_rev[token][rev_token] += 1
x = 0
start = max(min1, min2)
nbf.write(nb0, f, 4)
out[k] = v
desc = cursor.description
Q = [8, 7]
axes[2].pcolormesh(np.array(d2), cmap=plt.cm.coolwarm)
python
branch[event.key]()
state.update(value=next(iterable))
result = t.substitute(os.environ)
sio = StringIO()
view = rolling_window(arr, 2)
hover_tool.renderers.append(scatter)
sys.stdout = file
subplot.set_xlim((-7, 7))
args.d
new += l[1:]
i, j = 0, 0
UNIQUE(id)
subplot.plot(np.arange(10))
False
line = []
a = []
xstep = np.sign(x - 0.12) * -50
self.next_value = next(self.iterator)
m = np.zeros((1, 20))
first = update(first)
data
sortedPeople = people[inds]
exec_locals.update(copy_locals)
a_start_i = a * a_chunk_size
with_distances = ((myFunction(C), C) for C in originalList)
res
print(a)
print(i)
x = 0
model = obj._meta.module_name
records = records.reverse()
raise
split = item.split()
disc = b * b - 4.0 * c
cell.add_callback
it = iter(a)
out = StringIO()
groups = df.index.get_level_values(0)
parents_methods.update(members)
self.set_url(*parts)
int(50 + 0) is int(50 + 0)
print(t)
r = rgb[0]
a = lambda p: p - c
y0 = np.atleast_2d(ys[..., :-1])
PyCBack()
f.name
parser = reqparse.RequestParser()
s1 = s[s != 0]
m = np.random.rand(1, 224, 224, 64)
self
p = True
p2 = ctypes.c_char_p(sessionVar)
4, 5, 6
kwargs = dict((x, l[x]) for x in args if x in l)
result = e.text
number //= 10
x = np.append(x, i)
t.daemon = True
call_mifuntion_vers_1()
True
main()
print(today)
google.com
raise ExhaustedError(i)
pid, fd = pty.fork()
y += 0.0
distances[adj[0]] = adj[1]
k, v = self.popitem(False)
toc()
p = where(d == 0, p2, p0 - (p1 - p0) * (p1 - p0) / d)
ds = SupervisedDataSet(10, 11)
rebuilt_to_plot
cls._current_instance = Stats()
StartupNotify = false
PSH = 8
n = [e for e in l if e]
filename = os.path.basename(path)
answerSize += 1
print(a)
sqs_q = sqs.Queue(url=SQSQueueUrl)
d
level = DEBUG
tp = mystruct.type
y
print ()
raw.append(str(float(mod.__dict__[key])))
result
reactor.removeAll()
person = Person(person)
string
cols = ((np.arange(pdf.shape[1]) - p[1]) * 2 * np.pi * r / int_w / mult) ** 2
inoremap
text(bp, (ytop + ybot) / 2, LETTERS[seq(cats)], col=inv_col(seq(cats)))
out
samples1 = w1.readframes(w1.getnframes())
date = dates[0] + datetime.timedelta(tick - ticks[0])
print(count)
inner_read_b()
header_text = input.read(record_header.size)
abstract = True
resource = factory(request, res_id=res_id)
self.wordList = wordList
orders = dbsession.query(Order).order_by(Order.cdate.desc())[:100]
self.num_tweets = 0
compiler.walk(tree, visitor)
list_of_dicts = []
layout = vplot(toggle1, toggle2, plot)
myFoo.PrintBar()
memo[x]
a = 2, 0, 0, 0
branch_name = head.name
std = s.std()
Z = Y.real, Y.imag
raise StopIteration
e = a + b
print(dct)
text
EMAIL_PORT = 587
c = Counter(lst)
count = 0
l = len(x)
keylist = list(dict_1.keys())
K = NP.random.randint(1000, 9999, 1000000.0)
max_idx = -1
A.my_member.append(1)
df
value = seconds // count
_, y1 = ax1.transData.transform((0, v1))
mystruct = Bunch(field1=value1, field2=value2)
lst = []
i = i + 1
b = Board()
begin_ = nullptr
res = hres, vres
lt = localtime()
d.feeds[100].url
results = si.query(eval(qrystr))
geometry = models.MultiPolygonField()
key = row[1].value
img = args[1]
print(n)
H[(n), y2:y2 + clen] = list(T2)
then = tz.normalize(tz.localize(last_updated))
i = 0
str_type = h5py.new_vlen(str)
builtin_sum(iterable, startobj)
first = delimiters[0]
Mk = 64
i = 7
series = pd.Series(np.random.rand(len(dates)), index=dates)
df
pairLambs = []
maxballs = 5
print(a)
q.task_done()
parseTree(item)
directories = []
new_data = np.reshape(data[(row_ids), :], [data.shape[0] - 2, 12])
sss = StratifiedShuffleSplit(y, n_iter=1, test_size=0.5, random_state=0)
print(add(1)(15)(20)(4))
s
self.deco()
employee = Employee()
self.val
cum_sum_of_squares = np.zeros(im_size)
query = gdata.spreadsheet.service.CellQuery()
ivalue
txt = glob.glob(filepath)
mvv_array
firstSlice
running = 1
q = False
free(buf)
self.section_level -= 1
tree_dist = tree.sparse_distance_matrix(tree, max_distance=10000, p=2)
np.asarray([trial(N) for i in range(n_trials)])
root = Tk()
x = np.arange(1, 8, 1)
val = a[j] - b[j]
print(DataFrame(x))
future_time = epoch_time + 90 * DAY
print(b.example)
self.params = params
asyncio.ensure_future(listen_for_message(websocket))
set - e
x = 0
self.g[key] = val
group = 1
match = p(data)
tone1 = note(440, 2, amp=10)
_ntuple_diskusage(total, used, free)
current_time = datetime.datetime.utcnow()
iris = datasets.load_iris()
checkopfunc
tokens[index - left:index] + tokens[index + 1:index + right + 1]
1.8421741100028157
process = psutil.Process(proc_pid)
k = gen_pent_new(i)
authentication = TestResource.Meta.authentication
x
self.name = k
self.extended_get(parent_section, key)
cat.profile.d / path.sh
pipe = r.pipeline()
index, result = zip(*arraysums_recursive_all_positive(arrays, lower, upper))
wrap
workout = code_that_fetches_instance()
indexed_df = indexer.transform(df)
x == y
requirements = {{app_dir}} / requirements.txt
r + b
funcs = []
p1 = sy.plot_implicit(sy.Eq(x ** 2 + y ** 2, 4))
sign * 2 ** exp * (1 + mantissa * 2 ** -52)
q = a - b
limit = int(n ** 0.5)
ofh = StringIO()
print(volumes[0].attach_data.device)
orig_val += [my_pdf(e) * 100 * 2]
test.writeTo(outf)
item = deck.popleft()
it = iter(seq)
cosr = cos(radians(self.rotation))
print(cleanup(test_object))
print(e)
vars = globals()
b = PostFactory()
7 * 8, 5 - 6
upload(args.csvfile)
d
dt = sorted(dt.items())
dst_timedelta = now.dst()
j = 2
print(w)
memcache.add(image_key, response, 86400)
wrapper
z1 = e1(x, y)
labels, numL = label(array)
out = []
True
4 * x * z + 12 * x * y * z
indices = 1, 1, 2, 1, 5
N - fmin * f2
runs_scored = float(scores[0])
x
true
fail_url = self.driver.current_url
a = 500 * (XYZ[0] - XYZ[1])
im2 = cv2.imread(imgPath)
v = svm_model(px, pm)
z = norm.isf([sig / 2])
print(x)
item = q.get()
dic[input1, input2]
a = 1
unq_counts = np.bincount(unq_idx)
estimator.fit(input_fn=training_input_fn, steps=500)
store_and_clear(lst, k)
n & mask | m << i
intervals = zip(x_list, x_list[1:], y_list, y_list[1:])
fig = plt.figure()
BUU, BAA, DII, DUU = list(range(4))
path = self._treeView.get_cursor()[0]
x = np.random.random(size=(2000, 500))
argspec = inspect.getargspec(fn)
sample_multi_ix = list(product(sample_ix, time))
sys.excepthook = my_excepthook
all(allowed.match(label) for label in labels)
largest = inlist[1]
timestamp = str(int(time.time()))
ipdb > request.REQUEST
config.scan()
freeMem(s)
value += 1
cls = models.base.ModelBase.__new__(cls, name, bases, attrs)
song = Song.objects.get(id=song_id)
d = select_number.to_dict()
prgBar = FloatProgress(min=0, max=num - 1)
points = sorted(points, key=lambda point: point[0])
a, b, t, p = a1, b1, t1, p1
dic[gender][year]
y = x * x
print(self.inputs[in_])
keys = [n.s for n in node.keys]
available = [x for x, i in enumerate(board[y]) if i == 0]
years = [1997, 2016, 2000, 1989]
Num = gamma(1.0 * (d + df) / 2)
shinyApp(ui, server)
x = 1
Table2 = pd.DataFrame()
wrapped
txt
ind = list(range(1, int((1 + math.sqrt(1 + 8 * len(l))) / 2)))
FACTORY_FOR = Member
DB.connectAutoload()
h1 = SigmoidLayer(2)
fn = runtime.FuncForPC(pc).Name()
values = []
idx = roll(idx, -1)
prob_word2 = unigram_freq[word2] / float(sum(unigram_freq.values()))
print(e)
result = self.mapping[name]
sub = tk.Toplevel(root)
data = connection.read()
self.f = f
start = datetime.datetime(2015, 1, 1)
total += i
assert data[1].lc.col == 2
args = [-1]
m, n = df.shape
print(bar, baz)
max_mask |= dist2 < max_d * max_d
mindict = {}
x - x % 0.001
max_spaces = idx + 1
run
suffix += 1
compiled_regex.match(m)
+++b / python / pyspark / daemon.py
ctx.set_options(SSL.OP_ALL)
visualize_images(images)
self._close_old_connections()
IDEAL_GAS_EQUATION = P * V - n * R * T
initial_shape = initial_array.shape
get_char = chr
cursor = connection.cursor()
user = ubuntu
who_api = get_api(request.environ)
moo += np.outer(val, val)
library(ggplot2)
assert isinstance(column, str)
lines += 1
Samplesize = 100
counts = np.bincount(ID_arr * out_shp[1] + vals)
has_small_string = True
string.letters
update_tld_names()
content = BytesIO(resp.content)
font = MyTTF()
b.append(lambda foo=foo: foo)
self._original_installed_apps = list(settings.INSTALLED_APPS)
deleted[key]
p2.say_my_name()
console.log(txt)
rank[x] += 1
xvalues = numpy.linspace(0, 2 * math.pi, 1001)
jobs = [gevent.spawn(worker, url, True) for url in urls]
theta = np.linspace(-np.pi, np.pi, 200)
tree.body[0].body.insert(1, print_statement)
[pypi]
data_you_need = pd.DataFrame()
val = 4
some_long = ctypes.c_long(42)
coeff, var_matrix = curve_fit(gauss, bin_centres, hist, p0=p0)
simplify(vers1 - vers2) == 0
freq = f0 * (1 - ramp) + f1 * ramp
self._salary / 26
res = np.reshape(res, (-1, 4))
running_gid = grp.getgrnam(gid_name).gr_gid
width = max(coord[0] for coord in coordinates)
orgs = set(data.org)
memoryview(zm)[0]
print(a.eval())
self.transaction_manager = transaction.manager
func.__doc__ = doc
A = []
result = mpr.WNetGetConnectionW(local_name, remote_name, length)
vtk_win_im.Update()
conn.cursor().execute(insert, [isbn, shop_id])
myList = []
T = data[2]
mapper = Series(zip(names, intervals))
mat.polySphere(radius=7)
print(d())
self.alive = True
something
b = a[mg].T
_stdin = sys.stdin
SY = spline(t, sy, N, order=4)
list(lazy_funny_iter(n))
x.cat.codes
a
idx = consts.index(p.n)
b = 100
False
cols = [0, 4]
out_vec = out_vec[~numpy.isnan(out_vec)]
results.add(arr[i - n + 1:i])
indices = 1, 1, 2, 1, 5
foo.startStuff()
self._expensive_operation = self.expensive_operation()
tree.chomsky_normal_form()
output = sum(res)
self.logger = logger
newObj = self.copy()
print(r)
x, y = zip(*data[1:])
ssh.exec_command()
max_indices
index = int((target - start) / dt)
fpOutput[indexI + 1, indexJ] = True
delete_key_list = []
console.log(JSON.stringify(res))
neg = -100 * numpy.random.rand(20000000.0)
print(filepath)
s = s.upper()
tmp = []
U = sp.randn(10, 10)
mylist = []
f = lambda x: x * 2
print(list(perms(5)))
s.set_alpha(128)
crc = 0
font_description = pango_context.get_font_description()
2
count[request] += 1
row_indexer = pd.Index(cond1).intersection(cond2)
print((protocol, n, counts))
rv = (self.loggerClass or _loggerClass)(name)
response
root = Root()
my_filter,
password = Column(PasswordType())
res, part, others = [], words[0], words[1:]
transpose = zip(*table)
type(f.__code__)
m = [j for i in n for j in (i, 0)][:-1]
lambda *inputs: table[inputs]
daemon = True
data = (np.random.random((20, 2, 2, 1001)) - 0.5).cumsum(axis=-1)
text = nltk.word_tokenize(input_sentence)
key = RSA.importKey(key_data)
c = 10 ** 9
dir_util.copy_tree(test_dir, bytes(tmpdir))
height, width, depth = im2.shape
print(line)
c = mean(data)
context = ET.iterparse(file_name, events=events)
f1(a)
url = WS_CHANNEL_URL.format(client_id=client_id)
sandboxed = FunctionType(f.__code__, scope)
1
da.isEqualNode(db)
hm.KeyDown = OnKeyboardEvent
all_instances = {}
output += accum.decode(currentCodec)
serial_str = db.retrieve()
f
print(a)
data = urllib.parse.urlencode(parameters)
root = Tk()
x = np.ndarray(x)
s = {1, 2, 4, 5, 6}
geolocator = Nominatim()
a1 = (a + b) / 2
session.add(user)
min_val = closeness(diff[0:K - 1], K)
y, e = integral_numerical(f, 0, x)
total_count = count_permutations(counter)
SOME_NAME = 1
form = PersonForm(obj=person)
foo(parent1)
content += chunk
name, prob, cumprob, rank = line.split()
len(q.levels) - q.labels
FF
tb_last = sys.exc_info()[2]
Return(myobjects)
writefile.write(rec)
hash(tuple(sorted(self.items())))
str(obj)
rst.append(line)
dr, dw, de = select([sys.stdin], [], [], delay)
acells[x, y] = board[x][y]
production.py
t = l,
index2 = randrange(index1 + 1, len(a_list))
server_thread.setDaemon(True)
num1 = 20 if someBoolValue else num1
loop.stop()
result
print(list(datasets.keys()))
args = argparse.Namespace(a=a, b=b, c=c)
sentences = doc2vec.TaggedLineDocument(file_path)
out
singleitem, = mylist
legend = plt.legend()
s = set()
print(p)
True
xlApp.ActiveWorkbook.Close(SaveChanges=0)
cruncher = hashlib.md5()
r = []
timei = time.time()
self.verbose = verbose
num = 1
p0_s + p0[np.where(intersection)[0]]
set_country(text)
raw = derfile
wallpaper_dict = json.loads(data.read())
t.cancel()
foo_np_view = foo_np[50:150:2, 10:290:5, :]
loc = locals()
app.teardown_appcontext_funcs[i] = wrap_teardown_func(func)
iterator = iter(itt)
A = 1
d, m, y
h = sy.exp(-(t - x) ** 2 / 2)
app.preprocess_request()
delay(2000)
SoftDeletionQuerySet(self.model).filter(alive=True)
rescue
found_one = True
posn = dict((n, posi[Gi.node_labels[n]]) for n in G)
x = y
td = datetime.timedelta(seconds=2)
result = q.get_nowait()
data = urlencode(values)
upper, lower = t, tlist[i - 1]
payload = jwt_payload_handler(my_user)
[build]
memprg = self.member_programme
precision
n = scipy.stats.norm(n * p, np.sqrt(n * p * (1 - p)))
sign = 1 if a > 0 else -1
hashlist = list(hash)
clientApp = Bottle()
wrapper
print(area)
tomorrow + year > d + year
it_f = iter(f)
tmp = uniform(0, 1.5)
raise value.with_traceback(traceback)
x2, y2 = pt2
self._hal.libhal_device_get_property_string.restype = ctypes.c_char_p
result[i] = f[result[i - 1]]
print(True)
FW = FW.subs(x - x0, 0)
surf = plt.pcolormesh(xedges, yedges, heatmap)
ocwbKCiuAJLRJgM1bWNV1TPSH0F2Lb
print(stop - start)
count += 2
g = pd.groupby(pd.Series(y), c.labels)
s += x
show_strings = ShowStrings()
fast_reset_dict.reset_content_to_zero()
ctr_left.trunk * 2 + 1,
Week.thisweek()
counts = Counter(zip(chain[:-1], chain[1:]))
URL = getURL(mediaref)
print(minspan(aa))
[work, work, work]
user = models.ForeignKey(User, null=True)
a
a
chunk
statements
f = deco(f)
actions = parser.add_mutually_exclusive_group()
a
mydict = {}
obj = Object(index=id, **fields)
t.join()
vars = 4
sidebarDirective.js
v = float(val)
add_to_jar(file_to_add, jar_file)
df
model = Car
--follow
tagged_sentences = [nltk.pos_tag(sentence) for sentence in tokenized_sentences]
arr = []
d
offset = transforms.ScaledTranslation(0.0, 0.5, fig.dpi_scale_trans)
home = os.curdir
print(x)
counter = itertools.count()
mod2(5)
element
root._p_changed = 1
main()
smtp.stderr = StderrLogger()
list1_copy = list1[:]
False == 0
assert isinstance(sqlContext, HiveContext)
arr = np.random.rand(1000000.0)
close(unit=10)
total = 0
sum = sum << 8 | chunk
clf.estimators_
start
print(dict1 == dict2)
_ = plot_map(som_classif, matrix)
serializer = MyObjectsSerializer(queryset)
x2 = v2[0]
a
l = []
Response(status=status.HTTP_204_NO_CONTENT)
l = L()
text = escape(repr(value))
user = models.User.query.get_or_404(id)
x = 42
l = len(input)
map(int.__sub__, a, b)
switch(newState)
print(train_likes_df.columns)
x = np.linspace(0, 2 * np.pi)
readRequest += chr(startOffset / 256)
print(to_s(dt))
print(json.loads(r.content))
data
-1
k = np.diff(a)
beg = bisect.bisect_right(rangeList, num)
path = request.path
s
l[i] = 0
x = list(string.digits)
bbox = x / 2 - eX / 2, y / 2 - eY / 2, x / 2 + eX / 2, y / 2 + eY / 2
b = B()
sorted_htmls = [html for timestamp, html in zipped]
res
html = res.read()
values
es_formats.SHORT_DATETIME_FORMAT
BEGIN
FFwriter = animation.FFMpegWriter()
s = sched.scheduler(time.time, time.sleep)
vdisplay = Xvfb()
dates = df.date_of_last_hoorah_given
self.plotdata = chaco.ArrayPlotData(x=x, y=y, ymin=ymin, ymax=ymax)
Add(5)
bib_sorted = sorted(list(bib_data.entries.items()), cmp=sort_by_year)
262664
y, m, d, hh, mm, ss, weekday, jday, dst = time.gmtime(t)
result[old_arena] += old_timestamp - timestamp
OneOrMore(leaf)
cursor = db_connection.cursor()
mapping[u] = parent(mapping[u], mapping)
main_v2(csv_path)
federated_id = ndb.StringProperty()
indice, = y.nonzero()
i
n = self._namescallback[channel][1]
df
mask = group.values[1:, (4)] != group.values[:-1, (5)]
fig, ax = plt.subplots()
CONFIG += no_keywords
opendir.argtypes = [c_char_p]
im = np.empty([2, 2], dtype=np.object)
cal = pdt.Calendar()
factor2 = sum
pos = bisect_left(myList, myNumber)
c = int(hx[4:], 16) - int(key[4:], 16)
a[4, 2] = 1
media_ids = [api.media_upload(i).media_id_string for i in images]
len(locale.locale_alias)
_lock_services = threading.Lock()
text
client, address = s.accept()
last_guess = x / 2.0
modules = (path.splitext(m)[0] for m in module_files)
H5Tset_size(tid, dt.itemsize)
10 | D1 | ARG
func1 = foo.func1
list_my_repos()
done = Deferred()
proc.send_signal(signal.SIGINT)
calculate_stuff.delay(user_id)
self.__dict__ = self
parser = optparse.OptionParser()
a = arg1 + arg2
c1 = +1.189404e-10
BASE_DICT = dict((c, i) for i, c in enumerate(BASE_LIST))
app = QtGui.QApplication([])
execute(render, [])
h, s, v = cv2.split(hsv)
tmp
params = list(compiler.params.items())
letters = list(ascii_letters)
solutions = list(solution_set[1])
subfile.stuff()
print(self.s(10))
args = parse.parse_args()
photos.entry
root = objectify.fromstring(response)
updated.update(kwargs)
file_IsValid = True
c
self.has_params = False
s = sum(picked)
Selection = MSWord.Selection
date.set_student(task, student.count)
sx = str(x)
dataStack[0] = (np.random.random(25) * 100).reshape(dist.shape)
lower_color = np.array([color - sensitivity, 100, 100])
deleteBDF
l = ord(f.read(1))
out = np.take(strings, bool_arr)
selected_items = d[valid_indices]
idx
email.lower().strip()
burger_king.describe_restaurant()
print(output)
aString = file.read()
doc[key]
numbersPicked += 1
data1_list = []
mylist[j + 5] = i
u, s, vt = linalg.svd(documentTermMatrix, full_matrices=False)
c = a
end = drawdown.argmin()
mask = np.array([True] * 2000)
a
q = Queue()
not_self = self.clone()
inspect.getargspec(add)
ax.xlim(xmax=2)
p.connections()
area = 452.5
0
newl = []
palette.reverse()
head = next(it)
d = pq(html)
weights_stretched[0][0] = 4
print(distance)
formats.py
_wrapper
print(sd.query_devices())
ffty = np.fft.fftshift(fftyShift)
shutil.rmtree(tmpdir)
__round__(ndigits)
l = sorted(l)
h2 = SigmoidLayer(2)
b[100] = False
self_reference(x, 1)
Sr1 + Sr2
keys.append(evt)
fullname = myapp.settings.PRIVATE_AREA + filename
copy_globals = exec_globals.copy()
x[i].lowBound = LB_ind[i]
print(wrappedSocket.recv(1280))
listvals.append((xc, yc))
saved = list(times[0])
val = -1
N = 10000
atexit.register(readline.write_history_file, histfile)
self.app
clock = pygame.time.Clock()
0
hashed_password = bcrypt.hashpw(password, salt)
x + 1
numpy.fix(a)
loc = np.where(diff == np.min(diff))
pool.pool.put(conn)
done = 0
item
ipdb > request.GET
b = 1, 1, 1, 1
wrapper
self.figure = plot_class(self.plotdata)
r = requests.post(url, files=files)
authorization = Authorization()
hello
print(lst)
defaults.update(kwargs)
__metaclass__ = SubclassTracker
new_inlist.append(item.replace(prefix, prefix + separator))
inUnitsValue.selection_clear()
s
close_source = True
firstline = False
print(a_sum)
input
h, w = vis.shape
a = i + a
data = Data([x, y], z)
newloc.x = x
upper += 1
assert data[0].lc.line == 2
success = {t[0] for t in parsed}
df.columns = df.columns.droplevel(0)
main()
template_string, source = django_loader.find_template_source(e.name)
argsort = a.argsort()
original_text = tag.text
print(validate(id_value1))
False
product = 1
main_1(state)
mpz_mod(result, result, modulus)
X_pos.A
wide[c] = col.astype(int.time.dtype)
data = ChartData.check_valve_data()
itercars = iter(cars)
func2.__defaults__
req = request.Request(url)
font = style.fontName, style.fontSize, style.leading
df = sqlc.read.options(catalog=catalog).format(data_source_format)
fh.setFormatter(formatter)
d = defer.Deferred()
all_.append(name)
response
print(test_df)
value = data[i].value
7
size_limit = int(sys.argv[2])
_names = sys.builtin_module_names
n = y.strides[0]
parsed
a
self.draw()
t = StringIO(s)
overall[num, index, 1] = line[:, (1)]
bins = [-np.inf, W1, W2, np.inf]
print(df)
Formatter.get_value(key, args, kwds)
self.mainWindow = MainWindow()
loc = pyparsing.Empty().setParseAction(lambda s, locn, toks: locn)
c[0] = a
obj = f[st]
print(arr)
print(e)
datafilter = Q()
self._stop = value
LR = LinearRegression()
elapsed = time.time() - start
inidx = np.all(np.logical_and(ll <= pts, pts <= ur), axis=1)
svd.set_data(data)
print(c)
join.fill_value = np.NaN
__metaclass__ = BaseInspector
result[pd.isnull(df1) == pd.isnull(df2)] = True
img.anchor_x = img.width / 2
inq.put(i)
tree = lxml.html.fromstring(html)
decorator
frequencies = numpy.fft.fftfreq(len(spectrum))
next(it2)
week[weekday]
setUp()
ob = scn.objects.active
l2
9999999
x = [0, 1]
saved_state = mpl.rcParams.copy()
python
final
stack_trace = traceback.format_exc()
what_bson_type(1.2)
self.myConfig = myConfig
b
print(args)
distances = pairwise.pairwise_distances(features)
rand_int = 0
plt.subplot(212)
sizeof(pycmd),
print()
unit_totals = OrderedDict()
insert_stmt = insert(Test).values(a=1, b=1)
out_path
9
y = 1
self.b = b
zf.close()
raise
cv2 = CountVectorizer(tokenizer=mytokenizer, min_df=0.005)
pos = file_buffer.find(char)
pca = PCA(n_components=5)
five = MyInt(5)
True
my_global_base = dict()
t = os.read(fd, 4096)
image //= (display_max - display_min + 1) / 256.0
date = mdates.date2num(event_date)
zap.co.it
yourData = DataFrame(data)
axes = lm.axes
y[np.asarray(x) < 0] = -1
dlist = [b.decode(encoding) for b in bl1]
proxy = True
arrayIN.resize(len_arrayIN + len_NewRows, refcheck=False)
14
primes = []
cvSmooth(gray, gray, CV_GAUSSIAN, 7, 9)
output = []
BX_IN = Bx.copy()
value = float(value)
self[key]
res
x = np.arange(length)
dest_image.writeMetadata()
self.listeningPort.stopListening()
print(os.attr)
formula = lambda n, x: n / pi * (x * 0.1 + 1) ** 2 - pi * (x * 0.1) ** 2
model = Page
mylocale.AddCatalog(domain)
self.line_edit.editingFinished.connect(self.do_something)
copy
module = sys.modules.setdefault(name, imp.new_module(name))
cur = conn.cursor()
copied = 0
N = int(sys.argv[1]) if len(sys.argv) > 1 else 500
result = {}
print(b)
x, rnorm = nnls(A, b)
mock_funct.assert_called_once_with(mock.ANY)
unique_sequence = uniqueid()
l[4] = 22
exitcode = 1
sequence = map(replaceFunc, sequence)
len(on_locs)
filtered = []
form.email.data = my_user.email
page_two_task.delay(arg1, arg2)
yEstArray = []
callerframerecord = inspect.stack()[1]
object2varchar = lambda obj: str(base64.encode(cPickle.dumps(obj)))
1
word = []
_counter = 0
lst1 = list(range(100))
a_slider = widgets.IntSliderWidget(min=-5, max=5, step=1, value=0)
font = run.font
self._myScope = {}
endif
obj = SomeClass(myConfig)
Choice.objects.get(id=id)
i += step
pid = active_window.get_pid()
print(val)
y_coords = y[..., (np.newaxis)] * size + base
a = ctx.eval(js)
sign_options = SMBConnection.SIGN_WHEN_SUPPORTED,
word_freq[word] = word_freq.get(word, 0) + 1
f.write(syn.name[:-5])
mul = tf.mul(add, update)
s
i = 0
func
myarray = {}
x
levels.append(State.Before)
score_sum = 0
l2_x2 = np.arange(len(x2))
new_shapes = np.array(new_shapes)
url = models.URLField(max_length=255, blank=True)
a = MyNumber(5)
x
print(s.get_matching_blocks())
options, args = parser.parse_args()
your_app
output = str()
clipboard.CloseClipboard()
cycle_iter = context.render_context[self]
c.save()
it = iter(L)
log4j.appender.console.layout = org.apache.log4j.PatternLayout
future_1.set_result(9)
self.scores_matrix[i - 1, j] + 1,
print(results)
print(filelist)
True, False
X_std = np.ones(X.shape[0::2])
snBox.pack_start(canvas, True, True)
print(df)
g = ephem.Ganymede(Observer)
print(list(ddb.tables.all()))
Coefficient
t_dsm.timeit(100000)
runSikuliScript(p)
circle_dia2imp_2d
line_eqn = lambda x: (y2 - y1) / (x2 - x1) * (x - x1) + y1
jName, kName = t
minimum = min(i for j in Q for i in j)
row_idxs = N[4]
a
rng.freq
print(self)
y = [(i ** 2) for i in x]
src = textwrap.dedent(inspect.getsource(bs4.element.Tag.select))
b = 1
[(x, y) for x, y in g2 if x >= 0 and x < N and y >= 0 and y < N]
common_words = common_words[:25]
print(all_targets)
close_source = False
workbook = xlwt.Workbook()
Student.log = log
X - b
f = open(fname)
running = 0
exec(a)
a = sum(range(49999951, 50000000))
wsgiref.handlers.CGIHandler().run(application)
pick = itemgetter(0, 2)
x = 10
j = i + 1
dis.dis(foo)
epoch = datetime(1970, 1, 1)
c = img.pixel(x, y)
s2.index = list(range(1, len(s2) * 2, 2))
y = np.sin(2 * np.pi * (x - 0.01 * i))
f = Fraction(a, b)
a = list()
pwd
isLeaf = True
TEXT_STREAM = []
configobj.ConfigObj = MockConfigObj
union_set - intersection_set
session = requests.Session()
A, B
collection = db.collection
x = y = np.arange(5)
line = fObj.readline()
x = y = 9
pool = multiprocessing.Pool(15)
(PRH(iterations, x, y) - 0.5) * 2 / (iterations + 1)
print()
b.x, b.y = 1, 2
result = round(x / divider)
f2 = deepcopy(f1)
thequickbrownfoxjumped
self.dict[line] = self.count
out.append((tup[1] + 1, y))
sys.byteorder
parser = lxml.etree.HTMLParser()
coeff_dict = all_on_left.as_coefficients_dict()
url = urls.get()
result[original_index] = rank * 100.0 / (len(numbers) - 1)
time.ctime(sec)
numpy_zero_crossings2(big) == numpy_zero_crossings(big)
conv = converters.conversions.copy()
print(s.name, s.group.major, s.group.dept.name)
setting.INSTALLED_APPS = 10
d = matrix(g.degree())
monthly_sales_qs = SalesRecord.objects.filter(param=foo)
coefs = poly.polyfit(x, y, 4)
timesteps = generate_timesteps(10, 0.8, [0.001, 0.5])
aligned_sent = ibm.aligned(bitexts[0])
True
print(x, y, w, h)
i = 0
reader(date, book, total)
conn = urllib.request.urlopen(url, timeout=timeout)
base_in1 = in1[0]
pipdeptree - fl
get_query_string({self.parameter_name: lookup}, []),
print(sample(a, sz))
calc_column = end_time + case([(end_time < start_time, 86400000)], else_=0)
print(zero_crossings2)
list(hf2.values())
FOO = 1
surf = cv2.SURF()
smaller, bigger = sorted([a, b], key=len)
j = set(range(5000, 15000))
val1 = float(input())
a
some_sort_of_count(list1, list2)
0
ps = performance.now()
temp = 60 * (decdegrees - degrees)
new_words = [word for p, word in list(reversed(s[::2])) + s[1::2]]
b_start_i = b * b_chunk_size
et
date + seconds
buf = buf[:-1]
time.sleep(0.5)
match_cache[m] = compiled_regex.match(m)
hdr_cells = table.rows[0].cells
ward.labels_
icoeffs = [2, 4, 6]
key2value[item[0]] = [item[1]]
id(lst)
m = svm_train(prob, param)
reportlab_io_img = ImageReader(io_img)
data1 = data[0]
print(date1 - date2)
traceback.print_stack(file=log)
normal_mean = (mean - m_min) / (m_max - m_min)
rdlength, rdata = data[:2], data[2:]
False
print()
display(HTML(output))
k = Key(bucket)
res = x / norm
screen = Wnck.Screen.get_default()
lindex = int(filelist.index(line))
exc_line = traceback.format_exception_only(*exc_info[:2])
objects = models.GeoManager()
id = j.client__id
self.count = 1
s1 = set(list1)
sad = 2
nextdate = cron.get_next(datetime.datetime)
a[a > 255] = 255
ansible.constants.HOST_KEY_CHECKING = False
u = a.getObject()
socket.socket = socks.socksocket
self.corpus = corpus
print(dir(visit))
print(distance(valueList))
method_adder
df
form = SomeForm
play_music(intent, session)
tmp_grad = np.gradient(grad_k)
threading.stack_size(200000000)
document.msExitFullscreen()
print(d)
loop.run_until_complete(asyncio.wait([get_attachment(d, pool) for d in data]))
obj.word_count = sum(c.word_count for c in obj.comments)
wand.sequence.append(three)
rect_area = axes[0] * axes[1]
res2 = []
positions[a[i]] = i
childListStack.add(firstStack)
mkdir_p(output_dir)
type(series1)
data_dict = ValuesQuerySetToDict(data)
the_date,
x = p.run()
n2 = choice(list(range(1, 100)))
r[r < 0] += A.shape[1]
form_class = RegistrationFormUniqueEmail
noise = np.random.normal(0, std, len(x))
none_new(PyTypeObject * type, PyObject * args, PyObject * kwargs)
A, mu, sigma = p
t1 = [0, 0.5, 1.0, 1.5, 2.0]
instance.subject_init = instance.subject_initials()
ywin = y[:winsize * numwin].reshape(-1, winsize)
t = 42
left = units[:half]
pwd()
price_series = pd.Series(prices)
selected_option = select.first_selected_option
res = r[k1, k2]
fs.append(n)
attrs = self._get_attributes()
NpyIter_Deallocate(iter)
column_dict = {}
BT = BallTree(D, leaf_size=5, p=2)
res = []
username, account, password = secrets.authenticators(HOST)
work_with_cube(cube + offset)
row[5], row
process(entered)
n = 2
res = x / y
cvtColor(img, bin, COLOR_BGR2GRAY)
all_data += data
completion.set_model(liststore)
type.__init__(cls, classname, bases, dict_)
y_vals, junk = np.mgrid[w:0:-1, h:0:-1]
moduleDirectory = getModule(__name__).filePath.parent()
w1.write(reversed)
_invoker = Invoker()
eq = sqrt(x ** 2 + y ** 2)
ln = lambda f: getattr(MyTestCase, f).__func__.__code__.co_firstlineno
self.dict[line]
p
baz()
e = test_module.Example()
y = abs(x)
child = layout.takeAt(0)
PyObject * result
normalized = list(normfilter(vectors, 0.4))
print(counts)
show()
g = GenericFileForm()
edges[idx]
facecolor = cmap(numero / float(maximo), 1),
uninitialized_vars = []
first_day_of_the_month = datetime.now().replace(day=1)
exit = type(mgr).__exit__
str_record[x] = x
print(a)
recall_accumulator = Manager().list()
replace
sum is np.sum
2
x
pfoo = POINTER(Foo)()
reactor.listenTCP(9000, self.factory)
mod = sys.modules[fn.__module__]
pdf = defaultdict(int)
2, 200, 2000
status = SYSTEM_POWER_STATUS()
h = SHA.new(message)
__builtins__.hasattr = hasattr
update_trace()
args = indices(shape, dtype=dtype)
ar[2] = cos(inp_ar[0]) * cos(inp_ar[1])
lcmap[0] = 0.5, 0.5, 0.5, 1.0
tmp = random()
scale = xbar / a
opener = urllib.request.FancyURLopener()
[4.0, 6.0, 0.5, 2.0],
then = (now + relativedelta(months=1)).replace(day=now.day)
1241511
HALF_N = sys.maxsize + 1
st = os.statvfs(dirname)
assert _PyUnicode_CHECK(str)
cdf.append(cdf[-1] + P[i])
print([square_with_call_count(i) for i in range(10)])
cls.ID
app = QApplication(sys.argv)
norm_coeff = 255 / disp.max()
self.__name__ = name
u = u[:, :numDimensions]
step = quote(1)
self.elastic_con = Elasticsearch([host], verify_certs=True)
self.pred(other)
num = 0
pkg.a
user = User.query.get_or_404(id)
arg = 1, 2
gas = models.IntegerField()
self[elem] = self_get(elem, 0) + 1
listWidget = self.ListDialog.ContentList
print(hash)
im_np = numpy.random.rand(h, w)
country, count, sales = l.split()
m = pow(10, n)
stringer.NewEscFieldText[name]
update = _wrap(dict.update)
dim_array[given_axis] = -1
manager = Manager(application)
-pandas
frame2 = BDataFrame()
stack = []
maxlen = lens.max()
f.__closure__[2].cell_contents
tmp_sources.write(line)
x + 2
print(out)
db(db.dogs.id == id).update(**{column: value})
raise
margin = offset = 40
mask = (1 << end - start + 1) - 1
x = np.linspace(0, 1, 20)
handler = MyHandler()
lengthy_thingy.__len__ = lambda self: 20
intNullBlank = models.IntegerField(null=True, blank=True)
picks = [v for v, d in zip(vls, dst) for _ in range(d)]
type_code,
start = 0
groups = groupby(L, partial(eq, 0))
end = fh.tell()
SimpleHTTPServer.SimpleHTTPRequestHandler.end_headers(self)
self.input_stream = input_stream
y = np.sin(th)
lengths = [len(sub) for sub in lst]
self
bval = bval.values[0]
1 in r
b = i.read(block_size)
add_attributes(global_data)
self.extract_player_urls(response)
parts = []
client = context.socket(zmq.PUSH)
file_IsValid = False
filenames = [filenames]
encoder_class = CustomJSONEncoder
window.set_input_focus(X.RevertToParent, X.CurrentTime)
f, a = plt.subplots(1)
2
console.log(result)
h.digest()
res = session.query(ResultsDBHistory).all()
client = gconf.client_get_default()
p_rtns = (rtns + 1).cumprod()
k1, k2 = yield_g()
a = []
result = DEFAULT_VALUE
A
self.g = {}
s = min(a.strides)
t = Test()
person_object = people[person.name]
status_list = api.user_timeline(user_handler)
highestIndex = 0
number ^= number << 16
rule = self.rules[rule_name]
lst1 = [1] * 4
j -= 1
A[0][1] = 99
Trace(proc)
[[1]]
profile = cProfile.Profile()
self.observers = weakref.WeakKeyDictionary()
mylist[j + 4] = 1
ts = d.timestamp()
config.scan()
Capture = cv.CaptureFromCAM(0)
print(args)
pool = Pool(nprocs)
r = redis.Redis()
job_id = retrieve_job.id
i += 1
manage.py
excludes.add(item.firstname)
postvars = parse_qs(self.rfile.read(length), keep_blank_values=1)
my_path
p = 1.0 * w.cumsum() / w.sum() * 100
727
a = []
users_frame = sys._getframe().f_back
process(large_string[-200:])
JOIN
sales = sales.reindex(list(range(min(sales.index), 1 + max(sales.index)))).fillna(0)
print(exc.message)
x = np.random.multivariate_normal([0, 1.0], [[1.0, 0.5], [0.5, 1]], size=20)
finder = ModuleFinder()
t = tkinter.Tk()
py > ast._fields
l1 = list(range(10))
processed_foo = process_foo(foo)
x
imagedata = ImageData(parent=image_key(image_name))
print(wkspFldr)
cython.ulong
origin = line[0]
mixins.ListModelMixin,
info = inspect.getframeinfo(frame)
d
groups = [[my_list[0]]]
session = Session()
x, y, z = np.mgrid[0:m, 0:n, 0:r]
d = json_date_as_datetime(test)
prototype = WINFUNCTYPE(c_int, HWND, LPCSTR, LPCSTR, UINT)
major_index = np.compress(mask, major_index)
c
count -= 1
subparser1._actions[1].dest
print(result)
nums = [1, 2, 0]
digits = 1
True
post
unpickler = pickle.Unpickler(fh)
n = str(random.randint(10 ** 9, 10 ** 10 - 1))
G.layout()
remove_noise(gray, 10)
matches[data[count]] = word
(group([mapper.s(nr) for nr in nrs]) | reducer.s())()
fig = plt.figure()
img
x + y
n = 10
f = gzip.GzipFile(fileobj=buf)
print(numbers)
x = np.linspace(0.0, 1.0, num=100)
print(df)
max_date = max(murders.index)
a_tokens = set(a.split())
print(n)
dostuff(*args)
pad_size = math.ceil(float(b.size) / R) * R - b.size
labels = {}
print(clean(decrypted))
fd = open(filename)
print(t)
f = lambda x: x % 2 and x or x * 2
cimage = io.BytesIO()
coll2 = college_list[j]
dft_A = cvCreateMat(dft_M, dft_N, CV_64FC2)
json1_str = json1_file.read()
l = sum(1 for i in it)
customer_admin_link.allow_tags = True
sum2 = np.add.outer(A, B)
widgetToRemove = layout.itemAt(i).widget()
deleteoptions[option]
VideoManager().convert(gif_url)
readFile = os.fdopen(readEnd)
instance = model(**params)
do_stuff_writing_to(wfile)
DF_dism = 1 - np.abs(DF_diabetes.corr())
i = 2
result = np.bincount(dists.flat, weights=a.flat)
print(chunk)
WIDTH = 200
darray = dok_matrix((xlen, ylen))
first_job_result = q.fetch_job(first_job_id).result
bin_widths = np.diff(bin_edges)
res = jsonify(res=serialized)
count = 0
header.ParseFromString(data[pos:pos + next_pos])
tik = time.time()
valid_hours = np.arange(0, 24, 6)
r += n - (sl + 1)
i = funparams.index(param)
False
copy = type(original)()
l
a
degrees, minutes = divmod(minutes, 60)
theta = np.arctan2(y, x)
string
print(matches)
cls
array = list(col.find())
rv
Min = MinType()
colorof[k]
1 - test9.txt
CONCURRENCY = 200
print(s)
print(a.contents)
B = int(round(var_b * 255))
first_bigger_than_threshold1[indices_bigger_than_threshold[0]] = True
posix2local(timestamp)
result = func(*args, **kwargs)
path_buf = wintypes.create_unicode_buffer(255)
raise exc
result += res
count = 0
res_ols = sm.OLS(y, X).fit()
Bar.java
self._foo
text
results = np.zeros((l, l))
m2D
BIT6 = 2 ** 6
positions = sorted(list(range(len(a))), key=lambda i: a[i])
True
naughty = []
keys
print(compute_corr_lag_1(sample_signal(5000, 0.5)))
k = pykeyboard.PyKeyboard()
diff = difflib.HtmlDiff().make_file(fromlines, tolines, fromfile, tofile)
num_albums = df.Num_Albums.values
to_thread.start()
dataStack = np.zeros((2, 5, 5))
-1
ctx.update(settings.GLOBAL_SETTINGS)
transformed = model.transform(df)
guess
vals = np.random.rand(1000)
self.poll.question
line = input_stream.readline()
reverse_geocode.search(coordinates)
sess = tf.Session()
x, y = map(float, self.DataBase[key])
pdb.set_trace()
out.handle[i] = out.handle[i - 1] + arr.handle[i]
r = d * np.pi / 180.0
q.put_nowait(cmd)
print(d)
deployment / operations
x, y = index[0], index[1]
[(sum(e) / len(e)) for e in zip(*data)]
thing1 = thing.get()
total
team_entity = models.ForeignKey(Entity)
Test
print(set_)
nonzero_cols = np.any(original_rows != 0, axis=0)
ids = [str(i) for i in id_list]
b = islice(count(), 0, 5)
False
arg_vals.update(kwargs)
outputFile.write(chunk)
view = f.getbuffer()
current_date
f = a + b
magic_func(a)
PyObject * gi_qualname
print(line)
self._set.remove(item)
cool()
new_t2.delete(x)
container[i, 0] = x
start, stop = 1, 100
False
data = cursor.fetchall(sql, args)
mask = a != 0
val = val + 1
this_week = week_number(start_week_on)
winsound.Beep(800, 100)
writer.write(example.SerializeToString())
[]
form = AboutWindow()
reversed_row = self.scores_matrix[i][::-1]
index_file = local_repo.index_path()
1, 200, 1000
w[0] if len(w) else n
x = range(len(y_vals))
now
ex.append(ex[-1] * -(p - i) / (i + 1))
priv_key_string = open(priv_key_file).read()
f1()
XX, YY, count = 0, 0, 0
c = i >> 2 & 7
driver.maximize_window()
j = i * i
cluster_idxs = defaultdict(list)
urlparts = urlparse(url)
sr.data.set(station, cb)
v.append(i)
steps = c_int(2)
cl = closeness(diff[ind:ind + K - 1], K)
ymean = ywin.mean(axis=1)
rowValues = mainData_sheet.row_values(row, start_colx=0, end_colx=8)
self.file_1 = file_1
print(some_text)
a = [1, 2]
fp.update_preferences()
s = f.read(1)
token_idxs_padded = tf.pad(token_idxs, [[0, 0], [0, maxlen]])
self.thread.started.connect(worker.process)
b = int(hx[2:4], 16) - int(key[2:4], 16)
print((st, timeit.timeit(stmt=stmts[st], setup=se)))
freq += 1
print(m)
encoded_str
newLyr = arcpy.MakeFeatureLayer_managment(in_features, out_layer)[0]
benchmark = timeit.Timer(presplitsearch, presplit_prepare)
individuals = list(range(500))
res[n] = k
i += 1
z = np.random.random(numpoly) * 500
connect(resetButton, signal(clicked()), this, SLOT(myResetFunc()))
2 - test11.txt
fig, ax = plt.subplots(1)
nrow = traindf.count()
not health == max_health or not armor > enemy.attack or attack > enemy.defense
print(members)
self.x += self.vx
l = [dt, dt]
remove_blanks(xml)
serializer_class = AuthorSerializer
years, remainder = divmod(diff1.days, avgyear)
d = datetime.date(2002, 12, 4)
f = frozenset({1})
print ()
alist = []
sizer.Add(self.flash, proportion=1, flag=wx.EXPAND)
BarObject_Type.tp_dictoffset = offsetof(BarObject, dict)
MacAbsTime = int((dt - tmp).total_seconds())
vals = np.in1d(df.TRANSACTION_ID, df.BACK_REFERENCE_TRAN_ID_NUMBER).astype(int)
cnt.setdefault(item, 0)
_a = Functions.motion.move().left
num_mins += 1
id(num)
table_sql = CreateTable(Foo.table).compile(db_engine)
args[key] = value
int(line.split()[1]) >> 10
raise
orig_std = sys.stdout, sys.stderr
2, 2, 1
count.put(s, c + 1)
z = unbroadcast(x)
X = sm.add_constant(X)
probs, targets = map(theano.shared, (probs_, targets_))
decorated_get
handle.mainFunction(parameter)
a
obj = s.query(Foo).filter_by(id=key).scalar()
r = np.arange(inner_offset, 1.0 + inner_offset, 1.0 / 720.0)
others = len(s) - numbers - words - spaces
print(str(request))
inner_func()
l -= 1
local_vars[name] = value
s = s[::2]
_pairs[c] = [a, b]
allTrue = all(map(predicate, iterable))
fn(param1)
f.closed
s = sphere(X, Y, Z)
frame.Bind(EVT_FS_REFRESH, self.refresh)
edge_vertical = ndimage.sobel(greyscale, 1)
five_minutes_ago = now - datetime.timedelta(minutes=5)
key = tuple(sorted(Counter(tup).items()))
y1 = lsim2(tf, u, t, X0=0)
self.parts = list(urlparse(base))
cipher = []
yLower = y.lower()
possible_positives = K.sum(K.clip(y_true, 0, 1))
deletemod2
rightFork = (philosopherId + 1) % FORKS_COUNT
x1 = np.linspace(0, 1, 50)
converted.paste(original, (0, 0))
doOneMoreThing()
pushButton.setText(text)
req = request.Request(url)
SWIG_fail
expanded_a = tf.expand_dims(A, 1)
self.res = res
print(d.groupby(grps).apply(h))
help = choice_dict[key]
dataset = map(algorithm, dataset)
run_ends = np.where(np.diff(nums))[0] + 1
links = []
print(cv2.__file__)
high_word = int(num2, 16)
inserts = dict(zip(insert_locations, seq))
FLAG12 = 4
x1, y1 = numpy.meshgrid(copy=False, *grids)
notepad.callback(buffer_active, [NOTIFICATION.BUFFERACTIVATED])
seq, shift = tee(seq)
random_ind = bisect(cdf, random())
m = moments(data, 2)
self.obj
expected = expected.splitlines(1)
print(row)
DG = nx.DiGraph()
enc.n_values_
cf = inspect.currentframe()
print(e.message)
2
cmd, arg, line = self.parseline(line)
button.messageRequired.connect(myFunction)
total - choose_x_pseudoinverse(inv_odds * tCw, winners)
loglogmod_rsquared = loglogmod.score(x, y)
x = r * np.cos(theta) + center[0]
_PUBLIC_KEY = RSA.importKey(base64.standard_b64decode(_PUBLIC_KEY_BASE64))
cam.set(cv2.CAP_FFMPEG, True)
lower = 0
user = User.get_or_insert(msg.sender)
observer.lon = str(lon)
p1 = 0
start = 0
args = [iter(iterable)] * n
Yf = Xf * 0.0
howCentric
False
received = channel.recv(buf_size)
future_to_idday[executor.submit(do_stuff, value)] = key
self.simulThread.started.connect(self.simulRunner.longRunning)
handle_cleanup()
csrf_protect = CsrfProtect(app)
0
print(r)
r = range(2000, 2005)
fmt = lambda x: x
y
test = []
dist_out
resultList = []
list(category.keys())
batch.add_batch(table, keys)
heappush(pq, item)
res = obj.lookup()
print(id(uvw))
df
display.clear_output(wait=True)
print(Fore.RED + traceback.format_exc() + Fore.RESET)
cursor = db.cursor()
print(word)
data_to_send = f.read()
config = ZendConfigParser()
r = Request(url=link.url, callback=self._response_downloaded)
all_dfs = []
box.lat_max = rad2deg(lat_max)
pprint(foo_bad(), width=50)
cust_addresses = CustomerAddressSerializer(many=True)
print(b)
image = c.get_image(ec2_ami)
legend()
a1 = lambdified_expr(10, 10)
results = []
sha_1.update(eachpwd)
push(e.entities)
b[1:, (0)] = y
width = int(w)
vals = [song[x] for x in cols]
8.477055072784424
resolved = recipient.Resolve()
print(response.elapsed)
areas = dict()
my_token = generate_token()
rho - rho2 ^ 2
vals = ax.get_yticks()
visitordata = rec[1]
relerr = where(p0 == 0, p, (p - p0) / p0)
pprint(v.vocabulary_)
result = True
dists = []
Base.metadata.bind = op.get_bind()
edges.pop(i)
results[obj] = [size]
clusters
result = OrderedDict()
assert len(inShape) == len(finalShape)
response.content_type = mime_type
R = reciprocalApprox(B)
line = reader.readLine()
lo = 2 ** 0.5 * np.exp(-2j * np.pi * f_demod * t)
start = time()
id = np.zeros(Acol.size + 2, dtype=int)
cert = c.load_certificate(crypto.FILETYPE_PEM, certbuffer)
d = truncated_power_law(a=a, m=m)
print(id, name, semester, grade)
arg = int(arg)
6 - 1.404
list_of_worksheets = full_doc.worksheets()
ax1 = fig.add_subplot(111)
new_infected_users = dict()
clean(path)
bytes = int(gdb.parse_and_eval(argv[1]))
file1.write(content)
d.addCallback(hello)
sgd = SGD(lr=0.1, decay=1e-06, momentum=0.9, nesterov=True)
print(dev)
partial_integrals.append(log_log_integrate(a, k, x_lower, x_upper))
col = z.shape[1] * (x_world - x.min()) / x.ptp()
peer.setTimeout(timeout=0.1)
_pwd_context.encrypt(signed)
pem_key = RSA.importKey(pem)
process.stdin.write(data)
top = height / 4
plt.plot(x, np.sin(x + i * 0.5) * (7 - i) * flip)
records = []
pdata = cPickle.dumps(data, cPickle.HIGHEST_PROTOCOL)
hlib = lib._handle
my_list = [1] * k + [0] * (n - k)
taxIdZoning[record.tid].add(record.zone)
parse_url(url1)
gluPerspective(fieldOfView, aspectRatio, 0.1, 50.0)
MyPanel(frame, -1)
False
tok2 = toks[i + 1]
view = view_as_blocks(im_out, (h, w, c))
second_largest = i
node
b
df2
draw_menu(options, 2)
f = excutor.submit(collect_and_train, df)
l = lognorm(s=2, loc=0)
df
sklearn_pca = PCA(n_components=2)
data += bytes([length]) * length
validlist
x = 1
result
soup = BS(html)
True
x
map = {}
amplitude = yReal.max()
num = float(l[1])
max(enumerate(unistr, 1))[0]
res = sess.run([mul, mul])
[erlang]
a = np.random.random(40)
dataGrid[y][x]
W2 = 6
result = result[1:] + (elem,)
p2 = func(p1, *args)
CLIENT_CONNECTED = 1
share = conn.recv_bytes()
shape = 20, 50
group = group.reindex_axis(mi, axis=1)
a = -a
child = game_state.get_next_state(move, True)
coll = con.db_name.collection_name
ItemNumber = Dup[Item]
a.tick()
ml = max(len(s) for s in stringlist)
parent
this_list = this_list[:maxLength]
s.add(foo1)
tup += 4, 5
i & ~n_to_m(n, m) | pat << m
id | name | price
paths = {}
sum = 0
is_efficient[i] = np.all(np.any(costs >= c, axis=1))
fileobj = open(filename)
THUMB_SIZES = [(512, 512)]
funcs = []
foo.sh
filts = []
net.addLink(h2, s2)
rows = row_stop - row_start + 1
mysum = 0
primeind = 0
cross_validated = self.is_cross_valid(form, formsets)
sample1 = []
list(multiprocessing.pool.ThreadPool(N).imap(_single_compile, objects))
newstring += char
b = stack.enter_context(Dummy())
MYCONST1 = 1
f
date = dataframe.index
a = []
logger
match.endpos
d2[0] = 0
field = RadioField(question, validators=[Required()], choices=CHOICES)
getcontext().prec = 2000
inlines = [UserProfileInline]
formatter = self._get_formatter()
4
5
circle_imp_point_dist_signed_2d
b.x = a
print(y.__next__())
heapq.heapify(self.heap)
cell = ws2.cell(row=ws2.max_row, column=idx + 1)
image = tf.expand_dims(image, 0)
logger.info(args)
~1
i = 0
build(sep)
ffit = poly.Polynomial(coefs)
b = 1.00000001
counter = Counter(l)
s = []
elt = tree[0]
st
hdr_size = struct.calcsize(hdr_format)
1.06210708618e-05
m1.x
print(sieveOfAtkin(100))
tmp = np.empty([ROWS, COLS - PATLEN])
print(t)
True.__cmp__(1)
test_case = ut.TestCase()
_1
t.new_resources([])
l = list(range(2, 20))
old_isolation_level = self.conn.isolation_level
skip = q + int(2 * r >= surplus)
s
f = plt.figure(1)
print(nb.classes)
current = prepending + [s[i]]
b[data_length / 2:data_length / 2 + data_length] = a
seconds = 60 * (temp - minutes)
memcache.flush_all()
p = Pool()
N = 25
x0 = np.atleast_2d(xs[..., 1:])
seen = set()
7
pdtnow2 = pdt.localize(datetime(2014, 1, 1))
[path]
type.mro(type(b))
True, 60
np.bincount(r2.labels)
print(dist)
pos + 1
print(ch)
df
self.route_without_hid(route_name, *elements, **kw)
c.IPCompleter.limit_to__all__ = True
print(a)
1 | O | HOH
digit += 1
original = django.db.backends.utils.CursorWrapper.execute
s = requests.get(url).text
theta2 = theta2 - step * dEdtheta2 / n
res
console.log(Math.ceil(4500 / 1000))
scalar1 = 1
fourth_jan = datetime.date(iso_year, 1, 4)
summary_writer.add_summary(summary_str, i)
sortony([p1, p2])
res /= 2.0 * m
IP in p
s = mytable.select()
top = 804
self.__name__ = name
find_head_of_np(top_level_nps[-1])
vY = data[:, (0)]
subprocess.call(call)
expr = s.cos(x) + s.sin(y)
cvBgrImage = cv.fromarray(bgrImage)
trees[alley[i]] = i
findNonZero(bin, pts)
x = np.sin(np.arange(length)) * 10 + np.random.randn(length)
sparse = removeSparseTerms(dtm, 0.995)
self.name = rec.name
curses.wrapper(pbar)
scripts.push(div.innerHTML)
buf_from_mem.restype = ctypes.py_object
xn = np.random.randn(100)
res.a = cap.a - res.a
string_types = str,
print(s)
print(catalan.counter)
length = len(x)
mat < -matrix(seq_len(m * n), nrow=m, ncol=n)
print(param1_list[0])
nested_instance
inital_guess[0] = np.abs(Y).max()
l
Markup(clean(text, **kw))
x = [range(0, 5), range(5, 10)]
w, h = shutil.get_terminal_size()
group = parser.add_mutually_exclusive_group()
numin = 0
i = hash(line) % size
args = p.parse_args()
globals = nvl(globals, {})
names = {x.Name for x in lst}
_filters = []
NumpyScalarConverter()
size = xy.shape[0] - 2 * s
L.append(a)
y1, y2 = y2, y1
ys = []
dictionary = dictionary[node]
j = B
index = 0
cursor += 1
page = urlopen(url).read()
df
hwnd,
decorator
k = len(data) * percentage // 100
choice_data = select_choice()
B(0, 1)
sy.plot(fpp)
n = len(numbers)
result, sparsity
deleterequest.session[self.lookup_kwarg]
doc.append(data)
rule_name = func.__name__
result += add(result, a)
print(d)
sphinx.ext.autodoc.Documenter.add_line = add_line
f = foo()
chgStart += BOX * sign(chg) * (abs(chg) - 2)
exponent = exponent - 1
author = models.ForeignKey(User)
model
parsed.columns
object_sizes = obj.sizes.all()
content
l
print(guess(label))
sqrt = inverse(lambda x: x ** 2)
type(os) is type(sys)
ch += DICO_INVERTED[b]
print(mycustomer.orders)
names = []
havename = thestring.find(name, 0, firstcomma)
print(ul)
raise
tmp1 = xy[0:size] - xy[s:size + s]
d = 1.0 * Num / Denom
str[:-1 * len(end_ptr)] + rep_ptr
lo
name = client.name
[uwsgi]
print(im.size)
parallel_radius = radius * math.cos(lat)
e.tuple
samples1 = [bin_to_int(s) for s in samples1]
bob(2)
print(logging.foo)
a = np.arange(n_a_rows * n_a_cols).reshape(n_a_rows, n_a_cols) * 1.0
self.showlog = not self.showlog
mutex_group = parser.add_mutually_exclusive_group()
active = Page.objects.get(page_alias=page_alias)
[(n,)]
final_hsv = cv2.merge((h, s, v))
session = self.twitter.get_session((access_token, access_token_secret))
print(b)
frm.for_type(int, thousands)
type(a)
data_array = ColorBlock()
dosomething(12)
c = celery.Celery()
print(hash)
secret = db.Column(postgresql.BYTEA)
self.scores_matrix[i, j - 1] + 1,
Jinja2 == 2.7
msgs
print(memory_value)
file_obj = obj.the_file.open()
CONSOLE_ARGUMENTS
wintypes.LPDWORD = ctypes.POINTER(wintypes.DWORD)
bad_index = (longs > 0) & (longs < 1)
msg = email.message_from_string(raw_string)
result = t1[rows]
True
print(args.w)
[1, 2]
bar.__code__ = pickle.loads(code)
options = Data(True, False)
T_UNDEF = 0
cache_variable = json.load(json_data)
m, n = X.shape
get_means(ratings)
spider_finished = spider_finished_count()
xml = dicttoxml.dicttoxml(json_dict)
ln(x - loc) - ln(scale)
b = [True, False]
timeoutCall = reactor.callLater(60, d.cancel)
result
l = len(df.columns)
wt.append(x * ws[i])
KEY2 = value2 - on - a - new - line,
now = datetime.datetime.now(created_at)
res = getattr(w, _mirrored_op[op])(v)
x = 2
0
self.context.push()
a = True
result
d[t1.key] = t1
actor = ActorFactory()
print(prefix(0.9, 2))
df
timeout_add_seconds = _old_timeout_add_seconds
result.append((currentIdx, groupLen))
y = _deepcopy_list(x, memo)
item = QUEUE.get()
print(b)
cv_arg = sklearn.cross_validation.KFold(y.size, n_folds)
result[1::2] = tweets
zero_crossings2 = numpy.where(numpy.diff(numpy.sign(a2)))[0]
[logger_root]
sys.exit(0)
colorbar()
print(xmax, ymax)
target_vertex_id = edge.target
sio = StringIO()
WORD_RE.sub(capitalizeMatch, s)
fp.close()
comment_tree = []
sleep(X)
handle != hexc(exc), hval(allow_null(val)), htb(allow_null(tb))
_, y_t, _, h_t = cv2.boundingRect(new_contours[0])
EXAMPLEfoo, 60, 6
amoDb = amoServer.Databases[dbName]
__rmul__ = __mul__
double * l
articleView.html
imDiff = ImageChops.difference(im1, im2)
data.date.min() - dt.timedelta(2), data.date.max() + dt.timedelta(2)
mask = np.isfinite(part_data)
document = PDDocument.load(inFile)
denom = np.sum(a) + cs
self.do_open(self.getConnection, req)
visited = [False] * len(prefix)
top_matrix[0, 0] = 1
newStudent = Student()
n = Node()
print(df)
self._index = index.copy()
rows, columns = X.shape
x = a.copy()
b, _, _, c = a
print(newPathList)
sidx = np.argsort(cols)
c = Code.from_code(f.__code__)
print(sum(global_array))
loc = ram.mean()
flags = dict(invert_dict(flags))
pad_to_square(r2, 0)
result = schema.load(event, special=special_field)
screenname = model.ChatField(max_length=40)
e2, v2, r2 = stringToVersion(sys.argv[2])
nexts = cycle(islice(nexts, pending))
print(i)
rv = mpl.ticker.ScalarFormatter.__call__(self, x, pos)
a = 1
n_x = n[0]
anIntOBJECT = 8
time_epoch.tm_mon, time_at_hand.tm_mday - time_epoch.tm_mday
_pwd_context = LocalProxy(lambda : _security.pwd_context)
result = dict()
self.__dict__[field] = value
engine.SetSearchPaths(paths)
uri = boto.storage_uri()
number ^= number << 11
tagger = POSTagger()
df
slow.addTests(TestSlowSomeMore)
A, (B,), (C,), (D,) = in_tree
cart = models.ForeignKey(Cart)
a = 1.0
self.data = []
req_data = file_object_from_req.read()
sources = []
imagebox = OffsetImage(arr_vic, zoom=0.1)
object.__gt__(self, other)
NodeDb = []
length = 16 - len(data) % 16
c = Row._make(A)
x
inputs = locals()
program_directory = sys.path[0]
length = in_view.size()
compress(count(), x)
Z = hdfpivot.values
self.request.callbacks[:] = []
i += 2
join_string = instring[0:0]
accountList.sort()
reservations = ec2.get_all_instances(instance_ids)
min_two_dupes(list1)
False
i += 1
previous_idx = idx
b = False
dataStack[1] = (np.random.random(25) * 100).reshape(dist.shape)
AC
username = result.username
circle_lune_area_2d
number1 = int(number1) * 10
newMtx = Mtx[:, (s.A1 > 0)]
0
trades
a.shape = 4, 2
total_size = os.path.getsize(path)
print(a)
surface = gz.Surface(W, H)
top
df1.BB = df1.BB.mask(df1.Result, df1.AA)
mystruct = MyStructure()
response = {}
l1 = []
BATCH_SIZE = 5
conn_indices = np.where(a_numpy)
m = len(nx.bipartite.eppstein_matching(G)) / 2
integrand
y = np.exp(gmm.score(x))
not self.__eq__(other)
all_occ = dict({})
ret
a = a.decode()
serializer.serialize(queryset, fields=fields)
random_y = np.random.randn(N)
L = []
Alias / gallery / media / path / to / gallery / media
self.d = collections.defaultdict(dict)
print(lst)
i = 750
print(len(oo))
X = iris.data[:, :2]
paths
print(match.group(1).strip())
rx = ans[0][1]
print(k)
df
5
bundle_files = 2
new = np.sin(omega_t2[-1000:] % (2 * np.pi))
print(content)
a = -80.94076540944798
im_out = empty((n + dn) * h * w * c, im_in.dtype).reshape(-1, w * ncols, c)
f
y_coord = cell.y_coord
t = np.arange(0, 1, dt)
sites = fields.Field(widget=ManyToManyWidget(Site))
self.name = name
sr.oe.set(1, mainCallback)
self.num = num
(x ** m) ** m
lines = mc.LineCollection([[(5, 1), (9, 5), (5, 9), (1, 5), (5, 1)]])
start += len(L)
groupb = self.group[leaderb]
cj = browsercookie.chrome()
list_query = list_query.filter(List.ignore == False)
VT = SVD.components_
129471528618740000
--prefix / usr
p1.awareness_status = p2.awareness_status
tws = ibConnection(clientId=1)
myCursor = myConnection.cursor()
output = sys.stdout
signal.signal(self.sig, self.original_handler)
c = ColorTB()
uniq[i] = 1
n -= 1
form2 = Product2()
token = client.exchange_token(code)
aListOfHiPRIOevents = HiPRIOpoller.poll(timeout=0.2)
new = [df.D.values[0]]
print(hand)
logger.debug = LoggerLogger(logger.debug, name)
nice.append((nr, name))
displayPlantImage = originalPlantImage.subsample(2, 2)
d = {}
currentUserData += x
print(a)
conn.execute_query(query)
abstract = True
gone, alive = psutil.wait_procs(procs, timeout=1)
a
kde = ss.gaussian_kde(data.T)
mask2 = 128
results = engine.execute(do_nothing_stmt)
main()
item
bin_size = histo[1][1] - histo[1][0]
a = 0
a.x = 2
R > uniroot(irrSearch, c(0.01, 5))
session = dryscrape.Session()
W = W * 2 * 0.12
results = []
RowsToSkip = set(df.index.values).difference(stratsample)
print(getNearest(self.symbolsSorted, (1200, 1500), 1000))
solutions = rec_dubz(prev + seq[0][0], seq[1:], allowed=allowed)
txn.abort()
x in S
bNull = df.B.isnull()
True
RATE = wf.getframerate()
Y, X = n.histogram(data, 25, normed=1)
print(actions)
self.max_depth = 100
vbdrecord.VM = vm
num = 0
np.sum(est.score(X))
word = random.choice(lists[category])
print(perm)
newest_file = path
[openerp - server]
rp = request.path
i = 0
b = x.MyClass(a)
xticks, xticklabels = plt.xticks()
print(a)
n *= stack.pop()
x = 1
thread_.join()
y = r_len * math.sin(alpha)
se2 = db2.Session()
authentication = MyCustomAuthentication()
variable2 = int(data[1])
[rds]
print(adictionary.category)
new_sku += chr((ord(i) + 1) % 65 % 26 + 65)
age_is_one = test_rec.age == 1
lSize = os.stat(filename).st_size
print(a._shape._dims[0]._value)
arr_f[27]
some_dir = some_dir.rstrip(os.path.sep)
start, stop = args
args.foo
question_id, foo, bar = row
locals()[k] = v
x
count = os.stat(path).st_size / 2
allvars_bad()
sys.settrace(self.trace_callback)
clean_filter_openssl
txt = fn(txt)
signals.post_syncdb.connect(create_notice_types, sender=notification)
a = 5
feed.modified
hex_value
print(rnorm)
multiples_of_2 = range(0, 100, 2)
num *= 2
max_only = []
True
print(p)
adj[i, 2] = x
p = pkts[0]
TP = cm[0][0]
data = [(n, d[n]) for n in old_name_list]
Select.__call__ = monkeypatched_call
al = a.tolil()
headers = response.info()
pid = os.fork()
library(jsonlite)
print(df)
s = (values.cumsum() - ALLOWANCE).clip_lower(0)
b = B()
parser = OptionParser(usage)
bin.append(item)
python = sys.executable
print(p.Id)
magnitude = 0
sys.arg_set = expr
ch = Serial.read()
call_to_your_api()
data.dtype
ds[:] = xmldata
MyObject(sValidPath)
alpha = 0.05
dummies_frame = pd.get_dummies(df)
loss, acc = model_test.train([X_batch] * 2, Y_batch, accuracy=True)
text2save = str(text.get(1.0, END))
[Foo]
print(5)
env = Environment()
[filters]
value = next(it)
itemlist = sorted(list(itemset))
canvas.width = img.width
print(i)
print(i)
UsageCount = 1
print(a_link or image_link)
tmp = myfunc()
bs.Close()
t = list(pycountry.countries)
interpolated = f(rr, cc)
listener.bind(ADDR)
time += localtime(l.time).dst() - time.dst()
D.append(L.pop(i))
print(Fraction(1.25))
input = [server, sys.stdin]
dis.dis(test4)
inv = ax2.transData.inverted()
port = 5005
d[np.isnan(d)] = 1
foo
s
rv = self.router.dispatch(request, response)
list(lazy(fp))
remaining = list(countries)
d.location
value = output[col].ffill()
l
total = 0
distance = m.floor((distance - Ri + 1) * (height - 1) / (Ro - Ri))
e += Decimal(1) / fact
self.append(self._fx())
_.shape
is_parent, my_arg1, my_arg2 = daemonizer(path_to_pid_file, my_arg1, my_arg2)
_myclassmethod
print(b)
print(comment_entry.published.text)
cnt += 1
d[c] += 1
original_convert = o.convert
py - copy - clause
intercept = y_mean[:, (0)] - slope * x_mean[:, (0)]
constructor
groups = itertools.groupby(players, key=level)
print(b)
i.copy()
weighted_appearances = []
foo = bar
self.directive.result.append(self.indent + line, source, *lineno)
fixed = line[index + 1:begidx]
cents = [2000, 1000, 500, 200, 100, 50, 20, 10, 5, 2, 1]
txt = match.group(1)
myOldIntValue | string
y = x
idx2, dist = flann.knnSearch(desc1, 2, params={})
whole, frac = f.split()
hash.hexdigest()
_, last = next(row_iterator)
DEPTH_PRIORITY = 1
ahead = sd.iloc[index + 1]
match = False
address = Address()
56512064
plt.legend(shadow=True, fancybox=True)
data = bytearray(os.path.getsize(FILENAME))
srt_dict = deepcopy(a)
not same
df.assign(b=np.append(0, df.a.values[:-1]))
raise web.seeother(web.changequery(cookie_err=1))
d = 1
mod.__all__ = [fn.__name__]
ret, mail = x.fill_mail_data(5)
mpz_fdiv_q_ui(exponent, exponent, 2)
print(answer)
e1, v1, r1 = stringToVersion(sys.argv[1])
dir(anIntOBJECT)
stuff.doCommonStuff()
start = PyNumber_Index(start)
print(list(each))
C = C
newGroup.reference = hash
c = a | b
value = next(it)
tree = ast.parse(f.read())
item = TableItem()
resp.getWriter().append(csvString)
result < -preds[unseen] / freqs[unseen]
this.point_count = 0
p = lst[(i + j) / 2]
test = array([[tmp, tmp], [tmp, tmp]], dtype=object)
self.method_name = method_name
b = map(lambda x: x + offset, another_simple_list)
print(result)
df2
__builtin__.__import__ = newimport
lines = docstring.expandtabs().splitlines()
value = 122445.56
print(l)
item = my_list.pop()
fit = kmpfit.simplefit(model, [0.1, -0.1], x, y)
self.re
y_range = func(x_range)
files = list_of_files
start, length = map(int, sys.argv[2:])
circle.draw(surface)
len(d.feeds)
print(i)
qlow, median, qhigh = sr.dropna().quantile([pcnt, 0.5, 1 - pcnt])
window = np.blackman(chunk)
socket.setdefaulttimeout = old_setdefaulttimeout
data_items.sort()
list2 = []
bool(compiled.match(id))
rec_split(0, s, n)
exp = []
url = Field()
fig1 = pylab.figure()
df
param = svm_parameter()
uridecodebin
row = vectorized.getrow(i)
r = (b + g) * 5
greetings = {name: title for names, title in pairings for name in names}
reply = {}
print(df.columns)
print(b)
right = 1
pycb = cb
answers = values.dot(weights)
digits = datasets.load_digits()
print(a[index_at(idx, a.shape, axis=axis)])
parser = prepare_parser()
im_data = np.ctypeslib.as_array(im_data_base.get_obj())
plt.semilogy(fx, X, fy + f_demod, Y, fz + f_demod, Z)
mean = [1, 1]
tag
num - num % multiple
cosDec = math.cos(math.asin(sinDec))
print(p.op)
self.input_cursor = (1 + self.input_cursor) % len(self.input_values)
dfs = {sheet: xl.parse(sheet) for sheet in xl.sheet_names}
outp = SigmoidLayer(1)
deleteself.clients[sock]
out.write(part)
xwin = x[:winsize * numwin].reshape(-1, winsize)
data.append(flag * df[col])
df.iloc[row_indexer, col_indexer] = 999
null
r = robjects.r
Unipath.Path(mypath).components()[0]
print(a.A)
tempset = {edge[0], edge[1]}
a += d
widths = np.diff(bins)
ipdb > request.POST
energy = FloatCol()
print(c)
zipCode = models.IntegerField(max_length=7, blank=True, null=True)
self.send_response(200)
scores
_zips = random.sample(zip(lstOne, lstTwo), 5)
out[mask] = A[mask]
y -= APPHEIGHT / 2
yx *= img_height, img_width
consume(x)
print(result)
dstf = str(target[0])
some_value_related_to_key
cols = col_stop - col_start + 1
df
work = []
A = list(range(1, 94))
n, _ = np.histogram(x, bins=xbins)
plot = figure(plot_width=400, plot_height=400)
iterator = iter(L)
image = b64encode(event.logo)
m = scipy.sparse.coo_matrix(([1] * len(dfr), (dfr.y, dfr.z)), (size, size))
print(about.title)
y, x = np.where(h)
valid = [b for b in valid if b >= 0 and b <= 255]
results = []
print(o)
result = set(binaries)
DIRA
sys.stdin = f
x = 4
2, a, a, c
raise TypeError
new_strs
b = all_perm[np.random.randint(0, all_perm.shape[0], size=nrows)]
mainMonitor = CGDisplayBounds(CGMainDisplayID())
env[k] = v
sd.listen(5)
w.write_message(message)
start_urls, extra_domain_names, regexes = self._get_spider_info(name)
inp = eval(input())
d_max[first] = second, count
stream = tweepy.Stream(auth, StreamListener())
2 - 1
mapping = {}
assert a.sum() == x.sum()
y = x[:4]
results.insert(r, v)
reply = resp.json()
s[:half + rem], s[half + rem:]
a = self.convert(item)
df
(fatcows if weight > 50 else thincows)[name] = weight
file = pickle.dumps(obj)
iternext = NpyIter_GetIterNext(iter, NULL)
EXAMPLEfoo, 60, 6
others = [user for user in query if user.first != token]
self.update(*args[0])
max_size = 5
X_digits = np.array(x)
append(e)
kernel(samp)
maxForRow = allData.max(axis=0)
client = pymongo.MongoClient()
float(a_number) * 1000000
0.888865
llx, lly = np.meshgrid(np.arange(-180, 180, delta), np.arange(-90, 90, delta))
t = tuple(B)
val_list = []
son[key] = self.transform_incoming(value, collection)
value = int(bit_string, 16)
print(type(item))
local_bind_address = _local_bind_address, _local_mysql_port
g = np.meshgrid(poro_g, sw_g)
self.failUnlessIsInstance(evt, CGEventRef)
a
require(raster)
count = 0
hash[list[index]] = list
unidecode.unidecode(somestring)
data = str(data)
d[i] += A * b[n, k, j]
self.num += 1
print(s)
untrusted = dumps(round_floats(val))
(n1, n0), (d1, d0) = get_rational_coeffs(s * expr)
app = QtGui.QApplication(args)
dot_product.eval()
dx = int(i - Ro)
a_txt
Ll - -lowercase
q = abs(q)
alert(response)
print(summary_dict)
x = _test.x
base_html
func[1]
weights = [-0.4, -0.2, 0, 0.2, 0.4]
dict_temp = geocoding(target)
x = 5
d5_moving_av = moving_av(reader_list, 5)
print(i.date)
cooling_rate = 0.95
d
in_loop.add(neighb)
d = {}
x = deepcopy(test)
approximation_interval = pi.approximation_interval
id(a)
name = command.args[0]
en = {}
escaped_line = shell.escape_ansi(line)
deleteself._half
newfiles = []
point(0, -1)
foo.append(42)
2
assert_url_equals(url1, url2)
print(stdout)
newVersion = Math.max(0, Math.min(changeLog.length, newVersion))
parser = Parser()
rowlength = grouped.ngroups / 2
list1[ctr] = cin1 - in10
_i = 99
rgb = 50, 100, 150
sys.excepthook = did_you_mean_hook
frame.f_locals[name]
b, _ = np.broadcast_arrays(b, a)
plt.subplot(212)
test_area = tempfile.mkdtemp()
print(m)
set1 = {0, 1, 2}
diffs = memloc.diff()
c[:ma, 1::2] = b[:ma]
value = zzz()
xs = list(iterable)
recipient = recipient,
F, saveN / F
name_space[name] = value
request_status = Column(Boolean)
x = [(x / 1000) for x in random.sample(list(range(100000)), 100)]
current_index + 1, new_seasonal_indices, new_smoothed_observation, new_trend, new_loss_sum
1
ret = ord(msvcrt.getch())
b = np.random.normal(-2, 7, 100)
psyco_curs_callproc(cursorObject * self, PyObject * args)
count = 0
retval = Settings()
False
runend = curpos
y = list(range(10))
ticks_restrict_to_integer(ax.yaxis)
date = start
threads.append(t)
someValue = rand()
tell_the_truth()
x = np.linspace(0, 10, 1000)
r = self.seq[self.start]
samples = (int(s(t) * 127 + 128) for t in range(n_samples))
a ** b ** 15
a = 1
bias_to_hidden = FullConnection(bias, hiddenLayer)
send_by = obj.supporter,
bv = bitarray(len(input_li))
indexes = [0] * len(aa)
maxscrs = [scr for scr in scores if scores[scr] == maxscr]
points = []
print(distance_vectors)
fakeClient = Mock()
print(exp)
self.find_or_create(kwarg1=value1)
show()
j = 2
sentinel = object()
raise Ex()
np.asarray(information_gain)
subtract(a[k], b[k])
decorator
c.shape
sy, _ = np.histogram(x, bins=xbins, weights=y)
r = Tk()
adm1_shapes = list(shpreader.Reader(fname).geometries())
mkdir / tmp / logwtf
flattened = {}
cursor = built_dict = {}
response = requests.get(self.url, stream=True, headers=headers)
serializer = TaskListSerializer(tasks)
Ex, Ey, Ez = gradient(V)
RewriteCond % {HTTP_HOST} ^ colorurl.com[NC]
5
np.leaves()[-1]
L2 = [8, 1, 5]
parsed_t = dp.parse(t)
output = subprocess.check_output(command, shell=True)
print(df1)
urls = (row[0] for row in c.execute(SQL_URL))
skypeClient.Attach()
modes.append((int(mode.PelsWidth), int(mode.PelsHeight), int(mode.BitsPerPel)))
energy = tables.Float64Col()
tok = toks[i]
surface.finish()
print(100)
a + b
dstypos = yoff * dstwid + dstxbase
stack = []
_Py_RETURN_UNICODE_EMPTY()
products = set((1,))
valmax = 1.0
total = func(total, element)
session = db.Session()
self.connection = Database.connect(**kwargs)
ab = a * b.max() + b
sess.refresh(self)
form = DeviceAdminForm
PyObject * u
b = [1, 2]
i = 0
response = table.scan()
print(li)
value = mask & byte_from_file
cam = VideoCapture(0)
html = htmlmin.minify(html, remove_comments=True, remove_empty_space=True)
iterable = cycle(states)
worker1_result = mytask.delay(someargs)
log_x = log(x)
rundir = getcwd()
+--routes.py
seen = set()
m = gen()
max_val, hot_list, is_max_found = max(my_list), [], False
syn_set
d = {}
cluster_bar.add_node(node_bar)
print(search(500))
country_data[0] = tag.string
L2 = [1]
yn = y + 0.2 * np.random.normal(size=len(x))
result = tuple(islice(it, n))
print(response[y, x], type(response[y, x]), response.dtype)
low, high = t
q = Example()
password = result.password
self.o
counter = {}
flat.append(k)
g = [_]
inputElement.send_keys(dict[key])
child.before
keyname, fielditerator = result[1]._formatter_field_name_split()
diff = ImageChops.difference(im, bg)
daysDiff = str((d2 - d1).days + 1)
splits = ((v > threshold, p) for i, v, p in points)
myFoo.__bar
x = eval(mat.group(2))
struct.pack(fmt, *reversed(struct.unpack(fmt, a)))
answer = select(array)
ID = ID + 8
code = droid.scanBarcode()
f1 = (arctan(-x) + pi / 2) / pi
i = 0
[something_to_wait(), something_else_to_wait()],
d = h.read(64)
1
s
v = a * a + b * b + c * c
min_index = i
new_path = path + (t.node,) if found_cat else path
sequence = chain(sequence, (pad_symbol,) * (n - 1))
4, a, a, c
[blas]
self
info = model_instance._meta.app_label, model_instance._meta.model_name
chomped_uri = uri
translated_str = translator.gettext(str_to_translate)
look_at(reversed_arr)
2
ids = df.group.values
it = iter(nums)
False
AppDomain.CurrentDomain.Load(content)
this.richTextBox1.Text = stringBuilder.ToString()
self.resultQueue.put((1, 2))
ind = (a > 0).astype(int)
free(my_ints)
print(b)
lowest_acceptable = start_at
baz = baz or blar()
u
temp_p2 = PyNumber_Long(temp_p)
c = app.test_client()
q = list(q)
ar[1] = cos(inp_ar[0]) * cos(inp_ar[1])
f1, f2 = 1, 1
small = np.arange(0, m).reshape(m, 1).repeat(d, 1).T.reshape(-1, 1)
x = 1
my - apps / apps1.tar.gz
plot(logo)
SELECT[Date], [Time], [uSec], [twoCV]
Affine2DBase.__init__(self, **kwargs)
M.select()
r2 = next(file2)
n_rows = len(board)
prefix = NULL
self.__class__.num_of_tests = len(list(filter(self.isTestMethod, dir(self))))
0, 0
plt.plot(1.0 / freq[:N / 2], abs(W[:N / 2]))
instance.delete()
i = C(x=1, y=2)
results = set()
kwdefaults = attr.__kwdefaults__
True
text = git.pull()
hash = hashlib.md5()
s += t
a = np.cos(theta)
newpayload[quote(k)] = quote(v)
result = list()
f = gcf()
X_vectorized = count.transform(X_train)
print(key.bits)
animals = AnimalObject()
99.99000000001425
Heading
Y_digits = np.array(y)
pdm.SetInputConnection(geometryFilter.GetOutputPort())
max_name_len = max(len(x) for x in names_fmt)
print(res)
some_code
s
slow = TestSuite()
print(ans)
print(l)
a = ep.read(8, timeout=2000)
c.xkcd()
5
rect(inds, inds, 0.9, 0.9, color=some_colors)
paths = []
seconds, micros = divmod(dtms, 1000000)
field_2 = m.group(2)
self.prop = prop
4
samples = l.rvs(size=2 * 10 ** 7)
loop.close()
alpha_img.fill((255, 255, 255, alpha))
loc = models.TextField()
print(output)
print(txt)
wait
x * x
area = abs(np.linalg.det(t)) / dimfac
term_appearance
print(d_time2t_stamp == t_stamp)
st = st + key + str(val)
False
new_df = df >= threshold
df = df.head(10)
a, [b, c, (d, e)] = 1, [9, 4, (45, 8)]
-1
my_secure_rng = secrets.SystemRandom()
userprofile = UserProfile.objects.get(user=user)
desktops = se.desktops.display_name.get()
maxs = [max(col(m)).alias(m) for m in majors]
D = diag(w)
b = n - a ** 2
track_1 = np.array([1, 2, 5, 10000, 100000, 200000])
price_change = price_change ** 2 / (1 + price_change ** 2)
print(a)
cin1 = in1[ctr]
self.updates = set()
self.__load()
json.dumps(condition_loaded)
ex[0] += 1
sum_z, count_z = y.real, int(y.imag)
print(pairs)
ModuleType = type(sys)
_unique = 0
profile.set_proxy(proxy.selenium_proxy())
res.trend
second = splitted[1]
borders = xlwt.Borders()
-2
x
mypdf(e) * 100 * 2 == mypdf(e) * 200
rot_sprite
dfs(G, 2, [])
rst = table_div(num_cols, cell_width, 0)
result
print(x)
strcpy(date_str, prev_date)
my_logger.propagate = True
seq = []
print(formatStr.format(*item))
sys.stdout = StdoutFilter(sys.stdout)
a[min_row:max_row + 1, min_col:max_col + 1] = 1
diff = features[i][k] - features[j][k]
ret[k] = scrub(v)
SEM_NOGPFAULTERRORBOX = 2
print(qs)
res
engine.Execute(pySrc, scope)
result
i
a
l.append(x)
pred = lambda k: np.sum(s[:k]) / s_sum < retained_variance
tot = 0
wd = x.Whateverd(2.5)
settings = {}
black += 1
a = Authority.objects.get(area__contains=Point(lng, lat))
result = getattr(asarray(obj), method)(*args, **kwds)
0
b = skimage.measure.block_reduce(a, block_size=(2, 2), func=np.mean)
p.close()
dist = getattr(scipy.stats, d)
iterator = int(len(text) / cores)
12
sync_func
n = 0
5 in d
keypoints, descriptors = freakExtractor.compute(image, keypoints)
h = numpy.array([2, 8, 5, 10, 7])
max(temp_depth)
--bar_report.py
complexInput = cvCreateImage(cvGetSize(im), IPL_DEPTH_64F, 2)
fruitDB = db.DB()
request.response.redirect(trial_url)
c[:ma, ::2] = a[:ma]
self.scores_matrix[i, j] = self.scores_matrix[i - 1, j - 1]
self.curl.setopt(pycurl.URL, url)
parsed_number
varname = vs.pop(0)
print(num or self.data)
min, max
count = 0
a = x
line = p.stdout.readline()
result = somecalc()
value = float(value) / 255
Test
rc = p.commands[0].process.poll()
self.foo_x = self.bar_x
valid_paths.append(path)
p.memory_info()
0.004145860672
print(indices)
X, param_1, param_2, arg = args
xs = [-10, 0, 10]
audio = r.listen(source)
p = pol_ext.interpolate(d)
bool = False
m.assert_has_calls([call.m0(), call.m1()])
time_tuple = parsedate_tz(datestring.strip())
map_canvas.zoom_all()
freqs = fftpack.rfftfreq(len(datay), d=tdata[1] - tdata[0])
chunk = f.read(chunksize)
a
ret
data = wx.FileDataObject()
n = len(test_images)
style = []
_create_verified_https_context = ssl._create_default_https_context
v = qnames[v.text]
print(foo.a)
y = (coord[rows, 0, 1] - coord[cols, 0, 1]) * y_dist
self.attrb2 = a2
decomp = sm.tsa.seasonal_decompose(df, freq=52)
Response()
newCell = worksheet._Worksheet__rows.get(row)._Row__cells.get(col)
json_data = data.read()
B[vals[index]] += 1
k
ax.matshow(corr)
tmp_cookiejar = QNetworkCookie(cookie.name, cookie.value)
num = coord.shape[0]
negatedEven = []
connectSucceeded = True
b[i] = False
hessian
data_restored
first_five = string[:5]
c
nextNode = nextNode.nextSibling
python
file_handler.setFormatter(default_formatter)
array_wrapper = ArrayWrapper()
lower, upper = df.total_bill.quantile([0.25, 0.75]).values.tolist()
a = list(range(10))
len([x for x in s if abs(x) > eps])
self.model = model,
f = lambda x: x + offset
out_file.write(chunk)
rss_items = []
p, entropy = 0.0, 0.0
tagged_sent = nltk.pos_tag(tokens)
denom = np.empty(1)
print(local_minima_locations)
self.orig_view_angle = cc.view_angle
z = x[:, (np.newaxis)] + y ** 2
f = open(pathjoin(DATA_DIR, fn))
mratings
par = configparser.ConfigParser()
max(enumerate(str, 1))[0]
self.mode
ax2 = fig2.add_subplot(111)
text = root.clipboard_get()
sorting = np.argsort(values)
B = Y.imag
test.body[1].body
one.append(el)
point_neighbors_list = []
self.i = i
i = start
items_iter = iter(items)
connection = accept_connection()
config = ConfigObj(path_to_ini)
adic = {}
integral = integrate.quad(fun, 0, 1)
read_ok
all_R = []
cols_in_table1 = table2.columns[np.in1d(table2.columns, table1.columns)]
glob[key] = loc[key]
a[0] = 99
I = 0
loop = asyncio.get_event_loop()
n //= 10
ds.newSequence()
a.imag[abs(a.imag) < tol] = 0.0
primary = foo().bar()
result
standard_scalerX = StandardScaler()
frame = callerframerecord[0]
filepath = os.path.join(path, filename)
[0, 20],
rev = 0
__metaclass__ = M_C
num_items = len(items_list)
fn_dict = fn_match.groupdict()
what()
pr = cProfile.Profile()
B = []
table = [([False] * m) for x in range(n)]
result = []
cost2 = cost1 + len(s2 - s1) * marginal_cost
b = FancyView(a, p)
__metaclass__ = Singleton
print(m.evaluate(x))
app.response_class = Response
x[x.index(name)]
v2 = -1.15
url = API_URL + method
curr = s[i + 1]
cvWriteFrame(writer, img)
use_tab = guess_tab(editor.getText())
circle_exp_contains_point_2d
print(batRegex.findall(yourstring))
assert expected == current
set_pm_excepthook((IndexError, ValueError), True, True)
result = []
unique = []
Flask - SQLAlchemy == 1.0
mymodule.l.append(x)
a0 = np.empty(a.shape + (l,))
minCoins[change]
state
Out = 0,
guess = (lastGuess + x / lastGuess) / 2
file1[k] = v
deletee[attribute[0]]
thing_relations = inspect(Thing).relationships
True
HAS_NUMPY = True
a
pcolor(data, cmap=new_map)
i
snake.update(DOWN)
print(neginf)
self.curl.setopt(pycurl.CONNECTTIMEOUT, 5)
chr(106)
numprocs = 4
c = Converter()
[hooks]
print(parameter_B)
plotAnnotes = []
assert 0 <= seconds <= 86400
module1.cool_func()
t1_us = int(round(t1_unpacked % 52428800 / 52.4288, 0))
union.args
20
t /= 1000.0
self.attrb2 = a2
weight.append(r.choice(l))
default
font.dwFontSize.X = 11
idx = numpy.argmin(dists)
decimal.Decimal(-1000).exp()
inlines = MyInlines1, MyInlines2
x = list(range(5))
1
pred = lambda x: x[1] / s_sum < retained_variance
print(html)
self.calls = 0
SimilarPost = aliased(Post)
_consumer = deque(maxlen=0)
print(b)
updated_format = cell_format_dict
adj.set_value(adj.upper - adj.pagesize)
spam = x + y
m, n = input_array.shape
print(search_str in f)
it, other = tee(it)
test
data, errors = MySchema.loads(request.json())
finder = ModuleFinder()
y = x + 8
print(files)
date1 < date2
y_ = tf.gather(flat_y, flat_ind_max)
self._value_type = value_type
params.append(evaluate(child))
S = numpy.zeros(s_cols)
self.updateInstManagers(bars)
mysocket.sendto(user_input, dest)
a = np.zeros(n * n, dtype=np.complex128)
cmath.acos(1j)
print(ng.format_output(ng.best_group))
print(data_md5)
A * np.exp(K * t) + C
content
taggedLine = taggedLine.split()
root = {}
t.daemon = True
print(page_name)
varNames = sorted(variants)
city = cities_light.models.City.objects.get(pk=cityPK)
MWSConnection._parse_response = lambda s, x, y, z: z
sz = w.get_size()
old.delete()
print(newdata)
rand() <= probability
N = 100
print(wordin[wordnum])
object_type = models.ForeignKey(ContentType)
out = []
gen_vim_config
self.helpExpansion.grid_remove()
conf = SparkConf()
print(dset.shape)
submatches = Regex2.Match(match)
results_dict = defaultdict(int)
mapnik.render(m, surface)
pushed = True
u, s, v = ssl.svds(matrix, k=k)
cols = seq[:]
10
process(chunk)
defn = defns[0]
Collection.draw(self, renderer)
sqlalchemy_utils.types.password.PasswordType
d.addCallback(connected)
countries = {}
self._base_queryset = queryset
value = f_interp(*p)
target = lambda : callback(func(*args, **kwargs))
result.X = P + 1
filenameToModuleName = lambda f: os.path.splitext(f)[0]
m.assert_any_call(2)
len(test)
prediction = prediction,
max_groups = 1
a = True
lst = [1, 5]
2
mix = frozenset([color1, color2])
round_down(19, 5)
tokens = WordPunctTokenizer().tokenize(content_part)
self.accurateSeconds = int(currentTime)
s
size = 20
a = 1
x = 0
self.size = len(inner)
i = 0
print(items)
hashed = bcrypt.hashpw(password, bcrypt.gensalt())
img.anchor_y = img.height / 2
chunksize = 10 ** 6
range_limit = index + INSERT_INTO_HOMEFEED_BATCH - 1
mod.my_macro()
Py_MEMCPY(to, PyUnicode_DATA(str), PyUnicode_GET_LENGTH(str) * char_size)
system
curl - v
xc[0, k] = x[0, k]
1241511
height = max(coord[1] for coord in coordinates)
el = 0.94610742
line
c = conn.cursor()
connect_default_signals(Country)
c
print(df)
pos = f.tell()
foo()
neighbor_points = X[idx]
o = repo.remotes.origin
b = 2
sum, diff = foo(True)
val = 1
mixer = pygame.mixer
new_date = datetime_object + relativedelta(years=1)
B = np.fliplr(A)
lib = ctypes.cdll.LoadLibrary(rustLib)
GulServer, SolServer, RymdServer, SkeppServer, HavsServer
plot_class = available_plot_types[self.plot_type]
code, dist = vq(X, codebook)
line.py
pages.append(url)
used.append(obj)
print(arr)
print(out)
data = file.read()
decoder(obj[placeholder])
False
optimizer = tf.train.GradientDescentOptimizer(0.5)
size = int(dfr.max().max()) + 1
self.protocol = proto
Py_INCREF(key)
lines = []
datetime_obj = datetime(loc_year, loc_month, loc_date, loc_hour, loc_minute)
file = StringIO()
arr[i].member = i
dir(datetime.datetime.replace)
stop = timeit.default_timer()
unique_hash2 = pickle.dumps(c2)
startPoints.append(end + 1)
probs_y2 = probs[:, (T.arange(targets.shape[1])[(np.newaxis), :]), (targets)]
enemy1 -= kick
print((a1.flags.owndata, a1.base))
ans = memostirling1.get((n, k))
exp_A = A - max_A
wait = WebDriverWait(driver, 10)
add(w=11, t=11)
index.yaml
count
a
benchmark = timeit.Timer(longsearch, prepare)
str_[len(bom):]
acknowledged = False
msk = np.random.rand(len(df)) < 0.8
list = builtins.list
iterable = iter(iterable)
index += n
draw.font_size = 40
skippedItems.Add(item)
namedPi = Record(*tuplePi)
sumsCount += SumsCount(n - i) + 1
self.cwd = os.getcwd()
credentials = storage.get()
res = np.append(res, [i, j, p, q], axis=0)
data
myList = [i, i, i]
[uwsgi]
uvw = Singleton()
a = 42
module.__loader__ = self
j = s_len / i
entryx = int(e1.get())
any(map(eval, my_list))
print(res)
painter.translate(option.rect.x(), option.rect.y())
a = [ml.append(item) for l in df.DESCRIPTION for item in l]
dbObject.delete()
some_args = dict((k, kwargs[k]) for k in argspec.args if k in kwargs)
shape = map(len, vs)
value
my_signal
print(pair)
message = []
_array = _array[::][1:]
df
sadf
app.autodiscover_tasks(settings.INSTALLED_APPS, force=True)
handle = c_int()
dd[name] = createNewDf(i)
recipients = []
first, mysequence = res
print(result)
optional_error_handling()
x = NDDataArray(16, uncertainty=StdDevUncertainty(4.0))
w = WCS(hdu[hduid].header)
angle = 2 * np.pi * (1.0 * i / ncircles + t / duration)
root = Root()
player.name
primes = []
remote_ret = channel.recv_exit_status()
it = iter(seq)
my_cursor = my_db.cursor()
hour = dt.index.hour
surf(img2, GpuMat(), keypoints2GPU, descriptors2GPU)
c
update = tf.assign(v, add)
PQLC2
print(a1 == a2)
count = total_count * counter[v] / len(l)
extent = [xbins.min(), xbins.max(), ybins.min(), ybins.max()], linewidths
r.symbols.append(polygonSymbolizer)
x1 = 1,
resources = list()
app = make_application()
likely_cat = {}
mem += child.memory_percent()
self.text = []
source.extend(generated_source)
item = MyItem()
sum_samples = sum(samples)
lis2
alpha, doublereal * a, integer * lda, doublereal * x, integer * incx
lineMatch = True
print(hash)
user
document = docx.Document(filename)
total = count_above_cython(arr_view, thresh)
x = elems[i]
prob = svm_problem([1, -1], [[1, 0, 1], [-1, 0, -1]])
True == 1
pos += 1
tim = list(range(start_time, end_time + 1))
print(i)
gizmoid = numerator / denominator
result
ret
pubsub = redis.StrictRedis(REDIS_HOST).pubsub()
montecarlos = [MonteCarlo(result_queue, f, fargs) for fargs in farglist]
key = os.path.sep.join(path)
curpos = i + 1
from_, to = stack.pop()
name_sets_2 = [set(i) for i in list_of_name_tuples_2]
print(d)
self.l = {}
null_handler = NullHandler()
right = (1 << i) - 1
dp = os.path.dirname(os.path.realpath(__file__))
K.set_learning_phase(0)
set_difference(input, limit)
N = 2
ids
transformed = model.transform(rdd)
index
l = p[i:j]
rand = random.random()
print(delta)
False
in_data[0] = float(1)
aList
texts
5.0 ** 5.0 ** 5.0
align_array = np.array(alignment, np.character)
input_dir = tempfile.mkdtemp()
y = [(chgStart + i * BOX * sign(chg)) for i in range(abs(chg))]
60 * 60 * 24 * i
BZ_OUT = Bz.copy()
BX_OUT = Bx.copy()
ntok = 1
n = 2
print()
matches = tool.check(text)
x = np.linspace(0, 14, 100)
M = imaplib.IMAP4_SSL()
result = unittest.TextTestRunner(verbosity=verbosity).run(suite)
mime_root.attach(mime_video)
numerator = gamma(1.0 * (nD + df) / 2.0)
print(MyModel._counter)
propfaid = h5py.h5p.create(h5py.h5p.FILE_ACCESS)
decorator
myLoop(arange(20))
caller_frame = inspect.currentframe().f_back
name
1
sound.play(loops=-1)
currency = models.ForeignKey(Currency)
dev.play(data)
output = []
maxLen = max(len(t) for t in text)
s
self.prog = ProgrammeFactory()
BOOST_PYTHON_MODULE(foo_module)
print(d._block)
x = 4
result = np.ones_like(x)
lcmap[0] = 0, 0.5, 0, 1.0
--type - set
_multiply(a, b)
print(mean(x), len(x), x)
updated_format = dict(existing_cell_format_dict or {}, **cell_format_dict)
result[old_arena] += timestamp - old_timestamp
[build]
body.add(edges[i][0])
chr(cp)
regex_string = t.render(c)
uid = Column(Integer, autoincrement=True, primary_key=True)
categories = fields.Field(widget=ManyToManyWidget(Category))
fig.canvas.manager.window.activateWindow()
sha = repo.head.object.hexsha
form = GalleryForm
fmt_obj = sheet.book.format_map[xf.format_key]
print(time_epoch)
user = request.backend.do_auth(third_party_token)
print(s)
time = 0
value = r_value.search(line)
done, errored = get_progress(results)
idx_tups = zip(idx_arrays[0], idx_arrays[1])
print(b)
print(fib(100000))
d_mva = PD.rolling_mean(D, 10)
0, 1, 4
n = 2
print(RNA_integers)
farmersmarket.py - h | --help
s.sort()
country_data = [0, 0, 0, 0]
result
self.client_secret, scope = self.SCOPE, user_agent = user_agent,
labels = np.array(labels)
locs = numpy.indices(rows.shape[0:2])
p = PyString_AS_STRING(res)
fft = np.fft.fft2(data)
model = ModelA
p = ctx.Pool(4)
idx = first_index + 1, i + 1
print(ctime(response.tx_time))
sorter
lst = [1, 0, 2]
1
wrapper
attrs = vars(an)
print(Decimal(r.numerator) / Decimal(r.denominator))
__builtin__.open = Open()
m_menus[index]
dict1 = dict(table1)
content = Column(UploadedFileField)
print(matches)
print(b)
print(result)
print(networks)
print(pl(x, *popt_pl))
print(scientific_names)
max_x = x[y_av.argmax()]
created = set(new.keys()) - set(old.keys())
data = {}
https = requests.adapters.HTTPAdapter(max_retries=https_retries)
print(name_obj.__dict__)
X[:, (0)] = LabelEncoder().fit_transform(X[:, (0)])
print(s)
results = allpeople[100 * offset:100 * (offset + 1)]
xxs_pp.sort()
loc(i + 1)
part += sep + word
x = Distance(_, unit=u.kpc)
clipboard.OpenClipboard()
data = eval(input())
globals = PyEval_GetGlobals()
print(effectivehandlers(logger))
remaining_weights[k] = current_weights[k] - item_weights[k]
print(tagger.tag(tokens))
setColor(rightPixel, color_left)
abstract = True
self.im.pixel_access(self.readonly)
funcs = []
b or c and d
results = []
Session = sessionmaker(bind=some_engine)
counter = collections.Counter()
rdfrm
cut_idx = np.searchsorted(an[sidx], lags)
print(foo.a)
x / 10 ** exp, exp
box = BoundingBox()
os.chdir(_startup_cwd)
model = UsersInfo
point_neighbors = []
connected = conn.connect(system_name, 445)
print(x - y)
b = np.empty([1000]) + np.nan
__import__(self._subModules[attrname])
2 | 6
F.X
False
print(mat.groups())
C = attack > enemy.defense
password_store = urllib.request.HTTPPasswordMgrWithDefaultRealm()
myseries_three[0]
array2[i] = Array.get(array, i)
tic = time.time()
self.op = args[1]
ROW_SIZE = 100
bytes = len(data)
self.exclude = []
bool(self.arguments), -len(self._weights), self._weights
COMPREPLY = ()
maxValue = -Inf
9
x = 2
num = 1
r = range(s, -1, -1)
x
new_files = files[:100]
GaussFunc(x, height, centroid, sigma)
ss = SSL.Connection(ctx, s)
raise IgnoreRequest()
fig.add_axes(Bbox(fig_coords))
items_to_clean = list(items.objects.get.all().values())
name,
b = -b
print(R)
httplib.HTTPResponse._read_status(self)
dict(zip(assignment_names, average_assignment_score))
(0, 1, 0, 1),
data = np.random.rand(50000, 7)
inner
que = set(d.popitem()[1])
raise
False
xaxis = LinearAxis(ticker=ticker)
func1(chunk)
self.instancemethod = type(self.add_rule)
element
i = 4
sys.version
_6
min_mask &= dist2 > min_d * min_d
1 - test8.txt
cost = db.FloatProperty(default=0.0)
records = {}
s = s + s2
res = p.amap(sleepy_squared, x)
object_values = []
self.column = column
matches.append((xmin, ymin))
a
overall_structure = ZeroOrMore(Group(any_header + Group(ZeroOrMore(text))))
current = next(looking_for)
a |= 16
srcypos = yoff * srcwid
DBSession = scoped_session(sessionmaker(extension=ZopeTransactionExtension()))
trainer.trainUntilConvergence(maxEpochs=100)
ops = (pos, neg) * ceil(len(lst) / 2)
print(instance2 == instance1)
important_names = feature_names[importances > np.mean(importances)]
M.close()
_query = frozenset(parse_qsl(parts.query))
b.Version
tmp = lst[i]
True
many_to_many = {}
deletelogging
iterable = reversed(iterable)
chunk_names = []
ca[:] = bytes
TEMPLATE_DEBUG = False
row2 = adj_matrix[mapping[:row]]
self.obj.__add__(other)
attr = lst.attr
ds1.difference(ds2)
level = 0
np.divide.outer(i, j).sum()
text.set_font_properties(font)
print(server)
python
match = re.match(pat, req)
f = Frame(root)
addCellToPicks(bestCell)
tagger = nltk.tag.stanford.POSTagger(path_to_model, path_to_jar)
writer = csv.writer(m)
frames = inspect.trace()
b,
anchor_layout
delta += 1
retcode = libc.fclose(file_p)
row2 = [150, 200, 155]
d = dict(zip(lVals, [0] * len(lVals)))
progress = int(youarehere / len(toplevel) * 100)
print(base.summary(model))
job_queue = mp.Queue(maxsize=10 * workers_num)
c_values = self.data[c].values
new_page[field] = page[field]
base + datetime.timedelta(offset)
number = lv & 4294967295
top_features = [f[0] for f in top_features]
obj = MyModel()
logbins = np.max(xx) * (np.logspace(0, 1, num=1000) - 1) / 9
pages_horz = 1
idx2 = idx1.tz_convert(tz.tzlocal())
cls
letter = letters[index]
Builder.load_string(kv)
l = list()
debug = True,
0
point_in_plane + proj_onto_plane
xedges = np.linspace(x.min(), x.max(), xbins + 1)
b = np.reshape(a, (60, 50))
restaurant.open_restaurant()
pool = Pool(5)
pylab.plot(y_vals)
self.content = []
ipython - pylab
raise exception.NotAcceptable()
x = (xMin + xMax) / 2
Press(s, speed)
vtk_win_im.SetInput(vtk_rw)
b = [2]
key, iv = derive_key_and_iv(password, salt, key_length, bs)
res
a, b = tee(iterable)
-W900 - -ignore
e
new_inlist = []
tile.H = (abs(end.x - tile.x) + abs(end.y - tile.y)) * 10
n = 10
metadata.write()
class_instance.run()
gid = stat_info.st_gid
sum_ += item
np.argmin((disp * disp).sum(1))
type(self)(self.bar)
some_protobuf_object = SomeProtobufMessage()
content
map[:, 7 * World.MAP_HEIGHT / 4:2 * World.MAP_WIDTH] = -1
casefold = lambda u: str(icu.UnicodeString(u).foldCase())
ebins
c.Wait()
j = 1
2
callable(open)
False
parsed_tree = Tree.fromstring(parsed_sent)
d = []
per_row = []
net.addConnection(FullConnection(input_1, h1))
xnew = np.arange(70, 111, 1)
output[i] = j + 1
transform(1)
item.Value
passthru(f)
model = MyModel()
b
item[attribute.attribute.name] = attribute.value
docs = []
f = lambda x: x + 10
dir_util.mkpath = wrapper(dir_util.mkpath)
sys.modules[name] = module
c = lil_eye((4, 10))
diff = iso_week_day - val.isoweekday()
n = 27
g.project = Project.query.filter_by(name=project_name).first_or_404()
self.data_structure = data_structure
relerr = (p - p0) / p0
read_line_async(AsyncReadHandler)
dct_counts[item] = 1
parts[i & 1] << item
self
print(path)
chain_random(combinations(s, r) for r in lengths if not shuffle(s))
python
ylim = np.inf, -np.inf
ur = UserResource()
y = signal.convolve(x, h)
RES.real = SPMAT.dot(G.real)
scorer = make_scorer(score_func)
amount = int(float(seconds) / limit)
normalizedscores = {}
tmp[i] = extract < double > o[i]
merchant_puzzle(40, 4)
b.left.parent = b
bar._low
f.buffer
callable(k)
mapX[y, x] = x + 100.0 * (d.x - e.x) * (e.z / d.z)
result = []
P = 2.45
temp_dict = AppextItem()
numberOfPayments = float(numberOfPayments) * 12
r = DataResult()
path.reverse()
print(A.toarray())
b,
current_range = [start, end]
A
result[k] = PctOS.pct(df_flat.pair_dict[k])
print(dt)
driver = create_clidriver()
True
print(soup)
starty = obj.ax.y(d[1])
print(reg.pattern)
model = Album
msOutput.Seek(0, System.IO.SeekOrigin.Begin)
str.toCharArray(t, sizeof(t))
recurse()
print(number)
np.__config__.show()
results = []
-app_directory
account.refresh_balance()
A_c = np.ascontiguousarray(A, dtype=np.double)
inputHandler.gather_input()
imgstr = urllib.request.urlopen(imgurl).read()
freq = frq[list(range(n / 2))]
unpackbits(a.view(uint8))
coeffs = [2.0, 4.0, 6.0]
holes = list(gaps_between(table))
b_group.append(c_group | task_b.s())
connection_created.connect(activate_foreign_keys)
c = np.linspace(0, 10, 1000)
arg = [1, 4, -5, 15, -1]
ticks_at = [-abs(data).max(), 0, abs(data).max()]
dis.dis(f)
random_x = np.random.randn(N)
yx
workbook = writer.book
newRow = []
plist.append(p)
browser = mechanize.Browser()
self.content = []
lenM, lenK = lenK, lenM + lenK
modBinarySearch(arr[0:mid], x)
j = 2 ** i
a = numpy.linspace(-7, 7, 1000)
b = 257
mynow = now + tzoffset
fichierTemp.write(contentOfFile)
_addons = {}
hours, minutes = divmod(minutes, 60)
C = 1.2
operator.is_(*pair)
child_paths = adjlist_find_paths(a, child, m, path)
subject_alt_names = []
255
max_width = max(len(filename) for filename in filenames)
X_kpca
pool = Pool(processes=cores)
a
parser_classes = parsers.JSONParser,
total = len(items)
foo = 1
list(map(_convert, node.elts))
message.set_payload(signature)
print(time.time() - start)
newton(lambda x: f(x) - y, 1, f_prime, (), 1e-10, 1000000.0)
csvwriter.writerow(row)
auth.user = session.auth.user
2
location = id(string) + 20
print(hello1.A)
method_name = method.__name__
probs = np.fromiter(map(hashes.get, nested_loop_iter), dtype=float)
m = mock_open()
use_for_related_fields = True
r, prob
newMax = max(nMin, nMax)
nonzero_row_indice, _ = X.nonzero()
u._collect_sub_objects(instances_to_be_deleted)
days_from_jan1 += timedelta(1)
sel.click(val)
lines[-1] = lines[-1][:col2]
[Bar]
times_met[pair] += 1
d = r - x
g = Example()
W_conv1 = weight_variable([1, 10, 1, 1])
cls(path, opener=open)
EXAMPLE2, 120, 0
print(entry)
ret
1
Line2D([], [], **kwds)
blue = 16751018 & 255
email = models.EmailField()
(Set.new(string.chars) - Set.new(ignore.chars)).count
port.getHost().port
view_func = SimpleView.as_view()
earliest_end = min(r1.end, r2.end)
sm = lis2[ind]
X
tmp
n_fraction -= int(n_fraction)
py - down - clause
pred.count += 1
number_of_points = 5000000
start = start.increment()
4
inMemoryOutputFile = StringIO()
self.init_model()
y = 2
profiles = eval(json)
self.inc_intersections(ingredients)
A.test = stuff
rpcResult = blockingCallFromThread(reactor, self.myRPCDoer.doRPC)
a + b
a = rand(12, 12)
prob_word1 = unigram_freq[word1] / float(sum(unigram_freq.values()))
self.l = l
cython.short
True
queryset = Thing.objects.all()
s[i]
read_alan_int(sf + 12) == 24
msg = []
c = ConcreteSubclass()
shape = cols * 2 - 1, cols
fh = logging.FileHandler(LOG_FILENAME)
messages = FallbackStorage(request)
_normal = numpy.random.normal
10
img_local = rank.equalize(img, selem=kernel)
raise
y = model_func(t, A0, K0, C0)
point.X = 4
binary - data
pool_args.extend(args + [low, low + 10000] for args in some_args)
x = 1, 2
is_inherit(dict, Mapping)
buckets.setdefault(key, 0)
doEvenMoreStuff()
ret
self.__graph_dict = values
mock.assert_has_calls(calls, any_order=True)
idx = r.seq(0, 6.28, len=100)
tmp12 = np.column_stack((tmp1, tmp2))
self._block = block or deepcopy(xy8_block)
c.TerminalInteractiveShell.confirm_exit = False
ntoi[x].append(i)
count = np.bincount(zones.flat)
count = self_len + 1
v1, v2 = formula(b1, m1, p1, q1), formula(b2, m2, p2, q2)
max_index = len(self) - 1
_samples = [100, 200]
Z = np.exp(1j * np.pi * coords[:, :, (0)] / 180.0)
test_writer.add_summary(summary, n)
top_matrix[1, 2] = -1
module2.cool_func()
string = chr(65 + module) + string
locals = PyEval_GetLocals()
django
X_test
l = LogCapture()
[git]
session_list.exclude(session_key=session_to_omit.session_key)
self.cached_entry = markdown(value)
np.place(dat2, dat2 == i, j)
self.sum
print(total)
tag
days, seconds = divmod(seconds, 86400)
print(sHeader.SyncByte)
Py_INCREF(w)
msg
value = i % 2 ** 16
HIDDEN = 10
d = PyModule_GetDict(main)
print(self.method_name, kwargs)
2
architecture / common_features
normed_value = 2
color_occupations = np.column_stack((color1_occupations, color2_occupations))
birdsRemain = 4
print(s.check())
polygon_shape = Polygon(xy)
a = list(range(8))
False
EXAMPLEfoo, 60, 0
print(b.a.num)
print(out)
y, x, _ = plt.hist(hdata)
mydata = {}
account = Account(user_list[0])
doc = DocFactory.create(user=self)
remDr < -remoteDriver()
purls = load_urls(prev_urls)
val = df.Interval.values
print(spaceTest(s2))
w_real = 2.0 * math.cos(2.0 * math.pi * f)
ret
cls
self.addCleanup(kill_patches)
name = Column(Unicode(16), unique=True)
prime_str = str(prime)
height_smaller_than_width = tf.less_equal(height, width)
string
testset = random.rand(testSize, dim)
stdout_events_enabled = true
count
t1 = time()
cr = cairo.Context(surface)
writer = csv.writer(f)
observer = Observer()
score = mean_squared_error(regressor.predict(X), y)
junk = sys.stdin.readline()
mode_num = 0
mac = binascii.hexlify(wlan.mgmt.src)
lambda item: filt in item
4
dis.dis(g)
small_df = pd.DataFrame(data=small_data)
unit = unit.groups()[0]
Y = np.arange(-5, 5, 0.25)
gil_init = 1
top.location.replace(document.location)
blackimg = cam.getImage()
name = xmlStrdup(fullname)
c2 = random((10, 10, 10, 10))
a
s = s[s & (s.index > s.name)]
print(path)
sum_table.append(sum_table[-1] + v)
file = sys.modules[cls.__module__].__file__
print(files)
grammar.add_rule(ExampleRule())
h += sys.maxsize
Ref.inc(obj)
x + 2 * y, a + 2 * z
stuff = app.config.somefunc()
fourgrams = ngrams(tokenize, 4)
cls._instances[cls]
elements.add_element(elementname, element)
manager = ObjModel.load(my_objects)
futures = []
context = zmq.Context()
data_max = max(data)
k = n - k
print(wrapper.fill(hamlet))
f = [4]
10000000001000111101101011000011010010110011010101110011010100101101011110101110
path
indices = list(range(0, len(values)))
print(processed_foo)
s[d1.mul(token).any(1)]
username = pw.CharField()
dic = {}
x
run(command + hidden, *args, **kwargs)
hack - local - variables
b = 5
buf = numpy.zeros((n_samples, 2), dtype=numpy.int16)
X = fun(df.B, df.C, df.B.shift(s), df.C.shift(s))
req_bundle = ur.build_bundle(request=request)
counter += 1
td.setDaemon(True)
True
lst
cookieValue = decodeURIComponent(cookie.substring(name.length + 1))
page_groups.append(current_group)
r = ro.r
print(type(a) is str)
v = DictVectorizer()
query = si.query()
and_this()
self._intersections = {}
day = dayno + 1
args < -commandArgs(trailingOnly=TRUE)
self.password = password
doctest.testmod(module, glob=Context(module.__dict__.copy()))
template = np.cos(idx)
spam[s_from:s_to]
d = json.load(open(fname))
df
Console.WriteLine(eventNode.InnerText)
today = datetime.date.today()
sys.stdout.write(format_groups(split_groups(sensors)))
b
guess = (last_guess + x / last_guess) / 2
gdb.events.stop.connect(stopHandler)
anotherfile.name
self.obj = obj
obj_id = ObjectId(_id)
ofs.Second(1) - ofs.Second(1) == ofs.Second(0)
dispatcher.connect(self.spider_idle, signals.spider_idle)
xm = doc.toprettyxml()
T(0 * F + 10 * C)
a_names = list(attrs.keys())
x = np.random.randn(1000)
session.commit()
n = len(board)
True or 0
type(t)
c
x = np.linspace(0, 2, 1000)
ch
sid = get_sid_from_address(address)
print(value)
pygame.mixer.pre_init(44100, -16, 2, 2048)
b = 2
queue_dic = {}
wsgiref.handlers.CGIHandler().run(application)
start, stop, step = args
ofs.Minute(1) + (ofs.Second(1) - ofs.Second(1))
im = trim(im)
isp = False
B = copy.deepcopy(A[0:2])
1, 0, 4
best_group = []
ranges = [[np.min(lats), np.max(lats)], [np.min(longs), np.max(longs)]]
sys.exit()
pk = row.pk
debugLogSQL(sql)
INPUTS = 4
x = HtmlXPathSelector(response)
name_sets_1 = [set(i) for i in list_of_name_tuples_1]
fi = fileinput.FileInput(openhook=hook_nobuf)
print(merger(m))
print(GetAccurateTimeStampString(timestamp))
programs = celery, celeryb
sum += int(p.before)
dis.dis(small_then_large)
results.append(f)
raise ValueError
a = list(range(100))
print(pattern)
data
library(h2o)
print(myStrg)
row += 1
queryString = urllib.parse.quote(queryString)
_pack_ = 1
data = np.random.normal(size=100000000)
f = lambda x: x ** 2
table = SimpleTable(queryset)
print(cc)
parsers.DataAndFiles(data, result.files)
fun_of_mod2 = mod2.fun_of_mod2
NO_GROUP_WRITING = ~stat.S_IWGRP
has_small_string = False
R.append(asi)
simplejson.loads(value)
a, a + 1
foo.py
print(inner.__closure__)
formatted_list = format_exception_only(hexc, hval)
tempfile = im.rotate(270)
submodule.binsha = submodule.module().head.commit.binsha
d
point = [8, 7]
serv._port._realPortNumber
res = 0
_
double ** dataptr
violations2
x = Composite()
print(dirpath)
pdt.normalize(utcnow1)
f(2)
log4j.appender.console.target = System.err
shallPushd = os.path.exists(new_dir)
AwfulHackToGetTheInternedDict.argtypes = ()
abstract = True
self.len = read_limit
exponent = min(int(log(num, 1024)), len(unit_list) - 1)
my_mapping = Mapping()
getActiveFoos()
res = 4.0000000000004
a | b << 1 | c << 2 | d << 5
newick
content_file = ImageFile(figure)
CreateHeap - O(1)
time.sleep(10)
engine.speak(theText)
num1 = 20
data = attrdict(somedict)
-0.5
pub_dict[p.key] = p
[install]
c(val)
tf.addfile(ti, ff)
person_dict = defaultdict(list)
format_string.format(quotient, unit)
deletei
print(i)
compile_catalog = babel.compile_catalog,
hello - hallo - replaces
images.append(Image.open(fname))
False
n = (x ** 2.0 + y ** 2.0) ** -0.5
line = reader.readLine()
allkey = []
help(myclass)
index
[install]
g.db = client.database
cols = [[shape[1] * i / nop, shape[1] * (i + 1) / nop] for i in range(nop)]
raise AttributeError
c = True
count = 0
PyTuple_SetItem(pArgs, 1, pValue)
df_t_shift = df.shift()
main()
s = s.append(b)
ps_output = ps_command.stdout.read()
sintervals = sorted(intervals)
cur = conn.cursor()
nan = np.nan
print(s)
sql % dic
wintypes.DWORD(0),
choice(images)
colormap[categories]
type(meta)
cc = mlab.gcf().scene.camera
splited_list = []
104857600
shifter = np.arange(0, d).repeat(m).reshape(-1, 1).T * m
Options + ExecCGI
index = self.dict[item]
x * x
f = args.file
screen.fill(black)
start_long = math.radians(start_long)
ordereddict
handler = DefaultHandler()
rating = colander.SchemaNode(colander.String())
f = [j for i in contribs for j in i]
key = RSA.generate(1024, random_generator)
prepare(preparation_data)
self.modified = true
self.request = request
q = np.r_[0, np.cumsum(counts / float(n))]
15
n = arr.strides[0]
labels_to_drop = get_redundant_pairs(df)
message_types.VoidMessage,
c = array((20, 2))
pl(time.time())
counter = 0
value
x[last].remove(next)
True
self.iterate(lod)
print(s)
position = models.IntegerField()
dstdraw = ImageDraw.Draw(dst_img)
excDict = vars(builtins)
y = np.cos(x) + 5 * np.random.random(num)
bin_count = 10
-1
m_text = db.TextProperty()
print(write_curve.args[2].token.tvalue)
start = r.loc[:end].argmax()
midnight = datetime.time(0)
r1 = range_list_to_tree([(1, 1000), (1100, 1200)])
200
OLD_STDOUT = sys.stdout
result = x_t * tf.gather(e_t, x_t)
sort / tmp / uniques.txt | uniq - u
a
result = []
False
x = [ichg + 1] * abs(chg)
mask1 = cv2.inRange(img_hsv, lower_red, upper_red)
value *= -1
_raise_type_error()
rows, column_indices = np.ogrid[:A.shape[0], :A.shape[1]]
form = BookingForm()
{C} < ---epsilon - -----{E}
ret.dealloc_cb_p = dealloc_cb_p
allWords = nltk.tokenize.word_tokenize(text)
http = requests.adapters.HTTPAdapter(max_retries=http_retries)
counters = db.get(shard_keys)
request.param
n = x.strides[0]
N, L = len(str), []
opts = Options()
print(split(x))
tc.Start()
10
woof,
rows[(locs[0] - 80) ** 2 + (locs[1] - 80) ** 2 <= 20 ** 2] = [255, 255, 0, 255]
lst = _cache.setdefault(key, [])
-truck
mutation = list(word)
stream = tweepy.Stream(auth, listener)
n = 4
deletesys[modname]
q = ceiling(n / p)
print(instance2 in [instance1])
parser = OptionParser(usage)
f = 440.0
x = itertools.chain(iter(itr), (fillvalue,) * (n - 1))
odestsc = array([0.0])
retval, image = cam.read()
attachments = message.Attachments
win_top = win_geo.top()
clusterLabels = []
previous_plot_range += current_plot_range
counter = counter + 1
c = Counter()
l = li[:]
imgstr = urllib.request.urlopen(imgurl).read()
a = myobject.id.number
valid_FileExtensions = []
logfile.write(line)
circle_imp_point_dist_2d
0
x2 = x1
elmt in wanted_set
values[1] = values
s[1, 2] = 5
a
deleteprefix[-1]
err = lambda p, x, y: fit(p, x) - y
b
x1 = 1, 5
0
min_exp = sys.float_info.min_exp - sys.float_info.mant_dig
removed += [(keys[1], b[keys[1]])]
num
0
sqs = sqs.filter(filt)
pos_tag(word_tokenize(x))
bincenters = 0.5 * (binEdges[1:] + binEdges[:-1])
rows = pool.map(p, list(range(100)))
rights = [(item.get_x() + item.get_width()) for item in artists]
last_interesting = highest_values[len(highest_values) - 1]
logger = logging.getLogger(__name__)
ListOfArgSets = []
x = 5
print(item)
bin_centres = (bin_edges[:-1] + bin_edges[1:]) / 2
a[0, 0] = 100
saveOptions = []
s.dt.components
self.min_set = defaultdict(set)
value, traceback = err[1:]
rootApp.merge(clientApp)
a = int(hx[:2], 16) - int(key[:2], 16)
False
batch = neo4j.WriteBatch(graph_db)
self.get(username__iexact=username)
s = sorted(zip(map(int, points), words))
coord_trans_cache[cur_utm_zone] = wgs2utm, utm2wgs
string = StringIO.StringIO()
in_shape = self.inputs[in_][1:]
max_x = max(p[0] for p in d) + 1
text_pos = [x[idx], y[idx]]
df1 = daily.apply(f)
l = threading.Lock()
idx = np.arange(shape[0])
flattened.append(x)
foo = _num
key = args + (kwd_mark,) + tuple(sorted(kwargs.items()))
n = 2
a = np.array(a)
print(alist)
lvl += 1
print(mailboxen)
self._int = 1
job_for_another_core.start()
id(backup.bar)
dic.popitem()
print(strs)
tagged_sent = nltk.pos_tag(tokens)
a
tmp = list(range(N))
self._record(req.copy(), result.copy())
ip = IPRoute()
j = 0
index += 1
dict = r1.getheaders()
a = list(range(10))
W = W - 0.12
AAA
der_sig_in = asn1.DerObject()
x += 5
distance, index = spatial.KDTree(A).query(pt)
42
sums
px = svm_problem(rx, Data)
r += Fraction(1, d) - Fraction(1, d + 2)
findUnique = lambda s, v: sorted(list(set(findSubs(s, v))))
b.doSomething()
np.float64(5.6).dtype.num
sql = sql % tuple(placeholders)
a.__add__(b)
k -= 1
x += x.T.copy()
res = elt.find(get_tag_with_ns(tag_name, ns=ns))
chomp
d = Decimal(maxint)
proxy = get_proxy()
assert haystack.find(needle) == index
multisetPerms(_s, result + map[i])
EXAMPLE2, 120, 0
f, fn, d = imp.find_module(module, [pluginsDir])
Suppress(integer)
filter = {}
figleaf
sio = StringIO()
result[0]
print(A)
get_pairs_children = _get_pairs(ch, cat, new_path, new_idx, found_cat)
configuration.conf
tot = 0
servers = [MainServer(), DownloadServer()]
self.in_memory_zip.seek(0)
D.__eq__(4)
self.connectedProtocol = proto
queue[0]
p.name()
test = array([[tmp, tmp], [tmp, tmp]], dtype=object)
X = X.toarray()
rowDict = row.asDict()
columns = collections.OrderedDict()
int_start = int(start / increment)
sorted_Ar = Ar[(sorted_idx), :]
alert_read_criteria = copy[alert_status] >= 1
i, j = 2, 4
len(a)
people = results
values = arange(10, 26)
c = 0
text
currentCodec = encodingMap[ch]
slugify.slugify(username)
homeAdvantage = W[0][0]
print(key, value)
font_paths = mpl.font_manager.findSystemFonts()
Parameter
classRoster.append(newStudent)
y is pd.NaT
instance = clr.file.MyClass()
deletetb
s = s + term
pprint(test.__globals___)
sort(lists[0])
mask = TAP_MASKS[reglen]
y, x = np.ogrid[-radius:radius + 1, -radius:radius + 1]
number = int(linelist[0])
inds = np.ravel_multi_index(data.T, dshape)
network = splitNet()
model_ols.fit(X[iStart:iEnd], y[iStart:iEnd])
chocolate = 4
objects_prefetched = PrefetchWorkaroundManager()
user = User.objects.get(user=user)
htwin = htrot * np.hamming(N)
black
S = list(str)
result2 = pcrscpp_rx.replace_copy(bigstring)
filename = filename.lower()
dct[op](a)
c.NotebookApp.open_browser = False
loaded_mm = ctypes.cast(id_from_file, ctypes.py_object).value
db.add(p1)
library(h2o)
app = Klein()
w = np.cumsum(x + np.random.uniform(-delta, delta, n))
t2 = time()
n = a.size
y = x.round()
user = models.ForeignKey(User, unique=True, null=True)
inf = open(file_name_given)
folderTree(namespace.Folders)
value in grid[row]
print(ast.dump(ast.parse(inspect.getsource(constraint))))
ret
True
print(mask)
start = time.time()
cb = root.register(callbackFunc)
image = cam.getImage()
1 - sys.float_info.epsilon
encoded_dict = urllib.parse.urlencode(mydict)
counter.count += 1
self.value = value
print(session.access_token, session.access_token_secret)
edgePoint
EXAMPLEfoo, 60, 0
s = wx.ScreenDC()
isfixed
ipList
deletedf
execute(update, hosts=last_five)
res
lo = mid + 1
timeit.Timer(union).timeit(10000)
identity = VCrypto.lazy().dia(1024, purpose, personal, password)
average_of_all_assignments = grades.mean(axis=1)
builder.redirectError()
exit
print(dt)
choices = np.random.randint(len(perms), size=nrows)
a = numpy.arange(10000000)
results = simplejson.load(response)
self.stop_serving = False
isColor = 1
w = Worker()
verifier.update(data.encode())
bin_counts = np.random.randint(50, size=len(bin_locations))
dy, dx = np.gradient(p)
asc, desc = [], []
stack = []
System.out.println(index)
max_y = max(p[1] for p in d) + 1
partitions = client.topic_partitions[topic]
distances[adj[0]] = adj[1] + distances[next_node]
matrix[r + 1][c]
print(epoch)
dis.dis(no_unpacking)
index = data[i].index
cond = co.co_name == code.co_name and co.co_code == code.co_code
exec_date = date(2009, 11, 6)
cal = Calendar(SUNDAY)
app.jinja_options = Flask.jinja_options.copy()
main = glib.MainLoop()
i = j
b = hashable(a)
False
step = self.steps.current
ud = UnicodeDammit(content, is_html=True)
print(node)
mime_root.attach(mime_text)
S = numpy.array(s)
a = [1, 2, 20, 6, 210]
self.factory = RequestFactory()
sleep_time = start_time + t - time.time()
master, slave = pty.openpty()
get_truth(1.0, operator.gt, 0.0)
python
items
a
start = timer()
n = len(pool)
keyDER = b64decode(key64)
numMonths = 12
resources = [(test(n), n % 2) for n in range(10)]
s = example.Session(27)
Apple = 4
s = DBSession()
FIND_PACKAGE(PythonLibs)
df = DateFormat(dt)
x = y = 1
background = np.argmax(labelCount)
directory, file_name = os.path.split(abspath)
chain.append(getRecipe(item, quantity))
db = client.localhost
sum(map(fractions.Fraction, txt.split()))
inputElement.clear()
x
p = u.load()
TestResult.addError(self, test, err)
sql._write_mysql = _write_mysql
real_valued = r.real[abs(r.imag) < 1e-05]
plt.pcolor(XI, YI, ZI)
nf = tempfile.NamedTemporaryFile(delete=False)
parseTree(child)
Cl.tocsr()
out = cherr.read()
a = list(range(1000))
a
Text = title
f = InterpolatingFunction(axes, data)
a, floc, scale
os.close(handler.fd)
get_name()
numbers
op.bulk_insert(ClientCredential, clients)
A = 200
cls = getattr(module, type_)
t1 = time.time()
colNumber = 0
clean.clean(doc)
t = linspace(0, len, len * rate)
A = bsr_matrix((T_Arm[:n].flatten(), (row, col)), shape=(5 * n, 2 * n))
x.shape = len(x) // chunk_size, chunk_size
handle(document)
gc.collect
k = 0
hist = normalize(o.histogram())
f._instance_setitem = types.MethodType(new_setitem, f, Foo)
raise NotFound()
reshaped = []
txn = db.begin(write=True)
disable = R, C, W, E
suite = unittest.TestLoader().loadTestsFromTestCase(TheTest)
DefaultVal
country_data[1] = tag.string
saved_blob_string = retrieve_string_from_file()
out1[0][0]
ARRAY.as_ptr()
split_date = udf(split_date_, schema)
last_choices = collections.deque(maxlen=min_dist)
tx2, ty2 = x2 - cx, y2 - cy
df2
elapsed_time = timer() - start
s = keyPoint.size
PyTuple_SetItem(pArgs, 0, pValue)
old_max = 16000
january_first = datetime(2009, 1, 1)
n = hashlib.sha512()
oRS.MoveNext
tokens
month = sourcedate.month - 1 + months
storage[value]
Event.objects.filter(query_yesterday | query_today)
print(dateForm)
assert PyDict_CheckExact(dict)
l
data = json.loads(response.read().decode())
__pyx_v_i = int(0 + 1 * __pyx_t_2)
foo = Foo()
test_result = run_test()
Doc.VAR2 = val2
log2int_slow = int(math.floor(math.log(x, 2.0)))
messages = []
vals = np.zeros(shape=(n, weights.shape[1]), dtype=int)
rows, cols = np.indices((25, 25))
char * get_time()
gzip.GzipFile._read_eof = _read_eof
dat = np.zeros((siz, siz))
topics = frozenset(topic for tutorial in tutorials for topic in tutorial)
conn = ftplib.FTP(**kwargs)
largest = max(data)
matches = []
json.load(fin)
a = sin(phi_Lat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(phi_Long / 2) ** 2
batch_index = 0
a = MyClass(42)
Bx, By = np.meshgrid(Bx, By)
filename
b or [0]
False
it = iter(seq)
g.r = 4
filt = getattr(column, attr)(value)
8
_ComplexArrayTypeBase.from_param(obj)
show(board)
folder = convert_url_path_to_folder_path(request.path)
c = comb(n, start_k)
data = data2
model.id
list_length(PyListObject * a)
newScriptText = xmlFile.createTextNode(script.description)
df2,
future = datetime.datetime(t.year, t.month, t.day, t.hour, f_minute)
__setitem__ = modify_method(list.__setitem__, 1)
a = -0.0
i -= 1
b = [1, 2]
count += current_count
pos = randint(0, siz - 1), randint(0, siz - 1)
yvals = list(np.random.normal(0, 1, 10)),
figleaf
num_of_fs += 1
ctx = PyV8.JSContext(scope)
n.items < -length(items)
mm = mmap(f.fileno(), 0)
n_arrays = PyObject_Length(list)
False
end - of - line
id = random.randrange(sys.maxsize)
A.f1
results = []
a == b
self.put = _put
M.bar
y = fit_df[col].values
t[0, t2]
sum = dll.add(c_int(N), arr)
rows[(i), :len(array)] = array
0,
print(project_titles)
buffer.resize(size)
self._saved_page_states.append(dict(self.__dict__))
X, Y, Z = np.mgrid[x0:x1:n * 1j, y0:y1:n * 1j, z0:z1:n * 1j]
print(h / k)
b.x[2] = 4
thisPath < -thisPath + n
myModule.variableX = 10
event, binder = wx.lib.newevent.NewCommandEvent()
print(org_month_dict[org, m2] & org_month_dict[org, m1])
r = Redis()
stop = -1 if step < 0 else length
offset = int(offset)
ctx = ssl.create_default_context()
b_tokens = set(b.split())
ll.extend(u)
print(v)
s1, s2 = s2, s1
COMMIT
_MakeMyClass
token_idxs_embedding = tf.slice(token_idxs_padded, [0, 0], [-1, maxlen])
P[v] = u
myseries_one[0]
duration = int(duration)
d = XORDataSet()
1.291257290984504
toto_type.define(toto.class_type.instance_type)
ProxyFix(app)
help = action.help
pHeader = pointer(firstHeader)
mtime = st.st_mtime
tiles_letter.remove(rand)
r.raw.decode_content = True
subcategorySearchLink = urlparse.urljoin(response.url, subcategorySearchLink)
a, b = tee(iterable)
age = datetime.utcnow() - born
beginTime = time()
temp += 1e-08
print(value)
c = Client()
plt.hist(sample, bins=np.arange(m) + 0.5)
s.description
size += 95
buffer_deque.append(item)
o = choices[0]
sCmd.expect(pexpect.EOF)
r0.set(K[i], v)
email = fields.Str(can_update=False)
img = getsnapshot(vid)
cli = str(input(PROMPT))
unested
SUDO_GID = 1001
toAdd = xyzCoord[i]
plugin_name_choices = get_active_plugins()
q = PathTest.expanduser()
pid = proc.pid
gmm = sklearn.mixture.GMM()
corp = [dictionary.doc2bow(text) for text in texts]
z = zip(hyp, ref)
print(data)
adj[i, 1] = y
doc.build(parts)
a
t_start = time.time()
True
data[c.course_title] = c.grade
print(neighbors)
tests
m1 = months[mindex]
foo = get_odd_numbers(10)
vbdrecord.empty = true
tmshValue = Combine(tmshString | dblQuotedString.setParseAction(removeQuotes))
theta = simulate1(theta)
t2 = [4, 5, 6]
self.input_cursor = int(0)
y, X = zip(*((p.label, p.features.toArray()) for p in df.collect()))
b = Baz()
drawBoard(boardFrame, scale)
itertools.repeat(value).__next__
dy = y2 - y1
iris = load_iris()
self = Foo.happy
xmlHttp.responseText
mod1.pyx
method_names = [(klass.__name__ + m[0]) for m in methods]
s
a.initializer.run()
large_string = large_string[:-200]
func(weak_ptr < MyClass > wp)
vars = globals()
foo
xs = []
print(final)
python_tree,
domain = conn.lookupByName(domain_name)
startupinfo.wShowWindow = subprocess.SW_HIDE
delta = joined - joined.shift(axis=1).fillna(0)
map[item] = new_command
in_txn.put(key, im_dat.SerializeToString())
self._changeStateOf(ob, tdef, kw)
depth
df_g = df_y.groupby(func.hour(df_y.date))
False
s.oneFunction(lists)
data = []
smime_object = SMIME.PKCS7(m2.pkcs7_read_bio_der(bio._ptr()))
lcs[::-1]
message = fd.read()
stdout = os.dup(1)
device_num = 0
string
nL = W % 256
a
f10 = lambda x: iterate(f, 10, x)
driver, xenv = unpack(context)
print(cbh)
gateway = Gateway(**validated_data).switch_db(self.orgid)
main()
print(attribute, value)
rect(bp - rate, ybot, bp + rate, ytop, col=seq(cats), xpd=NA, border=NA)
sentencesProcessed = []
parser = objectify.makeparser(remove_comments=True)
sum = 0
print(t)
ADDITIONAL | Additional
nH = W // 256
to_select = set(to_select)
results = e.gather(futures)
print(e)
a = list(range(6))
self.start += 1
n_int /= 10
response_buffer = StringIO()
m.drawcounties(color=countyColor)
xd.sheet_names
self.ddof, self.n, self.mean, self.M2 = ddof, 0, 0.0, 0.0
vector < Rect > boundRect(contours.size())
s4 = np.row_stack(set4)
K += w2 * numpy.exp(-mu * chi)
n = np.empty_like(series)
stop = 0
t.interval(alpha, df, loc, scale)
fnc
instance
s
x = [([0] * (len_2 + 1)) for _ in range(len_1 + 1)]
max_groups *= int(x)
x = x + [2]
thetas = np.multiply.outer(2 * np.pi * t_full, w)
False
myRandom = Random(anewseed)
x[1]
theta1 = theta1 - step * dEdtheta1 / n
arg1, arg2, rest
updates.add(newVenue)
f = plt.figure(0)
reqs = [l.strip() for l in req_file.readlines()]
skf = KFold(len(Xy))
o = p.getObject()
a = 5
y1 -= 1
y_offsets = YY - Ndy.T
r.squared
Ax = bp.axes[0]
language = LANGUAGE_MAPPING[language]
self[args]
d
color_left = getColor(leftPixel)
2
coding = icu.CharsetDetector(data).detect().getName()
print()
output
window = Display().screen().root.query_pointer().child
inds = {e: i for i, e in enumerate(unique)}
help(libvirt)
print(data)
original_source = original_file.read()
print(item)
partition = chain(partition, iter([justseen]))
df
result = func(*args)
print(apply2d_along_first(trace, data))
excptDict = vars(exceptions)
y = 0
d
toto_type = deferred_type()
base_url = get_base_url(response)
np.tanh(1477.92 * temp) / temp
df = s.unstack()
this(null, tree)
-pip
print(arr)
group = Group(LBRACE + ZeroOrMore(leaf) + RBRACE) | leaf
table.selectRow(row)
y = x
result == expected
masterSet = masterSet.union(setA)
hcwh
PROCESS_TERMINATE = 1
modname, ext = os.path.splitext(filename)
rootApp = Bottle()
a
double = lambda x: x * 2
d = 0
people_left.remove(p)
print(boundaries(42))
df
keyValues = defaultdict(list)
func = mod.node.nodes[0]
99.98000000001424
size
Song.createTable()
b = 2.568
d = myarray[i][j2]
value = command.args[1]
print()
self.edit_widget = edit_widget
sets = (set(l) for l in posts)
f.write(script)
utc = pytz.utc
dis.dis(test5)
session = self.new_session()
sx = arr.shape[0]
parser = c_parser.CParser()
proceed_to_close()
create_table(dct, columns)
Lx, Ly = ((L2, L1), (L1, L2))[len(L1) <= len(L2)]
img = pygame.image.load(bytes_io)
print(text)
EXAMPLE2, 120, 6
a1_tuple = xlrd.xldate_as_tuple(a1, book.datemode)
print(myClass.randomMaths(42))
valid_value = self.valid_value
a = temporary_expr_result
sound = pygame.sndarray.make_sound(buf)
r
t / count * 1000
speeds_np[speeds_np > 0].mean()
figure, imshow(gr, [])
False
s = Mtx.sum(0)
s = Session()
b = BitArray(uint=s, length=10000)
col in self.d[row]
{{poll}}
first_index = -1
r
[production]
colors = []
annotator
job = beanstalk.reserve()
stream = tpl.generate(data=range(10000000))
plist = psutil.get_process_list()
suite2 = FixtureSuite(testCases)
cp = nltk.RegexpParser(grammar)
output_string
[EOF]
annulus_sector_area_2d
c11, c12 = halveCubic(pair.cub1)
c21, c22 = halveCubic(pair.cub2)
a = 1, 2, 4
flip[j].append(i)
xright = max(ax, bx, cx)
ledON
ledOFF
l = list()
toRemove = [0, 2]
x = round(x)
current_commit = last_commit()
trainer = BackpropTrainer(net, ds, learningrate=0.05, momentum=0.99)
__metaclass__ = models.SubfieldBase
s = parse(s, relations=True, lemmata=True)
extractor = parallelTestModule.ParallelExtractor()
wrapped
event.accept()
new_tuple
print(str(res.read()))
deleteself._x
reactor.callInThread(CommandProcessor().cmdloop)
trans = conn.begin()
one_zero_sum = [sum(TLabels[dist_zeros]) / t, sum(TLabels[~dist_zeros]) / t]
my_iters = tee(the_list, count)
self.config.optionxform = str
self.buffer_size = buffer_size
client = SimpleClient(brokers)
l
print(vertex)
letter_groups[name[0].upper()].append(name)
os.remove(tmp)
print(pixels.shape)
dt
bob, 5, M
value
v = d1 / (d1 + d2) * (v2 - v1) + v1
finalFreq = sorted(iter(d.items()), key=lambda t: t[1], reverse=True)
self.g = color.g
x > -2
answer - 1
self.callback = callback
x = foo()
score[winner] += 1
b = [7, 8]
finalinfo = {}
p1 = chr(254)
config.operation_timeout_in_ms = 15000
count = 0
usage = parser.format_usage()
strategy = chooseStrategy(operation)()
liststore = gtk.ListStore(str)
d = 0
deleteremaining[remaining.index(start)]
serializer = CommentFlat(instance=self.queryset, many=True)
print(X)
outf.write(contents)
app = TerminalIPythonApp.instance()
print(alist)
keyValues = defaultdict(list)
print(serializer.getvalue())
v_hist = NP.ravel(v)
bar
dic[operator](opd1, opd2)
url_adapter = reqctx.url_adapter
rvs = stats.beta.rvs(2, 5, loc=0, scale=1, size=1000)
deletex
8
graph
hello
callback
serialized_inventory = serialize(inventory)
python - O
s
list = []
a = 1.0
_default_decoder.decode(s)
N1 = math.floor(275 * month / 9)
a = 2
x
tb_list = traceback.format_list(tb_list)
yearmonth = YearMonthField()
p1x = tx1 * cosang + ty1 * sinang + cx
copy + item
axis = 1
label = str(node)
disassembled = urlparse(picture_page)
c = Counter()
f = ftpslib.FTP_TLS()
A = npr.randn(m, n)
self.dirname, self.filename = os.path.split(path)
runs_scored = float(league[team][0])
next_task_name, next_task_args = self.task_q.get()
~arr
cell = CellRendererPixbufXt()
shuffle(question_IDs)
p = argparse.ArgumentParser()
MYSIGNAL_LISTENERS = print_howdy, print_seeya
dns_cache[args]
dd < -data.frame(x=rnorm(15), y=rnorm(15))
x = (1 - q) * x + q * np.random.normal(size=len(t))
ipython
batchRequest.getEntries().add(batchEntry)
model = Transaction
cat_columns
endforeach
writer.add_summary(summt, tp[idx] * 100)
data = s.recv(size)
num = 42
m.background = mapnik.Color(0, 0, 0, 0)
exit(e)
X, y = data[:, 1:], data[:, (0)]
net.addConnection(FullConnection(input_2, h2))
c = Client()
self.cache[regex_string] = re.compile(regex_string)
batch[batch_index:batch_index + remaining_space] = context[0:remaining_space]
jobs = scheduler.get_jobs()
newitem = QtGui.QTableWidgetItem(item)
seek_offset = 0
node_or_string = node_or_string.body
M.login(getpass.getuser(), getpass.getpass())
other_file
self.depth -= 1
item = self.ui.comboBox.model().itemFromIndex(index)
b[6:10]
print(r)
1
raw = f.read()
ccn
val
ff = f.ravel()
new_y
document.webkitExitFullscreen()
counter += 1
mid = chr((ord(a) + ord(b)) // 2)
TS
auth.settings.register_onaccept = post_register
Foo.happy.some_behavior = happy_behavior
[n]
matrix[r - 1][c]
s = s[SOME_CHUNK_SIZE:]
np_pos = 1, 1
c < -x
self.name = name
self.name = name
scale = ram.std()
twine
num_linkages = sentence_parse(sent, opts)
0
node = character.eHips
other += 1
n = 2
p1, = plt.plot(z, Ua)
pkts = []
url_info = urllib.request.urlopen(RSSurl)
collend = p + 1
idx = mask == 0
self.r = color.r
params.update(defaults)
dead()
value[0] = True
c += arr2[i + 1]
Exec = python / home / your_path / script.py
[7.0, 0.5, 0.0, 0.12],
A[A <= 0] += 1
inverted = {}
generators = list(make_iterator())
label_rev = {v: k for k, v in list(FINDER_LABEL_NAMES.items())}
json = json_util.dumps(query._cursor)
arg1 + arg2
download_miniconda
10
log_observer = ScrapyFileLogObserver(logfile, level=logging.DEBUG)
temp += 1
x = 0
details[key].append(detailsItem)
10
print(bool(exp2))
postvars = {}
poller.unregister(fd)
group.link_set.clear()
m4 = int(np.ceil(field.max()))
n = 1245427
Xf = arange(10, dtype=float64)
a if not b else gcd(b, a % b)
12
q_filter_needed_1 = []
nssp = NSSpeechSynthesizer
doc
deletelines[index]
done, rema, succ = starf[0:2]
p.open_live(dev, 1600, 0, 100)
happy = 1
print(index + 1, i)
my_object = object
print(sec_perf.reindex(columns=secs))
ec2 = boto.connect_ec2()
cov.load()
deletei
FilePath = path
self.X_without_NaNs = X.copy()
app = QApplication(sys.argv)
result.append(format_str.format(width=widths, row=line))
res = boolExpr.parseString(t)[0]
obj.actor.position = [0, 0, 0]
cli = click.CommandCollection(sources=[cloudflare, uptimerobot])
nexts = cycle(iter(it).__next__ for it in iterables)
build_audio_response(url, should_end_session=True)
obj
server_class = oauth2_settings.OAUTH2_SERVER_CLASS
add = tf.add(v, c)
list_
print(st)
rem_delta = self.remaining_estimate(last_run_at)
browser = mechanize.Browser()
K = {min(E)}
name.bug(self)
subList
bson_obj = BSON(s)
hello.exe
data = np.array([[1, -1, 20], [1, 1, 50], [1, 1, 50], [2, 0, 100]])
x = 1.5
myval = arg2
max_digits = 14
n = 1
aa.save(argument)
_, y2 = ax2.transData.transform((0, v2))
chunk_head = png_tag + data
print(n.contents.seconds)
cov.stop()
generate_logger()
print(t1.timeit(1000) / 1000)
x, y = data
a, b = [1, 2]
x = np.random.normal(i + 1, 0.04, len(y))
0
primes.push_back(2)
f.m = 6
r1 = next(file1)
imageFileToConvert = Image.open(sourceFilePath)
print(host)
file_list
p
extensions = mr.developer
results = [s.value for s in string_buffers]
a = 100
print(p2[:sz])
frameGm.moveCenter(centerPoint)
4
item = next(it)
Debugger().register(app)
zf.extract(infos[ix], directory)
write_randomly_to_one_of_the_N_files
data = int(_hexlify(data), 16)
s.magicSplit()
mystruct_1.i = 2
p_rtns_md = (p_rtns / cummax(np.hstack((0.0, p_rtns)))[1:] - 1).min()
num_annots = len(annot_mappings)
jointProbs, edges = np.histogramdd(data, bins=numBins)
month_expr = oneOf(months)
measure_del()
httplib.responses[200]
app(_)
self.event = threading.Event()
print(cookieprocessor.cookiejar)
a
train_writer.add_summary(summary, n)
stop = np.append(start[1:], c.size)
python
mw.content2 = TreeWidget()
obj.texture_update()
id(a) == id(b)
self.clearDirectory()
[paths]
menuItem_Task = self.taskMenu.addAction(item[1])
means = np.bincount(inv, weights=given_array.ravel()) / cnts
raise Return(temp + 1)
logi = [operator.lt, operator.gt, operator.eq]
self.end = end
c *= n - k + i
ax
table += df.to_html()
N = 100
main()
f_curried
index.exposed = True
A
getsizeof(first)
ExposureTime(1, 60)
pth = distutils.sysconfig.get_python_lib(plat_specific=1)
pos, prob, state = S.run_mcmc(pos, Nsteps)
mu = 1.0 / numpy.mean(chi)
df1.columns = cols_saved
2097152
exec(new_src, bs4.element.__dict__)
key = reg.OpenKey(classes_root, path, 0, reg.KEY_SET_VALUE)
blah = []
M.login(username, password)
0
last = authors[-1]
channel = channel.lower()
training = data[:5]
ax1 = fig.add_subplot(2, 1, 1)
d = xmltodict.parse(f, xml_attribs=xml_attribs)
record = install.txt
query |= si.Q(word)
current = current.rest
ii = itertools.count(w[2])
C = ones((4,))
df1 = test_runs.loc[idx]
convert_variables.num_converted = 0
A.foo = foo_wrapper(A.foo)
self.request = request
ENDPYTHON
True
request = ml.projects().predict(name=modelName, body=requestDict)
stack.append(char)
l_neg = np.array(classif.classify_many(neg[100:]))
x_series = []
pool.map(processFunc, hostnames, 1)
print(x)
fh.setFormatter(formatter)
var1 == var2
black = 0, 0, 0
print(each_val)
rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)
o(0, 0) - ------+(0, 1) - ------+(0, 2)
x = maximal_difference_seeder(x)
x1.update(x2)
a = T((1, 2))
user = user_name
opt.text = strText
Bob
df
root_win = screen.root
[4, 24],
r = 1
ret = copy.deepcopy(x)
z = numpy.zeros(1000, numpy.uint8)
grouped_2Darray = np.empty(mask.shape)
img = cv2.blur(img, (7, 7))
False
maltparser = MaltParser()
mixins.ListModelMixin,
progress(bytes_total, bytes_total)
assert data[1].lc.line == 4
admin.site = mysite
x
commitctx = repo.commitctx
xa = np.random.rand(10)
server_ip = globals.server_ip
data = numpy.asarray(series)
timing = dict()
pid, retval = os.wait()
w = a * (1 - a) ** i
pixmap.save(buffer, fmt)
gr1 = greenlet(test1)
network = pickle.load(p_input)
print(n)
it2 = map(itemgetter(1), it2)
extra_link_args = -lgfortran - lquadmath
it = list(range(6))
memoryview(a0) == memoryview(b1)
res.append(B)
BX_OUT = Bx.copy()
desc.append(i)
other_stuff
future = time.time() + 600
line_c = [A[i % i_max][j % j_max] for j, _ in enumerate(line_b)]
2
x = 10
counts = ps.value_counts()
temperature_info = w.MSAcpi_ThermalZoneTemperature()[0]
processes[n] = p, a
a
0.5
print(x509_pubkey)
root.sides = [10, [1, 2]]
rect(inds, inds, 1.0, 1.0, color=colors)
display_with_gui(result)
EXAMPLE2, 120, 6
SO_RCVBUF
highest_values[l - i - 2] = highest_values[l - i - 1]
lines = []
sample_rate = 0.001
result.cumsum(out=result)
data = self.rfile.read(length)
self.travel_time_strm = npr.RandomState().seed(seed=self.seed)
range_expr = from_expr + till_expr
shp = A.shape
tag = next(parser.stream)
head, tail = l.popleft(), l
pdtnow1 = datetime(2014, 1, 1, tzinfo=pdt)
pending -= 1
root_path = path_parts[0] + app_id
matrix = cv.fit_transform(things)
filename2 = sys.argv[2]
fnt = ImageFont.load_default()
map(q.put, (-1 * magicComp(item, stuff) for stuff in set2))
l.extend(l2)
try_match
explore(path)
x, y = a
canvas.height = img.height
ball.x += math.sin(angle)
mailer.communicate(dialog)
start = time.clock()
im = Image.open(os.path.join(dirname, filename))
fact = math.factorial(i)
print(IsIronPython())
l = [(k.last_modified, k) for k in bucket_files]
used = Array(data.length).fill(false),
pending -= 1
print(results)
s.split(splitter)
square = lambda x: x * 2
count = 2
n = 50
c = comb(start_n, k)
print(t2.timeit(1000) / 1000)
x = w / 2
self.params = [self.w, self.b]
lek = qms.last_evaluated_key
bool(set(test) & test_characters)
g
any(map(s.__contains__, substring_list))
theSum
substring_counts = Counter(substring)
fuzz_frame = radiotap / dot11 / dot11probereq
notebook_util.pick_gpu_lowest_memory()
input = generate_random_input(size=n)
ret_code
end = intervals[-1]
row[1] = row[1].title()
end_long = math.radians(end_long)
__iter__
print(re.args, re.message)
host.xaxis_date()
self.dictList = dictList
print(showtime)
Camry98
image = np.array(pilImage)
person.make_statement
trueLine = trueLine.split()
set = True
N = 1000000
end_time = 120
strcpy(time_str, time_vec[i])
wgs = osr.SpatialReference()
unicode_modifiable(PyObject * str)
python - slugify
efg = alotoffunc.efg
sysTemp = tempfile.gettempdir()
progress = step / num_files
y1 = np.sin(x)
print(kwargs)
node.right_child = kdtree(point_list[median + 1:], depth + 1)
raise HTTPUnauthorized
stratsample.sort
print(b)
cache[n] = 1
python
self.scan_once = json.scanner.py_make_scanner(self)
rect(bp - rate, ybot, bp + rate, ytop, col=seq(cats))
class_b_inst = get_my_inst(500)
m < -10
playerList[i] = [whateverDataYouWantToStoreAboutEachPlayer]
zipdata = StringIO()
category_dicts = [dict(tuples) for tuples in grouped]
results = []
cooperate(worker(jobs))
special = dict.fromkeys(string.punctuation + string.whitespace, True)
tup = a, b, c, d
x = Empty()
s = eval(input())
a + b
model = Author
df
a
msg.setTo(room)
to_show.append(name_to_item_mapping[file])
print(replace_with_this)
user_result = json.loads(user_result_str)
idx = np.arange(shape[2])
dfUnstackedNoIndex
cls = str(obj.__class__)
0
node.location = point_list[median]
c = 5
T = cumulative[-1][0]
retrieve_job = vault.retrieve_archive(archive_id)
plt.plot(t1, y1)
out += c
node.s
print(str)
title = f.readline()
last_modified = feed.modified
Kt += w1 * numpy.exp(-mu * chi)
cp.get(section, key)
bar = 1
self.limbs = number_of_limbs
session = pkcs11.openSession(theOnlySlot, CKF_SERIAL_SESSION | CKF_RW_SESSION)
print(len(MyCache.cache))
r.app_name
weekend = set([5, 6])
temp = float(buy) - float(sell)
print(x)
ratio = lambda x: x.value_counts(normalize=True)
matrix[r][c] = random.randint(0, 1)
thing1
h = zip(r2, r)
xt = torch.fromNumpyArray(xn)
grp = []
x, y = pos[1]
saved_name = original_name
df[feature] = le.fit_transform(df[feature])
header = next(csvreader)
s[i] = create_string_buffer(8)
days = weekdays._days_cache[current_locale]
f = MyObjectLoadForm(aDict)
self.template_name = page
y = stats.uniform.rvs(size=100)
im = Image.open(os.path.join(dirname, filename))
gtk_container_remove(GTK_CONTAINER(parent), old)
cells = client.GetCellsFeed(key, wks_id)
employees = []
first = queue.enqueue(first_job)
chain_nodes = lambda nodes: map(compose_mult(nodes[1:]), nodes[0])
data = [1, 2, 5, 10, -1]
self.func(value)
self.app = app
self.key = key
self.file_2 = file_2
result = []
res = {}
x = random.randint(1, 10)
success = False
self.a = val
self.log.Hide()
df
use_cdn = No
d = 0
a = str1[:i + 1]
print(err)
result = M.A1
res = boolExpr.parseString(t)[0]
i = 0
c = Client()
tic = time.time()
np_query = np.array(query)
b, x = inc(x), x + 1
0
do_all = _consumer.extend
lower = Vertex()
dfrm
-1.0
end = self.timer()
pca.components_
a, b, c = pattern.search(x).groups()
index = offset_map.bisect(1275)
form = SpecieForm
ctx.check_hostname = False
au_corr = df.corr().abs().unstack()
hist_fit = gauss(bin_centres, *coeff)
level = level - 1
module_name = module.__name__
test.body[0].name
self.cached = get_dict_with_file(self.file)
names = list(items.keys())
list1
y = y[y.start < y.end]
char = match.group()
ssh_username = _username,
saw_first_char = False
logfile = log.txt
end = value
empty_copy_2.dtypes
pid, fd = os.forkpty()
next(callback.v)
val = queue.get()
open(myfile)
rd = rdelta.relativedelta(d2, d1)
ans
mystruct_1.x = 1.242
x = tuple(islice(iterable, n))
bin_edges = stats.mstats.mquantiles(data, [0, 2.0 / 6, 4.0 / 6, 1])
v *= 255
df_ = df.copy()
subject = self.format_subject(subject)
xedges[0] -= 1e-05
y = tuple(y for x, y in data)
level = level + 1
tkagg = False
webcodestyle.css
repeats = []
serialized_student_detail = studentSerializer(student_detail, many=True)
subparsers.required = True
pow *= 2
model = LogisticRegression().fit(X, y)
index, data = row
id = client.id
x = point.x()
print(word)
i < 0
np.sum(self.__src[row])
rec = next(cursor)
word = elem[0]
st.norm.ppf(0.95)
yy = set(y)
child = fdpexpect.fdspawn(command.stderr)
translation_unit = index.parse(source_file_path, file_args)
7
list(cls._cache.items())
readline.read_history_file(historyPath)
dest = sys.argv[2]
print(settings)
person = personToDelete[0]
self.grammar.parseString(s)
d[2]
s = np.sin(2 * np.pi * t)
res = gt.boykov_kolmogorov_max_flow(g, src, tgt, cap)
d += delta
val = URLValidator(verify_exists=False)
-s
D[10:15]
data = noisy_data([0.5, 2.1])
importances.plot.bar()
print(len(MyCache.cache))
threads = tf.train.start_queue_runners(coord=coord)
x if some_boolean else y
compiled_regex = compile_my_regex()
cam = cam_iface.Camera(device_num, num_buffers, mode_num)
iph.ttl = iph.ttl - 1
visit(curRoom.westNeighbor, curX - 1, curY)
Pdb
nbus = 40
p = multiprocessing.Process(target=grab_hdd_temp, args=(hdd, queue))
a.make_help()
print(a)
clock.tick(60)
ses = lt.session()
a = ABC()
FocalLength(107, 25)
curTID = i
L[i] = elem.capitalize()
color = pal[im[x, y]]
dev_sda1.size = 50
pygame.draw.rect(screen, YELLOW, yellow_rect)
x = spmatrix.ll_mat(10, 10)
suffix = 0
trecias_m = df_data[60:90].reset_index(drop=True)
m = PyModule_New(name)
output2 = [0] * len(x)
pyparsing.quotedString.reString
output[0], output[1]
leaf = Group(name + EQ + expr + SEMI)
x_sample = x[idx]
result = memoryview(hex(result))
pj.close_to_another_point = True
cursor = self._connection.cursor()
k_start = int(math.floor(f_start / f_step))
update_mandel = True
stack = [self.entities]
frame = self.page().mainFrame()
Database is newdatabase
print(kwargs)
d = x + y
n_fraction = n - n_int
mu1, sigma1 = pars1
XYZ[0] = round(X, 4)
an = Animal()
app_label = obj._meta.app_label
a
bytes_read
largest.nodes()
b
power(D, -0.5) * A * power(D, 0.5)
your_input_data = list(range(1000))
self.age = age
dr.get(baseurl)
1
print(doc)
l
list_magicInput = []
sess = tf.InteractiveSession()
domain = sdb.get_domain(MY_DOMAIN_STRING_NAME)
buckets[i].append(data[o])
empty_copy_1.dtypes
mean = sum(array) / size(array)
recover = True,
params = curve_fit(func, x, y, guess)
b = True
c = jsonpickle.decode(js)
x = 1.2
result = x[:]
pathname = os.path.join(dirpath, fname)
location_id
name, all_ = f.__name__, mod.__all__
a.billing_system_id = o.id
C = 1 / np.sqrt(cosLat ** 2 + FF * sinLat ** 2)
df
model = MyModel
sp1 = tk.Spinbox(root, **opts)
prob = (k - numbersPicked) / (len(seq) - i)
r[j] = i
i = prim
trueLine = testFile.readline()
diff = 0
term = sign * x ** k / m.factorial(k)
font_objects = mpl.font_manager.createFontList(font_paths)
OS / build | os.name | platform.system()
uuid - dev
num.value
compute(n)
self.last_date_modified = time.time()
ShowIndex()[0:5:2]
evaluations = [x for _ in range(5)]
time_text.set_text(time_template % t)
fitted_pl.alpha
True
result = result[1:] + (elem,)
drive, path = os.path.splitdrive(line)
request = request_map.get(threading.current_thread())
remote = route.pop()
axSlider = plt.axes([0.1, 0.8, 0.4, 0.05])
df1
pd.DataFrame.set_diag = set_diag
deleteA
dt
correction = 0.5 if n >= 0 else -0.5
raw = np.sqrt(x ** 2 + y ** 2)
print(ss)
dis(f)
1
cr.stroke()
text
img1.download(image1)
gb1 = GlobalDataBase()
xcoord = _1DCoord(42)
i = 0
b = 2
assert latitude_in_degrees >= -90.0 and latitude_in_degrees <= 90.0
primary.baz()
connectSucceeded = False
last = [next(iterator) for iterator in iterators]
processItemsNotTwo_case2(list2)
A = np.array(a)
1
print(df)
last_event_ticks = 0
NO_USER_WRITING = ~stat.S_IWUSR
region = CG.CGRectMake(0, 0, 100, 100)
given_sort = given_array.ravel()[sort_idx]
access_mode = ACCESS_MODES[internal_access]
counter = 0
start = timeit.default_timer()
set_pm_excepthook(IndexError, True, False)
resource.setrlimit(resource.RLIMIT_NOFILE, (1000, -1))
first_valid_idx = df.apply(lambda x: x.first_valid_index()).to_frame()
self
x
unittest.TestCase.assertRaisesErrNo = assertRaisesErrNo
2
show()
splits.sort()
net.addConnection(FullConnection(h1, h2))
print(n)
dir(base64)
a = arange(8)
k = Key(bucket)
b_minus_a = t - s
el.activeSite.replace(el, instrument.Violin())
t = time.time()
v
BT = BallTree(D, leaf_size=5)
in_data[1] = float(1)
print(opening_line.format(**info))
series_list = list(series)
true,
pad + s + pad
s.delete(foo)
checksum ^= ord(el)
im_ycrcb = cv2.cvtColor(im, cv2.COLOR_BGR2YCR_CB)
fmt.Println(i)
sleep(delay) // backoff
print(second)
Q[jj] = ones_row(Q[jj])
node = self
user = ur.obj_get(req_bundle, username=username)
self.__suppress_context__ = True
id1 = next(unique_sequence)
studentform.student_name = name
connection.logout()
a = 5
high_corr_out = np.zeros(A.shape[1])
result
listener = socket(AF_INET, SOCK_STREAM)
natsorted(versions)
__default = object()
cf.destroy()
require(RSelenium)
image(r)
print(save_as_binary)
max_idx = np.argmax(a)
numer, denom = x.as_numer_denom()
a1 * b
n = len(y)
lat_rad = math.atan(math.sinh(math.pi * (1 - 2 * ytile / n)))
i = 0
counter[msdif] += 1
str(boundField)
only = [(s - dupes) for s in allsets]
salaries = {}
a = np.array(list(zip(x, y)))
False
item
pdfname = sys.argv[1]
c = min(sums.values())
a
dd = deque(aa, maxlen=1)
min = 0
t = t.strip()
False
code = code.to_frame()
7
print(my_val)
results = self.db.query(schema.allPostsUuid).execute(timeout=20)
r
True
parse_url(url1) == parse_url(url1)
map.setCenter(pos)
previous_commit = last_commit()
topic_dist = gamma[0] / sum(gamma[0])
data += chr(length) * length
PyFrameObject * pyframe
ret, frame = cam.read()
x + y
test = Test()
sigma = 2
impl = getDOMImplementation()
theta = theta + random.uniform(-noise, noise)
r = []
print(d1)
c.subtract(d)
area = abs(t[0, 0] * t[1, 1] - t[0, 1] * t[1, 0]) / 2
res = 1
print(c)
start = 0
block1 = list(num[:4])
[Editor(typeof(StringArrayEditor), typeof(System.Drawing.Design.UITypeEditor))]
print(out)
5
d = difflib.Differ()
value * 2
print(1000)
html_data = connection.read()
lenM, lenK = 1, 1
B = ax.get_children()
v[p[0]] = p[1]
field = generate_field_for_question(question)
cities
my_float(0.97)
fx(1, 2, z=1)
list_keys = random.sample(list_keys, 10)
MyObject.ID
result = do_something(file_handle)
val = q / 10 ** (n - 1)
curr = parentMap[curr]
dt = datetime(*time_tuple[:6])
prof.runcall(f, 5)
potentialEnergy += (4.0 * r6i * (r6i - 1.0) - CUT_OFF_ENERGY).sum()
self.qa.vote_down_count += 1
--test
counts = pd.crosstab(df.type, df.subtype)
request_finished.connect(my_callback)
type.__new__(cls, name, bases, dct)
model = Order
ctx = cairo.Context(surf)
files = Set(lambda : SongSourceFile)
result = pool.map(numpy.sin, a)
(h - 8) % 12 * 60 + m
BOOST_PYTHON_MODULE(B)
new_dict = {}
delta_ticks = event.ticks - last_event_ticks
lst
self.rows_count = rows
print(l)
common_neis = neisets[v1].intersection(neisets[v2])
x = point(0, 0)
row = index.row()
model = ModelName
self.num_lines = int(1.0 / char_count * density)
texts = [[i for i in doc.lower().split()] for doc in docs]
i += 1
old.__class__ = MoreSpecificError
CATCGATCAG - --CGACATGCGGCATACG
flags = 0
print(d)
False
token_list.push_back(str.substr(lastPos, pos - lastPos))
initial_threads = threading.activeCount()
l = [1, 5, 8]
N2 = math.floor((month + 9) / 12)
code, message = error.args
text = text.replace(gr, rep)
output.running = False
print(root)
FieldSet.pop(field)
consumer = oauth2.Consumer(key=self._client_id, secret=self._client_secret)
B = Box(A, radius=2)
record = len(chain)
width *= Decimal(d_width)
iris = datasets.load_iris()
keys = dict(zip(order, list(range(len(order)))))
[11, 9]
_request_ctx_stack.top.user = self.anonymous_user()
strategy = strategy_objects.DefaultObject()
n
m -= 1
of = inspect.getouterframes(cf)[1]
pr = line1.interpolate(line1.project(pt))
func_py = cpplib.func_py
image_Re = cvCreateImage(cvSize(dft_N, dft_M), IPL_DEPTH_64F, 1)
engine.console_control_handler.subscribe()
self.values[[np.arange(n)] * 2] = values
count = collections.Counter(tag_weight)
conn = connections[Questionnaire.objects.db]
parser = JsonComment(json)
col = 0
Alias / admin_media / home / myuser / Django - 1.1 / django / contrib / admin / media
x = _
xf = sheet.book.xf_list[c.xf_index]
result
PRIORITY_1 = 1
ft(xg, yg, zg)
saved_a.append(next_a)
print(COUNT)
note = models.TextField()
print(parser.sections())
6, nan, 25.0
xx = set(x)
{(0): 1000000}
B = 1
clang = False
rf = model_rf.fit(X_train, Y_train)
print(b.pmf(k) - n.pdf(k))
order
address = serializers.CharField(max_length=1000)
fun()
results_fetched += 1
foo_np_view.copy().tostring() == foo_np_view.tostring()
year = wt.SelectField(choices=years)
result = 6
n = v.isnull()
new_max = 100
len(cellToBird[cell])
loader = FlipkartItemLoader(response=response)
extent = [0, 20, alpha_list[0], alpha_list[-1]]
spam = myLib.CreateInstanceOfClass()
allow_interrupt = True
query = parsed[4]
randnum = randint(start, end)
found_vals = {}
s
child_id
pi.contents.value
4 * int(year_dif) + int(qt_dif)
v1, v2 = val[ind].T
observer = ephem.Observer()
set1 = set(lst)
state = self.__dict__.copy()
mylist
mime_root.attach(mime_image)
self.end_time + 86400000
traverse_tree(callback)
value in collumnIterator(collumn)
scalar2 = 2
entry_text = _entry_text
np.dot(ai, bi, out=resi)
indexes = []
y
distances[i][j] = sumsquares
chrome_options = Options()
main()
date_time[i] = datetime(year, month, day, hour, minute, sec)
mylocale = wx.Locale(langid)
x
sample_width = stream.getsampwidth()
meth = cls.sync_maker(name)
numer * mod_inverse(denom, modulus) % modulus
netw = int(n.network_address)
False
sharedCalendar = namespace.GetSharedDefaultFolder(recipient, 9)
a[200] = 6
diffs = [(x - splits[i - 1]) for i, x in enumerate(splits)][1:]
a = 2
print((low >= high) & (high >= low))
tol = 1e-16
print(video)
c = 10
phrase
tot
largest_diff
label, num_label = ndimage.label(array == 0)
Legend._get_anchored_bbox = _get_anchored_bbox
builder.setApplicationName(appName)
False
snd_array.dtype
m.append(x)
wrapper
a
[sources]
print(generator.throw(ValueError))
meth = getattr(self, func)
common = set1.intersection(set2)
file_handler = dill.loads(serialized)
measuredSpeedsList.append(self.Value)
c = comb(v, k)
ticks = A.date.values.tolist()
print(df[contains & not_contains])
1
mul = reshaped_X * W1
Wrapper
set2 = set(list2)
s += e
auth_handler = urllib.request.HTTPBasicAuthHandler(password_mgr)
manager.window.showMaximized()
pushed = False
1 / 0
img = data_uri_to_cv2_img(data_uri)
b = array(B)
PyEval_InitThreads()
regressor = skflow.TensorFlowDNNRegressor(hidden_units=[5, 5])
excel.XlFormatConditionOperator.xlGreaterEqual
result = int(a, 16) ^ int(b, 16)
foundColors = defaultdict(set)
br.quit
readRequest += chr(startOffset % 256)
idx1 = row1.indices
z = X, Y
list_of_tokens = nltk.pos_tag(text)
print(assignments)
desktop = winshell.desktop()
session.execute(select([func.pg_advisory_unlock(key)]))
print(diff.hours)
results[X[:, (0)] == 1] = self.randomForest.predict(X[X[:, (0)] == 1])
Counts = [[(0) for x in range(128)] for y in range(128)]
labels = ax.get_xticklabels()
a = a.T
WSGIScriptAlias / v1 / Library / WebServer / Documents / hello_app / app.wsgi
ctm = utils.matrixMultiply(translation, rotating)
5 | D | ARG
helper = helperList[check_situation()]
webproc.scale(dynos)
post_save.disconnect(my_post_save_handler, sender=sender)
r = [1.0, nan, 9.0, nan, nan, nan, nan, nan, nan, nan, nan]
self._dict = dict_type
fft_of_rows = numpy.fft.fft(rows)
init_range = math.sqrt(6.0 / (n_inputs + n_outputs))
df.date_of_last_hoorah_given = pd.to_datetime(df.date_of_last_hoorah_given)
meta_decorator
shell = TerminalInteractiveShell(user_ns=namespace)
train, validate, test
model = MyModel
a, b = result[-1]
(False == True) == False
row = 1
sio.write(png_str)
vector < float > radius(contours.size())
ret = _location.gsm_location()
dis(g)
out = np.convolve(np.where(mask, 0, data), K) / np.convolve(~mask, K)
app = Flask(__name__)
raw_paras = self.raw_text.split(self.paragraph_delimiter)
nick = nick_on_current_line
lst, 0
0.0591987428298
a[int(sid)] = True
date_1 = datetime(2012, 10, 4, 1, 0, 51, 759)
deleteos, histfile, readline, rlcompleter
newpayload = {}
x.buyer_id
b[:, (diag), (diag)] = M
result = True if x > 5 else False
port = 4444,
inner()
rows = ptdBase.execute(query_str)
2 - 0.701126
print(Person._fields)
union_set = set()
__file__
result
data = tree[key]
sum += a
DBSession.add(doc)
bar = 2
print(msg % dict)
copy(fname, join(dst_folder, fname))
regr = SGDRegressor()
distr = getattr(stats.distributions, distrName)
True
buf.seek(0)
copylist = list
1
print(process.ProcessId, process.Name)
lst[0]
_singleton = Foo(something_else)
rgb[:, :, (0)] = rgb[:, :, (1)] = rgb[:, :, (2)] = a
offset = -1
b = i
resultIDs = list(results.keys())
out
d = decimal.Decimal
next_node = q.get()
LD_LIBRARY_PATH = my_path
a.name
ret += [((i,) + sub) for sub in _part(n - i, k - 1, i)]
mfcChanged = pyqtSignal()
centers = np.concatenate((a, b))
print((xp.itemsize, xp.nbytes))
args
GiraffeElephantBoat
net = FeedForwardNetwork()
ffty = fftshift(ffty)
deletecapture
inneropt, partition, x = setinner(Q, G, n)
B = -140
False
expanded_b = tf.expand_dims(A, 0)
FACTORY_FOR = MemberProgramme
count = int(metafunc.config.option.repeat)
P = [0.1, 0.25, 0.6, 0.05]
print(e.msg)
output1HTML.value = plot_to_html()
a = 4
DJANGO_SETTINGS_MODULE = foo.settings.local,
file_info_class = getFileInfoClass(f)
components = nx.connected_components(G)
record.exc_text = self.formatException(record.exc_info)
conn.send_bytes(share)
i = -1
bw = image.copy()
print(s1)
c = Counter(input)
my_numpy_array = vtk_to_numpy(my_vtk_array)
lazy_values = [delayed(f)(future, param) for param in params]
print(TAGS[k], exifdict[k])
testObj = test()
groups = itertools.groupby(sorted(data, key=f), key=f)
typeA = acc.accounttypeA
max_mask = True
setColor(leftPixel, color_right)
index.exposed = True
overflows[index] = new_lists[index][maxLength:]
encoded_Y = to_categorical(encoder.transform(Y))
node.left_child = kdtree(point_list[:median], depth + 1)
c.ClassName.propertie_name = value
q = qregnorm([0, 1, 2])
ceps, mspec, spec = mfcc(X)
mainloop = glib.MainLoop()
a = 10 ** 9
HoverCallback.args.update(dict(current_selection=current_selection))
p._hash = 2
set = set()
print(a)
s = Session()
prevMatrix = matrixDict[cell.index(max(cell))]
normalized
True
right = mergesort(lst[middle:])[0]
g()
unittest.util._MAX_LENGTH = 2000
indices = tree2.query_ball_tree(tree1, r=4.2)
s = slice(start, stop, step)
allspiders = []
np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)
e = Decimal(maxint)
cmpthese(1000, tl)
strtime
Gi = networkx.convert_node_labels_to_integers(G, discard_old_labels=False)
database.objects(newid=id).save()
dates = data.index
predicted_positives = K.sum(y_pred)
self.roomHandler = MucRoomHandler()
p = Pool(4)
key1_ab, key1_string = unpack_key(key1)
observer.lat = str(lat)
cid = cl.id()
print(np.ravel(mat.T))
max_matches = 4
left = mergesort(lst[:middle])[0]
a = abs(180 / math.pi * math.atan((y2 - y1) / (x2 - x1)))
area = abs(np.sum((e0 - e1) * 0.5))
split = []
procid = next(iter(procidset() - idset))
inds = np.nonzero(a > 2)
a = Foo()
prefix = strings[prefix][-5:]
evens = []
keys, values = zip(*list(machines.items()))
Indian
s = L, L[:]
x ** 2 - p
GLOBAL_NAME = _proxy_object.global_name
name = colander.SchemaNode(colander.String())
print(v)
print(user, group)
b = np.take(rand, a)
fileSet.add(relFile)
answer = calculate_answer(ruby_question)
print(a)
True is 1
id2 = next(unique_sequence)
CompareList(self[idx] and other[idx] for idx in range(len(self)))
a
n = 10
line_width = 20
k = Key(bucket)
lcmap = [cmap(i) for i in range(cmap.N)]
from_filenames = pd.Series(u)
perfect_corr = corrMatrix[col][corrMatrix[col] == 1].index.tolist()
res = request.urlopen(req)
a[ind] = start
str
concertation
s.connect(PROXY_ADDR)
a = 2
print(time)
lens = np.max([list(idx_max_array), list(idx_max_dict)], axis=0)
vals = ~np.isnan(M)
resource,
ndims = 40
response.status = 400
key = Key(your_string_with_key)
difference_image = original_grayscale - multiplier * blurred_grayscale
1
errorCount = T.sum(y)
halfway_point = len(sound) / 2
draw_box = False
d
bootstrap = Bootstrap(app)
print(digital_code, letter_code, units, name, rate)
old_stdout = sys.stdout
loop = asyncio.get_event_loop()
data = np.repeat(bin_locations, bin_counts)
bpython.embed(locals_=locals())
lines[0] = lines[0][col1:]
N = N[n_ind]
current = logs.get(self.monitor)
tup(A, A)(A, B)(B, A)(C, C)
new
train_end = int(train_percent * m)
self.point
self.groupable_nodes_total = len(self.groupable_nodes)
fractExpr = Optional(number) + Optional(fraction)
Presentation = Application.Presentations.Open(pathToPPT)
teacher = Teacher(profile=new_user.get_profile(), user=new_user)
Base = declarative_base()
chunk = inputFile.read(8192)
mytask.apply_async(eta=run_again)
inferior = gdb.selected_inferior()
self.classes_ = unique1d(y)
a = 1
chrome_options = Options()
tag = TagTraduit.objects.get(pk=int(pk_str))
col2 = y.strip().split()
df = df.ffill()
ydata = xdata ** 2
draw_box = True
where += n
cell.draw
capabilities = DesiredCapabilities.FIREFOX
l = []
o = []
Response(serializer.errors, 400)
Tree.fromstring(parsed_sent)
time_taken_ms = end_time.microseconds / 1000
latex_sphinx_howto
app = make_application_with_event()
overlap = math.hypot(dx, dy) - (circle.size - ball.size)
y(1)
bigrams.append(0)
notification.setInformativeText_(info_text)
self.current_value
country_data[2] = tag.string
2 in ll
toc = time.time()
console.log(r)
snake.update(LEFT)
author = author,
mu, sigma
not self
f = tfile.extractfile(t)
start <= temp <= end or randset.add(temp)
99
word = Word(alphas)
pivoted[pivoted.foo < 0]
p.__name__ = key
i = bisect.bisect_left(myPairs, targetDatetime)
block2 = len(num) > 4 and [num[4:6]] or []
i = 0
op.bulk_insert(client_credential, clients)
no_headers = client.GetCellsFeed(key, wks_id, query=query)
begin = datetime.date.today()
p_r_colors
b = a
print(df)
unique_pais = set(pais)
padded_sliding_windows(a, split_size=2, pad_length=1, padnum=100)
ret, frm = cap.read()
websites_urls = []
last_modified = current_time - timedelta(days=1)
batch = neo4j.WriteBatch(db)
4
info = tar.tarinfo()
print(letter)
print(value)
print(f)
print(constant.CLIENT_CONNECTED)
it = iter(t)
string % vars
remain = start + 10 * 60 - end
total = 0
print(X)
register(type1, type2, _Example(doSomething, doSomethingElse))
x[i].upBound = UB_ind[i]
di[str], di[Number]
jobs = []
x = bar
maxn, maxp = 0, 0
y, m, d, h, min, sec, wd, yd, i = t
config.add_subscriber(add_cors_headers_response_callback, NewRequest)
db(db.tablename.fieldname <= value).select()
thresh = 100
print(grouped)
loop = asyncio.get_event_loop()
name = record.name
x = f2(s[1:])
s = np.random.RandomState(0)
src = np.ones((100, 100))
b = -1
print(other)
oMSP = getMasterScriptProvider()
length = eval(input())
path_parts = path.split(app_id, 1)
A = np.vstack([x, np.ones(len(x))]).T
rollback
key_value = pp.Group(tag + exp)
frames = [df_1, df_2]
myCounter = 5
draw = ImageDraw.Draw(img)
a, b = b, a + 4 * b
baz
isok = False
test = dict(test)
start_point += inc
print(s)
self.age = age
print(b)
{aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa}
a_map = {}
s
a = 0
python
played = ~np.isnan(v)
self.customer_name
lines.append(line)
SMinX = 0
data = serializer.Deserialize(reader)
Xdb = 20 * scipy.log10(scipy.absolute(X))
zipped = zip(x, y)
self.checkState(index)
current_plot_range = labels[labels == i].size
exchange.getResponseBody.close()
a
b = [b]
pattern = patterns_split[pattern_num]
mod
nested_loop_iter = itertools.product(n_vocab, m_vocab)
lowerValue = value.lower()
c.InteractiveShellApp.exec_lines = []
count = 0
W = np.arange(9) / 9.0
rng = np.random.RandomState(1)
c = conn_1.cursor()
name = StringCol()
proposed_outsiders[outsider_to_swap] = tmp
instance_type = INSTANCE_TYPE, security_groups = [SECGROUP_HANDLE],
counter = 0
deque = collections.deque(maxlen=n)
self.uid = guid
i = 0
min_idx = 1, N
cs = cm.Set1(np.arange(40) / 40.0)
data = self.file_obj.read(min(amount, remaining_amount))
i16 = PngImagePlugin.i16
popt, pcov = curve_fit(func, x, y)
col = sh1.col_values(0)
0
assert all(post.visible for post in posts)
counter = 0
type = db.Column(SubscriptionType.db_type())
future.add_task_done(self.task_done)
z = roots[squares[x] + squares[y]]
sz = struct.calcsize(fmt)
values = np.array(values)
gridPoints = np.array([[[x, y] for y in yPoints] for x in xPoints])
cdf = [P[0]]
f.age = val
it1, it2 = tee(extract_ints(text))
lr.intercept_
c = list(b.keys())
havedisplay = exitval == 0
s
pizzas_bought = models.ManyToManyField(Pizza, through=PizzaSold)
parser = ViterbiParser(grammar)
sa_query.__class__ = BaseQuery
tester(**obj)
print(grappelli)
tzwhere = tzwhere.tzwhere()
xx, yy = zip(*shape)
i += 1
row = z.shape[0] * (y_world - y.min()) / y.ptp()
r_fd, w_fd = os.pipe()
total = supers(a) + supers(b) + supers(c)
person = Person.get(person_id)
1, 1
ps
starring
string
X = v.fit_transform(category_dicts)
bin_locations = np.random.rand(10) * 100
print_i1()
keypoints, descriptors = surfDescriptorExtractor.compute(im, keypoints)
X is 1, Y is 2
print(a)
mysql_cursor.execute(sqlStmt, record_ids)
6
has_polka_dots = False,
first = row[0]
lx = x % 5
False == 0
net.addInputModule(inp)
print(M)
myfuncFUNCTYPE = CFUNCTYPE(STRING)
sout = line.split(separator)
d = dict(self._sections)
b
reverse_iterator(end())
print(some_module.someOtherDict)
d[k] = v[::-1]
c = stdscr.getch()
print(settings.theThing)
new_strides = list(arr.strides)
electric_conductivity = lambda T, p: 1.0141 * T ** 2 * p
cv_splits = [(idxs[:i], idxs[i:]) for i in range(1, N)]
pip - -version
l[index] = chr(ord(l[index]) + 1)
a
topological_sort([replace, edges], default_sort_key)
expect(1 != 1)
decorator, all
larger = a[i + 1:].min()
MessageBox.Show(message)
print(end)
spider_finished_count.count = 0
people = {}
farmersmarket.py - d | --debug
top_features = [features[i] for i in indices[:top_n]]
credentials = store.get()
mask = np.argwhere(counter > 0)
G.node
company_ids_page = company_ids[page * 10:(page + 1) * 10]
python
points.push_back(p)
c = conn_1.cursor()
inputs = list(range(1000000))
ch.name = str(ch_node.id)
print(col)
saw_first_char = True
sendp(fuzz_frame)
F = N // R
out = []
self.myBool = True
out
cmd = []
popt, pcov = curve_fit(func, x, y)
a = list(range(1, 1001))
print(unColorString, len(unColorString))
groups.add(tuple(sorted(possible_group + (node,))))
firefox_capabilities = DesiredCapabilities.FIREFOX
debug = False,
updated = client.ExecuteBatch(batch_request, cells.GetBatchLink().href)
get_truth(1.0, operator.gt, 0.0)
22.12
f = lambda x: a * x
_hex = hex(_int)
set_of_related_nouns.add(synset)
k = key()
rc.level + 1,
L
a[magic_index]
out = A1.cumsum()
nop = 1000
f = lambda j: processDataLine(dataline, arg1, arg2)
i = 99
n
100
end = time.time()
as_view_fn = cls.as_view()
num % val
module.hello()
intBlank = models.IntegerField(blank=True)
diff = compare_metadata(migration_context, combined_meta_data)
self.x = int(grid_number[0:2])
time - time
darray
reordered = important + [c for c in df.columns if c not in important]
color = s_img[oy:oy + height, ox:ox + width, (c)] * (1.0 - alpha)
t = arange(4000000.0) / 1000000.0
mem = current_process.memory_percent()
trustStore.load(null, null)
customer_id = models.UUIDField(default=uuid.uuid4)
dt = 1.0 / num_t
X, info = zip(*(bicg(M, b) for b in B.T))
wgs2utm = osr.CoordinateTransformation(wgs, utm)
x = linspace(400, 6000, 10000)
data.reverse()
y = foo(100, 0)
max(candidates())
read_as_utf8(normal_file.fileno())
_currentWindowHandle = page.windowHandle
L = len(a) / n
args = inspect.getargspec(func)[0]
print(result)
first_alpha()
mydict = tripledict()
top_matrix = Matrix.zeros(8, 7)
extractor = Goose()
x, y
input_img = Input(shape=(64, 4))
buf = ctypes.create_unicode_buffer(260)
self.__columnWidth[colNum] = self.GetColumnWidth(c)
rads %= 2 * pi
obj = context[i]
m4 = int(np.ceil(field.max()))
pubs
x_lattice = x_lattice[mask]
p2, = plt.plot(z, fourier(z, *popt))
print(res)
assoc.pyw = Python.NoConFile
cvSplit(dft_A, image_Re, image_Im, 0, 0)
k = random.randint(1, len(A) - 1)
steps.append(step)
a
converted.putpalette(palette)
x = Test(10) - Test(5)
self.x = 1
num_converted = 0
records[l] = 1
f
loop = LoopingCall(follow, open(filename))
m = min(p)
stop = timeit.default_timer()
5 + 5
arr
credentials = tools.run_flow(flow, store, flags)
context[varname]
r = Math.random()
fuzz.partial_ratio(s1, s2)
stdin_fd = sys.stdin.fileno()
0
segments = [(x, r.choice(list(range(x + 1, 100)))) for x in lefts]
_, start, stop = shared[0]
mem, length = imagar.buffer_info()
util.__code__ = spam.__code__
TIMEOUT / T - 1
self.current_value = next(session)
im_floodfill_inv = cv2.bitwise_not(im_floodfill)
main()
foo(b, 2)
text
response = dns.query.udp(request, name_server)
bcrypt = Bcrypt(app)
answer = map(func, open_info)
cache[n] = 10
1, 200, 2000
list(node.value for node in prefix_trie._getnode(search).walk())
11
SMaxY = 5
H.add(a)
i
size = getsizeof(my_dictionary)
args = p.parse_args()
v = 2.0
x
9
min_length = N
i
priority = 998
+streams.append(stream)
tasks = []
i += 1
utc_dt = epoch + timedelta(milliseconds=int(ticks))
driver = webdriver.Chrome()
a = list(range(1, 1001))
first_n_sentences
sample.info()
5
image = ContentFile(b64decode(part.get_payload()))
email = ndb.StringProperty()
key.start, key.stop
sinr = sin(radians(self.rotation))
sign, logdet = slogdet(np.pi * V)
ctx = ssl._create_stdlib_context(ssl.PROTOCOL_TLSv1_2)
timeslots_left -= duration
handle_httpstatus_list = [500, 502]
pyexec_LTLIBRARIES = _myext.la
width_val = xnew[index_of_closest_width]
print(weighted_values(values, probabilities, 10))
sample = mangle(sample)
4
N = 1
u
Value = value
print(result)
g = gmail.Gmail()
i
mapping[key] = namedtuplify(value)
h = H(N)
default = object()
pr1 = urlparse(url1)
matrix[r][c + 1]
abstract = True
answer
foo.bar = bar
self.fig = fig
x
net.addModule(h1)
item
print(word)
kProfile.output(kFile)
Spam = 2
data
hist *= normed_value
False
values = traindf.rdd.map(lambda r: (r.id, r.image)).sortByKey().flatMap(lambda id_image: id_image[1]).collect()
D = PD.Series(x, t)
bigrams[threadnum] = zip(*[text[startpoint + i:endpoint] for i in range(2)])
pprint.pprint(business_hours)
xb = aest * (1 + 0.4)
back.show()
p1 = 2 * x * x
location = e.location
PRIORITY_2 = 2
my = MyClass(1)
type(parsed_sent)
utc = arrow.utcnow()
deleteself.trd
ret = copy.deepcopy(x)
dataset = random.rand(dataSize, dim)
print()
aList[i] = [pyp.nestedExpr().parseString(aList[i][1:]).asList()[0]]
self.topicName
results_file
raise ex
n >>= bitlen
d.toISOString = toISOString
rpkm
bc = np.bincount(a[:, (0)])
j = i
out
components[i:i + 1] = []
len_pfx_idx = map(lambda t: (len(t[0]), t[0], t[1]), pfx_idx)
c = get_config()
n_range = list(range(0, window_size))
create_dirs
A1.T
d = dummies.mask(dummies == 0).bfill(1).eq(1)
my_list = []
m = len(points) // r
filesize = filesize + fwrite(f, zeros(to_write, 1), datatype)
y, x = screen.getmaxyx()
d = collections.defaultdict(lambda : d)
self.authenticate = authenticate
k = 2
ret += [([i] + sub) for sub in _part(n - i, k - 1, i)]
result
a = list(reversed(expr.collect(x).as_ordered_terms()))
srv = bottle.Bottle()
swig - python - builtin - c + +test.i
N = 20
gen = my_generator(data)
d
t1_seconds = t1_unpacked / 52428800
akbar | 1000
y = np.random.random(size=N) * 100
cmr = ChatMessageResource()
cache[jid] = set()
assert d is not {}
marshal.dumps = pickle.dumps
record.message = record.getMessage()
print(D.d)
s
unq_coo = sorted_coo[unqID_mask]
commands.sort(key=lambda cmd: cmd.Name)
boby = BobyDog()
SixBuffers = c_char_p * 6
False
tx = ans[0][0]
sample_bucket = storage.Bucket(sample_bucket_name)
n = len(items)
is_cy_call = true
x1 = np.atleast_2d(xs[..., :-1])
int_end = int(end / increment)
cart.publisher = book.publisher.name
gpsp.join()
print(answer)
res
+_apply_key(key)
user_reviews = User.user_reviews
custom_call()
phone = colander.SchemaNode(colander.String())
[k]
a
socket = urllib.request.urlopen(link)
Py_INCREF(value)
farmersmarket.py - v | --version
pixmap = icon.pixmap(size)
label = label.get_text()
os_version.dwOSVersionInfoSize = ctypes.sizeof(os_version)
arr
common_neis = zeros(n, n)
print(word)
urls = []
current_page = paginator.page(paginator.num_pages)
a
res = []
name, price, LastUpdate, today = q
smaller = a[i]
t += t2
b = 2
n
round(item1, rounding_param) == round(item2, rounding_param)
i
it = it[:-2]
print(img.get_array())
pixels = image.load()
6 - 1.0
v = DictVectorizer()
seekpoints = [(0) for _ in range(40000)]
components.append({v1, v2})
wraps(view_method)(_decorator)
lol = df.values
response
ans = WConio.getkey()
bins = np.add.accumulate(probabilities)
a = 1
print(f.code)
o.foo = x
print(x + y)
CHUNK = 16 * 1024
size = 0
x2 = np.linspace(0, 2, 50)
python
df_large
postgresql - 8.4
current_site = get_current_site(request)
factory = SAXParserFactory.newInstance()
s = (s + 200) / 200.0
scf = xrc.XmlSubClassFactory()
False
width = len(x[0])
self._mtx
parent_archive.extractall(path=tmpdir)
print(t)
help(Tix)
image1.show()
self.p += p_temp
performance = [red, green, blue, grey]
shrink(a, 2, 1)
sample_time = float(i) / samplerate
new
print(topthree)
string.uppercase
retval
delegate = MyApplicationAppDelegate.alloc().init()
cell.font = bolded
so.Close()
AccessDenied()
hist_len = readline.get_current_history_length()
pending = len(iterables)
ftps.prot_p()
assert len(lists) == 1
l1_x1 = len(x1) - np.arange(len(x1)) - 1
id(temp)
mysld = StyledLayerDescriptor()
model = User
a.A
print(result)
result = array(result[decimation_factor - 1::decimation_factor])
app.add_processor(error_processor)
1 < x < 10
words = text.lower().split()
draw2 = ImageDraw.Draw(image2)
print(B)
print(w)
print()
fig = plt.figure(num=figure_id)
analyze_something_with_k_and_v_that_might_throw_an_exception
edge_removed = False
result = df1 == df2
self.cached.__getitem__(*args, **kwargs)
elapsed = time.time() - start_time
condition = 100
df
cmp = PyObject_RichCompareBool(obj, item, Py_EQ)
seen_titles = set()
domain = current_site.domain
n00 = n ** 2 - n - n11 - n10 - n01
value.append(item[1])
cl = request.content_length
print(d)
b = 1
indices_nonzero = []
self.x = 1
download(update_module)
key_name = shard + str(i)
True == 1
[9, 14, 0.0],
coef = msg_out[i]
idx += 1
a = list(range(100))
rect(inds, inds, 1.0, 1.0, color=colors, x_range=inds, y_range=inds)
current.append(data.pop())
[]
token = jwt.encode(payload, settings.SECRET_KEY)
iters = cycle((iter(a), reversed(a)))
traceback_path = os.path.join(settings.EXCEPTIONS_DIR, traceback_name)
item = self.sa_grid.itemAt(index)
out[deref(i).first] = convertVector(deref(i).second)
gencache.is_readonly = False
bool(set(test2) & test_characters)
refresh_user_shell
open_mode = OPEN_MODES[internal_access]
Value1 = Foo
shutil.move(newfile, oldfile)
raise NotFound()
r = self.basic_auth(r)
old_fb = file_buffer
g.annotate(stats.pearsonr)
dct
tpl.render_context(ctx)
d = {}
self._total
m = LowLevel.CK_MECHANISM()
X = load_iris().data
e = l - el
header = BytesIO()
to_replace = good_array[:, (i_column)] >= maxs[i_column]
paperheight = 11.7
row1 = [91, 90, 51]
help(Tix)
graph = parser.raw_parse(txt)
_PyObject_New(PyTypeObject * tp)
df
my_splitter.whitespace_split = True
out[colour] = array_
vertices.bind()
bufferFile = StringIO.StringIO()
db = client.primer
rot_matrices[..., (1), (1)] = cos
decode_header(a1)
v = session.get(k)
result = Prover9().prove(c, [p1])
numBytes = 1
sleep(0.025)
top_matrix[2, 2] = 1
re.compile = lambda pattern, flags: re.my_compile(pattern, flags | flag)
p1 = map(lambda x: sum(x, tuple()), product(*lists))
results[numberOfRuns, modelSolve(100)]
items = self.selectedItems()
result
folder
result.append((sample_time, new_is_loud))
b.p = a
GlobalSession = scoped_session(session_maker(bind=engine, transactional=False))
x = 1 / 1
config.save_results(self.stats, self.file_state.base_name)
self.messages = []
print(True)
lastStep = allSteps[0]
theta2 = theta2 - step * dEdtheta2
positionsJ = currentPositions[iParticle + 1:, :]
drawable = pdb.gimp_image_get_active_layer(image)
lower_red = np.array([0, 50, 50])
xf.write(rec)
print(l)
arr = arr.T[~(arr.T == 255).all(1)].T
wrap(**kwargs)
self.email = sanitize_email(request.user.email)
list(range(x))
form = SelectBandForm(event, request.POST)
mybucket / files / pdf / new / abc.pdf
task.deferLater(reactor, 1, self._called_by_deffered1)
qIndex = listWidget.indexFromItem(selectedItem)
math.log(prob_word1_word2 / float(prob_word1 * prob_word2), 2)
wgs2utm, utm2wgs = coord_trans_cache[cur_utm_zone]
fract * pos(fract, exp - 1)
current_page = paginator.page(page)
self.clients = {}
ls = LineString(np.c_[x, y])
d = {}
_mock_native_all_users
num_list.remove(biggest)
sleep(10)
y
S1 is S2
film.followed_genres = film.genres.filter(id__in=genre_ids)
print(p)
len(perm) - cyclecount(perm)
rdf
print(v.pattern.groupdict)
abstract = True
f = sys.stdin
print(5)
self.line_edit = QtGui.QLineEdit()
result[-1] = a, n
contents = page.getContents()
Pi ^ 2 / 6
6
Type = Application
_compile(pattern, flags)
ESCAPE + FORMAT % (color,) + text + RESET
idx = pd.IndexSlice
t_opt / t_no_opt
self.service_time_strm = npr.RandomState().seed(seed=self.seed)
self.owner = owner
reporter = debug.ExceptionReporter(request, *sys.exc_info())
print(x, y)
id - u
bbox = mapnik.Envelope(-10000000, 2000000, -4000000, -19000000)
print(result)
converters = str.strip, int, float, float, date_conv
time = total / 1000
train_images = extract_images(local_file)
N = 1.0 / 5
array
msg
head = repo.head
self.health = 0
True
a.objectAtIndex_(1)
theta1 = theta1 - step * dEdtheta1
total = start
sf = sin(twopi * f * t)
theList = list(range(20))
obj
test_module.time.sleep = dummy_sleep
processHeader(header)
net.addInputModule(input_2)
python
print(doc)
-lib
c = []
NaT = pd.NaT
vals = list(items.values())
socket = THttpClient(server_url)
Example[types][0](a, b)
c()
loop = asyncio.get_event_loop()
n_values = np.max(values) + 1
True
profile = __builtin__.profile
help(m.groups)
unique_neighbors, neighbor_counts = npi.count(neighbors_per_region)
b = bitstring.ConstBitStream(a_file_object)
singleton = MySingleton(sourcefile)
int(1 / 2)
setup(setup_requires=setup_requires)
validlist = []
row, col = [np.linspace(item[0], item[1], num) for item in [row, col]]
ufmt_str = jinja2.utils.soft_unicode(fmt_str)
self.fp = fp
data = sm.datasets.longley.load_pandas()
cov.save()
Pool(processes)
vec[put_m1] = -lens[0:put_m1.size]
0
start = 1
dist_dir = my / dist / dir
pip - review - -local - -interactive
text = script.text_content()
9
fit = optimize(obj, c(-5, 5), dt, rho)
rpkm
files_found = 0
subprocess.Popen([browser, browserParms, url])
ev.preventDefault()
st_john_time = utc_time.astimezone(tz)
b = [9, 10]
key = EVP.PKey()
a[(i), :lengths[i]] = r
d = {}
myobjects = env.Object(myfiles)
a = 5
f = MyModel.objects.all().get(id=0).saved_file
l_img[by:by + height, bx:bx + width, (c)] = color + beta
a
nan == nan
out_csv.writerow(rec.fieldData)
ct
future = asyncio.run_coroutine_threadsafe(add(1, b=2), loop)
__all__ = []
N = 4
print(google_dict)
loActor.GetProperty().SetColor(0.9, 0, 0)
print(C)
ABC - 799 - 99
set_attributes_from(entry_info)
istart = _int(start)
out
mysum = 0
resource.setrlimit(type, (limit, hard_limit))
r = itertools.zip_longest(*([iter(sin)] * 6 + [c * (len(sin) // 6)]))
self.default_depth = default_depth
num_tuples = 10
day_ago = local_tz.normalize(now - DAY)
value
data = ts[selector]
length = (wintypes.DWORD * 1)()
np_labels = np.array(labels)
bits = token.contents.split()
is_none
a = int(mean[1])
a
v = myVector(4, 2)
N = 1000000
do_stuff
subarray = a[:, (1)]
ret.l = l
rng = np.arange(20, 51, 5)
flattened_values = [item for sublist in values_to_insert for item in sublist]
maxrun = 0
self.reportPort(self.listeningPort.getHost().port)
SECRET_KEY = os.urandom(24)
print(result)
x < 10 < x * 10 < 100
plot(img50_lm[(50), :, (1)])
connect_default_signals(Region)
adj_check = (df.location != df.location.shift()).cumsum()
indexes[i] += 1
sample.some_func(si)
abstract = True
f = freq[i]
n = 10
ip = ip_adds[0]
timeout = 1
env = construct_general_environment()
harakiri = 120
Civic96
num2 = int(num2)
ret
print(row.center(2 * size))
numbers = [4, 8, 6, 2, 2, 5]
d
result = req.get_response(self._app)
print(each_sub_sub_subkey, value_num)
print(location)
screen_rect = screen.get_rect()
new_strides.insert(axis, 0)
id(a)
v
logging.foo = 1
cd / some / directory
print(p)
print(date_aware_la)
tree = ast.parse(contents, f.name)
filename = os.path.normcase(co.co_filename)
library(MASS)
spam
masked_data = ma.masked_array(data, mask)
s
j -= 1
docs
inds = np.digitize(a, bins) - 1
error = str(op.stderr.read())
[[n]]
2, 200, 1000
4, 4
[run]
c_numero = []
SPI_SETDESKWALLPAPER = 20
p = Process(target=generator)
pos.offset = 0
a = 10
s = 0
m.assert_any_call(1)
l, r = -r, -l
ind += i
c
calculated_time_delay = np.mean(track_2 - track_1) / frequency
myinstance.attr
dm = DenseMatrix(nrow, ncol, values)
c - 1.0
a
[v, p, q]
temp = []
ls - l / usr / bin / python
print(chr(i) + chr(j), Counts[i][j])
print(result)
N = 2
observers = []
mydict[c] += 1
plot(ax1, t, y, noisy_y, fit_y, (A0, K0, C0), (A, K, C0))
M.bar = 4
obj = D()
training_set = nltk.classify.apply_features(extract_features, documents)
result = PyImport_Import(pname)
result.append(div)
d[key] = data
p = Pool()
BytesReturned = ctypes.wintypes.DWORD()
id5, Tool, moreinfo5
id4, Tool, moreinfo4
187976.61
form = SQLFORM(db.auth_user)
res = matcher.get2ld(u)
x = NamedInteger(5)
pat = re.compile(s_pat)
w = event.widget
a, b
d[l[0]] = {}
res = pool.apply_async(do_this_other_thing_that_may_take_too_long, [8])
XYZ[1] = round(Y, 4)
2
print(_)
self.balance = self._balance()
yc = y[max(start - 1, 0):stop + 1]
foo = 7
builder = builder.filter(getattr(MyModel, key).in_(vals))
MyModelCreationSerializer
tempfile_io = StringIO.StringIO()
uid = stat_info.st_uid
spindex.insert(item=item, bbox=item.bbox)
__unicode__ = silently
f.buffer.raw
data
1
tic.goto(x + 0.25, y + 0.25)
subtokens = [[i for s in poster for i in s] for poster in st]
denom = df.notnull().sum(axis=1)
inner()
True
response
avg = sum(datetimes, datetime.timedelta(0)) / len(datetimes)
wrapper_dict = res_type.__dict__.copy()
pythonapi.PyCObject_AsVoidPtr.argtypes = [py_object]
start_lat = math.radians(start_lat)
mylist = list(range(5))
heap = []
x
header_flag = 0
roi = lab[y:y + half, x:x + w]
newIndexes[i] = indexes[i] - 1
mymap = maps.Map()
driver = selenium.webdriver.Ie()
node = models.ForeignKey(Node)
print(m.weekday)
tot_rtn = p_rtns[-1] - 1
s = 0.0
result
uniform_data = np.random.rand(10, 12)
new_num = 0
empty = []
PyUnicode_GET_SIZE(v),
rowCount = int(query.count())
shift = [(s % x.shape[ax]) for s, ax in zip(shift, axis)]
buf
cell_contents = []
a = 1
print(TE_in_TSS)
print(c)
h2 = Header(str(h))
pad = (k - s.shape[0] % k) % k
l = [x for x in array if x < pivot]
print(fname)
print(spaceTest(s))
records = records.order_by(sort)
fibs = [0, 1, 1]
f = float(x)
q.enqueue(STOP)
x is False
python << END_OF_PYTHON
net.addInputModule(input_1)
v
print(child)
docText = doc.Content.Text
is_r = obj.readable()
cuml = []
distinct2 = set(seq2)
city = Column(Text)
environment = SITE = domain1
ret += a[deg] * np.cos((deg + 1) * np.pi / tau * x)
table.addprevious(section)
print(time_formatted)
mydict[mykey] = tmp
t1_entry, t2_entry
2
x
assembly
loadRow(xmlToDict(tag))
gp = GaussianProcess(theta0=0.1, thetaL=0.001, thetaU=1.0, nugget=0.01)
missing = all_numbers - set(numbers)
matched = 0
print(in_loop)
True
list = []
print(m ** 0.5)
this.count = count
border.draw(drawer.drawer)
dtypedict
clear
A
myVariable = testVariable if bool(testVariable) else somethingElse
ssc = StreamingContext(sc, 10)
r = relativedelta.relativedelta(date1, date2)
shuffled = list(word)
intNull = models.IntegerField(null=True)
authors = serializer.IntegerField()
V = list(d.values())
self.render()
7 - 1.0
range_obj = range(1, 11, 2)
css = count / STEP
config.readfp(fp)
u = PyUnicode_New(nchars, PyUnicode_MAX_CHAR_VALUE(str))
d2.append([])
long_operation(arg1, arg2)
toolbar = fig.canvas.toolbar
settings[2] *= 5
print(error_string)
sgn * int(val) * 10.0 ** n
dt64 = np.datetime64(dt)
convexHull(Mat(contours[i]), hull[i], false)
i = 0
z = np.random.random((10, 10))
id(gb2.a)
customer_id = instance.id
stripped = (c for c in string if 0 < ord(c) < 127)
stop = 1
display_list = []
src = [0, 1]
c = HexInt(a + b)
timeout = 5
s = Series(np.random.rand(10))
random_keys = random.sample(item_keys, 20)
0
FreeLibrary(hlib)
self.data = self.from_id(id, db_connection)
setattr(self, elementname, element)
c = Child()
print(e)
t[v] = min(t[2 * v], t[2 * v + 1])
s = []
test
[build - menu]
print_zip(zipcode)
v = sre_parse.parse(pattern)
num += 1
a = optimize.brentq(func, xa, xb, disp=0)
patches = []
print(line)
register_adapter(LocalProxy, adapt_proxy)
send_over(shorten(k), v)
features_by_gram = defaultdict(list)
tree = tree[nodes[0]]
ir.py - h
usock.close()
xmlfile.write(newdata)
memo[s, t] = func(s, t)
dataGrid.ix[x] = nan
bi_tokens = bigrams(tokens)
dev = AudioDevice(2, bits=16, rate=16000, channels=1)
lcmap[i] = 0, 0.5, 0, 1.0
ssid = wlan.ies[0].info
ddl = [t for t in stmt.tokens if t.ttype in (tokens.DDL, tokens.Keyword)]
frameInfo = pFrameInfo.contents
start = 0
model = Model
myThreadState = Py_NewInterpreter()
nrows = (a.size + pad_length - L) // split_size + 1
ch = Tree()
mysum
t1 + t
cb.callback(namelist)
bytes_read += len
li = [(mat.group(1), eval(mat.group(2))) for mat in regx.finditer(ss)]
comments = list(thread.comment_set.all())
net.addConnection(FullConnection(h2, outp))
d = defaultdict(noisy_default)
pDict = PyModule_GetDict(pModule)
sum1 = count1[i]
task.retry = MagicMock(side_effect=Retry)
one = res[..., (1)]
self.items[position] = last_item
bItem = 0
x.dist = geomath.distance(geo_point.location, x.location)
print(x)
readline.write_history_file(historyPath)
infos = zf.infolist()
result < -update(userdata, freqs, diffs)
root / home / altera / www / mysite
float(test_utf16)
j = ephem.Jupiter(Observer)
print(spam)
counts = np.ones(ngroup, int) * (n // ngroup)
B = A[0:2]
self._ctx = self._hal.libhal_ctx_new()
buffer = ctypes.create_unicode_buffer(GetLongPathName(tmp, 0, 0))
aobj = a.A()
x >>= 1
bus = dbus.SystemBus()
docs = db.col.find()
PyEval_InitThreads()
l = [[x] for x in m]
print(test.row)
n >>= 8
similarities = collections.defaultdict(list)
pcorr
result
mask = arr != 255
X[closestN(X, 5)]
Xcart, Ycart = polar2cart(R, theta, center)
ends = ~a1 & a1_rshifted
print(a)
True == 2
randnum = istart
si = sample.simple_image()
bar = Bar()
text += msg
rr, rw, err = select.select([self.serversocket], [], [], 1)
sentiment = line_data[-1]
Pattern_groups = re.search(regex, self.Symbol)
d
p += n
fs = inspect.getframeinfo(of[0]).code_context[0].strip()
indx[slice_dim] = i
path = extend_path(path, name)
bad_lats = lats[bad_index]
parent = parent.parent
gl.get()
crustFrame = wx.py.crust.CrustFrame(parent=self)
[20, 22],
5
mapped = recursive_map(numbers, str)
tmp2.reverse()
df += int(self.smooth_idf)
change = db.PickleProperty()
pk = 0
self._engine.get_loc(key)
False
combos.add(tuple(item))
headers = {}
Returns
times = (row[0] for row in c.execute(SQL_TIME))
P, = plt.semilogy(X, Y)
src = [1, 2]
videos = []
y = x * nan
chunks, chunk_size = len(x), len(x) / 4
indices[sizes[j]:sizes[j + 1]] = m_ind[slice_]
o(1, 0) - -----o(1, 1) - -----o(1, 2)
v = 10.4
moo
resp
total = cov.report()
x
l = [(k.last_modified, k) for k in bucket]
steps = 1
dst_set = set(dst_seq)
m, n, r = mat.shape
d = defer.Deferred()
Kt = numpy.zeros(shape=(nt, n))
data(USArrests)
25.1 < lat < 49.1 and -125 < lng < -60.5
cov.stop()
params[names[-len(defaults) + pos]] = value
[nan, nan, nan, nan, nan],
d = overlap.setdefault(l1, {})
err.printTraceback()
Pose1 = posit(MarkerCoords, MarkerPixels1, F1)
a = defaultdict(make_hi)
rm / usr / local / bin / python
func.__code__ = c.to_code()
ctx = SSL.Context()
greeting
ret = get_jars_full(STORM_DIR)
self._app = app
s = np.random.RandomState(4294967295)
lgen[j] = gf_log[gen[j]]
d = NestedDict()
dostuff(my_element)
partial_counters = Pool(NUM_PROCESSES).map(Counter, chunks(y, NUM_PROCESSES))
object_id = models.PositiveIntegerField()
True
print(q[0])
model = user
model = Book
self.offset = 0
result = 0
datetime + timedelta
func(chunk, *args, **kwargs)
print(i)
first_row = False
str
feature_count = X.sum(axis=0).reshape(1, -1)
1 == 1 & 2 == 2
lst[i] = lst[j]
print(a, b, c)
sl[0] = sl[0][0], sl[1][1]
print(hex(id(method_reference)))
testme
n = master.index(first, n)
Application.Visible = True
generator = (cell for row in results for cell in row)
response = urllib.request.urlopen(request)
list()
running = True
arr = np.asarray(image)
draw2.text((0, 0), text=text, font=font, fill=(0, 255, 128))
new_dict[key] = value
idxs = np.arange(N)
deletev
mask = s.values != s.values.min()
adict = {(1): x}
self.match.end(n)
h.SetAutoLogonPolicy(0)
p2 = DummyObj(t1, list1, d1)
id = serializers.UUIDField(read_only=True)
test = test.strip()
bi = df.C == 0
print(test.SomeOtherName)
np.random.seed(0)
graph_def
max_len = val_len
kicks = [-5 * noise, 0, 5 * noise]
letter_groups = [letter_groups[key] for key in sorted(letter_groups.keys())]
print(10)
tmp = _ggplot2.ggplot_gtable(_ggplot2.ggplot_build(a_gplot))
test.body[0].lineno, test.body[0].col_offset
sint = ignore_exception(ValueError)(int)
preds < -preds(*1, **sum)
arg = PyTuple_GET_ITEM(arg, 0)
people[person.name] = constructors[person.gender]()
resident = resident.get()
s = {myString}
dictionary = dict(zip(*([iter(List)] * 2)))
d
print(docText)
i = 0
4 | 2
backToRows = zip(*columns)
print(x)
sequence
d = {}
UNDEFINED = runtime.UNDEFINED
x
settings_file
size += 50
y0, y1, y2 = np.log(fftData[which - 1:which + 2:])
domain = tldextract.extract(request.url).registered_domain
arr = vtk_to_numpy(vtk_array).reshape(height, width, components)
set2 = set()
squared_list_map = map(func, test)
reverse_iterator(begin())
Combined.append(entry2)
data = open(sys.argv[1]).read()
done = []
std_regex_duration = (std_regex_duration * i + (t2 - t1)) / (i + 1)
i = Image.open(fn)
m.close()
orig_py_compile = py_compile.compile
lcms.cmsCloseProfile(inprof)
L = pickle.loads(data)
-start
mime = MimeTypes()
print(d)
y = np.sin(x ** 2)
grep - v - e / app / projects / reallycool / lib
2 ** np.log2(2 ** 50) == 2 ** 50
c = [1000, 2000]
descriptions = list(description_el.stripped_strings)
xrange = np.arange(xlims[0], xlims[1], 0.1)
output = commands.getoutput(cmd)
l = list(row)
text
ModelClass = self.Meta.model
counts = np.bincount(inds)
res
seq + t(val)
x2 < -c(1, 11, 111)
out
myOldStrValue | int
1
smart_cmd = smart_str(cmd)
content = r.raw.read(100000 + 1)
field_data = self.rfile.read(length)
True
utm = osr.SpatialReference()
usock = opener.open(url)
4045
maximo = max(c_numero)
out = []
print(cap.isOpened())
utf8
ui = song.userInfo()
args_dict = {}
final_file = audio_class.render_audio(data=text_list)
L = linalg.cholesky(cov)
optimal = x2[0][1], x2[0][2]
samps = instance.rvs(k=1, size=10000)
context = self.listTools.get_style_context()
a
radiotap = RadioTap()
fghij
root = screen.root
output = subprocess.check_output(command, shell=True)
chosen_templates = []
cell = max(thisM), max(thisC), max(thisR)
app = wx.App(False)
result
a
A1.shape
cum_sum = np.zeros(im_size)
strings[0]
print(caller.__dict__)
db = dataset.connect(db_path)
value = 8
methods = inspect.getmembers(klass, inspect.ismethod)
model = Kumquat
upper = x
children.add(child)
10
new_loop = []
ds = sintheta * math.cos(center_angle) - costheta * math.sin(center_angle)
th.join()
RefCount = 0
print(master_table)
img2.download(image2)
con = df, df2
false
print(query_stat)
tags = [i]
Result_position = np.r_[[0], arrivals.cumsum()]
t = [55, 42, 18, 12, 4]
settings_dict = self.settings_dict
threads = tf.train.start_queue_runners(sess=sess, coord=coord)
result = {}
hover = p.select_one(HoverTool)
proxy = True
y = h / 2
matrix = [[(0) for _ in range(m)] for _ in range(n)]
bytes = [112, 52, 52]
cost = cost.split()
info = get_debug_queries()[0]
stack.pop()
chunksize = 20
prime_factors = get_prime_factors(180)
stratsample = []
body = part.get_payload(decode=True)
ArrayUtils.reverse(dst)
yellowness = y / (y + w)
self.buffer = StringIO()
temp_file_name = tmpfile.name
node = lexer.parse()
instance = LockServer(config)
row
birth_years = {}
m = s.todense()
real_part
idx_max_array = np.max(myarray, axis=0)
re.my_compile = re.compile
double(x)
df
d = jsonpickle.decode(js)
sources = env.CodeGenerator(file)
Man is [+HUMAN], [+MALE], [+ADULT]
False
ProcessId = ProcessIds[index]
print(color)
j = (a ** b ** 5) ** b ** 10
print(result)
infile = csv.DictReader(ifile)
response = request.get_response(self._f[request.path.lower()])
result_queue.put(execute(job))
c.base is a
i
self.doIt = myFunc
product_name, list_of_parts = input[bike_number]
focusednotebook = somevariablename
12
print(len_holes)
point = Point(12, 4)
head, tail = os.path.split(file)
G = D.to_undirected()
property_bsel = property_b[good_indices]
a = Anon()
result = []
out = {}
a_sps.A
str_record = {}
-1
0 < x
letter_groups = defaultdict(list)
table = tablerow[0]
dis.dis(Spam.egg)
log = Log()
rpm.labelCompare((e1, v1, r1), (e2, v2, r2))
result
self.m = spmatrix.ll_mat(*a, **k)
250000
s = _unhexlify(s)
root = ET.fromstring(vm_xml)
k = n - d
n.args = [stack.pop() for _ in range(num_args)][::-1]
d = collections.defaultdict(int)
edge_removed = True
print(tmp)
foo.size
x = lambda : bar()
+setattr(self, key, run)
required_idcs = sorted_dist_idcs_to_incl[:number_required]
raise
mem = MemcachedStats()
settings_dict = self.settings_dict
at_most(5, range(5))
X, info = bicg_solve(M, B)
items = list(range(10))
self.mayReturnEmpty = True
l1 = Lambda(x, Eq(x, 2))
df = yes_records_sample
model = MYMODEL
FLAG_1 = 1
abs.__text_signature__
opener = build_opener(HTTPCookieProcessor(CookieJar()))
url = response.url
a = []
item = self.getRandom()
close(unit=unit)
res = v is w
type(flights)
event.ignore()
needed = _GetShortPathNameW(long_name, output_buf, output_buf_size)
time = xDateTime.time()
0
valmin = -1.0
assert len(rdata) == 4
print(M_broadcast.shape, M_broadcast.flags.owndata)
my_ip = YOUR_IP
data = yaml.load(jAll, Loader=loader)
t = type(seq)
print(font_names)
Qt.QObject
pos = pixel_array_offset + row_size * y + pixel_size * x
retval = numpy.zeros((f, o))
foo
self.FileModel = FileSystemModel(self)
oldvalue.word_count -= _word_count(target.message)
print(prod)
self._total = self.tell()
res.tv_sec, res.tv_nsec
toolbar.addWidget(self.line_edit)
end = time.time()
output = csv.writer(outf)
tag = el.tag
s.convert_alpha()
gene_df
5 | 4
s = a[i:j]
fig, ax = subplots(1)
l
Cut - off
state = state_mat[(early_stop - 1), :, :]
size = a.shape[1]
print(df)
1.0141 * T ** 2 * p
2.0
sZones = Mid(sZones, 2)
intersected
up = (index + 1) / 2 - 1
someObject,
connection_id = 4497486125440
converted_number
mock_application = Mock(spec=Application)
y = x * 0.6
res = validate_test(CHILD(tree, 1))
emailMe(newData)
x_coord = cell.x_coord
f1, f2
instance.load()
raise
to_visit = [T]
2, 2, 2
a = map(f, simple_list)
matrix.A1
queue_name = queue_name,
RED += 1
out = out or {}
script_root / myapplication
frame = {}
spi = scipy.interpolate
print(a)
unigrams[token] = 1
i = 0
OR
a1.zipfiles,
wsgi_app(env, start_response)
print(w)
toks = list(tokenize.generate_tokens(f.readline))
matrix_surprise = [[0] * size] * size
element += 1
index.append((col, offset, length))
pct = []
valid = [slice(K // 2, -K // 2 + 1), slice(K // 2, -K // 2 + 1)]
file = cls.builtin_open(name, *args)
model = Question
_MAX_INT = sys.maxsize
d = dict(B)
idx_OUT_columns = [1, 9]
gene_count, TE_count = len(genes), len(TEs)
pop = stack.pop
self.Name = Name
only_ascii
sum = 0
volumeC = 10
cv2.floodFill(im_floodfill, mask, (610, 90), 128)
hundredDaysLater = now + timedelta(days=100)
key = offset_map.iloc[index]
vhost = true
python
k += 1
visit(curRoom.northNeighbor, curX, curY - 1)
selobj = lxml.cssselect.CSSSelector(csssel)
keys = [(j, c) for c in attribs]
src, tgt = g.vertex(0), g.vertex(1)
next_link
allWordDist = nltk.FreqDist(w.lower() for w in allWords)
textwrap.indent(replacement, indent)
python
f = Foo()
company_name = rowValues[0]
matlab = matlab_wrapper.MatlabSession()
self.s = s
[buildout]
PyErr_SetObject(PyExc_IndexError, indexerr)
encoded = s.encode(encoding)[:length]
x = np.random.random(size=N) * 100
print(error.httpcode, error.args)
contents = []
name | password_hash
insert_node(node, treenode.right, depth + 1)
Debug.Assert(arr != null)
obj = Struct(str(nr), *get_func(nr))
a
v = v - 1
pi * 1
f0(x)
mkdir / opt / portapy
f.labels
9 - 1.0
res = []
bx1, bx2 = sorted([random.random(), random.random()])
iterables.pop()
red_float = red_float * RMAX / 255 + 128
common_items = {}
line = line.trim()
t = BackpropTrainer(n, learningrate=0.01, momentum=0.99, verbose=True)
[install]
_hash = 1
model
print(result)
mask2 = mask1 & ~binary_closing(~mask1, [1, 1])
a.parent, b.parent = b.parent, a.parent
vanilla = 7
self.input_q = input_q
ty, er, tb = sys.exc_info()
prev = 0
top_bottom_y = min(y_t + h_t, y_b + h_b)
row
attr2 = Field()
attrN = Field()
5 + 4 + 6
query = json.loads(request.body)
version = request.endpoint
options[key] = value
window = gtk.Window()
a = 0
print(self.provider.get_greeting(self.who))
pthread_join(JoinThread, NULL)
stdout_events_enabled = true
locations = (lower_bound < a) & (a < upper_bound)
null
console.log(status)
s1 = pd.cut(s, bins=bins)
_eval_access(**f.access_control) == AccessResult.ALLOWED
warnings.formatwarning = custom_formatwarning
ch.highlight()
print((val1 + 0.0) / val2)
sl.on_changed(update_trace)
backend = default_backend()
wsgi_app(env, start_response)
totalToEnd = sumBefore[end + 1]
IntType = c_int
id(y)
epsilon = 1e-05
result
offset = sio.tell()
print(p4.diff(x))
classifications.append(classifier(sample))
switch(region)
old_hook = sys.excepthook
ob_start()
frame = QtGui.QWidget()
id(x)
0 - -(0)
unique_list_of_attributes = list(set(ml))
teacher = sch.Teacher()
account_id = 456
d_max
total += end - start
print(2 * (response[y2, x2] - min(response[y2, x2 - 1], response[y2, x2 + 1])))
random_list = [False] * j + [True] * k
encodingMap = {control_l: latin1, control_j: japanese}
len(token_dict)
dateBlank = models.DateTimeField(blank=True)
result = next(parseiterator)
kth_order_statistic1(r, k - len(l) - len(m))
queryVector = documentTermMatrix[:, (0)]
res = np.concatenate((zeros, a.take(np.arange(n - shift), axis)), axis)
app.Visible = False
userdata.append(result)
ridx = udist.row
print(a)
d = Deferred()
vocabulary_gensim[val] = key
l = [7, 8, 9, 10]
condition = lambda op1, op2: op1 > op2
pairwise[r, c] = games_won[r, c] / games_played[r, c]
point = Point()
self
print(create_tree(centers))
x
parser = ConfigParser.SafeConfigParser()
_logger = init_logger()
errors, okays = [], []
account = TestAccount
IPython.Cell.options_default.cm_config.lineNumbers = true
data = ruamel.yaml.load(jAll)
ComboBoxFrame().Show()
choices = set(choices)
f = Fernet(key)
counts = {}
prompts = []
Channel.BasicCancel(tag)
volumeB = 20
olist, ulist
xlsx = data.read()
builder = pjs.ObjectBuilder(schema)
backup.step()
print(data)
Xs = np.sort(X)
l
policy_encoded = base64.b64encode(policy)
exclude_binaries = 1,
value = args[0]
s
value = getattr(self, field.attname)
encoded_str = base64.encodestring(a)
print(p, p.is_alive())
cr.save()
print(to_sup(x.text))
register = Library()
form = PostForm(mydict)
hostname = hostname[:-1]
PyArray_Descr * dtype
example = {}
sum
print(f(1))
self.groupable_nodes = list(set(sum(self.groups, ())))
ball.y -= math.cos(angle) * overlap
self.subelements = p
clf = OneVsRestClassifier(MultinomialNB())
future = stream.read_bytes(128)
Digi_Results = [row, score, found]
frame = sys._getframe(1)
0
cal = pdt.Calendar()
self.content.append(st)
self._dx = dx
conn = EmrConnection(AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)
allSentences = []
coro = download(site)
mask = m < a
G = nx.Graph()
self.basedir / self.p
0 == False
print(tr.contents)
a = np.zeros(nx * ny * nz)
checker = [set(x) for x in checks]
data, addr = UDPSock.recvfrom(buf)
[DEFAULT]
worker_class = gaiohttp
Y = np.exp(-X)
y = mesh.points[edges[:, (1)]]
__metaclass__ = abc.ABCMeta
r = radius + altitude
mytest = Test()
bnds = (0.25, 0.75), (0, 2.0)
list2.fill(lis)
start = 0
centerY = (y2 - y1) / 2 + y1
retcode, output, err
subparsers = parser.add_subparsers()
xticks(*zip(*zip(count(0.4), prefixes)))
f.bar
shell.interact
rv = func(param)
val = 0
choice(p)
cvCvtColor(canny, rgbcanny, CV_GRAY2BGR)
a = Foo()
b = 0
manager.outputScan(ratio, 10)
self.__fn = fn
app_iter
destination
4
s = hardware.readbytes(2)
a = A()
print(vc)
print(output)
oRS.Close
whole_item = []
T_OPERATOR = 4
dictOfStuff = {}
1
N = 10 ** 4
a = np.random.rand(91, 91)
1
print(lemma.name)
count = defaultdict(int)
index = 0
q_key = ndb.Key(urlsafe=key)
total
tfidf = models.TfidfModel(corpus)
centerX = (x2 - x1) / 2 + x1
q = tf.QueueBase.from_list(q_selector, [train_q, test_q])
wrappedSocket.close()
[py2exe]
tag_dict = defaultdict(list)
pcolormesh(masked_data, cmap=cm.jet)
final += infile.read()
email_message = email.message_from_bytes(data[0])
buf = fsrc.read(length)
inner_session = session.registry()
new = appendabc(multilevelDict)
utm2wgs = osr.CoordinateTransformation(utm, wgs)
dtheta = np.arctan2(ds, dc)
print(text)
oneSquare = np.ones((nums.size, nums.size))
short_dict = shorten_keys(long_dict)
self.your_arg = your_arg
A = a.values
thread_results.append(response)
lines_required = 1000
rev = ele[::-1]
b = a
aggfunc = [np.sum, len],
switch_dict = {Foo: self.doFoo, Bar: self.doBar}
selected_i = i
p_temp = learning_rate * np.dot(e, self.q)
DF
print(content)
TypeError
SMaxX = 5
val = pp.OneOrMore(dotted_notation).parseString(tests)
k = 5
Other().self_prop()
custom_name = custom_name or name
QAbstractItemModel * model,
importances = regressor.feature_importances_
fh = logging.FileHandler(opt.logfile)
a = []
msg_out[:msg_in.shape[0]] = msg_in
serializer_class = api_serializers.SampleSerializer
conn = StrictRedis()
degToRad = lambda x: float(x) * math.pi / float(180)
win_geo = self.geometry()
i
i.remove()
utcnow1 = datetime(2014, 1, 1, tzinfo=pytz.utc)
h = {}
all_annots = 0
print(key)
[common]
myinstance = MyClass()
a
clearInterval(pinger)
shuffle(lengths)
self.namespace[tok.key] = tok.value
container = c.Container()
jr = gearman.job.GearmanJobRequest(j)
N = HALF_N * 2
print(soup)
dis.dis(Foo)
x_pt_in_device + x, y_pt_in_device + y
data[np.diag(rows, k=0), np.diag(cols, k=0)] = 0
group = grp.getgrgid(gid)[0]
v2 < -c(2, -10)
self.d[row][col] = val
out_arr[mask] = np.concatenate(V1)
d
Debug.Assert(list != null)
add_two = adder(2)
alldata = request.POST
phantom.exit()
print(object)
parts = cython - py
Rcpt
response = request.get_response(self._app)
command_help = dict()
users[users]
c.raw
pos = [event.x, event.y]
55 + 4
system(shared_obj_comp)
print(first)
manage.py
result = transform(a, b)
dtypedict = {}
newval = fooArray.frompointer(val)
par.read_file(t)
cell_entry.cell.inputValue = rows_map[row][col]
endpoint = enumerator.GetDefaultAudioEndpoint(0, 1)
1.5
b = 1
m = hashlib.sha512()
proxy = True
self.group[leadera].add(b)
print(B)
out
counts[ingredient] += 1
string
temp = 0
ax = timeSeries.plot()
post_save.connect(my_post_save_handler, sender=sender)
mkl_get_max_threads = mkl_rt.MKL_Get_Max_Threads
x_offset = y_offset = 50
date = date(year, month, 1)
fig = gcf()
temp_tuple = b, a + b
root.addHandler(fallback_handler)
f
x = [1]
x[i]
x = PrettyTable(dat.dtype.names)
threshold = 191
startsecs = 10
src, ext = build[obj]
print(a)
ngroup = 10
hours = datetime(2012, 5, 22, 9), datetime(2012, 5, 22, 18)
n /= i
iris = datasets.load_iris()
a
a = [1], [2]
bval = df.b[df.dt == p0]
r = int(tamaguchin.size)
ports = [60, 89, 200]
scr.insstr(row, max[1] - 1, str[offset], attr)
assert expression, info
ctx = {}
prec, _, _, _ = precision_recall_fscore_support(y_true, y_pred)
t2 = time()
print(C)
name, size = each.div.stripped_strings
self.ent = ent
sd.play(sig, fs)
f = Foo()
a1.appendleft(next(d))
objects_db2 = MyModelManager()
aList.append(row)
result
f = m * a
expr.resultsName = name
results = []
raise StopIteration
undefined_variable
d2 = frozenset(d)
pprint(expr)
funcs.append(lambda : x)
topFrame.pack()
temp_df_no_na.logged_dt
x ^= Py_SIZE(a)
f(item)
a = 1
rw = 51 * ((int(r) + 25) // 51)
print(prod)
len_lb = len(lb)
vectorizer = CountVectorizer(**kwargs)
print(val)
n = 2
a = pa - p0
myFoo = Foo()
exc_info = record.exc_info
subset_size = len(training) / num_folds
figure.scene.disable_render = True
PyObject * m
__metaclass__ = abc.ABCMeta
dirtyItems = {}
label
TE_in_TSS
x = CommentedMap()
os.close(pipe_w)
a.append((gene, TE_id, TEstart, TEend))
Gst.PadProbeReturn.PASS
post[k] = v
print(m)
{0} < {1}
b = B()
print(combined_astr)
c
phone_number = models.ForeignKey(PhoneNumber)
buffer_arr[:-1] = buffer_arr[1:]
o = Object(val)
resource.post(headers=headers, content=content, **params)
False
s
permutations = []
vec_states.push_back(i)
a
h = se * sp.stats.t._ppf((1 + confidence) / 2.0, n - 1)
cell = rnn_cell.BasicLSTMCell(num_nodes)
self.group[leaderb].add(a)
logger
self.pos = pos
out = StringIO()
cd / opt / elasticbeanstalk / bin
bio = response.read()
sete % al
ioResult = StringIO.StringIO()
magres = np.sqrt(u * u + v * v)
print(type(qqq))
str_info = _clean_str(usb.util.get_string(device, 256, 2))
print(Color.red.name)
x = 0.1
blabla
array = array[order]
s, i = find_size(n, i)
not_really_a_file = StringIO.StringIO(key_string)
num_components = 2
strings = pyparsing.Word(pyparsing.alphanums)
print(result)
id(9999)
pArgs = PyTuple_New(1)
str(freeGPUMemInGBs - GPUFreeMemoryInBytes / 1024.0 / 1024 / 1024), str
odecons = array([K])
monthlyPayment += 10
oScript = oMSP.getScript(sURL)
filename, line, procname, text = stack[-1]
long_dna = [dna_seq for dna_seq in DNA_list if len(dna_seq) > threshold]
make
K = 1.0
print(output)
[ui]
Ri = Vector([SomeCoordinates])
Rk = Vector([SomeCoordinates])
important_airports = (airport for airport in airports if airport.is_important)
N, COLOR
bytes_io = io.BytesIO(img_data)
threading._get_ident = gettid
record_dvd = session.xenapi.SR.get_record(sr[0])
available = list(range(lengthofdatabase))
result = sums * 1.0 / counts
print((provider, actor))
imgdata = cStringIO.StringIO()
idx = index.Index()
ftps = ftplib.FTP_TLS()
parser = argparse.ArgumentParser()
coup_sum = 0.0
user[:name].get
diff = sum(1 for x, y in zip(a, b) if x != y)
msg_out
func(4)
df1
cov = np.cov(xyi)
False
multi_line_word = OneOrMore(split_word + NotAny(White())) + Optional(word)
area = (maxX - minX) * (maxY - minY)
df
y = p.map(sleepy_squared, x)
args = [parser.parse_expression()]
pr2 = urlparse(url2)
print(pvt)
nlp = English()
response.image_index = index
m
[6, 4]
virtualenv - (2.7).python
_Lappend = self.L.append
className = list
a is b
print(x)
_processDataLine
childJoins = parentTable
m_min, m_max = mean.min(), mean.max()
-numpy
True
fnames = [fname for fname in fnames if isdir(fname)]
master, slave = pty.openpty()
cnt[item] += 1
cnt[k] = cnt[k] - 1
PostMessage(hWnd, WM_RBUTTONDOWN, MK_RBUTTON, lParam)
id(a)
x
scored = finder.score_ngrams(bigram_measures.raw_freq)
fig = plt.figure(figsize=(w, 0.7 * w))
n[k] += expected[o, k]
obj = getObjByType(objtype)
my_first_egg is my_second_egg
sentence
ports_strs = []
myList = [1]
items, item_ids = [], []
e = Decimal(0)
data = np.random.rand(n, batch_size, input_size)
sorted_dist_idcs_to_incl = sorted_dist_idcs[loc_to_incl_sorted]
user_input = eval(input())
img.compression_quality = 75
kwd_mark = object()
stack_trace = traceback.format_stack(frame)
some_list_of_stuff = list(some_set_of_stuff)
user_busy = [[1, 2], [2, 4], [5, 6]]
print(p1, p2)
print(dtz_string)
labels = np.unique(labeled_img)
dict2 = dict1.copy()
RES.imag = SPMAT.dot(G.imag)
b = [9, 10]
ydat = [np.sin(0.2 * (xdat - t) / np.pi) for t in tim]
w = evt.widget
data = next(self.stream)
Build.GC
x1 = p, d, q
start = time.time()
ma = np.ma.masked_where(T[(-1), :-1] >= -tol, T[(-1), :-1], copy=False)
Console.WriteLine(list.ChooseByRandom())
v = self.cache[key]
new_variable = 0
print(html)
end = PyLong_FromSsize_t(istop)
t = b
result = {}
Cre
row = prefs[user_id]
usertext = str(res.communicate()[0][:-1])
linger_time = 10
print(L)
print()
x, y = event.pos
free(c_arr1)
print(now)
board.digital_outputs = board.digital_inputs
s = s + 42
b.a = 10
handler = table.get(request.method, invalid_method)
print(tree)
result
ret += a[deg] * np.sin((deg + 1) * np.pi / tau * x)
r.history
dep = next(result)
env = dict(os.environ)
pygame.draw.rect(display, red, box, 1)
roc_auc = dict()
user = {}
iris = load_iris()
drop_privileges()
son[key] = self.transform_outgoing(value, collection)
d = stack.pop()
ptdBase = cndBase.cursor()
X = sm.add_constant(X)
cleaner = Cleaner()
end_lat = math.radians(end_lat)
b = categorical(a, drop=True)
linger_enabled = 1
junk = getch()
[extensions]
style.borders = borders
b = 2.0 * numpy.sum(temp * rays.direction, 1)
model = Survey
print(another_num)
stopwaitsecs = 600
numFontsAdded = AddFontResourceEx(byref(pathbuf), flags, 0)
shuffle(iterables)
request.vUser = authResult.account
Dur = 1000
res1 = []
l = []
c = c + 1
knotify.closeNotification(id)
number_as_str = str(number)
length = sum(1 for el in gimme())
buckets = defaultdict(list)
in_quotes = re.findall(str_in_doublequotes, pg)
x
inner()
size = image[0], image[1]
offsets_responses = client.send_offset_request(offset_requests)
execution_time = get_execution_time(input)
y = uniform(-2, 2, 100)
print(uid, gid)
document.body.appendChild(lngDiv)
7
c
print(url)
aio.Stuff.getter_s
buffer_size = 100
self.has_prev = bool(page - 1)
result[location] = 1
root.foo = Foo()
execute(pageFormat, [])
api.retweet(status.id)
A
links = set([n for n in group if n != node])
grouped = groupby(sorted_, key=itemgetter(0))
message[20]
v = sklearn.feature_extraction.DictVectorizer(sparse=False)
print(l)
print(_)
print(node.col_offset)
n = len(stock)
perr = np.sqrt(np.diag(pcov))
question_IDs = get_all_questions(dbconn)
request = event.request
buf_from_mem = ctypes.pythonapi.PyBuffer_FromMemory
tmp = max(lst)
lol[1]
a
parser.values.x_set_explicitly = True
acel_interp = interp1d(t_interp, acel(t_interp))
si.Close()
s += w * d * sf
4, 8, 9, 4.5
dist = euclidean_distance(o1, o2)
dsub
iter += 1
byteArrayOutputStream.reset()
DF_dism = 1 - DF_corr
result = result.rstrip()
_
print(win_percentage)
database = files
y = fit(results, x)
stream = BytesIO()
NOTIFY * HTTP / 1.1
print(location.latitude, location.longitude)
assert d is e
w_start = w_x
df
[commands]
n = 2
f = file(filename)
formfield
print(sensor.Value)
actual = string_representation(f(*args, **kwargs))
print(temperature_info.CurrentTemperature)
[non_rds]
answer = task(**next_task_args)
dr = ImageDraw.ImageDraw(im)
result
print(np)
count += 1
z = q.copy()
match
slots = sorted([(hours[0], hours[0])] + appointments + [(hours[1], hours[1])])
[]
self.obj = self.create(nr)
print(w)
self.event.set()
istop = _int(stop)
chan = ssh.get_transport().open_session()
c, x = inc(x), x + 1
print([(id(a), a.dest, a.option_strings) for a in parser._actions])
prev[url] = True
logistic._pdf(-500)
self.getitem(key)
blo, bhi = b.min(), b.max()
queues
obj.stringArr = dumps(data)
e_aligned = [i for i, _ in alignment]
old_a.__class__ = M.A
x = [(x * 0.005) for x in range(0, 200)]
randomized_list = some_list[:]
self
print(name_search)
fn = lambda : 1
model = Book
status, reason = error.httpcode, tostr(error)
const_reverse_iterator(cend())
foo = config.opt
asdf.image = i
Tprime = g[slices].T * Tprime
tmp += ch
PrimitiveGroup ** OUTPUT,
wkspFldr = existGDBPath.parent
nlines = int(nlines.split()[0])
deta = det(a)
setContentView(R.layout.install)
update_stmt = update(Test).where(Test.a == 1).values(b=2)
listdrivesout[idx] = drive.split()[2]
valids = valid[:-1]
my_new_posts = {(1): post1, (5): post5, (1000): post1000}
TGCTTGGACTACATATTGTTGAGGGTTGTA
payload_interceptor = PayloadInterceptor()
deleteports_strs
print(t)
all_on_left = all_on_left * -1
n = next(x)
mystruct.c = 0
current_process()._config
rev
Twitter(auth).update_status(status)
val, = islice(blah, 1)
list(multiprocessing.pool.ThreadPool(N_JOBS).imap(_single_compile, objects))
print(rendered1)
rssDataList = []
color_right = getColor(rightPixel)
x1 = range(min1, max1, step1)
numbers = [1, 15, 255]
server = self.buckets[serverhash % len(self.buckets)]
D2 = defaultdict(set)
numElems = int(math.floor(maxLength / len(remaining)))
PyGILState_Release(gstate)
print(self.indent + line)
s, s2
user_id
x += 1
urlsToVisit.Add(rootUrl)
employee_id
chunk = 1024
d[item2] = item2
print(codes)
xx = linspace(0, max(x), 500)
outer1 = 2
f
arr = np.array(range(2000))
train = df.sample(frac=0.8, random_state=200)
r = r.rename(columns=rename_cluster_cols)
a
passIf = createLambda(client)
log.ip_address = ip
sign = 1 if not keep_sign else int(math.copysign(1, integer))
a.attribute1
0 * F + T(10 * C)
shutdown / r
op = str_ops.get(my_operator)
display_picture.html
result = tuple(islice(it, n))
self.treeMenu = QMenu()
a = list(axis())
mdblist = createDeepMdbList(indir)
self.alive = 0
cache[n - 1][k - 1][pre - 1]
a_index = a_index + 1
a, b = 2, 0
switch(fdwReason)
ctx = gmpy2.get_context()
render_partial = template.render(template_dir, globals=template_globals)
ipython
print(cls.instance)
execute_unix(c)
length = 10
good = []
[1]
print(df)
app = get_app(app_name)
df = pd.DataFrame(np.random.randn(1000, 2)) * 1000000.0
timeit.timeit(t4)
d.addCallback(start_app)
items = []
plugin_module_name = entry_point.module_name
arrayIN[-len_NewRows:] = NewRows
target_leafpos = np.treeposition() + np.leaf_treeposition(0)
map(root.removeFilter, root.filters[:])
t = df_null[df_null]
self.heap = list(self.set.keys())
WSGIScriptAlias / app2 / app2 / app2.wsgi
iv = -4294967296 + iv
color1_occupations = [1, 0, 1, 2]
django - debug - toolbar == 1.5
print(sm)
cluster_foo.add_node(node_foo)
apdu = READ + STARTMSB + STARTLSB + MEM_L + DATA
assert d == {}
nstd = stats.norm.ppf(pp)
assert expected.sort_index().equals(alt)
x_rem = x - x_int
Blue = BufferedImage % 2 ** 8
current_combo = []
cache[n]
retcode = ps_command.wait()
x
the_sum = _ensure_numeric(values.sum(axis, dtype=dtype_max))
declaration = child
final_path = os.join(start_path, *list_of_vars)
print(astr)
observers.append(observer)
al = ActionList(Jump(), Run(), Jump(), Jump())
pygame.draw.rect(screen, BLUE, blue_rect)
0
expression = 0
[]
destinations = line[1:-1]
subplot = figure.add_subplot(111)
FFT_FREQS_INDS[ind] = led_ind
total = sum(f(next(x_strm)), axis=axis)
4
print(holder.obj)
_ + 5
z = np.zeros(size - nz.shape[0])
extra = ctypes.c_ulong(0)
avg = sum(mylist) / len(mylist)
ds = SequentialDataSet(INPUTS, OUTPUTS)
m, n, r = b.shape
BarObject_Type.tp_flags = Py_TPFLAGS_DEFAULT
cookieValue = decodeURIComponent(cookie.substring(name.length + 1))
volumeNameBuffer = ctypes.create_unicode_buffer(1024)
src = [0, 2]
e = pq(url=results_url)
__builtin__.greater_than_zero = lambda x: x > 0
X = np.fft.rfft(x, N)
index_url = YOUR_URL
reader = csv.reader(f)
chars_read = read(fildes, buf, chars_left)
total += word_count(l)
array = tuple(range(5))
ipython - -pylab
f(l[0]) | bool_loop(l[1:], f)
html = gz.read()
currentAxis = plt.gca()
b = int(mean[2])
s = uuid.uuid4().hex
use_tab_to_indent = true
labeled_img = measure.label(img)
k = 2
con.row_factory = namedtuple_factory
iv = os.urandom(16)
self._hash = hash(self.left) * hash(self.right)
file_name = field_storage.filename
sx, sy = ar.shape
y = y + y[-1] * (len(x) - len(y))
A * x + B
a
coins = []
2
diff = ImageChops.add(diff, diff, 2.0, -100)
graph = GraphAPI(token_app)
v.push_back(*rit)
decimal.getcontext().prec = ndigits
self.broadcast(data)
concordance_index = nltk.ConcordanceIndex(text.tokens)
es_formats.SHORT_DATE_FORMAT
last = np.zeros(len(df[categories[0]]))
out = []
record2 = Record.get(key)
X = np.arange(-5, 5, 0.25)
gene_pos += 1
memoryview(a0) == memoryview(a0)
dc = costheta * math.cos(center_angle) + sintheta * math.sin(center_angle)
tmp = np.sum(data[i::row_sp] for i in range(row_sp))
foo = FooObject()
product.listing.category = product.assets[0].category.name
i = -1
s
K1 = [K[i] for i, item in enumerate(V) if mask[i]]
print(item)
http.send(params)
inserts = []
args.update(params)
f(*(seq[:k] + (x,) + seq[k:]))
connection
ret = True
a = (sigma + z) * (k * (qs / cs) ** (z - 1)) * cp
boby.bark()
print(i)
x = np.multiply(gauss, r / length)
host, identity_file = identity_file, local_path = local_path,
x = [12, 101, 4, 56]
path = []
wrappingFunc
running_sum
mime_type = mime.guess_type(url)
self._paragraphs = []
-bin
filename
freqs = fftpack.rfftfreq(N, d=(xReal[1] - xReal[0]) / (2 * pi))
handle_exception()
r = [x for x in array if x > pivot]
Y = scipy.zeros(len(X))
print(row)
-1
self.old_lang = translation.get_language()
eastern_time = eastern.localize(datetime1)
final_labels = []
self.model.stop_training = True
tests.py
key1_dups = frame.key1[frame.key1.duplicated()].values
Y = dist_matrix(items, dist_fn)
job = {}
coins += [cent] * n
num = 11
approxPi(1000)
stacked = df.stack(dropna=False)
data
x += 20
nD = Sigma.shape[0]
ssh_password = _password,
print(s.name)
_, dy = inv.transform((0, 0)) - inv.transform((0, y1 - y2))
copied += len(buf)
pi = ctypes.cast(foo.pi, ctypes.POINTER(ctypes.c_double))
[default]
url = usock.geturl()
X_est_prev = dot(A, Y)
raise AttributeError
t = threading.Timer(timeout, conn.cancel)
max_mtime = 0
graph = GraphAPI(token_app)
future_to_key = {}
list_ex = [7, 8, 9, 0]
print(e)
print(s)
duration = 1.0
l = [dt, dt]
a = add
user[k] = v
content = paragraph.firstChild.data
carole = c(squid=0.2, octopus=1.0, cuttlefish=0.4, nautilus=0.4),
result = my_ten + my_one
2
b
file
lxml = match[0]
total
unsignedVal = int(input, 16)
{}[tuple()] = 1
num = 0
dirnames[:] = [d for d in dirnames if predicate(r, d)]
voronoiBackground = background_model.predict(np.c_[xx.ravel(), yy.ravel()])
so, sys.stdout = sys.stdout, StringIO()
intervals < -data.frame(start=intervals[-length(intervals)], end=intervals[-1])
comment_feed = yt_service.Query(comment_feed.GetNextLink().href)
inc()
p = parsedatetime.Calendar()
jobs.append(p.spawn(get_links, url))
set = False
hello, stderr
updateReference = restultBuffer.toString()
secret = yaml.load(content)
m = [x for x in array if x == pivot]
A = health == max_health
sound_encoded = b64encode(sound)
s = d / mdev if mdev else 0.0
np.multiply(fnc, t)
np.multiply(nfc, t)
res = np.concatenate((a.take(np.arange(n - shift, n), axis), zeros), axis)
favorite_color = pickle.load(f_myfile)
data = session.get_decoded()
np_training = np.array(training_data)
console_handler.setFormatter(default_formatter)
l = file(appendedFile).readlines()
keysym = Xlib.XK.string_to_keysym(emulated_key)
self._exception_type = exception_type
s.flush()
B1.expand(alpha1).integrate(r1_x)
end_iter = text_buffer.get_end_iter()
req_obj = json.loads(request.body.read())
employee.id = reader.getAttributeValue(0)
content = r.raw.read(100000 + 1, decode_content=True)
1
math.trunc(f)
val = sequence[i]
order = models.IntegerField()
mock_file = BytesIO(data)
layout.set_width(pango.SCALE * w)
raise VersionConflict(dist, req)
h = help(module)
freqs[items, items] < -freqs[items, items] + 1
results = heapq.nsmallest(4, flattened)
number2 = 1
x0, x1, y0, y1 = plt.axis()
print(c)
raise
print(pi)
value = w.get(index)
c = c * (n - k + 1) // k
msgs = {}
tree.body
cir_R = int(Ro * 2)
set1, set2 = set(), set()
triple_response = SPO(source, db_name, table_name, response)
8 / -7
f > 0
intercept = 0.0
m = ob.getData(mesh=True)
ts = time.time()
pool_args = []
v
renderer
rows = set([d for d, t in list(doc_term_dict.keys())])
A
algo = cert.get_signature_algorithm()
mod = imp.find_module(PACKAGE)
out = result.fetchall()
raw_ta[tty.OFLAG] |= tty.OPOST | tty.ONLCR
list_per_page = 10
numerator = sum(item[1] * upsilon ** (t - item[0]) for item in q)
res = res_male.get()
getsizeof(second)
x
cursor = connection.cursor()
ipdb > n
ctypes.pythonapi.PyTraceBack_Here.argtypes = ctypes.py_object,
index.initializer.run()
q = np.matrix(w * (A - B))
res = np.dstack(rows[i:i - window] for i in range(window))
loop = 2
coord.join(threads)
0
row = [user, latitude, longitude]
y = object()
OperationMode = 24672
1
ret.append(name)
DWMWA_EXTENDED_FRAME_BOUNDS = 9
send(pi, loop=True)
x_range = list(range(0, 224))
ts = [datetime.datetime(1601, 1, 1) + datetime.timedelta(microseconds=f // 10)]
events = ElementTree.iterparse(response.raw)
L1 = json.loads(s)
0
diff = col1 - numpy.roll(col1, 1)
result
g = lambda x: x * 2
result
bars[2].date
t = np.arange(0, t_total, 1 / f_sample)
print(a)
y = x / norms
payoff = PlainVanillaPayoff(Option.Call, 100.0)
read = fob.readlines()
m = df1 != df2
p0, p1, p2 = polygons
thorny
CloseHandle(hProcess)
False
out
1
self.drag_sphere = 0.47
arr = np.dot(x.T, x)
whole_item.append(image)
index_of_2nd_I
d = display.Display()
print(eval(line))
counter += 1
divisor -= 1.0
print(res)
plt.contourf(xx, yy, voronoiBackground)
HDFStore.__exit__(self, *args, **kwargs)
pos[1:] = np.cumsum(sub_sizes)[:num_threads - 1]
True
print(h)
recreatedModel = Sequential.from_config(modelConfig)
unit = 1
maximum = max(diffs)
N = 2
redirect_stderr = True
c = 0
q = pq(r.content)
d[t] = d.get(t, 0) + 1
[general]
print(y)
matches.apply(lambda x: bool_loop(x, bs))
dis.dis(method1)
N_JOBS = 4
end
b
folder = fso.GetFolder(folderPath)
print(s.check())
ClassLevelDocumenter.add_directive_header(self, sig)
fs.extend(l)
root = pow(a, (2 * p + 1) / 9, p)
x, y = l.get_data()
done
exA2 = a[2]
sc = SparkContext()
mkl_get_max_threads = mkl_rt.mkl_get_max_threads
converted = new.quantize(palette=src)
num_stars = 10
outputfilename = self.image_filename
DebugVarNode(bits[1])
attr = []
diff_to_previous = df.Grp != df.Grp.shift(1)
t = Text()
NotImplemented
limit = 100
userInput = 0
r[i][j] = (cos(x) + I * sin(x)) * y
old
zipped = zip(timestamps, htmls)
sums = a2.sum(axis=axis)
Const.x
self._data = wrapped
_another_string_
identifiers = codegen._Identifiers(compiler, node)
comparison_array = table.values == expected_table.values
print(fortran_mod_comp)
m = wx.MemoryDCFromDC(s)
data = T.matrix()
ws.send(message)
1
apt_pkg.init_system()
terminal_width = int(terminal_width)
background = arr == 0
origin.setConstrainTypesMode(constraintypes.ENABLED)
y, x = tup
last_result = result
Distribution.has_ext_modules = lambda *args, **kwargs: True
row = FooRow(1, 2)
result = h.responseText
w.document.open()
tone2 = note(140, 2, amp=10)
namedPi = Record._make(tuplePi)
factory = TCPClient(io_loop=io_loop)
a = {}
result
out = np.full(mask.shape, np.nan)
r_den = np.sqrt(ss(xm) * ss(ym))
print(response.answer)
self.path |= other_node.path | {other_node}
i = inspect()
my_first_egg.pk == my_second_egg.pk
cc_top += new_connected_triplets
g = compose(g, square)
exA1 = a[1]
y = 10.0 * np.sin(x)
readEnd, writeEnd = os.pipe()
char * data
free(final_array2)
out2 = csr_matrix(M1).dot(M2)
buf_from_mem = ctypes.pythonapi.PyMemoryView_FromMemory
finder = BigramCollocationFinder(word_fd, bigram_fd)
str
dict
bg_queue = Queue()
length = delfile.tell()
map.setCenter(center, zoom)
dataGrid = dataGrid.sort()
net.addOutputModule(outp)
id_orders = {}
host = _local_bind_address,
long_dna = (dna_seq for dna_seq in DNA_list if len(dna_seq) > threshold)
prev = item
print(D2.d)
pathbuf = create_unicode_buffer(fontpath)
sieve[i + val::val] = [0] * tmp
a = []
0.1 == 0.1000000000000999
10 < x < 20
lines[ln] = res
iterator = islice(l, 10)
d.addCallback(pprint)
remove = string.punctuation
client_id = {app - id}
result = result[0]
latest_start = max(r1.start, r2.start)
acceptance_prob = (high - proposal) / (high - mode)
update_script_startup_file
ParentFormSet = formset_factory(Parent, extra=1)
newHeight = 500.0
console.error(err)
tree = transformers[flag](tree)
number = number - number * 2
reg
logger.info(message)
[h2, e2, s2],
str(o)
s + self._file.read(amt - len(s))
inverse = str(1 / hz)
t, c, k = scipys_spline_representation
fields = m.groupdict()
print(p4.diff(y))
g.groups
ind | ind2
print(version)
cf = myclass(a=A, b=B, c=C, d=D)
y + 2
f
False
print(desired_val)
cov = coverage()
my_cursor.execute(insert, [isbn, shop_id])
a, b = 0, 1
-b
val = np.random.rand(1000)
record = outputTbl.append()
file4
self._values = array.array(self._value_type, zero_string)
print(result)
val = array[x]
od = OrderedDict()
d[l[0]] = v
y.a
print(field_of_circle(radius))
root
type(2 ** 62)
all_losses = [loss] + regularization_losses
cost = 0 if s[-1] == t[-1] else 1
mi = df.columns
domain = domain.concatenate(dns.name.root)
major, minor, micro, releaselevel, serial = sys.version_info
metadata = BoundMetaData(db)
linesNew.append(temp2)
process_pk()
print(k, m.getlist(k))
links = []
b = True
af = a.astype(float)
f - 1.0
s
soup = BeautifulSoup(r.text)
merge(split_image, output_image)
res
outer1 = 1
d += 4
print(values)
new_path = []
d = test.DoubleVector()
image_Im = cvCreateImage(cvSize(dft_N, dft_M), IPL_DEPTH_64F, 1)
processes = 8
y = x ** 0.5
myParam1 = 1
describe_symtable(child_st, recursive, indent + 5)
pairLambs = []
img1 = StringIO(data)
my_randoms = []
magic_index.insert(axis, indices)
testfile = tempfile.TemporaryFile(dir=path)
-defaults
score = 1
print(df)
inputs = list(range(10))
t = school.Teacher()
request.source(hit.sourceRef())
len_s, len_t = len(s), len(t)
offset = 1
three_gaussians(x, h1, c1, w1, h2, c2, w2, 0, 0, 1, offset)
nameOfFirstCustomer = customers[0].name
lat_min = lat - half_side_in_km / radius
good_array[to_replace, i_column] = maxs[i_column] - 1
m = m1[:]
score = np.array([[102], [106]])
mask = functools.reduce(lambda x, y: x & y, masks)
NO_WRITING = NO_USER_WRITING & NO_GROUP_WRITING & NO_OTHER_WRITING
patterns = resolver.reverse_dict.getlist(view_name)
True
point = {}
x
__iadd__ = modify_method(list.__iadd__, takes_list=True)
v
k, m, n = A.shape
arr = np.where(arr, 0, 1)
html = hxs.extract()
futures = c.compute(lazy_values)
provideUtility(Greeter(), IGreeter)
new_args = args[:k] + [x] + args[k:]
n = 1024 * 1024
d
a
cache = {}
self.database = database
print(notice)
allow_domains = allow_domains, deny_domains = deny_domains,
kwargs = eval(self.question.custom_query)
exit
havename = thestring.find(t, 0, firstcomma)
pprint(key)
y = w
str = String()
[]
print(has_microseconds_time)
d, m = divmod(number, base)
print(animals)
other_rooms_view(request)
edge_stats[a, b][0] += 1
command_help[key] = getattr(Task, key).__doc__
s
input_coordinates[ii] = output_coordinates[ii] - shift
1 in st
y[0, 0] = initial_y[0]
numEquations = 15
baz
tagged_sent = pos_tag(sentence.split())
output = []
self
igd = gupnp.igd.Simple()
self._compile(obj, src, ext, cc_args, extra_postargs, pp_opts)
links = []
thetas = simulate(theta, ticks)
594
598
x = np.arange(10)
raise
common_items = c.most_common(2)
foo1()
last = li[0]
self.y = 2
x
LoggingCursor.execute(self, query, vars)
url, body
f, filename, desc = imp.find_module(m, plugin.__path__)
mu1 = -1
print(neginf + inf)
mask.negate()
ndigits = int(log10(1.62) * num + 100)
ret
decoder = JSONDecoder(object_hook=hook)
x[value]
A_data = load_diabetes().data
0
desired_content_is_loaded = false
dir(cmath)
[resources]
not a
test_dir, _ = os.path.splitext(filename)
next_friday = today + rd
x0 = 1, 1
stderr_capture = False
user_db_list[0]
a
mytime = datetime.fromtimestamp(timestamp / 1000)
all_posts_uuid_list = all_posts_uuid_query.execute(timeout=20)
c = 0
perm = unrank(n - 1, d - 1, r)
T * data
packet.ParseFromString(msg)
runs_allowed = float(scores[1])
f = PDB_Calculator()
src
s = Suppressor(yourError, locals())
title = d.channel.title
my_set = my_set | {2}
j = i - j
callback(node)
_precalc_table[i] = i ** 2
x1 == x2
generator = gen()
y_db = db.fit_predict(distance_matrix)
print(t)
error.replace(suggestion)
CREATE_NO_WINDOW
print(next_item)
A = arange(100000)
Freq = 2500
print(b.eval())
r, g, b = im.getpixel((x, y))
Quartz.CGImageDestinationAddImage(dest, image, properties)
print(datetime.datetime.now(eastern).time(), a, b, c, d)
month_aggregate = defaultdict(list)
session = aiohttp.ClientSession()
n = 10
tuple(tasks)
idx[names] = True
all(0 < size < baz for size in lengths)
model_ols = linear_model.LinearRegression()
f = myplot(t, x)
self.console = sys.stderr
s = aio.Stuff()
s += arr1[i] * arr2[j]
cachable = make_response(rv).data
k, b = np.linalg.lstsq(A, y)[0]
numerator = self.n_executed + self.n_executed_branches
T_NAME = 1
print(_)
date + time
y.A
y[0, 1] = initial_y[1]
CWR = 128
x = 100
sys.excepthook = handleException
r = True
copy_of_regular_query_dict = regular_query_dict.copy()
exec(mod, globe)
storeSugar(hierarchy)
sbigger = set(bigger)
b_pages_links = getlinks(A)
print(alist)
nms
X = []
print(sep)
tree = self.get_fidesys_tree(*command.args)
self.subs = []
rows = []
values = defaultdict(list)
True
h = defaultdict(list)
more_data = transform1(piece)
image = decode_jpeg(file_buffer)
d.append(vals)
tdm = textmining.TermDocumentMatrix()
batch_size = len(pages) / SIMULTANEOUS_CONNECTIONS
self._defaults = self._dict()
ingredients.append(ingredient)
mask = np.logical_or(hourOfDay <= 7, hourOfDay >= 22)
records = sf_client.query(lead_qry)
sortkey, row = key
plugin = load_plugin(name)
links
all_combos = []
components = vtk_array.GetNumberOfComponents()
found = set()
awscli
1 - 1.0
print(out)
a = 1
shape_id, shape_pt_lat, shape_pt_lon, shape_pt_sequence, shape_dist_traveled
player = best[1]
a.parent.right = a
hddict[val[0]] = val[1]
user = sout[0]
url_trie = StringTrie()
magic_slice
self.somelist[key] * 5
rd, cd, order = optics(points, 4)
self.x = x
K, d, N = A.shape
end = source.find(e)
item = float(item)
print(A)
print(t)
b = 100
two = 2
count2
self.accuratePastSecond = currentTime - self.accurateSeconds
f.free_symbols
print(list(ddb2.tables.all()))
b
r0 = Redis(db=0)
remaining_space = min(batch_size - batch_index, len(context))
f.truncate(0)
result = packl(unpackl(data) ^ unpackl(key))
c1 = myVector(1, 1)
gotoLastVersion()
myShape = Part.makeBox(2, 2, 2)
T & m_t
train = df[msk]
exponent = ilog(n, base)
color2_occupations = [0, 2, 0, 1]
d1 = d1.div(d1.quantile(0.99))
argSplits = []
unique_id
xlen = 10
Integer.valueOf(o1.size()).compareTo(o2.size())
print([int(n) for n in y])
answer + 1
variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY)
gateway_info = netifaces.gateways()
c1
ar[m - i] = ar[m - i - 1]
b = b * pi / 180
test
print(table * 100)
tas = time.time() - tas
walk_tree(data)
s = slice(0, sys.maxsize + 1)
IntArray5 = c_int * 5
path = [destination]
clusters = dendrogram.as_clustering()
init_opts()
print(each)
self.possible_strings = list(invRegex.invert(regex))
indexed_what = pd.Series(what.values, index=basis.values)
result = done.pop()
myarray = [1, 5, 50, 500]
model = Post
PROCESS_TERMINATE = 1
a2.binaries,
print(key)
x = 1 / 0
indices = []
retry = True
xs, ys = a, b
abstract = True
B.my_member.append(2)
labels == 0
d1 = numpy.zeros(i1.shape)
data = in_file.read()
channels, sample_rate
es_formats.NUMBER_GROUPING
r = np.arange(n)
ctx = {}
c = get_config()
oldMethod = Foo.bar
self.intAttribute < other.intAttribute
valid_mask = np.mod(np.arange(M * M), M + 1) != 0
fg = urllib.request.urlopen(fg_url)
fib_helper(num)[0]
YResolution(72, 1)
A = Y.real
incSize = -1
tmp < -ggplot_gtable(ggplot_build(a.gplot))
indexes = ~np.isnan(x)
cv_acc = map(lambda tp: sklearn.metrics.accuracy_score(tp[0], tp[1]), ys)
print(r)
printer.start()
ind = bisect(dates, date, hi=len(dates) - 1)
l
retval
obj = CallMe()
self.verbose = verbose
print(x_normed)
x
x + offset
aStart.setParseAction(matchInterestingHrefsOnly)
detected_minima = local_min - eroded_background
new_instance = deepcopy(object_you_want_copied)
arglist = arglist.split()
client = cache._client
xvals = list(range(0, 10)),
result = _result.value
mappend = marked.append
t = np.arange(0, 10, 0.005)
D_inv = np.linalg.inv(D)
_MAX_INT = sys.maxsize
sqlhub.processConnection = connection
new_current_combo = current_combo[:]
story = [Image(img1), Image(img2)]
session.expire_date = timezone.now()
request = dns.message.make_query(domain, dns.rdatatype.ANY)
rst = add.apply(args=(4, 4)).get()
print(volume.GetMasterVolumeLevel())
index
[t, p, v]
gl = gevent.spawn(fail)
rcc.setFirefoxProfileTemplate(newFirefoxProfileTemplate)
FE_UPWARD = 2048
n = 5
DESCRIPTION
i0.b = 2
dt
model = UOMCategory
d1.append([])
compare_and_swap(taken[leftFork], true, false)
dis(f)
list(range(7))
referenceMatcher.appendTail(restultBuffer)
bval[q] ^= 1 << r
fb = []
FileNotFoundError = IOError
transformed.printSchema()
a = np.random.rand(num_tuples, 2) * max_int
cd / home / el / bin
b = numpy.zeros(data_length * 2)
f1 = lambda : 1 + 2
a = b
parser = argparse.ArgumentParser(parents=[argparser])
normalizer = Normalizer()
distance = currentPositions[(iParticle), :] - positionsJ
ret
window_starts = pd.Series(window_starts, index=window_starts)
sm = SequenceMatcher(a=answer, b=prediction)
a = A()
info
assertEquals(guavaVersion, commonsLangVersion)
maxsize = 1024, 1024
regex_test = timeit.Timer(regex_test, setup=regex_setup)
arr2 = arr1[0]
wrapped
p = w.palette()
probegenes
offset = max[1] - col - 2
l = list(range(12000))
compiler = MSVCCompiler()
1
done
print(Blues(0))
f = FactorWorker()
a
[openerp - web]
urllib.request.FancyURLopener = FixFancyURLOpener
nexts = cycle(iter(it).__next__ for it in iterables)
self.parent.write(self.func(str))
0.0
zindex = 0
obj, end = self.raw_decode(s, idx=_w(s, 0).end())
edges = numpy.vstack((mesh.vertices[:, :dim], mesh.vertices[:, -dim:]))
filled = sp.ndimage.morphology.binary_fill_holes(data)
plugins = set()
12
mask = A != 0
collstart = p
ip_addresses = df.source_ip.unique()
sinLat = np.sin(lat)
x
tid = ctypes.CDLL(libc).syscall(cmd)
fftyShift = np.fft.fft(yShift)
weighted_row = [row.ColA] * row.ColA_weights
raise PKIsFalseException()
x = np.random.normal(i, 0.02, len(y))
beta[i] = (c * ss - s * sc) / (ss * cc - sc ** 2)
is_parent, my_arg1, my_arg2 = daemonizer(path_to_pid_file, my_arg1, my_arg2)
print(fb_response)
cls = getattr(module, cls)
out
ends = np.insert(my_diff, -1, 1)
exec(bash)
print(b)
param = json.loads(self.param_str)
x is y
h2, m2, s2 = t2.hour, t2.minute, t2.second
nameOfFirstCustomer = customer[0].name
chars = self.col_seq[j - 1] + self.row_seq[i - 1]
self.anniversary_score = a_s
idx[mask] = i
r = FormRequest(url, formdata=frmdata)
resized = myimg.resize((5, 5), Image.NEAREST)
form_class = forms.KumquatForm
image = cv.LoadImage(filename, cv.CV_LOAD_IMAGE_COLOR)
thetas.append(theta)
diff = 60 * 60 * 24
masterSet = set()
today
lettfreq = OrderedCounter(test)
A = fwp(x, y, a)
ax2 = fig.add_subplot(2, 1, 2)
source = source[end + 1:]
c_values = c
print(s.index // k)
f
foo
k = PyKeyboard()
nrow = (len(accountList) + ncol - 1) / ncol
batch_request = gdata.spreadsheet.SpreadsheetsCellsFeed()
wintypes.DWORD(open_mode),
n < -length(ratings)
log4j.logger.org.eclipse.jetty.util.component.AbstractLifeCycle = ERROR
readRequest += chr(6)
y[i] = xi ** 2
df = DataFrame(Y)
testData
g = grad(your_loss)
print(e.code)
nan < 1
_i = 10
L
value = mc.get(key)
indices = [np.where(label == ind) for ind in range(1, n)]
isApple = True
application_path = sys._MEIPASS
redis_sub = redis_client().pubsub()
results = wordPattern.search(html)
resolver = urlresolvers.get_resolver()
save.side_effect = mock_save
dist, ind = tree.query(coords, k=2)
rv
copy = type(original)()
p = Parent(pname, pid)
carIndex = 0
bulkProcessor.close()
a = jsonpickle.decode(js)
d = defaultdict(int)
print(idx)
dic[5]
threshold(gr, bw, 0, 255, CV_THRESH_BINARY | CV_THRESH_OTSU)
build_ext.run(self)
files = files[:100]
b = []
sent = nltk.corpus.treebank.tagged_sents()[22]
fitted_pl = powerlaw.Fit(pl_sequence)
self.getvalue()
view_2_noblock = rc[0]
ready.append(0)
current_env = environ.copy()
not_indices = np.setxor1d(ia, indices)
inst.name = name
paths = list(get_pyfiles(directory=directory, exclusions=exclusions))
dir(datetime)
completed_chapter = models.ForeignKey(Chapter)
1
model = Author
do_whatever
p = PlotData()
ss += w * sf ** 2
aBytearrayOfINTs = bytearray()
inner_r = int(Ro - 0.5 - len(img))
df
Lval, x = quad(L, lastG, g)
ddof = 0
rand_num = random.randint(1000, 10000)
print(x)
combos.add(frozenset(item))
df1
foo_iterable(thing)
x
print(output)
x0 = np.linspace(5, 0, 25).reshape(1, -1)
virtualenv / tmp / temporary_virtualenv
w = widgets.interactive(sigmoid_demo, a=a_slider, b=b_slider)
instance_id = rc[0].id
print(newest)
newstring = oldstring[0]
print(dist)
a is b
Pose2 = posit(MarkerCoords, MarkerPixels2, F2)
count = count + 1
redirect_if_needed
[build]
M = int(sys.argv[1])
deleteos, atexit, readline, rlcompleter, save_history, historyPath
g = urlparse(u)
cooldown = memcache.get(cooldown_memcache_key)
k
X_test = unseenTestData
f_vals = np.random.normal(size=(xs.size, ys.size))
rolled = window_starts.apply(applyToWindow)
year = models.IntegerField()
StdDraw.line(xmin, ymin, xmax, ymin)
d2[-1].append(y + x)
[hour, minute, suffix]
print(result)
index = 0
d1, d2 = dist.T
vec = CountVectorizer(tokenizer=tokenize)
b = map(f, another_simple_list)
print(part1 + part2)
v
username, password = config.password, use_tls = config.use_tls,
++ok
M = L * (I * (1 + I) ** n / ((1 + I) ** n - 1))
res = _PyLong_Format(index, base, 0, 1)
oid = repo.write(g.GIT_OBJ_BLOB, contents)
nb_lines += 1
client = httpclient.AsyncHTTPClient()
user_options = []
temp_name = next(tempfile._get_candidate_names())
init_session()
score = temp_max
createLog(logpath)
arr
start_row = row_slice.start
x %= 2 ** 64
string
0
real_command = command
field.errors[:] = []
1, 2
a
chunker = nltk.RegexpParser(grammar)
id
FE_DOWNWARD = 1024
p = getPixel(aPic, w, h)
tree = cKDTree(data)
mylist = [[circle.m[0] - circle.r, 0, i] for i, circle in enumerate(circles)]
actions.py
conf.verb = 0
x = 2.5
num_rows = Application.ActiveDocument.Tables(2).Rows.Count
py2exe.build_exe.py2exe.plat_prepare = new_prep
values = column_stack((values.reshape(n, -1), col))
gui_app.start()
x = reshape_dataset(your_dataset)
ddof = 1
batch_request.AddUpdate(cells.entry[i])
(1 + interest) ** numberOfPayments - 1
raise ex
reqctx = _request_ctx_stack.top
func = lambda x: x ** 2
hashed = bcrypt.hashpw(password, bcrypt.gensalt())
current = {}
triangle = signal.sawtooth(2 * np.pi * 5 * t, 0.5)
items
cursor = results.getCursor().toWebSafeString()
rf = RequestFactory()
print(row)
it = iter(str(n))
print(list(invRegex.invert(data)))
seen.add(link)
extendedString(x, y)
job.body
redirect_if_needed
config.one.key, type(config.one.key)
e.append(f)
data = piexif.dump(exif)
assoc.pyc = Python.CompiledFile
start_coords = product(*start_indices)
x = z.real
class_builtins = set(dir(GenericClass))
header_flag = 1
build_structure(c, d)
passwords = urllib.request.HTTPBasicAuthHandler(password_store)
unique_nonzero_indice = numpy.unique(nonzero_row_indice)
lp1, lp2 = pd.tools.util.cartesian_product([l1, l2])
status = sp.Popen.poll(extProc)
1 % hgh & 12
urow_avg = weighted_sums / index_counts
__pyx_r
color = getColor(rightPixel)
n = 1
x, s = tpl
x = 9
print(d)
i = counter
sys.stdout = ProcessedFile(sys.stdout, reformat_float)
tree[0]
te = time.time()
enc.feature_indices_
f = f.f_back
codec_names = modnames.union(aliases)
active = CustomManager()
include / usr / share / cdbs / 1 / rules / debhelper.mk
ds = [Dummy() for _ in range(5)]
result
base.__class__ = Special
d = {}
lst = []
a
base_url = get_base_url(response)
A
python
ht = np.real(np.fft.ifft(hf))
count = 0
q = collections.deque()
print(b)
resp = requests.get(url)
quote1 = soup.blockquote
attrs[2] &= ~(termios.CSIZE | termios.PARENB)
child = node.make_child(reference)
output
False
db.dogs.truncate()
s = server.Server()
print(s)
G
m_menus.push_back(menu)
adder_lambda = lambda parameter1, parameter2: parameter1 + parameter2
list(self.x.values())
merged.value.subtract(merged.value_right)
obj.isoformat()
soggy
print(list2)
L = D - w
client = self.client()
sum
root.apps.myapp = MyApp()
diff
re_compile(self.pattern(format), IGNORECASE)
SECTION = E.section
r, prob
lncmp = lambda a, b: cmp(ln(a), ln(b))
0
Else
y = r * np.sin(theta) + center[1]
i = i - 1
status_code = 204
s
dict = model_to_dict(instance)
tot -= answer[-1]
object.__new__(cls._wrappers[wrapped_type])
df / denom
total_loss,
max_so_far = 0
n = f.__code__.co_consts[1]
tam = 0
queue.append(list(merge(queue.popleft(), queue.popleft())))
n_drives = GetLogicalDrives()
logz = -gamma(df / 2.0 + d / 2.0) + gamma(df / 2.0) + 0.5 * logdet
x = object()
counter = byte(counter + 1)
_ggplot2 = ggplot2.ggplot2
exec_time0.append(b - a)
settings.MY_LONG_QUERY
connection.connect(jid, password, onConnect)
ybot < -apply(rbind(0, dat), 2, cumsum)[-(cats + 1),]
a, = [1]
hashed = bcrypt.hashpw(password, bcrypt.gensalt(10))
wintypes.DWORD(2 | 1),
mysite = MyAdminSite()
6
print(q)
x = key
depth = 1
divisor = 0
fou.write(result)
network.trainf = nl.train.train_bfgs
theme = theme_gray()
d.question = instance.id
expr.args
micro_sec = 0
c = sum(floor(x / d) for x in a)
worker(urls)
DATABASES = DATABASES_SHARED.copy()
model.myBool = False
v4 = [array(vec) for vec in v2]
1
Green = BufferedImage % 2 ** 16 / 2 ** 8
foo + [7]
eth = dpkt.ethernet.Ethernet(buf)
der.decode(cert_asn1)
self.quantity * self.item.retail_price
remaining_weights = {}
time_series = hstack((time_series, time_stamp))
ml = glib.MainLoop()
tcks[-1] = vmax
data, errors = self.extractData()
dendrogram = graph.community_edge_betweenness()
Decimal.from_float(other)
actions_when_unchecked
str.concat(d)
rw = df.loc[df[col] == 0]
print(result)
result[name][something] = amount
X, y = iris.data, iris.target
hdlr.setFormatter(formatter)
print(status)
fp = (bt.bitarray(p) & ~bt.bitarray(g)).count()
cidx = udist.col
ret.emplace_back(fn(d))
a.baz
c = myarray[i2][j]
powerSet.add(tmp)
pool = tuple(iterable)
FAILED(failures=2)
_precalc_table = {}
print(arg1, arg2)
merge_the_N_files_one_line_each
speed = dist / frequency
product *= x
result
1
kwargs.update(preexec_fn=os.setsid)
print(elements)
Insert - O(logn)
sandwich
X = scipy.fft(x)
sig0 = der_sig_in.payload
EOL = lineEnd.suppress()
center_x = (x1 + x2) / 2
addr_bytes = [ord(c) for c in rdata]
c = 1
assert loc in range(1, 11)
styles = getSampleStyleSheet()
lc.start(0.1)
res = []
diff = lambda s1, s2: sum(1 if a != b else 0 for a, b in zip(s1, s2))
f(*a, **k)
chunk = s.read(200)
random_bytes = urandom(64)
x2 = arr2.flat[0]
names = self.cyclevars.resolve(context)
possibles
total
fft_of_convolution = fft_of_rows.prod(axis=0)
s
set_of_related_nouns = set()
log.debug(alldata)
global_learning_table = collections.defaultdict(PortDpidPair)
zip_path = os.path.join(zip_subdir, fname)
res
row, col = 10, 5
AAAA
im = ax.imshow(z)
cherrypy.engine.signal_handler.subscribe()
a
data2 = h5_file.root.data.read()
-avgDists
a
html
d = Serial.read()
keys = get_list_of_keys()
hashstring = md5Hash(somedata).hexdigest()
weighted_appearances += weighted_row
ShowIndex()[5, 5]
print(repr(data))
deck = list(range(52))
hddict = {}
print()
i = 0
call_args, call_kwargs = call
sf = np.flatnonzero(g[1:] != g[:-1]) + 1
curr = jinja2.Template(prev).render(**values)
_srcfile = __file__
tup = 1, 2, []
P = 2.45
width = 8
1
total = 0
True
_a = Functions.motion.move().left
elem.text = tagText
type(geom)([p for p in parts if not p.is_empty])
connection = MySqldb.connect()
item
fig
auth.is_logged_in = lambda : False
accept = 8001
tri_tokens = trigrams(tokens)
tweet = json.loads(line)
assert data[0].lc.col == 2
cd / tmp
elapsed_time = 0
pc.bar = bar
sre.LoadGrammar(grammar)
prev, cur = 0, 1
print(c)
result[word] = result.get(word, 0) + 1
a = map(lambda x: x + offset, simple_list)
length = GetWindowTextLength(hwnd)
structTime = time.localtime()
__getitem__
main(num)
self.spam = expression + that * generates - ham
tx.sort(reverse=True)
n = a.shape[1]
good_ones = np.logical_and(row >= -0.8, row <= 0.8)
dark.normal = light.normal = termcolors.Red
result
r = Request(environ)
print(result)
good = row[good_ones]
adict[key] = v
headers = r.info()
p1.shape
print(resource.getrusage(resource.RUSAGE_SELF).ru_maxrss)
seen = set()
1
var_h = H * 6
__builtin__.list = set
inner
G = nx.Graph(Gtmp)
vals[k - min_bin] = v
top_matrix[6, 1] = -1
mask = zones == label
x = defaultdict(list)
x.xycoords
int(text) if text.isdigit() else text
xa = pmnc.transaction.create()
b_index = b_index + 1
application = Application()
result
begin = begin + blockSize
BOW = cv2.BOWKMeansTrainer(dictionarySize)
False
anotherView(request, username, range)
t(value)
5 in primes
lNumbers = list(itertools.chain.from_iterable(lNumbers))
loo = cross_validation.LeaveOneOut(len(Y_digits))
result = pool.map(numpy_sin, a)
org.python.Python.PythonFramework - 2.7
GET / HTTP / 1.1
A_inv = A.inv_mod(5)
G = Graphics()
print(v)
compare
+speed_analysis.tex
f.__code__ = c.to_code()
b = y > 200
c = Context(js_template_data)
reader = csv.reader
print(obj)
threshold = vtk.Threshold()
Screen.wrapper(demo)
min_queue_examples = batch_size * 100
n = 100
python
DOG = 1
step = subs[m][l][n]
win_width = win_geo.width()
sqrt(X + Y)
request = webob.Request(env)
pwalk = np.vectorize(walk)
PyObject * op
print(a)
lists = topic.lists.all()
b
factors, idx = pd.factorize(df.name)
pos = map(len, pat.split(sep))
col_sp = a.shape[1] / cols
p_k_log = k * np.log(p)
print(x)
divisor = float(len(icoeffs))
probs = probs.T
actual = actual.splitlines(1)
a.parent.left = a
2
print(type(foo))
db = MimeTypes()
sa = [2, 4, 5, 8, 11]
pystr = PyObject_Str(pvalue)
a2[0, 0] = 10.0
previous = []
getFoosOverTheNetworkIfTheDatabaseIsntBeingAJerkface()
dif = list(Differ().compare(l1, l2))
ret.append((instance_state(original), original))
numDimensions = 4
a.__exit__(exception and type)
parsed_sent = cp.parse(tagged_sent)
column[i] = vals.index(string)
process(street[l], other_street)
ret = {}
self.context = app.request_context(environ)
self.proxy_auth = HTTPProxyAuth(*proxy_up)
print(attribute)
prob = betai(0.5 * df, 0.5, df / (df + t_squared))
self.computeSomethingFrom(rpcResult)
beingimported.remove(modulename)
kernels = [LINEAR, POLY, RBF]
N, _ = array.shape
d1[-1].append(y + x)
a.billing_system_id
x = 1.0
snakes = morphology.skeletonize(img < 1)
4
PIL.PdfImagePlugin
localStorage.setItem(locationName, encodeForStorage(dataObject))
print(name, j)
dosomething(12)
this.children = children
center = tuple(np.array([row, col]) / 2)
ss.do_handshake()
begin = time.time()
used = (st.f_blocks - st.f_bfree) * st.f_frsize
console.log(response.data)
soup = BS(html)
opt.icon = QIcon()
library(dplyr)
request = webob.Request(env)
outputBuffer = BytesIO()
WRITE = [0, 214]
result
w = w.lower()
self.orig_no_render = mlab.gcf().scene.disable_render
desired_srid = 22186
d -= 1
DOB
s == t
every_hours_crontab = CrontabSchedule(minute=0)
avail_items = [key for key, count in common_items if count]
print(ss)
memoryview(a0)
4
a.left, b.left = b.left, a.left
list_filter = [isClosedFilter]
code = e.args[0]
point = Point(int, lat)
event_handler = MyHandler()
true
Mycol
self._reportedPort
nodes = set()
item = str.split(line)
s
m = {}
ls - la
Xcum[0] = temp[H - 1]
f.access_control = dict(logged_in=logged_in, roles=roles)
s
matches = {}
df = pandas.DataFrame(randn(m, n)).cumsum()
N = 10
clock = pygame.time.Clock()
subject = data[:]
query
Z = Y.real, Y.imag
print(y)
frame = inspect.currentframe()
sold[sold.Sold.str.len() > 0]
cls.profile = FirefoxProfile()
urlsToVisit.Add(link)
fcb = matplotlib.backends.backend_agg.FigureCanvasBase(figure)
x
lst
newSave = self.EntryDict[key].get
arr > 2
FilePath = null
without_stp.update([word])
print(8)
klen = len(key)
certs = json.loads(certs)
[xr, yr]
output
buffer = StringIO()
combos = set()
-src
cols = [1, 2, 4, 5, 12]
A = whatever_dok_matrix_minus_constant_term
print((f1.a, f2.b))
u = urlencode(params)
y = np.sin(x)
mkl_get_max_threads = mkl_rt.mkl_get_max_threads
do_whatever
self.enable = self.enable_custom_consumer
size = pygame.display.Info().current_w, pygame.display.Info().current_h
ngroups = 10
process = Popen(cmd, stdout=PIPE, stderr=PIPE)
screen = pyte.Screen(80, 24)
cf = cos(twopi * f * t)
EPS = 1.2e-16
x = 170
states_from_slugs = {}
group = Group.get(group_key)
variables = []
g(6)
mask = np.zeros(M * N, dtype=bool)
column2 = updatetable.column2
proposed_subset[index_to_swap] = current_outsiders[outsider_to_swap]
list = __builtin__.list
neg_p_K_log = (n - k) * np.log(1 - p)
with_stp.update([word])
mocked_zipfile = Mock(wraps=zipfile.ZipFile)
s
a = 2
100
print(joined)
query_components = parse_qs(urlparse(self.path).query)
dt_naive
self._order < other._order
wx.SUNKEN_BORDER
b = 1.1, 2.1, 4.1
obj.name = name
connect = 8000
print(connection.closed)
eclipse_workspace
page = res.read()
der_sig = der[2]
some_normal_code()
print(subject, predicate, object)
[accuracy, validation_summary],
fields = messages(id, internalDate)
p1 = np.random.rand(len(dtrange)) + 5
snd_resample.dtype
bp1 < -barplot(dat, col=seq(cats))
holidays = cal.holidays(start=dr.min(), end=dr.max())
buff = ctypes.create_unicode_buffer(length + 1)
concat_string_arrays = concat(StringType())
type(identity)
x - small
successors = set()
true
signal *= dataCOS
idx = (yhat ** 2).argmax()
V = U.copy()
d
notification = NSUserNotification.alloc().init()
train = data_utils.TensorDataset(features, targets)
s.sqlite_version
print(bestCandy)
AUTH_LDAP_BIND_AS_AUTHENTICATING_USER = True
x
pk = a_method_that_may_rise_an_exception()
moduleX.py
x.setTop(4)
m.materials += [mat]
frequency = freqs[idx]
keep = pd.offsets.Day(60)
data
print(parser.format_usage())
done
fig = plt.figure()
lighter.light(self)
f[0] = 0
user_db
q_clean = haystack.inputs.Clean(q)
y1 = 1, 2
fds = []
bn.flags
p = prompt()
global_data = namespace()
m = mock.MagicMock()
orders_df
model = Course
threshold = 4
components = path.path(mypath).splitall()[0]
print(z)
cluster = Cluster(node_ips, protocol_version=1, auth_provider=getCredential)
sp = SoftwareProperties()
print(1 / 0)
divisor = N - 1
5 in r
Py_RETURN_FALSE
data = [[hdescrpcion, hpartida], [partida, descrpcion]]
id_arr2[sf[1:]] = sf[:-1] - sf[1:] + 1
colOffset = Integer.parseInt(col) - cellAddr.col
c = get_config()
PyErr_BadInternalCall()
sys.stdout = sys.stdout.parent
x
skip_footer = sheet.nrows - end
string_buffer = StringIO()
sched.configure(options_from_ini_file)
lncmp = lambda _, a, b: cmp(ln(a), ln(b))
self.application = application
s = serial.Serial(port)
self.data = []
print(args, kwargs)
share_string = quote_plus(instance.content)
r = requests.get(url)
dirtyItems[key.uid] = x
shuff_acc = roc_auc_score(Y_test, rf.predict(X_t))
evens
print(sympy.N(sympy.E, 100))
print(final)
average_of_all_assignments
A
factory = Factory(self, (REMOTEHOST, REMOTEPORT), Channel)
magic_index = np.ix_(*magic_index)
a
use_for_related_fields = True
calc = int(calc) + 1
joined_orig_types = joined.apply(lambda x: x.astype(orig[x.name]))
thresh_d = 0.1
map = array()
d
print(f.__doc__)
XResolution(72, 1)
w.foo = p
max = midPointOfList - 1
a.p, b.p = b.p, a.p
PATLEN = 20
setState(preState)
a, b = b, a
d
num = []
data = xObject[obj].getData()
newdata = fint(newdepth).T
True + True
self
a
self.seq = seq
tmshKey = tmshString
self.done = False
builtin_outputs = map(compute_something, inputs)
detach(USArrests)
buff.value
uniq - u / tmp / uniques.txt
I = array([10])
pi ** 2
tmp
print(a_char)
ndarray
m = np.divide(weight, 100.0)
data -= m
dis.dis(constructor)
StdDraw.point(x, y)
log(item1, item2)
b
loc_dt = utc_dt.astimezone(eastern)
rpkm = 10 ** 9 * theC / (theN * theL)
data / vector
to_skip = numpy.random.geometric(p) - 1
print([k for k in res1 if k in list(set1) or k in list(set2)])
some.production.host
numbers.Number.register(NamedInteger)
args = a1, a2
process_read_pair = tasks.process_read_pair.s
root.apps = Dir()
c1 = Counter(a)
f = Fernet(hashed_pwd)
a = 257
print(pkcs11.getTokenInfo(theOnlySlot))
int_len = 4
dt
a.attribute1, -a.attribute2
print(s)
print(mask)
all_maxes = [ele for ele in l if ele[1] == mx[1]]
callback_call(CallbackObject * self, PyObject * args, PyObject * kwds)
result
create_button(b)
r = requests.get(file, auth=HTTPBasicAuth(myUsername, myPassword))
i = bisect_left(s, ts)
hl_dict = {handle.get_label(): handle for handle in leg.legendHandles}
portion = (oldMax - x) * (newMax - newMin) / (oldMax - oldMin)
cvWaitKey(0)
totals = {0}
result = a[b]
response
copy_as_nparray = usable_a_copy.values
pragma(startaddress, foo)
nframes = 100
n = 450000
[distutils]
print(subject)
curs = db.get_connection().cursor()
result = _unhexlify(result)
a
print(summary(params))
network = splitNet()
funcs.append(make_f(x))
ctx
print(model_with_intercept)
denominator = sum(upsilon ** (t - item[0]) for item in q)
print(tempdf.describe())
instance
str_info
thing = MyModel.objects.create()
current_range = next(ranges)
self.has_next = len(paginatable) / per_page > page
current_option = options[0]
scores, []
inner
dx, dy = length * np.array([dx, dy]) / np.hypot(dx, dy)
ro.conversion.py2ri = numpy2ri
product = 1
running = False
user_db_qry = User.query(User.federated_id == federated_user.user_id())
field_names
digital_code, letter_code, units, name, rate = [c.text for c in cols]
7 | A1 | ARG
clip = mpy.VideoClip(make_frame, duration=duration)
zf.write(fpath, zip_path)
print(e)
megawarc
[logger_sloggerMain]
jedi.evaluate.representation.Instance.__getattr__ = __patched__getattr__
print(idx)
intersect = s & t
i = k / combs_per_set
tell_the_truth()
p.prevPrimes(10)
print(Blues(0.5))
c < -x
print(check_mapping(12))
print(imagesList)
blockSize = 16, 16
message = ws.receive()
running_sum += recview[i].f0
do_something_with_this_info
print(e)
prev = next(items_iter)
spread = rand(50) * 100
user
lut = lut.reshape(planes, 256, n)
filtered_x = lfilter(taps, 1.0, wave)
decimal.getcontext().Emax = ndigits
wordtable = data(rows)
assert 42 == example.test_specific_uint8(42)
frame = Frame.get_selected_python_frame()
show_all = False,
finalmap
raise
format_regex = _TimeRE_cache.compile(format)
shuffled_points = numpy.array(points)
cum_sum_of_squares += image ** 2
query_params = request.GET
f = functools.lru_cache(1)(f)
ball.x += math.sin(angle) * overlap
out
packet = Base()
calculated_chunks = []
tmp = [object()] + li + [object()]
fp = []
db_filename = os.path.abspath(DB_NAME)
1 in x
existing_databases = [d[0] for d in existing_databases]
fancy_indexing = [(i * M + n) for i in range(len(x) // M) for n in range(N)]
newdict = OrderedDict()
y = S(expression)
cls
h = tuple(next(id2))
print(lst)
B[0] = values
more_data = transform1(a_piece)
lproductions = list(productions)
total_quantity = 0
2
print(formatted_time)
base64_encoded
l
height = 768
tx = [(v, k) for k, v in list(word_freq.items())]
complete = left + middle + right
generatedClass = superClassCreator()
dictOfStuff[x] = 4
print(rule)
a
chained = []
locals()[key] = value
base_name = d[0:-(suffix.length + 1)]
activate
current.rest = lst
__metaclass__ = CombinedMeta
subtable = truthtable(n - 1)
stdin.channel.shutdown_write()
state_slugs[state_name] = slug
a
zp
years = [2005, 2007, 2008, 2009, 2011, 2012]
filter_col
print(row_template.format(*([rowname] + rowcontent)))
G.add_edge(a, b)
nthRootOfr = abs(z) ** (1.0 / n)
dC.to_host()
sniff_on_start = True
cols = zip(fd, fd)
labelInstructions.Text = instructions
collResv.rejected = True
maxn
long_description = readme,
print(error)
m1 = m.view(numpy.ndarray)
postData
raise e
timer(stateEq, 5)
ret = {}
cdf_stop = norm.cdf(b_s)
nan = np.nan
a
complex_out = []
1
n_below = 2
hours = _js_parseInt(match[0]) if match[0] else 0
scripts
T(0 * F) + 10 * C
x = 2
itr
name = Required(str)
MpiParams = ports = 15000 - 19999
set1 = set1.flatten() // etc
isbn = input()
os
bar
print(Subject(subjects))
referred_item = _ReferredItem
s
helper.Concat(helper.SkippedItems)
print(b)
MyCar = mycar.photo.url
print(grp)
delta = timedelta(hours=offset / 100)
google.loader.ClientLocation.latitude,
raise
WINDOW_SIZES = [i for i in range(20, 160, 20)]
bestEnd = len(arr)
min_length = length
table_headers, table_data = fetch_relations()
mask1 = df.b1.str.len() == 0
print(type(node))
k ^ 2
win_len = GetWindowTextLength(hwnd)
timestamp = {{obj.timestamp}}
Dependents
player.score
top_matrix[5, 4] = 1
low, high
l
line = bufferedReader.readLine()
X = 1
s = sorted(objs)
toc - tic
cal = calendar()
runtimes[n, i] = execution_time
im2, = plt.imshow(eye(2))
p = Fraction(1)
klass.x()
print(x)
lowRankDocumentTermMatrix = dot(u, dot(sigma, vt))
total = observed.sum(axis=0).reshape(1, -1).sum()
grouped
self.done = True
self._width = sys.maxsize
current_ct_offset = get_current_ct_offset()
d
v = all_occ[k]
canvas = FigureCanvas(figure)
x = all((z1[0] == z2[0]) == (z1[1] == z2[1]) for z1 in z for z2 in z)
varobj = object()
dstv[dstybase + yoff][dstxbase + xoff] = srcv[yoff][xoff]
print(artist, song, album)
s = 6
im1AsArray = numpy.array(im1)
a
im = ndimage.rotate(im, 15)
doc2.rst
a = T
ballrect = ball.get_rect()
s
int_n >>= 1
connect_default_signals(City)
print(choice)
index = n - 1
com.mycompany.AppleScript.LocalCommand
Alice, 0.005
self.workers = Semaphore(workers)
t = nuke.ProgressTask()
comment.is_removed = True
red = 1
l = chain(c, remaining)
1
x = 1 / 0
all_on_left = all_on_left - coeff_dict[s]
b
zeros = np.zeros_like(a.take(np.arange(n - shift), axis))
resultlist = []
{0} > {1}
(t2 - t1).days
ret = svm_predict(*args)
bStatus.on_clicked(get_status)
somelist = list(range(10))
ret
monitor.stop()
print(name)
fig = dict(data=data)
vnew | r
encrypted_secret = f.encrypt(secret)
Py_EndInterpreter(myThreadState)
other
sampleSize = 10
a.dataLim.update_from_data_xy(corners, ignore=True, updatex=False)
b = 5, 12
print(conacatData)
result = map(lambda x: x * M, diffs)
columns = x.columns,
cc[country.alpha2] = country.name
d = task.deferLater(reactor, 0, myFunction, parameter1)
readline.set_completer(completer)
self.keep_running = keep_running
assert len(X) == len(y)
bulkProcessor.add(request)
sorted(solve(x ** 2 + p * x + q, x))
py_exception = true
print(arr.shape)
print()
_four(output, input)
sequence = args[0]
a = np.arange(100)
out[l:r] = a[:n - sl] - a[sl:]
a = 42
c = y[ix]
ob_start()
out
cls
w = h = 100
test = [issubclass(np.dtype(d).type, baseType) for d in df.dtypes]
manager.outputScan(multiple, 10)
x = 1
lengths = list(range(len(s) + 1))
figsize = 8 * widthscale, 6
FLAG_2 = 2
0, image.rows, image.rows / 2
dt
words[w] = set()
c = 10
frame.f_globals[name]
idx2 = row2.indices
out
xy = list(range(20))
popt, pcov = curve_fit(fourier, z, Ua, [1.0] * 15)
deleteos, atexit, readline, rlcompleter, save_history, historyPath
issubclass(bool, int)
print(L, a, b)
getattr(self.parent, key)
0.2
my_image = load_my_image()
m, n = v.shape
h = []
gapz, gapy, gapx = 1, radius, radius
index.html
item = graphicsItem()
recall_ratio = true_positives / (possible_positives + K.epsilon())
diff = abs(v - value)
importance
logger.handlers = []
print(replaced)
X = np.sort(200 * rng.rand(100, 1) - 100, axis=0)
print(real_valued)
this.LocalString = this.richTextBox1.Text
console.log(result)
tn = ephem.newton(longitude_difference, t - ephem.minute, t)
strline
pi_list = []
hist_sel = normalize(sel.histogram())
r.namespace
radii = np.random.random(size=N) * 1.5
result[outerKey] = inner
a = es.enter_context(context1)
TOKEN(1).name
headers = remeber(request, login)
t[v] = a[start]
datalines_str
length_ = 0
start = d.bisect_left(key)
5
val
table_piece.drawOn(the_canvas, *coordinates)
wanted = set(a1)
sigmoid = vectorize(lambda x: 1.0 / (1.0 + exp(-x)))
mymodule.foo2
pyFunc = invokePyFunc(filename, func, args, Array(), Array())
a = set()
indices[:] = indices_vector
blocksize = 8192
original_path, original_extension = os.path.splitext(original_name)
toSendLength += tentative
print(chunk)
c_len = Counter()
traceLock.Lock()
b
y1 = np.atleast_2d(ys[..., 1:])
self.infile = infile
y = z.imag
dictionary = corpora.Dictionary(final_text)
con.text_factory = str
sys.stdout = so
CompareList(x and other for x in self)
Qt.QNetworkCookie
print(comment_entry.updated.text)
ccn = ccd * cc
bids
TITLE = E.title
print(q[0].games__count)
vals = list(set(column))
x2 = range(min2, max2, step2)
ParserElement.enablePackrat()
google = {map: {LatLng: LatLng}}
cc = spc.Spc(x, spc.CHART_X_MR_X)
p = pairs[cursor]
maxval = max(maxval, aa[i][indexes[i]])
d.addBoth(lambda _: l.start(timeout, False))
pip - -version
formatter = FuncFormatter(thousands)
itemloaded = l.load_item()
ctx.prec = 4
shape = len(l), max(lengths)
seen_add = seen.add
a
GPUFreeMemoryInBytes = sbcuda.cuda_ndarray.cuda_ndarray.mem_info()[0]
print(df)
time_d = datetime_1 - datetime_2
lines[-1] = lines[-1][:col2 + 1]
in_loop = set()
c = CallbackHandler()
print(e.msg)
mydict = defaultdict(int)
done = False
current_outsiders = proposed_outsiders
gen_random_decimal(9999, 999999)
result_words
x
band1 = biglist[1::nbands]
x, y = 1000 * np.random.random((2, 10)) + 50000
resource.setrlimit(type, (soft_limit, hard_limit))
pdf = main_doc.write_pdf()
[wheel]
6 * x ^ 2 * z
x_coord = x
n += nicklist
p_value = scipy.stats.f.cdf(F, df1, df2)
print(a)
var1 = longcalculation()
magicSplit = str.split
s
y = spam
--maintenance
data = CoverageData(file)
print(dpi)
unq_avg = unq_sum / unq_counts
[extensions]
f = executor.submit(RDD.collect, pred)
x = 10
runs_scored = float(runs_scored)
largest_dividable_number = max(k, n - k)
print(c)
StdDraw.line(xmin, ymax, xmin, ymin)
word1 = random.choice(WORDS)
payload
truncated_time_delay = min(mode(truncated_deltas).mode, key=abs)
bits = bytearray(len(text))
fmt.Println(i)
validator_class = oauth2_settings.OAUTH2_VALIDATOR_CLASS
b
L = len(y)
read_as_utf8(gpg.stdout.fileno())
print(mylist)
i_am_string(obj)
cart.author = book.author.name
print(out)
words = {}
INDENT
c -= v & 1
print(value)
A
l = []
l[x] = merge(l[x], l.pop())
avg = tot / count
m = m[m[:, (2)] <= limit]
PyByteArrayObject * creds
bestStart, bestEnd
result = {}
window = view.window()
m = MyList()
print(now() - t)
1
print(test.col)
cosLat = np.cos(lat)
shifted_array = numpy.append(original_array[1:], 0)
list2 = args[1]
value
runs_allowed = float(runs_allowed)
deletexlApp
print(s)
select_tool = p.select(dict(type=BoxSelectTool))[0]
app_label = Restaurant._meta.app_label
run
this.nextLoc = result.left
writer = csv.writer(wf)
self.speedTestForRecordType(_AppEngineUtilities_SessionData)
r.append(x)
dmp = diff_match_patch.diff_match_patch()
unified_mask = mask_my | mask_mx
iris = load_iris()
filename1 = sys.argv[1]
new_t
print(i)
tuple(index)
sel = Selector(response)
server = ThreadedTCPServer(serverAddr, SomeCode)
dis.dis(func_2)
Py_XDECREF(operation)
dbf1 = Dbf()
self._base = base
rss = resource.getrusage(resource.RUSAGE_SELF).ru_maxrss
df
[deps]
d = []
state = 0
ans = Cookie.SimpleCookie()
readIncoming(data.subarray(4 + size))
p = 0
legend1 = g_legend(p1)
multi_line_word = Forward()
der_cert = der[0]
print(b)
_w = Functions.motion.move().forward
[]
f = Factor(s)
result = []
cv.CvtColor(cvBgrImage, cvRgbImage, cv.CV_BGR2RGB)
env = Environment()
ax1 = fig.add_subplot(111)
msgs = getattr(translate, lang)
l.release()
socket.socket = socks.socksocket
read_ok = []
sorted_ab
positive[n] + negative[-n]
assert expected.equals(result)
c = container(list(range(num)))
False
PyArrayObject * elem
timeit.timeit(t2)
hot_result = [0] * len(row)
User_id
print(results)
address_df = pd.DataFrame(tagged_addresses)
result *= s
z = character()
1.5
webdriver_accept_untrusted_certs = TRUE,
mixins.DestroyModelMixin,
zeros = np.zeros_like(a.take(np.arange(n - shift, n), axis))
startPoints.pop()
func
x
result
arr
output = StringIO()
steps = []
prob = 0.0
print(Blues(price_change))
[A - Z]
service.LoadImages = false
h = HTMLParser()
ret
dcap = dict(DesiredCapabilities.PHANTOMJS)
v if len(v) < 72 else preserve_literal(v)
stdout_events_enabled = true
m = mmap.mmap(f.fileno(), 0, mmap.MAP_SHARED, mmap.PROT_READ)
print(numbers)
dout
weights.append(np.asarray(sub_list))
sigmoid_grad_sech2(500)
done(err)
django - debug - toolbar == 1.4
n = 11
dict_after = yaml.safe_load(data)
print(test.vec().readonly)
-1
{5}
dv = DictVectorizer(sparse=False)
parser = bibtex.Parser()
[(cond, Stmt(body)) for keyword, cond, colon, body in [if_] + elifs],
m = np.arange(16) * 10
w
kde = stats.gaussian_kde(ram, bw_method=scale)
a_padded = tf.concat(0, [a_as_vector, zero_padding])
handler = MyHandler()
data = dat_1.append(dat_2)
box.points(vertices)
print(aList)
on_disk.append((hashed, large_item))
last[i] = next(iterators[i])
count = count - 1
it = iter(iterable)
utc = pytz.utc
spans
print(i)
page1 = requests.get(ap)
k = n
conv[246] = float
years = list(range(2012, 2015))
blogView.html
ds = [d1, d2]
NPs
pyResponse
nextDate = startDate + timedelta(i)
res = chord((add.s(i, i) for i in range(10)), xsum.s())()
buff = create_string_buffer(len(newname) + 1)
assert spam == val
self
i
__metaclass__ = Final
b = 2 * a * b + c[1]
__END__
python
self
context = dict(my_list=my_list)
postdata = str(context.envelope),
threads = 2
minutes = _js_parseInt(match[1]) if match[1] else 0
decimal_point_index = len(ndigits) / 2
lock = wc.add_lock(self.path, core.svn_lock_create(core.Pool()), self.wc)
all_occ.update(occ)
tmp = self.field.toPlainText()
data
raise
aaaa
mock.side_effect = lst
nonzero_array = array[np.nonzero(array)]
result = chord(header)(callback)
source.env / bin / activate
10 is not ok
x = 6
Mh = M / 2
_PyObject_HEAD_EXTRA
self,
print(html)
exit
choices.append(n)
END = StringEnd()
out_x = in_x ** 2
arr
row_pos = [2, 6, 9]
foo = baz
width = 1024
tf = os.tmpfile()
LanguageRecord(*row)
vector < Vec4i > hierarchy
fs.get(query)
key = obj.key
old_socket = socket.socket
data = [randint(1, 1000) for _ in range(COUNT)]
minv = np.linalg.inv(corr + k * eye)
deletew
exit
0
list1 = args[0]
i += PyList_GET_SIZE(v)
trace
p2.Date = p2.Date.apply(Timestamp)
hex(id(data))
python
data_scaled = pd.DataFrame(preprocessing.scale(df), columns=df.columns)
cluster_facts = runner.run()
tup = tuple(sorted(tup))
fileSystemNameBuffer = ctypes.create_unicode_buffer(1024)
deleteset
url += urlencode(values)
__old__getattr__ = jedi.evaluate.representation.Instance.__getattr__
key, val = mydict.popitem()
bgrImage = np.array(pilImage)
question_IDs = get_stored_questions(dbconn, userID)
enddate = startdate + timedelta(days=6)
print(i)
256
self.Name = name
1.0 / 7
[build_sphinx]
memory1 = Memory(cachedir=mkdtemp(), verbose=0)
inner
cvCvtColor(img, gray, CV_BGR2GRAY)
instance = Target()
classList.append(cls)
result
deleteiterators[i]
recipe = zc.recipe.cmmi
third_scheduled_task = second_scheduled_task + timedelta(2)
self.path = path
encoding = parse_tree.docinfo.encoding
source / usr / local / bin / virtualenvwrapper.sh
memHandler.close()
ret = p.poll()
deleteN
perm = nextPermutation()
{}
mysql_result_json = self.myquery(account_num)
timeslots_left = test_duration * 1000 * 1000 / 20
updated = client.ExecuteBatch(batch_request, no_headers.GetBatchLink().href)
days, seconds = divmod(seconds, 86400)
b
print()
allnums = sorted(set(sum(aa, [])))
directories = [self._root.template_path],
string = f.read()
dt
self.bar = bar
model = SGDRegressor()
object_list
x ** x
router = SimpleRouter()
a
False
cstr = pp.quotedString.addParseAction(pp.removeQuotes)
print(result)
var_types = list(coeff_dict.keys())
d = ImageDraw.Draw(im)
help > modules
string_buffer = StringIO(data)
self.subdir = subdir
Z = A, B
retval.name = name
{{i18n_val[obj.activity]}}
a
users
data
t = time[j]
model = Simple
deletedivision
self.file
session.row_factory = tuple_factory
persons = []
sr.clock.set(0, cb)
vocabulary_gensim = {}
model = gensim.models.Word2Vec(documents, min_count=1)
temp = np.sqrt(E * E + T * T)
a = x
p = subprocess.Popen(argv, stdout=o, stderr=e)
colors = []
print(foo)
self.nGramCounts[word] = unigramCount
False
lev_tol = per * narray.min()
tt = (sm - m) / np.sqrt(sv / float(n))
initial = 0,
c4 = count / 10000.0
lo, hi = sys.maxsize, -sys.maxsize - 1
fixed_comments = []
mod
visible = self.itemAt(0, 0)
part / 10 ** ndigits
loop.call_soon(schedule_something)
print(first_ul)
raise
r = coin_combos(500, [500, 200, 100, 50, 20, 10])
goto - char(point - min)
ya = axes.get_yaxis()
print(active)
float(s)
vector < Vec2f > lines
1
test.body[0].body
27
a = 10
Image.Image.load = patched_load
maxchain = l
temp = x
init_op = tf.global_variables_initializer()
dateNull = models.DateTimeField(null=True)
print(n)
total -= supers(a | b)
my_state.count += 1
-verbose
2010 - 6 - 19
idx = idx + 1
clf = estimator(**params)
bmp(smile, 8)
exit
where = 0
model = gensim.models.Word2Vec(documents, min_count=1)
data[countzone][key] = ar
self.next = page + self.has_next
first_five_and_stripped
result = []
x = list(range(16))
steps = 1.0 / divisor * (stop - start)
self.mayIndexError = False
ans = 0
mindist = dist
d = {}
True
self.sym = sym
numImages = x_data.shape[0]
self._str = value
other_object = java_object.doThat()
5
badCharSet = set(badChars)
lst
foo
0
items[where] = v
ds.add(x, y)
0
true
a.r, b.r = b.r, a.r
_cache[n, k] = result
print(diffs)
print(lw)
print(_)
print(rs)
register = template.Library()
0
feed = {seq_length: 20}
fig_size[0] = 12
res
topic_weights = topic_prob_extractor(hdp, 500)
sprite.body = body
lsh.query(X_sim, num_results=1)
frame
excDict = vars(exceptions)
dev_req == 1.0
parent_only_code()
key, value = key_value
x[idx_2D]
print(arr)
a = bytearray(1000000)
foo
X, y = shuffle(X_orig, y_orig, random_state=i)
variable is not defined
bs.SetQuality(11)
df
num = 60
distinctMappings = set(zip(seq1, seq2))
parent_map[c] = [p]
vocab = vec.get_feature_names()
bar_value_to_label = 100
Crome_beta
removed_pks = prev_groups_pk_set - not_realy_added_pk_set
count = c_int()
type = auto_int,
5 - 1.0
cc.view_angle = self.orig_view_angle
CD, BE, BF, BD, BC
c2 = conn_2.cursor()
plus = 1
min = ++midPointOfList
aliases = set(encodings.aliases.aliases.values())
tot += item
append_fields
print(i)
SIGNAL(javaScriptWindowObjectCleared()),
var2 = 10
mask = counts == 0
parameter = str(1000000)
print(AnotherTuple)
print(s.name)
slack_client = SlackClient(SLACK_TOKEN)
f = tsk
prev_hour = datetime(dt.year, dt.month, dt.day, dt.hour) - timedelta(hours=1)
register = template.Library()
item = sample(seq, size)
pfo.SetOperationFlags(shellcon.FOF_NOCONFIRMATION)
a
choices = (0, 0, 0), (255, 255, 255)
AD, 500.0
a
rsrc = resource.RLIMIT_DATA
out = X.reshape(f.shape).T
ColorCategory(key)
print(hashed)
n = len(stocks)
u.bytes
diff = np.concatenate([diff, [True]])
partition = iter([current])
a
m1.x = 1
False
self.get_results(i)
c = Client()
result = json.loads(res.content)
Test
raise ex
not_verbose_regex
sys.stdout = oldStdout
integrate(g, t)
store = ctx.get_cert_store()
print(i)
id = i
exit
inList
print(colNames)
1 > 2
short_sha = repo.git.rev_parse(sha, short=1)
1
response
func = entry_point.load(require=True)
a
sin = math.sin
ShowIndex()[5]
time = localtime(l.time + timedelta(days=7))
[torrent]
bWgt = 0.7
spam2 = spam
camProxy.releaseImage(nameId)
__str__, __repr__ = StrMixin.__str__, StrMixin.__repr__
_, row = heapq.heappop(new_heap)
print(relative_url)
a
print(about.title)
True
s = df.stack()
Script2.MakeStringBall()
builder = MyModel.query
8724414529
window.data = {{data | json}}
prob_c = 0.1
self.f = f
ndim = numel(size(rawdata))
migration_context = MigrationContext.configure(engine.connect())
my_tree = tree()
magnitude, 0
data = vec.fit_transform(text).toarray()
popd
my % hash
gateway
result = list_users()
SizeCategory(key)
term = Thread(target=someQueueVar.join)
Y = X
input
x
inc = 5
a + 5
user
patient_list = list(physician.patients)
klass.__matcher.findall(formatString)
with_idx = enumerate(range(10))
metadata = extractMetadata(parser)
150 ** x
script
json_force_ascii = False
print(neginf * inf)
seen < -names(userprefs)
results = {}
ffit = poly.polyval(x_new, coefs)
0
a
password = DB_PASSWORD
ps
my_series
it = reversed(s)
x = u - v
total
newMin = min(nMin, nMax)
T = 1,
datetime.date = FakeDate
DynamicEnum.foo
self._root = True
compressed = 1
fdist = FreqDist(words)
_cache = {}
p1 * p2
ordinal -= 1
100 * 0.56
total += counter.count
sin = math.sin
token = request.facebook.user.oauth_token.token
line = lines[j]
self.fields = fields + general_fields
FROM / path / to / used / docker / image
d
POP_TOP
metadata
environ = builder.get_environ()
A
c[0, 0] = 10000
behind = sd.iloc[index - 1]
formatter = logging.Formatter(FORMAT)
channels = [[] for time in range(num_channels)]
CryptContext(schemes=schemes, default=pw_hash, deprecated=deprecated)
a = b = 1
paused = True
devices = discover_devices()
r = ro.r
data
result = reg.search(str)
method = foo
py - execute - clause - python2
ctx
mouseEvent(kCGEventMouseMoved, posx, posy)
cfg = get_ipython().config
uri = atom.http_core.ParseUri(redirected_page)
[FORMAT]
print(x)
filter_backends = filters.DjangoFilterBackend,
form = TeamForm
decorated_func = django_l_r(func)
mydict2 = MultiDefaultDict(defaults, a=0)
deployment / reference
print(x - y)
_, file_buffer = reader.read(filename_queue)
basicblock * fb_block
stacked = y.stack()
self.ids_seen = set()
PyObject_VAR_HEAD
2 + 4
ys.append((y[valid_idx], cur_pred))
index_of_bar_to_label = 0
data = array()
print(df)
TOTALPAGES = doc.page
io = StringIO(get_info())
a
items = GetData(url)
d = cls()
elements = []
id = j.client.id
volumeNameBuffer, ctypes.sizeof(volumeNameBuffer), serial_number
raise IllegalMoveError
parent_map[c].append(p)
sample = d.rvs(size=N)
beginning - of - line
result
attempts += 1
monkey_embedding_column(marital_status, dimension=8),
print(log)
x = mesh.points[edges[:, (0)]]
result
true_successors = [child for child in children if child not in self.path]
self.payload = payload
DT = 1.0 / float(RATE)
pool.join()
g1_r = p.add_glyph(source_or_glyph=source, glyph=g1)
a = x * 2
obj, first
xx = yy = zz = np.arange(-0.6, 0.7, 0.1)
self.player_urls = []
max_y = MIN_INT
fileInput
url_trie = trie.Trie()
memory_value = memory.read()
c
result = False
res = v is not w
head = next
ac = ord(line_p[i])
print(name)
bar = 2
0
h = {}
ydata = [52, 48, 160, 94, 75, 71, 490, 82, 46, 17]
print(fmt % (i, name, grade))
y = y1 + I * y2
boolarr
print(using_perms(array))
y = [0, 1]
ind = X.argmax(axis=0)
now = timezone.now()
ProcessOneWidget(widget)
maxn = max(maxn, len(item.name))
dset[:] = np.random.random(dset.shape)
error_stream = MyErrorStream()
distance = node._get_dist(obj)
print(connection_id)
False
n.key2
pdf = renderPDF.drawToString(drawing)
1
x = rec_dd()
print(x)
class_labels = iris.target
num = 100
deletelist
n = 1000000
ht = {}
decorator
s
mid = (lo + hi) // 2
fst.output_symbols = your_symbol_table
self.orig_clipping_range = cc.clipping_range
hot_index = row.index(max(row))
sys
area = cv2.contourArea(c)
print(my_model.my_field)
c
form_data = urllib.parse.urlencode(temp)
instance.previous_state = instance.state
d1[8] = 8
subset_a = a > 80
y, y_backup = tee(y)
r
x1 <= fx < x2 and y1 <= fy < y2
ee = deepcopy(e)
raise
self.initialize()
print(short_unc)
v4 = [1, 4]
img_global = exposure.equalize_hist(img)
total += supers(a | b | c)
keypress(shift_a_sequence)
self.old_prepare()
sentinel = object()
buffer
1
bl1 = []
print(obj)
p = Proxy(obj)
self.ref_object = ref_object
img
Elsewhere
false
border_line_color, border_line_dash, border_line_dash_offset
success_list = map(count_success, args)
reps = 500
data
running
[1]
trans = conn.begin()
print(format.format(*values))
ip_packet.ttl = 10
0.899779
print(result)
ob_end_flush()
pb = p[j]
doit()
b
msg = funk()
bSize = os.statvfs(filename).f_bsize
amazon = AmazonAPI(ACCESS_KEY, SECRET, ASSOC)
p = math.pi
someX, someY = 0.5, 0.5
N
ham = y
c
pipeline = Pipeline(stages=indexers)
digits = make_pi()
arr
_windows[_currentWindowHandle] = page
mysql - python
608
inverted[v] = max(inverted[v], k)
print(v - 10)
bool = True
y = x
restaurant_router = DefaultRouter()
print(cluster_output)
length = float(len(sequence))
readline.write_history_file(historyPath)
UDP in p
DOWNLOAD_DELAY = 1
last = x
delta = []
say_hi
value
s
bs.CopyTo(msOutput)
component.append(a)
result.right.add(n2.accept(this))
x == y
x / (len(mydata) * 1.0)
print(MyStr(16) > MyStr(7))
output_line
monthlyInterestRate = annualInterestRate / 12.0
print(text)
nodes.add(v1)
print(c)
a = a0.copy()
xml = xml + o.to_xml()
a
A = rand(100, 2)
Notes
maximum_ix = argrelextrema(A_f, np.greater)
instance_groups = []
_method = method
entrystr in modelstr
times_met = defaultdict(int)
avg_vals = grp_sums * (1.0 / np.bincount(ids, ~m))
ax = plt.Axes(fig, [0.0, 0.0, 1.0, 1.0])
dstv[dstypos + xoff] = srcv[srcypos + xoff]
email = true
inherit_from = SkyNet
serializedData = yaml.dump(data, default_flow_style=False)
cj = browser_cookie.firefox()
some_string = in_utf8
line = _infile_
l[i] = d
sr.clock.set(1, cb)
arr
connection.converter = conv
fi, li = c.first_valid_index(), c.last_valid_index()
args = shlex.split(cmd)
html[0:250]
model = YourModel
yourstring
0
max_val, max_args = max(starmap(lambda *args: (f(*args), args), args_iterable))
reg_constant = 0.01
raise WordNetError(msg % synset.pos)
context = iter(context)
print(rec)
a = torch.fromNumpyArray(getImage)
ST_WITHIN({YOUR_POINT}, boundary)
g_loop.daemon = True
NewList = OldList[:]
grades = []
torrent.url = response.url
x
print(longest_match_length)
Py_INCREF(parameters)
data = self._sock.recv(left)
rl = iter([expr]).__next__
cd / some / dir
pos = result.start() + 1
a
sz == 0
print(handler.level)
combinationToIdx[comb]
AssertionError
stop = PyNumber_Index(stop)
text = list(li.children)[2]
der_algo = der[1]
CRONTAB = true
this.nextLoc = result.right
p2 = xy[s:size + s]
MyClass.kind
1j
responses[200]
matT
list_of_dfs = os.listdir(dir_with_data)
BarObject_Type.tp_getattro = PyObject_GenericGetAttr
search = re.escape(search)
ws.append(w)
user_id
player_wins
CODE_GOES_HERE_FOR_BUILDING_YOUR_FRAGMENT_RESPONSE
dictionary = PyDictionary()
s
hierarchy += 1
code = parser.expr(formula).compile()
mydict
i >>= 1
reader_task = asyncio.ensure_future(reader.read(1000))
factors.append(f)
n = 20
_g = globals()
cptInsert += 1
answer
dset[-10 ** 4:] = np.random.random(10 ** 4)
caseSensitivePath
sftp = paramiko.SFTPClient.from_transport(transport)
num /= 1000.0
site_name = domain = domain_override
obj = arg_parsers[argtypename](argval)
unique_items
HttpProtocolParams.setVersion(params, HttpVersion.HTTP_1_1)
stack = stacks[0]
name = n
deletem.p
rows = [row.to_dict() for row in Taxes.query()]
fmt.Println(n)
a
s = stripper.transformString(s)
red_point = s + red_len * b_hat
False
self.data = thestruct
++outbuffer_len
MyClass.ff
mylist = list(kf)
self.orig_pos = cc.position
g.user = user
mouseEvent(kCGEventLeftMouseUp, posx, posy)
cats.setDACValue.restype = c_uint8
self._waitingForPort.addCallback(self.port_cb)
disc = disc[possible_hits]
make
print(id(x) == id(stuff2.z))
quickResult * 2
label.size_hint = 0.1, 0.1
evt.RepeatCount = 1
C += max_A + max_B
averages = sums / countings
print_all_libs_info(stderr, INDENT | SHOW_VERSION)
x
false
d.addBoth(completed)
y0 = center[1]
cookieJar = cookielib.CookieJar()
user.comment
y = spoons
impl = types.DateTime
out = jq(rule, _in=json_data).stdout
http.client = client
quickResult = x * 2
radioValue = activated_radio_button(butRadio, my_list)
print(like)
h - 1.0
dayno = dayno - year_size(year)
Xy_train, Xy_valid = Xy[ind_train], Xy[ind_valid]
[defaults]
result = [prefix]
locals()[k] = v
r = 0
dlg = StartSub2()
c is d
wiringpi2.pullUpDnControl(4, 1)
size = PyTuple_GET_SIZE(arg)
ones[rolled_mask] = 255
path_to_temporary_directory = tempfile.mkdtemp()
is_sys_imported = True
print(x)
c = np.zeros((ma, na + nb))
a
records = []
dateshift = dates.shift(1)
[run]
res
state_slugs = {}
n = 20
x = 2.0
raise
d
x = self & not_other
plugin_name = entry_point.name
print(1 in MyEnum)
x[step + 1] = x[step] + h * y[step]
line = self.lines[row]
0
dropSource.SetData(data)
url_trie[url] = url
mod = (num - 1) % 26
self
Xlib.protocol.request.QueryExtension
clusters[idx] = clusters[idx] + clusters[idx + 1]
keep = []
form % expr
display_with_gui(result)
print(idx)
expSum = 0
fs.append(f)
different_than_defaults = {}
print(non_overlapping_occ(kw_all_occ))
plot(mean_estimate)
data
print(tag)
win_left = win_geo.left()
__metaclass__ = ABCMeta
bad_longs = longs[bad_index]
text
t
f, e = os.path.splitext(infile)
self._order <= other._order
price = unit_price * quantity
xdebug.remote_host = localhost
legend2 = g_legend(p2)
request.param
exceptions[exc_name] = []
updater()
hdlr = logging.FileHandler(log_file)
myFile = secure_filename(form.fileName.file.filename)
total -= supers(b | c)
ol
cols = set([t for d, t in list(doc_term_dict.keys())])
self.y = 2
converter = time.gmtime
b = a
converted.show()
value == value2
found_kanji_previous = gef_kanji
arr_pairs
db, host, user, password = x
y
a = map(str, list(range(100000)))
IEnumerable < T > source
info = i._getexif()
mapped = lib.map_infer(self.values, func)
day = digit * 2
idx = mask.idxmax()
Electronics | Computers | Desktop
score = -9999
a = 9
main(sys.argv)
r
subset_sizes = reversed(list(range(2, k + 1)))
data = HTTPHeaderDict()
u = Q.popleft()
F[order] = F.copy()
new
N = 1000
1
xs, ys = triu_cache[len(x)]
regions, neighbors_per_regions = npi.group_by(centers[valid], neighbors[valid])
synset1.lin_similarity(synset2, ic, verbose)
img2 = StringIO()
print(COUNT)
M.bar = 6
enc_msg = map(bytes_to_long, message)
print(N[N[4]].flags)
print(nums)
channel = mySoundFile.play(0)
x
library(XML)
out_dates = []
a
commons = functools.reduce(set.intersection, nodes)
d = connectProtocol(endpoint, Socks4Client())
cap.setCapability(ChromeOptions.CAPABILITY, options)
part = word
end_row = row_slice.stop
get_pixels = clibblah.get_pixels
char * file
sdfasdf
slice = myarray[indx]
ly = y % 5
b
i /= 100.0
_wc.svn_wc_get_pristine_copy_path(*args)
print(value)
node = node.parent
d
start_point = 0
x = 9
num = secrets.randbelow(50)
MRTO4
chomp
d
xx = np.arange(10)
memHandler.flush()
config.scan()
lis1
values, mask, dtype, dtype_max = _get_values(values, skipna, 0)
dollars = round(float(dollars), 2)
M, N, R = allData.shape
deleteself.set[smallest]
outdata[:] = indata * [1, 0.5]
match = l
valid = (merged.date >= merged.valid_from) & (merged.date <= merged.valid_to)
a
self._uuid
drive, path = os.path.splitdrive(line)
rect2 = 12, 8, 2, 10
test.body
print(i)
val = 7
print(m)
number
delay = ctypes.c_longlong(0.25 * 10000)
print(_)
demo.printer()
view_1_block = rc[0]
x_pos = line.get_xdata().mean()
new = copy.deepcopy(old)
n = len(x)
model = Device
print(element)
base
inds = [str(x) for x in [2, 5, 6, 8, 9]]
L = []
devices
newGroup.link = x
check - sat
u = unquote(u)
s
g = day_generator()
w, h = disp.pixmap.get_size()
cyc = cycle(k)
instance.wait_until_running()
addrlen = sizeof(address.sun_family) + strlen(sockname)
password = secret
schema = reader.meta
print(required_list)
first_word = False
m.__contains__.side_effect = d.__contains__
titlebar = [x for x in window.AccessibleChildren if x.accRole == TitleBar]
print(results)
print(results)
s = split(s)
sql_dict = yaml.safe_load(sql)
c = group.counter
ib += 1
n_above = 2
svd = SVD()
handle_error
f = Foo()
x = list(range(10))
objectQuerySet = ConventionCard.objects.filter(ownerUser=user)
b = ~a
print(uni)
names = type_char_p.from_address(names_addr)
print(item)
ingredients.sort()
[merge]
inds = [2, 5, 6, 8, 9]
data = []
password
MyError
pageTracker._trackPageview()
jinja_environment.install_gettext_translations(translation)
pairs.pop(cursor)
args, _, _, values = inspect.getargvalues(frame)
array = manager.list([0] * n)
li
-format % c
d = deque()
self.qa.vote_down_count += 1
c.IPythonWidget.font_size = 11
site_name = current_site.name
c = Counter(ls)
id = question_IDs.pop()
job_for_another_core = multiprocessing.Process(target=plot_a_graph, args=())
mylist[j] = circles[i].m[0] - circles[i].r
get_uuid = HardwareUuid()
pool_results = p.map(process, np.array_split(big_df, 8))
print(X[ind, a1, a2])
X
dst = os.path.join(dst_base, d)
20151015
process(large_item)
accuracy = tf.reduce_mean(correct)
ds = s, s
m = magic.open(magic.MAGIC_MIME)
im = Image.open(filename)
dict_intersection
s
C = []
_, (channel, views) = show_views_channel
print(my_randoms)
config = ConfigParser.RawConfigParser()
tags = bytag[bytag.pid >= 2].index
perimeter = n_interior + n_boundary
64
compiled = re.compile(pattern)
s
results = list(sum(zip(a, reversed(a))[:len(a) / 2], ()))
startsecs = 10
self.group[a] = set([a, b])
state_slugs[state_code] = slug
foo
X_t = X_test.copy()
shell_table = Table(data, colWidths=[t1_w, t2_w])
cyc = cycle((-1, 1))
tp = (bt.bitarray(p) & bt.bitarray(g)).count()
mkfifo / tmp / screencap.fifo
red = red.__dict__
1
elem.requestFullscreen()
cookie1 = value1
contour_bounding_rect = cv2.boundingRect(contour)
{placeholder: feed}
element._start_line_number = self.parser.CurrentLineNumber
dist_zeros = dist_ == 0
fm = Foundation.NSFileManager.defaultManager()
Driver = freetds
print(k)
self._root = False
tmpCls
print(address_df)
array[array < 0.5] = np.nan
x
Character.toLowerCase(ruleName.charAt(0)) + ruleName.substring(1)
_dispatch = pprint.PrettyPrinter.copy()
assert 42 == example.test_generic_uint8(42)
sites.site = mysite
udp_data = udp.assemble(udp_packet, 0)
reference.pdf
python
_base = generic.GenericRelation(Base)
[server - xml]
linalg = np.linalg
Right = constructBalancedTree(values, median + 1, max)
print(z)
a = ~n
res
dot11 = Dot11(type=0, subtype=64, addr2=target)
us = []
users, next_curs, more = User.query().fetch_page(50, start_cursor=curs)
5
connection = Connection(self.host)
out
cmp
ret.extend(get_non_overridables(source.__bases__))
x = 5
current = lst
sub_parsers = parser.add_subparsers()
7
data = dt[selector]
free(r)
mpz_set(exponent, e)
m
info_hash = info.info_hash()
max_features = 10,
FNumber(12, 5)
max_tries = 100
legend1 < -g_legend(p1)
self.prev = page - self.has_prev
c
readline.read_history_file(historyPath)
s
this.limit = limit
ticket.__repr__ = build_daily_history_table_repr
max_len = max(len(n) for n in vim.current.buffer)
[rects]
log4j.appender.stdout = org.apache.log4j.ConsoleAppender
wid = max(len(w) for w in a)
pyqtRemoveInputHook()
cd / tmp
print(last_row)
ordered = len(self.__class__.__members__) + 1
pos = nx.random_layout(G, dim=2)
value = 0
base64_encoded = base64_encoded[1:]
--ignore
repetitions = 4
print(val)
fdist = FreqDist(words)
do_something_with_state_change()
ser_orig[start:end] = new_manual_mode_text.format(i)
python - -version
date_removed
print(unicodedata.name(c))
img = img_as_ubyte(data.moon())
truncated = s[:-1]
rs = (grequests.get(u) for u in urls)
initLimit = 5
a = list(range(1000000))
main
g_loop = threading.Thread(target=gobject.MainLoop().run)
f
B = np.triu(oneSquare, 1) * nums[0]
contours = measure.find_contours(gimg, 0.8)
self._order >= other._order
[paths]
M
i
ret = False
y = FunctionWithYield()
output = input[(0), :]
PyErr_NoMemory()
data.push_back(d)
original.png
age = 99
index = c[n].index
--twitter
domain = deltas.cumsum()
insample_mp = np.concatenate(results) < iso
logger = LocalProxy(lambda : current_app.logger)
comment = obj,
total -= supers(a | c)
flags
i2 = 18496
request = record.request
schema = reader.datum_reader.writers_schema
primary = foo()
foo = othermodule.Foo()
item
cols
result
session.login(PIN)
d
counts = [(x + epsilon) for x in counts]
C
print(grouped_a)
count > 0
l
respond(exchange, 200, action().toString)
tool_2_view = Tool_2.as_view()
tic = time.time()
print(filtered)
a
deletebig_sh
inc = lambda t: t + 1
warnings.warn(err)
k2.metadata = k.metadata
temp = conf1.server
print(sentence)
rot_mat = cv2.getRotationMatrix2D(center, angle, 1.0)
delay()
unit = unit_list[0]
process - row(row)
parser = create_arg_parser()
i = 1
STATUS_OK = 0
n = int(npy.log10(q / 10.0))
s
l = [l]
my_member = []
c += w * d * cf
userInput = ord(charG)
signal_ssi = -(256 - tap.ant_sig.db)
print(res)
h = 1
count = count + 1
print(me)
clienthostid
0
self.get_combinations = get_combinations
21
python
result.addError = self.__add_error_replacement
done = true
v = base[k]
word.Visible = False
b
original_timeout = socket.getdefaulttimeout()
l
err = []
print(counter + 1)
s = s + record.exc_text
print(screen.get_at([50, 50]))
print(node)
doc.build(Elements)
id = []
out
dict_after
score = collections.Counter()
c
answer = []
tagContent = reader.getText()
ntoi = dict((x, []) for x in allnums)
print(x)
print(codec_names)
eq_(rst, 8)
a1.scripts,
d
cmap = palettable.colorbrewer.sequential.PuRd_9.mpl_colormap
a = 4
extentB, extentR = dataStack.shape[1:]
b
amazon = bottlenose.Amazon(ACCESS_KEY_ID, SECRET_KEY, ASSOC_TAG)
default = sys.maxsize
self._server = ServerProxy(self.API_URI.format(self.email_hash))
print(bool(exp1))
attrib = zone.attrib
c
ipython
elem.msRequestFullscreen()
oMSP = getMasterScriptProvider()
onFirstPage = self._on_page,
time_format[lang] = locale.nl_langinfo(locale.D_FMT)
entropy -= p * NP.log2(p)
self.arg2 = arg2
y = load_iris().target
BITS, BYTES, KILOBITS, KILOBYTES = 1, 8, 1024, 8192
temp_max, _ = alphabeta(child, alpha, beta, False)
lines[0] = lines[0][col1:]
l_index = 0
print(outstr)
print(h)
partiallyCalculated4DimensionalEvolutionGraphOfPandasInOptimisticEnvoronment
tokenized = tokenizer.tokenize(text)
x
k1 = A * x
null
i1 = 50165
Meta.foo = 1
M * E
ranges = find_objects(labels)
xs < -loop
c = get_config()
rf.fit(train_X, train_y)
print(q)
sources
logo = self.fig.figimage(self.img, xo=260, yo=2600, zorder=100)
angle_bandwidth = 0.996 * (1 / math.sqrt(2)) * (np.pi / number_orientations)
Options + FollowSymLinks
info_event = info.get_event()
map(root.removeHandler, root.handlers[:])
vid = videoinput(v_input)
parser_context = parser_context or {}
raise
s += arr1[i] * c
print(channel)
4 in r
i
arr
other_street = tree.next(street[l])
xx, xx, xx, xx, xx, xx, xx, xx, xx, xx, xx, xx, xx, xx, xx, xx
raise MyException
print(u)
a = defaultdict(hi)
w_stop = w_x
print(ctxAuth.getLastErrorMessage())
a, b = 257, 257
records.keys
cr.paint()
rows
scores = np.asarray(scores).reshape(-1)
--type - add
datetime64[ns]
output += line
config = Configuration.objects.get(**lookup_kwargs)
checker |= 1 << val
self.setItem(m, n, newitem)
test_set
route_id, agency_id, route_short_name, route_long_name, route_desc, route_type, route_url, route_color
resp
high = max(y)
PortReporter(Factory(), showPortNumber).setServiceParent(application)
foo
print(dfsum)
print(put)
dates = [datetime.datetime.fromtimestamp(ts, est) for ts in timestamps]
res = fib(1000000)
print(parameter_A)
sCmd.sendline(pwd)
print(data, rand)
2
f = SomeFilter(request.GET)
print(d)
dns_cache = {}
result
deletelst
x
D = np.diag(diagonal_entries)
print(magicJsonData)
cnt[item] -= 1
(neighbors, centers), counts = npi.count((neighbors[valid], centers[valid]))
ys = std_xs.dot(v[:, (0)])
min = midPointOfList + 1
print(func_test.timeit(100))
a
queryset_1._result_cache.append(query)
listC
output = four(5)
companies_map = {c.id: c for c in q}
posTagged = pos_tag(text)
index = on_disk.create_index(lambda rec: rec.hash)
y[200:400] = 1
__delattr__ = __setattr__
local
xml_dict = xmltodict.parse(xml_data)
c
sigma = diag(s)[:numDimensions, :numDimensions]
manager = Manager()
print(resp)
centre_x, centre_y, radius = 150, 200, 100
ip = eth.data
x[0, 1] = initial_x[1]
title
x = 1
oldx, oldy = lines2d[0].get_data()
pd = PyArray_DATA(elem)
print(location.address)
v
funcs = []
desc = Desc()
tracker.added_group_ids = realy_added_pks
td = self.estimated_duration - self.get_program_duration()
s
z = character(length(x))
0.0
launch(file, globals, locals)
model = Word2Vec(sentences)
i = inspect(model)
temp_list = list(group)
sched = Scheduler()
a
print(c)
serializer = TypeSerializer()
other_object = java_object.doThat()
dictionary_from_class = {}
it2 = iter(lst)
before
s = [fractions.Fraction.from_float(x).limit_denominator(6 ** 9) for x in X]
modules = {}
requires_model_validation = False
myarray
i
a_minus_b = s - t
2
length = len(flist) - 1 if len(flist) % 2 == 1 else len(flist)
loader = self.app.blueprints[bp].jinja_loader
string = char + string
True
url = Foundation.NSURL.fileURLWithPath_(path)
bw[..., (2)] = 0
ws
b
complex_num(num)
result = ds1Cursor.fetchall()
acceptEncodings = acceptEncodings.ToLower()
policy = input.read()
val = 2
auth.secure = True
print(_)
user = DB_USER
domain = []
a
themin = value
H = set(A)
BarObject_Type.tp_basicsize = sizeof(BarObject)
register = template.Library()
w, f, fs = 0, 2, []
type(p0.intersection(p1)) is geometry.LineString
env = Environment()
_user_data = user_data
example = np.array(np.random.random()).reshape((1, 1, 1, 1))
print(one, two, three)
raise add.retry(exc=exc, countdown=60 * add.request.retries)
{}
electronDensity = value
foo = Foo()
python << END_OF_PYTHON
F = 1
sect = self.make_reports(self.stats, previous_stats)
spamreader = reader(memfile)
msgNameStack.append(tokens[0])
C
pyResponse = PyResponse()
a
f
output = msOutput.ToArray()
False
d
L
print(infile)
df2
cv = CountVectorizer(tokenizer=lambda doc: doc, lowercase=False)
constraint = e.orig.diag.constraint_name
browser.download.manager.showWhenStarting = FALSE,
result_data2 = avg[zones]
deg, mins, secs, comp_dir
sorted_coo = coo[sortidx]
m = mock.MagicMock()
toSendLength = 0
serverhash = serverHashFunction(key)
False
testSize = 1
state = number
print(response[y2, x2], type(response[y2, x2]), response.dtype)
print(simplifiedTags)
print(user)
client, addr = sd.accept()
provider = backend.name
STNAME
v = _escape_attrib(v, encoding)
sizeof_item = 1
library(sqldf)
deletea
d = simplejson.load(open(fname))
a = 5
bd = [parse(i) for i in bd]
print(b)
N = 100000
image = cv2.imread(p)
om.set(myVar)
s.stop
[7.5, 5.5],
print(ans(1000000000))
que
ln = lambda f: getattr(TestEffortFormula, f).__func__.__code__.co_firstlineno
haar_flags = cv.CV_HAAR_DO_CANNY_PRUNING
a
data.addRows(numRows)
start + increments
hello
output = res.asNumpyArray()
False == (True == False)
b
x.itemsize
True
python
res
print(m)
legend2 < -g_legend(p2)
flush_at_shutdown = True,
rc = clp.EnumClipboardFormats(0)
_.uuid
n_input, n_output = structure
mask = mask.reshape(M, N)
low, high = chi2.ppf(a / 2, 2 * k) / 2, chi2.ppf(1 - a / 2, 2 * k + 2) / 2
angle = f.protein_folding_angle
app = QCoreApplication([])
orig_type = sa.dtype
key, d = tup
df.dtypes
df
p = portal.Portal(realm)
days, hours = divmod(hours, 24)
ret.push(values[0][i + 1] - values[0][i])
set - e
5
i0 = drange(0.0, 1.0, 0.1)
ID_array = np.append([False], np.diff(A) > tolerance).cumsum()
print(p)
c = 0.2 - 1.0
0
threshold = 0
a
print(node.lineno)
flattened
l = len(fl)
chntrain_X, chntrain_y = chntrain[:, :-1], chntrain[:, (-1)]
assert Index.DeviceType.value == 4096
expr = Keyword(keyword).ignore(javaStyleComment | dblQuotedString)
char * bar
c1 = decimal.getcontext().copy()
costListTest[i, j] = cost.err(xt_, xv_, yv_, c)
raise
x[0, 0] = initial_x[0]
do_expensive_operation_to_get_attribute()
p1.extend(p2)
p
demo02(arg)
phrases.add(((e_start, e_end + 1), src_phrase, trg_phrase))
modulename = fun.__module__
time_info
disp_coords = ax.transData.transform(bb_data)
encoded_str
r == l
any_header = header_1 | header_2
nrows, ncols = M.shape
self._order > other._order
self.user_agent = user_agent
print(group_data)
ax = data.A.plot()
record.levelname = record.levelname.lower()
x = 5
a
Options + ExecCGI
iinfo(uint8).max
ds1Cursor.execute(selectSql)
simplify(grad)
total = 0
mydict = dd(lambda : dd(lambda : {}))
done = True
integrate(expr)
B.flags
1
tiempo = list(range(len(senial)))
data
LoggingConnection.initialize(self, logobj)
print(convert_ascii(i))
result = {}
unit_list2 = unit_list[1:]
k = k2
5
denominator = self.n_statements + self.n_branches
model.myBool
genre_count = data[genres].sum()
minval = MAXINT
types = type(a), type(b)
10
labels
ssh - add - l
searchResponse = client.prepareSearchScroll(searchResponse.getScrollId())
params = [evaluate(child) for child in node]
cert_asn1 = c.dump_certificate(c.FILETYPE_ASN1, cert)
x
False and 1 / 0
f = anobj.amethod
CELL_LIST = []
self.line = line
print(dataToSendBack)
done
s2 = Singleton()
weight = []
plural
testfile = urllib.request.URLopener()
fstr = repr(n)
[report]
i.thumbnail(size_64)
point.y = 1
User = ipynb
line_no = _n_
f, w = f + wheel[w], w + 1
B
u = np.unique(media_frame.values)
print(kwargs)
COUNT += 1
monkey_embedding_column(native_country, dimension=8),
X = df[predictors]
microseconds = 0
a
System.Collections.IEnumerator
d1
t = (time.time() - curs.timestamp) * 1000
probs = []
libs += glob.glob(path)
k2 = A * (x + S(1) / 2 * k1 * dt)
limit = max(map(len, words))
idx_IN_columns = [1, 9]
where_are_NaNs = isnan(a)
y = T.sum(A) * b * c
basket = basket_one.copy()
getBest(tgt, r)
col, start = test_col, rownum + 1
rslt = session.execute(bound_stmt)
hi
print(y)
td = Threaded_worker()
shp = x.size // M, N
tasks = []
print(content)
lst
print(a)
caption = String.valueOf(ast.payload)
t = 1
y = (rad * C + alt) * cosLat * np.sin(lon)
a
stocks.head(5)
i = minax0
a[inds]
r = 5
obj = getObjByName(objname)
int_fx = integrate(fx, (x, a, b))
a
abstract = True
x
expr
i = 6
serie_name = a.name
seconds = java_timestamp / 1000
line = line.decode()
model = Person
dict(ary)
persistent = yes
ACCESS_DENIED_ERROR, ER.CON_COUNT_ERROR, ER.TABLEACCESS_DENIED_ERROR
current = dict_[self.key]
float_repr(PyFloatObject * v)
lp = pickle.dumps(lock)
ob_end_clean()
LookupElement._fields
DATA_FILES = []
mv = memoryview(data)
getsource(sum)
_java_options = []
foo.dtypes
logger = logging.getLogger()
4
A = -0.75, -0.25, 0, 0.25, 0.5, 0.75, 1.0
gb2 = GlobalDataBase()
future = now + 10
http_server = HTTPServer(WSGIContainer(app))
dump_list(self.seen, 20, self.logfile)
chain += [primes[secnum]]
v
s = bin(i)[2:]
input
deactivate
_ = _
maxchange = row[-1], high - low
id_orders[id] = i
svn_rev
Integer, 8
mean_image = cum_sum / n
value = 17
a.id = r.artist_id
red << 16 + green << 8 + blue
ts = Series(np.random.randn(len(range)), range)
grid_search.fit(X, y)
ids_list = list(ids)
div2 = 0 if div1 is 0 else len(ones) / div1
n.sortModules()
port = 5000 + random.randint(0, 999)
row_sp = a.shape[0] / rows
length = len(tupleofnames)
raise self._value
ss.close()
line1, line2, time_text
scores = defaultdict(list)
b = 17
p = pool.Pool(10)
start += duration
entropy_x_set = 0
m
d = factory.getRootObject()
b = myarray[i2][j2]
data
predictions = perceptron.predict(features)
OuterPackage.SubPackage.TestWithGlobals
_proxy_object = Proxy()
scheduleForAThreadToRunMe()
v, _, _ = platform.mac_ver()
BaseObject.manage_beforeDelete(self, item, container)
exchange.getResponseBody.write(bytes)
tic = timeit.default_timer()
foo = 1,
user_details
coarse_threshold = (0.98 * threshold) ** 2
entry = Frame(boardFrame, bd=1, relief=RAISED)
diffs[items, items] < -diffs[items, items] + ratdiff
Ya = A2 * Xa + b2
T_NUMBER = 2
dec_msg = map(partial.key._decrypt, enc_msg)
rv = GetLongPathName(path, buf, 260)
self.mainloop = GObject.MainLoop()
stream = ContentStream(TEXT_STREAM, page.pdf)
insert_node(node, treenode.left, depth + 1)
a = CommentedMap()
got_match = matches.any(1)
print(metalist)
to_idx = 0
x
X, fx = psd(x, NFFT=nfft, noverlap=nfft / 2, Fs=f_sample)
x
changes = {}
grad_sigmoid = vectorize(lambda x: sigmoid(x) * (1 - sigmoid(x)))
row, col = image.shape
-bikes
p1 = xy[0:size]
start = flow.StartFunction(create_flow).Next(this.end)
[https]
pylab.legend()
49 % 48
out
new_list = Link(self.first)
resutls = np.zeros([numberOfRuns, ShapeOfModelResults])
square = optimise(square)
hi = code2[1]
ptree
x
tree = etree.parse(yourfile)
BatchUtils.setBatchId(batchEntry, cellAddr.reference)
print(g)
old_content = file_ptr.read()
print(b.pmf(k))
print(mt.between(1.5))
res_type = type(result)
print(l)
m = PyMouse()
best_move = move
total_weight = 0.0
print(f.fact)
c = Converter()
2
a + 7
hist = state.get_history(attr.key, True)
syn_set = []
m = Message()
major_tick_locs = axis.get_majorticklocs()
n = idx + 1
n = 2 ** 6
[pytest]
DETACHED_PROCESS = 8
a
objectQuerySet = ConventionCard.objects.filter(ownerUser=user)
y = [4, 9, 2]
x = df.OldCol
PORT = 8080
pids = []
e
sync = true
n = RecurrentNetwork()
PyThreadState * _save
templist = []
s
d
out
print(finalResult)
roots
y_predicted = model.predict(X)
compute(dq)
1
net = apollocaffe.ApolloNet()
index = itertools.count()
song_details = {}
something = Thing()
header_len = 4
[lib]
start.RedirectStandardOutput = true
v = myVector()
H = set()
T(0 * F) + T(10 * C)
close(unit)
4
intro = RichTextField(blank=True)
pcrscpp_duration = (pcrscpp_duration * i + (t2 - t1)) / (i + 1)
test
print(rgba)
label = kmeans.labels_
pair = index1[0]
application,
lstIgnoredRows.append(row)
a = sl.hilbert(10)
z
x = [1, 2, 20, 6, 210]
pa = p[j]
minutes, seconds = divmod(seconds_since_epoch, 60)
foo = DUp.parse(funky_time_str)
Py_RETURN_NONE
y_coord = y
allow_reuse_address = True
s = ImageFile._safe_read(self.fp, len)
AB, 100.0
x = x1 + I * x2
ma, na = a.shape
m = 0
l_results = l_query[2]
handlers = consoleHandler, infoFileHandler, debugFileHandler
print(varname)
month = 9
python
self.default = default
sb = set(b)
valid_groups.append(group)
obj
x
W = update_weights(G, weights_dict_test)
print(spam)
unq_avg
series
students = select(s for s in Student).prefetch(Group, Department)[:]
tot = numpy.cumsum(a)
a, b = 257, 257
telnet > quit
b = 2
names
ion()
strides = a.strides + (a.strides[-1],)
long_description = README_TEXT,
obj
print(digits)
a
n2 = f.__code__.co_consts[2][1]
idx = np.searchsorted(t, seconds)
wql_r = wmi_o.query(wql)
b
z += 128
ls - l
L = float(L)
time2 = timeit.Timer(setup=setup, stmt=stmt2)
bucket = conn.get_bucket(self.options.bucket)
cnt = 0
buffer += data
match = re.match(regex, string)
N = 100
month = 9
255
f_opener = opener.open(url_that_requires_a_logged_in_user)
[files]
m.logout()
selected_data = testdata.take(required_idcs)
decimal = False
toAdd = random.choice(vowel)
print(result)
print(tests)
keepalive_handler = HTTPHandler()
indexes = set((0, 7, 12, 25))
total = 0
print(u)
ignore = frozenset([5, 17])
A
c.connect()
topn = 20
TEST_ENV = XXXXXXX
value = request.post_vars.value
target_date_time_ms = 200000
otherText = ~messageKw + pp.Suppress(text)
x = 20
G = nx.Graph()
s
rss >> 20
full.append((s.ratio(), i))
vmidi_out.send_message([144, 48, 100])
correctDate = True
MAX = max(TAGS.values())
data_index = (data_index + 1) % len(data)
index < -combn(seq_along(int), 2)
model = FlatPage
_s = Functions.motion.move().back
measure_time
scrapy
mock.assert_has_calls(calls)
starttime = datetime.now() + timedelta(minutes=1)
1
print(stuff.contents)
print(b)
maxlen
region = eu - central - 1
minn
sims = index[vec_tfidf]
set(flatten(res))
i = 5
blackSet = {excptDict[exception] for exception in exceptionNames}
np.multiply(fc, t)
p = Process()
v = Document(review, type=int(rating), stopwords=True)
b
False
parts = [redistribute_vertices(part, distance) for part in geom]
review_ids = [review_ids]
rows = len(A)
theta = arccos(r / rho)
daemon = True
df
first_word = True
region_group = group_by(centers)
data = Data([trace1])
site = urllib.request.urlopen(link)
df
mydata = Data_pb2.MyData()
printcounter = 0
h = hl.md5(p)
arrayoftagList.string = [malloc, anothertag]
b[0] = 55
raw_ta[tty.LFLAG] |= tty.ISIG
print(x)
System.Net.WebRequest.Create(webPath)
s
yy = np.random.random(10)
1
decimal = Py_UNICODE_TODECIMAL(ch)
+4,
p = multiprocessing.Process(target=time.sleep, args=(1000,))
ht, htrot, htwin
print(key)
deletelib
Z = scipy.zeros(2 * len(X))
clusters = {}
x = 0.75
m = magic.open(magic.MAGIC_MIME_ENCODING)
q.labels
print(c)
list < -empty
f.denominator == 1
sb = set(b)
my_project
9 | C1 | SER
original_set_item = HttpResponse.__setitem__
print(a_string)
len = sqrt(len)
__import__(module_name)
full_stack = true
new_type = type(res_type.__name__, (res_type,), wrapper_dict)
test = pytest
b
lower_limit = scoreatpercentile(arr, percent / 2)
other
previous = element ^ previous ^ key
okays_append = okays.append
node = pop(stack)
lib_a
my_bigdict = BigDictLookup()
user = models.ForeignKey(UserProxy)
ll = line.split()
csvwriter = csv.writer(csvfile)
grantpt(pt)
t = np.log2(nfc / (c * (1 - f)))
pos = 0
st = prior[st]
cls.web = WebDriver(PHANTOMJS)
MARKER_LOWER_BOUND = 0, 0, 0
slow.addTests(TestSlowAnother)
InitializeComponent()
double = partial(mul, 2)
elem.webkitRequestFullscreen(Element.ALLOW_KEYBOARD_INPUT)
input_iters = map(sortkey, map(csv.csvreader, FILE_LIST))
sprite.rotation = math.degrees(-sprite.body.angle) + 180
root.Items.Item.OfferSummary.LowestNewPrice.FormattedPrice
reverse_lookup = defaultdict(list)
f_inrange = [(fx, fy) for fx, fy in f if x1 <= fx < x2 and y1 <= fy < y2]
xx, xx, xx, xx, xx, xx, xx, xx, xx, xx, xx, xx, xx, 62, xx, xx
raise
interactive
get_slots(hours, appointments)
ball.angle = 2 * tangent - ball.angle
print(len)
print(foo)
self._mfc = CarManufacturers(int(mfc)).name
d.rotate(-1)
b = clusters[int(merge[1])]
C.bar = 2
deep_annotate(a) > deep_annotate(b)
s2 = set(list2)
a = 10, 10
self.stopped_epoch = 0
10 > x <= 9
parse = parser.parse
I = float(I) / 100 / 12
PyObject * f_gen
out
python
orientation_component = np.exp(-0.5 * (dtheta / angle_bandwidth) ** 2)
result1 = kdtree.query(testset, 5)
x = Res(0.271, 0.001)
user.token = token
index
formset = ComponentInlineFormSet
msg = mailparser.parsestr(data[0][1])
deletes
10
self.user1
toAdd = random.choice(consonant)
lol = arg1 + arg2
n.key1
cls._client
uid = altera
Xr = X + Ar + Cr
p2 = mod(2 * pi * f1 * dur1 + p1, 2 * pi)
print(r)
arr2.base
x_list = list()
compare - verbose
set - e
I2 = iter(M)
Q.__bases__ += QQ,
p = cnt.get(item, 0)
result = Link(self.first, result)
tgt = arr.slice(i)
dic
globalMax = maxForRow.max()
user = serializer.save()
a = 257
angle = radians(self.theta - self.delta * pos)
func = getattr(self, key)
iterator = iter(values)
data = Data(*row)
res = g()
make
x
[chunk for chunk in ne_chunk(tagged_sent) if isinstance(chunk, Tree)]
encodings_to_try = [r.encoding]
f
my_namespace = {}
p = pkl.dumps(sorted(s))
batchEntry.changeInputValueLocal(updateReference)
True
nbLamps = 200000
toint = lambda x: int(x)
test
arr2 = arr1[0]
best_score = rf.oob_score_
wanted_set = set(wanted)
print(sys.float_info.min)
start = 1.5
DataFrame
Flask - SQLAlchemy == 1.0
lst
yn = ys + 0.2 * np.random.normal(size=len(xs))
ctrl_err(SQL_HANDLE_STMT, ODBC_obj.stmt_h, ret, ODBC_obj.ansi)
matches = tagged.apply(nvm)
done = {name}
edge_stats = defaultdict(lambda : list([0, 0.0]))
f = lambda a, b, c, d, e: d / e
rowcount = -1
classif = SklearnClassifier(pipeline)
-2.6
code = ruamel.yaml.load(inp, Loader=ruamel.yaml.RoundTripLoader)
start_col = col_slice.start
raise
data = StringIO.StringIO(zlib.decompress(content))
commit = r.head.commit
lst = lst.rest
driver.port._reconfigurePort()
unit = 40
importances = rf.feature_importances_
w, h = view.canvas.size
a is b
win_right = win_geo.right()
A
K
[client]
s = 0.05
p1 = tform.imap(point_in_front_of_screen_center)
component.append(b)
rs
file_name, num1, num2 = argv
pairs = {}
origin.setLocallyAllowedTypes(new_types)
sst = sst_data(x, y)
Ctrl + B
x0 = y0 = size // 2
hexdump(fuzz_frame)
dlist[a][1].append(b)
obj
BEGIN
raw_ta = tty.tcgetattr(stdin_fileno)
b = 0.0
data
MyConverter = NBConverter(config=config)
profile = LineProfiler()
out_dates.append(idx[iEnd])
user[:name]
MyClass.LAMBDA = MyClass.ClassMethod
a = 10
print(curr)
iterate(f, 4, 4)
model = Picture
sorted_deltas = np.sort(deltas) / frequency
dayoftheweek = 2
library(reshape2)
Qt.QWidget
step = Number(1)
layout = cairo_context.create_layout()
connnection.fetch(num, rfc)
thing
tpr = dict()
Py_END_ALLOW_THREADS
error_description = strdup(str)
nan < 1.0
print(mytext)
print((d.Caption, d.FreeSpace, d.Size, d.DriveType))
theOnlySlot = pkcs11.getSlotList()[0]
force[iParticle + 1:, :][(ind), :] -= ljdist
width = istop - istart
sgn = npy.sign(q)
raise
print(st_john_time)
self.amount_seen += len(data)
arr2.ctypes.data
FIND_PACKAGE(PythonInterp)
platform = sys.platform
exp = pp.Forward()
v = x.range.values
s = s + 42
gradient(A * B * C)
state = (1.0 - rel_coeff) * sample + rel_coeff * state
library(lubridate)
ret = []
something
multiply = a * b
primes = set(primes_to_one_million_however_you_want_to_get_them)
m = Mock(spec=[])
observer = startLogging(stdout, setStdout=False)
UseShellExecute = false,
csrf = CsrfExtension
base = base_size ** num.arange(base_size)
mls = unary_union(lr)
pc_dud_ = pc_dud[:]
roc_auc[i] = auc(fpr[i], tpr[i])
add_label = lambda lst, lab: [(x, lab) for x in lst]
Fs = 1600
adder_node = a + b
resp_json_payload = response.json()
z = randn(2048, 2048)
n[k] = expected[o, k]
model = PageFile
exceptions[exc_name].append(currentRowIdx)
A
print(hex(bits))
zero_mat
help(divmod)
minlen, maxlen = 2, 22
print(ss)
_rollback_on_exception()
4
buf = vim.current.buffer
cd(saveDir)
t = np.log2(fnc / ((1 - c) * f))
threadLimiter = threading.BoundedSemaphore(maximumNumberOfThreads)
serial.data
f = 1 / precision
x.dtypes
fig_size[1] = 9
first + second
PyObject_HEAD
object
demo(h2o.randomForest)
interactive
func = entry_point.load(require=True)
C
box.close()
not aborted
array2
tot = 0.0
num = 0.1111111111
enc = OneHotEncoder()
raise
kCGEventTapOptionListenOnly, CGEventMaskBit(kCGEventLeftMouseDown)
make
point.x = 5
tagged_addresses = [usaddress.parse(line) for line in data]
s = set(excludes)
nsamples = 400
errorCount.tag.test_value
print(pool.map(ping, addresses))
value
ignore = tests.py, urls.py, migrations
print(e)
runstart = curpos
mantissa = n / base ** exponent
ajgagag
currentUser = x
{}
a
listOfDf = list()
results
_read_eof = gzip.GzipFile._read_eof
RefCount = RefCount + 1
marshal.loads = pickle.loads
irpd = iter(raw_png_data)
acc = roc_auc_score(Y_test, rf.predict(X_test))
changes[attr.key] = hist.added
master = true
raise
tail
ret
sf.setHostnameVerifier(SSLSocketFactory.ALLOW_ALL_HOSTNAME_VERIFIER)
leaderb = self.leader.get(b)
week_day
file
interval_ms = 15
mydict = code_to_generate_dict()
message = buffer[:length]
children = parent.children(recursive=True)
dispatch_release(group)
ipshell = IPShellEmbed()
foo1.__call__
print(ans)
light.in_normal = termcolors.Blue
leadera = self.leader.get(a)
a = to_none(a)
values
cmds()
touch / tmp / foo.tar
filter = get_exception_reporter_filter(request)
invokePyFunc = oScript.invoke(args, outIdxs, outArgs)
libs_path = libs_folder.GetPath()
X, y = iris.data, iris.target
hostnames = [HOST1, HOST2]
cap.setCapability(CapabilityType.ACCEPT_SSL_CERTS, true)
r_list, w_list, x_list = select.select(r_list, w_list, x_list)
z
2
-redis
c_1 = data.col1 == True
b_index = 0
unord = set(unordered)
print(af.labels_)
kwargs = {}
combinations = permutations(letters)
sorted_no_zeroes
next(cycle_iter)
__mock_native_all_users
d = DesiredCapabilities.CHROME
column
exec(template, namespace)
tst.num_testsuites = FOO
StreetCat.__base__ is Cat
page = _decorateNewWindow(page)
t = np.log2((1 - f - c + fc) / ((1 - c) * (1 - f)))
countLines(name)
arr = [10, 10]
b = a > 4
start = -1
Terminal = false
dataset = getDataSet(tiffFileLocation)
9
AtoCIm = []
toDoublefunc = UserDefinedFunction(lambda x: float(x), DoubleType())
6
total = len(fp)
needed = self.resolve(parse_requirements(requirements))
date
foo.txt
j = 1
df
a = clusters[int(merge[0])]
c = 2 * asin(sqrt(a))
rho, theta = line[0]
deleteLTU
var1 = db.name,
cores = 4
toSend = []
a
arrImage = np.array(sceneImage)
child = deepcopy(child)
a
print(word_freq_sorted)
fst.input_symbols = your_symbol_table
res
yclass = y[nz[1][i]]
num, denom = expr.as_numer_denom()
num = 2
print(m)
print(path)
annotated_films = []
Z[::2] = X
min = midPointOfList
welcomeString = welcomeString.lower()
free(list2)
s.set_seq1(i)
compress_level = 6
double * dn
free(ret)
listOfDf
d = {}
more_fragments = bool(ip.off & dpkt.ip.IP_MF)
n += 1
f, (ax0, ax1) = plt.subplots(1, 2)
names
mu = 0
B = B
repoItem = json.loads(r.text or r.content)
tag = tag_query[0]
rec = rec[rec_end + 1:]
q &= Q(authors=author)
B = A.B
cond.release()
y = v
conv[10] = str
rho, theta = line[0]
root = RootLogger(WARNING)
True
students = select(s for s in Student).prefetch(Student.group, Group.dept)[:]
colours.bind()
r = Fraction(1, d)
print(var2)
foo[2]
a_index = 0
fragment_offset = ip.off & dpkt.ip.IP_OFFMASK
seq_type = type(seq)
longest
m
assert ha == hb
a() and b() or c() or d()
e
engineConfig = EngineConfig()
C = 400
newdom = transform(dom)
self.now
l
str.concat(d)
lc = LoopingCall(doComputation)
sum = 0
classifier = svm.SVC(gamma=0.001)
a
host = host_on_current_line
tn = (~bt.bitarray(p) & ~bt.bitarray(g)).count()
print(digits + chars)
a + +ab
x
model = TheModel
a is b
_.dtype
delta = part - int(part)
x
1 is 1.0
cv = LeaveOneLabelOut(labels)
newhours = hours * 60
a
delta = 0.1
2, 2
a = 5
serializer.Serialize(jtw, myObject)
bob = c(squid=1.0, octopus=0.5, nautilus=0.2),
print(backToRows)
1
items_bought
read_as_utf8(pipe_r)
0.75
upper_limit = scoreatpercentile(arr, 100 - percent / 2)
s[s].index.values
_2
results = device.get_ips()
L
gr = P.OneOrMore(P.Group(key_equal + val))
num = 10
c = OpenSSL.crypto
self is other
inv_d = 1.0 / d
ifor_val = something_else
x
b
accounts = defaultdict(attribute)
assert attrs != -1
listen = 128
sizes
s
country_data
InvalidKey = object()
readline.set_completer(complete)
result_score, result_words = search(clean(text))
double * pd
name or code
pp = pprint.PrettyPrinter(depth=6)
x
PyObject ** f_stacktop
prefix = args[i]
kwargs.update(start_new_session=True)
make
result = n
mlabel2 = Label(myGui, text=mtext).place(x=180, y=200)
a
all_songs = Song.select().orderBy(Song.q.name)
chain = ChainMap(d, *extras)
info = resource.getrusage(resource.RUSAGE_SELF)
done = true
discard_first_request = True,
storage = CreateMemStorage(0)
year, week, _ = now().isocalendar()
d
object_sizeof(PyObject * self, PyObject * args)
url = comment_feed_url % video_id
print(grouped)
text
index = 2
state = 0
precision_ratio = true_positives / (predicted_positives + K.epsilon())
half = 0.5 if number >= 0 else -0.5
PyErr_BadInternalCall()
full = []
z = getch()
attachment = {}
self.ignoreExpr = ignore
countChars(name)
s = z.dumps()
sz = 0
list = object.method()
n = 80
100
1
indices = set([0, 7, 12, 25])
cd / Library / Frameworks
correctDate = False
BEGIN
simlen = 5
last_event_ticks = event.ticks
dx, dy = 1, 2
sort_by = eval(by)
times = pd.DatetimeIndex(data.datetime_col)
df
bestStart = -1
Q = [start]
a_sps = sps.csr_matrix((data, indices, indptr), shape=(rows, cols))
has_more = 1
hour, min
N = 10
sum = 0
htrot = np.roll(ht, N2)
application_root = __dirname
ii = [700, 2000, 10000]
table
unt(il)
output_lambda
l
doSomethingWhenNothingFailed()
curpos = 0
l
max_x = MIN_INT
a = list(linsolve(lista, a1, a2))
server = servers.FTPServer(address, FTPHandler)
done
NNs_inside_NPs
t[~np.isfinite(t)] = 0
pb = NSPasteboard.generalPasteboard()
notification.setTitle_(title)
n = 12
rect1 = 2, 2, 10, 10
out.flat[inds] = values
free = st.f_bavail * st.f_frsize
print(nice.myGlobal)
print(baz.func)
timeit.timeit(t1)
Date_Time
libs
html5lib == 0.999
print(y)
sendp(pe, loop=True)
6
measuredSpeedsList = []
d2.Prod.div(d2.Col2)
realm = manhole_ssh.TerminalRealm()
a = []
i = 0
print(w.fact)
timeSeries ** exponent
outputfilename = self.image_filename
v = memoryview(dest)
t_len = int(t_len, 16)
parser = LRParser(lr, pinfo.error_func)
di = InternDict()
[Q, R, E] = qr(M)
interactive
tag
lst = [10, 11]
struct
handlersToKeep.append(handler)
a = x
InitializeComponent()
where_are_NaNs
lastImage.visible = true
_testme = dill.loads(dill.dumps(testme))
w = np.where(abs(w) > box)[0]
start = time.time()
cd / some / directory
Lu - -uppercase
threading._active[gettid()] = threading._active.pop(current.ident)
peaks = feature.corner_peaks(bw, min_distance=min_dist, indices=True)
hm = HookManager()
ie = webbrowser.BackgroundBrowser(iexplore)
2
out[colour] += array_
R
cat / tmp / uniques.txt | uniq - u
model = DistinctAlert
theta0 = theta0 - step * dEdtheta0 / n
1
elements.append(shell_table)
x = x1
nested_instance.__class__ = nested_class
f = Foo()
data = yaml.safe_dump(dict_before)
self.includeMatch = include_
x = myrandom.random
worksheet = spreadsheet.get_worksheet(0)
print(current)
product *= num
is_not_method = lambda o: not inspect.isroutine(o)
A4D
d
mask2 = df.b2.str.len() == 0
cf.add_widget(tc, 10, 10)
print(DF)
recipe = collective.recipe.template
W_fc1 = weight_variable([7 * 7 * 64, 1024])
4
A = Y.real
partition = [current]
DateField(question.text)
rd = IntervalTree()
self.__wrapped__ = wrapped
res = next(chunks)
f = mp.figure()
dns_cache[args] = res
output = output.split()
combo_password = raw_password + salt + master_secret_key
s = StringIO(large_string)
org.python.Python.PythonProfileChanges - 2.7
a
exceptions = {}
yourMethod(condition, 1, 2)
print(sensor.Name)
body = ev.msg.body
self.size = size,
g.latlng
set2 = [greeting for greeting in set1 if filt in greeting]
s2 = extendAndInterpolate(s1, depth2)
pypreprocessor.removeMeta = True
raise
print(separator)
print(Color.red)
I1 = iter(M)
monkey_embedding_column(education, dimension=8),
parts = python
pdb.pm()
print(set2)
dir_path = os.path.splitext(os.path.relpath(__file__))[0]
rootlist = []
foo2[foo2 == 0] = nz_values[middle]
s = len(a)
contrived.CONST = 200
oauthlib_backend_class = oauth2_settings.OAUTH2_BACKEND_CLASS
connection
test
A = Y.real
lower_corner = [2, -2]
middleware.process_request(request)
American
iris = load_iris()
a
a = bitarray.bitarray(total + 1)
base[k] = test_wrap(v)
lib_b
R = robjects.r
lookback = 60
use_question(id)
B
_decorated
NotImplemented
gs = GridSeachCV(clf, params_grid, cv=cv, n_jobs=-1, verbose=2)
points
float
0.0
foo = lambda x: dico.index[(dico[1] > x) & (dico[0] <= x)][0]
id_arr2[sf[0]] = -sf[0] + 1
self.orig_fp = cc.focal_point
instances_to_be_deleted = CollectedObjects()
len = 0
sums = Counter()
g = SQLFORM.grid(db.dogs, searchable=False, csv=False, user_signature=False)
cancel(grad)
raiseMe()
DB_USER = foo,
folds = train_test_split(list(range(len(y))), test_size=0.5, random_state=15)
dist = sqrt(total)
tuples
pi = ProductImage(product=product)
item = 4.4
result_ips = [ip.ip for ip in results]
line_contents_expr.runTests(sample)
uid = uuid.uuid4()
result = op(lhs, rhs)
objects[the_key] = obj
areaCodes(n_int)
b[0, 0] = 99999
doc = nlp(sent)
x
clean_array
int_gx = integrate(gx, (x, a, b))
component_stats[component_map[a]][0] += 1
a
_check_something.__wrapped__ = func
t = name, age, sex
tcp = ip.data
state = present
customer_id
cvPow(image_Re, image_Re, 0.5)
print(split)
raise j
next(filter(my_criteria, e))
make
a
Py_DECREF(incr)
raise
PyObject * result
df
root
hi + 1
s
print(VeryCommonModel)
mydict = {}
df
-defaults
true
8
scores[names[i]].append((acc - shuff_acc) / acc)
print(mask)
print(a)
Level1
lt
print(a)
driver in shift_data[shift - 2 - nudge]
label_im, num = ndimage.label(invert_im)
[run]
self.listeningPort = reactor.listenTCP(0, self.factory)
(0.02)(0.01)(0.01)
sh - l
self.simulRunner = SimulRunner()
testing_this_round = training[i * subset_size:][:subset_size]
least
n_below = 2
entropy_x_not_set = entropy_x_not_set - probs * np.log(probs)
currentmap[j * 2][k * 2] = uppermap[j][k]
result = os.read(stdin_fd, 1024)
environment = SITE = domain1
gr = [iter(c)] * 2
group
library(data.table)
filepath
print(min_count)
A
max_length = 255,
strip = data[:, n * 24:(n + 1) * 24]
data = [[0, 0.25], [0.5, 0.75]]
builtins.open = original_open
h
retval[i] = numpy.arange(Tsf * i / Tso, Tsf * i / Tso - o, -1.0)
utc = pytz.utc
m = list(list(range(1 * i, (n + 1) * i, i)) for i in range(1, n + 1))
tree
id(GlobalDataBase.a)
time_header = [words[1:]]
-restart
int
sub_seconds = java_timestamp % 1000.0 / 1000.0
s
print(constants.PI)
out
s
size = 5
self._kind
max_distance = 0.0001
a
print(probs_y2.eval())
js = json.load(f)
ret[decoded] = value
d = nx.drawing.nx_pydot.to_pydot(g)
b
ls - al
bar = 2
list(range(48, 57))
a
series
predictions = Flatten()(v4.layers[-4].output)
n = 10
x
+4
database = _db_name,
s
dict
lr.is_simple
data = list()
udf = UserDefinedFunction(numpy.random.normal, DoubleType())
a
mask[:c] = True
names
nb_lines
make
show()
vector < float > descriptors1, descriptors2
n.lineno = n.lineno * 1000 + n.col_offset
print(ar)
dst = pre[dst]
l1
machine = machine[1],
adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)
FOO = 1
t = example,
null
count = 0
path = calculate_path(params)
root.dist = 0
self.direction = direction
subjectlines = []
area_cell
gridsize = 512
lo = code1[1]
guessesMade += 1
time
print(df1)
width = incomingImage.width()
runner = CrawlerRunner(get_project_settings())
t = now()
extract_messages = babel.extract_messages,
media
hf = 1 / (2 * np.pi * x / N2)
tuples = 0
s
lang = pycountry.languages.get(alpha2=two_letter_code)
j += time_interval
a
Location.createTable()
topWords = {}
a
delta
chmod + x / tmp / install.sh
Project
elem.mozRequestFullScreen()
x, y = line.split()
user = users[1]
retcode
activation
ineqLB = rep(0, 2 * countw),
entropy_x_set = entropy_x_set - probs * np.log(probs)
loaded = True
zeros = sum(1 for bit in range(N) if number >> bit & 1 == 0)
tst.name = FOO
p._hash = 9
a
datatoplot = a1.pop()
LC_ALL = C
raise error(v)
object.attribute = object.attribute | variable
d
root = Dir()
x
leftover = set(str(seq).upper()) - set(alphabet.letters)
myvariable = 4
Type = simple
stopsignal = INT
app_iter = self.application(environ, self._sr_callback(start_response))
hostname = result.hostname
d = 1.2
kwargs.update(preexec_fn=os.setsid)
-A
queryset = ImportMinAttend.objects.all()
kwargs.update(creationflags=DETACHED_PROCESS | CREATE_NEW_PROCESS_GROUP)
ds = pd.Series(distancesArray)
__pyx_r = __pyx_v_data
decryptedString
assert all([pieces.scheme, pieces.netloc])
a
img1StringIO = StringIO(img1.read())
password = foobar
least = args[0]
False
queryset = queryset_1
print(sorted([int(n) for n in nodes]), count, time)
l.stop()
articleDirective.js
column_list = zip(*row_list)
print(gb)
B
grayscale = cv.CreateImage(image_size, 8, 1)
print(5)
item = PySequence_Fast_GET_ITEM(seq, i)
print()
i
now = str(time.time())
message = PyString_AsString(pvalue)
artist = StringCol()
queryRequest.setExpressionAttributeValues(expressionAttributeValues)
press(ENTER)
PyObject_VAR_HEAD
print(a.my_member)
voronoiBackground = voronoiBackground.reshape((resolution, resolution))
tree = lambda : defaultdict(tree)
search
base = num ** (1.0 / r)
temp2 = ans(n / 2 - 1)
count = 0
a
P = Prob[-a <= X <= a] = Prob[-a / sigma <= N <= a / sigma]
key = lineSplit[0]
G = nx.path_graph(10)
already_found = False
module = Module()
token_dict = {}
values = np.cumsum(np.random.random(n) - 0.5)
QEvent * event,
out
DateTime
c2 = decimal.getcontext().copy()
True
dist = (points - single_point) ** 2
indices
true
_a_valid_string_
retcode = 0
o = ord(byte)
n = ap.Namespace(**d)
raise
doc = ET.parse(someFile).getroot()
print(2 + toint(s))
TGCTTGGACTACATATGGTTGAGGGTTGTA
bits0
distance = distance - BOX_LENGTH * (distance / BOX_LENGTH).round()
t = pow(fract, exp // 2)
vector < Vec4i > hierarchy
n = 4
it = iter(seq)
max_ = tmp, lst.index(tmp)
monkey_embedding_column(occupation, dimension=8), age, education_num
new_levels = F[boundaries]
row_list = []
a = np.array(yourlist)
s_name = os.ttyname(slave)
one
[accuracy, training_summary],
container = parentbbox.padded(-self.borderaxespad * fontsize)
data
1
print(match.location)
u = list[tmp - 1] + l
file_util.copy_file = wrapper(file_util.copy_file)
Custom_ModelContainer.setModel(f.result())
key = future_to_key[future]
print(combinations)
print(totals)
Domain = Orange.data.Domain([List, Of, Column, Variables])
p = Pool(4)
driver.port.fd, peer.fd = posix.openpty()
s_to = 44 + eggs()
somefields
somfields
A
LOCALPORT = 8888
print(s)
code = Required(int)
-1
arrayoftagList.tag_list = [malloc, anothertag]
self.accuracy = accuracy
tcuda = e - s
+report.tex
frame = frame_info[0]
canvas.renderAll()
{{adminForm.is_admin.label}}
font_names = [f.name for f in font_objects]
metadata.addUserMetadata(metadataKey, value)
done
d
arr
data = variable_decode(result.data)
FindMin - O(1)
print(AA)
x
aList = []
r
char * letter
fpr = dict()
21,
peer._reconfigurePort()
transID
done
correlations = {}
bwimshow(dots)
c = get_config()
id_arr2 = np.ones(v.size, dtype=int)
gdb > pystack
data.add_tuple((VALUE, username, user_likes))
contents.operations.extend(TEXT_STREAM)
count = 1000
print(sam if sam > 1e-05 else 1)
e = Subscriber.objects.create(email=email)
rs = func(*args, **kwargs)
child = TaskSerializer()
sio = StringIO()
1.0
have
percentile_list
t_step = 0.01
props = iface.GetAllProperties()
next
Math.sqrt(this.distanceSquaredTo(p))
poi = points_of_interest[ASK_PRICE]
str_name
raise StopAsyncIteration
__old_runfile(file)
b.finalize_options()
d = match.groupdict()
fn.__annotations__.update(original)
freeGPUMemInGBs = GPUFreeMemoryInBytes / 1024.0 / 1024 / 1024
x
int
uniqueSet = sets.Set(conacatData)
gn = geocoders.GeoNames()
win_bottom = win_geo.bottom()
closest_samples = closestN(X, 5)
func = lambda i: 1
paragraph.keepWithNext = True
ifor_val = something
i = 0
x
x
f
margin = 1.0
nz = X.T.nonzero()
result = boxBoxes(data)
flip = defaultdict(list)
youarehere = toplevel.index(curdir)
min_y = MAX_INT
fdir, fname = os.path.split(fpath)
gz.close()
fill_value = 0,
req
print(v2)
first, second = 10, 20
applicationDirectory,
value
self.start = start
rand_int <<= 8
self.text = text
maxCols = lastCol
latest_start = max(r1.start, r2.start)
nbyte - chars_left
pwd - P
dict1
names(DATA) < -HEADER
cond.notifyAll()
A
True
count = len(q)
execute_app()
DynamicEnum.bar
IconImage = PhotoImage(file=IconFile)
conn
descr = orig_type.descr
5
1
end
print(gateway_info)
ratio = 2 / 5
np = t[np_pos]
log4j.rootCategory = ERROR, console
X_idx = X_int - X_int.min()
script.sh
collResv.rejected = True
test1()
low = -4 * np.sqrt(6.0 / (fan_in + fan_out))
print(d)
array
reg_data2 = h5_file.root.reg_data.read()
to_revision = pysvn.Revision(pysvn.opt_revision_kind.head)
out[key] = i
make
a
X_scaled
inc_count
print(apple)
bytestr[:L]
hello
hello - world
myFunc.innerFunc = innerFunc
self.size, self.direction = sd
res, = res
sslify = SSLify(app)
print(p1, p2)
epsilon = 1e-05
start = PyLong_FromLong(0)
number_scales = 5
A
targets = zip(list(grouped.groups.keys()), axs.flatten())
rawdata = h5read(h5Filename, h5Dataset)
cd / home / pi / circulation_of_circuits
shrink(a, 2, 2)
element *= V.value
ndigits.insert(0, int(n_fraction))
checkbox = text.parent
False
bw = 1 - img_as_float(color.rgb2gray(image))
log4j.appender.logfile = org.apache.log4j.RollingFileAppender
set
kw = self.keywords.copy()
False + True
pending -= 1
walk_tree(v)
a <<= 2
where = n
temp = {}
UNION
step = PyLong_FromLong(1)
runPipe(funcs, i)
encoded_string = i_have_no_control()
server_side = True,
this.LocalByteArray = Encoding.UTF8.GetBytes(myString)
python
fft[0, 0] = 0
w = weakref.ref(foo)
False
str_
cc = {}
APPWIDTH = 800
PACKAGE = numpy
i
python
text = pb.stringForType_(kUTTypeUTF8PlainText)
m1
Left = constructBalancedTree(values, min, median),
_______________
delay = (reset - datetime.now()).total_seconds() + buffer
t[1, t2]
data_to_use = np.take(data_to_use, reqIndices)
done
yag = yagmail.SMTP(from_add, password)
processItemsNotTwo_case1(list1)
exit
init(convert=True)
sol2 = sl.lstsq(a, b)[0]
Index
rbf.nodes
scale = 16
self.speed = 0
p = 11
labels[node] = node
d.addErrback(command_die)
[install]
c
print(x, y)
select_obj = Select(inputElement)
qp = QPixmap()
datalines_int
workers = 2
model = Film.director.through
i = left
python
set - f
hashed = hash(large_item)
A
a
x
14 < 17
cd / home / el
date
python
print(h)
deletetest
start_delta
toc - tic
curr
w_list = list()
1
pd = 100 * abs(a - b) / a
1000.0
mod.doc
stdout
traceback.exec_print()
wrapper
cc.position = self.orig_pos
x = list(range(10))
ndigits.append(n_int % 10)
x
print(song_details)
sum = sum + i
print(importances)
python
next_nearest = holidays[indices]
a = 1.0
res
x
v4 < -c(2, 5)
T(0 * F) - T(10 * C)
Elements = []
done > README.rst
robjects.r.source(PATH_TO_R_SOURCE, chdir=True)
o = Object()
out
number = 10000
tunnel
X_batch_projected = clf.transform(X_train_mmap[batch])
lis
last = doc
changes = settings.db.changes(since=since)
mid = int(N / 2)
6 | O1 | HOH
username, password = config.password, use_tls = config.use_tls,
print(response)
latex_sphinx_base
opt.icon = icn
find_inter = FindIntersectionsWrapper(ent, collidable)
x = {p, q, r, s}
di = {}
a = Poly(expr, x)
self.retries = retries
y = 4
dark.in_normal = termcolors.Green
self.failOn = failOn
extra = 1
y &= 4095
KeyCount = len(SplitKeys)
v, = l
s = self.fp.read(amt)
gstate = PyGILState_Ensure()
a1
x = blist([0])
B1.expand(alpha1)
diff = True
new_src = replace_code_lines(src, start_token, end_token, replacement)
A.my_member
xbins = list(range(0, len(x)))
base_url = CONSOLE_ARGUMENTS.base_url
print(t2 - t1)
ExistingSession | Disconnect - PSSession | Out - Null
_
NUM_COLORS = 22
s2 += e * e
result = decoder.decode(data)
s
arr
b = json.loads(js)
x = 1
option = value
self.execute(Command.CLOSE)
rnd -= item.Proportion
Y = iris.target
self.leader[a] = self.leader[b] = a
raise
lin_idx
f.__dict__ = func.__dict__
print(sums)
first, rest = field_name._formatter_field_name_split()
topRowOfSpan = cellAddr.row + rowOffset
temp
BarObject_Type.tp_setattro = PyObject_GenericSetAttr
height = 720
data_file = get_pdata_path(base, 1)
cond.wait()
found_in_b = True
run = paragraph.add_run(name)
wp.A
print(m)
2
full_l = disj_part + subs_part
sort = np.argsort(result2)
anObject.score()
spindex = pyqtree.Index(bbox=[0, 0, 1000, 500])
x.sizes.add(sizes)
_write_data(writer, attrs[a_name].value)
print(wrapper.fill(para))
rpc = []
ts_column
target = row.address_chi
[v] = l
firefox
a = 12
arr
self._nodes
print(entry)
fmin = N / f2
420
sums = defaultdict(int)
dir(sys)
data = image[6]
print(line, file=f)
A.assign(**d)
microseconds += delta_microseconds
builder.resource()
i
rank = [item for sublist in rank for item in sublist]
pending = len(iterables)
m
c
variable1 = data[0]
BEST, UL, UR, LL, LR, R, CL, CR, LC, UC, C = list(range(11))
exif = i._getexif()
table_pieces = table.split(width, height)
cron = croniter.croniter(sched, now)
values = [42]
f = lambda : y
diff
PYTHONIOENCODING = utf8
us = int(t % 1.0 * 1000000)
table_plan = Plan._meta.db_table
hierarchy -= 1
end = start + dist * (count - 1) + 1
myGeolocCountry = DoReverseGeocode(lat_start, long_start)
a
[pytest]
print(file2.foo)
mpz_set_ui(result, 1)
sum += polys[i] * maybeX ** i
lst
cat > myModule / subModule.py
rep(alphabet, each=n - 1),
r2i = 1.0 / distanceSquared[ind]
y = 2
bytestr[:L - x]
nchars = len * PyUnicode_GET_LENGTH(str)
print(subtree)
background.composite(original_thumbnail, 0, 0, CompositeOperator.InCompositeOp)
gaps = []
rounded = time + datetime.timedelta(minutes=round_to / 2.0)
Feature = type(division)
column2 = upd.column2
sys.path = [p for p in sys.path if not p.startswith(dist_site)]
s = c.read(1 << 20)
-2.7
tree
print()
_w = Functions.motion.move().forward
kProfile = lsprofcalltree.KCacheGrind(profile)
num = 100000000
aList
c
obj.d_prop
x = (rad * C + alt) * cosLat * np.cos(lon)
value = 40
num = 21
col_uni_val = {}
s
word_form = p.number_to_words(i)
input_date
print(joined.dtypes)
N = 128
auto_choose = True
filesize = 0
sorted = CarManager()
self.leader[k] = leadera
data_length = 8192
to_exclude = {1, 2}
raise DatabaseTimeoutException
comments, submission = comments_and_submission
timer = threading.Timer(DELAY, doStuff)
plugins = python
list2
max_execution_time = 10000000
array
myapp / templates / main / index.html
now
ERROR = 4
self.leader = {}
model = MeasurementPoint
a
n = 4
dumps(pt1)
print(arr)
list[i]
c
__builtin__.object
hover.perform()
SALES, REPRESENTATIVE - Sales
value = CallMemberTest(spam)
Tuple.Create < object, object > (null, null)
tmp
_____going_________________you_
cond = threading.Condition()
f
CONST
date = db.DateTime()
A
StdDraw.line(xmax, ymin, xmax, ymax)
new_length = 50
mystr
python
png_str = d.create_png()
variable2 = 2
server_side, verification_mode
PyObject * list2_obj
indices
A_f_delta = abs(f[X_delta]) ** 2
result = page_two_calculation(arg1, arg2)
dbDatetimeNoTz = getFromMysqlDatabase()
_, x = t
currentForm = 0
num_vert = int(round(geom.length / distance))
10, 1
-D
p.servers
X = pd.DataFrame(b.data)
UDPSock.bind(addr)
self.leader[a] = leaderb
C
word2 = random.choice(WORDS)
workers = 2
r = random.randint(1, 100000)
override_str_here(obj)
ipdb.post_mortem(trace)
a
text = Group(~any_header + ~END + restOfLine)
display_size,
cut - c2 - yourfile
n_above = 2
priority = 996
wxPyEndBlockThreads(blocked)
lastCount = lenOfPage
project_name, project_id
a
cc_btm -= broken_connected_triplets + broken_open_triplets
Factory = forwarding.SSHListenForwardingFactory
True
l = inspect.stack()[1][0].f_locals
select
lastLeft = left
start = PyInt_FromSsize_t(istart)
verifyClass(IFoo, Foo)
SQLITE_DELETE = 9
xml = etree.parse(StringIO(content))
hi
S = C * FF
browser.helperApps.alwaysAsk.force = FALSE,
x
frame
year = 2012
a
obs.date = utc_time
x = initial
self.gomez = body
path_buf = wintypes.create_unicode_buffer(wintypes.MAX_PATH)
true
tot = sum(v for t, v in prevValsBuf)
images = [f for f in listdir(dir) if isimage(f)]
[pytest]
ndigits.insert(0, 0)
comp = n2[:]
ll = []
apt - update
print(hash(i) % 8)
y = x * a
group_sizes[key] = len(group)
values
x
with_statement.getOptionalRelease()
64
vx, vy = 0, 0
binplace
assert PyFloat_Check(v)
info = c.inspect_container(container)
config.one.key2, type(config.one.key2)
EOF
auth = SiteAuth()
start = 0
result = (v for t in zip(data, tweets) for v in t)
fetchOptions.startCursor(Cursor.fromWebSafeString(cursor))
Example
translation_table = {}
__END__
ret
print(double_encode)
clienthostid
m
out
group_id = fd.require_group(group_path)
print_all_libs_info(stderr, INDENT | SHOW_CONFIG)
print(stamp + text)
anchored_box = bbox.anchored(c, container=container)
s
attribute
sums = [np.sum(x) for x in weights]
args = pa.parse_args()
mask = dates[lower:upper]
pGlobal = PyDict_New()
X
numerator.floordiv(denominator)
strings = []
now
++i
code
integer_intersect = intersect(IntegerType())
false = False
table_post = Post._meta.db_table
users_table = class_mapper(User).mapped_table
print(final)
i -= 12
[install]
log_observer = log.ScrapyFileLogObserver(logfile, level=log.DEBUG)
sent = sentence_create(input_string, dict)
regex = {alternatives}
4
model = Group
params = 4, 5, 6
old_state = output.running
marker_seg_mask = cv2.inRange(img, MARKER_LOWER_BOUND, MARKER_UPPER_BOUND)
inner[innerKey] = innerValue
us = 0
access_result = _eval_access(logged_in, roles)
num = c_int64(0)
_unused = q.popleft()
a
diamond = 6
[aliases]
loader = importlib.machinery.SourceFileLoader
self.microseconds %= 1000000
padding = -len(a) % n
Y = robjects.FactorVector(df.b)
rho
self._sections = self._dict()
triu_cache[len(x)] = xs, ys
c = get_config()
pid / run / nginx.pid
idx0
ls - l
mesh = spatial.Delaunay(pts)
toc = timeit.default_timer()
sigmoid_grad_sech2(-500)
observer = log.PythonLoggingObserver()
diff = False
a = p.a
builtins.open = bin_open
sim_df
pairs = inner_product(universe)
b = distutils.command.build.build(distutils.dist.Distribution())
x is y
False == True == False
http_data = speed_test(False, 1000)
char * contents
max = --midPointOfList
cfg = Config()
char * str
y
parsers = parsers.JSONParser
b = 4, 4
solve
base = 10
i = 6
PAR = E.par
npy_intp * shapeX
userdata
print(i.name, i.definition)
1.0
the_exception = cm.exception
n /= f
b
rotation = math.radians(rotation)
mpz_set_ui(one, 1)
table
a = Document()
someList = [JobState.RUNNING]
unique_pairs = itertools.filterfalse(same, pairs)
a
x = 10.5
tree = cKDTree(points)
steps
t = 5, 6, 7
temp1 = ans(n / 2)
cap.setCapability(ChromeOptions.CAPABILITY, chromeOptionsMap)
Parameter * component
coinCount = minCoins[cents - j] + 1
min = ++midPointOfList
num_folds = 10
print(d)
scenario_name = match_label()
cut - c2 - filename
Namespace(auto=False)
print(substitution)
tail
n = 100
small_mask = 10
8
print(PKey)
res
chars = 0
arr
parent_only_code()
argv = FLAGS(argv)
a = 6
c2 = myVector(1)
y
d
contained(fake)
dropped_copies = []
log = logger.Log()
precision = 0.1
thisMatch.Groups[0].Value
answer
string
a
deletefp
raw = np.log2(raw)
column1 = upd.column1,
N = 10000000
result
MetaModel.module_to_models[module_record.name] = []
regexp_tagger = nltk.RegexpTagger(patterns)
0 or 8
i = 0
ls - l
F1 = focal(I1)
div, mod = divmod(node_id, 58)
V = sc.broadcast(someValue)
baz = foo.bar.baz
domain_config = ET.fromstring(domain.XMLDesc())
process_name = my_regular_worker
remove
start
collector.collect([objective])
x
current_range[1] = end
ast = readMathMLFromString(xmlString)
arr
dt
div = 2
apple
t
arr[i] = PyLong_AsUnsignedLong(temp_p2)
Py_SIZE(a)
muints.registry
c = a[:, ([0, 1, 2])]
re._MAXCACHE = 1000
max_sz = int(len(a) * probability)
filename = argv.pop(0)
divider = float(1 << power2)
parser = XMLTreeBuilder(target=handler)
c
a = b = c = 2
x &= 4095
t
out
print(s)
fdist1 = FreqDist(text)
f = d ** e
EOF
strides = a.strides + (a.strides[-1],)
2
F2 = focal(I2)
pylab.grid()
gen = (Paragraph(self, p) for p in raw_paras if p)
pylint_output = WritableObject()
data = list(range(1, 11))
d
arg2 = args.arg2
result = func(self)
monkeyPatchDBConnection()
df
nan == nan
update_catalog = babel.update_catalog,
p1, p2 = pprompt()
x
PyObject * gi_name
True
featureSelector = SelectKBest(score_func=f_regression, k=2)
x
z
c
__metaclass__ = NewMeta
[report]
pylint_output = WritableObject()
start
dmp.diff_cleanupSemantic(diffs)
D = -260
ol = newOl
48 % 48
ratdiff < -rep(ratings, n) - rep(ratings, rep(n, n))
cPickle.dump(my_state, f_state)
rev
X_delta = abs(freq - F) < delta
level
not found
old = np.sin(omega_t2[-1000:])
print(energy)
12
li
answer = answer - 12
d = endpoint.connect(factory)
res = parameters
methodName = attrName
recipe = zc.recipe.egg
rank = tmp.map(range)
done
a
RegistryManager.new(cr.dbname)
seq = tuple(seq)
cd / tmp
o | o
xGp
ctx = pyudev.Context()
prevValsBuf.append((t, v))
user = _db_user,
end
exit
regions, neighbors_per_region = region_group.sum(counts)
wjson = weather.read()
b
tagging = st.tag(text.split())
out_x = in_x ** 2
diff = relativedelta(other_time, now)
window = Gtk.Window(Gtk.WindowType.TOPLEVEL)
node
t = s
used += 2
result
value.testAttr
totalRows += 1
j
TDS_Version = 8.0
PyGILState_Release(state)
x
a
SubPackage.TestWithGlobals
producer = SimpleProducer(kafka)
+report.pdf
print(h.__doc__)
DEBUG = True
f.__doc__ = func.__doc__
num
sqs_msg = sqs_q.receive_messages(MaxNumberOfMessages=1)
inherit_from = object
out
g = Generator(fp, mangle_from_=False, maxheaderlen=0)
internalFoo(intArray)
result = expensive(item)
mapping = list(mapping.items())
--reports
0
assoc.py = Python.File
foo
a
Py_NoSiteFlag = 1
s = list(iterable)
A
totPrimes = int(totPrimes)
dfTest
0
checker = checker | 1 << val
ret = [(instance_state(current), current)]
google.loader.ClientLocation.longitude
params = 1, 2
Default(program)
sleep(delay)
1
output = server.xml
python
topWords[iWord] = 0
64
adjusted_points += 1
2, 5
mergedVersions = [[versions[0]]]
square_root = num ** (1 / 2)
g.flatten(msg)
x
DETACHED_PROCESS = 8
begin
i
doc1.rst
A = np.array(sets)
py - backward - clause
print(img)
A
x
n = PyLabNode()
self._must_cancel = False
b = -0.1
t[2, t2]
x
5
raw[mid, mid] = 1
element = Element.object.get(pk=1)
clienthostid
topicWord = udf(lambda tkn: label_maker_topic(tkn, topic_words), StringType())
dir
actor, = [actor for actor in self.actors if actor.name == actorName]
r
urls
lines[0] = lines[0][col1:col2 + 1]
s = Selenium2Library.Selenium2Library()
lib / kivy - dist
0.0
Debug.Assert(source != null)
user = schema.User(name, full_name, password)
str = PyString_AsString(pystr)
b
prng = np.random.RandomState(0)
y = v + bt
t2_secs - t1_secs
u1 | t
geo
2
point_in_front_of_screen_center = screen_center + d1
self._order = ordered
(0.04)(0.01)(0.02)
X = 10
org_types = origin.getLocallyAllowedTypes()
df
print(name)
h1, m1, s1 = t1.hour, t1.minute, t1.second
b
rf.fit(train_X, train_y)
cout << runPipe(funcs, i) << endl
Type = Application
d
print(hPrinter)
7
checksum = 0
k = 2
t
spyder
done
iter(list(itr)[1:]) if itr_index == 0 else itr
a
JobState = _JobState()
print(myurl)
mydict
kwargs = {}
thing = Thing()
python
items < -names(ratings)
done
m
my_program(aggregate | find[-q | -f])
x / 2.0
A
c
5
d
__len__
g
is_inherit(MyPerfectDict, Mapping)
dx * dx + dy * dy
1.0
my % count_of
check_success(self, ret)
selected_values = (e_data > no_data + eps) & (e_data < no_data - eps)
root.bars = BarCollection()
v4 = array(v2)
s
PyObject_HEAD
NONHEADER = BlobReturnedFromPython[2:length(BlobReturnedFromPython) - 1]
threads = {}
-cars
wrapped_f
month
a
pagesize = resource.getpagesize()
x = interval.interval[10, 15]
mySoundFile = mixer.Sound(filepath + i)
cl = clusters.head()
this
print(inf)
d
dists, points = tree.query(shuffled_points, k=2, p=1)
init_printing()
[distutils]
querystring
rec_func = recApply(func, n - 1)
x - large
raise
self.leader[b] = leadera
a.bar = backup.bar
t = suds.transport.http.HttpTransport()
Xr = X + Ar + Er
raise
inst_dict = instances_to_be_deleted.data[k]
a
NAME
test
x & y
BarObject_Type.tp_new = PyType_GenericNew
typ = dtype.type
c = byteplay.Code.from_code(func.__code__)
self.namespace = namespace
s
p.fast = True
runner = CliRunner()
data
spam
email = false
StdDraw.line(xmax, ymax, xmin, ymax)
plot_margin = 0.25
set_ = set()
print(d)
one
print()
img
c = a - b
p not in mp and mp.append(p)
df
_loggerClass = klass
x[selector]
g
make
filelist = [(i[9] if i[9] else i[8]) for i in filelist]
high = 4 * np.sqrt(6.0 / (fan_in + fan_out))
foo
us = int(frac * 1000000.0)
AuthUserFile / root / apache_users
y
col
ordered
data = np.random.normal(0, 1, (10, 100))
grouped_2Darray[mask] = v
response = ddb.list_tables()
__END__
sm._A = []
objects = [env.Object(x) for x in sources]
tokenizer = MWETokenizer()
df2
dstfile.write(src)
[etc]
f
port = 5672
data1 = row1.data
Node * next
lo = mid + 1
maxval = 7
ineqUB = rep(1, 2 * countw),
retval[i][j] = sinc((Tsf * i - Tso * j) / Tso)
today
whenConnected.addCallbacks(cbConnected, ebConnectError)
print(sqrt)
pep8style = pep8.StyleGuide(quiet=True)
memHandler.setTarget(fileHandler)
match = self.packet_regex.search(self.buffer)
[FORMAT]
second_half = sound[halfway_point:]
finalmap[j][k] = displace(iterations, x0 + j, y0 + k)
print(d)
labels
script
a
data2 = row2.data
warpAffine(bin, rotated, M, bin.size())
labels, number_of_regions = label(a)
print(root.sides)
Document.createTable()
lw, num = measurements.label(z2)
make
geolocator = Nominatim()
-flask
num_samples = 10 * frequency
visit(initialRoom, 0, 0)
allSteps = step.build.getStatus().getSteps()
admin_user = auth.user
buff = create_string_buffer(128)
[wheel]
ham = spam.eggs
R > data
print(p)
bytes = lines = 0
ext_modules = [simple_module],
matrix1, matrix2
print(count)
origin = aq_parent(aq_inner(self))
lst[j] = tmp
final = a + b + c
self._caller = lambda f: f()
style.font.height = 180
M
counter = 0
bar - (0.8).tar.gz
acc = []
x
token_dict[i] = txt1[i]
max_seq_len = 5
SENTINEL = object()
s
fn
sport = 2927
filter_backends = filters.DjangoFilterBackend,
delta = template[j, k] - img[j_plus, k_plus]
d = tree()
packet = A()
d[t0.key] = t0
features = extractFeatures(tweet)
keys
hash += hash >> 2
box.expunge()
A
arr
model = Profile
print(requests.certs.where())
A
dict1 = {}
local
enc == s
result = cached
grid_search.fit(X, y)
print(val1 / val2)
size = rect.right - rect.left, rect.bottom - rect.top
Plain_text = Temp_Obj.toPlainText()
concat_clip = mp.concatenate_videoclips(clips)
library(raster)
meta = site.info()
a
Flask,
user = ApiUserFactory()
xr = x + randn(2048, 2048)
this.length
True != False != False
bytes = 500 - 999
x1 = 11
ib = A[k]
new_item = 4.0
d
B
s
print(mask)
val, = t
query_cols
userid, username, body
memHandler = logging.handlers.MemoryHandler(capacity=1024 * 10)
time1 = timeit.Timer(setup=setup, stmt=stmt1)
spawn_pool(8)
flags |= O_CREAT | O_TRUNC
box.logout()
print(q)
print(mask)
ind = 1
mylist1 + mylist2
ndx = arr1 == itm
f
output = run(input)
p0 = tform.imap(screen_center)
index
s
b[i % 1000] = value
getcontext().rounding = ROUND_DOWN
print(val1 / (val2 + 0.0))
i = counter_generator.call
[report]
foo
N = 10
secret = f.decrypt(encrypted_secret)
sz = sz + 1
n2.accept(this)
ignore - errors(backward - sexp)
rb = redisbayes.RedisBayes(redis=redis.Redis())
latest_start = max(A_start, B_start)
app.teardown_request_funcs[bp][i] = wrap_teardown_func(func)
current_timestamp = timestamp_from_iteration(iteration)
Np = 80
x
PyArrayObject * X
y = x
open
raise
name = modelName,
YES, YES, NO, YES, YES
a1
rgb
e
2
python
-B
B
i0.a = 1
out
category, value
print(myModule is sameModule)
vtk_win_im = vtk.vtkWindowToImageFilter()
cls._wrappers[wrapped_type](wrapped)
b = pb - p0
msg.recipients = [email]
float
r = start
v = df.values
make
uic
l = misc.lena()
b
Py_RETURN_NONE
interval_num = 2
raise ty(err).with_traceback(tb)
0.5
j = right
n
interactive
pwd
a
month
ClientTLSOptions(hostname, ctx)
s1 ^ s2
report_job = q.enqueue(generate_report)
a.zipfiles,
index = in1d(a2, a1)
[Socket]
init_catalog = babel.init_catalog,
index = 2
helper = Helper()
test2_eastern = eastern.localize(test2)
C = 72
Py_SetPythonHome(directoryWhereMyOwnPythonScriptsReside)
bar = 42
++i
free(c_arr2)
response1 = after_request_compress(response)
sCmd.logfile_read = sys.stdout
region = 1
__builtins__.__NUMPY_SETUP__ = False
lChannel.basic_publish(lMessage, exchange=Exchange)
c[row] = sum
char * text
link
contains
BatchUtils.setBatchOperationType(batchEntry, BatchOperationType.UPDATE)
G = pgv.AGraph()
a
s
OR
pathsToNode.AddMany(newPathsToNode)
merged
print(df)
results = defaultdict(lambda : list([0, 0.0]))
count = [0]
where
banana
make
cg.dendrogram_row.linkage
idx
str = str
x
y = keyPoint.pt[1]
pause
y
a
rval = -1
asdf.thumb_a = i
other_street = tree.prev(other_street)
missing = all - s
err = PySet_Add(x, w)
commitctx(ctx, error)
r, n, p = 200, 400, 400
d
matches = timing & target_hit
cherrypy.thread_data.scoped_session_class = GlobalSession
attribute = value
lst1 in lst2
log4j.rootCategory = INFO, console
c = 1.2
exceptions.Exception(exceptions.BaseException)
b.uint
python
frequency_component = np.exp(-0.5 * (draw / scale_bandwidth) ** 2)
+group
model = Account
alt
pause
s
args = str_value,
_s = Functions.motion.move().back
python
starts = a1 & ~a1_rshifted
rv
x
p = parser()
fds = IO.select[py, STDIN]
step = 50
make
Editor
mask = num >> 1
writer = animation.FFMpegWriter(bitrate=500)
4
a
strategy = operationFuncs[operation]()
_Py_ReleaseInternedStrings = ctypes.pythonapi._Py_ReleaseInternedStrings
pytz == 2016.4
char * data
cons = []
a
gui = Program()
mytransport_instance = MyTransport()
data = [trace]
MyClass * obj
config.gpu_options.allow_growth = True
qualname = sloggerMain
print(minimum)
polar_img = img[(Ycart), (Xcart), :]
print(grouped)
then
INFO = 2
codepoint, latex = m.groups()
theta0 = theta0 - step * dEdtheta0
accountNos = set(file)
a = LetterFactory.getLetterObject(1)
result = insertBoxes(input)
a
duration = 10
-user2
b
m = line_regex.match(line)
done(null, results)
names = db_train.iloc[:, 1:].columns.tolist()
data
a
minEnclosingCircle(contours[idx], center, radius)
best_grid = g
done
print(comparison_array)
Flask
a
x
s1 + s2
print(g)
year(map)
b = 6
result = A[rows, column_indices]
width = 12
vector < vector < Point >> contours
cond.acquire()
screen
figure(4)
stopwaitsecs = 600
-S
g
a
intervals.start, intervals.end
s2 = 0
x
validate_except_clause(node * tree)
matcher.matchSingle(descriptors1GPU, descriptors2GPU, trainIdx, distance)
tempo = event.new_tempo
--allow - empty
merit
raise
self.failOn = Literal(failOn)
n
print(neededData)
d = sympy.Rational(rational).q
self.verificationErrors = []
b = 7
ptr
matches = on_disk.search((hashed,))
test
ipdb > n
PyObject * gi_weakreflist
b
C
result = wrap(result)
xDateTime = row[0]
nb = -(-n // 8)
admin_auth = session.auth
result
a
x
-stop
result = foo()
process_value = delete_random_garbage_from_url,
region = 2
empty_copy_2
B
(0.11)(0.04)(0.07)
y
height = incomingImage.height()
great_circle(l1.point, l2.point)
print(X_Train_embedded.shape)
Python
match = set(match_list)
workers = multiprocessing.cpu_count() * 2 + 1
mymessage = Hello
Server.root = application_root
N = 4
group = CGroup.new
original = state.committed_state[self.key]
BAR = 2
events = PROCESS_LOG
Cols = 140
fast_check = set()
costListTrain[i, j] = cost.err(xt_, xt_, yt_, c)
c
dct
t = arange(nsamples) / sample_rate
cd / the / directory / where / your / unit / tests / are
a
python
python << EOF
start = 4
dat = np.random.randn(10, 10)
removed_pks = set()
homeController.js
bins
b
b
today
5
x and y
_wc.svn_wc_add_lock(*args)
a = a[possible_hits]
font_size = 1024 * increase
prev = tpl
sizeOnDisk = (lSize / bSize + 1) * bSize
rand = 222
folds_split = np.ones_like(y)
list_o_dicts = json.loads(json_data)
print(xLower)
x
min_dist = 50
compose_mult = partial(reduce, compose)
nums = [1, 18]
arr
data2
next
m.m0, m.m1 = m0, m1
10
prv_getaddrinfo = socket.getaddrinfo
state = (1.0 - att_coeff) * sample + att_coeff * state
21
print(t.strides)
x
a
df = group[days_back_fil]
urlpatterns = router.urls
groupby = IT.groupby
a
cmath.phase(z)
splits < -binary.splits(word)
tracker.removed_group_ids = instance._cleared_groups_pk_set
c = anchor_coefs[loc]
null
date
fo = cairo.FontOptions()
x
r = geoip.GeoIp()
END_OF_PYTHON
test
indices = 0, 2
g
y = 0.0
val
b = LetterFactory.getLetterObject(2)
regexp_tagger.tag(your_sent)
fck.ReplaceTextarea()
code
print(m)
result
print(p)
v.vendorName
setuptools(2.1)
year = 1999
toSendLength = tentativeLength
__old_runfile = runfile
lh = largest_haloes.values
values = PATTERN.match(s).groupdict()
s
bw = ~im2bw(gr, graythresh(gr))
1.0
x
new_mag = magnitude.new_mag
raw = decoder.decode(cert)[0]
fmt.Fprintf(w, csvData)
some_tau = 1 / 0.5 ** 2
album = StringCol()
f.__doc__
mydf
SOME_CHUNK_SIZE = 4096
d
t
terms = tokenize(document)
finalmap[j][k] = currentmap[j + xoff][k + yoff]
KeyboardInterrupt
Version = 1.0
strategy = operation_dispatcher.get(operation, default)
operation = Spline()
g = gauss()
res
b
Terminal = false
v = re.sub(INTERPOLATION_RE, interpolate_func, v)
python
settings.GLOBAL_SETTINGS
k = 5
hierarchy = 0
vc = apt_pkg.version_compare(a, b)
py - execute - clause - ipython
self.pts = pts[:]
url = BASE58[mod] + url
A = 12
trace(M)
s = MatchAllQuery()
K = 5
gvs = optimizer.compute_gradients(cost)
hi, stdout
todo_include_todos = True
520
a
g = h = x
decoded = TAGS.get(tag, tag)
print(st)
make
c
mask = 12
empty_copy_1
a
print(c)
hashesToPoints = {}
[Section]
make
-2.7
out
sha = repo.head.object.hexsha
A
sumVal = t1 + t2
make
isApple = False
raise
v = optparse.Values()
mask
make
cnt
fintech_countries
service.IgnoreSslErrors = true
False
tmp = ex * pr + ess - ion
sz = randint(0, max_sz)
interactive
deletedivision
monthinteger = 4
x
deleteempty
a = lambda : 1
sp_mat
A
MonkeyRunner.waitForConnection(deviceId=serial)
x = prod[7]
vector < KeyPoint > keypoints1, keypoints2
foo2 = foo[:]
b
12
data
userdata = []
posts
dic = wd[wc][dist][True]
kv = K.nbytes + V.nbytes
regexMatches.Add(trailingString)
suite
end
x = keyPoint.pt[0]
cvReleaseVideoWriter(writer)
i
y
char * msg
triple = (URIRef(t) for t in triple)
N
print(selected)
end
average = average_of_many(images)
ExamenYear
d
print(a)
x
a
your_project
ttkcal = Calendar(root2, firstweekday=calendar.SUNDAY)
A
print(pages)
end
ctx = PyV8.JSContext()
-2.6
s = 1.1
difference = -1
s
B
a
msg = EmailMultiAlternatives(subject, text_content, from_email, [to])
_ = d.popleft()
read_command.bytes = 4
[Paths]
date
auth.user = admin_user
b
y
21
mean_squared_error(test_y, y_submission)
inst = inspect(model)
unit = 40
result = best_font.fname
sub_seconds
converter = quickfix.UtcTimeStampConverter()
end
encryptedString = binascii.unhexlify(encryptedString)
Date, Open, High, Low, Close
ex.args
x
random_generator = Random.new().read
cc_top -= broken_connected_triplets
p
print(c)
x = 4
visit(curRoom.southNeighbor, curX, curY + 1)
c = get_config()
agg_fnxs = [len, len, len]
red_len = p_hat.dot(b_hat) * p_len
DATA_FILES = []
start > tocompare
B
FACTOR_LIMIT = 100
append = 1
a
id
print(x)
p = PhonyHash()
true = True
67
75 % 4
deleteinterpolate
req2 == 1.0
d
CloseHandle(hProcess)
this.length = length
niceMathTextForm = ticker.ScalarFormatter(useMathText=True)
vector1 = matrix1[:, (0)]
2
4
l.start(timeout)
nested(*(res for res, enabled in resources if enabled))
a
coinCount = cents
ln - sf / usr / local / bin / vim.exe / usr / bin / vim
real, imag = inp.split()
a
StringIndexerModel.labels = labels
total += delta * delta
vars = sorted(expression.free_symbols)
y
before
A = nums * np.tril(oneSquare)
i = 0,
param.C = 10
res = root(objective, x0=x0)
msInput.CopyTo(bs)
0.0
a
maxi = maxval(tmp)
4 in primes
mac
print(t[i] + delay)
pprint(bd)
data = rec[:rec_end]
to_filenames = from_filenames.str[1:] + from_filenames.str[0]
topRowOfSpan = cellAddr.row
MARKER_UPPER_BOUND = 20, 20, 20
result, strings = bldStep.getResults()
ml = []
e.printStackTrace()
dis.dis(literal)
use_readline = self.has_readline,
data
[pytest]
name
s = 6
allNotificationsList, default_notifications = enabledNotificationsList,
PATH
badstr
minCoins[cents] = coinCount
key_0
__metaclass__ = _MetaClassy
hourOfDay[~mask] = 0.2
raise
pop
model = Groups
b, = T
LineCollection
session.auth = admin_auth
check_vim
myrandom = random.SystemRandom
permutations
print(smile)
True
res
B
x
light = prompts.PColLightBG.colors
leave
LOG_STDOUT = True
_
a
done
hello
request_feed.AddInsert(entry2)
n = 1000
fruits
print(bg)
arr1.base
x
mydict[h] = V[C == h]
b = True[BoolElement]
hi
python
next
results
a = print
++cTop
prefix_score = log10(score(prefix, prev))
end += 6
python
bs.SetWindow(22)
float * M
g = group(compute_for_user.s(user.id) for user in users)
qs
__metaclass__ = ABCMeta
SimilarPostOption = aliased(PostOption)
parser = Integer()[1:]
secure = True
a
passwd = sout[1]
duration = today - modified_date
red = 1
Tuple < object, object > F()
PyArrayObject * sampling_arr,
x.xytext
text
extent = np.arange(-N / 2, N / 2 + N % 2)
df
invokeScriptFunc = oScript.invoke(args, outIdxs, outArgs)
H
includesFile.write(includesContents)
monitor_n_geo = screen.get_monitor_geometry(n)
b = p.b
make
parse = reqparse.RequestParser()
numbers
deleteX
10,
wx0 = cx - x0
quickResult, verboseResult = getResult(2)
background.composite(border, 0, 0, CompositeOperator.OverCompositeOp)
WantedBy = multi - user.target
ds - dd
obj = SomeObject()
webInventory = ansible.inventory.Inventory(hosts)
restart = True
ls
DoubleVector.foo = foo
low = CompareList([1, 2])
python
a, hello
cluster
x
parser = OptionsParser()
arr2.base is arr1
PyObject * gi_code
java
DictCursor
lastRight = right
r_threshold = 0.6
data = request.executeQuery(requestUrl=requestUrl)
M = 1000000
default = -1
L
hourOfDay[mask] = 0.4
print(comp)
++cRight
img = mpimg.imread(sio)
a, hello
i0 = select
B1.integrate(r1_x)
out
Desired = Unknown / Install / Remove / Purge / Hold
s = mode
5.0
BEST, UR, UL, LL, LR, R, CL, CR, LC, UC, C = list(range(11))
strategy = default
result
tol = 2
deletedc
where = n
dummy
strs
z = interval.interval[12, 18]
col1
z
B
DB_PASS = bar
print(grids)
n1.accept(this)
npy_index_info * indices,
new
model = Ad
4
BStrings = BStrings + B_Object.string + newline
BAD_REQUEST = 2
val
list(freqs=freqs, diffs=diffs)
headrev = pysvn.Revision(pysvn.opt_revision_kind.head)
self.data = value1 + value2
mystr
repo = git.Repo(search_parent_directories=True)
now
print(each)
recipe = zerokspot.recipe.distutils
kitchen.funcs = someFuncs
clicked_series = p.clicked.sum()
d2
q
Encoding = UTF - 8
end
labels = {}
index1()
assert not kwds
PyObject * pygame_module
assert json
min_x = MAX_INT
x
d
END
y
is_alternating_signs(c)
state
queue < int > path
theEditWidget = EditWidget()
three
nums
request = ClientRequest(url, ctxAuth)
print(max_flow)
ScheduleConn.Open()
vertices_gl = vbo.VBO(vertPoints)
DialogResult = DialogResult.Cancel
hash += hash >> 10
pad = r / 2 * c
print(weights)
dataX, dataY = next(self.stream)
race
task
vector < Vec4i > hierarchy
gridsize = 512
_fl = CDLL(lib)
python - V
call = mock_funct.call_args
compare
timeout = 60
python
age = 19
[unittest]
a
sched = Scheduler()
python
print(poly)
circle = 1
s1, s2 = v.strides
match_start, match_end = found
FR_PRIVATE = 16
context.rounding = decimal.ROUND_HALF_UP
needed = self.resolve(parse_requirements(requirements))
testval = 1
d
a
etc
n = 999
zero = False or 1
CoverageACol
task = GetTask(taskindex)
events = PROCESS_LOG
temp_celcius
b
a = -2.0
x = low > high
colormap = vtk.vtkLookupTable()
_, queue_batch = reader.read_up_to(filename_queue, enqueue_many_size)
req1 == 1.0
c1.rounding = decimal.ROUND_HALF_UP
mode = bw
retries = retryCount
r
foo = []
n, m = v.shape
_pack_ = 1
b
pause
question.rb | answer.py
print(row)
done
where
model = Author
make
s2.errors
l = task.LoopingCall(run_spider)
le.classes_
python
print(primes_below(10 * 1000))
7
Patch
gdb
b
cmp
print(b)
s = NoQuotedCommasSession()
xx - large
56
shift = FreqShift(mic, shift=shiftfreq, mul=0.5).out()
convert
pub = lastItem.pub_date
c
totPrimes = int(totPrimes)
cmdtables = {}
r_list = [stdin_fd]
8 | B1 | CYS
qt_dif = val[6] - first[6]
power_smooth = spline(T, power, xnew)
euro_scale_system = CalendarScaleSystem(*(HMSScales + EuroMDYScales))
ConfigParser = configparser.SafeConfigParser
log4j.appender.logfile.MaxBackupIndex = 0
getMaxDeviation(iterations - 1) + dev
shape = ndim, ndim, ndim
df
msk = sorted1 < sorted2
print(temp)
67
sigmoid_grad(-500)
restart = False
model = book
char * color
n_repr = 1000
ruby = Jewel()
x
n = 8
diffs < -diffs / freqs
python - dateutil(2.2)
e = d
new_shorter_edge = 400
good = (compose != compose.shift()).any(1)
EMERGENCY = 255
pilImage = camera.render(scene, samplePattern)
PythonEngine.ReleaseLock(gs)
ab
a
mg = magnitude.mg
c
a
a
0
index
d = self._rooms
data
p = 0.4
d
Some(userDataGrouped)
g
a
alpha = alpha_list[i]
start = PyLong_FromSsize_t(istart)
prod_req == 1.0
zero = 0 or 1
duration.days > 90
(temp - 7.5) * 40 / 21
timedOutStep
image_size = cv.GetSize(image)
files = list(filter(test.search, files))
15
totalRows = 0
[Install]
test
pdata = oauthdata.getpdata()
url
UTC_OFFSET = 4
begin
homeService.js
a2.zipfiles,
fract
threshold = 0.2
resource = BookResource()
exit
data_files = DATA_FILES,
output.running = command
a
example = addSeven(example)
github.com
entry_point = sys.argv[1]
NSString * nsString
char * var_name
s
w_start = space.wrap(0)
[versions]
live_mode
cp = buf
NUMBER = 42
modify
busType = Gio.BusType.SESSION
scale = StandardScaler()
counter2 = Counter({k: (v / 2) for k, v in list(counter.items())})
src = self.someReferenceProperty
context_manager = expression
chars_left -= chars_read
arr
self.method = method
45
self.f = callable
waitQueueTimeoutMS = ms
curr = target
objects.extend(pack_objects)
matrix
t
KeyError
0.8
attach(USArrests)
done
models = database_call_of_some_kind
all_posts_uuid_query = self.db.query(schema.allPostsUuid)
group
freq
val
holes = ndimage.find_objects(label_im)
myimg = ImageGrab.grab()
lazy_loader = importlib.util.LazyLoader.factory(loader)
c
A
foo1 = foo(foo_arg)
hash += h
pwd
ab == lst
n = PyTuple_GET_SIZE(bases)
xx - small
+bin
root <<= 1
make
d = (lo + hi) / 2
M
fontlabel_size = 10.5
output = json
[install]
PythonEngine.ReleaseLock(pythonLock)
testing_mode
PyObject ** ob_item
j = 0
nan is nan
looking_for = iter(when_to_change_the_mode)
model = TagStatus
u
raise DontCloseSpider
v
suffixes = importlib.machinery.SOURCE_SUFFIXES
uname - srvmpio
strLine = objFile.ReadLine
weights = []
l_f = LogFormatter(10, labelOnlyBase=False)
a
n_rows, n_cols = 10, 10
m2.x = 2
print(rider)
k
screen
out = timeobj
project
V = list(range(100000))
lhs, params = compiler.compile(self.lhs)
ans
depth = 10
redirect_stderr = true
plugins = http, python
obj = usersModelInstance
dataObject = decodeStoredObject(rawStoredData)
root = h5file.root
ok
print(shuffled)
count = bc[bc == 1].size
key_0
a1.datas,
s1
dat
A
assoc.py = Python.File
diagram = builder.ScreenNodeBuilder.build(tree)
y
g
end
a
boundaries = fsorted.searchsorted(levels)
mini = minval(tmp)
maxVal = 15
sub_list = []
source
time
10
s
future
char * vocab
num_to_run = 100000
full = RSA.generate(2048)
max = --midPointOfList
myapp
red = 1
pos = -neg
barList = item1, item2
eventNode = eventNode.FirstChild
use_tab_to_indent = false
b
oldAnnotations = lastFrame.videoannotation_set.filter(ParentVideoLabel=label)
func_test = timeit.Timer(func_test, setup=func_setup)
int
end
r
cg.dendrogram_col.linkage
mask = pixel_array == paddingVal
stuff
chunk = binary.read(4096)
I = iter(S)
phone_home
iflag_ptr = cast(pythonapi.Py_InteractiveFlag, POINTER(c_int))
obj.vx = obj.vy = 0
Column | Type | Modifiers
temp = rays.origin - self.center
PATH_TO_R_SOURCE = __builtin__.myapp_PATH_TO_R_SOURCE
backend = CustomSimpleSearchBackend
lists = OneOrMore(countedArray(integer)).parseString(source)
pattern
a = alpha
US - ASCII
snap = deserialized(rank, rank)
library(intervals)
parent_map = {}
RC_FILE = YourApp.rc
image.compression_quality = 99
sin
model = Bottle
data = Data()
target = embedTag + pyparsing.Optional(aTag)
18
red = 1
self.clipsToBounds = NO
dbkind = dict(sqlite=SQLite, oracle=Oracle)
PyObject_VAR_HEAD
make
y = 4
true
y
idx
dark = prompts.PColLinux.colors
imag_part
raise
scala > findDaysSinceLastHoliday
prod_type
print(p in d)
done
df2
t
song_10_db_quierter = song - 10
y
e
z_valid = z[mask]
12
tickTime = 2000
previous
a
sequence = []
ipdb > next
urlopen = urllib.request.urlopen
output = text
num = 0.2 + 0.1
end
idx
layer[key] = value
strFile = objArgs(0)
safe_matches
2
print(p)
model = Ticket.replies.through
from_revision = pysvn.Revision(pysvn.opt_revision_kind.number, headrev - 5)
disable = all
renderer = fig._cachedRenderer
a
Date
iris = DS.load_iris()
autoscale = boto.connect_autoscale()
output
d
cd
____
EOF
notAFixedPoint = true
print(ParsedValue)
Person = ns.ExampleSchema
parser = SafeConfigParser()
PythonToPairConverter < T1, T2 > fromPy
sValidPath = AlwaysSuppliesAValidPath()
request_feed.AddInsert(entry1)
high = CompareList([2, 2])
++cLeft
x
res = prv_getaddrinfo(*args)
X
all_sequences
region = 4
html_copy_source = False
AB, 200.0
Y
index
type
res
map[j][k] = map[j][k] / maxdeviation
print(spChrome.pid)
Ts
frame1 = PDataFrame()
Hello
since = 1
file2
fi
Name = AppName
current = triangle[r][c]
signal = pure + noise
x = monitor_n_geo.x
a
scope = {}
end
zip
actualFrame = (actualFrame + 1) % totalFrames
d
cols
scale_pow = 2
dset = Schedule.objects.all()
b = p.get_bbox()
PATH
rc = clp.EnumClipboardFormats(rc)
grade
sumsCount = 0
total = st.f_blocks * st.f_frsize
wiz
python
ctr.leaf + ctr.trunk
users
index
m
time
fsorted = ff[order]
a
python
priority = 500
messages
name
y = 6
A
tst.time = FOO
print(rev)
tree
answer = a * b
partial = RSA.construct((full.n, 0, full.d))
t = 500000, 500, 5
max = midPointOfList
interactive
comment_feed = yt_service.GetYouTubeVideoCommentFeed(uri=url)
now
EOFError
t = 500000, 500, 5
deletegeneratedClass
df2
cwd = repr(pwd)
fi
inventory = ansible.inventory.Inventory(inventory_file)
deletent
[Unit]
s2
amin = 0
phantom.viewportSize = {width: 1024, height: 768}
fi
keyValList
d2 = c2.create_decimal(f)
ok
a
h
df
y = monitor_n_geo.y
raise
fi
print(triple.subject, triple.predicate, triple.object)
fi
END_OF_PYTHON
x = dm.values
Parameter = parameter
print(listing)
fi
insertIntoMysqlDatabase(arrowDt)
e_view = e.view(dt)
self.wrappers = wrappers
smallEnoughCoins = list(filter(lambda each: each <= cents))
python
y
make
print(n2)
t
safe_attrs = clean.defs.safe_attrs
range
formfield.choices = formfield.choices
match
LazyIterMap < Iterator, Function > (i, f)
end
0
loader.session
gui_installed = True
hash
current_indent = new_indent
thelist
sumsCount
third
NpyIter_IterNextFunc * iternext
++p
x
pair, members
OK
apply_any_exclusions(myfiles)
x
d
ID | Method
Count
make
word[i] = save
end
x
GET_SERVER_QUEUE = 9998
M
self.client = SMTPAsync()
NpyIter * iter
N = 1000
problem = 0
b
make
fi
pinv = [-m / k, 1 / k]
xs
make
b = 4, 5, 6
T * px
Index
nb_val_samples = X_val.shape[0], samples_per_epoch = X_train.shape[0],
result
d2
handlerDict = {}
0.5
a
print(a2)
print(winner)
final = a + b + c
fruits
1 | uk
new_thresh = total - thresh
foo = 1
foo
verifyInRightHalf
fn.__annotations__ = parent_fn.__annontations__
size = 4
serializer = AllFieldsSerializer()
u2
6
day = xDateTime.date()
pair
diffs
Hello
gui_installed = False
n
Data
cum_growth
b
ExamenYear
grouper
d2
sFileName = Dir
integer = Word(nums)
isinstance(unicode_literals, Feature)
date
x
r
problem = 1
gg
python
s
val
set
pp = pprint.PrettyPrinter(indent=4)
strategy = operation_dispatcher[operation]
model = AdType
recipe = cns.recipe.symlink
attr1 = Field()
k = K * loop_id + i
print(kwds)
dateTaken
print(rng)
print(parameter_A * parameter_B)
Hello
module1
begin
Y
Node * pre
vp = [x * vs, y * vs, z * vs]
General
C
GET
N = 100000
m = 1000000
sums
Value = values[median],
x = gauss
id
InteractionStrength
pwd = getEncryptedPassword()
a
ps = 0,
this.source = source
value
input = _
++it
bottomRowOfSpan = cellAddr.row + rowOffset
20
var1 = 11
vmidi_out = rtmidi.MidiOut()
req_version = 2, 5
s
two
text = indexes.EdgeNgramField(document=True, use_template=True)
perl << EOF
cd
uid.hex
od
POST / HTTP / 1.1
hello
cook = a.cookies
colours_gl = vbo.VBO(vertPoints)
p_hat = p / p_len
x = temporary
s2
d
hello
delete_table
gz_open
language
su
year
make
c
Options + Indexes
chosen_part = 1, 1
mydf
first_ul
code = 0.1
end
spi = interpolate
TOTAL = 100000
end
A = numpy.array([list(range(10))] * 10)
aa
hash += hash >> 12
somelist
e
scala > findDaysTillNextHoliday
compare
ts
gs
-user1
Two = 2
ls
raise DeletePermissionDenied
pyResponse.cefResponse = cefResponse
root
ptr
__END__
echo
branch = r.head.reference
day
other_street = tree.prev(street[l])
deletesimple
enqueue_many_size = SOME_ENQUEUE_MANY_SIZE
w
aa
User_ID
p = 1, 4
gr = rgb2gray(im)
foo
all = a.all
a2
Options + FollowSymLinks
row
__pyx_t_4 = __pyx_v_i
ok
cls.binary = FirefoxBinary(FF_BINARY_PATH)
1.0
[Common]
blocksize = 51
app = APP,
alert(ret)
L = R * 299 / 1000 + G * 587 / 1000 + B * 114 / 1000
t
quickResult, verboseResult
a
expr2
page.cookieJar = _cookieJar
a2 = a
phrase_term = phrase_word | quotedString
mod2.pyx
d
GET / users
vals
error
gzip
a
s
time
++cBottom
results
foo
passIf = make_passIf(client)
big
domain
NSHTTPCookie * setCookie
error
re
col1
retry = true
triplet = 0, 128, 64
id
end
SET_TOP(x)
make
z = a
sm.MyClass.kind
orders
PYTHONHASHSEED = random
echo
s.name = 10
resize = curses.is_term_resized(y, x)
zero = 1 == 0 and 0 or 1
1.5
Py_complex
x = u + at
cont
f = 1.4
lis
max = min + 500
frac
lis[_] = _
resetClock,
s
end
ipdb > display
d
height = 12
matches = Regex.Match(log)
cmd = Cmd.cmdOne
+templatetags
bullet.ACTIVE_TAG
_empty = empty
wrappers = []
112
log4j.appender.stdout.layout = org.apache.log4j.PatternLayout
cat
hello
pull_sources
dat,
deleteMin - O(logn)
match
99
Z = Transform(Z)
_singleton = Foo(whatever)
end
re = __init__.re
array_out = flag(values)
Blah
car1 = original_image_rect
actions_when_checked
mydata
Tk = 1000
RED = 1
starts = signals & (signals != signals.shift())
blogService.js
cmd
print(constant.GET_SERVER_QUEUE)
masterSeed < -42
before
s
matrix
s2
flat
cron = CronTab()
Foo
mylist
exitRequested = false
my % unique_colors
date
xs
Django == 1.4
d = D()
loop
yr = y + randn(2048, 2048)
pp = 10 ** p
d
X
month
integer = Word(nums)
Class2
b, world
NumEngines
b
b, world
Options - Indexes
1000 in x
runtime = channel.runtime
results
isSpace = true
print(d)
DATA
num = 8
map
s
__________________________________________________________________________
ini_section = config.get_section(config.config_ini_section)
allowedSet = set(allowedList)
ToTSize
Y
urlRequest.HTTPShouldHandleCookies = YES
Body
done
ticker = SingleIntervalTicker(interval=5, num_minor_ticks=10)
COMMAND
STRING_nonzero(char * ip, PyArrayObject * ap)
less.pip / pip.log
some
s
moustacheId, moustacheStyle
stationLat = -40
name
C
d1 = c1.create_decimal(f)
nan is nan
Name
CONST = 200
flags |= O_CREAT
InteractiveConsole
log4j.appender.logfile.layout = org.apache.log4j.PatternLayout
make
etc
cmd = null
5
x
assoc.py = pyfile
end
xs
client_id
0.0
whole
shape = 1000, 1000
ERROR = 9999
python << _EOF_
exec(fstr)
nb_epochs = 4
num_vert = 1
matshow
make
ret = BatProc(whatIsCalled)
raw
util = selenic.util.Util(driver)
s
NAME
exc = e
file1
LocalFree(output.pbData)
m1 = batRegex.search(html)
zero = False and 0 or 1
deleteoldTerm
min += 500
cy_converted == en
7
classify
pause = 2
ls - la
cmd
1000
externalFoo(arrayTest)
b
ctx = ClientContextFactory.getContext(self)
month
d_truncated
params = col1_value, col2_value
this.webElement = element(selector)
fi
blogController.js
h = argparse.ArgumentDefaultsHelpFormatter
VALUES
chain
[behave]
ID
2
second
make
FooBar
union
j1
host = localhost
stop = 4.5
MB = 1024 * 1024.0
-bs4
A
PdfImagePlugin
__DATA__
broken = true
AttributeError
prod_type
s
END
prod_type
QUrl(html)
t
fi
rng
a = 4
print(dtd)
cl = NaiveBayesClassifier(train)
past < present
T
lol
ABC
end
L
weather