[int(x) for x in str(num)]
np.array(x._data).reshape(x.size[::-1]).T
itertools.combinations
pygame.display.flip()
print([l[i:i + n] for i in range(len(l)) for n in range(1, len(l) - i + 1)])
max(min(my_value, max_value), min_value)
pd.get_dummies(df)
[x[1] for x in elements]
root.mainloop()
[i for i, e in enumerate(a) if e != 0]
max(a_list, key=operator.itemgetter(1))
[item for item in a if item[0] == 1]
[a[i] for i in (1, 2, 5)]
sum(len(v) for v in food_colors.values())
plt.show()
plt.show()
plt.show()
[[[4, 4, 4], [4, 4, 4], [4, 4, 4]], [[4], [4], [4]]]
sorted(list(myDict.items()), key=lambda e: e[1][2])
sorted(list(tag_weight.items()), key=lambda x: int(x[1]), reverse=True)
max(flatlist, key=lambda x: x[1])
df.sort(axis=1, ascending=False)
[i for i, j in zip(a, b) if i == j]
conn.commit()
sorted(list_of_tuples, key=lambda tup: tup[1])
datetime.datetime.now() - datetime.timedelta(days=1)
{k: v for d in L for k, v in list(d.items())}
a.sort(key=lambda x: b.index(x[0]))
instance.__class__.__name__
sorted(list(data.items()), key=lambda x: x[1])
f.close()
datetime.datetime.now().date()
numpy.array([[0, 1, 0], [0, 0, 0], [0, 0, 0]])
[i[0] for i in a]
sorted(list(data.items()), key=lambda x: x[1][0])
sorted(a, key=foo)
ax.plot_trisurf(XS, YS, ZS)
map(dict, zip(*[[(k, v) for v in value] for k, value in list(d.items())]))
datetime.datetime.fromtimestamp(ms / 1000.0)
SomeModel.objects.filter(id=id).delete()
print(random.choice(words))
a.sort(key=lambda x_y: b.index(x_y[0]))
zipped.sort(key=lambda t: t[1])
np.where(a == 1)
f.close()
list(itertools.product(*a))
[input[i:i + n] for i in range(0, len(input), n)]
logging.getLogger().setLevel(logging.DEBUG)
sorted(enumerate(a), key=lambda x: x[1])
array([[True, True], [False, False], [False, False], [True, True]], dtype=bool)
random.sample(list(range(100)), 10)
max(abs(x - y) for x, y in zip(values[1:], values[:-1]))
df.unstack()
[dict(y) for y in set(tuple(x.items()) for x in d)]
sum(d.values())
decimal.Decimal(random.randrange(10000)) / 100
root.destroy()
pandas.concat([df1, df2], axis=1)
[(x, y) for x, y in a if x == 1]
sorted(iter(dict_.items()), key=lambda x: x[1])
xs.sort(key=lambda s: len(s))
len(set(mylist)) == 1
plt.show()
plt.show()
__init__.py
[len(x) for x in s.split()]
[(i // 2) for i in range(10)]
sorted(iter(result.items()), key=lambda key_value: key_value[0])
ax.scartter(XS, YS, ZS)
df.sort(df.columns, axis=1, ascending=False)
[(k, v) for k, v in a.items()]
list(range(9))
L.sort(key=operator.itemgetter(1))
plt.show()
dict((k, v) for k, v in parent_dict.items() if 2 < k < 4)
os.path.dirname(os.path.abspath(existGDBPath))
dict([(e[0], int(e[1])) for e in lst])
df.groupby(level=[0, 1]).median()
plt.show()
my_list[-10:]
all(isinstance(x, int) for x in lst)
[[X[i, j] for i in range(X.shape[0])] for j in range(x.shape[1])]
fh1.seek(2)
(i + 1, j), (i - 1, j), (i, j - 1), (i, j + 1), (i + 1, j - 1), (i + 1, j + 1)
[[X[i, j] for j in range(X.shape[1])] for i in range(x.shape[0])]
[(0, 4), (7, 9), (11, 11)]
[x for y, x in sorted(zip(Y, X))]
myFunc(lambda a, b: iadd(a, b))
plt.gca().invert_yaxis()
numpy.where(mask)
sorted(list(dictionary.items()), key=lambda x: x[1])
numpy.array([(x in a) for x in b])
p.stdin.flush()
dict([(k, v) for k, v in zip(keys, values)])
plt.show()
np.outer(a, b)
[x[0] for x in G]
os.kill(process.pid, signal.SIGKILL)
dict((k, v) for k, v in zip(keys, values))
[set(item) for item in set(frozenset(item) for item in L)]
x[(np.arange(x.shape[0]) != 1), :, :]
plt.show()
(i + 1, j), (i - 1, j), (i, j - 1), (i, j + 1), (i - 1, j - 1), (i + 1, j - 1)
[(i, sum(j) / len(j)) for i, j in list(d.items())]
dogtail.rawinput.click(100, 100)
sorted(d, key=lambda k: d[k][1])
[item for item in a if 1 in item]
session.query(Entry).join(Entry.tags).filter(Tag.id == 1).count()
list(d.values())
[x[1] for x in L]
df.div(df.sum(axis=1), axis=0)
sum(your_list)
[sum([x[1] for x in i]) for i in data]
[k for k, v in i.items() if v == 0]
dataList.sort(key=lambda x: x[1])
plt.show()
sum(x * y for x, y in list(zip(a, b)))
HttpResponse(status=204)
df.apply(lambda x: x.tolist(), axis=1)
list.sort()
[int(x) for x in bin(8)[2:]]
df.apply(lambda row: label_race(row), axis=1)
sorted(list_of_tuples, key=lambda tup: tup[::-1])
plt.show()
[x for x in items if x[2] == 0]
os.path.split(os.path.abspath(existGDBPath))
l.sort(key=alphanum_key)
[x for x in l if x[1] == 1]
df[~df.index.duplicated()]
print([key for key, value in list(d.items()) if value == 1])
[i for i in y if y[i] == 1]
bar.sort(key=lambda x: (x.attrb1, x.attrb2), reverse=True)
print(soup.get_text())
sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
[j for i in zip(a, b) for j in i]
df.groupby(df.index).sum()
plt.gca().invert_xaxis()
s.groupby(grouper).sum()
[4, 5, 5, 6, 6, 6]
self.request.url
logging.basicConfig()
[y for x in list(dict.items()) for y in x]
sorted(lst, reverse=True)
[x for x in a if x != [1, 1]]
print(bool(a))
os.path.dirname(os.path.abspath(__file__))
sorted(a, key=lambda x: (len(x), [confrom[card[0]] for card in x]))
df.sort_values(by=1, ascending=False, axis=1)
list(itertools.islice(it, 0, n, 1))
sys.stdout.flush()
plt.show()
array([[1, 2], [2, 0]])
next(iter(list(dict.values())))
{x[1]: x for x in lol}
plt.show()
a[:] = [x for x in a if x != [1, 1]]
sorted(mylist, key=lambda x: order.index(x[1]))
cv2.destroyAllWindows()
matplotlib.pyplot.show()
sum(map(lambda x: x * x, l))
sorted(lst, key=lambda x: (sum(x[1:]), x[0]), reverse=True)
unittest.main()
sorted(item, key=lambda x: x.id)
np.cumsum(x[::-1])[::-1]
pd.concat([df1, df2], axis=1)
plot([0, 0.5], [0.5, 0.5], [0.5, 0.5], [0.5, 1], [0.5, 1], [1, 1])
keys.sort(key=lambda k: (k[0], int(k[1:])))
sorted(lst, key=lambda x: (x < 0, x))
[(v, k) for k, v in a.items()]
map(sum, zip(*l))
df[(df.iloc[:, -12:] == -1).any(axis=1)]
fig.add_subplot(1, 1, 1)
print(any(x in a for x in b))
print([key for key, value in d.items() if value == 1])
[i for i in y if y[i] > 1]
getattr(your_obj, x)
np.sum(a)
sorted(unsorted, key=lambda element: (element[1], element[2]))
f.close()
vectorizer.get_feature_names()
pygame.display.update()
your_list.sort(key=lambda x: x.anniversary_score)
time.sleep(1)
[(lst[i], lst2[i]) for i in range(len(lst))]
[x[0] for x in os.walk(directory)]
all(i < j for i, j in zip(a, b))
sorted(lst, key=lambda x: (sum(x[1:]), x[0]))
[sorted(item) for item in data]
print(browser.current_url)
db.session.commit()
sum(j ** i for i, j in enumerate(l, 1))
pygame.display.update()
b = dict(zip(a[0::2], a[1::2]))
pd.concat([df, res], axis=1)
any(np.equal(a, [1, 2]).all(1))
datetime.datetime.now().date()
dict(x[1:] for x in reversed(myListOfTuples))
{key: val for key, val in list(myDict.items()) if val != 42}
[k for k, v in d.items() if v == desired_value]
[[sum([x[1] for x in i])] for i in data]
np.mean(np.array([old_set, new_set]), axis=0)
plt.subplots_adjust(top=0.5)
sorted(list_of_medals, key=lambda x: (-x[1], x[0]))
plt.show()
self.pushButton.clicked.connect(self.showDial)
dict(x[i:i + 2] for i in range(0, len(x), 2))
df.index.values.tolist()
[[int(x) for x in sublist] for sublist in lst]
np.diff(arr[:, (1)])
func(*args)
data[:, ([1, 9])]
lambda a, b: a + b
df.index.get_level_values(0).unique()
plt.show()
map(int, str(num))
[[[x[0]] for x in y] for y in listD]
all(isinstance(x, int) for x in lst)
pd.DataFrame(df.columns[np.argsort(df.values)], df.index, np.unique(df.values))
df.groupby(df.columns, axis=1).sum()
ax.set_xticks([])
arr[:, (1)]
array([True, False, False, True], dtype=bool)
sorted(list(a_dict.items()), key=lambda item: item[1][1])
dict((k, v) for d in dicts for k, v in list(d.items()))
db.commit()
[x for x in my_list if not any(c.isdigit() for c in x)]
arr[arr != 0].min()
os.chdir(os.path.dirname(__file__))
df.head()
pd.concat([students, pd.DataFrame(marks)], axis=1)
dict(zip(list(range(1, 5)), list(range(7, 11))))
threading.Thread(target=SudsMove).start()
zip(*list_of_tuples)
sum(d.values())
root.mainloop()
plt.show()
plt.show()
deletemy_list[2:6]
sys.stdout.flush()
urlfetch.fetch(url, deadline=10 * 60)
plt.show()
sys.exit(app.exec_())
plt.show()
root.destroy()
plt.show()
l1.sort(key=lambda x: int(x[0]))
my_list.sort(key=lambda x: x[1])
br.select_form(nr=0)
plt.show()
time.sleep(5)
plt.show()
pygame.display.set_mode((0, 0), pygame.FULLSCREEN)
[list(d.keys()) for d in LoD]
df.value.astype(str).apply(list).apply(pd.Series).astype(int)
isinstance(s, str)
a[tuple(b)]
plt.show()
[[[x[0]] for x in listD[i]] for i in range(len(listD))]
[row[0] for row in a]
x, y = np.random.rand(2, 100) * 20
y = str(int(x, 16))
s.sort(key=operator.itemgetter(1, 2))
root.mainloop()
df.head()
any([True, False, False])
np.delete(1, 1)
ax.xaxis.set_major_locator(MaxNLocator(integer=True))
[float(i) for i in lst]
[(x * x) for x in range(10)]
x = numpy.delete(x, 0, axis=0)
[x[0] for x in a]
plt.show()
max(enumerate(a), key=lambda x: x[1])[0]
driver.set_window_size(1400, 1000)
os.path.realpath(os.path.join(root, name))
list(set(frozenset(item) for item in L))
myList = [i for i in range(10) if i % 2 == 0]
vol.extend((volumeA, volumeB, volumeC))
pylab.ylim([0, 1000])
d.stack().groupby(level=0).apply(pd.Series.value_counts).unstack().fillna(0)
plt.show()
any(item[2] == 0 for item in items)
dict((v, k) for k, v in map.items())
plt.show()
[l[i:i + n] for i in range(0, len(l), n)]
Book.objects.filter(author__id=1).filter(author__id=2)
{k: v for d in dicts for k, v in list(d.items())}
[item for item in my_list if 1 <= item <= 5]
pd.DataFrame(d)
sum(my_counter.values())
sorted(list(data.items()), key=lambda x: x[1])
[[X[i][j] for j in range(len(X[i]))] for i in range(len(X))]
dict((k, v) for k, v in hand.items() if v)
sorted(data.values())
__init__.py
getattr(test, a_string)
len(dict_test) + sum(len(v) for v in dict_test.values())
[o.my_attr for o in my_list]
plt.show()
f.close()
[i for i in x if i in y]
plt.show()
gca().get_lines()[n].get_xydata()
df.loc[(df.loc[:, (df.dtypes != object)] != 0).any(1)]
dict((i, i * 2) for i in range(10))
[(x + tuple(y)) for x, y in zip(zip(a, b), c)]
{i: (i * 2) for i in range(10)}
time.mktime(dt.timetuple()) + dt.microsecond / 1000000.0
binascii.a2b_hex(s)
s[::2], s[1::2]
plt.show()
[(x1 - x2) for x1, x2 in zip(List1, List2)]
sorted(unsorted_list, key=lambda x: order.get(x, -1))
[l[i:i + n] for i in range(0, len(l), n)]
plt.show()
1j * np.arange(5)
plt.show()
sorted(trial_list, key=lambda x: trial_dict[x])
pd.concat(d, ignore_index=True)
sys.stdout.flush()
plt.show()
file.close()
self.process.terminate()
plt.show()
np.all(np.all(test, axis=2), axis=1)
numpy.ma.array(strided, mask=mask)
plt.show()
df.mean(axis=1)
zip(*np.where(a == 1))
random.sample(range(1, 50), 6)
os.path.abspath(__file__)
plt.show()
a, b = map(int, input().split())
dbb.commit()
sys.exit()
fig.subplots_adjust(wspace=0, hspace=0)
setattr(self, attr, group)
np.array([1j])
df.index
session.query(Shots).filter_by(event_id=event_id).count()
requests.post(url, headers=headers, files=files, data=data)
requests.get(url, verify=True)
sum(list_of_nums)
plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))
[i for i in range(len(a)) if a[i] > 2]
sum(len(x) for x in list(food_colors.values()))
session.query(Shots).filter_by(event_id=event_id)
numpy.delete(a, index)
plt.show()
plt.show()
x = numpy.delete(x, 2, axis=1)
[row[1] for row in A]
sorted(lst, key=lambda x: (-sum(x[1:]), x[0]))
np.where(np.diff(arr[:, (1)]))[0] + 1
win.show()
[(x, y) for x, y in zip(myList, myList[1:]) if y == 9]
sum(sum(x) for x in lists)
sorted(a, key=dict.values, reverse=True)
plt.show()
list(range(10, 0, -1))
np.any(np.in1d(a1, a2))
groupby(tags, key=operator.itemgetter(0))
a = sorted(a, key=lambda x: x.modified, reverse=True)
plt.show()
self.axes = self.figure.add_axes([0, 0, 1, 1])
subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
sum(d * 10 ** i for i, d in enumerate(x[::-1]))
conn.commit()
quadmesh.set_clim(vmin=0, vmax=15)
A(1) + A(2)
somelist.sort(key=lambda x: x.resultType)
mylist.sort()
numpy.concatenate([a, b])
datetime.datetime.now() + datetime.timedelta(seconds=10)
dict((k, v) for k, v in parent_dict.items() if k > 2 and k < 4)
requests.post(url, headers=headers, data=data, files=files)
a[[[0, 0], [0, 0]], [[0, 0], [0, 0]], [[0, 0], [0, 0]]]
cv2.destroyAllWindows()
unittest.main()
os.walk(directory)
pd.DataFrame(df.values - df2.values, columns=df.columns)
d = dict((k, v) for k, v in d.items() if v > 0)
writer.writerows(A)
pd.concat([df_slcd, signs], axis=1)
df.apply(lambda x: x.fillna(x.mean()), axis=0)
root.destroy()
time.sleep(1)
np.nonzero(np.any(a, axis=0))[0]
[x[0] for x in l1 if any(x[0] == y[0] for y in l2)]
sum(d.values())
a = [0] * 10000
admin.site.register(Blog, BlogAdmin)
plt.show()
sorted(s, key=float)
gtk.main()
ax.set_ylim((-10, 80.0))
np.delete(a, list(range(0, a.shape[1], 8)), axis=1)
plt.show()
plt.show()
df.groupby(df.index.year).sum().head()
a[np.argsort(a[:, (1)])]
itertools.permutations([0, 0, 0, 0, 1, 1, 1, 1])
plt.show()
plt.show()
plt.show()
plt.show()
print(x[0], x[1])
lst.append(map(int, z))
app.run()
jsonify(my_list_of_eqtls)
[x for y, x in sorted(zip(Y, X))]
f.write(g.read())
zip(*sorted(enumerate(a), key=operator.itemgetter(1)))[0][-2:]
np.array([fnan, pinf, ninf]) < 0
print(arr[1, 1])
sorted(zipped, key=lambda x: x[1])
ax2.legend(loc=0)
[elem.tag for elem in a.iter() if elem is not a]
plt.show()
plt.show()
dict((v, k) for k, v in my_dict.items())
dict(zip(keys, zip(*data)))
deletemylist[:]
list(df.index)
db.close()
root.mainloop()
plt.show()
root.mainloop()
[sum(x) for x in zip(*l)]
print([key for key in d if d[key] == 1])
app.run()
photo.put()
plt.show()
x = x[~numpy.isnan(x)]
np.sqrt(((A - B) ** 2).sum(-1))
app.run()
plt.show()
platform.system()
[(a, b, c) for a, (b, c) in l]
a.index(max(a))
plt.show()
list(set(listA) & set(listB))
[i for i in a if i.isdigit()]
os.system(command)
plt.show()
[tup[0] for tup in A]
plt.show()
plt.show()
list(itertools.combinations(a, 2))
ax.xaxis.tick_top()
json.dumps(your_data, ensure_ascii=False)
plt.show()
writer.writerow(A)
d.apply(pd.Series.value_counts, axis=1).fillna(0)
sparse.coo_matrix(([6], ([5], [7])), shape=(10, 10))
writer.writerow([item[0], item[1], item[2]])
root.lift()
numpy.where(x == x.min())
plt.show()
plt.show()
list(zip(a, b))
mercury(1, 1, 2)
list(itertools.product(*arrays))
np.dot(np.atleast_2d(a).T, np.atleast_2d(b))
[dict(t) for t in set([tuple(d.items()) for d in l])]
df.values.tolist()
cur.execute(sql, list(d.values()))
sum([True, True, False, False, False, True])
plt.show()
plt.show()
plt.show()
[[0, -1, -2], [1, 0, -1], [2, 1, 0]]
np.sqrt(tangent[:, (0)] * tangent[:, (0)] + tangent[:, (1)] * tangent[:, (1)])
pd.to_datetime(pd.Series(date_stngs))
sorted(list(y.items()), key=lambda x: (x[1], x[0]), reverse=True)
[list(i) for i in set(tuple(i) for i in testdata)]
plt.show()
numpy.array([[key, val] for key, val in result.items()], dtype)
window.destroy()
matplotlib.pyplot.show()
driver = webdriver.PhantomJS()
df.values.flatten()
multiprocessing.Process(target=foo, args=(x,)).start()
dict((k, v) for k, v in parent_dict.items() if 2 < k < 4)
sum(df.apply(lambda x: sum(x.isnull().values), axis=1) > 0)
numpy.array([(key, val) for key, val in result.items()], dtype)
plt.show()
datetime.date(2010, 6, 16).isocalendar()[1]
df.isnull().values.any()
pd.concat([x] * 5)
sorted(a, key=lambda i: list(i.values())[0], reverse=True)
print(func.__name__)
[x for x in lst if fn(x) != 0]
list(itertools.chain(*a))
Book.objects.create(**d)
x = [int(i) for i in x.split()]
pd.concat([distancesDF, datesDF.dates], axis=1)
img.show()
ax.set_ylim(0, 5)
plt.show()
pd.concat([pd.DataFrame(l) for l in my_list], axis=1).T
[map(int, sublist) for sublist in lst]
plt.show()
print(list(itertools.chain.from_iterable(a)))
[list(x) for x in zip(*sorted(zip(list1, list2), key=lambda pair: pair[0]))]
sorted(unsorted_list, key=presorted_list.index)
M.sum(axis=0).sum(axis=0)
sorted(list(range(len(a))), key=lambda i: a[i], reverse=True)[:2]
[value for pair in zip(a, b[::-1]) for value in pair]
app.run()
grouped.filter(lambda x: len(x) > 1)
[(lambda x: x * x)(x) for x in range(10)]
app.run()
sorted(list(d.items()), key=lambda k_v: k_v[1])
yourdatetime.date() == datetime.today().date()
df.groupby(df.index.map(lambda t: t.minute))
plt.show()
self.showMaximized()
[(i, j) for i, j in zip(lst, lst2)]
conn.commit()
np.where(out.ravel())[0]
df.round()
a[np.all(a != 0, axis=1)]
[(x + y) for x in l2 for y in l1]
A[(np.random.randint(A.shape[0], size=2)), :]
plt.show()
pd.concat([a, b], ignore_index=True)
table.sort(key=lambda t: t.points)
df.iloc[:, (np.r_[1:10, (15), (17), 50:100])]
foo()
[item[0] for item in queryresult]
plt.show()
[(a * b) for a, b in zip(lista, listb)]
array([[0, 0], [1, 1], [2, 2]])
server.serve_forever()
numpy.nonzero(m.mask)
Motifs.append(Motif)
range(10, 0, -1)
plt.show()
plt.show()
[max(len(a), len(b)) for a, b in zip(*x)]
zip(list(range(10)), list(range(10, 0, -1)))
df.groupby(level=0, axis=1).mean()
time.sleep(5)
{k: v for k, v in list(hand.items()) if v}
duck.quack()
next((idx, x, y) for idx, (x, y) in enumerate(zip(list1, list2)) if x != y)
pd.concat([x] * 5, ignore_index=True)
my_string.splitlines()[0]
dfts.groupby(lambda x: x.month).mean()
(a.T * b).T
[key for item in lst for key, value in list(my_dict.items()) if item in value]
pd.read_json(elevations)
plt.show()
hash(pformat(a)) == hash(pformat(b))
np.all(a == a[(0), :], axis=0)
plt.show()
plt.show()
df2 = pd.DataFrame(index=df1.index)
[s for s in (square(x) for x in range(12)) if s > 50]
sys.exit(0)
plt.show()
[max(abs(x) for x in arr[i:i + 4]) for i in range(0, len(arr), 4)]
sys.exit()
plt.show()
plt.show()
df = df.reset_index()
plt.show()
[sum(map(int, s)) for s in example.split()]
plt.show()
response = requests.get(url, headers=HEADERS)
any(e in lestring for e in lelist)
plt.show()
Blog.objects.filter(pk__in=[1, 4, 7])
self.canvas.create_image(0, 0, image=image1, anchor=NW)
plt.show()
root.mainloop()
pd.concat(map(pd.DataFrame, iter(d.values())), keys=list(d.keys())).stack().unstack(0)
df.sort_index(ascending=False)
datetime.timedelta(-1, 86100).total_seconds()
sorted(list(d.items()), key=lambda k_v: k_v[1], reverse=True)
fig.add_subplot(111)
plt.show()
[(y - x) for x, y in zip(L, L[1:])]
[a for c in Cards for b in c for a in b]
plt.show()
[j for i in zip(a, b) for j in i]
pd.concat((df1, df2), axis=1).mean(axis=1)
map(lambda x: max(x, key=lambda y: y[1]), lists)
list_.sort(key=lambda x: [x[0], len(x[1]), x[1]])
next((key, value) for key, value in list(c.items()) if value > 1)
df.loc[(df.index < start_remove) | (df.index > end_remove)]
sorted(s, key=str.lower)
np.linalg.solve(np.dot(a.T, a), np.dot(a.T, b))
os.chdir(path)
[int(x) for x in regex.findall(filename)]
zip(*l)
A[:, -2:]
plt.show()
dict((k, float(d2[k]) / d1[k]) for k in d2)
a.append(b).reset_index(drop=True)
print(np.array(list(mystr), dtype=int))
ax.get_yaxis().set_ticklabels([])
plt.show()
dict(zip(l[::2], l[1::2]))
dfts.groupby(lambda x: x.year).std()
root.destroy()
[(v, k) for k, v in d.items()]
[f(x) for x in list]
plt.show()
plt.show()
dict((key, sum(d[key] for d in dictList)) for key in dictList[0])
plt.show()
plt.show()
plt.show()
x = x[numpy.logical_not(numpy.isnan(x))]
plt.show()
cv2.destroyAllWindows()
any(isinstance(el, list) for el in input_list)
func(*args, **kwargs)
csvwriter.writerow(row)
l = [[x for x in range(5)] for y in range(4)]
[[y for x, y in sublist] for sublist in l]
cb.ax.xaxis.set_major_formatter(plt.FuncFormatter(myfmt))
list(range(11, 17))
numpy.in1d(b, a)
list(range(1, 11))
plt.show()
plt.show()
plt.show()
plt.show()
db.commit()
sum(x[1] for x in structure)
result = min(max_value, max(min_value, result))
func(*args)
os.kill(pid, signal.SIGUSR1)
[list(group) for key, group in itertools.groupby(data, operator.itemgetter(1))]
all(value == 0 for value in list(your_dict.values()))
plt.show()
sorted(map(list, list(totals.items())))
pylab.setp(_self.ax.get_yticklabels(), fontsize=8)
numpy.dstack((your_input_array, numpy.zeros((25, 54))))
plt.show()
__init__.py
new_list = [x.split()[-1] for x in Original_List]
min([x for x in num_list if x > 2])
pd.concat([good, new], axis=0, ignore_index=True)
plt.show()
print(hex(new_int)[2:])
print(proc.communicate()[0])
a[a != 0]
dict(my_object)
plt.show()
hex(sum(b << i for i, b in enumerate(reversed(walls))))
my_list == list(range(my_list[0], my_list[-1] + 1))
Book.objects.filter(pk=pk).update(**d)
print(urllib.request.urlopen(request).read())
[[Foo() for x in range(10)] for y in range(10)]
yourdatetime.date() < datetime.today().date()
np.concatenate(input_list).ravel().tolist()
km.fit(x.reshape(-1, 1))
plt.show()
max(alkaline_earth_values, key=lambda x: x[1])
sorted(subjects, operator.itemgetter(0), reverse=True)
plt.figure(figsize=(1, 1))
[(x + y) for x, y in zip(first, second)]
Gtk.main()
numpy.array(b).reshape(5, 5)
plt.show()
dic.setdefault(key, []).append(value)
df = pd.DataFrame(np.random.random((1000, 100)))
plt.show()
result = [sum(b) for b in a]
print([word for word in words if word[0].isupper()])
df.loc[:, ((df != 0).any(axis=0))]
plt.show()
s[0].upper() + s[1:]
[y[1] for y in sorted([(myDict[x][2], x) for x in list(myDict.keys())])]
p1.communicate()[0]
cherrypy.quickstart()
People.objects.all().order_by()
dict(pair for d in L for pair in list(d.items()))
json.dumps({str(k): v for k, v in data.items()})
sheet.write(1, 1, 2)
alist.sort(key=lambda x: x.foo)
all(a_list)
plt.show()
plt.show()
plt.show()
unittest.main()
map(list, zip(*main_list))
plt.show()
plt.show()
plt.show()
B[np.argsort(A)] = np.sort(B)
np.random.uniform(0, cutoffs[-1])
[f.name for f in br.forms()]
conn.commit()
self.request.get_all()
np.savez(tmp, *[getarray[0], getarray[1], getarray[8]])
[k for k, v in sorted(list(mydict.items()), key=lambda k_v: k_v[1][1])]
list(i[0] == i[1] for i in zip(list1, list2))
plt.show()
lambda x, y: x + y
print(all(word[0].isupper() for word in words))
sorted(li, key=operator.itemgetter(1), reverse=True)
sys.exit(main())
plt.show()
time.sleep(0.1)
plt.show()
print([y for x in list(dict.items()) for y in x])
[x for x in list_of_nums if x != 2]
pygame.display.flip()
new_list = [x[:] for x in old_list]
plt.scatter(*zip(*li))
ax.scatter(XS, YS, ZS)
numpy.dot(numpy.dot(a, m), a)
[(a + i.reshape(2, 2)) for i in np.identity(4)]
plt.show()
plt.show()
plt.show()
self.sock.connect(self.url, header=self.header)
urllib.request.urlopen(url).read()
Activity.objects.filter(list__topic__user=my_user)
mylist.sort(key=str.lower)
plt.show()
[(i, max(j)) for i, j in list(d.items())]
sum(i * j for i, j in zip(a, b))
ax.contour(x, y, z, levels, cmap=cmap, norm=norm, antialiased=True)
os.path.join(*x.split(os.path.sep)[2:])
time.sleep(1)
[(x / y) for x, y in zip(a, b)]
plt.show()
get_client_ip(request)
sorted(list(d.items()), key=lambda x: (x[1], x[0]))
sum(isinstance(x, int) for x in a)
list(zip(a, b, zip(c[0::2], c[1::2]), d))
df = df.reset_index(drop=True)
plt.show()
result = {k: d2.get(v) for k, v in list(d1.items())}
ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
plt.cla()
set(d.keys())
args[-1] + mySum(args[:-1])
[False, False, True]
plt.show()
threading.Timer(delay, self.update).start()
df.columns = df.columns.get_level_values(0)
archive.write(pdffile, os.path.basename(pdffile))
plt.show()
t = tuple(x[0] for x in s)
root.mainloop()
plt.show()
{{car.date_of_manufacture | datetime}}
x[::-1]
sorted(list(u.items()), key=lambda v: v[1])
len(set(a)) == len(a)
np.dot([1, 0, 0, 1, 0, 0], [[0, 1], [1, 1], [1, 0], [1, 0], [1, 1], [0, 1]])
sys.exit()
a = np.array(a)
print(re.findall(pattern, x))
df.sub(df.mean(axis=1), axis=0)
[j for i in x for j in i]
plt.show()
self.assertEqual(response.status_code, 200)
next(iter(dictionary.values()))
os.read(f.fileno(), 50)
np.split(a, [-1])
plt.subplots_adjust(wspace=0, hspace=0)
[i for s in [list(d.keys()) for d in LoD] for i in s]
self.myList.extend([0] * (4 - len(self.myList)))
[[i, i * 10] for i in range(5)]
sorted(list(range(len(a))), key=lambda i: a[i])[-2:]
random.randint(100000000000, 999999999999)
[(c / t) for c, t in zip(conversions, trials)]
np.sqrt(np.square(df).sum(axis=1))
link.click()
[(x[i] == y[i]) for i in range(len(x))]
[list(t) for t in zip(*list_of_tuples)]
string[0].isdigit()
[[0, 0, 0], [1, 1, 1], [0, 0, 0]]
np.array([0.0, pinf, ninf]) < 0
{(x ** 2) for x in range(100)}
connection.commit()
numpy.dstack(numpy.meshgrid(x, y)).reshape(-1, 2)
numpy.array(your_list)
[x[0] for x in rows]
plt.figure(figsize=(8, 8))
array([True, True, True, True, True, True, True, True, True, True], dtype=bool)
file.close()
np.apply_along_axis(mahalanobis_sqdist, 1, d1, mean1, Sig1)
sum(ord(c) for c in string)
sorted(a, key=lambda x: x[1])
logging.disable(logging.CRITICAL)
np.cumsum(a[::-1])[::-1] - np.cumsum(a)
sum(i * i for i in l)
[dict(zip(k, x)) for x in v]
df.drop_duplicates()
urllib.parse.unquote(string)
lista_elegir[np.random.choice(len(lista_elegir), 1, p=probabilit)]
x[[0, 1, -2, -1]]
screen.blit(img, (0, 0))
(now - datetime.datetime(1970, 1, 1)).total_seconds()
plt.show()
plt.show()
c[np.logical_or(a, b)]
[(x, lst2[i]) for i, x in enumerate(lst)]
plt.show()
plt.show()
ax.yaxis.set_visible(False)
data[i][j][k]
reverse(str1[1:] + str1[0])
a[-1:] + a[:-1]
plt.show()
self.show()
np.where(np.in1d(A, B))[0]
map(lambda x: heapq.nsmallest(x, 2)[1], list_of_lists)
Group.objects.get(id=1).members.all()[0]
plt.show()
driver.current_url
AtB.loc[:2, :2]
plt.show()
pd.get_dummies(s.apply(pd.Series).stack()).sum(level=0)
itertools.product([False, True], repeat=5)
[x for x in a if x not in b]
gtk.main()
np.count_nonzero(~np.isnan(data))
df.iloc[:, ([2, 5, 6, 7, 8])]
merged.reset_index()
f.write(makeGrayPNG([[0, 255, 0], [255, 255, 255], [0, 255, 0]]))
A = np.array(sorted(A, key=tuple))
os.stat(filename).st_mtime
plt.show()
[func(a, b) for a, b in zip(arrA, arrB)]
np.diag(np.rot90(array))
lambda a, b: (a, b)
set(a).intersection(b)
datetime.datetime.combine(my_date, datetime.time.min)
plt.show()
[(v, k) for k, v in list(d.items())]
[int(i) for i in str_list]
sorted(l, key=asum)
np.array(x).reshape(2, 2, 4)[:, :, (0)]
df[df.columns[df.max() > 0]]
[([0] * width) for y in range(height)]
ax.legend()
root.mainloop()
fig.canvas.draw()
the_list.sort(key=lambda item: (-len(item), item))
time.sleep(0.5)
float(math.factorial(171))
len(set(list1).intersection(list2)) > 0
df.index.to_series().diff()
sorted(matrix, key=itemgetter(1))
threading.Thread(target=play2).start()
birthdays.sort(key=lambda d: (d.month, d.day))
len(set(lst)) == len(lst)
len(list(dictionary.values())) == len(set(dictionary.values()))
plt.show()
[x.lower() for x in words]
df.groupby(key_columns).size()
dict(zip(x, y))
print(sum(map(int, x[num - n:num])))
f.close()
plt.show()
A[np.ix_([0, 2], [0, 1], [1, 2])]
np.column_stack(np.where(b))
list(accumulate(list(range(10))))
plt.show()
Group.objects.filter(member__in=[1, 2])
entity.key.id()
plt.show()
sorted(list_of_dct, key=lambda x: order.index(list(x.values())[0]))
df = df.ix[:, 0:2]
regex.findall(string)
[y for y in a if y not in b]
a = a[:n] + k + a[n:]
y = [i[0] for i in x]
int(Decimal(s))
plt.scatter(x, y, color=color)
plt.show()
df.isnull().sum()
name[0].firstChild.nodeValue
list(permutations(list(range(9)), 2))
list(range(10))
print(repr(data))
{k: (d2[k] / d1[k]) for k in list(d1.keys()) & d2}
numpy.sort(arr, axis=0)
cb.ax.yaxis.set_major_formatter(plt.FuncFormatter(myfmt))
plt.show()
print(response.read())
plt.show()
a = [mynamedtuple(*el) for el in a]
element.click()
{{json.key1}}
list(itertools.product(list(range(-x, y)), repeat=dim))
do_something()
a = sorted(a, key=lambda x: float(x))
numpy.concatenate(LIST, axis=0)
any(substring in string for substring in substring_list)
np.in1d(b, a).nonzero()[0]
len(myArray)
data[:, ([1, 2, 4, 5, 7, 8])]
sorted(iter(cityPopulation.items()), key=lambda k_v: k_v[1][2], reverse=True)
[item for innerlist in outerlist for item in innerlist]
plt.show()
a[i] += 1
pygame.display.set_mode(size, FULLSCREEN)
User.objects.filter(userprofile__level__gte=0)
list_of_lists = [[try_int(x) for x in lst] for lst in list_of_lists]
ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=45)
sorted(t, key=lambda i: (i[1], -i[2]))
app.run(debug=True)
pyplot.show()
sys.stdout.flush()
plt.show()
plt.show()
plt.show()
print([u for v in [[i, i] for i in range(5)] for u in v])
sys.stdout.flush()
sorted(itertools.chain(args), cmp)
plt.legend(frameon=False)
cv2.waitKey(0)
min(myList, key=lambda x: abs(x - myNumber))
pd.DataFrame(d)
A[[0, 1], [0, 1]]
sorted(yourdata, reverse=True)
pd.DataFrame(df.values * df2.values, columns=df.columns, index=df.index)
list(itertools.combinations(L, 2))
[item for item in my_list if any(x in item for x in bad)]
list(x * y for x, y in list(zip(a, b)))
b = np.concatenate((a, a), axis=0)
[[int(x)] for y in list_of_lists for x in y]
gtk.main()
result = sys.stdin.read()
pickle.loads(s)
figure(figsize=(11.69, 8.27))
[list(v) for k, v in itertools.groupby(mylist, key=lambda x: x[:5])]
str1.split()
legend(numpoints=1)
root.mainloop()
any(x in string for x in search)
df1.groupby([df1.index.year, df1.index.hour]).mean()
len(max(i, key=len))
sorted(iter(d.items()), key=lambda x: x[1])
plt.show()
y = map(operator.itemgetter(0), x)
dict((x, set(y) & set(d1.get(x, ()))) for x, y in d2.items())
vobj.adr
np.equal.reduce([1, 0, 0, 1])
i = np.array([[0], [1]])
plt.show()
xs.sort(lambda x, y: cmp(len(x), len(y)))
df_result.apply(get_col_name, axis=1)
uinfo.save()
arr[[0, 1, 1], [1, 0, 2]]
set([i for s in [list(d.keys()) for d in LoD] for i in s])
[x for b in a for x in b]
sorted(a.items()) == sorted(b.items())
plt.grid(True)
[int(d) for d in str(bin(x))[2:]]
Reporter.objects.all().delete()
df.groupby(level=[0, 1]).quantile()
{{value | safe}}
{k: int(v) for k, v in d.items()}
df[[1]]
[max(len(str(x)) for x in line) for line in zip(*foo)]
a.fromlist([int(val) for val in stdin.read().split()])
session.query(Tag).distinct(Tag.name).group_by(Tag.name).count()
c = [[(i + j) for i, j in zip(e, b)] for e in a]
plt.show()
np.corrcoef(x)
[sublist[::-1] for sublist in to_reverse[::-1]]
[str(wi) for wi in wordids]
os.chmod(path, stat.S_IRUSR | stat.S_IRGRP | stat.S_IROTH)
[[] for _ in range(n)]
win.show_all()
cursor.execute(sql, list(myDict.values()))
len(s.split())
pd.concat([df, df.dictionary.apply(str2dict).apply(pd.Series)], axis=1)
plt.colorbar(im, ax=ax)
df.reset_index(inplace=True)
print([obj.attr for obj in my_list_of_objs])
dates_dict.setdefault(key, []).append(date)
[[-1, 2, 0], [0, 0, 0], [0, 2, -1], [-1, -2, 0], [0, -2, 2], [0, 1, 0]]
next(iter(dict.values()))
sorted(zip(a, b))
max(len(word) for word in i)
df.to_pickle(file_name)
sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
isinstance(a, dict)
aapl.groupby((aapl.sign.diff() != 0).cumsum()).size()
self.view.header().setModel(model)
np.where((vals == (0, 1)).all(axis=1))
pd.concat([A, B], axis=1)
root.quit()
sum(map(ord, string))
l = (int(x) for x in s.split())
time.sleep(1)
root.mainloop()
datetime.now() - datetime.now()
connection.close()
msglist = [hextotal[i:i + 4096] for i in range(0, len(hextotal), 4096)]
text.config(state=DISABLED)
new_list = my_list[-10:]
array([[-1, -1], [0, 0], [1, 1]])
y = [row[:] for row in x]
datetime.datetime.combine(dateobject, datetime.time())
mylist.sort(key=lambda x: x.lower())
plt.show()
sum(1 for i, j in zip(a, b) if i != j)
sorted(set(my_list))
p.properties()[s].get_value_for_datastore(p)
np.random.randn(5) * 10
db.session.commit()
df.ix[:-1]
Toy.objects.filter(toy_owners__parents=parent)
A.ravel()[A.shape[1] * i:A.shape[1] * (i + A.shape[1]):A.shape[1] + 1]
plt.show()
plt.show()
ax.axes.get_yaxis().set_visible(False)
df.stack().groupby(level=0).first()
sck.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
sorted(sorted(s), key=str.upper)
[line.split() for line in f]
plt.show()
plt.show()
print(zip(my_list[0::2], my_list[1::2]))
file.close()
json.dumps([dict(list(row.items())) for row in rs])
[k for k, v in User._fields.items() if v.required]
d = {t[0]: t[1:] for t in l}
ax2.set_ylim([0, 5])
sys.exit(0)
browser.submit()
sorted(Profile.objects.all(), key=lambda p: p.reputation)
writer.writerows(zip(*[d[key] for key in keys]))
sum(len(y) for y in x if len(y) > 1)
b = np.delete(a, -1, 1)
some_func(*params)
app.run()
((25 < a) & (a < 100)).sum()
sum(x * y for x, y in zip(a, b))
[k for d in list(foo.values()) for k in d]
self.assertEqual(response.status_code, 200)
float(a) / float(b)
itertools.product(list(range(2)), repeat=4)
time.sleep(1)
{k: v for k, v in enumerate(range(10)) if v % 2 == 0}
b.update(d)
[s[:5] for s in buckets]
a[np.in1d(a, b)]
[x for x in j if x >= 5]
d = pd.DataFrame(0, index=np.arange(len(data)), columns=feature_list)
sorted(d, key=d.get)
[m.group(1) for l in lines for m in [regex.search(l)] if m]
sorted(iter(mydict.items()), key=itemgetter(1), reverse=True)
plt.plot(x, y)
plt.show()
df.iloc[:, ([2, 5, 6, 7, 8])].mean(axis=1)
plt.show()
plt.draw()
tuple(sorted(a.items()))
plt.show()
time.sleep(5)
A[(np.random.choice(A.shape[0], 2, replace=False)), :]
lst.sort(key=lambda x: x[2], reverse=True)
output.append(max(flatlist, key=lambda x: x[1]))
y = sorted(set(x), key=lambda s: s.lower())
list(itertools.product(*a))
str(n) == str(n)[::-1]
db.session.commit()
np.arange(len(df.columns)) // 2
root.mainloop()
[(lambda x: x * x) for x in range(10)]
[1, 1, 1, 10, 10, 5, 5, 5, 5, 5, 5]
window.set_position(Gtk.WindowPosition.CENTER)
df.iloc[:, ([2, 5, 6, 7, 8])].mean(axis=0)
np.array(arr[:, (1)], dtype=np.float)
time.sleep(10)
reactor.run()
np.array(arr[:, (1)])
plt.show()
plt.show()
random.choice([k for k in d for x in d[k]])
session.commit()
zip(*main_list)
(e == np.array([1, 2])).all(-1)
plt.show()
logger.setLevel(logging.DEBUG)
random.sample(range(1, 50), 6)
ssh.close()
a = a[-1:] + a[:-1]
df.columns[df.max() > 0]
df.info()
list_of_tuples[0][0] = 7
plt.show()
print([[l[:i], l[i:]] for i in range(1, len(l))])
{k for d in LoD for k in list(d.keys())}
sorted(lst, key=lambda x: (-1 * c[x], lst.index(x)))
networkx.draw_networkx_labels(G, pos, labels)
x = [i[0] for i in x]
p.terminate()
b = np.where(np.isnan(a), 0, a)
plt.show()
cv2.destroyAllWindows()
webbrowser.open_new(url)
db.session.delete(page)
df[df.applymap(isnumber)]
sum(1 for x in list(d.values()) if some_condition(x))
root.mainloop()
app.exec_()
plt.show()
Group.objects.get(id=1).members.all()[0]
m[~m.mask]
[item for item in a if sum(item) > 10]
sorted(list(dictionary.items()), key=operator.itemgetter(1))
[(x, f(x)) for x in iterable if f(x)]
app.run(debug=True)
glfw.Terminate()
print(select([my_table, func.current_date()]).execute())
element.click()
plt.show()
process.stdin.close()
session.commit()
a = np.concatenate((a, [0]))
app.run(threaded=True)
pd.concat([df.head(1), df.tail(1)])
app.debug = True
model.predict(X_test)
time.sleep(1)
np.flatnonzero(x).mean()
print(template.render())
np.array(list(arr[:, (1)]), dtype=np.float)
map(sum, zip(*lists))
CustomPK._meta.pk.name
[next(it) for _ in range(n)]
cursor.close()
driver.implicitly_wait(60)
[1, 1, 0, 0, 1, 0]
df.T.apply(tuple).apply(list)
root.mainloop()
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
plt.show()
os.remove(filename)
plt.show()
df.reindex_axis(df.mean().sort_values().index, axis=1)
print(sorted(xs, key=len))
pdb.set_trace()
df.groupby(by=df.columns, axis=1).mean()
plt.show()
numpy.apply_along_axis(numpy.linalg.norm, 1, a)
myList[:] = [(x / myInt) for x in myList]
plt.show()
df = df.reset_index()
my_list[:]
d.setdefault(x, []).append(foo)
obj.save()
driver.page_source
list(chain.from_iterable(a))
ForkedPdb().set_trace()
sum(v for v in list(d.values()) if v > 0)
writer.writeheader()
print(max(x, key=sum))
plt.show()
plt.show()
dict((k, v * dict2[k]) for k, v in list(dict1.items()) if k in dict2)
math.cos(math.radians(1))
logger.setLevel(logging.DEBUG)
zip(it, it, it)
{_key: _value(_key) for _key in _container}
[list(x) for x in list(results.values())]
cv2.waitKey()
np.where((a[0] == 2) & (a[1] == 5))
data = [[0, 0], [0, 0], [0, 0]]
fig.set_size_inches(w, h, forward=True)
df.groupby(level=0, as_index=False).nth(0)
df.iloc[2, 0]
self.buttonBox.button(QtGui.QDialogButtonBox.Reset).clicked.connect(foo)
s.reset_index(0).reset_index(drop=True)
con.commit()
plt.show()
plt.show()
app.run(debug=True)
sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
db.close()
pygame.display.flip()
[i for i, v in enumerate(a) if v > 4]
cv2.waitKey()
[(i, j) for i, j in zip(a, x)]
plt.show()
files.sort(key=file_number)
df[pd.isnull(df).any(axis=1)]
conn.commit()
plt.show()
a[1::2] = -1
print(pattern.search(url).group(1))
self.SetSizerAndFit(bsizer)
print(sorted(student_tuples, key=lambda t: (-t[2], t[0])))
sum(x == chosen_value for x in list(d.values()))
plt.show()
sum(l) / float(len(l))
process.start()
plt.show()
arr[arr[:, (2)].argsort()]
grouped.reset_index(level=0).reset_index(level=0)
isinstance(s, str)
plt.show()
arr[-2:2]
signal.signal(signal.SIGCHLD, signal.SIG_IGN)
datetime.utcnow() + timedelta(minutes=5)
[elem.tag for elem in a.iter()]
[(x, y) for x, y in zip(myList, myList[1:]) if y == 9]
app.mainloop()
self.root.destroy()
[0, 2, 4, 5]
c[np.logical_and(a, b)]
numpy.append(a, a[0])
win.setWindowFlags(QtCore.Qt.WindowMinimizeButtonHint)
[element for i, element in enumerate(centroids) if i not in index]
np.isnan(np.array([np.nan, 0], dtype=np.float64))
os.system(my_cmd)
app.run()
new_list = [d[key] for key in string_list]
root.mainloop()
os.path.join(root, name)
plt.show()
[{key: dict(value)} for key, value in B.items()]
plt.show()
pprint(dict(list(o.items())))
print((a, b, c, d))
plt.show()
pd.concat([d1, df1], axis=1)
(set(x) for x in d.values())
unittest.main()
datetime.datetime(2010, 7, 26, 0, 0)
plt.show()
pygame.display.flip()
pd.concat([df2, df1], axis=1)
sorted(s, key=str.upper)
[item for item in my_list if some_condition()]
my_list.pop(2)
datetime.utcnow()
pd.concat([df[:start_remove], df[end_remove:]])
lines.sort()
df.applymap(lambda x: isinstance(x, (int, float)))
server.serve_forever()
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
sort()
(e == np.array([1, 2])).all(-1).shape
app.run(debug=True)
plt.show()
plt.clf()
deletemy_list[index]
[(myList[i - 1], myList[i]) for i in range(len(myList)) if myList[i] == 9]
sum([(i * j) for i, j in list(itertools.combinations(l, 2))])
plt.figure()
logging.getLogger().setLevel(logging.DEBUG)
sys.hash_info
text_file.close()
plt.show()
numpy.in1d(b, a).all()
array([True, False, False, True, True, False], dtype=bool)
[key for key, value in list(my_dict.items()) if set(value).intersection(lst)]
sys.stdout.flush()
plt.show()
Book.objects.filter(id=id).update()
zip(*a)
ax.yaxis.set_label_coords(0.5, 0.5)
unittest.main()
int(math.ceil(x)) - 1
[dict(d, count=n) for d, n in zip(l1, l2)]
C / C.astype(np.float).sum(axis=1)
cv2.waitKey()
sys.exit(0)
{{grains.fqdn_ip}}
sorted(data, key=data.get)
scipy.spatial.distance.euclidean(A, B)
proc.terminate()
plt.show()
plt.show()
d = {(a.lower(), b): v for (a, b), v in list(d.items())}
s.split()
[np.unravel_index(np.argmin(a), (2, 2)) for a in A2]
a.insert(0, k)
list(map(list, set(map(lambda i: tuple(i), testdata))))
plt.show()
plt.show()
plt.show()
max(list(MyCount.keys()), key=int)
numpy.fft.fft([1, 2, 1, 0, 1, 2, 1, 0])
x = map(int, x.split())
plt.show()
{k: (float(d2[k]) / d1[k]) for k in d2}
a.contains(b)
print(my_string[0:100])
[lambda x: (x * x for x in range(10))]
array([0, 1, 4, 5, 6, 1, 7, 8, 8, 1])
a[np.in1d(a[:, (1)], b)]
arr[mask] = arr[np.nonzero(mask)[0], idx[mask]]
root.mainloop()
df.sort(inplace=True)
plt.show()
df.stack()
print_tree(shame)
tuple(zip(*t))
datetime.datetime.fromtimestamp(calendar.timegm(d.timetuple()))
print(response.geturl())
plt.show()
locals()[x]
f.read()
next((i for i, j in enumerate(lst) if j == 2), 42)
dict(d)
driver.current_window_handle
f.close()
df.unstack(level=1)
np.concatenate((np.sort(a[~np.isnan(a)])[::-1], [np.nan] * np.isnan(a).sum()))
a.where(~np.isnan(a), other=b, inplace=True)
f.write(chr(i))
50 - list1[0][0] + list1[0][1] - list1[0][2]
[x for t in zip(list_a, list_b) for x in t]
sorted(list(d.items()), key=lambda x: x[::-1])
plt.show()
plt.show()
plt.show()
df.iloc[:, (0)]
random.choice(list(d.keys()))
list(set(a).union(b))
z = zip(x, y)
locals()[x]
a = list(a)
A = [i for i in A if i not in B]
unittest.main()
plt.show()
my_list = [item for item in my_list if item.isalpha()]
plt.show()
len(re.findall(pattern, string_to_search))
driver.close()
a[0:0] = k
{k: [lookup[n] for n in v] for k, v in list(my_dict.items())}
df.loc[:, (cols)] / df.loc[ii, cols].values
np.amin(V, axis=0)
b.append(c)
setattr(test, attr_name, 10)
pg.mixer.init()
zip(*a)
f(*((1, 4), (2, 5)))
np.array(list(itertools.product([0, 1], repeat=n ** 2))).reshape(-1, n, n)
plt.show()
print(etree.tostring(root, pretty_print=True))
l.sort(key=alphanum_key)
plt.show()
sorted(timestamp, reverse=True)
l[-1:] + l[:-1]
str.isdigit()
unittest.main()
df.apply(pd.Series.nunique, axis=1)
MyClass().mymethod()
list(joined_dataset.values())
plt.show()
MyModel.objects.get(id=1).my_field
model.fit(X_train, y_train)
df.to_pickle(file_name)
ax1.xaxis.get_major_formatter().set_powerlimits((0, 1))
sum(1 for i in range(1, len(a)) if a[i - 1] * a[i] < 0)
plt.show()
plt.show()
plt.show()
getattr(foo, bar)(*params)
{k: list(v) for k, v in groupby(sorted(d.items()), key=itemgetter(0))}
a[np.in1d(a[:, (2)], list(b))]
print(max(list(d.keys()), key=lambda x: d[x]))
y = str(int(x, 16))
[(i + j) for i, j in zip(x[::2], x[1::2])]
y = np.cumsum(x)
print(max(d, key=d.get))
multiprocessing.Process.__init__(self)
root.mainloop()
self.submenu2.menuAction().setVisible(False)
y[:, (cols)].sum()
[(item for sublist in list_of_lists) for item in sublist]
[i for i in d for j in range(d[i])]
writer.writerows(zip(*list(d.values())))
sorted(L, key=itemgetter(1), reverse=True)
b = a[:, :-1, :]
sum(v[1] for d in myList for v in d.values())
len(s)
print(df.to_string(index=False))
plt.draw()
ax.scatter(xs, ys, zs, c=cs, marker=m)
sorted(a, key=lambda x: x[1], reverse=True)
[y for sublist in l for x, y in sublist]
plt.show()
res.drop_duplicates()
numpy.prod(a)
urlfetch.set_default_fetch_deadline(60)
session.commit()
db.commit()
np.dot(x, y)
[[j for j in families[i] if i != j] for i in range(len(families))]
[i[0] for i in e]
array([[1, 0, 1, 1], [0, 0, 0, 0], [1, 1, 1, 0]])
file.close()
print(soup.prettify())
self.est.fit(X, y)
a = [[(0) for y in range(8)] for x in range(8)]
numpy.apply_along_axis(numpy.linalg.norm, 1, dist)
d.update((k, frozenset(v)) for k, v in d.items())
plt.show()
plt.show()
np.vstack(a)
dict(map(lambda a: [a[1], a[0]], iter(d.items())))
plt.show()
deletedct[key]
ctypes.addressof(bufstr)
app.run()
plt.show()
(df.notnull().cumsum(axis=1) == 4).idxmax(axis=1)
entry_list.extend([entry.title.text for entry in feed.entry])
plt.show()
plt.legend()
app = Flask(__name__)
df = df.loc[:, ((df != 0).any(axis=0))]
[line[2:] for line in lines]
list([a for a in A if a not in B])
[max(len(b) for b in a) for a in zip(*x)]
app.exec_()
next((i for i, v in enumerate(L) if v != x), -1)
zip(*l)
df.stack().groupby(level=0).first().reindex(df.index)
pd.concat([s1, s2], axis=1).reset_index()
app.MainLoop()
app.run(debug=True)
map(float, i.split()[:2])
plt.figure().canvas.draw()
[item for pair in zip(a, b) for item in pair]
logging.getLogger().setLevel(logging.DEBUG)
p.start()
y = [s for s in x if len(s) == 2]
top_n.sort(key=lambda t: (-t[1], t[0]))
deletemylist[:n]
int(str1.split()[0])
Employee.objects.select_related()
b[a].shape
print(json.dumps(data))
test_rec[(test_rec.age == 1) & (test_rec.sex == 1)]
match.group(1)
list({(x[0], x[1]): x for x in L}.values())
sys.stdout.isatty()
btn.grid(column=x, row=y, sticky=N + S + E + W)
plt.show()
root.mainloop()
f.read()
pd.concat([df, df.sum(axis=1)], axis=1)
np.searchsorted(A, np.intersect1d(A, B))
session.commit()
np.resize([1, -1], 10)
plt.show()
plt.show()
equal([1, 2], a).all(axis=1)
fig.subplots_adjust(wspace=0, hspace=0)
print(sorted(d.keys()))
plt.show()
new_list = copy.deepcopy(old_list)
np.linspace(0, 5, 10, endpoint=False)
somelist.sort(key=lambda x: x.resultType)
f.close()
array[itemindex[0][0]][itemindex[1][0]]
type(ham).__name__
tuple([(10 * x) for x in img.size])
plt.show()
root.mainloop()
root.mainloop()
plt.show()
[(x, y) for x, y in zip(myList, myList[1:]) if y == 9]
print(os.path.abspath(__file__))
urllib.request.install_opener(opener)
scipy.stats.hypergeom.pmf(k, M, n, N)
btn.clicked.connect(self.close)
plt.show()
cv2.destroyAllWindows()
np.array([a, a, a])
a[:, :2]
[item for sublist in list_of_lists for item in sublist]
main.mainloop()
plt.show()
pd.value_counts(d.values.ravel())
np.tensordot(ind, dist, axes=[1, 1])[0].T
plt.show()
[4957, 4957, 1945]
plt.show()
[2, 4, 6, 8]
plt.show()
n = int(input())
sorted(my_tuple, key=lambda tup: tup[1])
ftp.quit()
plt.show()
xs.sort(key=len)
mylist.sort()
[sum(x, []) for x in zip(L1, L2)]
lst.sort(reverse=True)
workbook.close()
list(sorted(iter))[-10]
i = 5 + Tup()[0]
numpy.concatenate((a, b))
driver.quit()
list(dict.items())
lst = [[] for _ in range(a)]
[(1, 4), (4, 8), (8, 10)]
zip(*heapq.nlargest(2, enumerate(a), key=operator.itemgetter(1)))[0]
[mystr[i:i + 8] for i in range(0, len(mystr), 8)]
logging.Logger.__init__(self, name, logging.DEBUG)
StreetCat._meta.get_parent_list()
plt.show()
B = np.split(A, np.where(A[:, (0)] == 0.0)[0][1:])
plt.show()
list(dict(((x[0], x[1]), x) for x in L).values())
numpy.nonzero(numpy.in1d(a2, a1))[0]
list(zip(s[::2], s[1::2]))
sys.stdout.flush()
l = [(x * 2) for x in l]
list(your_iterator)
new_dict = dict(zip(keys, values))
[dict(zip(r.dtype.names, x)) for x in r]
[x for x in L if x >= 0]
plt.show()
[0, 1, 0, 1, 0, 0, 1, 0]
time.sleep(2)
app.mainloop()
random.shuffle(a)
isinstance(s, str)
plt.show()
data[(np.where(masks)[1]), :]
next((x for x in range(10) if x > 5))
YourApp().run()
a = datetime.datetime.now().year
[row[2:5] for row in LoL[1:4]]
cursor.close()
rates.sub(treas.iloc[:, (0)], axis=0).dropna()
values = [d[k] for k in a]
csv_file.close()
d2 = {k: f(v) for k, v in list(d1.items())}
sorted(list(mydict.values()), reverse=True)
plt.show()
mylist[0][0]
lst.sort(key=lambda x: (-x[2], x[0]))
Gtk.main()
f.close()
logging.disable(logging.NOTSET)
plt.show()
[len(x) for x in a[0]]
ax.auto_scale_xyz([0, 500], [0, 500], [0, 0.15])
plt.show()
print(etree.tostring(f, pretty_print=True))
[item for sublist in [[i[1:], [i[0]]] for i in l] for item in sublist]
l = [(ord(a) ^ ord(b)) for a, b in zip(s1, s2)]
client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
df.set_index(s.index).sort()
plt.show()
pd.Series(np.concatenate([a, b]))
df.to_csv()
C = [i for i in A if i not in B]
sum(map(sum, a))
list(range(max(x[0], y[0]), min(x[-1], y[-1]) + 1))
sorted(((v, k) for k, v in d.items()), reverse=True)
transaction.commit()
np.resize([1, -1], 11)
plt.show()
df.plot(x=df.index.astype(str))
[(x - y) for x, y in zip(a[1:], a)]
plt.show()
list(zip(keys, values))
plt.colorbar()
set([1, 2, 2]).issubset([1, 2])
plt.show()
list(itertools.chain(*[item.split() for item in lst]))
pygame.display.flip()
np.isnan(a).any(1)
models.PositiveSmallIntegerField(default=0)
set(a).intersection(b, c)
plt.show()
sorted(dct, key=dct.get)
x, y = zip(*[(i, -1 * j) for i, j in enumerate(range(10))])
np.where(np.any(a == 2, axis=0) & np.any(a == 5, axis=0))
ax.set_ylim([0, 5])
splitlists[-1].append(splitlists[0][0])
plt.show()
a = [a[i] for i in range(1, len(a)) if a[i][1] > a[i - 1][1]]
wb.save(file)
[i for i, (a, b) in enumerate(zip(vec1, vec2)) if a == b]
driver = webdriver.Firefox()
list(SomeModel.objects.filter(id=instance.id).values())[0]
y = list(x)
np.where(np.triu(np.ones(A.shape[0], dtype=bool), 1), A.T, A)
f.close()
list(dict.keys())[0]
random.choice(string.ascii_letters[0:4])
df.groupby(df.columns, axis=1).agg(numpy.max)
numpy.array([v for v in vals if len(set(v)) == len(v)])
np.where(~a.any(axis=1))
plt.show()
df = pd.read_pickle(file_name)
workbook.close()
plt.show()
[1, 1, 2, 2]
sorted(trial_list, key=lambda x: trial_dict[x])
app.run()
plt.hist(x, bins=list(range(-4, 5)))
np.array([j for i in arr for j in np.arange(i - 0.2, i + 0.25, 0.1)])
CB.lines[0].set_linewidth(10)
sum(map(sum, my_list))
handler.setLevel(logging.DEBUG)
print(np.split(a, b, axis=0))
app.run(debug=True)
np.diag(np.fliplr(array))
[x[0] for x, y in zip(l1, l2) if x[0] == y[0]]
ax.yaxis.set_major_formatter(formatter)
logger = logging.getLogger(__name__)
plt.show()
tuple(l)
writer.writerows([val])
json.dump(data, f)
a[i:j] = sorted(a[i:j])
len(set(new_words))
df = pd.concat([df1, df2], ignore_index=True)
fig.legend(lines, labels, loc=(0.5, 0), ncol=5)
[i for i in a if i not in b]
f.close()
[row for row in listOfLists if row[x].isdigit()]
plt.show()
set(data1).intersection(data2)
time.sleep(1)
__init__.py
df.values.max()
(f(x) for x in list)
df.drop(grouped.get_group(group_name).index)
ax.xaxis.set_major_formatter(plt.NullFormatter())
sys.stdout.write(msg)
workbook.close()
np.kron(np.eye(n), a)
df[0].values.tolist()
plt.show()
[(index, row.index(val)) for index, row in enumerate(mymatrix) if val in row]
plt.show()
np.take(a, idx, axis=1)
foo(n - 1) + [1]
zip(*data)
ssh.close()
df1.apply(lambda x: x.asof(df2.index))
c = dict(list(a.items()) + list(b.items()))
numpy.array([v for v in vals if len(numpy.unique(v)) == len(v)])
[(0, 0), (0, 1), (1, 0), (1, 1)]
[key for key, values in list(rev_multidict.items()) if len(values) > 1]
cv2.waitKey()
plt.show()
reversed(x)
print(list(set(chain(*array))))
plt.show()
s1.dropna(inplace=True)
plt.show()
a, b = (int(x) for x in s.split())
listener.close()
plt.show()
sys.exit()
matplotlib.pyplot.scatter(x, y)
rows_list.sort(key=operator.itemgetter(0, 1, 2))
round(1.679, 2)
ax = plt.gca()
my_logger.setLevel(logging.DEBUG)
[name for name in starring if name.strip()]
{i: np.where(arr == i)[0] for i in np.unique(arr)}
func(*r)
plt.show()
plt.show()
plt.show()
df.head(10)
len(my_list)
isinstance()
root.mainloop()
S2[:len(S1)] == S1
Counter(v for sublist in list(d.values()) for v in sublist)
server.serve_forever()
set([a, b, c, a])
np.where(x == 5)
map(ord, hex_data)
time.sleep(1)
[y for y in x for x in data]
tornado.ioloop.IOLoop.instance().start()
plt.show()
[list(zip(a, p)) for p in permutations(b)]
print([y for x in l for y in (x, x + 1)])
print(dict(zip(keys, [list(i) for i in zip(*data)])))
any(i.isdigit() for i in s)
list(range(1, 6)) + list(range(15, 20))
a = [0] * 10
bucket.copy_key(new_key, source_bucket, source_key)
window.destroy()
root.mainloop()
print([x[0] for x in data])
clf.fit(X, y)
c[:] = b
pdb.set_trace()
a.argmax(axis=0)
plt.show()
df[self.target].str.contains(t).any()
User.objects.filter(userprofile__level__lte=0)
ma.array(np.resize(b, a.shape[0]), mask=[False, False, True])
len(set(a))
a = list(set(a))
list(itertools.product(*s))
set(d1.items()).issubset(set(d2.items()))
db.session.query(Printer).all()
plt.draw()
plt.show()
p.wait()
plt.show()
os.rename(file, new_name)
my_model.save()
match.group(1)
img.save()
plt.show()
dict((m.get(k, k), v) for k, v in list(d.items()))
lst.sort()
[x[0] for x in listD[2]]
value.isdigit()
[tuple(l) for l in nested_lst]
my_array[:, ([0, 1])] = my_array[:, ([1, 0])]
s.reset_index().drop(1, axis=1)
x = all((a, b, c, d, e, f))
python - -version
cursor.commit()
random.seed()
[(a + b) for a, b in zip(s[::2], s[1::2])]
test[numpy.apply_along_axis(lambda x: x[1] in wanted, 1, test)]
numpy.apply_along_axis(sum, 1, X)
v.dot(np.rollaxis(a, 2, 1))
print(sys.path)
pygame.display.flip()
x = [i for i in x if len(i) == 2]
[word for word in words if any(not char.isdigit() for char in word)]
plt.show()
[(x + y) for x, y in zip(L1, L2)]
[(e in lestring) for e in lelist if e in lestring]
plt.figure(figsize=(6, 6))
plt.draw()
datetime.datetime.fromtimestamp(1284286794)
plt.legend(numpoints=1)
o.save()
print({word: word_list.count(word) for word in word_list})
pdf.close()
print(Event.objects.filter(date__lt=datetime.datetime.now()).delete())
[elem for x in list for elem in (x, 0)][:-1]
list(itertools.product(*list(mydict.values())))
[int(n) for n in bin(21)[2:].zfill(8)]
{key: list(set(a[key]).difference(b.get(key, []))) for key in a}
sys.exit(1)
pd.to_datetime(pd.Series(date_stngs))
list(next(it) for _ in range(n))
plt.show()
plt.show()
result.extend(item)
timestamp = (dt - datetime(1970, 1, 1)) / timedelta(seconds=1)
plt.show()
array[itemindex[0][1]][itemindex[1][1]]
plt.show()
Person.objects.filter(**kwargs)
myfile.write(c_uncompData_p[:c_uncompSize])
df[df.index.map(lambda x: x[0] in stk_list)]
plt.show()
[(2, 1, 1), (1, 2, 1), (1, 1, 2)]
isinstance(s, str)
set(L[:4])
plt.show()
f.close()
ind[np.argsort(a[ind])]
df1.reset_index()
os.path.dirname(sys.executable)
plt.draw()
transmission_array.extend(zero_array)
all(x == mylist[0] for x in mylist)
plt.show()
a[:] = [x for x in a if x <= 2]
json.dumps(list)
plt.show()
myList = sorted(set(myList))
a[0:1][0][0] = 5
df.A.apply(lambda x: pd.Series(1, x)).fillna(0).astype(int)
zip(a, b, c)
plt.scatter(list(range(len(y))), y, c=z, cmap=cm.hot)
app.run(debug=True)
df.loc[ii, cols]
plt.show()
np.exp(-x)
print(json.dumps(foo))
{k: (v() if callable(v) else v) for k, v in a.items()}
df.drop(x[x].index)
hehe()
Book.objects.create(**d)
plt.show()
dist = math.hypot(x2 - x1, y2 - y1)
1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0
sorted([-5, 2, 1, -8], key=abs)
out = np.concatenate(input_list).ravel().tolist()
[(i, j) for i, j in zip(a, x) if i >= 4]
ax1.set_xticks([int(j) for j in range(-4, 5)])
datetime.datetime(d.year, d.month, d.day)
s = s[:pos] + s[pos + 1:]
sorted(d, key=d.get)
np.cumsum(a, axis=1, out=a)
sorted(a, key=len)
pd.concat((df1, df2), axis=1)
len(d[obj]) == 2 and isinstance(d[obj][0], int) and isinstance(d[obj][1], int)
inspect.getfile(C.__class__)
sorted(x) == sorted(y)
print(os.path.dirname(os.path.abspath(sys.argv[0])))
pd.concat(series_list, axis=1)
sum([x for x in list if isinstance(x, (int, float))])
numpy.where(a <= 2, a, 2)
pd.DataFrame(s).T
[[4], [5, 5], [6, 6, 6]]
i = np.indices(B.shape)[0]
a[-2:] + a[:-2]
re.findall(pat, s)
d = dict([(y, x) for x, y in enumerate(t)])
x = Dish.query.filter(Dish.restaurants.any(name=name)).all()
driver.implicitly_wait(10)
dict((d1[key], value) for key, value in list(d.items()))
np.tile(b, (2, 2, 2))
result = [d[key] for key in d if key.startswith(query)]
zip(*it)
y = numpy.unique(x)
set(x[0] for x in zip(a, a[1:]) if x[0] == x[1])
sys.exit(0)
root.mainloop()
d = dict((m.get(k, k), v) for k, v in list(d.items()))
app.run()
np.kron(a, np.ones((B, B), a.dtype))
a = zip(list(range(10)), list(range(10)))
plt.show()
f.write(bytes((i,)))
server.serve_forever()
plt.show()
random.choice(mylist)
a[i:j].sort()
some_action.triggered.connect(functools.partial(some_callback, param1, param2))
json.dump([], f)
self.assertTrue(issubclass(QuizForm, forms.Form))
session.query(Shots).filter_by(event_id=event_id).order_by(asc(Shots.user_id))
f.write(hex(i))
decimal.Decimal(str(random.random()))
next(g)
OrderedDict(sorted(list(d.items()), key=d.get))
plt.show()
sorted(a, key=lambda x: b.index(x[0]))
plt.show()
plt.show()
db.commit()
plt.xlim([0, bins.size])
A.sum(axis=0, skipna=True)
df.groupby(df.index).mean()
numpy.argwhere(numpy.in1d(a, b))
plt.show()
datetime.datetime.utcfromtimestamp(1284286794)
a.nonzero()
bool(value)
plt.show()
time.sleep(1)
set(a).intersection(b)
urllib.request.install_opener(opener)
plt.show()
[[word, len(word), word.upper()] for word in sent]
logger.setLevel(logging.DEBUG)
pdb.set_trace()
np.array([[int(i[0], 2)] for i in a])
plt.show()
[str(item[0]) for item in x if item and item[0]]
df = df.reset_index()
{k: v for k, v in list(points.items()) if v[0] < 5 and v[1] < 5}
f.close()
json.dumps(c, default=lambda o: o.__dict__)
sck.setproxy()
list(range(N, -1, -1)) is better
print(tuple(my_list))
set(aa.items()).intersection(set(bb.items()))
rows = [i for i in range(0, len(a)) if a[i][0] == value]
HttpResponse(status=500)
plt.show()
plt.show()
[(x + i * y) for i in range(1, 10)]
len(df.columns)
np.savez(tmp, *getarray[:10])
sys.stdin.read(1)
np.hstack([np.arange(i, j) for i, j in zip(start, stop)])
app.run(threaded=True)
n = int(input())
A.ravel()[:A.shape[1] ** 2:A.shape[1] + 1]
[(x + y) for x in l2 for y in l1]
plt.show()
time.sleep(spacing)
plt.show()
np.fromiter(a, dtype=np.float)
~np.isnan(a).any(1)
matplotlib.pyplot.show()
dict(set.intersection(*(set(d.items()) for d in dicts)))
s * (a + b) == s * a + s * b
some_func(**mydict)
my_list = sorted(list(dict.items()), key=lambda x: x[1])
c = a.flatten()
any(i in a for i in b)
log.start()
sum(x * y for x, y in zip(a, b))
[0, 1, 0, 1, 2, 5, 6, 7, 8, 9]
round(random.uniform(min_time, max_time), 1)
A.ravel()[i:max(0, A.shape[1] - i) * A.shape[1]:A.shape[1] + 1]
app.run()
print([i for i in range(5)])
df
plt.show()
logging.basicConfig(level=logging.WARNING)
plt.show()
plt.show()
itertools.repeat(0, 10)
ax.set_xlim([0, 100])
{k: (float(d2[k]) / d1[k]) for k in d1.keys() & d2}
dct[key].append(some_value)
[([k] + [(sum(x) / float(len(x))) for x in zip(*v)]) for k, v in list(d.items())]
[ord(c) for c in s]
os.makedirs(newpath)
results.sort(key=lambda r: r.person.birthdate)
response = urllib.request.urlopen(req, json.dumps(data))
a, b = np.sin(x), np.cos(x)
form.save()
b = a[:-1] + (a[-1] * 2,)
plt.show()
a = [str(wi) for wi in wordids]
print(np.unravel_index(result.argmax(), result.shape))
fcntl.ioctl(s.fileno(), SIOCSIFFLAGS, ifr)
dir()
auth.set_access_token(access_token, access_token_secret)
zip(*[[5, 7], [6, 9], [7, 4]])
df2 = df.astype(float)
img.save()
root.mainloop()
d[i[0]] = int(i[1])
foo[:, (1)]
datetime.combine(date.today(), time()) + timedelta(hours=2)
root.mainloop()
a = np.array(a, dtype=np.float128)
[[random.random() for i in range(N)] for j in range(N)]
c = [(x | y) for x, y in zip(a, b)]
input()
print(list(enumerate(words)))
pdb.set_trace()
cnxn.commit()
print(os.path.join(dirpath, filename))
cursor.execute(query, data)
root.quit()
[(i, j) for i in range(10) for j in range(i)]
results = [t[1] for t in mylist if t[0] == 10]
driver.quit()
zip(iter(x.items()), iter(y.items()))
heapq.nlargest(6, your_list, key=itemgetter(1))
plt.show()
os.path.relpath(subdir2, subdir1)
[[], [], [], [], [], [], [], [], [], []]
sys.stdout.flush()
df.ix[idx]
setattr(self, key, value)
[l[i::5] for i in range(5)]
operator.itemgetter(*b)(a)
[(m.start(0), m.end(0)) for m in re.finditer(pattern, string)]
any(map(eval, my_list))
df.values.T.tolist()
[i for i in range(len(s1)) if s1[i] != s2[i]]
[list(e) for e in zip(*[fl[i::2] for i in range(2)])]
plt.show()
l[1:]
y[argrelmax(y)[0]]
root.mainloop()
cv2.waitKey()
plt.show()
my_list.sort()
a[~(a == 5).any(1)]
dict([(m.get(k, k), v) for k, v in list(d.items())])
forminstance.is_valid()
plt.show()
socket.gethostname()
np.repeat(a, [2, 2, 1], axis=0)
done = [(i, x) for i in [a, b, c, d]]
plt.setp(axs[1].xaxis.get_majorticklabels(), rotation=70)
array([0, 100, 100, 100, 4, 5, 100, 100, 100, 9])
plt.show()
[i for i, x in enumerate(testlist) if x == 1]
dict((key_from_value(value), value) for value in values)
p.start()
self.submenu2.setVisible(False)
array([0, 0, 2, 1, 0, 1])
np.vstack((np.cos(theta), np.sin(theta))).T
pdb.set_trace()
equal([1, 2], a).all(axis=1).any()
[v for k, v in self.items() if v == value]
len(set(d.values())) == 1
min(L, key=lambda theta: angular_distance(theta, 1))
img.seek(1)
l = [(x * x) for x in range(0, 10)]
plt.show()
plt.show()
plt.show()
df.applymap(time.isoformat).apply(pd.to_timedelta)
df.groupby(by=df.columns, axis=1).apply(gf)
l = map(lambda x: x * 2, l)
new_list = [seq[0] for seq in yourlist]
app.run(port=port)
map(lambda x: x + 1, L)
sys.stdout.flush()
s[::-1]
ip.iptype()
a[list(np.ogrid[[slice(x) for x in a.shape]][:-1]) + [i]]
plt.show()
self.layout.addWidget(self.button)
img.save(sys.argv[2])
db.session.commit()
list(chain.from_iterable(zip(list_a, list_b)))
{i: j for i, j in zip(list(range(1, 5)), list(range(7, 11)))}
plt.show()
results = cursor.fetchall()
m[m.mask]
x[np.where(x == 5)]
int(time.mktime(dt.timetuple()))
plt.show()
{k: v for k, v in list(mydict.items()) if k >= 6}
plt.show()
plt.show()
app.run()
[(x * 2 if x % 2 == 0 else x) for x in a_list]
browser.close()
[(x * 1.0 / y) for x, y in zip(a, b)]
pygame.display.update()
root.mainloop()
root.mainloop()
x = [x for x in b.split() if x in a.split()]
wx.Frame.__init__(self, parent)
multiprocessing.cpu_count()
plt.show()
map(self.queryQ.put, self.getQueries())
sorted(s, key=lambda x: int(x[-1]))
func(1, *args, **kwargs)
float(a)
list(globals().keys())[2]
d = dict.fromkeys(string.ascii_lowercase, 0)
root.mainloop()
plt.show()
cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
plt.show()
result = [(x + dx, y + dy) for x, y in points for dx, dy in offsets]
array([[True, True], [True, True]], dtype=bool)
gca().xaxis.set_major_formatter(FuncFormatter(formatter))
list(d.keys())
min([x[::-1] for x in a])[::-1]
plt.show()
x = (x + y) % 48
[ord(x) for x in letters]
plt.show()
zip((1, 2), (40, 2), (9, 80))
r = dict((v, k) for k, v in d.items())
self._bar()
plt.show()
plt.show()
print([(x[0], x[-1]) for x in l])
time.sleep(1)
df.loc[(df == 1).any(axis=1)]
newsampledata.reindex(newsampledata.index.repeat(n)).reset_index(drop=True)
plt.show()
time.sleep(1)
a.sort(key=Counter(a).get, reverse=True)
len(os.walk(path).next()[2])
df.dtypes
results = sorted(list(results.items()), key=lambda x: x[1], reverse=True)
sorted((sorted(item) for item in data), key=lambda x: (len(x), x))
sorted(os.listdir(whatever_directory))
[i for i in x if 60 < i < 70]
lst.sort()
[(x[i] + x[i + 1]) for i in range(0, len(x), 2)]
plt.show()
self.grid_rowconfigure(1, weight=1)
plt.show()
sys.exit(app.exec_())
json.loads(s)
driver.quit()
plt.show()
[v[0] for v in sorted(iter(d.items()), key=lambda k_v: (-k_v[1], k_v[0]))]
functools.reduce(np.logical_or, (x, y, z))
d = {int(k): [int(i) for i in v] for k, v in list(d.items())}
cursor.execute(sql)
sys.exit()
[[(k, x[k], y[k]) for k in x if x[k] != y[k]] for x, y in pairs if x != y]
linalg.svd(a[:, :, (1)])
print(dict(new_dict))
[int(s) for s in str.split() if s.isdigit()]
np.moveaxis(np.indices((4, 5)), 0, -1)
list({e.id: e for e in somelist}.values())
plt.show()
time.sleep(0.1)
max(A, key=A.get)
a[i, j] = x
app.run()
model.fit([X])
plt.show()
[dict(zip(keys, a)) for a in zip(values[::2], values[1::2])]
[item for sublist in l for item in sublist]
[item for sublist in list_of_lists for item in sublist if valid(item)]
plt.show()
df.index
plt.show()
f.write(doc.render())
plt.show()
shutil.copyfileobj(from_file, to_file)
main()
df.apply(lambda x: sum(x.isnull().values), axis=1)
{k: v for k, v in points.items() if v[0] < 5 and v[1] < 5}
myFunc(lambda a, b: iadd(a, b))
pl.show()
main()
s.getsockname()[0]
array([4, 5, 5, 6, 6, 6])
os.killpg(self.process.pid, signal.SIGTERM)
fh.close()
list(range(0, 100, 5))
[x for x in foo]
plt.show()
[x for x, y, z in G]
b = np.delete(a, i, axis=0)
root.mainloop()
my_list = [col for row in matrix for col in row]
list(set(dict_a.values()) & set(dict_b.values()))
a = datetime.date.today().year
map(list, list(totals.items()))
np.argmax(np.max(x, axis=1))
cursor.close()
my_list = list(set(my_list))
plt.show()
f.close()
Student.objects.filter(studentgroup__level__pk=1)
self.window.keypad(1)
a.flatten()
files.sort(key=lambda x: os.path.getmtime(x))
df[df.columns[2:5]]
Farm.objects.filter(tree__in=TreeQuerySet)
t.start()
plt.show()
df.replace(0, np.nan).bfill(1).iloc[:, (0)]
root.mainloop()
cherrypy.quickstart(Root())
p.terminate()
set([1])
plt.draw()
sys.stdout.flush()
print(calendar.monthrange(now.year, now.month)[1])
client.transport.write(message)
cell.value = statN
[row[i] for row in matrix]
[(a - int(a)) for a in l]
cbar.ax.tick_params(labelsize=10)
[[[(0) for _ in range(n)] for _ in range(n)] for _ in range(n)]
plt.show()
A = np.squeeze(np.asarray(M))
root.mainloop()
pd.Series([np.array(e)[~np.isnan(e)] for e in x.values])
curses.endwin()
User.objects.filter(Q(income__gte=5000) | Q(income__isnull=True))
random.choice(string.letters)
[dict(zip(keys, values[i:i + n])) for i in range(0, len(values), n)]
(local_dt - datetime.datetime.utcfromtimestamp(timestamp)).seconds
res = np.zeros((arr.shape[0], m), arr.dtype)
np.where(np.in1d(values, searchvals))
logger.setLevel(logging.DEBUG)
dictionary = dict(zip(List[0::2], List[1::2]))
data = {tuple(sorted(item)) for item in lst}
df.apply(lambda x: np.all(x == 0))
{v[0]: data[v[0]] for v in list(by_ip.values())}
sys.stdout.flush()
Kid.objects.filter(id__in=toy_owners)
os.stat(path).st_birthtime
data = [[int(v) for v in line.split()] for line in lines]
[list(l[0]) for l in mylist]
json.dumps(s)
sum(v[0] for v in list(d.values())) / float(len(d))
datetime.datetime.combine(dateobject, datetime.time.min)
numpy.array(list(c))
hash(frozenset(list(my_dict.items())))
original[::-1]
root.mainloop()
sum([(x * y) for x, y in zip(*lists)])
result = np.zeros(b.shape)
c = [tuple(x + b[i] for i, x in enumerate(y)) for y in a]
keys, values = zip(*list(dictionary.items()))
db.commit()
dict([i for i in iter(d.items()) if i[0] in validkeys])
plt.colorbar()
bin(10)
s.split()
z = dict(list(x.items()) + list(y.items()))
plt.show()
plt.show()
print(sys.path)
sys.stdout.flush()
plt.show()
df2.reset_index()
len(df.index)
plt.show()
np.corrcoef(x[0:len(x) - 1], x[1:])[0][1]
rows.sort(key=itemgetter(1), reverse=True)
sorted(lst, key=lambda x: (c[x], x), reverse=True)
pd.DataFrame(s).T
[i for i in range(10) if i % 2 == 0]
__init__.py
t.start()
plt.gca().xaxis.set_major_formatter(FixedFormatter(ll))
thread.exit()
d = {k: frozenset(v) for k, v in list(d.items())}
root.mainloop()
sorted(data, key=itemgetter(1))
print(json.dumps(data, indent=2, sort_keys=True))
reactor.run()
[1, 2]
cv2.waitKey(0)
x = np.maximum(x, y)
list(flatten(elements))
time.sleep(1)
f.close()
self._socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
word[1:]
print(date.today().year + 1)
df.apply(lambda x: np.sqrt(x.dot(x)), axis=1)
print(str(2) + str(1))
d = dict((y, x) for x, y in enumerate(t))
zip(*s)[0]
list(chain.from_iterable(list_of_lists))
MyApp().run()
server.serve_forever()
np.concatenate((a, val))
map(partial(f, x), y) == map(f, [x] * len(y), y)
a, b, c = (int(i) for i in line.split())
f.close()
sys.path.insert(1, os.path.dirname(os.path.realpath(__file__)))
map(list, zip(charlist, numlist))
time.sleep(5)
np.hstack(b)
test[numpy.logical_or.reduce([(test[:, (1)] == x) for x in wanted])]
results = [s for s in strings if any(m in s for m in matchers)]
s.sendmail(FROMADDR, TOADDR + CCADDR, msg.as_string())
ndb.StringProperty(repeated=True)
ax1.set_xticklabels([])
deletelist[-n:]
np.where(np.in1d(a, b))
dict(zip(*([iter(l)] * 2)))
L[:] = new_list
strg[n:] + strg[:n]
df[~df.applymap(np.isreal).all(1)]
b = [int(i != 0) for i in a]
driver = webdriver.Firefox()
print(proc.communicate()[0])
names = [description[0] for description in cursor.description]
plt.show()
plt.show()
plt.show()
dict((k, v) for k, v in list(points.items()) if all(x < 5 for x in v))
inlinkDict[docid] = adoc[1:]
(x * x for x in range(10))
main()
singleitem = mylist[-1]
len(dict[key])
array.append([int(x) for x in line.split()])
[[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]
pd.DataFrame(df.to_records())
{k: v for k, v in zip(range(1, 5), count(7))}
cursor.execute(sql)
main(sys.argv[1:])
sys.exit(app.exec_())
A = [[(0) for i in range(n)] for j in range(2 ** n)]
x = float(x)
sorted(test, key=lambda x: isinstance(x, list) and len(x) or 1)
root.mainloop()
fig.show()
((a[:, (np.newaxis), :] - v) ** 2).sum(axis=-1).shape
plt.show()
print(datetime.datetime.now(EST()))
(array_2d == row).all(-1).sum()
sorted([True, False, False])
random.sample(range(len(mylist)), sample_size)
array([[0, 1, 0], [1, 1, 1], [0, 1, 0]])
np.argmax(np.max(x, axis=0))
plt.show()
df[df.index.levels[0].isin([int(i) for i in stk_list])]
df.show()
process.stdin.flush()
np.vstack(counts_array)
ax.xaxis.set_major_locator(ticker.LogLocator(numticks=6))
datetime.datetime(2012, 4, 1, 0, 0).timestamp()
[list(x) for x in zip(*sorted(zip(list1, list2), key=itemgetter(0)))]
os.makedirs(path_directory)
m[:, (0)].reshape(5, 1).shape
ax.set_axis_off()
queryset.filter(created_at__gte=datetime.date.today())
os.getpid()
next((i for i, v in enumerate(l) if is_odd(v)))
smtp.sendmail(send_from, send_to, msg.as_string())
print(list(sk.d.items()))
plt.scatter(x, y, color=c)
settings.py
print(pd.Series(df.values.tolist(), index=df.index))
[[random.random() for x in range(N)] for y in range(N)]
set(alllists).difference(set(subscriptionlists))
plt.show()
[values for key, values in list(rev_multidict.items()) if len(values) > 1]
plt.tight_layout()
pd.concat([df_current, df_future]).sort_index()
bin(_)
a = a.reshape((m, n)).T
result = [list(someListOfElements) for _ in range(x)]
x = list(set(x))
plt.show()
print(all(lst[i].lower() < lst[i + 1].lower() for i in range(len(lst) - 1)))
max(l, key=lambda x: (x[1], random.random()))
bin(6)[2:].zfill(8)
dict(zip(it, it))
data.apply(lambda r: sorted(r), axis=1).drop_duplicates()
sum(int(c) for c in strs if c.isdigit())
arr[np.maximum.accumulate(np.isnan(arr), axis=1)] = np.nan
writer.writerow([val])
cursor.execute(sql_and_params[0], sql_and_params[1:])
df.sort_index(inplace=True)
print(df.head())
print(os.path.basename(sys.argv[0]))
plt.show()
self.somevalue = somevalue
plt.show()
[x for i in range(len(l)) for x in l[i]]
np.vstack(dat_list)
max(l, key=lambda x: x[1] + random.random())
self.date = d.replace(tzinfo=pytz.utc)
a.insert(0, a.pop())
min(list(range(len(values))), key=lambda i: (values[i], -i))
timestamp = dt.replace(tzinfo=timezone.utc).timestamp()
print([x for x in A if all(y in x for y in B)])
plt.show()
ax.set_xticklabels(xlbls)
type(iter(d.values()))
df = df / df.max().astype(np.float64)
conn.commit()
plt.show()
[(lambda x: x * i) for i in range(4)]
df = pd.read_sql(sql, cnxn)
test.__name__
plt.show()
os.isatty(sys.stdin.fileno())
scipy.optimize.leastsq(residuals, p_guess, args=(x, y))
print(decrement())
df.corr().mask(np.equal.outer(df.index.values, df.columns.values))
random.choice(mylist)
{{OBJNAME.get_FIELDNAME_display}}
p.stdin.close()
f.write(s)
text_file.close()
sys.setrecursionlimit()
root.mainloop()
{k: (v * dict2[k]) for k, v in list(dict1.items()) if k in dict2}
json.dumps(fu)
map.put(key, new_value)
root.mainloop()
plt.show()
arr[[1, 4, 5]]
logger = logging.getLogger(__name__)
fig.tight_layout()
cherrypy.engine.start()
root.mainloop()
df.columns = pd.MultiIndex.from_tuples(df.columns.to_series())
somelist[:] = [x for x in somelist if not determine(x)]
{x[0]: len(list(x[1])) for x in itertools.groupby(sorted(mylist))}
(lambda x, f: list(y[1] for y in f(x)))(lst, lambda x: (sorted(y) for y in x))
connection.commit()
sum(a)
pdb.set_trace()
np.split(a, np.nonzero(np.diff(a))[0] + 1)
self.button.clicked.connect(self.calluser)
blog.comment_set.all()
[array([0]), array([47, 48, 49, 50]), array([97, 98, 99])]
ax.set_xticklabels(x)
ma.array(a, mask=np.isnan(a)).mean(axis=0)
pd.crosstab(df.A, df.B).apply(lambda r: r / len(df), axis=1)
pd.DataFrame([record_1])
app.run(debug=True)
scipy.stats.hypergeom.cdf(k, M, n, N)
[np.nonzero(np.in1d(x, c))[0] for x in [a, b, d, c]]
pd.DataFrame(np.where(df, 1, 0), df.index, df.columns)
f = lambda x, y: x + y
data = json.load(f)
tuple(tup[0] for tup in A)
datetime.fromtimestamp(1268816500)
plt.show()
len(set(a)) == len(a)
np.isnan(a)
np.cov(x)
np.linalg.norm(x, ord=1)
[1, 4, 5, 6, 7]
inspect.getmembers(my_module, inspect.isclass)
s.map(lambda x: x[:2])
ioloop.IOLoop.instance().start()
[list(g) for k, g in itertools.groupby(iterable)]
np.equal.reduce([False, 0, 1])
f.write(json.dumps(data, ensure_ascii=False))
Counter(map(tuple, list1))
os.path.dirname(fullpath)
list(range(len(strs) - 1, -1, -1))
csv_file.writerows(the_list)
python - -version
np.cumsum(np.concatenate(([0], np.bincount(v))))[v]
[k for k, g in groupby(sorted(chain.from_iterable(iter(content.values()))))]
np.asarray([func(i) for i in arr])
numpy.in1d(a, b).nonzero()
df.fillna(0)
ax.set_yticks([])
server.starttls()
np.hstack([X, Y])
plt.figure()
sys.exit(1)
env.skip_bad_hosts = True
not any(my_list)
map(max, zip(*alist))
Book.objects.filter(Q(author__id=1) & Q(author__id=2))
Thread(target=cherrypy.quickstart, args=[Root()]).start()
app.mainloop()
f = os.path.join(path, f)
df[last_row.argsort()]
dict(zip(l[::2], l[1::2]))
[(i ** 2) for i in list]
numpy.where(mask, 1, numpy.where(numpy_array == 0, 0, 2))
QApplication.desktop()
plt.show()
sys.exit()
server.serve_forever()
numpy.empty((10, 4, 100))
{k: v for k, v in list(dict.items()) if v > something}
admin.site.register(User, UserAdmin)
fig.autofmt_xdate()
plt.show()
[k for k, count in list(Counter(L).items()) if count > 1]
plt.show()
etree.tostring(e, pretty_print=True)
admin.site.register(Person, PersonAdmin)
pygame.display.set_mode((1, 1))
sorted(iter(cityPopulation.items()), key=lambda k_v: k_v[1][2], reverse=True)
y.astype(int)
print(m.group(1))
data = numpy.genfromtxt(yourFileName, skiprows=n)
localtime(now()).replace(hour=0, minute=0, second=0, microsecond=0)
df2.reindex(df.index)
plt.show()
plt.show()
np.random.random((N, N))
app = Flask(__name__)
setattr(i, x, f(getattr(i, x)))
max(x, key=x.get)
plt.show()
zip(*sorted(zip(x, y), key=ig0))
[dictio for dictio in dictlist if dictio[key] in valuelist]
sum(abs(x - y) for x, y in zip(sorted(xs), sorted(ys)))
[[int(y) for y in x] for x in values]
[OrderedDict((k, d[k](v)) for k, v in l.items()) for l in L]
l = np.array([list(method().values()) for _ in range(1, 11)])
ax.xaxis.set_major_locator(locator)
sys.stdout.flush()
outfile.write(infile.read())
os.path.dirname(sys.argv[0])
button.clicked.connect(self.commander(command))
__init__.py
print(re.findall(pattern, x))
[i for i, item in enumerate(a) if item in b]
[tuple(l) for l in nested_lst]
[transform(x) for x in results if condition(x)]
min(x for x in lst if isinstance(x, str))
server.serve_forever()
os.path.abspath(math.__file__)
sum(map(int, l))
list_.sort(key=lambda x: x[0])
do_something()
[[(i * j) for i, j in zip(*row)] for row in zip(matrix1, matrix2)]
result = sorted(iter(promotion_items.items()), key=lambda pair: list(pair[1].items()))
sys.exit(app.exec_())
getattr(model, fieldtoget)
output.close()
sorted(list(d.items()), key=operator.itemgetter(1, 0))
foo()
[int(i) for i in str(number)]
plt.show()
os.system(cmd)
pd.DataFrame(a, df.index, df.columns)
(a1[:, (numpy.newaxis)] == a2).all(axis=2).astype(int)
gtk.main()
s1.reset_index(drop=True) * s2.reset_index(drop=True)
df.applymap(np.isreal)
[(i * y + x) for i in range(10)]
df.reindex_axis(sorted(df.columns), axis=1)
l = list(set(l))
p = subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE)
logging.basicConfig(level=logging.WARN)
logging.Formatter.__init__(self, msg)
plt.show()
datetime.utcfromtimestamp(float(self.timestamp))
curses.doupdate()
A = A - A.multiply(B)
plt.show()
sys.exit(0)
zip(*lists)
plt.show()
plt.show()
dict((k, 2) for k in a)
a[:, ::2] + a[:, 1::2]
np.array(list(g))
win.show_all()
plt.show()
list1.sort(key=convert)
[a for a in s if s.count(a) == 1][0]
numpy.nonzero(numpy.in1d(a, b))
browser.quit()
plt.subplots_adjust(top=0.75)
session.commit()
dict([(t.__name__, t) for t in fun_list])
sorted(temp, key=itemgetter(1), reverse=True)
l = [x for x in l if x.strip()]
a[np.arange(np.shape(a)[0])[:, (np.newaxis)], np.argsort(a)]
root.mainloop()
b.sort(key=lambda x: a.index(x))
np.put(arr, np.where(~np.in1d(arr, valid))[0], 0)
b[a[1, 1]]
z = arr[:, (5)].sum()
ftp.quit()
ast.literal_eval(reclist)
sorted(d, key=lambda x: (-x[1], x[0]))
df.append(new_df, ignore_index=True)
df.sort_index(inplace=True)
set(x[0] for x in list1).intersection(y[0] for y in list2)
print(etree.tostring(root, pretty_print=True))
string.split(pattern, 1)[0]
root.mainloop()
sys.stdin.isatty()
os.kill(pid, signal.SIGTERM)
os.path.join(directory, filename)
RotatingFileHandler(filename, maxBytes=10 * 1024 * 1024, backupCount=5)
plt.legend()
a[-1] * (a[-1] + a[0]) / 2 - sum(a)
sympy.sstr(_)
plt.show()
[x for d in thedict.values() for alist in d.values() for x in alist]
pd.concat([data, ts]).sort_index().interpolate().reindex(ts.index)
print(repr(the_string))
list({len(s): s for s in jones}.values())
np.tile(np.arange(y), x)
print(list(itertools.combinations(a, i)))
ax.set_ylim(0, 1)
python - mserver
sum(jdcal.gcal2jd(dt.year, dt.month, dt.day))
User.query.join(User.person).filter(Person.id.in_(p.id for p in people)).all()
Project.objects.filter(action__person=person)
x = min(float(s) for s in l)
threading.Thread.__init__(self)
sorted(list(c.items()), key=itemgetter(0))
np.polyfit(x, y, 4)
sorted(a, key=lambda v: (v, random.random()))
[i for i, x in enumerate(lst) if x < a or x > b]
plt.show()
np.count_nonzero(boolarr)
y = (i[0] for i in x)
plt.show()
queryset.filter(created_at__range=(start_date, end_date))
QtCore.Qt.ItemIsEnabled
time.sleep(10)
datetime.datetime(1970, 1, 1) + datetime.timedelta(seconds=-2082816000)
data = numpy.loadtxt(yourFileName, skiprows=n)
a.transpose(2, 0, 1)
df.to_dict()
b = np.fill_diagonal(np.zeros_like(a), value)
python - pip
f(tup1[0], tup1[1], tup2[0], tup2[1])
print(bytes.decode(encoding))
sys.stdout.flush()
plt.show()
plt.show()
plt.setp([ax.get_xticklines(), ax.get_yticklines()], color=color)
z = merge_two_dicts(x, y)
f(*args)
cursor.close()
a.index(max(a))
p.wait()
ma.vstack([a, ma.array(np.resize(b, a.shape[0]), mask=[False, False, True])])
__init__.py
G[i, j] = C_abs[i, j] + C_abs[j, i]
{x: (0) for x in string.printable}
tuple(s[i:i + 2] for i in range(0, len(s), 2))
[map(int, x) for x in values]
app.mainloop()
browser = webdriver.Safari()
print(math.ceil(4.2))
tf.sqrt(tf.reduce_mean(tf.square(tf.sub(targets, outputs))))
gtk.main()
[(s + mystring) for s in mylist]
ser.readline()
result = sum(x for x in range(1, 401, 4))
doctest.testmod()
os.chmod(path, mode)
[[0.4, 0.6, 0.0, 0.0], [0.2, 0.4, 0.4, 0.0], [0.0, 0.0, 0.4, 0.6]]
df.corr().iloc[:-1, (-1)]
[0] * 4
sorted(l, key=lambda i: hypot(i[0] - pt[0], i[1] - pt[1]))
frozenset(list(a.items()))
norm.ppf(norm.cdf(1.96))
plt.show()
root = tree.getroot()
sorted(set().union(*input_list))
plt.gca().set_position([0, 0, 1, 1])
d = {k: [] for k in keys}
f.close()
forms.ModelForm.__init__(self, *args, **kwargs)
socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
file.read(1)
f.seek(0)
print(nat.index(nat.Germany))
plt.show()
plt.subplots_adjust(bottom=0.2)
random.choice(string.ascii_letters + string.digits)
a = [map(int, row.split()) for row in stdin]
list(itertools.accumulate(lst, lambda a, b: tuple(map(sum, zip(a, b)))))
plt.show()
main()
simplelist.append(x)
[word for line in f for word in line.split()]
print(arr[[1, 4, 5]])
plt.show()
p = ax.scatter(xs, ys, zs, c=cs, marker=m)
list(itertools.chain.from_iterable(list(d.values())))
collections.Counter(a)
self.show()
[numbers[i % len(numbers)] for i in range(start, start + len(numbers))]
plt.show()
json.dumps([dict(mpn=pn) for pn in lst])
plt.imshow(cv2.cvtColor(cube, cv2.COLOR_BGR2RGB))
print(list_end_counter([1, 2, 1, 1, 1, 1, 1, 1]))
map(itemgetter(1), elements)
root.deiconify()
test.reshape((4, 4))[:, :2].reshape((2, 4))
dt = tz.localize(naive, is_dst=True)
print(json.dumps(result))
print(applejuice.__name__)
sys.path.append(module_path)
d += datetime.timedelta(1)
subprocess.call(cmd, stdin=f)
map(lambda y: [np.mean(y[i:i + length]) for i in range(0, len(y), length)], a)
bool(random.getrandbits(1))
(arr == arr[0]).all()
[(0, 0, 1, 1), (0, 1, 0, 1)]
test.__defaults__
sys.exit(main(sys.argv[1], sys.argv[2]))
A = np.delete(A, 50, 1)
print(json.dumps(result))
my_dictionary = dict(map(lambda k_v: (k_v[0], f(k_v[1])), iter(my_dictionary.items())))
zipfile.ZipFile(path)
[sum(zip(*x)[1]) for x in data]
data.groupby(level=[0, 1]).sum()
plt.show()
sys.exit(1)
res_list = [i[0] for i in rows]
sys.exit(1)
plt.show()
plt.show()
np.polyfit(X, Y, 1)
b = [i for sub in a for i in sub]
os.close(fh2)
plt.show()
cursor.commit()
[[y for y in x if y not in to_del] for x in my_list]
print(sum(map(ord, my_string)))
a[key].append(1)
c.most_common(1)
sum(d.values())
[(int(i) if i.isdigit() else float(i)) for i in s]
plt.show()
plt.minorticks_off()
output.close()
ax.get_xaxis().get_major_formatter().set_scientific(False)
app = Flask(__name__)
tree.delete(*tree.get_children())
[n for i, n in enumerate(xs) if i == 0 or n != xs[i - 1]]
plt.show()
r = np.ptp(a, axis=1)
d.update((b, a[:, (i)]) for i, b in enumerate(a))
cbar.set_ticklabels([mn, md, mx])
next((i for i, val in enumerate(lst) if np.all(val == array)), -1)
reactor.run()
root.mainloop()
df.groupby(df.index.year // 10 * 10).sum()
x = [[foo for i in range(10)] for j in range(10)]
self.response.out.write(self.request.body)
plt.show()
Category.objects.filter(category__isnull=True)
ax.w_yaxis.set_ticklabels([])
[len(x) for x in a[0]]
plt.show()
os.path.join(mydir, myfile)
plt.show()
plt.show()
driver.quit()
list1[0][2]
[v for i, v in enumerate(myList) if i not in toRemove]
(df == 1).sum()
asyncio.get_event_loop().run_forever()
np.flatnonzero(x[:-1] != x[1:]).mean() + 0.5
datetime(date.year, date.month, date.day)
plt.show()
map(lambda f: f(*args), funcs)
numpy.zeros((i, j, k))
y = [i[0] for i in x]
plt.show()
df.ix[:5, :10]
[x for x in a if x <= 1 or x >= 4]
proc.communicate()
f(*args, **kwargs)
c = [item for pair in zip(a, b) for item in pair]
ax.lines.pop(0)
sorted(Thing.objects.all(), key=lambda t: t.name)
ssh.close()
sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
root.mainloop()
a[:, (0)][mask]
plt.plot(x[i:i + 2], y[i:i + 2])
l = [i.split() for i in l]
reactor.run()
ax.set_yticklabels([])
self.searchqueryset.filter(group__isnull=True)
some_list.remove(thing)
datetime.datetime(1, 1, 1) + datetime.timedelta(microseconds=ticks / 10)
[x for x in l if x % 2 == 0]
logger.setLevel(logging.DEBUG)
np.cross(a, b, axis=0)
c = dict(list(a.items()) | list(b.items()))
self.canvas.pack()
root.mainloop()
plt.show()
[1, 1, 1] < [1, 1, 2]
df.iloc[i]
df[df.apply(lambda x: min(x) == max(x), 1)]
app.run(debug=True)
logger = logging.getLogger(__name__)
my_list.sort(key=nonesorter)
__init__.py
assertTrue(math.isnan(nan_value))
sum(v for k, v in c.items() if v > 1)
s.send(my_bytes)
pylab.show()
np.place(a, np.isnan(a), 0)
writer.writerows(cursor.fetchall())
array([[0, 1, 2], [0, 2, 0], [0, 1, 2], [1, 2, 0], [2, 1, 2]])
y.mean(axis=1).mean(axis=-1)
ZipFile.write(a, compress_type=zipfile.ZIP_DEFLATED)
sys.stdout.flush()
pylab.show()
setattr(self, k, v)
x.reshape(2, 2, 5).transpose(1, 0, 2).reshape(4, 5)
l = [item.lower() for item in l]
[item for item in my_list if some_condition()]
session.query(q).limit(10)
tuple([tuple(row) for row in myarray])
help(my_func)
p1.start()
Post.objects.filter(createdAt__lte=datetime.now() - timedelta(days=plan.days))
sorted(lst, key=lambda L: (L.lower(), L))
plt.show()
time.mktime(time.gmtime(0))
plt.show()
getattr(foo_obj, command)()
df = pd.DataFrame.from_dict(data)
print(result.group(0))
time.sleep(1)
form = MyModelForm(instance=someinst)
self.Bind(wx.EVT_PAINT, self.OnPaint)
{l[1]: l for l in lol}
any(k in s for k in keywords)
len(a) == len(b) and all(a.count(i) == b.count(i) for i in a)
a[a == 2] = 10
sorted(lst, key=operator.itemgetter(1), reverse=True)
cols = list(df.columns.values)
ax.legend()
Gtk.main()
myscript.py
nx.draw(G)
signal.signal(signal.SIGINT, signal_handler)
root.mainloop()
df = df.append(pd.read_sql(querystring, cnxn, params=[i]))
n = sum([(len(v) + 1) for k, v in list(dict_test.items())])
[random.choice(list_of_lists) for _ in range(sample_size)]
mySet = set((x, y) for x in range(1, 51) for y in range(1, 51))
numpy.intersect1d(a, b)
A[np.ix_([0, 2], [0, 1], [1, 2])]
spDF.rdd.first()
[i for i, (a, b) in enumerate(zip(vec1, vec2)) if a == b]
root = Tk()
json.loads(s)
dict(j for i in L for j in list(i.items()))
ax.set_xticks([])
outfile.write(line)
df = pd.DataFrame(data=matrix.toarray(), columns=names, index=raw)
plt.show()
print([s[i] for i in index])
print((i, [round(255 * x) for x in rgb]))
[-2, -2, -2, -2, -8, -8, -8, -8, -8, -8]
ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
plt.show()
cv2.waitKey(0)
list(range(11, 17))
Thread(target=fct).start()
[len(x) for x in s.split()]
[y for y in a if y not in b]
df.insert(idx, col_name, value)
[(x + 1) for x in y]
defaultdict(lambda : defaultdict(dict))
db.session.add(query)
Group.objects.get(id=1).members.filter(is_main_user=True)[0]
sqs.filter(has_been_sent=True)
plt.show()
plt.show()
df.sort_index()
np.linspace(0, 5, 10)
numpy.transpose([numpy.tile(x, len(y)), numpy.repeat(y, len(x))])
np.array(x).reshape(2, 2, 4)
admin.site.unregister(Site)
plt.figure(figsize=(5, 6))
{i: (0) for i in range(0, 10)}
os.setsid()
drawPropagation(1.0, 1.0, numpy.linspace(-2, 2, 10))
[item for sublist in (list_of_lists for item in sublist)]
[a for a in A.objects.all() if a.b_set.count() < 2]
z = merge_dicts(a, b, c, d, e, f, g)
logging.basicConfig(level=logging.DEBUG)
int(s[1:], 2) / 2.0 ** (len(s) - 1)
os.path.splitext(os.path.basename(f))
[x[0] for x in a]
plt.show()
list(my_dict.items())
plt.show()
array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])
plt.show()
numpy.argwhere(a.max() == a)
lines.sort()
np.random.seed(1)
plt.show()
(lambda x, y: x + y)(1, 2)
plt.show()
array([0, 0, 1, 0, 0, 1, 0])
ax.set_xticks([])
doctest.testmod()
max(enumerate(props), key=lambda tup: len(tup[1]))
(M == 0).T.nonzero()
a[np.lexsort(a[:, ::-1].T)]
plt.plot(x, y)
numpy.mean(gp2)
a[key].append(2)
my_dict2 = {y: x for x, y in my_dict.items()}
func(*args, **kwargs)
df.iloc[:, ([0])]
sum([True, True, True, False, False])
[key for key, val in list(dct.items()) if val]
root.mainloop()
[heapq.nsmallest(x, 2)[1] for x in list_of_lists]
a = [(b + 4 if b < 0 else b) for b in a]
b = a[:]
L.append([7, 8, 9])
zipfile.ZipFile(zipbytes)
np.allclose(a, b)
fig = plt.figure()
any(np.array_equal(np.array([[0, 0], [0, 0]]), x) for x in my_list)
[(x, y) for x, y in numpy.ndindex(a.shape)]
admin.site.register(User, UserAdmin)
l = ast.literal_eval(s)
plt.draw()
self.process.terminate()
sorted(chain(a, b), key=lambda x: x.name)
pd.DataFrame(s.groupby(level=0).apply(list).to_dict())
Gtk.main()
admin.site.register(YourModel, YourModelAdmin)
a[i, j] = 5
sum(1 for row in rows for i in row if i)
c.bin[2:]
gtk.main()
[0] * 10000
locals().update(my_dict)
plt.show()
{k: sum(v) for k, v in list(trimmed.items())}
time.sleep(1)
print(getattr(somemodule, class_name))
plt.show()
time.sleep(1500)
print(pdf_file.read())
(dist ** 2).sum(axis=1) ** 0.5
print(sys.stdin.read())
p.wait()
sheet.write(1, 0, 1)
lst = [os.path.splitext(x)[0] for x in accounts]
odeint(func, y0, t, a, b, c)
np.dot(I, np.ones((7,), int))
fig.colorbar(p)
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
df.to_csv(f, index=False, header=False)
bids.append(int(bid))
connection.close()
Some_Model.objects.filter(id__in=ids_list).delete()
platform.architecture()
plt.show()
sum(1 for c in string if c.islower())
[a[i // 2] for i in range(len(a) * 2)]
[1505]
pickle.dumps(threading.Lock())
open(f.name).read()
ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.jet)
df.loc[(df.isnull().any(axis=1)), :] = np.nan
df.toPandas()
int(sum(jdcal.gcal2jd(dt.year, dt.month, dt.day)))
{tuple(x) for x in l1}.intersection(map(tuple, l2))
print(celery.current_task.task_id)
sum(zip(*structure)[1])
x.reshape(2, 2, 5).transpose(1, 0, 2)
locals()[4]
S1.intersection(S2)
plt.gca().invert_yaxis()
[list(itertools.chain(*x)) for x in zip(L1, L2)]
s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
plt.show()
{k: [(a + b) for a, b in zip(*v)] for k, v in list(d.items())}
datetime.datetime.combine(birthdate, datetime.time())
A * B[:, (np.newaxis)]
np.dot(np.dot(I, np.ones((7,), int)), mat)
z = int(str(x) + str(y))
np.mgrid[0:5, 0:5].transpose(1, 2, 0).reshape(-1, 2)
list(dict.keys())
plt.show()
cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)
[(2 * x) for x in some_list if x > 2]
Toy.objects.filter(owner__parent__id=1)
random.uniform(-1, 1)
plt.show()
B = numpy.array([A[0, 0, 1], A[2, 1, 2]])
json.dump(data, outfile, ensure_ascii=False)
data = [[int(i) for i in line.split()] for line in original]
plt.show()
self.response.out.write(key)
plt.show()
print(os.path.join(subdir, file))
greet_selves()
plt.show()
[next(iter(s)) for _ in range(10)]
response = requests.post(url, data=data)
ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
[os.path.split(r)[-1] for r, d, f in os.walk(tree) if not d]
pprint([OrderedDict(zip(names, subl)) for subl in list_of_lists])
(df != 0).any(axis=0)
plt.show()
tornado.ioloop.IOLoop.instance().start()
plt.show()
re.findall(rx, st, re.VERBOSE)
max(a, key=sum)
plt.show()
root.mainloop()
plt.show()
a[([i for i in range(a.shape[0]) if i != 1]), :, :]
myfile.close()
f.subs(x, 1)
[(x, y) for x in a for y in b]
sys.stdout.buffer.write(pdf_file.read())
webbrowser.open(filename)
print(requests.get(url, data=data, cookies=cookies).text)
datetime.datetime(ddd.year, ddd.month, ddd.day)
sorted(list(range(len(s))), key=lambda k: s[k])
plt.show()
reactor.run()
foo()
sys.stdout = sys.__stdout__
[str(n) for n in range(10)]
print(os.path.join(directory, file))
plt.show()
filtered_dict = {k: v for k, v in list(d.items()) if filter_string in k}
set(dic1.keys()) == set(dic2.keys())
MyMIDI.addNote(track, channel, pitch, time, duration, volume)
root.mainloop()
int(float(s))
msg.attach(MIMEText(text))
reactor.run()
print(doctree.toprettyxml())
print(line.rstrip())
list(l) == [0] * len(l)
dict(mylist)
np.concatenate((A[::-1, :], A), axis=0)
mylist[0][:1]
fig.autofmt_xdate()
[random.random() for _ in range(0, 10)]
print(numpy.array([X()], dtype=object))
plt.show()
plt.show()
plt.show()
map(truediv, a, b)
a = np.frombuffer(Data)
df[(df <= 2).all(axis=1)]
np.allclose(ans1, ans2)
f.write(e8)
[i for i in range(len(word)) if word[i] == letter]
print(soup.prettify())
d = collections.defaultdict(lambda : [0, []])
thing.save()
plt.show()
[random.sample(s, 1)[0] for _ in range(10)]
app.run()
max(PlayerList, key=lambda p: max(p[1:]))[0]
set(a) & set(b)
sys.exit(0)
plt.show()
db.session.commit()
np.linalg.norm(A - B, axis=-1)
[0, 16, 17, 18]
random.shuffle(array)
json.dumps({str(k): v for k, v in list(data.items())})
sorted(d, key=d.get, reverse=True)
c = [(i, 0) for i in a]
Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)
np.isnan(np.array([np.nan, 0], dtype=object))
result = (list_[0][0] + list_[1][0]) * (list_[0][1] + list_[1][1])
zip(*elements)[1]
print(df.applymap(lambda x: str(x).isdigit()))
q = Model.objects.filter(Q(field1=f1) | Q(field2=f2)).distinct()
sum(sum(1 for i in row if i) for row in rows)
zip(keys, values)
repr(s)
plt.show()
ax.legend()
sum([v[0] for v in list(d.values())]) / float(len(d))
time.sleep(1)
time.sleep(0.1)
sys.stdout.flush()
ax.set_xlim(0, 7)
plt.hist(b, bins)
[(m.get(k, k), v) for k, v in list(d.items())]
[(mylist[i:] + [newelement] + mylist[:i]) for i in range(len(mylist), -1, -1)]
x.pop(random.randrange(len(x)))
df = df / df.loc[df.abs().idxmax()].astype(np.float64)
plt.show()
df.reset_index(level=0, inplace=True)
plt.show()
sorted(lst, reverse=True, key=operator.itemgetter(0))
np.argwhere(a[:, (1)] == -1)[np.argmin(a[a[:, (1)] == -1, 0])]
print([tryeval(x) for x in L])
python - mplatform
[(m + str(n)) for m, n in zip(b, a)]
sum(int(n) for n in str(2 ** 1000))
new_list.append(fruit)
random.choice(words)
time.sleep(1)
myfunc(*args)
time.sleep(1)
foo()
s.dropna()
br.set_handle_robots(False)
plt.show()
[int(s) for s in I.split() if s.isdigit()]
random.shuffle(l)
df_example.iloc[([1, 4]), :-1].T.corr()
max(d, key=d.get)
print(first_list + list(set(second_list) - set(first_list)))
ax.legend()
lambda i: i[0]
np.array(m2)[:, (1)] > 10
np.concatenate((A[::-1, :], A[1:, :]), axis=0)
np.mean(a, axis=1)
array([True, True, True, False, False, False, False], dtype=bool)
app.run()
do_something_with(line)
r = requests.post(url, data=json.dumps(data), headers=headers)
[x[0] for x in tuple_list]
new_list = [(a, new_b) for a, b in tuple_list]
A = np.random.randn(1000, 1000)
ax.set_xlim([0, 1])
sorted(list(a.items()), key=itemgetter(1), reverse=True)
time.sleep(1)
fig.show()
plt.show()
sorted(l, key=lambda s: (s.isdigit(), s))
ax.plot_wireframe(T, z, abs(U), cstride=1000)
root.mainloop()
max(x, key=lambda i: x[i])
arr = np.append(arr, np.array([[4, 5, 6]]), axis=0)
[list(map(int, x)) for x in values]
r = requests.post(url, files=files)
code.interact(local=locals())
_w()
pdb.set_trace()
matplotlib.pyplot.show()
np.isclose([10000000000.0, 1e-07], [10000100000.0, 1e-08])
int(x) / int(y) == math.floor(float(x) / float(y))
_cxn.commit()
gtk.main()
set.intersection(*(set(x) for x in d.values()))
sum(i for i in a)
pygame.display.set_mode(size)
df.sub(df.a, axis=0)
dict((k, mydict[k]) for k in keys_to_select if k in mydict)
str(1).zfill(2)
print(line.rstrip())
out = [a, b, c, d, e, f]
reactor.run()
list1.sort(key=int)
plt.show()
ax.plot(x, y)
sorted(lst, key=lambda x: (-counts[x], firstidx[x]))
sys.stdout.write(chr(x))
sorted(lst, key=str.lower)
set(zip(*[lst[i:] for i in range(n)]))
A = [(A[i + 1] + A[i]) for i in range(len(A) - 1)]
[numbers[i] for i in range(len(numbers)) if i not in indices]
print(os.path.join(path, filename))
[i for e in bad for i in my_list if e in i]
(s * 5).tolist()
myDict[item[1]] += item[2]
scipy.sparse.csr_matrix(df.values)
bin(0)
time.sleep(1)
plt.show()
db.rollback()
np.any(my_array[:, (0)] == value)
os.getpid()
list([x for x in l if x not in f])
lst = [int(i) for i in str(num)]
obj.save()
res = list(set(a) ^ set(b))
sys.stdout.write(str(x))
l.sort(key=sum_nested)
np.fill_diagonal(df.values, 0)
__init__.py
cherrypy.quickstart(HelloWorld())
[i for i, j in enumerate(a) if j == m]
mySet = set([myString])
self.matches = [s for s in self.options if s and s.startswith(text)]
MyModel.objects.all()
plt.show()
length = len(list(clusterList))
data.append(json.loads(line))
sorted(zipped, key=operator.itemgetter(1))
c = sum(1 for word in words if word[0] == word[-1])
cnx.commit()
np.eye(foo.shape[1]) * foo[:, (np.newaxis)]
app.run()
plt.show()
[map(dict.get, list(range(1, 6))) for _ in range(10)]
re.sub(reg, rep, text)
Py_Finalize()
conn.commit()
self.cdr = cdr
x = np.array([(1, 0), (0, 1)])
plt.show()
gtk.main_iteration()
new = [int(i) for i in old]
any(x in set(b) for x in a)
print(settings.BASE_DIR)
requests.get(url, params=query)
A[B == x].sum()
ax.set_xticklabels([])
sys.stdin.isatty()
ax.xaxis.set_major_formatter(xfmt)
sys.stdout.flush()
np.where(np.eye(A.shape[0], dtype=bool), A, A.T + A)
self.Bind(wx.EVT_LEFT_DCLICK, self.OnDoubleClick)
datetime.datetime.now() - datetime.timedelta(minutes=15)
sys.stdout.flush()
app.exec_()
ma.array(a, mask=np.isnan(a))
[(j - i) for i, j in zip(t[:-1], t[1:])]
writer.writerow(row)
all(b >= a for a, b in zip(the_list, it))
zip(*A)
plt.show()
plt.show()
[word for word in l if word.isalnum()]
c = [x for x in b if x in _auxset]
[list(x[1]) for x in itertools.groupby(data, lambda x: x == 0) if not x[0]]
list(itertools.chain(*[([k] * v) for k, v in list(d.items())]))
self.save()
print(time.mktime(d.timetuple()))
np.roll(a, 1)
round(number * 2) / 2.0
pprint(sys.path)
A[i, j]
print(doc.toprettyxml())
app.logger.setLevel(logging.DEBUG)
random.shuffle(lst)
data_slices.sort(key=lambda s: s[-1].start)
reactor.run()
sorted(mydict, key=lambda key: mydict[key])
plt.show()
results = list(map(int, results))
df.where((df > df.shift(1)).values & DataFrame(df.D == 1).values)
user.put()
cv.WaitKey(0)
dfrm.drop(dfrm.index[len(dfrm) - 1])
df.stack().reset_index(level=[0, 1], drop=True)
img.show()
t1start <= t2start <= t1end or t2start <= t1start <= t2end
df.iloc[indexers]
plt.legend(loc=4)
Foo.foo()
json_string = json.dumps(list_name, default=obj_dict)
[x for b in a for x in b]
unittest.main()
plt.show()
br.select_form(nr=1)
ax.xaxis.set_visible(False)
plt.show()
{key: val for key, val in parent_dict.items() if 2 < key < 4}
cursor = db.cursor(dictionary=True)
numpy.in1d(a, b)
plt.show()
sorted(mylist, key=cmp_to_key(locale.strcoll))
np.array([(arr + i) for i in np.arange(-0.2, 0.25, 0.1)]).T.ravel()
tf.constant(1) + tf.constant(2)
min([t for t in l if not math.isnan(t[1])], key=itemgetter(1))
sorted(l1 + l2)
zeros = [([0] * M) for _ in range(N)]
driver.switch_to_alert().accept()
sys.exit()
dict([k_v for k_v in list(d1.items()) if k_v[0] in d2 and d2[k_v[0]] == k_v[1]])
random.sample(list(range(1, 10)), 5)
Series([str(x) for x in htmldata])
print([(lst[i], lst[i + 1]) for i in range(0, len(lst), 2)])
session.commit()
ftp.quit()
a.transpose(2, 1, 0)
lst.append(os.path.splitext(x)[0])
re.split(seperator, f.read())
myTextCtrl.SetFont(font1)
a == a[(0), :]
plt.show()
zip(l, l[1:])
print([(s, s in st1) for s in re.findall(pat, st2)])
df.idxmax(axis=1)
plt.show()
[x for y in l for x in y]
list(range(x1, x2 + 1))
root.mainloop()
method()
writer.writerow([])
pd.concat([df_a, df_b], axis=1)
time.sleep(0.1)
{tuple(key): value for key, value in zip(bins, count)}
p.start()
map(int, bin(6)[2:])
[10, 9, 8, 4, 7]
calendar.timegm(time.gmtime())
conn.commit()
{key: list(set.difference(set(a[key]), b.get(key, []))) for key in a}
print(file_contents)
print(list(chain.from_iterable((x, x + 1) for x in l)))
nx.draw_spring(G)
df.index
[[[x, y] for x in list1] for y in list2]
ssh.connect(IP[0], username=user[0], pkey=mykey)
df[(df.iloc[:, -12:] == -1).all(axis=1)]
a.__init__(*args, **kwargs)
a[~np.isnan(a).any(1)]
plt.show()
list(StreetCat._meta.parents.keys())[-1]
print(f.read())
sorted(a) == sorted(b)
set(data1) & set(data2)
pl.show()
ax.get_xticklines()[i].set_visible(False)
time.sleep(0.5)
df.dot(weight)
chr(128512)
array[(i[0]), (i[1]), (i[2]), ..., (i[n - 1])]
plt.show()
[6, 7, 8, 9]
len([x for x in frequencies if x > 0])
x[:, 1::2]
df[0].apply(lambda x: (0, 0) if x is np.nan else x)
plt.show()
app.run()
inlinkDict[docid] = adoc[1:] if adoc[1:] else 0
C = np.hstack((A, B[:, 1:]))
sys.exit(1)
print(date(today.year + 1, today.month, today.day))
sum(Decimal(n) * Decimal(10) ** Decimal(i) for i, n in zip(count(0, -1), a))
plt.show()
MyClass.__dict__
df = pd.DataFrame([df.sum()] * len(df))
pd.crosstab(df.saleid, df.upc)
plt.show()
print(data.reshape(-1, 2).mean(axis=1))
max(n for n in range(1000) if str(n) == str(n)[::-1] and is_prime(n))
np.maximum.accumulate(Q[:, ::-1], axis=1)[:, ::-1]
clf.fit(X_train, y_train)
np.random.seed(1)
main()
datetime.time()
test.f(0)
df.stack().between(2, 10, inclusive=False).unstack()
y = [j for i in x for j in i]
hex(x)[2:]
im = Image.open(image_file)
session.delete(instance)
result.append(b[index])
server.starttls()
np.concatenate(counts_array).reshape(len(counts_array), -1)
plt.show()
name = sys.argv[1:]
plt.show()
s.groupby(level=0).apply(list)
df.convert_objects(convert_numeric=True)
pobj.stdin.flush()
plt.show()
plt.show()
foo()
multiprocessing.Process.__init__(self)
[sum(x) for x in zip(*lists_of_lists)]
pd.concat([pd.Series(initial_value), cum_growth]).reset_index(drop=True)
np.concatenate(input_list).ravel()
a[0]
app.run()
mp.Process(target=foo, args=(x,)).start()
sys.stdout.write(line)
df.drop(df.columns[i], axis=1)
plt.show()
ax.xaxis.set_major_locator(locator)
A.ravel()[np.in1d(A, B)] = 0
my_list.sort(key=my_key)
cv2.waitKey(0)
os.path.expanduser(path)
time.sleep(1)
plt.show()
df.ix[:5, :10]
a.ravel()
ax.set_xticklabels(nonRepetitive_x)
deletepkt[TCP].chksum
[x for i, x in enumerate(numbers) if i not in indices]
A[0][0:4]
conn.rollback()
a[[0, 1], [1, 2], [2, 2]]
set.intersection(*map(set, d))
df.columns.droplevel(1)
[2, 6, 8, 7, 9, 6, 5, 4, 2]
[[]] * 10
time.sleep(0.1)
print(r.dtype)
ax.axes.get_xaxis().set_visible(False)
str.isalpha()
sys.exit(app.exec_())
{i: functools.reduce(dict.__getitem__, keys, d[i]) for i in d}
os.chown(path, uid, gid)
set(map(tuple, listB)) <= set(map(tuple, listA))
(x for x in List)
print(sum(num for num in numbers if num % 2 == 1))
dict(zip(i, i))
np.array([a, a]).shape
[[], [], []]
instance.__class__.__name__
json.dump(data, outfile)
time.sleep(60)
print(max(group, key=lambda k: len(list(k[1]))))
f.close()
some_func(*params)
numpy.clip(x, 0, 255)
x.reshape(2, 2, 5)
lines.sort(key=itemgetter(2), reverse=True)
sorted({x for v in content.values() for x in v})
set(tuple(i) for i in l)
set([1, 2])
self.ham = dict()
unravel_index(a.argmax(), a.shape)
[e for i, e in enumerate(main_list) if i in indexes]
cv2.rectangle(image, (x, y), (x + w, y + h), (255, 255, 0), 5)
self.ui.closeButton.clicked.connect(self.closeIt)
sum(int(x) for x in digit if x.isdigit())
app.run()
r = requests.post(url, files=files, data=data, headers=headers)
plt.plot(x, y)
root.mainloop()
[k for k, v in colour.items() if v == min_val]
plt.show()
[y for y in a if y not in b]
np.fft.fft(xfiltered)
root.mainloop()
matplotlib.pyplot.plot(raw_audio_data)
root.grid_rowconfigure(1, weight=1)
palette.append((0, 0, 0))
today + datetime.timedelta(days=1)
[peaks([x, y]) for x, y in zip(xscat, yscat)]
print(json.dumps(dict(table_data)))
sorted(li1, key=k)
list(range(0, 6, 2))
admin.site.register(Foo, FooAdmin)
plt.axvline(x=2.20589566)
df.column_A.apply(to_binary)
df.max()
plt.show()
yacc.yacc(debug=0, write_tables=0)
nx.draw_networkx_edges(G, pos, edgelist=black_edges, arrows=False)
sys.exit()
good_data = [data[(n), :][flag == 1].tolist() for n in range(data.shape[0])]
img[:, :, (0)] = 0
self.SetSizer(sizer)
sum(x > 0 for x in frequencies)
json.dumps(geodata)
print(A.reshape(-1, k)[np.arange(n * m), B.ravel()])
np.in1d(A, B).any()
plt.show()
y = set(x.flatten())
date.today() > self.date
pygame.init()
plt.show()
canvas.create_image(0, 0, anchor=NW, image=displayPlantImage)
root.mainloop()
[(key, len(list(it))) for key, it in itertools.groupby(list_one)]
df.isnull()
df1.apply(lambda s: df2.corrwith(s))
self.response.out.write(html)
plt.plot(list(range(10)))
[int(x) for line in data for x in line.split()]
ax.plot(x, y, color=uniqueish_color())
QtGui.QMainWindow.__init__(self, parent)
print(etree.tostring(root, pretty_print=True))
sdb.close()
np.mgrid[[slice(row[0], row[1], n * 1j) for row, n in zip(bounds, n_bins)]]
results = [r for k in keywords for r in re.findall(k, message.lower())]
getattr(this_prize, choice)
root.mainloop()
time.sleep(0.2)
int(bin(n)[:1:-1], 2)
plt.show()
requests.post(url, data=body, headers=headers)
print([hex(x) for x in numbers])
zip(string, string[1:], string[2:])
win.show_all()
sum(Decimal(i) for i in a)
np.split(x.reshape(x.shape[0], -1), 9, axis=1)
conn.close()
process.terminate()
f.close()
xxxxx.yyyyy.zzzzz
d = os.path.dirname(os.getcwd())
list2 == sorted(list2, key=lambda c: list1.index(c))
dict((y, x) for x, y in t)
myothermodule.py
print(repr(s))
plt.show()
print(list(range(n, (m + 1) * n, n)))
type(theobject).__name__ in dir(__builtins__)
root.mainloop()
func()
[[cell for cell in row] for row in X]
s[::-1]
text_file.close()
print([[x for x in a if len(x) == i] for i in set(len(k) for k in a)])
y = x.astype(int)
plt.show()
root.mainloop()
signal.signal(signal.SIGINT, quit_gracefully)
self.request.user
Mainscreen()
ax.xaxis.set_major_formatter(myFmt)
ax.set_yticklabels([])
sys.stdout.flush()
self.assertEqual(my_patch_method, patch_my_lib().target_method.__func__)
logging.getLogger().setLevel(logging.INFO)
pgdb.paramstyle
time.sleep(5)
[L[i] for i in [2, 1, 0]]
fig.tight_layout()
plt.show()
plt.show()
self.f.close()
x[1::2, 1::2]
arr[arr > 0].min()
etree.tostring(div)
painter.restore()
zlib.decompress(data)
plt.show()
array([[0], [7], [1], [0], [4], [0], [0], [0], [0], [1], [0], [0], [0]])
out = mat[0] * (len(ixs) - len(nzidx)) + mat[ixs[nzidx]].sum(axis=0)
[str[start:start + num] for start in range(0, len(str), num)]
np.asarray(V).min(0)
[[0, 0], [1, 1]]
ax2.set_xlim([0, 5])
plt.show()
x = dict(zip(list(range(0, 10)), itertools.repeat(0)))
list(item[1] for item in pkgutil.iter_modules())
datetime.datetime.date(2011, 1, 1)
i, = np.where(a == value)
cv2.destroyAllWindows()
b = numpy.append(a, numpy.zeros([len(a), 1]), 1)
A[np.random.choice(A.shape[0], num_rows_2_sample)]
fig, ax = plt.subplots(figsize=(6, 1))
pil_im.show()
mlab.show()
ax.set_yticks([])
pd.concat([s1, s2], axis=1)
file.write(str(m))
sys.stdout.flush()
Activity.objects.filter(list__topic=my_topic)
app.exec_()
np.logical_or.reduce((x, y, z))
writer.writerow([item])
print(rawstr(test7))
{{settings.MY_SETTING_NAME}}
[s.strip() for s in data_string.splitlines()]
fo.write(fp.read())
sess.run(assign_op)
ts.reindex(pd.date_range(min(date_index), max(date_index)))
print(alphs[:i] + alphs[i::-1])
plt.show()
[dict(zip(d, v)) for v in product(*list(d.values()))]
self.text.pack()
a = numpy.frombuffer(buffer, float)
mylist = list(set(mylist))
print(sorted(list(a.items()), key=lambda t: get_key(t[0])))
np.in1d(a, b).reshape(a.shape).any(axis=1)
self.assertEqual(my_patch_method, patch_my_lib().target_method.__func__)
deletemy_dict[k]
plt.show()
threading.Thread(target=play1).start()
x = np.random.rand(5, 1)
plt.show()
os.path.sep
csv_writer.writerows(cursor)
app.run()
df2.reset_index(drop=True)
print(lxml.etree.tostring(order, pretty_print=True))
globals()
print(max(result, key=lambda a: a[1]))
all_data.append(data)
matplotlib.pylab.show()
input_file.close()
self.setWindowFlags(PyQt4.QtCore.Qt.WindowStaysOnTopHint)
deleteL[index]
print(f.read())
d = dict((v[0], v[1:]) for v in arr)
print(lxml.etree.tostring(tree))
pygame.init()
list(d.values())
[item for item in lis if item[1] not in seen and not seen.add(item[1])]
any(([1, 2] == x).all() for x in a)
[(x + b[i]) for i, x in enumerate(a)]
[(tuple[a], tuple[a + 1]) for a in range(0, len(tuple), 2)]
np.array(a).reshape(-1, 100)[::2].ravel()
df.index.values
[((i // 2) ** 2 if i % 2 else i // 2) for i in range(2, 20)]
zip(*([iter(l)] * 2))
os.kill(os.getppid(), signal.SIGHUP)
len(sum4) - np.count_nonzero(sum4)
gtk.gdk.pixbuf_new_from_array(arr, gtk.gdk.COLORSPACE_RGB, 8)
print(etree.tostring(e, pretty_print=True))
print(equations((x, y)))
ham.__class__.__name__
os.kill(12765, 0)
calendar.timegm(dt.utctimetuple())
sum(int(i) for i in data)
pdb.set_trace()
[[[flatten[int(i * 2)]]] for i in range(int(len(flatten) / 2))]
plt.show()
results = [int(i) for i in results]
func(*args, **kwargs)
[m.group(1) for m in (re.search(regex, l) for l in lines) if m]
print(sum(sum(map(int, r.findall(line))) for line in data))
[x[1] for x in L]
plt.tight_layout()
df.genres.apply(pd.Series).stack().drop_duplicates().tolist()
nms.dropna(thresh=2)
admin.site.register(Person, PersonAdmin)
ax1.set_xticklabels([])
result = copy.deepcopy(source_dict)
soup = BeautifulSoup.BeautifulSoup(urllib.request.urlopen(url).read())
[([0.0] * 10) for _ in range(10)]
a[1, 1]
eliminated.append(x)
print(etree.tostring(x, pretty_print=True))
emp.delete()
[myDictionary.get(key) for key in keys]
urllib.parse.unquote(url)
max((t for t in yourlist if t[2] >= 100), key=itemgetter(1))
urllib.parse.unquote(urllib.parse.unquote(s))
app.exec_()
list(sys.modules.keys())
code.interact()
range(N, -1, -1)
ws.cell(row=i + 2, column=1).value = statN
plt.show()
a = a.reshape((a.shape[0], -1, n))
procs.append(multiprocessing.Process(target=worker))
setattr(current_module, new_name, func)
print(f.read())
groupby(a, [0, 1])
list(metadata.tables.keys())
webbrowser.open_new_tab(url)
plt.show()
s.reset_index(drop=True, inplace=True)
reactor.run()
dict((item[0], (item[1], z[item[0]])) for item in l)
pd.crosstab(df.A, df.B).apply(lambda r: r / r.sum(), axis=1)
process.terminate()
soup.body.insert(len(soup.body.contents), yourelement)
json.loads(_)
x.do_something()
total = sum([int(i) for i in cost])
writer.writerows(all)
random.shuffle(lst)
n ^= (1 << upper) - 1 & ~((1 << lower) - 1)
my_series.sort()
time.sleep(1)
deletemyList[i]
session.commit()
max(x, key=sum)
[(x ** 2) for x in range(10)]
sum(a * b for a, b in zip(it, it))
df.a = df.a / 2
example2()
time.sleep(1)
[(float(c) / t) for c, t in zip(conversions, trials)]
self.assertEqual(4, 2 + 2)
user.save()
window.after(1, lambda : window.focus_force())
time.sleep(1)
[list(t) for t in set(tuple(element) for element in xx)]
print(et.tostring(tree, pretty_print=True, xml_declaration=True))
root.mainloop()
sys.stdout.flush()
np.cos(-1.5)
time.time() * 1000
ctypes.cast(s, ctypes.c_void_p).value
df.ix[pd.to_datetime(df.Date).order().index]
sorted(l, key=lambda x: (x[:-1], x[-1].isdigit()))
result = array[:, (idx)]
print(os.path.join(root, name))
sys.exit(0)
sum(map(int, str(n)))
q.T.reshape(-1, k, n).swapaxes(1, 2).reshape(-1, k)
sys.exit(0)
round(math.degrees(math.asin(0.5)), 2)
min(enumerate(a), key=itemgetter(1))[0]
print(list(sampleDict.values())[0].keys()[0])
initgstreamer()
time.sleep(4)
test_df.where(~(test_df < 4))
l = list(map(lambda x: 2 * x, l))
plt.show()
im.show()
app.run()
myShelvedDict.update(myDict)
{v: (v ** 2) for v in l}
im = Image.open(tempimg)
plt.show()
app.run()
[[try_int(x) for x in lst] for lst in list_of_lists]
subprocess.Popen(executable, creationflags=DETACHED_PROCESS, close_fds=True)
app.run()
np.array(my_list, dtype=np.float)
{{request.session.foo}}
driver.quit()
plt.show()
n.index(min(n))
t.start()
x = [(0) for i in range(10)]
file_handle.close()
a.__setitem__(slice(0, 1), [1])
[data[i:i + n] for i in range(0, len(data), n)]
server.serve_forever()
a.take(np.arange(start, end), axis=axis)
plt.xticks(ticks, labels)
sum(map(float, s.split()))
print(ET.tostring(newdom, pretty_print=True))
array([0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0])
f.set_size_inches(11.69, 8.27)
df._get_numeric_data()
circle1.set_visible(False)
ast.literal_eval(a)
logging.getLogger().handlers[0].setLevel(logging.DEBUG)
pyplot.draw()
df.iloc[:, (your_col_index)]
plt.show()
items = [some(a.split(), d, n) for a, d, n in (list(m.values()) for m in dl)]
isinstance(now, datetime.datetime)
ax.set_xticklabels([])
server.serve_forever()
np.repeat(np.arange(x), y)
df1.ix[0, 1]
plt.show()
a_lower = {k.lower(): v for k, v in list(a.items())}
your_list = map(int, your_string)
plt.show()
[list(g) for k, g in itertools.groupby(sorted(iterable))]
sys.stdout.flush()
cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
User.objects.filter(active=True)
[key for key, val in list(dct.items()) if val == True]
data = np.concatenate((im, indices), axis=-1)
mimetypes.init()
cv2.destroyAllWindows()
random.randrange(1, 10)
numpy.histogram(a, bins=(25, 100))
my_list = my_list[:8] + new_array
dictionary[key] = value
app.run()
print(list(range(0, (m + 1) * n, n))[1:])
df.columns = [strip_non_ascii(x) for x in df.columns]
L.grid(row=6, column=0)
cv2.waitKey(0)
sorted(A, key=operator.itemgetter(2, 0, 1))
df = pd.concat([df, s1, s2], axis=1).reset_index(drop=True)
[[int(j) for j in i] for i in a]
[0, 0, 0, 0, 0, 0, 0, 0, 0],
db.commit()
madata.mean(axis=1)
a = np.array([[1, 2], [10, 20], [100, 200]])
set(list1).intersection(list2)
np.bincount(accmap, weights=a)
isinstance(d[obj], list)
time.sleep(1)
self.canvas.pack(fill=BOTH, expand=YES)
plt.show()
plt.scatter(x, y)
verts = [(0) for x in range(1000)]
[(1) for _ in range(6)]
np.linalg.norm(x)
connection.connect()
time.sleep(100)
[(1, 2, 2), (5,), (1, 1, 1, 1, 1), (1, 1, 1, 2)]
sorted(Author.objects.all(), key=lambda a: a.full_name)
jsonify(eqtls=[e.serialize() for e in my_list_of_eqtls])
sum(len(i) for i in x if len(i) > 1)
[[k for k in x if x[k] != y[k]] for x, y in pairs if x != y]
admin.site.register(Product, ProductAdmin)
norm = [(float(i) / max(raw)) for i in raw]
df.iloc[[2, 4]]
next(s for s in list_of_string if s)
Gtk.main()
[x for x in mylist if x in pattern]
fcntl.flock(fd, fcntl.LOCK_EX)
plt.show()
[x[:] for x in [[foo] * 10] * 10]
root = tk.Tk()
arr = arr[:, :, 0::2]
df[(df.A == 0) & (df.B == 2) & (df.C == 6) & (df.D == 0)]
[set(i) for i in OrderedDict.fromkeys(frozenset(item) for item in L)]
MyModel2.mymodel1.through.objects.all()
_.sum()
df.groupby(df.index.year)
[i for i in range(4) if i <= 1 or i >= 4]
plt.show()
time.sleep(10)
df.mean(axis=1)
sorted(a, key=lambda x: aux.index(x[0]))
np.where(a == a.max())
hasattr(Dynamo, key) and callable(getattr(Dynamo, key))
[math.log10(i) for i in x]
do_something()
np.where(condition(zeta), func1(zeta), func2(zeta))
numpy.array(list(result.items()), dtype)
a.mean(axis=-1).mean(axis=-1)
pdb.set_trace()
sys.modules
plt.show()
np.argwhere(arr)
im = Image.open(BytesIO(base64.b64decode(data)))
print(json.dumps(json_output, indent=4))
print(a.pop(0))
data = np.atleast_2d(np.loadtxt(filename))
Employee.objects.active()
[(not x) for x in some_list]
print(hex(int(string, base=16)))
df.dropna(thresh=len(df) - 7)
session.query(Location, func.count(Work.id)).outerjoin(Work).group_by(Location)
cursor.execute(sql, args)
plt.show()
plt.hist(x, bins=n, range=(a, b))
plt.show()
plt.show()
[(x + 1 if x >= 45 else x + 5) for x in l]
reactor.run()
list(chain(*(i if isinstance(i, tuple) else (i,) for i in l)))
print(chr(1081))
print(cursor.fetchall())
crypthash.hexdigest()
[func(x, y) for x, y in zip(xs, ys)]
pygame.mixer.music.play()
[filterList(numbers, ranges[i], ranges[i + 1]) for i in range(len(ranges) - 1)]
f.close()
int(value or 0)
MyModel.objects.filter(name__exact=models.F(title)).exists()
{{my_num | intcomma}}
map(set, list(d.values()))
list(df.index.values)
plt.show()
plt.draw()
[k for k, v in numbers.items() if v == max(numbers.values())]
f.write(os.linesep.join(data))
dictionary[new_key] = dictionary.pop(old_key)
root.mainloop()
[i for i, (m, n) in enumerate(zip(bool_array[:-1], bool_array[1:])) if m != n]
fh.close()
sys.stdout.flush()
plt.figure()
print((key, value))
sys.modules
lst[0] in lst[1:]
the_list.sort(key=len, reverse=True)
filtered_dict = {k: v for k, v in d.items() if filter_string in k}
plt.show()
str(chr(97))
myList.append(i)
globals()[name] = 10
Model.__table__.create(session.bind)
time.sleep(1)
df.index = list(range(len(df)))
conn.commit()
print(np.sort(np.partition(x, -10)[-10:]))
[list(group) for k, group in groupby(l, bool) if k]
good_data = [data[(n), :][flag == 1] for n in range(data.shape[0])]
input()
np.cumsum(a)
datetime.datetime.now() + datetime.timedelta(days=1)
[l for l in a if l in b]
df1.loc[(df1 > s).any(axis=1) == True].index.tolist()
list([a for a in x if a != 2])
plt.show()
ar.reshape(ar.shape[0], -1)
[random.uniform(lbound, rbound) for i in range(n)]
sys.path.append(root)
list(double([1, 2]))
any(key.startswith(mystr) for key in mydict)
Py_Finalize()
{{form.as_table}}
plt.show()
webdriver.Firefox(firefox_profile=fp)
[1, 0, 1, 1]
server.serve_forever()
[int(digit) for digit in bin(n)[2:]]
a = a + [0] * (maxLen - len(a))
list(d.keys())
signal.signal(signal.SIGCHLD, signal.SIG_IGN)
plt.show()
[True] * 5000
d.sort(key=itemgetter(1), reverse=True)
sorted(items, key=cmp_to_key(comparer))
self.setupUi(self)
br.select_form(nr=0)
np.asarray(map(func, arr))
x, y = -y, x
print((cities[0][1], cities[1][1]))
plt.show()
a, b, c
f(*((1, 4),))
__init__.py
Achievement.objects.get(name=str(b))
np.ma.array(np.tile(arr, (cond.shape[0], 1)), mask=~cond).argmax(axis=1)
plt.imshow(lena, cmap=plt.cm.gray)
server.serve_forever()
array2[:, :, :, :] = array1.copy()
gtk.main()
df.T
[item for item in my_list if item not in to_be_removed]
df.loc[(df != 0).any(axis=1)]
f.close()
requests.get(url, auth=auth)
browser.quit()
cherrypy.request.params.get(key_name)
((a == b) | numpy.isnan(a) & numpy.isnan(b)).all()
plt.show()
np.random.permutation(arr)
conPG.commit()
[item for item in my_list if 1 <= item <= 5]
print([next(c) for _ in range(10)])
ax.set_xlim([0, len(df)])
app.MainLoop()
plt.show()
ax.yaxis.set_visible(False)
not set(list1).isdisjoint(list2)
time.sleep(60)
shutil.copy(filename, dest_dir)
_(a + b * c)
f.close()
csv_output.writerows(zip(*rows))
my_list.sort(key=lambda x: order.index(x[0]))
np.sin(-1.5)
__init__.py
list(string.ascii_lowercase)
simulation.someloop()
conn.close()
arr[arr < 0] = 0
plt.show()
sys.stderr.write(str(e))
session.query(RssFeed).all()
server.serve_forever()
buffer1[:] = buffer2
A = np.array([C[:, (B == i)].sum(axis=1) for i in range(M)])
plt.show()
math.hypot(p2[0] - p1[0], p2[1] - p1[1])
plt.show()
dic = {x: i for i, x in enumerate(al, 1)}
f.close()
np.where(a == a.max(axis=1, keepdims=True), a, 0)
mlab.show()
self.est.fit(X, y)
os.makedirs(dirname)
self.Bind(wx.EVT_LEFT_DOWN, self._onMouseDown)
tar.close()
plt.show()
pygame.display.update()
__init__.py
tuple(l)
ax.scatter(x, y, z, depthshade=0)
plt.show()
unittest.main()
timediff.total_seconds()
[abs(a - b) for a, b in zip(l, l[1:] + l[:-1])]
self.d.setdefault(index, []).append(value)
plt.show()
df.mean().sort_values()
pygame.display.update()
[-2, -1, 0, 1, 2]
sorted(li, key=operator.itemgetter(1))
random.choice(string.ascii_lowercase)
window.mainloop()
plt.close()
[(k, list(g)) for k, g in groups]
app.exec_()
sum(my_list)
{{model.datetime | time}}
tuple(map(tuple, arr))
plt.show()
list(itertools.combinations(list(range(6)), 2))
plt.show()
s.sort(key=operator.itemgetter(1, 2))
roundrobin(my_list, my_list)
root.mainloop()
sys.exit()
today = date.today()
json.dumps(result)
pyplot.close()
plt.show()
br.submit()
log.start()
list(map(len, s.split()))
print(item.strip())
plt.show()
sys.stdout = sys.stdout.detach()
[(items[:i] + items[i + 1:]) for i in range(len(items))]
np.arange(a.shape[0])[~np.in1d(a, b)].tolist()
df.apply(lambda x: x.value_counts()).T.stack()
app.run()
np.argwhere(M == 0)
out_file.close()
x = dict((i, set()) for i in range(10))
reactor.run()
s = s[0].lower() + s[1:]
picturetags.py
map(list, df.values)
list(set(list1 + list2))
plt.step(x, y)
C = np.dot(A, B)[:, :, (0), :]
sorted(iter(adict.items()), key=itemgetter(1), reverse=True)
func(*args, **kwargs)
driver.close()
(df == 0).sum(axis=1)
s.isnull().sum()
[item for item in my_list if any(x in item for x in bad)]
output.append([items[0], int(items[1]), int(items[2])])
ax.annotate(str(j), xy=(i, j + 0.5))
word in wordList[:4]
pprint.pprint(filtered)
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
forms.ModelForm.__init__(self, *args, **kwargs)
es.refresh()
conn.rollback()
np.insert(a, 1, np.array((1, 1)), 1)
df.apply(np.prod, axis=1)
p.pattern
df.T.drop_duplicates().T
self.thread.start()
p.stdout.close()
self.figure.canvas.draw()
[key for key, group in groupby(li) if all(i == 0 for i, j in enumerate(group))]
matrix.append([0] * columns)
a[:] = []
os.path.dirname(sys.argv[0])
ax.set_ylim([-0.5, 0.5])
print(os.getcwd())
transaction.commit()
lst.append(z)
a[0:1] = [[5]]
sorted(counter.items())
[0, 0, 0, 0, 1, 0, 0, 0, 0],
df_with_x7.show()
datetime.timestamp()
a[2:10] = []
driver.quit()
map(str.upper, letters)
plt.show()
pkg_resources.get_distribution(name).activate()
sum(map(lambda x, y: bool(x - y), [1, 2], [1]))
zip(t[::2], t[1::2])
time.sleep(1)
parts = [s[indices[i]:indices[i + 1]] for i in range(len(indices) - 1)]
[4, 5, 5, 6, 6, 6]
list(chain.from_iterable((i, i ** 2) for i in range(1, 6)))
{{add(a, b)}}
time.sleep(1)
a.sort(axis=1)
plt.show()
f.close()
f.close()
hash(frozenset(iter(self.__dict__.items())))
len(a[0])
plt.show()
cv2.bitwise_and(gray, gray, mask=mask)
fig, ax = plt.subplots()
plt.show()
np.hstack((a, b, c)).ravel()
plt.show()
lowest_dirs.append(os.path.split(root)[-1])
print(soup.get_text().strip())
ax.set_xlim(-5, 5)
time.sleep(1)
data = OrderedDict(sorted(list(data.items()), key=lambda x: x[1][0]))
time.sleep(1)
db.close()
min(max_val, max(min_val, val))
{key_for_value(value): value for value in values}
tuple(list(x[0]) + [x[1]])
np.take(A, np.arange(ncols) % A.shape[1], axis=1)
my_list2, my_list1 = zip(*my_list)
Gtk.main()
all(key in dict_obj for key in properties_to_check_for)
Clock.schedule_once(partial(self.update, message), 0)
random.uniform(1.5, 1.9)
datetime.timedelta(seconds=10) + datetime.timedelta(hours=5)
np.equal.reduce([True, 1])
[[x, y] for x in list1 for y in list2]
[x for x in lelist if lestring.count(x)]
termios.tcsetattr(fd, termios.TCSAFLUSH, old_settings)
L = [bytes_obj[i:i + 1] for i in range(len(bytes_obj))]
a.transpose(0, 2, 1).ravel()
pickle.loads(pickle.dumps(PickalableC()))
random.shuffle(thelist)
print(a if b else 0)
self.appExeCB.addItems(list(self.items.keys()))
plt.xticks(xvalues, xlabels)
[(x * 0.1) for x in range(0, 10)]
np.argwhere(np.all(e - array([1, 2]) == 0, axis=2))
help(my_list)
[int_or_float(el) for el in lst]
shutil.copy2(file, dest_dir)
self.Center()
print(sys.argv)
plt.show()
cv2.imwrite(name, imagem)
toolz.unique(obj_list, key=lambda x: x.my_attr)
operator.itemgetter(1)(row)
a[np.argsort(ma[:, (1)])]
my_array = numpy.array(my_list, dtype=numpy.float64)
app.run(port=port, debug=False)
x[:] = [value for value in x if len(value) == 2]
os.startfile(filename)
plt.show()
sys.argv[2]
not any(dict.values())
[(item, value) for item, value in config.items(section)]
np.hstack(a.flat)
my_list.sort(key=operator.itemgetter(1))
globals()
self.thread.start()
app.run()
json.load(request.body)
{c: s.count(c) for c in chars}
tk.mainloop()
pdb.set_trace()
B_p.to_csv(sys.stdout, index=False)
{str(k): convert_value(v) for k, v in list(d.items())}
QtCore.Qt.ItemIsEnabled
data = [map(int, line.split()) for line in f]
urllib.parse.urlencode(f)
d = dict(zip([o.name for o in object_list], object_list))
writer.writerows(lines)
keys = [i for i, v in scores.items() if v == max_value]
[i[0] for i in x]
plt.show()
session.commit()
map(lambda frame: frame.query(expr), [df, df2])
prod(list(range(1, 5)))
keys.update(list(d.keys()))
(df != 0).dot(df.columns)
print(object.__repr__())
thread.start()
self.x += STEP
plt.show()
plt.show()
int(b, 2)
f = figure(figsize=(5, 1))
ssh.close()
fp.close()
list({x.tag: x for x in myList}.values())
p.delete()
all(i.count(1) == n for i in l)
df.reset_index()
result = np.arange(20, dtype=np.float).reshape((2, 10))
datetime.datetime.fromtimestamp(0) + datetime.timedelta(seconds=2147570047)
pd.crosstab(df.A > 0, df.B > 0)
self.get()
plt.show()
app.exec_()
ContactForm.get_reason_display()
len(x) >= 4
my_list = [json.loads(line) for line in f]
session.query(func.count(User.id)).scalar()
l.append(elt2)
all(v == 0 for v in values)
plt.show()
result.wait()
ssh.close()
zip(*([iter(L)] * 2))
img = Image.open(file)
df2.show()
(dict(zip(dicts, x)) for x in itertools.product(*list(dicts.values())))
[x for x in strings if x]
sum(v) == sum(v + [n])
df.eq(df.iloc[:, (0)], axis=0).all(1)
list(d.values())
module1.Relay()
print(arg, getattr(args, arg))
[word for word in words if not word.isdigit()]
plt.show()
data2 = sorted(data, key=operator.itemgetter(1))
plt.show()
plt.show()
ax.set_xticklabels(labels)
print(etree.tostring(root))
df = pd.DataFrame(data[1:], columns=data[0])
im2.putdata(list_of_pixels)
np.sqrt(s.multiply(s).sum(1))
np.tile(data, 5)
[0, 0, 1, 1, 1, 1, 1, 0, 0],
plt.show()
w.writerow(my_dict)
pdb.set_trace()
QtGui.QMainWindow.__init__(self, parent)
print(output.stdout.read())
show()
print(tuple(itertools.chain.from_iterable(product)))
l.sort(key=key)
df.groupby([df.a.apply(tuple)])
c.save()
plt.show()
d = dict(zip((o.name for o in object_list), object_list))
plt.show()
np.repeat(data, 5)
pd.concat([df[col].apply(pd.Series) for col in cols], axis=1, keys=cols)
pprint.pprint(a, width=1)
sum((Counter(d) for d in list(data.values())), Counter())
test.__kwdefaults__
print(sum(1 for x in arr if x is False))
cherrypy.engine.start()
plt.show()
db.session.add(product_obj)
df.iloc[-6:-1, (2)]
extmodule.dontoverride()
sum([[False, False, True], [True, False, True]])
np.linalg.lstsq(A.T, y)
[0, 0, 0, 1, 1, 1, 0, 0, 0],
plt.show()
random.shuffle(temp)
d2 = dict((k, f(v)) for k, v in list(d.items()))
np.putmask(elevation, elevation > 0, np.nan)
plt.draw()
sorted(vec, key=itemgetter(1), reverse=True)[:5]
gtk.main()
func(*args, **kwargs)
[name for name, age in list(mydict.items()) if age == search_age]
somelist.sort(key=predefined_list.index)
df = df.apply(myfillna)
signal.signal(signal.SIGINT, signal.SIG_DFL)
pyplot.show()
func.__code__.co_code
cursor.execute(sql)
self.canvas.draw()
deletemyList[-2:], myList[:2]
print(np.allclose(sola, solb))
zip(*l)
df.iloc[:5, :5]
set(a) & set(b) & set(c)
datetime.datetime(2010, 9, 29, 11, 15)
gevent.monkey.patch_all(httplib=True)
plt.show()
cursor.execute(query, l)
self.actionthread.start()
instance.instance_method()
dict((x, i) for i, x in enumerate(t))
pygame.init()
app.register_blueprint(someappmod)
sum(int(x) for x in s if x.isdigit())
sys.stdout.flush()
[x for y in collection for x in y]
frame.grid(row=0, column=0)
os.path.dirname(sys.argv[0])
outfile.close()
[(i, [j for j in L if j != i]) for i in L]
remote_file.close()
np.sum(my_list)
[int(i) for i in str(bin(x))[2:]]
list(itertools.chain(*list(d.values())))
moo.py
d = dict((x.key, x) for x in object_list)
((x, y) for x in a for y in b)
select(L, [2, 5])
transposed_l.sort(key=lambda x: x[1], reverse=True)
nonVarargMethod(args[0], args[1], args[2])
f(*list(range(5000)))
print(line)
(dict(zip(dicts, x)) for x in product(*iter(dicts.values())))
plt.show()
shutil.copy(full_file_name, dest)
random.seed([x])
array([1.05206154, 1.96929465, 0.94590444]), 1
plt.show()
plt.show()
server.stop()
ax.yaxis.set_visible(False)
{f(k): v for k, v in d.items()}
a = [t[1] for t in enumerate(a[1:]) if t[1][1] > a[t[0] - 1][1]]
doctest.testmod()
[[2, 4, 6], [8, 10, 12], [6, 8, 12]]
session.rollback()
[i for i, d in enumerate(lod) if 2 in d]
OrderedDict(sorted(list(d.items()), key=lambda t: t[0]))
file.write(str(formatted))
plt.show()
DataFrame(values, columns=columns)
os.chdir(path)
ax.plot_surface(X, Y, Z, facecolors=cm.Oranges(V))
sorted(qs, key=lambda x: x.id == id)
self.assertEqual(5, self.testme)
float(math.factorial(170))
pdb.set_trace()
[item for sub_list in a[1:] for item in sub_list].count(1)
kethread.start()
json.loads(s)
df1.reset_index()
B = A[[0, 2], [0, 1], [1, 2]]
writer.writerow(row)
edges.append((m.group(1), m.group(2)))
set.intersection(*map(set, p))
print(repr(line))
sys.exit()
[main_list[x] for x in indexes]
df.apply(func, axis=1)
sys.exit()
f.newmethod()
os.remove(filename)
print(top[0][1])
{k: v for k, v in list(d.items()) if k.startswith(s)}
root.mainloop()
conn.commit()
s = sum(a * b for a, b in zip(list_1, list_2))
list(range(10, 0, -1))
l1.sort()
plt.show()
df.drop_duplicates()
db.session.commit()
main()
list(my_dataframe.columns.values)
a[:, :, ::-1, ::-1]
C = np.sum(A[:, :, :, (np.newaxis)] * B[:, (np.newaxis), :, :], axis=2)
ax1.set_xticklabels([])
b = [x[:] for x in a]
datetime.utcfromtimestamp(timestamp1)
plt.show()
self.button.clicked.connect(self.handleButton)
np.repeat(np.repeat(a, 2, axis=0), 2, axis=1)
new_list.append(f(x))
plt.show()
plt.show()
QtGui.QFrame.__init__(self)
pycurl_connect.perform()
((s.iloc[::2].values + s.iloc[1::2]) / 2).reset_index(drop=True)
list(g)
plt.show()
(vals == (0, 1)).all(axis=1)
np.unravel_index(np.argmax(corr_img), corr_img.shape)
element.click()
plt.show()
writer.writerow(map(quote, row))
time.sleep(0.25)
deletemy_dict[x]
Entry.objects.filter(weekdays=HasBit(WEEKDAYS.fri))
any(a_list)
ftp.set_pasv(False)
d = dict(zip(l, t))
__init__.py
{i[0]: i[1:] for i in list1}
foo(*t)
array = np.fromiter(iter(result.items()), dtype=dtype, count=len(result))
dict(my_list)
ea.Reload()
sorted(items, cmp=comparer)
plt.show()
pd.value_counts(d.values.ravel())
int(list(filter(str.isdigit, str1)))
[(x, y) for x, y in pairs if x != y]
q = Model.objects.filter(Q(field1=f1) | Q(field2=f2))
result[k].append(v)
process.terminate()
print(sys.argv[1])
plt.plot(dat0[:, (0)], dat0[:, (1)])
aapl.index.to_series().diff().median() / (60 * 60 * 10 ** 9)
output = [value for value, count in list(counts.items()) if count > 1]
app.exec_()
plt.figure()
time.sleep(1)
A[0] is A[0]
singleitem = mylist.pop()
data = np.loadtxt(filename, ndmin=2)
min(timeit.repeat(lambda : dict((k, v) for d in (x, y) for k, v in list(d.items()))))
writer.writerows(data)
brr[:] = brr[::-1]
ax.set_xlim(0, 10)
list2b == sorted(list2b, key=lambda c: list1.index(c))
print(sys.argv[1].lower())
A[:, (2)]
plt.show()
ctypes.addressof(bufstr)
sys.stdout.write(RESET)
q = Queue(maxsize=0)
np.concatenate([a[a == i][:2] for i in np.unique(a)])
root.mainloop()
unittest.TextTestRunner().run(suite)
nodebox.__version__
[(x + y) for x, y in l]
urllib.parse.quote(item.url)
new_dict = dict((k, v) for k, v in list(old_dict.items()) if v in allowed_values)
ax.yaxis.tick_left()
func(that, session, *args, **kwargs)
reactor.run()
sum(letterGoodness.get(c, 0) for c in yourstring.upper())
self.button.grid(row=2, column=2, sticky=W)
cs.collections[0].get_paths()
np.any(a == 2, axis=0) & np.any(a == 5, axis=0)
f.pack_propagate(0)
n * factorial(n - 1)
{k: v for k, v in list(metadata.items()) if v}
self.axes = self.figure.add_subplot(111)
s.groupby(s.notnull()[::-1].cumsum()[::-1]).transform(lambda g: g[-1] / g.size)
k, v = list(d.items())[0]
session.query(JT.aID).filter(not_(JT.bID.in_(ids))).all()
datetime.datetime.today().replace(hour=0, minute=0, second=0, microsecond=0)
plt.show()
arr.sum(axis=0, keepdims=True)
print((date_string, dt.date()))
[sum(l) for l in l_o_l]
np.average(list(map(float, meanNumbers.split())))
fig.canvas.draw()
result = set(d[0]).intersection(*d)
plt.show()
self.after(100, self.periodiccall)
df.fillna(0, inplace=True)
[(sum(x) / len(x)) for x in zip(*a)]
instance.__class__.__name__
plt.show()
threading.Thread.__init__(self)
A.shape
d = dict(zip(keys, values))
client.close()
np.repeat(data, data[:, (-1)], axis=0)
print(now.year, now.month, now.day, now.hour, now.minute, now.second)
plt.show()
l = [(2 * x) for x in l]
outfile.write(line)
connection.commit()
line = ser.readline()
self.setLayout(self.layout)
plt.tight_layout()
ax.set_xlim(0, 1)
len(your_list) != len(set(your_list))
ax2.set_zorder(-1)
foo = [{} for _ in range(n)]
list(s)
dict((k, [v[1] for v in itr]) for k, itr in grob)
lambda x: np.dot(A, x) - b
getattr(foo, bar)(*params, **keyword_params)
Html_file.close()
(a > 1) & (a < 5)
f(*args, **kwargs)
ax1.set_xlim(-4, 4)
list(accumu([4, 6, 12]))
plt.show()
np.multiply(a, b[:, (np.newaxis)])
app.run(debug=True)
dev.leds()
df = pd.concat(list_of_dataframes)
y = [int(val) for val in x]
plt.plot(x, y)
np.where(np.any(a == 2, axis=0) & np.any(a == 5, axis=0))
my_list = list(range(1, 1001))
sorted(L, key=operator.itemgetter(1))
threading.Timer(2, interrupt).start()
list(itertools.chain(*lst))
np.arange(new[0]) % old[0]
app.run()
driver.quit()
print(len(path) - 1)
print(b[0])
[(2, 5), (12, 17)]
print(df.loc[i].reset_index())
B = np.reshape(A, (-1, ncols))
writer.writerows(a)
df = df.drop_duplicates()
mylist.insert(0, mylist.pop(5))
f = lambda x: x * 2
f.close()
ax.plot(x, y)
plt.show()
answer.extend(map(str, list(range(int(start), int(end) + 1))))
make_adder(5)
pyplot.show()
list(filter(func, data))
plt.show()
df = pd.DataFrame(data)
{k: d1[k] for k in set(d1).intersection(l1)}
nx.topological_sort(G)
x = x.split()
sys.stdout.close()
f.close()
[(x, y) for x in L for y in L]
c = random.choice(a)
d = datetime.today() - timedelta(days=days_to_subtract)
L.sort()
time.sleep(60)
driver.quit()
plt.show()
print(ZipFile(path).namelist())
assertTrue(text in self.driver.page_source)
np.in1d(a[:, (2)], list(b))
df.loc[mask]
{k: v for k, v in list(d1.items()) if k in l1}
help(bar)
setattr(self, key, kwargs[key])
L[i:i + 2] = reversed(L[i:i + 2])
user.save()
pylab.text(max_x, max_y, str((max_x, max_y)))
deletefoo.fields[-1]
df = pd.read_csv(filename, error_bad_lines=False)
results.setdefault(i, []).append(benchmark(i))
pivoted.cumsum()
plt.show()
list(str(n) for n in range(10))
pool = mp.Pool(processes=1)
A[B == 1.0].sum()
print(s[1:])
br.set_handle_referer(True)
plt.show()
l = [dict(zip([1], [x])) for x in range(1, 100)]
cv2.destroyAllWindows()
sys.exit(app.exec_())
pkl_file.close()
list(gen_items())
any(map(lambda v: v in list2, list1))
print(some_object.__repr__())
np.where((A > 2) & (A < 8))
print(et.tostring(tree))
HttpResponse(json.dumps(data))
sys.exit(0)
app.debug = True
s.getvalue()
ax.set_yticks(ax.get_yticks()[:-1])
pool.terminate()
a, b, c = func()
[(1, 2)]
numpy.logical_not(array)
json.dumps(dict(foo=42))
print(sorted([Card(c[0], c[1]) for e in a for c in e]))
print(json.dumps(data, indent=4))
myf.close()
plt.scatter(x, y, color=next(colors))
root.mainloop()
len(s) - len(s.lstrip())
map(s.__setitem__, a, m)
plt.show()
f([1, 1, 2], [1, 1])
cls.dosomethingelse()
ax.set_ylim(ylim)
WSGIApplicationGroup % {GLOBAL}
yourmodule.py
plt.show()
unittest.main()
fig.subplots_adjust(hspace=0.5)
output.write(new_line)
a = numpy.array(b)
painter.restore()
globals()
driver.switch_to_window(window_after)
f.close()
ax2.set_rlim([0, 1])
ax.xaxis.set_major_formatter(formatter)
total = sum(int(v) for name, v in table)
plt.show()
sys.exit(0)
np.hstack(np.meshgrid(*L)).swapaxes(0, 1).reshape(ndims, -1).T
[(sum(group) / size) for group in zip(*(data[x::size] for x in range(size)))]
print(os.lseek(fd, 0, os.SEEK_CUR))
plt.show()
list(product([a, b, c, d], [x]))
a.sum(1) / (a != 0).sum(1)
webdriver.Firefox(firefox_profile=fp)
sum(1 for x in l if x)
plt.show()
print(chr(4))
sys.stdout.flush()
pd.concat([data, ts]).sort_index().interpolate()[ts.index]
math.sqrt(x)
lambda x, y: (x + y, x - y)
json.dump(data, fp, sort_keys=True, indent=4)
ax.xaxis.set_minor_locator(mdates.MonthLocator())
print((lbl.winfo_width(), lbl.winfo_height()))
a[np.mod(np.arange(a.size), 4) != 0]
np.where(np.isclose(a, val, tol))
ax.plot(x, y)
do_stuff()
root.mainloop()
print(p.communicate(answer)[0])
session.commit()
widget.show()
plt.show()
[p for p in process_list if all(e not in p for e in exclude_list)]
plt.show()
num_list[-9:]
map(f, my_list)
plt.tight_layout()
self.redirect(newurl)
np.vstack([np.array(u) for u in set([tuple(p) for p in points])])
d = dict((m.get(k, k), v) for k, v in list(d.items()))
[rex.split(i) for i in sequence_list]
D[(idx), :]
db.session.commit()
hash(repr(d))
unittest.main()
{d[0]: d[1:] for d in data}
np.delete(a, list(range(0, a.shape[0], 8)), axis=0)
list(reversed(sorted(a.keys())))
dict((v, v ** 2) for v in l)
ax.xaxis.set_minor_locator(minor_locator)
print(today.replace(year=today.year + 1))
pd.concat([s, pd.rolling_mean(s, window=4, min_periods=1)], axis=1)
self.button[i].grid(sticky=W + E + N + S, row=row, column=col, padx=1, pady=1)
time.sleep(5)
np.tensordot(a, b, axes=1)
(df - 0.2).round()
print(etree.tostring(root))
plt.show()
im = Image.open(f)
df.mask(np.random.choice([True, False], size=df.shape, p=[0.2, 0.8]))
[x for x in l1 if tuple(x) in intersection]
a, b = 5, 8
subprocess.Popen(cmd, shell=True, stdout=f, stderr=f)
ct.reindex_axis(a_x_b, axis=1).fillna(0)
print(a[1][1])
sum(1 + count(i) for i in l if isinstance(i, list))
print(func(*args))
np.random.shuffle(dataset)
map(dict, list(dict(sorted(map(sorted, map(dict.items, s)))).items()))
plt.show()
df.fillna(df.mean())
app.run(threaded=True)
a.split()
plt.show()
sys.exit(1)
print(m.group())
max(index for index, value in data if value == max_value)
mylist.sort(key=lambda val: SORT_ORDER[val[1]])
row.append(row[0])
[name for name in names if any([(p in name) for p in pattern])]
count = np.all(listScore == np.array([2, 0]), axis=1).sum()
plt.show()
list(filter(func, data))
arr = np.arange(10).reshape(5, 2)
random.shuffle(data)
plt.show()
f.seek(0)
max(s, key=lambda x: x.arity())
writer.writerow(row + [row[0]])
x = np.fromfile(f, dtype=np.int)
sys.stdout = old_stdout
pd.to_timedelta(df)
sys.exit(1)
np.all(a == b)
a.take(np.arange(1, 2), axis=1)
f.close()
dict((x, a.get(x, 0) + b.get(x, 0)) for x in set(a) | set(b))
base64.urlsafe_b64decode(uenc)
my_func.__doc__
b.widget().deleteLater()
dis.dis(withlocals)
np.isclose(a, b)
cleaned_list = [_f for _f in some_list if _f]
self.matches = [s for s in self.options if text in s]
pylab.show()
lst = [float(x) for x in lst]
[tuple(g[1]) for g in itertools.groupby(enumerate(l), lambda i_x: i_x[0] - i_x[1])]
wr.writerows(RESULTS)
ax.set_ylim([-10, 10])
np.hstack((test, test[:, ([0])]))
cursor.execute(sql, args)
result = list([_f for _f in orig if _f])
self.root.after(1, self.openfile)
functools.partial(self, obj)
matrix[0].pop()
foo()
plt.show()
file.close()
deleteL[:]
next(g)
[(a + b) for a, b in zip(A, B)]
time.sleep(0.1)
time.sleep(interval)
time.sleep(1)
buckets = [[(0) for col in range(5)] for row in range(10)]
load_source(module_name, path_to_file)
1, 0, 0, 1, 0, 0, 1, 0, 0
set(map(frozenset, lst))
print(list(csv.reader(f)))
bin(8)
plt.show()
g0.plot()
a[:1000] = [0] * 1000
items.sort()
s1.combine_first(s2)
A[tuple(rc1)], A[tuple(rc2)] = A[tuple(rc2)], A[tuple(rc1)]
plt.legend()
[list(g) for _, g in groupby(bool_array)]
df = df.divide(df.sum(axis=1), axis=0)
sys.stdout.flush()
[word for word in l if word.isalpha()]
np.array([np.where(np.in1d(array, matched))[0] for array in arrays])
print(len(set(map(len, my_lists))) <= 1)
sys.stdout.flush()
dict(d)
process.close()
list = [(str(a[i]) + str(b[i])) for i in range(len(a))]
deleted[max(d, key=d.get)]
ax.margins(0.1, 0.1)
[i for i, (l1, l2) in enumerate(zip(list1, list2)) if l1 >= 1 and l2 == 0]
db.session.commit()
plt.show()
{k: list(g) for k, g in groupby(sorted(l, key=len), len)}
x[np.isnan(x)] = 0
fig.subplots_adjust(wspace=0)
ax2.set_xticklabels([])
df.drop_duplicates()
a[[[0] * 5, [1] * 5], index]
button.click()
ax.set_ylim((valmin, valmax))
np.delete(a, [2, 4, 5])
im.show()
cv.CvtColor(img, gray, cv.CV_BGR2GRAY)
x[2:6] = []
driver = webdriver.Chrome(chrome_options=chromeOptions)
sys.exit(main(sys.argv))
self.assertEqual(json.loads(call_args[0]), expected)
plt.show()
a[numpy.nonzero(numpy.in1d(a, b))]
pickle.dumps(data, 0)
self.Bind(wx.EVT_LEFT_DOWN, self.OnLeftDown)
exit(0)
any(c.isalpha() for c in string_2)
sum(map(int, zip(*table)[-1]))
self.legend.figure.canvas.draw()
[[] for _ in range(2)]
{k: mylist.count(k) for k in set(mylist)}
sum(val for val in l1 if isinstance(val, numbers.Number))
sum(counter_list, Counter())
plt.show()
x.astype(int)
sys.executable
sys.stdout.flush()
con.commit()
logging.Handler.__init__(self)
pdb.set_trace()
ax.xaxis.set_major_locator(ScaledLocator(dx=6))
result = sum(timedeltas, datetime.timedelta())
ts[datetime(2011, 1, 8):][0]
(CENTROIDS - x.mean()) / x.std()
cv.CvtColor(cv_img, cv_img, cv.CV_RGB2BGR)
sys.stdout.flush()
print([((a + b) / 2) for a, b in zip(data[::2], data[1::2])])
session.commit()
cv2.destroyAllWindows()
[a for a, b in zip(nums, nums[1:] + [not nums[-1]]) if a != b]
django.setup()
ax.bar(list(range(len(dates))), values)
plt.show()
sys.exit(0)
bool(list(someDict.keys()) & set(someSet))
dist = math.hypot(x2 - x1, y2 - y1)
rdd1.cartesian(rdd2)
someclassname.ask()
plt.show()
a.sort(key=lambda x: x[0])
[e for e in lelist if e in lestring]
pygame.draw.circle(screen, (0, 0, 0), (100, 100), 15, 1)
np.where(np.all(np.all(win_img == pattern, axis=-1), axis=-1))
MyModel.objects.filter(pk=instance.id).update(**data)
log.setLevel(logging.DEBUG)
d = dict(zip([o.name for o in object_list], object_list))
f.read()
time.sleep(10)
subprocess.call(args, stdout=FNULL, stderr=FNULL, shell=False)
[t for t in enumerate(l)]
plt.xlim(-2 * np.pi, 2 * np.pi)
[np.ma.array(arr, mask=~c).argmax() for c in cond]
a = [1, 2]
print(cls.__name__)
lst.sort()
dict((k, v) for k, v in dictionary.items() if begin <= k <= end)
FO.close()
print(args)
[y for y in x for x in data]
y = [x for x in list(dict.keys()) if dict[x] > 0.0]
print(a[key])
qs.distinct()
b = [a.ix[i] for i in a.index if sorted1[i] >= sorted2[i]]
bids.sort(key=int, reverse=True)
[v for k, v in enumerate(mylist) if k % 2 == 0]
mydict[new_key] = mydict.pop(old_key)
setattr(self, key, value)
a = dict.fromkeys(list(range(n)))
plt.show()
np.in1d(data, np.hstack(test)).reshape(data.shape)
(len(word) for word in wordslist)
self.data += self.ser.read()
main()
ws.add_image(img)
df.reset_index(level=1, drop=True, inplace=True)
df.stack()[df.stack().values == 1].reset_index()
urllib.parse.quote_plus(a)
any(char.isdigit() for char in s)
ax.yaxis.set_ticks([0, 2, 4, 8])
bttn_0.grid(row=5, column=0, pady=5, columnspan=2)
driver = webdriver.Firefox(firefox_profile=profile)
d = dict((str(n), list(range(20))) for n in range(1000000))
df.T.drop_duplicates().T
pylab.show()
lines.sort(key=lambda x: int(x.split()[0]))
[0] + [(i + 1) for i in [4, 9, 12, 14, 18]] + [len(bool_array)]
datetime.datetime.combine(tdate, datetime.time())
subprocess.call(my_cmd, stdout=outfile)
x = np.random.randint(0, 20, 1000000)
pd.isnull(df).any(1).nonzero()[0]
plt.plot(x, y)
print(pix[x, y])
app.debug = True
os.path.abspath(checkIP.__file__)
pprint.pprint(obj)
client.set_option(new_url)
A[0:4][1]
re.sub(pattern, replacement, text)
master.grid_columnconfigure(0, weight=1)
root.mainloop()
plt.show()
ast.literal_eval(some_string)
a.__getitem__(slice(0, 1)).__setitem__(0, 5)
bids.append(bid)
os.path.dirname(os.path.dirname(file))
Thread(target=p.start).start()
list(foo)
os.remove(f)
((m.get(k, k), v) for k, v in list(d.items()))
ax.xaxis.set_major_formatter(tkr.FuncFormatter(formatter))
y = x.subs({a: b, b: a}, simultaneous=True)
writer.writerow(row)
OrderedDict((k, queue[key]) for k in key_order)
my_model.save()
[{y: x[y].lower()} for x in messages for y in x]
integer.setParseAction(lambda t: int(t[0]))
[list(x) for x in a_strpadded]
print(np.where(a == a.min()))
[item for item in l for repetitions in range(2)]
[x for x in matrix if x[2] == 1.0]
[min(j) for i, j in itertools.groupby(A, key=lambda x: x[:7])]
urllib.request.urlretrieve(stream_url, target_path)
d.update((k, v * 0.5) for k, v in list(d.items()))
plt.show()
res = os.system(sys.argv[1], sys.argv[2])
signal.signal(signal.SIGINT, signal_handler)
self.Bind(wx.EVT_PAINT, self._onPaint)
fcntl.flock(g, fcntl.LOCK_UN)
print(json.dumps(json.loads(json_string)))
[listofLines[i] for i in sortedIndex]
plt.show()
numpy.zeros((10, 4, 100))
br.set_response(resp)
[b.append(item) for item in a if item not in b]
time.mktime(d.timetuple())
(n + 1) ** 2 == n ** 2 + (2 * n + 1)
sys._getframe().__code__.co_argcount
gems.add(gem)
dict(zip(keys, values))
session.close()
sys.exit(app.exec_())
split_str.groupby([0, 1])[2].apply(fnc)
sys.stdout.flush()
myfile.write(buffer(c_uncompData_p.raw, 0, c_uncompSize))
np.asarray(t)
pd.DataFrame(series_data, columns=series_name)
plt.show()
sys.getsizeof(x)
myl[:] = [(x if x != 4 else 44) for x in myl]
df.mycolumn.map(func)
appcfg.py
app.MainLoop()
cmap(np.linspace(0.2, 0.8, 100))
self._driver.quit()
len(a) - len(a.lstrip())
plt.show()
self.append(x)
sorted(l) == list(range(min(l), max(l) + 1))
file_obj.seek(0)
print(get_ip())
plt.show()
grouped.apply(wavg)
results = cursor.fetchone()
s.lower()
map(ord, s)
app.run(port=0, debug=True)
plt.show()
a[:, (b)]
sorted(L, key=operator.itemgetter(1))
len(mylist) - mylist[::-1].index(myvalue) - 1
len(s)
plt.show()
self.grid_columnconfigure(0, weight=1)
n = str(input())
map(sum, l) == [n] * len(l)
f.write(content)
mratings.mean(axis=1)
plt.show()
plt.show()
fu_list = [(k, fus_d.get(k), fus_s.get(k)) for k in s]
np.sum(c[:, 1:] == c[:, :-1], axis=1)
sum(n * (n - 1) // 2 for n in list(index2count.values()))
p[0], p[1]
MyClass.Property1
a = [int(x) for x in input().split()]
p.getfitness()
[6, 5, 1]
json.dumps(list)
f(*args, **kwargs)
df_test.iloc[0]
pdb.set_trace()
cv2.drawContours(image, [ctr], 0, (255, 255, 255), 1)
np.random.seed(0)
df.head()
sorted(iter(d.items()), key=operator.itemgetter(1))
list(range(0, 100 + 1, 5))
sorted(a, key=lambda x: order_dict[x[0]])
plt.show()
plt.draw()
plt.show()
p.terminate()
root.config(menu=menu)
np.argwhere(np.isnan(x))
[ks[i] for i in range(len(ks)) if i == 0 or ks[i] != ks[i - 1]]
print(df.applymap(lambda x: str(x).isdigit()).T)
re.findall(p, test_str)
sum(x ** 2) * (x[1] - x[0])
json.dump(data, jsonFile)
(x * 2 for x in [2, 2])
a = [i[0] for i in sorted(zip(a, ind), key=lambda x: x[1])]
plt.show()
json.dumps(cls=MyEncoder)
do_stuff()
print(a[:, (0)])
template.render(context)
workbook.close()
arr[np.argsort(arr[:, (1)])]
result = datetime.datetime.now() - datetime.timedelta(seconds=X)
list.__setitem__(index, value)
test_df.where(test_df >= 4)
zip([a, b, c, d], repeat(x))
session.query(RssFeed).get(1)
new_list
plt.show()
sorted(set(mylist), key=lambda x: mylist.index(x))
random.shuffle(x)
os.system(cmd)
lasts.append(bpos)
df.agg(*[count(c).alias(c) for c in df.columns]).show()
array([0, 2, 1], dtype=int64)
m.group(1)
logging.getLoggerClass().root.handlers[0].baseFilename
np.digitize([1.5], a, right=True)[0]
math.sqrt((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2)
result = max(iter(your_dict.items()), key=operator.itemgetter(1))[0]
items = sorted(list(ipCount.items()), key=lambda item: socket.inet_aton(item[0]))
myA[(myA > val).nonzero()[0][:2]] = 0
isinstance(a, Test1)
server.quit()
dict((k, mydict[k]) for k in keys_to_select)
[((index % 8 + 2) * item) for index, item in enumerate(range(1, 21))]
df.convert_objects(convert_numeric=True)
(lambda a, b: a(a, b))(lambda a, b: b * a(a, b - 1) if b > 0 else 1, num)
sys.getsizeof(s)
list(itertools.chain.from_iterable(a))
df
app.mainloop()
writer.writerows([[item] for item in new_text_list])
list(set(dict_a.values()).intersection(list(dict_b.values())))
[my_tuple[isinstance(x, str)].append(x) for x in a_list]
[[f for f in family if f != i] for i, family in enumerate(families)]
print(f())
ax.yaxis.set_major_locator(yloc)
os.path.dirname(str(__file__, encoding))
plt.show()
print(p.communicate()[0])
numpy.dstack((A, B)).transpose(0, 2, 1).reshape(A.shape[0] * 2, A.shape[1])
{{request.META.HTTP_NAME}}
all(x == mylist[0] for x in mylist)
ax.xaxis.set_major_locator(ticker.LogLocator(base=1000.0))
Counter(elem[0] for elem in list1)
time.sleep(1)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
slice = arr[0:2, 0:2]
a.reshape(-1, m / k, k).swapaxes(0, 1).reshape(-1, k)
df.append(row, ignore_index=True)
result = sum(some_list[1:])
res = [(i if i < 4 else 0) for i in range(1, 6)]
print(ET.tostring(root))
plt.show()
indices = np.where(np.in1d(x, y))[0]
get_keyring()
print([x for x in a if x in b])
new_dict.setdefault(v, []).append(k)
np.sum(boolarr)
form = UserForm(user=request.user)
file.close()
my_dataframe.columns.values.tolist()
[k for k in seq if counts[k] == 1]
result = [r for r in x if not any(z in r for z in y)]
sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq)
df.applymap(np.isreal).all(1)
self.Bind(wx.EVT_SIZE, self.OnSize)
print(f.readlines())
db.CommitTrans()
list(im.getdata())
plt.show()
[(x + y) for x, y in zip(string, string[i:])]
np.array(a)
cherrypy.session.regenerate()
list_of_lists = [[] for _ in columns]
print(recursive_dict_eval(my_dict))
plt.tight_layout()
list(conn.execute(query).keys())
nf.write(str(random.randint(0, 1000)))
plt.show()
set(itertools.permutations(lst))
pipe.close()
datetime.timedelta(0, 540)
t.start()
f = lambda x, y: x[0] + x[1] + (y[0] + y[1])
os.path.abspath
df = pd.concat(dfs)
ax.set_xticks(xticks)
db.session.commit()
numpy.array([sub_array for sub_array in counts_array])
mysocket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
self.Bind(wx.EVT_CHAR_HOOK, self.onKey)
t = s.reshape(-1, 2)
{{(news.description | truncatewords): 50}}
sum(map(sum, input))
plt.show()
list(range(2, 2))
list1.sort(key=int)
sys.stdout.flush()
cluster.fit(X)
print(et.tostring(tree, pretty_print=True))
print({k: v for k, v in mime_types.items()})
fig.tight_layout()
QtWidgets.QMainWindow.__init__(self, parent)
list(filter(os.path.isdir, [os.path.join(d, f) for f in os.listdir(d)]))
print(np.array(list(mystr)))
conn.close()
print(json.dumps(info))
print(list(range(n, (m + 1) * n, n)))
set(mylist)
plt.colorbar()
pyplot.show()
print(is_cardano_triplet(2, 1, 5))
btn.grid(column=x, row=y, sticky=N + S + E + W)
a.__class__.print_x(b)
model.fit(X, y)
keep.update(yoursequenceofvalues)
df.groupby(lambda x: x, axis=1).sum()
ax.xaxis.set_major_formatter(mdates.AutoDateFormatter(locator))
image.save(image_out_path)
main()
res = pd.DataFrame(json.loads(out))
l = list(gen_items())
mymodel.objects.get(pk=a[i])
[int(t) for t in (True, True, False)]
config.write(configfile)
frame.pack()
logger.setLevel(logging.DEBUG)
df[df.columns[2]]
sorted(x) == sorted(y)
plt.show()
logging.getLogger().addHandler(logging.StreamHandler())
time.sleep(1)
data = [([0] * cols) for i in range(rows)]
s.start()
urllib.request.urlopen(req)
frw.close()
plt.show()
pool.apply_async(test, (t,), dict(arg2=5))
profile.save()
np.logical_or(np.logical_or(x, y), z)
df = df.astype(str)
good_data = data[:, (data[0] == 1)]
(x.count(item) for item in set(x))
[_f for _f in lis if _f]
df = pd.read_sql(query.statement, query.session.bind)
w.pack()
con.commit()
root.mainloop()
list(OrderedDict.fromkeys(my_list))
arr[np.isnan(arr).cumsum(1) > 0] = np.nan
y = numpy.r_[0, x[:-1]]
[item for item in full_list if all(x not in omit for x in item)]
df = df[df.line_race.notnull()]
self.thread.start()
time.sleep(1)
isinstance(s, str)
img[..., ::-1]
app.mainloop()
(x * sin(y)).subs([(x, y), (y, x)], simultaneous=True)
df.append(duplicates).sort_index()
set(second_list).difference(map(f, first_list))
df.drop(remove, axis=1, inplace=True)
f.apply(clean, axis=1)
max((v, i) for i, v in enumerate(a))[1]
self.a, self.b = a, b
self.grid_columnconfigure(1, weight=1)
conn.commit()
print(datetime.now())
np.sum(np.abs(x) ** 2, axis=-1) ** (1.0 / 2)
pylab.show()
logging.getLogger().addHandler(handler)
cnxn.commit()
datetime.date(2015, 8, 9).isocalendar()[1]
br.set_handle_equiv(True)
combs.extend(els)
ax.set_ylim(0, 1)
datetime.datetime.now() - datetime.timedelta(minutes=15)
np.random.uniform(-10, 10, size=(1, 5, 1))
dict((key, getattr(self, key)) for key in keys)
df = pd.concat([pd.read_sql_query(q, connection) for q in queries])
np.array([x for x in set(tuple(x) for x in A) & set(tuple(x) for x in B)])
{{d.content}}
np.array([[0], [1]])
bytearray(100)
[0, 1, 0, 1, 0, 1, 0, 1, 0, 1],
conn.commit()
results = [int(match.group(1)) for match in matches]
root.mainloop()
os.uname()[1]
f.write(etree.tostring(root, pretty_print=True))
[val for i, val in enumerate(values) if i not in indices]
[some_string[i:i + 2] for i in range(0, len(some_string), 2)]
termios.tcsetattr(sys.stdin, termios.TCSADRAIN, old_settings)
ds.to_netcdf(new_file)
cython.uchar
plt.show()
zf.close()
a[:, :, ([5])].shape
tuple(x for sublist in base_lists for x in sublist)
expense.save()
urllib.parse.unquote(url)
pygame.display.flip()
plt.show()
conn.commit()
pd.DataFrame([data])
admin.site.register(User, UserProfileAdmin)
list(groupings.values())
np.argmin(df.applymap(np.isreal).all(1))
list(flatten(a))
df.max() > 0
plt.show()
print(et.tostring(tree, pretty_print=True))
max(array.flatten())
df.append([df_try] * 5, ignore_index=True)
result = [i for k, g in groupby(lst, bool) for i in ((sum(g),) if k else g)]
plt.show()
my_process.kill()
print(linalg.solve(A, x))
[s[i:i + 2] for i in range(0, len(s), 2)]
data = request.stream.read()
sum(delta_list, timedelta()) / len(delta_list)
data = (float(row[1]) for row in incsv)
[1, 2, 1, 1, 2, 1, 2, 2, 1, 2]
time.sleep(0.001)
db.session.commit()
sys.exit(app.exec_())
ax2.yaxis.set_major_locator(matplotlib.ticker.LinearLocator(nticks))
plt.show()
sys.stdout.write(line)
time.sleep(0.1)
print(new_func.__name__)
plt.show()
lambda x, i=i: x % i == 0
obj = result.json()
root.mainloop()
exit()
self.view.setModel(model)
conn.commit()
np.dot(a, b)
print(json.loads(json_string))
a[np.arange(a.shape[0])[:, (np.newaxis)], i]
pyplot.plot([point[0], point2[0]], [point[1], point2[1]])
MyApp().run()
c = b[1:]
pool = multiprocessing.Pool(2)
ax1.set_yticklabels([])
subprocess.call(cmd)
set(pd.DataFrame(df.genres.tolist()).stack().tolist())
array([0, 7, 1, 0, 4, 0, 0, 0, 0, 1, 0, 0, 0])
np.ravel_multi_index(X.T, dims)
[x for t in zip(*lists) for x in t]
print(np.sort(np.partition(y, -10, axis=1)[:, -10:], axis=1))
df.index.get_loc(ds)
[entry for tag in tags for entry in entries if tag in entry]
outputfile.close()
pd.concat([s1, s2], axis=1)
cipher.decrypt(base64.b64decode(text))
len(set(map(len, (a, b, c)))) == 1
list(bin(6)[2:])
self.Bind(wx.EVT_ENTER_WINDOW, self._onMouseEnter)
sorted(top_n, key=lambda t: (-t[1], t[0]))
setattr(self, key, initial_data[key])
b.__class__.__class__
soup = BeautifulSoup.BeautifulSoup(html_string)
[item for item in l for _ in range(r)]
yaml.dump(dataMap, f, default_flow_style=False)
rdd = df.rdd.map(list)
d += dt.timedelta(days=1)
root.destroy()
[1, 0, 1, 0, 1, 0, 1, 0, 1, 0],
ax6.set_yticks(np.linspace(0, 1, 7))
print(df.to_html())
[(n - 9 * int((n - 1) / 9)) for n in list1]
requests.post(url, params=params, data=json.dumps(data), headers=headers)
c = dict(a, **b)
array([[[4, 5], [12, 14], [24, 27]], [[0, 0], [6, 7], [-8, -9]]])
plt.show()
df[(df.a > 0) & df.index.isin([0, 2, 4])]
f.close()
plt.show()
sort(data, key=datekey, reverse=True)
time.sleep(1)
profile.save()
plt.show()
sys.stdout = self._stdout
session.commit()
c = [x[0] for x in A]
json.dumps(o)
sorted(unsorted_list, key=order.__getitem__)
self.lc.Bind(wx.EVT_LIST_BEGIN_DRAG, self.onDrag)
[(A[x], B[x % len(B)]) for x in range(len(A))]
value = list(d.values())[index]
plt.show()
pattern.match(string)
g.add_nodes_from(l)
np.log(df / df.shift())
br.set_cookiejar(cj)
plt.show()
time.sleep(2)
l[len(l):-len(l) - 1:-1]
sum(1 for _ in iterable)
df = pd.DataFrame(list_of_series, columns=cols)
d = {k: (lambda s, k=k: s * A[k]) for k in range(n)}
ax1.set_xlim([0, 5])
signchange[0] = 0
[(p[0], sum(p[1:]) / 2.0) for p in PlayerList]
plt.show()
set(a).intersection(b)
df.merge(s.to_frame(), left_index=True, right_index=True)
[[i for i in sublist if counts[i] == 1] for sublist in mylist]
np.matmul(a, b)
buckets = [[0] * 100] * 100
ax.set_ylim(-5, 5)
next((a for a in s if s.count(a) == 1))
bigList.sort(key=operator.itemgetter(*args))
print(sum(1 for elem in list1 if elem[0] == entry[0]))
map(tuple, map(flatten, zip(a, b, c)))
print(etree.tostring(root, pretty_print=True))
finder.score_ngrams(bigram_measures.pmi)
print(np.nanmean(arr, axis=0))
ivd = dict((v, k) for k, v in list(d.items()))
a[np.arange(np.shape(a)[0])[:, (np.newaxis)], np.argsort(a)]
keys = set(l1).intersection(d1)
df = pd.concat([df, dummy_df], axis=1)
doc.toxml()
isinstance(fn, collections.Callable)
df.reindex(prev_dates.union(df.index))
foo.save()
len(words)
MainWindow.show()
map(centroids.__delitem__, sorted(index, reverse=True))
a = [0, 1]
testDf.iloc[:, 1:].stack().groupby(level=0).nunique()
np.where(np.all(a == b, axis=1))
s = set(lst)
plt.show()
print([item for item, count in list(collections.Counter(a).items()) if count > 1])
outfile.writelines(lines)
iqr = np.subtract(*np.percentile(x, [75, 25]))
product([[1, 2], [4, 5]])
print({k: round(v) for k, v in x.items()})
array([[1, 0, 1], [2, 0, 1]])
Foo.allocate_ids(max=26740080011050)
sys.exit(test())
hex(random.randint(0, 16777215))[2:].upper()
numpy.vstack((a, b, c)).T
server.serve_forever()
B = list(A[0])
b = [x for x in a if x not in itemsToRemove]
plt.show()
df = pd.DataFrame(df_dict)
root.mainloop()
args = parser.parse_args()
plt.show()
d.setdefault(x, []).append(y)
json.JSONEncoder.default(self, obj)
(x - y for x, y in it.izip(a[1:], a))
c = a[(np.searchsorted(a[:, (0)], b)), :]
np.concatenate([[88], a, [77]])
plt.show()
plt.show()
pylab.show()
time.sleep(0.01)
plt.show()
r.setdefault(key, []).append(lst2dct(val))
admin.site.register(Email, EmailAdmin)
len(arr)
print(element.tag, element.text, element.tail)
app.exec_()
reactor.run()
help(assign2)
d = dict([(k, v) for k, v in zip(l[::2], l[1::2])])
np.array([[d[str(i)], d[str(j)]] for i, j in A])
self.response.out.write(simplejson.dumps(data))
tst.save()
list(range(0, 10, 2))
df[(df[[0, 1]] > 0).all(1)]
cnxn.commit()
df.where(~outliers_low, down_quantiles, axis=1)
datetime.datetime(*d.timetuple()[:6])
GC.remove_edge(clique[0], clique[1])
ax1.set_ylim(0, 1)
gca().xaxis.set_major_formatter(xfmt)
myMethod(myVariable, *myTuple)
print(np.unravel_index(result.argmax(), result.shape))
ipdb.set_trace()
plt.show()
cursor = conn.cursor(MySQLdb.cursors.DictCursor)
np.fill_diagonal(out, np.diag(A))
b = [list(x) for x in b_set]
ax.plot(x, y)
json.dumps(o)
x ** 2 + 1
ax.yaxis.set_major_formatter(mpl.ticker.FuncFormatter(mjrFormatter))
msg.send()
print(somefake.readlines())
C = [[(0) for row in range(len(A))] for col in range(len(B[0]))]
db.Close()
ax.get_xaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())
pd.DataFrame(data, tid1, ucat)
file = forms.FileField(required=False)
logging.getLogger(__name__).setLevel(logging.WARNING)
my_dict = {k: [] for k in keys}
input_seq[ix1], input_seq[ix2] = input_seq[ix2], input_seq[ix1]
math.sqrt((p0[0] - p1[0]) ** 2 + (p0[1] - p1[1]) ** 2)
app.mainloop()
ax.scatter(x, y)
d = {c: i for i, c in enumerate(ascii_lowercase, 1)}
conn.commit()
self.assertTrue(issubclass(QuizForm, forms.Form))
cursor.execute(sql, args)
conn.execute(sql, list)
dict_compare(dict_a, dict_b)
np.arange(new[1]) % old[1]
root.mainloop()
aapl.index.to_series().diff().mean() / (60 * 60 * 10 ** 9)
shapesMatch([(0, 0), (1, 0), (1, 1), (2, 1), (2, 2), (0, 2)], l_shape)
(my_array[:, (np.newaxis)] == my_array).all(axis=2).sum(axis=1)
[d[k] for k in lst]
[i for i, x in enumerate(t) if x]
traceback.print_stack()
time.sleep(1)
Entry.objects.bulk_create([Entry(id=x) for x in list])
jsonify(json_list=qryresult.all())
dict(a)
print(soup.prettify())
{{myexample}}
b = dict(zip(i, i))
self.transport.write(self.message.encode())
np.sort(m)[:, -N:]
array([[4, 5], [1, 4]])
foo.__class__.__class__
set(listA) & set(listB)
dict(list(x.items()) | list(y.items()))
[e for l in lst for e in l]
[y for y in listOfLists if y[x].isdigit()]
result.append(os.path.join(root, name))
setattr(self, pointer, group)
plt.ylim(-6, 6)
a[[0, 1], [1, 2], 2]
raise NotImplementedError()
sum(1 for _ in takewhile(lambda x: x == a[0], a))
i = int(math.floor(x) - 1)
[(x, y) for x, y, label in data_one]
pprint(dict(grouped_by_soundex))
portalocker.lock(file, flags)
print(m.group(1))
hand = {k: v for k, v in hand.items() if v != 0}
ftp.quit()
nx.draw_networkx(G)
pl.show()
f = open(os.path.join(sub_dir, file))
[[copy.deepcopy(foo) for x in range(10)] for y in range(10)]
dict((x1, (x0, x2)) for x0, x1, x2 in zip(x[:-2], x[1:-1], x[2:]))
df.div(df.sum(1), axis=0)
image = cv2.cvtColor(image, cv2.cv.CV_BGR2RGB)
dill.pickles(f)
m = sqrt(a ** 2 + b ** 2)
plt.show()
sys.stdout.close()
df.reindex(df.index.drop(1))
x[index] if len(x) > index else default
self.show()
cursor.execute(query_insert, data * 2)
canvas.config(scrollregion=canvas.bbox(ALL))
list(itertools.chain(*list(foo.values())))
plt.show()
logging.handlers.pop()
result = [numbers[i] for i in indices]
Hsub = H[1:H.shape[0] - 1, 1:H.shape[1] - 1]
logging.config.stopListening()
ax.plot(list(range(10)), list(range(10)))
[0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]
app.run(debug=True)
random.seed(SEED)
plt.show()
print(proc.stdout.readline())
pd.DataFrame(L)
plt.show()
cursor.execute(sql, (val1, val2))
random.choice(string.ascii_letters)
User.query.filter_by(**kwargs)
array([0, 1, 0, 0])
df.drop(df.columns[[1, 69]], axis=1, inplace=True)
a = np.delete(a, zero_row, 0)
file_writer.writerow([x[i] for x in lol])
g.filter(lambda x: len(x) > 1)
df.T.groupby(level=0).first().T
[[0, 1, 0], [0, 0, 1], [0, 1, 0], [1, 0, 0], [0, 1, 0]]
tornado.ioloop.IOLoop.instance().start()
[sympy.diff(sum(m * m.T), i) for i in m]
arr[[2, 1]]
t.start()
np.in1d(fake, [0, 2, 6, 8]).reshape(fake.shape)
thread.start_new_thread(interrupt_user, ())
requests.post(url, data=data)
sys.stdout.flush()
5.55 % 1
json_string = json.dumps(row)
s.flush()
sys.stdout.flush()
plt.show()
len(os.listdir(directory))
print(socket.gethostbyname_ex(socket.gethostname())[2])
cgi.parse_qs(qs)
all(0 < n < 50 for n in thetuple)
list_of_nums[:] = [x for x in list_of_nums if x != 2]
lambda m: replacement_dict.get(m.group(), m.group())
sum([i for i in l1 if isinstance(i, int)])
[[k, len(list(g))] for k, g in groupby(strs)]
ax1.set_yticks([int(j) for j in range(0, 4)])
plt.subplot(122), plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
im = cv2.imread(path, -1)
zip(xnew[1:], ynew[1:])
f = lambda x, a=a: x ** a
pygame.mixer.music.play()
django.setup()
datetime.date.today()
zip(*filterer(list1, list2))
max(l1, l2, key=len)
numpy.sqrt(numpy.sum((A - B) ** 2))
ax.plot(x, y, z)
__init__.py
np.argsort(K)[-5:]
getattr(module_a, mod)()
c[a & b]
output_file.close()
GPIO.output(4, False)
[2, 5, 7, 8, 9, 12]
min(alist, key=itemgetter(1))[1], max(alist, key=itemgetter(1))[1]
main()
setattr(self, k, v)
a[~np.isnan(a).any(axis=1)]
scipy.signal.ltisys.lti
dfUnstacked2.columns
meta.Session.commit()
self.layout.addWidget(self.button)
np.tensordot(A, B, axes=[[0, 1], [0, 2]])
root.mainloop()
result = set(d[0]).intersection(*d[:1])
self.root.mainloop()
gevent.wait()
sess.run(y, feed_dict={i: d for i, d in zip(inputs, data)})
c = list(chain(*zip(a, b)))
response = requests.post(url, data=json.dumps(payload), headers=headers)
math.isnan(x)
logger.setLevel(logging.INFO)
255, 255, 255
{k: v for k, v in d.items() if k.startswith(s)}
plt.show()
(dict(x=x[ii], y=y[ii], z=z[ii]) for ii in range(10))
time.sleep(1000)
driver.quit()
print(my_list)
result = json.dumps(response[1])
s = map(sum, zip(*([s] * 2)))
max_index = max(max_index, index)
print(repr(input()))
timeit(lambda : list(test(12, 5)), number=1)
root.mainloop()
test.dosomethingelse()
time.sleep(1)
plt.show()
np.exp(2j * np.pi * np.random.rand(n, 1)).view(dtype=np.float64)
setattr(self, k, kwargs[k])
d.setdefault(k, []).append(v)
b2[np.in1d(b1, a)]
[x for t in a for x in t]
root.mainloop()
f.close()
s * a == s * a + s * 0
plt.plot(*zip(*a))
dict.fromkeys(my_list)
plt.show()
ax.axes.get_yaxis().set_visible(False)
myList[:] = [x for x in myList if x not in totoss]
time.sleep(60)
dict(lst)
a = a[0:100]
parser.parse_args()
workbook.close()
__init__.py
numpy.random.seed(42)
canvas.pack(side=LEFT, expand=True, fill=BOTH)
self.write(jsonp)
conn.commit()
self.grid_rowconfigure(0, weight=1)
Foobar.objects.filter(Q(blah=1) ^ Q(bar=2))
deletemylist[-2:]
plt.show()
time.sleep(5)
s = [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]
plt.show()
worker.start()
plt.figure()
child.kill()
[item for item in yourlist if item % 2]
[int(i in locs) for i in range(size)]
time.sleep(2)
s.groupby(s.index.weekday).transform(lambda x: pd.rolling_mean(x, window=n))
plt.show()
[x for x in matrix if x[2] == 0.0]
ax.xaxis.set_major_formatter(ScaledFormatter(dx=6))
s.quit()
time.time()
set(a[i] for i in range(1, len(a)) if a[i] == a[i - 1])
A[np.isnan(A)] = 0.0
new_list = [dict((transform[k], v) for k, v in list(d.items())) for d in old_list]
sys.path.append(root)
plt.show()
max(t, key=lambda e: (-e[1], e[2]))
regex.findall(s)
f.seek(0)
display.sendstop()
input.close()
driver.implicitly_wait(secs)
data.groupby([lambda x: x.year, lambda x: x.time])
plt.show()
plt.xticks(list(range(10)), labels)
res = service.cse().list(q=search_term, cx=my_cse_id).execute()
os.rmdir(temp_dir)
plt.show()
subprocess.call(cmd, shell=True)
cur.execute(query, (sortname, limit1, limit2))
print([d.isoformat() for d in get_week(datetime.datetime.now().date())])
root.mainloop()
bisect.bisect_left(mylist, compareValue)
ax.set_xlim([0, N])
fh4.close()
plot(x, y)
np.vstack({tuple(row) for row in a})
ser.read(5)
random.sample(list(range(1, 10)), 10 - 1)
l = L[1::2]
plt.show()
b = a[:, :, ::-1]
parser.parse_args()
[(a % 1) for a in l]
se2.commit()
[j for i in x for j in i]
print(np.allclose(cols, cols2))
data.sort(key=lambda entry: entry[1], reverse=True)
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
db.session.commit()
time.sleep(1)
l[::-1]
rolling_corr.iloc[-200:].mean(axis=0)
list(itertools.permutations(set([1, 1, 2, 2])))
[t for t in mylist if t[0] == 10]
df.isnull().values.ravel().sum()
unittest.main()
a[a < 0] += 1
new_list = [foo for foo in foos if foo.location == 2]
a.reshape(-1, m / k, k).transpose(1, 0, 2).reshape(-1, k)
socket.setdefaulttimeout(15)
print(list(chain.from_iterable(A)))
[hex(ord(c)) for c in chars]
HttpResponse(response.content)
os.startfile(file)
Gtk.main_iteration()
A = [operation(A[i], A[i + 1]) for i in range(len(A) - 1)]
print(etree.tostring(builder, pretty_print=True))
root.mainloop()
4 * scipy.integrate.nquad(f, [[0, 1], [0, 1]])[0] / 12.565472446489999
sys.stdout.flush()
array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]])
plt.show()
a = set()
print(etree.tostring(new_root, pretty_print=True))
a = list(set(a))
A.sort(key=lambda x: B.count(x))
my_dict = {x[0]: {k: v for k, v in zip(my_headers, x[1:])} for x in my_list}
random.sample(the_list, 50)
a, b, c, d = [x[i:i + step] for i in range(0, len(x), step)]
ax.hist(mydata, weights=np.zeros_like(data) + 1.0 / data.size)
x, y = y, x
wx.Frame.__init__(self, parent, ID, title, pos, size, style)
df_new.head()
min(li, key=lambda x: x.number)
datetime.fromtimestamp(timestamp2)
df.ix[idx]
rest = text.split(sep, 1)[0]
cursor.executemany(sql, rows)
a.append(s)
df.replace(d)
unique_a.view(a.dtype).reshape((unique_a.shape[0], a.shape[1]))
f.close()
self.Bind(wx.EVT_LEAVE_WINDOW, self._onMouseLeave)
plt.show()
set(range(1, 101)) - s
list1.sort(key=natural_sort_key)
sns.kdeplot(x, shade=True)
set(list2).issubset(list1)
local_file.close()
json_string = json.dumps(foo.__dict__)
self.queue.pop()
list = map(str.strip, list)
session.flush()
[list(t) for t in zip(*l)]
res_list = [x for x, _ in rows]
x[5:]
plt.show()
shutil.rmtree(name)
np.flipud(your_array)
p.wait()
df.apply(lambda row: row[1] if row[0] > 0 else row[2], 1)
vbar.pack(side=RIGHT, fill=Y)
set(a[i] for i in range(1, len(a)) if a[i] == a[i - 1])
np.multiply(np.arange(1, 5), np.cumprod([1, 2, 2, 2])[np.newaxis].T)
timestamps.sort()
QtCore.QObject.__init__(self)
list(k for k, g in itertools.groupby(x for x in numbers if x != 0))
fvtool(Hd1, Hd2)
[int(i) for i in x[num - n:num]]
res = cv2.matchTemplate(img, template, cv2.TM_CCORR_NORMED)
y = x.reshape(x.shape[0] / 2, 2, x.shape[1], 2)
a = datetime.datetime.today().year
newList = [(x / myInt) for x in myList]
self.setWindowState(QtCore.Qt.WindowMinimized)
cv2.destroyAllWindows()
datetime.datetime(1890, 1, 1, 0, 0)
pd.read_csv(Reader(gen()))
plt.show()
session.query(MyTable.col1).count()
array([[18, 6], [19, 5], [17, 9], [10, 5]]),
df.iloc[:, ([1])]
plt.show()
signal.signal(signal.SIGQUIT, handler)
self.top_frame.grid_columnconfigure(1, weight=1)
sorted((i, j) for i, j in zip(x, y))
args = parser.parse_args()
plt.show()
lambda x, y: x + y
open(location, mode).write(content)
db.commit()
time.mktime(dt.timetuple()) + dt.microsecond / 1000000.0
((0, 1),) * 5
[False] * 10
x2[:, (0)] = np.roll(x2[:, (0)], -2)
plt.show()
self.root.mainloop()
ax1.plot(x[i:i + 2], y[i:i + 2])
f(*args, **kw)
datetime.datetime.today().weekday()
os.path.dirname(file)
stream.close()
added.sort(key=lambda x: os.stat(os.path.join(path_to_watch, x)).st_mtime)
f.close()
my_model.save()
c.ravel()
ctx.Process(target=foo, args=(x,)).start()
obj.refresh_from_db()
[i for i in my_list if my_counter[i] > 1]
infile.close()
client.images.data(img)
np.random.seed(1977)
df.iloc[df.index.get_indexer([2, 7])]
df.stack()
numpy.array(list(c))
self.frame.pack()
G.remove_nodes_from(to_remove)
reactor.run()
print(line)
df.apply(lambda f: to_number(f[0]), axis=1).sum()
plt.xlim(0, 10000)
matplotlib.pyplot.plot_date(dates, values)
wx.Frame.__init__(self, *args, **kwargs)
arr = arr[:, :, ::2]
df = pd.DataFrame.from_dict(map(dict, df_list))
func(*args, **kwargs)
self.checkqueue()
print(rdd.collect())
np.all(a == 0)
process_file(sys.argv[1])
ax1.yaxis.set_visible(False)
time.time()
plt.show()
NOT_DONE_YET
inspect.signature(datetime.datetime.now)
print(np.allclose(rows, rows2))
time.sleep(0.5)
f()
{t[0]: t[1:] for t in s}
con.commit()
df1.ix[:, (1)]
admin.site.register(Session, SessionAdmin)
new_lst.sort()
print([v for v in simplex.vertices])
os.kill(cpid, signal.SIGKILL)
tiffiles.sort(key=getint)
arr.argsort()[:n]
random.shuffle(lst)
my_array.pop()
fliplr(m.swapaxes(0, 1))
dict(map(lambda l: l.split(), s.splitlines()))
df.index = pd.to_datetime(df.index)
[sum(e) for e in zip(*data)]
time.sleep(10)
plt.show()
doc = lxml.html.parse(url)
pd.DataFrame(list(d.items()))
C = [[(0) for col in range(len(B[0]))] for row in range(len(A))]
pd.value_counts(list(concat(df.categories.values.tolist())))
fh.close()
random.shuffle(x)
result = sorted(mylist, key=lambda x: d[x[0]])
list_of_hets.append(hets)
np.unravel_index([0, 18, 26], a.shape)
urllib.request.urlopen(url).geturl()
np.where((a >= 6) & (a <= 10))
print(a.dtype)
df[df.isnull().any(axis=1)]
index = numpy.clip(index, 0, len(my_list) - 1)
[i for i in range(10) if i == 9]
input()
plt.subplot(212, sharex=ax1, sharey=ax1)
list(s)[0]
glOrtho(self.left, self.right, self.bottom, self.top, 1, -1)
time += datetime.timedelta(hours=1)
main()
[random.random() for _ in range(100000)]
driver = webdriver.Chrome(chrome_options=chrome_options)
f.close()
app.mainloop()
ax.plot(x, y)
plt.show()
df.stack().apply(pd.Series).unstack().swaplevel(0, 1, 1).sort_index(1)
plt.show()
out_file.write(replace_all(text, spelling_dict))
ax1.set_ylim([0, 5])
f.close()
list_2 = [i for i in list_1 if isinstance(i, (int, float))]
plt.show()
G = nx.DiGraph()
out = np.linalg.norm(row.data)
np.array(_)
self.listbox.selection_set(first=0)
np.fromiter((row[index] for row, index in zip(X, Y)), dtype=int)
sorted(l, key=lambda x: (x[:-1], x[-1].isdigit()))
help(func)
np.subtract.outer(a, b)
min(a, key=lambda t: t[1])
self.check_object_permissions(self.request, obj)
plt.show()
list(tuple(mydata.transpose()))
a[..., (numpy.newaxis)] * b[(numpy.newaxis), ...]
self.lock.acquire()
self.value = value
theproc.communicate()
[item for item in theList if item in theDict]
user.save()
df1.count()
setattr(self, k, v)
print(sorted(set(my_list)))
s = pd.Series([1, 5, 20, -1])
self.Bind(wx.EVT_MOTION, self.OnMouseMove)
user.save()
do_it_lots()
np.where((vals[:, (0)] == 0) & (vals[:, (1)] == 1))[0]
numpy.array([[elem for elem in x_row] for x_row in X])
lst.extend(data)
request.remote_addr
round(1.5145, 2)
print([m.start(1) for m in matches])
time.sleep(0.5)
ax.set_xlim([datetime.date(2014, 1, 26), datetime.date(2014, 2, 1)])
some_class(*os.path.split(somefile))
set(word_list).intersection(a_string.split())
plt.pause(1)
self.baseDict[key]
cl.getlevel(2)
ordered = OrderedDict((k, mydict[k]) for k in myorder)
np.MAXDIMS
time.sleep(0.2)
zip(s, s[1:], s[2:])
__init__.py
plt.show()
decimal.Decimal(1.1)
self.__dict__.update(*args, **kwargs)
x = x[:50]
z = dict(list(x.items()) + list(y.items()))
ax.margins(0.05)
[a[i:i + 2] for i in range(0, len(a), 2)]
sys.exit(0)
logging.basicConfig()
plt.show()
[_f for _f in lst if _f]
sys.exit(1)
[y for x in list(d.values()) for y in x]
sorted([(0, 0, 0, int(random.getrandbits(4))) for x in range(10)])
min(a, b) / max(a, b)
self.client.post(url, data=post_data)
d = {t[0]: t[1:] for t in arr}
plt.show()
admin.autodiscover()
x, y, z = (v + 2 for v in l)
min(list(d.items()), key=lambda x: x[1])
print(pix[x, y])
curses.endwin()
words_list.extend(contents[i].split())
plt.show()
os.path.normpath(os.path.join(os.getcwd(), os.path.dirname(__file__)))
f.close()
d = pd.concat([d, temp])
rows = session.query(func.count(Congress.id)).scalar()
self.label.pack()
file = models.FileField(blank=True, null=True)
text_area.pack()
plt.plot(list(range(5)))
[tuple(zip(*x)) for x in lst]
root.mainloop()
plt.show()
print(Foo.bar)
[a.index(item) for item in b]
writer.writerow(list(d.keys()))
sock.bind((MCAST_GRP, MCAST_PORT))
shutil.copy(file, dest_dir)
map(lambda x: x ** 2, list)
update_fitness()
new_list = [f(x) for x in it.takewhile(lambda x: condition(x), l)]
tk.Tk.__init__(self, *args, **kwargs)
plt.show()
[i[0] for i in list(zip(listOfTuples, bools)) if i[1] == True]
os.path.dirname(__file__)
ax.plot_surface(X, Y, Z)
cv2.waitKey(0)
arbiter.run()
__init__.py
screen.fill((255, 255, 255))
data.append([int(v) for v in line.split()])
pygame.display.flip()
list(map(fs.format, sum(map(str.split, l), [])))
plt.xticks([])
plt.show()
sys.exit(1)
[b for a in ((x, -x) for x in range(1, 10 + 1)) for b in a]
print(soup.get_text())
list(r.keys())
plt.show()
df.reset_index(inplace=True)
[item for item in my_list if any(x in item for x in bad)]
[[10, 6, 45, 18, 49], [5, 6, 45, 6, 14]]
time.sleep(1)
csv_writer.writerow([x for x in line])
mars.circle(228, 1)
print([len(x) for x in partition(list(range(105)), 10)])
[4, 4, 2, 1, 2]
plt.ylim([-4, 2])
foo.__getitem__(slice(a, b, c))
plt.show()
plt.show()
plt.contour(xi, yi, zi, 20, linewidths=1)
math.modf(x)
pfile.seek(0)
time.sleep(5)
f = np.vectorize(f, otypes=[np.float])
func(*args, **kwargs)
new_list = sorted_set(my_list)
base64.b64decode(coded_string)
a[(a != 5).all(1)]
plt.figure()
[(i, sublist.index(item)) for i, sublist in enumerate(list)]
[v for k, v in d.items() if k not in (2, 5)]
filtered_list = list([x for x in input_list if x % 2 == 0])
server.serve_forever()
data = np.array([float(f) for f in file(filename).read().split()])
main()
result = [r for r in x if all(z not in r for z in y)]
any(kidname == row[ct] for row in csv.reader(file))
plt.show()
--honour - stdin
[[int(i) for i in line.split()] for line in data]
logger = logging.getLogger(__name__)
sum(1 for _ in itertools.takewhile(str.isspace, a))
con.commit()
test.reshape(-1, 2)[::2].reshape(-1, 4)
w.show_all()
JsonResponse(list(data), safe=False)
[(k, v)] = list(d.items())
driver.refresh()
{}
time.sleep(1)
result.stack()
app.run()
plt.show()
type(d.copy())
grouped.boxplot()
tuple(sum(z) for z in zip(a, b))
ax.add_patch(circ)
[[True, False], [False, True]]
plt.imshow(rotate_lena, cmap=plt.cm.gray)
sum(strat(line) for line in f)
[[10, 6, 45, 18, 49], [5, 6, 45, 6, 14]]
print(pd.concat([d1, df], axis=1))
cv2.waitKey(0)
nx.draw(G, pos)
float_to_hex(17.5)
[x[0] for x in listD[1]]
print(sorted(list(d.items()), key=lambda x: x[1], reverse=True)[0])
result = [a for a in A if a not in subset_of_A]
main()
a, b = map(int, sys.stdin.readline().split())
[(x * y) for x, y in zip(lis[0], cyc)]
app.run()
Toy.objects.filter(owner__parent=parent)
np.in1d(arr1, arr2)
plt.figure()
sock.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)
json.dump(feeds, feedsjson)
data[:, (set_col)] = val
time.sleep(1)
Mailbox.quit()
all(word[i + 1] >= word[i] for i in range(len(word) - 1))
plt.show()
list(sum(list(dict.items()), ()))
parser = argparse.ArgumentParser()
sorted(l, key=alphanum_key)
list.focus_set()
df.values[:] = df.sum()
[m.group(0) for m in matches]
os.makedirs(dir_path)
logging.basicConfig(level=your_level)
locale.setlocale(locale.LC_ALL, saved)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
A.a.__get__(a, A)
vf(numpy.outer(phases, numpy.arange(1, 4)))
print(date.isoformat())
plt.show()
df.a.value_counts()
mydict = default.copy()
Y[:, (1)]
df = df.loc[:, (~df.columns.duplicated())]
np.where(idx)
plt.show()
array([0, 0, 0, 0])
logger.setLevel(logging.DEBUG)
session.commit()
[[w for w in L if len(w) == num] for num in set(len(i) for i in L)]
hex(291)
setattr(c, key, value)
result_list = [elements[i] for i in indices]
os.kill(pid, signal.SIGTERM)
plt.show()
A[np.arange(A.shape[0]), (A != 0).cumsum(1).argmax(1)] = 0
sys.exit(0)
SomeModel.objects.filter(id__in=ids_list).delete()
plt.show()
con.commit()
{{a.name}}
cygstart / cygdrive / c / Python27 / python.exe
y = [0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0]
unittest.main()
print(response.content)
np.dot(a, b)
gtk.main()
plt.show()
sum(x > i for i in x)
map(itemgetter(0), G)
print(getattr(test, a_string))
plt.figure(figsize=(4, 4))
{i: words.count(i) for i in set(words)}
sys.setrecursionlimit(10000)
res = df - df.shift()
df = df.reset_index()
sum((doSomething(x) for x in originalList), [])
[([0] * cols) for x in range(rows)]
[pair for pair in itertools.combinations(li, 2) if sum(pair) == 10]
print(max(max(x) if isinstance(x, list) else x for x in my_list))
root.update_idletasks()
(s.iloc[::2].values + s.iloc[1::2]) / 2
shuffle(x)
plt.show()
plt.show()
Reporter.objects.all().delete()
conn.commit()
ax = fig.add_subplot(111)
d = {k: [] for k in keys}
stack[-1]
some_list.append(dic)
blogpost.tags[:] = []
plt.show()
result[np.lexsort((result[:, (0)], result[:, (0)]))]
[i for i in range(10) if i not in digits]
root.mainloop()
loop.run_forever()
print(json.dumps(data))
dateutil.parser.parse(date_string)
plt.show()
new_string, np.tensordot(tensor1, tensor2, axes)
last = df.index[-1]
writer.writerow([latlon])
parser = parse_args(sys.argv[1:])
output = proc.communicate()[0]
args = parser.parse_args()
itertools.chain(*lists)
fout.writelines(data[1:])
root.mainloop()
ax.xaxis.set_major_locator(mdates.YearLocator())
time.sleep(1)
sys.stdout.flush()
self.send(data)
pygame.display.flip()
plt.show()
[i for i in zip(narrative, subject, activity, filer)]
self.progressbar.pack(padx=10, pady=10)
chain.from_iterable(combinations(s, r) for r in range(len(s) + 1))
print(f.read())
OrderedDict(itertools.islice(iter(d.items()), 500))
sheet.merge(top_row, bottom_row, left_column, right_column)
resultlist.append(M[:])
outfile.write(line)
df1.date = pd.to_datetime(df1.date)
figure(1, figsize=(6, 6))
self.timer.cancel()
writer.writerow([val])
print(matrix.data)
os.remove(filename)
a[np.argpartition(-a, np.arange((~np.isnan(a)).sum()))]
ws0.write(row, col, value, style)
print(line.strip())
unittest.main()
x, y = map(list, zip(*[(e, -e) for e in range(10)]))
writer.writerow([word])
ax.legend(handles, labels)
session.query(SomeClass).all()
[p[0] for p in datapoints[0:5]]
admin.site.unregister(User)
threading.Thread.__init__(self)
np.sum(M, axis=(0, 1))
bool(np.where(np.array([0, 0])))
print(Temperature.value)
result = [x for x in orig if x]
istr.close()
scipy.stats.chi2_contingency(data)
[True, True, False].count(True)
df.loc[df.Col4.isin(target_array)].index
list(chain.from_iterable(zip_longest(d, reversed(e))))
deletemydict[key]
print(cls.__base__)
root.mainloop()
sys.stdout.flush()
list_1, list_2 = list(list_1), list(list_2)
my_dictionary = dict(line.split() for line in f)
objs.append(MyClass())
[len(max(i, key=len)) for i in tableData]
msg.attach(html_text)
smtp.sendmail(send_from, send_to, msg.as_string())
[int(s[x[1]:x[2]]) for x in parser.parse(s)[1]]
setattr(self, attr, val)
np.arange(1000000).dtype
f.seek(0)
label.destroy()
out = [(1 if num & 1 << 7 - n else 0) for n in range(8)]
np.pi
n.append(float(row[8]))
my_list.remove(item)
file.close()
a[:5, :5]
time.sleep(1)
sys.exit(app.exec_())
time.sleep(0.1)
df[(df <= 2).any(axis=1)]
Counter(words).most_common(10)
list(wrapper(raisinggenfunc()))
plt.show()
ax1.set_xlim(0, 1)
root.mainloop()
do_something()
root.mainloop()
urllib.request.build_opener(HTTPCookieProcessor).open(url)
df2.reset_index(drop=True, inplace=True)
plt.show()
sys.exit(app.exec_())
row.save()
list_of_tuples
logging.basicConfig(level=logging.INFO)
print(self.request.body)
plt.colorbar(im, cax=cax)
shutil.copy(str(my_file), str(to_file))
plt.show()
print(d[key])
response = urllib.request.urlopen(req)
buffer.append(np.ndarray((len(my_buf),), buffer=my_buf, dtype=datatype))
func1(1, 2)
[(i ** 2) for i in l]
myDict[x] += 1
pylab.show()
s.sendmail(me, to, msg.as_string())
ax.set_yticks([])
p = [(i + 1) for i, (x, y) in enumerate(zip(a, a[1:])) if x > y]
plt.show()
c = (a + b)[:len(b)]
plt.colorbar()
time.sleep(1)
json.dumps(new_D)
printx2()
sys.exit(0)
map(list, list_of_tuples)
delta.total_seconds()
list(k for k, _ in itertools.groupby(k))
str(dec)
top.mainloop()
MyModel.filter(id__in=ids)
df.loc[~(df == 0).all(axis=1)]
img.putalpha(alpha)
plt.show()
self.__class__(os.path.expanduser(str(self)))
plt.show()
plt.subplots_adjust(left=0.2, top=0.8)
QtCore.Qt.ItemIsEditable | QtCore.Qt.ItemIsEnabled
pd.DataFrame(df.values.reshape(-1, 2, df.shape[1]).mean(1))
sys.path.append(submod_path)
wM.reset()
A.stack(0).dot(twos).unstack()
print(parser.parse_args())
now.replace(hour=0, minute=0, second=0, microsecond=0)
print(df.sort_index(axis=1))
file.write(content)
a, b, c, d, e = my_string.split()[:5]
dir(__builtins__)
forms.ModelForm.__init__(self, *args, **kwargs)
connection.close()
window.show_all()
word[1:]
sys.exit(app.exec_())
root.mainloop()
model.objects.filter(id=i[1]).update(order=i[0])
x.ravel().tolist()[0]
socket.getfqdn()
rows = csv.reader(f1, delimiter=dialect.delimiter)
A[np.arange(A.shape[0]), A.shape[1] - 1 - (A[:, ::-1] != 0).argmax(1)] = 0
pd.DataFrame(zip(a, b), columns=[a.name, b.name])
db.commit()
p1 = Process(target=func1)
content = urlopen(url).read()
main()
imshow(data)
pylab.plot(x, y)
[x for x in collection]
browser.implicitly_wait(10)
canvas.save()
logging.getLogger().handlers[0].setFormatter(formatter)
root.mainloop()
bit_array.setall(0)
app.run(debug=False)
2 ** np.arange(m)
[(2 ** i) for i, v in enumerate(bin(109)[:1:-1]) if int(v)][::-1]
map(sum, data)
cursor.execute(query)
x[0][0].append(value1)
A[:, (np.arange(ncols) % A.shape[1])]
screen.blit(transsurface, (0, 0))
sum(1 for x in frequencies if x > 0)
con.close()
plt.figure()
len([_f for _f in a_list if _f]) > 0
os.unlink(filename)
transmission_array.append(1)
sorted(lst, key=lambda L: (L.lower(), L))
yvalues[idx]
print((k, v))
print(os.path.dirname(os.path.realpath(sys.argv[0])))
yticks[-1].set_visible(False)
x = np.delete(a, zero_row, 0)
User.objects.create_user(**data)
b = [(n >> i & 1) for i in range(7, -1, -1)]
logger.setLevel(logging.INFO)
ax.invert_yaxis()
locals()
OrderedDict(sorted(list(d.items()), key=lambda t: len(t[0])))
B = [i for i in A]
sys.stdout.flush()
logging.basicConfig(stream=sys.stdout, level=logging.INFO)
{x: 1, y: 2}
data[i][0] = math.sin(data[i][0])
signal.pause()
os.path.join(*choices[:-1])
a[:, (np.newaxis), :] - v
[tuple(y for y in x if y) for x in a]
print(max(flatten(l)))
functools.reduce(operator.add, map(collections.Counter, dict1))
setattr(A, the_name, classmethod(func))
max([l1, l2], key=len)
f.seek(0)
cv2.destroyAllWindows()
random.shuffle(shufflethis)
ax.xaxis.set_major_formatter(ticks)
next(i for i, j in enumerate(lst) if j)
pd.concat([total, xtabs], axis=1)
list(set(tuple(sorted(s)) for s in all_the_ways))
np.sum(arr, axis=0)
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
[x for i, x in enumerate(myList) if i not in toRemove]
solve(eqs, [x, y])
np.intersect1d(A, B)
sys.path.append(os.path.abspath(path))
admin.site.register(Item, ItemAdmin)
conv.ravel()
ax1.imshow([[0, 1], [2, 0]])
e[np.all(e - np.array([1, 2]) == 0, axis=2)]
sc.parallelize(List(line)).collect()
time.timetuple()
s.multiply(sparse.csr_matrix(1 / np.sqrt(s.multiply(s).sum(1))))
A[:] = [1, 2]
print(sum(i == 1 for i in flatten_list(x)))
obj.save()
print(str(socket.gethostbyname(socket.getfqdn())))
np.std(sample)
os.path.abspath(os.path.dirname(__file__))
plt.show()
np.isnan(y), lambda z: z.nonzero()[0]
b = np.array([list(word) for word in a])
help(parrot.Norwegian)
(lambda a, b: a(a, b))(X, b)
plt.grid()
A[0:2, 0:2]
round(2606.89579999999, 2)
model.fit(S)
output.write(bytearray(int(i, 16) for i in yoursequence))
np.take(a, b, axis=1)
data.sort(key=lambda x: sorted(tally[i] for i in x))
(np.cumsum(np.bincount(v, minlength=u.size)) - 1)[v]
cursor.close()
pipeline.fit_transform(data)
ax.plot_surface(X, Y, Z)
lambda i: isinstance(i, (int, float))
{x: (x + 6) for x in range(1, 5)}
np.concatenate([[0.2], linspace(1, 60, 60), [60.8]])
print(sys.argv[0])
a.shape = a = a.reshape((a.shape[0], -1, n))
all(x > limit for x in my_list)
a[1:] -= a[:-1]
ax.plot_trisurf(triang, z_refi, cmap=cm.jet, lw=0.0)
plt.show()
_cache.clear()
plt.show()
all(getattr(self, key) == val for key, val in list(kwargs.items()))
a[:, ::2] + a[:, 1::2]
{k: v}
s.close()
pdb.set_trace()
df.apply(lambda x: x.argmax(), axis=1)
a = [[], [], [], []]
sys.stdout.flush()
list(starmap(add, zip(lst, lst[1:])))
b = [(n >> i & 1) for i in range(0, n.bit_length() - 1)]
plt.show()
{tuple(x) for x in l1} & {tuple(x) for x in l2}
time.sleep(0.5)
plt.pcolormesh(x, y, z, cmap=mpl.cm.Reds)
label.pack(fill=BOTH, expand=1)
np.isnan([nan, nan]).any()
list(y)
cb.ax.xaxis.set_ticks(minorticks, minor=True)
result = requests.get(LOGIN_URL, auth=(USERNAME, PASSWORD))
plt.show()
self.canvas.pack()
root.mainloop()
MPI_Finalize()
posts = Post.objects.filter(tags__in=tags)
cursor.execute(sql)
file.close()
form.save()
plt.plot(x_list, y_list)
sorted(zip(listofTimes, listofLines))
set(list1 + list2)
A = np.array(A)
session.commit()
df2.T.drop_duplicates().T
plt.show()
pipe.stdin.close()
(a[n:n + 1] + [default])[0]
pprint.pprint(obj, compact=True)
A.sum(axis=0)
ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())
ts[datetime(2011, 1, 8):]
b = numpy.vstack((numpy.zeros(a.shape, int), a))
print(list(map(lambda x, y: x + [y], A, list(range(1, len(A) + 1)))))
conn.commit()
pylab.show()
sum(functools.reduce(operator.mul, data) for data in zip(*lists))
sys.exit(1)
print(s.seconds / 60)
[(i, lst.count(i)) for i in set(lst)]
line[5:]
sorted(a, key=my_key)
arr = np.array(list_of_arrays)
print(match.group(2))
session.commit()
sum(i for i in range(a, b + 1) if i % 2 == 0)
nx.draw_networkx_labels(G, pos_higher, labels)
conn.escape_string()
os.path.dirname(f)
random.shuffle(migrant)
numpy.setxor1d(a, b)
df.cumsum()
plt.show()
arr.sum(axis=(0, 1)).shape
[x for x in x if x[id] == 20]
plt.show()
repr(a)
f.seek(0)
sort(arr, arr.size)
plt.show()
element = ET.parse(fp).getroot()
df.drop(df.columns[11:], axis=1)
2 ** 2 ** numpy.arange(5)
pl.show()
a.insert(0, a.pop())
root.mainloop()
r.mainloop()
app.run()
print(MyClass())
self.show()
data = numpy.array(f.read().split(), dtype=float).reshape(7000, 8)
df.mean(axis=1)
new_dict[key].extend(value)
print(get_lists_with_sum(11, 8))
session.expunge_all()
A[::-1, :]
ax = fig.add_subplot(1, 1, 1)
itertools.chain.from_iterable(lists)
np.mean(t, axis=1)
root.mainloop()
session.query(WhateverClass).filter(WhateverClass._containerClassId == 5).all()
driver.quit()
h.setLevel(logging.DEBUG)
np.cos(np.pi * x) * np.sin(np.pi * y)
self.clickcursor.execute(query)
pd.value_counts(list(chain(*df.categories.values.tolist())))
plt.show()
A[A == NDV] = numpy.nan
print(any(l[i:i + len(pat)] == pat for i in range(len(l) - len(pat) + 1)))
pygame.init()
x[np.r_[0:2, -2:0]]
print(s.tell())
time.sleep(5)
print(my_new_list)
df.loc[row, key] = data[key]
pipeline.steps[1][1]
dir(request.body)
df[(df > 16) & mask]
xvfb.wait()
print(new_string)
files = [f for f in os.listdir(dirToScreens) if path.isfile(f)]
[random.randrange(1, 10) for _ in range(0, 4)]
root.mainloop()
sys.stdout.flush()
plt.show()
sum(1 for i in x if i)
x = (x + y) % 48
[l[i:i + n] for i in range(0, len(l), n)]
pprint.pprint(obj, depth=1)
req.close()
hash(self.__key__())
a.__getitem__(slice(0, 1)).__getitem__(0).__setitem__(0, 5)
app = create_app()
len(set(a)) == len(a) == max(a) and min(a) == 1
time.sleep(1)
print(etree.tostring(page, pretty_print=True))
sess.run(train_op)
label.pack()
site.delete(os.path.join(path, ftpfile.name))
(dt - datetime(1970, 1, 1)).total_seconds()
ax1.set_zorder(1)
np.any((0 < x) & (x < 1))
gtk.main()
[a for a, b in zip(aa, bb) if a == b]
issubclass(C, A)
fig.tight_layout()
df = pd.concat([df, pd.DataFrame(new_data)])
matplotlib.get_backend()
conn.commit()
[s[i:i + 2] for i in range(0, len(s), 2)]
os.path.basename(f.name)
p.start()
any(x[1:] == x[:-1] for x in zip(*arr))
df.stack().reset_index(1)
self.assertEqual(0, os.getpid())
my_array[:, (0)], my_array[:, (1)] = my_array[:, (1)], my_array[:, (0)].copy()
df.shape[1]
len(df)
cts.minute == 0 and cts.second == 0
[0] * 10
pyplot.show()
fragments
sys.stdout.flush()
root = tree.getroot()
ax.xaxis.set_major_locator(myLocator)
print(min(Mylist, key=lambda x: x[1]))
tup[0] = tup[0].__iadd__((4, 5, 6))
Gtk.main()
python - devel
ax.set_xlim(1, 11)
plt.draw()
{i: a[i] for i in np.nonzero(a)[0]}
[i.strip() for i in txt.split(default_sep)]
p.wait()
tmp[:, :-1] += a[:, 1:]
plt.show()
plt.show()
newD = dict(zip(list(d.keys()), [round(v) for v in list(d.values())]))
self.save()
gtk.main_quit()
A[((0,), (1,)), B]
int(t[0], 2) + int(t[1], 2) / 2.0 ** len(t[1])
print([(int(i) + 1) for i in s.split()])
df.apply(calculateC2, axis=1)
window.show()
pdb.set_trace()
str = str[:1].upper() + str[1:]
collections.OrderedDict(sorted(result.items()))
(10)()
f.close()
plt.show()
x = (x + y) % 48
df_with_x5.show()
t2c.main()
sorted(get, key=sortkey)
plt.show()
sys.exit(app.exec_())
requests.get(url)
os.remove(filename)
watchout()
skycake()
plt.show()
func(self, *args, **kwargs)
show()
foo.update(list(range(2, 6)))
pg.mixer.set_num_channels(50)
df.mask(np.arange(df.shape[0]) >= np.arange(df.shape[1])[:, (np.newaxis)])
[os.path.join(root, *choices[:i + 1]) for i in range(len(choices))]
print(iter2(A.copy(), rc1, rc2))
df.loc[target_index]
b = a[0:2]
dsp.close()
root.mainloop()
np.nanmean(data, axis=0)
Counter(test.split()).most_common()
print(df.sum().sum())
isinstance(dates, pd.DatetimeIndex)
df.columns = [str(i) for i in df.columns.values.tolist()]
canvas.pack()
(my_array[:-1] * my_array[1:] < 0).sum()
reactor.run()
isdeployed.strip()
print(a[0][0])
list(set(a) & set(b))
ws.write(rowi, coli, converters[coli](value))
array([[-1, -2, -1, 2], [1, 0, 1, 4]])
plt.show()
sys.exit()
do_something()
x[::2, 1::2]
[a[i] for i in np.argsort(a)[-2:]]
plt.show()
np.allclose(r1, r2)
emp.save()
f.seek(0)
os.makedirs(dir)
os.makedirs(mypath)
pygame.joystick.init()
plt.gcf().canvas.get_supported_filetypes_grouped()
df.reindex(stk_list, level=0)
deletec[0]
plt.show()
os.remove(i)
plt.show()
func()
print(etree.tostring(root, pretty_print=True))
d = dict(map(str.split, list1))
np.array([arr[([0, n]), :], arr[:, ([0, n])].T]).ravel()
random.choice([True, False])
[x for x, _ in lst]
(abs(x) + x) / 2
cgi.parse_qsl(qs)
dict1.update([(key, dict2[key]) for key in list(dict2.keys())])
pd.read_csv(StringIO(s), parse_dates=[0], date_parser=parser)
blogpost.tags[:] = new_tags
redirect(request.path)
sys.path.append(os.path.normpath(os.path.join(SCRIPT_DIR, PACKAGE_PARENT)))
root.mainloop()
dict(zip(range(1, 5), count(7)))
plt.show()
x, y = zip(*[l.split() for l in f])
len(set(map(tuple, M))) == len(M)
Superlist.__init__
plt.show()
admin.site.register(Product, padmin)
test()
plt.show()
s = sorted(s, key=operator.itemgetter(1, 2))
y[(1 < x) & (x < 5)]
pg.init()
ax.set_zlim(-10, 0)
writer.writerow(row)
result.extend(list(t))
logger.setLevel(logging.DEBUG)
time.sleep(1)
plt.show()
[tuple(x) for x in data_set.to_records(index=False)]
plt.show()
plt.show()
a.add([1, 2])
os.path.join(os.path.dirname(parent), template)
time.mktime(datetime_object.timetuple())
employee.license_set.all()
inspect.getargspec(g)
cherrypy.quickstart(Root())
conn.close()
ax = fig.add_subplot(111)
os.close(f)
[j for i in sequence_list for j in rex.split(i)]
result[:a.shape[0], :a.shape[1]] = a
func()
widget2.grid(row=0, column=1)
numpy.linalg.norm(A - B, numpy.inf)
f.seek(0, 0)
nx.draw(G)
QtNetwork.QSslSocket.supportsSsl()
p = subprocess.Popen(cmd, stdout=subprocess.PIPE, shell=True)
plt.show()
set(map(itemgetter(0), l1)) & set(map(itemgetter(0), l2))
etree.fromstring(s, parser=utf8_parser)
m2[np.array(m2[:, (1)] > 10)[:, (0)]]
request.user_agent
pckl_file.close()
shutil.rmtree(sub_folder)
[(my_array + [i]) for i in input_elements]
pygame.font.init()
sympy.solve(l - r, c)
np.random.seed(0)
self.worker.start()
a = [[(0) for _ in range(ROWS)] for _ in range(COLUMNS)]
print(sys._getframe().f_code.co_name)
[(x ** 2) for x in range(10) if x < 7]
thingy1.f()
self.panel = wx.Panel(self)
f = anotherdecorator(lambda x: x * 2)
np.ma.array(a, mask=mask)
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
json.dump(data, sys.stdout, indent=2)
[x for x in lst if float(x.split()[-1]) not in s]
StringIO()
ax2.set_ylim([0, 1])
r.destroy()
str1.replace(str2, str2.upper())
self.transport.write(data.encode())
np.array(lists)
[(y if y not in b else other_value) for y in a]
array([[100, 200], [255, 255]], dtype=uint16)
np.in1d(a, [14, 16, 18])
t.start()
parser.parse_args(read_my_file(sys.argv[1:]))
root.mainloop()
plt.show()
browser.get(url)
measure.grid(row=0, column=0)
root.mainloop()
session.commit()
os.close(fh2)
value = next(v for i, v in enumerate(d.values()) if i == index)
m[:, :1].shape
pl.show()
{x[0] for x in list1} & {y[0] for y in list2}
out_im.putpalette((0, 0, 0, 255, 0, 0, 0, 255, 0, 255, 255, 0))
tmp[:, 1:] += a[:, :-1]
os.path.abspath(os.path.expanduser(path))
fwrite.close()
f = lambda X, model, **kw: cost(X, model, sparse=np.random.rand(10, 10), **kw)
e = next(iter(S))
plt.show()
sorted(L, key=lambda x: x[0] / (x[1] * 1.0))
self.main()
(df * weight[0]).sum(1)
pygame.draw.rect(screen, black, (0, 0, width, height), 0)
int(n)
test()
dest = dict(chain.from_iterable(map(dict.items, list_of_dicts)))
self.__dict__.update(b)
pickle.load(f)
df[df.apply(pd.Series.nunique, axis=1) == 1]
sorted(l1)
driver = webdriver.Firefox(capabilities=caps, firefox_profile=profile)
msg.send()
plt.hist(a, bins)
p.poll()
logger.setLevel(logging.DEBUG)
f.close()
f.close()
x = Example()
file.write(port.read())
pygame.quit()
210.184175597721, 210.184175597721, 210.184175597721, 210.184175597721
print(test())
QtGui.QWidget.__init__(self)
time.sleep(5)
metadata.reflect(engine)
map(lambda x: f(x, fixed), srclist)
f.close()
br.set_handle_refresh(mechanize._http.HTTPRefreshProcessor(), max_time=1)
os.path.getsize(path)
plt.show()
f.close()
os.unlink(path)
ax.add_patch(circle1)
df.columns = col_list
gtk.main()
QTcpSocket.__init__(self)
A = dot(A, R.T)
[(x + y) for x, y in grouper(2, q)]
ssh.close()
{(x, y) for x in r for y in r if x + 2 == y}
date = models.DateTimeField()
wx.Icon(sys.argv[0], wx.BITMAP_TYPE_ICO)
[([0] * 8) for x in range(8)]
unittest.main(argv=[sys.argv[0]])
array2 = [int(x == 4) for x in array1]
plt.show()
root.mainloop()
html.escape(string)
max(item[1] for item in alkaline_earth_values)
sorted(list(d.items()), lambda a, b: b[1] - a[1] or a[0] - b[0])
[(next(z) if i < 0 else i) for i in y]
proc.wait()
arr.tolist()
print(Model.objects.get(pk=1).ranking)
equation1(**dict_of_parameters)
n = np.apply_along_axis(np.linalg.norm, 1, a)
[(x, y) for x, y in zip(it, it1)]
my_list.insert(index, item)
set([(4, 5), (2, 2, 5), (1, 20), (2, 10)])
f2.close()
writer.writerow(row)
self.assertEqual(2, 0)
f1.writelines(lines)
A.extend(B)
connection.close()
root.deiconify()
cv2.rectangle(eroded, (0, 0), (x, y), (255, 255, 255), 1)
df = pandas.concat([df1, df2], axis=1)
a[a.argsort()[-10:]]
QtGui.QTableView.__init__(self, *args, **kwargs)
[[4, 2, 6], [8, 10, 12], [6, 8, 6]]
list(x)
test[1].index + pd.DateOffset(hours=16)
[((x + (x - 1)) / 2) for x in list_of_nums]
print(input[indices[(0 <= indices) & (indices < 5)]])
f.close()
d.pop(your_key)
plt.show()
result = (M[:, :9] * N[:9, :].T).sum(1)
queue.Queue(maxsize=0)
(lambda i: lambda x: x % i)(i)
session.query(inc_type_md_col).filter(cnt_col > 0)
zip(itertools.repeat(ls[0]), ls[1:])
plt.colorbar()
window.show_all()
ax.set_ylim([0, 5])
self.process.start()
result = [key for key, value in dict.items() if value == min_value]
dict.fromkeys(list(range(2)), object())
plt.plot(x, y1)
main()
f.flush()
plt.show()
[v[0] for v in sorted(list(dict.items()), key=lambda k_v: (-k_v[1], k_v[0]))]
print(template.render())
print(json.dumps(jsonobj))
string.ascii_uppercase + string.digits
any((myrow1 == x).all() for x in myarray)
pandas.read_csv(s)
x, y = y, x + y
y = [i[j] for i in x for j in range(len(i))]
my_list = list(my_set)
first_type if all(type(x) is first_type for x in iseq) else False
time.sleep(5)
any(t.isupper() for t in month[1:])
random.choice(string.ascii_letters + string.digits)
list([x for x in mylist if x in pattern])
sum(i * j for i, j in zip(v1, v2))
sum(map(lambda x, y: bool(x - y), a, b))
print(list(Counter(l).items()))
s = sum(b for a, b in zip(list_1, list_2) if a)
sys.exit(1)
model.objects.all()
data = np.random.randint(0, 10, size=(100000, 2))
print(sys.version)
a.append((1, 2, 4))
df = df.reindex(columns=cols)
exp.evalf(subs={a: 6, b: 5, c: 2})
settings.__dict__
A.data = np.array([10, 6])
master.mainloop()
dict(list(i.items())[0] for i in L)
A = P * D.sum(axis=1) - D.dot(P)
plt.hist(x, bins=20)
subprocess.Popen(cmd).communicate()
test()
map(max, arr)
mail.Send()
data = np.arange(-50, 50, 10)
df.eq(df.iloc[:, (0)], axis=0)
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
plt.show()
sorted(d, key=lambda i: int(d[i]))
self._droplock()
new_foo.append(item)
e = [x[0] for x in eagles]
[key for key, group in groupby(li) if len(tuple(group)) == 1]
np.unravel_index(match_indices, result.shape)
pd.DataFrame(res)
session.commit()
[(val, np.sum(A[B == val])) for val in np.unique(B)]
plt.show()
plt.show()
itertools.product(list(C.items()), repeat=2)
instance.save()
hey()
hist(b.ravel().astype(np.uint8), bins=255, range=(0, 255))
{k: v for k, v in list(dictionary.items()) if begin <= k <= end}
first = l.pop(0)
tkmc.close()
cleaned = [i for i in (word.strip() for word in words) if i]
f.close()
G.data = np.ones(G.nnz)
time.sleep(1)
ax = fig.add_subplot(111)
lambda a, b: b * a(a, b - 1) if b > 0 else 1, b
sys.getsizeof(s)
[list(s) for s in sets]
ser.close()
clf.fit(X, y)
plt.subplots_adjust(bottom=0.17)
bool(my_list)
os._exit(1)
__init__.py
[(x + 1 if x >= 45 else x + 5) for x in l]
tornado.ioloop.IOLoop.instance().start()
print(list(mydict.keys())[list(mydict.values()).index(16)])
plt.show()
sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
id(copy_my_list[0]) == id(my_list[0])
x.append(i)
df1.sort(axis=1) == df2.sort(axis=1)
my_list = list(my_set)
solve(my_func, 16)
int(a)
df.groupby(df.columns.tolist(), as_index=False).size()
frame.show()
__init__.py
setattr(self, name, number)
a = db.ReferenceProperty(A)
d + datetime.timedelta(hours=8)
sys.path.pop(0)
b.remove(i)
print([x for x in words if len(x) > average])
sorted(text, key=lambda x: (str.lower(x), x))
plt.show()
distance[0][1][2]
fig.set_size_inches(18.5, 10.5, forward=True)
{k: v for k, v in zip(list(range(1, 5)), list(range(7, 11)))}
p.start()
self.setWindowFlags(QtCore.Qt.Tool)
print([x for x in a if counts[x] >= 2])
sys.stderr = sys.__stderr__
__init__.py
QMainWindow.__init__(self, parent)
x2[:, (4)] = np.roll(x2[:, (4)], 2)
print(is_list_of_strings(i))
time.sleep(5)
e / e.sum(axis=1, keepdims=True)
subprocess.Popen(cmd)
plt.show()
x = x[:-1]
__builtins__.set
ax = fig.add_subplot(111)
not set(a).isdisjoint(b)
br.submit()
print(w.readline().strip())
l.sort(key=lambda x: x[1])
ax2.set_ylim(0, 10)
platform.system()
setattr(obj, prop_list[0], something)
centroids.append((x, y))
plt.show()
random.sample(list(enumerate(a)), 5)
plt.show()
sys.version
soup = BeautifulSoup(page)
line = line[2:]
main.run()
p.start()
lst[:] = [v for v in lst if pred(v)]
[x for x in L if not any(set(x) <= set(y) for y in L if x is not y)]
plt.subplots_adjust(wspace=0.001)
n[:] = [[(b - 1) for b in a] for a in n]
urllib.request.urlopen(request).read()
self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
logger.setLevel(logging.DEBUG)
np.random.uniform(5, 10)
plt.show()
clf.fit(X)
reactor.run()
unittest.main()
df = df.loc[mask]
plt.show()
main()
df.head()
time.sleep(0.5)
rf.merge_arrays((arr, x), flatten=True)
set(x) == set(y)
X_test = sc.transform(X_test)
json.dumps(d)
form = MyForm(questions=your_list_of_questions)
print(Matrix[x][y])
ser.close()
isinstance(b, Test2)
normal_dist.set_shape([input_data.get_shape()[1], labels.get_shape()[1]])
sys.stdout.write(REVERSE + CYAN)
a = np.array([d])
IOLoop.instance().start()
print([obj.name for obj in gc.get_objects() if isinstance(obj, potions)])
QtCore.Qt.ItemIsEditable | QtCore.Qt.ItemIsEnabled
csv_writer.writerow([i[0] for i in cursor.description])
values = [max(x, 0) for x in values]
HttpResponse(simplejson.dumps(data_dict))
list(csv.reader(s, skipinitialspace=True))
[x[0] for x in listD[0]]
workbook.close()
print(hex(new_int))
df
mylist[:] = [(not x) for x in mylist]
ax.set_axis_bgcolor((1, 0, 0))
random.sample(s, 1)[0]
c = [item for t in zip(a, b) for item in t]
ax.margins(0.2)
setup.py
ordered = [item for item in ordered if item in unordered]
[OrderedDict(row) for i, row in df.iterrows()]
c = dict.fromkeys(s, 0)
print(datetime.utcfromtimestamp(tai_timestamp))
a[:, (0), (0)], b[:, (0), (0)] = b[:, (0), (0)], a[:, (0), (0)].copy()
fout.close()
data.reset_index(drop=True)
[sum(int(c) for c in str(num)) for num in list1]
list(map(hash, list(range(1, 6))))
nx.has_path(G, 1, 5)
user.save()
date = models.DateTimeField(default=datetime.now, blank=True)
df1.combine_first(df2)
s.tolist()
wx.Frame.__init__(self, parent, id, title)
plt.show()
A - mean.reshape(mean.shape[0], 1)
app.run()
plt.show()
plt.show()
len(alist) - alist[-1::-1].index(value) - 1
file.write(unicode_text)
root.mainloop()
regr.fit(Xtrain, ytrain)
plt.show()
df.rolling(window=10).mean().applymap(round).shift()
os.kill(process.pid, signal.SIGINT)
circular()
[i for i in range(len(bv)) if bv[i]]
plt.draw()
f.write(line)
self.process.terminate()
sorted(A, key=A.get)
df = pd.DataFrame(data, columns=columns)
plt.figure(figsize=[6, 6])
driver = webdriver.Chrome(chrome_options=options)
hist(b.ravel().astype(np.uint8), bins=255)
my_list = list(the_tuple)
ax1.xaxis.set_visible(False)
self.root.mainloop()
login(request, user)
result = re.sub(regex, subst, file_contents)
Foo._bar()
[random.shuffle(x) for x in workList]
plt.show()
l = l[0] + (l[1],)
plt.show()
df.to_excel(ew)
a[..., ([1, 1])]
[(s[i], i) for i in indices]
d = dict(list(row.items()))
ax.xaxis.set_ticks(x)
a - a.min(axis=0)
infloop()
sys.exit(app.exec_())
root.mainloop()
np.minimum(arr, 255, out=arr)
sorted(list(range(len(K))), key=lambda x: K[x])[-5:]
plt.xlim(-1, 1)
tf.multiply(x, y).eval()
elements.append(table)
pdb.set_trace()
app.MainLoop()
form = CModelForm(UPOST(request.POST, c_instance), instance=c_instance)
time.sleep(1)
df.a / df.b.replace({(0): np.nan})
zip(np.nonzero(starts)[0], np.nonzero(ends)[0])
print(pandas.concat([s1, s2], axis=1).min(axis=1))
my_dict.clear()
xlbook.close()
[seq[i:i + n] for i in range(len(seq) - n + 1)]
[len(list(group)) for key, group in groupby(a)]
do_something()
1 - residual / sum((y - y.mean()) ** 2)
ax.set_xlim(ts.index.min(), ts.index.min() + 24)
df.fillna(0, inplace=True)
all(x <= y for x, y in zip(L, L[1:]))
time.sleep(1)
plt.show()
y = int(x, 16)
layout.setContentsMargins(20, 0, 20, 0)
[8, 5, 6]
root.mainloop()
os.rename(tmpFile, myFile)
lst.sort(key=itemgetter(1), reverse=True)
admin.site.register(TestModel, TestModelAdmin)
print(etree.tostring(tag, pretty_print=True))
root = Tk()
plt.tight_layout()
os.killpg(os.getpgid(p.pid), signal.SIGTERM)
sys.exit(app.exec_())
((a[:, (np.newaxis), :] - v) ** 2).sum(axis=-1).min(axis=0).sum()
time.sleep(x)
[index[start:end] for start, end in zip(slices[::2], slices[1::2])]
df.append(dm2)
df = df.reset_index()
(1 for i in x if 60 < i < 70)
plt.plot(x, y)
a, b, c = do_something()
bane.astype(np.float).view(np.complex64)
self.configure(width=width, height=height)
plt.clabel(cs, inline=1, fontsize=9)
keys.sort(lambda x, y: cmp(dict[x], dict[y]))
[0, 1, 2, 4]
time.sleep(1)
random.sample(zip(xs, ys), 1000)
app.MainLoop()
[j() for j in [(lambda i=i: i) for i in range(10)]]
line = sys.stdin.readline()
time.sleep(1)
logger.setLevel(logging.DEBUG)
plt.show()
print(numpy.round(dataAC, 10)[:, :4])
lst = []
[y for x in data for y in x]
a[0].append(1)
obj = PageModel.get_by_id(page_id)
M = np.column_stack((x ** 2, x, np.ones_like(x)))
solve(eqs2, [x, y])
[item for item in mylist if item[0][0] == letter]
plt.show()
fh.close()
ax.set_yticklabels([])
df.append(data)
print(Foo.bar.__get__(f, Foo))
all(e == a[0] for e in a)
next(x for x in (f(y) for f in hundreds) if x)
self.process.wait()
pygame.joystick.quit()
worksheet.save()
d[i[i < d.shape[0]]]
self._socket.bind((self._host, self._port))
f.write(text)
print(str(n)[::-1])
b = [(n >> i & 1) for i in range(n.bit_length() - 1, -1, -1)]
[sorted(item, key=priority.get) for item in my_lists]
test[n:]
sys.stdout.flush()
zip(*[(lst[i:] + lst[:i]) for i in range(n)])
print([(x - i) for i, x in enumerate(a)])
lists[0].append(1)
Image.fromarray(result).save(sys.argv[2])
dict(zip(l[::2], l[1::2]))
sess.close()
result = [r[0] for r in result]
plt.show()
plt.show()
any([(x[1:] == x[:-1]) for x in zip(*arr)])
doctest.testmod()
logging.getLogger().getEffectiveLevel()
df
MyThread().start()
round(2.607, 2)
[k for k, n in Counter(seq).items() if n == 1]
root.mainloop()
indices = [i for i, x in enumerate(myList) if re.search(regex, x)]
np.abs(A[:, (np.newaxis)] - B)
self.timer.stop()
pd.read_csv(f, **kwargs)
soup = BeautifulSoup.BeautifulSoup(html)
sys.path.append(path)
deletemy_list[1]
foo((noniterable,))
app.root.mainloop()
print(sorted(iter(counter.items()), key=lambda x: x[::-1]))
vectors /= np.sqrt((vectors ** 2).sum(-1))[..., (np.newaxis)]
s.find_longest_match(0, len(a), 0, len(b))
{k: v for k, v in list(dict.items()) if v > something}
db.session.commit()
results = sorted(list(results.items()), cmp=lambda a, b: b[1] - a[1])
[k for k, g in groupby(data)]
my_func(*arr.T)
sys.exit(app.exec_())
sum(map(len, [s for s in x if len(s) > 1]))
test_rec[indices]
Color(*Color2.as_list())
xbook.close()
plt.colorbar()
combined = [item for sublist in lists for item in sublist]
deletec[:]
root.mainloop()
ws.cell(row=index, column=2).value = x1
datetime(1970, 1, 1)
my_dict = json.load(f)
dot(x, y)
print(match.groups())
Y = X - X.mean(axis=1, keepdims=True)
df.where(df.eq(df.max(1), 0), -1)
f_out.close()
plt.show()
data = pickle.load(f)
Response(serializer.data, status=status.HTTP_201_CREATED)
sum(map(r, v)) == -n
np.cross(c, d).reshape(5, 4)
e = Example(size=10)
result.append(x[:2].tolist())
method()
self.ProgressBar.SetValue(0)
func(*args, **kwargs)
df.loc[df.index.tolist() + missing]
result[:-1]
df.loc[set(df.index) - set(blacklist)]
time.sleep(1)
np.where(a == a.max())
[f(a) for f in funcs for a in args]
current_module = sys.modules[__name__]
response = mechanize.urlopen(request, data=data)
sys.path.append(path)
print(f.stdout.readline())
tup = tuple([(element.foo, element.bar) for element in alist])
sys.exit(app.exec_())
print(c.most_common()[0])
plt.show()
main()
df.iloc[np.argmin(np.abs(df.index.to_pydatetime() - dtObj))]
a[:] = [s.strip() for s in a]
p[s] == np.arange(n)
random.shuffle(newcolors)
t + np.roll(t, -1)
l.sort(operator.itemgetter(0), reverse=True)
al[0], al[1] = float(strs[0]), float(strs[1])
str(random.random())[2:]
r = requests.post(URL, data=payload)
list(set().union(a, b, c))
main()
self.graph = self.ax.hexbin(self.xData, self.yData)
csvwriter.writerow(row)
c.setopt(c.HEADERFUNCTION, storage.write)
admin.site.unregister(Group)
sys.stderr = sys.__stderr__
numpy.invert(array)
sum(1 for x in gen)
print(a[x][y])
a[1].append(2)
np.log(df.col1 / df.col1.shift())
L = [[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]]
make_adder(5)(10)
cbar.set_ticks([mn, md, mx])
np.random.seed(1977)
lol = [list(range(10)), list(range(2, 12)), list(range(5, 15))]
split_curve(np.array([0, 1]), np.array([0, 1]), 2)
sys.stderr.close()
print(my_new_list)
Base.metadata.create_all(engine)
window.show_all()
a.append(str(wi))
plt.show()
logging.Handler.__init__(self)
ax7.yaxis.set_label_coords(-0.2, 0.5)
ax2.set_xlim(0, 10)
t.date()
len(set(perms))
np.random.choice(array1, 5, replace=False)
getattr(module, class_name)
plt.imshow(crop_lena, cmap=plt.cm.gray)
plt.show()
con.close()
df = pd.DataFrame(data)
data = [tuple(line) for line in csv.reader(f)]
wx.Panel.__init__(self, parent)
a[-9:]
ax.grid(True)
plt.show()
df.reindex(s.index)
a.repeat(2, axis=0).repeat(2, axis=1)
signal.signal(signal.SIGALRM, signal_handler)
a.reshape(-1, 100)[::2].ravel()
a[np.arange(len(a)), [1, 0, 2]]
sys.exit()
Project.objects.all()
isinstance(f, float)
plt.plot(x, y2)
form = MyForm(request.user)
print(df.astype(float).sum().astype(int).astype(str))
entry.focus_set()
[myfunc(a, b) for a, b in zip(data[::2], data[1::2])]
plt.show()
pd.DataFrame(a.reshape(A.shape[0], -1), A.index)
mask = np.in1d(a[:, (0)], b)
time.sleep(0)
y[y.nonzero()]
1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6
driver = webdriver.Firefox()
print(list(f()))
list(Blog.objects.values())
ax.xaxis.set_major_formatter(dates.AutoDateFormatter(locator))
tornado.ioloop.IOLoop.instance().start()
print(cmod.greet(a))
print(random.choice(a))
writer.writerows(new_data)
np.array_split(a, 2, axis=1)
f.write(leds[0])
(vals[:, (0)] == 0) & (vals[:, (1)] == 1)
{key: data[key] for key in one_by_ip}
ax.xaxis.set_major_locator(mdates.YearLocator())
tk.mainloop()
item_labels.sort(key=lambda t: c[t[1]])
br.title()
list(set(theList).intersection(theDict))
Decimal(1) / Decimal(7)
heapq.nsmallest(l, 2)
max(i[0] for i in oceans[regcode - 1])
sorted(a, key=lambda x: (x[0].isdigit(), x))
plt.show()
a.dot(v)
set([x for x in l if l.count(x) > 1])
f.seek(0, 2)
root = Tk()
admin.site.register(User, UserAdmin)
logging.basicConfig(level=logging.DEBUG)
orcl.close()
root.grid_columnconfigure(0, weight=1)
df.apply(lambda s: s.value_counts().get(0, 0), axis=1)
plt.colorbar()
ax.set_xticklabels(x_labels)
dict(form=form)
plt.xlim(0, data.shape[0])
df = df[df.line_race != 0]
plt.contourf(xi, yi, zi, v, cmap=plt.cm.jet)
zip(*data)
print(row[0].read())
L.append(l)
any(i.isdigit() for i in string)
f.seek(-len(line), os.SEEK_CUR)
QtGui.QWidget.__init__(self)
sum(s[i:].startswith(subs) for i in range(len(s)))
logging.getLogger().addFilter(Aggregator)
len([x for x in myList if x in myDict]) > 0
print(date.isoformat())
table.create()
HttpResponse(status=500)
sys.exit(0)
my_dict[key].append(value)
df.drop(drops, inplace=True)
writer.writerow(dict(zip(fieldnames, row)))
print({k: [d[k] for d in dd if k in d] for k in all_keys})
sys.stdout.flush()
layout.addWidget(btn)
sorted(a.keys())
A[np.lexsort((A[:, (0)], A[:, (1)]))]
session.commit()
plt.hist(np.clip(values_A, bins[0], bins[-1]), bins=bins)
plt.show()
time.sleep(0.1)
lst[:] = [word for words in lst for word in words.split()]
requests.delete(url, data=json.dumps(data))
earth.speed(0)
mars.speed(0)
df.stack().value_counts()
b.sort(key=float)
autoreconf - i
hdf5.close()
reactor.run()
dict(i=i, j=j, k=k)
sorted(lst, key=lambda x: (counts[x], -firstidx[x]), reverse=True)
changewriter.writerow([productcode, amountentered] + changecoins)
os.system(cmd)
plt.gcf().canvas.get_supported_filetypes()
plt.show()
threading.Thread.__init__(self)
s.setsockopt(socket.SOL_SOCKET, socket.SO_LINGER, linger_struct)
main()
sys.stdout.write(line)
x[y.nonzero()] = y[y.nonzero()]
self.assertEqual(response.status_code, 200)
pd.concat([pd.DataFrame(out, df.index, a), df], axis=1)
urllib.request.urlopen(req)
self.__getitem__(slice(start, stop))
itertools.chain(*([i] * i for i in range(1, 5)))
[range(2, 5), range(12, 17), 20]
time.sleep(1)
mySet = {x[0] for x in TUPLES}
print(os.listdir(path))
cursor.execute(sql, args)
extra_logger.setLevel(logging.INFO)
pylab.show()
v = int(float(s)) if int(float(s)) == float(s) else float(s)
deletefoo.fields[index]
fig.canvas.draw()
print((char, char.isalpha()))
plt.show()
plt.draw()
getattr(someobject, foostring)
np.append(a, z, axis=1)
map(str.strip, my_list)
list(ordered_dict.values())[2]
np.concatenate((arr[([0, n]), :].ravel(), arr[1:-1, ([0, n])].ravel()))
np.random.seed(1)
f.close()
list(set(a))
[int(i) for i in bin(x)[2:]]
HttpResponse(line)
br.set_cookiejar(cj)
plot_data = [[] for _ in positions]
a = np.array([np.array(list()) for _ in y])
(np.abs(a - val) <= tol).argmax()
plt.show()
__init__.py
[seen[c] for c in list]
QApplication.restoreOverrideCursor()
plt.show()
sys.stdout.flush()
QtGui.QWidget.__init__(self)
widget.destroy()
pd.concat([df.iloc[:, :1], df.shift(1), df.shift(2).iloc[:, 4:]], axis=1)
transmission_array.append(0)
app = Flask(__name__)
np.insert(B, np.arange(len(A)), A)
plt.show()
df
ax.set_ylim((0, 10))
mylist.append(item)
df.show()
button1.config(height=WHATEVER, width=WHATEVER2)
a[-1]
[x for x in ls if ls.count(x) == 1]
ones = [x for x in l if x[1] == 1]
main()
f.close()
fout.close()
json_data = json.loads(response.text)
self.fig.canvas.draw()
termios.tcsetattr(sys.stdin, termios.TCSADRAIN, old_settings)
reverse_dict.setdefault(value, []).append(keypath)
mlab.show()
list(itertools.chain(*l2))
new_list.append(item[1])
out = [l for l in out if l]
json.loads(text)
nltk.tokenize.sent_tokenize(text)
self.response.out.write(photo.imageblob)
time.sleep(2)
(x[i:j] for i, j in itertools.combinations(range(len(x) + 1), 2))
[i for i, j in zip(x, y) if i == j]
driver.switch_to_window(driver.window_handles[0])
ts.ix[ts.index.indexer_between_time(datetime.time(9), datetime.time(18))]
max(max(p[1:]) for p in PlayerList)
print(os.walk(DIR_PATH).next()[1])
pool = Pool(processes=4)
plt.show()
print(aslocaltimestr(datetime.utcnow()))
plt.show()
ser.read(bytesToRead)
aa = [d[k] for k in f]
np.transpose(arr, [2, 0, 1]).reshape(5, -1)
f(lambda x, y: x + y, 1, 2)
print(etree.tostring(bar, pretty_print=False, with_tail=True))
results[i].append(benchmark(i))
unique_list.append(sorted(item))
plt.show()
db.close()
plt.gca().add_artist(myline)
plt.show()
plt.show()
isinstance(n, int)
img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)
pylab.show()
[x[0] for x in G]
result = [y for y in (expensive(x) for x in mylist) if y]
self.connection.commit()
np.concatenate([a[(np.newaxis), :], b[(np.newaxis), :]], axis=0)
tekstboks2.pack()
plt.subplot(211)
list(permutations(list_of_tuples))
self.ax.set_xlim(0, R + pR)
deleted[k]
httpd.serve_forever()
x.shape
ts1.corr(ts2)
pkgutil - -pkgs
res.reset_index()
z = [x] + (y if isinstance(y, list) else [y])
formatdate(time.mktime(dt.timetuple()))
np.array_equiv(A, B)
myArray[1][1] == 2.71828
fro.close()
zip(*([s] * 2))
list(itertools.chain.from_iterable(L))
x = str(something)
print((value, count))
[(len(list(g)), k) for k, g in itertools.groupby(l)]
test.append(pd.Series(200, index=[101]))
[1] * 5
str(int(value))
Dataset.objects.filter(i_end_int__gte=x, i_begin_int__lte=x)
zip(a, x)
plt.plot(x, y)
next(gen)
print(first.lower() <= second.lower() <= third.lower())
list(chain.from_iterable(a))
[(x * (2 - x % 2)) for x in a_list]
ax.plot(x, y)
instance.save()
random.shuffle(array)
X_train, y_train, X_val, y_val, X_val, y_val
p.wait()
list1 = [_f for _f in list1 if _f]
print(len(unique_values))
ax.set_xticks(np.arange(data.shape[1]) + 0.5, minor=False)
self.__init__(*args, **kwargs)
Response(status=204)
plt.figure(figsize=plt.figaspect(1))
sys.stdout.flush()
plt.draw()
print(self.bar)
nlargest(5, vector, key=itemgetter(1))
random.shuffle(s)
bin(10)
list(product(x, chain.from_iterable(y)))
msg.attach(MIMEText(text))
BillboardTracker.objects.filter(expiry_date__le=datetime.now())
func2(**locals())
bsizer.Add(yourTxtCtrl, 1, wx.EXPAND)
sum(n for _, n in structure)
ssh.close()
do_something()
a[index] += 1
matplotlib.pyplot.show()
handler.setLevel(logging.DEBUG)
json.dumps(data, ensure_ascii=False)
a.add(2)
zip(s, s)
x[np.isnan(x)] = something_not_nan
self.grid_columnconfigure(2, weight=1)
B = np.linalg.inv(A.T).T
[(sum(e) / len(e)) for e in zip(*data)]
df1[df1 == 1].count()
os.getlogin()
process.wait()
sys.exit(1)
words = f.read().split()
cursor.close()
b += int(a)
br.add_handler(PrettifyHandler())
reactor.run()
writer.writerow(csvdata)
a = np.hstack(([0.2], np.linspace(1, 60, 60), [60.8]))
current_command()
pylab.hist([random_triangular(1, 6, 5) for t in range(10000)])
moving_average(a, n=4)
tf.py_func(func, inp, Tout, stateful=stateful, name=name)
result = set(x for l in array for x in l)
plt.show()
timeit([x for x in a if x in b])
ax = fig.add_subplot(111)
plt.show()
QtGui.QMainWindow.__init__(self)
d = dict((k, v) for k, v in list(d.items()) if k)
sys.exit(app.exec_())
print(soup.prettify())
fh.close()
plt.show()
df.apply(lambda x: x.apply(lambda x: [] if math.isnan(x) else x))
app.run(server=server)
arr.sum(axis=1).shape
r = [[] for i in range(4)]
df.append(df.sum(numeric_only=True), ignore_index=True)
a.get() + b.get()
lst.append(lambda x: f(x, i))
app.root.mainloop()
[x for x in L if x >= 0]
print(key, value)
setattr(module, name, value)
print(df.applymap(lambda x: x > 1))
[x[1] for x in sorted(random.sample(enumerate(myList), K))]
logging.set_up_done = True
np.hstack(results)
(a == b).sum()
newsampledata.sample(n, replace=True).reset_index(drop=True)
[sum(map(f, x)) for x in data]
sns.heatmap(data, ax=ax)
tornado.ioloop.IOLoop.instance().start()
time.sleep(0.1)
list(dict((tuple(x[:2]), x) for x in L).values())
[wordList[i] for i in indexList]
print(s.recv(1024))
sum(a[i] != b[i] for i in range(len(a)))
do_something_with(lines)
window.Minimize()
fig.canvas.draw()
fig.canvas.draw_idle()
dict.__init__(self, *args, **kwargs)
self.table.setColumnCount(5)
root.destroy()
signal.signal(signal.SIGINT, signal.SIG_DFL)
ax.pcolormesh(x, y, z, cmap=mpl.cm.Reds)
unittest.main(*args, **kwargs)
result = map(sum, a)
pd.concat([pd.DataFrame(a), pd.DataFrame(b)], axis=1)
lst.extend([5, 6, 7])
col.find_one()
numbers = iter(list(range(100)))
my_queue.put(x)
len({s[i:i + n] for i in range(len(s) - n + 1)})
shutil.copyfileobj(buf, fd)
ftp.cwd(path)
[x for item in l for x in repeat(item, 2)]
dict(zip(headers, zip(*sdata)))
pattern.format(s)
random.shuffle(x)
virtualenv
pd.isnull(df).any()
tasklist.append(newtask)
[x for x in lst if x.lower() not in seen and not seen.add(x.lower())]
array([[1, 0, 0], [0, 1, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [0, 1, 0]])
log = logging.getLogger(__name__)
app.run()
sys.exit(0)
list(takewhile(lambda x: x < 5, list(range(5))))
p.kill()
np.array_equal(A, B)
plt.show()
Base.metadata.create_all(engine)
new_array = np.array(df.index.to_pydatetime(), dtype=numpy.datetime64)
output.close()
nodes.CallBlock([call], [], [], [])
requests.post(url, data=data, headers=headers)
lambda i: isinstance(i, int)
any(isinstance(e, list) for e in my_list)
time.sleep(5)
{{value | unlocalize}}
test[(1), :]
df[0].to_json()
s.getvalue()
t = tuple(lst)
math.ceil(x / 500.0) * 500.0
print(ET.tostring(graph, pretty_print=True))
zip(*[s, s])
im = Image.open(StringIO.StringIO(buffer))
test[:, (0)]
c = list(itertools.chain.from_iterable(zip(a, b)))
[item for item, flag in zip(s, b) if flag == 1]
reactor.run()
_draw_point(renderer, position, j, i)
os.path.dirname(sys.executable)
print(min(strings, key=len))
ax.set_xlim(0.5, 5)
[(x + (y,)) for x, y in zip(a, h)]
self.sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
sorted(mydict.items())
self.log.setLevel(logging.INFO)
np.multiply(np.arange(1, 5), 2 ** np.arange(0, 4)[np.newaxis].T)
[0, 1, 2]
plot(x, y, color=color)
Image.open(file).verify()
[x for pair in zip(l, l) for x in pair]
func(*args, **kwargs)
reactor.run()
{randint(0, 9): (v + 1) for v in list(mydict.values())}
R = np.array(mean_data[:, (0)])
layout.addWidget(QtGui.QLineEdit(self))
fcntl.flock(self.__lock_file.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
sys.exit(0)
r.grid(sticky=(N, E, S, W))
cv2.destroyAllWindows()
plt.show()
matches.append(os.path.join(root, filename))
regex.findall(filename)
a + b
print((m.span(), m.group(0)))
list(s)
[a for a, b in list(params.items())]
cur.close()
datetime.datetime.combine(tdate, datetime.time.min)
c = tuple(x - y for x, y in zip(a, b))
plt.show()
[e for sub in a for e in sub]
pygame.quit()
p.start()
dall.update(d)
X - np.dot(A, B)
Blender.Redraw()
im.wcs[::2, ::2]
server_socket.close()
print([key for key, group in groupby(x) if len(list(group)) > 1])
app.run(debug=True)
func()
requests.get(url, verify=path_to_bundle)
all(x[i] - x[i - 1] == x[i + 1] - x[i] for i in range(1, len(x) - 1))
app.run()
s.seek(0, os.SEEK_END)
pd.__version__
mainwin.mainloop()
plt.show()
map(tuple, np.array(list(combinations(list(range(N - 1, -1, -1)), M)))[::-1])
print(f.read())
plt.bar(x, y)
widget.deleteLater()
sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
df.columns = df.columns.str.lower()
size = fields.IntegerRangeField(min_value=-100, max_value=100)
pd.concat([df, dict_col.apply(pd.Series)], axis=1)
main()
app.run()
ax2.xaxis.set_visible(False)
now = datetime.datetime.now()
app.MainLoop()
os.remove(os.path.join(dir, f))
(dt - datetime.datetime.utcfromtimestamp(0)).total_seconds()
func(that, session=session, *args, **kwargs)
date = datetime.datetime.fromtimestamp(your_timestamp / 1000.0)
print(np.mgrid[:5, :5])
sys.stdout.flush()
root.mainloop()
numpy.random.seed(0)
window.mainloop()
pprint(stiff)
wx.Frame.__init__(self, *args, **kwargs)
plt.subplot(2, 1, 2)
sys.exit(app.exec_())
a[np.array(n1)[:, (np.newaxis)], np.array(n2)[(np.newaxis), :]]
plt.legend(loc=0)
f_in.close()
print(a[s])
[[y for y in x if y not in to_del] for x in my_list]
time.sleep(0.05)
[t for t in tuples if all(f(t) for f in filters)]
json.loads(json.loads(b))
plt.show()
[(1, 5), (8, 11), (200, 202)]
my_dict = {k: (v if len(v) > 1 else v[0]) for k, v in list(tmp.values())}
dict1.update((k, dict2[k]) for k in keys)
list(itertools.combinations(items, 2))
pid, stdin, stdout, stderr
time.mktime(datetime.datetime.now().timetuple()) * 1000
ax.collections
data = [float(fractions.Fraction(x)) for x in data]
doc = lxml.etree.parse(xml)
(s[i:j] for i in range(length) for j in range(i + 1, length + 1))
my_list.remove(4)
scipy.array(x).ravel().tolist()
name = models.CharField(max_length=255)
itertools.chain.from_iterable([i] * i for i in range(1, 5))
l.append(x[:len(x) - k])
b = a[0][:]
data = p.stdout.readline()
plt.show()
[element for tupl in tupleOfTuples for element in tupl]
GC.remove_edge(clique[0], clique[1])
new_list = [{transform[k]: v for k, v in list(d.items())} for d in old_list]
pylab.show()
np.place(arr, ~np.in1d(arr, valid), 0)
conn.send(stranza)
fig.canvas.draw()
plt.show()
(A == B).all()
startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
date += datetime.timedelta(days=1)
cbar.set_clim(newimg.min(), newimg.max())
writer.writerows(sheet.row_values(row) for row in range(sheet.nrows))
f = (lambda a, b, c: lambda x: a + b * c - x)(a, b, c)
[a for a in x if a != 2]
s1[s1.isin(s2)]
pygame.event.poll()
data = json.loads(resp.text)
sorted(lst)[-20:]
pptable(x_axis, y_axis, a.tolist())
exec(open(filename).read())
s.reset_index()
list(set([(a, l.count(a)) for a in l]))
b = np.fill_diagonal(np.zeros((N, N)), value)
QtCore.QThread.__init__(self)
session = request.session
numpy.matrix(numpy.identity(n), copy=False)
list(itertools.product(*arrays))
bytearray(random.getrandbits(8) for _ in range(size))
fig.subplots_adjust(bottom=0.2)
a.A * ~mask.A
sorted(array, key=lambda x: x[:24])
print(mirror([mirror(sublist) for sublist in inputs]))
deletemydict[k]
object_list.sort(key=lambda x: string_list.index(x.key))
list(itertools.zip_longest(fillvalue=0, *lists))
driver.find_element_by_id(tc.value).click()
cherrypy.engine.block()
plt.draw()
pprint({k: getattr(f.__code__, k) for k in dir(f.__code__)})
[x for x in lst if x % 2]
plt.scatter(x, y, c=t, cmap=cm.jet)
deletemy_dict[key[-1]]
time.sleep(0.1)
print(uuid.uuid4())
A[~np.isnan(A)].mean()
P[np.arange(n), x, y]
form = ContactForm()
numbers.append(random.randint(a, b))
client.close()
s.index(t.lower())
pygame.mouse.get_pos()
t = s.reshape(-1, k)
random.shuffle(l, random.random)
temp.iloc[[0, 1, 4]].index.tolist()
urlfetch.set_default_fetch_deadline(60)
print([(x - empty) for x in test])
sys.exit(0)
float(s)
time.sleep(1)
plot(x, sin(x) * cos(x))
[x for x in range(m) for y in range(n)]
request = client.read_holding_registers(0, 4, unit=1)
zlib.decompress(data)
print(line.rstrip())
sorted(list(counts.items()), reverse=True, key=lambda tup: tup[1])[:top]
df.stack(0).reset_index(1)
app.exec_()
datetime.now()
time.sleep(1)
log.start()
out = (m[1:] > m[:-1]).sum() + m[0]
plt.show()
list(filter(os.path.isdir, os.listdir(os.getcwd())))
df.columns[df.isnull().any()].tolist()
ax.scatter(x, y, zflat)
tk.Text.__init__(self, *args, **kwargs)
df.groupby(df.index).max()
a = np.arange(10)
d = ast.literal_eval(some_string)
dict(list(dict1.items()) + list(dict2.items()))
plt.show()
obj = session.query(ObjectRes).order_by(ObjectRes.id.desc()).first()
plt.ylim([-0.5, 1.5])
indices = [i for i, x in enumerate(myList) if re.match(regex, x)]
Series(df.values.ravel()).unique()
plt.ylim(-1, 1)
driver.close()
pyodbc.connect(connect_string, autocommit=True)
self.widget_name.deleteLater()
len(set(len(x) for x in l)) <= 1
val = img.getpixel((x, y))
a = [a]
D()
foo = decorator(foo)
time.sleep(2)
a = [0] * 10000000
df.reindex(columns=cols)
A = map(lambda t: list(t), A)
img = client.images.get(IMAGE_ID)
text.splitlines()[0]
self.response.out.write(template.render(path, template_values))
raise FileNotFoundError(errno.ENOENT, os.strerror(errno.ENOENT), filename)
file.close()
time.sleep(0.01)
print(getglobals(f))
max(set(lst), key=lst.count)
ExampleApp().run()
author = models.CharField(max_length=60)
sys.stdout.flush()
plt.axis([min(x_arr), max(x_arr), max(y_arr), 0])
[myfunc(x, y) for x, y in myiter(data)]
all(bb[k] == v for k, v in aa.items() if k in bb)
plt.show()
datetime.date.fromordinal(datetime.date.today().toordinal() - 1)
plt.plot(x, y)
root.destroy()
set(x)
x[:, (i)] = np.roll(x[:, (i)], i)
p1.stdout.close()
print(cmp(list1, list2))
self.main.show()
plt.show()
Gtk.main()
dict(zip(unique, counts))
sorted(lst, key=str.lower, reverse=True)
sorted(myList, key=itemgetter(1))
p.wait()
results = dict.fromkeys(inputs, [])
[indexes[x] for x in l]
f = x ** 2 + 1
self.list_of_strings.append(str_to_add)
words[word[0] + word[-1]].append(word)
s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
self.a = a, self.b = b
sock.setsockopt(socket.IPPROTO_TCP, TCP_KEEPALIVE, interval_sec)
plt.show()
plt.show()
(i * i for i in range(5))
call([command, parameter])
pyplot.show()
d[key][0] = x
(dt.replace(month=dt.month % 12 + 1, day=1) - timedelta(days=1)).day
plt.close()
driver = webdriver.PhantomJS()
print(match.group(0))
time.sleep(float(sys.argv[1]))
np.where(~a.any(axis=1))[0]
[z0] * len(seconds)
a[-1] * (a[-1] + 1) / 2 - sum(a)
50 - List1[0][0] + List[0][1] - List[0][2]
ax.plot(x, y)
shutil.copy2(src, dst)
client.disconnect()
df = df.loc[mask]
m.save()
[i for i, _ in itertools.groupby(ks)]
entity.key().id_or_name()
ax.set_ylim([-1, 10])
np.reshape(data, newshape=(len(data) / 5, 5))
self.Bind(wx.EVT_ERASE_BACKGROUND, self._onEraseBackground)
1, 0, 1, 0, 0, 0, 0, 0, 1, 0
plt.show()
pd.rolling_mean(aapl, 200).plot()
df[~pd.isnull(df[list_of_cols]).all(axis=1)]
df.apply(lambda x: x.apply(lambda x: [] if isnan(x) else x))
min(t, key=lambda i: (i[1], -i[2]))
ax.autoscale()
response = br.submit()
string_list.sort(key=lambda s: len(s), reverse=True)
plt.show()
next((i, d) for i, d in enumerate(lod) if 1 in d)
sorted(l, key=lambda name_score: int(name_score[1]), reverse=True)
rows = table.tbody.find_all(True, recursive=False)
time.sleep(0.1)
replace(my_dict)
json.dumps(c.__dict__)
response = urllib.request.urlopen(req).read()
np.random.shuffle(arr)
f.write(data)
foo = Foo()
root.mainloop()
next([i for i in userInput if i in wordsTask])
QtGui.QDialog.__init__(self, parent)
numpy.linalg.lstsq(a, b)
browser.submit()
[(entry if tag in entry else []) for tag in tags for entry in entries]
plt.show()
element.clear()
conn.commit()
A.test()
QMainWindow.__init__(self)
s.sendmail(sender, recipients, msg.as_string())
map(id, a)
proc.stdin.close()
y *= np.hanning(len(y))
a.shape
np.where(np.triu(np.ones(A.shape[0], dtype=bool), 1), A.T, A)
np.reshape(self.data, newshape=(self.data.shape[0] / 5, 5))
print(sum(iter(lambda : len(sys.stdin.read(4096)), 0)))
contents = self.view.substr(sublime.Region(0, self.view.size()))
sorted(new_lst, reverse=True)
gevent.sleep(5)
print(expr.evalf(subs=dict(a=2, b=4, n=5)))
np.where(arr == arr.min())
a.__getitem__(slice(0, 1)).__setitem__(0, 1)
os.lseek(fd, 0, os.SEEK_SET)
logging.getLogger().setLevel(logging.DEBUG)
parser = argparse.ArgumentParser()
dict.fromkeys(my_list, 0)
plt.show()
pool.join()
bin(int(binascii.hexlify(st), 16))
np.sqrt(((A - B) ** 2).sum(-1))
print(json.dumps(out))
plt.show()
list({t[1]: t for t in reversed(l)}.values())
ax.add_artist(rect)
web.HTTPError.__init__(self, status, headers, data)
ax.set_xticks(list(range(0, 11)))
img = cv2.imdecode(nparr, cv2.CV_LOAD_IMAGE_COLOR)
value.Increament()
df1.merge(df2)
[(((x - 1) % 8 + 2) * x) for x in range(1, 21)]
pyl.draw()
ax[1].autoscale(True)
time.sleep(1)
{k: d1[k] for k in d1.keys() & l1}
plt.show()
x.loc[(x.B >= 111.0) & (x.B <= 500.0)]
dict(y, **x)
list_.sort(key=lambda x: len(x[1]))
array([[1, 2], [0, 2]])
Note.objects.filter(created__year=years.year)
np.nonzero(starts)[0], np.nonzero(ends)[0]
plt.show()
print(p.stdout.read())
print(handle.read())
[el for el in lst if isinstance(el, collections.Iterable) and st in el]
random.shuffle(keys)
print(test[numpy.in1d(test[:, (1)], wanted)])
int(numberA), int(numberB)
np.linalg.lstsq(a, b)
somelist.sort(cmp=lambda x, y: cmp(x.resultType, y.resultType))
set(df.Col1).union(set(df.Col2))
s.decode(encoding)
[c for c in words if not c.isalpha() and not c.isdigit() and not c.isspace()]
[d[x] for x in a]
float(1.001).is_integer()
foo()
self.user.get_full_name()
self.Bind(wx.EVT_CHAR_HOOK, self.hotkey)
arr[1, -2]
image[idx] = chex[idx]
print([tuple(t[1] for t in v) for k, v in groupby(myList, key=itemgetter(0))])
p.kill()
ax1.legend(loc=2)
f.close()
list(my_dataframe)
root.mainloop()
[k for k, v in list(my_counter.items()) if v > 1]
df = pd.concat(list_of_series, axis=1).transpose()
driver.switch_to_window(driver.window_handles[1])
sys.stdout.write(chr(c + 48))
equation1(*list_of_parameters)
bool(set(a) & set(b))
os.kill(pid, 0)
self.create_socket(socket.AF_INET, socket.SOCK_STREAM)
print(line)
Player.objects.filter(Q(games1__pk=self.pk) | Q(games2__pk=self.pk))
values = json.loads(data)
np.triu(A.T, 1) + A
x = rnorm(n=100, mean=0, sd=1)
l.append((4, 5))
ax.set_xlim([-1, 10])
[[j.span() for j in rex.finditer(i)] for i in sequence_list]
browser.set_window_size(1400, 1000)
map(math.log10, x)
sorted(tuples, key=lambda x: (x[0], x[2]))
A[np.isnan(A)] = 0
froms[p[0]].append(p)
result = np.array([list(g) for _, g in groupby(a)])
BeautifulSoup(r.content).title.text
out = np.concatenate(input_list).ravel()
(area_width - string_width) / 2
urlparse.urljoin(url, urlparse.urlparse(url).path)
mrg.drop(drops, axis=1)
list(compress(seq, criteria))
x = 256 * ord(pS[0]) + ord(pS[1])
xvfb.terminate()
(e.T / e.sum(axis=1)).T
pylab.show()
[0, 1, 0, 9, 0, 25, 0, 49, 0, 81]
quit_gracefully()
a += b[idx].sum(0)
d = np.array(dataPoints.tolist())
posts = TodaysObject.objects.filter(datafilter)
first2vals = [v for v in list(mydict.values())[:2]]
np.random.shuffle(A)
plt.legend()
data[0]
s.close()
cls.objects.get(pk=self.pk)
d2 = dict((k, v) for k, v in list(d1.items()) if v > 0)
[1, 1]
z = dict(itertools.chain(iter(x.items()), iter(y.items())))
np.median([2, 0, 1, 0, 0])
B[X.ravel()] = A.ravel()
print([k for k, v in d.items() if v == 1])
draw()
runserver.py
plt.plot(x, f(x), zorder=1)
redirect(client.authorize_url)
urllib.request.urlopen(url, postData)
plt.show()
df[df.ix[:, 2:].abs().lt(1).all(1)]
k.set_contents_from_string(data_file.readlines())
df.reindex(idx)
subprocess.Popen([name], stdout=devnull, stderr=devnull).communicate()
reactor.run()
gtk.main()
print(dt.year, dt.month, dt.day)
timedelta(hours=6) / 2
self.modules = []
df1.merge(df2)
setattr(self, k, v)
os.unlink(path)
plt.show()
sys.exit(app.exec_())
l[i].append(j)
ax.plot(list(range(10)))
np.argwhere(M.T == 0).squeeze()
print(list(set(tuple(i) for i in a)))
browser.get(url)
x.reshape(2, 2, 2, 2).swapaxes(1, 2).reshape(4, -1)
mpl_plt.show()
con.close()
locals().update(parm)
result = DataFrame(result).reset_index(drop=True)
type(b) is Test1
map(list, set(map(tuple, k)))
d = {t.key: t for t in [t0, t1, t2]}
b.shape
any(x in someDict for x in someList)
dists /= dists.max(axis=(0, 1))
d = dict((k, tuple(v)) for k, v in d1.items())
time.sleep(0.5)
plt.show()
array1.reshape(array2.shape)
l.pop(0)
b = map(lambda x: x[:9], g)
os.path.join(path, format)
app.mainloop()
plt.clf()
np.random.choice(np.flatnonzero(b == b.max()))
instance.save()
print(np.allclose(r[1], b))
list(d.keys())
parse_freebase_quadruple_tsv_file(file_name)
first2pairs = {k: mydict[k] for k in list(mydict.keys())[:2]}
writer.close()
[(i, z) for i in [1, 2] for z in zs_i]
((x, y) for x in range(width) for y in range(height))
pylab.show()
ax.set_yticks([])
cursor.execute(sql, args)
d[cols[0]] = dict((headers[idx], v) for idx, v in enumerate(cols[1:]))
sys.exit(app.exec_())
group[group.apply(lambda x: len(x) > 1)]
root.mainloop()
random.shuffle(itrange)
winfile.close()
self.exec_()
result[i].append(j)
avgs[np.where(binplace == 1)]
self.user_set.all()
sys.exit()
sess.run(train_op)
random.randint(1, 6)
server.mainloop()
a = numpy.nan_to_num(a)
my_file.copy(to_file)
Py_Finalize()
find_eulerian_tour(cg4)
df[-mask.any(axis=1)]
deletetest[2]
b += [c]
plt.gcf().axes[0].xaxis.set_major_formatter(formatter)
rdd = df.rdd
plt.show()
print(doc.toxml())
plt.plot(xs, density(xs))
numpy.column_stack((a, b, c))
A - mean[:, (np.newaxis)]
grid[[a[second_mask] for a in np.where(mask)]] = 100
func()
fcntl.ioctl(s.fileno(), SIOCGIFFLAGS, ifr)
auth_login(request, user)
a[0, 1, 2]
print((key, values))
frame.axes.get_xaxis().set_ticks([])
ax2.contour(theta_edges[:-1], r_edges[:-1], H)
print(t.total_seconds())
map(len, s.split())
max(set(list), key=list.count)
ax1.yaxis.tick_left()
foo = _log_error(logger)(partial(bar, someparam))
urllib.request.install_opener(opener)
self.box.grid(column=0, row=0)
sys.exit(0)
request.session.set_expiry(request.session.get_expiry_age())
dict([(an_object.name, an_object) for an_object in object_list])
sys.exit()
render_to_response(your_custom_template, ctx)
df.ix[0]
draw.text((10, 0), txt, (0, 0, 0), font=font)
layout.addWidget(self.lineedit)
ax.add_patch(polygon1)
a.split()
[9.444064187694842, 1.2256912728995506]
{{jsonData | safe}}
not seen.add(x)
f.close()
{x: (x * x) for x in range(10)}
sys.stdout.write(data)
plot(X, Y)
wx.Dialog.__init__(self, *args, **kwds)
datetime.timedelta(hours=-5)
time.mktime(now.timetuple())
time.sleep(10)
tuple(l.T)
mngr.window.setGeometry(newX, newY, dx, dy)
isinstance(b, Test1)
my_file.seek(0, os.SEEK_END)
[s[i:j] for i, j in zip_longest(start, end)]
np.random.shuffle(b)
writer.writerows(new_rows)
print(list(matdata.keys()))
con.close()
reverse(str1[1:]) + str1[0]
fig.canvas.draw()
print(simplejson.loads(json_string))
__init__.py
self.canvas.draw()
{{form.certification()}}
[ComVisible(true)]
df = pd.concat(list(pd.read_csv(Reader(gen()), chunksize=10000)), axis=1)
len(haystack) - len(parts[-1]) - len(needle)
sorted(l, key=lambda x: (x[:-1], x[-1].isdigit(), x))
dict(widget_set.pop())
plt.show()
s.group(0)
list(q)[0]
print(lilfoo.baaz)
sorted(l, key=lambda x: float(x[1]))
self.button.pack()
print(regex.search(data).groups())
sys.exit()
ax.plot_surface(X, Y, Z)
plt.show()
print([n for n in (x.giveMyNum() for x in q) if n > 1])
L2.sort(key=lambda x: L.index(x))
int(log10(x)) + 1
mySet = set(x[0] for x in TUPLES)
os.kill(9999999999999, 0)
user.profile.save()
Foo.__init__.__self__.__class__
print(track.permalink_url)
a, b = int(a), a - int(a)
plt.show()
newlist.append(i)
np.frombuffer(test)
dict([(k, v) for k, v in list(mydict.items()) if k >= 6])
l[:1] + [b for a, b in zip(l, l[1:]) if a != b]
left.remove(left[0])
local_file.write(f.read())
[seq for seq in my_list if [item for item in seq if some_condition()]]
[(2 ** i) for i, v in enumerate(bin(109)[:1:-1]) if int(v)]
server.serve_forever()
print(key, d[key])
model_to_dict(instance, fields=[field.name for field in instance._meta.fields])
sys.exit(0)
{k: min(h1.get(k) or h2[k], h2.get(k) or h1[k]) for k in list(h1.keys()) + list(h2.keys())}
platform.system()
sorted(A, key=A.get, reverse=True)[:5]
stdout, stderr = p.communicate()
[age] = [t[1] for t in mylist if t[0] == 10]
Publication.objects.all().delete()
[(a, b) for a in A for b in B if a in b]
number = random.randint(5, 20)
some_queue.get()
re.findall(s, text)
np.min(np.nonzero(np.hstack((B, 1))))
m = coo_matrix((v, (l - 1, c - 1)), shape=(l.max(), c.max()))
func(func, *args, **kwargs)
pygame.display.flip()
reactor.run()
c.setopt(pycurl.WRITEFUNCTION, lambda bytes: len(bytes))
unsure_rows[key].append(row[key])
(item for sublist in list_of_lists)
numpy.digitize(b, a)
cleaned = [_f for _f in map(str.strip, words) if _f]
ax.set_xlim(-10, 10)
app.MainLoop()
p = sparse.dia_matrix(1.0 / np.array(x), shape=(len(x), len(x)))
numpy.array([0.24])[0] == 0.24
type(list(d.values()))
self.assertEqual(content, expected_content)
s = pd.Series([0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1])
glob.glob(name)[0]
result_dict = [u.__dict__ for u in my_query.fetchall()]
curses.endwin()
time.sleep(1)
getattr(filters, method)(**options)
driver.switch_to_window(driver.window_handles[-1])
{k: map(sum, zip(*v)) for k, v in list(d.items())}
a[:, (1)]
reactor.run()
newNums = [i for i, x in enumerate(nums) if x == 12]
os.close(fh1)
fig = plt.figure(figsize=(6, 6))
now = datetime.now()
s.play()
werte[1:-1][(diff(werte)[:-1] > 0) * (diff(werte)[1:] < 0)]
numpy.unravel_index(A.argmin(), A.shape)
f.__dict__.update(b)
sys.stdout.buffer.write(pdf_file.read())
ax.xaxis.set_minor_locator(MultipleLocator(0.2))
df = df[df.columns[:11]]
[True, True, False, True, True]
f = lambda *x: sum(x) - 1
print(dir(__builtins__))
contents = urllib.request.urlopen(request).read()
print(args)
ax.yaxis.set_ticks([16, 8, 4, 2, 1, 0])
numpy.reshape(array, array.shape + (1,))
min(timeit.repeat(lambda : dict((k, v) for k, v in zip(keys, values))))
deletex[i + 1:]
self.setWindowFlags(Qt.FramelessWindowHint)
list[0].pop(0)
req.close()
[x[0] for x in sorted(data, key=lambda x: x[1], reverse=True)[0:6]]
pdb.set_trace()
[elem[:12] for elem in g]
plt.show()
setattr(module_obj, method_name, func)
self.clickcnx.close()
df.reindex(approach1(df.A.values, df.B.values))
re.findall(pattern, s)
pd.tslib.repr_timedelta64
app.run(debug=True)
next((x for x in lst if x % 2 == 0))
self.assertDictEqual(a, b)
b.insert(bisect(b, a), a)
union([(10, 12), (9, 16)])
f.write(line)
build_stylus()
br.set_response(response)
[k for k, v in list(mydict.items()) if list(mydict.values()).count(v) > 1]
pygame.init()
dev.leds(verbose=True)
[sum(sublist) for sublist in zip(*myListOfLists)]
pygame.init()
ax = fig.add_subplot(111)
res = cv2.bitwise_and(closex, closey)
print(__file__)
plt.show()
eval(x)
cv2.destroyAllWindows()
c = [[(x + b[i]) for i, x in enumerate(y)] for y in a]
funkytown._asdict()
fig, ax = plt.subplots()
print(read_records(data))
Foo().bar()
glUniform1i(self.tex2D, 0)
list.__getitem__(self, index)
print(parser.parse(treebank.sents()[0]))
numpy.vstack((x, y))
[[], []]
ax.set_xticks(xticks)
button.clicked.connect(lambda : self.commander(command))
l[0][0] += 1
tree.removeItemWidget(i, 0)
fig.canvas.draw()
sys.getsizeof(i)
print(fibonacci(int(eval(input()))))
ax = fig.add_subplot(1, 1, 1)
d = {b: a[:, (i)] for i, b in enumerate(a)}
tk.mainloop()
f.write(content)
TextCtrlInstance.GetValue()
np.flatnonzero(~a[:-2] & a[1:-1] & a[2:])
asdf.save()
plt.ylim(10, 40)
libdl.dlclose(handle)
Z = func(X, Y)
plt.show()
ax.set_yticklabels(y_label, fontsize=20)
cursor.execute(qry, list(myDict.keys()) + list(myDict.values()))
os._exit(0)
random.shuffle(r)
my_treeview.setEditTriggers(QAbstractItemView.NoEditTriggers)
total = value[c1 - 1] + value[c2 - 1]
plt.show()
df.groupby(level=0, sort=False).transform(lambda x: sorted(x, key=pd.isnull))
print(lxml.etree.tostring(doc))
m.mask = np.repeat(i == j, k.size, axis=2)
subversion.search(s).group()
raise AssertionError(expression2)
calendar.monthrange(2012, 2)[1]
frames.append(pandas.DataFrame(row))
np.sqrt((a * a).sum(axis=1))
QtGui.QWidget.__init__(self)
print(os.path.abspath(my_module.__file__))
plt.show()
self.view.setModel(self.model)
random.shuffle(word)
data.setdefault(k, []).append(v)
self.func(*args, **self.kwargs)
print(y.max())
df.apply(OrderedDict)
print(list(date_range(5, 2)))
QMainWindow.__init__(self, *args)
phrase.strip().capitalize()
min_keys = [k for k in d if d[k] == min_value]
list(choice(json_obj[k]).values())[0]
df.head()
df.plot(subplots=True)
[tuple(d.values()) for d in l]
time.sleep(1)
sys.path.insert(0, p)
plt.show()
sys.stdout.write(next(spinner))
new_lst.append(x)
sys.stdout.flush()
curses.endwin()
PyErr_Clear()
np.asarray(np.bmat([[A, Z], [Z, B]]))
ax.add_patch(polygon2)
sock.bind((UDP_IP, UDP_PORT))
nodeenv - -python - virtualenv
p.wait()
[(sum(group) / size) for group in zip(*([iter(data)] * size))]
list(itertools.product(*l))
helloworld.helloworld()
plt.show()
pd.to_numeric(s)
sum(x > 7 for x in a)
abs(n)
df = pd.read_csv(io.StringIO(string), delim_whitespace=True)
ax = pylab.gca()
p.stdin.close()
file.close()
threading.Timer(60, f).start()
plt.show()
self.create_socket(socket.AF_INET, socket.SOCK_STREAM)
x[0].append([])
l = list(t)
obj.func1()
HttpResponse(html)
sys.stdout.flush()
sum(bool(x) for x in l)
c = np.in1d(a, b)
diag = [row[i] for i, row in enumerate(mat)]
[0, 0, 0, 0, 1, 1],
pygame.quit()
self.sections.clear()
all(a % i for i in range(2, a))
sys.stderr = logger
sys.exit(100)
time.sleep(10)
[[item for item in seq if some_condition] for seq in my_list]
list(range(start, end, step))
conn.close()
proc.wait()
plt.plot()
plt.show()
PyObject_HEAD_INIT(NULL)
age = models.IntegerField()
print(response.status_code)
main()
sorted(iter(cityPopulation.items()), key=lambda k_v: k_v[1][0], reverse=True)
f.write(bytes(bin_array))
sum([i for i in l1 if isinstance(i, int)])
np.meshgrid(x, x, sparse=True)
df.iloc[0:2, :]
logging.getLogger().addHandler(console_handler)
app.MainLoop()
max([x for x in ls if x < 0])
data = numpy.arange(5 * 4).reshape(5, 4)
all(x * y > 0 for x, y in zip(l1, l2))
app.MainLoop()
f = lambda x: x[0] * x[0] * x[0] + x[1] * x[1]
datetime.datetime.date(2011, 1, 1)
self.grid_columnconfigure(0, weight=1)
sleep(1)
plt.xlim(0, 125)
logger = logging.getLogger(__name__)
print([int(x) for x in T1])
A[~np.in1d(A.dot(cumdims), B.dot(cumdims))]
[x for x, y in groupby(L) if len(list(y)) < 2]
plt.scatter(x, y)
TimeModel.objects.create(time=td.total_seconds())
__init__.py
df.columns[pd.isnull(df).any()].tolist()
a = [([0] * 8) for _ in range(8)]
print(binascii.hexlify(content))
now.replace(minute=0, hour=0, second=0, microsecond=0)
p.wait()
plt.show()
sys.exit()
writer.writerows(rows)
time.sleep(5)
float(x)
sys.path.append(dirname(__file__))
all(x == L[0] for x in L)
[a for a in s if s.count(a) == 1]
fig, ax = plt.subplots()
np.multiply(a, b)
result = [separator.join(map(str, x)) for x in product(*lists)]
[name for name in data1 if name in data2]
df.drop_duplicates()
server_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
writer.close()
print(imap_conn.list())
plt.show()
os.path.dirname(sys.argv[0])
json.dumps(data)
[[random.random() for i in range(N)] for j in range(M)]
src.close()
gtk.main()
len(a) / np.sum(1.0 / a)
datetime.date.fromtimestamp(ts).month
df.divide(df.ix[0] / 100)
df.apply(lambda x: sum(x.isnull().values), axis=0)
print(json.dumps(e, cls=new_alchemy_encoder(), check_circular=False))
print(d.get(frozenset((2, 1))))
time.sleep(5)
l = [d for d in days if d.weekday() in [1, 2]]
barbar.py
[x for i, x in enumerate(y) if i != 1]
s.lstrip(punctuation)
data = urllib.request.urlopen(url).read()
wav_file.close()
ax.legend()
x()
os.rename(os.path.join(base, old_name), os.path.join(base, new_name))
plt.show()
ax.scatter(x, y, c=c, cmap=cmap)
chain.from_iterable(combinations(s, r) for r in range(1, len(s) + 1))
np.vstack(a)
ftpc.close()
fig.tight_layout()
ax.set_ylim(0, 10)
Response(serializer.data)
ax.set_xlim(0, 20)
plt.legend()
kNN1.fit(data, class_labels)
df.index
a = a[(a >= -100) & (a <= 100)]
datetime.datetime.fromtimestamp(1004256400)
self.finish()
p.terminate()
a.reshape(-1, np.prod(a.shape[-2:]))[:, ::-1].reshape(a.shape)
df.max(1)
matches.append([os.path.join(root, filename), error])
sock.connect((address, port))
func()
__init__.py
fig.close()
time.sleep(5)
R2a.__init__(self)
map(int, sum(map(lambda x: list(str(x)), lst), []))
plt.plot(x, x)
app.mainloop()
Series(df.Letter.values, index=df.Position).to_dict()
df.prod(axis=1)
l.sort()
dicts.flatMap(lambda x: list(x.items()))
sorted(li, key=lambda x: x[1])
[myfunc(a, b) for a, b in zip(idata, idata)]
sum(data[x::size] for x in range(size)) / size
root.overrideredirect(True)
[np.max(arr) for arr in np.split(v, np.where(mask)[0] + 1)]
r = client.post(URL, data=login_data, headers=dict(Referer=URL))
setattr(self, name, value)
print(top[0][1][2])
random.seed(1)
np.histogramdd(data, bins=(2, 2, 2))[0]
numpy.count_nonzero((25 < a) & (a < 100))
a += numpy.histogram(b, numpy.arange(len(a) + 1))[0]
sorted(arr[ind])
response = view(request)
a[np.isfinite(a)]
ax.xaxis.set_major_locator(MultipleLocator(20))
np.eye(d.shape[1]) * d[:, :, (np.newaxis)]
time.sleep(1)
plt.show()
dict(d1, **d2)
clf.fit(X_train, y_train)
[(0) for _ in range(10000)]
string.format_map({k: Pluralizer(v) for k, v in list(data.items())})
[c for c in df]
ax.set_navigate(False)
data = json.loads(response.body)
dict((c, string.count(c)) for c in string)
sys.path.insert(0, p)
self.stdout.write(data)
temp[::-1].sort()
[peaks([x, y]) for x, y in zip(xscat, yscat)]
[1, 4, 7]
fig.tight_layout()
[(arr[i], arr[-i - 1]) for i in range(len(arr) // 2)]
sys.exit(app.exec_())
df.loc[df.A.isin(a)]
list(_)
print(output[0])
[[1, 5], [6, 11]]
time.sleep(5)
print(argparse._sys.argv[0])
pd.DataFrame(data)
root.mainloop()
driver.manage().timeouts().pageLoadTimeout(15, TimeUnit.SECONDS)
matches.extend(isbn.findall(line))
y[:, ::2]
OrderedDict(items)
time.sleep(0.1)
a = np.array(a)
application = wsgi.WSGIHandler()
a = a.clip(min=0)
threading.Thread.__init__(self)
lambda x, y: set([x]) == (y if b else lambda x, y: x in y)
main()
plt.show()
random.randrange(100, 20001, 100)
plt.figure(figsize=(10, 7))
print(m.group(1))
cv2.waitKey(0)
f.close()
results.append((url, urlopen(url).read()))
ax2.set_xlim([0, repeat_length])
root.mainloop()
array = list(range(numCase))
list(solve(4))
plt.show()
convertfile.write(line)
match.start(1)
plt.show()
np.put(a, np.ravel_multi_index(idx.T, a.shape), 5)
stackless.run()
np.argmax(np.random.multinomial(1, a, 1))
lin.split()
print(dict(zip(keys, zip(*data))))
result = [dishes[key] for key in list(crucial.keys()) & list(dishes.keys())]
df
A.dot(B).dot(C)
sorted(points)
1 / 2
solution.sort_index()
df.isnull().any()
data = data.groupby(data.index).sum()
memory2.clear()
numpy.hstack((x, y))
name.ljust(15)[:15]
[datetime.date(2010, 2, 27), datetime.date(2010, 2, 28)]
f2.write(lines[i + 2])
print(os.walk(DIR_PATH).next()[2])
sys.stdout.write(os.read(stdout.fileno(), 1024))
[line[i:i + n] for i in range(0, len(line), n)]
Point(x, y)
ax = fig.add_subplot(211)
db.session.add(new_provider)
threading.Thread(target=play_audio).start()
Counter(words).most_common(10)
np.where(np.array([0, 1]))
[100, 10, 20]
cur.execute(query, args)
df = df.sort()
max(l_one + l_two)
gnuplot.stdin.flush()
ppf(q, loc=0, scale=1)
to_file.write(replacement_line)
ax.yaxis.set_major_locator(MultipleLocator(0.5))
pylab.show()
hatch_path_stroke.width(1.0)
ctypes.c_void_p(offset)
__init__.py
s.apply(pd.to_datetime, dayfirst=True)
locals()[string1 + string2]()
print ()
np.mean(gp)
df[df.groupby(level=0).transform(np.size).gt(1).values]
combo.focus_set()
ws.write(rowi, coli, float_if_possible(value))
sys.exit(app.exec_())
fig.canvas.draw()
df.sort_index(inplace=True)
np.count_nonzero(a[:2, :2])
df[cols] = np.where(df[cols] < 0, np.nan, df[cols])
remove_extras_and_sort(my_list)
signal.signal(signal.SIGINT, signal_handler)
d[len(lst)] += 1
time.sleep(10)
new_instance.save()
br.set_handle_redirect(True)
p[i:j] = list(sorted(p[i:j]))
text_classifier.fit(X_vectorized, y_train)
salesdata.Outlet_Size.dropna().unique()
l.extend(map(int, (w for w in line.split() if w.isdigit())))
{{person.get_gender_display}}
instance.save()
files.extend(glob(os.path.join(dir, pattern)))
[os.path.splitext(os.path.basename(fn))[0] for fn in a]
ppp_data.rename(columns=dict(zip(columns[2:], names)), inplace=True)
lines = random.sample(f.readlines(), 5)
f.write(text)
sumlog([5, 4, 1, 0, 2]) < sumlog([5, 1, 4, 0.0001, 1])
LOGNORM.DIST(x, Ln(mean), standard_dev, FALSE)
LOGNORM.DIST(x, Ln(mean), standard_dev, TRUE)
self.attr2 = attr2
bottle.run()
a.any(axis=1)
array([2, 2, 2, 2, 1, 2, 1, 2])
print(file(path).read())
nx.draw(G, pos=pos, with_labels=True)
open_smbus.restype = ctypes.c_void_p
expit(0.458)
a.max(axis=0)[0]
time.sleep(1)
letter2, letter1, letter4, letter5
cur.close()
os.path.split(s)
ax.add_patch(rect1)
sys.path.append(path)
time.sleep(1)
any(char.isdigit() for char in inputString)
Py_Finalize()
out_file.write(line)
print(xls.sheet_names())
list(itertools.product(*l))
bool(np.array([0, 0]))
(1, 2)[0:1]
pickle.loads(pickle.dumps(C()))
list(itertools.chain.from_iterable(a))
DBSession.close()
output_stream.close()
plt.show()
cherrypy.engine.exit()
os.execl(sys.executable, sys.executable, *sys.argv)
queryset.filter(mycolname__len__gte=10)
file_out[-1] = file_out[-1][:-1]
A[(0, 1, 2), (0, 1, 0)]
reactor.run()
list_.sort(key=lambda x: float(x[1]))
[0.0, 0.0, 0.0, 0.4, 0.6]
print(match.group(), match.start(), match.end())
e = Example()
ipshell()
values[np.where((coo == [1, 2]).all(1))].mean()
list(adjacent_tuples(list(range(8)), 4))
self.Bind(wx.EVT_LEFT_UP, self.OnLeftUp)
app.run()
base = df.index.get_indexer_for(df[df.A == 2].index)
self._tree = (lambda f: f(f))(lambda t: defaultdict(lambda : t(t)))
print(json.dumps(data, ensure_ascii=False))
doctest.testmod()
logging.basicConfig(level=logging.DEBUG)
(m[1:] > m[:-1]).sum() + m[0]
cords_set.add((x, y))
print(list(message.keys()))
t = dt.time(0, 0, 0)
df.tail(1).index
syncdict.update([(key, 0)])
plt.show()
f.close()
self.window2.show()
(s + mystring for s in mylist)
other_list.remove(other_list[index])
(a[n:] + [default])[0]
maxlen = max(len(sublist) for sublist in a)
x, y = zip(*lst)
run()
str(dt)
[(x - 1) for x in perm_index[i][1:]]
s.sendmail(from_email, emails, msg.as_string())
self.entry.pack()
True
sent_detector.tokenize(your_text)
tuples = [tuple(x) for x in subset.values]
app.exec_()
time.sleep(1)
a /= a.sum(axis=1)[:, (numpy.newaxis)]
layout.addWidget(grview)
A[0:4, (1)]
module.workflow_set.filter(trigger_roles__in=[self.role], allowed=True)
do_something_with(wrapper[0])
[([0] * len(row) if 0 in row else row) for row in matrix]
plt.show()
datetime.time(0)
r = requests.delete(URL_delete, params=mydata)
app.register_blueprint(heysyni)
print(os.getcwd())
plt.subplots_adjust(right=0.75)
any(sublst == lst[i:i + n] for i in range(len(lst) - n + 1))
out.remove(x)
winsound.Beep(Freq, Dur)
print(sorted(inputWords, key=lambda word: [alphabet.index(c) for c in word]))
urllib.parse.unquote(s)
testit()
task.cancel()
bothlists[x[0]].append(x)
request.data
requests.delete(url, **kwargs)
ax.autoscale()
new_list = map(operator.itemgetter(1), old_list)
glVertex2i(10, 10)
zip(*lis)
df.ix[:, ((df == 0).all())]
cv2.destroyAllWindows()
print(np.where(~mask)[0])
ax.legend()
plt.imshow(im2, cmap=plt.cm.gray)
p = Process(target=fn)
popen.wait()
self.periodiccall()
plt.ylim([-400, 400])
[Teaser(Context(result)) for result in self.post.results]
mp.Process(target=run, args=(_QUEUE, cb, func, args, kwargs)).start()
print((dt.datetime.combine(dt.date(1, 1, 1), t) + delta).time())
len([_f for _f in a_list if _f]) == len(a_list)
plt.show(block=True)
s.multiply(1 / np.sqrt(s.multiply(s).sum(1)))
sys.stdout.flush()
os.path.exists(my_path)
ax.set_ylim([-2, 2])
mp.Process.__init__(self)
m[:, ([0])].shape
self.button.clicked.connect(self.testMethod)
print((m.group(1), m.group(2)))
a.reshape(2, 2, 2, 2).sum(axis=1).sum(axis=2)
x.reshape(4, 2, 2)
raise ValueError
sorted(s1, key=prefixed_digits())
plt.show()
df.index = pd.DatetimeIndex(df.index)
list(range(1, 6)) + list(range(15, 20))
df.index.level_map
br.select_form(nr=0)
pd.rolling_apply(df, 12, lambda x: np.prod(1 + x) - 1)
temp.append(sub_list[0])
admin.site.register(Employee, EmployeeAdmin)
i += 1
print(np.sqrt(np.sum((p[:, (np.newaxis)] - p[(np.newaxis), :]) ** 2, axis=-1)))
set(x for x, count in common if count == common[0][1])
print(my_list)
signal.signal(signal.SIGALRM, handler)
plt.show()
pd.DataFrame(MM, dtype=int, columns=Col)
db.session.add(region2)
time.sleep(2)
print_matrix(spiral(5, 5))
map(list, list(result.items()))
mylist = [(w[0] + w[1]) for w in words]
img.fill(255)
random.randrange(5, 10)
max(iter(stats.items()), key=operator.itemgetter(1))[0]
args = parser.parse_args()
print(line)
some_module.py
list(obj.children)
print(map(str, young_fellas))
do_something()
sorted(list(the_dict.items()), key=lambda x: x[1], reverse=True)[:10]
a = [two for one, two in zip(a, a[1:]) if two[1] > one[1]]
f.close()
df = df[dupemask]
cursor = db.cursor()
plt.xlim(x.min(), x.max())
os.remove(temp_file)
app.MainLoop()
pd.concat([df, df1], axis=0, ignore_index=True)
ax.grid()
tuple.__new__(cls, (x, y))
sessions.append(sessionmaker(bind=engine)())
f.geturl()
v, b, n = j[4:7][::-1]
np.array([[x] for x in a1])
log.start()
print(test2())
form.save()
plt.subplots_adjust(bottom=0.1)
df
app.run(debug=True)
sometuple + (someitem,)
x[x.columns[0]]
driver.quit()
id = Column(Integer, primary_key=True)
app.MainLoop()
knapp.pack(pady=10)
views / __init__.py
QMainWindow.__init__(self, parent)
func(*args)
int(n ** 0.5) + 1
main()
list(chain.from_iterable((i, i * i) for i in range(1, 10)))
L += [4] * 10
ufunc.reduceat(mat.data, mat.indptr[:-1])
pygame.init()
response.set_data(json.dumps(d))
df[col_values] = df[col_values].astype(float)
f.write(text)
df.to_json()
print(time.mktime(new.timetuple()))
session.add(obj)
plt.show()
termios.tcsetattr(sys.stdin, termios.TCSADRAIN, new_settings)
self.entry.focus()
k.reshape(k.shape + (1,))
reactor.run()
a, b, c
result = first_date + np.arange(24) * datetime.timedelta(hours=1)
dictionary[next(iter(dictionary))]
deletec[:2]
input()
print(int(date[:4]) + 1)
__main__()
QtGui.QMainWindow.__init__(self)
df.mean()
print(sys.path)
t = threading.Thread(target=task, args=(data,))
pd.DataFrame.from_dict(d)
yx.sort()
window.show_all()
f.close()
browser.quit()
filtered_list = [x for x in input_list if x % 2 == 0]
newdf.head()
d = datetime.date.today()
d = dict((t.key, t) for t in [t0, t1, t2])
print(list(tb_notes.select().execute()))
writer.writerow(row)
result.append(([key] * len(values), values))
plt.axis([0, 10, 0, 1])
pickle.load(f)
p.communicate()
sys.path.append(os.path.dirname(__file__))
[(lower + x * (upper - lower) / length) for x in range(length)]
time.sleep(1)
get_object_or_404(Book, pk=id)
inspect.stack()[2]
fig.canvas.draw()
dists.shape
plt.xlim(0, 20)
list(_)
time.mktime(dt.timetuple())
plt.draw()
print(txtrecord.to_text())
HttpResponse(status=410)
ax.set_xlim(0, 6)
name[0][0][-1][-1]
pool.append(Process(target=pool_func, args=(q,)))
sys.stdout.writelines(sorted_lines)
p.terminate()
thestring[:-len(ending)]
output_list = [x for x in input_list if isinstance(x, list)]
dftmtx(2)
img = pygame.image.load(filename)
socket.close()
last_lines.append(line)
X.dot(A.T)
foo()
blob.delete()
zeros = [([0] * N) for _ in range(M)]
list(chain.from_iterable(ls[:1] + ls[2:]))
root.mainloop()
[item for item in sequence if item < value]
sys.exit(0)
lock.acquire()
v.setdefault(value, []).append(key)
dict_setitem(self, key, value)
[1][0][0]
res = requests.post(url, files=files, data=data, headers=headers)
items = SomeModel.objects.all()
user.save()
plt.tight_layout()
pylab.xlim([-2.5, 2.5])
sudo(command, user=sudouser)
plt.show()
dict([(k, v) for k, v in d.items() if k >= begin and k <= end])
Dataset.objects.filter(i_begin_int__lte=170, i_end_int__gte=170)
data.append(sheet1.cell(i, 1).value)
time.mktime(then.timetuple()) * 1000.0 + then.microsecond / 1000.0
not sum([(not i in A) for i in B]) if len(A) == len(B) else False
plt.show()
ax = fig.add_subplot(1, 1, 1)
df.reset_index(inplace=True)
[a.join(b) for a, b in zip(df.a[10:20], df.b[10:20])]
plt.ylim(0, 5)
print(sys.argv[0])
top.mainloop()
[[i for i, n in enumerate(li) if n == x] for x in sorted(set(li))]
print(k, d2.get(k, 0))
reactor.run()
sheet.set_portrait(False)
simplejson.JSONEncoder.default(self, obj)
plt.pcolor(data, vmin=0.01, vmax=0.99, cmap=my_cmap)
df.Group.value_counts()
foo()
df.a.sort_values()
Number(randint(1, 100))
result = [makedict(elem) for elem in yourlist]
plt.show()
server.serve_forever()
regex.findall(s)
any((a[:] == [1, 20]).all(1))
plt.gcf().show()
iter(self.books.values())
listbox.pack()
ax.add_patch(rect2)
tuple(map(operator.add, a, b))
s.replace(d)
pd.DataFrame(stdf.tolist())
print([element for element, count in Counter(list1).most_common()])
plt.gcf().autofmt_xdate()
[(next(car) if item else next(a)) for item in lyst]
pd.concat(g for i, g in grouped if len(g) > 2)
proc.stdin.close()
alist = [arr[(0), :], arr[1:, (-1)], arr[(-1), :-1], arr[1:-1, (0)]]
main()
app.mainloop()
cherrypy.engine.start()
extra_logger.setLevel(logging.DEBUG)
[match for match in matches]
s[::-1]
toarchive.filter(date__gt=interval).delete()
root = tk.Tk()
plt.show()
data.pop()
fig = plt.figure()
[(x + 1) for x in L]
sum(i for i in range(a, b + 1) if not i % 2)
z = dict(x, **y)
np.sum(a), np.nonzero(np.any(a, axis=0))[0]
conn.close()
rect.set_visible(True)
[vali[i] for i, vali in enumerate(f(*vals))]
pd.melt(piv)
urllib.request.install_opener(my_opener)
obj = json.loads(json_string)
s = s.lower()
globals()[module_name] = __import__(module_name)
sys.stdout.flush()
results.extend(re.findall(key, message, re.IGNORECASE))
print([list(v) for k, v in groupby(sorted_list, key=move)])
print(dumps(a.__dict__))
plt.show()
weekly.append(sum(visitors[x:x + 7]))
df[column_list].iloc[row_index_list].mean(axis=0)
func()
L4 = [n for n in L1 if n not in tmpset]
shutil.copyfile(path, os.path.join(*path_rel))
counter_list = [item for item in counter_list if len(item) != 0]
{{f.following_set.count()}}
plt.show()
np.isclose([10000000000.0, 0], [1.00001e-10, 0])
workbook.close()
print(df2.set_index([0, 1]))
df
ax.imshow(pawprint)
g.plot()
df[(df != 0).all(1)]
list.remove(item_to_be_removed)
set(x[0] for x in zip(a, a[1:]) if x[0] == x[1])
print(os.path.getmtime(os.path.join(SOME_DIR, filename)))
plt.show()
ctypes.cast(x, ctypes.POINTER(ctypes.c_ulong))
vec.fit_transform(measurements).toarray()
map(bool, a).index(True)
l[0][1]
print(a[:-10:-1])
bottleneck.partsort(a, a.size - 10)[-10:]
l = list(zip_longest(x, x, fillvalue=[]))
draw.ellipse((x - r, y - r, x + r, y + r), fill=(255, 0, 0, 0))
__init__.py
[(A[k], B[k]) for k in A if k in B]
p.stdout.close()
min(items, key=lambda item: p1.compute_distance_to(item.loc))
arr = numpy.random.randint(2, size=(n,))
list(chain.from_iterable(l))
round(random.random() * (m_time - min_time) + min_time, 1)
plt.show()
cv2.destroyAllWindows()
np.allclose(C0, C2)
ax.plot(data)
mydog.findall(s)[0]
uniq_animal_groups = set(map(tuple, animal_groups))
ax.set_xticklabels([])
QtCore.Qt.ItemIsEnabled
writer.writerow(the_list)
logger.setLevel(logging.DEBUG)
a / (a - 1)
A[1], A[0], A[1] = A[0], A[1], A[1]
next(e in lestring for e in lelist if e in lestring)
print(np.all(norm1 == norm2))
canvas.pack()
django.setup()
print(df2.reindex(df.index[df.index.isin(df2.index)]))
ii = np.nonzero(a == 4)
subprocess.Popen(command, stdout=subprocess.PIPE).communicate()[0]
json.loads(data, object_hook=_json_object_hook)
sys.stdout.flush()
a[::2] = 1
value = my_dic.get(100, 0)
fig = plt.figure()
numpy.isnan(myarray).any()
b = a[:]
do_something_with(result)
ax.set_yticks([0.5, 1.0])
cnx.sendInitPresence()
np.average(a, axis=-1).repeat(a.shape[-1]).reshape(a.shape)
classifier.fit(X, y)
log.setLevel(logging.DEBUG)
print(trks.name())
plt.draw()
a.setdefault(key, [])
axcut.set_visible(False)
array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 0.0]])
reactor.run()
pd.isnull(df).any(axis=1)
win.run()
new_list.extend(i)
text_file.close()
np.exp(-4 * np.log(2) * ((x - x0) ** 2 + (y - y0) ** 2) / fwhm ** 2)
A.objects.filter(id=some_a.id).update(hidden=True)
s.apply(lambda x: Series(1, index=x)).fillna(0)
self.SetSizerAndFit(sizer)
pkl_file.close()
print(m.group(1))
resp.text, resp.status_code, list(resp.headers.items())
self.tcp_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
X_train = scaler.fit_transform(X_train)
f.close()
request.user.get_profile().token
session.commit()
self.frame.pack(fill=BOTH, expand=YES)
count = sum(1 for line in myfile)
fig = plt.figure()
time.sleep(10)
random.choice(list(range(100, 20100, 100)))
[f(aItem, bItem) for aItem, bItem in zip(a, b)]
G = nx.Graph()
s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
match.group(0)
print(sum(map(lambda x: x * x, l)))
resp = urllib.request.urlopen(req)
all_data = []
a.extend(a, b)
dict((k, sum(d[k] for d in dict1)) for k in dict1[0])
urllib.request.urlopen(url).read()
datetime.timedelta(0)
M = scipy.sparse.csr_matrix(M)
runserver.py
dict(itertools.islice(iter(dictionary.items()), begin, end + 1))
main1()
[a for a, a in list(params.items())]
tk.Tk.__init__(self, *args, **kwargs)
{{(user | hash): item}}
len(set(sum(sl) for sl in L)) == 1
[id(x) for x in test]
[x for x in L if x not in delitems]
sum(i != j for i, j in zip(a, b))
a.reshape(-1, R)
random.shuffle(myList)
conn.commit()
self.thisptr.clone()
np.average(df.y - df.x, weights=df.index.asi8)
[line for time, line in sorted(zip(listofTimes, listofLines))]
frame.axes.get_yaxis().set_ticks([])
e.pack()
self.window1.show()
foo()
resp.peercert
df.iloc[0]
cursor.execute(insert_query, data)
pygame.display.flip()
spherical_dist(locations_1, locations_2[:-1])
plt.show()
G = nx.Graph()
print(repr(line))
sock.connect((host, port))
possibles.update(locals())
fh.write(base64.decodestring(imgData))
fig = plt.figure()
re.compile(regex).groups
[(v * v) for v in vals]
MyApp().run()
print(self.time)
[char for char in yourstring]
sum(1 for item in arr if item == 0 and type(item) is type(0))
time.sleep(1)
np.stack(np.nonzero(df.values)).T
user.user_trips.all()
list(map(lambda f, a: f(a), *zip(*itertools.product(funcs, args))))
print(result.group(1))
app = wx.App(False)
browser.select_form(nr=0)
print(r.data())
print(sorted(a, key=Counter(a).get, reverse=True))
pandas.DataFrame.from_records([s.to_dict() for s in signals])
df.groupby(level=0, as_index=False).nth(2)
proc.stdin.flush()
dictionary = json.loads(cur.fetchone()[0])
proc.wait()
c = (len(a) * a - sum(a)) / b
ax.set_title(title)
[0][0][0]
field.setAlignment(QtCore.Qt.AlignCenter)
__init__.py
a.func(**kwargs)
bool(number % 2)
A[np.lexsort(A.T)]
sample(10, [2, 4, 8, 16])
sum(a, b)
len(np.atleast_1d(a))
df = pd.DataFrame(data.tolist(), columns=data.dtype.names)
tornado.ioloop.IOLoop.instance().start()
os.makedirs(dst)
list(map(len, s.split()))
user.put()
a = sorted(list(a.items()), key=lambda x: x[1])
plt.xlim(X[0] - day, X[-1] + day)
plt.plot(list(range(10)))
a = numpy.tile([1, -1], 15)
server.quit()
plt.show()
plt.show()
mylist = [mylist[i] for i in myorder]
name = models.CharField(max_length=100)
p1.join()
new_array = map(list, old_array)
infile.close()
Base.metadata.bind = engine
plt.show()
print(key, sum(r[2] for r in rows))
content = content_file.read()
ax.set_ylim(0, 10)
conda - -version
Page.query.get(page_id).query.delete()
np.allclose(result_data, result_data2)
time.sleep(1800)
c.fetchall()
print(len(unicode_string))
pl.plot(X, Cosine)
plt.show()
hex(15)
[0, 1, 1, 0, 0, 0],
Peak()
app.MainLoop()
ax = fig.add_subplot(111)
plt.subplot(122)
mylist.count(mylist[0]) == len(mylist)
p.join()
r = requests.post(url, files=files, headers=headers)
scrapyd
new_dict[v].append(k)
avg.append(sum(d[key]) / len(d[key]))
list(merge(list1, list2))
urllib.request.install_opener(opener)
{{form.content()}}
s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
df.dropna(thresh=df.shape[1] - 7)
lines.sort(key=extract_time, reverse=True)
fig, ax = plt.subplots()
sleep(1)
plt.show()
a = np.array(df.C)
plt.show()
lambda name: (name[0], -len(name), name)
print(nodes[0].firstChild.nodeValue)
__init__.py
sorted(list(d.items()), key=foo)
bytearray(hex_data)
final_data[cnames[i]] = np.zeros((nalpha, nmach, nbeta, nalt))
hello.helloworld()
Motifs.insert(x, Motif)
main()
tree = ET.fromstring(msg)
list(zip(foo, bar))
[x for x in range(LOW, HIGH) if len(set(str(x))) == len(str(x))]
db.session.commit()
self._file.close()
request.user
logging.setLoggerClass(ColoredLogger)
d > timedelta(minutes=1)
print(json.dumps(obj, indent=2))
time.sleep(5)
np.allclose(omega, slicing_summing(a, b, c))
Popen(cmd, shell=True, cwd=newpath)
rdd.collect()
window.show()
[a for b, b in list(params.items())]
hex(int(time.time()))
response = requests.get(url, headers=headers)
mlab.show()
type(a)(b)
ax.plot(x, y)
plt.plot(x, y)
print(team.__dict__ == team2.__dict__)
w.pack()
sum(len(word) for word in wordslist)
ax.plot(x, y)
df.TIMESTAMP.dt.hour
ax.margins(0.1)
time.sleep(1)
PyArray_ENABLEFLAGS(arr, NPY_ARRAY_OWNDATA)
sum(num for num in numbers if num % 2 == 1)
np.append(xs, arr[i])
s = numpy.fromstring(s, numpy.int16) / 10 * 5
layout.addWidget(self.button)
[k for k, v in list(self.__class__.__dict__.items()) if type(v) is property]
urllib.request.urlopen(url)
counts.sort(key=operator.itemgetter(1))
transaction.commit()
ax.set_yticks([1, 2, 8])
my_array = my_array.reshape((50, 50))
test.pop()
int(x)
p.close()
plt.xlim([-400, 400])
print(my_list[1::2])
ax2.yaxis.set_visible(False)
len(x) >= 4
process.stdin.flush()
app.ActiveWorkbook.ActiveSheet.Cells(r, c).Formula
[(0 if i < 0 else i) for i in a]
subprocess.check_call(cmd, startupinfo=startupinfo)
smagnoni
d.setdefault(year, []).append(value)
[0, 0, 0, 0, 0],
plt.show()
[child for child in soup.td.children if isinstance(child, str)]
dg.Items.Add(value)
ax.get_xaxis().set_ticklabels([])
s.save()
app.register_blueprint(mod)
divtd(datetime.timedelta(hours=12), datetime.timedelta(hours=2))
time.sleep(1)
sum(map(operator.mul, vector1, vector2))
[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]
df.T.squeeze()
dict((x, data.count(x)) for x in data)
B in (A[i:i + len(B)] for i in range(len(A)))
buf.seek(0)
sum(itertools.starmap(operator.mul, itertools.combinations(l, 2)))
my_shelf.close()
strat2.execute()
main()
yourProcess.terminate()
x2 = sorted(x1, key=lambda t: t[1])
conn.close()
s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
np.diagonal(np.dot(b, a)).T
plt.subplots_adjust(top=0.85)
pygame.display.flip()
writer.UpdatePipeline()
A[([0, 2]), :, 1:]
plt.show()
ax1.plot(X, Y)
do_something()
data.columns = [x.lower() for x in data.columns]
mlab.show()
[doSomethingWith(ch) for ch in s]
df.values.tolist()
s.sum()
plt.draw()
matplotlib.pylab.show(block=False)
xcode - select - -install
img.putdata(data)
max([a for a in yourlist if a[2] >= 100], key=itemgetter(1))
(df == 1).any(axis=1)
args = main_parser.parse_args()
plt.close()
ax.set_yticks(np.arange(data.shape[0]) + 0.5, minor=False)
eval(input())
bar()
df = DataFrame(data)
random.shuffle(list(range(n)))[:k]
time.sleep(20)
pdb.set_trace()
self.response.out.write(zipstream.getvalue())
parse_qs(urlparse(url).query)
set([1, 2]) in {1, 2, frozenset([1, 2])}
gtk.gdk.notify_startup_complete()
numpy.where(your_array_name != 0, 1, 0).sum()
setattr(self, property, getattr(self, property) + amount)
self.cursor.execute(query)
random.choice(states.split())
pyplot.show()
random.sample(list(D.items()), K)
self.foo.kill()
results = [[1, 0, 1], [0, 1, 0], [1, 1, 0]]
classifier.classify(test_sent_features)
scipy.signal.filtfilt
p.stdout.close()
results = map(int, results)
cursor.close()
a = forms.CharField(max_length=20)
sum(p) * (c[1] - c[0])
self.process.stdin.flush()
pipeline.fit(X, y)
f.write(response.content)
im.save(newpathname)
Counter(chain.from_iterable(map(set, listOfLists)))
window.SetFocus()
mask1 &= ~mask2
self.grid_columnconfigure(0, weight=1)
evt.Skip()
(idx[1::2] - idx[::2]).max()
inv.fill((255, 255, 255, 255))
print(collections.Counter(words))
pd.concat([T, df])
getattr(obj, name)
session.commit()
line = line.rstrip()
someMethod.__code__.co_argcount
sorted(li, key=itemgetter(1))
plt.clf()
serve_pil_image(img)
cursor = db.test.find(timeout=False)
solution.loc[df.index]
foo[i], foo[j] = foo[j], foo[i]
plt.show()
find_majority([1, 1, 1, 1, -1, -1, -1, 0])
clf.fit(X, y)
driver.manage().window().maximize()
matches = [x for x in a if x in str]
sorted(templist, key=int, reverse=True)
unittest.main()
d = defaultdict(lambda : defaultdict(lambda : defaultdict(list)))
cursor.close()
plt.draw()
y[:][::2]
logger.setLevel(logging.DEBUG)
commands[com](*args)
file.flush()
np.add.reduceat(X[:, (idx0)], cut_idx, axis=1)
logger.setLevel(logging.DEBUG)
dict(zip(tokens[0::2], tokens[1::2]))
len(set(items)) == 1
setattr(self, name, value)
pd.DataFrame([s1, s2]).min()
time.sleep(0.1)
cnxn.close()
args = parser.parse_args()
plt.show()
df.astype(int)
ax.legend()
l1.append([4, 5, 6])
time.sleep((future - t).seconds)
signal.signal(signal.SIGALRM, original_handler)
x, y = a[0:2]
print(response.text)
min(items, key=lambda x: abs(x - pivot))
time.sleep(1)
root.mainloop()
print(f.getvalue())
numpy.all(product1 == product2)
User.query.get(id)
plt.draw()
values = [d[k] for k in keys]
df.where(df.a.isNull()).count()
a.symmetric_difference(b)
{v: k for k, vs in list(extension_to_type_mapping.items()) for v in vs}
cv2.waitKey(0)
self.request.query_string
new = str[:1] + new + str[6:]
print(sys.exit.__doc__)
im.show()
print(f(4))
json.dumps(data)
plt.show()
x[(list(range(0, i)) + list(range(i + 1, x.shape[0]))), :, :]
main()
proc.stdin.close()
pygame.sprite.Sprite.__init__(self)
testdataframe2.plot(style=styles2, ax=ax)
np.log(absd, absd)
plt.contour(data)
ax.patch.set_visible(False)
print(Digit[i])
{{car.date_of_manufacture | strftime}}
df.iloc[:, (n)]
ax.get_xaxis().set_ticks([2, 4, 6, 8])
xprt.excel()
run()
data.append(ruamel.yaml.load(open(file_name)))
~a.any(axis=1)
subprocess.Popen(cmd_str, shell=True)
pool.terminate()
process.terminate()
Test.__init__()
con.set_option(ldap.OPT_X_TLS_REQUIRE_CERT, ldap.OPT_X_TLS_NEVER)
print(line)
result = self.cur.executemany(sql, data)
plt.figure()
np.argwhere((Ax == Bx.min()) & (Ay == By.min()))
s.stack().reset_index(level=1, drop=True)
plt.show()
plt.ylim(0, 20)
cv2.destroyAllWindows()
print(datetime.fromtimestamp(timestamp))
obj.save()
time.sleep(wtime)
ax = fig.add_subplot(111)
plt.show()
plt.ylim(-1, 1)
d = [(0.25 * math.sin(math.radians(i))) for i in range(0, 1024)]
os.path.join(dir_name, base_filename + suffix)
sizer.Add(buttons, 0, wx.EXPAND | wx.ALL, 5)
plt.figure()
m = re.search(reg, s)
cherrypy.tree.mount(root)
print(hash.hexdigest()[:10])
smtp.starttls()
pd.to_datetime(dte.stack()).unstack()
msg.attach(body)
cax.get_xaxis().set_visible(False)
plt.xticks([])
a = [x for x in names if any(pat in x for pat in pattern)]
sys.exit(0)
indices = tf.where(where)
print(link.text)
plt.show()
plt.show()
arr.T.reshape(5, -1)
ax.set_xlim(0, 24)
print(x[np.unique(a)])
errf.close()
proc.terminate()
ax.set_ylim(-40, 40)
abort(404)
print((a, b, c))
connection.commit()
df = df2.transpose()
c.py
bmp.Bind(wx.EVT_ENTER_WINDOW, onWindow)
[(not i) for i in mylist]
pdfkit.from_string(html_text, output_filename)
issubclass(A, A)
abs(b - c) < abs(b) / 1000000000000
u = Union(a, b)
pygame.display.update()
s += str(n)
df.rename(index=lambda x: tup)
seaborn.voilinplot(ax=ax, data=df, **violin_options)
ax.set_xlim([-0.5, 4.5])
[x for y in zip(list, list) for x in y]
df1.corr()
initpyxmod()
plt.show()
map(f, list(range(10)))
line = line.rstrip()
self.assertEqual([attr, val], [attr, getattr(self.nu, val)])
filename = sys.argv[-1]
Base.metadata.create_all(engine)
fig.savefig(os.path.join(my_path, my_file))
instance.__dict__
sum(tuples, ())
df
sys.argv[1:]
k = lambda x: x[1]
list(k for k, g in itertools.groupby(numbers))
ax.set_xlim((0, 10))
ax.yaxis.set_major_locator(ticker.MultipleLocator(1))
object.__getattribute__(self, name)
cmp(x.lower(), y.lower())
print ()
logger.addHandler(handler)
dict(zip_longest(x, y))
df.apply(update_vals, axis=1)
cleared, dominated
fill_between(x.values, y.min(), y.values, alpha=0.5)
plt.show()
print(name.lower())
sys.stdout.write(line)
b.doSomething()
sock.connect((host, port))
bulk.execute()
gevent.wait()
libxslt - devel
(OrderedDict(row) for i, row in df.iterrows())
mylist[:]
menu.remove(i)
logger.setLevel(logging.INFO)
globals()[n] = 1
new_array = list(set(main_array) - set(second_array))
np.corrcoef(df1.s1, df1.s2)
row.delete()
[[ix.upper() for ix in x] for x in nested_list]
array2 = np.tile(array1, (20, 20, 1, 1))
cv2.destroyAllWindows()
req.close()
s[-1].isdigit()
print(arr[idx])
pd.Series(*zip(*((b, a) for a, b in data)))
conn.close()
df.iloc[:5, :4]
app.run(threaded=True)
l.sort(key=asum)
print(etree.tostring(document, xml_declaration=True))
print(unicode_text.encode(sys.getfilesystemencoding()))
root.overrideredirect(True)
sys.exit(1)
{key: list(set(a[key]) - set(b.get(key, []))) for key in a}
time.sleep(0.01)
time.sleep(5)
np.reshape(self.data, newshape=(len(self.data) / 5, 5))
[flatten[int(i * 2)] for i in range(int(len(flatten) / 2))]
Fraction(*(0.25).as_integer_ratio())
signal.signal(signal.SIGINT, self.handler)
np.may_share_memory(a, a[:, 1::2])
o = numpy.delete(n, deletions, axis=0)
sum(r(i)) == -n
foo.bar()
unittest.main()
np.linspace(x[0], x[-1], 10)
B[:, :, (2)] = 0
df.values
s1[s1.index.isin(s2.index) & s1.isin(s2)]
nobj.__dict__ = oobj.__dict__.copy()
sys.exit(0)
(a > 2).sum()
df.ix[d1:d2]
print(oct(9))
norm.ppf(0.95, loc=10, scale=2)
[(s % x) for x in itertools.product(l1, l2)]
r.json()
print(re.search(find, l).group(0))
max(self.left.depth(), self.right.depth()) + 1
print(os.name)
cv2.FONT_HERSHEY_SIMPLEX
self.root.mainloop()
qdict.update(dict)
df.stack(level=1).reset_index(level=1, drop=True).reset_index()
writer.writerow(row)
root = Tk()
print(s.group())
root.mainloop()
etree_to_dict(tree.getroot())
np.repeat(np.arange(4), 4)
img_io.seek(0)
data.columns = map(str.lower, data.columns)
df.groupby(diff_to_previous.cumsum())
print(ElementTree.tostring(xmlET))
button.pack()
parser.feed(data)
new_list
ax2.yaxis.get_major_ticks()[0].label1.set_visible(False)
{data[k].append(v) for k, v in list(line_dict.items())}
[s[i:j] for i in range(length) for j in range(i + 1, length + 1)]
list(split_on_members(l, s))
sorted(the_list, key=splitter)
music.play()
db.session.commit()
my_func(*my_list)
a[idx[:, (0)], idx[:, (1)], idx[:, (2)]] = 5
classifier.fit(X, Y, sample_weight=weights)
indices = np.arange(len(arr))
r = requests.post(url, data=json.dumps(payload))
plt.show()
add_matrices(c, d)
sns.set()
data.reshape(2, -1).mean(0)
random.shuffle(x)
d[tup[0]][tup[1]] = [tup[2]]
np.dot(a, b) == np.tensordot(a, b, axes=([-1], [2]))
lcmm(*list(range(1, 21)))
len(list(d.items())[0][1])
y.do_something()
QtGui.QWidget.__init__(self, parent)
df.values is df.values
ax.set_yticks([0.2, 0.55, 0.76])
print(evil_vals[0] in list(dict_with_evil_keys.keys()))
woduplicates = set(lseparatedOrblist)
df[(df == pd.Series(conditions)).all(axis=1)]
ax.legend()
self.clslength()
Books.objects.exclude(authors__in=bad_authors)
thread.start()
round(2.615, 2)
admin.site.register(Game, MyModelAdmin)
self.proc.wait()
reactor.run()
output = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)
self.linenumbers.config(state=DISABLED)
matrix = [list(line.strip()) for line in matrixfile]
zlib.decompress(decrypt(data))
shapely.ops.unary_union(list(shapely.ops.polygonize(lines)))
print(df.values.tolist())
print(list(d.values()))
[x for x in library if terms.issubset(x)]
out = proc.communicate()[0]
counter += 1
plt.show()
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
todb.commit()
args = parser.parse_args()
fig, ax = plt.subplots()
db.session.remove()
sleep(1)
Gtk.Entry.__init__(self)
sys.stdout.flush()
print([type(x) for x in htmldata])
model.fit(X)
pl.pop()
process.wait()
workbook.close()
print(sys.version)
x.total_seconds()
os.path.dirname(sys.executable)
(dict(zip(keys, row)) for row in zip(nums, chars))
im.shape
any(1 in x for x in d)
multiprocessing.Process.__init__(self)
plt.show()
data = numpy.asarray(im)
df.columns = columns
map(len, s.split())
sorted(s)
checkbox.Click()
pdb.Pdb.interaction(self, *args, **kwargs)
data = json.loads(mtext)
self.func(*args, **kwargs)
print(buffalo)
time.ctime()
zip(it, it)
model.fit(X_train, y_train)
do_something()
bytes(10)
msg.attach(attachment)
redirect(redirect_url())
list(itertools.chain(*[([k] * v) for k, v in sorted(d.items())]))
lki.sort(key=itemgetter(1))
app = Flask(__name__)
name = models.CharField(max_length=100)
x[~np.any(np.isnan(x), axis=1)]
min(itertools.product(*lists), key=distance)
df.AC = df.AC.astype(float)
result = json.dumps(d, ensure_ascii=False)
df.plot(subplots=True, layout=(1, 2))
print(match.groups())
df2 = df.stack().reset_index(1)
[0, 1, 1, 1, 1],
print(df.groupby(df.A // 2).A.apply(pd.Series.sample, n=2))
User.objects.count()
json.dump(LoL, myfile)
random.sample(deq, 10)
print(dt - datetime.fromtimestamp(s))
q, bins = pd.qcut(a, 2, retbins=True)
ax.set_xlim(-40, 40)
app.url_map
ax1.set_ylim(0, 1.2)
ax.xaxis.set_visible(False)
sys.exit(0)
deletel[100:]
self.response.out.write(simplejson.dumps([p.to_dict() for p in photos]))
array.tolist()
a.flat[np.abs(a - a0).argmin()]
object.__getattribute__(self, attr)
plt.show()
session.commit()
df.reset_index(drop=True).T
fig.subplots_adjust(wspace=0.5)
self.transport.write(data)
out = [(1 if num & 1 << bits - 1 - n else 0) for n in range(bits)]
mainloop()
tuple(A[:, (0)])
ssh.close()
print(connection.getresponse().read())
is_cardano_triplet(2, 1, 5)
random.shuffle(new_lst)
max(i + 1 for i in range(20) if n % (2 << i) == 0)
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
new_data = [float(n) for n in data]
L[-1:], L[:-1] = L[:1], L[1:]
request.resolver_match.app_name
[6, 7, 8]
df.columns = df.columns.str.strip()
pylab.show()
plt.pause(0.05)
image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)
fig.canvas.draw()
linregress(X, Y)
image = tk.PhotoImage(data=b64_data)
np.fill_diagonal(corrs.values, -2)
f.close()
a.remove(x)
ax.plot(x, y)
sess.run(init_op)
print(channel.recv(1024))
r = requests.post(url, data=json.dumps(payload), headers=headers)
numpy.count_nonzero(boolarr)
np.random.shuffle(x)
print(etree.tostring(root, pretty_print=True))
p.stdin.close()
[a for b, a in list(params.items())]
time.sleep(2)
Y == np.array([6, 7, 8, 9])
MM().__dict__
l1.extend([4, 5, 6])
self.assertEqual(a, b)
logger.addHandler(mh)
shutil.copyfileobj(source_file, target_file)
input()
user.save()
lookup.setdefault(key(item), []).append(item)
f.close()
skrift2.pack(pady=10)
writer.save()
df.col2.replace(-1, np.nan).interpolate().astype(int)
isinstance(a, Test2)
session2.add(obj1)
dff.drop(c, axis=1, inplace=True)
array([8.0, 5.5])
m.groups()[0]
do_something()
wr.writerow([item])
product(list(range(2)), repeat=k)
x + ((0, 0),)
[chr(ord(uc)) for uc in udata]
np.take(mat, ixs, axis=0).sum(axis=0)
int_arr[-2, -2] + int_arr[0, 0] - int_arr[-2, 0] - int_arr[0, -2]
self.socket.close()
conn.set_timeout(self.timeout)
result = func()
main()
print(round(a, 2))
sys.getsizeof(10 ** 10 ** 7)
all(x == items[0] for x in items)
df2 = df.transpose()
label.mainloop()
proc.wait()
ax.set_xticklabels(dates, rotation=90)
plt.plot(x, y)
self.response.out.write(row)
y.astype(int)
db.collection.find().limit(1).skip(Math.floor(Math.random() * N))
dlg.ShowModal()
main()
signal.signal(signal.SIGALRM, handler)
rnd = np.random.rand(n) / np.sqrt(2.0 * np.pi)
datetime.date(2011, 1, 1)
fig.subplots_adjust(bottom=0.2)
abs(A[0] - B[0]) + abs(A[1] - B[1])
np.any((x, y, z), axis=0)
set_trace()
form.populate_obj(user)
app.run()
os.path.dirname(filepath)
max(map(len, tup))
plt.axvline(x=0.22058956)
a.f4(1)
set([1])
ax.add_patch(patch)
sum(1 for _ in assignments(12, 5))
time.sleep(10)
print(OpenSSL.crypto.dump_certificate(OpenSSL.crypto.FILETYPE_TEXT, x509))
QtGui.QFrame.__init__(self)
sys.path.insert(0, self.install_lib)
setup()
np.median(x, axis=0)
np.where(cond, arr, -inf).argmax(axis=1)
newstr = oldstr[:midlen] + oldstr[midlen + 1:]
db.close()
print((a, b, c, d))
set_contents_from_string(data_file.read())
decorator_to_enhance(func, *args, **kwargs)
plt.show()
np.random.seed(seed)
df.show()
A.view(dtype=np.complex64)
l.sort()
x.pop(0)
self.__dict__.update(d)
d.setdefault(k, []).append(v)
frame.pack()
A[:, (np.mod(np.arange(ncols), A.shape[1]))]
print([x for x in p.findall(s) if x])
plt.close()
data = json.loads(input_str)
self.assertEqual(callresult, [xargs, yargs])
list(metadata.tables.keys())
print(datetime.datetime.utcfromtimestamp(dt))
mlab.show()
print(clf.coef_)
fopen.close()
setattr(someobject, name, user)
op.worksheet.Worksheet.iter_rows()
set([2, 1]) in list
db.close()
urllib.request.install_opener(opener)
(list(g) for k, g in grouped)
res = np.array(sorted(a, key=lambda x: -x[0]))
plt.figure(figsize=(5.15, 5.15))
d.copy()
self.thread.start()
ax.set_ylim([177, 196])
c = numpy.linalg.lstsq(b.T, a.T)[0].T
QtGui.QWidget.__init__(self)
plt.show()
result = dict(setup1)
g.add_edge(a[0], a[1])
signal.signal(signal.SIGINT, signal_handler)
os.setsid()
self.response.out.write(str(datetime.datetime.now() - starttime))
isinstance(obj, ModuleType)
[(x * x) for x in range(10)]
[x for x in ls if c[x] == 1]
y = dict((k.lower(), v) for k, v in x.items())
os.isatty(sys.stdout.fileno())
np.isnan(np.nan)
config.write(configfile)
d = eval(some_string)
display.flush()
min(s.find(i) for i in a if i in s)
round(x / 500.0) * 500.0
f(a, b)
images.reshape((images.shape[0], -1))
self.assertEqual(len(result), 2)
javasphinx - apidoc - -help
self.response.out.write(row)
self.d = self.d + 1
formset.save()
np.random.seed(1977)
keys = [k for k, v in list(dict.items()) if v == maxval]
lines = tuple(lines)
map(tuple, (N - 1 - np.array(list(combinations(list(range(N)), M))))[::-1])
os.path.relpath(filename, blog_images)
batch.execute(http=http)
bin(1)
d.dot(d.T)
setattr(namespace, dest, value)
ax.set_ylim([0, 2])
pd.Series(dict(col1=a, col2=b))
data = np.array(data)
plt.show()
y = r * np.sin(t)
print(any(x in regx.split(string) for x in search))
ent2.grid(row=1, column=1)
[tuple(chain.from_iterable(prod)) for prod in product(*lists)]
{{mywidget.script()}}
{{item}}
dateutil.parser.parse(date_string)
app.run()
print(etree.tostring(elem))
[0, 1, 1, 0, 0, 1],
ax.get_yticklabels()[i].set_visible(False)
sys.modules[__name__] = Foo()
l.append([])
app.run(debug=True)
plt.close()
backup.close()
t5.start()
fro.readline()
view_func(request, *args, **kwargs)
lines = sorted(shopping.readlines())
a = dict((key, value) for key, value in a.items() if key not in exclusion)
s[0].lower() + s[1:]
csum = np.cumsum(a[:, (1)])
pkgutil.iter_modules()
ax.set_yticks(np.linspace(0, 200, 11))
Tablename.objects.filter(fieldname__lt=value)
map(list, my_array)
float(x)
print(data.split())
set(d[0]).intersection(*d[1:])
np.full((200, 20, 10, 20), 0)
plt.setp(ax.get_xticklabels()[-1], visible=False)
str(0.1)
setattr(self, key, dictionary[key])
plt.subplots_adjust(hspace=0.001)
dict(zip(headers, sdata))
termios.tcsetattr(fd, termios.TCSADRAIN, old)
func(*parameters)
plt.tight_layout()
parser = argparse.ArgumentParser()
PrintLn(Abs(vf))
image.show()
os.remove(path)
print(urlparse.urlunparse(url_parts))
list(chain(*x))
np.array(list(itertools.zip_longest(fillvalue=np.nan, *ll))).T
logging.getLogger().addHandler(handler)
root.mainloop()
a[len(a) - 1:-len(a) - 1:-1]
foo(*t)
numpy.random.shuffle(ids)
my_list.append(int(i))
df.loc[~df.index.isin(t)]
ax.set_xticklabels(x_labels)
set(my_list) - {i for e in bad for i in my_list if e in i}
list(x[x > 0].stack().index)
dll.add.restype = c_double
numpy.where(M == 0)
[(x + 1) for x in mylist]
pprint([(my_array + [i]) for i in input_elements])
mydict[key].append(line.strip())
server.serve_forever()
x[x & x - 1 == 0]
random.choice(files)
deletesys.path[0]
model4.py
scipy.signal.lfilter
Department._objects.filter(group__exact=self.group)
next(i for i, j in list(enumerate(s))[::-1] if j == x)
result = json.loads(result)
server.close()
driver.close()
outer_list.sort(key=MyOrdering)
plt.plot(y)
fig = plt.figure(figsize=(5, 5))
reactor.run()
r = random.choice(numbers)
logging.disable(logging.CRITICAL)
ax2.imshow([[0, 1], [2, 0]])
time.sleep(5)
the_sum += A[k] * B[k]
type(a.tolist()[0])
[(slice(*map(int, a)) if len(a) > 1 else int(a[0])) for a in ranges]
np.random.seed(seed)
ftp.login()
[(x < 0 and x + 4 or x) for x in [1, -2, 2]]
maze_dict[r, c] = [(r - 1, c), (r, c + 1)]
e.update()
sys.stdout.flush()
simplejson.JSONEncoder.default(self, obj)
mylist.sort(key=lambda v: v.x ** 2 + v.y ** 2)
ax.imshow(data)
figure(figsize=(4, 4))
time.time()
asin(2).evalf()
f.close()
plt.plot(x, y)
fxn()
dict(zip(x, map(x.count, x)))
session.commit()
painter.setPen(Qt.QColor(100, 100, 100))
self.assertEqual(1, 0)
connection.close()
wx.Yield()
[i for i, j in c.most_common()]
plt.clf()
print(json.load(json_file))
os.remove(os.path.join(parent, fn))
l = list(t)
np.dot(a, a)
r = requests.post(url, files=files, data=values)
threading.Thread.__init__(self)
array([[24, 20, 21], [4, 0, 1], [9, 5, 6]])
os.remove(os.path.join(dirpath, file))
fib = lambda n: n if n < 2 else fib(n - 1) + fib(n - 2)
root.columnconfigure(0, weight=1)
Image.open(path)
dx, dy = 1, 0
gluLookAt(eX, eY, eZ, cX, cY, cZ, 0, 1, 0)
set([])
np.diagonal(np.dot(np.rollaxis(a, 2), a), 0, 2).T
res = [([x] * len(y), y) for x, y in d.items()]
func(*posargs, **fkwargs)
print(rawstr(test4))
b[x, y] = z
self.sftp.putfo(fileobj, path)
[n.name for n in tf.get_default_graph().as_graph_def().node]
im.show()
inset.set_ylim(axis.get_ylim())
screen.blit(background, (0, 0))
dict.__setitem__(self, key, value)
print(str(names)[1:-1])
ssh.close()
res.cluster.value_counts()
list(itertools.chain(pat.split(line) for line in data))
[(i * j) for i, j in combinations(array, 2)]
my_objects.append(MyClass(i))
plt.draw()
[[0.4, 0.6, 0.0, 0.0], [0.2, 0.4, 0.4, 0.0], [0.0, 0.0, 0.4, 0.6]]
self.setLayout(self.layout)
a.writerows(data)
df.values - df2.values
json.dump(data, f, ensure_ascii=False)
theano.printing.debugprint(f)
fig, ax = plt.subplots()
ax.lines.remove(lines[0])
test.py
smtp.sendmail(from_addr, to_addr, m.as_string())
ch.setLevel(logging.DEBUG)
mask = cv2.cvtColor(mask, cv2.COLOR_GRAY2BGR)
db.create_all()
ax = fig.add_subplot(111)
help(dir)
plt.show()
button.pack()
T = map(lambda i: L[i], Idx)
f = lambda x, y: x if x > 100 and y < 50 else y
line[len(prefix):]
proc.stdin.flush()
{{a}}
self.create_socket(socket.AF_INET, socket.SOCK_STREAM)
print(s, s[-1].isdigit())
t.pack()
self.Layout()
app.logger.handlers[:] = []
data.split()
today.day
dVal.apply(lambda series: series / dX)
plt.show()
do_something()
result[key] += int(row[0])
ax.xaxis.set_visible(False)
names = pd.concat(names, frame, ignore_index=True)
print(my_list)
scores.close()
Response(serializer.data)
writer.writerow(row)
threading.Timer(1, greeting, (oh_hi,)).start()
[row[s] for row in LoL[r]]
np.random.choice(np.squeeze(a))
list(dict1.items()) ^ list(dict2.items())
blowfish()
np.in1d(a, b)
(k, v), = list(d.items())
output.append(float(row[4]))
log = logging.getLogger(__name__)
sys.argv[i]
a.remove(set([2]))
self.table.setRowCount(5)
array([1, 1, 1, 1, 0])
y = np.hsplit(x, np.arange(10, 129, 10))
self.queue.add(item)
print(list(a[b]))
print(b.__class__.__name__)
int(n) == n
x[::2]
plt.plot(data)
{{form.as_div}}
files = list(filter(path.isfile, os.listdir(dirToScreens)))
pd.to_datetime(df.Date).order().index
func(func, *args, **kwargs)
{str(key): value for key, value in zip(bins, count)}
m.put()
skrift1.pack(pady=5)
tekstboks.pack(pady=5)
t.start()
plt.show()
time.sleep(5)
os.system(cmd)
plt.show()
self.add(record)
subprocess.call(args)
f.close()
right.remove(right[0])
time.sleep(1)
main()
admin.site.register(ItemPending, ItemAdminPending)
out.extend(map(str, list(range(a, b + 1))))
pygame.init()
ax.invert_yaxis()
a.xaxis.set_major_formatter(ticker.NullFormatter())
foo.__class__
id = models.AutoField(primary_key=True)
threading.Thread(target=play_audio).start()
sum(isinstance(i, int) for i in a)
print(map(lambda x, y: x + [y], A, list(range(1, len(A) + 1))))
sys.stdout.write(message)
pylab.plot(x, y)
proc = subprocess.Popen(command, startupinfo=startupinfo)
print(conn.notices[-1])
self.method()
df.index.values
bmp.Bind(wx.EVT_LEAVE_WINDOW, onWindow)
data = np.loadtxt(f)
screen = pygame.display.set_mode(size)
instance.save()
ax.plot(xx, yy)
sum(map(pow, l, count(1)))
print(map(hex, a))
logging.basicConfig(level=logging.INFO)
res = urllib.request.urlopen(req)
(myset - (myset - set([b]))).pop() is a
app.MainLoop()
app.logger.addHandler(stream_handler)
f.read()
self.root.after(1000, self.update_clock)
min(s.find(i) for i in a)
session.query(Foo).filter(tuple_(Foo.a, Foo.b, Foo.c).in_(items))
data = f.readframes(chunk)
QtCore.QVariant()
[2, 5, 6, 7, 8, 10]
time.sleep(1)
print(pd.concat([df, df1]))
sys.exit(2)
plt.show()
board[i].append(0)
f(*args, **kwargs)
print(datetime.timedelta(days=1))
[item for item in my_list if item not in to_be_removed]
items = sorted(list(d.items()), key=keyfunc)
plt.scatter(x, y, c=z, s=20)
query_set.filter(deleted_at__isnull=True)
plot(data)
a = set(a)
self.bottom_frame.grid_columnconfigure(0, weight=1)
y = np.arange(10, 20)
settings.py
mech.set_handle_robots(False)
df = df.sortlevel(level=1, axis=1)
file.seek(-len(line), 1)
[k for k in x if type(k) == str]
list1.sort()
app.root.mainloop()
a = [row for row in a if all(row[j] <= 0 for j in range(0, len(row), 2))]
loop.run()
exit(0)
cv2.waitKey()
zip(list_a, list_b)
print(dss)
ax.set_xticks([])
plt.show()
string[0].isdigit()
application = django.core.handlers.wsgi.WSGIHandler()
data = response.json()
sys.stdout = FlushFile(sys.__stdout__)
d = {x: y for x, y in zip(m[::2], m[1::2])}
app.exec_()
app = QtGui.QApplication([])
x[np.ix_(np.arange(x.shape[0]), x_range, y_range)]
cygstart / cygdrive / c / Python27 / Scripts / ipython.exe
a = np.where(np.eye(7), np.nan, 1)
opener = urllib.request.build_opener()
areas.apply(multiply_by_demand).unstack(0)
btn.pack()
df[(df.values > 1.5).any(1)]
[([k] * v) for k, v in list(Counter(L).items())]
os.listdir(base)
yourcode()
indices = np.where(a >= 1.5)
window.show()
x = list(x)
plt.subplot(122)
content = urllib.request.urlopen(req).read()
unittest.main()
np.where(np.isnan(a), ma.array(a, mask=np.isnan(a)).mean(axis=0), a)
{k: v for k, v in somedict.items() if key_criteria_func(k)}
print(df)
np.roll(a, -1)
[(new_element if i in indices else e) for i, e in enumerate(lst)]
plt.show()
map(int, list(bin(YOUR_NUMBER)[2:]))
d = {name: int(value) for name, value in splitstrs}
plot(x, y)
plt.ylim(1, 0)
print(np.may_share_memory(a, b))
plt.show()
pd.DataFrame(d)
print(datetime.datetime.fromtimestamp(dt))
gevent.joinall([job1, job2])
plt.show()
shutil.rmtree(self.name)
b.shape
elementwiseApply(add, [[0, 0, 0], [0, 0], 0], [[4, 4, 4], [4, 4], 4])
[x for x in list_1 if isinstance(x, numbers.Number)]
datetime.datetime.utcfromtimestamp(x.tolist() / 1000000000.0)
f.write(mytext)
set([0, 9, 4, 6, 7])
apps.get_models()
print(match.group(0))
time.sleep(1)
ax.scatter(x, y, z)
list(set(q) & set(w))
user.save()
response
self.frame.Show()
root.mainloop()
plt.show()
np.count_nonzero(np.bitwise_xor(a, b) & r != 0)
list[:10]
run_cmd()
file.writelines(data)
self.show()
sys.stdout.flush()
example1()
assertDictEqual(dict1, dict2)
df.sort(axis=1, inplace=True)
text = sys.stdin.read()
min(max(num, start), end)
index_list.append([(i + temp) for i in range(items)])
plt.show()
df.Cat1 = np.where(df.Cat1.isnull(), df.Cat2, df.Cat1)
df = pd.DataFrame.from_records(data)
Tkinter.Frame.__init__(self, root)
logger = logging.getLogger(__name__)
(lambda : 1)() == (lambda : 1)()
app.jinja_env.filters.update(my_filters)
startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
data.append(row)
[LoL[i][s] for i in range(len(LoL))[r]]
df[df.index.levels[0].isin(stk_list)]
plt.pause(0.5)
print(time.mktime(datetime.datetime.now().timetuple()))
getattr(parent, collection).append(child)
result.append(b[index - 1])
row = [item[0] for item in cursor.fetchall()]
plt.show()
B, C = A[::2], A[1::2]
proc.communicate()
np.arange(1, a.shape[1], 2)
plt.show()
ax.lines = []
df1.ix[0,]
x = all(list_of_bools)
print([(k, len(index[k])) for k in sorted(index.keys())])
my_model.duration = datetime.timedelta(days=20, hours=10)
np.argwhere(np.in1d(a, np.intersect1d(a, b)) == False).flatten().tolist()
print((len(s), len(data), data))
sorted(qs, key=lambda n: (n[0], int(n[1:])))
dict(enumerate(google_price_data, start=1))
json.load(f)
print(decoded.strip())
[k for k, v in list(d1.items()) if v == max(d1.values())][0]
print(row.get_text())
process.exit()
sys.stdout.flush()
gtk.main()
[x for x in seq if x not in seen and not seen.add(x)]
p.start()
print(socket.gethostname())
driver.close()
loop.close()
weekdays[datetime.now().weekday()]
getattr(obj, name)
np.unique(a.round(decimals=4))
set(x * x for x in range(10))
sys.exit(1)
d.setdefault(item[0], []).append(item[1:])
plt.show()
[dict(zip(keys, row)) for row in zip(nums, chars)]
f.seek(old_file_position, os.SEEK_SET)
mylist.pop(0)
df = df.applymap(str)
df = pd.DataFrame([])
fig.autofmt_xdate()
a.append(1)
q = {(i, j): (0) for i in range(5) for j in range(4)}
print(request.get_message().request_body.flatten().data)
models.py
func()
plt.plot(x, g(x), zorder=1)
set(d2.items()).issubset(set(d1.items()))
session.query(BlogPost).filter_by(visible=True)
Gtk.main_quit()
twrv.start()
tasks[sys.argv[1]]()
users = db.session.query(User).all()
random.shuffle(items)
f.close()
self.show()
subprocess.call(row, shell=True)
print([columns[0] for column in cursor.fetchall()])
np.minimum.accumulate(a)
interleaveHelper(lst[:len(lst) / 2], lst[len(lst) / 2:])
int(input(msg))
print(json.dumps(somedict))
time.sleep(1)
pl.show()
sys.exit(0)
name.__class__.__class__
session.query(ZKUser).filter(ZKGroup.id.in_([1, 2])).all()
len([char for char in unistr if unicodedata.combining(char) == 0])
x.as_matrix()
[elem for elem in some_iterable]
imshow(gray1, cmap=cm.gray, alpha=0.5)
dict(dict_list)
c.flatten()
plt.show()
matched[0]
zipDocment.extractall()
np.sort(reference)
v = data[row][col]
list_2 = [num for num in list_1 if isinstance(num, (int, float))]
sys.stdout.write(alphabet[bisect.bisect(f_list, random.random()) - 1])
session.rollback()
map(numpy.random.shuffle, a)
[item for item in x if not y.intersection(item)]
x[index] if -len(l) <= index < len(l) else default
result = [r for r, in result]
app.MainLoop()
list_of_tuples = [(x, y) for x, y, label in data_one]
bisect.bisect(grid, value)
print(Matrix[0][0])
frame.grid(row=0, column=0, sticky=N + S + E + W)
print(sys.argv[0])
a.deiconify()
self.conn.send(msg)
print(calendar.timegm(d.timetuple()))
keys = set().union(*all_dicts)
Py_Finalize()
x ** 2
ax.grid()
shutil.move(name, dst)
text = dlg.ui.lineEdit.text()
plt.show()
sys.exit(app.exec_())
app.logger.setLevel(logging.DEBUG)
start_server()
np.random.shuffle(a.flat)
shutil.copytree(from_path, to_path)
cogrouped.mapValues(lambda x: (list(x[0]), list(x[1]))).collect()
curses.endwin()
l.sort(key=itemgetter(1), reverse=True)
pd.DataFrame(data)
[10, 40, 60, 90, 100]
np.random.choice(array1, 5)
{k: (p[k] - m[k] ** 2) for k in m}
f = open(fpath)
t.start()
plt.figure()
object.__setattr__(self, name, value)
[[m[row][col] for col in range(0, width)] for row in range(0, height)]
json_data.close()
self.setSizePolicy(QtGui.QSizePolicy.Expanding, QtGui.QSizePolicy.Fixed)
os.isatty(sys.stdout.fileno())
list(b)
logging.Handler.__init__(self)
os.killpg(process.pid, signal.SIGKILL)
print(f())
Photo.objects.filter(tags=t1).filter(tags=t2)
data = [[eval(x) for x in y] for y in data]
list(s)
writes.writerows(mygen(reader))
QtCore.Qt.ItemIsEnabled
plt.pcolormesh(X, Y, Z)
ser.close()
primes = {x for x in range(2, 101) if all(x % y for y in range(2, min(x, 11)))}
email.send()
print(r.url)
list(chain.from_iterable(sorted(sub) if len(sub) > 1 else sub for sub in G))
row.remove(row.getchildren()[1])
Py_Finalize()
x = np.linspace(-np.pi, np.pi, 100)
print(model.summary())
result = sorted(iter(dictionary.items()), key=lambda k_v: (k_v[0].field, k_v[1]))
ax.set_xticks(np.arange(0, 6, 1))
math.isnan(b)
df2.plot(ax=axes[0, 1])
json.dumps(a, default=encode_b)
pd.end_time = pandas.to_datetime(pd.end_time)
x = tf.Variable(tf.constant(0, shape=[2, 2]))
int((value - epoch).total_seconds())
ax.xaxis.set_visible(False)
a = dict.fromkeys(a, 0)
self.root.destroy()
self.Acceuil.show()
lst.append(st[i:i + 10])
current_module.new_name = func
self.configure(image=self.image)
animals.sort(key=lambda name: (name[0], -len(name), name))
HttpResponse(status=204)
array([1]), array([0])
print(datetime.now() - datetime.combine(bday, time()))
[k for k, v in sorted(iter(d.items()), key=lambda k_v: (-k_v[1], k_v[0]))]
plt.show()
np.where(a > 0)
isinstance(y, float)
zip(*a)
classifier.fit(X_train, y_train)
ax.set_xlim([-2, 2])
sys.exit(0)
np.split(data, np.where(np.diff(data) != stepsize)[0] + 1)
conn.commit()
[self[n] for n in range(start, stop)]
parser = argparse.ArgumentParser()
sys.argv[1]
d = make_defaultdict(2, list)
print((x, y))
sum(dict[i] for i in range(1, 5))
subprocess.call(cmd, shell=True)
arr.sum(axis=(0, 1))
shutil.copy(src, dst)
b.remove(e)
dict(MyClass(5, 6, 7))
new_file.close()
dict(itertools.chain.from_iterable(list(dct.items()) for dct in dicts))
plt.show()
A[i, j] = D[i, j]
self._body
self.setLayout(layout)
[k for k in itertools.chain(*(list(d.keys()) for d in list(foo.values())))]
pyplot.show()
s = pd.Series(np.random.randn(5))
main()
array([[1.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 1.0], [0.0, 0.0, 1.0, 1.0]])
form = waypointForm(user)
app.MainLoop()
sys.stdout.write(mystdout.get_text())
l.index(d)
[list(x) for x in dt.T.itertuples()]
df.apply(func, axis=1)
print([x for x in range(2, 100) if not [t for t in range(2, x) if not x % t]])
soup = BeautifulSoup(f)
A[1:1] = B
np.diff(m.tocsr().indptr)
db.session.commit()
foo()
self.ax.axis([-10, 10, -10, 10])
[j() for j in [create_lambda(i) for i in range(10)]]
print(list_end_counter([1, 2, 1, 1, 1]))
df = pd.DataFrame(data[1:], columns=data[0])
ax.get_yticklines()[i].set_visible(False)
unittest.main()
Clock.schedule_interval(self.update, 2)
foo = d.get(x, bar)
plot_df.plot(subplots=True)
plt.draw()
[(ix, iy) for ix, row in enumerate(a) for iy, i in enumerate(row) if i == 0]
self.set_tab_reorderable(tab.child, True)
df.apply(pd.value_counts)
self.origstream.write(self.escape_char)
p1.start()
s = set(A() for i in range(1000000))
images[idx].reshape(90, 90)
cv2.destroyAllWindows()
writer.writerow(row)
dict((key, value) for key, value in a.items() if key == 1)
results = map(lambda x: (x[0], x[1:]), reader)
session.commit()
axis.set_major_formatter(ScalarFormatter())
response = serializers.BooleanField(required=True)
df = df.iloc[:, ([j for j, c in enumerate(df.columns) if j != i])]
date = models.DateTimeField(default=datetime.now, blank=True)
x, y = (val - delta for val, delta in zip((x, y), (1, 2)))
[np.argmin(a) for a in A2]
df
query = query % conn.escape(args)
setattr(Foo, v, 0)
process.start()
np.abs(a - b) < atol + rtol * np.abs(b)
map(list.__add__, L1, L2)
cnxn.commit()
list(range(x1, x2 + 1))
np.delete(arr, 2, axis=1)
plt.scatter(X, Y)
cls(a, b)
jsonFile.close()
ax.set_xticklabels(alphab)
__init__.py
scipy.linalg.cython_blas
admin.site.register(Contest, ContestAdmin)
files_list.sort(key=operator.itemgetter(1))
l2 = [l1.index(x) for x in sorted(l1)]
plt.show()
print(list(db.keys()))
lowess(y, x)
print(time.time())
y = tuple([(z * 10) for z in img.size])
mydict = {x[0]: x[1]}
pumpedThread.start()
Fraction(0.185).limit_denominator()
c.update(line.split())
b = cosfromsin(x, a)
map(str, numbers)
lbl7.grid(row=1, column=0)
np.where(cond, arr, -100).argmax(1)
threading.Thread.__init__(self)
app.run(processes=2)
time.sleep(0.1)
send_file(tempcreator.somePath)
grequests.map(rs)
print(neigh.predict_proba([[0.9]]))
directory_list.append(os.path.join(root, name))
foo(a[:, :, (np.newaxis)] - b[:, (np.newaxis)])
tree.write(filename, pretty_print=True)
timestamp = (utc_naive - datetime(1970, 1, 1)).total_seconds()
i += 1
abc = dict((c, string.count(c)) for c in set(string))
timestamp = dt.timestamp()
tree = html.fromstring(page)
plt.show()
__init__.py
axe.set_xticklabels(df.index, rotation=0)
self._dynprop
dict[array[i][0]] = array[i][1]
subprocess.call(command.split(), shell=False)
print(_[0][0].decode(_[0][1]))
[c for c in col_names if not any(f in c for f in filter_array)]
b = word in wordList[:1] + wordList[2:]
scatter([(a, b) for a, b in zip(x, y) if a > 0 and a < 10])
ZipFile.write(os.path.basename(a), compress_type=zipfile.ZIP_DEFLATED)
mydict = dict.fromkeys(string.printable, 0)
int(math.log(n, 2))
print([a[i], a[i + 1]])
v.split()
json.dumps(pyDict)
self.Bind(wx.EVT_LEFT_UP, self._onMouseUp)
fig.autofmt_xdate()
results = cur.fetchall()
MyApp().run()
self.assertEqual(response.status_code, 200)
A[(0, 2), :, 1:]
[a[row, col] for row, col in enumerate(col_index)]
popt, pcov = curve_fit(goal, xdata, ydata, p0=[1] * 5)
metadata.create_all(engine)
plt.show()
self.setupUi(self)
print((name, val))
[hex(ord(c)) for c in data]
[2, 1, 0]
sm[(np.random.sample(sm.shape[0], K, replace=False)), :]
ax = fig.add_subplot(1, 1, 1)
time.sleep(60)
list(filterer(list1, list2))
data = {tuple(item) for item in map(sorted, lst)}
con.close()
sorted(gen)
my_handler.setLevel(logging.INFO)
plt.close()
session2.commit()
np.fill_diagonal(a, 0)
[item for t in tuples for item in t]
qs.filter(name__startswith=self.kwargs.name)
(foo().bar() if condition else foo()).baz()
hscrollbar.grid(row=1, column=0, sticky=E + W)
time.sleep(2)
pd.concat([df.T[x] for x in df.T], ignore_index=True)
round(0, 4)
cor.loc[:, :] = np.tril(cor.values, k=-1)
logging.getLogger(my_module.__name__).setLevel(logging.DEBUG)
print(df.groupby(ind).head())
np.where(a == a.max())
print(map(joiner, sixgrams))
time.mktime(time.strptime(time1, format))
a[(0), :, :], a[(1), :, :], a[(2), :, :]
plt.show()
f.close()
asyncio.get_event_loop().run_until_complete(hello())
ax.yaxis.set_minor_locator(MultipleLocator(0.2))
[(i in fruit_dict2) for i in fruits]
workbook.close()
plt.show()
print(my_list[-1])
html = driver.page_source
fig = PLT.figure()
fruitdict[i] = locals()[i]
plt.show()
ax = fig.add_subplot(1, 1, 1)
your_method()
np.sum(arr[1:-1, 1:-1])
plt.colorbar()
print(flatten_count(x, 1))
np.getbufsize()
self.decorator(func)
item_set[category].append(item)
plt.xticks()
list(zip(lst[:-2], lst[1:-1], lst[2:]))
ax = fig.add_subplot(111)
result = [(x * P) for x in S]
bar[a:b:c].foo()
json.JSONEncoder.default(self, obj)
pl.clf()
data = [(line[0], line[1:]) for line in csv.reader(f)]
writer.writerow(row)
print(cv2.__version__)
[log(y, 10) for y in x]
df
[x for i, x in enumerate(unculledlist) if i % 6 % 2 == 0 if i % 5 % 2 == 0]
time.sleep(delay)
startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
[x for x in lst if x % 2 == 0]
new_df.iloc[0, 0] = 1
s.setsockopt(SOL_SOCKET, SO_BROADCAST, 1)
min(l1, l2)
os.remove(file_list.pop())
self.crawler.engine.unpause()
ax2.set_yticklabels(y_label2, fontsize=20)
self.driver.quit()
ax.legend(numpoints=1)
con.commit()
soup = BeautifulSoup(html)
threading.Thread.__init__(self)
string[start:end]
tuple(d[k] for k in keys)
etree.fromstring(xml_response)
conn.close()
subprocess.call(cmd, stdin=subprocess.PIPE)
{k: d1[k] for k in list(d1.keys()) & l1}
plt.show()
df.columns[np.argsort(df.values)]
df.groupby(level=0, group_keys=False).apply(first_last)
plt.show()
g.sum()
[[400, 200]]
df1.loc[df2.index[0]] = df2.iloc[0]
get_color(1)
fig.set_figwidth(24)
[a[x:x + seg_length] for x in range(0, len(a), seg_length)]
ax = fig.add_subplot(111)
print([zip(A, item) for item in product(B, repeat=len(A))])
print(sys.stdin.readline())
random.shuffle(data)
self.layout().addWidget(self.child)
logger.setLevel(logging.DEBUG)
np.count_nonzero(df.isnull())
start_time = time.time()
intbids.append(int(bid))
[dict(template, **{k: value}) for value in add]
print(time.mktime(d.timetuple()))
[Request(self.start_url, callback=self.parse_listings, follow=True)]
time.sleep(20)
ws.cell(row=1, column=1).style.border.top.border_style = borders.BORDER_MEDIUM
[(x + y) for x, y in zip_longest(reversed(P), reversed(Q), fillvalue=0)][::-1]
unittest.main()
x[mask] = np.nan
table.append(row)
len()
workbook.close()
nsolve([x * y - 1, 4 * x ** 2 + y ** 2 - 5], [x, y], [1, 1])
reactor.run()
print(math.ceil(v * 100) / 100)
example[4:1]
out = [np.sum(data[c]) for c in contribs]
plt.show()
conn.rollback()
next(x for x in list_of_tuples if value in x)
screen.blit(image, (0, 0))
arr.resize((arr.shape[0] * 2, arr.shape[1]))
b.close()
a[tuple(idx.T)] = 5
fig = plt.figure()
libc.cprogram(wts, res, kks, byref(n), ex)
c = np.concatenate((a, b))
time.sleep(1)
df.reindex([2, 0, 1])
np.array(map(str, a))
buff += sys.stdin.read(1)
lst.sort()
{{a.some_other_field}}
datetime.datetime(2001, 12, 11, 0, 0)
ax.set_aspect(2)
[len(list(group)) for value, group in itertools.groupby(b_List) if value]
output = stdout.read()
do_stuff()
sum(len(v) for v in d.values())
print(new_list)
result.append((btoa[k], k))
admin.site.unregister(User)
[0, 1, 1, 1, 0],
self.assertEqual(response.status_code, 200)
pixels.append(((x, y), pixel[:-1]))
dist = numpy.linalg.norm(a - b)
x.reshape(-1, np.prod(x.shape[-2:])).shape
data.append(json.loads(line))
y = set(x.flat)
[sum(int(i) for i in num) for num in list]
time.sleep(1)
print(np.allclose(coeffs1, coeffs2))
np.random.seed(seed)
kOUT = np.zeros(N + 1, dtype=object)
cython.ushort
cython.longlong
cython.ulonglong
[(i - 1) for i in l]
plt.show()
urllib.request.install_opener(opener)
browser._update_state(response)
OrderedDict(lla[::-1])
self.close()
image.close()
df[~df.index.isin(df_a.index + df_b.index)]
ent.grid(row=0, column=1)
i.setGridIntersection(i.pos())
main()
coords.reshape(-1, 2)
cv2.waitKey(0)
df.groupby(dr5minute.asof).agg(ohlcsum)
sum(1 for _ in iter)
self.ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
seen.add(i)
plt.imshow(rotate_lena_noreshape, cmap=plt.cm.gray)
s.send(data)
[tuple(sequence[i:i + n]) for i in range(count)]
c = copy.deepcopy(a)
print(sys.path)
list(d.items())
urllib.parse.quote(a)
[dict(template, z=value) for value in add]
wrapped()
sorted(lst, key=lambda x: x[1], reverse=True)
df.iloc[:, 2:] = a
print(int(Nationality.PL))
as_strided(a, shape=(2, 2, 2, 2), strides=(2 * s, 0, s, 0)).reshape(4, 4)
f.read()
root.destroy()
map(min, zip(*alist))
dict(lst)
main()
print(ET.tostring(tree))
driver = webdriver.Chrome(chrome_options=options)
[token for token in text.split() if token.isdigit()]
print(np.fft.fft(x))
d[k].append(v)
main()
a_unique_max[np.argsort(perm[last])]
lst.sort(key=lambda x: x[1])
ax.scatter(x, y, z)
print((cities[0][0], cities[1][0]))
p.Start()
dict(zip(keys, values))
user = models.ForeignKey(User)
reversed(sorted(a.keys()))
signal.signal(signal.SIGALRM, _handle_timeout)
[1, 1, 0, 1, 0, 1]
ax = fig.add_subplot(1, 1, 1)
cv2.waitKey(0)
self._s.get(k.lower())
lst[1::2]
lots_list.sort(mycmp)
f1.write(line)
self.socket.close()
len(df.columns)
print(get_drives())
res = [s[i - 2:i + 1] for i in range(2, len(s)) if s[i] == s[i - 2]]
str(float(your_string_goes_here))
df[~df.field.isin(ban_field)]
__init__.py
gtk.main()
test()
self.send_response(200)
pl.figure(1)
result = cursor.fetchall()
np.concatenate((a1, b1))
my_list2 = [i[0] for i in my_list]
[1][0][1]
vectors / norms.reshape(1, -1)
print(line)
m.create_all()
lines.append(ax.plot(np.arange(1000) / 2.0))
sys.exit(1)
self.button.clicked.connect(self.handleButton)
result.update((k, dol1[k] + dol2[k]) for k in set(dol1).intersection(dol2))
sys.stdout.flush()
response = requests.delete(url, data=json.dumps(payload), headers=headers)
a[0:1][0] = 1
df = pd.DataFrame([series])
print(nplats[index], nplons[index])
print([tuple(x for x in y if x) for y in a])
history.append(next(sequence))
zip(t[::2], t[1::2])
print(max(foo))
sys.modules[__name__].__file__
test()
itertools.zip_longest(fillvalue=fillvalue, *args)
Z[(raw[:, 0:2] - minimum(raw[:, 0:2], axis=0)).T.tolist()] = raw[:, (2)]
sns.kdeplot(x, shade=True)
c.save()
plt.close()
Counter(words).most_common(10)
df.plot()
app.mainloop()
celery.config_from_object(celeryconfig)
time.sleep(random.random())
dic.setdefault(key, []).append(item[-1])
list(itertools.product((0, 1), repeat=4))
print(find_nearest(array, value))
logfile.close()
plt.legend()
pygame.sprite.Sprite.__init__(self, self.groups)
print(len(someList))
d[pair[0]] = int(pair[1])
items = sorted(list(ipCount.items()), key=my_key)
page = html.fromstring(urllib.request.urlopen(url).read())
list = x.split()
nic.EnableDHCP()
map(id, a[1:])
logging.basicConfig(level=logging.ERROR)
lst.count(1) > 1
msg.send()
sorted(adict, key=adict.get, reverse=True)
convert_file(sys.argv[1], sys.argv[2])
wb.save(filename=dest_filename)
sorted(l1, key=lambda id_and_name: id_and_name[0])
[0, 0, 0, 0, 0, 0, 1, 1],
beat(app=app).run()
new_dic.setdefault(1, {})[2] = 5
matrix.append([0] * ncols)
print(f(2))
random.shuffle(values)
pd.DataFrame(dfN, columns=wordlist).fillna(0)
print(line)
next(key for key, value in d.items() if value == my_value)
data = File.read(16 * 1024 * 1024)
plt.show()
time.sleep(sleep_time)
dict(((a, b, c), 1) for a in A for b in B for c in C)
pygame.display.set_mode((infoObject.current_w, infoObject.current_h))
os.path.dirname(foo.__file__)
plt.contour(r * np.cos(t), r * np.sin(t), z)
nx.draw_networkx(G, pos)
plot(b[:, (0)], b[:, (1)])
label.pack()
len(gc.get_referrers(my_obj))
data.get(num, data[min(list(data.keys()), key=lambda k: abs(k - num))])
np.random.seed(0)
json.dumps(row)
print(line)
mod == __import__(module_name)
self.assertEqual(res, 7)
file1.close()
A = (B == np.arange(M)[:, (np.newaxis)]).dot(C.T)
lst.attr.get(idx, default_value)
screen.fill((0, 0, 0))
df = df.merge(df.apply(calculate, axis=1), left_index=True, right_index=True)
[(1, 4), (6, 8), (10, 10)]
lbl6.grid(row=0, column=0)
np.empty((M, N, L))
sorted(lst)
Route.objects.filter(stops_forwards__contains=[285])
plt.show()
random.shuffle(random_order)
sess.run(train_op)
items.sort()
writer.writerow([test_data[0][1]])
signal.signal(signal.SIGINT, self.old_handler)
dir(settings)
python - V
print(etree.tostring(root, pretty_print=True))
pprint.pprint(list(cursor))
QtGui.QWidget.__init__(self, parent)
df.stack().dropna().reset_index(drop=True)
pygame.display.list_modes()
list(chain(repeat(0, a.count(0)), compress(a, a)))
file_date_tuple_list.sort(key=lambda x: x[1], reverse=True)
plt.gcf().canvas.draw()
sum(totals.values())
data = json.loads(result.text, object_pairs_hook=OrderedDict)
myscript.py | xclip
np.random.seed(0)
pg.display.flip()
[[next(b) for _ in range(x)] for x in l]
webbrowser.open(url)
simplejson.JSONEncoder.default(self, obj)
dict.__init__(self, *args, **kwargs)
sum(n * (n - 1) // 2 for n in list(index2count.values()))
print(match.group(1))
d.save()
ax.legend()
csv.writer(f, quoting=csv.QUOTE_NONE).writerows(cursor)
self.driver.implicitly_wait(20)
writer.writerows(data)
df.join(s)
s[s == 12].index
all(x != y for x, y in itertools.combinations(objs, 2))
test_f()
ax.patch.set_visible(False)
fh.write(h.hexdigest())
ax[1].plot(np.arange(2) / p, c=c)
time.sleep(1)
writer.writerows(zip_list)
sys.path
bar.sort(reverse=True)
app.mainloop()
a.reshape(-1, R).mean(axis=1)
np.where(np.logical_and(a >= 6, a <= 10))
pool = Pool(processes=5)
{{my_json | safe}}
root.grid_rowconfigure(0, weight=1)
writer.writerow(reorderfunc(row))
print(my_file.read())
fib(n - 1) + fib(n - 2)
platform.architecture()
min(x, key=lambda t: (t[1], -t[0]))
ax.plot(list(range(10)))
[x for x in A if x not in subset_of_A]
subprocess.Popen(cmd)
greeter.greet()
sys.maxsize + 1
self._handle.close()
output, err = process.communicate()
base64.b64encode(chr(255))
list(ordered_dict.keys())[2]
np.diag(A.dot(B.T))
pylab.show()
keys.add(parts[1])
myreportscode.py
plt.xlim(0, 4)
main()
buff.seek(0)
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
time.sleep(0.5)
any(first == c for c in letter)
vectors.T / norms.reshape(-1, 1)
wx.Frame.__init__(self, wx.GetApp().TopWindow, title=self.title)
sorted(list(some_dict.items()), key=operator.itemgetter(1), reverse=True)[:10]
array([[11.4, 4.0], [12.0, 5.0]]),
self.text.focus()
[e.value for e in Color]
path, file = os.path.split(path_and_file)
writer.writerow(row)
f.write(file_str)
copy.copy()
load_documentation()
{{toctree(collapse=False)}}
g[:] = (elem[:12] for elem in g)
print((i, p))
df = pd.DataFrame({i: list(range(1000)) for i in range(100)})
fig = plt.figure()
sum(1 for i in set(list_of_purple_items) if i not in main_set)
users = User.objects.filter(event__in=events)
int(utc_mktime(dt.timetuple()))
f2.close()
datetime.timedelta(2.5)
ax = fig.add_subplot(1, 1, 1)
norm.cdf(norm.ppf(0.95))
not float(your_number).is_integer()
arr.append([0, 0, 0, 0])
df.as_matrix(columns=df.columns[1:])
self.setdefault(key, self.default_factory(key))
array([[1, 1], [2, 2]])
common_keys = [k for k in dict1 if k in dict2]
l.last_index()
collections.Counter(dictionary).most_common(2)
[0, 0, 0, 1, 1, 1, 0, 0],
set(tuple(element) for element in xx)
f.close()
time.sleep(2)
ax1.plot(list(range(2)), list(range(2)), linewidth=2)
c[tuple(list1[0])]
tornado.ioloop.IOLoop.instance().start()
all(item1 == item2 for item1, item2 in zip(list1, list2))
sorted_rows[i[0]].append((i[1], i[2]))
Response(serializer.data, status=status.HTTP_200_OK)
AC_SUBST([PYTHON_CFLAGS])
some_list.append(some_list)
imagedata.put()
a[~b] = np.nan
conn.commit()
pool = Pool(processes=1)
p = numpy.vstack([p, q])
transaction.commit()
np.random.seed(seed)
ax.xaxis.set_major_formatter(hfmt)
deletemylist[:]
pyplot.show()
p.start()
os.path.join(expanded, filename)
opener = urllib.request.build_opener(MyHTTPHandler)
win.set_app_paintable(True)
app.exec_()
IOLoop.instance().start()
l = [y for x, y in sorted(zip([key(i) for i in l], l))]
fsock.close()
QtGui.QWidget.__init__(self, parent)
plt.draw()
[(x + y) for x, y in zip_longest(P, Q, fillvalue=0)]
MPI_Finalize()
s.close()
print(x.apply(lambda a: list([v for v in a if v == v])))
ax.add_patch(rect)
array([[0], [0], [0], [1], [1], [0]])
sorted(trial_list, key=trial_dict.get)
inspect.getouterframes(inspect.currentframe())[1][1:4][2]
set(a_list).intersection(a_string.split())
cv2.waitKey(0)
app.run(debug=True)
sys.stdout.flush()
print(soup.prettify())
object.__getattribute__(self, name)
pfile.close()
zin.close()
x == y and type(x) == type(y)
print(hashlib.sha1(json.dumps(b, sort_keys=True)).hexdigest())
print(line)
[(4 if x == 1 else x) for x in a]
sys.stdout.flush()
list(chain(*zip_longest(d, e[::-1])))
colorbar()
p.terminate()
new_list
float.hex(8.25)
layout.addWidget(self.button)
np.hstack([np.repeat(a, len(a), 0), np.tile(b, (len(b), 1))])
server.quit()
a.sort()
json.dumps(dict)
self.layout.addWidget(self.button)
a[slice(*b)]
reactor.run()
s[start:end]
sys.exit(app.exec_())
rank = models.IntegerField(default=0)
xax.setTicks(ticks)
pd.stats.moments.rolling_std(timeseries, periods, ddof=0)
sorted(list(a_dict.items()), key=lambda k_v1_v2: k_v1_v2[1][1])
df.T.apply(lambda x: x.nunique(), axis=1)
print(cls.__name__)
print(request.LANGUAGE_CODE)
self.cls.instances[key]
q = Queue.Queue()
self.save_m2m()
self.show()
[random.random() for i in range(N)]
requests.get(url, cookies=load_cookies(filename))
id = db.Column(db.Integer, primary_key=True)
[(i[0] + j[0], i[1] + j[1]) for i, j in zip(a, b)]
[i for i in L1 if i in L2]
admin.site.register(User, UserAdmin)
os.path.basename(fullpath)
main()
a[1:4].sort()
np.where(detected_minima)
sorted(s1, key=trailing_digits)
ssc.awaitTermination()
ax = fig.add_subplot(111)
ax.w_xaxis.set_major_formatter(ticker.FuncFormatter(format_date))
myFunction()
response = subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT)
text = text.translate(replace_punctuation)
print(now - dateutil.relativedelta.relativedelta(months=1))
main()
root.clear()
Article.objects.all().delete()
sqlContext.createDataFrame(rdd)
self.lc.Bind(wx.EVT_MOTION, self.OnMouseMotion)
a = [x[:] for x in [[0] * cols] * rows]
[f(x) for x in l if f(x)]
result = child.communicate()[0]
test.myfun(f)
args = parser.parse_args()
mylogger.setLevel(logging.INFO)
foo.mymethod(1, 2)
df.loc[df.loc[:, (columns)].eq(value).all(axis=1)]
data.groupby(data.date.dt.year)
dir()
df.groupby([times.hour, times.minute]).value_col.sum()
df = DataFrame(np.random.randn(1000, 2))
plt.show()
app.run()
[dict(items) for items in product(*flat)]
print(sum(1 for _ in f))
r = np.hypot(x, y)
print(cts.minute == 0)
reactor.run()
mydict = {rows[0]: rows[1] for rows in reader}
pprint(d, width=40)
dict(a)
d = d.replace(tzinfo=tz)
a.sum(axis=0)
proc.kill()
p = Process(target=f, args=(arr,))
main()
plt.show()
random.uniform(0, numpy.nextafter(0, 1))
[e for e in lelist if e in lestring]
ax.grid(True)
plt.show()
print(iorf.fup(2))
x.pop()
random.shuffle(idx)
ax0.yaxis.set_ticks(np.arange(70000, 80000, 2500))
response = requests.post(url, files=files)
plt.show()
source.close()
curses.endwin()
mpmath.besselk(0, 1714)
int(1 / 2)
self.a, self.b = a, b
name = models.CharField(max_length=64)
deleteglobals()[name]
plt.figure()
df.subtract(df2, fill_value=0).reindex_like(df).astype(int)
[x for x in lst if x % 2 == 0]
print(z[k.astype(int)])
bigfloat.exp(5000, bigfloat.precision(100))
con.commit()
[(), (0,), (1,), (2,), (0, 1), (0, 2), (1, 2), (0, 1, 2)]
ax.add_patch(polygon)
plt.imshow(np.array(img.tolist()))
sys.exit(start_ipython())
time.sleep(timeout)
set.union(*lis)
__init__.py
sorted(a, key=a.count, reverse=True)
driver.add_cookie(cookie)
{{count}}
sys.exit()
itertools.chain(*itertools.zip_longest(*iters))
[i for i, j in mylist]
self.show()
ax = fig.add_subplot(111)
mylist.sort(key=sort_func)
client.close()
self.__dict__[key]
thread.start()
requests.post(url, params=params, json=data)
d[k].append(v)
os.chdir(os.path.dirname(__file__))
grid.cbar_axes[1].colorbar(im1)
main()
main()
root.withdraw()
plt.plot(y)
np.split(indices, np.where(np.diff(args))[0] + 1)
tree.xpath(xpathselector)
Bar.objects.filter(pk=foo.id).update(a=bar.id)
simplejson.loads(_)
q.queue.clear()
msg = email.message_from_string(msgtxt)
{{a.some_field}}
gc.collect()
f.write(g)
[tup[0] for tup in mylist]
df = pandas.read_csv(filename, skiprows=skip)
session2.commit()
app.mainloop()
l = nx.topological_sort(g)
np.insert(a, 1, np.array((1, 1)), 0)
len(zdumps(z))
dir(MyClass)
list(dict((len(i), i) for i in l).values())
calendar.day_name[1]
time.sleep(0.1)
main()
HttpResponseRedirect(user.redirect_to())
df.dictionary.apply(str2dict).apply(pd.Series)
f.save()
[woman for woman in list(graph.keys()) if woman not in list(match.keys())]
stream.close()
time.sleep(0.5)
g = myfunct()
text = str(combobox1.currentText())
timeout.cancel()
plt.gcf().autofmt_xdate()
a[[0, 1], [1, 1], [2, 2]]
a = [[]] * 2
plt.show()
outfile.close()
time.sleep(0.02)
w.start()
myfile.write(template.format(**context))
self.foo.wait()
arr = np.empty((N, M))
print(list(mydict.keys())[list(mydict.values()).index(16)])
foo(a=1, b=2)
items = [item.time for item in objects]
{k: v for k, v in list(d.items()) if k.startswith(s)}
words.add(line.strip())
ax.add_line(Line2D([-50, 0, 50], [-50, 0, 0], linewidth=80))
print(i, repr(binify(i)))
screen.blit(picture, rect)
server.sendmail(FROM, TO, message)
entryFrame.grid(row=0, column=1)
[l[:1], l[1:]]
curses.endwin()
output.close()
time.sleep(1)
range(-20, 0, -1)
tree = etree.HTML(result.read(), etree.HTMLParser())
window.show_all()
plt.plot(x, y)
plt.clf()
X.argmin(axis=1)
nf.write(str(random.randint(0, 1000)))
isinstance(x, collections.Iterable)
reduce(lambda d, key: d[key], path, aDict).update(aSecondDict)
plt.show()
locale.currency(188518982.18, grouping=True)
os.unlink(self.dest)
func(*args, **kwargs)
int(round(2606.89579999999, 2) * 100)
x.append(1)
x.astype(int)
inspect.getmembers(MyClass, lambda a: not inspect.isroutine(a))
output.close()
lpr.stdin.write(your_data_here)
plt.show()
print({key: a[key] for key in a if key not in keys})
sys.exit(app.exec_())
ModelA.objects.filter(Q(instance_of=ModelB))
profile.save()
map(dict.fromkeys, l)
call_with_dict(some_func, my_dict)
self.SetSize((self.Size[0], self.figurecanvas.Size[1]))
{c.name: getattr(self, c.name) for c in self.__table__.columns}
out = np.vstack((lats, lons, vals))
ax.axis([0, 10, 0, 10])
s[0].astype(int)
json.dumps(recursive_asdict(data))
root.mainloop()
f()
tuple([x[0] for x in G])
print(requests.post(target_url, data=xml, headers=headers).text)
(a * 67108864.0 + b) / 9007199254740992.0
RichIPythonWidget.__init__(self, *args, **kw)
((a + a[:0:-1]) * len(a))[::len(a)][:len(a)]
print(document.text_content())
self.newargument = myarg
first_element = myList[i[0]]
f.flush()
[[m[row][col] for row in range(0, height)] for col in range(0, width)]
series.dt.date.astype(str).to_json()
plt.colorbar()
mask[::4] = 0
a.append(2)
x = {k: v for k, v in spec1.items() if k in spec2 and spec2[k] == v}
[entry for tag in tags for entry in entries if tag in entry]
p.Start()
plt.subplot(121)
urllib.request.install_opener(opener)
screen.blit(surf1, (100, 100, 100, 100))
print(urlparse.parse_qs(qs))
combo.pack()
path = path.to.module.__file__
a = numpy.array([Register() for _ in range(4)])
sorted(list(mydict.items()), key=itemgetter(1))
[0][1][0]
bar = dict(foo)
reverse(text[1:]) + text[0]
DELTAFETCH_ENABLED = True
Py_Finalize()
ws.cell(row=2, column=2).value = 2
df.rename(columns=lambda x: int(x) if type(x) == float else x)
sys.exit(app.exec_())
link.click()
entry.pack()
np.allclose(C0, C1)
sys.stdout.flush()
plt.plot(x, density(x))
f.write(bin_array)
ax.yaxis.set_major_formatter(mpl.ticker.ScalarFormatter())
plt.hist(data, bins=bins, alpha=0.5)
ax.get_xaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())
urlfetch.set_default_fetch_deadline(60)
ax2.get_position()
any([(i in fruit_dict2) for i in fruits])
os.chdir(path_dir)
dt = datetime.fromtimestamp(mktime(struct))
plt.show()
a = sps.csr_matrix((a.data, a.indices, a.indptr), shape=(10000, 10020))
tk.Tk.__init__(self)
set(itertools.combinations(S, m))
self.grid_columnconfigure(1, weight=1)
xs.intersection(y)
my_file.seek(0, 0)
time.sleep(remain)
value = cache.get(key) or cache.setdefault(cache, func(key))
{k: mylist.count(k) for k in set(mylist)}
obj.foo42()
proc.wait()
a, b, c = [(lambda n=n: n * n) for n in l]
x.__add__(x)
np.frombuffer(ftdi.read(RXcount), dtype=np.uint8)
self.ax = self.fig.add_subplot(111)
plt.close()
setattr(someobject, key, value)
plt.axvline(x=xc)
zip(*args)
frame.values[0][0]
itertools.cycle(list(range(2, 10)))
conn.close()
time.sleep(1)
print({v[0]: v[1:] for v in list(d.values())})
indices = np.where(a == a.max())
d = np.diag(a[:, (0)])
time.sleep(1)
plt.colorbar()
s.reset_index().groupby(s.index.names).first()
ax.add_collection(coll)
self.__class__.__name__
[(v + 1 if i % 2 != 0 else v) for i, v in enumerate(list1)]
k, v = list(d.items())[0]
uuid.UUID(int=rd.getrandbits(128))
deletethe_dict[key]
df.groupby(by=[df.index.year, df.index.month]).sum().transpose()
__init__.py
[x for x in lst if [(x[A], x[C]) not in seen, seen.add((x[A], x[C]))][0]]
A[(2), (2), :, :]
cvuint8.dtype
self.__dict__.update(s)
admin.site.register(TwitterUser, TwitterUserAdmin)
new_list
do_something_with_frame(frame)
[0, 0, 0, 1, 0, 1, 0, 0],
data = json.loads(contactFile.read())
ciao.ciao()
server.starttls()
pprint(sorted(flatten(THIS)))
r = size ** (1 / (n - 1))
signal.alarm(0)
numpy.apply_along_axis(lambda row: numpy.linalg.norm(row, ord=1), 1, a)
numpy.where(numpy.all(a_view == may_b, axis=1))[0]
[x for x in a if x not in b]
next(x for x in lst if matchCondition(x))
queryset.filter(id__in=articles)
modernthingy = datetime.datetime.fromtimestamp(zopethingy.timeTime())
session.query(Page.url).filter(tuple_(Page.url_crc, Page.url).in_(keys))
f.write(str(x))
solve([5, 10], [1, 4])
list(chain(*a))
pd.DataFrame(x.T).T.drop_duplicates(keep=False).as_matrix()
lines = lines[:-1]
transaction.rollback()
lst.sort(key=lambda c: POS[c])
ax.xaxis.set_major_locator(locator)
C = np.dot(A, B)
ip_list
time.sleep(1)
ax.w_xaxis.set_major_locator(ticker.FixedLocator(some_dates))
root.mainloop()
[sum(x) for x in zip(*lis)]
time.sleep(1)
result = json.load(urllib.request.urlopen(url))
name = models.CharField(max_length=100)
-r72 - g595x842
plt.figure()
pd.options.display.max_colwidth
ax.set_rmax(1)
[1][1][0]
np.random.seed(5)
result = {k: (v / len(list_of_dicts)) for k, v in list(summed.items())}
next(iter(q))
libxml2 - devel
file_2.write(file_1.read())
[x for y in z if sum(y) > 10 for x in y if x < 10]
locale.setlocale(locale.LC_ALL, saved)
tuple(itertools.chain.from_iterable(t))
[hex(i) for i in data]
ax.plot_surface(x, y, z, rstride=4, cstride=4, facecolors=bm)
plt.show()
modules[module] = sys.modules[module]
sys.getsizeof(string_drawer)
doc = yaml.load(f)
plt.subplot(121)
df = df[(df.one > 0) | (df.two > 0) | (df.three > 0) & (df.four < 1)]
max(im.getcolors(im.size[0] * im.size[1]))
root.mainloop()
pd.Series(a, a._fields)
l = [max(g, key=lambda x: x[1])[0] for _, g in groups]
True
__init__.py
chain.delay()
x.reshape((x.shape[0], -1)).mean(axis=1)
list(dd.values())
ax.plot(x)
logging.basicConfig(filename=settings.log_file, level=logging.DEBUG)
app = application(urls, globals())
deletex[:N]
fh.seek(0)
etree.fromstring(goodxml)
newdict = {x: [] for x in range(10)}
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
app.run(debug=True)
xl.Quit()
urllib.request.install_opener(opener)
a.func(b=b, c=c)
window.show()
print(Outputstring)
self.y += STEP
np.random.seed(1)
{i: [] for i in x}
diag = [row[-i - 1] for i, row in enumerate(mat)]
os.makedirs(savedir)
maxLPFt = max(lpfData, key=operator.itemgetter(1))
data = np.random.rand(10, 15, 5)
type(f).__str__ is not object.__str__
(-avgDists).argsort()[:n]
lambda x, i=i: x % i == 0
~pd.isnull(df[list_of_cols]).all(axis=1)
text.collocations(num=20)
plt.show()
s += timedelta(minutes=minutes, seconds=seconds * 100)
L.append([])
tqdm_notebook().pandas(*args, **kwargs)
np.array([[int(i) for i in line.split()] for line in data])
ax.clear()
basemodule.dontoverride()
pdb.set_trace()
[zip(x, main2) for x in itertools.combinations(main1, len(main2))]
my_failing_task()
ax1.imshow(source, cmap=plt.cm.gray)
key in self.__dict__
pool.close()
complete_path = os.path.join(root_path, sanitised_filename)
type(plain_string), type(unicode_string)
self.rect.set_xy((self.x0, self.y0))
[(x[0], len(x[1]), x[1][0][0]) for x in l]
browser.close()
m.dot(m.T)
[0][0][1]
Decimal(math.factorial(171))
Base.metadata.create_all()
fliplr(matrix)
tornado.ioloop.IOLoop.instance().start()
matrix[0][1]
app.run()
berlin.delete()
ax.plot(xp, yp, zs=zp)
UserProfile.objects.create(user=instance)
dict((c, string.count(c)) for c in set(string))
plt.imshow(data, vmin=-10, vmax=10)
pd.concat([price, vol], axis=1)
all([(xdiff[0] == xdiff[n]) for n in range(1, len(xdiff))])
print(len(japanese))
master.mainloop()
s[::-1].replace(old[::-1], new[::-1], count)[::-1]
print(im.size)
plusone.append(int(value))
DialApp().run()
a_b = [e for e in a if not e in b]
print(sys.exc_info()[0])
extension = os.path.splitext(filename)[1]
df.rename(columns, inplace=True)
l[1::2] = [(x * 2) for x in l[1::2]]
plt.show()
ts.index.freq
np.nonzero(np.all((lower_bound < m2D) & (higher_bound > m2D), axis=1))[0][0]
file.seek(0)
self.data.columnconfigure(0, weight=1)
d = ordereddict(dic, relax=True)
plt.plot(x, y)
p.start()
[len(t) for t in tuples]
file.write(line)
self.window.unfullscreen()
df1.to_sparse().info()
self.capture = cv.CaptureFromCAM(0)
print(zed())
layout.setSpacing(10)
func(parameters[0], parameters[1], parameters[2])
sheet1.write(i, 0, n, fmt)
dic[keys[-1]] = value
cbar = fig.colorbar(im)
count.most_common()[:10]
plt.subplots_adjust(bottom=0.2)
random.shuffle(l)
conn = pyodbc.connect(odbc_conn_str)
heapq.nsmallest(1, ((k, i) for i, k in enumerate(s)))
models.py
answer = [v for v in itertools.product(*ranges) if sum(v) == 100]
s = c.connect()
fig = plt.figure()
[i for i, v in enumerate(list1) if v >= 1 and list2[i] == 0]
print([(num if num > 0 else z.pop(0)) for num in y])
print([i for i in results])
print(np.argmax(counts))
data[:5]
print(rsp.content)
[id(x) for x in l2]
sys.modules[module_name]
moduleA.py
ScrolledText(root).pack()
content = f.read()
pygame.display.flip()
len(max(sum(tableData, []), key=len))
list_of_lists
counter.save()
f.close()
sys.exit()
my_list.remove(new_dict)
complete_path = os.path.join(root_path, sanitised_path, sanitised_filename)
b = copy.deepcopy(a)
self.queue.pop()
list(df.T.to_dict().values())
show()
window.show_all()
print(line)
root.mainloop()
zip(*(x[i:] for i in range(n)))
flask.jsonify(**course_list)
[1] * 6
ax.set_xticklabels(final_labels)
print(list(map(int, chain.from_iterable(line.split() for line in f))))
json_data = json.dumps(data)
x.reshape(x.shape[:-2] + (-1,)).shape
response.render()
not any(el == 0 for sublist in maze for el in sublist)
button.pack()
{{message | safe}}
min(s, key=lambda c: (-s.count(c), s.index(c)))
False
libfoo.dylib
t.grid(sticky=(N, E, S, W))
ax.set_xticklabels(label_text)
os.remove(os.path.join(dir, file))
ax.imshow(im, *args, **kwargs)
fp.close()
random.shuffle(temp)
p.stdin.write(cmd)
data = urllib.request.urlopen(req).read()
[]
ofimg[0].getHomography()
main.show()
t.start()
self.write(response.content)
txt_frm.grid_columnconfigure(0, weight=1)
df.sort_index(inplace=True)
answer = msvcrt.getch()
x, y = zip(*xy)
soup.contents[0]
httpd.serve_forever()
n.show()
print(instance.name)
figure.canvas.draw()
httpd.serve_forever()
Thread.__init__(self)
p.stdin.flush()
json_object = json.loads(json_raw[0])
df.append(s)
sys.exit()
writer.writerow([date, value])
ax.set_axis_off()
threading.Thread(target=run_all).start()
(2 - N) % 7
df.A.apply(pd.value_counts).fillna(0).astype(int)
print(sys.exc_info())
d = [a, b, c]
self.__dict__.update(adict)
np.allclose(D0, D2)
df_b.combine_first(df_a)
print(sum([i[list(i.keys())[0]][1] for i in myList]))
fig = plt.figure()
[item for item in full_list if not omit & set(item)]
datetime.datetime(now.date(), datetime.time(tzinfo=now.tzinfo))
plt.figure(figsize=(5, 5))
self.canvas.configure(yscrollcommand=self.vsb.set)
result.write(new_text)
p = subprocess.Popen([cmd_list], shell=False)
print(list_of_hets)
print(df.to_string())
A.T[B == 1].T
foo = (x ** 2 for x in count())
execution.history()
x[x].index
Row(**row_dict)
root.mainloop()
TotSize[:] = map(sum, data)
print(parse_qsl(urlparse(url)[4]))
print(list(d.values()))
max(values[i + 1] - values[i] for i in range(0, len(values) - 1))
random.shuffle(l)
result = [split_result[0], split_result[1], [i for i in split_result[2:] if i]]
print(list_end_counter([1, 2, 1, 1]))
plt.show()
deletex[index]
print(parse_python_source(os.path.join(d, f)))
hello(sys.argv[1], sys.argv[2])
object_list.sort(key=lambda x: key_precedence[x.key])
ax = fig.add_subplot(111)
i = max(i - 1, 0)
file.close()
map(sum, zip(*([iter(q)] * 2)))
list(set(A).intersection(B))
pl.show()
np.where(x == np.max(x))
ax.set_ylim(y_min, y_max)
print([attr.get(idx, default_value) for attr in attrs])
self.y = math.sin(a) * original_x + math.cos(a) * original_y
subprocess.Popen([file], shell=True)
sys.setrecursionlimit(10000)
my_array[:, (1)] = temp
sorted(l, key=lambda *args: random.random())
[[[0] * n] * n] * n
fig = plt.figure(figsize=(4, 4))
response = DeviceView.as_view()(request, pk=1)
path = os.path.abspath(args.file.name)
pyplot.show()
fig.canvas.draw()
S.pop()
a = set([1])
len(list(flatten(mylist[0:1])))
ax.add_patch(angle_plot)
__init__.py
plt.xlim((-1, 4))
invite_reason = models.CharField(max_length=64)
time.mktime(time.localtime(calendar.timegm(utc_time)))
sys.stdout = sys.__stdout__
app.mainloop()
s.listen(1)
pylab.show()
B.sendall(A.recv(4096))
br.set_cookiejar(cookiejar)
y = np.array([2, 1, 5, 2])
conn.autocommit = True
plt.plot(z, t)
time.sleep(1)
set(dict1.items()).symmetric_difference(list(dict2.items()))
pygame.init()
os.dup2(si.fileno(), sys.stdin.fileno())
print((item, value))
tree = etree.parse(filename, parser)
datetime.now(timezone.utc).isoformat()
plt.show()
rdd.zipWithIndex().filter(lambda tup: tup[1] > 0).map(lambda tup: tup[0])
tuple(lines[0])
serializer.save()
map(lambda x: x.title(), s)
int(ceil(adjusted_dom / 7.0))
{{post.tags}}
time.sleep(5)
time.sleep(0.01)
df.drop(df[df.amount == 0].sample(frac=0.5).index)
print(l[x][y])
words = sorted(set(stream.read().split()))
YourModel.objects.filter(query)
arr[[1, 1]]
f.close()
etree.XMLParser(recover=True)
f(x=100)
insert_ids.append(cur.lastrowid)
result = np.concatenate((a, val))
datetime.datetime.strptime(dt, fmt)
myRoundedList.sum()
ax.add_patch(rectangle)
pygame.init()
tuple.__new__(*args, **kwargs)
A[A == pinf] = 0.0
print(calendar.monthrange(2012, 1)[1])
dict((k, D[k] - v) for v, k in enumerate(albums_today))
z = np.ones((5, 1, 1))
(b - b[0] == 0).all()
help(foo.__name__)
print([_ for _ in range(5)])
a[slice(1, 2)]
fig.canvas.draw()
plt.show()
print(sp.communicate()[0].split())
QtGui.QWidget.__init__(self)
driver = webdriver.Firefox(firefox_profile=firefoxProfile)
DataFrame(dict([(k, Series(v)) for k, v in d.items()]))
print(line)
plt.imshow(img, cmap=plt.cm.gray)
np.split(np.asarray(quaternion0), 4, -1)
os.remove(path)
con.commit()
json.loads(json.dumps(my_dict))
d[k].setdefault(kk, 0)
df = pd.concat(pool.map(process, links), ignore_index=True)
threading.Thread(target=post_request, args=(q,)).start()
ax2.xaxis.set_visible(False)
button.configure(bg=colour)
result = np.sum(product, axis=1)
a.extend(memoryview(b)[14:20])
plt.show()
a = a.ravel().view((np.str, a.itemsize * a.shape[1]))
np.hstack((x, np.prod(x, axis=1, keepdims=True)))
sum(dct.get(k, 0) for k in lst)
print(json.dumps(dict(r.headers)))
pd.DataFrame(data=[l])
app.run()
c = list(map(operator.or_, a, b))
B = np.random.rand(2, 4)
server.starttls()
tk.mainloop()
unittest.main()
results.sort(key=lambda x: x[0], reverse=True)
getattr(obj, name)
os.sysconf(2)
pygame.quit()
data = pd.DataFrame(list(data.items()))
self.progbar.pack()
self.Bind(wx.EVT_CLOSE, self._on_close)
self.Bind(wx.EVT_TEXT, self.OnFiltr, self.filtr)
pylab.show()
button.clicked.connect(myFunction)
user = models.ForeignKey(User, unique=True)
session.sendmail(sender, recipients, message)
b / (b - 1)
{k: list(map(add_element, v)) for k, v in list(dicty.items())}
df = pd.DataFrame.from_dict(d)
cur.close()
signal.signal(signal.SIGINT, signal.SIG_DFL)
t.start()
print(type(Foo.__dict__))
__init__.py
plt.colorbar(im, cax=cax)
self.log = logging.getLogger(self.__class__.__name__)
browser = webdriver.Firefox()
canvas.pack()
output = process.stdout.read()
result = np.minimum(arr, 255)
x = x or y
plt.bar(idx, c[0], color=hexencode(c[1]), edgecolor=hexencode(c[1]))
f(a, b)
numpy.linalg.norm(a - b, ord=1)
plt.show
out = a[np.sort(sidx[np.searchsorted(a, b, sorter=sidx)])]
[1, 1, 0, 1]
file.write(html)
print(int(s))
df = df.append(data)
ax1.scatter(X, Y, Z)
p.start()
main()
os.kill(8861, 0)
list(zip(*itertools.zip_longest(*ll)))
curses.endwin()
list(set(a) & set(b))
s.diff().fillna(0)
[(row if all(row) else [0] * len(row)) for row in matrix]
widget.setWindowFlags(QtCore.Qt.Window)
update_list(l, [4, 5, 6])
traceback.print_stack()
args[0].__disown__()
not any(data)
match(a, b)
print(whisper())
plt.show()
time.sleep(120)
Response(serializer.data)
cnx.commit()
t + np.r_[t[1:], t[0]]
request.add_data(edata)
userProfile.save()
[a for a in alphastartgen(8)]
{i[0]: map(int, j) for i, j in p}
lines = f.readlines()
self.fig.canvas.draw()
cursor.fetchall()
dockerpty.PseudoTerminal(client, container).start()
canvas.grid()
pyflakes - -version
root.mainloop()
json.dumps(arrays)
plt.show()
fun()
plt.show()
datetime.datetime.strptime(date_string, format1).strftime(format2)
json.dumps(my_dict)
dict(zip(freq[1::2], freq[0::2]))
[(l[i], l[(i + 1) % n]) for i in range(n)]
plt.colorbar(sm)
self.autocomplete()
my_list
numbers[start:] + numbers[:start]
__init__.py
plt.show()
last_row.argsort()
C = 1 - np.prod(D, axis=1)
fp.close()
simplejson.dumps(d, ignore_nan=True)
app.MainLoop()
w.show()
o.write(line)
fox.quit()
plt.show()
A = coo_matrix((values, coords.T))
person.put()
Base.metadata.create_all()
module.main()
sys.stdin.readline()
name = db.StringProperty()
display(w)
sys.path.append(path)
sys.stdout.close()
foo.bar
view_func(request, *args, **kwargs)
plt.legend()
self._build_data()
parser.print_help()
from_file.readline()
HttpResponse(escape(repr(request)))
plt.show()
ax.get_yaxis().set_label_coords(-0.1, 0.5)
list(chain(*a))
print(cursor.lastrowid)
all(not X for X in dict.values())
transmission_array.extend([1] * 400 * slot_duration)
plt.setp(cg.ax_heatmap.yaxis.get_majorticklabels(), rotation=0)
result = bytes.fromhex(some_hex_string)
app.mainloop()
print(sorted(sub_strings, key=lambda x: levenshtein_distance(x, s))[0])
f.close()
input_file.close()
PLT.show()
self.sock.bind((self.host, self.port))
path = os.path.realpath(path)
deserialized_object.save()
app.logger.setLevel(logging.ERROR)
logger.setLevel(logging.DEBUG)
Counter(list(d.values()))
a[0] = 5
my_tuple = tuple(my_list)
[(v1 * list1[j]) for i, v1 in enumerate(list1) for j in range(i)]
random.randint(10 ** (x - 1), 10 ** x - 1)
writer.writerows(out_data)
client.connect()
plt.show()
df[df.a < df.a.quantile(0.95)]
list_of_lists
new_list = list(set([date for date in dates if dates.count(date) > 1]))
time.mktime(dt_obj.timetuple())
len(buf.read())
print(np.abs(s[0] - s[1]) / std)
df[0:2]
df.mean()
func()
print((lambda x: chr(ord(x) + 1))(i))
tkinter.deletefilehandler(file)
time.sleep(random.randint(1, 4))
unittest.main()
client.load_system_host_keys()
app = QtGui.QApplication([])
(index for index, value in enumerate(obj))
vbox.setContentsMargins(0, 0, 0, 0)
df = np.dot(df, p_value)
pool.apply_async(test2, (t,), [dict(arg2=5)])
type(b)(a)
Session.objects.filter(pk__in=user_sessions)
object.save()
print(rawstr(test6))
[sum(g) for b, g in itertools.groupby(bits) if b]
sys.exit(app.exec_())
print(subg.edges())
[it for it in l for _ in range(2)]
a = df.iloc[:, 2:].values
pickle.dump(data1, output)
server.quit()
plt.show()
len(tested) == len(input)
pool = mp.Pool(processes=4)
plt.gcf().set_size_inches(10, 10)
pygame.draw.circle(surf1, (0, 0, 200, 100), (100, 100), 100)
print([b(5, 8) for b in bases])
cv.Remap(image, remapped, mapX, mapY, cv.CV_INTER_LINEAR)
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
print(df.loc[mask])
im.show()
a[tuple(idx)] = 5
root.grid_columnconfigure(0, weight=1)
info = collection.find_one(obj_id)
a = np.array([[1, 1], [2, 2], [4, 4]])
plt.show()
logger.removeHandler(hdl)
euclid(nums[1], gcd(nums[:2]))
fig = plt.figure()
df[(df.foo == 222) | (df.bar == 444)]
sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
plt.clabel(CS, inline=1, fontsize=10)
plt.ylim(plt.ylim()[0], 1.0)
plt.show()
br.submit()
plt.show()
sys.stdout.write(os.read(fd, 1024))
sys.exit(1)
df = pd.concat([df, market], axis=1)
func(*args, **kwargs)
all(v in value for v in input_list)
gc.garbage
numpy.kron(a, [[1, 1], [1, 1]])
print(d[k])
self.top.destroy()
plt.show()
plt.show()
print(list(range(len(words))))
cf.insert(uuid.uuid4(), [{k: str(v) for k, v in d.items()} for d in x])
np.isfinite(b)
json.dumps(object())
time.sleep(1)
pickle.dumps(defdict)
a[b[:, (0)], b[:, (1)]]
isinstance(v, type(LAMBDA)) and v.__name__ == LAMBDA.__name__
layout.addWidget(self.browser)
ax.set_yticklabels([])
s.fill((255, 255, 255))
(dist ** 2).sum(axis=2) ** 0.5
l1.extend([7, 8, 9])
any(isinstance(e, list) for e in my_list)
solve(eqn, Rsense)
t.start()
a.execute(sql)
self.label.pack()
f.close()
any(thelist.count(x) > 1 for x in thelist)
help(list)
self.add_tag(tag)
listening_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
j2 = [x for x in j if x >= 5]
np.reshape(x, (-1, 1))
[i for i, letter in enumerate(s) if letter == ch]
self.worker.start()
df.stack()
sum(map(mul, a, b))
[datetime.datetime(2012, 1, 5, 0, 0)]
app = Flask(__name__)
fun(ctypes.c_void_p(indata.ctypes.data), ctypes.c_void_p(outdata.ctypes.data))
ent6.grid(row=1, column=1)
admin.site.register(Group, GroupAdmin)
self.send_response(200)
plt.show()
scipy.optimize
df.to_csv(f, header=False, index=False)
print(hex(-1 & 4294967295))
deletel[0]
win.show_all()
print((i, line))
this_array[indices[0]:indices[-1] + 1].fill(new_v)
plt.show()
dropped_copies = [(lambda i: (x[i] for x in copies[i]))(i) for i in range(2)]
df_subset.apply(lambda x: x.C * x.E, axis=1).sum()
os.kill(pid, 0)
os.isatty(0)
print(re.findall(p, test_str))
res = cv2.bitwise_and(img, img, mask=mask)
result = p.communicate()[0]
cursor.fetchall()
serializer = CommentSerializer(comment, data=request.data, partial=True)
[entry for tag in tags for entry in entries if tag in entry]
shelf.close()
graph = facebook.GraphAPI(access_token)
self.ax.set_ylim(0, R + pR)
s.connect((HOST, PORT))
a[(0), :, :]
cdf1.update(cdf2, overwrite=False)
print(os.path.abspath(__file__))
sys.stdout.flush()
self.pack(fill=BOTH, expand=1, padx=5, pady=5)
print(br.response().read())
characters += sum(len(word) for word in wordslist)
print(df.loc[:, (~mask)])
datetime.now(timezone.utc).astimezone().isoformat()
any(np.allclose(row, x) for x in myarray)
f.seek(0)
Companies.objects.filter(q)
print(s.getvalue())
ind[np.where(np.diff(ind) == 0)]
server.sendmail(self.EMAIL_FROM, self.EMAIL_TO, msg.as_string())
p.stdout.close()
l.extend(map(int, r.findall(line)))
dict.__setitem__(self, keys[-1], value)
app.run(debug=True)
a[0]
sum([i for i in l1 if isinstance(i, numbers.Number)])
t.start()
{k: min(i for i in (h1.get(k), h2.get(k)) if i) for k in list(h1.keys()) | h2}
lst.sort(key=operater.itemgetter(2), reverse=True)
app = QtGui.QApplication([])
result = [sum(el) for el in itertools.zip_longest(fillvalue=0, *lists)]
unittest.main()
d = {r[0]: tuple(r[1:-1]) for r in reader}
self.instance.status
signal.signal(signal.SIGINT, signal_handler)
plt.show()
virtualenv - -help
f = lambda r: r * (sp.j0(r) + sp.jn(2, r))
pygame.display.init()
a = np.loadtxt(stdin, dtype=np.int)
random.shuffle(lis)
x[0] + x[-1]
a = k + a
sizer.Add(text, 0, wx.ALL, 5)
sys.exit(app.exec_())
people_list.append(person)
ax = fig.add_subplot(111)
plot(tmp.max(axis=0))
mat = sparse.coo_matrix(points, (I, J))
im.show()
admin.site.register(LocationCode, LocationAdmin)
config.write()
self.initUI()
siympify(y)
A[i, j] = C[j, B == i].sum()
ax.xaxis.set_major_locator(mdates.AutoDateLocator())
logging.Handler.__init__(self)
text.pack()
print(table.ascii_table(data, has_header=True))
jsonify(json_list=[i.serialize for i in qryresult.all()])
self.schedule.run()
plt.colorbar()
plt.draw()
max(0, min(a[1], b[1]) - max(a[0], b[0]))
json.dumps(o)
df.head()
{(x, x + 2) for x in r if x + 2 in r}
cherrypy.quickstart(HelloWorld())
calendar.timegm(dt.utctimetuple())
turtle.circle(circumfrence / 2)
temp_list = (x * x for x in range(0, 10))
cv.WaitKey(0)
sc.addFile(some_path)
print(len(a) - a.index(min(a)) - 1)
PyMem_DEL(self)
sys.path.insert(0, lib_path)
tk.Label(frame, text=t).grid(row=row, column=1)
any(v > 0 for v in pairs.values())
help(pyudt)
self.pack()
data = pd.DataFrame(json.loads(line) for line in f)
print(line, file=file)
[1, 1, 1],
trainer.trainEpochs(1000)
g.filter(lambda x: len(x) >= 10)
self.grid_rowconfigure(0, weight=1)
list(range(len(sent)))
link.click()
print(v, type(v))
webbrowser.open(whatever)
[0, 0, 0, 1, 0, 1]
np.arange(x[0], x[0] + 60, 10)
np.allclose(a, b)
plt.ion()
ax.imshow(im)
model1.objects.all()
print(json.dumps(df.T.as_matrix().tolist(), indent=4))
getattr(module, name)
os.chdir(currdir)
self._autosave()
QAbstractTableModel.__init__(self, parent)
print(template.render())
plt.figure()
self.factories.append(factory)
mpl.pyplot.legend(**dict(list(defaults.items()) + list(kwargs.items())))
plt.savefig(file_path, dpi=80)
httpd.serve_forever()
(numpy.diff(numpy.sign(a)) != 0) * 1
thread.start()
max(knapsack(i - 1, W), values[i] + knapsack(i - 1, W - weights[i]))
timedelta(hours=6)
ax.set_ylim([-2, 2])
numpy.transpose(matrix7, axes=(1, 0, 2)).tolist()
plt.draw()
b = a[..., ::-1]
paramdata.columns
setattr(self, key, value)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
sum(v[1][1] for v in itertools.chain(*[list(d.items()) for d in myList]))
browser.close()
f.close()
all([])
max(b, key=inverse)
setpath(d.setdefault(p[0], {}), p[1:], k)
df.groupby(date).mean()
val, _ = funky_func()
wrpcap(OUTFILE, paks)
ax1 = fig.add_subplot(2, 1, 1)
ax.yaxis.set_major_locator(mtick.LinearLocator(5))
f.write(bin_data)
set(tuple(sorted(elt)) for elt in example)
b = [dict(a)]
plt.plot(x, y)
fact = lambda x: 1 if x == 0 else x * fact(x - 1)
main()
conn.request()
cax.get_yaxis().set_visible(False)
a[:len(bbins)] += bbins
f()
Entry.objects.filter(created__range=(start_date, end_date))
y = x.astype(np.float)
np.hstack(x).shape
plt.show()
cursor.execute(sql, [id])
data = [(item + 256 if item < 0 else item) for item in data]
x[0] + x[-1]
MyDiccoSorted = sorted(list(MyDicco.items()), key=lambda s: s[1][2])
time.sleep(5)
self.label.setAlignment(QtCore.Qt.AlignCenter)
sorted(sentence, reverse=True)[0]
list(list(zip(r, p)) for r, p in zip(repeat(a), permutations(b)))
self.transport.write(line)
np.array_equal(np.asarray(foo_cv), foo_np_view)
self.timer.join()
plt.show()
sys.exit(0)
screen.blit(surf, (100, 100))
print(list(iter(root.children[1])))
np.hstack((vector1.reshape(-1, 1), matrix2))
out_file.write(line)
unittest.main()
root.mainloop()
self.post(*args, **kwargs)
ax2 = fig.add_subplot(2, 1, 2)
imshow(np.asarray(pil_im))
circle.grid(row=1, column=1)
df.apply(lambda x: x[np.where(x > 0)[0][0]], axis=1)
Fraction.from_float(0.25)
max(sum(1 for i in g) for k, g in groupby(L))
pyl.show()
self.stream.close()
array ^= numpy.random.rand(len(array)) < prob
plt.show()
shutil.copyfileobj(f_in, f_out)
f()
plt.show()
self.__dict__.update(state)
matplotlib.pyplot.show()
time.sleep(2)
df.groupby[di.month].Category.apply(pd.value_counts)
[next(gen) for _ in range(6)]
plt.show()
print(sorted(list(globalHotItems.items()), key=lambda x: x[1])[-4:])
abs(x=5)
plt.subplots_adjust(right=0.85)
float(s)
main()
list(IT.izip_longest(*readers))
self.foo()
dot(A, x)
webapp2.RequestHandler.dispatch(self)
s.listen(1)
a.max(axis=1)
seq[::2], seq[1::2]
sys.exit(app.exec_())
print([r.lower() for r in row])
df.apply(print_row, axis=1)
pyplot.show()
r = np.sqrt(x * x + y * y)
queryset = queryset.filter(full_name__icontains=string)
plt.subplots_adjust(top=0.9)
document.close()
plt.show()
element.clear()
server.serve_forever()
Thread.__init__(self)
ax.xaxis.set_major_locator(MultipleLocator(1.0))
s == s[::-1]
ax.plot_surface(x_surf, y_surf, z_surf, cmap=theCM)
reactor.run()
A = np.array(mean_data).mean(axis=0)
new_rows.append([str(elt).expandtabs() for elt in row])
s = requests.Session()
t.start()
Image.fromarray(imarray)
[(i, sum(j)) for i, j in list(d.items())]
sys.stdout.flush()
item = singlet_list[0] if len(singlet_list) == 1 else False
figure(figsize=(5, 10))
self.Bind(wx.EVT_PAINT, self.OnPaint)
cbgen(int(x), base, iexps), cbgen(x - int(x), base, fexps)
root.mainloop()
shutil.rmtree(temp_dir)
dataframe.iloc[:, ([0, 1, 4])]
curses.curs_set(0)
QtCore.QVariant()
b = a * (a > 0)
os.nice(1)
result.drop(0, axis=1, inplace=True)
sorted(dictionary, key=dictionary.get, reverse=True)[:10]
response = requests.get(url)
self.show_all()
[x.time for x in list_of_objects]
pd.MultiIndex.from_tuples(list(product(*categories)), names=names)
Acut[np.isnan(Acut)] = np.nanmean(Acut)
total += float(current_number)
s[~s.isnull()]
[0, 0, 0, 0]
changes.setdefault(k, []).append(v)
pd.read_excel(filename)
[0] * (len(a) - len(c)) + c
logger.addHandler(handler)
plt.figure(1, figsize=(size_x, size_y), dpi=98)
aobj.__class__
django.contrib.auth.middleware.AuthenticationMiddleware
b.swapaxes(0, 1)
res = [((s[i] + s[i + 1]) / 2) for i in range(0, len(s) - 1, 2)]
serializer.save()
themod.__dict__.update(thedict)
logger.setLevel(logging.DEBUG)
np.searchsorted(np.sort(x), x)
plt.axvline(x_position)
mylist.insert(0, mylist.pop(mylist.index(targetvalue)))
ax.plot_surface(X, Y, F)
Done
min(map(lambda x: string.index(x) if x in string else len(string), specials))
random.shuffle(all)
now = datetime.datetime.utcnow().replace(tzinfo=utc)
subprocess.Popen(cmd).wait()
threading.Thread.__init__(self)
plt.scatter(x, y, c=t, cmap=cm.cmap_name)
driver = webdriver.PhantomJS()
filter_func(parent_dict, lambda x: 2 < x < 4)
response
[1][0][2]
sorted(A, key=lambda e: e not in B)
sys.path.append(os.path.abspath(scriptpath))
tuple(numpy.subtract((10, 10), (4, 4)))
image.image.save(file_name, files.File(lf))
seq2str(img.getdata())
b.sort()
threading.Thread.__init__(self)
list(compress(list_a, fil))
moduleA.py
moduleB.py
ar = [[str(item) for item in results] for results in cur.fetchall()]
plt.show()
x = EqM_list(someiter)
data = [x for x in data if type(x) == float]
sorted(set(a_list))
service.files().delete(fileId=dir_id).execute()
gtk.main()
f.close()
plt.show()
f.close()
str1.split()
ax.set_xlim(-0.5, 1.5)
print(mystring[2:4])
[i for i in l for r in range(2)]
x = f.readlines()
tree = etree.parse(StringIO(your_xml_string), magical_parser)
map(f, tuple_list)
[(x - y) for x, y in it.izip(a[1:], a)]
b = word in (w for i, w in enumerate(wordList) if i != 1)
self.assertEqual(actual, expected)
ax2.set_ylim(0, 1.2)
print(map(itemgetter(0), next(bykey)[1]))
subA.tick_params(labelsize=6)
queryset = User.objects.all()
fun(**{b.decode(): v for b, v in list(dic.items())})
x = EqM_list(iter(d.keys()))
app.run()
sympy.solve([sympy.Eq(b - a ** 2.552 - c), sympy.Eq(b, 2)], rational=False)
globals().update({name: module_dict[name] for name in to_import})
np.random.seed(seed=0)
zip(*(s[i:] for i in range(n)))
print(r.status_code)
new_list.append(temp_list)
object.__new__(cls, *args, **kwargs)
A = (A - mean(A, axis=0)) / std(A, axis=0)
list(itertools.product(a, b))
[0.00148820116, 0.000295700572, 0.00441516179],
df.iloc[:, (0)]
getattr(self, name)
ax1 = fig.add_subplot(1, 2, 1)
print(ruamel.yaml.dump(d, Dumper=ruamel.yaml.RoundTripDumper))
np.sum(x, axis=-1)[:, (np.newaxis)] - np.cumsum(x, axis=-1)
ax.yaxis.set_major_locator(MultipleLocator(1.0))
b, g, r = img[:, :, (0)].copy(), img[:, :, (1)].copy(), img[:, :, (2)].copy()
smtp.sendmail(from_addr, to_addr, message.as_string())
lst.sort(key=lambda x: x[2], reversed=True)
process.kill()
views.py
conn.send(data)
hist([(t.hour + t.minute / 60.0) for t in ts], bins=24 * 60 / 15)
session.add(p)
c.append(quad(f, -1, 1, args=list(range(1, n + 1)))[0])
content = some_file.read()
print([result.get(timeout=10) for result in results])
print(lxml.html.tostring(doc))
df = df.append(df)
[11, 11, 11, 1, 18, 14, 14, 9, 9]
logging.getLogger().addHandler(setupcon.ColoredHandler())
arr[indices[:, (0)], indices[:, (1)]]
users.create()
parrot(**d)
ax = fig1.gca()
app.mainloop()
self.pack()
itertools.count(1000000000000)
sum(a)
time.sleep(2)
os._exit(0)
print(sess.run([x, y]))
self.queries.append(a[1])
json.dumps([str(nparray.dtype), base64.b64encode(nparray), nparray.shape])
ax.set_zticks(np.arange(0, 9, 0.5))
print(list(itertools.chain(*kana)))
sys.stdout.flush()
img = np.empty((100, 100, 1), dtype=np.uint16)
k.append(j)
client.send(message)
newobjs._register(obj)
p.kill()
math.exp(-np.logaddexp(0, -x))
ax.boxplot(data)
win.show_all()
args = parser.parse_args(get_xyz_cmd_line(sys.argv[1:]))
reactor.run()
json.dumps()
master.mainloop()
pandas.merge(df.stack(0).reset_index(1), id, left_index=True, right_index=True)
time.sleep(1)
plt.gcf().show()
os.symlink(linkto, dst)
print(yaml.dump(data, Dumper=yaml.RoundTripDumper, indent=4))
mainloop()
numpy.array([network.activate(x) for x, _ in train])
print(os.path.join(path, file))
Thread.__init__(self)
np.dstack(np.nonzero(df.values))[0]
hash(str(d))
print(response.read())
QtGui.QTabWidget.addTab(self, widget, title)
result_list = list(result.values())
print(cls.__name__)
X, Y = np.meshgrid(XB, YB)
print(icon_info.get_filename())
pylab.draw()
print(celery.AsyncResult.task_id)
a.argsort()[-10:]
window.activateWindow()
print(f.read())
deleteL[::2]
arr[1, -1]
print(sum(a))
np.argsort(b)[c]
time.sleep(0.5)
[(x * 2) for x in [2, 2]]
console.setFormatter(color_formatter)
ax = fig.add_subplot(111)
signal.signal(signal.SIGINT, old_action)
silhouette_score(iris.data, iris.target, sample_size=50)
print(fout.read())
plt.ylim([0, 1])
sys.exit()
map(lambda x: group(x, a), sum_vals)
[(stuff + stuff[:n / 2 - 1])[i:i + n / 2] for i in range(n)]
math.acos(dotproduct(v1, v2) / (length(v1) * length(v2)))
reactor.run()
rest = (n - last_digit) / 10
x = math.ceil(x * 100.0) / 100.0
root.mainloop()
view.configure_traits()
M.reshape(-1, 2, 2).sum(axis=0)
a = np.random.randint(0, 9, 10)
tuple(l)
admin.site.register(Session, SessionAdmin)
row[0, col.argsort()]
ax.add_artist(circle)
wb.Close()
np.where(np.diff(x) > 0.5)[0]
self.text_ent.grid(row=1, column=0)
5 + np.random.sample(10) * 5
ax.xaxis.set_major_formatter(formatter)
math.radians(45.0)
max(depth(self.left), depth(self.right)) + 1
flask.request.user_agent.string
print(list(reader))
next(iter(list(c.items())))
sorted(2 * list(range(5)))
session.query(Action).filter_by(name=name).one()
ShowAppsView.as_view()(self.request)
df.to_excel(writer)
name = models.CharField(max_length=64)
df.loc[cond1 | cond2]
ax.legend(loc=0)
print(list_end_counter([1, 1, 2, 2, 2, 2]))
os.chown(path, uid, gid)
app.exec_()
[(int(lst[x]) if x in indices else lst[x]) for x in range(len(lst))]
my_dictionary_list
x.__enter__()
a % b
i = [int(x) for x in s.split()]
dict(zip(x, y))
webbrowser.open(url, new=0, autoraise=True)
ax.set_xlim(-10, 10)
show()
df.apply(fillnull)
[k for k in list(mydict.keys()) if k >= 6]
show(p)
rows = [[field[k][i] for k in list(field.keys())] for i in range(2)]
window.show()
clientsocket.send(p)
process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
a + b
print(os.path.join(dir, file))
datetime.datetime.utcfromtimestamp(seconds)
self.y = 0
e.toxml()
[ast.literal_eval(el) for el in lst]
next(y)
Thread.__init__(self)
plt.draw()
print(np.partition(x, -10)[-10:])
plt.plot(x)
req.get_method()
t.start()
time.sleep(1)
print([abs(v - l[(i + 1) % len(l)]) for i, v in enumerate(l)])
print(df)
[(k, adict[k]) for k in sorted(adict, key=adict.get, reverse=True)]
s.replace(0, np.nan).dropna().astype(s.dtype)
sp.wait()
test.ix[i::4]
sock.settimeout(5)
pd.DataFrame(data, df.index, u)
file.seek(0, os.SEEK_END)
parser.parse(open(filename))
a[0][0]
str(f)
sizer.Add(input, 1, wx.EXPAND | wx.ALL, 5)
ax.plot_surface(Rnew * np.cos(Tnew), Rnew * np.sin(Tnew), Znew)
result = np.average(_array[::][1:], axis=1)
imgc = cv2.imread(file)
plt.legend()
any(map(my_dict.__contains__, my_list))
mpl.rcParams.update(manager._rcparams)
list(_)
np.dot(W, B)
[[z[i] for z in foo] for i in (0, 1)]
ax.plot(list(range(10)))
plt.show()
B = A[::2, :, 1:2]
os.chdir(path)
ab[x].sort()
arr[20:] = [0] * (len(arr) - 20)
S2.startswith(S1)
self.initialized = True
np.clip(arr, 0, 255, arr)
{{forloop.counter0}}, {{j}}
new_column.index
{t: [next(it) for _ in range(next(it))] for t in it}
app.mainloop()
br.set_handle_gzip(True)
plt.show()
df.apply(lambda x: x.between(2, 10, inclusive=False))
s.setsockopt(socket.IPPROTO_IP, socket.IP_HDRINCL, 1)
plt.subplot(111)
time.sleep(2)
all(item[2] == 0 for item in items)
self._background_task()
ax.set_xticks(numpy.arange(0, 1, 0.1))
c.showPage()
theproc.communicate()
plt.subplots_adjust(left=0.25, bottom=0.25)
myApp.setWindowFlags(QtCore.Qt.Tool)
driver = webdriver.Firefox(firefox_profile=profile)
s.bind((HOST, PORT))
main()
df.rename(columns=lambda x: x[1:], inplace=True)
print(html.tostring(table, pretty_print=True))
sys.excepthook = info
results = [t.age for t in mylist if t.person_id == 10]
mat.data -= numpy.repeat(vec.toarray()[0], numpy.diff(mat.indptr))
i = int(round(float(s)))
subprocess.Popen.communicate()
sys.modules.pop(module_name)
[x for i, x in enumerate(y) if i != 0 and x != 6]
d.execute()
print(todayDate.replace(day=1))
f.close()
socket.setdefaulttimeout(60)
[t for t in my_set if my_list.count(t) > 1]
bar()
A = numpy.array([[2, -1, 0], [-1, 2, -1], [0, -1, 2]], numpy.float)
{{value.name}}
child_process.kill()
L1.sort(key=lambda x: L.index(x))
func(*args, **kwargs)
list(filter(f, list(range(2, 25))))
map(operator.add, a, b)
self.create_socket(socket.AF_INET, socket.SOCK_STREAM)
main()
layout.addWidget(self.de)
print(r.content)
[(seen.add(obj.id) or obj) for obj in mylist if obj.id not in seen]
multiprocessing.cpu_count()
plt.boxplot(boxes, vert=0)
self.setGridIntersection(self.pos())
self.layout.addWidget(self.view)
Entry.objects.bulk_create(aList)
[a.join(b) for a, b in zip(df.a, df.b)]
show()
s.close()
C = map(sub, A, B)
func()
sys.stdout.flush()
np.maximum.reduceat(v, idx)
window.show()
my_list = [dict(out[v]) for v in sorted(out)]
[k for k, g in groupby(a) if len(list(g)) >= 2]
output.close()
print(cur.fetchall()[0])
tree = ET.ElementTree(ET.fromstring(xmlstring))
type.__new__(cls, name, bases, dct)
time.sleep(0.11)
sorted(list(x.items()), key=lambda kv: kv[1])
ctypes.c_ulong(-1)
result = [line.upper() for line in lines]
f.axes[0].set_position([0.05, 0.05, 0.4, 0.4])
t = [x for x in q if x in w]
print(match.group(1))
self.set.remove(d)
the_list.sort()
names = [row[0] for row in curs.fetchall()]
time.sleep(1)
python - -version
Py_Finalize()
1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0
w.writerow(row)
rfecv.fit(X_train, y_train)
df[~((df.A == 0) & (df.B == 2) & (df.C == 6) & (df.D == 0))]
[df.loc[list(p)] for p in permutations(age.get_group(21).index)]
print(sess.run(Z))
label.pack()
self.__dict__.update(kwargs)
db.close()
ssh.close()
fatal.setLevel(logging.FATAL)
process.stdin.write(data)
gtk.main_iteration(block=False)
solve(do_something(something))
clf = pickle.load(f)
a = MyClass()
reactor.run()
df[sheet] = pd.read_csv(csv)
df[df.duplicated(keep=False)]
pyplot.show()
data = json.loads(elevations)
deletelist1[:]
data.sort(key=keyfunc)
array([[1, 0], [1, 2]])
x.shape
s = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_IP)
print(im.format, im.size, im.mode)
br.set_handle_robots(False)
wx.Panel.__init__(self, parent)
sys.exit(app.exec_())
root.mainloop()
model = get_object_or_404(Customer, id=id, user=1)
Py_Initialize()
ax.xaxis_date()
print(f(a))
A = np.zeros((6, 6))
s.logout()
set(range(1, 101)) - s
list_one.append(list_two)
classroom.py
(l[i:i + n] for i in range(0, len(l), n))
o = [(l[i], l[i + 1]) for i in range(0, len(l), 2)]
rreverse(s[1:]) + s[0]
os.waitpid(p.pid, 0)
FI.close()
session.commit()
frame.groupby([pd.DatetimeIndex([x.date() for x in frame.index])]).sum()
q.filter(or_(*conditions))
query = Session.query(Table).filter(clauses)
zip(range(1, 7, 2), range(2, 8, 2))
response = urllib.request.urlopen(req)
any(np.array_equal(np.array([a, a]), x) for x in my_list)
uuid.UUID(value)
[1, 2, 2]
f = Foo()
res.append(lst[i])
json.dumps(self.json)
time.sleep(0.5)
any(len(set(x)) == 1 for x in zip(*arr))
struct.pack(new_format, *args)
server.set_debuglevel(1)
plt.show()
[[0], [1], [2], [42], [4]]
(u + x) * (a + d + g) + (v + y) * (b + e + h) + (w + z) * (c + f + i)
print(cur.fetchall())
np.vstack(j).T
zcat.wait()
time.sleep(0.25)
df[df.Phrase.str.len() != 0]
f.close()
sys.exit(app.exec_())
print(my_list)
sys.getsizeof(a)
f2.close()
plt.draw()
self.canvas.pack()
signal.signal(signal.SIGINT, signal.SIG_IGN)
sys.getsizeof(n.__dict__)
out.extend(map(str, list(range(r[0], r[-1] + 1))))
QtCore.QAbstractItemModel.__init__(self)
gtk.main_quit()
numpy.atleast_2d(x[x[:, (2)] == 1])
sum(int(x) for x in s if x.isdecimal())
__init__.py
plt.xticks(rotation=70)
cur.connection.close()
test.myfun(test.f)
self.assertEqual(r, a)
cur.execute(sql, list(values.values()))
pygame.display.flip()
[prod(x) for i in range(2, len(lst) + 1) for x in combinations(lst, i)]
instance.save()
rdd.mapPartitions(f).collect()
q = Queue.Queue()
{b.pop(0): {b.pop(0) for _ in range(1)} for _ in range(1)}
a[::-2]
test_handler()
print(in_nested_list(x, [1, 2]))
id = Column(Integer, primary_key=True)
root.quit()
data[abs(data - np.mean(data)) < m * np.std(data)]
pip2 - -version
print(A[idx])
zip(a, b, c)
result.append([list[index][0], list[index + 1][1]])
plt.scatter(x, y, c=t)
list(Counter(words).values())
ax.set_axis_off()
xDate = sys.argv[1]
caketaste()
timedelta(seconds=_diff.total_seconds())
ctx.set_font_size(font_size)
admin.site.unregister(User)
Foo.allocate_ids(max=26740080011040)
fig.canvas.draw()
max((len(v), k) for k, v in flows.items())
set(a).intersection(b)
ax.spines[direction].set_visible(True)
sys.exit(exit_code)
len(self.children) == 0
sorted(_, key=lambda x: sum(x))
[([x] * i) for i, x in zip(A, B)]
plt.figure()
sys.path
plt.imshow(Z)
sys.exit(0)
PyInit_gstreamer()
[bar() for i in range(10)]
foo(1, 2)
app.run(extra_files=extra_files)
sys.stdout.flush()
t, z, y, x = np.indices(temp.shape)
file(filename).read()
np.where((abcd <= data2a) & (abcd >= data2b), 1, 0).sum()
print(len(letters) > len(no_rep))
print([[x for x in a if len(x) == i + 1] for i in range(m)])
ax.set_aspect(1)
i += 1
ax.set_xlim(0, 10)
print([A[p][i] for i, p in enumerate(P)])
filtered_list = list(filter_list(full_list, excludes))
json.JSONEncoder.__init__(self, *args, **kwargs)
sys.exit(app.exec_())
list_of_lists = [list(elem) for elem in list_of_tuples]
s = random.randint(0, 2 ** 10000 - 1)
pd.concat(pd.read_html(url), ignore_index=False)
urllib.parse.urlencode(a)
np.array(__, dtype=float)
curses.echo()
urllib.parse.urlencode(url_dict, True)
conn.close()
s1.reset_index(drop=True)
f.close()
time.sleep(1)
loop.close()
np.where(a[:, (1)] == 2)
tokenize.sent_tokenize(p)
print(f(1))
login()
keys = set(chain.from_iterable(dicts))
plt.show()
min(iList, key=lambda i: i.number)
tk.Label(self.frame, text=t).grid(row=row, column=1)
QtWidgets.QGraphicsScene.mouseMoveEvent(self, event)
zip((x.count(item) for item in set(x)), set(x))
print(f.read())
start_date + relativedelta(months=2)
pygame.quit()
response.close()
first, rest = seq[0], seq[1:]
root.mainloop()
print(repr(f.readline()[:1]))
QtCore.QVariant()
msg = msg.rstrip()
list(map(itemgetter(0), G))
results = sorted(list(results_dict.items()), key=lambda x: abs(x[0]))
logger.setLevel(logging.DEBUG)
[list(islice(b, x)) for x in l]
pprint.pprint(row)
connect.commit()
self.Bind(wx.EVT_KEY_DOWN, self.OnKey)
pickle.dump(a, f)
items = [[1, 2, 0], [1, 2, 1], [1, 2, 0]]
time.sleep(2)
pprint(sys.path)
list(itertools.dropwhile(math.isnan, reversed(r)))[::-1]
isinstance(obj, int)
print(select([func.count()]).select_from(table))
time.sleep(1)
a + b
ax.set_xlim(0, 25)
plt.show()
deletex[2]
fig = plt.figure()
a = b
result.setdefault(column, []).append(value)
next(x for x in range(10) if x == 7)
str(tdo)
bisect.bisect_left(l, 4)
list(df.T.to_dict().values())
signal.signal(signal.SIGTERM, signal_handler)
o5.method()
self.crawler.start()
[np.insert(j, 0, i) for i, j in product(a, np.array((b, c)).T)]
df.groupby(df.index)
date -= timedelta(days=5)
result = [el.text_content() for el in result]
selfref_list.append(selfref_list)
plt.figure(figsize=(7.15, 5.15))
os.path.split(fullpath)
celery.control.revoke(uuid, terminate=True)
{{42.55 | round}}
print(user.username, user.get_full_name(), user.email)
cls(*args, **kwargs)
[(x ** 2) for x in range(5)]
yourThread.daemon = True
print(pattern.search(text).group(1))
label.pack()
plot.show()
sys.stdout = sys.__stdout__
df.ix[row.name]
numpy.array(strings, dtype=float)
my_dict[key] += 1
writer.writerow(keys)
deleteall[max(current - 2, 0):current]
value = int(value)
print(num)
f.read()
wb = load_workbook(filename=BytesIO(input_excel.read()))
sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))
a[[ind]]
list(enumerate(reversed(test)))
pdb.set_trace()
any(c.isalpha() for c in string_1)
neurons.append(neuron)
f.close()
print([tuple((a, b + 1) for a, b in group) for group in t])
print(numpy.argmax(a_by_a, axis=1))
do_something(my_object)
controller1.py
np.dot(a, weights)
tar.close()
deletea[k]
plt.show()
print(np.where(mask)[0])
d2 = copy.deepcopy(d)
deletesys.argv[1]
len([x for x in str_.split() if x in list(dict_1.values())])
cur.close()
r = urllib.request.urlopen(req)
logging.getLogger()
media_frame.stack().map(m).unstack()
DataFrame.mode()[0]
d = dict(l)
app.test_request_context().push()
np.split(index[sort_idx], np.cumsum(cnt[:-1]))
df
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
mylist.pop()
c = b[index]
[do_stuff(a, b) for a, b in itertools.permutations(A, 2)]
sys.exit(app.exec_())
a = numpy.arange(25).reshape(5, 5)
self.figurecanvas.draw()
df = pd.read_csv(StringIO(text), parse_dates=[0])
followers_df.reset_index()
print(sys.version)
set(yourString) & set(badChars)
np.arange(10)[::-1]
plt.yticks(np.arange(y.min(), y.max(), 0.005))
arr = np.empty(dims, dtype=kerneldt)
[e for e, g in groupby(sorted(my_list))]
heapq.heappush(heap, (-prod, n, n))
unittest.main()
foo(*values)
self.__dict__.update(cls.__dict__)
matched[1] += 1
bucket.delete()
sys.stderr.write(str(prompt))
plt.subplots_adjust(bottom=0.2)
writer.writerow(item)
pdb.Pdb.__init__(self)
df.CITY
self.socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
foo()
print(json.dumps(OrderedDict(table_data)))
plt.show()
d = {key: value for key, value in zip(keys, values)}
fig.clf()
id = Column(Integer, primary_key=True)
root = tk.Tk()
result = op_func(a, b)
sns.kdeplot(np.array(data), bw=0.5)
sum(delta_list, timedelta()) / len(delta_list)
deletedictionary[old_key]
plt.show()
parser.parse_args(f.read().split(), namespace)
Thread(target=run, args=(args.arg1, args.arg2))
newList
pkt[TCP].payload = send_hdr
termios.tcsetattr(fd, termios.TCSAFLUSH, new_settings)
threading.Thread.__init__(self)
socket.connect((HOST, PORT))
myList.index([x for x in myList if x != 0][0])
loop.run_forever()
print(msg.as_string())
lambda partition: target == sum(map(int, partition))
classifier.classify(featurized_test_sentence)
setattr(self, Properties_Pointers[i], group)
sorted(lst, key=lambda x: -x[1])
plt.scatter(list(range(len(y))), y, s=60, c=z, cmap=cm.hot)
plt.gca().add_artist(circle)
help(uuid.UUID.__init__)
fly.set_data([fdata[0][0], fdata[0][-1]], [fdata[1][0], fdata[1][-1]])
fig.show()
pandas.DataFrame(data).groupby(0).mean()
self.id = self.get_next_id()
_to.update(_from)
print(difflib.get_close_matches(target_word, list_of_possibles))
[(x + y) for x, y in zip(*([iter(q)] * 2))]
do_something()
s = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
custom_API()
np.delete(x, indx)
QtWidgets.QListView.__init__(self, parent)
[(1 if p < 0.5 else 2) for p in classifications]
result = map(lambda x: x * P, S)
a = a[:]
print(os.read(f.fileno(), 50))
len(mylist)
p.terminate()
f.close()
abs((10 ** 0.5) ** 2 - 10) < 1e-10
vals[idx].tolist()
[np.argmin(a) for a in A1]
logger.setLevel(logging.WARNING)
oname.text
signal.signal(signal.SIGUSR1, handler)
np.sum(np.dot(xdiff, L_inv.T) ** 2, axis=1)
plt.subplot(212)
my_string.split()[:5]
ax.xaxis_date()
time.sleep(0.5)
fig.autofmt_xdate()
MyClass.__init__(a)
cursor.execute(sql, data)
threading.Thread.__init__(self)
thread.start()
main()
geoms.append(p)
np.argsort(x, axis=1)[:, 0:k]
threads.setdefault(row[2], []).append(row)
array([[11], [12]])
plt.pause(1)
pd.rolling_mean(data, window=5, center=True)
main()
[x for x in tokenize(txt)]
print(d[key])
soup.prettify()
df.drop(idx)
termios.tcsetattr(fd, termios.TCSADRAIN, new)
b = (x ** 2 for x in a)
x = x[:50]
lst.sort(key=itemgetter(1))
5 // 2
results[i].append(benchmark(i))
f.close()
yourlist.append(yourdict.copy())
self.socket.connect((server_ip, server_port))
threading.Thread(target=listen_to_audio).start()
merge(DataFrame(tmp, index=[0]), data)
zip(*lst)[0]
tick_params(labeltop=True, labelright=True)
parser = argparse.ArgumentParser()
client.load_system_host_keys()
np.vstack([get_col(col) for col in cols]).T
time.sleep(0.5)
a = np.array([0, 0, 0, 0, 0, 0])
sorted(set(val for row in content.values() for val in row))
msg.attach(part)
r = redis.Redis(connection_pool=pool)
pl.xlim(0, df2.shape[1])
QWidget.__init__(self)
plt.show()
data = list(datareader)
form = UserForm(request.POST, user=request.user)
sum(dict(structure).values())
driver.set_window_position(0, 0)
np.unpackbits(b)[:n].reshape(shape).view(np.bool)
copy.deepcopy()
l.sort(key=itemgetter(0))
id = Column(Integer, primary_key=True)
os.startfile(d)
pg.QtGui.QApplication.exec_()
f.write(doc.toxml())
ax1.yaxis.set_major_locator(matplotlib.ticker.LinearLocator(nticks))
plt.show()
python - config - -cflags
python - config - -ldflags
main()
br.select_form(nr=0)
min_keys = [k for k in d if all(d[m] >= d[k] for m in d)]
print(zip(*p))
itertools.product(universe, repeat=2)
ax = fig.add_subplot(1, 1, 1)
sys.path.append(os.path.basename(os.path.dirname(__file__)))
list(zip_longest(*([iter(chain([0], *liPos))] * 2)))
plt.figure(1)
f.seek(0)
df = pd.read_csv(yourdata, dtype=dtype_dic)
plt.show()
ax = fig.add_subplot(1, 1, 1)
gen.__code__.co_name
df.columns = df.iloc[1]
sys.stdout.flush()
session.add_all([a, b])
Foo.__str__ is not object.__str__
QtGui.QWidget.__init__(self)
app.logger.setLevel(logging.INFO)
signal.signal(signal.SIGUSR1, debug)
HttpResponseRedirect(url)
fig = plt.figure()
l = [0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1]
list(product(*iterables))
parser.parse(some_file)
print(max(path.nodes, key=lambda item: item.y))
requests.get(url, cookies=load_cookies_from_lwp(filename))
time.sleep(60)
tf.matmul(x, tf.transpose(y))
self.someSignal.connect(self.someSlot)
a2.ravel()[:] = m.reshape(2, -1).T.tolist()
np.where(binplace == 1)
pprint.pprint(value)
print([list(g[1]) for g in groupby(sorted(l, key=len), len)])
instance = form.save(commit=False)
fig, ax = plt.subplots()
fig, ax = plt.subplots()
Books.objects.filter(q)
datetime.time(0, 0, 0)
sys.path.append(lib_path)
print(my_list)
ax.set_aspect(1)
input.close()
p.terminate()
print(numpy.linalg.norm(x))
plt.close()
myfunc(*mylist)
fig.show()
fig.autofmt_xdate()
f = sys.stdin
input()
dis.dis(lambda : i)
root.mainloop()
blobs = BlobInfo.all().fetch(500)
first_elements, second_elements = zip(*data)
sorted([i for i in lst if i > 0]) + sorted([i for i in lst if i < 0])
y = math.cos(1 * math.pi / 180)
s = math.sqrt(max(radius * radius - i * i, 0.0))
print(urllib.request.urlopen(ipcheck_url).read())
c.execute(query)
cs.send(c + 1)
timestamp.sort(reverse=True)
fig = plt.figure()
base64.b64encode(stream.getvalue()).decode()
out_file.write(indata)
print([num for num in a if counts[num] > 1])
QtGui.QWidget.__init__(self, parent)
[np.where((B == x).sum(axis=1))[0] for x in A]
file.write(line)
d.update([a, b, c])
results = Orchard.objects.filter(**options)
plt.show()
(v1 == v2).all()
self.timer.start(10)
reactor.run()
[c for c in col_names if all([(f not in c) for f in filter_array])]
f.axes[5].set_position([0.95, 0.05, 0.05, 0.4])
df2 = df[df.Group.isin(groups)]
out.shape
clp.CloseClipboard()
self.crawler.install()
np.count_nonzero(A == B)
pipe.communicate()
plt.imshow(data.T)
ax.plot_wireframe(X, -Y, Z, rstride=1, cstride=1)
df.shape[0] - df.dropna().shape[0]
str(self.person)
fstools.py
args = parser.parse_args()
f(*args, **kwargs)
ax.set_ylim(bot, top)
f = lambda x: 2 * x
os.waitpid(cpid)
SumLine.extend(ast.literal_eval(x))
print(list(Counter(L).items()))
x[np.lexsort((x[:, (0)], x[:, (1)]))]
ax.set_xlim(x_min, x_max)
print(cert.get_issuer().as_text())
p.terminate()
plt.show()
Base.metadata.create_all(engine)
root.destroy()
self.f(*args, **kwargs)
infile.close()
self.graph, = self.ax.hexbin(self.xData, self.yData)
i += 1
array([[0, 0, 1, 1], [0, 1, 1, 0]])
result.append(myDict)
plt.draw()
time.sleep(0.01)
sys.stdout.write(out)
zip(a[0], a[1])
globals().update(test.__dict__)
log.start()
foo()
np.ma.median(y, axis=0).filled(0)
[0, 1, 0, 2, 1, 1, 1, 0],
object.__new__(cls, x)
sandboxed()
inspect.getargspec(func)
np.where(np.in1d(a, b))[0]
max(depth(d[k], level + 1) for k in d)
result = [_f for _f in map(expensive, mylist) if _f]
sys.stdout.flush()
results = cursor.fetchall()
print(r.cookies)
x.append(y)
list(itertools.chain(*a))
socket.close()
time.sleep(5)
f.close()
print([(dotted[n][:-1] + (i,)) for s in signs for n, i in enumerate(s)])
n, bins, patches = plt.hist(x, histedges_equalN(x, 10), normed=True)
signal.signal(signal.SIGINT, signal.SIG_DFL)
next(g)
repr(self.contained)
web.show()
hasattr(obj, name) and type(getattr(obj, name)) == types.MethodType
time.sleep(1)
pool.terminate()
time.sleep(self.interval)
ftp.close()
fig = plt.figure()
plt.tight_layout(rect=[0.05, 0.15, 0.95, 0.95])
hex(x)[2:]
matplotlib.get_backend()
plt.draw()
unittest.TextTestRunner().run(suite)
p = Pool(5)
layout.addWidget(self.button)
pygame.mixer.init()
bytearray(os.urandom(1000000))
chain.from_iterable(combinations(s, r) for r in range(1, len(s) + 1))
wrapper_object.blink()
self.progress.pack()
self.output.append(data)
lst[0].append(1)
print([(k, len(d[k])) for k in sorted(d.keys())])
print(x.apply(lambda y: list(filter(np.isfinite, y))))
sorted(list(dct.items()), key=lambda p: p[1], reverse=True)
os.dup2(cat.stdin.fileno(), sys.stderr.fileno())
plt.colorbar()
min(data, key=lambda t: t[1])
print(tuple([k] + [v for d in L for v in list(d.values())]))
f.write(bytes(int(x, 0) for x in L))
my_tuple[isinstance(x, str)].append(x)
ax = fig.add_subplot(1, 1, 1)
self.window.set_default_size(self.width, self.height)
a[len(a)]
df[~df.isnull().all(axis=1)]
event_box.set_events(gtk.gdk.BUTTON_PRESS_MASK)
list2 = [dict2[k] for k in commons]
smtpObj.sendmail(sender, receivers, message)
f.read()
top.mainloop()
browser = webdriver.Firefox()
main()
img = Image.open(BytesIO(response.content))
[int(elem) for elem in testList]
[functools.reduce(dict.__getitem__, keys, d[i]) for i in d]
plt.show()
datetime.time
diags.sum(axis=1)
m.groups()[0].strip()
input_file.close()
plt.show()
[myFunc(p, additionalArgument) for p in pages]
inspect.ismethod(d.__setitem__)
plt.show()
a = np.arange(100).reshape(2, 50)
d = json.loads(s)
sys.exit(1)
a, b = divmod(a, 1)
p.terminate()
doctest.testmod()
lists[1].append(url)
np.random.shuffle(a)
pdb.set_trace()
Job.fetch(job_id, connection=conn)
HttpResponse(status=500)
print(s, len(s))
self.SetClientSize((self.bmp.GetWidth(), self.bmp.GetHeight()))
foo.wait()
plt.show()
id = models.CharField(max_length=255, default=create_id)
x = np.linspace(0, 1, 20)
main()
QtGui.QMainWindow.__init__(self)
array_proxy()
os.kill(int(pid), signal.SIGTERM)
print(ET.tostring(dom))
main()
signal.signal(signal.SIGUSR2, lambda sig, frame: code.interact())
f(*args, **kwargs)
ax.scatter(X[:, (0)], X[:, (1)], s=s)
plt.show()
self.a = a
[np.bincount(xs, minlength=10) for xs in itertools.combinations(list(range(10)), 2)]
numpy.linalg.norm(A - B)
plt.subplots_adjust(0, 0, 1, 1, 0, 0)
self.driver.close()
max(lengths(l))
x = {i: set() for i in range(10)}
print(line)
args[-1] + mySum(*args[:-1])
myDict[name]
len(s)
arr = numpy.array([(base + datetime.timedelta(hours=i)) for i in range(24)])
fig = plt.figure(1)
df.replace(to_remove, np.nan, inplace=True)
data.sort()
255, 255, 255
ax2.set_xlim(ax1.get_xlim())
self.calendar.pack()
some_list[:target_len] + [0] * (target_len - len(some_list))
ax2.plot(x2, x2, alpha=0)
a = str(datetime.now())
time.sleep(1)
object.__repr__(self)
max(len(str1), len(str2))
t.start()
print(func_name)
plt.contour(xi, yi, zi, con_levels, linewidths=1)
cv2.circle(cimg, (i[0], i[1]), i[2], (0, 255, 0), 2)
df.sort_index(inplace=True)
result = map(f, [x, y, z])
utc_dt = local_dt.astimezone(pytz.utc)
df = pd.concat([df1, df2], ignore_index=True)
axcut.set_visible(True)
np.random.seed(0)
file_out.write(line)
json.loads(page_detail_string)
sys.__stdin__ = dummyStream()
ax.clear()
nan in np.array([nan])
list1.append(i)
self.data.append(data)
set(b.items()) ^ set(a.items())
print(response.status, response.reason)
s.dt.to_pydatetime()
dictionary[round(a, 4)]
meta.create_all()
app.exec_()
data[data[data[:, (0)] == 0, 1] == 0]
f.close()
df2.fillna(0, inplace=True)
dill.pickles(f)
list(set(a) - set(b))
rdd = df.rdd.map(tuple)
all([(len(i) == len(set(i))) for i in zipt])
stock_vals[stock_name][day_index]
myDict = dict(list(element.attributes.items()))
np.hstack([R, phase])
{{test | tojson | safe}}
out = ohc.fit_transform(X)
print(repr(a))
np.where(np.diff(x) > 0.5)[0] + 1
zip(a, b)
0j
x[nonzeros].dot(mat[nonzeros])
pygame.init()
found = any(word == line.strip() for line in file)
A[:, (0)]
self.file.close()
ContentType.objects.get_for_model(obj)
np.bmat([[A, D], [C, B]]).A
self.panel.SetSizer(main_sizer)
os.chdir(curdir)
fig, ax = plt.subplots(1, 1, figsize=(12, 5))
array([1, 2])
p4in.close()
pp.sort(key=lambda p: math.atan2(p[1] - cent[1], p[0] - cent[0]))
Py_DECREF(v)
l[:] = [(x * 5) for x in l]
l1.append([7, 8, 9])
min(dictionary.values())
[elem for i, elem in enumerate(inputlist) if i not in excluded_indices]
Bar.objects.foo_active()
df.index + pd.offsets.MonthEnd(0)
print(list(locals().keys()))
server.quit()
plt.xticks(x)
list(replaceiniter(range(11), lambda x: x % 2))
np.any(a == 5, axis=0)
[list(g) for k, g in groupby(a, lambda x: x != 0) if k]
cursor.execute(*sql_and_params)
session.query(User, User.entries_count(Entry.date > start_date))
root.mainloop()
df1.groupby(level=0)[cols].apply(find_window)
k += 1
a.shape
plt.show()
d = {m.get(key, key): value for key, value in list(d.items())}
pool = Pool(processes=2)
map(dictionary.__delitem__, lst)
reduce(dict.get, path, aDict).update(aSecondDict)
n * n
LOGGER.setLevel(logging.WARNING)
self.root.mainloop()
cookiejar.set_cookie(cookie)
np.power(df, 2)
GC.remove_edge(*clique[0:2])
a[::-1]
random.shuffle(b)
plt.show()
time.sleep(1)
sum(map(lambda x, y: x * y, l1, l2))
print(thingy.attrib)
min(a, key=itemgetter(1))
ax = fig.add_subplot(111)
vscrollbar.grid(row=0, column=1, sticky=N + S)
time.sleep(1)
print(np.loadtxt(io.BytesIO(trace.text)))
os.nice(20)
df = pd.read_csv(filename, skiprows=lines2skip)
array([nan + 0j, nan + nanj, nan + nanj, nan + nanj, nan + nanj])
dis.dis(f)
sys.excepthook = handle_exception
f.close()
dis.dis(lambda x: x)
logging.Handler.close(self)
ax.set_yticks(list(range(0, 90, 10)))
main()
found = re.findall(regex, my_txt)
print(f.decorator)
df.matches.sum()
print(numpy.sum(c * a))
plt.show()
plt.pcolormesh(X[i - 2:i], Y[i - 2:i], C[i - 2:i])
sys.path.insert(0, self.path)
random.shuffle(thelist)
module1.Relay(1, 1)
User.objects.filter(id=self.request.user.id)
time.sleep(5)
[list(i) for i in set([tuple(sorted(i)) for i in a])]
lbl8.grid(row=2, column=0)
ao[:, :-1] += ai[:, 1:]
fpid.close()
f(1, 2)
print(sys.path)
print(np.allclose(a2, a))
sorted(templist, key=int)
tt = np.linspace(0, 19, 20)
ord(chars[0])
func(arg)
print(a[:, (1)])
(d1.year - d2.year) * 12 + d1.month - d2.month
self.children = {}
queryset = Model.objects.all()
show()
input.close()
plt.draw()
user.save()
parser = argparse.ArgumentParser()
my_func()
show()
result = bool_indices.apply(lambda x: df.loc[x, col_values].sum())
cv2.cv.CreateMat(500, 500, template.dtype)
time.mktime(t.timetuple()) + t.microsecond / 1000000.0
conn.close()
df.loc[lhs, column] = rhs
callback(self)
plt.clf()
response
np.vstack((a, a, a))
height = img.shape[0]
zip(list(range(len(a))), a)
os.path.join(root, file)
output.close()
print(self.__name__)
canvas.grid(row=1, column=1, sticky=Tkconstants.NSEW)
obj.save()
decorator
x = [(bah * 2) for bah in buh]
self._socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
s.connect((ip_addr, port))
a.py
list(results.values())
Counter(A.flat).most_common(1)
scores.append(clf.score(X[outer_test], Z[outer_test]))
plt.show()
jsonFile.seek(0)
sorted(lst, key=lambda x: (x < 0, x))
lis.append(lambda i=i: i)
(get_comments.s(url) | render_template.s()).apply_async()
a = numpy.empty([210, 8])
communication_set.save()
self.setWindowFlags(QtCore.Qt.FramelessWindowHint | QtCore.Qt.Popup)
words = sorted(wordset)
plt.gca().yaxis.set_major_locator(MaxNLocator(nbins=6))
pivoted.cumsum() + (pivoted == -1)
pd.isnull(np.array([np.nan, 0], dtype=object))
C = A * B
time.sleep(1)
ax = fig.add_subplot(111, frameon=False, xticks=[], yticks=[])
pygame.display.quit()
file.flush()
print(Y.transpose())
root.mainloop()
self.create(request, *args, **kwargs)
type(li)(map(double, li))
plt.legend()
p = subprocess.Popen(cmd, shell=False, stdout=subprocess.PIPE)
category = forms.ChoiceField(choices=CATEGORIES, required=True)
pygame.display.set_mode()
arr[arr > 255] = x
cursor.execute(sql)
test_moduleB.py
main.py
plt.gca().add_artist(leg2)
plt.gca().add_artist(leg4)
plt.gca().add_artist(leg6)
[1][1][1]
x.pattern
zip([iter(l)] * 2)
len(set(hashlib.sha256(str(i)).hexdigest()[:5] for i in range(0, 2000)))
name = models.CharField(max_length=200)
print(time.time())
Counter(list(c.values()))
results = pbex.run()
data = json.load(f)
ax = fig.add_subplot(1, 1, 1)
ax.set_xlim(0, m.shape[1])
numpy.random.rand(count)
result = next(x for x in my_list if works(x))
ts = pd.Series([2, 1, 2, 1, 5], index=date_index)
np.savetxt(s, x)
s.close()
t = datetime.datetime(2009, 4, 1)
ax2.xaxis.set_visible(False)
Gtk.main()
root.mainloop()
img.write(pdf_path)
self.entry.focus_set()
print(result.groups())
worker.send(msg, zmq.NOBLOCK)
{{(request.user.username | multiply): 5}}
AB = np.matmul(A, B)
list(itertools.product(list(range(5)), list(range(5))))
a.insert(len(a), 5)
self.stateChanged.connect(self.handleStateChanged)
temp = tuple(map(sorted, zip(*alist)))
print(x[0], len(list(x[1])))
somelist.sort(key=ordering.get)
isinstance(value, list)
population = [a for n, a in zip(pops, alleles) for _ in range(n)]
__import__(module)
etree.tostring(tree)
a[:2, (2)] = 0
app.run(debug=True, use_reloader=False)
[(1.0 * conversions[n] / trials[n]) for n in range(len(trials))]
self._dealer = dealer
func(*args, **kwargs)
shutil.copyfileobj(key, rsObject.stream())
tk.Tk.__init__(self, *args, **kwargs)
--Commentasfkjaskfj
fig, ax = plt.subplots(1, 1)
resultqueue.join()
np.isnan(a[2]).nonzero()
setattr(obj.a, p, value)
add_something(l)
plt.show()
res = (list(range(s, s + step + 1, step)) for s in range(start, stop, step))
app.MainLoop()
type(())
L.sort()
print(contruct.__version__)
print(m.group())
array([[100, 200], [255, 255]], dtype=uint16)
print(json.dumps(parsed, indent=4, sort_keys=True))
ent7.grid(row=2, column=1)
list(zip(*(d[k][n] for k in keys for n in d[k])))
MyObject.objects.bulk_create(my_objects)
value = models.CharField(max_length=240, db_index=True)
np.mean([0, 1, 2])
theclass.run()
signal.signal(signal.SIGINT, s)
u = np.random.random(100)
[(key, list(val)) for key, val in itertools.groupby(lst, lambda x: x[0:5])]
self.x.pack(side=LEFT)
find_majority([-1, -1, 0, 0, 0])
print(dom.toxml())
sorted(xs, key=len)
[func(elem) for elem in lst]
ax.add_patch(polA)
ax.add_patch(polB)
out.close()
df.head(5)
df.iloc[:, (0)]
pylab.show()
my_category.category.all()
window.unfullscreen()
ax.xaxis.set_ticks_position(direction)
plt.figure()
lxml.html.tostring(root)
os.unlink(f.name)
excel.Quit()
(A + B).min(axis=1)
connection.close()
task.AsyncResult(task.request.id).state
numbers = list(map(int, s.split()))
df
model.fit_transform(X, y)
list(range(0, n + 1, 2))
main()
time.sleep(1)
results.sort(key=lambda x: x[1])
listmatrixMap(lambda val, r, c: ((r, c), val), a, indices=True)
yaml.dump(self.__dict__)
parser = argparse.ArgumentParser()
app.run()
ax.set_yticklabels(row_labels, minor=False)
diff_file.write(difftext)
diff(unwrap(phase(hilbert(filtered_data))))
data.depth * len(data.getbands())
t.start()
ntxt.write(rline)
server.quit()
QtGui.QApplication.sendEvent(clipboard, event)
pd.groupby(b, by=[b.index.month, b.index.year])
some_file.seek(0)
df[~df.index.isin(dropThis)]
token.save(force_insert=True)
browser.close()
strange_sandwich()
[lst[indices[i]:indices[i + 1]] for i in range(n)]
idx = np.argsort(a[1])
pygame.display.flip()
self.f.make_a_doo()
b = copy.deepcopy(a)
df.round()
self._rooms = dict()
itertools.chain(*zip(*iters))
sizer.Add(notebook, 1, wx.EXPAND)
list()
s = urllib.request.urlopen(form_url)
os.getpid()
set([4, 5, 6])
output.append(acids[0])
np.diff(m.tocsc().indptr)
yacc.errok()
print(locals())
print(repr(tokzr_SENT(inp1)))
plt.xlim(np.log10(ilim))
print(ET.tostring(f))
f.write(ip)
main()
func(*parameters)
main()
app.run()
label.pack()
[a for i in items if C]
fo.close()
plt.show()
session.add(stud)
data = json.loads(response.get_data(as_text=True))
logger.setLevel(logging.DEBUG)
print(item)
foo(*params)
df.sort_index(inplace=True)
logger.setLevel(level)
p.start()
globals[key] = value
df[~df.field.isin(ban_field)]
plt.show()
QApplication.restoreOverrideCursor()
ax2 = fig.add_subplot(1, 2, 2)
items.remove(item)
db.session.commit()
installer.uninstall()
plt.show()
dict(heapq.nlargest(5, list(names_dict.items()), key=itemgetter(1)))
arr[idx[:, (0)], idx[:, (1)]]
df.apply(lambda x: (x - np.mean(x)) / (np.max(x) - np.min(x)))
main()
self.data[column].add(row)
df.isnull().sum()
GL.glOrtho(-1.0, 1.0, -1.0, 1.0, -1.0, 1.0)
widget.show()
print(A.T)
b.swapaxes(0, -1)
stream.Close()
C.objects.create(a=a1, b=b)
inputElement.submit()
os.unlink(tmpfile_name)
print(G.nodes())
data = re.findall(pattern, line)
root.mainloop()
parser = etree.XMLParser(remove_blank_text=True, strip_cdata=False)
datetime.datetime.fromtimestamp(0) + datetime.timedelta(seconds=2047570047)
ax = fig.add_subplot(111)
print(df)
self.filelist.append(zinfo)
mlab.axes()
gtk.main()
self.setCentralWidget(self.button)
type(a)
newprefix = prefix[:]
lstbox.grid(column=0, row=0, columnspan=2)
map(lambda *x: sum(x), list(range(10)), list(range(10, 0, -1)), list(range(0, 20, 2)))
wx.Button.__init__(self, *a, **k)
matrix = np.random.randint(2, size=(row, col))
development.py
p.wait()
f.write(line)
pool.close()
ax = fig.add_subplot(111)
sum(map(doSomething, originalList), [])
result.append(func(e))
self.Bind(wx.EVT_BUTTON, self.OnClick, b)
exit(0)
[False, False, False, False, False],
tk.Tk.__init__(self, *args, **kwargs)
__init__.py
self.buttonStart.clicked.connect(self.worker.run)
Base.metadata.create_all(bind=db.engine)
foo(n - 1) + [1]
connection.start()
webdriver.ActionChains(driver).move_to_element(el).click(el).perform()
app.run()
driver.quit()
f.writelines(file_lines)
np.where(self == value)
root.mainloop()
session.commit()
y[0] = 0
print(response.read())
time.sleep(10)
searchfile.close()
[add_number(xi) for xi in my_list]
ax.add_line(line_2)
sys.path
plt.gca().add_patch(rect)
f.close()
A, = np.array(M.T)
sys.path.pop(0)
int(bin(n)[:1:-1], 2)
doc = etree.parse(url)
optimize.fmin(func, x0=[y_estimate, z_estimate], args=data)
result = (x.sum() ** 2 - x.dot(x)) / 2
session.query(Workflow).get(id)
filtered_output.write(line)
psutil.cpu_times()
msglist.append(hextotal[start:start + 4096])
data.write(c + n)
b1.insert(END, item)
x.append((i, j))
dict(zip(fields, row))
True
test[:, ([0])]
y = np.array([-1, 1, 1, 1, -1, 1])
controller2.py
controllerapi.py
utilities.py
extfoo.py
array = np.ones((n, n))
words = {line.strip() for line in file_a}
Cmd.cmd.__func__()
Base.metadata.create_all(engine)
data = pd.concat([data, stock_data], axis=1)
self.window.fullscreen()
data = cursor.fetchone()[0]
math.degrees(math.atan(1.18))
Category.objects.get(pk=2).get_descendants(include_self=True)
client.close()
self.root.mainloop()
cv.SetCaptureProperty(video2, cv.CV_CAP_PROP_FRAME_WIDTH, 800)
print(open(my_module.__file__).read())
L.pop(i)
self.image.show()
text = Tkinter.Text()
fin.close()
df.loc[g.groups[1]]
[(x[0:index] + x[index + 1:]) for x in L]
s.groupby(s.index).first()
[x for x in seq if not (x in seen or seen_add(x))]
dt.replace(microsecond=int(parts[1]))
plt.gca().add_artist(mynewline)
sys.maxunicode
new_list = [foo for foo in foos if foo.location == 2]
fig, ax = plt.subplots(figsize=(8, 8))
f.seek(0, 0)
dict_of_lists[key].append(val)
[next(generator) for _ in range(n)]
ax.set_xticks(np.linspace(0, 2 * np.pi, 5))
ax1.xaxis.set_major_locator(xloc)
x.append(sublist[0])
L4 = list(item for item in L1 if item not in unwanted)
time.sleep(duration)
foo.module_method()
os.path.normpath(path1) in (os.path.normpath(p) for p in list_of_paths)
list(chain.from_iterable(zip(a, reversed(a))))[:len(a)]
np.finfo(np.float).eps
self.finish()
arr[(arr[:, (0)] >= xmin) & (arr[:, (0)] <= xmax)]
Thaidump(text)
plt.show()
a[0] = np.nan
data = [(b[1], p, b[0], b[2]) for p, b in list(rays_starters.items())]
plt.show()
image.show()
print(term.move(term.height - 1, 0))
a[i1, i2, i]
msvcrt.get_osfhandle(a.fileno())
pd.Series(np.nanmean(val.reshape(-1, k), axis=1))
msg.send()
os.makedirs(final_path)
time.sleep(0.01)
math.factorial(n)
[(i - set.union(*[j for j in allsets if j != i])) for i in allsets]
text.pack()
dict((k.lower(), v) for k, v in d.items())
df.reset_index(inplace=True)
s.groupby(idx).mean()
module.myif.__init__(self)
cur.execute(query, parameters)
set(tuple1).issubset(tuple2)
sum(itervalues(d))
instance = YourModel(name=value, image=self.get_image_file())
value = np.ctypeslib.as_array(value).tolist()
r.json()
tree = scipy.spatial.cKDTree(array_of_coordinates)
abs(a - b) <= max(rel_tol * max(abs(a), abs(b)), abs_tol)
dict(d2, **d1)
df2 = pd.DataFrame(index=df1.index.copy())
image = Image.open(file)
df = df[df.line_race != 0]
np.unravel_index(np.ravel_multi_index((10, 1, 2), arr1.shape), arr2.shape)
time.sleep(10)
all(not element for element in data)
min([s for s in lst if isinstance(s, str)])
root = tk.Tk()
id = Column(Integer, primary_key=True)
plt.show()
arr = np.array(arr_ip, dtype=dtyp)
[[[1]][[2]]]
logger.setLevel(logging.DEBUG)
sys.exit(app.exec_())
df.sum()
signal.signal(signal.SIGINT, handler)
a = np.empty((15,))
mymodel.objects.filter(pk=a[i]).update(attr=i)
[i for i, v in enumerate(a) if v in b_set]
print(name.title())
df_both.swaplevel(0, 1).sort_index().swaplevel(0, 1)
x = list(y)
self.pot.temperatureRaisedSignal.connect(self.temperatureWarning)
plt.show()
{{post.text | markdown}}
self.user.username
self.get_solr_results()
df
widget.setWindowFlags(QtCore.Qt.Widget)
print(et.tostring(tree))
plt.show()
button.show()
a2.append(float(s))
[0][0][2]
repo.push()
lexobj.writetab(lextab, outputdir)
(lst[i] for i in indices)
resolve(request.path).app_name
b[a] = 10
f.close()
len([x for x in a_list if x[0] == 1]) > 0
fig.subplots_adjust(bottom=0.2)
ax2.set_xticklabels(new_labels)
plt.imshow(Z)
datetime.utcfromtimestamp(timestamp1)
plt.show()
args = parser.parse_args(sys.argv[1:])
(lambda : 1) == (lambda : 1)
g = nx.Graph()
foo.x
print(sum(i * i for i in l))
print(max(b - a for a, b in pairwise(values)))
plt.legend()
w.show_all()
pcap_lookupnet(dev, ctypes.byref(mask), ctypes.byref(net), errbuf)
server.serve_forever()
setattr(cls, attr_name, prop)
list(nx.weakly_connected_component_subgraphs(G))
ax0b.plot(x, y)
ax0c.plot(x, y)
mysignal.connect_via(app)(print_howdy)
fig = plt.figure()
app.run()
root = Tk()
logging.Handler.__init__(self)
serializer = NewModelSerializer(data=request.data, context=context)
win.show_all()
zip(*elements)
any(1 in d for d in lod)
urlparse(request.url).query
{(1, 1): something}
post_save.connect(create_user_profile, sender=User)
process.kill()
print(y.shape)
raise TypeError(node)
func(*args, **kw)
print(aiff_file.nframes / float(aiff_file.samplerate))
m.toarray()
d.setdefault(y, []).append(x)
pd.DataFrame({n: c.apply(lambda x: x.get(n, 0)) for n in wordlist})
session = requests.Session()
fid.close()
[0] * A + [1] * B
binascii.hexlify(bytearray(array_alpha))
wavf.write(out_wav, fs, out_data)
print(p.stdout.read())
[(car.pop(0) if item else a.pop(0)) for item in lyst]
dic[g][y] = df[(df[Gender] == g) & (df[Year] == y)]
validate(yaml.load(bad_instance), yaml.load(schema))
new_list = [v for v in a if v not in b]
app.start()
form = PostForm(obj=post)
sizer.Add(self.canvas, 1, wx.EXPAND)
np.put(out, np.ravel_multi_index(idx.T, dims), vals)
cb = plt.colorbar(sc, ax=ax1, aspect=10, format=Myfmt())
gs1.update(wspace=0.025, hspace=0.05)
yylex()
admin.site.register(User, UserProfileAdmin)
row = cursor.fetchmany(10)
root.mainloop()
sorted(a) == sorted(b)
math.floor(math.log(n, 2)) + 1
f.write(sio.getvalue())
num_fatals += 1
server.run()
blogpost.tags[:] = new_tags
writer.writerow(row)
isinstance(amodule, __builtins__.__class__)
HTMLParser.HTMLParser.__init__(self)
ax = fig.add_subplot(111, polar=True)
QtGui.QFrame.__init__(self, parent)
print(m.group(1).rstrip())
gtk.main()
cv2.__version__
qs.filter(map(operators.or_, [Q(k=v) for k, v in list(request.GET.items())]))
L[idx].append(item)
cashflow[-1] += 100
ax.get_yaxis().set_minor_locator(mpl.ticker.AutoMinorLocator())
runner.run()
np.mean([0, 0, 1])
file.seek(0)
urllib.request.urlretrieve(url, filename)
print((word, count))
s1.reset_index()
b = a[:]
list(unique_everseen(lst, key=len))
isinstance(obj, collections.Callable)
df.columns = new_cols
time.sleep(1)
time.sleep(1000)
self.send_response(200)
root.columnconfigure((0, 2), weight=1)
element = max(myset)
[x for x in myTuple if foo(1, x, 4)]
[(elem + func()) for elem in myList]
d[k].append(v)
results = sorted(list(results_dict.items()), key=lambda x: x[1])
db.session.add(post)
self.y = [self.x for i in range(1)]
ax.plot_surface(X, Y, Z)
nodes = [node() for _ in range(100)]
popt, pcov = curve_fit(lambda x, a: func(x, a, b), x1, x2)
User.objects.get(id=uid)
plt.gcf().subplots_adjust(hspace=0.5, wspace=0.5)
plt.show()
msvcrt.setmode(sys.stdin.fileno(), os.O_BINARY)
cmp(A[adiff], b[bdiff])
network.draw()
np.sqrt((w * q * q).sum())
np.allclose(np.dot(A, B), A * sparse_B)
threading.Thread.__init__(self)
[[df.columns[j] for i, j in grp] for k, grp in groups]
foo(*x, **y)
time.sleep(1)
session.commit()
FOUT.close()
root.mainloop()
ax1 = fig.add_subplot(111)
ax.minorticks_off()
df1.index & df2.index
print(x.apply(lambda y: [a for a in y if pd.notnull(a)]))
[(sum([(i * i) for i in vec]) ** 0.5) for vec in x]
proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, env=initial)
(value for key, value in sorted(dictobj.items()))
list.__setitem__(self, index, value)
d.sort(key=itemgetter(0))
pd.DataFrame({n: c.apply(lambda x: x[n]) for n in wordlist})
n = n + 1 / 10 ** (len(repr(n)) - 2)
[x for x, y in groupby(L) if sum(1 for i in y) < 2]
b[1:] = b[1:] - b[:-1]
driver = webdriver.Chrome(chrome_options=opts)
df
ax.xaxis.set_visible(False)
np.delete(x, 1, 1)
conn.close()
pylab.show()
driver.get(url)
a = np.hstack((a, b))
d = {k: list(v) for k, v in groupby(tags, key=lambda x: x[0])}
-tox
fsizer.Add(self.filtr, 1, wx.EXPAND)
tfile.seek(0)
print(chr(i))
parser = argparse.ArgumentParser()
os.dup2(w, sys.stderr.fileno())
[numpy.all(-2), numpy.all(-1), numpy.all(0), numpy.all(1), numpy.all(2)]
sorted(population, key=keyfun)
td_series.astype(pd.Timedelta).apply(lambda l: l.days)
GPIO.output(4, True)
formset.save_m2m()
soup = BeautifulSoup(page)
pattern = re.compile(re.escape(motif))
id(df._data.blocks[0].values)
writer.writerow(row)
df.loc[df.isin([1, 2]).any(1)]
os.path.join(base_path, relative_path)
array[mask] = 255
sftp.close()
print(temp_df.apply(lambda x: x - temp_arr[x.index], axis=1))
[k for k, v in list(d1.items()) if v == m][0]
cmds.ls(sl=1, fl=1)
pygame.draw.circle(surf2, (200, 0, 0, 100), (100, 100), 100)
writer = csv.writer(f)
exit()
ax1 = fig.add_subplot(111)
s = s[117:]
b.extend(map(ord, s))
text = nltk.Text(tokens)
run()
subprocess.call([PLAYERPATH, FILEPATH])
yaml.add_representer(OrderedDict, represent_ordereddict)
ax.imshow(im)
[(float(p[1] + p[2]) / 2) for p in PlayerList]
main()
print(br.response().read())
self.create(request, *args, **kwargs)
all(starmap(lt, zip(a, b)))
signal.pause()
y = list(x)
print([(y - x) for x, y in l])
df = df[colnames]
results = [do_smth(slurp_file(f)) for f in filenames]
print((k, v))
plt.colorbar(pc, cax=axes)
math.isnan(a)
df.iloc[sort_slice]
Base.metadata.create_all(engine, checkfirst=True)
plt.plot([0, 1])
sys.stdout.close()
print(zip(*(zip(itertools.repeat(ls[0]), ls[1:]) for ls in data)))
ax.scatter(xs, ys, zs)
self.response.out.write(xml)
print(list(d.keys()))
formset.save()
neuron.draw()
self.textEdit.setPlainText(mytext)
image = Image.open(io.BytesIO(bytes))
df.rdd.map(lambda r: r.zip_code).collect()
server.quit()
time.sleep(1)
tf.div(x, y)
print([data[id == i].max() for i, _ in groupby(id)])
fh.close()
sys.path.append(path)
df.iloc[:, 1:]
f.write(line)
a.sort(key=len)
soup = BeautifulSoup(data)
time = datetime.strptime(time, DATETIME_FORMAT)
self.ax.figure.canvas.draw()
f.close()
window.add(vbox)
s = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_IP)
plt.pause(0.001)
func(*args, **kwargs)
df.comments.dropna()
img = f.read()
groups.sortlevel([0, 2], sort_remaining=False)
pool = Pool(processes=2)
warnings.resetwarnings()
imshow(skeleton, cmap=cm.Greys_r)
q = Post.query.options(db.joinedload(Post.tags)).all()
yacc.errok()
float(sum(lst[len(lst) / 2 - 1:len(lst) / 2 + 1])) / 2.0
s[s.index.dayofweek < 5]
df.applymap(lambda x: (0, 0) if x is np.nan else x)
self.mthread.start()
print(zip(*lists))
browser.get(url)
print(soup.html.string)
cursor = conn.cursor()
timestamp = (aware - datetime(1970, 1, 1, tzinfo=pytz.utc)).total_seconds()
plt.tight_layout()
time.sleep(1)
eyear1.grid(row=1, column=1)
layout.removeWidget(self.widget_name)
mc.__dict__
draw = ImageDraw.Draw(im)
ax.patch.set_alpha(0.5)
self.__getattribute__(name)
df
df2
plt.figure()
print(list(words))
[1][2][0]
plt.show()
a = numpy.array(a)
pylab.show()
bin(int(my_hexdata, scale))[2:].zfill(num_of_bits)
print(repr(data))
s = chr(i)
plt.ylim((-5, 5))
func(*args, **kwargs)
f()
locale.setlocale(locale.LC_ALL, lang)
(counts == 1).all(axis=1)
fig.autofmt_xdate()
df = pd.DataFrame.from_dict(data)
f()
plt.show()
ax.set_ylim(0, m.shape[0])
a.shape
session.add(inst)
Representative.objects.create(**dict(zip(fields, row)))
turtle.forward(100)
a.tolist()
self.sprockets.add(spr)
print(ord(s[0]))
data.get(num) or data[min(list(data.keys()), key=lambda k: abs(k - num))]
model.fit(X, y)
table.cols.key.createIndex()
p.terminate()
print(char, char.isalpha())
printRecurrence()
ax.axis((x1, x2, y1 - 1, y2 + 1))
square(double(Maybe(5)))
driver = webdriver.Firefox(firefox_binary=binary)
ax.yaxis.set_major_formatter(formatter)
dict(enumerate(grouper(numbers), 1))
x = [[] for i in range(4)]
f = open(fd, closefd=True)
bar.name
[id(v) for v in list(d.values())]
problems
[1][1][2]
[0][1][1]
mydict[index] += 1
moobar()
print(json.dumps(data, indent=4))
df[g.cumcount() == n - 1]
dict((k, dict(v)) for k, v in list(r.items()))
plt.show()
[word for words in lst for word in words.split()]
ax.set_rlim([0, 5])
session.add(feed)
User.name.property.columns[0].type.length
r = requests.get(url, params=payload_str)
i += 1
list(filter(my_filter, my_iterable))
image.save(savepath)
print(pd.concat([df, pd.DataFrame(D, index=df.index)], axis=1))
np.random.rand(5) < 0.8
a.tolist()
chain.apply_async()
fd.close()
print(f.getvalue())
t.start()
ent5.grid(row=4, column=1)
data = {}
1.0 - scipy.stats.hypergeom.pmf(0, N, M, Q)
print(r.json())
[(i, mylist.count(i)) for i in set(mylist)]
__init__.py
print(func())
lst[:] = (v for v in lst if pred(v))
time.sleep(0.5)
x = list(itertools.islice(list(d.items()), 0, 4))
proc.stdout.close()
unittest.main()
image[(mask[:] == 0), ...] = chex[(mask[:] == 0), ...]
wr.writerow(list1)
[subword for word in list for subword in word.split()]
self.thisptr.myBMethod(dereference(a.thisptr), getAMethod())
m.group(1)
n = np.clip(n, minN, maxN)
ax.set_xticklabels(column_labels, minor=False)
spherical_dist(locations_1[0], locations_2[0])
raise NotImplementedError
f2.write(lines[i + 1])
plt.scatter(_x, _y, marker=_s, c=c)
L[1][:]
inset.xaxis.set_tick_params(labelsize=INSET_TICK_FONTSIZE)
tuple(x + y for x, y in zip(xs, ys))
(value[i:i + n] for i in range(0, len(value), n))
[i for v, i in sorted((v, i) for i, v in enumerate(x))]
ws = base.add_sheet(k.upper())
mycanvas.pack(fill=BOTH, expand=YES)
mylist.remove(min(mylist))
img.size
np.broadcast(x, y, z).shape
cols_to_use = df2.columns - df.columns
find_majority([1, 1, -1, -1, 0])
[ord(uc) for uc in udata]
plt.legend(handles, labels)
twitterDataFile.close()
self.panel.SetSizer(sizer)
np.concatenate([a[:k] for k in x])
time_list[np.arange(5, 7)]
lst.append(4)
b = a.copy()
print(line)
pprint(a)
get_proc_name()
l = list(map(lambda x: f(indices=x), itertools.product(x, y, z)))
print(checktype(i))
(x for x in full_list if x not in s)
sorted(l, key=lambda x_y: (-x_y[1], x_y[0]))
ax.set_ylim(0, 5)
answer[pk].append({sk: L[i][1]})
row = dict(zip(list(row.keys()), row))
[2, 0, 1, 0, 1, 0]
index_list.append(last_index)
csv_file.writerows(mylist)
self._reverse_mocks()
self.Bind(wx.EVT_RIGHT_UP, self.OnExit)
module_name.__file__
np.array(avgDists).argsort()[::-1][:n]
sys.stdout.write(line)
fig = plt.figure()
name_in_module()
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
Gtk.main()
self.ax.clear()
{k: (D[k] - v) for v, k in enumerate(albums_today)}
itertools.combinations()
max((len(v), v, k) for k, v in flows.items())[1:]
tz.fromutc(utc_time)
transaction.commit()
result.append(message)
fig, ax = plt.subplots()
print(hex_to_datetime(s), dt)
array[i:i + size] + array[:max(0, i + size - len(array))]
fcntl.flock(g, fcntl.LOCK_EX)
h.encode()
t = threading.Thread(target=get_url, args=(q, u))
self.send_response(200)
data = line.split()
print(2 * math.asin(1))
pak.show2()
value = a_lower[key.lower()]
signal.signal(signal.SIGINT, signal.SIG_DFL)
os.chdir(directory)
np.repeat(arr, rep.flat).reshape(2, -1)
data = {foo: foo_value, bar: bar_value}
[alist[i:i + sublen] for i in range(0, len(alist), sublen)]
self.name = name
print(frame.f_lineno)
sys.exit(1)
point.x, point.y
obj = MyModel.objects.create(val=1)
print(url)
print(m[0])
self.ShowModal()
list(data.keys())
process_url(a)
jsonFile.write(json.dumps(data))
self.assertEqual(yargs[0], yexpected)
my_list = list(my_set)
[8, 8, 8, 8, 8, 8, 8, 8, 8, 8]
self.main_app(environ, start_response)
pl.plot(X, Sine)
reactor.run()
ax1.plot(s1.index, s1)
p.communicate()
print(sys.builtin_module_names)
cur.execute(query, (limit1, limit2))
collatz(10)
data = sys.stdin.read()
self.assertEqual(xargs[0], xexpected)
plot.colorbar(im, cax=ax2)
ax.set_ylim(-0.5, 1.5)
driver.set_window_size(1120, 550)
app.logger.addHandler(file_handler)
jsonify(d)
self.redis = Redis()
L.sort()
isinstance({}, dict)
sin(x) * cos(x)
s.rstrip(punctuation)
plt.show()
sys.stdout.flush()
{{request.user.pretty_username}}
plt.show()
sp.sourceslist.save()
pd.DataFrame(X, columns=v.get_feature_names(), index=grouped.index)
fig = plt.figure()
os.system(mycommand)
worker.start()
cmp(x, y)
os.chmod(path, 511)
a[:] = [(x, mapping[x]) for x in b]
soup = BeautifulSoup(html)
map(list, a)
signal.signal(signal.SIGINT, signal_handler)
sys.exit(12)
min(filtered, key=lambda x: x.last - x.first)
[i for i, x in enumerate(a) if x in list_duplicates(a)]
tk.Tk.__init__(self, *args, **kwargs)
zip(MONTHS, MONTHS)
x = X.objects.get(id=x.id)
bisect.bisect_left(list_, item)
np.log(sample_df).diff()
some_list == sorted(some_list)
QApp().run()
e1.pack()
res = func(*args, **kwargs)
n = clamp(n, 7, 42)
print(random.choice(data))
os.chdir(random.choice([d for d in os.listdir(os.curdir) if os.path.isdir(d)]))
json.dumps(doc, sort_keys=True, indent=4, default=json_util.default)
subprocess.Popen(smart_cmd)
plt.xlim((-5, 5))
os.kill(2405, 0)
b[indices] = a[indices]
layout.addWidget(self.button)
print(map(lambda x, y: abs(x - y), l[1:] + l[:1], l))
plt.figure(figsize=(12, 8))
self.after(1000, self.countdown)
reshaped2.show()
my_list.sort()
app = Flask(__name__)
data = json.load(json_data)
screen.blit(temp_surf, (0, 0))
df.groupby(np.arange(len(df)) // 10)
self.app(environ, custom_start_response)
print(list(get_week(datetime.datetime.now().date())))
plt.setp(ax.get_xticklabels(), visible=False)
__init__.py
last_inner_append(x[-1], y)
self.driver.quit()
driver.get(url)
ax.xaxis.grid(True)
signal.signal(signal.SIGALRM, signal_handler)
L = [(x + [0]) for x in L]
colorbar()
time.sleep(0.1)
[2.0, 2.0017]
app.debug = True
client.put_file(dropbox_path, f)
sorted([(i, j) for j in range(10) for i in range(10) if j > i])
df.xs(1)
print(f.bar)
cursor = conn.cursor()
temp.append(data.tolist())
app.MainLoop()
func_to_call()
pylab.show()
list(filter(bool, l))
dt.microsecond
print(json.dumps(t, cls=MyEncoder))
self._numberButtons[i].clicked.connect(partial(self._number, i))
df2.apply(lambda x: df2.loc[~x.isin(df1[x.name]), x.name])
df = df.sort_index(axis=1)
False
logger.setLevel(logging.DEBUG)
plt.ylim(0, 8)
btn5.grid(row=4, column=0)
[r for r in x if not any(s in r for s in y)]
client.set_options(wsse=security)
user.get_all_permissions()
counterpart.sendall(data)
print(Photo.objects.filter(tags=t1).filter(tags=t2).query)
reactor.run()
plt.show()
(x - 1) // 10 if x > 0 else 0
event.wait()
A - A.multiply(BisBigger) + B.multiply(BisBigger)
id = Column(Integer, primary_key=True)
browser.quit()
{k1: d2[d1[k1]] for k1 in d1 if d1[k1] in d2}
db.session.commit()
[arr[max(0, idx - 1):idx + 2] for idx in range(0, len(arr), 2)]
np.where(x & x - 1 == 0)
local_dt.replace(microsecond=utc_dt.microsecond)
newgrid.append([x[i] for x in grid])
ax.set_yticks([])
enemy1 -= punch
func(*args, **kwargs)
date = datetuil.parser.parse(string, tzinfos=tzd).astimezone(pytz.utc)
sess.run([init_op])
engine.execute(createview)
ax0b.set_xticklabels([])
seen.add(item.lower())
float_array.fromstring(input_file.read())
app.MainLoop()
self.grid_rowconfigure(1, weight=1)
timer.timeout.connect(self.move_towards)
fig = plt.figure()
print(response.content)
df.columns = list(resoverall.keys())
reactor.run()
print(df2[[15, 16, 17, 18, 19, 8]])
texts[0].set_fontsize(4)
fig = plt.figure(figsize=(xinch, yinch))
ws.cell(row=i, column=j)
sys.exit(0)
ax.set_zlim(0, 5)
main()
[0, 0, 0, 0, 1, 1, 1]
p.wait()
client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
df[col] = df[col].sum()
ng.run()
lambda : [func() for _ in range(n)]
pattern = re.compile(pattern_string)
fout.close()
df[~df.From.str.contains(ignorere)]
sstd.on_changed(update)
__builtins__.set
plt.legend()
e.shape
random.choice(my_list)()
alist.append(string[i:j + 1])
all((x > 0) == (y > 0) for x, y in zip(l1, l2))
print(response.text)
ax = fig.add_subplot(111)
np.array(list(chain(*[np.arange(20).reshape(4, 5)[i::2] for i in range(2)])))
ax.xaxis.set_minor_locator(MultipleLocator(5))
dict.__setitem__(self, x, value)
ax.figure.show()
Tkinter.mainloop()
s.between(0, 1).any()
self.data[attr]
np.random.shuffle(arr[:, (i)])
X, Y = np.meshgrid(X, Y)
print(len(s), len(data), repr(data))
print(img.shape)
r.read()
pylab.ylim([0, 1000])
plt.plot(c[0], c[1], c[2])
list(intermix([1, 0, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 1, 2]))
proc.wait()
np.fill_diagonal(out, 1)
redirect(login_url)
frame = cv.QueryFrame(self.capture)
print(s.read())
msg = MIMEMultipart()
D = np.r_[np.c_[A, B], np.c_[B.T, C]]
print(list(itertools.islice(arith(10, 2), 100)))
bool(_digits.search(d))
L[item][0]
manual_wcwidth(data)
a = np.append(a, i)
response = json.loads(jsonResponse)
final_l.append((p[0], visit(p)))
tmp.append([X[i, j] for i in X])
sys.exit(app.exec_())
BabyDataSet = list(zip(names, births))
d = int(s[0:7], 2) + int(s[8]) / 2.0
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
foo()
pool = multiprocessing.Pool()
print(df.iloc[:, (0)].tolist())
ax.set_zlim(-100, 100)
ax = plt.gca()
a[i, j]
self.clip.disconnect(self.signal_id)
server.ehlo()
deleterow[1]
axes.set_ylim([ymin, ymax])
Y[(1), :]
time.sleep(0.1)
do_stuff()
x = x[1:]
quit()
time.sleep(1)
cur.execute(sql, params)
plt.show()
fig, ax = plt.subplots()
sw.pack(fill=tk.BOTH, expand=1)
l.extend(t + t2)
print(token.access_token)
dict((k, bigdict[k]) for k in wanted_keys if k in bigdict)
NameRank.sort(key=lambda x: int(x.split()[1]))
set(x) == set(y)
print(save_data.get())
{{i}}, {{j}}
cls.__new__()
list(OrderedDict.fromkeys(t).keys())
a, b = b, a + b
plt.show()
self.setCentralWidget(self.window)
random.choice(list(dictionary.values()))
lbl5.grid(row=4, column=0)
n * factorial(n - 1)
[_ for _ in itertools.compress(d, map(lambda x: x >= 4, a))]
df.stack().map(m).unstack()
d += timedelta(days=7)
conn.send(data)
a, b = 1, 1
c.mymethod2()
str(User.query.filter_by(role_id=user_role))
view.show()
ax.set_ylim(0, 10)
df.iloc[np.sort(np.concatenate([idx[~iszero], keep_these]))]
new_pressures.append(0)
x = ast.literal_eval(x)
ser.write(str(d))
table[1][2]
plt.xticks(list(range(len(x))), x)
func()
(myarray[i] for i in myindex)
collections.deque(itertools.islice(iterator, n), maxlen=0)
fig = plt.figure()
driver.set_window_size(1024, 768)
A.shape
[o.specific_attr for o in objects]
x = list(someiter)
[(a if a else b) for a in sequence]
df.reindex(ind & ind2)
test[2] = new_value
o4.method()
X.__setitem__(0, 2)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
plt.show()
dict((k, int(v)) for k, v in d.items())
names = self.__class__.__dict__
Ainv = np.zeros_like(A)
func(*args, **kwargs)
df2.apply(lambda x: df2.loc[~x.isin(df1.values.ravel()), x.name])
df
fig.set_size_inches(11.7, 8.27)
math.hypot(y[0] - x[0], y[1] - x[1])
next(decfa)
decimal.Decimal(1) / decimal.Decimal(7)
arr = (ctypes.c_int * len(pyarr))(*pyarr)
os.kill(self.pid, signal.SIGKILL)
Response(token, status=200)
plot_df.plot()
ftp.quit()
print([(k, v) for k, v in list(dupl.items()) if len(v) > 1])
json.dump(row, outfile)
f.seek(0)
j2 = sorted(i for i in j if i >= 5)
suffix_array.sort(key=lambda a: buffer(content, a))
sess = tf.InteractiveSession()
Py_Finalize()
sys.stdout.flush()
ao[:, 1:] += ai[:, :-1]
self.predictions_.append(classifier.predict_proba(X))
driver.switch_to.window(driver.window_handles[1])
print(list_of_dict)
result = [tuple([ai, bi] + ci) for ai, bi, ci in zip(a, b, c)]
main()
subprocess.call(command, shell=True)
ancestors_descendents.add(descendent)
par2.xaxis.set_ticklabels([i[0] for i in data])
proc.wait()
sys.exit(app.exec_())
ax.clear()
print([list(g) for g in group([], lambda x: x % 5 == 0)])
mark_safe(simplejson.dumps(data))
loader.load_module()
map(lambda x, y: x + y, itertools.repeat(x), y)
print([w for w in txt.split() if not w in s])
test.py
list(d.items())
literal_eval(s)
random.shuffle(items)
trace.main()
pylab.show()
xl.Workbooks.Close
df = df.T.stack().reset_index()
pd.concat([d1, df], axis=1)
Py_INCREF(interned)
df.dtypes
IOLoop.instance().start()
fig = plt.figure(figsize=(4, 10))
print(sys.argv)
time = time - datetime.timedelta(microseconds=time.microseconds)
[indicies[elements == i] for i in range(1, N)]
print(re.findall(p, test_str))
Sample.objects.filter(date__range=[startdate, enddate])
L[i] = sorted(L[i], key=operator.itemgetter(1, 2))
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
(sum(a) ** 2 - sum([(x ** 2) for x in a])) / 2
examplemod.do_stuff()
os.unlink(filename)
d = collections.defaultdict(dict)
session_list.delete()
[right for left, right in pairwise(a) if right[1] > left[1]]
fig = plt.figure()
plt.show()
db.session.add(c)
do_stuff()
line.set_ydata(r[:, (1)])
form = ExcludedDateForm(user=request.user)
globals()[funcname](**argsdict)
driver = webdriver.Firefox(p)
f.close()
my_list
(i for i, j in zip(seq, shift) if (i, j) != (x, x))
app.exec_()
a, b = b, a + b
sum(value for _, value in list(a.items()) if value > 0)
foo()
data = json.dumps(myobject.__dict__)
print(powercheck([1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1]))
ax.set_position(pos2)
id(lines[0]), id(ax.lines[0])
draw.ellipse((x1, y1, x2, y2), fill=background_color)
hasattr(obj, method_name) and callable(getattr(obj, method_name))
foo(2)
cursor = collection.find(spec={}, snapshot=True)
sorted(d, key=sorting)
df[new_columns]
data = myfile.read()
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj))
d.setdefault(t[0], {})[t[1]] = t[2]
handle.close()
writer = csv.writer(f)
out = np.asarray(np.bmat([[A, Z], [Z, B]]))
x[0] = x[0] + 1
run()
adder(10)
plt.show()
curses.noecho()
print(soup.prettify())
np.array(result)[::-1]
client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
sys.maxunicode
master.grid_rowconfigure(0, weight=0)
b.foo()
include(GenerateExportHeader)
db.session.commit()
[(arg + 1) for arg in args]
d = [list(map(int, x)) for x in DATA]
hi()
mylist.sort(key=lambda x: x[1])
TaskBase.__call__(self, *args, **kwargs)
self.assertTrue(mock.called)
t.start()
foo.name
func(*args, **kwargs)
admin.site.register(User, CustomUserAdmin)
parser = argparse.ArgumentParser()
[lst[i::n] for i in range(n)]
admin.site.register(CherryTomato, TomatoAdmin)
self.session.execute(count_query).scalar()
user2 = forms.ChoiceField(choices=choices)
ActionChains(driver).move_to_element(element).perform()
json.dumps(convert(d))
sys.exit()
writer.writerow(row)
message.save()
self.grid_rowconfigure(0, weight=1)
i, j = np.indices(a.shape)
time.sleep(0.5)
fig = plt.figure()
{k: add_element(v) for k, v in list(dicty.items())}
json.loads(x)
self.sock = ssl.wrap_socket(sock, self.key_file, self.cert_file)
time.sleep(1)
globals()
func.__code__.co_consts
float(element)
x.isoformat()
y.compute()
tt = np.linspace(0, 20, 201)
sys.exit(1)
fout.close()
foo = set(range(0, 4))
__init__.py
[x[0] for x in G]
list(s) == sorted(s)
sum(ord(c) << i * 8 for i, c in enumerate(mystr))
list(roundrobin(l1, l2))
a, b = b, a + b
res = urllib.request.urlopen(req)
ax.add_line(line_1)
spstereo.scatter(x, y)
n11.add(n111)
datetime.timedelta(seconds=seconds)
str(a)
x = x + a + b + c
im.show()
s1.reset_index(inplace=True, drop=True)
self.canvas.update_idletasks()
os.remove(filename)
print(me.toJSON())
loggerCent.setLevel(logging.DEBUG)
new_list = [(a + b) for a, b in zip(a_list, b_list)]
type([])
all(c in gram.lower() for c in string.ascii_lowercase)
module.workflow_set.filter(trigger_roles__in=[self.role.id], allowed=True)
form.rate.queryset = Rate.objects.filter(company_id=the_company.id)
pool = multiprocessing.Pool(4)
sys.exit(1)
cls.recalc_mro()
os.kill(os.getppid(), 0)
(data.T / vector).T
{w: counts[w] for w in word_list}
new = map(int, old)
d2 = {k: (v * 0.5) for k, v in list(d.items())}
(A.stack(0) << np.arange(10)).sum(1).unstack()
plt.show()
print({k: (x.get(k, 0) + y.get(k, 0)) for k in set(x) | set(y)})
ax.figure.canvas.draw()
key[:2].upper() + key[2:]
deletelist[index]
cur.execute(query, (b,))
self.button.pack(padx=10, pady=10)
m = re.search(pat, t)
persons = Person.objects.all().order_by(birthday, anniversary)
r.status_code
a.index(4)
dff[[c for c in dff if dff[c].isnull().sum() < 2]]
dropped_copies = [(lambda j: (x[j] for x in copies[j]))(i) for i in range(2)]
print([value for value in x if not math.isnan(value)])
otest.sort(key=lambda x: int(x))
df.tail(5)
print(text[i])
s == len(s) * s[0]
sys.getsizeof(Bar.__dict__)
plt.show()
plt.plot(data.index, data.amount)
[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
fig.subplots_adjust(left=0.25, bottom=0.25)
json.loads(obj)
query = users.select().order_by(-users.c.id.desc()).limit(5)
bucket.configure_lifecycle(lifecycle_config)
x.digits(10, 0, -1, 1)
np.array_equal(a, b)
self.temperatureRaisedSignal.emit()
raise web.notfound()
df.head()
self._task.cancel()
a[:, (idx)]
logger.addHandler(file_handler)
out = [x for x in a if x in b and x in c]
plt.xlim([0, len(data)])
dropped_copies = [make_gen(i) for i in range(2)]
main()
f(**{str(k): v for k, v in list(kwargs.items())})
ax.plot_surface(grid_x, grid_y, grid_z, cmap=plt.cm.Spectral)
reactor.run()
print(files[0])
print(json.dumps(output, indent=4))
main()
req.read()
df.loc[:, (msk)]
[y for x in data for y in x]
logger.setFormatter(logFormatter)
plt.subplot(1, 2, 2)
np.ma.array([[1, 0, 0, 1], [1, 0, 1, 0]], mask=[[0, 0, 0, 1], [1, 1, 0, 1]])
enumerate(list(range(2000, 2005)), 1)
self.transport.write(data)
s.update(list(fus_s.keys()))
browser = webdriver.Firefox()
print(cmp(memoryview(test1), memoryview(test2)))
signal.signal(signal.SIGQUIT, dumpstacks)
print([(100 * (b - a) / a) for a, b in zip(prices[::1], prices[1::1])])
output = urllib.request.urlopen(url).read()
[mm_fib(i) for i in range(20)]
fig.canvas.draw_idle()
data.append([w.getparams(), w.readframes(w.getnframes())])
app = flask.Flask(__name__)
request.user.get_myuser().pretty_username()
[i for n, i in enumerate(d) if i not in d[n + 1:]]
new_dict = {k: v for k, v in my_dict.items() if v >= threshold_value}
ax.scatter(a.real, a.imag)
self.previewImage.show()
print(arr_list)
df = pd.DataFrame()
array([1, 2, 4, 5, 6, 7, 8])
regr.fit(chntrain, austrain)
print(response.read())
tk.Tk.__init__(self)
p.start()
container.grid_columnconfigure(0, weight=1)
ax.set_xticks(np.arange(len(df.columns)) + 0.5)
print(df)
df.fillna(1, inplace=1)
list(product())
imshow(gray2, cmap=cm.gray, alpha=0.5)
imshow(gray2b, cmap=cm.gray, alpha=0.5)
db.init_app(app)
app = Bottle()
string1.join(string2)
fileObj.close()
loader.construct_yaml_str(node)
decorator
foo(params[0], params[1])
fileinput.close()
sys.stdin.close()
background_label.place(x=0, y=0, relwidth=1, relheight=1)
layout.addWidget(self.label)
[0, 1, 0, 2, 1, 0]
print((i, os.path.join(dir, file)))
python - -version
plt.figure()
sys.exit(2)
deletesys.modules[name]
a = [a]
worksheetObject.portrait = False
d = dict(t for t in zip(m[::2], m[1::2]))
{c.name}
app.mainloop()
plt.plot(signal)
s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
plt.scatter(R, P, s=150, color=c, zorder=2)
l2.append([x[1] for x in zip(pattern, facs) if not x[0]])
print(key[index].reshape(a.shape))
args = parser.parse_args()
myData.dtype.names
socket.close()
MyModel.objects.all().delete()
data = [[([0] * h) for _ in range(w)] for _ in range(d)]
traceback.print_exc()
min(timeit.repeat(lambda : {k: v for d in (x, y) for k, v in list(d.items())}))
mainloop()
deleteself.__dict__[key]
max(max(l_one), max(l_two))
any(child.contains(other_node) for child in self.children)
regressor.fit(X, y)
print(x)
plt.show()
__init__.py
do_your_thing_with(item)
self.close()
thread.start()
im.show()
map(join, zip(s, drop(s, 1)))
newlist += mylist[i:i + 22]
[i for i in userInput if i in wordsTask]
f.close()
print(d[1] + f.split(d)[1])
instance.__init__(cls, *args, **kw)
pd.concat([df, df.shift(-1)], axis=1, keys=[0, 1]).dropna()
admin.site.register(Example, MyAdmin)
list(itertools.product(l1, l2))
x[np.argmin(abs(f2 - f1))]
json_data = json.load(StringIO(json_str))
a = map(float_or_string, mylist)
data = dict((key, request.form.getlist(key)) for key in list(request.form.keys()))
f.close()
fig.show()
((1 + sqrt(5)) ** n - (1 - sqrt(5)) ** n) / (2 ** n * sqrt(5))
[(next(it), next(it1)) for _ in range(10)]
os.makedirs(expanded)
print(key, value)
str(d)
browser.get(googleURL)
self.app.run()
out.close()
help(parrot)
sys.stderr.close()
ax.axis([-1, 10, -1, 10])
ax.transData.transform([(0, 1), (1, 0)]) - ax.transData.transform((0, 0))
zf.close()
setup.py
num2words(10000000000000000000000000)
time.sleep(10)
root.mainloop()
self.__dict__.update(dictionary)
print(Board([1, 2]))
fig, ax = plt.subplots()
pyglet.app.run()
cache.update()
print(instance.Variable)
root = tree.getroot()
print(root.winfo_height())
tree = ET.fromstring(xmlstr)
m / m.norm(1, axis=1).reshape((m.shape[0], 1))
l.extend(list(range(1, n + 1)))
reactor.run()
print(list(roundrobin(*l)))
np.partition(x, -10)[-10:]
smtp.close()
timestamp.sort(reverse=True)
print(find_eulerian_tour(graph))
df1 = df1.fillna(0)
time.sleep(1)
[list(g) for k, g in groupby(inp, key=lambda i, j=count(): i - next(j))]
plt.show()
reactor.run()
myTreeView.setEditTriggers(QAbstractItemView.NoEditTriggers)
plt.show()
base.rhyme()
do_something_special()
array([1, 1])
workbook.close()
webdriver.ActionChains(driver).move_to_element(el).click(el).perform()
outputfile.close()
[k for k, v in list(mydict.items()) if c[v] > 1]
layout.addWidget(self.connectButton)
str1_list.sort()
selenium_logger.setLevel(logging.WARNING)
plt.hold(True)
a[ainb]
df.isnull().sum().sum()
print(time.time() - start)
offset += datetime.timedelta(days=1)
pygame.draw.circle(screen, (0, 0, 0), (250, 250), 125)
i / int(pow(10, l - m)) % int(pow(10, m - n + 1))
rs = urllib.request.urlopen(req.to_url())
[x[start:end] for start, end in slices if end - start > 1]
td.findAll(text=True)
r = requests.delete(URL_delete, data=json.dumps(mydata))
print(bool([]))
list(intermix([1, 0, 1, 1, 2, 1, 0, 1, 1, 1, 1, 1, 1, 2]))
sys.stdin.close()
t[0][0]
any(i in array2 for i in array1)
fig, ax = plt.subplots()
traceback.print_exc(file=sys.stdout)
self.openBtn.clicked.connect(self.openClicked)
[x[1] for x in Counter(n).most_common() if x[0] > 1]
y = arr[29].sum()
df[1].plot(ax=axes[0, 1])
listbox.config(width=0)
TestApp().run()
y[(1), :, (2), :]
simplejson.load(f)
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(jar))
pylab.show()
axborder.set_xlim(0, binimg.shape[1] - 1)
any(np.array_equal(b, x) for x in my_list)
ax.set_ylim(-20, 100)
admin.site.register(CMSMediaDocument)
cj = cookielib.LWPCookieJar()
sys.exit(0)
pygame.image.save(Surface, filename)
plt.pause(0.0001)
lst = [x for x, in mysql_rows]
do_something()
self.text.configure(yscrollcommand=self.vsb.set)
sm.OLS(df[ycol], df[xcols]).fit().predict()
response = urllib.request.urlopen(url).read()
time.sleep(0.1)
OrderedDict.__setitem__(self, key, value)
u.save()
any(e[1] == search for e in data)
F(n - 1) + F(n - 2)
[day for day in range(len(day_list)) if day_list[day] == inp][0]
Py_DECREF(arr)
logging.StreamHandler.__init__(self)
unique[maxsort], counts[maxsort]
df_out = pd.DataFrame(out, index=df_index)
list(itertools.dropwhile(lambda x: x == r[-1], reversed(r)))[::-1] + r[-1:]
somelist = [i for j, i in enumerate(somelist) if j not in remove_indices]
writer.close()
self.server.serve_forever()
fig.subplots_adjust(hspace=0.5, wspace=0.001)
plt.show()
cPickle.loads(_)
l.append((floar(row[0]), float(row[1])))
main()
sorted_list == list(range(sorted_list[0], sorted_list[-1] + 1))
y = [0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0]
dict(a)
app = Flask(__name__)
d = collections.defaultdict(int)
net.build()
plt.scatter(x, y)
nmf_model.fit(A)
plt.tight_layout()
browser.set_handle_robots(False)
libc.cprogram(wts, res, kks, pointer(n), ex)
print([(a, b, z[a]) for a, b in l])
server.listen(5)
res.append(copy.deepcopy(l))
gb.apply(lambda x: dict(zip(*x))).unstack()
[97, 98, 114, 97, 107, 97]
pylab.show()
f.close()
lst.append(lambda x, z=i: f(x, z))
plt.show()
print(list(chain(*listOfTuples)))
print((x, y))
[ord(b) for b in bytestr]
s.set_xticklabels(group_labels)
{i: str(i) for i in range(5)}
unittest.main()
self.emitter.start()
followers_df.index = list(range(20))
blocklist.append(line)
plt.scatter(t, x, c=y)
root.mainloop()
writer = csv.writer(out_file)
layout.addWidget(self.label)
reversed_arr = arr[::-1]
simplejson.dumps(object())
QObject.__init__(self)
hist = np.histogram(img.flatten(), 256, [0, 256])[0]
self.left.extend(self.right[0:x])
print(list(d))
count.most_common(2)
p1.join()
process = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True)
sorted(iter(x), key=lambda k: random.random())
glTranslatef(100, 100)
legobj.set_linewidth(2.0)
self.response.set_status(401)
items.append(self.listWidget.item(index))
plt.show()
threading.Thread.__init__(self)
signal.signal(signum, sighandler)
df[0][0]
PyMODINIT_FUNC
numpy.where(a != 0, 1, 0).sum()
x.sort()
arr = numpy.array(((2, 2), (2, -2)))
f()
next(x for x in range(10) if x == 11)
print(repr(object))
sorted(list(mydict.items()), key=itemgetter(1, 0))
res.fillna(0)
np.diff(a)
output = defaultdict(lambda : defaultdict(int))
print(bar.__name__)
image.set_from_pixbuf(pixbuf)
self.img.set_from_file(fname)
app.setStyleSheet(stylesheet)
server.NOT_DONE_YET
b = [(sl + [0] * (len(max(a, key=len)) - len(sl))) for sl in a]
[t[i:i + n] for i in range(0, len(t), n)]
json.dump(data, f)
unittest.main(verbosity=2)
df.C.plot(ax=plt.gca())
print(line)
submodule2.py
np.linspace(0, 1, 10, endpoint=False)
size = fields.IntegerRangeField(list(range(1, 50)))
map(ord, os.urandom(10))
logger = logging.getLogger()
do_something_with(name)
x.sort()
urllib.request.install_opener(opener)
pd.read_csv(io.StringIO(t), header=False)
print(list(iterable))
widget.lift()
user.save()
((x - a) / (b - a)).clip(0, 1)
self.fitness = 2 * self.i
plt.gcf().add_subplot(422)
self.render_to_response(self.get_context_data(form=form))
stdin.flush()
ax.bar(x, y, width=10)
form = ContactForm(request.POST)
myscript.py
tornado.ioloop.IOLoop.instance().start()
time.tzset()
float(output_string)
list_2 = [item for item in list_2 if f(item)]
x = pickle.load(f)
x = foo[index]
a = np.arange(729).reshape((9, 9, 9))
browserify()
A[i, j] += C[j, k]
hash.update(line)
dists = np.vstack(([x_dists.T], [y_dists.T])).T
par1.set_ylim(0, 4)
sorted(l1)
[day for day in range(len(day_list)) if day_list[day] == inp][0]
stats.weibull_min.fit(data, floc=0)
sorted((k, ordered(v)) for k, v in list(obj.items()))
float(value)
self.matplotlibWidget.canvas.draw()
os._exit(1)
cv2.destroyAllWindows()
sys.exit(1)
msg.attach(part1)
f.tell() == os.fstat(f.fileno()).st_size
[item[0] for item in tl]
p.start()
app.run()
data = np.random.uniform(-1, 1, 44100)
plt.show()
print(value[:min(len(value), size)].ljust(size))
list(remove_reversed_duplicates(a))
self.ui_web_view.installEventFilter(self)
p.join()
time.sleep(0.1)
clf.fit(X, y)
a.setLevel(logging.DEBUG)
deletearray[0]
pd.get_dummies(df.apply(tuple, 1)).groupby(level=0).sum()
app.run()
gtk.main_quit()
self.finish()
main()
{{mydocimage.property.date_added}}
plt.plot(x2, my_curve2)
foo.bar()
a()
all(x > y for x, y in zip(L, L[1:]))
QtGui.QWidget.__init__(self, parent)
percentages.append(temp)
pyplot.show()
l.append(i)
self.mainframe.columnconfigure(0, weight=1)
QtGui.QDialog.__init__(self)
fig.subplots_adjust(wspace=0)
self.socket.bind((server_ip, server_port))
self.common1()
results[i].append(benchmark(i))
h.append({k: d.get(k) for k in get_keys})
sorter[np.searchsorted(b, a, sorter=sorter)]
grid_1.AddMany(wx.StaticText(self.panel, label=str(i)) for i in range(24))
x[row_idx.reshape(-1, 1), col_idx]
sys.stdout.flush()
f(Foo(1))
print(next(zip(*s)))
print(row.column_name)
l.append([x, y])
a = A()
df.loc[all_days]
dates.sort()
self.filelist.append(zinfo)
np.equal(a, tgt).all(1).any()
length = sum(1 for x in clusterList)
ax.set_xticklabels(df.columns, rotation=90, size=15)
d = tf.constant([[1.0, 1.0], [0.0, 1.0]])
self.rect.set_width(self.x1 - self.x0)
lines = [line for line in infile][:N]
bananaxxxxxxxxxgestrawberryxxxxxxxar
df.hist(layout=(1, 2))
df = pd.concat([df.ix[:, :5], x], axis=1)
rconsole.spawn_server()
pycurl_connect.setopt(pycurl.URL, your_url)
cv2.waitKey()
item.setCheckState(QtCore.Qt.Unchecked)
f.seek(0)
ax.set_axis_off()
print(df.loc[:, (mask)])
time.sleep(1)
scored.sort()
d = dict(urlparse.parse_qsl(qs))
print(word)
gtk.main()
sorted(set(chain.from_iterable(iter(content.values()))))
s = ax.scatter(X, Y, c=C)
self.button.clicked.connect(self.createTab)
process.wait()
print((k, v))
np.where(x < 0, -x / x.min(axis=0), x / x.max(axis=0))
tuple([x for sublist in base_lists for x in sublist])
print(widget.GetName())
label.pack()
sum(range(a[0], a[-1] + 1)) - sum(a)
b = [ord(x) for x in s]
driver = webdriver.Chrome()
[group for group in groups if a.isdisjoint(group)]
print(json.dumps([1, a, b]))
a = csc_matrix([[1, 0, 0, 0], [0, 0, 10, 11], [0, 0, 0, 99]])
t = tuple(s)
os.system(cmd)
numpy.linalg.norm(a - b, ord=1)
process.kill()
os.makedirs(directory_name)
[idx for idx, el in enumerate(foo) if np.array_equal(el, arr)]
sys.exit(1)
ax = plt.gca()
dict(c)
p.stdin.flush()
main()
[False] * 20
app = QtGui.QApplication(sys.argv)
time.gmtime(0)
self.Bind(wx.EVT_PAINT, self.on_paint)
thread.start()
x.g(2)
wx.Frame.__init__(self, parent, title=title, size=(200, 100))
m.drawcoastlines()
i += 1
print(objectify.dump(root))
browser.back()
map(lambda x: 0.4 if 7 <= x <= 22 else 0.2, hourOfDay)
json.dumps(object())
zip(A, B + B)
ax.set_xticks(np.arange(25))
sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPCNT, max_fails)
[id(x) for x in list(dic.values())]
w.readline()
str2_list.sort()
n += 1
fig = plt.figure()
time.sleep(10)
print(a.get())
print(np.percentile(map(int, i), 95))
foo(a, b)
((i, o) for i in l)
p.plot()
result.append(item)
plt.draw()
f(2)
lists.append(pickle.load(infile))
a * b
plt.show()
etree.LXML_VERSION
item.lower()
print(doc.text_content())
pd.concat(dfs, ignore_index=True)
proc.terminate()
b[static_indices[0], static_indices[1], static_indices[2]]
codeErr.close()
r = sum(compress(list_2, list_1))
self[key].add(value)
np.allclose([np.nan], [np.nan])
yy = np.concatenate((y, [0] * 10 * len(y)))
arr[:, (col)] /= abs(arr[:, (col)]).max()
lines.append(line)
writer.writeheader()
positionsList.sort(key=lambda p: howCentric(p, boardLength))
p.terminate()
main()
sorted(zip(unique_rows, counts), key=lambda x: x[1], reverse=True)
fixed.write(line)
log.setLevel(logging.INFO)
cv.SetCaptureProperty(video2, cv.CV_CAP_PROP_FRAME_HEIGHT, 600)
app.exec_()
sys.stdout.buffer.write(TestText2)
server.serve_forever()
sample_df.apply(np.log).diff()
[a, b, c, d]
print(re.findall(pattern, string))
my_method()
print(browser.title)
img = cv2.imread(sys.argv[1])
fig = plt.figure()
r.reset_index()
proc.start()
br.set_handle_equiv(False)
a.foo = new_foo.__get__(a, type(a))
test_file.close()
add_column(engine, table_name, column)
d2 = [k for k, v in sorted(d.items()) for _ in range(v)]
foo()
nums = map(lambda x: x * 2, nums)
divtd(datetime.timedelta(hours=12), 2)
element.click()
root.withdraw()
d[row[0]].append(row[1:])
print(sorted(list(mydict.items()), key=lambda k_v: ordering[k_v[0]]))
settings.name
sum(x[1] for x in divs)
csv2.close()
print(res[1])
my_foo.echo_bar()
f.seek(0, 2)
wx.ListCtrl.__init__(self, *args, **kwargs)
QWidget().setLayout(self.layout())
imobj.set_data(np.zeros((100, 100)))
np.piecewise(a, [a > 80, (40 < a) & (a <= 80), a <= 40], [funcA, funcB, funcC])
Funny.dynprop
self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
yaml.dump(data, ff, allow_unicode=True)
time.sleep(1)
X, Y = np.meshgrid(np.linspace(xmin, xmax, 100), np.linspace(ymin, ymax, 200))
{e: str1.count(e) for e in set(str1)}
time.mktime(ts)
clips.Run()
fig = plt.figure()
print(dom.toprettyxml())
m = m.multiply(m >= 10)
[1, 1, 1, 1, 1, 1, 1, 1],
w.show()
pd.DataFrame.from_records(records_from_json(fh))
y = np.hsplit(x, [((i + 1) * 10) for i in range((129 - 1) // 10)])
mydict = dict((k, v) for k, v in mydict.items() if k != val)
sys.getsizeof(sys.getsizeof)
temp = temp.reshape(-1, 1)
pygame.quit()
id = Column(Integer, primary_key=True)
ax.xaxis.set_label_position(direction)
main()
tuple(zip(*ii))
unittest.main()
print(regex.group(1))
ax2.yaxis.set_major_locator(mtick.LinearLocator(5))
prettyp([1] * 100)
print((x.eval(), y.eval(), tf.gradients(y, [x])[0].eval()))
new_dict = nested_dict(2, float)
l = [(x * (2 if i % 2 == 1 else 1)) for i, x in enumerate(l)]
plt.xlim(xmin, xmax)
QWebView.__init__(self)
frame.Show(True)
df.shape
legend.draggable(state=True)
urllib.request.Request.__init__(self, *args, **kwargs)
burger.save()
wilma.save()
myList[:] = [(a, b) for a, b in myList if myDict.get(a, sentinel) != b]
regex.findall(string)
df = pd.read_sql_query(query.statement, engine)
random.shuffle(tmp)
text = tk.Text()
print(my_list_of_objs)
ax.plot_wireframe(xp, yp, zp)
map(sum, a)
json.dumps(data)
df2.fillna(0, inplace=True)
help(func)
t.start()
plt.show()
print(CreateTable(Model.__table__).compile(engine))
queue = Queue()
sys.getsizeof(bitArray.tobytes()) / float(len(sequence))
Af.reshape(A.shape)
file_handler.setLevel(logging.INFO)
self.setLevel(logging.INFO)
sys.__stdout__.write(s)
df.iloc[:, (np.lexsort(v.T[::-1]))]
[a for v, a in sorted((x[a], a) for a in y)]
df1.reindex(index)
[m.group(1) for m in matches if m]
self.my_list.extend(repeat(0, 4 - len(self.my_list)))
pprint.pprint(l)
plt.figure()
os.setsid()
name = models.CharField(max_length=50)
id = Column(Integer, primary_key=True)
[(i, z) for i in [1, 2] for z in zs_i]
s.quit()
compressed_table.append((istart, i, table[i]))
print(subprocess.list2cmdline(sys.argv[1:]))
ax.clear()
df.groupby(1)
root = Tk()
b = [a, a]
plt.show()
sys.stdout
print(data.splitlines())
sum_yearly_data(*list(data.values()))
axes.set_xlim([xmin, xmax])
dict.get(self, key)
pdb.set_trace()
output.close()
numcount[num] += 1
next(g, default_value)
axm.xaxis.set_visible(False)
print(etree.tostring(root, xml_declaration=True))
tuples = [(1, 1), (0, 1), (1, 0), (0, 0), (2, 1)]
datetime.datetime(*eut.parsedate(text)[:6])
print((1, 2, get_nesting_level()))
layout.addWidget(self.buttons)
year = datetime.date.today().year
signal.signal(signal.SIGINT, on_interrupt)
ax.invert_yaxis()
shm_test()
driver = webdriver.Firefox(firefox_profile=profile)
os.close(fd)
self.builder.get_name(widget)
math.sin(2 * math.pi / LIMIT * x) + 0.001 * random.random()
l.sort(key=int)
myModule.printX()
db.put(models)
[0, 1, 1, 2, 2, 2, 1, 0],
argparse.ArgumentParser.__init__(self, *args, **kwargs)
sorted(list(range(len(K))), key=lambda x: K[x])
X, Y = np.meshgrid(x, y)
tar.close()
df = pd.DataFrame(d)
[subl for subl in _itersplit(l, splitters) if subl]
p.wait()
show_windows()
x[0] + np.arange(0, 60, 10)
do_sth()
x = Bunch(d)
sio.seek(0)
paramdata.index
lst.sort(key=POS.get)
int(p.stdout.read())
mcastsock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
[(x * y) for x, y in zip(list(range(1, 21)), cycle(list(range(2, 10))))]
print(repr(tokzr_QA(inp1)))
numpy.full((2, 2), True, dtype=bool)
s.map(Timestamp.date)
data.groupby([a, b]).count()
np.split(b.indices, b.indptr[1:-1])
print(str(item[0:])[1:-1])
show()
np.fromiter(a, dtype=np.float)
numpy.median(numpy.array(lst))
list(d.keys())
any(b == a[i:i + len(b)] for i in range(len(a) - len(b) + 1))
button.clicked.connect(self.make_calluser(name))
lst.sort(key=lambda x: x[0])
plt.tight_layout()
result = json.loads(line)
con.close()
b.append(i + 1)
1 in set([l[0] for l in a_list])
data = cur.fetchone()[0]
[_f for _f in sequence if _f]
pygame.draw.rect(x, y, width, length)
sys.stdout = sys.__stdout__
clf.fit(Xs, ys)
countvec.fit_transform(df.title)
do_stuff()
other_list.append(obj)
min(list(range(len(L))), key=L.__getitem__)
pickle.dump(my_list, f)
writer.writerow([i[0] for i in cursor.description])
print(repr(arr))
result = [convert(i, j) for i, j in enumerate(tlist)]
print(list(map(replace, a)))
x, y
foo()
[dishes[x] for x in crucial if x in dishes]
time.sleep(10)
os.dup2(copied.fileno(), stdout_fd)
response = br.submit()
writer.close()
setattr(self, name, val)
df2 = df[(df.a != -1) | (df.b != -1)]
items = [[1, 2, 0], [1, 2, 0], [1, 2, 0]]
app.run()
print(first.lower() <= second.lower() <= third.lower())
np.unique(struct)
print(cur.fetchone())
unittest.TextTestRunner().run(suite)
admin.site.register(Group, GroupAdmin)
self.dg.Items.Add(self.value)
xl.ActiveWorkbook.ActiveSheet.Columns(1).AutoFilter(1)
p.start()
print(list(value.keys())[0])
axclust.imshow(clustimg)
print(df[c].value_counts())
tags = Tag.objects.all()
anims.append(f)
root.setLevel(logging.DEBUG)
db.close()
fout.close()
axr.yaxis.set_major_locator(yrloc)
dict_x.setdefault(key, []).append(value)
exit(0)
plt.show()
[remove_cruft(s) for s in sites]
context
app = QtWidgets.QApplication(sys.argv)
f.write(value)
b.save()
sess = tf.Session()
data = pd.DataFrame(list(collection.find()))
ret[line.strip()] = parse_message_to_tree_helper(buf, index)
app = Flask(__name__)
matplotlib.pyplot.show()
screen.blit(pygame.transform.scale(pic, (500, 500)), (0, 0))
name = models.CharField(max_length=100)
deleted[key_to_delete]
floor_float(10.8976540981, 8)
numpy.median(d, axis=0)
self.SetSizer(sizer)
self.logentry.append(line)
os.path.dirname(str(sys.executable, encoding))
map(list, iter(c.items()))
df.sub(df2, fill_value=0)
gtk.main()
dosomething()
self.layout = QtGui.QHBoxLayout()
print(df[df.Name.isin(val)].reset_index(drop=True))
func2(**locals())
ax = fig.add_subplot(2, 1, 1)
np.isclose(arr_f, a, atol=0.01).any()
numpy.prod(a)
([next(it) for _ in _range(s)] for s in count(1))
sys.stdout.flush()
1 in [len(set(i)) for i in zip(*arr)]
my_strings.sort(key=last_part)
print([sum(daily[x:x + 7]) for x in range(0, len(daily), 7)])
[x for x in lst if x % 2 == 0][0]
main()
print(args)
MyApp().main(sys.argv[1:])
print(a.sum())
plt.xticks(list(range(len(D))), list(D.keys()))
args = parser.parse_args()
print((key, value))
df[(df.a < df.b) & (df.b < df.c)]
print(random.random())
form = ContactForm(request.POST)
{{django_version}}
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
arr.sum(axis=0)
[s for n in range(12) for s in [square(n)] if s > 50]
f.seek(0, 2)
pygame.init()
print(df.iloc[:, (0)].values.tolist())
output.writelines(data)
m * c[:, (np.newaxis)]
time.sleep(5)
proc.kill()
tuple(totuple(i) for i in a)
sorted([15, 8])
self.grid_columnconfigure(2, weight=1)
frame.Show()
self.assertEqual(cm.exception.code, 1)
img = Image.open(image_path)
app = Flask(__name__)
np.vstack(a) - b
cv2.waitKey(0)
[0][2][0]
print(get_authoritative_nameserver(sys.argv[1], log))
a = np.arange(5)
isinstance(s, string_types)
list(islice(rows, 0, len(rows), int(1 / proportion)))
q = multiprocessing.Queue()
func_to_cache()
f.close()
ax1 = fig.add_subplot(111)
file = models.FileField(upload_to=content_file_name)
np.maximum(X.A, Y.A)
[x for x in l if x is not 0] + [x for x in l if x is 0]
avg = sum(mylist) / len(mylist)
shutil.copy2(os.path.join(dirpath, file), dstdir)
t.date.dt.to_pydatetime()
L.append(L[-1][:] + [L[-1][-1] + 1])
list(itertools.zip_longest(*ll))
plt.hist(val, weights=weight)
con.commit()
nx.draw(G, node_size=1000)
id(a[0:2])
L[:start] + L[start + n:i] + L[start:start + n] + L[i:]
c = MyClass()
id = Column(Integer, primary_key=True)
{0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1}
cv2.waitKey(0)
do_something()
Response(serializer.data, status=status.HTTP_201_CREATED)
lines[-n:]
s.fill((255, 255, 255, 128))
pl.show()
sum(j << i for i, j in enumerate(reversed(l)))
b.T
dfile.close()
s = json.dumps(foo.__dict__)
df.loc[idx]
print(np.cross(a, b))
root.winfo_children()
s = s[::-1]
x[:5]
scipy.misc.imshow(im_out)
list({len(x): x for x in reversed(lst)}.values())
print(a[i, j])
fig = plt.figure(figsize=(15, 10))
python - -version
0, 1, 1, 0, 0, 0, 0, 1, 0
self.frame.destroy()
printx()
show()
item in self.queue
l + [pad] * (n - len(l))
s.close()
next(f)
a = np.arange(27)
os.unlink(file_path)
[2, 0, 1, 0, 1, 0]
signal.signal(signal.SIGINT, handler)
list(chain(*zip(list(range(1, 7)), list(range(-7, 0))[::-1])))
widget.show()
cv.CvtColor(vis0, vis2, cv.CV_GRAY2BGR)
dict.__setitem__(self, keys, value)
obj.save()
columns.setdefault(column, []).append(row)
l += [sum(v) / len(v)]
soup = BeautifulSoup(html_text)
grouped.JobNos.sum().order(ascending=False)
btn.grid(row=0, column=tabslen, sticky=W + E)
b.shape
f.close()
ax.set_yticklabels(df.index)
matches = (x for x in lst if x > 6)
session1.add(item)
color = models.CharField(max_length=2)
setattr(self.obj, self.attr, val)
con.commit()
plt.clf()
not set(a).isdisjoint(b)
inner(myList, [])
tornado.ioloop.IOLoop.instance().start()
isinstance(x, tuple) and isinstance(x.__dict__, collections.abc.Mapping)
b = np.lib.stride_tricks.as_strided(a, (1000, a.size), (0, a.itemsize))
df = pd.DataFrame(rows_list)
s.value_counts().index[2:]
reactor.run()
session.commit()
obj if isinstance(obj, dict) else range(len(obj))
outf.flush()
apsched.start()
bit[::-1]
ax.set_yticks(y_tick * np.pi)
self.mc.Play()
list(filter(pattern.search, strings))
conn.sendmail(sender, destination, msg.as_string())
_.view(data.dtype)
self.handle_request()
[(a + b) for a, b in x]
expander.py
shell.interact()
not bool
ax = fig.add_subplot(111)
MyClass.call_me()
new_d = dict((val, d[val]) for val in reverse_d.values())
func()
studying / VBG
numpy.sum(boolarr)
(np.cumsum(np.bincount(v)) - 1)[v]
cls._instances[cls].__init__(*args, **kwargs)
reactor.run()
requests.status_codes._codes[200]
myList[:] = [x for x in myList if myDict.get(x[0], sentinel) != x[1]]
[0, 0, 0, 0, 0, 0, 0, 0],
im.set_clim(vmin, vmax)
final.append(compound[x])
np.linalg.lstsq(A.T.dot(A) + lamb * np.identity(n_col), A.T.dot(y))
Employee.__init__(self, name, salary)
plt.show(block=True)
im = Image.open(imgfile)
s.bind((host, 8080))
list(range(min((a, b)), max((a, b)) + 1))
conn.send(filepath)
arr.dtype.names
print(doCombine(target, x, len(target), 0, 0))
tk.Canvas.__init__(self, *args, **kwargs)
x[np.logical_and(x > -2, x < 2)]
args = parser.parse_args()
sys.exit(0)
plt.show()
[x for x in lst if x % 2 == 0][:1]
a + b == c or a + c == b or b + c == a
admin.site.unregister(User)
a[slice(*b)]
time.ctime()
set([zip(perm[::2], perm[1::2]) for perm in permutations(list(range(9)))])
any(np.array_equal(a, x) for x in my_list)
fig.autofmt_xdate()
np.random.choice(keys, size=n, replace=True, p=prob)
f_out.write(i)
self.panel.SetSizerAndFit(self.sizer)
plt.plot(data)
print([d.__name__ for d in foo.bar._decorators])
[v for v in x if v == v]
sys.exit(app.exec_())
thread.start()
show_firm_url.allow_tags = True
print(list_end_counter([1, 1, 2]))
ax.bar(arange(len(grosses)), grosses)
data = json.loads(json_string)
get_max(dicts)
b = np.array([[5, 6], [7, 8]])
raise ValueError
print(solve([2, 0, 1]))
version.search(s).group()
dir(module)
os.waitpid(-pid)
self.assertTrue(settings.DEBUG)
child.widget().deleteLater()
plt.subplots_adjust(left=0, bottom=0, right=1, top=1, wspace=0, hspace=0)
fp.close()
ax.set_xlim(0, len(changes) + 1)
items = list(yourdict.items())
PLT.show()
my_dict[len(data)].append(id)
r = requests.get(url, cookies=cd)
obj = MyClass()
sys.getrecursionlimit()
fig.autofmt_xdate()
b = map(bool, a)
soup.find_all(text=is_comment)
result.append(x)
plt.show()
datetime.datetime.strptime(date_txt, DATE_FORMAT)
fig.show()
format_timedelta(timedelta(minutes=-5))
self.graphicsView.setScene(scene)
datetime.fromtimestamp(0)
test[start:end]
self.socket.listen(1)
plt.plot(x, 2 * x)
browser.get(url)
all(val == testval for val in list(d.values()))
contact_form.save()
acc.setdefault(key, []).append(value)
sbtn.click()
myList.sort(key=extractNum)
df.columns = [c_name.strip() for c_name in df.columns.values.tolist()]
image = Image.open(buffer)
__init__.py
Foo.class_method()
mat[ixs].sum(axis=0)
tuple(map(sum, zip(a, b)))
plt.draw()
pool.join()
idx = numpy.argmin(numpy.abs(A - target))
cursor.execute(sql)
self.assertTrue(users.is_current_user_admin())
print(myString[len(myString) - 1])
self.save()
id = Column(Integer, primary_key=True)
s[len(start):-len(end)]
match.groups()
app.run()
print(repr(b))
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
runserver.py
print(soup)
writer = csv.writer(outfile)
print(line)
plt.setp(list(ax.spines.values()), color=color)
bins = np.array([0, 1, 10, 60, 60 * 10, 60 * 60, 24 * 60 * 60])
turtle.forward(size)
host.close()
self.board[y][x]
sys.path.append(PYSOLR_PATH)
d = dateutil.parser.parse(s)
[False, False, True, False, False],
print(os.path.join(root, name))
s[4]
pd.concat([c.series for c in [France, Germany]], axis=1)
os.remove(os.path.join(root, file))
ax.set(xticks=np.arange(dates.size), xticklabels=datelabels)
dialog.setLayout(some_layout)
ax.set_xlim(0, 5)
time.sleep(1)
img.putdata(data)
fig = plt.figure()
a = numpy.empty_like(b)
ws.cell(row=r, column=1).value = statN
print(soup.li.findAll(text=True, recursive=False))
xl.Application.Quit()
ser.setDTR(False)
sum(b[i] << i * 8 for i in range(4))
np.meshgrid(x, x)
os.unlink(path)
np.subtract.at(dW, np.s_[:, (y)], masked.sum(axis=2))
len(tup)
ax1.set_xlim([0.1, 10])
commands[command](*sys.argv[1:])
s.commit()
plt.hlines([0], -10, 20)
QtDBus.QDBusConnection.sessionBus().send(msg2)
map(lambda a_b: a_b[1] - a_b[0], pairwise(L))
result = dict(result)
sets = [set(i + j) for i in g for j in g if i != j and set(i) & set(j)]
collections.deque.__getitem__(self, index)
draw = ImageDraw.Draw(img)
set(bell).issubset(printset)
frame.columnconfigure(1, weight=1)
self.a[-1]
plt.xticks(rotation=25)
plt.contourf(X, Y, Z)
pi = square(a + b) / (4 * t)
setattr(object, name, value)
my_dict[item] = a[index + 1]
print(max(len(s) for s in row))
datetime.datetime(2012, 11, 16, 0, 0)
print(output)
random.shuffle(x)
all(map(lambda x: x == items[0], items))
k = np.arange(n)
sys.path.append(SYS_PATH)
main()
sys.maxsize
random.shuffle(thelist)
s.get_text()
backend.setsockopt(zmq.XPUB_VERBOSE, True)
logger.setLevel(logging.ERROR)
logging.shutdown()
np.array(zip(*(A[i:] for i in range(n))))
time.sleep(1)
pd.concat([i for _, i in df.items()]).dropna().reset_index(drop=True)
[_f for _f in map(func, x) if _f]
ax = fig.add_subplot(111)
li2 = [y for x in li for y in x]
root.mainloop()
plt.xlim(0, 4)
br.select_form(nr=0)
cursor = db.cursor()
len(x)
self.verticalLayout.addWidget(self.label)
df = pd.concat([df1, df2])
MY_SORTED_TUPLE = tuple(sorted(MY_TUPLE, key=itemgetter(1)))
root = Tk()
print(g.reset_index(drop=True))
data_dict[regNumber].append(details)
plt.figure()
raise KeyError(request.POST)
__init__.py
print(find_nearest(x))
output.sort()
df.loc[mask.any(axis=1)]
pd.__version__
os.makedirs(dir)
[int(any(full.endswith(last) for last in B)) for full in A]
self.est.predict_proba(X)[:, (1)][:, (numpy.newaxis)]
date = models.DateTimeField(auto_now_add=True, blank=True)
locals().update({col: df[col]})
django.setup()
[item for item in my_iterable if my_filter(item)]
re.findall(p, test_str)
client.send(msg)
str(b)
plt.annotate(labls[i], xy=(x[i, 2], y[i, 2]), rotation=rotn[i, 2])
jsonFile.close()
do_many_amazing_things(a, b)
math.isnan(x)
plt.show()
sys.exit(1)
X, Y = np.mgrid[:bignum, :bignum]
df[col].replace(to_remove, np.nan, inplace=True)
channel.basic_consume(callback_func, queue, no_ack=True)
df.ix[df.index.indexer_between_time(datetime.time(10), datetime.time(14))]
mratings.mean(axis=0)
store.put(key, value, table=True, append=False)
tk.Tk.__init__(self)
plt.yticks(np.arange(y.max() + 1), labels)
outfile.write(file2.read())
do_something()
area1 + area2
type(a[0])
sum(map(len, primes))
main()
[(x % 2 == 0) for x in t_f_list]
a.childNodes[0].nodeValue
[val for val in a for _ in (0, 1)]
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
test[:, (0)]
sys.stdout.write(RED)
template.render()
gevent.killall([obj for obj in gc.get_objects() if isinstance(obj, greenlet)])
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
getdict(x)
list(range(1, 11))
printArray([str(x) for x in row])
self.send_blob(blob_info, save_as=True)
x.sort(key=str.lower)
output.close()
a[:0] = b
os.symlink(linkto, dstname)
im.file.save(img_filename, File(img_temp))
print(repr(t[1]))
p[np.argsort(p)]
int(b[::-1], 2)
root.mainloop()
app.run()
setHatchThickness(1.0)
self.queue.add(item)
[(item + (z[item[0]],)) for item in l]
sess = tf.Session()
time.sleep(5)
y.mean()
datetime.fromtimestamp(time.mktime(time_tuple))
np.sin(2 * np.pi * freq * t)
s.replace(d, regex=True)
sound.play()
df
pprint(dict_to_etree(d))
YourModel.objects.filter(some_datetime__date=some_date)
[item for item, count in Counter(a).items() if count > 1]
ax.scatter(a, b, c, c=[use_colours[x[0]] for x in d], s=50)
suite.addTest(unittest.TestLoader().loadTestsFromModule(module))
ax.set_xlim(xlim)
a.itemset((i, j), x)
df.loc[[(df.iloc[(i), 1:].duplicated().sum() == 0) for i in df.index]]
path = sys.modules[self.__module__].__file__
app.register_blueprint(post_blueprint)
df[k] = df[k].astype(v)
type(json.loads(data))
[k[1] for k in d]
button.grid(row=1, column=4)
str(165).zfill(4)
img = Image.open(stream)
np.linalg.norm(A[1:] - A[:-1], axis=1)
locals().update(d)
fobj.close()
{{page.get_title}}
sum(np.array(a) > 7)
time.sleep(4)
Py_Finalize()
Table.query.filter(Table.name == con.name).first()
array2[:] = [e for e in array2 if e not in set1]
lucky.append(L[0])
r = np.exp(np.sqrt(x * x + y * y))
[1, 2] in a.tolist()
self.mainloop()
args = parser.parse_args()
args = parser.parse_args()
ax.plot([1, 1, 1])
str(self.as_date())
print(len(list(group)), key)
int(True)
table.sort(functools.cmp_to_key(team_cmp))
G.add_edge(prereq, target)
driver = webdriver.PhantomJS(desired_capabilities=dcap)
obj.save()
con.close()
QtGui.QWidget.__init__(self, parent)
df.loc[:, ((df != df.ix[0]).any())]
iter(self._data)
cv2.waitKey(0)
my_list = [False for i in range(n)]
[s for s in perms if valid(s)]
main()
canvas.pack()
plt.show()
plt.subplot(154)
numpy.random.seed(x)
fig = plt.figure()
painter.rotate(90)
plt.ion()
fh.close()
values[i] = struct.unpack(endian, f.read(bytes))[0]
os.chdir(whatever)
f.close()
df = df.sample(frac=1).reset_index(drop=True)
driver = webdriver.Firefox(firefox_binary=binary)
time.sleep(0.1)
[s.index(x) for x in lst]
sys.getrefcount(object)
plt.show()
bar = foo.copy()
print(line)
module.run_pool()
sum(A, [])
ast[([0, 1, 2]), ([0, 1, 0]), ([0, 2, 2]), (0), :2, :2]
same_structure(a[0], b[0]) and same_structure(a[1:], b[1:])
a * x ** 2 + b + c * np.sin(x)
indices = np.split(sidx, np.flatnonzero(np.diff(arr[sidx]) > 0) + 1)
list(s)
dict((k, dol1.get(k, no) + dol2.get(k, no)) for k in keys)
M.A.diagonal(2)
Py_Finalize()
time.sleep(0.5)
A[:, (1)].sum()
wx.StaticBitmap(panel, -1, jpg, (10, pos), (jpg.GetWidth(), jpg.GetHeight()))
map(complex, row)
[(item, the_list.count(item)) for item in sorted(set(the_list))]
s.splitlines()
master.grid_rowconfigure(1, weight=1)
[(x + 1) for x in l]
zip(a[::2], a[1::2])
[val for sublist in mylist for val in sublist]
df.set_index(df.merged_ix, inplace=True)
a[np.ix_(*[list(range(0, i, 2)) for i in a.shape])]
fig = plt.figure()
time.sleep(0.1)
ax.plot(x, y)
y.shape
sorted(listofLines, key=extract_time)
np.random.uniform(-10, 10)
deletemydict[k]
store.close()
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
deleterecursive_dict[key]
X.T
fp.seek(0)
lines.sort(key=second_column)
print(ame_to_bre(text))
b = [i for i in a]
func(*args, **kwargs)
imresize(np.ones((1000, 1000)), 50).shape
wx.Frame.__init__(self, parent, id, title, size=(600, 600))
root.mainloop()
any([(sorted(sub) in range(min(l), max(l) + 1)) for sub in subs])
ldap.set_option(ldap.OPT_DEBUG_LEVEL, 0)
k, _, _, _ = np.linalg.lstsq(M, y)
dta.co2.interpolate(inplace=True)
a[i:j]
connlisten_thread.start()
print(foo.bar())
self.yet = True
A[np.arange(m), idx]
print(line.strip())
np.dot(X, np.dot(M, X.T)).trace()
ax.set_xlim([x[0], x[1]])
(220922000, 2428),
(220922001, 2429),
(220922564, 2992),
(220922566, 2994),
(220924161, 4589),
lines = ax.plot(list(range(10)), np.random.randn(10), list(range(10)), np.random.randn(10))
print(is_shifted_copy([1, 1, 1], [1, 1, 1]))
HttpResponse(status=400)
text.pack()
[audio[i // 2] for i in range(0, len(audio) * 2)]
df = pd.concat(series, axis=1)
pipeline.fit(X[:, (np.newaxis)], y)
time.sleep(0.05)
y = np.array([0, 0, 1, 1])
plt.plot(x, y)
a.repeat(2, axis=1)
True
b = tuple(a)
obj.save()
sess.query(Tag.name).distinct()
im.save(sys.argv[2])
bool([1, 2])
plt.plot(x, y)
self.Bind(wx.EVT_MOTION, self.on_motion)
pub_dict[p.key].append(p)
print(data)
[j for j in range(2, n) if isprime(n)]
c = itertools.chain(a, b)
df1.plot(ax=axes[0, 0])
tar.close()
dict(re.findall(pattern, json_string))
df.ix[df.Col1.isin(search_list)]
self.app = app.app.test_client()
lock = threading.Lock()
ax2.get_yaxis().set_animated(True)
[cube(i) for i in range(1, 11)]
int(1.0 / -2)
ax1.yaxis.set_major_locator(y1loc)
func(a)
img.save(filename=output_destination)
prettyp(CrazyClass())
myfunc(a, b, c, d, e, f)
next((x for x in seq if predicate(x)))
ftp.cwd(path)
self.multlineCommands = Forward()
fig = plt.figure()
execlist[i][4] = mydelay
x, y = zip(*points)
x.append([])
Z[xidx, yidx] = raw[:, (2)]
temp = temp[1:]
self.model.objects.filter(active=True)
df.iloc[2:6]
print(map(itemgetter(1), g))
print((r.status_code, r.reason))
chain.from_iterable(combinations(xs, n) for n in range(len(xs) + 1))
np.diagonal(np.rollaxis(np.tensordot(a, a, (1, 1)), 1), 0, 2).T
Gtk.main()
f.close()
dict(d1, **d2)
signal.pause()
[(k, len(list(g))) for k, g in groupby(s)]
serverSocket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
Counter(item for lst in listOfLists for item in set(lst))
self.canvas.after(50, self.check_queue)
str(numpy.array([0.24])[0])
self.assertEqual(resp.status_code, 200)
[0][1][2]
print(recursive_lambda(lambda a, b: b * a(a, b - 1) if b > 0 else 1)(6))
list(set(a) & set(b))
cursor.execute(query)
root.mainloop()
sys.getsizeof(b)
data.append(item)
np.moveaxis(np.indices(dims), 0, -1)
a = dict.fromkeys(list(range(4000000)))
ax1 = fig.add_subplot(111)
b = [6, 7, 8, 9, 0]
soup = BeautifulSoup(browser.page_source)
m.close()
self.httpd.stop()
{x for x in a if x == x}
dictionary = dict(zip(keys, values))
process.stdout.close()
list(itertools.chain.from_iterable([l[x] for x in lslice]))
sys.stdout.write(s)
print(json.dumps(foo))
os.startfile(filename)
QtCore.Qt.ItemIsEnabled | QtCore.Qt.ItemIsSelectable | QtCore.Qt.ItemIsEditable
cv2.waitKey(0)
cv2.destroyAllWindows()
(x + 1 for x in l)
numpy.ndarray((5, 5))
user = models.OneToOneField(User)
pyglet.app.run()
self._stack.pop()
time.sleep(1)
b.py
webtail
list(range(m, (count + 1) * m, m))
main()
func(x)
print(sys.exc_info()[2].tb_next.tb_frame.f_locals)
datetime(2015, 12, 2, 0, 0), datetime.datetime(2015, 12, 8, 0, 0)
f.write(text)
d.update(locals())
Notify.uninit()
celery.config_from_object(app.config)
len(a)
a.append(row)
print(df.attr.iloc[i])
data = np.random.random((int(1000.0), int(100000.0)))
any((a[:] == [1, 2]).all(1))
np.vstack((a, a, a))
doctest.testmod()
plt.setp(plt.xticks()[1], rotation=90)
cursor.execute(qSQL)
print(json.dumps(data, default=date_handler))
frame1.axes.get_yaxis().set_ticks([])
arr.append(list(df.iloc[i]))
threading.Thread.__init__(self)
[map(counter.__getitem__, all_features) for counter in counters]
file.close()
~pd.isnull(df[list_of_cols])
2 * frexp(n)[0]
gdata.gauth.AeLoad(users.get_current_user().user_id())
G = nx.MultiGraph()
df.stack()
sock.close()
np.vstack([np.diag(c[:, (i), (i)]) for i in range(A.shape[0])]).T
f = open(filename)
qs.filter(user=request.user)
screen.mainloop()
QtCore.Qt.ItemIsEnabled
MyApp().run()
result[numpy.argsort(A)] = numpy.sort(B)
time.sleep(10)
print(queue.method.message_count)
item.set_fontsize(20)
cal_window.show_all()
test_moduleA.py
mpl.ticker.MaxNLocator.__init__(self, nbins=9, steps=[1, 2, 5, 10])
main()
dict((k, json.dumps(v)) for k, v in list(json.loads(val).items()))
signal.signal(signal.SIGALRM, old_handler)
(m.T * c).T
df.iloc[idx]
new_list = list(range(1, 6)) + list(range(15, 20))
app.MainLoop()
fig = plt.figure()
os.chdir(storetodir)
axborder.set_ylim(binimg.shape[0], -1)
print(codeproc.stdout.read())
image = Image.open(f)
dset1.apply(func, axis=1)
layout.addWidget(self.label)
repeat(lambda : bar(42))
connection.commit()
elapsed2s.append(elapsed2)
elapsed1s.append(elapsed1)
d[key].append(row[1:])
subsampled = df.ix[(choice(x) for x in grouped.groups.values())]
p.map(process_file, listdir(inputDir))
locale.resetlocale()
b.foo()
python - mfoo.bar
thread.start()
img.size
User.insert_many(row_dicts).execute()
df.Group.map(df.Group.value_counts())
plt.draw()
pdf_text_object.textOut(text)
imp.load_dynamic(__name__, __file__)
form.save()
main()
df = df.sort()
mock.assert_called_with(42)
fig.subplots_adjust(wspace=0.4)
print(df[(df.Symbol1 == df.Symbol2) & (df.BB == df.CC)])
wx.StaticBitmap(panel, -1, bmp, (10, pos), (bmp.GetWidth(), bmp.GetHeight()))
other_app.other_view(request, **kwargs)
print(map(float_or_str, line.split()))
myArray = np.vstack(myArray)
process_data(line)
moduleZ.py
plt.plot(X, Y, lw=0)
do_some_other_stuff()
legline.set_color(color)
df_out
json.dumps(result, default=json_util.default)
fig, ax = plt.subplots()
self.__class__(data)
t.start()
f(*args, **kwargs)
print(tag.nextSibling.nextSibling.__class__)
[(a if C else b) for i in items]
uniq_animal_groups = map(list, set(map(tuple, animal_groups)))
fig, ax = plt.subplots()
x + 1
root.withdraw()
pool = multiprocessing.Pool(multiprocessing.cpu_count())
r = requests.get(URL, cookies=jar)
foo()
conn.close()
greetings.hello()
numpy.zeros((2, 2), dtype=bool)
r.findall(s)
output, err = p.communicate()
a = a.reshape(-1)
d += timedelta(days=6 - d.weekday())
print(yaml.load(f))
jsonify(result=wordlist)
print([filters.get(word) for word in sentence.split() if word in filters])
proc.terminate()
[[2], [0], [1], [0], [1], [0]]
np.dot(Zij, G)
tuple(x[0] for x in G)
print(t.timeit(5))
fig, ax = plt.subplots()
ax2.set_xticks([100, 80, 50])
df
a.remove(i)
hex((val + (1 << nbits)) % (1 << nbits))
pyglet.app.run()
distinct()
result = response.read()
hashlib.md5(img.tostring()).hexdigest()
button.pack()
MyClass in MyClass.__mro__
self.listTools.add(self.addButton)
a.append((1, 2, 4))
xml.close()
sorted([B, C, A, D, X], key=lambda cls: len(cls.mro()))
hash(self.PersonID)
str_list = [item for item in str_list if item]
next(hex_list)
OrderedDict(sorted(list(d.items()), key=lambda t: t[1]))
X[:, (i)] = x
platform.system()
print(newcorpus.sents())
len(set(it_copy)) == 1
a.flatten()
random.shuffle(array)
pprint(data)
uniq_animal_groups = map(list, set(map(tuple, map(set, animal_groups))))
all(x == 0 for x in list(d.values()))
b.setdefault(j, []).append(i)
os.remove(os.path.join(my_dir, fname))
self.name = name
form.save()
B[A[1], cat_index] = A[2]
shutil.rmtree(tmpdir)
f.flush()
seq[n:] + seq[:n]
df
logger.addHandler(fileHandler)
b = np.array([0] * 4)
result = [sum(data) for data in zip(*args)]
fig = plt.figure()
new_list.append(x)
unique_a.view(a.dtype).reshape((unique_a.shape[0], a.shape[1]))
plt.gcf().tight_layout()
Thread.__init__(self)
arity.__class__.arity = arity
numpy.histogram(my_values, bins=numpy.r_[-numpy.inf, my_bins, numpy.inf])
p.start()
df.clip(upper=4400).plot.hist(stacked=True, bins=bins, normed=True)
df = pd.DataFrame([[1, 0, 0, 0], [0, 0, 1, 0]])
self._server.shutdown()
ax.set_autoscale_on(False)
traceback.print_exc()
help(hehe)
arr[([1, 1]), :]
[x for x in mylist if not any(c.isdigit() for c in x)]
traceback.print_exc()
self._list[x]
b[i] = 1
itertools.islice(mygenerator(), 10)
l = json.loads(s)
a, b = 1, 2
fig = plt.figure()
func()
Py_Finalize()
dialog.setAttribute(QtCore.Qt.WA_DeleteOnClose)
stack[-1].append([])
mask1 = (arange(10) > 5) & (arange(10) <= 8)
self.sock.connect((host, port))
list(map(chr, list(range(ord(s[0]), ord(s[-1]) + 1))))
a.reshape((2, 2, 2))
logger = logging.getLogger(__name__)
a, result = a[:-1], a[-1]
top.sort(key=lambda a: a[1])
b = tuple(b)
print(delta.days * 24 * 60 * 60 + delta.seconds + delta.microseconds / 1000000.0)
tf.contrib.layers.embedding_column(workclass, dimension=8)
GEN_SUSPENDED
x.view((float, len(x.dtype.names)))
setattr(self, k, d[k])
result.append(list[-1])
output.append(float(row[4]))
words = [x for x in words if x not in bad_words]
list(set([x for x in l if l.count(x) > 1]))
[[6, 2], [7, 5], [8, 7], [9, 9], [0, 4]]
print(x)
do_something_dangerous()
fig.autofmt_xdate()
AB = [(a + b) for a, b in itertools.zip_longest(A, B, fillvalue=0)]
unittest.main()
sys.exit(1)
ax2 = ax.twinx()
foo()
any(some_func(x) for x in some_list if x > 5)
r.json()
time.sleep(1)
from_date = from_date - datetime.timedelta(days=1)
df.dtypes
out.close()
some_value
uuid.uuid1(random.randint(0, 281474976710655))
unittest.main(failfast=True)
nonzero(r_[1, diff(t)[:-1]])
bar.foobar()
dev / tests / test_file.py
print(textelem.text)
x = json.loads(x)
np.vstack([topbottom, xvalues])[:, (mask)].T
ax.xaxis.set_major_formatter(major_formatter)
fig = plt.figure()
s.add(get_my_new_random_number())
self.label.pack()
ispower(1, 1)
print(json.JSONEncoder().encode(response))
df.loc[:, (df.dtypes == object)]
random.shuffle(ans)
args = parser.parse_args()
norm.cdf(1.96)
self.fileobj.seek(-8, 1)
Base.metadata.create_all(engine)
views.py
foo.f()
element.clear()
[1426802400, 1429218000]
cursor.commit()
self.scrollbar.grid(column=2, sticky=N + S)
ax2.set_ylim([np.amin(image[:, (5), (5)]), np.amax(image[:, (5), (5)])])
print(p.stderr.read())
plt.show()
QtCore.QAbstractListModel.__init__(self)
canvas.configure(yscrollcommand=vsb.set)
soup.prettify()
print(Foo.instance_count)
zip(*lol)
ax.yaxis.set_visible(False)
tableWidget.show()
json_data.close()
bool(urlparse.urlparse(url).netloc)
hash(obj)
print(request.headers)
subList = [tempList[n:n + N] for n in range(0, len(theList), N)]
feeder_lock_object.lock()
f.columnconfigure(0, weight=1)
parser.parse(string)
ax.clear()
seen_add(element)
a[b]
self.window.show()
batch.execute(http=http)
soup = BeautifulSoup(html)
do_the_stuff(my_list)
zip(*r)
plt.subplots_adjust(top=0.55)
df.stack().loc[first:last].min()
run(reloader=True)
str(self.__dict__)
cursor.execute(CQLString)
x.pop()
np.testing.assert_almost_equal((x, x, x), (y, y, y), 5)
bar()
c.save()
fnan == fnan
zip(words[1:], words[:-1])
outsock.close()
sorted(list(range(len(a))), key=a.__getitem__)
PLT.show()
sns.regplot(x, y, lowess=True)
a[a < 0] = 0
cmp(x[1], y[1])
main()
event.SetEventObject(self)
option.click()
datetime.datetime(year=year, month=month, day=day, hour=hour)
[(i + j) for i, j in zip(list_of_urls, string.lowercase[:14])]
contents = fh.read()
print(db_data.count(with_limit_and_skip=True))
outputStream.close()
plt.show()
np.arange(lllon, urlon, 2.0),
print(a, b, c)
self.widget.click.connect(self.onWidgetClick)
xlim(0, 0.8)
print(A[0], B[0])
print(2 * math.acos(0))
max(a, key=itemgetter(1))[0]
out.close()
np.sum(np.linalg.solve(L, xdiff.T) ** 2, axis=0)
globals()[name] = value
syncdict.update([(key, syncdict.get(key) + inc)])
ax2.imshow(template, cmap=plt.cm.gray)
print(list1[-5:])
sys.exit(app.exec_())
gc.get_objects()
ASTVisitor.__init__(self)
logger = logging.getLogger(COMPANY_LOGGER)
m[:, :, ::-1]
server.terminate()
C.__init__(self)
[(y1 - x1, y2 - x2) for (x1, x2), (y1, y2) in combinations(myList, 2)]
ax = fig.add_subplot(1, 1, 1)
(b - a).total_seconds()
writer.writerow(row)
int(round(170, -2))
self.view.header().resizeSection(column, width)
test()
tdelta.total_seconds()
root.mainloop()
self.assertAlmostEqual(em(1, 2), 0.1481, 4)
print(len(request.headers))
[(x * next(cyc)) for x in lis[0]]
i = int(float(s))
ax.xaxis.set_major_formatter(mpl.ticker.FuncFormatter(myFormatter))
pprint(od, width=40)
args = parser.parse_args()
HttpResponse(status=204)
mylib.mySub.argtypes = [POINTER(c_double), c_int, POINTER(c_double)]
ax.yaxis.set_major_formatter(y_formatter)
user = User.objects.get(pk=uid)
even = list(next(iter(())) if n == 412 else n for n in numbers if 0 == n % 2)
ttk.Radiobutton(self.mainframe, value=0).grid(column=1, row=2)
print(ArrayAddition([2, 95, 96, 97, 98, 99, 100]))
map(func, *sequences)
print(float(x))
[ips_data[ip] for ip in sorted_ips]
plt.show()
reactor.run()
self.assertEqual(expected, self.nums.marshal())
self.fcall(*args)
signal.signal(signal.SIGTERM, sigterm_handler)
admin.site.register(LocationGroup)
container.grid_columnconfigure(0, weight=1)
numpy.fromiter((your_func(row) for row in X), dtype=bool, count=len(X))
time.sleep(1)
zip(*data)
self.frame.pack()
f.close()
name = CharField()
f.read()
plt.ylim(-1, 2)
[str[i:i + chunk_size] for i in range(0, len(str), chunk_size)]
l[t[0]][t[1]] = something
sorted(li, key=lambda x: x.anniversary_score)
sys.exit(-1)
np.roots([a, b, c])
main()
title = models.CharField()
plt.show()
MyInterpreter().cmdloop()
x = np.linspace(0, 2 * np.pi)
np.issubdtype(np.complex64, np.integer)
sizer.Add(widget, proportion=0, style=wx.ALL, border=5)
csv_out.close()
self.fp.flush()
print([v for v in values if len(v[1]) > 1])
str1_list == str2_list
int(s)
pprint(list(iter_rows(ws)))
ax.plot(data1)
tunnel.start()
plt.plot(x, y)
xbook.close()
pd.Series(test).where(lambda x: x != 1).dropna()
f(*args)
process.poll()
lines = [line for line in f if line.strip()]
info[2][1] == 6
Text.__init__(self, *args, **kwargs)
a, b = given_str[:len(given_str) / 2], given_str[len(given_str) / 2:]
s.reset_index()
df.reindex(all_days)
get_value(dic, 0)
mdd, start, end
fig.canvas.draw()
[a, b, c]
subprocess.call([path_to_notepad, path_to_file])
data = [(x if x.isalpha() else float(x)) for x in line.split()]
np.array([0, 1]).any()
data = self.request.recv(1024)
file = os.path.join(os.getcwd(), os.listdir(os.getcwd())[0])
plot(x, y)
dict([(elem, 0) for elem in s])
out[1:, :] += tmp[:-1, :]
ax.xaxis.set_major_locator(ticker.MultipleLocator(20))
ssh.load_system_host_keys()
keys = [k for k, v in Arr]
plt.show()
requests.get(url, stream=True)
aw2.show()
do_something(i)
out = []
q.put(urllib.request.urlopen(url).read())
print(type(parsed))
A = alpha * x * y + beta * x ** 2 + gamma * y ** 2
foo(**{key: 1, foo: 2})
json.dumps(datetime.datetime.now(), default=date_handler)
found = m.group(1)
print(response.read())
os.close(fh1)
a.reshape((-1, 5))[:, 1:4] = 100
vfunc(*np.ix_(xv, yv, zv))
email = forms.EmailField(required=True)
fib(n - 1) + fib(n - 2)
p.wait()
[push(D, k, K) for K, D in list(c.items())]
signal.signal(signal.SIGINT, signal_handler)
mask = numpy.random.choice([False, True], len(data_arr), p=[0.75, 0.25])
list(ordered_dict.values())[2]
words[0] == words[-1] == check_str
plt.ylim([0, 5])
winfile.close()
df.A.append(df.B).dropna().reset_index(drop=True)
time.sleep(2)
print([arr[i][i][i] for i in range(len(arr))])
uwsgi - H / path / to / your / virtualenv
urllib.request.urlopen(r)
print(my_queryset.query)
self.mfcChanged.emit()
deletemydict[key]
logger = get_task_logger(__name__)
a[(0, 2), :, :]
self.rect.left += self.xvel
pipe.wait()
[k for k, v in groupby(sorted(a))]
a + _(b * c)
c = [(x + [y]) for x, y in zip(a, b)]
data = numpy.fromfile(my_file, dtype=numpy.uint8).reshape(-1, N)
print([name for name in dir(B) if isbuiltin(getattr(B, name))])
sample_object.save()
print(tree.getpath(e))
os.makedirs(dest_dir)
time.sleep(5)
list(range(*args))
r, g, b = wfloat.transpose((2, 0, 1))
d = {k: v for dct in l for k, v in list(dct.items())}
f.write(urllib.request.urlopen(url).read())
numpy.random.randint(0, 1000, count) * 0.001
s.sort()
ax.plot(x, y * 2)
zip_longest(fillvalue=fillvalue, *args)
[0, 1, 1, 1, 1, 1, 1, 0],
l = [cond(i) for i in range(1, n)]
base64.urlsafe_b64encode(encoded_string)
ax.plot(x, y)
c.execute(query)
print(lxml.etree.tostring(the_doc, pretty_print=True))
screen.blit(surf2, (200, 200, 100, 100))
plt.figure(figsize=(7, 7))
sizer.Add(fsizer, 0, wx.EXPAND)
tf.matmul(tf.transpose(x), y)
logging.info(line)
main()
tree.add(2)
plt.show()
avg_sum.append(A.sum(axis=1).mean())
(self.players1.all() | self.players2.all()).distinct()
result = process.communicate()[0]
signal.signal(signal.SIGINT, signal_handler)
Gtk.main()
options = webdriver.ChromeOptions()
int(math.ceil(x / 100.0)) * 100
[i for i in a if i != [0]]
[solution for solution in solve(4)]
time.sleep(0.5)
image.astype(np.uint8)
map(lambda d: abs(d - date), dates)
sys.setrecursionlimit(100000)
cols.append(str(col))
s.cookies.clear()
dates_dict[key].append(date)
np.maximum.accumulate(Q, axis=1)
self.own_id = current_socket.getsockname()[1]
ax.yaxis.set_major_locator(ticker.MultipleLocator(20))
ax.plot(x, y)
random.shuffle(l)
stream = sys.argv[1] if len(sys.argv) > 1 else sys.stdin
obj.save()
wx.Panel.__init__(self, parent)
x = int(x)
i += 1
plt.show()
plt.setp(ax2.get_yticklabels(), visible=False)
json.dump(my_dict, f)
a.split()
sum(map(my_condition, l))
ax.add_patch(patch)
df.loc[(df[0] == k[0]) & (df[1] == k[1])] = [[v[0], v[1]]]
deletex[k]
indices = zip(*sp_matrix.nonzero())
X[np.ix_(idx, idx)]
mail.starttls()
[z0] * len(seconds)
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
p.start()
x = numpy.arange(data.shape[1])
out.value_counts(sort=False).plot.bar()
test.pop(5)
add(*l)
plt.show()
writer.writerows(clean_list)
a = fig.add_subplot(1, 2, 1)
[0, 0, 0, 0, 1, 0, 0, 0],
signal.signal(signal.SIGALRM, _handle_timeout)
array.sort(key=lambda k: (k[0] - point[0]) ** 2 + (k[1] - point[1]) ** 2)
os.open(os.devnull, os.O_RDWR)
self.setCentralWidget(self.view)
conn.rollback()
y = numpy.arange(data.shape[0])
print(dict(d))
[i for i, (a1, a2) in enumerate(zip(s1, s2)) if a1 != a2]
f_new.close()
df.as_matrix(columns=[df[1:]])
self.axes.set_title(title)
num_words += len(line.split())
image = np.zeros((max_x, max_y))
index = np.array([0, 1, 2])
new.append(l[i:i + 5])
main(sys.argv[1])
ax1.plot(list(range(0, 10)))
print(r.content)
df.to_excel(writer, index=False)
line = line.strip()
heapq.heappush(heap, (-prod2, x, y - 1))
plt.setp(g.ax_heatmap.get_xticklabels(), rotation=90)
ttypager(text)
self.add_widget(Label(text=str(data)))
type(c)(a)
A.f.__func__(b)
sys.path.append(somepath)
A = (A - mean(A)) / std(A)
buffer += ser.read(ser.inWaiting())
p = np.poly1d(np.polyfit(t, data, 2))
l.extend(t)
fig = plt.figure()
soup = BeautifulSoup.BeautifulSoup(data)
ax1.set_color_cycle([cm(1.0 * i / (NPOINTS - 1)) for i in range(NPOINTS - 1)])
new_list.append([some_tuple])
pir(df)
self.figure.canvas.draw()
ax.imshow(X, cmap=cm.jet)
f.write(image_response.read())
ax.set_xlim(-1, 7)
df.merge(melted_items, left_index=True, right_index=True)
[x for x in data if func(x)]
recur(n - 1, count + 1)
self.response.write(name)
document.append(line)
[x for x in range(len(self.states)) if self.states[x]]
plt.show()
series.hist(bins=division)
driver = webdriver.Chrome()
plt.plot(list(range(10)))
not any(d.values())
plt.show()
dict((x, duplicates(List, x)) for x in set(List) if List.count(x) > 1)
print(r[i:i + n])
print(new_dic)
self.assertAlmostEqual(em(1, 1), 0.6407, 4)
a.sort(key=key, reverse=True)
print(year_fraction(datetime.datetime.today()))
print(counter.most_common())
numpy.nextafter(1, 0)
element.clear()
df.ix[yesterday.strftime(fmt):now.strftime(fmt)]
fig.canvas.draw()
print((f.__name__, f.__hash__))
plt.setp(ax2, xticks=[], yticks=[])
win.set_keep_above(False)
child.interact()
plt.xlim([0, 1])
ax1.set_color_cycle([colormap(i) for i in np.linspace(0, 1, number_of_plots)])
a.remove(10)
fig.autofmt_xdate()
df.join(pd.concat([pd.DataFrame(s).T] * len(df), ignore_index=True))
0, 1, 0, 1
signal.alarm(0)
urllib.request.install_opener(opener)
(a1[:, (numpy.newaxis)] == a2).all(axis=2)
OrderedDict(sorted(list(d.items()), key=lambda t: t[0]))
collections.Counter(lst)
ax.fill_between(np.arange(1, 10), 1, 2, zorder=-1, **kwargs)
id = Column(Integer, primary_key=True)
frame.Show()
df.columns = zip(*col_names)[1]
float(x) / float(x)
print(url_without_query_string)
img.putdata(my_list)
urllib.request.install_opener(opener)
self.canvas = tk.Canvas(self, width=100, height=100)
data = json.loads(json_input)
reactor.run()
B = np.array([2, 4, 6, 8])
[x for x in l1 if not any(fnmatch(x, p) for p in l2)]
f.close()
self.video_out.release()
uniq_animal_groups = set(map(tuple, animal_groups))
fig, ax = plt.subplots(2, 1)
outfile.close()
db.session.commit()
conset = set(map(frozenset, consarray))
a[::-1]
print(message.get_payload())
astar(formation, heuristic, solution, getneighbors)
zip_longest(fillvalue=fillvalue, *args)
sum(masked, axis=1)
a.tolist()
set(df.Col1) | set(df.Col2)
data = [str(float(fractions.Fraction(x))) for x in data]
self.driver.close()
[1][2][2]
admin.site.register(FooProxy, FooAdmin2)
(datetime.datetime.min + value).time()
jsonpath.jsonpath(data, path)
new_dict = dict(list)
a = np.arange(100)
time.sleep(0.1)
reader = io.open(sys.stdin.fileno())
PLT.show()
np.random.seed(0)
series[10] = np.nan
matplotlib.pyplot.close()
np.nanargmax(a, axis=1)
file = zipfile.ZipFile(BytesIO(request.content))
msglist = list(chunkify(hextotal, 4096))
ax.xaxis.set_minor_locator(MultipleLocator(0.2))
django.setup()
shutil.copyfileobj(infile, outfile)
celery.start()
x.reshape(x.shape[0], -1).shape
Response(UserSerializer(request.user).data)
[Factorial(x) for x in it]
f()
np.roll(a, -2)
fp.close()
gca().get_xaxis().get_major_formatter().set_useOffset(False)
myfunc()
res.cumsum().applymap(lambda x: np.unique(list(x)))
plt.show()
p.start()
pd.DataFrame(v[i0:i1], df.loc[df.name].index[i0:i1], df.columns)
new_string
connection.disconnect()
type(a).__call__(a)
f.write(chunk)
b.sort(key=order.get)
self.setWindowFlags(Qt.FramelessWindowHint)
print(f.read())
ax.plot_surface(x, y, 10, rstride=5, cstride=5, facecolors=img)
im = img.load()
self.__class__.__name__
print(df.reset_index())
[1, 2]
[list(g) for k, g in groupby(a)]
self.start.connect(self.run)
plt.bar(J2 - 0.5 * width, z(J2), width=width)
csv_fileh.seek(0)
User.objects.get(pk=user_id)
ee.save()
max(n for n in a if n < 0.7)
{{raw | unquote_raw}}
inspect.getargvalues(traceback.tb_frame)
dict.__delitem__(self, key)
p.start()
a if b else c
instance.save()
df
l = np.array([[0, 0], [0, 1], [1, 1]])
[1][2][1]
r = requests.post(url, files=files, data=values)
pprint({key: getattr(f, key) for key in dir(f)})
self.fig = mplfig.Figure(figsize=(5, 4), dpi=100)
frec(word)
keys = set()
ax.bar(list(range(len(dates))), values, width=width)
module1.f()
s.run()
app = QtGui.QApplication(sys.argv)
nums.sort(key=functools.cmp_to_key(lambda x, y: cmp(y + x, x + y)))
plt.legend(handles=legend_patches)
ssh_client = paramiko.SSHClient()
print({i: f.lower() for i in nums for f in fruit})
request.finish()
print(cursor.fetchall())
df.reindex(ind - ind2).join(df2.reindex(ind - ind2))
inithello()
base64.b64decode(a)
ax.scatter(x, y)
np.shape(result)
reader = csv.reader(f)
plt.show()
df.index.get_level_values(0)
p.plot(x, y)
fig, axes = plt.subplots((2, 2))
time.sleep(0.1)
plt.pcolormesh(X[0:1], Y[0:1], C[0:1])
newList = [word for word, mask in zip(s, b) if mask]
mask[y:y + h, x:x + w] = img[y:y + h, x:x + w]
zip(*([iter(l)] * 2))
server.sendmail(FROMADDR, TOADDRS, msg)
out.close()
db.put(1)
df.loc[i] = [float(d) for d in data]
len([i for i in x if 60 < i < 70])
(df == 0).astype(int).sum(axis=1)
b = a[m]
board.append([])
destination.close()
y = x[1:] - x[:-1]
c.coords(x)
plot(x, sin(x))
instance._meta.app_label
subprocess.Popen(SCRIPT % filename, shell=True)
python - V
plt.ion()
next(p)
x.astype(int)
sys.stdout = old_stdout
[x for x in l if x not in f]
[x for i, x in enumerate(a) if i in indices]
list(intermix([1, 0, 1, 1, 2, 1, 0, 1, 1, 1, 2]))
a()
Silly(0)
ax.yaxis.set_visible(False)
[id(i) for i in x]
plt.figure(1)
double([1, 2])
fig.canvas.draw()
int(s)
app.MainLoop()
isinstance(x, int)
sorted(array, key=lambda x: x is 0)
c.append(l)
main_sizer.Add(content_sizer, 1, wx.EXPAND)
a = A(10)
file.seek(0, os.SEEK_END)
print(url)
ax.set_ylim(0, max_height)
a[i] = d.get(a[i], a[i])
surround.py
result.append(item)
self.show()
xl.ActiveWorkbook.Close(SaveChanges=1)
driver.switch_to_default_content()
out, err = proc.communicate()
fig = plt.figure(figsize=(10, 5))
shout.start()
list(f([9, 8], [2, 1]))
map(int, testList)
img.show()
print((a, b))
wrapper(fn(*args, **kw))
[ulist.append(x) for x in l if x not in ulist]
print(a, b, c, d)
plt.show()
sys.stdout.write(line)
user().key().id()
unbroadcast(y).shape
plt.show()
z, x, y = d.nonzero()
text = str(encoded_string, the_encoding)
arr[:] = [a, b]
a1[mask.A] = 0
ax2.yaxis.get_offset_text().set_color(plot_ax2.get_color())
[item for item in mylist if item.isalpha()]
thread.start_new_thread(loop0, ())
[n]
plt.show()
ax.set_theta_direction(-1)
graph.tree().pprint()
np.where(binplace == 2)
self._numberButtons[i].clicked.connect(lambda i=i: self._number(i))
self.listbox.pack(padx=10, pady=10)
setattr(self, key, value)
do_post_install_stuff()
print(k, a[k])
data = s.recv(4096)
app.exec_()
print(Foo.bar.__get__)
uniques[col].update(chunk[col].unique())
ax.yaxis.set_ticks([])
sys.exit(1)
f.write(s)
print(df1[[0, 7]])
l = [s.name for s in sections]
self.transport.loseConnection()
self.suggestions.append(a[1])
p.map(g, list(range(10)))
self.name
time.sleep(1)
print(user_result)
subprocess.call(cmd, stdin=fd)
df.drop(df.index.get_duplicates())
[0, 0, 1, 1, 1, 1, 1, 0],
self.selenium.start()
os.kill(int(pid), 0)
app.exec_()
(x & -x).bit_length() - 1
show()
print([[(each - x) for x in l] for each in l])
dir()
writer = csv.writer(f)
a = 1 if x < 1 else 10 if x > 10 else x
B = A[0]
yourdate = dateutil.parser.parse(datestring)
plt.show()
a[:, :, :, (0)].flatten()
ax.yaxis.labelpad = 20
json.dumps(_data, indent=4)
plt.show()
descendents_ancestors.add(descendent)
min(dates, key=lambda d: abs(d - date))
plt.show()
mask.reshape(-1, 20).sum(1)
sleep(1)
df.loc[mask]
logger.setLevel(logging.INFO)
api.update_status(status=single_tweet)
print(nat.Poland)
output.writeframes(data[0][1])
self.thread = threading.Thread(target=self.run, args=())
print(df.to_csv(index=False, header=False))
ax.set_ylim(-40, 40)
pd.concat(vals, axis=1, keys=keys, **kwargs)
obj.save()
root = Tk()
plt.show()
process.poll()
categories = Category.filter(animals__in=animals).all()
s.sendmail(me, you, msg.as_string())
l.extend([pad] * (n - len(l)))
b = list(a)
df.plot()
map(list, zip(*lis))
size = sum(1 for _ in bucket.objects.all())
x, y = np.ogrid[:shape[0], :shape[1]]
ax.set_axis_off()
start.mainloop()
set(chain.from_iterable(df.genres))
db = client.get_default_database()
df.idxmax()
sys.exit()
[row.tostring() for row in data]
np.vstack(np.hsplit(a, m / k))
plt.show()
Z[np.where(Z == 0)] = np.nan
cv2.CV_FONT_HERSHEY_SIMPLEX
self.SetIcon(icon)
context.pop()
x += tuple(y)
audio.save()
plt.plot(xvalues, yvalues)
setattr(self, attr, getattr(student, attr))
pts = [(10, 10), (10, 11), (20, 11), (20, 10), (10, 10)]
ii = (s1 ** 2 + s2 ** 2 < 1).sum()
GL.glVertexAttribPointer(self.loc, 1, GL.GL_FLOAT, GL.GL_FALSE, 0, 0)
p2.stdout.close()
pg.draw.rect(surf, STIMCOL, (10, 20, 40, 50))
lst[i:] + lst[:i]
json.dump(pickle.load(fpick), fjson)
inF.close()
x_new = sparse.lil_matrix(sparse.csr_matrix(x)[:, (col_list)])
print((f, b))
scipy.stats.linregr(X, Y)
{k: (v() if callable(v) else v) for k, v in a.items()}
plt.show()
pd.get_dummies(s1[s1.notnull()])
time.sleep(1)
toppings = forms.ModelMultipleChoiceField(queryset=Topping.objects.all())
df_norm.max() - df_norm.min()
browser = webdriver.Chrome(chrome_options=co)
self.send(response.toXml())
print(count.most_common(16))
[(a, b, c) for a in range(x + 1) for b in range(y + 1) for c in range(z + 1)]
f.seek(0, os.SEEK_END)
plt.show()
traceback.print_exc()
app.MainLoop()
forwarder.write(serial_out)
root = Tk()
GpsPoint(self.x + other, self.y + other, self.z + other)
tuples.remove((entry[1], entry[0]))
plt.scatter(latt, lont, c=uniqueish_color(len(latt)))
f.write(data)
ax.set_yticklabels(map(str, list(range(90, 0, -10))))
data.most_common(1)
response = urllib.request.urlopen(req)
ax.yaxis.set_visible(False)
logger.addHandler(handler)
set_keyring(PlaintextKeyring())
map(int, temps)
self.button.pack()
print(args.bar)
window.show_all()
np.random.seed(seed)
l = math.floor(math.log10(i)) + 1
list(collection.questions)
entry_list.extend(x.title.text for x in feed.entry)
a.sort(key=operator.itemgetter(1))
random.random() < probability
bin(100)
df2.reindex(ix)
[multiply(*pair) for pair in zip(iterA, iterB)]
plt.plot(x_fit, y_fit)
min(data, key=operator.itemgetter(1))
y = np.linspace(0, 1, 20)
serializer.save()
groups.append(list(g))
print(dishes[key])
self.SetTitle(str(event.GetSize()))
x, y = zip(*li)
[(x[0] * x[1]) for x in result]
c[a | b]
admin.site.register(ModelMock)
list(np.array(a) - np.array(b))
sys.stdout.write(next(spinner))
curses.endwin()
obj.__dict__[prop]
theclass
any(lst[i:i + ln] == sub for i in range(len(sub) - ln + 1))
str(str(self))
sys.modules[__name__] = ModuleClass()
n * (n - 1) * 2
[node() for _ in range(100)]
title = CharField()
proc.stdin.write(text)
current_time = time.time()
plt.ylim([0, 1])
[(y - x) for x, y in it.combinations(a, 2)]
df.buyer_id = df.apply(make_buyer_id, axis=1)
np.linalg.inv(a)
lst = ast.literal_eval(strab)
app = Flask(__name__)
max(MyCount, key=int)
ax = fig.add_subplot(111)
sp.Matrix(np.diag(d - 4) + 4)
print(random.triangular(0, 1, 0.7))
print([(i, sum(j)) for i, j in list(d.items())])
p.stdin.close()
urllib.request.install_opener(opener)
r = int(s)
lines.pop(0).remove()
plt.hold(True)
platform.version()
[1, 0, 1, 1, 0, 0, 0, 1],
print(eventdata)
logger.setLevel(logging.INFO)
pos = nx.spring_layout(G)
content = browser.page_source
wb.save(stream)
time.sleep(1)
shutil.rmtree(TEST_OBJECTS_DIR, onerror=on_rm_error)
a.update(1)
a.bit_length()
print(match.groups())
i = s.index(t.lower())
serializer.is_valid()
self.connection.close()
db.session.commit()
[datetime.datetime(2012, 1, 1, 0, 0), datetime.datetime(2012, 1, 1, 1, 0)]
df.apply(lambda row: get_nth(row, n), axis=1)
result.extend(list(range(a, b + 1)))
data_cluster.fit(data_numeric)
x.dtype
index_list(l)
docvec = model.docvecs[99]
self.save()
time.sleep(1)
list2 = [[item[i] for item in list if len(item) > i] for i in range(0, 100)]
client.close()
(1, 2) in d
print(list(kwargs.items()))
result = DataFrame(list(cursor), columns=tweet_fields)
draw.ellipse((0, 0) + size, fill=255)
print(__file__)
list(itertools.product(a, b))
form = forms.ChapterForm(request.POST, request.FILES, instance=chapter)
(df[self.target] == t).any()
cfloats[i] = pyfloats[i]
np.argmin(myList)
[list(zip(a, p)) for p in permutations(b)]
print(type(im))
signal.signal(signal.SIGINT, signal.SIG_IGN)
br.set_handle_refresh(mechanize._http.HTTPRefreshProcessor(), max_time=1)
print(info.get_content_maintype())
self.lock.acquire()
aDict[name].append((startTime, endTime))
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
pool = multiprocessing.Pool()
list.pop(self, *args, **kwargs)
urllib.request.install_opener(opener)
browser.show()
out.append(l[new_i].pop(random.randint(0, len(l[new_i]) - 1)))
print(sqrt(2))
dest_file.close()
set().union(*lis)
values = list(dictionary.values())
matrix = [line.rstrip() for line in infile]
np.where(a > 5)[0][0]
a.astype(numpy.int64)
mylist = [p for i, p in enumerate(mylist) if i not in remove]
int(s)
plt.show()
main()
unittest.main()
filename = input()
sleep(1)
f.write(file_data)
sess = tf.Session()
x_2, y_2
sys.stdout.write(line)
ax.set_xticks(np.arange(len(dates)) + width / 2)
serializer = UserSerializer(user, data=request.DATA, partial=True)
format_to_year_to_value_dict.setdefault(format_str, {})[year] = value
x = array([0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1], dtype=np.bool)
subprocess.Popen(shlex.split(command))
print(f.__self__)
session.add(another_obj)
[1, 0, 0, 0, 0, 1, 0, 1],
print(np.array([i, j], dtype=np.int64))
iter(self.__dict__)
decimal.Decimal(x.seconds)
_(1, 4)
reactor.run()
logging.getLogger().setLevel(logging.INFO)
form = CustomQueryConstraintForm(initial=request.POST)
process.kill()
self.fig.canvas.draw()
match = re.search(pat, s)
new_df = pandas.DataFrame.from_dict(a_dict)
b = np.array([1.0, 0.9, 0.8, 0.7, 0.6])
ax.scatter(theta, r)
response = requests.get(bl_url, headers=headers)
print(polygon(4, 2, math.pi / 4, [10, 10]))
self.canvas.after(10, self.move)
p.wait()
list(hex_list)
self._handler.close()
self.show()
-np.linalg.det(self.state)
ax.imshow(data)
print(r.content)
data.remove(row)
[0, 0, 0, 0, 0]
session = requests.session()
[(x == y) for x, y in zip(s, t)]
current_milli_time()
self.lock.release()
random.shuffle(c)
((int(x), int(y)) for x, y in split)
{{form.as_p}}
sys.exit(1)
print(make_hash(Foo.__dict__))
print(test._tests)
self.rect.top += self.yvel
print(list(get_names(func)))
main()
a.remove(b)
inithello()
sys.exit(main())
printFoo()
{{analytics_code}}
v = fbx.FbxVector4(x, y, z)
newdict.update(mydict)
grequests.map(rs)
TaskBase.__call__(self, *args, **kwargs)
main()
random.shuffle(row)
sys.getwindowsversion()[0] >= 6
d[k].add(v)
map(flat_tuple, a, b, c)
OrderedDict.__getitem__(self, key)
l = [0] * 10000
b[0].append(1)
sorted(lst)
area += (p1[0] - p0[0]) * ((p1[1] + p0[1]) / 2 if trapezoid else p0[1])
show()
time.sleep(5)
sys.stderr.close()
setattr(self, name, kwargs[name])
img.resize((width, height), Image.ANTIALIAS)
pdb.set_trace()
print(intersects(a, b))
print(dict(customers))
canvas.pack()
k, v = random.choice(list(d.items()))
data = f.read()
rgb_values.pop(-1)
{k: (v / len(list_of_dicts)) for k, v in list(summed.items())}
MyModel.objects.filter(created__isoyear=year, created__week=week)
getattr(hello, m)()
string.ascii_lowercase[:14:2]
scipy.optimize.fsolve(g, 0.0)
list(params.items())
items = list(dictionary.items())
nltk.clean_html(html)
do_something_useful()
someList.sort(key=key2, reverse=True)
soup = BeautifulSoup.BeautifulSoup(doc)
print(dateparser.parse(date_string).date())
os.path.join(path, fname)
ax.get_xticklabels()[i].set_visible(False)
service.files().copy(fileId=originalId, body=newfile).execute()
self.run.grid(row=4, column=0, sticky=EW)
df_new
json.dump(sample, fp)
f(1)
self.Show()
(b - a).seconds
len(self.__dict__)
sys.stdout.flush()
browser.submit()
ax = plt.subplot(111)
loader.construct_yaml_map(node)
inspect.getmembers(a, predicate=inspect.ismethod)
df.isnull().any(axis=1)
myClass.__subclasses__()
print(L[i])
infile.close()
frame1.axes.get_yaxis().set_visible(False)
fig.autofmt_xdate()
{k: c[k] for k in li}
output.append(sublist[0])
ws.append(l)
elem.clear()
[zip(x, list2) for x in itertools.permutations(list1, len(list2))]
ax2.set_xlim([0, repeat_length])
plt.figure()
ax.set_xlim(-40, 40)
self.finish()
time.sleep(1)
imshow(Z1, cmap=cm.hsv, alpha=0.6, extent=extent)
unittest.main()
time.sleep(5)
result = pattern.sub(lambda x: d[x.group()], s)
sleep(1)
all(x >= y for x, y in zip(L, L[1:]))
[v for v in x2 if v[1] == optimal[0] and v[2] == optimal[1]]
today = datetime.datetime.today()
df[1].apply(pd.Series)
s.get_data()
app.run()
ssh_client = paramiko.SSHClient()
data = json.loads(file)
mystr.replace(k, v)
getattr(self._i, n)
result = sorted(iter(promotion_items.items()), key=item_value)
print(x.task_id)
sorted(s, lambda x, y: cmp(x.lower(), y.lower()) or cmp(x, y))
value = next(iter(some_collection))
self.__dict__.update(_dict)
my_list
time.sleep(10)
self.builder.add_from_file(self.glade_file)
math.isnan(math.nan)
a[np.arange(a.shape[0]), entries_of_interest]
d = math.floor(sdl2.SDL_ALPHA_OPAQUE * (math.ceil(s) - s) + 0.5)
time.sleep(1)
[list(comb) for i in range(1, n + 1) for comb in itertools.combinations(x, i)]
startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
shlex.split(raw_args, posix=False)
A = numpy.vstack([A, newrow])
logging.Formatter.converter = time.gmtime
bar.baz[a:b:c].foo()
mainFrame.grid()
writer.writerows(worksheet.get_all_values())
number += 1
sys.stdout.flush()
logging.getLogger(className)
len(set(sum(a, [])) & set(b) & set(c).is_empty()) > 0
MySuperClass.__init__(self)
t.start()
QtGui.QWidget.__init__(self, parent)
A.remove(i)
plt.legend(numpoints=1)
out.read()
list(y)
clf.fit(X, y)
print(root.winfo_width())
a = np.arange(10)
logger.setLevel(logging.DEBUG)
httpd.serve_forever()
person.delete()
client = requests.session()
my_list.pop()
self._getlock()
df[[iscomedy(l) for l in df.genre.values.tolist()]]
element = min(myset)
some_object = klass()
form.save()
app.start()
ax.add_patch(rect)
list.append(run(*i))
conn.commit()
min(max(start, num), end)
group in user.groups.all()
y = odeint(func, 0, t)
np.delete(arr, index, 0)
np.vstack([A[i:i - width] for i in range(width)]).T
message.save()
t.isoformat()
[word.strip(string.punctuation) for word in text.split()]
f.write(response.body)
timestamp = (dt - datetime(1970, 1, 1)).total_seconds()
f_out.write(data)
ax.xaxis.set_major_locator(ticker.FixedLocator(x))
ax1.plot(pd.Series(np.random.uniform(0, 1, size=10)))
plt.show()
seq.sort()
print(map(itemgetter(1), g))
[i for i, elem in enumerate(lst) if condition(elem)]
time.sleep(0)
a = list(range(10))
any(i) and not any(i)
result = np.array(list(ranges(intersect(a, b))))
main.py
list(grpname.keys())
list(subgrpname.keys())
print(df)
pylab.show()
ax.add_patch(unmanhattan_patch)
ax = fig.add_subplot(111)
EmailThread(subject, html_content, recipient_list).start()
pd.rolling_mean(aapl, 50).plot()
arr[mask != 5] = 0
writer.writeheader()
self.root.quit()
set(b1).intersection(b2)
fig, ax = plt.subplots()
a.sort(key=lambda v: v != 0)
a[mask] = 888
print(Child.getId())
plt.plot(x, y, color=(r, g, b))
A().test()
[mapping[value] for value in a1 if value in mapping]
mask = pd.Index(base).union(pd.Index(base - 1)).union(pd.Index(base + 1))
JsonResponse(posts_serialized, safe=False)
a = np.array(t)
send_thread.daemon = True
bigdata = data1.append(data2, ignore_index=True)
result = collections.defaultdict(lambda : collections.defaultdict(list))
time.mktime(utc_tuple) - time.mktime((1970, 1, 1, 0, 0, 0, 0, 0, 0))
calendar.timegm(time.gmtime(0))
b = A[(2), :].copy()
key = sum(map(itemgetter(play)))
win.show()
app.register_blueprint(auth_blueprint)
libtest2d.print_2d_list(arr2d.shape[0], arr2d.shape[1], arr2d)
result += [[x, y, z]]
np.linalg.inv(b)
testclassb().testmethod2()
self.response.out.write(filename)
raise tornado.web.HTTPError(404)
writer.writerow(header)
lst = [maybe_int(s) for s in lst]
np.arange(100, 1, -1)
[x for x in a if x not in b]
thread.start()
op(x, y)
self._stdout = sys.stdout
ax.set_xticks(np.arange(AUC.shape[1]) + 0.5, minor=False)
objc.__version__
list(IT.izip_longest(readers[0], readers[1], readers[2]))
plt.draw()
print(data[:, :, :, (1)])
im = Image.open(filename)
session2.add(new_item)
c = np.hstack((a[a_inds], b[b_inds]))
f.close()
dict[firstname] = dict.get(firstname, 0) + 1
create_engine(db_connect_string, connect_args=ssl_args)
deletelst[len(lst) - n:]
stringaxis.setTicks([list(xdict.items())])
b = zip(*a)
time.sleep(1)
b.__class__
imshow(X, norm=norm)
Counter(protein[i:i + 6] for i in range(len(protein) - 5))
iter(f)
models.ForeignKey(EntryAdmin)
a, b, c, d = map(float, line.split())
timeit.timeit(lambda : timeit.timeit(f), number=100)
data.dtype.names
pyplot.plot(x, y)
time.sleep(1)
args = parser.parse_args()
ax.legend()
app.exec_()
canvas.pack()
ax.set_xlim(0, 2 * np.pi)
driver = webdriver.Firefox(profile)
hex(ord(chars[0]))
x = x + 1
c = pygame.time.Clock()
s.send_message(msg)
df.reset_index(inplace=True)
x.append([])
audio_data, pyaudio.paContinue
z = np.sqrt(x ** 2 + y ** 2) + np.sin(x ** 2 + y ** 2)
ax.set_ylim(min(y), max(y))
format_elements(reduce_list(some_list))
self.progbar.start()
tk.Toplevel.__init__(self, *args, **kwargs)
label.pack(padx=4, pady=4)
self.app = Flask(__name__)
shutil.copyfileobj(src, dest)
plt.show()
temp.sort()
db.put(groups)
print(sum(sum(map(int, r.findall(line))) for line in data))
self.window.set_border_width(8)
server.serve_forever()
device.dispose()
max(hand, key=lambda c: rank_cards.index(c[0]))
a = [[0] * ROWS] * COLUMNS
self.out.write(bytearray([self.accumulator]))
A = np.empty((15, 15))
client_sock.close()
app = QtGui.QApplication(sys.argv)
ax1.set_ylim([0.1, 10])
offset = datetime.fromtimestamp(0) - datetime.utcfromtimestamp(0)
fig = plt.figure()
analysed.add(color)
[(a if tC else b) for i in items if fC]
result.predict(np.vander(x_new, degree + 1))
max(elements, key=lambda e: int(e[0]))
[e for sub in tgt if isinstance(sub, (list, tuple)) for e in sub][-5:]
print(sum(a * b for a, b in combinations(xList, 2)))
x = np.array([0, -1, -1, 0, 1, 1])
itertools.product(list(range(2)), repeat=n)
print([dict(zip(keys, items)) for items in res])
plt.matshow(M, cmap=plt.cm.Blues)
all_challenges = session.query(Challenge).all()
all_pixels.append(luma)
print(soup.prettify())
[(key, other) for key in keys for other in prefixes[key[1:]]]
sys.exit(1)
plt.rcParams.update(params)
foo.__defaults__
a = np.fromiter(Data, dtype=np.float, count=DataLength.value)
np.random.shuffle(indices)
result.update(d)
fluidsynth.play_Note(64, 0, 100)
screen.blit(surface, (0, 0))
issubclass(test, object)
parser.parse_args([])
some_list[start:stop:step]
df[:5]
doctest.testmod()
client = Client(url, transport=ntlm)
win.add(vbox)
x = [False, True, True, False]
id = Column(Integer, primary_key=True)
np.fromiter(a, dtype=np.float, count=100000)
a.exec_loop()
server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
ax = fig.add_subplot(111)
pprint.pprint(output)
plt.show()
{a: 1, b: 2}
cppcode.init()
print(json.dumps(data, indent=4))
sys.exit(app.exec_())
d + timedelta(weeks=week - 1, days=-d.weekday())
base64.b64encode(bytes([foo]))
self.lineedit.setFocus()
pd.concat(df_list, ignore_index=True)
app_log.addHandler(file_handler)
self.belltimer.Start(1000)
ax.set_zlim((0, 50))
filename = tkFileDialog.askopenfilename(filetypes=FILE_DIALOG_FILETYPES)
app = Flask(__name__)
ax.plot(x, y * 10)
self._shape = self._shape[0] - 1, self.shape[1]
m.group(1), int(m.group(2))
my_list.sort(key=lambda elem: [my_alphabet.index(c) for c in elem[0]])
pd.DataFrame(zip(X.columns, np.transpose(model.coef_)))
test.py
dict((k, sum(map(itemgetter(k), dict1))) for k in dict1[0])
ws = wb.active
args = parser.parse_args()
f.close()
out = np.add.reduceat(X[:, (idx0)], cut_idx, axis=1)
len(set(str_.split()) & set(dict_1.values()))
maxu2().sum()
subprocess.list2cmdline(args)
m[list(zip(*map(range, m.shape)))] = 0
db.commit()
HTML_with_style(df.head())
self.SetSizer(self.sizer)
print(df.sum(1).to_frame())
pprint.pprint(yourDict)
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
new_matrix.append(matrix[i])
self.children = weakref.WeakValueDictionary()
sys.path.append(path_to_parent)
a, b = zip(*my_list)
os.chdir(default_path)
ax = fig.add_subplot(111)
df.reset_index(drop=True)
json.dumps(rh)
deleteL[len(L) % 2::2]
Tkinter.mainloop()
bSizer.Add(button6, 0, wx.ALL, 5)
bSizer.Add(button7, 0, wx.ALL, 5)
bSizer.Add(button8, 0, wx.ALL, 5)
new_list = [foo for foo in foos if foo.location == 2]
plt.xlim([0, bin.size])
objs[0].do_sth()
ast.literal_eval(s)
frame.focus_set()
out[-1]
axborder.set_axis_off()
print(le.tostring(doc))
file.close()
file.close()
cursor.execute(sql)
self.assertOK(response)
thread.start_new_thread(updateCounter, ())
list(range(0, 1)) == list(range(0, 1))
(a - a[0] == 0).all()
print(datetime.now() - start)
a = models.ForeignKey(Foo, default=lambda : Foo.objects.get(id=1))
print(add.addtwo_(byref(a), byref(b)))
plt.show()
reactor.run()
groups.append(list(g))
{{form.title}}
C / C.astype(np.float).sum(axis=0)
writer.writerow(row)
os.listdir(short_unc)
c = a[2:]
mean = A.mean(axis=1)
r = requests.post(post_url, data=json.dumps(payload), headers=headers)
pygame.display.flip()
tm += datetime.timedelta(minutes=10)
bool(b)
datetime.datetime(*map(int, values))
argv.pop(0)
plt.figure()
timer.start()
time.sleep(10)
self.cmdloop()
timedelta(seconds=_diff.total_seconds()) - timedelta(wek)
json.dumps(message)
cvtColor(src, gray, COLOR_BGR2GRAY)
print(f.readlines()[1:15])
lists = [[]] * 5
s.send(data_string)
ax.cla()
[x for x in s.lower() if x in string.ascii_lowercase]
all_pairs.sort(key=lambda p: distance(p[0][0], p[1][0]))
zfile.close()
time.sleep(random.random())
b.save()
keys = list(test)
gtk.main_quit()
day_list.index(inp)
print(x, categorize(x))
np.sum(np.log(np.arange(1, n + 1)))
s.ioctl(socket.SIO_RCVALL, socket.RCVALL_OFF)
plt.plot(np.arange(10), 4 * np.arange(10))
out_file.write(line)
plt.plot(y)
time = models.FloatField()
cooler()
circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT)
v.toPyObject()[0]
Page.objects.published()
df.iloc[:10, :5]
[map(second, row) for row in data]
list(filter(str.isdigit, text))
n = re.findall(pattern, string)
ax.set_xticks(indeces)
self._fd.close()
a * np.exp(-c * x) + d
root = Tk()
dict(counts)
area = area1 + area2
C.f(2)
self.stop()
main(sys.argv)
output = p2.communicate()[0]
threading.Thread(target=cli).start()
ax.xaxis.set_major_formatter(formatter)
sys.exit(0)
r._meta.id
np.array(mp.arange(600))
repo.pull()
plt.xlim([0, n])
task.react(main_task)
[value for value in the_list if value != val]
result.append(c)
driver.set_window_size(1024, 768)
lis.sort(key=itemgetter(1))
self.request.route_url(name, id=self.id, **kw)
self.target(*args, **kwargs)
obj.save()
wb.Close()
lambda x: f(g(x))
time.sleep(1)
plt.subplots_adjust(left=0.2, bottom=0.2)
q.open()
list(unique_everseen(a, key=frozenset))
codecs.BOM_UTF8
chi2_contingency(data)
datetime.strptime(text, fmt)
response.status_code
canvas.place(x=5, y=height + 10)
unittest.main()
model.setData(index, newValue, QtCore.Qt.EditRole)
[5, 6, 7, 8, 9]
ndimage.gaussian_filter1d(np.float_([0, 0, 0, 0, 1, 0, 0, 0, 0]), 1)
total = sum(total)
print(mystring[:1])
data[k].append(fitem(v))
Thread(target=serve_on_port, args=[1111]).start()
sum(1 for i in x if 60 < i < 70)
list(chain.from_iterable(result))
print(p.url)
axarr[0].set_xticklabels(map(str, axarr[0].get_xticks()))
p.start()
writer.writerow(d)
c.__getattribute__
print(Decimal(2) ** Decimal(2))
c.add(1).cumprod()
__metaclass__ = Singleton
text = pattern.sub(lambda m: rep[re.escape(m.group(0))], text)
print(df.groupby(lambda x: x.month).agg([min, max, np.mean]))
mlab.show()
xl.Quit()
Counter(data).most_common()
p1.wait()
social.set_extra_data(extra_data)
main()
print(paths(p)[0])
elapsed_time = time.time() - start_time
print(np.sort(x)[-10:])
my_randoms = random.sample(range(100), 10)
grid.cbar_axes[2].colorbar(im2)
l = [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 2, 2, 2]
process.wait()
runInParallel(func1, func2)
mainloop()
[Link(url, text) for url, text in urlstext]
driver = webdriver.PhantomJS()
HttpResponseRedirect(settings.LOGIN_URL)
stdout, stderr = p.communicate(in_string)
self.timeout.cancel()
self.name = name
ax.set_xticks([])
response.read()
Base.metadata.create_all(engine)
filter_func(parent_dict, func)
f.seek(0, 0)
t.date()
print(cur.fetchall())
s = pd.Series([2], index=[2])
result.append(x)
tuple(int(i * 255) for i in colorsys.hsv_to_rgb(h, s, v))
process.wait()
[a[i] for i in b]
asyncore.loop()
wd.config(height=500, width=500)
plot.rcParams.update(params)
print(list(chain(*A)))
quit()
self.label.pack()
lines = infile.readlines()
A.__init__(self, n)
rows, cols = X.nonzero()
root.mainloop()
print(ndimage.zoom(data, (1, 2, 2)))
df = df.stack().sample(frac=0.8).unstack()
cur.execute(sql, macs, host)
dict2 = dict1.copy()
[0, 0, 0, 0, 0, 0, 0, 0, 0, 164],
my_list.extend([int(i) for i in row if i.isdigit()])
print(Dummy())
[[4, 2, 6], [8, 10, 12], [6, 4, 6]]
{{user.username | e}}
Model.objects.filter(filters_for_query)
table[0][1]
r = s.post(url, data=data)
[2, 5]
[1, 1, 1, 0, 1, 0, 0, 1],
list(gen())
m = np.log10(np.abs(x))
print(hex(res))
date = datetime(year=int(s[0:4]), month=int(s[4:6]), day=int(s[6:8]))
[lst[i::n] for i in range(n)]
ax.xaxis.set_major_formatter(date_format)
self.__addL__[self.number][x]
container.grid_rowconfigure(0, weight=1)
issubclass(B, A)
self.response.out.write(json.dumps(response))
s.add(item)
max(depth(self.left), depth(self.right)) + 1
myprocess.kill()
sys.stdout.write(sio.getvalue())
self.parent.x
datetime.now() + relativedelta(weekday=FR(-1))
plt.show()
manager.start()
sys.executable
f(x)
graph = facebook.GraphAPI(oauth_access_token)
console_handler.setLevel(logging.DEBUG)
match = next((x for x in a if x in str), False)
[0, 0, 1, 1, 0, 1, 1, 0],
plt.plot(x, y)
zip(x, y, z)
id9, Wood, moreinfo9
show()
print(etree.tostring(elem, pretty_print=True))
x[0][0][1] = 111
cv2.waitKey(0)
gimpfu.main()
form.save()
doc = etree.fromstring(xml)
array([np.linalg.solve(x, identity) for x in A])
self.append(x)
[x for x in a if x.size > 0]
q.interruptable_get()
np.random.choice(elements, 10, p=probabilities)
plt.plot(xdata, ydata)
all(is_okay(s) for s in some_array)
rect.set_height(h)
dict(urlparse.parse_qsl(urlparse.urlsplit(url).query))
screen = pygame.display.set_mode((500, 500))
name = module.name
soup = BeautifulSoup(html)
np.nanargmax(a, axis=0)
imobj.set_data(img)
dict((k, [v[1] for v in vs]) for k, vs in itertools.groupby(l, lambda x: x[0]))
fig = plt.figure()
ax = plt.gca()
plt.fill([0, 0, 1, 1], [0, 1, 1, 0])
Image.objects.all().large().portraits()
response
np.dot(a, b)
ax.scatter(x, y, z)
ax.set_zlim(z_min, z_max)
f.close()
a = np.random.rand(10, 10)
df1.reset_index(inplace=True)
my_list = [tuple(i) for i in my_list]
print(df.sum().to_frame())
sum(letterGoodness[c] for c in yourstring)
bool(array)
p = (b - a) * p + a * p.ceil()
pl.show()
draw()
Column(id_column_name, UUID(), primary_key=True, default=uuid.uuid4)
main()
writes.writerow(x)
f.writelines(mylist)
checkbutton.grid(row=1, column=0)
im.show()
isinstance(gen, types.GeneratorType)
print(twenty.data[958])
df = pandas.DataFrame(data)
logger.addHandler(dh)
conn.send(data)
logger.addHandler(handler)
board[x, y]
win = tk.Toplevel(root)
list(zip(*G))[0]
size = win.window.get_size()
layout.addWidget(self.edit)
df.replace([np.inf, -np.inf], np.nan)
plt.figure(1)
np.min(np.nonzero(np.hstack((A, 1))))
y = [a for a in x]
soup = BeautifulSoup(driver.page_source)
np.unique1d(np.floor(10000000.0 * x) / 10000000.0)
b[0].append(1)
l1.remove(x)
lambda s: int(s) if s.isdigit() else 0
[mean(cluster) for cluster in cl.getlevel(2)]
GST_VERSION_MAJOR,
df2 = df[df.dte < lastyear].head(depth)
[iter(l)] * 2
site.addsitedir(self.install_lib)
self.ui.PoseBtn_GridLayout.addWidget(self.button, 0, 0, 1, 1)
ax2.yaxis.set_major_locator(MaxNLocator(nbins=len(ax1.get_yticks())))
a = np.arange(100).reshape(10, 10)
q.close()
sum(args)
ax = fig.add_subplot(111)
max(dict_depth(v, depth + 1) for k, v in d.items())
browser.get(url)
a = np.random.randint(0, 2, (10, 8))
set(a) == set(c)
compat.register()
os.close(f)
x[1::2]
df.divide(df.sum(axis=1), axis=0)
mylist = mylist[2:-2]
b[b > 0]
trimmed.setdefault((k[0], k[-1]), []).append(v)
plt.xlim(bins[0], bins[-1])
file.seek(0, os.SEEK_END)
f.apply(clean, axis=1).reindex(f.index)
fct()
list(theDict.keys() & theList)
source_file.readline()
print(os.getegid())
B = A[([0, 2]), :, :][:, :, ([1, 2])]
temp_file.close()
time.sleep(1)
df_a.merge(df_b, left_index=True, right_index=True)
w.menuBar().addMenu(menu)
a[a < 0] = 0
ax = fig.add_subplot(111)
dosomethingelse
sorted(list(scores.items()), key=itemgetter(1), reverse=True)
mapping[frozenset(list(d.keys()))](**d)
aaa()
random.shuffle(charlst)
stdin.close()
plt.legend(scatterpoints=1)
ax = fig.add_subplot(1, 1, 1)
list(set(seq))
print(calendar.month(tgtdate.year, tgtdate.month))
ip = models.CharField(max_length=200, blank=True, db_index=True)
plt.gca().get_xaxis().get_major_formatter().set_useOffset(False)
s.seek(0)
(df * weights).sum(1)
logger.addHandler(logging.StreamHandler())
len(set(in_list)) == len(in_list)
[(L1[i] + L2[i]) for i in range(min(len(L1), len(L2)))]
self.connection.commit()
sub_df.iloc[0]
zip(*([it] * 2))
foo()
__init__.py
frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
answer.append((key, len(list(iter))))
(4, 5, 6) > (1, 1, 1, 9)
os.setsid()
ax2 = fig.add_subplot(2, 2, 2)
Simulation.mocked_method
plt.show()
select_indices = np.where(np.logical_or(x < 1, x > 5))
print(line)
draw.ellipse((x - r, y - r, x + r, y + r), fill=(255, 0, 0, 0))
f.write(new_text)
x.subs([(y, z), (x, y)])
inset.set_xlim(inset_xlimit[0], inset_xlimit[1], auto=False)
float(p[1] - b[1]) / float(p[0] - b[0]), p[0] < b[0]
startupinfo.dwFlags |= _subprocess.STARTF_USESHOWWINDOW
f.write(s)
now.timetuple().tm_isdst
set(a) == set(b)
list(product(x, flatten(y)))
list(set(array2))
MyList = [inst1.i, inst2.i]
self.send_result
app = wx.PySimpleApp()
RNA_integers = [RNA_dictionary[i] for i in RNA_list if i in RNA_dictionary]
print(twenty.data[0])
tgt.close()
dict((k, json.dumps(v)) for k, v in list(json.loads(val).items()))
x1, y1, x2, y2 = itertools.repeat(0, 4)
res.append(count)
ssh = paramiko.SSHClient()
print(os.path.join(root, f))
pprint.pprint(dataDict)
reactor.stop()
array([[14, 22], [46, 54]])
app = wx.App(redirect=True)
(2, 2, 10, 10), (12, 8, 2, 10)
fxn()
screen.update()
print(list(go(iter(lst))))
self.foo.kill()
x = np.arange(100)
sess.run([sparse_update])
A[c1b, r1b], A[c2b, r2b] = A[c2b, r2b], A[c1b, r1b]
t.selection_get()
tornado.ioloop.IOLoop.instance().start()
fig = plt.figure()
sys.stdout.write(session.recv(4096))
[[next(a_iter) for _ in range(n)] for n in b]
a[np.ix_(index, index)]
sum(range(start, start + n))
0, 0, 0, 0 | 0, 1, 0, 1, 1, 0
newdf.iloc[:10, :5]
p.kill()
print(func.__name__, args, kwargs)
data[:size]
f.write(r.content)
plt.show()
plt.show()
set(a)
print(a.data.nbytes + a.indptr.nbytes + a.indices.nbytes)
pygame.quit()
print(json.dumps(tree, indent=4))
h.setdefault(x, []).append(y)
time.sleep(1)
np.intersect1d(b1, a)
print([dict[i] for i in dict if dict[i] >= x])
screen.exitonclick()
name = models.CharField(max_length=150)
print(match.groups())
x1 = y1 = x2 = y2 = 0
print(t.timeit(number=1))
self.emitter.append(e)
self.platforms.append(e)
ax.set_xlim(xbnds)
s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
df.to_csv(s)
a.sort(key=lambda d: list(d.values())[0], reversed=True)
result_dict.setdefault(x.key, []).append(x.value)
self.button.clicked.connect(self.handleButton)
dic[i].append(j)
time.sleep(1)
eval(command)
connection.close()
plt.clf()
x = [[i] for i in range(10)]
[len(set(i)) for i in data.reshape(data.shape[0], -1)]
print(repr(html_to_text(html)))
setup.py
list.append(run(i[0], i[1], i[2]))
platform.system()
self.Raise()
min(timeit.repeat(lambda : dict([(k, v) for k, v in zip(keys, values)])))
plt.xlim(0, 9)
str(self.i)
reversed(lines)
map(functools.partial(f, y=fixed), srclist)
stdout_thread.start()
a.reshape(a.shape[0] // n, n, a.shape[1]).sum(1)
self.button.Bind(wx.EVT_BUTTON, self.OnButton)
pickle.dump(data, fp)
ax.set_yticks(numpy.arange(0, 1.0, 0.1))
grouped.sort(key=itemgetter(1), reverse=True)
a.close()
heapq.heappush(heap, (-prod1, x - 1, y))
args = parser.parse_args()
self.canvas.scale(ALL, x, y, self.scale, self.scale)
limit = int(limit)
window = gtk.Window()
chris.userprofile.followed_by.all()
keys = [k for k in scores if scores[k] == scores[key]]
cursor.execute(sql)
[{k: d[k]} for k in sorted(d)]
driver = webdriver.PhantomJS()
(lambda j: lambda x: x == j or x % j != 0)(i)
z = a[0] * b[1] - a[1] * b[0]
main.py
d = dict(matches)
subprocess.call(cmd)
[dic[k] for k in sorted(dic)]
plt.imshow(img)
self._id = uuid1().urn
termios.tcsetattr(sys.stdin, termios.TCSADRAIN, orig_settings)
dbQueryModel.itemData(treeView.selectedIndexes()[0])
bp.stdout.readline()
frame.grid()
iter(self.books.values())
min(zip(Lat, Lon), key=operator.itemgetter(1))[0]
ax.set_xticks(np.arange(-0.5, width, 1), minor=True)
print(sys.argv[0])
GF4(self.__addL__[self.number][x])
list(groups.values())
plt.figure()
time.sleep(0.5)
ax.autoscale()
cap.release()
[5, 5, 5, 4]
print(np.arange(100).nbytes)
print(df.head())
y.reshape(2, 1) - x
self.urls_seen.add(request.url)
self.send_blob(blobstore.BlobInfo.get(blob_key), save_as=True)
setattr(fundamentalconstants, name, value)
plt.scatter(X, Y)
do_something_with(x)
sns.distplot(a, bins=list(range(1, 110, 10)), ax=ax, kde=False)
QMainWindow.__init__(self, parent)
np.allclose(df_norm.values.dot(coef), pca.fit_transform(df_norm.values))
my_dict[k].append(dict1[k])
[i for i in mysites if i not in list(sites.keys())]
chr(65)
pyplot.plot(x, y)
[index_dict[x] for x in b]
p.get_open_files()
logger.addHandler(handler2)
x = np.asarray(x)
all(c in string.hexdigits for c in s)
m = coo_matrix((values, (row, col)), shape=(nrows, ncols), dtype=float)
QtGui.QMainWindow.eventFilter(self, widget, event)
fig, ax = plt.subplots(ncols=2)
print(G.edges())
plt.plot(x, y)
x.append(l)
models.ForeignKey.__init__(self, User, null=True, **kwargs)
zip(a, b)
main.config.from_object(config)
cPickle.load(f)
s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
plt.plot(freqs[idx], ps[idx])
ax2.set_ylim(0, 2)
print(info.get_content_type())
sum(scipy.stats.hypergeom.pmf(k, N, M, Q) for k in range(1, Q + 1))
db.model_to_protobuf(your_entity)
list(combinations(x, 2))
zip(l, combinations(reversed(l), len(l) - 1))
self.send(message)
plt.show()
fig = plt.figure()
x.split()
client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
new_array = new_array.reshape(old_array.shape)
data = data[~np.isnan(data).any(axis=1)]
print(int(x))
pygame.draw.rect(game_display, (0, 0, 0), rect_old)
np.argmin(abs(f2 - f1))
regex.findall(string)
ax.plot(x, x)
chmod + x / home / randy / lib / python / gbmx.py
round(2.675, 2)
s = p.sub(process_match, s)
sum(range(a + a % 2, b + 1, 2))
pd.DataFrame(d)
dict_.update((prefix, value) for prefix in prefixes)
gui.root.mainloop()
Foo()
numpy.arange(11, 17, 0.5)
list.append([])
myarray[x.group(1)] = [x.group(2)]
driver.set_script_timeout(10)
app.MainLoop()
do_something(f.result())
app = QtGui.QApplication(sys.argv)
lambda _: f()
image = Image.open(data)
list(range(string.ascii_lowercase))
b = np.identity(A.shape[2], dtype=A.dtype)
q = mp.Queue()
ax = fig.add_subplot(111)
nx.traversal.dfs_successors(G)
sys.stdout.write(out)
self.sizer.Add(self.canvas, 1, wx.LEFT | wx.TOP | wx.GROW)
{k: v for k, v in list(d.items()) if k not in excluded_keys}
max(len(i[j]) for i in x)
df.index[(df == window_stop_row).all(axis=1)]
result[-1].append(thetext)
[max(min(x, 255), 0) for x in oldList]
QtWebKit.QWebView.__init__(self)
ssl.OPENSSL_VERSION
root.mainloop()
[self[i] for i in index]
plot_date(a, 2)
df.columns
bar()
merged[k].append(d2[k])
print(d[2])
start_response(status, headers)
now = datetime.datetime.now()
form
print(a)
palette.set_bad(alpha=0.0)
display(fig)
start_time = time.time()
p.join()
traceback.print_exc()
data[0, 0] = [1, 2]
area = cv2.contourArea(contour)
numpy.random.seed(1)
df
locale.currency(float(cents) / 100.0)
plt.show()
dict(d)
bar(ind, num, width, color=colors)
ax.xaxis.set_major_formatter(daysFmt)
app.run(debug=True)
subprocess.call(cmd, shell=True)
plt.show()
print(tailq.get_nowait())
ws.cell(row=1, column=1).hyperlink = link
Response(status=204)
self.origstream = sys.stdout
Entry.objects.bulk_create([Entry(name=x) for x in a])
list(product(*map(lambda x: list(range(x[0], x[1] + 1)), args)))
Row(**OrderedDict(sorted(row_dict.items())))
plot.append(axE)
plot.append(axPA)
writer = csv.writer(output)
cast(a, POINTER(c_int))
lst[-1:] + reverse(lst[:-1])
p.start()
tk.Tk.__init__(self, *args, **kwargs)
main(sys.argv)
Qt.QFrame.paintEvent(self, event)
IOLoop.current().run_sync(runner)
print(m.group(1))
app = Flask(__name__)
plt.plot(X, Y)
print(OrderedDict.fromkeys(s))
os.close(sys.stderr.fileno())
self.figure.set_facecolor((1, 1, 1))
win.mainloop()
writer.writerow(out)
x = np.linspace(0, 2 * np.pi, 100)
1j * numpy.inf
area = img.crop(box)
time.sleep(1)
f2.write(line)
grid.grid(sticky=N + S + E + W, column=0, row=7, columnspan=2)
self.est.predict_proba(X)[:, (1)]
np.tile(v, (1, 2))
[dict(zip(columns, row)) for row in cursor]
np.cumsum(a, out=a)
id = db.Column(db.Integer, primary_key=True)
session.query(QuerySchema).filter(QuerySchema.way.ST_Within(bbox))
listbox.pack()
self.set.add(d)
fib(n - 1) + fib(n - 2)
new_dict = dict(zip(keys, values))
Counter(chain.from_iterable(map(str.split, f)))
a, b = map(int, input().split())
o.writerow(line.split())
map(lambda x: int(255 * x), (r, g, b))
np.arange(0, 1, 0.1)
list(it1)
app.register_blueprint(child2.child2)
someList.sort(key=key1)
line = line.strip()
abs(numpy.array([0.24])[0] - 0.24) < numpy.finfo(float).eps
plt.show()
print(newcorpus.sents(newcorpus.fileids()[0]))
self.root.destroy()
random.shuffle(x)
wtr.writerow(r)
os.chdir(prev_cwd)
EMAIL_USE_TLS = False
process.stderr.close()
cursor.close()
df1[ind].append(df2[ind])
KillerApp().run()
print(hashlib.sha1(json.dumps(a, sort_keys=True)).hexdigest())
driver = webdriver.Remote(desired_capabilities=options.to_capabilities())
b[0].append(1)
k[np.in1d(list(map(np.ndarray.dumps, k)), list(map(np.ndarray.dumps, k2)))]
new_x = itertools.chain(y, x)
print(np.array_equal(A, C))
list(d.values())
imshow(img, zorder=0, extent=[left, right, bottom, top])
sys.exit(0)
app.mainloop()
p.wait()
time.sleep(1)
args = parser.parse_args()
t.start()
blobstore.delete(key)
emonth1.grid(row=1, column=2)
re.findall(str_in_doublequotes, text)
plt.colorbar()
[a, b] = [1, 2]
[x for x in individual(nest)]
numpy.random.seed(29)
conn.response()
pyplot.show()
np.savetxt(myfile, sample_array)
ax2.set_yticks(y_tick * np.pi)
ax.set_xlim(-5, 100)
main_menu.display()
content = fp.read()
axr.set_ylim(altitude.min(), altitude.max())
path = os.getcwd()
tree = etree.ElementTree(root)
df2.boxplot()
tf.mul(scale, x)
gc.collect()
list([val for val in range(10) if val & 1])
deletetup[0]
my_file.close()
setattr(obj, name, value)
str(self)
reactor.run()
self.handler = logging.StreamHandler(self.stream)
print(dict(re.findall(r, z)))
root.mainloop()
sort(data, key=key, reverse=rev)
response.set_data(soup.prettify())
emailer.send(messages)
list2 = [int(y) for y in list(itertools.chain(*[str(x) for x in list1]))]
a[i].append(int(value))
print(sum(chain(n, o, p)))
axes[0].legend(bbox_to_anchor=(0, 0.5))
plt.show()
ax.set_ylim(-1, 7)
[(2, 5), (12, 17), (22, 22), (25, 26), (28, 28), (51, 52), (57, 57)]
pixels = [pixels[i * width:(i + 1) * width] for i in range(height)]
plt.subplot(111)
list(repeat(100, foo))
s2[s2.isin(s1)]
plt.xlim([0, 6])
self.write(self.request.uri)
ldap.set_option(ldap.OPT_X_TLS_REQUIRE_CERT, ldap.OPT_X_TLS_NEVER)
df_out
random.seed()
ax1 = fig.add_subplot(2, 2, 1)
myArray.append(np.array([i, i + 1, i + 2]))
self.category.name
game.init()
root.mainloop()
mlab.show()
print(m.cancel())
np.savetxt(outfile, slice_2d)
counts = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
myDict.setdefault(newKey, []).append(value)
plt.show()
contours, _ = cv2.findContours(edges, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)
l[1::2]
set(map(tuple, map(sorted, pairs)))
ax.xaxis.set_major_formatter(fmt)
self.log.close()
self.config_from_object(app.config)
app.run(debug=True, threaded=False)
union([(10, 12), (14, 16), (15, 22)])
print(PixelAt(int(sys.argv[1]), int(sys.argv[2])))
id = db.Column(db.Integer, primary_key=True)
event.widget.pack_forget()
a = fig.add_subplot(1, 2, 2)
np.intersect1d(amem, bmem).size
scores.ffill().sum(axis=1)
proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
s.close()
m.save()
wb = openpyxl.load_workbook(filename=file)
outarr[x1to:x2to, y1to:y2to] = inarr[x1fr:x2fr, y1fr:y2fr]
np.where(M == 0)
a2.ravel()[:] = [tuple(l) for l in m.reshape(2, -1).T]
ttk.Radiobutton(self.mainframe, value=1).grid(column=2, row=2)
filtered_list = [x for x in your_list if all(f(x) for f in filters)]
Base.metadata.create_all(engine)
x.a = 2
{file: find_mime_with_file(file) for file in files}
rx.findall(allsorts)
lines = f.readlines()
ax.set_xlim(0.5, ly + 0.5)
pool.map(lambda x: preprocess(x), real_preds)
dest = dict(chain(list(orig.items()), list(extra.items())))
Toplevel.__init__(self, parent)
lines.append([(x, lastY), (x, y)])
foo(x, y)
plt.show()
print(np.all(A[a_to_b] == B))
draw.rectangle(bbox, outline=(0, 255, 0))
repr(tst2)
s.set_missing_host_key_policy(paramiko.AutoAddPolicy())
[0, 1, 0, 0, 1, 0, 1, 0],
f.close()
opener = urllib.request.build_opener()
df[df.one.isin(checkList) | df.two.isin(checkList)]
datetime.date(datetime.now()).isocalendar()[1]
d = defaultdict(int, zip(list(range(1, 10)), list(range(50, 61))))
B().a()
layout.addWidget(self.canvas)
l = [item for sublist in list for item in sublist]
data = data.reshape(data.size / 2, 2)
PyErr_Print()
x.argsort().argsort()
plt.clf()
self.sock.close()
signal.signal(signal.SIGINT, handle)
os.symlink(pythonapp, newpython)
file = models.FileField(upload_to=get_random_filename)
kmeans.fit(p_df)
bin(a ^ b)
pos = emcee.utils.sample_ball(mean, np.sqrt(np.diag(C)), size=Nwalkers)
driver = webdriver.Firefox(firefox_profile=profile)
os.system.__module__
pd.crosstab(df.gender, df.doctor)
urllib.request.install_opener(opener)
all(x < y for x, y in zip(L, L[1:]))
q.T.reshape(-1, 2, 2).swapaxes(1, 2).reshape(-1, 2)
cache._cache.flush_all()
ax.plot(data2)
cv.create_rectangle(10, 10, 50, 50)
df[df.genre.map(iscomedy)]
sum(sys.getsizeof(x) for x in s)
connection.close()
profile = request.user.get_profile()
MyApp().run()
Done
next(it1)
print(np.linalg.det(A))
json_data_rdd.flatMap(lambda j: processDataLine(j, arg1, arg2))
p.stdin.close()
zip(*[L[i::4] for i in range(4)])
list(accumulate(example_list, add))
ax = self.figure.add_subplot(111)
s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
b = a.transpose()
__init__()
plt.show()
v.append(n)
np.take(arr, inds)
a = datetime.datetime.now()
G.add_nodes_from([1, 2])
__init__.py
writer = csv.writer(f)
print(df.loc[mask])
f(x, y, z)
pylab.figure(figsize=(20, 9))
{{nhl_form.league}}
dict(alist[i:i + 2] for i in range(0, len(alist), 2))
f()
pygame.display.update()
profile.user.save()
df.loc[df.name].tail(2)
Node.objects.get_queryset_descendants(my_queryset, include_self=False)
self.panel.Bind(wx.EVT_CHAR, self.OnKeyDown)
t.start()
df
thread.start()
plt.setp(xticklabels, visible=False)
list(t)
tobin(x / 2) + [x % 2] if x > 1 else [x]
subprocess.call(args, stderr=subprocess.STDOUT, stdout=f)
logger.setLevel(logging.INFO)
self.table.setItem(1, 0, QtGui.QTableWidgetItem(self.led.text()))
someClass.doSomething()
df.columns = df.columns.astype(str)
pylab.gca().add_patch(arr)
print(etree.tostring(tree))
regex.match(string)
a.result() + b.result()
tk.Frame.__init__(self, root)
f.write(s.getvalue())
f.seek(0, 2)
self.out_file.close()
a.print_x.__func__(b)
print(s[:])
f = np.array([(df * n if n < N / 2 else df * (n - N)) for n in range(N)])
my_dict = {x: (x ** 2) for x in range(10)}
print(json.dumps(doc.reprJSON(), cls=ComplexEncoder))
g.username = user.name
file.close()
p.stdout.close()
[os.path.join(*choices[:i + 1]) for i in range(len(choices))]
print(row[0])
fig = plt.figure()
{c: counter.get(c, 0) for c in chars}
sys.path
do_stuff()
list(it.product(x, mit.collapse(y)))
fun(*args, **kwargs)
type(s)
m_action2.perform()
ax = self.figure.add_subplot(111)
process.kill()
timezone.localtime(timezone.now())
width, height = img.size
c.append(a[index])
df.ix[idx]
config.write(configfile)
main()
cur.close()
gp1.iloc[0].values
fig = plt.figure()
fsizer.Add(self.stext, 0, wx.ALL)
pickle.dump(selfref_list, output, -1)
start_response(status, response_headers)
print(list(takewhile(lambda x: bool(x.strip()), v)))
np.dot(J, mat)
df = pd.DataFrame(list(BlogPost.objects.all().values()))
response = urllib.request.urlopen(url)
all_pairs += [((nA, 0), (nC, 2)) for nA, nC in itertools.product(listA, listC)]
result[nI] = v2[nI]
smtp.quit()
os.dup2(savout, 1)
a = a & b
{{(user | hash): item}}
print(tmp)
pd.concat((df1, df2), axis=1)
print(str(mytuple)[1:-1])
queryset = Profile.objects.filter(condition)
fig, ax = plt.subplots(1, 1)
plt.subplot(122)
print(yaml.dump(a, default_flow_style=False))
parameters(my_get_params)
get_lineage(dt, df.columns)
my_list = [item for item in range(10)]
strided(a, shape=((a.size + n - 1) // n, n), strides=(n * s, s))[:, 1:]
self._app(environ, log_response)
f.seek(2)
len(a)
time.sleep(1)
plt.rcParams.update(params)
QtCore.QAbstractTableModel.__init__(self, parent)
plt.hexbin(x, y)
self.right.extend(self.left[0:x])
shallow_copy_of_set = set(old_set)
clf.fit(K, y)
ax.xaxis.set_major_locator(dates.MinuteLocator())
fig, ax = plt.subplots()
QtCore.Qt.ItemIsEnabled | QtCore.Qt.ItemIsSelectable | QtCore.Qt.ItemIsDragEnabled | QtCore.Qt.ItemIsDropEnabled
pri()
self._decks = []
object_list.append(new_element)
sleep(10)
Feed.objects.update_one(push__posts=post)
s.ix[x:y].asfreq(BDay()).count()
print(arr[[1, 2], [0, 1]])
user = models.ForeignKey(User, unique=True)
image.show()
os.symlink(src, dst)
txt_frm.grid_rowconfigure(0, weight=1)
np.sum(a == b)
result.extend(flatten_to_strings(i))
self._display.sync()
[datetime.datetime(2012, 1, 2, 0, 0)],
frozenset(itertools.chain.from_iterable(args))
next(i for i, string in enumerate(strings) if substring in string)
other_work()
func(*args, **kwargs)
curses.wrapper(MyApp)
self.name = name
convert_A_to_B(sys.stdin, sys.stdout)
time.mktime(utc_dt.timetuple())
infile.seek(0)
self.process.run()
output.append((num, val))
datetime.date(int(a[:4]), int(a[5:7]), int(a[8:10]))
result = [x for k, v in list(d.items()) for x in k * v]
print(cursor.bindnames())
{{(value | currency): request.session.currency_type}}
execute(sys.argv[1])
fh.readlines()
t.to_datetime()
c.append(int(digit))
somelist = [i for j, i in enumerate(somelist) if j not in indices]
[fac(n) for n in nums]
app
numpy.float64(1.0) / 0.0
f.close()
np.issubdtype(np.bool, np.integer)
a[ind]
{{test | safe}}
tuple(f())
self.data = data
flipbf(m).swapaxes(1, 2)
states.split()
func()
np.argmax(np.mean(complete_matrix, axis=1))
sys.exit(app.exec_())
a = [0, 1, 0, 1, 0, 0, 0, 0]
ax.grid(True)
shutil.copyfile(source_path + file_name, dest_path + file_name)
app = Flask(__name__)
p.stdout.flush()
self.__name__
conn.send(msg)
print((k, v))
np.rollaxis(result, 0, result.ndim)
print(sys.maxunicode)
Py_Finalize()
plt.clf()
print(bar.x)
elevation[elevation > 0] = numpy.NAN
list(range(start, stop + 1, step))
print(add_number(A))
args = parser.parse_args()
locale.setlocale(locale.LC_COLLATE, newone)
a * b[:, (np.newaxis)]
handles, labels = ax.get_legend_handles_labels()
dir(nltk.corpus)
plt.gca().add_artist(scalebar)
s.connect((host, port))
self.stop.grid(row=4, column=1, sticky=EW)
print(df1.to_string())
c = np.array([[1, 0, 0], [1, 0, 0], [1, 0, 0], [1, 1, 0]])
G = np.array([[0, 0, 0, 0], [1, 0, 0, 0], [1, 1, 0, 0], [1, 1, 1, 0]])
manager.connect()
plt.show()
print(rf.predict([testdataset[-1]]))
django.setup()
[i for i in x]
Food._meta.get_all_related_objects()[0].model
[list(range(2, 6)), list(range(12, 18))]
ax.pcolormesh(theta, r, Z)
[Factorial(x) for x in arg]
response
f.write(template)
print(link.text.strip()[5:])
ax = fig.add_subplot(111)
PyEval_SaveThread()
numbers = map(int, s.split())
text.set_rotation(90)
joe(joe(joe({}, myTupleList[0]), myTupleList[1]), myTupleList[2])
setp(ax1.get_xticklabels(), fontsize=6)
time.sleep(1)
myNames = f.readlines()
logger.addHandler(fh)
o.a = 2
app.SetTopWindow(frame)
plt.show()
B = matrix(expm(A))
print(f(1))
x[1]
stdscr.getch()
2 * a + b
vbox1.addWidget(self.edit2)
progbar.pack()
main()
result_dict[str(len(word))].append(word)
logging.root.setLevel(logging.DEBUG)
data = request.GET
between1(b[0], p[0], q[0]) and between1(b[1], p[1], q[1])
myDict[key] += val
print(s[i:])
Obj2.grid_forget()
result = list(DBProcessor().get_listings())
res += [os.path.join(root, d) for d in dirs]
cap = cv2.VideoCapture(0)
dict.fromkeys(s, 0)
app.register_blueprint(mod)
cur.close()
sys.exit(app.exec_())
x = np.arange(len(df.columns))
min(map(lambda x: s.index(x) if x in s else len(s), a))
{{message}}
df
plt.show()
e.save()
find_indices(a, lambda e: e > 2)
nodes[2] = 1
print(regex.group(2))
obj.refresh_from_db()
self.visit_typeA(dataobj)
a = np.array([1, 2, 2, 1]).reshape(2, 2)
user.Setinfo()
html = gzipper.read()
gmpy.divm(1, 4, 9)
dict(dd)
a = str(tag.getArtist())
df.to_excel(writer, sheet_name=sheetname)
main()
app = QtGui.QApplication([])
nlargest(2, tags, key=lambda e: e[1])
response
simplejson.loads(json)
sys.exit(EMERGENCY)
result.append([])
axes.legend(handles, labels)
img = Image.open(StringIO(response.content))
app.cgirun()
image = Image.open(picture)
groupby(a, [1])
[groups[k] for k in sorted(groups.keys())]
sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPINTVL, interval_sec)
signal.signal(signal.SIGTERM, self.exit_gracefully)
res = urllib.request.urlopen(req)
setattr(obj, self.name, float(val))
plt.figure()
q = DBSession.query(model.Name).distinct(model.Name.value)
obj.post_set.count()
draw(2, 4, 5)
plt.locator_params(nbins=10)
print(hex(id(x)))
print(dll.get_buf())
p = figure(x_range=(-1, 1), y_range=(-1, 1))
words.flatMap(set).distinct().count()
a = defaultdict(lambda : 1)
sys.exit(0)
print(key, dict[key])
zippend((one_array, two_array), two_outputs())
l[:n]
numpy.set_printoptions(threshold=numpy.nan)
self.label.setMouseTracking(True)
m = merge_a_b(a, b)
print([sum(x) for x in itertools.zip_longest(fillvalue=0, *lists)])
sys.exit()
writer = csv.writer(self.response.out)
s = requests.Session()
int_list = [int(x) for x in line.split()]
plt.set_cmap(viridis)
documents = [doc[0] for doc in documents]
print([b(5) for b in bases])
(dt - epoch).total_seconds()
Py_DECREF(result)
sigmoid(W1 * x1 + W2 * x2 + B)
not any(data)
list(zip(A, B * 2))
options, args = parser.parse_args()
{1}.pop()
my_list = [b, a]
cv.SetCaptureProperty(camcapture, cv.CV_CAP_PROP_FRAME_WIDTH, 1280)
(np.diff(sdata) > 0).sum(axis=1) + 1
list(chain.from_iterable(a))
data.append(map(str.strip, row))
id = Column(Integer, primary_key=True)
category = models.ForeignKey(Category)
mail.quit()
pylab.show()
unittest.main()
self._shape = self._shape[0], self._shape[1] - 1
app
[sum(i) for i in zip_longest(fillvalue=0, *l)]
cursor.close()
listD.append(listC[num])
canvas.grid(row=0, column=0, sticky=N + S + E + W)
x = np.clip(x, 0, 1)
list(itertools.combinations(enumerate(a), 2))
result = np.vectorize(my_dict.get)(a)
type(counts)
admin.site.register(Department, DepartmentAdmin)
c.close()
cleaned = [i for i in map(str.strip, words) if i]
print([element for element in lst])
app = Flask(__name__)
Counter(map(tuple, a))
text = pipe.communicate()[0]
filename = models.CharField(max_length=128)
sock.close()
random.shuffle(l2)
parser.parse_args()
a = [1, 1, 1, 1, 1]
fig, ax = plt.subplots()
diff(x)
map(a.__getitem__, b)
[0, 2, 6, 7]
matrix[:] = [([0] * len(row) if 0 in row else row) for row in matrix]
pickle.dump(abe, f)
qs_sorted.append(qs.get(id=id))
sys.path.insert(0, parent_dir)
collections.deque(iterator, maxlen=0)
root.rowconfigure((0, 1), weight=1)
print(x.group(1))
zip(*list_of_values[i:i + len(pattern)])
[item for item in items if item.col2 == 2006]
asyncore.dispatcher.__init__(self)
DataFrame([row for i in range(1000)])
isinstance(dict(), collections.MutableMapping)
plt.show()
wr.writerow(mylist)
[x[i:i + chunk_size] for i in range(0, chunks, chunk_size)]
plt.colorbar()
pd.DataFrame(r, i, u)
sys.path
output += item[0].upper() + item[1:]
df.join(x)
fib(n - 1) + fib(n - 2)
date_parser = pd.datetools.to_datetime
pylab.show()
func()
pprint(result)
win = gtk.Window(gtk.WINDOW_TOPLEVEL)
list.__setitem__(self, index, value)
suite.sort()
list[i].append(random.randint(0, 9))
print(df.reset_index())
df.loc[[0, 2, 4]]
writer.writerows(zip(*test_data[1:]))
user.put()
4.0 * scipy.integrate.nquad(f, [[0, inf], [0, inf]])[0]
print(dict.setdefault.__doc__)
print(json_data[entry])
main()
[[[1][2]]]
print(e.subs([(a, d), (b, f)]))
fig.clf()
time.sleep(1)
s.bind((TCP_IP, TCP_PORT))
scipy.misc.factorial(6)
db.init_app(app)
gc.collect()
image.paste(ic, box)
groups_no_a = [i for i in groups if a not in i]
QWebView.page().setNetworkAccessManager(myNetworkAccessManager)
print(moneyx)
django.setup()
{{request.user.get_myuser.pretty_username}}
clear()
n = gmpy2.next_prime(n)
plt.scatter(x, y, zorder=1)
max_by_group.collect()
print(next(next(mp.parse_sents([sent, sent2]))))
print(list(myDict.keys()))
self.rect.set_height(self.y1 - self.y0)
do_something(column)
tuple([x for x in map(itemgetter(0), G)])
n.addConnection(bias_to_hidden)
reversed_dict[value].append(key)
plt.figure(1)
os.listdir(long_unc)
cv2.destroyAllWindows()
do_something()
ax.set_xlim(x.min(), x.max())
math.pow(x, y)
B = np.hstack((splits[0], splits[2]))
[x for x in filename if x.isdigit()]
os.path.split(x)[-1]
cursor = cnx.cursor(dictionary=True)
unittest.main()
self.show_popup()
print(fin.read())
c.connect((hostn, 80))
df.index = df.index + 1
a / (math.sqrt(2) * erfinv(P))
test.py
plt.step(x, y)
print(cookie)
itertools.zip_longest(fillvalue=fillvalue, *args)
tuple_foo(tuple(a))
os.makedirs(path)
df[:-1]
df
plt.show()
ax.plot(x, y)
test = np.array([0, 1, 2, 5, 0])
args = parser.parse_args(sys.argv[1:])
Response(serializer.data)
image.save(output)
np.set_printoptions(suppress=True)
pyhk.addHotkey(SomeHotkey, SomeFunction)
df
[list(range(s, s + step + 1, step)) for s in range(start, stop, step)]
fn(*args, **kwargs)
pygame.quit()
conn.close()
p.start()
nx.draw(G)
do_code()
out, err = p.communicate()
nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)
do_stuff()
app = QApplication(sys.argv)
curses.endwin()
bar = models.CharField()
data = json.load(f)
sum(int(c) for c in s if c.isdigit())
ws = wb.worksheets[0]
print(columns[0])
Gtk.ContainerClass.list_child_properties(parent)
signal.signal(signal.SIGINT, handler)
ax2.plot(list(range(100)), np.ones(100))
df.loc[df2.index, df2.columns] = df2
print([(k, out[k]) for k in sorted(out.keys())])
self.columnconfigure(10, weight=1)
axclust.set_xticks([])
axcltwo.set_xticks([])
ax.autoscale(False)
self.window.refresh()
curses.initscr()
{{field.errors}}
out.append([])
list(itertools.combinations(keys, 2))
mqtt.client.loop_start()
run_loop_with_timeout()
self.fig.canvas.draw()
most_expensive_cars.append(list(company.cars_by_price.all())[0])
time.sleep(0.1)
yests += [yest]
fileout.close()
[x for x in seq if x not in seen and not seen.add(x)]
str.__init__(self, *args)
print(list(zip(A, i)))
[e] * n
bool(s.intersection(list(someDict.keys())))
sys.exit(1)
{file: check_image_with_pil(file) for file in files}
result.setdefault(v, []).append(k)
self.func()
plt.xlim([0, len(sub_data)])
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
btn.Bind(wx.EVT_BUTTON, self.onDialog)
df
simplejson.JSONEncoder.default(self, obj)
sys.stdout.write(char)
sys.stderr.flush()
int(f) if f.is_integer() else f
cursor.execute(sql)
server.start()
plt.show()
print([eq1] == [eq2])
f.write(contents)
q = B.select().join(A).where(B.date == last_entry_date)
[0.66666667 - 0.66666667]
__DBNAME__[0] = name
dict.__setitem__(self, frozenset((idx,)), value)
items = sorted(list(dct.items()), key=lambda kv: kv[0])
list(zip(a, b, zip(*gr), d))
self.x == p.x and self.y == p.y
df = pd.DataFrame(np.random.randn(10, 6), columns=cols)
p = subprocess.Popen(cmdline, stdout=sys.stdout, stderr=sys.stderr)
parent.config(menu=menubar)
edge_dict[e[0]][e[-1]] += 1
lambda s, *args, **kw: not v(s, *args, **kw)
im = Image.open(filename)
result = list(filter_value(a, 1))
float(x)
gray = img[:, :, (0)]
thread.start()
print(s.query(myTable))
min_obj_set.append(obj)
sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))
app = QtGui.QApplication(sys.argv)
plt.figure(1)
con.commit()
z.close()
y.std()
id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
reader = csv.reader(f)
result[a][b] = n[a][b] - 1
now = datetime.datetime.utcnow()
x
out, err = p.communicate()
evaluate(lambda x: x < 5 and x > -5)
self.y / self.x
random.shuffle(arr)
numpy.std(rolling_window(observations, n), 1)
zip(np.ravel(ix0), np.ravel(ix1), np.ravel(v2))
handle_last_line(last_line)
wm.add_watch(watched_dir, pyinotify.IN_CLOSE_WRITE, proc_fun=MyProcessEvent())
shutil.rmtree(dir)
print((r.status_code, r.reason))
x += y.todense()
ax.figure.canvas.draw()
np.random.shuffle(coordinates)
func(*args, **kwds)
model4.py
print((find_interval(tlist, item) for item in newlist))
sheet.write(0, index, value)
soup = BeautifulSoup(html_object)
np.array([row[:num_cols] for row in arr])
x += datetime.timedelta(1)
print(int(round(random.randint(100, 200001), -2)))
session.add(s)
list(takewhile(lambda i, j=iter(list2): i == next(j), list1))
p.close()
df = pd.concat((ser1, ser2), axis=1)
urllib.parse.unquote_plus(t)
fig = plt.figure()
driver = webdriver.Firefox(firefox_profile=firefox_profile)
array.append([0] * 8)
sys.stdout.write(prompt)
idx = np.argsort(a, axis=1)
proc.wait()
k = [(ord(x) - 96) for x in l]
model.setData(index, editor.currentIndex())
httpd.serve_forever()
[(8, 9), (4, 9), (7, 9)]
f.write(data)
max(MyCount, key=int)
QtGui.QMainWindow.eventFilter(self, source, event)
ax.set_axis_off()
QtGui.QWidget.__init__(self)
HttpResponse(response, content_type=mimetype[0])
False
plt.plot()
driver.set_window_size(1280, 1024)
{i: (IDsums[itr], value_sums[itr]) for itr, i in enumerate(unqID)}
s = int(s)
json.dump(parse(sys.stdin), sys.stdout, indent=2)
ax.plot([0, normp[0]], [0, normp[1]], zs=[0, normp[2]])
app = Flask(__name__)
child.kill()
matrix.data[row].append(column)
to_call(*args, **kwargs)
any(x in mystr for x in ls)
lists = [[] for _ in range(n)]
self.Show()
results = sorted(query.fetch(FETCHED), key=_func)
Counter(data[1]).most_common()
idx[mask].argsort()[unqID]
new_list = [g(f(x)) for x in old_list]
db.session.add(provider)
set_column(first_col, last_col, width, cell_format, options)
fin.seek(0)
resp = session.post(url, headers=headers, data=form)
hand.sort(key=lambda c: rank_cards.index(c[0]), reverse=True)
[hex(c) for c in chars]
wx.ListCtrl.__init__(self, parent, ID, pos, size, style)
df = concat([reader(f) for f in files], keys=files)
img = Image.open(input_path)
pickle.dump(d, afile)
cause
feedback.save()
a = [[0, 0], [0, 0]]
setattr(object, attrname, value)
writer = csv.writer(output, quoting=csv.QUOTE_NONNUMERIC)
element.close()
raise AttributeError()
child.destroy()
pairs = list(my_dict.items())
random.choice([p for p in itertools.product(x, repeat=2)])
signal.signal(signal.SIGINT, signal.SIG_IGN)
plt.legend()
auth.set_access_token(access_token, access_token_secret)
df1.add(df2, fill_value=0)
np.random.seed(1)
plt.scatter(x, y)
group.plot(ax=ax[ix], title=i)
setup.py
self.root.mainloop()
{file: mimetypes.guess_type(file) for file in files}
urllib.request.install_opener(opener)
foo.bar()
getattr(self.ham, func)(*args, **kwargs)
[list_a for list_a in list_a if list_a[0] in list_b]
array([[1.0, 0.1, 0.1], [0.09, 1.0, 0.1], [0.2, 0.1, 1.0]])
df = pandas.DataFrame.from_records(data_records)
number = random.randrange(1, 10)
d.setdefault(key, [])
lines.append(line)
w.show()
print(set_list_intersection(set_list))
self.save()
soup = BeautifulSoup(html)
plt.scatter(x, y, c=c)
ax.set_ylim(0, 16000)
entry.grid(row=0, column=0)
random.shuffle(a)
g = f()
print(len(locals()))
model.add(Dropout(0.5))
deleteseq[i]
groups.mean().b
writer.writerow(values)
v = myDict[k]
DISPATCH()
ax.add_patch(circle)
hbar.pack(side=BOTTOM, fill=X)
self.get_next_probe(new_list, probes, unit_length)
test()
img = ndi.gaussian_filter(img, (10, 10))
img.show()
fig, ax = plt.subplots()
HTML(df.to_html(escape=False))
Serial.println(a)
df = df.dot(p_value)
X[[[0], [1]], [0, 1]]
browser.set_handle_equiv(True)
m.group(1)
list(islice((x for x in a if x not in bset), 100))
plt.show()
t.start()
np.array([1.0, 1.0]).astype(int)
print(list(request.headers.keys()))
[5, 6, 9]
x + y + z
self.get_type_display()
self.greet()
fp.close()
g.write(base64.decodestring(newjpgtxt))
loads(dumps(input_ordered_dict))
df.end_time = pd.to_datetime(df.end_time)
ax.xaxis.set_minor_locator(FixedLocator(x_da))
fig, axes = plt.subplots(nrows=2, ncols=2)
curs.execute(query, args_tuple)
[(x, y) for x in nums for y in nums]
now = datetime.now()
data = {a: int(float(sum(b)) / float(len(b))) for a, b in list(data.items())}
rates.sub(treas.squeeze(), axis=0).dropna()
list(zip_longest(*a))
app = Flask(__name__)
time.sleep(0.5)
print(hdict_from_dict(data))
s.getsockname()
print(repr(value))
slice = arr[:2, :2]
globals()[lib] = __import__(lib)
print(sock.recv(10240))
raise SystemExit(1)
r.content
print((x.subs(sol[0]), y.subs(sol[0])))
sum(dice) - min(dice)
t.start()
age.__class__.__class__
cur_date += relativedelta(months=1)
datetime.datetime(*time.gmtime()[:6])
response
df.isnull()
myapp.db.session.commit()
print(driver.page_source)
your_list = f.read().split()
self.config(width=self.width, height=self.height)
x = EqM_list(bah * 2 for bah in buh)
reversed_arr = np.fliplr([arr1d])[0]
children.append(node.starargs)
id = Column(Integer, primary_key=True)
dummy_df[cols[cols].index]
[list_[v:indices[k + 1]] for k, v in enumerate(indices[:-1])]
popt, pcov = curve_fit(func, x1, x2)
print([(x, text.count(x)) for x in set(text)])
ax.plot(x, y)
res = {k: coords[nzvals == k] for k in range(1, num_labels + 1)}
pprint(d)
b_any(word in x for x in lst)
stack.append((y0, w0))
list(combinations(list(range(len(sent))), n - 1))
self.root.update()
ao[1:, 1:] += ai[:-1, :-1]
print((b[2][0] == b[2][0]).all())
raise KeyboardInterrupt
new_button.pack()
print(datetime.date.today() - datetime.timedelta(1))
[o for o in gc.get_objects() if isinstance(o, Foo)]
test_trisolve2.test_trisolve()
pool.join()
plot_selected.xaxis.set_ticks(np.arange(0.2, 1.1, 0.2))
req = Request(environ, shallow=True)
f.axes[1].set_position([0.05, 0.45, 0.4, 0.05])
np.random.permutation(indices)
queryset = SomeObject.objects.filter(owner=request.user)
tk.Tk.__init__(self, *args, **kwargs)
first_name, last_name
x, y, z = scipy.sparse.find(a)
permu(l)
plt.yticks(visible=False)
my_handler.setLevel(logging.DEBUG)
worksheet.write(row, col, key)
[bool(x) for x in [[], {}, np.array([])]]
np.interp(np.linspace(0, npt, nbin + 1), np.arange(npt), np.sort(x))
listbox.insert(tk.END, key)
time.time() - time
list(itertools.chain.from_iterable(line.split() for line in f))
str(int(match.group(0)) - 1)
wi.fooi(7)
plt.show()
pdb.set_trace()
app = Flask(__name__)
now = datetime.datetime.now()
df = pd.DataFrame(data)
plt.clf()
np.maximum(a, 0, a)
self.listofrecords.append(record)
Category.objects.filter(child__isnull=True)
f.close()
df = pd.concat([df[:], tags[:]], axis=1)
table = Table(data, colWidths=270, rowHeights=79)
wx.Frame.__init__(self, parent)
models.OneToOneField(EntryAdmin)
result = [i for s in S for i, row in enumerate(X) if (s == row).all()]
Response(serializer.data)
n = sorted([minN, n, maxN])[1]
y = [0.0, 0.5, 1.0, 1.5, 2.0, 2.5]
[1, 0, 0, 0, 0]
dlg.ShowModal()
print(list(flatten_group(b)))
np.broadcast_arrays(*output)
stdscr.refresh()
self.SetTopWindow(mainDlg)
grid = np.zeros((10, 10))
sum(dct[k] for k in lst if k in dct)
main()
self.finish()
[x for x in s if x in printable]
deletearray[0]
B = np.array([[1], [2]])
ax.zaxis.set_major_locator(LinearLocator(10))
new_list
np.alltrue((a == b).compressed())
fig = plt.figure()
[min(y, max(x, z)) for x, y, z in zip(a, b, c)]
df.eq(df.max(1), 0).astype(int)
[list(v) for k, v in groupby(a, np.isfinite) if k]
pixbuf = gtk.gdk.Pixbuf(gtk.gdk.COLORSPACE_RGB, False, 8, width, height)
pstree - p - a
root.mainloop()
q.write(w)
tree = ET.ElementTree(root)
np.ma.masked_array(np.interp(value, x, y))
sys.path.insert(0, os.getcwd())
outfile.write(json.dumps(output, indent=4))
[a, b, c, d, e]
soup = BeautifulSoup(html)
req = urllib.request.Request(url)
map(str, x)
app.mainloop()
browser.set_handle_referer(True)
Process.__init__(self)
self(*args, **kwargs) + other(*args, **kwargs)
distances = numpy.linalg.norm(np_cell[1] - srcPos, ord=1, axis=1)
A = np.arange(600)
thread.start()
random.shuffle(tmp)
x[~np.isnan(x)]
A[:, (j)] = (C[j] * mask).sum(axis=-1)
f = open(str(path, encoding))
f.seek(0)
ax.xaxis.set_major_locator(ticker.FixedLocator(pos_list))
print(file.read())
f.write(file_str)
setattr(modelclass, collection_name, (cls, self))
calling_func(*args, **kw)
x = defaultdict(int)
process = subprocess.Popen(cmd, stdout=subprocess.PIPE)
print(name.lower())
print(request.json)
code.interact(local=locals())
output_file.write(line)
hashlib.sha1(bn.T).hexdigest()
img.show()
a[0].append(8)
xs[1::4]
all_data = np.hstack((my_data, new_col))
abacus[index] = abacus[index] + 1
p = Popen(cmd, stdin=PIPE, stdout=PIPE, stderr=PIPE)
p1.wait()
app_log.setLevel(logging.INFO)
numpy.std(arr, axis=0)
hex(x)
sys.exit(0)
main()
glOrtho(0, 1, 0, 1, -1, 1)
the_integers[a:b:c].foo()
time.sleep(10)
new_list_of_dict = map(new_dict, list_of_dict)
sess = tf.InteractiveSession()
time_d.total_seconds()
im = np.asarray(x)
t.start()
f = {x: make_func(x) for x in range(10)}
write(n, 0, 0, 0)
np.arange(n) >= arr[:, (np.newaxis)]
result()
ax1.yaxis.get_offset_text().set_color(plot_ax1.get_color())
A[i], A[j], A[k] = A[j], A[k], A[i]
w.writerow([key, val])
line
data = response.json()
module_b.py
self.Bind(wx.EVT_SIZE, self.on_size)
browser.set_handle_redirect(False)
tcpCliSock.close()
d.tzname()
child.kill()
print(np.asarray((unique, counts)).T)
f.write(bytearray(b))
model.fit(X, Y, nb_epoch=5, batch_size=100, verbose=1)
print(np.flatnonzero(npi.contains([[0, 1]], vals)))
print(pd.get_dummies(values))
print(type(data))
app.run(debug=True)
self.canvas.delete(self.last_img)
plt.subplot(6, 1, 1)
my_dict = obj.__dict__
example.examplemod.do_stuff()
np.random.seed(1)
np.all(a == b, axis=1)
Sensor.__init__(self, *args, **kwargs)
plt.xticks(x, my_xticks)
s = [(e + d) for e in line.split(d) if e]
a.do_something()
pygame.mixer.init()
f.close()
get_template(self.template_name)
self._lock.__exit__(*args, **kwargs)
p.start()
subprocess.Popen([command] + args, startupinfo=startupinfo).wait()
[(4 - x, x) for x in range(5)]
sizer.Add(button, 0, wx.ALIGN_CENTER)
unpickler.load()
image_output.seek(0)
setattr(target, attr, value)
self.w.show()
ast.literal_eval(s)
self.setCentralWidget(self.form_widget)
row.append(0)
outfile.close()
print([i for r in ranges for i in range(int(r[0]), int(r[-1]) + 1)])
any(sublst == lst[i:i + n] for i in range(len(lst) - n + 1))
output = f.read()
f()
print(f.read(line_len).decode())
reader = csv.DictReader(csvfile, fieldnames)
pool.terminate()
a[sort_indices, static_indices[1], static_indices[2]]
int(x) if x else 0
idx = np.array([[0, 0, 0], [1, 1, 0], [0, 1, 2]])
time.sleep(delay)
print(df)
ss.chisquare(FRQ)
matches = list(compress(totalist, selectors))
pool.map_async(f, args)
app.run()
ECD.close()
True
print(sign.getvalue())
B.append(A[0])
plt.contour(X, Y, scalar_field)
net.params
L[:1], L[1:] = L[-1:], L[:-1]
ax = fig.add_subplot(111)
tf.set_random_seed(1)
print(json.loads(jsonstring, object_hook=hinted_tuple_hook))
db.session.add(query)
s.commit()
results.div(weights, axis=0)
os.path.isdir(path)
s.group(0)
data_file.close()
[d[i] for i in k]
factarr * cplxarr.real + 1j * cplxarr.imag
df.iloc[0, 2] = np.nan
f(*args, **kwargs)
print(filename[0])
print(row[0], binascii.b2a_hex(row[1]))
x[1][0][2]
nx.draw(G, pos, with_labels=False, arrows=False)
plt.xticks(rotation=15)
now = datetime.datetime.now()
msg.attach(img)
y_pred = [0, 1, 0, 1, 2, 2, 1]
plt.axis([-2, 2, -12, 12])
setattr(self, name, value)
sum((y_pred - y_true) ** 2, axis=-1)
wx.PyControl.__init__(self, parent, id, **kwargs)
self.d.callback(self.buffer)
[99.0, 99.0, 99.0, 99.0, 99.0, 99.0],
server_ssl.close()
[1, 2]
{y: x for x, y in t}
fliplr(m).swapaxes(0, 1)
stdin, stdout, stderr
window.show()
do_stuff()
f.close()
l.sort()
C = scipy.delete(C, 1, 1)
r = dict(list(a.items()) + list(b.items()) + [(k, a[k] + b[k]) for k in set(b) & set(a)])
shop1()
self.byid[row[0]] = item
input.sort(key=sortkeyfn)
betas.iloc[:5, :5]
print(list(row))
Silly(1)
df.columns = pd.to_datetime(df.columns)
a * b
plt.plot(list(range(10, 20)))
root = tk.Tk()
print([item for items, c in Counter(a).most_common() for item in [items] * c])
writer.writeheader()
r.text
b = map(list, zip(*a))
ax.scatter(x, y, c=z, cmap=cm, norm=norm)
r = proc.stdout.readline()
True
result.append(item)
newList = map(lambda y: max(0, min(255, y)), oldList)
plt.colorbar()
driver.implicitly_wait(20)
print(pool.map(square, range(1000)))
y = np.sin(x)
main()
inspect.isclass(X)
len(self.left) + len(self.right)
res.append(f(v))
out[:-1, :] += tmp[1:, :]
genn(igap, igap + 2)
func2(gen2)
result = []
print(resp.status_code)
plt.show()
ax2.xaxis.set_major_formatter(copy.copy(Formatter))
time.sleep(10)
b = datetime.datetime.now()
id = Column(Integer, primary_key=True)
str(self)
scipy.stats.norm(100, 12).cdf(100)
print(repr(text))
err = p.communicate()[1]
imshow(data)
fcntl.flock(f.fileno(), fcntl.LOCK_EX)
print(a.intersection(b))
df.columns[(df == 0).all()]
grid.cbar_axes[0].colorbar(im0)
app = Flask(__name__)
print(trk.name())
dists.value
file1.close()
myfile.write(S)
smallerThanN([1, 4, 10, 2, 7], 5)
top.mainloop()
z = {(s[x:] + s[:x]) for x in range(len(s))}
print(f.read())
f.close()
pdf.add_page()
__init__.py
np.concatenate((M, new_face), dim)
sys.exit()
width = img.shape[1]
Py_Finalize()
NULL
seq[-a:] + seq[:-a]
name = models.CharField()
self.harmstat = harmstat
current_child.save()
foo[0][0][0] is foo
getattr(self._ref2, name)
s.connect((HOST, PORT))
cursor.execute(query, param)
time.sleep(1.0)
arr = [[] for _ in range(5)]
b = json.loads(a)
myList.sort(cmp_dict)
signal.signal(signal.SIGINT, signal_handler)
print((c, p(c)))
PyObject_HEAD_INIT(NULL)
np.arange(n)
whisper
x = a << 1 & 4294967295
print(paramdata.values)
data = urllib.request.urlopen(url).read()
np.dstack((a1, a1.T)).reshape(-1, 2)
window.fullscreen()
print(sys.argv[1])
f.pack(padx=100, pady=100)
pdf.savefig()
print(re.findall(r, s))
print(my_list)
ax.plot(list(range(10)), color=color)
x = df.reset_index()
pat.findall(text)
conn.close()
plt.xticks(rotation=90)
f.write(e)
yappi.start()
print((x, y))
matches = [string for string in l if re.match(regex, string)]
bool(collections.Counter([1]))
i = np.array([[0, 0], [1, 1]])
df.sort_index(inplace=True)
sys.getsizeof(a)
excel.Quit()
plt.tight_layout()
self.canvas.scan_mark(event.x, event.y)
y = tf.slice(x, [i], [1])
wx.BeginBusyCursor()
[math.sqrt(sum([(i * i) for i in vec])) for vec in x]
myproject / myapp / middleware / globalrequestmiddleware.py
s.sendmail(me, family, msg.as_string())
self.mainframe.grid(column=0, row=0, sticky=(N, W, E, S))
self.canvas.configure(scrollregion=(0, 0, 1000, 1000))
glfw.WindowHint(glfw.OPENGL_FORWARD_COMPAT, GL_TRUE)
print(channel.recv(1024))
print(trimmed_text)
random.shuffle(shuffled)
htmlentitydefs.entitydefs[x[1:-1]]
fig, ax = plt.subplots()
shutil.move(tempname, zipfname)
start_time = time.time()
sys.stdout.flush()
db.commit()
turtle.mainloop()
Counter(myletters)
df
writer.writerow(fields)
new_file.write(new_line)
datetime.date(2011, 1, 1)
list(df)
QObjectCleanupHandler().add(self.layout())
D = np.diff(np.sort(product.T, axis=0), axis=0) == 0
Notification.objects.exclude(pk__in=list(notes)).delete()
A[(idx), :]
my_list.Skip(1).Concat(my_list.Take(1))
print(data.text)
x = np.linspace(0, 10, 50)
x, y, z = v
deletex[key]
a = np.frombuffer(array_pointer.contents)
ax = fig.add_subplot(111)
print(paragraph.text)
new_a = np.delete(a, index)
self.fileobj.fileno()
c = matplotlib.pyplot.contour(x, y, f(x, y))
c = [tuple([(i + j) for i, j in zip(e, b)]) for e in a]
self.num = 1
df = pd.DataFrame(data)
Py_Initialize()
self.sock.listen(5)
tree.add(0)
server.listen(5)
fig = plt.figure()
df1.index.get_loc(t)
inner1()
data = s.recv(2048)
main()
l.pack()
model.fit(X)
created_at = models.DateTimeField()
output.close()
flipbf(m).swapaxes(0, 2)
root = Tk()
shutdownJVM()
instance.save()
d + (date(d.year + years, 1, 1) - date(d.year, 1, 1))
newList = [elem for elem in oldlist]
dct = dict(zip(l2, lens))
yaml_file.write(yaml.dump(data, default_flow_style=False))
id = Column(Integer, primary_key=True, nullable=False)
sys.stdout.write(format % args)
np.issubdtype(np.void, np.integer)
ax.set_xlim(-0.5, 4.5)
self.assertEqual(first, second, msg)
child.start()
list(incremental_range(0, 20, 1, 1))
np.array_split(a, [1], axis=1)
df.index = pd.to_datetime(df.index)
QtCore.QThread.__init__(self)
print([int(ch) for i in list1 for ch in str(i)])
print((k, list(g)))
print(my_object)
plt.scatter(i, y)
foofunc()
ax.set_ylim(6, 24)
b.append((begin, end))
functest()
os.fsync(f.fileno())
threading.Thread.__init__(self)
(w for w in wordlist if is_neighbors(word, w))
plt.show()
pandas_df_to_markdown_table(infodf)
d[key].append(list(value))
build_cscript()
{{(img.height | div): 2}}
d.update({1})
plt.show()
dev.ledstates(verbose=True)
arr = input().split()
dicC.update(dicB)
x = np.linspace(0, 1, N)
foo()
httpd.serve_forever()
list(self).index(obj)
foo = np.array([[0, 1], [1, 1]])
instance = klass()
pygame.camera.quit()
print_foo()
c_uint.__init__(self, value)
crl_url.strip()
ax2 = fig.add_subplot(122)
process.start()
main()
w = Button(root)
fig.canvas.draw()
self.scat.set_offsets(data[:2, :])
_draw_point(renderer, position, i, j + 1)
app.exec_()
df = pd.concat([df[df.columns[:5]], a], axis=1)
np.index_exp[10:4, ::-1, ...]
sys.exit()
content = resp.read()
print(dtd.error_log.filter_from_errors())
contourf(x, y, H1, levels1, cmap=cmap_lin1)
plt.gca().add_collection(lc)
plt.show()
now = time.time()
mask = x == 0
browser = webdriver.Firefox(fp)
fig.subplots_adjust(wspace=0, hspace=0)
fp.close()
pygame.draw.rect(game_display, (255, 0, 0), rect_one)
app.debug = True
inner1d(U.transpose(0, 2, 1), V.T)
test.main()
G = nx.Graph()
plt.show()
abs(x), angle(x)
self.scat = self.ax.scatter(x, y, c=c, s=s, animated=True)
False
plt.plot(np.sin(np.linspace(0, 10, 100)))
locale.setlocale(locale.LC_ALL, loc)
G.add_node(1)
a[:i] + MIDCHAR
next(self.iterator)
f.close()
time.sleep(10)
name = models.CharField(max_length=64)
heap_sort()
print(list(range(maxend - maxrun + 1, maxend + 1)))
np.random.seed(1977)
fig, ax = plt.subplots()
reuests.post(url, files=files)
pdb.set_trace()
de[i].extend(j)
sphinx - apidoc - -help
print(functools.reduce(lambda x, y: x & y, [a, b, c]))
f(*args, **kwds)
opener = urllib.request.build_opener()
gc.collect()
np.random.choice(choices, 5, p=counts / len(a), replace=False)
print(hashlib.sha1(bencode.bencode(info)).hexdigest())
do_something(line)
self.stdin.flush()
os.unlink(filename)
pl.show()
plt.xlim([min(data) - 5, max(data) + 5])
admin.site.register(Person, PersonAdmin)
main(sys.argv)
time.sleep(1)
a[0] += 1
list2 = [1, 1, 0, 0, 1]
conn = pymongo.MongoClient()
len(nearbystrikes) > 0
server.starttls()
apos += alo
a, b
pd.read_json(json.dumps(r)).unstack()
u.delete()
id = Column(Integer, primary_key=True)
time.mktime(date.timetuple())
suite = unittest.TestSuite()
self.table.item(1, 0).setBackground(QtGui.QColor(125, 125, 125))
tk.Frame.__init__(self, *args, **kwargs)
setp(ax2.get_xticklabels(), visible=False)
d.apply(pd.value_counts)
{k: (v[0] if len(v) == 1 else v) for k, v in qdict.lists()}
np.where(y == 0, 0, x / y)
deletelist_2[int(i)]
help(window.set_position)
[5] * 4
simulations_to_run.join()
s.connect((TCP_IP, TCP_PORT))
print(df.head())
df = pd.DataFrame()
iren.Start()
s.starttls()
self.driver = webdriver.Firefox()
d1.update(d2)
ranges.append((1, 10))
4.0 * scipy.integrate.nquad(f, ([0, d / 2], [0, d / 2]))[0]
myDictionary.get(key)
[1, 2, 5, 6, 7, 10]
json.JSONEncoder.default(self, obj)
p = pyaudio.PyAudio()
ax.set_xlim([-2, 2])
t.start()
app = QtGui.QApplication(sys.argv)
np.argsort(x)
os.setsid()
query_set.filter(deleted_at__isnull=True)
getattr(c, m)()
seen.add(x)
f = x.decl()
numpy.random.bytes(length)
label.pack()
a *= a > 0
tree = lxml.etree.fromstring(doc)
loop.run_forever()
print(len(lines))
pyplot.plot(x, y)
dir = os.path.dirname(os.path.dirname(file))
self.transport.loseConnection()
connection.close()
mail.sendmail(EMAIL_FROM, EMAIL_TO, msg.as_string())
ax.plot(x, y)
DF.cumsum()
thirdpartymodule_b.dosomething()
list(le.inverse_transform([2, 2, 1]))
self.root.mainloop()
roc_curve(y_true, y_score)
print(ascii_num[::-1])
MDD_start, MDD_end, MDD_duration, drawdown, UW_dt, UW_duration
print([(r / s) for s in [psum(raw)] for r in raw])
layout.addWidget(self.toolbar)
p = subprocess.Popen(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
zip(cv.get_feature_names(), np.asarray(X.sum(axis=0)).ravel())
{x: (0) for x in alphabet}
id = db.Column(db.Integer, primary_key=True)
data = np.random.normal(size=1000)
df = pd.read_csv(io.StringIO(data))
dfcopy.a.ix[0] = 2
subprocess.call(args)
round(2.605, 2)
round(2.067, 2)
file.seek(lastKnownSizeOfFile)
Base2.bar()
res.read()
print(list(filter(len, a)))
s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
plt.bar(x2, y)
print([(2 ** ((N - abs(N - k)) % N)) for k in range(2 * N + 1)])
ax2.plot(list(range(10, 20)))
print(PATTERN.split(data)[1::2])
X[::-1, ::-1, ::-1]
fout.write(regex.sub(replfunc, line))
print(tuple(l))
df1.join(df2)
X = X.reindex(np.roll(X.index, 1))
x = a if b else 0
img = plt.imread(filename)
ax.legend()
sorted(y, key=x.__getitem__)
fig = plt.figure()
root = Tk()
c.setopt(c.URL, url)
df = df.loc[(df[col].isin(counts[counts > threshold].index)), :]
s = f.read()
y = np.arange(Y)
print(i, j, k)
table.sort(reverse=True, key=Team.getPoints)
result.append(list(g))
unittest.main()
logger.removeFilter(dup_filter)
print(get_image_info(data))
plt.ylim(0, 40000)
print(soup.prettify())
print(resp.url)
fig, ax = plt.subplots()
conn = boto.connect_dynamodb()
s[0]
QApplication.__init__(self, *args)
print(key, value)
df = pd.DataFrame(a.T)
ax.set_yticks([])
ax = fig.add_subplot(121)
self.assertEqual(404, response.status_code)
plt.draw()
self.myParent.grid_columnconfigure(0, weight=1)
tuples = list(d.values())
m.mymethod()
stdscr.refresh()
[1, 2][::-1]
zip_longest(fillvalue=fillvalue, *args)
list(OrderedDict.fromkeys(items))
random.seed(42)
list_of_pairs = [(p1, p2) for p1 in people for p2 in people if p1 != p2]
time.sleep(5)
li = [id_s[c] for c in list]
plt.bar(df.index.to_pydatetime(), df.Val, width=0.4)
pad.refresh(top, 0, 0, 0, curses.LINES - 1, curses.COLS - 1)
app = Flask(__name__)
dict.__setitem__(self, key, value)
os.makedirs(directory_name)
new_a = a[(a <= 100).all(1)]
ax.set_ylim(0, 5)
[str(v) for v in obj.attrs.all()]
c = copy.deepcopy(a)
namestr(a, globals())
df[df.a < np.percentile(df.a, 95)]
func(b)
np.linalg.norm(coef, axis=0)
open_file.close()
pprint.pprint(arr)
z.update({key: value})
all_pairs += [((nB, 1), (nC, 2)) for nB, nC in itertools.product(listB, listC)]
(data[index] for index in indices[field][key])
result._fields
df = pandas.DataFrame(data)
print(np.corrcoef(x_tag[0:len(x_tag) - 1], x_tag[1:])[0][1])
df.apply(make_plot)
(i.bit_length() + 7) // 8
ordered = list(list_dict[val] for val in ordering_list)
print(df5.groupby(level=0).apply(process))
self.show()
np.argwhere(np.in1d(a, np.intersect1d(a, b)) == False)
get_max(my_list)
plt.gcf().gca().add_artist(circle1)
cursor.execute(query, [id])
newlist = old_list.copy()
imshow(A)
ax1.set_xlim(0, 1000.0)
matrix[~mask] = 0
ax.w_zaxis.set_major_locator(LinearLocator(10))
self.SetSizer(self.sizer)
zfile.close()
[(id(x) == id(y)) for x, y in zip(lis, new_lis1)]
plt.ylim(ymin, ymax)
s += etree.tostring(sub_element)
writer.writerows(row[:1] + [0.0] + row[1:] for row in reader)
ax.grid()
plt.show()
print(soup.p)
new_list.append(l1[index] + l2[index])
cursor.execute(sql)
dilation.process(tree.clone(), tree)
f(1)
aList.sort(key=lambda x: (x[idx] for idx in args))
Counter(string)
numpy.vectorize(complex)(Data[..., (0)], Data[..., (1)])
port = int(port)
type(data)
plt.draw()
root = ET.fromstring(xmlstr)
random.sample(list(enumerate(l)), 5)
print(df)
stupidtrick()
parser = argparse.ArgumentParser()
1 / (1 + math.exp(-x))
db.create_tables([ModelA, ModelB, ModelC])
imshow(cm.hsv(Z1), alpha=0.6, extent=extent)
model = Sequential()
myDB.connect()
writer.writerow(row)
all([0, 1])
[s[5 * i:5 * i + 5] for i in range(0, math.ceil(len(s) / 5))]
x = [n.strip() for n in x]
a.A()
axins1.set_xlim(x1, x2)
socket.setdefaulttimeout()
audio /= np.max(np.abs(audio), axis=0)
map(str, lst)
plt.subplots_adjust(bottom=0.15)
result = sum(range(1, 401, 4))
text_entry.pack()
A[:] = somedata[:]
results.append((a[first][0], a[second][0], a[third][0]))
self.builds = builds
print(lines[:100])
cost_obj.save()
UserModel.save(using=db, force_insert=True)
ip = socket.gethostbyname(socket.gethostname())
self._result.addFailure(self, sys.exc_info())
matplotlib_fig.show()
g.__code__.co_name
nlargest(n, your2DList, key=lambda x: x[-1])
df = pd.concat([df] * 100000).reset_index(drop=True)
plt.show()
ax.plot(list(range(10)))
sys.stdout.flush()
root2.minsize(root2.winfo_reqwidth(), root2.winfo_reqheight())
webbrowser.open_new(url)
a[-1].shape
e.pack()
plt.plot(np.cos(np.linspace(0, 10, 100)))
d.bar()
handles, labels = plt.gca().get_legend_handles_labels()
a.add(x)
foofoo.py
os.kill(int(sys.argv[1]), 0)
strat1.execute()
nil
dictionary[len(i)] += 1
response = urllib.request.urlopen(url)
sorted(l, key=alphanum_key)
datetime.datetime.now()
help(raw_input)
matmult(x, y)
g.index = g.index.swaplevel(1, 2)
creatures = dict()
meds.sort(ascending=False)
canvas.pack(side=LEFT, fill=BOTH, expand=TRUE)
print(self.parent.__name__)
time.sleep(0.1)
fig, ax = plt.subplots()
next(combs2)
app.run(debug=True)
print(type(data))
__init__.py
row, col = numpy.where(M == 0)
self.setupUi(self)
plt.plot(x, 4 * x)
pnt.ewkt
__init__.py
ax.set_xlim(0, 10)
arg[::-1]
plt.scatter(a[0], a[1], s=50, c=colormap[categories])
ax = plt.gca()
size = models.IntegerField(blank=True, null=True)
dct = dict(zip(ascii_uppercase, lens))
self.model = QtGui.QStandardItemModel()
sublist.sort()
len([letter for letter in word if letter not in BAD_LETTERS])
plt.figure(2)
shutil.copyfileobj(r, f)
len(response.content)
plt.show()
a.append(a.pop(0))
print(f.info())
os.unlink(targetLink)
b_result.append(b)
pd.read_csv(s, parse_dates=[0], dayfirst=True)
tuple(l)
objs.append(pickle.load(f))
df
response
pl.hist(data, bins=np.logspace(0.1, 1.0, 50))
x = copy.deepcopy(y)
print(sys.executable)
self.process.communicate()
print(utc_dt.astimezone(get_localzone()))
len(set(list_)) == len(list_)
httpd.serve_forever()
print(self.__class__.__dict__)
final_ensemble.estimators_ += ensemble.estimators_
s = requests.Session()
print(abs(x) % 1000)
logger.removeHandler(logger.handlers[0])
self.foo.start()
[1695.86408654, 2140.0, 6969.0],
msg = MIMEMultipart()
s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
print(key)
f.seek(999999)
l = list(filter(str.strip, l))
form = ContactForm(request.POST)
root.mainloop()
result = [myFunc(p, additionalArgument) for p in pages]
b()
end_date[-1] = end_date[-1][:4]
Counter(map(tuple, a.T))
pylab.show()
kpt_data.reshape(h_r.shape[:2] + (-1,))
x.upper()
gobject.threads_init()
tt = matplotlib.delaunay.triangulate.Triangulation(x, y)
time.sleep(0.01)
time.sleep(0.1)
R1.__init__(self)
print(types[bisect.bisect(points, Point(0.1, 0.1)) - 1])
time.sleep(seconds / 1000000.0)
root.mainloop()
wtr.writerows(in_iter)
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
s[1]
list(chain.from_iterable(zip(data, tweets)))
lines = (line.rstrip() for line in f)
s.set_debuglevel(1)
stdoutdata, stderrdata = proc.communicate()
open_workbook(excel_file_full_path, formatting_info=True)
df.university.apply(extract_city)
sys.exit(app.exec_())
self._exit()
arr2d.sum(1)
HypotheticalBranch(0, 1, 1)
shutil.copyfileobj(zf, f)
Parent.__init__(self, *args, **kwargs)
df.reset_index()
ax = plt.gca()
file.seek(-1024 * 1024, os.SEEK_END)
a = numpy.empty(n, dtype=object)
np.array(sorted(set(a) | set(b)))
self.button.clicked.connect(self.plot)
writer = csv.writer(f)
plt.axis([-1, 6, 0, 6])
ftp.close()
pygame.draw.circle(screen, COLOR, POS, RADIUS, WIDTH)
pprint.pprint(w.config())
float(num) / float(denom)
result
path = urllib.request.url2pathname(path)
md5.digest()
logger.setLevel(logging.ERROR)
cmyk.append(cmyk_im[i].load())
loop.close()
print(C.x.__doc__)
newImage.paste(srcImage, (x1, y1, x1 + oldWidth, y1 + oldHeight))
f.close()
[hash(tpl[0]) for tpl in stackframe[1:]]
timediff.total_seconds()
loop.run_forever()
itertools.zip_longest(fillvalue=fillvalue, *args)
ax.plot(VecStart_x + VecEnd_x, VecStart_y + VecEnd_y, VecStart_z + VecEnd_z)
{k: v for k, v in list(d.items())}
foo()
xml.write(m.group(1))
joint = [[(x + y) for x, y in zip(*row)] for row in zip(outgoing, incoming)]
l.pack()
frozenset().union(*l)
np.array(test)
list(a.keys())
self.val = 0
list(accumulative_product(A, B, C))
server_socket.bind((HOST, PORT))
gevent.joinall(greenlets)
print(myzip.namelist())
pool = multiprocessing.Pool(processes=cpus)
df.drop(df.columns[1:], axis=1)
urllib.request.HTTPSHandler.__init__(self)
plt.hold(True)
plt.boxplot(x)
layout.addWidget(self.button)
a.reshape((-1, 5))
lines.append([(lastX, lastY), (lastX + 1, lastY)])
Planet.MERCURY
print(soup)
out, err = proc.communicate()
engine.block()
p.start()
root.mainloop()
out = abs(z[..., (np.newaxis)] - z)
_nextkey += 1
hash(foo)
cv2.drawContours(drawing, [cnt], 0, (255, 255, 255), 2)
self.platforms.append(p)
app.MainLoop()
list(gen())
df = pd.read_excel(path + filename)
pd.infer_freq(ts.index)
c.execute(sql, tup)
f.close()
temp_list.append(item)
{{(floatvalue | floatformat): 2 | intcomma}}
data = data.reshape(shape)
[0, 2, 4, 10, 12, 14, 20, 22, 24]
gamma + log(n) + 0.5 / n - 1.0 / (12 * n ** 2) + 1.0 / (120 * n ** 4)
print(m.start(), m.group())
pygame.display.update()
imp.find_module(imported)
list(filter(pattern.match, strings))
sorted(lst, reverse=True)
print(arr.reshape(2, 2, 2, 2).swapaxes(1, 2).reshape(2, 2, 4).max(axis=-1))
my_list = list(my_iterable)
form.field(disabled=True)
data.append(group_data)
spsd.euclidean(nparray1, nparray2)
self.ax.add_patch(self.rect)
list(enumerate([4, 5, 6, 7]))
setattr(cls, membername, lockedmethod)
pd.concat([Out[24], Out[25]], axis=1)
chain.from_iterable(listOfLists)
range_prod(1, n)
print(driver.page_source)
System.out.println(id.getClass().getName())
random.choice([4, 5, 6])
im = Image.open(StringIO.StringIO(f.read()))
a[y[:-1]] -= x[:-1]
foosparse[key1, key2] = value
browser.driver.set_page_load_timeout(10)
soup = BeautifulSoup(urllib.request.urlopen(url).read())
fitness_landscape.shape
func(*args, **kw)
[list(g) for _, g in groupby(sorted(flat, key=len), key=len)]
sys.exit(app.exec_())
a, b, c = [list(g) for k, g in it.groupby(mylist, keyfunc)]
axes.hist(x, bins=binedges, weights=weights, *args, **kwargs)
args = parser.parse_args()
canvas.setStrokeColorRGB(0, 0, 0)
self.opt.stdin.write(string)
type(a)
data = np.zeros((200, 200), dtype=np.float)
cursor.fetchall()
list[list.index(target) - 1]
pl.ylim(0, ymax)
print(sorted(a, key=to_minutes))
array.sort(key=lambda item: item is 0)
iv = Random.new().read(16)
[remove_bad_substrings(s) for s in sites]
net.addModule(hidden1)
zelib.multiplier.argtypes = [ctypes.c_float, ctypes.c_float]
ax.xaxis.set_major_locator(ticker.MultipleLocator(1))
word[-1:-len(word) - 1:-1]
path = os.path.join(os.path.dirname(__file__), template_file)
traceback.print_stack(file=sys.stdout)
etree.tostring(fragment)
sleep(10)
list(result[0][1].keys())
response = urllib.request.urlopen(req)
[convert_value(item) for item in lst]
df.update(df2)
r = np.linspace(1, 5, n)
n, bins, patches = plt.hist([x, y])
same_structure(a[1:], b[1:])
plot(c(0, 1), c(0, 1))
fig.tight_layout()
np.resize(a, 10).reshape(5, 2)
plt.clf()
len(df)
print(drives)
np.allclose(OP(cords, atoms, atom_proj), project_atom(cords, atoms, atom_proj))
screen.keypad(0)
list(test)[0]
print(ast.literal_eval(input()))
array([True, True, False], dtype=bool)
app.exec_()
xs = np.array([[0, 1, 0], [0, 0, 1], [0, 1, 1]]) * 1.0
df.set_index(keys=[df.index.year, df.index.month]).transpose()
set(MyList).intersection(MyDict)
functools.reduce(op.mul, (sum(x) for x in zip(*list_)))
ax.set_ylim(ybnds)
PROJECT_ROOT = os.path.realpath(os.path.dirname(__file__))
plot(x, y1)
pdb.set_trace()
arr = numpy.array(data)
self.apple_button.Bind(wx.EVT_BUTTON, self.apple_button_click)
fig.autofmt_xdate()
slice_list(x, 7)
br.select_form(nr=0)
draw.ellipse((0, 0) + size, fill=0)
timedelta(hours=2)
d[x].append(y)
plt.gca().add_artist(leg1)
plt.gca().add_artist(leg5)
window.show()
np.set_printoptions(suppress=True)
repr(s)
[0.0, 0.0] / sum([0.0, 0.0])
arr.sum(axis=0).shape
content = file.read()
[list(g) for k, g in groupby(l, bool) if k]
data = json.dumps(data, cls=DjangoJSONEncoder)
frame = pd.read_csv(path, names=columns)
xlim(0, 1)
draw()
plt.show()
p = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.IGNORE)
server.close()
array([0, 2, 4], dtype=int64)
Py_Initialize()
email.send()
d = {}
print(df1.groupby(df1.columns, axis=1).sum())
self.close()
df = pd.DataFrame(m.toarray())
parent.kill()
sys.stderr.close()
B = np.array(A)
Qapp.exec_()
ax = fig.add_subplot(111)
_draw_point(renderer, position, i, j)
print(lol[1:4, 2:5])
self.listofrecords[listnum][record] = value
True
sqllogger.addHandler(sqlhandler)
session.quit()
indices = np.searchsorted(u, arr.flat)
False
self.a + self.b
hxs = HtmlXPathSelector(response)
plot(x, cos(x))
pprint(ddiff)
time.sleep(0.1)
example_df.iloc[(1), :].corr(example_df.iloc[(2), :])
print(zlib.decompress(b))
[x for xs in a for x in xs]
connection.close()
self.__class__.bar(self)
server.sendmail(FROM, TO, message)
ax.scatter(x, y, z)
time.sleep(1)
results = [do_smth(file.read()) for file in files]
ar.sort()
data = np.random.normal(0, 20, 1000)
threading.Thread.__init__(self)
x = np.array(x, copy=False, ndmin=1)
s = pd.Series(np.random.randn(n).cumsum())
plt.plot(X[i])
out = [float(f_interp(*p)) for p in zip(X, Y)]
fig = plt.figure()
self.delete(0, Tkinter.END)
a[0] = [1, 2]
print(isinstance(MyClass, MyClass()))
plt.scatter(X, Y)
pool.join()
main()
l = []
print(dtd.validate(root))
True
ax.set_xticklabels(labels, minor=False)
[given[i:i + len(sublist)] for i in range(0, len(given) - len(sublist))]
out = data[np.in1d(data[:, (1)], goodIDs)]
df.mean()
admin.site.register(Foo, FooAdmin1)
[seq[i:i + k] for i in range(0, len(seq), k)]
plt.ylim(-0.1, 1.1)
np.vstack(np.unravel_index(indices, arr.shape)).T
unwrap_method(get_func) is unwrap_method(Client.get)
Permission.objects.all()
setattr(something, k, v)
pygame.display.flip()
ts.ix[ts.index.indexer_between_time(datetime.time(10), datetime.time(14))]
main()
list(set(x[0]).union(*x[1:]))
List.append(Item)
fig = plt.figure()
kde.integrate_box_1d(1, 2)
sys.stdout.write(out)
bstr[0]
A[(1), (1), :]
print([str(x) for x in l])
set.intersection(*lis)
[[0, 1][name.split()[-1] in set(B)] for name in A]
self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
browser.back()
True in set(map(lambda x: x[0] == 1, a_list))
output.addPage(page)
regex = re.compile(pattern, re.MULTILINE | re.DOTALL)
print(solution(list(range(1, 2000))))
s = requests.session()
self.setCursor(QtCore.Qt.SplitHCursor)
self.log.addHandler(self.handler)
chardet.detect(elems[0].getText())
path = os.path.dirname(os.path.abspath(filename))
sys.getwindowsversion()[0] >= 6
app.exec_()
print(LH.tostring(doc, pretty_print=True))
start_time = time.time()
self.forms[self.initial_form_count():]
fig = plt.figure()
p = Pool(1)
keys[-1] in lastplace
result = cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)
ax.set_ylim(bottom=0)
df = xl.parse(0, converters={i: str for i in range(ncols)})
dict_lol = {item[1]: item for item in lol}
re.findall(regex, statements, re.I)
sys.stdout.write(line)
csvfile.seek(0)
player_list.append(player)
admin.autodiscover()
main()
ax.set_rmax(1.25)
cur.execute(sat)
b.shape
foo
a + b * c
arr.resize((k, M))
print(b[0])
y = 2 * np.sin(x)
f.close()
print(match.group(1))
object.__setattr__(self, name, value)
func()
counts[item] += 1
pipeline.fit(X, Y)
im.resize(size, Image.BILINEAR)
env.use_ssh_config = True
polB.set_transform(tB)
clipboard.store()
np.all([i for i in range(10)])
sess.run(init_op)
mylist.append(first_el)
idx = list(range(len(S)))
obj.__class__._default_manager.get(pk=obj.pk)
dict(page=context)
d[i].append(int(j))
[list(islice(it, i)) for i in b]
db.connections.close_all()
plot(list_of_dates, counts)
fs.noteoff(0, 60)
z = [int(i == j) for i, j in zip(x, y)]
print([joiner(words) for words in sixgrams])
ctx.set_source_rgb(1, 0, 0)
print(message.get_body_encoded())
zipped = zip(*l)
A[:, ([1, 2])]
plt.scatter(x, y)
str({})
doSomething()
y = x.reshape(x.shape[0] / 2, 2, x.shape[1] / 2, 2)
array_to_filter[np.in1d(array_to_filter, equal_array)]
s = list(filter(str.isalnum, s))
tar.close()
self._socket.recv(buffersize, flags)
send_mail(subject, message, settings.DEFAULT_FROM_EMAIL, [self.user.email])
lst.insert(randrange(len(lst) + 1), item)
bin(10)
os.dup2(se.fileno(), sys.stderr.fileno())
self.fc2.draw()
[getrange(x) for x in newlist]
self.navigate(1)
j = index - d * (d - 1) / 2 + (d - i) * (d - i - 1) / 2 + i + 1
username = db.Column(db.String(80), unique=True)
np.allclose(old, new)
root.update()
print(p.pattern)
NULL
list(set(x[-1]).union(*x[1:]))
b = np.dot(a, c)
time.sleep(1)
app = Flask(__name__)
client.set_options(soapheaders=ssn)
QtGui.QLabel.__init__(self)
setattr(modadd, camel_name, f)
df2 = df2.reset_index()
driver.switch_to_default_content()
func(obj, *args, **kw)
image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
Bar.py
Html_file.write(html_str)
python - i
main(sys.argv[1])
array([10, 4, 1], dtype=int64)
ET.fromstring(t)
len(new_strs.split())
log.setLevel(logging.INFO)
foundwords.extend(words[1:])
QtGui.QMainWindow.__init__(self)
results = sorted(results, key=getaccountingdate, reverse=True)
deletealist[i]
t.start()
wf.close()
logger.info(parsed_item_info)
tag.save()
cursor.execute(sql)
self.image.set_from_pixbuf(loader.get_pixbuf())
url
foo()
webapp2.RequestHandler.dispatch(self)
br = mechanize.Browser()
self.wfile.flush()
ax = plt.subplot(111)
time.sleep(0.5)
CE, BF, BC, BD, BE
do_stuff()
perf_func(root.getroot(), print_level)
x if f else random.choice(good)
today = datetime.datetime.today()
curs.fetchone()
fd.close()
self.results.append(result)
List.append(Item)
sys.getsizeof((1, 2))
a[0:1] = [1]
ax1.semilogx(data[:, (1)], data[:, (2)])
results = pool.map(solve1, args)
fig = plt.figure(figsize=(10, 8))
os.close(fd)
[func(mylist) for func in map(globals().get, fxnOfInterest)]
os.path.join(path, filename)
print(p.communicate()[0])
a, b = b, a + b
type(d)
print(finfo.dtype, finfo.nexp, finfo.nmant)
threading.Thread(target=thread_job).start()
window.show()
xl.Workbooks.Close()
pool = multiprocessing.Pool()
deleteL[-n:]
np.testing.assert_allclose([np.nan], [np.nan])
app = QtGui.QApplication(sys.argv)
w.show()
f.close()
root.rowconfigure(1, weight=1)
q = A.select(A, B).join(B).where(B.date == last_entry_date)
r.close()
tornado.ioloop.IOLoop.instance().start()
index = d * (d - 1) / 2 - (d - i) * (d - i - 1) / 2 + j - i - 1
dict.__setitem__(self, key, val)
g.Category.apply(pd.value_counts).unstack(-1).fillna(0)
a[i]
df
value.__format__(format_spec)
random.shuffle(s)
a.upper() == b.upper()
pool.join()
MySuperClass.__init__(self)
conn.perform()
d = datetime.datetime.now()
g.add_edge(1, 2)
db.session.remove()
df.to_records().dtype
a = [([k] + [x[1] for x in g]) for k, g in groupby(r, key=lambda row: row[0])]
dumps(a.__dict__, default=encode_b)
logging.getLogger().setLevel(logging.DEBUG)
do_stuff(A[i], A[j])
C = np.empty((A.shape[0] + B.shape[0], A.shape[1]))
root = Tk()
script = os.path.abspath(sys.argv[0])
print(sys.executable)
self.setCentralWidget(page)
[distance(*pair) for pair in zip(repeat(pts[0]), pts[1:])]
your_module.get_logger().log_to_file(filename)
print(set(n1).difference(set(n2)))
bin(7)[2:]
res.fillna(0).squeeze().dt.days
ax.set_ylim(ylim)
ax1 = fig.add_subplot(121)
conn.commit()
ex2.show()
QtCore.QSize(150, 75)
print(tuple(pad_strings(x)))
14.078685
ax.scatter(x, y, c=colors, s=50, cmap=mpl.cm.Reds)
plt.figure()
process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)
outfile.close()
fig, ax = plt.subplots()
print((i, l))
print(pool.map(f, list(range(10))))
B = A[[col1, col2]].iloc[idx]
plt.legend(handles=[select], scatterpoints=1)
browser.submit()
df
f(*args, **kwds)
stack.append(stack[-1][-1])
zf.write(os.path.join(dirname, filename))
self._children = []
contents.sort(key=itemgetter(1))
df = df.reset_index()
plt.style.use(style_name)
DISPATCH()
canvas.rect(i, 0, 2, 100)
df.apply(lambda x: x.astype(object).replace(1, x.name))
np.split(df1.index[c], np.flatnonzero(r[1:] > r[:-1]) + 1)
traceback.print_stack()
help(myFunc.__code__)
self.panel.Bind(wx.EVT_KEY_DOWN, self.OnKeyDown)
grid = np.random.random((10, 10))
new_dic[1][2] = 5
x.astype(int)
print(sum([float(x) for x in re.findall(p, test_str)]))
x * 2
sorted(files)
tar.add(source_dir, arcname=os.path.basename(source_dir))
biglist2.sort(key=(operator.itemgetter(2), operator.itemgetter(0)))
dict((k, v) for k, v in list(mydict.items()) if k >= 6)
plt.plot([pt[0], pt[0]], [0, pt[1]])
tk.Canvas.__init__(self, *args, **kwargs)
raise ValueError((a, b))
True
name = models.CharField(max_length=100)
data = np.array([1, 4, 5, 5, 6, 8, 8, 9])
str(datetime.strptime(value, FORMAT_STRING))
do_something()
handle.close()
plt.show()
ao[1:, :-1] += ai[:-1, 1:]
df2 = pd.read_csv(StringIO(df2_text), delim_whitespace=True)
float(Mixed(1, 1, 2))
isinstance(x, list)
plot(a[:, (0)], a[:, (1)])
ax.plot(theta, r)
print(len(set(probes)))
data = dd.from_pandas(df, npartitions=2)
frame.append(1)
localtime(now()).date()
x[x]
models.py
y = np.array([1, 2, -1, 1, 1])
g.axes[0][0].legend(loc=1)
cnx.close()
self.canvas.clear()
spam.ham
plt.imshow(np.random.random(100, 100))
print(k, v)
server.quit()
[staging]
print(str_to_type(v))
doSomething()
reader = csv.reader(f)
traceback.print_stack()
writer = csv.writer(f)
print(img.shape)
p = argparse.ArgumentParser()
print(file.read())
image.set_from_stock(gtk.STOCK_CLOSE, gtk.ICON_SIZE_MENU)
plt.yticks(pos, labels.sort_index())
0.2775516299989249
plt.show()
math.degrees(math.atan(1))
a[0:1] = [1]
np.random.seed(10)
f.write(site.read())
user = User.objects.get(pk=request.user.id)
__main__.py
db.delete(item)
words = {}
parser = argparse.ArgumentParser()
os.path.join(path, filename)
[x for xs in a for x in xs]
print(response.content)
True
i += 1
self.assertEqual(fn(i), output[i])
ordereddict.py
any(c in yourString for c in badChars)
{{(img.height | add): 1}}
self.request.send(self.data.upper())
setattr(self, key.lower(), val)
glDrawArrays(GL_TRIANGLE_STRIP, 0, 4)
[iplocation]
c = sorted(set(a).intersection(b))
print(in_nested_list(x, []))
sys.exit(1)
listofLines.sort(key=extract_time)
print(df.values.flatten())
setattr(self, name, callable)
print(map(lambda x: not B_set - set(x), A))
main()
reactor.connectTCP(host, port, factory)
ps.wait()
thisprogramdoesntexist
jsonFile.truncate()
1 / 2
Response(serializer.data, status=status.HTTP_201_CREATED)
fig, ax = plt.subplots()
f.write(line)
data = json.load(contactFile)
pprint(sorted(list(results.items()), key=lambda x: x[1]))
l[:n] + [0] * (n - len(l))
obj_list[0].do_somthing()
tuple(y)
b = np.random.rand(10, 10)
method(*args, **kwargs)
instance.topping_set.add(topping)
time.sleep(2)
main()
os.mkfifo(thefifo)
ax = fig.add_subplot(111)
data[data < threshold] = 0
B[:, (col)] = np.prod(np.delete(A, col, 1), 1)
d.replace(hour=0, minute=0, second=0, microsecond=0)
time.sleep(2)
random.shuffle(rects)
powerpoint.Quit()
main_window.show()
f()
print(list(itertools.chain(*list(parser_config.keys()))))
a = np.array([1e-09])
A.columns = pd.MultiIndex.from_product([list(range(A.shape[1] / 10)), list(range(10))])
z.set_zorder(-1)
pool = multiprocessing.Pool(4)
conn.close()
np.where(abs(arr_f - a) < t)[0].any()
a = np.arange(8)
f_new.write(line)
do_something(item)
print(df.sum(1).to_frame().dot(df.sum().to_frame().T).div(df.sum().sum()))
json.loads(json1)
Py_Finalize()
self._connect()
df = df.reset_index()
print(requests.post(endpoint, data=data, headers=headers).json())
lib.get_strings(c_array, len(list_to_send))
conn.sendmail(sender, destination, msg.as_string())
mat - vec[:, ([0, 0, 0])]
A.reshape(h // ph, ph, w // pw, pw, -1).swapaxes(1, 2).shape
reactor.run()
self.driver.close()
(m.transpose() - v).transpose()
collections.Counter(x) == collections.Counter(y)
logging.getLogger().setLevel(logging.DEBUG)
self.window.show_all()
list(chain(ls[:idx], replace_with, ls[idx + 1:]))
print(np.corrcoef(x[0:len(x) - 1], x[1:])[0][1])
s.commit()
f.writelines(lines)
os.chmod(full_path, stat.S_IWRITE)
data = numpy.fromfile(f, dt)
pd.io.json.dumps(summary, double_precision=2)
revlist(lst[1:]) + [lst[0]]
foo = Foo()
[5, 7, 9, 11]
ShapedFrame().Show()
stack[-1].append(x)
file.close()
id = Column(Integer, primary_key=True)
main()
pool = Pool(processes=4)
plt.plot(sorted, yvals)
plt.show()
df.set_index([0, 1], inplace=True)
connection.close()
b = Matrix([[0, 0], [0, 0]])
files.sort(key=os.path.getmtime)
mainloop()
lst[:] = whatever
newlist = [[y[0] for y in list if y[1] == x] for x in values]
d.setdefault(word[0].lower(), []).append(word)
a[:, (0)]
urllib.request.Request.__init__(*args, **kwargs)
type(dates[0]) == pd.tslib.Timestamp
entry_list = [x.title.text for x in feed.entry]
foo()
self.driver = webdriver.Firefox()
output.close()
result_dict = dict((n, res_list[i]) for i, n in enumerate(header))
ax.annotate(str(j), xy=(i, j))
s.listen(1)
print(m.group())
clf.fit(X, y)
smtp.close()
fig = plt.figure()
rtc.Newline()
output = check_output(cmd, stdin=file)
entry.pack()
print([0] * i)
file_writer.writerow([x[i] for x in lol])
print(type(result))
d = dict(zip(list(adict.values()), list(adict.keys())))
plt.show()
plt.colorbar()
tk.Frame.__init__(self, parent)
ax.annotate(str(y), xy=(x, y))
str(list(self.__iter__()))
data = f(data)
self.figure.set_canvas(self.figurecanvas)
self.ui.main_plot.figure.subplots_adjust(bottom=0.4)
screen.fill((0, 0, 0))
coords.reshape(-1, N)
self.ax.cla()
child.kill()
p = subprocess.Popen(your_command, preexec_fn=os.setsid)
self.g.get(key)
test.py
b = a.T
self.update({element.tag: element.text})
root.mainloop()
print(sum(a))
Process(target=do_something).start()
print(sum(ord(char) - base for char in mystring))
line_count += 1
print(sum1(-1, 0, 6, 10))
ax = fig.add_subplot(gs[1])
pygame.display.update()
func()
__init__.py
res = urllib.request.urlopen(req)
ax = fig.add_subplot(111)
random.shuffle(Order)
draw.line((0, im.size[1], im.size[0], 0), fill=128)
new = numpy.zeros_like(arr)
s.join()
fig, ax = plt.subplots()
sc._conf.getAll()
ax0.imshow(img, cmap=plt.cm.gray)
A.reshape(h // ph, ph, w // pw, pw, -1).swapaxes(1, 2)
self.label.configure(text=now)
o = object()
print((d1 + datetime.timedelta(i)).isoformat())
print(workdaycount(date(2011, 8, 15), date(2011, 8, 22), 1))
np.concatenate(alist)
self.SetTopWindow(frame)
l.sort(key=f)
list(intermix([1, 1, 1, 1, 1, 2, 2, 2, 2, 2]))
os.kill(pid, 0)
l.pop()
a + b
a = [1000 + 1, 1000 + 1, 1000 + 1]
dict[key] = val
test.my_redifinable()
httpd.serve_forever()
print(traceback.format_exc())
plt.ylim([40, 110])
node_schema.load(json_data, instance=Node().query.get(node_id), partial=True)
x = np.arange(10)
self.setupUi(self)
timeit(stmt4, setup4, number=100)
p.start()
ax.yaxis.grid(True)
print(dirname(dirname(__file__)))
np.cov(data.T)
any(e in s for e in b)
file.close()
ax.set_xlim([-1, 0.5])
d[k].extend(v)
func(self, *args, **kwargs)
time.sleep(1)
r.json()
site.set_debuglevel(1)
sheet.set_clip(pygame.Rect(SPRT_RECT_X, SPRT_RECT_Y, LEN_SPRT_X, LEN_SPRT_Y))
data = cursor.fetchall()
print(pd.concat([df, pd.concat([dm] * df.shape[1], axis=1, keys=df.columns)]))
print(sys.argv)
tips.reset_index(inplace=True)
self.assertTrue(result)
l = [i for sub in l for i in sub]
__path__ = extend_path(__path__, __name__)
help(string)
np.allclose(tmp, tmp2)
print(int(number) - int(number[::-1]))
print(dis.disco(f.f_code, i))
sys.exit(0)
print(m.hexdigest())
time.sleep(1)
print(repr(a))
numpy.zeros((5, 5))
sys.stdout.flush()
ctx.set_source_rgb(0.47, 0.47, 0.47)
data.append(0.25 * math.sin(math.radians(i)))
y = np.array([1, 2, 0, 1, 1, 2])
print(sys.path)
a[0]
[[1][2]]
label.grid(row=0, column=0)
subprocess.Popen(subprocess)
X[np.ix_([0, 1], [0, 1])]
print(fpp[1])
np.datetime64(datetime.utcnow()).astype(datetime)
df
ax.yaxis.set_minor_locator(MultipleLocator(0.2))
your_code.run()
df.query(qry)
model.objects.filter(id=id).update(order=order.index(id))
start()
transsurface.fill((255, 0, 255))
print(s.__dict__)
id(b[0]), id(b[1])
thread.start()
matrix[0]
somethingThread.join()
x.ix[random.sample(x.index, n)]
self.post(request, *args, **kwargs)
rs = json.dumps(dict(lst))
s == s[::-1]
df.describe().transpose()
root.deiconify()
_ = plt.setp(p.get_xticklabels(), rotation=90)
lines = f.readlines()
result.append(list(set1.union(set2)))
formset.save()
m.eliminate_zeros()
A = np.array(ss.zscore(A))
frame.axes.get_yaxis().set_ticks([])
print(repr(n))
Response(content)
ax.clear()
pd.options.display.max_columns = 50
plt.figure()
ax = plt.subplot(111)
[[2, 2, 2, 2], [2, 2, 2, 2], [2, 2, 2, 2]],
sys.exit(main(sys.argv))
self.fp.write(buf)
h = [[1, 0, 0][0, 0, 0][0, 0, -1]]
fig = plt.figure()
fig = plt.figure()
[1, 1, 1, 1, 1, 1]
list(set(l1) & set(l2))
next(iter(list(self.items())))
[(a + b) for a, b in zip(l, l[1:])[::2]]
print(monotonic_time())
print(f.read())
conn.rollback()
ax.set_ylim([-1, 1.5])
entry1.grid(row=0, column=0)
new = dict(old)
ax.yaxis.set_minor_locator(MultipleLocator(0.1))
logger.addHandler(ch)
self.fp.write(zinfo.FileHeader(zip64))
key = line.strip()[1:]
func(1, 2)
foo = models.IntegerField()
out = np.column_stack((sortedA[(start_unqA), :-1], np.nanmax(grpA, axis=1)))
inspect.getargspec(someMethod)
self.assertForbidden(response)
print(type(f.__self__))
loop.run_until_complete(main())
reduce(lambda d, k: d.setdefault(k, {}), keys, dict_nested)[newkey] = newvalue
Y.mean(axis=1)
print((k, v))
{{r.report_desc}}
print(df[df.columns[2:5]])
plt.subplot(122)
handler = logging.StreamHandler()
value[-2:]
d += timedelta(days=7)
pylab.show()
str(value)
pid.wait()
print(sys.argv)
show(p)
df
[row[colidx] for row in self._getrow(rowidx)]
oceans[regcode - 1].append((temp, fecha))
print(b.decode())
my_randoms = [random.randrange(1, 101, 1) for _ in range(10)]
self.x -= STEP
im = Image.open(BytesIO(base64.b64decode(data)))
print(str(l)[1:-1])
conn = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
isinstance(y, X)
print(counter.most_common(10))
G = nx.Graph()
letter_count = dict(zip(string.lowercase, itertools.repeat(0)))
map(lambda s: s.split(), a)
file_1.write(line)
fig, ax = plt.subplots()
pool.close()
o.many2many.all()
{data[k].append(v) for line_dict in dr for k, v in list(line_dict.items())}
get_value(dic, 4)
r.findall(url)
plt.figure(figsize=(12.5, 2.5))
query_model.save()
input.seek(0, 2)
a = [i for i in range(2, 10)]
QApplication.setOverrideCursor(Qt.WaitCursor)
False
matches = {x for x in a if x in str}
plt.plot([0, 2], [2, 4])
data = [tryconvert(x, int, float) for x in line.split()]
mean = sum_x / n
test()
os._exit(EMERGENCY)
plt.show()
subplot(2, 1, 1)
mask = x ** 2 + y ** 2 + z ** 2 < radius ** 2
obj.__dict__
fig.colorbar(im)
tasks.remove(t)
random.shuffle(data)
random.shuffle(random_list)
ax.set_xlim(-50, 50)
root = Tk()
sock = socket.socket()
df_norm.mean()
pool = multiprocessing.Pool(processes=4)
self.init()
bins = np.arange(-100, 100, 5)
p.wait()
out, err = ssh_process.communicate()
handler.setLevel(logging.DEBUG)
time.sleep(0.05)
helloset.issubset(printset)
manager.run()
self.makeList(aNode.lChild) + [aNode.data] + self.makeList(aNode.rChild)
plt.show()
self.initUI()
plt.contour(xgrid, ygrid, zgrid)
unittest.TestCase.__init__(self, test_name)
msg.attach(msg_image)
k, len(v)
result.append(el)
sys.maxunicode
AMOServer.Disconnect()
pyplot.show()
driver.quit()
window = Tk()
d = pd.DataFrame(np.zeros((N_rows, N_cols)))
QtGui.QFileDialog.__init__(self, *args)
help(file.read)
excel.ActiveSheet.Columns.AutoFit()
C = MyReallyBigClassNameWhichIHateToType
self.Layout()
self.func(self.parent_obj, *args, **kwargs)
f.write(chunk)
process(data)
print(fcount(path))
a[0, 1, 1] = [0, 1, 0]
print(df1[df1.B.isin(df2.B)])
logger.addHandler(ch)
max(allfuncs)
object.__getattribute__(self, name)
root = tk.Tk()
df.gdp = df.gdp.shift(-1)
choice.things.all()
x[np.where([c != 2])[1]]
pygame.display.flip()
plt.ion()
np.sin(y * x)
audio.save()
cbar = fig.colorbar(cax, ticks=[0, 5, 10])
session.execute(sql_string).fetchall()
d += timedelta(days=6 - d.weekday())
print(df_Quota)
app.run()
B = A[:]
fig = plt.figure()
print(s.find(s2))
min(darr)
window.show()
self.hlayout.addWidget(self.b)
Encoders.encode_base64(eml_atch)
my_dict[1]
dialog.exec_()
self.foo.wait()
ax.set_xticklabels(categories)
zip_longest(fillvalue=fillvalue, *args)
curses.echo()
show()
print(next(a))
df.drop_duplicates(inplace=True)
find_matches(list(a), list(b))
layout = QtGui.QVBoxLayout(self)
plt.figure(2)
response = br.submit()
window.Maximize()
threading.Timer(1, greeting, args=(oh_hi,)).start()
matches.extend([os.path.join(root, fn) for fn in filenames])
np.linspace(0, 1, 11)
self.data.grid(row=0, column=0, rowspan=4, columnspan=2, sticky=N + E + S + W)
objs = map(get_object, random.sample(list(range(length)), 0.001 * length))
json_docs.append(json_doc)
admin.site.unregister(User)
plt.subplot(2, 1, 1)
ax.get_xaxis().set_visible(False)
theclass.run
y = data[:, (0)]
tasks.join()
f.writelines(lines)
u[np.argmax(np.bincount(indices))]
ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
ax = fig.add_subplot(111)
driver = webdriver.Firefox(proxy=proxy_config, firefox_profile=prof)
print(out.upper())
cs = a, b, c, d
keys, values = list(dict.keys()), list(dict.values())
mydriver.maximize_window()
cursor.execute(query)
termf.pack(fill=BOTH, expand=YES)
str(self)
i += 1
foo.stop()
root = tk.Tk()
sns.set_palette(flatui)
ContestResults.objects.filter(contest=instance).delete()
foo = Foo()
ax1 = plt.subplot(gs1[i])
driver = webdriver.Firefox()
lambda v: tryconvert(v, 0, int)
db.session.commit()
soup = BeautifulSoup(html)
new_list.append(data[index][current_index])
driver.close()
zf.seek(0)
df[df.ge(0)].fillna(-9999)
soup = BeautifulSoup(html)
ax.xaxis.set_major_locator(days)
{{narratives.narrative_text}}
axclust.set_yticks([])
axcltwo.set_yticks([])
f.close()
frame.columnconfigure(1, weight=1)
urllib.request.install_opener(opener)
map(lambda row: map(int, row), inputVals)
pl.figure()
a + list(repeat(0, 6))
plt.imshow(a, cmap=plt.gray())
cv2.destroyAllWindows()
arr[0, 0]
names.remove(name)
print(map(str, rr[::2]))
ax = fig.add_subplot(111)
result[k] += myDict[k]
ax = fig.add_subplot(gs[0])
HTMLParser.__init__(self)
result = {k: d1[k] for k in keys}
plt.imshow(img_a)
OrderedDict.__init__(self, *args, **kwds)
globals()[key] = value
sys.exit(app.exec_())
sess = tf.Session()
ax.set_yticklabels(names)
table.reset_index()
y = x[:]
print(prev.tb_frame.f_locals)
self.cursor.commit()
ax1 = fig.add_subplot(111)
sys._getframe(number)
fd.write(data)
setattr(self, key, value)
b = a + b
pprint(Matrix([[1 / (4 * pi), 1], [1, f(x)]]))
A.todense()
pd.concat(subs)
self.canvas.configure(yscrollcommand=self.ysb.set, xscrollcommand=self.xsb.set)
opener = urllib.request.build_opener(urllib.request.HTTPHandler, handler)
set([5, 6])
ax = fig.add_subplot(111)
plt.show()
p.start()
self.name = name
gtk.main()
db.backup.insert(list(cursor))
django.setup()
my_logger.setLevel(logging.DEBUG)
main.py
print(df.head())
time.sleep(1)
screen = pygame.display.set_mode((640, 480))
[a, b]
index = np.array([0, 1])
client.options.transport.last_headers
sys.exit(rc)
date = datetime.datetime.fromtimestamp(timestamp)
pd.merge(df1, df2, left_index=True, right_index=True)
plt.draw()
parser = etree.XMLParser(recover=True)
PROJECT_ROOT = os.path.dirname(__file__)
today = date.today()
o.subscribe(my_callback_func)
print([x for x in range(1, 1000) if pred(x)])
raise SystemExit(1)
plt.show()
conn.close()
df = pd.DataFrame()
model_to_dict(instance, fields=[field.name for field in instance._meta.fields])
os.chdir(path_dir)
np.corrcoef(signal[:-1], signal[1:])[0][1]
print(dt - datetime.fromtimestamp(s * factor))
Decimal((0, a, -len(a) + 1))
df = df[df.end_date.notnull()]
metadata.create_all()
sys.stdout.flush()
ax = fig.add_subplot(1, 1, 1)
textfile.write(artigo)
whos
django.utils.simplejson.loads(someJson)
df.columns
self.show_progress(100)
response = view(request)
print(zdd1.join(zdd2).collect())
p[i] += 1
p2 = Process(target=func2)
Class.method(instance, argument)
pyximport.install()
gen1, gen2
np.add.outer(a, a)
r = requests.post(url, data=form_data, headers=user_agent)
hash(tuple())
mlab.start()
urllib.parse.quote(s)
DataFrame(foo, index=df.index)
process(line)
np.array([x for x in aset & bset])
self.__dict__ == other.__dict__
frames.append(df)
pd.to_datetime(s)
c.setopt(c.WRITEFUNCTION, retrieved_body.store)
s.connect((ip, port))
id = db.Column(db.Integer, primary_key=True)
m.bluemarble()
draw = ImageDraw.Draw(mask)
app.register_blueprint(filters.blueprint)
b[:len(a)] == a or is_sublist(a, b[1:])
wx.NO_BORDER ^ wx.SYSTEM_MENU ^ wx.MINIMIZE_BOX ^ wx.MAXIMIZE_BOX ^ wx.CLOSE_BOX
pd.read_csv(s, index_col=0, parse_dates=True, dayfirst=True)
self.navigate(-1)
main()
self.last_name = last_name
a = np.array([[5, 7], [12, 18], [20, 29]])
AaBbCcDdEeFfGgHhIiJjKkLlMNOPQRSTUVWXYZ
print(p.groupby(p.ne(p.shift()).cumsum()).cumcount())
df
main()
np.random.seed(0)
fig, ax = plt.subplots(figsize=a4_dims)
d = dict(zip(m[::2], m[1::2]))
np.sort(np.partition(x, -10)[-10:])
bot.polling()
sys.stdout = sys.__stdout__
d = dict(map(tabsplit, list1))
Obj1.grid_forget()
window.show()
fig, ax = plt.subplots()
process.stdin.close()
plt.setp(ax.get_xticklines()[-2:], visible=False)
Thread.__init__(self)
f.write(line)
map(convert, a)
print(d.foo())
urllib.request.urlopen(URL).read()
print(my_hex)
numpy.isfinite(myarray).all()
self._sock.sendall(data)
paramdata.to_csv(sys.stdout)
ser.readline()
p1.stdout.close()
df[df.apply(lambda x: x.A in x.B, axis=1)]
sum(x is 0 for x in arr)
file_bytes.seek(0, 0)
main()
self.client = paramiko.SSHClient()
x = numpy.array([0, 1, 1, 2, 2, 2])
np.random.shuffle(curr_data)
self.layout.addWidget(self.button1)
conn.commit()
buf.seek(0)
complete_path = os.path.abspath(complete_path)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
os.play()
run()
result = a[np.argsort(a)[:k]]
app.exec_()
test.py
[0, 1, 2]
self.value = self.left.value + self.right.value
lines.append(text)
func()
datetime.datetime(d.year, d.month, d.day)
len(np.unique(arr)) == 1
print([x for x in a if x not in b] + [x for x in b if x not in a])
s.set_debuglevel(0)
parser.parse(f)
A = np.empty((len(x), 2))
x = np.arange(1000)
sum(list(dict.items()), ())
func(**r._asdict())
arr.reshape(k, 2, k, 2).swapaxes(1, 2).reshape(k, k, 4).max(axis=-1)
session.add(foo)
pairs = tuple(combinations(list(range(len(A[0]))), 2))
heapq.heappush(heap, (a + b, a, b))
plt.clf()
plot(x, y2s)
scipy.stats.poisson.cdf([4, 17], 10)
print(slept)
fig.canvas.draw()
root = Tk()
np.diff(array1) - lens[:-1] + 1
x.append(np.nonzero(np.in1d(a, c))[0])
key = lambda x: x[1][0]
a[:, (1)].toarray()
data = sys.stdin.read()
print(new_list)
SudsObject.__init__(self)
task.revoke(terminate=True)
label_Image.setPixmap(QtGui.QPixmap.fromImage(image_profile))
data.reshape(2, -1)
ResultSerializer(results, many=True).data
QWidget.__init__(self, parent)
plt.show()
thread.start()
np.random.seed(2015)
QApplication.setOverrideCursor(QCursor(QtCore.Qt.WaitCursor))
print(sys._getframe().f_code.co_name)
pygame.init()
print(link.url, link.text)
out, err = proc.communicate()
main2()
help(module)
my_list = [int(i) for line in f for i in line.split() if i.isdigit()]
answer.append((alo, blo))
x = numpy.zeros((i, j, k))
profiler.start()
pdb.set_trace()
sys.exit(app.exec_())
ax1.bar(x, y)
length = len(string)
os._exit(0)
int(hashlib.sha1(s).hexdigest(), 16) % 10 ** 8
self.set_text(new_text)
server.start()
window.show()
print(x[:10])
clf.fit(X, y)
n if n - 1 < x <= n else n + 1
sys.stdout.write(line)
print(data)
HttpResponse()
reactor.do(thing1)
a * np.exp(-b * x) + offset
datastream.seek(0)
l[:x] + l[-y:]
time.sleep(duration)
quote.save()
do_something_based_on_the_request_endpoint(request)
app = web.application(urls, globals())
x, y = foo(50)
app.config.from_object(__name__)
p.terminate()
print(repr(a))
plt.show()
locale.setlocale(locale.LC_COLLATE, old_locale)
print(requests.get(url, proxies=proxies).text)
numpy.isnan(a).any()
os.kill(os.getpid(), signal.SIGUSR1)
time.sleep(2)
total += int(row[1])
results = query.all()
ax.legend()
app.exec_()
os.system(bashCommand)
[tuple(getattr(obj, field) for field in fields) for obj in listobj]
a[np.abs(a) < eps] = 0
main()
plt.xlim([-0.5, len(values) - 0.5])
ax = plt.gca()
plt.show(block=False)
stations = []
dist(site1[0], site1[1], site2[0], site2[1])
float_to_str(4.2e+17)
print(arreq_in_list(myarr1, mylistarr))
round(float(x) / 500) * 500
p.start()
ao[:-1, :-1] += ai[1:, 1:]
self.button.append(Button(frame, text=name, command=callback))
plt.plot(z, f(z, tval))
time.sleep(120.0)
f.__class__
fig = plt.figure()
print(dt + datetime.timedelta(days=d + 1))
e = 0.081819191
s.listen(1)
f.writelines(lines)
ax.add_collection(collection, autolim=True)
ax.imshow(img, extent=[min(xi), max(xi), min(yi), max(yi)])
t.start()
setattr(self, method, wrapped_method)
print(stdout.read())
all(x != y for x, y in zip(s[:-1], s[1:]))
next(reader)
mydict.setdefault(mykey, myfunc())
a[np.lexsort(np.transpose(a)[::-1])]
out = mat[0] * (len(ixs) - np.count_nonzero(nzmask)) + nzsum
do_something()
response = request.execute()
Thread(target=callback).start()
_trace(args[0])
fig, ax = plt.subplots()
driver = webdriver.Firefox()
element.remove(subelement)
conn.close()
fig.tight_layout()
a.sort(key=len, reverse=True)
test.py
sys.stdout.write(line)
signal.signal(signal.SIGTERM, lambda signum, stack_frame: sys.exit(1))
c = np.tile(a, (b.shape[0], 1))
A.__init__(self)
pythoncom.PumpMessages()
int(x * 10 ** (1 + a) + y)
plt.bar([1, 2], [5, 4])
print([(c.rate(), c.accrualPeriod()) for c in coupons])
db.create_all()
fileHandler.setLevel(logging.DEBUG)
writer.writerow(codecs.BOM_UTF16_LE)
result = np.average(_array, axis=1)
signal.signal(signal.SIGINT, my_signal_handler)
lesser + [pivot] + greater
list(a)
print ()
print((11 + 7) % 12)
conn.setopt(pycurl.FOLLOWLOCATION, True)
soup = BeautifulSoup(html)
list(Project.__table__.columns.keys())
channel.start_consuming()
mylist.pop(0)
unittest.main(failfast=True)
item.active = not item.active
df[(df > 0).all(1)]
tuple(list(zip(*G))[0])
result.setdefault(widget_type, []).append(app)
plt.subplots_adjust(hspace=0.0)
v = np.array([0, 1, 2])
[id(x) for x in a]
self.__class__.num += 1
FlaskApplication().run()
json.JSONEncoder.default(self, o)
list_of_tuples = [(1, 2), (4, 5)]
False
app.run(debug=True)
g.user = current_user.username
plt.gca().yaxis.set_minor_locator(mpl.ticker.NullLocator())
app.MainLoop()
val = rtpinterpolator(xyz2rtp(x, y, z))
sorted(my_set, key=natural_sortkey)
sum(args) == 1
g = nx.Graph()
db.session.add(p)
aic.append(x)
g = a + b + np.sqrt(d * d + e * e + f * f)
self.list[key]
func()
app = Flask(__name__)
deleted[key]
print(do_something())
window.show()
interleave(lst[:len(lst) / 2], lst[len(lst) / 2:])
time.sleep(1)
x = np.arange(100).reshape(10, 10)
dest.close()
np.kron(a.reshape(-1, 2), np.ones((2, 2), dtype=int))
my_array = np.clip(my_array, minN, maxN)
fig.canvas.draw()
ax = fig.add_subplot(111)
graph = GraphAPI(oauth_access_token)
fg.canvas.draw()
print(df)
root.after(0, add_letter)
sc.parallelize([], n).count()
self.rebuild_index()
br = mechanize.Browser()
globals()[string1 + string2]()
plt.plot(data)
s.write(line)
logging.basicConfig(level=logging.DEBUG, format=FORMAT)
a.sum(axis=1)
l.pop()
result = []
items.sort(key=lambda obj: (obj.firstname, [(-ord(c) for c in obj.lastname)]))
setp(ax.get_yticklabels(), fontsize=8)
json.loads(json.dumps([dict1, dict2]))
decorator
help(foo)
list_list.append(list1)
self.ProgressBar.SetValue(event.count)
self.thread.start()
-min((x, -i) for i, x in enumerate(values))[1]
plt.subplot(6, 1, 2)
self.setCentralWidget(widget)
plt.show()
name = models.CharField(max_length=255)
print(row.rstrip())
str(int(match.group(0)) - 1)
ax = fig.add_subplot(1, 1, 1)
file.close()
self.fd.close()
m.fit(X, y)
fig, ax = plt.subplots()
s.between(0, 1)
e2.pack()
dict((f, getattr(self, f)) for f, _ in self._fields_)
os.unlink(file)
result_dict[k] = v
wjoykhsapcmvjmar
reader.SetFileName(filename)
self.num += 1
print(line)
reactor.run()
dir(__builtin__)
time.time() - start
flatten_to_strings(list_of_menuitems)
os.killpg(p.pid, signal.SIGKILL)
print([(x, y) for x in range(5) for y in [f(x)] if y != 2])
setattr(cls, name, new_value)
a.append({mykeys[n]: values[n] for n in range(0, len(mykeys))})
r = func(*args, **kwargs)
self.transport.write(self.name, (self.host, self.port))
m.put(k, m.get(k) + 1)
writer.writerow(row)
window = QtGui.QMainWindow()
print((letter, count[letter]))
self.setSceneRect(0, 0, width, height)
datetime.time(*values)
FooModel.objects.get(pk=1).children.all()
test = array([[0, 1, 2], [1, 1, 6], [2, 0, 4]])
background.paste(top, (0, 0))
testRust()
[x for x, y in pairwise(xs) if x != y]
self.ax.set_xlim(self.min_x, self.max_x)
self.file.flush()
df[df.line_race != 0]
PyQt4.QtCore.QPoint(1867, 416)
picture.putpixel((x, y), new_color)
list(mkimap())
gradients
NUMBER_OF_EXCEPTIONS += 1
copy + copy_to_depth(item, depth - 1)
z = [int(i == j) for i, j in zip(x, y)]
fig, ax = plt.subplots()
cursor.execute(query)
all_labels.sort()
self.assertEqual(self.seq, list(range(10)))
f.write(bitbufstr)
list(compress(listOfTuples, bool_array))
print(f.read())
(values.cumsum() - ALLOWANCE).clip_lower(0).diff().fillna(0)
zin.close()
HttpResponse(escape(some_string))
self.newargument = myarg
myfile2.write(text)
plt.show()
print(s)
a = concat(a, b)
time.sleep(1)
map(itemgetter(1), rows)
ax1 = fig.add_subplot(111)
bisect.bisect == bisect.bisect_left
func(*args, **kwargs)
plt.title(title)
now.replace(minute=now.minute - now.minute % 15, second=0, microsecond=0)
Script1.py
A.objects.filter(id=some_a.id).update(hidden=False)
print(sys.stdin.read())
script = os.path.abspath(sys.argv[1])
pairs = tuple(combinations(list(range(len(A[0]))), n))
df.loc[new_index] = pd.Series([99], df.columns)
plt.figure()
id(Point(1, 2)) == id(Point(1, 2))
loop.run_until_complete(asyncio.wait_for(asyncio.sleep(60), 5))
print(html2text.html2text(html))
link.click()
clientsocket.send(r.encode())
image.show()
root = etree.fromstring(xml)
server.ehlo()
output_file.write(ablob[0])
warning.setLevel(logging.WARNING)
print(args.file.readlines())
module
sorted(set(a).intersection(xyz))
fixedser.dropna().plot(ax=axes[1])
newser.dropna().plot(ax=axes[1])
figure.canvas.draw()
app.MainLoop()
func_a(s)
driver.get(url)
sys.exit(app.exec_())
l.append(x[:k])
list(pairs(board))
now = datetime.datetime.now()
m.close()
numpy.set_printoptions(precision=15)
answerlist.extend(templist[:lengthmodified])
_finditem(v, key)
workList.sort(key=len, reverse=True)
foo.x = 0
main()
[(double(x) if isinstance(x, list) else x * 2) for x in numberlist]
fig = pyplot.figure()
ax.set_xticks(bins)
cookies = browser.get_cookies()
pg.draw.rect(surf, STIMCOL, (60, 70, 80, 90))
time.sleep(5)
jsonify(username=g.user.username, email=g.user.email, id=g.user.id)
image = Image.open(image_in_path)
x if x < y else y
something()
fig = plt.figure()
new_list.append(tmp_list)
fig = plt.figure(figsize=(5, 10))
list(dill.detect.badtypes(f, depth=1).keys())
admin.site.register(User, UserAdmin)
text = models.TextField()
pool = Pool()
pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)
scipy.linalg.solve(X, Y)
insert_sort(descend_list, i, lambda x, y: x[1:] < y[1:])
display(fig)
self.Refresh()
pd.DataFrame(list(ds1.difference(ds2)))
df
df
test(1, 2)
s.connect((host, port))
[1, 0, 1],
resp = urllib.request.urlopen(request)
self.driver = webdriver.Firefox()
ax = fig.add_subplot(111, polar=True)
print(map(lambda x: dict(zip(reader[0], x)), reader))
print(os.getpid())
resp.set_data(soup.prettify())
fig.multi_line(y_err_x, y_err_y, color=color, **error_kwargs)
c += initval2
np.array(b)
permutate(n, k) // permutate(k, k)
other_file.py
sys.exit(app.exec_())
sorted(list(y.items()), cmp=reverse_comparison)
print(word[1], word[0])
all(c in string.printable for c in bell)
parser.print_help()
sum(ele[1] == 1 for ele in a)
ax.set_position([0.1, 0.1, 0.5, 0.8])
list(skip(list(range(10)), at_start=2, at_end=2))
f1.close()
WSGIScriptAlias / myapp / code / wsgi / wsgi.py
test.postmodel_set.all()
print(max(node.y for node in path.nodes))
self.setCentralWidget(self.view)
math.ceil(float(177) / 10)
np.random.seed(0)
d1.x1 - d2.x2.values
numpy.array([Register() for i in range(4)])
application = QtGui.QApplication(sys.argv)
print(i, list(csv.reader(source)))
setattr(e, key, val)
result = np.empty_like(zeta)
chars.append(c)
n = random.randint(1, 1000)
b = [indicies[elements == i] for i in range(1, N)]
do_something_else(array[-1])
p.stdin.write(answer)
self.setStrokeColorRGB(0, 0, 0)
set(a).intersection(b)
Image.open(filepath)
s[-1]
0.0, -64.0, 208.0, 0.0, -90.0, 0.0, -80.0, 0.0, 0.0, -80.0, -48.0
plot([4, 5, 6])
time.sleep(0.1)
main()
b = OrderedDict(sorted(a.items()))
np.set_printoptions(**original)
h = [[0, 0, 1][0, 0, 0][-1, 0, 0]]
serializer = UserSerializer(data=request.DATA)
neurons.append(neuron)
b = numpy.arange(5)
plt.show()
main()
self.toolbar.update()
hash({})
strat0.execute()
msg.attach(attachment)
latex_float(1000000000.0)
bisect.bisect(l, 55)
print(socket.gethostname())
A[np.where(~np.isnan(A))[0][0]:]
df.stack().str.split().str[-1].unstack()
server.serve_forever()
sys.stderr = os.devnull
Path(__file__).parent.parent
collections.OrderedDict()
plt.show()
print(get_last_non_zero_index([]))
Response(serializer.data)
ax.set_xticks(xticks[1:-1])
val = hex(val)
history.append(item)
app.mainloop()
chardet_detector.close()
now = utc.localize(datetime.datetime.utcnow())
numbers.append(map(int, line.split()))
dt + datetime.timedelta(seconds=delta)
pickle.dump(requests.utils.dict_from_cookiejar(session.cookies), f)
list1 = [1, 1, 1, 0, 0]
merged = list(joinz(0, zusers.iter(), 0, zratings.iter()))
f(1, np.pi)
Z = itp(X, Y, grid=False)
soup = BeautifulSoup(totstring)
mod.__file__
self.stopped = True
points.append((x, y))
plt.scatter(data1, data2, c=colors, cmap=my_cmap)
data = conn.recv(4096)
self.setWindowFlags(self.windowFlags() | QtCore.Qt.FramelessWindowHint)
options[0]
plt.yticks(rotation=0)
norm.ppf(0.5)
sine_list.append(math.sin(2 * math.pi * freq * (x / frate)))
print(child.tag, child.attrib, child.text)
a.func()
x = lst.pop()
print(ridge.coef_)
[a for a in s if len(a) > 0]
app.exec_()
hex(n & 4294967295)[:-1]
d.update(dict(d))
hbar.config(command=canvas.xview)
B_p.to_csv(sys.stdout)
M.iloc[index][col]
Signal.send_robust(sender, **kwargs)
self.response.out.write(output.getvalue())
shapesMatch([(0, 0), (1, 1), (0, 2), (-1, 1)], l_shape)
X, Y = np.meshgrid(X, Y)
sorted(randlist2(2000000000, 10000000, 1900000000))
plt.show()
unplugged()
entretien_send_email.send_mail(self.id)
printout()
time.sleep(1)
signal.signal(signal.SIGINT, lambda number, frame: sys.exit())
pprint.pprint(tup, depth=6)
c, b
db.init_app(current_app)
list(zip(lst[:-1], lst[1:]))
name = models.CharField(max_length=100)
tree = ElementTree.parse(StringIO.StringIO(output))
{{formset}}
plt.axis([xmin, xmax, ymin, ymax])
p = Process(target=f, args=(arr,))
__init__.py
a, b, c
fig.tight_layout()
print(df.to_latex())
app = Flask(__name__)
dill.pickles(Foo.x)
oneone
s.fillna(0).plot()
all(a == b for a, b in zip_longest(gen_1, gen_2, fillvalue=sentinel))
ax.add_artist(ell)
flt = float(random.randint(0, 100))
case(re.search(pattern, st))
idx = np.arange(n)
out.close()
python / Users / luca / Documents / python / gameover.py
a[indices]
db.test.remove(doc_id)
send_email()
game.update()
(rollingcor.sum(skipna=0).sum(skipna=0) - n) / 2 / n
pickle.dump(dict2, fp)
set(l1) | set(l2)
im.set_clip_path(clip_path)
print(line)
(0 < x) & (x < 1)
self._points = []
raise KeyError(key)
fh.setLevel(logging.DEBUG)
newlist.append(d)
trainer = deepbelief.DeepBeliefTrainer(net, dataset=ds)
ax = fig.add_subplot(111)
root = tk.Tk()
pickle.dump(score, file)
df.ix[:, (2)]
image.save(self.get_thumbnail_path())
f.write(something)
ax.set_xlim(0, X)
sum(i == word for word in str1.split())
imresize(np.ones((1000, 1000)), (100, 100)).shape
a.set_xlim(0, 4 * pi)
[x[i:i + step] for i in range(0, len(x), step)]
print([list(b) for b in zip(l, inner)])
ax.yaxis.set_major_formatter(ticker.FuncFormatter(myLogFormat))
df.info()
self.crawler.engine.crawl(self.create_request(), spider)
smtp.sendmail(send_from, send_to, msg.as_string())
httplib.HTTPConnection.connect(self)
sorted(numbers)[-2]
plt.figure(figsize=(4.5, 2.5))
print(D.x.value)
themsg.attach(msg)
item
chain.from_iterable(combinations(s, r) for r in range(len(s) + 1))
ax1 = fig.add_subplot(111)
urllib.request.urlopen(request)
func(*args, **kwargs)
p.start()
start_date = start_date.replace(tzinfo=local_tz)
pylab.show()
os.remove(path)
img = np.uint8(np.random.random((720, 1280)) * 256)
win.set_decorated(False)
browser = webdriver.Firefox()
matches = regex.findall(my_str)
sess.run(apply_transform_op)
itertools.chain(iter(self.items.values()), iter(self.people.values()))
ax.plot(list(range(10)))
arr = np.vstack((arr, np.array([4, 5, 6])))
G = nx.Graph()
soup = BeautifulSoup(html_page)
sum(1 if int(line) % k == 0 else 0 for line in sys.stdin)
pythoncom.CoInitialize()
all_data.shape
root.withdraw()
plt.plot(y)
ax = plt.subplot(gs[i, j])
db.delete(q.fetch(200))
print(np.allclose(res1, res2))
fig.canvas.draw()
getattr(self.cp, attr)
engines.append(engine)
self.finish()
self.tk.config(menu=self.menu)
new_list = copy.copy(old_list)
print(firstMatch.group())
s.setsockopt(socket.IPPROTO_IP, socket.IP_HDRINCL, 1)
csvout.close()
fig, ax = plt.subplots()
type(s)
a.max(axis=0)
self.setCentralWidget(self.web_view)
writer.writeheader()
fig.subplots_adjust(wspace=0.05)
fs.noteoff(0, 67)
x = 2
plt.show()
myQuery.Availability
tar.extractall(path, get_members(tar, args[1]))
A[:] = (sub for sub in A if st.issubset(sub))
reader = csv.reader(f)
velcro.right(180)
do_something(val)
word_list.sort(key=lambda i: i[0].lower())
odeint(func, y0, t, *list1)
print(Second_row_first_column.strip() + Second_row_second_column.strip())
l = sorted(list(d.items()), key=lambda x: x[1], reverse=True)
p.start()
df
ax.xaxis_date()
np.sin(y * x) + z
points = np.random.randint(0, 5, (10, 2))
list(chain.from_iterable(pattern.split(w) for w in input_list))
print(f.text)
s.setsockopt(SOL_SOCKET, SO_BROADCAST, 1)
pygame.event.pump()
s[~s.index.duplicated()]
plt.axis([0, 10, 0, 10])
compressor.close()
n = a.shape[0]
[(k1[0], k1[1], k2) for k1, k2 in zip(chain.from_iterable(dge), nde)]
cv.Rectangle(color_image, pt1, pt2, cv.CV_RGB(255, 0, 0), 1)
sys.exit(0)
max(zip((x.count(item) for item in set(x)), set(x)))
list(range(int(toks[0]), int(toks[1]) + 1))
f.close()
app.MainLoop()
print(parser.parse_args())
print(name, value)
self._worker_handler.start()
vbox.add(label)
lambda a, b: (a + 1, b * 1)
demangled[:-1]
model.train_on_batch(state_action_vector, target)
ax1.set_xlim(0, 60)
self.assertEqual(a, b)
numpy.finfo(numpy.longdouble)
screen = pygame.display.set_mode((500, 500))
int(round(5678, -1))
print(df.eq(df.iloc[0]))
sorted(set(range(start, end + 1)).difference(L))
print(combinedRDD.collect())
data += proc.stdout.read()
server.start()
plt.tight_layout()
html = urlopen(url).read()
keys.insert(i, k)
np.floor(series)
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
[[l[x] for l in lists] for x in range(len(lists[0]))]
mainloop()
tst.main(globals())
{k: [da.get(k, []), db.get(k, [])] for k in set(listanum + listbnum)}
s.setsockopt(socket.SOL_TCP, socket.TCP_KEEPCNT, 5)
print(re.findall(pattern, line))
pbar.finish()
image.swapaxes(0, 1), out
print(nums.mean(axis=1))
get_value(d[l[0]], l[1:])
y = np.random.rand(m, n)
out.close()
logger.addHandler(handler)
print(new_pressures)
print(f())
nosetests - v
remove_even([4, 5, 4, 7, 9, 11])
response = urllib.request.urlopen(req)
Label.__init__(self, master, image=self.frames[0])
d[a].append(b)
x[0::2]
self.n += 1
wr.writerows([k] + v for k, v in list(od.items()))
window.show_all()
df.mean()
pickle.dump(saved_data, outfile, protocol=pickle.HIGHEST_PROTOCOL)
datetime.datetime(*dtuple[:6])
s.compute()
list_1 = [i for n, i in enumerate(list_1) if n not in index_list]
your_csv_file.close()
book = xlwt.Workbook()
df.groupby(np.arange(len(df)) // 2).mean()
ax.add_line(line)
data.sum()
d[key] = value
button.pack()
p = Pool(5)
testdataframe1.plot(style=styles1, ax=ax)
list(set(a) - set(b))[:100]
plt.figure()
ax.set_ylim(-0.5, 4.5)
b[:, ([True, True, True, False, False])]
pd.concat([df[col].apply(pd.Series) for col in cols], axis=1, keys=cols)
writer.writerow(row)
list_2 = [i for n, i in enumerate(list_2) if n not in index_list]
events.append([])
e.findall(data)
add_patch(axes[0], alpha=0.2, rasterized=False)
zk.start()
ax.add_patch(polygon)
df = pd.read_csv(StringIO(text), parse_dates=[0])
id = Column(Integer, primary_key=True)
results.append(pool.apply_async(foo, args=(words[i], numbers[i])))
list(range(item.start or 0, item.stop or len(self), item.step or 1))
window.show()
string.ascii_letters[:random.randint(1, 50)].title()
{{instance.key().name()}}
app.mainloop()
time.sleep(0.25)
Base.metadata.create_all()
sorted(results)
df = df.unstack()
Tkinter.Label(root, image=imgtk).pack()
self.show()
res.extend([entry[1:], entry[:1]])
np.array(a) - np.array(b)
user.save()
np.isnan(np.nan)
plot_selected.yaxis.set_ticks(np.arange(0, 1.1, 0.2))
self.wb.save(self.dest)
proc.join()
ax1 = fig.add_subplot(111)
fig.subplots_adjust(right=0.75)
set(perms)
int(round(5678, -2))
x = numpy.random.uniform(1.5)
self.Bind(wx.EVT_LEFT_UP, self.OnClick)
points = np.random.randint(0, 5, (N, 2))
self.thisptr.calculate()
self.spinbox.valueChanged.connect(self.worker.update_value)
d = dict((an_object.name, an_object) for an_object in object_list)
filename = sys.argv[1]
f.close()
[(1 if any(full.endswith(last) for last in B) else 0) for full in A]
np.allclose([np.where(a <= x)[0][0] for x in b], np.digitize(b, a))
ax.set_xlim(0, 1)
n = n % len(strg)
out = np.where(mask, np.nan, a)
print(i, chr(i))
session.commit()
gzip_obj.read()
result = timedelta1 + timedelta2
x[index]
sys.exit()
QGraphicsTextItem.mouseMoveEvent(self, event)
user.groups.add(group)
t.start()
x ** 2 + y ** 2 + z ** 2 < radius ** 2
R_mean1.append(R)
s = s.lower()
output = np.array([1, 1, 5])
output.writeframes(data[1][1])
time.sleep(0.1)
ax = plt.subplot(gs[:, :])
plt.subplot(121)
app = Flask(__name__)
ax.tick_params(labelsize=8)
print(x)
object.__getattribute__(self, name)
wx.version()
c = f.read(1)
print(fig.axes[0])
self.__dict__.update(d)
self.q.join()
print(foo[1:5, (1), (2)])
self.wsgi_app(environ, start_response)
sub_cmd.cmdloop()
test()
df[idx]
nosetests - -all - modules
res = dict([(t, nt(*t)) for t in pairs])
data.sort(key=get_score, reverse=True)
sys.exit(app.exec_())
df[df.b.isnull()]
[int(line) for line in f]
im2.set_xdata(np.arange(n))
dynamic(name, bases, attrs)
query = query.filter(and_(*filter_group))
indices[field][key].add(i)
plt.show()
new.setdefault(i, []).extend(j)
print(list([x for x in words if len(x) > average]))
self.write(data)
time.sleep(1.0 - elapsed)
self.mainframe.rowconfigure(1, weight=1)
all_pairs += [((nA, 0), (nB, 1)) for nA, nB in itertools.product(listA, listB)]
df.columns = ts_clip.iloc[:len(df.columns)].index.time
value
item, value
text.pack(expand=1, fill=BOTH)
print(settings.BASE_DIR)
layout.itemAt(i).widget().deleteLater()
areas.apply(foo)
sum(l) + 0.529964086141668
averaged = {k: (sum(d[k] for d in folds) / len(folds)) for k in folds[0]}
scipy.misc.factorial(temp)
plt.bar(indexes, values, width)
lambda a, b: (a + 1, b * 1)
app.exec_()
w.GetWindowText(w.GetForegroundWindow())
sys.exit(-1)
plt.show()
0.0054 is 0.0054
self.output(0.1, Op.setlinewidth)
pd.get_dummies(df.Knownvalue // 10)
dd.min(axis=1)
foo.sort()
parser = argparse.ArgumentParser()
im = A2.shape[1] - 1 - np.argmax(A2[:, ::-1] < 0, axis=1)
resp.raise_for_status()
preincrement(i)
self.setLayout(self.layout)
1j * numpy.inf * 1
ax0b.get_yaxis().get_offset_text().set_size(10)
ax0c.get_yaxis().get_offset_text().set_size(10)
df = pd.DataFrame(data)
potential(abs(b[np.triu_indices_from(b, 1)])).sum()
linesamples.add(int(4 * i + 1))
s.bind((HOST, PORT))
link.allow_tags = True
my_array = my_array.reshape(nrows, ncols)
root = tk.Tk()
w.close()
isinstance(d, dict)
dic[mygroup].append(entry)
r = s.post(url, data=data)
HypotheticalBranch(0, 0, 0)
time.sleep(0.01)
pool = Pool()
pdb.set_trace()
cv2.waitKey()
G = nx.Graph()
[u for u in self.custom_fields if self.cleaned_data[str(u.id)]]
row.insert(0, a)
G.add_node(1)
[x for y in l if len(y) < 4 for x in y if isinstance(x, int)]
random.shuffle(order)
widget.show()
obj.__class__ = cls
frame.set_linewidth(0)
dir(obj)
(-np.array(avgDists)).argsort()[:n]
toc2()
print(repr(s))
print(df1.columns.unique())
a, b, c, d, e, f = flatten(v)
i.close()
line = file.readline()
pp(list(map(list, zip(*grid))))
main()
this_row.append(s.cell_value(row, col))
plt.ylim(-20, 60)
your_csv_file.close()
df
self.set_positions((xs[0], ys[0]), (xs[1], ys[1]))
list(intersect(*postings))
x = np.array(x)
Base.Foo(self)
db.session.add(entry)
x = np.array([0.1, 0.2, np.nan, 0.4, 0.5])
ax1.plot(np.array([1, 5]) * i, label=i)
ynew = csc_matrix((data, (rows, cols)), shape=(N, M), dtype=dtype)
pdb.set_trace()
q, r = divmod(x, y)
s.connect((HOST, PORT))
matplotlib.pyplot.close(f)
sc = SparkContext()
[int(c) for c in s if c.isdigit()]
screen = pygame.display.set_mode((640, 480))
os.mkfifo(path)
self.lock.acquire()
ax1.plot(x, y)
d = {x: i for i, x in enumerate(lis)}
foo.py
print(len(list1))
data = np.genfromtxt(urllib.request.urlopen(url), skip_header=1, skip_footer=4)
(i * i for i in range(5))
asyncio.get_event_loop().run_until_complete(start_server)
app = QtGui.QApplication(sys.argv)
x = tab.query()
y_pred = pipe_lrSVC.predict(X_test)
np.maximum.accumulate(idx, axis=1, out=idx)
celery.start()
np.array(tmp).reshape((len(longlist), len(longlist[0])))
QtGui.QItemDelegate.__init__(self, parent)
m2[np.asarray(m2[:, (1)] > 10).flatten()]
strncpy(addr.sun_path, UD_SOCKET_PATH, sizeof(addr.sun_path) - 1)
soup = BeautifulSoup(data)
mylist.remove(max(mylist))
p.parse_args([])
reader = csv.DictReader(f)
pprint.pprint(combs)
add_cols(*x.T)
painter.rotate(-angle)
list(d.items())[1]
self.canvas.config(scrollregion=self.canvas.bbox(ALL))
ax.xaxis.get_minorticklines()
modinv(exp, (p - 1) * (q - 1))
response = urllib.request.urlopen(url, data, headers)
sns.kdeplot(x, ax=ax2)
f.seek(-len(os.linesep), os.SEEK_END)
self.changeLayout(QtCore.Qt.Vertical)
list(set(x) & set(y))
print(format_float(1500000.0))
A = A[np.ix_(L)]
self.assertTrue(mock_bar.called)
p.start()
wav_file.close()
sum(is_monotonic(num, reverse) for num in range(start, end))
len(set(a) - set(b))
random.sample(a, len(a) + 1)
l.append(row[i])
pyplot.show()
thread.start()
Book.create_table()
print((a, b, c, d))
app = QtGui.QApplication(sys.argv)
sess.run(init_op)
logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)
cursor = connection.cursor()
df.sum()
my_module.__file__
pdb.set_trace()
file.save()
self._thread.start()
button.pack()
[int(line) for line in f]
df
iter(List)
channel.queueDeclarePassive(queueName).getMessageCount()
ssh = paramiko.SSHClient()
ax.set_yticks([0, 0.5, 1])
data.append(fileData)
threading.Thread.__init__(self)
data = np.random.uniform(-1, 1, fs)
print(browser.title)
max(-15, 0)
blank_image.paste(image64, (0, 0))
int(time.mktime(d.timetuple()))
p.start()
soup = BeautifulSoup.BeautifulSoup(your_data)
foo.start()
yaml.load(s)
[5, 6, 10]
vc.release()
text = open(filename).read()
plt.plot(list(range(10)))
sys.stdout.flush()
np.array([float(sym.subs(all_dict)) for sym in syms])
some_fun()
meta.py
cursor = db.cursor()
find_chamber_discard2(locals())
dict(const1=const1, const2=const2)
users = User.objects.all()
writer.writerow(next(reader))
self.ui.gridLayout.update()
readFileObject.close()
bin(-4)
print(sum(s) / len(s))
set(l1).intersection(l2)
a_string.encode(encoding)
ranges.append((4, 10))
dot(Phi, R)
[sublist for sublist in list_ if sublist[1] != 1]
my_data.append(line)
file.seek(0)
pygame.sprite.spritecollide(hook, fish, False, pygame.sprite.collide_circle)
time.sleep(1)
d += timedelta(days=inc)
thread.start()
self.ax.set_autoscaley_on(True)
app.exec_()
print(msg.get_payload())
a, b = [], []
np.vstack([a, b])
a[0:1][0] = 4
tuples = [(freq, word) for word, freq in D.items()]
x + 1
a[:, (1)] = -1
print(numpy.array_equal(new_data, output))
canvas.itemconfigure(cwid, width=wi, height=hi)
self.button.grid(row=1, column=0, sticky=W)
sys.stdin = sys.__stdin__
rdd.groupByKey().mapValues(lambda x: sum(x) / len(x)).collect()
print(scipy.optimize.brentq(f, 0.0, 100.0, args=(77.0 / 27.0, 1.0, 1.0, 10.0)))
a, b = int(a), int(b)
df = pd.DataFrame(delimit)
t = datetime.timedelta(seconds=1)
cv.SetCaptureProperty(camcapture, cv.CV_CAP_PROP_FRAME_HEIGHT, 720)
a.newMethod = newMethod.__get__(a, A)
thread.start()
file.readline()
df.iat[0, 0]
widget.setLayout(layout)
Thread(target=recv).start()
()
func()
len(max(tup, key=len))
logger.setLevel(level)
df.plot(ax=axs, alpha=0.7)
data = cursor.fetchone()
[gu(i) for i in range(len(uo))]
template.render(context)
a = numpy.load(memfile)
dir(__builtins__)
result.extend(literal_eval(line.strip()))
b[sort_indices, static_indices[1], static_indices[2]]
sample.save()
print(d[keyList[i - 1]])
deletep_list[idx]
line = proc.stdout.readline()
zlib.decompress(inf, 16 + zlib.MAX_WBITS)
ecb()
df.iloc[last - 2:last + 1]
ax = plt.subplot(111)
print(fmax, pinf, ninf, fnan)
fout.write(f.getvalue())
f[i] += 1
l[1] = 5
G.add_nodes_from(L4)
my_new_list = list(my_set)
m2[:, (1)] > 10
data = np.vstack((data, (np.ones(data.shape[0]) * num).reshape(-1, 1)))
df_two.show()
main()
foo.save()
hops.insert(0, response.geturl())
pygame.mixer.music.load(soundfile)
driver = webdriver.Chrome()
print(binascii.hexlify(x))
user.save()
list_one.insert(2, list_two)
sizer.Add(self.grid, 1, wx.EXPAND)
no_vow(seq, index + 1)
image = cv2.imread(imagepath)
writer.commit()
unittest.TextTestRunner(verbosity=2).run(suite)
points[index]
os.fdopen(fd, *args, **kwargs)
[x for x in pattern.split(s) if x]
plt.show()
df = pd.DataFrame(list(cursor))
sizer = wx.BoxSizer(wx.VERTICAL)
self.root.after(1000, self.circle)
obj._meta.concrete_model._meta.model_name
mask = np.isnan(arr)
zip_longest(fillvalue=fillvalue, *args)
z.close()
window.setGeometry(0, 0, 400, 200)
print(min((f(i, j), i, j) for i in l for j in l))
df1.info()
b.append([begin, end])
server.shutdown()
sys.exit(app.exec_())
act.triggered.connect(self.on_triggered)
ax.plot_surface(x_surf, y_surf, z_surf, cmap=cm.hot, alpha=0.2)
L.sort(lambda x, y: cmp(x.name, y.name) or -cmp(x.year, y.year))
arrows(0, 0, 1, 1)
lines = (line for line in f if line.strip())
[y for x in lst for y in (x if isinstance(x, tuple) else (x,))]
sys.exit()
dt = datetime.fromtimestamp(ts, tz)
X[np.ix_(np.where(mask1)[0], np.where(mask2)[0])]
ax.set_xticks(list(range(len(g))))
process.terminate()
shutil.copyfile(src, dest)
datetime.timedelta(seconds=seconds)
data[np.isnan(data)] = dfrand[np.isnan(data)]
c.sort(axis=1)
func2(innerfunc)
parts = splitparts.split(match.group(2))
socket.inet_pton(socket.AF_INET, address)
p[pair[1]] += 1
y.shape.eval()
handles, labels = ax1.get_legend_handles_labels()
self.setLayout(hbox)
df1.values / df2[df1.columns].values
ax.plot([2, 2, 2])
log.setLevel(logging.INFO)
column(A, 1)
X = np.zeros((100, 100, 100))
a2.ravel()[:] = np.array(ll)
show_svg()
lines = f.readlines()
sizer.Add(self.ultimateList, 1, flag=wx.EXPAND)
fig, ax = plt.subplots()
[n] = set(sum(sl) for sl in L)
heapq.heappush(heap, (-prod, n, n))
ax1 = fig.add_subplot(211)
time.sleep(1.0)
Decimal(0.5)
print(x.name, x.hometown.name, x.hometown.id)
sys.getdefaultencoding()
sum(f(x) for f in funcs)
self.modules
a[a < 0] += 1
timeit(hugeequal1, hugeequal2, 10000)
output = p.communicate(input)[0]
b[i] = a[i]
solve(M * x + N * y, x)
deletemylist[:2]
plt.show()
csv_writer = csv.DictWriter(csv_file, headers)
soup = BeautifulSoup(urllib.request.urlopen(url).read())
pprint.pprint(result)
df.min(1)
resp = br.open(url)
root.rowconfigure(0, weight=1)
s.connect((HOST, PORT))
doctest.testmod()
inspect.getgeneratorstate(gen)
locals().update(mydict)
avg = tot / ((data.shape[0] - 1) * data.shape[0] / 2.0)
np.dot(b, a)
df.drop(cols, inplace=True, axis=1)
text.split(a)[-1].split(b)[0]
pool.join()
[(s, s1.index(s), s2.index(s)) for s in maximal]
[p for p in itertools.product(x, repeat=2)]
pdb.Pdb.__init__(self, nosigint=True)
p2.communicate()
list = [i for i in stuff]
sys.exit(app.exec_())
newlst.append(int(i))
fmt.format(**d)
list_one.extend(list_two)
earth.circle(150, 2)
sys.stdout.write(line)
os.symlink(os.path.realpath(sys.argv[0]), exe_install_path)
output[0]
self._list[i][1]
self.set_picture(picture)
data = bytearray(f.read())
type.__init__(cls, name, bases, d)
sys.stdout.flush()
nums = list(range(1000000))
image = image.resize((width_new, height_new))
result = [item for sublist in l for item in sublist]
new_dict = defaultdict(dict)
b = tf.add(a, a).eval()
ax.set_ylim([-2, 2])
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
scipy.stats.hypergeom.sf(0, N, M, Q)
s.prompt()
info.setLevel(logging.INFO)
btn.grid(column=1, row=1)
func()
f.seek(55)
found = word in file.read().split()
isinstance(x, X)
plt.figure(i)
root.mainloop()
timer2.start()
main()
fig = plt.figure()
print(root.winfo_geometry())
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
ax.set_extent([4, 16, 47, 56], ccrs.PlateCarree())
self[key].append(value)
draw.text((10, 10), unicode_text, font=unicode_font, fill=font_color)
os.kill(int(processId), signal.SIGTERM)
df
tmp.append(chr(d))
mylist[:] = []
print(priv.private_decrypt(ctxt, RSA.pkcs1_oaep_padding))
Person.query().filter(Person.guilds == self.key)
[(s[0], s[1]) for s in (s.split() for s in strings)]
path_list[0] = path_list[0][0]
print(i, j, k, v)
np.ma.MaskedArray(x, mask)
plt.plot(x, y)
[i.value for i in d]
fig = plt.figure()
b = do_something(a, b)
x = [True, True, True, True]
self.window.clear()
sys.exit(app.exec_())
print(root, dirs, files)
self.f.writeframes(output)
logging.getLogger().addHandler(handler)
print(key, sum(d[key]) / len(d[key]))
process.start()
mean(arr[k + 1:n - k])
hax2.set_position([0.1, 0.1, 0.8, 0.8])
plt.legend()
a = np.array([1.0, 2, 6, 2, 1, 7])
do_the_stuff(key, value)
sheet1.write(i, 1, e)
f.seek(-4, 2)
os.setsid()
model = model.fit(X_train, y_train)
logger.addHandler(handler)
br.load(url)
min(allowedList, key=sortedList.index)
fig, axes = plt.subplots(nrows=4, sharex=True)
m = re.match(regex, line)
s.bind((host, port))
ax1 = plt.subplot2grid((1, 1), (0, 0))
data = []
worksheet.write(row, col + 1, item)
my_date = date.today() - timedelta(days=days_to_substract)
datetime.datetime(t.year, t.month, t.day)
np.arange(10)[10::-1]
soup = bs4.BeautifulSoup(YOUR_CONTENT)
fig, ax = plt.subplots()
time.sleep(1)
host.set_xlim(0, 2)
plt.setp(labels, rotation=0)
self.root.mainloop()
foo = bar(foo)
browser = mechanize.Browser()
gb1.assign_to_a([1, 2])
plt.close(fig)
df2 = pd.concat([df] * 10000)
df.groupby(level=0).cumcount()
print(os.ttyname(sys.stdin.fileno()))
bins.append(int(df.val1.max() + 1))
y = np.concatenate((firstvals, y, lastvals))
output, err = p.communicate()
plt.quiver(X, Y, Z2, width=0.01, linewidth=1)
v.iloc[-1]
parser = etree.XMLParser(schema=oaischema)
plot_events(x, y)
sys.exit()
b = a.tolist()
info[0][0] == 1
log.setLevel(logging.ERROR)
sessionmaker(bind=self.engine, autocommit=True)
all(recursively_empty(c) for c in e.getchildren())
df = pd.concat([df] * 1000, axis=1)
form = MyModelForm(instance=my_record)
req = urllib.request.Request(url, data)
(data.T - vector).T
ax = fig.add_subplot(1, 1, 1)
np.random.seed(0)
ts = pd.Series(zip(*my_list))
h.funcB()
h.funcC()
distance[0][0][0] = 1
df[2].plot(ax=axes[1, 0])
data = self.request.recv()
print(my_string.format(**d))
matched = [c for c in cmds if c.startswith(s)]
np.unravel_index(np.ravel_multi_index((10, 52), arr2.shape), arr1.shape)
print(hb.norm.vmin, hb.norm.vmax)
np.split(lst, np.cumsum(sec))
self.get_user_from_cookie()
time.sleep(0.01)
ranges.append((2, 10))
r = requests.get(url)
r.json()
pool = Pool()
self.num = self.num + 1
lines = f.readlines()
django.setup()
[(5, 0), (8, 2)]
plt.show()
plt.subplot(2, 1, 2)
df_test.reindex(idx)
list(itertools.islice(fib(), 10))
print(np.trapz(counts, bins))
gtk.main()
plt.show()
[k for k, v in sorted(list(dct.items()), key=lambda p: p[1], reverse=True)]
pd.read_json(jsonfile, lines=True)
main()
self.socket.sendall(image_data)
print(np.allclose(r[0], k))
print(a[i:j])
HttpResponse(something)
Doc.docimage_set.all()
df.columns = pd.to_datetime(df.columns)
r = float(s)
sheet = book.sheet_by_index(index)
np.split(a, [int(0.8 * len(a)), int(0.9 * len(a))])
h5file.close()
self.update_clock()
np.where(a < b * 10, a * 2, -a)
module = sys.modules[func.__module__]
self.parent_model.objects.get(pk=resolved.args[0])
a = create_matrix(8, 8)
pygame.mixer.music.play()
h.Do()
file.write(line)
a.mainloop()
args = parser.parse_args()
mydict.update(myitem)
np.tensordot(gggg, T, axes)
Py_INCREF(v)
send_file(file_name, as_attachment=True)
f.__defaults__
result = np.clip(arr, 0, 255)
True
ax.axis([-0.2, 1.2, -0.2, 1.2])
render_to_response(template, context)
ctypes.string_at(self._buffer, self.size)
-autobus
query.filter(Cls.field.in_(terms))
print(response.url)
ax.scatter(xflat, y, z)
z = np.array([complex(c.m_x, c.m_y) for c in cells])
arr[1, 0]
s.groupby(s.shift().notnull().cumsum()).transform(lambda g: g[-1] / g.size)
logging.debug(line)
urllib.request.install_opener(opener)
pprint(ddiff, indent=2)
PLT.show()
df.query(qry)
np.random.shuffle(ones)
df.index.values
self.hide()
foo[1, 2]
fig = plt.figure(figsize=(4, 4))
a = a[::-1]
round_down(10, 10)
[j for i in lst for j in (replace_with if i == to_replace else [i])]
plt.gca().add_artist(leg2)
self.fig.canvas.draw()
print(response.url)
root = tk.Tk()
a[..., (0)].flatten()
(a + 1) % 2
df = pd.read_sql(querystring, cnxn, params=orders)
print(time.localtime())
print(tostring(root))
fig = plt.figure()
self.glade.connect_signals(self)
np.linalg.norm(x - y) < np.linalg.norm(sx + sy)
ax1.plot(t, s)
a = df.iloc[:, 1:]
ax = plt.subplot(111, polar=True)
data = render_template(path, **context)
wordcount = Counter(file.read().split())
transport = ssh.get_transport()
s.get(url)
writer.save()
print([l[0].strip() for l in re_data_fields.findall(line)])
ZipFile.namelist()
sys.stdout = sys.__stdout__
x = [0, 1, 0, 1, 0, 0, 0, 0]
A = csr_matrix((data, (row, col)))
self._socket.sendto(message, self._dest)
print(child.tag, child.text)
self.render_template([template], **context)
TestApp().run()
im.crop((0, 0, width, l_start_y + 2)).save(sys.argv[1])
my_method_name()
msg.attach(img)
main()
Base.metadata.create_all(engine)
self.submitButton.grid()
im2.show()
temp()
a = numpy.random.rand(N)
foo(a)
logger.setLevel(logging.DEBUG)
MyModel2.mymodel1
l = sorted(d.keys())
self.showMaximized()
plt.show()
parser = argparse.ArgumentParser()
root.lift()
index = MyModel.objects.filter(sortField__lt=myObject.sortField).count()
l.remove(i)
self.put()
people.groupby(mapping).sum()
data = json.loads(response_data)
row = cursor.fetchone()
print(x)
finder1.score_ngrams(bigram_measures.pmi)
Thread.__init__(self)
book = xlrd.open_workbook(filename)
ranges.append((5, 10))
ax.scatter(xs, ys, zs)
frame.pack()
print(user.columns.name.type.length)
print(numbers, sum(numbers))
df.columns.tolist()
sns.pairplot(df)
decimal.Decimal(x).to_eng_string()
json.dumps(d.isoformat())
aw2.redraw_plot()
numpy.__version__
aapl_200ma.plot(legend=True)
site.close()
print(resp.read())
fp = webdriver.FirefoxProfile()
pd.isnull(np.array([np.nan, 0], dtype=float))
dlg.Destroy()
zip_longest(fillvalue=fillvalue, *args)
i, j = np.meshgrid(np.arange(N), np.arange(N))
accum0.append(cc0)
num = np.sum(np.abs(diffs) < some_value)
print(pd.DataFrame(result, df.index, df.columns))
odds.append(i)
np.kron(a, np.ones((blockSize, blockSize)))[:rows, :cols]
time.sleep(random.randint(1, 4))
letter_count = dict(zip(string.ascii_lowercase, [0] * 26))
s.diff()
server.close()
data = np.random.randint(25, size=(4, 4))
a[:, (i)]
calendar.setdefault(date, []).append(event)
im = numpy.array(img)
f.seek(0, 0)
__import__(module)
plt.set_cmap(cmaps.viridis)
my_dict[k].append(dict2[k])
A()
pool = multithreading.Pool(1)
plt.gca().add_patch(cir)
MKTYPE2(Stitcher)
sys.stdout.write(char)
df
enc.transform([[0, 1, 1]]).toarray()
newNums = (i for i, x in enumerate(nums) if x == 12)
ssh = paramiko.SSHClient()
screen.blit(newGameButton, (button_x, button_y))
data = f.read()
head, tail = (lambda x: (x[0], x[1:]))(my_func())
datetime.datetime.fromtimestamp(1004260000)
res.append(l)
s.cookies.set_policy(BlockAll())
t.timeit(5)
gibberish(10)
np.mean(self.predictions_, axis=0)
nk -= 1
zipped_file.seek(0)
output[-1].append(item)
m.group()
print(result)
os.kill(-self.proc.pid, signal.SIGKILL)
a = list(range(10000, 20000))
print(sys.path)
the_file.close()
x.argmin(axis=1)
False
result = solve((x + I * y) ** 2 - z, (x, y))
d.update(makedict(elem))
fig = pylab.figure()
sum(v[idx] for k, v in stats.items() if k[ikey] == keyv)
ax = fig.add_subplot(211)
pipeB.send(20)
sp.coo_matrix((C, coords), (a.shape[0], b.shape[1]))
redis.StrictRedis(connection_pool=connection_pool)
self.results = pandas.concat(frames)
ax.set_xlim(0, n_pts)
ax.set_xlim(0, 255)
plt.contourf(X, Y, Z)
[1, 2, 0, 0, 0]
engine.start()
sns.despine()
self.lock.acquire()
print(df)
sys.stdin = Peeker(sys.stdin)
Clock.schedule_once(self.create_webview, 0)
m, n = map(int, input().split())
db.session.add(region)
data.seek(0)
pygame.quit()
float(str)
a[i] += 1
server.starttls()
os.kill(-self.proc.pid, signal.SIGTERM)
ssh.close()
time.sleep(4)
df_c.ix[df_b.index] = df_b
ax[0].legend()
self.render_to_response(context)
w = csv.DictWriter(f, list(my_dict.keys()))
now_epoch = time.time()
notifier.loop()
ax = fig.add_subplot(111)
points.append((x, y))
print(set(chain(*array)))
numbers = zip(*data)
w.show()
a = [a.ix[i] for i in a.index if sorted1[i] < sorted2[i]]
z2[i, list(range(z2.shape[1]))]
sorted(map(sorted, sets), key=lambda x: (len(x), x))
o.close()
smtp.quit()
self.grid()
data.rename(columns=str.lower)
self.hello()
time.sleep(1)
stream.flush()
my_list.append(map(int, ints))
csv_out.writerow(row)
setattr(user, key, value)
np.where(np.array([0, 0]))
A[[0, 1]].shape
response = urllib.request.urlopen(url)
p.start()
np.arange(N).reshape(shp).transpose(np.arange(len(shp))[::-1]).ravel()
print(most_common_words)
ax.clabel(terr, fontsize=9, inline=1)
d1 - d2.values
context.driver.switch_to.alert.accept()
sys.stdout = sys.__stdout__
earth.circle(150, 1)
ax.set_xticks(ind + width)
self.fileobj.close()
db.commit()
my_list = pickle.load(f)
[x for x in the_list if the_list.count(x) == 1]
df
QDialog.__init__(parent)
self.Show()
res = t.render(items=items)
df.replace(replacements, regex=True, inplace=True)
plt.figure()
frame.grid(row=0, column=0, sticky=N + S + E + W)
defaultdict.__init__(self, list)
writer.save()
chr(int(match.group(1), 16))
self.children.append(obj)
tar.getmembers()
cherrypy.config.update(server_config)
pygame.mixer.music.play()
sum(atuple)
parent.kill()
datetime.date(2016, 6, 9),
map(int, list(bin(n)[2:]))
obj.update(add_obj)
print(text_re)
logging.basicConfig(format=FORMAT, level=logging.INFO)
self.__add__(-other)
m.transpose(1, 2, 0)[0, 1]
admin.site.register(question, QuestionAdmin)
Potato(**validated_data)
print(json.dumps(d, indent=4))
t1 = threading.Thread(target=foo)
[([_] + list(itertools.takewhile(lambda x: x != 2, a))) for _ in a]
fig.subplots_adjust(right=0.55)
plt.show()
process.kill()
print(foofile.read())
root.config(menu=menubar)
plt.ylim(max(y) + 0.5, min(y) - 0.5)
type(1)
s.count(s[0]) == len(s)
move_to_root_folder(root_path, os.path.join(cur_path, filename))
callee()
app.logger.addHandler(handler)
writer.writerows(data)
count_2.most_common(2)
plt.show()
element = ElementTree.fromstring(line)
df[df.User_ID.isin(counts[counts > 1].index)]
sns.plt.show()
ax1.xaxis.set_major_locator(mticker.MaxNLocator(10))
print(neighbors(A, 1, 0))
text.set_transform(fig.transFigure)
payload.set_verdict(nfqueue.NF_DROP)
answer.append((apos, bpos))
logging.Handler.__init__(self)
dt + timedelta(days=7 - dt.weekday())
sympy.sympify(r)
[max(islice(map(abs, array), i, i + 4)) for i in range(0, len(array), 4)]
self._on_change()
np.where(a == a.max())
plt.xlim((1e-12, 1))
list(it.starmap(op.sub, it.izip(a[1:], a)))
len(pytz.all_timezones)
handler.setLevel(logging.DEBUG)
self[key]
(dt - epoch).total_seconds() * 1000.0
narr
name = os.path.realpath(os.path.join(root, name))
d = lisp(d[0])
print((first_num, first_arrangement))
self.ax.grid()
x.append(y)
self.ssh.close()
current_time = datetime.datetime.now()
f(a, b)
df.apply(lambda S: S.append(dm))
self.comboBox_2.addItem(QIcon(pixmap), text)
server.starttls()
result = list(set(s for s in stringlist if len(s) == ml))
view_func(request, *args, **kwargs)
key.get_contents_to_file(f, headers)
print(rf.predict(testdataset[-1:]))
f(f, *args, **kwds)
pprinttable([data, data])
[dict(zip(list_of_keys, row)) for row in spamreader]
array.pop(0)
print(paramiko.__version__)
self.conn.commit()
print(df_concat.median())
print(soup)
file.writelines(input_lines)
self.mplvl.setLayout(self.vLayout)
pl.show()
x = conn.cursor()
borderseg, X, labels, Xslice
time.sleep(1)
row_result.append(row_separator)
sys.exit(e)
logging.Handler.__init__(self)
np.transpose(arr, [2, 0, 1]).shape
-47.5, -10.4, 19.1, 25.9, 18.9, -10.4, -2.1, -47.6, 41.8, -12.1, -15.7, 12.1, -11.0, -0.6
window.show()
func(*args, **kwargs)
(df == 0).all()
loop.run_until_complete(task)
a[:, (0)].max()
os.chdir(folder)
L.grid(row=i, column=j)
np.sqrt((q * q.T).sum())
words = l.split()
str(theint)
[i for i, j in takewhile(lambda i_j: i_j[0] == i_j[1], zip(list1, list2))]
window._master = tk.Frame(window)
s.add(val)
os.dup2(so.fileno(), sys.stdout.fileno())
print(driver.title)
x[2:].sort()
ch = logging.StreamHandler()
next(reader)
plt.colorbar(heatmap)
c.writerow(sh.row_values(r))
plt.show()
json.dump(jsonData, outfile, sort_keys=True, indent=4, ensure_ascii=False)
model1.py
now = datetime.datetime.now()
plt.clf()
fd.close()
A.__init__(self, *a, **k)
res.append(value)
window = pygame.display.set_mode((WIDTH, HEIGHT))
session.add(marten)
session.add(shrew)
session.add(loris)
Newlist.append(x)
d.setdefault(k, []).append(v)
base64.urlsafe_b64decode(enc)
a, b
np.ones(10, dtype=bool)
print(as_list)
np.random.seed(42)
yaml.load(s)
random.choice([left, right]), random.choice([top, bottom])
f.quit()
layout.addWidget(self.list)
plt.tight_layout()
pd.Series(date_rng.format())
z = pd.read_csv(io.StringIO(x))
obj.__class__ = newclass
ax.set_yticks(list(range(1, 5)))
self.panel.SetFocus()
sock.close()
nax.set_yticks(tcks)
{(1): 2, (2): 1}
func(*args, **kwargs)
df.POINTS = (df.POINTS * (df.POINTS == df.DATA)).fillna(0)
tree = et.fromstring(xml)
username = db.Column(db.String(20), unique=True)
print(sys.path)
fig, ax = plt.subplots()
np.where(np.isnan(a), ma.array(a, mask=np.isnan(a)).mean(axis=1), a)
do_something()
self.generator.__len__()
json.dump(row, jsonfile)
plt.ion()
sum(l)
dest.close()
fig = pl.figure(figsize=(6, 6))
hist2d(xval, yval, bins=1000, range=np.array([(-6, 6), (-4.5, 4.5)]))
next(i for i in range(100000) if i == 1000)
self.command()
text_widget.index(Tkinter.INSERT)
nbrs.kneighbors(X)
print(tensor[0].eval())
self.frame.focus_set()
set([l[0] for l in a_list])
im.seek(im.tell() + 1)
my_input.ask()
p.stdout.close()
writer.writerow(row)
np.tile(a, (6, 1))
merged_dict = {k: [d.get(k, np.nan) for d in all_dicts] for k in keys}
list(takewhile(lambda i_j: i_j[0] == i_j[1], zip(list1, list2)))
raise argparse.ArgumentTypeError(msg)
out = np.dot(arr_one, arr_two.T)
msg.attach(img)
f[::-1]
urllib.request.install_opener(opener)
ioloop.IOLoop.instance().run_sync(main)
_ranks.append({})
print(list(dedupe_adjacent(data)))
deletex
print(argparse.__dict__)
ax = fig.add_subplot(111)
plt.subplot(121)
somethingThread.start()
item.set_rotation(45)
Client(*sys.argv[1:]).run()
b = np.array([2, 4, 6])
Session.remove()
screen = pygame.display.set_mode((800, 800))
print(str(a[1]))
book_author.save()
session.add(stoat)
df.shift(2).iloc[:, 4:]
dt = datetime.datetime.strptime(s, fmt)
a.shape
s = SomeClass(bar=1, foo=0)
func(*args, **kwargs)
list(filter(pred, A))
print(f.readlines())
self.itemSelectionChanged.connect(self.print_row)
a, b = test()
token.get_access_token(code)
tmp.append(float(line))
df
re.predict_proba(X_test)
new_list = [fruit for fruit in a if fruit not in b]
log = logging.getLogger(__name__)
a = np.array([[1, 2], [1, 2]])
df.eq(0).apply(lambda x: list(df.columns[x]), 1)
m.groups(1)
y = random.randrange(0, maxy)
setattr(self.obj, self.property_names[item], value)
os.path.abspath(sys.modules[LocationArtifact.__module__].__file__)
p.x, p.y, p[0], p[1]
c.nonzero()
xs.append(x)
(-4) ** 2
ax.yaxis.set_ticks(np.arange(0, 100, 10))
-rtest - requirements.txt
mylist.sort(key=itemgetter(1))
self.button.clicked.connect(self.dialog.show)
smax.on_changed(update)
ax.set_xticklabels(xlabels)
love_ctx.add((alice, loves, charlie))
ax.set_yticks(np.arange(len(df.index)) + 0.5)
sleep(1)
x = x - int(x)
myset.add(item)
b = p.map(func, a)
globals()
pprint({x: list(range(x)) for x in range(10)})
time.sleep(0.001)
a.add_child(b)
print(ToSI(d))
x.bar()
sys.path.append(os.getcwd())
plt.show()
fig.colorbar(cf, cax=cax)
print(dpkt.ethernet.Ethernet(packet))
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj))
l.append(s[i:i + 10])
ax2.set_xticklabels(X2tick_location)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
y = x.dot(w)
do_something_useful()
df = df.swaplevel(0, 1, 1)
dfile.write(sfile.read())
admin.site.unregister(User)
hermes.__loader__
self.frame.pack()
{k: map_nested_dicts(v, func) for k, v in ob.items()}
solve(fprime, x)
app.mainloop()
time.sleep(0.25)
random.shuffle(count_list)
multiprocessing.Process.__init__(self)
self.onThread(self._doSomething)
threading.Timer(10, foo).start()
cur.execute(query)
plt.show()
i_take_strings(*s.split())
max_idx = l.index(max_val)
ax1.legend(bbox_to_anchor=(1.2, 1))
name = models.CharField(max_length=50)
self.setCentralWidget(self.central)
[([x] + p) for x in seqs[0] for p in [[]]]
sys.stdout.write(str(result))
dict.__setitem__(self, key, value)
sys.exit(main(sys.argv[1:]))
r = requests.get(url, stream=True)
print(m.groups())
fcntl.fcntl(thePipe, fcntl.F_SETFL, os.O_NONBLOCK)
self.data = np.array([])
smtpserver.starttls()
draw = ImageDraw.Draw(im)
c.add(o)
json.dump(data, fp)
rdd = sc.parallelize(np.random.randint(1000000, size=700000))
name = models.CharField(max_length=10)
sys.exit(0)
Foo.bar()
time.sleep(0.5)
args = parser.parse_args()
len(np.unique(array)) > 1
select.select([A], [], [])
_location.gsm_location()
root = lxml.etree.fromstring(xmlstr)
ax.ticklabel_format(useOffset=False)
intvals[i - 1:i + 1]
fh.seek(offset)
get_indices(a, b)
True
c.set_dashes([(0, (2.0, 2.0))])
sorted(dictionary.values())[0]
(df == 0).astype(int)
get_key(d, 22)
np.bincount(A, B)
result = random.sample(coo, 2)
fig = plt.figure()
service = get_vision_service()
print(df[column])
process.crawl(MySpider)
self.x1 += self.speed * math.cos(self.bearing)
dict.__setitem__(d, new_key, v)
print(timedelta(minutes=6 * 60))
l = l[:1] + x + l[2:]
pool.terminate()
f.seek(0, whence=2)
list2.append(dict2.get(key))
soup = BeautifulSoup(urllib.request.urlopen(url).read())
np.bincount(ixs, minlength=mat.shape[0]).dot(mat)
min(k for k in d if k > key)
draw()
self.add_node(destination)
list(grouper(2, my_list))
arcpy.RefreshTOC()
gb1.copy_to_a([1, 2])
add.apply_async((1, 4), task_id=i)
grid_sizer_1.Add(self.window_1, 1, wx.EXPAND, 0)
list(iterateFinitely(lambda x: [x / 2] if x else [], 20))
raise NotImplementedError
p.start()
sys.exit(0)
print(audio.info.length)
app = QtGui.QApplication([])
ao[1:, :] += ai[:-1, :]
DataFrame(dict(s1=s1, s2=s2)).reset_index()
numbers.append(i)
[(5,), (2, 2, 1), (2, 1, 1, 1), (1, 1, 1, 1, 1)]
logging.basicConfig(level=logging.INFO)
form.save()
fullname = os.path.join(path, filename)
[seq[i:i + n] for i in range(0, len(seq), n)]
sum(1 for _ in it)
kwargs_new = {k: v for k, v in list(d.items()) if isinstance(k, str)}
print([[item.p1, item.p2] for item in uniq])
im2 = ax2.plot(image[0:time, (5), (5)])
map(id, b)
result.extend(changecoins)
t.cancel()
sum(p[0] for p in datapoints[0:5]) / 5.0
abort(405)
mainwin.show_all()
self._base.all()[0]
id(x) == foo(x)
{{a}}
tseries.order()
math.sqrt(point[0] ** 2 + point[1] ** 2)
f = a ** 2 + x * b ** 2 + y * a * b * np.cos(c) + z * a * b * np.sin(c)
out.save(output_path)
L[:4]
b = Matrix([[2, 2], [2, 2]])
x = pd.DataFrame(np.random.randn(20, 5))
axes.plot(xs, ys)
view_func(request, *args, **kwargs)
plt.scatter(x, y, c=x, s=100, cmap=reds)
set(l1) & set(l2)
nsmallest(4, list(range(len(values))), key=lambda i: values[i])
container.grid_rowconfigure(0, weight=1)
dis.dis(func)
print(os.path.join(root, pathname))
current_app.login_manager.unauthorized()
new_list = []
print(node.text)
a = input()
root = objectify.fromstring(xml_string)
self.configure(width=imagesize[0], height=imagesize[1])
HttpResponse(status=200)
ax = plt.gca()
print((datetime.date(year, month, day) - datetime.timedelta(1)).isoformat())
ssh = paramiko.SSHClient()
df
print(file_content)
{10}.issubset(chain.from_iterable(x))
self.worker.beep.connect(self.update)
self.clients.append(client)
np.put(arr, list(range(len(arr) + num, len(arr))), np.nan)
A = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]])
result.fillna(df1, inplace=True)
fig, ax = plt.subplots(nrows=1, ncols=1)
bytes([1, 65, 2, 255])
conn, addr = s.accept()
self.SetSizer(sizer)
f.close()
id = Column(Integer, primary_key=True)
B = copy.deepcopy(A[0])
ax = fig.add_subplot(111)
e.pack()
widget.show()
time.sleep(2.0)
print(p.stdout.read())
df.loc[df[:-1][df.index.month[:-1] != df.index.month[1:]].index]
print(zap)
plt.show()
np.random.shuffle(a.flat)
show()
blit_text(screen, text, (20, 20), font)
d = np.repeat(b, a.shape[0], axis=0)
proc.communicate()
print(os.getcwd())
cal_window.set_type_hint(gtk.gdk.WINDOW_TYPE_HINT_DOCK)
print(response.content)
entries = dict([(x, y) for x, y in zip(out[::2], out[1::2])])
a.wut
rdd1.join(rdd2)
fn(*args, **kwargs)
msg.attach(MIMEText(message))
wx.App.__init__(self, False)
result.extend(pat.findall(text))
np.array([1, 2]).size
self.setLayout(layout)
sys.exit(subprocess.call(sys.argv[i:]))
htmlDoc.close()
plt.show()
f.close()
con.close()
[p[0] for p in deck]
print(a.headlines.all())
sorted(list(kwargs.items()), key=lambda i: i[0])
figure(1, figsize=(6, 6))
self.appExeCB.addItems(list(self.items.keys()))
b_thread.start()
{(x * x) for x in range(10)}
punto.wkt
count = sum(1 for _ in emoticons)
groups.append([x[1] for x in g])
res = cv2.bitwise_and(img, img, mask=mask)
{{post}}
func(*args, **kwargs)
deletedic[k]
d = defaultdict(lambda : 1)
app.run()
result[key] += 1
np.datetime64(dt.isoformat())
sys.stdout.write(str(tuple[0]))
plt.scatter(*zip(*new_points))
headers.setContextMenuPolicy(Qt.CustomContextMenu)
network.draw()
zk.stop()
df
print(not not r.search(s))
a = defaultdict(dict)
f()
plt.figure(figsize=(8, 6))
zip(l, l[1:], l[2:])
draw = ImageDraw.Draw(image)
time.sleep(0.05)
self.header = header
ax.patch.set_visible(False)
pd.concat(df.xs(d, axis=1) for d in dupes).groupby(level=0, axis=1).mean()
C[k] = np.dot(A[k], B[k])
self.canvas.scan_dragto(event.x, event.y, gain=1)
stream.write(data)
np.fromiter(test, dtype=np.int)
id(lines), id(ax.lines)
print(x, y)
f.seek(0)
False
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
data.columns = data.iloc[0]
soup = BeautifulSoup(page)
cv2.drawContours(mask, [largest_area], 0, (255, 255, 255, 255), -1)
time.sleep(0.1)
pythoncom.PumpWaitingMessages()
sys.exit(2)
show()
print(index, key, value)
file.close()
df
random.randint(0, int((stop - start) / step)) * step + start
self.x0 += self.speed * math.cos(self.bearing)
smtpserver.starttls()
sys.stdout.write(s)
(np.arange(n) >= m).astype(int)
pd.show_versions(as_json=False)
np.dot(copy, onevec)
self.panel.Bind(wx.EVT_KEY_UP, self.OnKeyDown)
len(list(flatten(mylist)))
pdb.Pdb(stdout=sys.__stdout__).set_trace()
data = response.read()
a.add(1)
data = line.split()
print(cardsdiscarded)
a + [a < 0]
sock.close()
iph.show2()
QObject.__init__(self, parent)
frame.append(4)
sign * 2.0 ** (expo - 25) * prec
print(tupl.a, tupl.b)
pprint(d)
table.resizeColumnsToContents()
df.loc[start:end]
numbers = [random.randint(1, 1000) for x in range(SOMEVERYLARGENUMBER)]
x = Counter([-1, -1, -1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0])
resulting_list.extend(x for x in second_list if x not in resulting_list)
[sorted(sub) for sub in result]
x = np.arange(X)
ax2 = fig.add_subplot(212)
print(unanimous(list(dd.values())))
model.save([spark_context], [file_path])
root = tk.Tk()
app = QtGui.QApplication(sys.argv)
db = SQLAlchemy()
urlfetch.set_default_fetch_deadline(10)
f.close()
eventLoopThread.start()
print(df)
myList.append(myList)
test.py
r = requests.get(url, stream=True)
label.grid_remove()
print(lines[i])
cb.ax.yaxis.set_tick_params(pad=45)
do_something()
a in (b + c, b - c, c - b)
arr = np.array([nbLamps, nbDays], dtype=np.bool)
items = [(-value, key) for key, value in list(the_dict.items())]
__init__.py
print(time.ctime(cdate), os.path.basename(path))
models.py
B = csr_matrix((data, indices, indptr))
print(fdist1.most_common(10))
plt.plot(x_new, ffit)
ax1 = fig.add_subplot(2, 1, 1)
print(p.match(s).groups())
input_date.astimezone(current_tz)
attr = {}
[datetime.datetime(2012, 1, 2, 0, 0)]
getattr(o, name)()
sys.path
[(5 * n) for n in range(1, 10 + 1)]
d = {}
A = [(A[i] + (0 if i % 2 == 0 else 0.1)) for i in range(len(A))]
itertools.chain(iter(self.items.items()), iter(self.people.items()))
print(json.dumps(mydata, indent=4))
f.flush()
map(int, numbers.strip().split())
df = pd.read_csv(csv_file)
result = df.a.sort_values().apply(lambda x: sorted(x))
print(thisRDD.toDebugString())
subprocess.Popen(winCMD, stdout=subprocess.PIPE, shell=True)
result.append(line)
lst2.append([x[0] for x in lst])
browser.close()
s.close()
min(foo, key=float)
deletedf.index.name
bokeh.io.show(page)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
fig = plt.figure()
client.get(URL)
driver = webdriver.Firefox()
fig = plt.figure(figsize=(10, 8))
f.close()
np.tensordot(A, Combinations, [2, 1]).transpose(2, 0, 1)
f.axes[2].set_position([0.45, 0.05, 0.05, 0.4])
connection = urllib.request.urlopen(url)
Session.commit()
np.put(arr, list(range(len(arr) + num, len(arr))), np.nan)
initcaller()
rdd_malformed.flatMap(lambda x: seq_try(json.loads, x)).collect()
dict_writer.writerows(toCSV)
self.end_headers()
app.config.from_object(config_obj)
out, err = proc.communicate(open(fn).read())
plt.imshow(np.random.randn(10, 10))
ax.add_patch(circ)
print(data)
document.update(**conv_dict_to_update(data))
df.index = df.index.droplevel(1)
Maemo4Spec()
fig = plt.figure(figsize=(8, 4))
table.sort(reverse=True, key=Team.getName)
time.sleep(5)
r, g, b = map(lambda x: x / 255.0, [r, g, b])
imarray.shape
writer = csv.writer(f)
target.update(request, *args, **kwargs)
cv2.rectangle(img, top_left, bottom_right, 255, 5)
screen.blit(my_image, another_position)
[(x + y) for x, y in zip(a, b)]
lines = f.readlines()
br.show()
processes.append(Popen(command, stdout=pipe, close_fds=True))
ax2 = fig.add_subplot(2, 1, 2)
logger.setLevel(logging.NOTSET)
a = np.random.rand(size)
self.layoutChanged.emit()
path.path(mypath).splitall()[0]
b in l[l.index(a) + 1:]
a[i1, i2]
layout.addWidget(self.table)
deletedict_[key]
server.bind(sockfile)
fig = plt.figure()
list(map(add, [2, 2]))
cls.method_two()
fs.noteoff(0, 76)
p.stdin.close()
s = requests.Session()
ax1.plot([x1, x2], [y1, y2])
x = np.linspace(0, 20, 1000)
setup.py
print(str(a[2]))
now = datetime.datetime.now()
print(df)
x, y
np.where(a > b * 10, a * 2, -a)
rec.array([[40.0, 140.0], [50.0, 150.0], [60.0, 160.0]], dtype=float64)
gca().get_lines()[n].get_xydata()
app = QtGui.QApplication(sys.argv)
df
f.flush()
cb = fig.colorbar(im, ticks=LogLocator(subs=list(range(10))))
my_svr.fit(x_training, y_trainr)
msg.get_payload()
plt.show()
print(ET.tostring(newroot))
root.columnconfigure(1, weight=1)
file.close()
print(bool(pattern.search(byte)))
sps.coo_matrix((data, (rows, cols)), shape=(x.shape[0], theta.shape[0]))
ax1.set_xlim(1, 6)
mail.starttls()
df.idxmin(1)
str(unichar)
result = [[k, da[k] + db[k]] for k in set(da.keys()).intersection(list(db.keys()))]
result.append(key)
self.panel_sizer.Add(self.tin2, 0, wx.EXPAND)
threading.Thread.__init__()
frame.append(2)
griddata.addSample([X.ravel()[i], Y.ravel()[i]], [0])
arr = np.array([5, 4, -2, 1, -2, 0, 4, 4, -6, -1])
h, w = img.shape
settings.py
root.resizable(width=False, height=False)
time = datetime.now()
[i for i in B if i in A] + [i for i in A if i not in B]
baz2()
[d[item] for item in a]
pickle.dump(dict1, fp)
str(d)
plot.append(axF)
data = urllib.parse.urlencode(values)
arr = np.array(list(it))
list2 = [foo(i) for i in list1]
im.putalpha(256)
line = line.strip()
p.pattern
QGraphicsTextItem.__init__(self)
splitmaptime / parsetime
summaptime / parsetime
strp / parsetime
plt.show()
sum(a * b for a, b in zip(A, B))
print(get_last_non_zero_index([-2, -2, 0, 0, 0, 0, 0]))
max(b)
print(random_with_N_digits(4))
IOLoop.instance().start()
int(self.opt.stdout.readline().strip())
5 < [1, 2]
plt.show()
msg.attach(part1)
plt.show()
self.panel.Bind(wx.EVT_LEFT_DOWN, self.OnMouseDown)
print([(k, v) for k, v in list(self.items())])
pickle.dump(parameters, out_file)
ax.autoscale_view()
[random.randrange(10000) for _ in range(length)]
fill_node(root)
m = urllib.request.urlopen(url)
time.sleep(60)
min(collection, key=lambda x: abs(x - num))
fig, ax = plt.subplots()
today = datetime.datetime.now()
vobject.contents
np.where(a == a.min())
datetime.strptime(s, f)
file.seek(0, 2)
w.setPalette(p)
plt.plot(t, s)
d2 = [k for k, v in list(d.items()) for _ in range(v)]
trimmed[k[0], k[-1]] += v
len(x)
list(range(10))
sys.path.insert(1, parent_dir)
l.set_option(ldap.OPT_X_TLS, ldap.OPT_X_TLS_DEMAND)
print([(sum(nums[:count]) / count) for count in range(1, len(nums) + 1)])
self.append(item)
fig, ax = plt.subplots()
driver = webdriver.Chrome(chrome_options=chrome_options)
xticks(list(range(1, 6)))
gca().yaxis.set_major_locator(NullLocator())
numpy.exp(numpy.sum(numpy.log(a)))
combination[r - 1] += 1
f1.write(line)
text = json.loads(jsonurl.read())
print([val[1] for val in enumerate(a) if val[0] != i])
y1 = (x - x0) * sin(theta) + (h - y - y0) * cos(theta)
np.dot(X, A)
img = ImageTk.PhotoImage(Image.open(path))
s.bind((HOST, PORT))
self.log.write(message)
do_some_stuff(i)
pool.join()
[0, 0, 0]
settings.development.py
a, b, c, d
Test().run()
a, b
b.sort()
pyplot.show()
e.pack()
lfilter(b, a, data)
json.loads(json_repr, object_hook=_decode_dict)
list.append(values[i])
connection = opener.open(request)
hl.set_ydata(numpy.append(hl.get_ydata(), new_data))
weed.save()
felix.save()
fixedser.plot(ax=axes[0])
pickle.dumps(test)
self.b = a
driver = webdriver.Firefox()
np.fmin(np.digitize(A, hist[1]), bin_count)
[gu(i) for i in range(len(uo))]
True
print(mystring[-1])
p.start()
menu_item.show()
plt.show()
ax.set_ylim(0, Y)
(a != b).nonzero()
self.socket.write(self.request)
psutil.virtual_memory()
a_game.run()
second_list.append(ls[1])
self.Show()
root = et.fromstring(text)
x.Bar()
(a * prior_reci + (1 - a) * prior_reci / 10).sum(axis=1)
app = QtGui.QApplication(sys.argv)
np.vstack(np.triu_indices_from(a, k=1)).T
bcut.label.set_visible(False)
self.s.lower() == other.s.lower()
subplot(2, 2, 4)
z = dict(list(x.items()) + list(y.items()))
plt.ylim(0, 2.5)
print(list(result))
wx.Frame.__init__(self, parent, -1, title, size=(600, 400))
aList.append([element.strip() for element in row])
points.intersects(poly.unary_union)
ax1 = fig.add_subplot(111)
frame.pack()
self.connection.close()
sum_chunk(a, 2, axis=0)
print(lines[0][0].shape)
confusion_matrix(y_actu, y_pred)
x = x.set_value(i, i ** 2)
id = Column(Integer, primary_key=True, nullable=False)
result.append(list_to_html(item))
math.sqrt(2)
signal.signal(signal.SIGPIPE, signal.SIG_DFL)
cherrypy.tree.mount(Root())
frozenset(chain.from_iterable(L))
numpy.__version__
data = [line.strip().split() for line in f.readlines()]
df.T
print(tmpl.render(v=Myobj()))
parent.mainloop()
print(list(traverse(data)))
conn.commit()
create_user_profile(user)
np.all(A == B)
pool = Pool(processes=4)
item.append(item[0])
d = json.loads(json_acceptable_string)
[i for i in range(100000) if i == 1000][0]
print((current_item, next_item))
f.close()
a.f()
g.mean()
print(ax.lines[0])
raise KeyboardInterrupt
os.dup2(oldstdout_fno, 1)
int(random.randrange(0, 255))
MyButton1.grid(row=0, column=0)
ax.lines[-1].set_linewidth(8)
shlex.split(teststring)
user = User.objects.get(pk=1)
z = [[y for y in row if y] for row in x.T]
help(subprocess.list2cmdline)
ax = fig.add_subplot(111)
time.sleep(5)
f(x, y)
my_dict[key] = 1
jsonify(d)
decorator(method)
sys.stdout = old_target
result.append(item)
print(formatter.format(fmt, **data))
f.write(df.to_html())
subplot(4, 1, 1)
self.update_status()
print(df)
eval(x)
result = []
[0] + list(accumulate(sum(1 for _ in g) for _, g in groupby(bool_array)))
wrapper
now = time.time()
regex.sub(_replacer, string)
assertion_raiser()
res = np.array(sorted(a, key=lambda x: (-x).tolist()))
self.comboBox_2.addItems(list1)
time.sleep(0.001)
dask.set_options(get=dask.multiprocessing.get)
last_name = forms.CharField(max_length=256)
writer = csv.writer(csvfile)
deleteL[idel:]
np.matrix(m)
plt.draw()
soup = bs4.BeautifulSoup(thehtml)
arr = arr.flatten()
s.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)
hxs = HtmlXPathSelector(response)
self._timer.cancel()
driver = ChromeDriver(options)
print([x for x in pattern.split(string) if x])
ax.add_artist(ab)
foo.read()
set(d[0]).intersection(*d)
unittest.main()
(np.random.rand(40, 40, 9, 1, 9, 1, 8) + np.random.rand(1, 9, 1, 9, 8)).shape
upload.save(file_path)
r = requests.get(url, stream=True)
df.Mathscore.map(d)
foo(noniterable, isiterable=False)
arr = numpy.zeros((50, 100, 25))
sd.SetSecurityDescriptorDacl(1, dacl, 0)
f.close()
tree = ElementTree.parse(StringIO(text))
x / y
start_date + timedelta(days=days_in_month)
app = QtGui.QApplication([])
np.cumsum(v)
id = Column(Integer, primary_key=True)
x.close()
x += c
moving_average(a)
cf.body[0].names[0].name
collection.insert(data)
views.py
greet()
l = [sublist[:] for sublist in l]
mytest.start()
pd.Timestamp(0)
min(S)
value = sheet.cell(row, col).value
query = query.filter(~table_a.id.in_(subquery))
tuple({name: score} for name, score in max_scores.items())
main()
ent.put()
dis.dis(test)
print(Kerma())
p = subprocess.Popen(inputcommand, stdout=subprocess.PIPE, shell=True)
dy = RK4(lambda t, y: t * sqrt(y))
ax2.plot(list(range(10)))
user_id = db.Column(db.Integer, primary_key=True)
print(list(range(math.floor(min(y)), math.ceil(max(y)) + 1)))
df
print(map(lambda x: x[:-1], test))
ax.get_yaxis().set_visible(False)
dict.__setitem__(self, key, value)
g[1].nunique()
q = mp.Queue()
HttpResponseRedirect(request.path)
df1 = df.ix[:, 0:12]
True
os.fstat(f.fileno()).st_nlink
logger.addHandler(handler)
thumb = ImageOps.fit(image, size, Image.ANTIALIAS)
set(frozenset(ts) for ts in x)
[(a, b, c) for a in range(10) for b in range(a, 10) for c in range(b, 10)]
f.close()
print(my_list)
json.dumps(lst)
print((filename, oct(mode)))
df.index = df.index.values + df.RecordID.map(str)
main()
root.remove(child)
btn_1.focus_set()
ordered = sorted(Foo.objects.all(), key=lambda n: (n[0], int(n[1:])))
a[a > 2]
float(str(x)[:i])
plt.figure(2)
msgunfmt[path_to_file.mo] > [path_to_file.po]
cv2.convertScaleAbs(image, result, alpha, beta)
self.retrieve(request, *args, **kwargs)
ax.quiver(X, Y, Z, U, V, W)
luckynumbers.append(item)
print(unicode_row)
y = [p[1] for p in points]
root.update()
t.close()
fig = plt.figure(figsize=(8, 8))
print(map(str, rr))
yourFile.write(raw_data)
(a[1], b[1]),
f(2)
user = models.OneToOneField(User)
array[0],
print(xyz.__doc__)
plt.colorbar(pc, ax=axes)
plt.xticks(x, labels)
d.setdefault(a, []).append(b)
clf.tree_.apply(np.asfortranarray(X.astype(sklearn.tree._tree.DTYPE)))
pythoncom.CoInitialize()
form.category.data = post.category.id if page.category else 0
np.diff(np.array(s))
np.allclose(a.indices, b.indices)
a = np.arange(10)
self.conn.close()
bp.output_notebook()
imgplot = plt.pcolormesh(lum_img)
proc.append(p)
a = np.arange(10)
ax.bar(dates, values, width=100)
ui.WebDriverWait(browser, 10).until(waiter)
df.to_records()
show()
print(solve(eqn))
collection.find({}, limit=10).sort(sort)
win.setWindowFlags(win.windowFlags() & ~QtCore.Qt.WindowMaximizeButtonHint)
os.makedirs(myTemp)
opener = urllib.request.build_opener(authhandler)
print(list(Squares(20, 90)))
self.ax.autoscale_view()
time.sleep(1)
a = [1, 2, 7]
y = tf.slice(x, i, [1])
ax.legend(handles, labels, loc=2, ncol=4)
inset.yaxis.set_tick_params(labelsize=INSET_TICK_FONTSIZE)
print(s.strip(punctuation))
P = multiprocessing.Pool()
self.draw_grid()
pygame.init()
divide(2, 7, 1000)
plt.imshow(im, cmap=cm.gray)
run_thread.start()
sess = tf.Session(config=config)
all(x == s[0] for x in s)
np.count_nonzero(df.isnull().values)
fig = plt.figure()
np.array(sorted(a, cmp=lambda x, y: list(x).index(1) - list(y).index(1)))
zip(zip(*a), zip(*b))[0]
wx.Menu.__init__(self)
value = test[2]
b = copy.deepcopy(a)
c.append(list(el))
globals()[tupleofnames[i]] = data[i]
f()
date += datetime.timedelta(days=2)
message.send()
Py_DECREF(name)
rows.append(row)
print(w.cget(item))
file_list.append((os.stat(filename)[stat.ST_MTIME], filename))
self.driver.get(response.url)
self.pot.Boil()
ax.update_datalim(np.column_stack([x, y]))
print(icon_info.get_filename())
content = urllib.request.urlopen(some_url).read()
window.activateWindow()
sys.stdout = stdout
round(2.99999999999)
qmgr.connectTCPClient(queue_manager, pymqi.cd(), channel, conn_info)
np.count_nonzero((abcd <= data2a) & (abcd >= data2b))
response.read()
Response(body, status=status, headers=headers)
f.readline()
datetime.now() - datetime.combine(bday, time())
cv.fit(X, y)
np.random.seed(1977)
ser.sum()
plt.close(fig)
max(a, b)
print([x for x in groups if a not in x])
elements.append(q.get_nowait())
{{field}}
msg = email.message_from_string(data[0][1])
p.stdin.write(input)
app = Flask(__name__)
ctx.pop()
print(b[:, :, (2)])
a = a.__iand__(b)
df.A.combine_first(df.B)
df.loc[df[1:][df.index.month[:-1] != df.index.month[1:]].index]
m.swapaxes(0, 2)[::-1, :, :]
np.argsort(p)
stream_handler.setFormatter(formatter)
words = input_string.split()
df.apply(lambda x: len(set(x)) == 1, axis=1)
seq.sort(key=itemgetter(1))
response = requests.get(url, data=data)
False
GEN_CLOSED
_async_raise(self._get_my_tid(), exctype)
Base.metadata.create_all(engine)
pd.isnull(df).sum() > 0
os.chdir(cwd_path[0])
fig = plt.figure()
fillmylist(l, 5)
frame.Show()
self.admin_model_path = self.model.__name__.lower()
self.video_cap.release()
result_dict = {k: list(g) for k, g in it.groupby(mylist, keyfunc)}
dict([x for x in list(data.items()) if x[0] > 5])
print(f(2))
aapl.sign.iloc[(aapl.sign.diff() != 0).cumsum().drop_duplicates().index]
args = parser.parse_args()
d[x].append(foo)
f.close()
myarray[0][-1]
self.pack()
ax.set_ylim(0, np.pi)
setattr(self, field.attname, getattr(db_instance, field.attname))
d = defaultdict(list)
plt.plot(list(range(10)))
-bottleneck.partsort(-a, 10)[:10]
np.cov(np.nan_to_num(data.T))
self.filter(id__in=ids)
d = pd.DataFrame()
current_time = start_time = time.time()
f.close()
fig, ax = plt.subplots()
canvas.draw()
[rect.set_visible(False) for rect in rects]
time.sleep(5)
a[0], a[1] = [4, 5]
plt.colorbar(cax=cax)
datetime.datetime(2001, 11, 12, 0, 0)
signal.pause()
numpy.zeros((2, 20))
print(self.myVar)
in_file.close()
inithello()
print(data)
windowSurface.blit(s, (0, 0))
GST_VERSION_MINOR,
self._data[key]
result = np.cumsum(np.random.uniform(size=100))
[memoized(x) for x in l if memoized(x)]
self.d[key] = max(self.d[key], n)
ax.set_rasterization_zorder(0)
result = eval(myString)
len(set(str_.split()).intersection(list(dict_1.values())))
today = datetime.datetime.now()
m.click(x, y, 1)
date = dateutil.parser.parse(text)
dc.SetBackground(wx.Brush(wx.Colour(255, 0, 255)))
myapp.db.create_all()
[0, 0, 0, 0, 1, 0, 0, 0, 0],
bar = p[0]
data = np.random.randint(0, 100, (400000.0, 206))
b.grab_set()
layout.addWidget(self.view)
frame.a.str.contains(pattern)
time.sleep(2)
df.applymap(atof)
n = a.shape[1]
info[0][1] == 2
ax1.patch.set_alpha(0.0)
db.add_son_manipulator(Transform())
form.jobs[0].company.choices = company_list
cameraL.SetFocalPoint(0, 0, 0)
ax.set_ylim(-0.5, 1.7)
print(res.cluster.value_counts())
print(t.astimezone(EST))
dir(settings)
A.view(dtype=np.complex128)
fig = plt.figure()
doc = ET.fromstring(content)
[(x, sum(map(itemgetter(1), y))) for x, y in groupby(L, itemgetter(0))]
df.dtypes
browser = webdriver.Firefox(firefox_binary=binary)
help(modulename)
np.issubdtype(np.uint8, np.integer)
app
element.remove(subelement)
a[1:][::2]
q.all()
print((group.id, group.last_response))
vals = redis.zrange(key, 0, -1)
screen_width = root.winfo_screenwidth()
print(sess.run(tf.shape(parsed), feed_dict={raw: my_data}))
items = [dicttolatex(dic) for dic in items_to_clean]
print([x for x in list(globals().keys()) if isinstance(globals()[x], FunctionType)])
sys.stdout.write(line)
local_namespace.clear()
arr[97][99][99]
d = dict(zip((o.name for o in object_list), object_list))
s = socket.socket()
grouped.size().idxmax()
[i for i in np.argsort(a[:, (0)]) if a[i, 1] == -1][0]
list(merged.values())
parser.add_argument(*option, **config)
foo()
random.choice(list(i))
t_points = t_image[t_pos[:, (1)], t_pos[:, (0)]]
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
pg.AxisItem.__init__(self, *args, **kwargs)
os.system(command)
filename = os.path.abspath(os.path.realpath(filename))
list(flatten(remove(l, 1)))
sys.stdout = sys.__stdout__
print(br.title())
print(m.group(1))
dom = xml.dom.minidom.parseString(document)
main()
D.ix[idx]
print(Decimal(x))
pythoncom.PumpWaitingMessages()
dateForm.set_index(pd.DatetimeIndex(poorList), inplace=True)
set_trace()
df
[1, 17, 1, 0, 2, 0]
browser.select_form(nr=0)
chain.from_iterable([x] if isinstance(x, str) else x for x in lst)
plt.show()
fileconcord.close()
b = [(sl + [0] * (maxlen - len(sl))) for sl in a]
(bad, good)[x in goodvals].append(x)
arg2value
connection.put_record(stream_name, data, partition_key)
[sum(q[i:i + 2]) for i in range(0, len(q), 2)]
webdriver.Firefox(firefox_profile=fp)
stats.normaltest(x)
seen_add(k)
self.on_finish()
_test()
admin.site.register(model)
_quicksort(array, left, stop)
writer.writeheader()
sys.stdin.readline()
t.start()
root.mainloop()
window.set_icon(windowicon)
print(curve_fit(func, (x, y), z, p0))
sorted(mydict)
plt.subplot(121)
4, (0, 5, 0, 0)
self.textLayout.addWidget(text)
o.do()
csv_writer.writerows(mylist)
print(my_dict)
print(foo(**d))
print(pool.map(f, list(range(10))))
a[i].append(x)
val = val[:-1]
self.gzfile.close()
db.Column(*args, **kwargs)
config = configparser.ConfigParser(defaults=myDefaults)
total = sum(marks.values())
sys.getsizeof(10 ** 10 ** 6)
soup = BeautifulSoup(html)
browser.set_handle_redirect(True)
msgBox.exec_()
app = Flask(__name__)
max(set(words), key=words.count)
s = [0] + [i for i in range(1, len(x)) if x[i] != x[i - 1] + 1] + [len(x)]
ax.plot(dataX, dataY, linewidth=0.5)
response = urllib.request.urlopen(req2)
f.write(header)
draw()
ax.set_ylim(ax.get_ylim()[::-1])
{{day}}
p.stdout.read().strip()
draw.text((5, 5), char, (0, 0, 0), font=font)
tuple(map(itemgetter(0), G))
Process.__init__(self)
libfoo.dll
val = ast.literal_eval(val)
p.join()
s = pd.Series([10, 10, 10, 14, 10, 10, 10, 14, 100, 14, 10])
http.HttpResponseRedirect(url_with_get)
subplot(1, 2, 1)
db.session.add(entry)
add(*arg)
s = input()
print(self._applecount)
[n for d, n in sorted((abs(x - myNumber), x) for x in myList)[:k]]
result.append(a)
[dct for dct in listA if dct.items() >= dictA.items()]
p.start()
gunicorn_django - c / path / to / website_gunicorn.conf.py
self.values.add(item[1])
np.split(a - b, np.cumsum(y))
max(zip(map(sum, a), a))[1]
{(x + 1) for x in l}
print(foo)
Parallel(n_jobs=2)(delayed(foo)(parameters) for x in range(i, j))
uuid.uuid4().hex
yaml.dump(data, outfile, default_flow_style=False)
self.pack()
d.cards.remove(Card(1, 1))
tree.xpath(expr, namespaces=nsmap)
form.save()
print(line)
do_something_else()
logger = logging.getLogger(name)
soup = BeautifulSoup.BeautifulSoup(htmldoc)
self.filter(id__in=ids)
df.combine_first(s.T)
sys.getsizeof(t1)
result = [list(map(player, group)) for level, group in groups]
x.digest()
out = [(x, y, z, c) for (x, y, z), c in zip(a, h)]
my_logger.setLevel(logging.DEBUG)
args = sys.argv[2:]
vv.plot(x, y, z, lw=10)
df = pd.DataFrame(np.random.randint(10, size=(10, 10)))
t.daemon = True
demand.ix[series.name].apply(lambda x: x * series).stack()
d = defaultdict(list)
tag.insert(1, subtag2)
plt.scatter(x2, y2, label=str(pointset2))
reader = csv.reader(csvinput)
new_func_name()
name[0][0][-1]
data = json.load(jsonFile)
a = [x[:] for x in repeat([0] * cols, rows)]
Profile.objects.filter(full_name__iregex=regex)
df.astype(float).sum().astype(int).astype(str)
num_df[num_df[data_columns].notnull().all(axis=1)]
conn.close()
print(g.user_set.all())
f.close()
ax.get_children()
[vector.index(x) for x in sorted(list(range(n)), key=vector.__getitem__)]
print(list(od.values()))
ax = fig.add_subplot(111)
a.remove(item)
y.sort(key=sort_key)
bucket.configure_lifecycle(lifecycle)
map(cls.my_func, items)
instance.save()
key = bytearray.fromhex(hexs)
ax.xaxis.set_major_formatter(ticker.NullFormatter())
[0, 0, 0, 0, 0, 1, 0, 0, 0],
L = [np.arange(start[i], stop[i]) for i in range(ndims)]
app.debug = True
print(file.readline())
res = [f.name for f in message.DESCRIPTOR.fields]
sys.path.insert(0, os.path.abspath(__file__).rsplit(os.sep, 2)[0])
[x for x in iter if is_even(x)]
result.get()
print(isinstance(obj, BaseClass))
ax.plot(x, y)
queryset.filter(created_at__range=(first_date, last_date))
arr[1, 1]
win = gtk.Window()
a.reshape(sh).mean(-1).mean(1)
plt.plot(list(range(10, 20)))
signal.signal(signal.SIGALRM, nothing)
print(float(2))
index = np.ogrid[:z2.shape[0], :z2.shape[1], :z2.shape[2]]
func(*args)
root = tk.Tk()
l.sort(cmp=lcmp)
cherrypy.quickstart(CServer(), config=conf)
self.audio.terminate()
cb = plt.colorbar()
tree.predict(iris.data)
str(self.client_address[0])
reactor.run()
output.append([item])
df.values
y[np.isnan(y) | np.isinf(y)] = 0
log_file
writer = csv.writer(out)
map(mydict.get, [k for k in list(mydict.keys()) if k >= 6])
(x - x.min()) * (b - a) / (x.max() - x.min()) + a
fig.subplots_adjust()
x(os.path.join(dirpath, f))
self.y -= STEP
scipy.sparse.coo_matrix((data, ij), shape=(nrows, ncols))
curs.execute(sql)
mutate_dict(lambda x: x + 1, my_dictionary)
textobj.set_text(wrapped_text)
pool = multiprocessing.Pool()
max(list(d1.items()), key=operator.itemgetter(1))[0]
result_dict = OrderedDict()
matplotlib.hatch._hatch_types.append(CustomHorizontalHatch)
plt.show()
plt.ion()
p.start()
data[s < m]
result[i] = func1d(x, y)
textwrap.fill(s, width=10)
sorted(list(range(len(a))), key=lambda i: positions[i])
[[(e - d) for d in l] for e in l]
ax.xaxis.set_major_formatter(ticker.FixedFormatter(name_list))
list(d.items())
[0, 0, 0, 0, 0, 0, 1, 0, 0],
docx.write(os.path.join(tmp_dir, filename), filename)
wx.EndBusyCursor()
gtk.main()
mod = importlib.import_module(name)
d.add(2)
print(etree.tostring(doc, pretty_print=True))
Tup()[0]
n = collatz(int(n))
print(sum(1 for x in range(1000000) if my_condition(x)))
ctypes.memmove(self._buffer, value, size)
zbar.version()
df.iloc[[p] + [i for i in range(len(df)) if i != p]]
{{b}}
lst = [(word[0].upper() + word[1:]) for word in s.split()]
HypotheticalBranch(1, 2, 1)
self.label = QtGui.QLabel(self)
print(hex(id(b)))
plt.setp(labels, rotation=90)
date_paris.astimezone(pytz.utc)
df.dot(s)
parser = argparse.ArgumentParser()
user = request.user
data.sort(key=lambda data: [alphabet.index(c) for c in data[0]])
res = [x for x in res if x.size > 1]
double_to_hex(17.5)
r = requests.get(url)
ax1.axis([xmin, xmax, ymin, ymax])
plt.grid()
array([16, 6, 8])
self._timer.start()
A = np.arange(16).reshape((4, 4))
print(maskborder.shape[:2])
f.write(xml)
np.set_printoptions(threshold=np.inf, linewidth=np.inf)
writer.close()
ax.grid()
print(b.dtype, b[0].dtype, b[1].dtype)
result = db.engine.execute(sql)
a = np.array([sum(row * weights) for row in values])
z = z.reshape(x.shape)
cj = cookielib.CookieJar()
time.sleep(60)
np.random.seed(1145)
p.stdout.close()
data = response.read()
self.tws.connect()
print(concatenate((tone2, tone1), axis=1))
self.assertEqual(resp.status_code, 200)
self.output = []
basemetaclasses.append(metacls)
source.camlp4.ocaml
fd.close()
fig.figimage(np.random.random((xpixels, ypixels)))
python - -version
TRUE
max(i[j] for i in l)
sess = tf.Session()
timestamp = calendar.timegm(d.utctimetuple())
cursor = connection.cursor()
pyplot.ioff()
set(dic1) == set(dic2)
self.assertDictEqual(input_dict, expected)
c.writerow([cell.value for cell in r])
count += 1
new.setdefault(k, []).append(v)
[(a - b) for a, b in zip(dividers + [total], [0] + dividers)]
files_grabbed.extend(glob.glob(files))
ax.set_xticks(np.arange(0.5, 10.5, 1))
ax2.plot(x, y)
{{saved_setting}}
random.shuffle(indices)
makesymbexp(makesymbtree(T, L))
print(response.getvalue())
list1 = [int(x) for x in list1]
f.seek(0)
print(a)
{k: min(i for i in (h1.get(k), h2.get(k)) if i) for k in h1.keys() | h2}
do_something()
self.clear_button.pack()
self.func(*(args + self.args), **kwargs)
zip(assignment, *grades)
pylab.imshow(image)
self._data = {}
pool.close()
id = models.CharField(max_length=255, default=create_id)
plt.tight_layout()
len(bitArray.tobytes()) / float(len(sequence))
ax.legend()
theFile.close()
words = line.split()
sum(chain(*my_list))
array = [myNumber]
not int(a)
fig = plt.figure()
print(__main__.__file__)
msg.attach(text)
np.argwhere(A > 50)
Department.objects.filter(group__exact=self.group)
[_f for _f in map(f, string) if _f]
self.root = tk.Tk()
s = sparse.csr_matrix(a)
df.iloc[indexers]
data.append(value)
app = wx.PySimpleApp()
print(best2)
__getitem__
neurons.append(neuron)
my_array.clip(0, 255)
result = list(create(10))
cosetCoding.cosetCoding(10, 11, 8, ctypes.byref(arr), 0)
mpp.start()
callback(myargument)
np.random.seed(100)
a = next((i for i in userInput if i in wordsTask), 42)
lxml.html.etree.tostring(a)
foo(20, 5)
G = nx.gnp_random_graph(n, p)
AB = [(a + b) for a, b in zip(A, B)]
[a, b, c, d, e, f]
self.stream.stop_stream()
update_document(person, data)
os.path.normpath(os.getcwd() + os.sep + os.pardir)
output.append(lst)
plt.plot(datenums, values)
pdb.set_trace()
a + b
parser = argparse.ArgumentParser()
result = dict(defaults, **request)
[]
setattr(obj, key, value)
app.exec_()
worksheet.column_dimensions[get_column_letter(i + 1)].width = column_width
sess.run(init_op)
isinstance(obj.method, types.MethodType)
np.add(a, b, out=c)
reader = csv.reader(f)
df
random.shuffle(a)
df
[list(g) for _, g in groupby(numbers, lambda x: x // 10)]
gethandler
time.sleep(0.1)
result = regex.match(str)
nbrs.fit(X)
self.setLayout(layout)
client = suds.client.Client(sys.argv[1])
map(tuple, pairs)
f.close()
output.write(resp.content)
time.sleep(x)
binascii.unhexlify(line)
indices = np.split(sidx, cut_idx)[1:]
__init__.py
fh.write(dh.read())
plt.hold(False)
plt.figure()
tags = ManyToManyField(Tag)
z = np.arange(Z)
pilImage.close()
tuple(it.chain(*base_lists))
d = dict.fromkeys(a, 0)
process(line)
{{my_dollars | currency}}
axins1.set_ylim(y1, y2)
sorted([[x, y] for x, y in list(distances.items())], key=lambda x: x[0])
plt.xticks(visible=False)
_test_model()
print(r[0] + r[1])
print(value)
socket.gethostname()
[(a[i] - a[i + 1]) for i in range(len(a) - 1)]
print(hex(i)[2:].zfill(2).upper())
res.append(x)
s.apply(partial(map, lambda x: x * 2))
d[parts[0]] += parts[1:]
Decimal(2).sqrt()
r = requests.get(file_url)
foo = decorator_with_args(arg)(foo)
importlib.import_module(name)
server.close()
print(letters[:i] + letters[i::-1])
d.mean(axis=tuple(range(1, d.ndim)))
plt.clf()
soup = BeautifulSoup(text)
a.func()
MyUser.friends.append(Friend(MyUser.id, MyFriend.id))
df * df2.values
list(map(lambda m, n: m - n, a, b))
np.random.seed(10)
ns = np.linspace(-5, 5, 1000)
print(extract_text(htmlDom))
id = Column(Integer, primary_key=True)
logging.error(e)
t = np.copy(a[:, (0), (0)])
tz.localize(parser.parse(a_datetime))
json.dumps(my_data)
mw.dockWdg2.setWidget(mw.content2)
log.addHandler(fileh)
output.close()
root.config(menu=menubar)
raise Exception()
f.axes[4].set_position([0.55, 0.45, 0.4, 0.05])
reader = csv.reader(input, **options)
fig, ax = plt.subplots()
pool = Pool(processes=4)
handler()
[x for x, y, z in G]
print(line.rstrip()[::-1])
np.npv(0.01, cashflow)
urllib.request.install_opener(opener)
list2 = list(total_and_item(list1))
digits = int(math.log10(-n)) + 2
doSomethingWith(match.group(0))
zip(l, itertools.repeat(o))
app.debug = True
Ainv[i] = np.linalg.inv(A[i])
ast.literal_eval(s)
s.listen(1)
divisibleBySeven = [num for num in inputList if num != 0 and num % 7 == 0]
time.sleep(1)
id = Column(Integer, primary_key=True)
fig = plt.figure()
instance.save()
observer.start()
self.response.out.write(os.stat(path).st_mtime)
print(numpy.__version__)
c.most_common()[0]
result.get()
u.close()
subplot(4, 1, 2)
C4.foo()
C5.foo()
c_array[:] = chain(p for p in points)
writer.save()
df.drop(df.columns[cols], axis=1, inplace=True)
print(p.groupby(p.diff().cumsum()).cumcount())
pprint(dict(grouped))
app.listen(8888)
parser = argparse.ArgumentParser(add_help=False)
nopreds.add(u)
np.maximum.reduceat(given_sort, first_idx)
tree = etree.parse(StringIO(data), magical_parser)
im.set_clim([frame.min(), frame.max()])
app = QtGui.QApplication(sys.argv)
image /= image.max() / 255.0
w.tk.mainloop()
int(s)
process(0)
plt.scatter(xs[i], ys[i], marker=m[i])
signal.signal(signal.SIGALRM, self.handle_timeout)
fig = plt.figure()
print(is_perfect_cube(2146689000))
screen = pygame.display.set_mode(DISPLAY, FLAGS, DEPTH)
print(x)
fig.autofmt_xdate()
int(time.mktime(value.timetuple()))
self.Bind(wx.EVT_LEFT_DOWN, self.on_left_down)
sum(map(lambda x: map(lambda f: f(x), ListArg), listFunc), [])
sys.getsizeof(Bar())
self.out, self.err = self.proc.communicate()
math.ceil(f / 2.0) * 2
print(json.dumps(categories, indent=4))
m = [[(row - col) for row in l] for col in l]
abs(1)
f.bar(1, 2)
subprocess.call(subprocess_cmd)
transpose.sort(key=itemgetter(0))
hash(round(6.75, 1))
p.stdin.close()
pool = multiprocessing.Pool()
loop.run_until_complete(main())
df2[cols]
dict.__setitem__(self, frozenset(idx), value)
x + y
text[(value + step) % len(text)]
gevent.joinall(jobs)
print(requests.get(url).text)
outfile.write(self.archive.getmember(name).read())
ax.set_xticklabels(mons)
f.close()
n % 2 == 0
t.join()
{k: {k_: v[k_] for k_ in common_keys} for k, v in d.items()}
sys.exit(0)
mylist.append(item)
list(dict.keys())[0]
tn.close()
tree = ET.parse(StringIO(text), parser)
dict_writer.writerows(rows)
MyModel.objects.filter(complexQuery)
ax = fig.add_subplot(111)
df.ix[start:end]
o.call()
np.random.shuffle(zeros)
a2[:, (1)] > 10
a = bitarray(2 ** 20)
pool.join()
[del_zeros(L, i) for i in range(5)]
nll
result.add(elements[0])
df
rconsole.spawn_server()
f(**locals())
XXX
func(*args, **kwargs)
now - timedelta(seconds=15)
os.chdir(os.path.dirname(os.path.realpath(__file__)))
reload_urlconf()
x = int(str(x)[::-1])
pylab.draw()
b = np.matrix(np.array(a))
a[0] * b[1] - a[1] * b[0]
writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
wx.Frame.__init__(self, parent, id, title, pos, size, style, name)
__main__.py
doctest.testmod()
print(list(igroups([0, 0, 0])))
ax = fig.add_subplot(111)
r = boxplot(data)
nx.draw(G, pos)
groups.apply(existedBefore)
a = np.delete(a, b, 0)
numpy.ma.masked
socket.setdefaulttimeout(10)
print(list(unzipped[0]))
pyplot.show()
parent.remove(elem)
Package - 2 / namespace / module2 / __init__.py
ax = fig.add_subplot(111)
entryFrame.columnconfigure(0, weight=10)
d[k] = tuple(d[k] for d in ds)
p.join()
plt.hist2d(a, b, (50, 50), cmap=plt.cm.jet)
b = word in (w for i, w in enumerate(wordList) if i not in ignore)
obj.load_from_filename(filename)
all(isinstance(i, int) for i in l)
fig, ax = plt.subplots(1, 1)
g.set(xticklabels=[])
t = np.linspace(0, T, nsamples, endpoint=False)
ax.scatter(x, y)
random.seed(1)
name = models.CharField(max_length=100)
raise OSError(p.stderr.read().rstrip())
print(response.read())
add_keys(d[l[0]], l[1:], c)
X[:, (np.where(mask1)[0])][np.where(mask2)[0]]
df.groupby(df.columns, axis=1).apply(lambda x: x.info())
self.common1()
root.tag
setattr(self, key, [company])
merged = list(joinz(1, zdf1.iter(), 0, zdf2.iter()))
bitmap = np.array(bitmap, np.uint8)
time.sleep(2)
pd.concat([group for _, group in grouped if len(group) > 1])
plt.draw()
print(match.groupdict())
print(string)
df = pd.concat([df] * 1000).reset_index(drop=True)
toggle_btn.pack(pady=5)
write.writeheader()
t, dt = np.linspace(0, 1, num_t, endpoint=False, retstep=True)
self.__dict__ = self._dict
a = [1, 2, 1, 4, 1, 1, 1, 1]
ln.set_xdata(list(range(len(data))))
x.reshape(-1, x.shape[-1]).shape
signal.signal(signal.SIGINT, _forward_to_django_shutdown_signal)
self.Bind(wx.EVT_WINDOW_CREATE, self.SetWindowShape)
np.isfinite(b_0).all()
int(string[::2], 2)
xscroll.grid(row=1, column=0, sticky=E + W)
ax.set_xticks(x_labels_pos)
roster.append(dayroster)
tableWidget.setItem(i, j, item)
tic2()
f = lambda x: x * np.cos(x - 4)
cursor = cnxn.cursor()
accumulationList.extend(doSomething(x))
{{item_forms.empty_form}}
_stack.append(self.kwargs)
[[f(v) for v, f in zip(x, funcs)] for x in a]
mod = __import__(module_name)
os.path.join(*choices)
unicodedata.category(character)
code_country.append([key, countries[key]])
self.window.set_default_size(100, gtk.gdk.screen_height())
w = Gtk.Window()
collections.defaultdict(recursive_dict)
ttk.Frame.__init__(self, *args, **kwargs)
parse(data)
data = json.loads(json_content)
result = my_range[:-1]
self.exit(0)
max(sentence)
self(other(*args, **kwargs))
w.writerow(list(somedict.values()))
time.sleep(1)
DEVNULL.close()
self.session.get(url)
ax.set_zlim(-100, 100)
textdata.set_index(mergecols, inplace=True, drop=False)
User._default_manager.get(username__iexact=username)
form = UploadForm(request.POST, request.FILES)
canvas.grid(row=1, column=1, sticky=Tkconstants.NSEW)
(x + y) / 2
list(map(sub, a, b))
[x for x in b for b in a]
Base.metadata.reflect(bind=engine)
idx = np.arange(A.shape[0])
list(product([]))
fig, ax = plt.subplots()
list(totals.items())
ax = fig.add_subplot(111)
my_list = json.load(f)
test = defaultdict(defaultdict(list))
list(set(chain(*x)))
fig = plt.figure()
d.update(extra)
f.close()
result.append(list(range(last, last + v)))
app.register_blueprint(simple_page)
[0, 0, 0, 0, 0, 8, 0, 0, 0, 8, 0, 0, 0],
results = Queue.Queue()
chi2.ppf(0.8, df=2)
path = os.path.realpath(path)
inner(x)
print(avg(arr))
print(df.iloc[:, (0)].values.flatten())
C5.bar()
r = requests.post(finalURL, data=payload)
unittest.TextTestRunner(verbosity=1).run(testsuite)
f.readline()
os.system(image)
len([(1) for _ in takewhile(lambda x: x == a[0], a)])
output_file.writelines(merge(*files))
deletenew_list[0][0], new_list[1][0]
db.session.commit()
socket.bind((HOST, PORT))
ax.set_xlim([-0.1, 1.1])
True
foo.foo()
parser.print_help()
now_date.replace(day=1)
all(x == first for x in it)
m = cv2.moments(c)
self.level(sys.stderr)
s.ioctl(socket.SIO_RCVALL, socket.RCVALL_OFF)
reader = csv.reader(csvfile)
a = np.array([0, 0, 0, 0, 0, 0])
ax = fig.add_subplot(111)
self.response.out.write(template.render(template_values))
solve(z ** 2 + (1 + I) * z + (6 + 18 * I), (x, y))
hist([t.hour for t in ts], bins=24)
any(s in l for l in lines2 for s in search_strings)
family.remove(i)
model.feature_importances_
print(pool.map(f, list(range(10))))
f.close()
main()
wx.Frame.__init__(self, parent, title=title, size=(200, 100))
leadingzerocounts[i] += 4
pylab.show()
lst = json.loads(string)
np.split(np.concatenate((a, np.zeros(padding))), n)
round(number * 20) / 20
tar.close()
obj.save()
ser.close()
browser = webdriver.Firefox()
signal.signal(signal.SIGINT, self._signal_handler)
max(a)
b = Finalizable()
np.all(np.linalg.eigvals(x) > 0)
cv2.circle(img, (x, y), 4, (0, 255, 0), -1)
foo.baz()
key = lambda x: x[0]
result
df[:-1]
self.frame.SetFocus()
np.sum(np.where(m, 1.0 / p, 0.1 / p), axis=1)
res[(i), (j), :] = [C, X, 0]
shutil.rmtree(path)
df[idx]
df
self.device.open()
math.factorial(10)
application = django.core.handlers.wsgi.WSGIHandler()
getattr(obj, self.attr)
[x for x in a_list if x[0] == 1]
print(list(multilpy_string(l)))
panel.to_frame().unstack().T.groupby(level=0)
data = requests.get(url).json
json.loads(json_data)
time.sleep(0.05)
zip(l, l[1:])[::2]
self.conditions[:] = [helper(c, type, params) for c in self.conditions]
print(mystring[:100])
psutil.pid_exists(os.getpid())
x = list(d.keys())
print(proc.communicate())
print(repr(test), repr(is_valid_name(test)))
os.chmod(path, stat.S_IWRITE)
[parser.parse(x) for x in _split(s)]
ax.plot(xs, ys, *args, **kwargs)
y[:]
fig = plt.figure()
array([27, 27, 27, 26, 26, 26, 26, 26, 26, 26])
pandas.set_printoptions(max_colwidth=100)
doing_fd.seek(0)
{{value}}
abs(x) % abs(y) * (1 if x > 0 else -1)
config.readfp(buf)
plt.tight_layout()
dict.__init__(self, *args, **kwargs)
app.exec_()
print(interestingelts[0])
[dict(pairs) for pairs in unique]
data_entry.save()
print(url_string)
self.panel.Bind(wx.EVT_PAINT, self.OnPaint)
writer.writerows(changes)
frame.Show()
d[l[0]]
serve_on_port(2222)
plt.close()
cov = np.array([[200, 100], [100, 200]])
time.tzset()
plt.contourf(Yi, Xi, Z, alpha=0.7, cmap=plt.cm.jet)
lambda x: int(float(x))
ax = plt.subplot(111)
2 * np.arcsin(np.minimum(1, np.sqrt(a))) * radius
do_something()
mlb.focus_set()
plt.subplot(211)
form.is_valid()
auth_login(request, user)
DO_SOMETHING()
log()
inverse_dict[v].append(k)
br.set_cookiejar(cj)
ax.axis([0, 10, 0, 255])
t.colname == getattr(t, Table.colname.property.key)
ax.axis([0, max_dim, 0, max_dim])
map(joiner, sixgrams)
plt.stem(x, y)
settings.py
print(newList)
self.frames.append(ImageTk.PhotoImage(frame))
print((a, b, c))
plt.show()
frame.axes.get_xaxis().set_ticks([])
app = web.application(urls, globals())
G.add_edge(1, 2)
time.sleep(random.random() * 5)
random.seed(0)
arrow.utcnow().isoformat()
os.read(sys.stdin.fileno(), 4096)
len(line) == 9 and sum(line) == sum(set(line))
m = re.search(pattern, text)
local_p.kill()
saveglobals(savepath)
print(response.info())
print(type(my_date))
self.instream.close()
a = [[i] for i in range(5)]
os.chdir(directorypath)
df.index[:-1].union([df.index[-1] + pd.offsets.MonthEnd(0)])
ax.autoscale()
foo[index] = foo[index][0], new_value
setattr(c, a, getattr(cls, a))
print(value[0])
print(row)
do_something_with_i(i)
mock_output.reset_mock
br = mechanize.Browser()
str(self.num)
_style.fill.start_color.index
[(b - a) for a, b in pairwise(L)]
obj.some_method()
ax.invert_yaxis()
img = cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)
s = match.group(0)
System.out.println(str.toString())
self.x == other.x
df = df.append(data)
self.mock_requests.get.assert_called_with(url)
p.i, p.fitness
d[number].append(line)
screen.show()
new_dict
str(value)
instance.delete()
HttpResponse(folders)
[random.randint(low, high) for _ in range(count)]
print(my_func.__doc__)
QGraphicsTextItem.mouseReleaseEvent(self, event)
ind = [i[0] for i in sorted(enumerate(b), key=lambda x: x[1])]
suspect[k] = v
db.delete(d)
req.send(data)
deactivate
print(r.url)
filelike.seek(0)
new_im_vec = ravel(rollaxis(im, 2))
self._handle(*args, **options)
print(get_max_count(l=l, num=7))
list.activites.all()
a[::2] = [-1, -2]
[list(filter(str.isalpha, word)) for word in s.lower().split() if word[0].isalpha()]
[double(x) for x in li]
sys.exit(app.exec_())
print(f(2))
contourf(x, y, H, levels, cmap=cmap_lin)
contourf(x, y, H, levels, cmap=cmap_nonlin)
body = urllib.parse.urlencode(post_data)
Response(post_serializer.data)
lock.acquire()
t[0].__sizeof__()
self.connectToMUC()
Br = [x, x, x, x, x, 0]
urlparse(url).query
im.show()
json_string = json.dumps(d)
T2()
parser = argparse.ArgumentParser()
p.wait()
deleteself.d[k]
plt.imshow(normalized)
c = a[::2]
chain.from_iterable(combinations(s, r) for r in range(len(s) + 1))
pool = ThreadPool(processes=1)
compare(mylist[i], mylist[j])
fig = plt.figure()
[0.0, 0.4, 0.6, 0.0, 0.0]
sys.stdout.flush()
FALSE
main()
np.inner(a, b)
print(permutenew(l))
print(cv2.__version__)
fin.close()
u = np.unique(arr)
time.localtime().tm_isdst > 0
list(it.product(x, mit.flatten(y)))
set(x for x in hello if hello.count(x) == m)
plt.gca().cla()
session.commit()
ssh = paramiko.SSHClient()
func2()
p.start()
datetime.utcfromtimestamp(dt64.astype(int))
sleep(1)
db.create_all()
ax = fig.add_subplot(221)
df.ix[:, (df.columns.isin(col_list))]
self._lines.append(d)
a = np.arange(11)
plt.figure()
{{item.date | localtime}}
o5.method
plt.show()
time.sleep(0.5)
path, tail = os.path.split(path)
ax = fig.add_subplot(111)
raise NotImplementedError
list.__init__(self)
f1()
re.findall(p, test_str)
list(set(result))
soup = BeautifulSoup(html)
Counter((type(x), x) for x in arr)
wkt.dumps(point)
math.floor(numpy.nextafter(x, -numpy.inf))
print(error.__class__.__name__, error)
plt.scatter(x[i], y[i], marker=mapping[m[i]])
b = {name: a[name] for name in a.dtype.names}
signal.signal(signal.SIGINT, signal_handler)
np.random.shuffle(lst)
ret = urllib.request.urlopen(req).read()
msg.attach(part)
print(pd.get_dummies(values[mask]))
surface.write_to_png(ofile)
cbar = plt.colorbar(CF, ticks=lvls, format=l_f)
match.group(0)
1 << np.arange(m)
sum(alist)
df1.iloc[1:5, 2:4]
new_df.index.set_levels(group_names, level=0, inplace=True)
n = [x for x in n if x in string.whitespace or x not in string.printable]
[]
send_from_directory(cache_timeout=0)
key, value = dict.popitem()
log_file.close()
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj))
B = np.split(A, np.argwhere(A[:, (0)] == 0.0).flatten()[1:])
slice_coords_by_x(arr, xmin=1, xmax=5)
[counts[w] for w in word_list]
unittest.main()
popen.wait()
f(*args)
AC_SUBST([PYTHON_LIBS])
[6.49, 48.9995]
sorted(matches, key=len, reverse=True)[0]
print(line)
gtk.main()
table[table.column_name == some_value]
graph = nx.Graph()
Test(somevalue)
os.chdir(curdir)
[e for e in l if e % 2 == 0]
pool = multiprocessing.Pool(processes)
img.show()
img.execute_transforms(output_encoding=images.JPEG, quality=1)
Clojure
Response()
s.bind((ADDR, PORT))
print(G.neighbors(1))
print(sess.run(output))
[x for x, y in list(collections.Counter(l).items()) if y > 1]
func(**literal_eval(params))
d = dirname(dirname(abspath(__file__)))
any([(i in fruit_dict1) for i in fruits])
output = [(x, y) for x, y, label in L]
psycopg2.connect(database=database_name)
os.chdir(WORKDIR)
sys.getsizeof(x)
df
print(r.read())
print(deco2.__name__)
model = Sequential()
lst = lst[0].split()
s = pygame.Surface((1000, 750))
print(time.mktime(t1))
fill_between(x, 0, l[0], color=colors[0], alpha=alpha)
parser = argparse.ArgumentParser()
[(item * 2) for item in x]
fig = plt.figure()
self.queue.pop()
self.log_window.Show()
im.show()
f.seek(0)
list(od.values())
pprint.pprint(recur_dictify(df))
help(x)
map(sum, zip(a, b, c, d, e))
print(ord(sys.stdin.read(1)))
result
sorted(set().union(*list(results[env].values())), key=str.lower)
f.seek(0)
self.queue.put(item, block=True)
df = df.reindex(pd.DatetimeIndex(df.index), fill_value=NaN)
print(e.message)
user = User.objects.get(pk=1)
data = json.loads(response.read())
print(mechanize.urlopen(form.click()).read())
self.assertEqual(obj.val, 2)
im.seek(im.tell() + 1)
abc = lambda *args, **kwargs: myFunction(*args, **kwargs)
plt.show()
parallelismPool.close()
ax.cla()
ax1 = fig1.add_subplot(111)
writer.writerow(record)
-javascript
pl.ylim(0.0, 1.0)
cp / usr / bin / pdb / path / to / virtual / env / bin
print(sys.path)
pool = multiprocessing.Pool()
b.extend([i, i])
mask = np.in1d(A, B)
cv2.circle(mask, (i[0], i[1]), i[2], (255, 255, 255), -1)
img.ConvertToBitmap()
line = f.stdout.readline()
print(bisect(b, a))
fb.append(str(n))
os.write(1, a.tostring())
model = Sequential()
plot_confusion_matrix(df_conf_norm)
new_list.index(to_find.lower())
pcap_lookupnet(dev, ctypes.byref(net), ctypes.byref(mask), errbuf)
button.pack()
type(a)
r = sqrt(2 * random.uniform(0, 1) / A + r_min * r_min)
type(img_str)
signal.signal(signal.SIGALRM, old_handler)
worksheet.write(row, col, text)
s = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_IP)
print(settings.SIMPLE_CONF)
print(x)
gen_move(list(range(10))[::-1])
d = {}
self.sizer.Add(self.inner_sizer, 1, wx.ALL | wx.EXPAND, 20)
browser = webdriver.Firefox()
im.show()
time.sleep(10)
label.set_fontproperties(ticks_font)
g.kill()
data = ctypes.POINTER(ctypes.c_char)()
save_file.write(str(tweet))
nil
ii = df[pd.notnull(df.C)].index
self.timeout = timeout
np.setdiff1d(a1_rows, a2_rows).view(a1.dtype).reshape(-1, a1.shape[1])
pos = f.tell()
time.sleep(1)
res = next(idx for idx, (x, y) in coupled_idx if x != y)
y_pred = [0, 0, 2, 1, 0, 2, 1, 0, 2, 0, 2, 2]
fork()
file2.close()
plt.show()
test()
plt.plot(x, y)
ax.plot(dates, data)
f(u(n - 1))
new_stdout.seek(0)
logging.getLoggerClass().root.handlers[0].baseFilename
cols = df.columns.values.tolist()
vals = [g(i) for i in range(100)]
a.index(a.lstrip()[0])
string[i:i + len(keyword) + 5 + 1]
ax.pbaspect = [2.0, 0.6, 0.25]
c.setopt(c.HEADERFUNCTION, retrieved_headers.store)
app = flask.Flask(__name__)
ssh = paramiko.SSHClient()
both.reset_index(inplace=True)
output.close()
d.setdefault(a, {}).setdefault(b, {}).setdefault(c, []).append(value)
self.response.set_status(404)
vt[:, (0)]
hey()
group.save()
ds.addSample((1, 1), (0,))
np.linalg.solve(a, b)
result = collections.defaultdict(list)
total = sum(c.values())
threading.Thread(target=listen_to_audio).start()
console = logging.StreamHandler()
plt.plot(list(range(10)), rasterized=True)
numbers = [aux[x] for x in row]
plt.yticks(positions, labels)
ax.xaxis.set_minor_locator(hours)
substrings.sort(key=len)
python - i
qPlg.append(QPointF(*p))
today = datetime.date.today()
np.asarray(0 for i in range(10))
plt.subplots_adjust(hspace=0.5, wspace=0.001)
a[-1].append(5)
print(df)
out.write(largedata)
round(VALUE * 2.0, 1) / 2.0
os.close(wpipe)
main()
t.start()
deleteself.__dict__[key]
conn.close()
s = a.sum(axis=(0, 1, 2))
msg.attach(part)
[[i for i in sublist if i < n][:5] for sublist in ls]
fig = plt.figure()
numpy.sin(x)
df = df.astype(object)
window.show_all()
app = wx.PySimpleApp()
scipy.sparse.linalg.spsolve(coeff_mat, np.ones(2 * (n - 1)) * n)
dictonary[k].append(file)
f = lambda x: 2 * x
np.arange(10)[10:-1:-1]
s.add(x)
substrings.sort(key=lambda s: len(s))
sh.write(n, 1, v)
d[a][b] = c
contents.sort(key=itemgetter(2))
date = datetime.datetime.fromtimestamp(seconds + sub_seconds)
func(cpy)
handler.setFormatter(formatter)
f.write(imgdata)
fig, ax = plt.subplots()
len(df[~pd.to_datetime(df.index).isin(dropThis)])
pylab.plot(t)
peasant.badly_hurt()
ax.plot(list1)
serializer = UserSerializer(request.user)
deleteordered_dict[k]
BASE_DIR = os.path.dirname(os.path.dirname(__file__))
[c.__name__ for c in cls.__subclasses__()]
raise Exception()
print(a[:10])
zip(a, b)
d[i] = np.sum(a[(i), b[i]:c[i]])
sys.exit(0)
glVertex2i(10, 110)
result.append(list[index])
max(result, key=len)
list(map(ord, list(L)))
sorted(s) == sorted(t)
mlab.pipeline.iso_surface(src, contours=[s.max() - 0.1 * s.ptp()])
plot(x, y)
tk.Frame.__init__(self, parent, *args, **kwargs)
gevent.sleep(r)
wrapper1
x += a * np.cos(2 * np.pi * f0 * t + 0.11)
img = img.resize((160, 240), Image.ANTIALIAS)
conn.accept()
pprint({k: getattr(creator.__code__, k) for k in dir(creator.__code__)})
counter.save()
(d[i] for i in k)
download_ftp_tree(ftp, remote_dir, local_dir)
shutil.rmtree(target)
df = df.append(r)
os.unlink(f_path)
list(map(pow, list(range(10)), repeat(2)))
mylist[n // 10].append(n)
df.convert_objects(convert_numeric=True)
df = pd.Panel.from_dict(d).to_frame()
cv.Circle(color_image, center_point, 20, cv.CV_RGB(255, 255, 255), 1)
print(countOccurencesAtTheEndOfTheList([1, 2, 1, 1, 1, 1, 1, 1]))
plt.clf()
auth.login(request, user)
{{form.as_p}}
project.some_func()
[x for t in zip(a, reversed(a)) for x in t][:len(a)]
event.Skip()
OrderedDict.__init__(self, *a, **kw)
df.iloc[7:9, (5)] = np.nan
lines = ax.plot(np.arange(1000))
session.commit()
chardet_detector.reset()
set.intersection(*sets)
np.where(x ** 2 + y ** 2 > 1e-10, x * y / (x ** 2 + y ** 2), 0.5)
sys.path.append(egg_path)
hzfile.printdir()
print(words == sorted(words, key=str.lower))
dict(CharCounter(text))
(Convert(i, base) for i in range(start, end, step))
Doc.save()
help(cherrypy.engine.exit)
picture.getpixel((x, y))
stoppool.start()
mpmath.besseli(0, 1714)
self.traceback = traceback.extract_stack()[-2]
os.remove(str(filename))
insert_sort(ascend_list, i, lambda x, y: x[1:] >= y[1:])
rpy2.robjects.numpy2ri.activate()
df = pd.concat([s1, s2], axis=1).ffill().dropna()
self.value += 1
out[:, :, (mask)] = B[:, :, :, ::-1][:, :, (mask[:, ::-1])]
dict((k, v[v < 0].to_dict()) for k, v in compat.iteritems(data))
Frame.__init__(self, master)
self._window.show()
f(1, 2)
panel.SetSizer(sizer)
time.sleep(1)
print(etree.tostring(child))
run(reloader=True)
f = urllib.request.urlopen(req)
cbar.set_clim(-2.0, 2.0)
current.append(item)
nonzero(t == 8)[0][0]
print(f.split(d)[0] + d[0])
print(stealth_check[key])
s.close()
form.save()
df
horoscope.check_all()
figure()
show()
cursor = db.execute(sql % params)
q.write(str)
session.rollback()
ax.imshow(field1, cmap=plt.cm.YlGn, vmin=_min, vmax=_max)
words = string1.split()
print(submission.url)
nsmallest(4, list(range(len(values))), key=values.__getitem__)
0.08400000000000002, 0.9999999882280098
shapesMatch([(0, 0), (1, 1), (0, 2), (-1, 1)], rectangle)
unittest.main()
ged.close()
r = requests.get(my_url, cookies=cookies)
ax1 = fig.add_subplot(111)
out = np.mod(c, 2)
cursor = db.cursor()
getattr(self.base, name)
newList = np.clip(oldList, 0, 255)
sys.stdout.write(c)
exit.__str__()
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
self.edges.setdefault(n2, []).append((n1, w))
a[numpy.where(a > 2)]
s.unique()
a = np.array([0, 0.1, 0.5, 1])
d = defaultdict(list)
r = Ribbon(root)
myOjbect.doStuf().doMoreStuf().goRed().goBlue().die()
plt.grid()
np.diag(d - 4) + 4
response
mapping = map(chr, list(range(256)))
[[x0, y0] for x0 in x for y0 in y]
isinstance([], (tuple, list, set))
fig.canvas.mpl_disconnect(cid)
plt.figure(figsize=(20, 8))
ax.add_artist(bbox_image)
time.sleep(1)
foo.bar()
text(x, y, s, fontsize=12)
s.close()
queries &= Q(**{key: options[key]})
G2.add_nodes_from(nodes)
self.paths = []
distances = numpy.linalg.norm(np_cell[1] - srcPos)
[]
metadata.create_all()
string.ascii_lowercase
list(filter(os.path.isfile, os.listdir(os.curdir)))
dis.dis(myfunc)
ax = plt.gca()
f(*args, **kwargs)
print(sum(len(mystr) for mystr in strings))
list(d.keys())
ax.figure.canvas.draw()
fh.seek(0)
screen = pygame.display.set_mode((500, 500), HWSURFACE | DOUBLEBUF | RESIZABLE)
queryset = Town.objects.all()
y = myodeint(lambda y, t: func(y, t, alpha), [1, 0, 0], t)
title = models.CharField(max_length=100)
ax[1].add_collection(collection)
randint(100, 999)
dictpsl[key].append(pslrc)
li = list(filter(condition, li))
my_array = list(filter(lambda x: x != value_to_remove, my_array))
matrix[0][2]
initial_array += increments[::-1].cumsum()[::-1]
s2.reset_index(inplace=True, drop=True)
t = np.linspace(0, 1, 6)
entry_list = [entry.title.text for entry in feed.entry]
print([1, 0] in chain(*sample))
module.workflow_set.filter(trigger_roles__id__exact=self.role.id, allowed=True)
df
sorted(data) == sorted(data2)
self.lbl.after(1000, self.updateGUI)
sorted(list(range(len(vals))), key=vals.__getitem__)
self.values.append(value)
session.put()
fig = plt.figure(1)
eval(strab)
simplejson.load(f)
item, = singlet_list
self.rfile.close()
[[11, 12], [21, 21]]
things.filter(category=category)
plt.imshow(x, cmap=mpl.cm.bone)
s.remove(1)
win.idlok(True)
win.leaveok(True)
app.run()
output, err = process.communicate()
a = 1
reactor.connectTCP(host, port, factory)
pdf.getNumPages()
plt.draw()
termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)
item.save()
cur = conn.cursor()
print(np.random.dirichlet(np.ones(10) * 1000.0, size=1))
ax = fig.add_subplot(111)
symmetric_dec(body, session_key)
print(df.head())
screen.refresh()
random.shuffle(tmp)
child1()
child2()
sess.run(outputs, feed_dict=feed)
Y = Y + Z[::-1] - Z[-1]
self.crawler.stop()
np.roll(a, 2)
sorted(list(totals))
g = (i for i in a + b)
new_df
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
my_array[i] = el
self.glade.add_from_file(self.gladefile)
list(10 ** pos * val for pos, val in enumerate(reversed(test)))
app = Flask(__name__)
new_file.write(line.replace(pattern, subst))
app.yaml
part.get_payload()
result.append(row)
Wire.write(number)
ax.figure.canvas.draw()
tree.delete(i)
pl.xlim(0.0, 100.0)
print(form.is_valid())
feeder_lock_object.release()
ao[:-1, 1:] += ai[1:, :-1]
self.dictset = {}
(A != 0).cumsum(1).argmax(1)
list(results)
print(s.query(A).filter(A.boolean).all())
self._callfunc(self, *args, **kwargs)
print(ET.tostring(dict_to_etree(d)))
slice1.append(a, b)
ws = wb.active
outdict[k.lower()] = v.lower()
g.add_edge(2, 4)
np.in1d(test, states)
list(res)
ax = plt.gca()
lgd = ax.legend(loc=9, bbox_to_anchor=(0.5, -0.02))
tty.tcsetattr(stdin_fileno, tty.TCSANOW, old_ttyattr)
test.main()
C.reshape([4, 2, 2])
qjup
self.popitem(last=False)
setattr(cls, name, decorator(fn))
print(r.json())
signal.alarm(0)
d = {k: [] for k in range(10)}
result.append(L.pop())
a.remove(e)
plt.show(f)
ax.add_artist(p)
proc.join()
ts = (dt_with_tz - datetime(1970, 1, 1, tzinfo=pytz.utc)).total_seconds()
self.columnconfigure(0, weight=1)
ShowAppsView.as_view()(self.request)
random.shuffle(keysShuffled)
chr(97)
list1.append(word)
os.getcwd()
self.data[k]
log.setLevel(logging.DEBUG)
A = A[0]
c = {v: k for k, v in list(a.items())}
console.setLevel(logging.INFO)
all(k in dic2 for k in dic1) and all(k in dic1 for k in dic2)
type(f)
df = df.mul(df.columns.to_series(), axis=1)
self.finished.emit()
plt.figure(figsize=(width, height))
IedConnection_getServerDirectory.restype = c_void_p
print(fib(i))
time.sleep(poll_seconds)
df = pd.DataFrame(array, columns=columns)
nums.append((item, n - item))
i += 1
df[subset[subset.isin(myList)].stack().duplicated().unstack().any(1)]
platform.release()
test.main()
print(res.queryString())
[d[:4] for d in MyArray]
json.loads(page_detail_string)
{a[d]: todict([x for x in X if x[d] == a[d]], d + 1) for a in lst}
print(self.recv(8192))
sorted(s, key=lambda c: (-s.count(c), s.index(c)))[0]
request.FILES.update(files)
xticks[-1].label1.set_visible(False)
list(pkgutil.iter_modules())
S[int(line[0]), int(line[1])] = True
df.B.plot(ax=plt.gca())
fig = plt.figure()
sys.exit(1)
imgfile.close()
fig, axes = plt.subplots(nrows=2, ncols=4, figsize=(12, 5))
db.session.add(g)
now = datetime.now()
time.sleep(0.2)
m = scipy.sparse.coo_matrix((data, (r, c)), shape=(100000, 40000))
fig, ax = plt.subplots()
sys.path.insert(0, root_path)
server.ping()
test_maybe_recursive()
fl.close()
os.getcwd()
fig = plt.figure()
[c for c in foo if c not in temp and (temp.add(c) or True)]
sys.stdout.write(line)
out.putpixel((x, y), color)
numpy.array(imc)
print(resp.status_code, resp.text, resp.headers)
response = requests.get(url)
sys.path.insert(0, virtual_site)
instance.save()
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj))
sys.exit(9009)
pylab.scatter([p[0] for p in pp], [p[1] for p in pp])
time.sleep(1)
np.histogram(sampling, bins=np.arange(len(A) + 1))[0]
ao[:-1, :] += ai[1:, :]
server_sock.listen(1)
float(MyClass())
p.kill()
print(json.dumps(doc.identity.addr.reprJSON(), cls=ComplexEncoder))
npi.group_by(a[:, :2]).split(a)
temp.sort()
print(np.ma.masked_invalid(a))
time.sleep(1)
Z = np.array(mean_data)[:, (2)]
Z = f(np.dstack(np.meshgrid(x, y)))
print(e.gmm())
x = np.random.rand(10)
flatten(Cards)
self.edges.setdefault(n1, []).append((n2, w))
content = browser.page_source
gca().set_autoscale_on(False)
[i for i, ltr in enumerate(s) if ltr == ch]
ax.add_patch(patches.Rectangle(pos, w, h, color=c))
b.grab_release()
dict(MyDict.lists())
conn.close()
sys.getsizeof(b)
writer = csv.writer(output)
(abs(arr_f - a) < t).any()
sum_over_n[(-1) ** n * x ** (2 * n) / math.factorial(2 * n)]
dataFrame.pow(timeSeries, axis=0)
args = parser.parse_args()
writer = csv.writer(outfile)
show(0)
f = urllib.request.urlopen(req)
turtle.Screen().exitonclick()
Resources.objects.filter(user=self.request.user.username)
self.finished.emit()
sys.exit()
data = np.array(imc)
deletea[:]
reactor.run()
dc.SetFont(self.GetFont())
signal.signal(signal.SIGINT, self.exit_gracefully)
com.convert_robj(rdf)
InitializeComponent()
max(groups, key=_auxfun)[0]
df = pd.DataFrame(data_as_2d_ndarray)
block_reduce(arr * area_cell, block_size=(2, 2), func=np.ma.mean)
t = np.random.randint(0, 50, 500)
rel_path.split(os.path.sep)
print(match)
a = Finalizable()
[x for x in s if not x in rm]
a[subset_a] += 1
print(delta.total_seconds())
wx.Panel.__init__(self, parent)
plt.close()
raise NotImplementedError
random.shuffle(keys)
env.forward_agent = True
os.path.splitext(f)
plt.close()
checkIP.__file__
df.sort_index()
hash((self.i, self.k, self.j))
self.cardsdiscarded += 1
--nologcapture
leg.set_zorder(1)
img = Image.open(file)
outfile.write(text)
df = pd.DataFrame(dict([(k, pd.Series(v)) for k, v in list(sample.items())]))
setattr(s, name, value)
plt.xticks(list(xMap.values()), list(xMap.keys()))
df = df1.append(df2)
[[my_sum]]
split_list = [listo[i:i + n] for i in range(0, len(listo), n)]
t.start()
example.split()
layout = QtGui.QHBoxLayout()
app.run(True, False)
print(df.loc[name])
data
foo()
print(matchobj.group(1))
button.Bind(wx.EVT_BUTTON, on_button)
l.setLevel(logging.INFO)
numpy.linalg.matrix_rank(A)
np.random.seed()
line = f.readline()
id = Column(Integer, primary_key=True)
B = np.array([2, 4, 6, 8])
list(range(0, len(list1), 2))
areas.apply(multiply_by_demand)
curses.echo()
con.close()
tk.Frame.__init__(self, master)
decorator
df.Stake[i] = 2 * df.Stake[i - 1]
X.sum(axis=1).sum(axis=0)
repr(test.make_fptr())
self.assertEqual(1, 1)
ax = fig.add_subplot(111)
word[0].isupper()
func()
layout2.addWidget(frame2)
final_ensemble.estimators_ = []
plt.scatter(a, b)
args = parser.parse_args()
plt.show()
map(list, combinations(A, 2))
socket.inet_pton(socket.AF_INET6, address)
root = tkinter.Tk()
photo.close()
id = Column(Integer, primary_key=True)
min(min(l_one), min(l_two))
self.fail(msg)
lines.append(inf.readline())
main()
dict()
np.ones(4, dtype=int)
handler.setFormatter(formatter)
c.most_common()
sol[0][0] + sol[0][1] * I
print(np.all(insample == insample_mp))
print(sum(takewhile(lambda x: x < p90, a)))
ax.yaxis.set_major_formatter(matplotlib.ticker.FormatStrFormatter(format))
matches.extend(os.path.join(dirpath, x) for x in dirnames + filenames)
x = sum(similarity(i, j) for i in a for j in b)
df = df.apply(lambda x: np.random.shuffle(x) or x, axis=1)
l.extend(t2)
A = np.array([[0, 1, 0, 0, 1], [0, 0, 1, 1, 1], [1, 1, 0, 1, 0]])
self.lock.acquire()
len(list_of_ids)
pool.join()
list(flatten(lis))
s = s.lower()
a = array(your_list)
[]
queryset = MyModel.objects.all()
ax.add_artist(a)
list(zip(a, b, grouper(c, 2), d))
startfile(os.getcwd())
print(url)
form = ContactForm()
fig = plt.figure()
text = file.read()
math.sqrt((self.x - x) ** 2 + (self.y - y) ** 2 + (self.z - z) ** 2)
np.flatnonzero(goal)
rollaxis(im, 2)
np.fill_diagonal(coocc.values, 0)
print((subject.text, subject.head.text, numbers[0].text))
self.raise_()
Bar.objects.filter(pk=foo.id).update(a_id=bar.id)
set(second_list) - set(x[0] for x in first_list)
map(ord, letters)
time.time() - startTime
list(set(x) - set(y))
execlist[index][4] = mydelay
10 * np.cos(np.hypot(x, y) / np.sqrt(2) * 2 * np.pi * cycle)
[e] * 4
np.rot90(m, 1)
model.add(Dropout(0.2, input_shape=(60,)))
a = [list(item) for item in a]
array[:] = t
self.agg_log.setLevel(logging.DEBUG)
self.setPixmap(image)
xl.Visible = True
ax.set_xlim(xlim)
G = nx.MultiGraph()
p.some_method()
p = subprocess.Popen(my_cmd, shell=True)
self._stop.set()
pat.findall(s)
sizer.Add(self.panel, 1, wx.EXPAND)
len(x) * (len(x) - 1) * 2
time.sleep(0.2)
new_list = []
time.sleep(2)
time.sleep(interval)
my_lib.py
y = [1, 2, 0, 1, 1, 2]
print(paths[min_index], path_distances[min_index])
is_linear(eq1, [a, c])
self.__setattr__(attr, value)
psutil.cpu_count()
parser.print_help()
type(Foo.__init__)
ax.xaxis_date()
fig.show()
pool.terminate()
intvals[bisect.bisect(intvals, 42000)]
parser.parse_args([])
array([[0.0, 1.206, 1.58]])
print(xy_to_index(x, y))
length = len(list(g))
browser = webdriver.Firefox()
np.split(lst, np.where(np.diff(lst) < 0)[0] + 1)
np.array([row[:num_cols] for row in arr[:num_rows]])
ssh_client.connect(host)
user.save()
new_class._ordered_items.sort(key=lambda item: item[1].creation_counter)
br.select_form(nr=0)
plt.figure(1)
f1.close()
any(t in k for k in df[self.target])
root = tk.Tk()
map(str.lower, l)
a[0] + a[1] + a[2]
self.show()
ContentType.objects.get_for_model(obj)
np.shape(x)
settings.py
bubble_sort_2nd_value(tuples_list)
print(hash(frozenset(lines)))
min(mywords, key=len)
new_list = []
json.load(f)
numpy.set_printoptions(precision=16)
app = QtGui.QApplication(sys.argv)
print(0.0 <= x <= 0.5)
array([[106, 140], [178, 220]])
elem.clear()
tag.attrs.append((attr, val))
a2.append(decimal.Decimal(s))
s.close()
print((a, b, c, d, e))
outF.close()
suite = unittest.TestSuite()
conn = psycopg2.connect(conn_string)
xml = ET.fromstring(xmlData)
r = [(a, b) for a, b in zip(l, l[1:] + l[:1])]
any(x is False for x in [a, b, c, d])
newSingle.getHeader().setField(fix.SendingTime(1))
map(lambda a: a[0], takewhile(len, iterate(lambda y: f(y[0]), [x])))
self.redraw(event.x, event.y)
all(isinstance(e, int) and e > 0 for e in [1, 0, 1])
ax2.xaxis.set_major_locator(MultipleLocator(2))
dicts = [{k: v.lower() for k, v in list(d.items())} for d in messages]
{k: sum(d[k] for d in dict1) for k in dict1[0]}
print(args.benchmark)
ax2.set_xticks(new_tick_locations)
a.append(k)
sys.path.append(plugin_path)
deletea[100:99999]
scipy.stats.norm(0, 1).cdf(0)
plt.show()
regex = re.compile(pat)
print(df.groupby(df.index).applyParallel(tmpFunc))
print([([k] + v) for k, v in list(dic.items())])
args = parser.parse_args()
print(map(f, [100, 50, 1000, 150]))
ax.set_xticklabels(())
new_d.append(x)
app = Flask(__name__)
foo_list.append(lambda : bar.func1(100))
a[[0, 1], 1, 2]
x.__exit__()
print(zip(rlist1, rlist2))
{{adminform.form.non_field_errors}}
f(*args, **kargs)
print(str(q.statement.compile(dialect=postgresql.dialect())))
print(np.random.rand())
f.close()
w.writeheader()
result.append(a)
A().my_dir()
os.path.isdir(d)
l.set_option(ldap.OPT_REFERRALS, 0)
MyKlass().func1()
instance = form.save(commit=False)
db.session.add(user)
today = date.today()
self.context.leave()
print(sum(li[:i + 1]))
x[-1:0:-1]
print(s.recvfrom(65565))
code.interact()
req = urllib.request.Request(url, urllib.parse.urlencode(params), http_header)
d = OrderedDict(sorted(list(data.items()), key=itemgetter(1)))
bytes = (ord(b) for b in f.read())
raise KeyError(key)
x = df.ix[:, 5:].sort_values(by=0, ascending=False, axis=1)
frame = pd.concat(list_)
print(list(grp))
ax1.xaxis.set_major_formatter(xticks)
print(loc_dt.strftime(fmt))
array = numpy.array(((2, 2), (2, -2)))
1 / sqrt(2 * pi) * exp(-x ** 2 / 2)
pool.close()
plt.plot(x, y)
np.arange(10)[10:-5:-1]
print(next(second_it))
inner_func
df.isin([1, 2])
zip(*([iter(iterable)] * n))
obj.foo.__func__
[(scores, sum(scores)) for scores in combos]
print(doc.getvalue())
print(bookmark.text)
Aggregator._output()
d[k].append(v)
user.save()
ax = fig.add_subplot(1, 1, 1)
print(dur.total_seconds())
round(number / roundto) * roundto
n > 1 and all(n % i for i in islice(count(2), int(sqrt(n) - 1)))
local_tz.normalize(local_dt)
Py_DECREF(n_ptr)
glutInitDisplayMode(GLUT_RGBA | GLUT_DOUBLE)
print(hello())
fig = plt.figure()
np.nextafter(0, 1)
print([mylist[i:i + 4] for i in range(0, len(mylist), 4)])
print(CAT.number_of_legs)
r, g, b = colorsys.hsv_to_rgb(hue, 1, 1)
markdown_below()
cls.__new__(cls)
log.setLevel(logging.INFO)
print((day_of_year, julian_day))
dict_x[key].append(value)
self.saved = sys.stdin, sys.stderr, sys.stdout
[(i * j * k) for i, j, k in product(a, b, c)]
df
conn.close()
os.abort()
logging.disable(logging.CRITICAL)
b2.insert(END, item)
datetime.fromtimestamp(unix_timestamp)
s.bind((host, port))
[development]
(item for pair in zip_longest(x, y, default) for item in pair)
root = ET.fromstring(xml_string)
cv.SetData(foo_cv, foo_np_view.data, foo_np_view.strides[0])
Person.__init__(self, name, phone)
writer = csv.writer(out_file)
[distance(*combo) for combo in combinations(list_of_coords, 2)]
b = np.zeros_like(a)
layout = QtGui.QVBoxLayout(self)
IOLoop.instance().run_sync(test_it)
Foo()[:42]
threading.Thread.__init__(self)
model.add(Reshape((6, 2)))
index[count][1].append(url)
self.cl.autosetmode()
con.close()
value.append([x for x in getdatas])
df
output.write(resp.content)
self._s = dict((k.lower(), k) for k in d)
x = [1, 2]
result = lengths.nonzero()[0][0] + 1
someList.sort(key=mixed_order)
y = np.zeros((10, 10))
self.file.write(msg)
dict(word.split(value_sep, maxsplit=1) for word in lexer)
a.repeat(2).reshape(2, 2 * len(a[0]))
fig, axes = plt.subplots(nrows=2, ncols=2)
conn.close()
APIResponse(status=status.HTTP_200_OK, data=data)
s.isdigit()
answer.append([(each - x) for x in l])
print(in_nested_list(x, 2))
print(a)
print(response.status_code, response.url)
property_asel = list(itertools.compress(good_objects, property_a))
print(len(args) + len(kwargs))
df.c_contofficeID.str[-4:]
axes[0, 0].legend(bbox_to_anchor=(0, 0.5))
plt.show()
fpid.write(str(pid))
datetime.datetime(2012, 1, 1, 1, 0, 0),
c = a[b[np.searchsorted(b, a[:, (0)]) - len(b)] == a[:, (0)]]
a[numpy.lexsort(a.T)]
self.x + other.x
np.random.shuffle(indices)
json.JSONEncoder.default(self, o)
table.insert(chunksize)
result = [(x + y) for x, y in product(mylist, mysuffixes)]
a.shape[0] == a.shape[1] and np.linalg.matrix_rank(a) == a.shape[0]
deleteelem.getparent()[0]
x.tobytes()
i += 1
sleep(0.05)
self.Show()
pylab.show()
int(x, 0)
r = requests.get(url % params_json)
self.n
subprocess.Popen([command] + args, startupinfo=startupinfo).wait()
fig, ax = plt.subplots()
engine = create_engine(dsn, listeners=[SearchPathSetter()])
p.run()
np.hstack([a, lookup[(a[:, (0)] - 1), :]])
ax.grid(True)
ax.set_yticks(np.arange(AUC.shape[0]) + 0.5, minor=False)
numpy.linspace(10, 20, 5)
screen_height = root.winfo_screenheight()
riak_bucket.delete(key)
type(d)
list(filter(f, list(range(2, 25))))
a[4].append(10)
width += (len(string) - 1) * charspace
json.dumps(data)
BaseDocTemplate.__init__(self, *args, **kwargs)
alt.close()
upgrade(obj)
sys.exit(0)
list(self.__dict__.items())
print(delta.seconds)
parser = argparse.ArgumentParser()
self.device.close()
main.quit()
tree.add(4)
self.assertEqual(self.nums, self.nu_nums)
sys.exit(app.exec_())
gb.get_group(your_key)
raise error
data = json.load(contactFile)
list(itertools.chain(*[list_[s[0]:s[1]] for s in slices]))
self._choices.append((index, val))
[[int(x == y) for x in range(0, n)] for y in range(0, n)]
print(key, value)
fig = plt.figure()
tup[0] = x
np.random.seed(2)
print(unit.objects.all())
df
print(locals())
virEventLoopNativeStart()
np.reshape(df.values, (1, df.shape[0] * df.shape[1]))
pairs = IT.combinations(idx, 2)
b = np.array([[5, 6], [7, 8]])
instance.save()
self.stdin_sock.close()
main()
moduleY.py
p.close()
out[mask] = A[mask]
plt.show()
print(collections.Counter(y for x in listOfLists for y in set(x)))
b = map(list, b_set)
self.delete(self.position, Tkinter.END)
[OrderedDict(zip(list_of_keys, row)) for row in spamreader]
hash(frozenset(iter(self.items())))
random.choice(tuple(bigset))
deletesys.modules[mtr]
build_tree_recursive(tree[child.name], child, nodes)
np.arange(10)[10:-2:-1]
[[(0) for _ in range(length)]]
a[1:2]
cv2.waitKey(0)
name = models.CharField(max_length=50)
server.login(gmail_user, gmail_pwd)
idx = np.argsort(a[1])
np.sqrt(sqrDiff.sum(axis=1))
locale.getdefaultlocale()
app = create_app()
X, Y = np.meshgrid(X, Y)
df = df[(df.date >= df.beg_date) & (df.date <= df.end_date)]
result.append((a, b))
modList.append(len(self._myList))
dict1 = {x.split()[0]: x.split()[1] for x in list1}
diff(sin(x(t)), t, 2).subs(f, sin(x(t)))
sys.exit(p.wait())
ET.tostring(root)
process.join()
fig, ax = plt.subplots()
B[0, 0, 0]
pylab.plot(data)
print(re.match(regex, line).groups())
plt.setp(ax1.get_yticklines()[1::2], visible=False)
task()
dict2 = dict((item[0], item[1:]) for item in table2)
psycopg2.__version__
nodes = [node() for _ in range(100)]
decorator_maker
rows = np.random.random((100000, 8))
print(etree.tostring(tree, xml_declaration=True, encoding=docinfo.encoding))
_trace
print(a[:, :, (np.newaxis)].shape)
worksheet.set_column(0, len(data), 15, formater)
plt.colorbar()
end_date = date.today().toordinal()
s[-7]
do_sth()
sample_object.users.add(1, 2)
users = db.session.query(User).filter(User.numLogins == max_logins).all()
in_file.seek(0, os.SEEK_END)
args = parser.parse_args()
enc.transform([[0, 1, 1]]).toarray()
match.group(1).lower()
find_max(d)
req.add_data(urllib.parse.urlencode(data))
sum(x for x, c in list(Counter(args).items()) if c == 1)
d = dict((k, v) for k, v in list(d.items()) if v >= 10)
l.sort(key=lambda t: t[0])
html = urllib.request.urlopen(url).read()
me.save()
x[1][2]
process.start()
print([key] + map(sum, zip(*value)[1:]))
p.start()
t.close()
x = dict([(k, list(l)) for k in range(1000)])
ax = plt.gca()
len(l)
s = socket.socket()
list1.pop(2)
im.thumbnail(size)
plot(ar)
f(1)
plt.xlim([start - width, end + width])
handler.setFormatter(fmt)
OrderedDict()
l[1]
s = s[:-1]
x[:5] + x[5:].strip()
fig.subplots_adjust(bottom=0.1 * df.index.nlevels)
imshow(wally)
reader = csv.DictReader(f, fieldnames=h)
2 * x + 6
counts = collections.Counter(l[1] for l in a)
str(self.__dict__)
set(second_list) - set(map(f, first_list))
p1 = np.power(np.power(np.pi * 2, k), -0.5)
sum(some_counter.values())
xor_(b.begin(), b.end(), a.begin(), b.begin())
main()
foolist.hml
xml = ET.fromstring(xmlData)
print([r.match(string).groups() for string in strings])
2 * A * sin(distance / (2 * B))
self.canvas.delete(self.img_id)
axes = plt.gca()
im = Image.open(file_path)
orm.YourModel.objects.update(field_name=DEFAULT_VALUE)
Category.query.all()
plot_selected.yaxis.set_ticks(np.arange(0.2, 1.1, 0.2))
ax.set_xlim([0, 2])
p.start()
worker.start()
groups.union_set(a, b)
setattr(self, key, value)
os.chdir(cd)
a_test.__class__
now = datetime.datetime.utcnow().replace(tzinfo=utc)
x = numpy.arange(0, 2 * numpy.pi, numpy.pi / 1000)
matplotlib.__version__
foo()
df.ix[rows]
n += 1
d[k].append(v)
round(x, -int(floor(log10(abs(x)))))
app.MainLoop()
solve([5, 10], [1, 5])
main(list(range(1, 10)))
np.identity(2)[Ellipsis]
app = Flask(__name__)
d += datetime.timedelta(days=1)
pi.source_image.save(image_name, ContentFile(image_file.read()))
main()
new_nums.append(nums[-1])
itertools.dropwhile(it, makepred(5))
min(alist)[0], max(alist)[0]
print(solve(eqs, x, y, dict=True))
plt.subplot(121)
result = img.copy()
plt.show()
get_color(0)
pygame.init()
sys.stdout = flushfile(sys.stdout)
a[np.arange(a.shape[0]), I]
min(l_one + l_two)
test.print_array(a)
[date for date in dates if dates.count(date) > 1]
_st += timedelta(days=7)
zip(a, a)
[(np.bincount(i) > 0).sum() for i in data]
sys.stdout.flush()
hash(self.normalized)
x, y
res.append((toktype, tokval))
print([max(v) for _, v in itertools.groupby(l, lambda x: x[0])])
w.setWindowFlags(QtCore.Qt.FramelessWindowHint)
flag.groupby(level=[0, 1]).max().reset_index()
print(df.join(s))
datfiles[0].seek(0)
plt.show()
mock_last_transaction.assert_called_once_with()
ImageDraw.Draw(blurred_halo).text(position, text, font=font, fill=col)
self.__dict[name]
plt.show()
d.f()
sess.commit()
find_intersection(lst)
new_list.append(my_array + [e])
newR.mean()
doc = xml.dom.minidom.Document()
self.assertEqual(mocked_handler.call_count, 1)
response = urllib.request.urlopen(req)
[(x + L2[i]) for i, x in enumerate(L1)]
users = Users.objects.filter(pk__in=[1, 2])
a = k + a
print([item for sublist in out for item in sublist])
func()
socket.setdefaulttimeout(0.5)
print(request.headers)
gtk.CellRendererPixbuf.__init__(self)
filename, size = read_gzip_info(gzipfileobj)
ax.add_patch(circle)
axcltwo.set_xlim(0, binimg.shape[1] - 1)
df2 = df.iloc[[0, -1]]
tuple(x for sublist in base_lists for x in sublist)
Atomic.register(str)
soup = BeautifulSoup(test_html)
traceback.print_tb(tb)
{{form.content()}}
[([item] if not isinstance(item, list) else item) for item in l]
my_dict = request.query.decode()
print((k + 1) * lcm)
root.withdraw()
listener.setsockopt(SOL_SOCKET, SO_REUSEADDR, 1)
arr[2, 1] == arr[2, 1]
sess = tf.Session(config=config)
window.add(entry)
mask = np.concatenate(([False], np.isnan(a), [False]))
tar.extractall()
np.random.seed(seed)
arr = np.arange(729)
zip_longest(fillvalue=fillvalue, *args)
logger.setLevel(logging.DEBUG)
any(is_subset(d, d1) for d1 in my_list if d1 != d)
result.get()
builder.connect_signals(self)
self.stdout, self.stderr = p.communicate()
driver = webdriver.Firefox()
self._global_wealth
session.commit()
c = pycurl.Curl()
Foo.run_static_method()
{{your_python_data}}
self.logger.removeHandler(ch)
l[:n]
app = flask.Flask(__name__)
isinstance(result, collections.Iterable)
cv.pack()
widget1.grid(row=0, column=0)
df = pd.read_csv(path, skiprows=rest)
pygame.init()
client.service.method(string_array)
print((current_item, next_item))
0.5 * ceil(2.0 * x)
out.clear()
fig.canvas.draw()
epoll.register(p.stdout.fileno(), select.EPOLLHUP)
data2 = data2.groupby(data2.index).sum()
now.astimezone(tz).dst() != timedelta(0)
ax.add_patch(rect)
PROJECT_ROOT = os.path.abspath(os.path.dirname(settings_dir))
followers_df.reindex(index=list(range(0, 20)))
connection.send_command(command, *args)
callable_method(user=user, **{option_name: user_defaults[option_name]})
list[0:10]
json.dump(lst, f)
self._applecount += 1
writer.writerow(row)
buffer(self)[:]
network.draw()
t1.start()
self.worker.moveToThread(self.mthread)
List.append(Item)
f.write(pat.sub(jojo, content))
print(tempfile.gettempdir())
groups = np.array([0, 0, 1, 2, 2, 1])
line = next(f)
users.get_current_user()
all_data = np.append(my_data, new_col, 1)
a = 2
p.wait()
print(ip)
app = QtGui.QApplication(sys.argv)
etree.tostring(nodes[0])
self.connectButton.clicked.connect(self.connectToServer)
contents = f.read()
app = QtGui.QApplication(sys.argv)
plt.scatter(X, Y)
ax.hold(True)
name = models.CharField(max_length=20)
[comment.extract() for comment in comments]
np.issubdtype(float, np.inexact)
new_dict = {k: d1[k] for k in list(d1.keys()) & wanted_keys}
[v for k, v in list(mydict.items()) if k >= 6]
plt.plot(list1)
self.root.overrideredirect(1)
m = re.search(regex, text)
plt.gca().xaxis.set_major_locator(dates.HourLocator())
x = [0] * 10
plt.show()
m = matrix([[1, 1], [1, 2]])
cv2.waitKey()
smtp.starttls()
dt = datetime.datetime.now()
ax.set_xticks([])
df
print([str(b) for b in repo.heads])
self.NEWTAGS.append(tag)
a[1:, 1:]
s = socket(AF_NETLINK, SOCK_DGRAM)
fig = plt.figure()
repo = Repo(repo_dir)
list(dic1.keys()) == list(dic2.keys())
X_train, y_train, X_val, y_val
chr(97)
object_list = Content.objects.filter(subset__lte=no_of_subsets)
os.dup2(self._oldstdout_fno, 1)
print ()
list(itertools.chain(*lst))
pylab.plot(abs(fft))
dbkind[db_type](rest)
last = len(s) - i - 1
a[a == 1] += -epsilon
a[np.where(~a[:, (-1)].astype(bool))]
dfrand = pd.DataFrame(data=np.random.randn(rows, cols))
[a[l[0] + 1:l[1] + 1] for l in zip(e, e[1:])]
time.tzset()
foo(**d)
threading.Timer(1.25, lambda : webbrowser.open(url)).start()
self.hide()
im.show()
y = flatten(x)
m2[m2[:, (1)] > 10]
min(n for n in a if n > 0.7)
hfile.seek(0, os.SEEK_END)
X[:, (n)] += np.dot(A, colb)
sc.close()
myDict = dict().reduceto(lambda t: t[1], lambda o, t: o + t, myTupleList, 0)
max([a for a in yourlist if a[2] >= 100], key=itemgetter(1))
points = np.array(list(product(x_p, y_p, z_p)))
self[key].extend(value)
nn.activate([1, 1])
Spam().foo()
max(min(maxn, n), minn)
df = pd.DataFrame()
client.server_info()
object.__new__(cls)
a, b = b, a
python - virtualenv
count += 1
print(self.cursor.fetchall())
result = yaml.load(fin.read())
np.array([A2[i, slices[j]] for i, j in zip([0, 1, 2], [0, 1, 0])])
sorted(somelist, key=key)
len(result[0])
t.start()
g.add_edge(4, 5)
w.setLayout(lay)
doc = BeautifulSoup(xml)
r.cookies.get_dict()
label = tk.Label(image=image)
frames.append(numpy.fromstring(data, dtype=numpy.int16))
np.max(x, axis=axis) - np.min(x, axis=axis)
min(_, key=lambda pair: pair[0] / pair[1])
new_list
main()
[unique.append(item) for item in sequence if item not in unique]
server.ehlo()
pd.DataFrame(df.values[a], df.index.values[a], df.columns)
sandwich()
print(a.base)
lambda x: x == i or x % i != 0
heapq._siftdown(h, 0, i)
draw.line(((x1, y1), (x2, y2)), fill=color, width=1)
df
z = np.array([1, 2])
plt.show()
pd.DataFrame(d)
fig = PLT.figure()
r[numpy.isreal(r)]
print(json.dumps(dict(rh)))
cherrypy.config.update(config)
self.assertEqual(r.status_code, 200)
hello.ff(x, y)
self.process = subprocess.Popen(args, shell=True)
unittest.main()
addition.extend(array)
func(*a, **kwargs)
fig = plt.figure()
device.close()
dict((k, rank_a[k] - i) for i, k in rank_b)
nx.draw(G, pos)
CV_rfc.fit(X, y)
x.reset_index()
fig.colorbar(surf, shrink=0.5, aspect=5)
a[-4:]
newPic.save()
unittest.main()
[(a if c else b) for item in list]
sys.exit(0)
file.seek(4)
ftp.cwd(directory)
self.data.append(item)
list.__getitem__(self, index % len(self))
soup = BeautifulSoup(html)
res.ready()
button.clicked.connect(self.onStart)
sys.exit(app.exec_())
neuron.draw()
ax1.plot(list(range(10)))
hash(1)
w.writerows(list(somedict.items()))
sc.stop()
print(row[0], row[1])
print(metrics.accuracy_score(y[100:], clf.predict(X[100:])))
db.session.add_all(users)
__init__.py
data = urllib.request.urlopen(url).read()
pow2(a, out=a, num_threads=4)
datetime.timedelta(seconds=result)
b[:, :-1] = a
norm = mpl.colors.Normalize(vmin=0, vmax=1)
matrix([[0.0, -1.0, -1.0, 0.0], [0.0, 0.0, 1.0, 1.0]])
do_stuff()
self.buf.write(contents)
df.iloc[np.random.permutation(len(df))]
plt.figure()
[1, 1, 0, 0, 0, 0, 0]
count += 1
self.socket.shutdown(SHUT_WR)
order = models.PositiveIntegerField(blank=True, null=True)
process(line)
myFunction(*args, **kwargs)
help(bytes)
any(c in badChars for c in yourString)
field.get_attname_column()
soup = BeautifulSoup(urllib.request.urlopen(address).read())
type(_)
entry1.grid(row=1, column=1)
DirectClass.__init__(self)
x = [[int(float(j)) for j in i] for i in x]
isinstance(d, (dict, collections.MutableMapping))
list(set(newIntersections))
print(sys.path)
writer.writerow([subject, itemID, bias1Answer])
now = datetime.utcnow()
list(islice(iter(preresult.items()), 100))[-10:]
conn.send(data)
file_handler.setLevel(logging.DEBUG)
self.frame.pack()
cherrypy.config.update(config)
print(C[np.searchsorted(C[:, (0)], I)])
t.daemon = True
map(functools.partial(myFunc, some_arg=additionalArgument), pages)
plt.figure()
seq[::2], seq[1::2]
os.remove(thefifo)
self.redraw()
json.dumps(fb._asdict())
pool.close()
nx.draw(G, edgelist=edges, edge_color=colors, width=10)
train_op = tf.group(train_op1, train_op2)
self.redraw()
timeit.Timer(timewrapper)
process.start()
setattr(A, name, _method)
c.max()
frame.ix[frame.index[i]]
dt = datetime.datetime.now()
df.columns = pd.MultiIndex.from_tuples(df.columns)
self.assertEqual(auth_result, attempted_auth_result)
soup = BeautifulSoup(html)
self.tree.pack()
shutil.rmtree(dir)
s = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_IP)
ser.hist(cumulative=True, normed=1, bins=100)
df = pd.DataFrame(df, columns=sorted(custom_dict, key=custom_dict.get))
print(res.json())
clf.fit(np_training, np_labels)
pool = multiprocessing.Pool(4, maxtasksperchild=1)
wave_file.writeframes(frame_data)
root.update_idletasks()
print([list(words) for key, words in itertools.groupby(data, init)])
print(response.body)
f = lambda : i
sizer.Add(hsizer, 0, wx.EXPAND)
self.crawler.engine.crawl(self.create_request(), self)
datetime.combine(d, datetime.min.time())
some_func(*params)
str(lst[0]), lst[1:]
my_dictionary.len()
app = QtGui.QApplication(sys.argv)
{{label}}
h2.setLevel(logging.WARNING)
print([item for sublist in [(rep * [i]) for i in a] for item in sublist])
test = set(numpy.random.randint(0, 10, 5))
m.start()
delfile.seek(0)
deletestr
author = models.ForeignKey(User)
HypotheticalBranch(1, 4, 2)
bop.pack(side=tk.LEFT)
[tuple(x for y in i for x in y) for i in list(d.items())]
ax.set_xticklabels([])
l.append(i)
app = Flask(__name__)
data = urllib.parse.urlencode(params)
workbook.close()
b = df.iloc[:, 1:].values
next(value)
s.readline()
K[np.ix_(np.arange(K.shape[0]), train, train)]
container.grid_columnconfigure(0, weight=1)
_myql.__version__
logging.basicConfig(filename=log_name)
stdout.flush()
B.IMC = IMC
ax.set_xticks([0.15, 0.68, 0.97])
sys.setrecursionlimit(10000)
gp2.append(float(i))
soup = BeautifulSoup(response.text)
print([d.b[i] for i in range(5)])
PLT.show()
i + 1
lambda num: num % 2 != 0
els[-1]
author = models.ForeignKey(Author)
print((ss.name(), ss.lemma_names()))
sns.regplot(x, y, ax=ax1)
axes.set_yticks([])
scatter = ax.scatter(np.random.randn(100), np.random.randn(100))
not sum([(not i in A) for i in C])
self.updater.start()
np.mean(arr.reshape(-1, stride), axis=1)
ziph.write(os.path.join(root, file))
db.delete(results)
h5file.close()
new_strs.split()
classifier.fit(X_train, Y)
df
__init__.py
somecell.fill.start_color.index
screen.refresh()
time.sleep(0.1)
setattr(self, name, attr)
A = scipy.sparse.csc_matrix((size, size))
m.p
self.Bind(wx.EVT_LEFT_DCLICK, self.on_left_dclick)
win1.destroy()
parser = etree.XMLParser(schema=schema)
plt.draw()
d = set()
main()
id = db.Column(db.Integer, primary_key=True)
b.shape
list.__init__(self, *args, **kwargs)
button.pack()
image_data = im.load()
html.title.text
data[(data > upper_threshold) | (data < lower_threshold)] = default_value
text.set_color(line.get_color())
time.sleep(10)
data = urlfetch.fetch(feedUrl)
plt.close(fig)
msg.set_payload(zf.read())
print([name for _, name, _ in pkgutil.iter_modules([pkgpath])])
sum(l[-n:]) / float(observations)
cursor = conn.cursor()
print(d[7])
a += b
df.convert_objects(convert_numeric=True).dtypes
dict()
legline.set_linewidth(10)
fig = plt.figure()
self.connect()
args = parser.parse_args()
sel_cur.close()
root.wait_window()
os.write(fd, data)
d = dict()
widget2.grid(row=1)
audio = models.FileField(upload_to=aud_get_file_path)
curl.perform()
print(pd.factorize(pd.lib.fast_zip([df.x, df.y]))[0])
print(tag.name)
date = parser.parse(ds)
parser = argparse.ArgumentParser()
2, 0, 0, 0, 0, 0, 1, 1, 20160224, 20160226
df = df.join(split_names)
a = [0] * K
self.client.close()
nbsumeq(A, B)
plot_data[0].append(1)
driver.quit()
cv.Circle(color_image, center_point, 40, cv.CV_RGB(255, 255, 255), 1)
self.stream.close()
self.count += 1
H = sps.coo_matrix((data, (rows, cols)), shape=(num, num)).tolil()
self.setCentralWidget(_widget)
mask = np.isfinite(x)
conn.send(data)
list(set(theList).intersection(set(theDict.keys())))
f = np.poly1d([1, 0, 0, -1])
session.close()
p.start()
module
hex(buffer.rd(1))
rows = (a != 0).sum(1)
lines = [l.split() for l in f.readlines()]
names = names.append(frame, ignore_index=True)
np.set_printoptions(precision=5)
path = path.strip()
combs = [[x for i, x in enumerate(data) if mask[i]] for mask in masks]
self.application.exec_()
plt.plot(dates, values)
gtk_dlls.append(os.path.join(include_dll_path, dll))
df = df.set_index(cols).apply(f, axis=1).reset_index()
second_largest([1, 1, 1, 1, 1, 1])
self.matrix.append([0] * len(list(adjacencyList.keys())))
points = [random() for _ in range(1000 * 2)]
set_trace()
cv2.waitKey(5)
[x for x in lst if x % 2 == 0][0]
np.apply_along_axis(v.dot, 2, A)
server_sock.listen(1)
cv2.drawContours(filledI, cs, i, color=255, thickness=-1)
os.close(fd)
pylab.legend()
pool.join()
time.sleep(1)
systemtest_n.py
reduce(dict.__getitem__, path, aDict).update(aSecondDict)
id = Column(Integer, primary_key=True)
QWidget.__init__(self, *args, **kwargs)
user = Session.query(User).first()
browser = webdriver.Firefox()
print(np.sum(data, axis=0))
arr[rs:re, cs:ce] = np.rot90(np.copy(arr[rs:re, cs:ce]))
ccb()
self.panel = wx.Panel(self)
writer.writerows(zip(bins, frequencies))
data[row][set_col] = val
r.close()
unittest.main()
new_df = old_df.loc[:, (list_of_columns_names)]
s[4:10]
list(items.keys())
print((key, value))
out = a[sidx[idx]]
timezone.localize(localdt).astimezone(utc)
dialog.ui.setupUi(dialog)
sqlContext.sql(query)
one, four, ten = lst[1], lst[4], lst[10]
print(repr(vocab))
plt.yticks(np.arange(0))
add(**x)
zip(*A)
crawler.crawl(spider)
df2 = pd.DataFrame(np.random.rand(4, 2))
self.opn[op](op1, op2)
obj.__dict__[attr]
a = np.array([0, 0, 15, 17, 16, 17, 16, 12, 18, 18])
print(html2text(html))
dir(modulename)
Base.prepare(engine)
G.edges(data=True, keys=True)
do_stuff()
server_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
w.start()
cur = conn.cursor()
self.instance.olddrivers = instance.drivers.all()
ax.xaxis.set_minor_formatter(ticker.FuncFormatter(ticks_format))
humansize(58812)
humansize(68819826)
df.index[1]
do_foo(obj)
print(list[i][j])
[elem[0] for elem in most_common]
time.sleep(0.1)
os.rename(pathAndFilename, os.path.join(dir, titlePattern % title + ext))
hist, xedges, yedges = np.histogram2d(x, y, bins=4)
fig.tight_layout()
merged[item[key]].update(item)
any(match(str1, str2) for str1 in set1 for str2 in set2)
print(next(first_it))
data.sort(key=getitems)
totaldict[tuple(x[:2])].append(x)
con.close()
ax.legend(loc=1)
print(match.group(0))
process = multiprocessing.Process(target=do_expat, args=(q,))
p.join()
self.assertEqual(target.str(), b62)
ax.xaxis.set_major_formatter(copy.copy(Formatter))
self.flush()
np.arccos(np.clip(np.dot(v1_u, v2_u), -1.0, 1.0))
np.allclose(m[slc], target)
int(b[:-1]) + unicodedata.numeric(b[-1])
pythons_tasklist.append(p)
1 / 0
myset.add(x)
df.ix[List]
M[:, (colnumber)] *= scalar
self.scrollbar.pack(side=RIGHT, fill=Y)
self._stack = []
heapq.heappush(heap, Neg(item))
plt.draw()
ax.get_xaxis().set_major_formatter(mf)
urllib.request.urlopen(r)
s.send(q)
os.fstat(f.fileno()).st_size
cv2.destroyAllWindows()
df = pd.DataFrame([])
nodes.mlab_source.dataset.point_data.scalars = np.random.random((5000,))
self.layout.addWidget(self.button2)
print(the_table.properties())
h, s, v = hsv[:, :, (0)], hsv[:, :, (1)], hsv[:, :, (2)]
app = Flask(__name__)
print(str(name).lower())
sess = tf.Session()
ax.grid()
A = np.diag(1.0 / np.arange(1, 10000))
self._stream.write(text)
r.join(df)
os.path.normpath(path1)
d2 = {key: value for i, (key, value) in enumerate(d.items()) if i % 2 == 1}
dest.blit(tmp, destpos, dest.get_rect().clip(maskrect))
t1.start()
arr = np.array([4, 4, 1, np.nan, np.nan, np.nan, -5, -4])
entry.set_text(new_text)
caketaste()
set(box(df.genres.tolist()).ravel().tolist())
self.result.SetLabel(self.editname.GetValue())
{{title}}
main()
get_type_hints(Starship)
record2.put()
PETSc.Mat().createAIJ(size=(nrows, ncols), csr=(ai, aj, aa))
l.append(float(t))
s.apply(enumerate)
print(coc.x)
print(json.dumps(test_json, cls=MyEncoder))
fcntl.fcntl(fd, fcntl.F_SETFL, fl | os.O_NONBLOCK)
main()
[0, 0, 0, 0],
np.dot(np.array(L1).sum(0), np.array(L2).sum(0))
t.join()
pickle.dumps(self._cookies)
form = MyModelForm(hide_condition=True)
opener = urllib.request.build_opener()
zf.close()
model.train(sentences)
columns = [column[0] for column in cursor.description]
G = bipartite.projected_graph(B, inmates)
[a[i + 1:j] for i, j in zip(zeros, zeros[1:]) if len(a[i + 1:j]) > 0]
timer_thread.start()
pool = multiprocessing.Pool()
ax.figure.show()
datetime.datetime(2012, 1, 1, 0, 0, 0),
ax1.set_xticks(numpy.arange(x1 - 1, x2 + 1, 0.5))
id = Column(Integer, primary_key=True)
l2 = list(zip(*l1))
WebDriverWait(self, timeout).until(staleness_of(old_page))
x.append([4, 5])
my_list[i] = item
time.sleep(refreshrate)
self.mthread.finished.connect(self.worker.deleteLater)
f.write(fileobj.read())
QtCore.QObject.__init__(self)
logging.set_up_done = False
[i for j in (list(range(10)), list(range(15, 20))) for i in j]
self.goButton.clicked.connect(self.simulThread.start)
s = s[:begin] + s[end + 1:]
app.MainLoop()
time.sleep(1)
out = np.zeros_like(array)
os.uname()
stdin.flush()
plt.xlim(-20, 60)
length = len(data)
traceback.print_stack()
new_rows.append(new_row)
plt.ion()
rows = input.filter(lambda line: line != header)
data = cursor.fetchall()
int(revbin, 2)
polA.set_transform(tA)
coo_matrix((vals, (i, j)), shape=(m, n)).asformat(format)
hi()
self.release()
f.close()
fcntl.ioctl(sock, SIOCSIFADDR, ifreq)
fig, ax = plt.subplots()
[seq[0]] + noVow(seq[1:])
print(tz_to_timedelta(tz))
clf2.fit(X, y)
ax.xaxis.tick_top()
print(list(product(list(range(2)), repeat=k)))
getattr(self.wrapee, attr)
dist = numpy.sqrt(numpy.dot(temp, temp))
np.linalg.inv(a)
print(testmodule.__doc__)
total = sum(int(i) for i in line)
f2(**d)
newstr = str[-4:]
plt.plot(t, s)
ax.xaxis_date()
set(a.items()) - set(b.items())
br.set_cookiejar(cj)
dep_list.append(opcodes[i])
layout = QtGui.QVBoxLayout(self)
print(map(str, EmployeeList))
lambda d=d: self.root.change_directory(d)
print(fn(10))
d = datetime.date(year=1940, month=1, day=1)
a[:2, :2]
print(i.text)
getattr(foo, string1 + string2)()
list(get_stuff(d))
not any(i in seen or seen.add(i) for i in x)
request = requests.get(image_url, stream=True)
print(solve(array1, 1, 5))
ax = plt.subplot(111)
p.search(s).group(1)
any(map(eval, my_list))
atexit.register(report)
ld.append({l[0]: int(l[col]) for l in ll})
x.wrong
request.user.pretty_username()
lists.append([])
childobject.parprint()
print(titlenode[0].firstChild.nodeValue)
[x for _, x in zip(list(range(n)), generator)]
print(line)
ax.set_aspect(1)
id = Column(Integer, primary_key=True)
fn(*args, **kwargs)
console_handler.setLevel(logging.DEBUG)
a, b = c.imag, c.real
startupinfo = subprocess.STARTUPINFO()
first_mask[first_mask] = second_mask
self.archive = py7zlib.Archive7z(fp)
xticks[0].label1.set_visible(False)
conn.close()
parser = argparse.ArgumentParser()
calendar.timegm(d.timetuple())
irn += repr(num)
client = paramiko.SSHClient()
fig.set_size_inches(10, 15)
plt.tight_layout()
[2, 4]
ax.xaxis_date()
screen.refresh()
c[5:6, (7)]
print(stdout.read())
ax.add_patch(polygon)
print(model.predict(np.array([[1, 0]])))
_quicksort(array, 0, len(array) - 1)
x = np.linspace(-1, 1, 201)
c = Counter([values[1] for values in d.values()])
a1.destroyCallback.add(b)
pygame.mixer.music.play()
tk.Frame.__init__(self, master)
X, Y = np.meshgrid(x, y)
print(ops[op](True, False))
time.sleep(timeout)
f.__code__.co_name
add(**arg)
print(traceback.format_exception_only(e.__class__, e))
G.add_edge(1, 2)
np.digitize(date_bins_i8, date_bins_i8)
print(tcpdump)
stateB()
stateC()
sum([x] * 10)
pl.plot(pl.randn(100))
Foo.bar.__func__ is foo
np.concatenate((x[:, (i), (i)], x[:, (i), (j)]), axis=1)
urllib.request.install_opener(opener)
self.extracting(random.uniform(0, self.weight))
self.sampling(random.uniform(0, self.weight))
matches.append(item)
X, Y = numpy.meshgrid(x, y)
df.groupby(group_hours).apply(insert_missing_hours).reset_index(drop=1)
A.shape
admin.site.register(Log, LogAdmin)
pdf = df.toPandas()
spinbox.grid(row=2, column=0)
[42, 1] in a.tolist()
df = df.dropna().reset_index(drop=True)
f.read()
ax.plot(plotlist[tracenum])
set(q).intersection(w)
os.makedirs(target_path)
sock.sendto(dns.pack(), (MCAST_GRP, UDP_PORT))
traceback.print_exc()
data = data.ix[data[cols] > 0]
my_dict = json.loads(input)
stats.norm.interval(0.68, loc=mu, scale=sigma)
self.browser.quit()
self.transport.loseConnection()
new_a = a.reshape(new_shape)
root = tk.Tk()
ax = plt.gca()
msg.attach(att)
diff = difflib.ndiff(file1.readlines(), file2.readlines())
compressed_table.append((istart, iend, table[i - 1]))
sample = lognorm.rvs(sigma, 0, scale, size=1000000)
l = np.asarray(l)
d = array([0, 1])
p()
__init__.py
random.shuffle(list_of_questions)
plt.imshow(image, extent=[x.min(), x.max(), y.min(), y.max()])
id = Column(Integer, primary_key=True)
self.window.setLayout(self.layout)
colorbar.set_ticks(np.linspace(0, ncolors, ncolors))
Process(target=worker, args=(task_queue, done_queue)).start()
[True, True, False, True, True, False, True],
cv2.waitKey(1)
m.save()
cythonize(*args, **kwargs)
response = urllib.request.urlopen(req)
value = myVariant.toString()
cmp(len(a), len(b))
prev.append(line)
subject = forms.CharField(max_length=100, required=True)
temp[mask2] = 2
l.sort(key=lambda t: t[1], reverse=True)
print(a[np.sort(idx)])
w.set_linewidth(2)
df2 = pd.DataFrame(df1)
main()
t.start()
data.plot()
logging.getLogger(__name__).setFormatter(log_format)
sess.run(embedding_init, feed_dict={embedding_placeholder: embedding})
layout = QVBoxLayout()
sum(conf_matrix[i][i] for i in range(len(conf_matrix))) / t
print(a[1, 5])
Data[..., (0)] + 1j * Data[..., (1)]
print(4 * math.atan(1))
index = [(i + 1) for i in range(10)]
array([1, 1, 1, 1])
self._stop = threading.Event()
pool = multiprocessing.Pool()
f = input()
sock.setsockopt(socket.IPPROTO_IP, socket.IP_ADD_MEMBERSHIP, mreq)
x = 0.1 * np.sin(2 * np.pi * 1.2 * np.sqrt(t))
ax = fig.add_subplot(111)
np.mean(arr, axis=1)
plt.xticks(new_xticks, new_xticks)
print(soup.title.string)
urllib.parse.urlencode(params)
s = pxssh.pxssh()
lis[0]()
set(item) - set(z)
p.join()
y.append(sublist[1])
input = sys.stdin.readline()
frame.grid(column=0, row=0, sticky=(N, S, E, W))
0, 42, -1, 0, 45, 1
fig = plt.figure()
app = QApplication(sys.argv)
do_something_6()
jmag = np.array(jmah)
np.interp(np.linspace(0, npt, nbin + 1), np.arange(npt), np.sort(x))
sys.stdout.write(term.BOL + term.CLEAR_EOL)
count += 1
os.utime(path_to_file, (access_time, modification_time))
np.vstack((a, b, c)).T
df
y = np.random.rand(n)
print(Counter(n1) - Counter(n2))
plt.legend()
print(response.headers)
ax0b.get_yaxis().get_offset_text().set_x(-0.075)
ax0c.get_yaxis().get_offset_text().set_x(-0.075)
a = np.arange(100)
ax = plt.gca()
self.__add__(other)
repr(s)
numpy.where(a > 2)
batch.add(service.farmers().list(), callback=list_farmers)
delta = timedelta(hours=t.hour, minutes=t.minute, seconds=t.second)
self.assertAlmostEqual(tr(2, 1), 0.0718, 4)
[x[x != 0] for x in np.split(a, np.where(a == 0)[0]) if len(x[x != 0])]
A = (C * mask).sum(axis=-1)
plt.ion()
reader = csv.reader(fin)
self.view.setColumnWidth(0, 800)
a[[[0], [1]], i]
x += (0, 0),
len(net.params)
ser.dropna().plot(ax=axes[1])
[0, 0, 0, 0]
plt.xlim(0, 10)
display.popen.terminate()
print(df.iloc[new_index])
print(sline)
n += 1
app.run(port=7080, **kwargs)
d2 = {k: f(v) for k, v in list(d.items())}
tuple(zip(MONTHS, MONTHS))
plt.show()
parity([perm0[i] for i in perm1])
sys.stdout = progA.stdin
df.loc[g.groups.get(2, [])]
time.sleep(5)
plt.tight_layout()
mylist.sort()
page = urllib.request.urlopen(req).read()
s.set_debuglevel(1)
urllib.request.Request(url, data, header)
console.setLevel(logging.INFO)
f.close()
new_list = [dd for dd in my_list if not dd is new_dict]
print(k, Dictionary[k])
ax.scatter(x, yflat, z)
img_temp.write(opener.open(url).read())
[i for i in l1 if not any(j in i for j in l2)]
ax = plt.axes()
line = f.readlines()[7]
self.result_queue.put(answer)
np.take(arr, inds)
t = np.arctan2(y, x)
current_line += 1
name, age
self.__dict__.update(locals())
ax.add_patch(patch)
soup = BeautifulSoup.BeautifulSoup(html)
res.get()
print(model.predict(np.array([[0, 0]])))
data = client.get_spot_price()
[(i + i * weight) for i in v] + [n]
im.wcs[::1 / 128, ::1 / 128]
hasattr(self, name)
self.listbox.select_set(0)
ax = fig.add_axes([0, 0, 1, 1], frameon=False)
ip.close()
d.setdefault(i, set()).add(j)
a.save()
response.close()
decorator2(f)
s = sys.stdin.read()
response = request.get_response(main.app)
plt.show()
[os.getpid(param) for param in params]
self.SetSizer(s)
self._window.destroy()
func(*args, **kwargs)
parser = argparse.ArgumentParser()
a == a
worksheet.set_column(i, i, width)
d = dict(d)
root = Tk()
L[i] = L[i][::-1]
time.gmtime(ts / 1000)
f = pd.DataFrame(dict(year=list(range(2000, 2011)), A=np.random.rand(11)))
print(not any(dict2.values()))
writer.writerows(grouped)
print(df[df.Name.isin(val)])
my_thread.start()
self.layout.addWidget(self.statusBar)
df1.update(df2)
thread.start()
proxy.ProxyClient.__init__(self, *args, **kwargs)
elem_list.append(i)
fig = plt.figure(figsize=(10, 5))
ast.literal_eval(raw)
print(a[-9:])
fig.subplots_adjust(left=0, right=1, top=1, bottom=0, hspace=0, wspace=0)
db.engine.execute(schema)
r.destroy()
CORBA.__file__
d.setdefault(j, []).append(i)
group(5, list(range(5)))
int(round(n[0]))
len(s)
plt.show()
M.diagonal()
root.quit()
a = np.arange(24).reshape((4, 6))
ax2 = ax1.twinx()
os.setpgrp()
start = time.time()
layout.addWidget(self.table)
wait = WebDriverWait(driver, 5)
pylab.figure()
response
X[np.ix_(a, b)]
tk.Frame.__init__(self, master)
print(avg)
tqdm_pandas(tqdm_notebook, *args, **kwargs)
b = dict(zip(i, i))
zip(s, s[1:])
self.pic = QtGui.QPixmap(imagePath)
data = output.getvalue()[14:]
changecolor(rect)
instance = ModelClass.objects.create(**validated_data)
matches.append(m.group(0))
a, b = select_choice()
a[::2]
reader = csv.reader(fin)
array = np.random.random(10)
dict.__setitem__(self, key, value)
self._result_handler.start()
count += 1
plt.ylim(0 - 0.5, data.shape[0] - 0.5)
lst.sort(key=lambda x: x[1])
int(base * round(float(x) / base))
ax1.yaxis.tick_left()
main()
A = numpy.concatenate((A, newrow))
g.user.is_authenticated()
app = wx.PySimpleApp()
plt.hold(True)
self.expunge(record)
print(df.sub(a, axis=0))
signal.signal(signal.SIGUSR1, signal_handler)
ax.set_ylim(0, 255)
br = mechanize.Browser()
np.putmask(a, a >= m, m - 1)
doc.appendChild(el)
time.sleep(5)
name = models.CharField(max_length=128)
client.close()
os.makedirs(os.path.dirname(dst))
window2.destroy()
timer2.stop()
serializer = VenueSerializer(venues, many=True)
gleason.setParseAction(diceGleasonParseAction)
numpy.dot(c, a)
end = string.index(end_marker, start + 1)
tex_data[tex_data == 0] = np.nan
hxs = HtmlXPathSelector(response)
os.write(fh, zf.read(name))
e = {v: k for k, v in a.items()}
reversed(it.islice(it.chain.from_iterable(reversed(a)), 5))
dict.update({item[0]: item[1]})
random.shuffle(l)
cv.Circle(color_image, center_point, 10, cv.CV_RGB(255, 100, 0), 1)
result = db.table.filter(db.table.column.ilike(looking_for))
e.extract()
dict(zip(l2, map(len, list(list(g[1]) for g in groups))))
current_date += datetime.timedelta(days=1)
classifier.fit(train_features, train_labels)
k.sort()
client.create_video(**kwargs)
[1, 1, 1, 2, 2, 2],
ax.set_yticks([])
Serial.println(number)
self.build_response_from_file(request)
bytes(key)
time.sleep(1)
do_stuff()
urlopen(req).read()
exit()
p.terminate()
hash(frozenset(self.__dict__.items()))
theother()
N += 1
writer.writerow(line)
driver.get(url)
logging.root.addHandler(file_handler)
excel.Application.Quit()
next(b)
app = Flask(__name__)
a.insert(0, x)
workbook.close()
matplotlib.pyplot.scatter(n.predict(nfeatures).tolist(), targets.tolist())
numpy.bincount(x, weights=w)
id = Column(Integer, primary_key=True)
sum(c.values())
b.comments[0].content
draw_networkx_edges(G, pos)
painter.setBrush(QBrush(Qt.white))
pdb.set_trace()
os.rename(infilename, newname)
[1, 1, 1, 1]
fig, ax1 = plt.subplots()
sys._getframe().f_back.f_code.co_name
text = msg.as_string()
df.iloc[pd.np.r_[10:12, 25:28]]
session.add(model)
ax4.set_ylim(0, 1.2)
self.clear_canvas()
new_dict[length] = {mykey: name_num[mykey]}
self.Show()
dir = os.path.join(root, i)
main()
lst.sort(key=lambda x: x[0])
merged[k].add(d2[k])
binary_search([1, 5, 8, 10], 15)
f = lambda r: r * (sp.j1(r) / r) ** 2
l = [(0, 1, 0), (1, 1, 0)]
reader = csv.reader(f)
self.add_node(origin)
pylab.show()
self.layout.addWidget(self.spinBox)
subset[subset.isin(myList)].stack().duplicated().unstack().any(1)
print(str(a[0]))
lbl.pack()
[m.start() for m in pattern.finditer(sentence)]
print(my_list)
ax = fig.add_subplot(111)
any(map(lambda c: c.isdigit(), value))
print(mylist)
traceback.print_exception(type_, value, tb)
df.applymap(onlynumbers)
app = flask.Flask(__name__)
print(CreateTable(Model.__table__))
parser = argparse.ArgumentParser()
pylab.plot(data[:, (0)], data[:, (1)], label=label)
minheap.add(maxheap.poll())
plt.autoscale()
list(itertools.chain(*list_))
painter.save()
plt.plot(x, y, fmt, label=label)
result.append([k, ms[k] + mb[k]])
ax.plot()
main()
plt.show()
plt.subplot(2, 2, n + 1)
row = {name_map[name]: val for name, val in list(row.items())}
yolk
xs, ys = [], []
[iterable[i:i + length] for i in range(len(iterable) - length + 1)]
sys.exit(1)
json.JSONEncoder.default(self, obj)
sorted(list1)[:2]
app = Flask(__name__)
[i for i in range(1, len(x)) if x[i] != x[i - 1]]
B = np.interp(xx, x, A)
s = df.ix[:, (0)]
b.a.filter(a=a1)
[0, 1, 0, 0, 1, 29]
frame.grid(column=1, row=1, sticky=Tkconstants.NSEW)
polycube = numpy.rot90(polycube)
time.sleep(0.5)
cursor = connection.cursor()
((0 < x) & (x < 1)).any()
mywidget.pack()
a = np.array(literal_eval(a))
sum(map(len, list(d.values())))
d[v].append(i)
image.save(b.image.path, quality=20, optimize=True)
stream_handler.setLevel(logging.INFO)
act.pyqtConfigure(triggered=self.on_triggered)
calendar.day_name[dayoftheweek]
MyUser.objects.filter(tags__in=id_list)
sys.exit(0)
browser = webdriver.Firefox()
df = DataFrame(data)
self.assertAlmostEqual(tr(2, 2), 0.865, 4)
print(info.group(1))
sys.exit(unittest.main())
is_separately_linear(eq1, [a, c])
new_df = old_df[list_of_columns_names].copy()
sc = ax.scatter(x, y, z)
self.fcall = fcall
w.writerow([row[0], colname, colval])
print(soup)
print([pos for pos, char in enumerate(s) if char == c])
np.random.uniform(0, 1, (500, 2000))
print(y.round(2))
self._compile_rules()
MySQLdb.escape_string(SQL)
self.result.append(word[:-1])
o.A(1)
plt.show()
idx = np.where(~mask, np.arange(mask.shape[1]), 0)
[x for b in a for x in b]
fig = plt.figure()
print(m.group(2))
f1.close()
time.sleep(1)
self.timer = Timer(self.timeout, self.handler)
copy_a -= copy_a[0].copy()
self.__dict__.update(**attrs)
file.close()
f.write(etree.tostring(root, pretty_print=True))
print(pd.concat([df.iloc[(0), :], df.iloc[(-1), :]], axis=1))
os.rename(outfilename, in_filename)
f.seek(0)
platform.system()
mail.ehlo()
urllib.request.install_opener(opener)
pickle.dumps(value)
data = sys.stdin.readline()
self.crawler.start()
result.insert(1, row_separator)
dt = datetime.datetime.now()
app.mainloop()
cj = cookielib.CookieJar()
pd.options.display.max_colwidth
somelist[:] = [tup for tup in somelist if determine(tup)]
time.sleep(0.5)
plt.plot([pc[i][0], pc[i + 1][0]], [pc[i][1], pc[i + 1][1]], color=c)
page = resp.read()
data = sin(2 * pi * 1000 * t)
app = Flask(__name__)
event.set()
plt.show()
circular.append(p)
p4.readarray(x)
self.lb2.yview(*args)
TrueXor(True, False, False)
solve(a * x ** 2 + b * x + c, x)
[max(s.index(max(s)) - s.index(min(s)), 0) for s in lst]
merged[k].append(d1[k])
out = sys.stdout.getvalue()
print(ET.tostring(root))
f = plt.figure(figsize=(10, 6))
getattr(self.myobj, attr)
np.vstack(l)
func.__code__.co_argcount
deletes[i]
urllib.request.HTTPSHandler.__init__(self)
plt.show()
self.entry.pack(pady=4)
print((a, b))
random.choice(my_list)()
p = np.array([(0, 0), (1, 0), (0, 1), (1, 1), (2, 2)], dtype=np.float)
fig = plt.figure()
main()
plt.ylim(-1.1, 1.1)
fh.close()
print(random.choice(value), key)
p2.start()
br.set_handle_robots(False)
print(data)
ch = logging.StreamHandler()
soup.prettify()
df2 = df2.reset_index()
labels = ax.get_xticklabels()
plt.setp(ax2.get_yticklabels(), visible=False)
cDC.DeleteDC()
cur.fetchone()
self.mainframe.columnconfigure(0, weight=1)
do_something_with(obj)
hist(date2num(list_of_dates), cumulative=True)
a * exp(-(x - x0) ** 2 / (2 * sigma ** 2))
reader = csv.DictReader(fp)
sys.exit(main())
sys.exit(application.exec_())
logging.basicConfig(level=logging.DEBUG)
df.set_index(date_col_name, drop=True, inplace=True)
pygame.init()
self.task.cancel()
main()
print(pd.merge(df_subset, df).equals(df_subset))
math.sqrt(-1) / 0
list(solve(5))
my_list.append(item)
json.dumps(obj, default=method_name)
s.getvalue()
self.data = np.zeros((100,))
ax = fig.gca()
app = QApplication(sys.argv)
sys.modules[name] = mod
win.set_size_request(100, 100)
ax.clear()
cv2.circle(img, corner, 7, (255, 255, 0), -1)
numpy.finfo(float).max
kurt
image = Image.open(image_string)
self.panel.SetSizer(sizer)
queryset = Workout.objects.none()
plt.figure(figsize=(10, 10))
raise StopIteration()
response = requests.get(url, stream=True)
do_something_in_mechanize()
my_logger.addHandler(handler)
pylab.plot(list(range(11)), list(range(11)))
reader = csv.reader(open(filename))
print(myhtml.text_content())
print(json.dumps(test_json, default=json_debug_handler))
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
sys.exit(1)
driver.close()
sieve.primerange(a, b)
axes.append(ax.twinx())
main()
df = pd.concat([df] * 1000).reset_index(drop=True)
len(line)
color = [(255, 0, 0), (0, 255, 0), (0, 0, 255)]
oFid.close()
sys.stdout = stdout
comp += numpy.min(first + second, axis=2)
print(i, j)
plt.plot(Time, signal)
mywidget.update_idletasks()
logger.setLevel(logging.DEBUG)
self.sizer.Add(self.list, proportion=1, flag=wx.EXPAND | wx.ALL, border=5)
QtGui.QWidget.__init__(self, *args, **kwargs)
s.close()
np.count_nonzero(a & r != b & r)
np.array([d[x] for x in u])[inv].reshape(a.shape)
result = [s for s in data if len(s) == maxlen]
process(line)
self._stream.flush()
r = requests.post(url, data=values)
result.append((int(k), c))
curses.noecho()
cols = df.columns.tolist()
ax4.plot(data, data, data, data ** 2 / 10, data, np.sin(data))
[A[b] for b in range(9, -1, -1)]
print(df)
[(B.pop(0) if x else A.pop(0)) for x in selector]
C = np.swapaxes(B, 1, 2)
all.append(row)
self.write(login_response)
r.reduceByKey(lambda x, y: x + y).collect()
x = list(sum(list(dict.items()), ()))
shutil.copy2(path, temp_path)
lst[i] = lst[i] * 2
add_patch(axes[1], alpha=0.2, rasterized=True)
axcltwo.set_ylim(binimg.shape[0], -1)
self.seek(0, 2)
f.seek(findex[n] + 1)
print(max(len(i[j]) for i in x))
fig = pyplot.figure()
func()
fp.close()
user.user_permissions.add(perm)
{NULL, NULL, 0, NULL}
sio.getvalue()
pipe_lrSVC.fit(X_train, y_train)
indices = sp_matrix.nonzero()
p = sns.regplot(x=dat.x, y=ydat, data=dat, ax=ax)
form = UserprofileForm(request.POST)
pygame.quit()
Child().on_start()
plt.show()
user = models.ForeignKey(User)
raise WindowsError()
self.Show(True)
plt.show()
ax.set_xticklabels(columns_my_order)
Fraction(0.185)
peaker(Y)
print(BASE_DIR)
X[:, (0)] - a
time.sleep(2)
df
ax.w_xaxis.set_pane_color((1.0, 1.0, 1.0, 1.0))
print(cur.fetchone())
l.append(v)
print(line)
fig, ax = plt.subplots()
re.compile(RE, re.UNICODE)
sum(1 for i in a.flat if i)
plt.plot(list(range(10)), [math.sin(x) for x in range(10)])
multiples.update(list(range(i * i, n + 1, i)))
date.replace(tzinfo=timezone.utc)
print(x)
fapp(request.environ, self.start_response)
list(islice(gen(), n))
ax.patch.set_visible(False)
mean = all.mean(axis=-1)
print(df.TIMESTAMP.dt.hour)
button.pack()
plt.plot(x, y)
print(np.unravel_index(np.argmax(x), x.shape))
array([[NaN, NaN, NaN, NaN], [NaN, NaN, NaN, NaN], [NaN, NaN, NaN, NaN]])
ax = fig.add_subplot(111)
newdate = datetime.datetime(*map(int, values))
index, value = max(data, key=lambda item: item[1])
df2 = pd.DataFrame(columns=cols, index=list(range(2)))
map.drawcoastlines()
f.readline()
ast = compiler.parse(eq)
outfile.close()
annotation(name, value)
deletesublist[index]
System.out.println(answer.toString())
numpy.dstack((x, y))
mydict = {key: value for key, value in zip(x, y)}
width, height = win.get_size()
pd.concat([df.iloc[-shift:], df.iloc[:-shift]])
models.Model.save(self, force_insert, force_update)
print((a, b, c))
app.mainloop()
map(np.random.shuffle, arr2d)
df.pivot(index=0, columns=1, values=2)
print(float(line))
d = dict(zip(list(range(1, 10)), list(range(50, 61))))
print([(x if x else y) for x, y in p.findall(s)])
[0.001, 0.25, 0.5, 0.75, 0.99, 0.999]
f = foo()
app = Flask(__name__)
canvas.Canvas.__init__(self, *args, **kwargs)
conn = urllib.request.urlopen(url)
json.dumps(recursive_asdict(data))
os.path.join(os.path.normpath(directory), filename)
f.__closure__[0].cell_contents
file_list.sort(key=lambda a: a[0])
s = pd.Series(l)
print((x, next(it)))
x[1, 2]
np.random.shuffle(arr)
sys.path.append(vendor_dir)
df.col = df.col.dropna().apply(lambda x: str(int(x)))
os.chmod(path, current_permissions & NO_WRITING)
score = sum(i * w(i) for i in x if i in y) / sum(i * w(i) for i in x)
answer1[i] += 1
self.meth()
print(matches[1])
dict.__init__(self, *args, **kwargs)
key = parts[-1]
self.obtainingparams(df, tau_1, tau_2, residuals).called
categories.setdefault(i[1], []).append(i[0])
L = [OrderedDict((k, d[k](v)) for k, v in l.items()) for l in L]
column_header.set_focus_on_click(False)
[([x] + p) for x in seqs[0] for p in product(*seqs[1:])]
min(x)
megawarc.main()
Grandparent.my_method(self)
zip(*ntup)
soup = BeautifulSoup(html)
print(a, b)
a.show()
server_socket.listen(10)
self.frame.Show(True)
ax = fig.add_subplot(gs[n])
print(r.url)
im.seek(i)
thread.start()
key, value = min(list(dict.items()), key=lambda __v: abs(__v[1] - target))
f.save()
NP.insert(T, 2, r, axis=0)
i += 1
b.sort(reverse=True)
dir = os.path.dirname(__file__)
main()
r, g, b = im.getpixel((0, 0))
s.close()
{k: [v for _, v in g] for k, g in groupby(arr, lambda x: x[0])}
make_unicorns_from(f)
a_pet.say()
d1 = datetime.datetime.now()
zip_longest(fillvalue=fillvalue, *args)
form.fieldname.choices = choice_list
p2 = subprocess.Popen(args, stdout=subprocess.PIPE)
server = Process(target=app.run)
c = sys.stdin.read(1)
itertools.product(*([list(C.items())] * 2))
logging.exception(e)
print(x)
main()
ax = fig.add_subplot(111)
sys.exit()
sys.exit(0)
np.random.shuffle(arr)
print(prettyformat(obj))
frw.seek(seekpoint, 0)
df.columns = [col_dict.get(x, x) for x in df.columns]
q = Queue.Queue(maxsize=0)
list.remove(s)
self.text.config(yscrollcommand=self.scroller.set)
df.append(df2)
definitions.py
main()
print(ElementTree.tostring(tree))
l.set_option(ldap.OPT_REFERRALS, 0)
is_palindrome(letters)
df.stack().values
new_contact.save()
ax1.yaxis.label.set_color(plot_ax1.get_color())
a = A()
logging.Formatter.format(self, record)
br.set_handle_redirect(True)
soup = BeautifulSoup(xml_string)
B = A
fig, ax = plt.subplots(1, 1)
np.dot(rot_matrices, p)
pycharm[path_to_your_file]
f2.write(data)
logging.root.addHandler(console_handler)
print(sys.version)
orig(repo, remote, *args, **kwargs)
names = list(a.dtype.names)
ind.append(arr.index(list(df.iloc[i])))
totuple(array)
app = Flask(__name__)
print(format(tree))
logging.error(e, exc_info=True)
a[0](1)
main()
list()
p.join()
msg.attach(MIMEText(text))
lst.sort()
form = EditEventForm(instance=event)
min((angular_distance(theta, L[i], mod), i, L[i]) for i in [i1, i2])
results.sort(key=lambda x: (int(x[0]), x[1]), reverse=True)
data = urllib.request.urlopen(url).read()
pickle.dump(data1, output)
l.set_option(ldap.OPT_X_TLS_DEMAND, True)
setup()
f(*args)
Guild.query().filter(Guild.members == self.key)
ax.set_xlim(-51, 51)
sorted(sentence)[-1]
print(np.allclose(dets(M), dets_fast(M.copy())))
data += np.random.normal(size=data.shape) * 0.4
sys.exit(app.exec_())
MyClass(arg1, arg2)
bitmap = wx.Bitmap(path)
setattr(self, attr, value)
item = row[1:]
plt.axvline(x=0.2)
obj = memcache_client.gets(key)
d[l[0]] = l[1]
do_another_thing(object_list[-1])
l.extend(v)
opt.add_argument(*args, **kwargs)
groups.setdefault(y, []).append(x)
temp = pd.concat([temp, temp2], axis=1)
d[key] = value
df.apply(LabelEncoder().fit_transform)
print(l2set)
fig = plt.figure()
print(i, is_square(i))
admin.site.register(Class, ClassAdmin)
browser.add_cookie(cookie)
print(x.date())
l.append(elt)
f.read()
time.sleep(0.0)
X = sc.transform(X)
[c, d, e, f]
ax2 = plt.subplot(212)
comments = soup.find_all(string=lambda text: isinstance(text, Comment))
parser = argparse.ArgumentParser()
line = line.rstrip()
ax.add_patch(circ)
print(int(math.sqrt(5)))
im.getbbox()
fig.tight_layout()
p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
sleep(snooziness)
parser.parse_args()
print(foo.bar._decorators)
os._exit(1)
[string[i:i + k] for i in range(length - k + 1)]
a[ind]
process.wait()
list(range(0, len(given) - len(sublist) + 1))
window.add(widget)
l[i + 1], l[i] = l[i], l[i + 1]
print(np.split(x, np.where(np.diff(x) > 0.5)[0] + 1))
timestamp = (utc_dt - datetime(1970, 1, 1)).total_seconds()
SomeClass.some_static_method()
print(foo)
B = numpy.split(A, split_at)
f()
app = Flask(__name__)
not any(i in seen or seen.append(i) for i in x)
(np.corrcoef(M) == 1).sum() == M.shape[0]
num_words = sum(len(sentence.split()) for sentence in text)
ipshell()
ax = fig.add_subplot(111)
earth += 100000.0
time.sleep(1)
response
s += A[k] * B[k]
time.sleep(0.2)
sys.path.append(str(top))
lst = [1, 2]
make_square(2)
local.py
ax.plot_surface(X, Y, Z)
split_list = lambda lst: (lst[0], lst[1:])
root = tk.Tk()
print(mimetypes.guess_type(url))
self.loop.run_forever()
setattr(model, name, request.get(name))
time.sleep(0)
fig.canvas.draw()
a = [1, 2]
links[1].click()
p = multiprocessing.Pool(processes=1)
a = list(range(10))
[1, 2]
response.write(p.body)
foo_list.append(lambda : bar.func2([7, 7, 7, 9]))
p = Pool(processes=10)
sum(x ** 2)
patcher.start()
ax.xaxis.set_visible(False)
print(len(itemlist))
root.after(500, add_letter)
foo()
self.deauthorize()
Story.append(table)
session1.commit()
datetime.datetime.now()
dir(f)
print(image.shape)
server2.handle_request()
self.pubsub = self.client.pubsub()
getattr(object, attrname)
str([])
self.my_text.splitlines()
self.comboBox_2.clear()
pysvn.__file__
ax1.legend(loc=2)
shuffle(word)
self.name = name
pool.map(processMdb, mdblist)
print(formatdate(timestamp, True))
self.client.connect()
pylab.figure()
ax.xaxis.set_minor_formatter(FixedFormatter(bin_labels))
time.tzset()
seen.add(line)
print(difft2(time(20, 40, 0), time(18, 41, 0)))
wb.close()
extend_array(data, 10)
root = Tk()
df[~bad_df]
print(k, v)
np.array(rdd.collect()).nbytes
start += 1
id = Column(Integer, primary_key=True)
list(chain.from_iterable(islice(theList, *t) for t in [(4, 7), (12, 18)]))
parser = argparse.ArgumentParser()
__init__.py
os.fdopen(fd, access)
ax1.set_xlim(*np.log10(olim))
G.edges(data=True)
ipdb.runcall(foo, 1, 2)
print(num.contents[0])
print(np.all(B[b_to_a] == A))
p.map(Copier(target_dir), file_list)
file = forms.FileField()
map(lambda x_y: x_y[0] + x_y[1], zip(repeat(x), y))
a[:] = [((x,) + mapping[x]) for x in b]
ab = np.hstack((a, b))
nums = [int(n) for n in x.split()]
c.__bases__
(options + [False])[current_option == options[0]]
window.set_border_width(10)
ax.set_yticks(z)
self.y2 += self.speed * math.sin(self.bearing)
list.append(i)
out = np.where(~a_extm[1:-1] & mask[1:-1], np.nan, a)
df.iloc[approach1(df.A.values, df.B.values)]
count += 1
self.bar()
print(set(regx.split(string)) & set(search))
scons
stdscr.refresh()
b.load()
ax.set_xticks([])
sb.plt.show()
p.map(mp_worker, (task1, task2))
print(repr(str(row[0])))
X = vectorizer.fit_transform(documents)
deletel[n:]
f.write(buffer(array))
[convert(element) for element in input]
func(*args, **kwargs)
self.webview.pauseTimers()
print(np.where(df.index == 5)[0])
5 * f(f, 4)
[((x >> shifter) % 2) for x in range(2 ** (K * N))]
zip(fields, row)
ax1 = fig.add_subplot(111)
say_boo_twice()
rows.append(row)
unittest.main(failfast=True, testRunner=unittest.TextTestRunner)
ax1 = fig.add_subplot(1, 1, 1)
print(sys.getsizeof(myint))
num = int(s)
df.groupby(df.date.dt.month).apply(f)
dsp.write(data)
myTurtle.left(90)
base = datetime.datetime.today()
data_tuple = Item(*raw_data)
ax1.bar(x, y, 0.2)
os.mkdir(self.cache_location)
f = etree.fromstring(data)
86400.0 * self.days + self.seconds + 1e-06 * self.microseconds
blog.save()
data.shape
print(soup.prettify())
paw_number[1:] += 1
main()
print(a, b)
list(self.items())[-1]
print(func())
sinks.append(sys.stderr)
main()
window.wm_withdraw()
fig, ax = plt.subplots()
sys.stdout.write(line)
console.interact()
Base.metadata.create_all(engine)
[(p[:i] + [l[0]] + p[i:]) for p in perm(l[1:]) for i in range(sz)]
raise web.notfound()
f.seek(0)
venus.speed(0)
numpy.array(list(range(25))).reshape((5, 5))
self.button.pack(side=TOP)
q = Question.objects.filter(criterion1 & criterion2)
main()
os.kill(p.pid, signal.SIGKILL)
self.y = []
grouped.cumcount()
plt.show()
[a[S] for S in s if a[S] > 0]
[t.get() for t in tasks]
list(range(100))[:10]
show()
print(value_set[1:-1])
print((x, y))
adic[i] += 1
br.submit()
fsum([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])
print((x[idx], y[idx]))
q = q.with_entities(User.id)
b.grid()
target.close()
logger = logging.getLogger(__name__)
setup_mock()
int(math.pow(10, int(math.log(b, 10)) + 1) * a + b)
result = Model.objects.filter(id__in=object_ids)
end_date = datetime.datetime(pub.year, pub.month, pub.day)
main()
collections.Counter(window(x))
ui.syn()
print(soup.prettify())
co.co_nlocals, co.co_stacksize, co.co_flags
axes[1].legend().set_visible(False)
to_delete.append((corpus.index(match), len(match)))
[(lambda splt: (splt[0], splt[1]))(s.split()) for s in input]
ax.w_zaxis.set_major_formatter(niceMathTextForm)
df = pd.DataFrame()
d1 = {(1): 1, (2): 2}
g.add_edge(1, 7)
x = Decimal(2606.895)
id = Column(Integer, primary_key=True)
a = 1
obj.save()
self.ax.imshow(im)
l.sort(key=lambda t: (t[0], -ord(t[1])))
results = Orchard.objects.filter(**options)
d[x][y] = z
time.sleep(0.25)
self.listofrecords[listnum][record]
nil
do_something_with_results(resuls)
soup = BeautifulSoup.BeautifulSoup(txt)
sys.stdout.flush()
gtk.main_quit()
db.init_app(app)
random.shuffle(lst)
fh.seek(0)
[[d.get(str(y)) for y in x] for x in A]
newmethod(obj, node, **kwargs)
current_date += datetime.timedelta(days=1)
set(b.items()) - set(a.items())
a = [(item + 1) for item in a]
set(word_list).intersection(a_string.split())
time_list[np.arange(5, 6)]
table = Orange.data.Table(df.as_matrix())
form = StopAdminForm
paralell_notifications(new_rss)
[0, 0, 1, 1, 0, 0, 0]
np.percentile(S, np.array([0, 100]))
followers_df.index = list(range(len(followers_df)))
items[pos], items[index] = items[index], items[pos]
print(g(1))
print(now.year)
ax = fig.add_subplot(111)
print(list(seach_replace(message, codes)))
a, b = b, a + b
plt.show(block=False)
sftp.get(log_file, local_name)
fig.canvas.draw()
np.zeros_like(x, dtype=bool) | initial
request.json
e = Example(10)
out_file.close()
print(set(better_d))
shutil.copy2(pathname, dstdir)
ln.set_ydata(data)
a, b, c, d, e = a
next.click()
driver = webdriver.Firefox()
grayimg = cv2.equalizeHist(grayimg)
sqrt(res)
f()
sum(count[letter] for letter in valid_letters)
a = np.array([[0, 1, 1, 0], [1, 1, 1, 1], [1, 1, 1, 1], [0, 1, 1, 0]])
fib(n - 1) + fib(n - 2)
self.file.write(data)
sys.exit(a.exec_())
v[0] += 1
plt.show()
set([1, 2]) in a
plt.figure(1)
plt.show()
sess = tf.Session()
burroughs_wheeler.test(10000)
pickle.dump({(1): 2}, f)
print(cls.foo_string)
gc.get_referrers(obj)
print(yaml.dump(doc, indent=4))
self.__getitem__(key)
print(line)
app.exec_()
time.sleep(1.0)
plt.xticks(list(range(len(D))), list(D.keys()))
s.close()
pickle.dump(foo, f)
yourmodel.objects.filter(location__dwithin=(geom, 0.02))
all(c == s0 for c in s[1:])
hov.perform()
open(fname.lower())
next(alternator)
scipy.misc.imshow(img)
(x + y) * z
print(map(sum, zip(flattend1, flattend2)))
d.stack().groupby(arange(4))
np.may_share_memory(get_sliding_window(df, 2), df.values)
a = b
thread.start()
ax1.plot(list(range(10)))
self.city_set.filter(is_capital=True)
datetime.datetime.combine(dt.date(), midnight)
x = mungesomedict(dict(adict, **anotherdict))
a.name
counter_list[:] = (c for c in counter_list if c)
print(query.explain())
df.index = df.index.map(str)
items.append(values)
ax = plt.subplot(111)
plt.plot(x, x)
print(Duck().speak())
replacer_regex.sub(lambda m: dict[m.group(1)], regex)
self._data_unoccupied.wait(5)
datetime.date(2016, 8, 26),
max(frequencies, key=counts.get())
reader = csv.reader(f, skipinitialspace=True)
parser.feed(data)
f.write(c)
pool = mp.Pool(8)
r.content
a, b, c = [int(i) for i in line.split()]
next(d for i, d in enumerate(lod) if 1 in d)
log.append((name, attr))
fig, ax = plt.subplots()
dt = datetime.now()
model.docvecs[1]
p = multiprocessing.Process(target=worker, args=(q, nameStr))
run - the - app
ax = fig.add_subplot(111)
print(args)
info[2][0] == 5
[li[i:j] for i, j in zip(inds, inds[1:])]
self.stdout_sock.close()
data[int(i), int(j)] += 1
print(tree.text_content().strip())
temp.iloc[[0, 1, 4]].index
self.window.add(self.box)
A = [6, 7, 8, 9, 10, 11, 12]
gx = np.zeros_like(f)
linearmodel(X, Y, Z)
True
app
test()
w = QtGui.QMainWindow()
_quicksort(array, begin, end)
np.random.seed(seed)
requests_log.setLevel(logging.DEBUG)
d2 = datetime.datetime.now()
Gallery.objects.filter(pk__in=valid_ids)
label.master.overrideredirect(True)
foo.__name__
set(A) - set(B)
result = collections.defaultdict(list)
zip(*([iter(iterable)] * n))
my_array[pos]
id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
array([[1.0, 1.0], [1.0, 1.0], [1.0, 1.0]])
print(Foo().bar.arity())
actor.save()
df = pd.DataFrame(data=np.random.randn(1, 8))
sys.exit(app.exec_())
dir = os.path.dirname(module.__file__)
profile.save()
fig = plt.figure()
a = numpy.array([10, 7, 2, 0])
mylist.append(x)
C()
list(unique)
tk.Frame.__init__(self, parent, *args, **kwargs)
len(df)
users = [userA, userB, userC]
m = a.shape[0]
plot.plot(x, y)
self.canvas.draw()
setattr(self, name, value)
np.dot(ZCAMatrix, inputs)
self.Bind(wx.EVT_BUTTON, self.OnOkayCanButton, okayButton)
content_type = models.ForeignKey(ContentType)
app = Flask(__name__)
l[get_index(l, find_min(l))]
print(x)
ax.set_yticks(list(range(nb_names)))
sys.stdout.write(data)
file.readline()
open_file.write(upload.file.read())
[intify(i) for i in maybeLst]
NULL
[gb.get_group(x) for x in gb.groups]
zip(l, l[1:])
r.json()
list(chain(repeat(0, len(a) - len(c)), c))
lst[0].pop(0)
irenR.Start()
loop.close()
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
string.ascii_uppercase[5]
tempDF[mask]
func.restype = ctypes.c_void_p
[f for f in User._meta.get_fields() if f.auto_created and not f.concrete]
find_lyrics()
searchB.pack()
x.sort()
smtpserver.quit()
p.start()
apsched.add_interval_job(checkThirdAPI, seconds=5)
start = cols[1].get_text()
conn.commit()
process.stdout.readline()
draw.rectangle((rect_start, rect_end), outline=color)
print((np.average(b), np.mean(b), np.ma.average(b), np.ma.mean(b)))
f.tell()
plt.show()
c.decompose()
xlApp.Workbooks.Add()
print(parmap(lambda x: x ** x, list(range(1, 5))))
br.set_cookiejar(cj)
locations = Locations.objects.filter(**params)
random.seed(4555)
arr = np.arange(10).reshape(5, 2)
win.run()
print(Base.getSubclasses())
True
globals()[name] = val
B.__init__(self, 4)
self.hack_mro()
np.where(k, 2, 5)
np.random.seed(0)
plt.contourf(np.random.randn(10, 10))
elevate()
setattr(obj, self.func.__name__, value)
print(a)
matplotlib.pyplot.close()
conn.endheaders()
wordlist = [ch for ch in s]
select.select([process.stdout, process.stderr], [], [])
count = sum(1 for i in l if my_condition(i))
x += 1
zip(*df.values)
self.currentStack.pop()
zip(*lis)
print(postcodes)
self.datadex[x] + 1
self.stream.write(data)
t.start()
f = plt.figure(figsize=(size, size))
random.shuffle(x)
dlg.exec_()
plot(x, y)
d[j].append(i)
[x for i, x in enumerate(y) if i != 0 and i != 1]
(-17.5).hex()
print(sorted(list(globalHotItems.items()), key=lambda x: x[1])[-1])
shutil.rmtree(tdir)
df
output = [(x, y) for x, y, label in L if x > 10]
ax.set_yticks(y_pos)
print(scipy.ndimage.zoom(x, 2, order=0))
tree = ET.parse(filename)
time.sleep(0.1)
sys.stderr.write(line)
ax1.set_color_cycle([cm(1.0 * i / (NPOINTS - 1)) for i in range(NPOINTS - 1)])
fig, ax = plt.subplots()
dict1 = dict2[key]
grouped.loc[1, 2]
plt.bar(bins[:-1][i], n_x[i], width=10)
self.levelno = levelno
time.sleep(1.1)
app.run()
defaultdict(lambda : nested_dict(n - 1, type))
tuple(sorted(x))
hash1.update(text1)
plt.hexbin(x, y, gridsize=20, cmap=cmaps.pop(), mincnt=1)
main.mainloop()
self.__init__()
pd.DatetimeIndex(df.date) + pd.offsets.Hour(1)
b = a
print(GetWindowText(GetForegroundWindow()))
newk.append(i)
p.x, p.y
json.loads(s)
cmp(len(A), len(B))
models.DateTimeField(null=True)
copy.deepcopy(d)
name = models.CharField(max_length=255)
b = numpy.vstack((a, a))
pool = Pool()
client = s.getsockname()[0]
stream.write(chunkout)
np.random.seed(1010)
f.write(doc.toxml())
time.sleep(0.1)
df.head()
self.close()
parser = argparse.ArgumentParser()
new = a + (b,)
time.sleep(delay)
ax = pl.subplot(111, polar=True)
plt.colorbar()
stringbuilder.py
process = subprocess.Popen(your_command, stdout=subprocess.PIPE)
setattr(self, d[name], value)
itemgetter(2, 5)(L)
print(floor(log(1000, 10)))
sort_indices = np.argsort(brr)[::-1]
m[:, (0)].shape
ax.set_xticklabels(a)
self.set_val(self.valinit)
[x for x in lst if x % 2 == 0][:1]
np.array(xlist, dtype=dt)
self.insert(len(self._list), val)
app = wx.PySimpleApp()
instance = SomeModel.objects.get(id=id)
text.strip()
client.close()
fig = plt.figure()
a[:] = b
float(value)
pickle.dump(clf, f)
b = 1
destination.close()
d[k]
time.sleep(10)
self.button.clicked.connect(self.start_download)
functools.partial(func, p)
a.remove(10)
NULL, NULL
df
stdout.close()
pi = square(a + b) / 4 * t
bitarray.bitarray(l).tostring()
writer.save()
b[:, ([1, 2, 0])] * c[:, ([2, 0, 1])] - b[:, ([2, 0, 1])] * c[:, ([1, 2, 0])]
chain.from_iterable(permutations(xs, n) for n in range(len(xs) + 1))
self.altitude *= -1
len(s)
coc.x.append(2)
sys.exit()
deleteself.__dict__[field.get_cache_name()]
draw.ellipse(bbox, fill=128)
print((self.x, self.y, self.z))
A.__init__(self)
print(convert(1692))
plt.ion()
print(bisect.bisect_left(L, (2,)))
map(sum, zip(a, b, c))
new_im.paste(im)
models.signals.post_save.connect(create_api_key, sender=User)
[sum(starmap(mul, zip(first, col))) for col in zip(*second)]
X.copy()
print(scipy.ndimage.zoom(x, 2, order=1))
result[-1].append(temp)
self.socket = socket(AF_INET, SOCK_STREAM)
r = s.post(url, data)
mydog.findall(s)
mngr.window.setGeometry(50, 100, 640, 545)
obj.isoformat()
tmp.append(map(int, line.split()[:w]))
self.stop()
a = list(a)
module2.py
call_fn(*args, **kwargs)
node_schema.load(json_data, instance=Node().quey.get(node_id))
x, y, z, w = map(int, input().split())
tup[0] += 4, 5, 6
kernel = np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]])
np.linalg.norm(xs)
form = MyForm(request.POST)
print(urllib.request.urlopen(request).read())
par2.set_ylim(1, 65)
dt = datetime.datetime.now()
self.write_cell(sheet_name, cell, existing_value, updated_format)
subprocess.call(cmd, shell=False)
G.add_edges_from(tuples)
deleteyour_dict[unwanted_key]
get_supported_types()
print(local_tz.localize(datetime(2000, 6, 15)))
list(chain(a))
mem.Blit(0, 0, size[0], size[1], screen, 0, 0)
app.listen(8888)
temp_file.write(bytes)
do_something()
tree = et.fromstring(data)
self.edit2 = QLineEdit()
app = create_app()
widget.Bind(wx.EVT_COMBOBOX, self.onSelect)
pprint(table)
end += datetime.timedelta(1)
w = np.fft.fft(x)
fo.write(content)
setattr(obj.a, p, value)
print(etree.tostring(element))
markov(arr)
Base.metadata.create_all()
[l for l in list_dirs if os.path.basename(l) not in unwanted_files]
df.mul(vector, axis=0)
wx.Frame.__init__(self, *args, **kwargs)
ith_diag.eliminate_zeros()
test[:, ([0, 2])]
gui.root.mainloop()
ax.quiver(x, y, u, v)
audio.add_tags()
self._treeView.get_cursor()[0][0]
db = SQLAlchemy(app)
writer.writerows([object2list(obj, attr_list) for obj in list_of_objects])
a[0], a[2] = a[2], a[0]
lambda seq: [(lambda : el) for el in seq]
-r72
df.dtypes
loop.run_forever()
strcpy(buffer, path)
text = [x for x in text.lower() if x in string.letters]
plt.show()
csX.n = X.shape[1]
pool.join()
outf.write(ser.read())
list(d.items())
versioned_session(session)
w = distanceM()
print_hello_world()
cv2.namedWindow(winName, cv2.CV_WINDOW_AUTOSIZE)
NULL
sorted(set(li), reverse=True)[n]
app.mainloop()
GPIO.setmode(GPIO.BOARD)
ax2.plot([x1, x2], [y1, y2])
f.close()
app = Flask(__name__)
print(combs(sampleip2))
res[k].append(v)
df_r.show()
data.insert(bslindex, newcol)
tk.Frame.__init__(self, master, height=42, width=42)
a.sort(axis=1)
print(tuple(list(a)))
[i for i in range(1, n) if n % i == 0]
os.uname()
list(tokenize(stream))
s.sendmail(me, you, msg.as_string())
X -= X.mean()
json.dump(json.load(ifile), ofile, indent=4, ensure_ascii=False)
cursor.execute(*sql_and_params)
form = ContactForm(request.POST)
json_obj = json.load(metros_file)
plt.cm.coolwarm(t)
plt.show()
print(repr(Fraction(f)), Fraction(f))
print(m.shape)
foo = np.array([1, 2])
Base.objects.instance_of(ModelX) | Base.objects.instance_of(ModelY)
raise AssertionError
self._logger.setLevel(logging.INFO)
p.relative_to(*p.parts[:2])
indices.sort(key=lol[1].__getitem__)
draw()
user.save()
print(match.group(2))
o.x += 5
print(line)
time.mktime(datetime.date(year, 1, 1).timetuple())
a = list(range(1, size + 1))
eval(strs)
embed()
result.sort(key=lambda x: -x[1])
f(*args, **kargs)
print(my_new_list)
gs.fit(X, y)
pool = mp.Pool()
result = v.cumsum()
any(some_func(x) and False for x in some_list if x > 5)
cb = plt.colorbar()
br = mechanize.Browser()
User.query.all()
file.write(old_lines)
print(list(myDict.values())[i][j])
logging.basicConfig(format=format, level=logging.INFO)
tuple(map(operator.add, a, b))
print(line)
collections.Counter(lst)
Session.query(FooClass).filter(FooClass.somevalue == 8).all()
x.transpose(1, 2, 0).reshape(2, 4)
plt.figure()
axis.plot(x_data, y_data)
fig.subplots_adjust(hspace=0.5, wspace=0.001)
[fact(a) for a in args]
list(gb.keys())
sys.path.append(PATH)
transaction.rollback()
views.py
list(B.intersection(A)) + list(set(A) - B)
all(isinstance(s, str) for s in obj)
print(dir(foo))
out = np.zeros([n, len(arrays)], dtype=dtype)
x = x[(0), :, :]
c = list(itertools.product(a, b))
parser = argparse.ArgumentParser()
a.insert(randint(0, len(a)), x)
c = [i for i in a if i in b]
my_string.split()[:4]
d = dict(input().split() for _ in range(n))
ax = fig.add_subplot(111)
df
_stack.pop()
sys.path.append(here)
fig = plt.figure()
doctest.testmod()
print(np.array(result))
opener.open(req)
b, a = sorted((a, b), key=len)
Response(status=200, data=data)
self.__dict__.update(kwargs)
data = json.load(data_file)
len(list(filter(str.islower, string)))
dayDict = dict.fromkeys(weekList, 0)
output += np.sum(integrand(a), axis=1)
login(request, user)
(1 - 1 / Decimal(7000000)).ln()
win.update_idletasks()
obj.__class__.__dict__[1]
session1.commit()
all(y - x >= 2 for x, y in zip(locs, locs[1:]))
b = db.ReferenceProperty()
{{name}}
saved.append(element)
args = parser.parse_args()
data = data[keep_mask]
Base.metadata.create_all(engine)
[list(g) for k, g in groupby(nums, key=lambda n, c=count(): n - next(c))]
post2.delete()
request.session = {}
p.stdin.close()
x = np.arange(-10.0, 10.0, 0.1)
type(s)
self.assertEqual(reference, test)
main()
os.setsid()
x[1]
nx.draw_networkx(G, pos=pos)
np.dot(arr_pairs, xy)
list(range(x, x + 10 * y, y))
ax = fig.add_subplot(111)
DF.dtypes
plt.xticks(xx, ll)
count += 1
fig.show()
dt = tz.localize(dt)
book.save(filename)
date = models.DateField()
temp.flush()
sum(p * q for p, q in zip(vector1, vector2))
d = defaultdict(int)
p.wait()
zipstream.seek(0)
df
do_something()
sys.path.insert(0, PROJECT_ROOT)
models.CharField(null=True)
writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
self.fig, self.ax = plt.subplots()
json.dump(jsonDict, f, indent=4)
a.writerows(data)
jez(df1)
ret = func(*args, **kwargs)
print(list(result))
k = k[..., (np.newaxis)]
user = models.ForeignKey(User)
ax = plt.subplot(111)
seq.append(line)
add_chain.apply_async()
b = sum(a)
np.hsplit(a, 2)
img = Image.open(image_path)
render(request, template, context)
cur = conn.cursor()
dbapi_conn.commit()
print(etree.tostring(cityModel, pretty_print=True))
fig, ax = plt.subplots()
df.apply(zscore)
first_name = forms.CharField(max_length=256)
pickle.dump(data, output)
plt.subplot(211)
self.handler.close()
z.append(y)
math.factorial(10)
os.path.exists(destination)
self.master.columnconfigure(5, weight=1)
self.buffer.seek(0)
print(a_list)
a2.set_xticks([])
print(df)
MyMacro(indirect)
print(str(delta))
sum(map(lambda i: bool(i and i.pop(0) and i) + len(i), x))
MyButton2.grid(row=1, column=0)
list_of_dict.append(mydict)
s = np.sum(a)
output.close()
test = df.head(1)
inst1.i = 4
float_to_str(5e-08)
Py_Finalize()
f(*a)
f2.write(Lines[i + 1])
cursor = cnx.cursor()
plt.figure(figsize=(12, 6))
x += 1
time.sleep(1)
a = 1 if b else 0
randprime(a, b)
wsgi_handler.run(wsgi_app)
print(a[i] - a[i - 1])
dict((x, x * x) for x in range(10))
rule_list.append(value())
__authentication_required
plt.show()
list(set().union(*x))
print(is_arr_in_list(mylistarr[2], mylistarr))
S = [fnx() for c in range(5)]
self.Show(True)
ax.set_xlim([0, x.max() + 1])
ob.stackoverflow()
plt.plot([1, 2, 6, 4])
a180[0, 0, 0]
[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]
y = np.array([2, 1, 5, 2])
urllib.parse.urlencode(query_pairs)
out.write(f.read())
t = list(set(q) & set(w))
print(exit)
self._socket.close()
s = pygame.Surface((16, 16), flags=pygame.SRCALPHA)
G.remove_edges_from(G.selfloop_edges())
gray = cv2.imread(image_path, cv2.CV_LOAD_IMAGE_GRAYSCALE)
print(interleave(a, b))
stdin.flush()
pyplot.locator_params(nticks=4)
L = [1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, -1, 1, -1]
date.replace(tzinfo=pytz.utc)
now = datetime.datetime.now()
self.window.add(self.image)
float(value)
mtransforms.Transform.__init__(self)
newlist.append(v + str(count + 1) if totalcount > 1 else v)
apply_labels(h, labels)
df2 = pd.read_csv(StringIO(txt2))
plt.imshow(flip_ud_lena, cmap=plt.cm.gray)
show()
canvas.Canvas.__init__(self, *args, **kwargs)
print(dog.lemma_names())
foo.save()
tk.Canvas.move(self, *args, **kwargs)
c = b
print(s.groupby([s.index.weekday_name, s.index.hour]).sum())
fig, axes = plt.subplots(nrows=2)
datetime.strptime(value, format)
print(parser.parse_args())
urllib.request.install_opener(urllib.request.build_opener(LowLevelHTTPHandler))
list(x * x for x in range(10))
Test.static_init()
oldperson.hello()
func(one=1, two=2)
a = np.arange(1, 7)
kernel = np.uint8([[1, 1, 1], [1, 10, 1], [1, 1, 1]])
numpy.atleast_2d(x[x[:, (2)] == 0])
indices = np.empty((m * n, 8), dtype=int)
heapq.heapify(h)
json.loads(dictString)
fp.write(part.get_payload(decode=True))
open(filename, *args, **kwargs)
e.click()
ax.get_xaxis().get_major_formatter().set_useOffset(False)
dict((j, locals()) for _ in range(i))
G = nx.DiGraph()
print((a, b, c, d))
s.readline()
increments.append(onediff[i])
msg.attach(part1)
math.sqrt(dotproduct(v, v))
ax.yaxis.set_major_formatter(matplotlib.ticker.ScalarFormatter())
ssh = paramiko.SSHClient()
r.status_code
data = np.random.uniform(-1, 1, 44100)
combo.set_active(0)
C4.bar()
a.sort(key=w.__getitem__)
abort(404)
canvas.tag_lower(secondRect)
c.f()
self.figure.subplots_adjust(right=0.9)
obj_list.append(obj)
lst = ast.literal_eval(strab)
np.zeros(s)
w.show()
cur = con.cursor()
HELLO
event.save()
view(request, *args, **kwargs)
pygame.display.flip()
browser.show()
response = urllib.request.urlopen(url)
cache.commit()
plt.plot(x, y)
np.all(i for i in range(10))
column_widths += [len(cell)]
(items + (item,) for items in product(*args[:-1]) for item in args[-1])
quat_multiply(a1[1, 2], b1[1, 2])
f = os.path.join(path, filename)
np.median([0, 2, 6, 5, 4])
self.x1 = self.x0 + self.width / 2
wb = excel.Workbooks.Open(fname)
df.drop(rows)
y[x.argsort()] = np.arange(x.size)
[randint(1, 9999) for _ in range(randint(50, 200))]
print(Counter(zip(words, words[1:])))
fig, ax = plt.subplots()
optionmenu.configure(width=yourwidthhere)
fig, ax = plt.subplots()
n, bins, patches = plt.hist(x, histedges_equalN(x, 10))
app = Flask(__name__)
[i for i, x in enumerate(lst) if x == item]
sess = tf.Session()
self.assertEqual(expresults, results)
plt.show()
cursor = conn.cursor()
df = pd.DataFrame(np.random.random((N, M)), index=dates)
ax.set_yticks([-1.25, -0.75, -0.25, 0.24, 0.75, 1.25], minor=True)
id = Column(Integer, primary_key=True)
print(repr(ordliste))
main()
ax.set_ylim(ymax=100)
B = [0, 0, 1, 1, 1, 1]
print(sorted(words) == words)
writer.writerow(row)
G.nodes()
self.treeview.set_search_column(0)
ax1 = fig1.add_subplot(111)
number += 1
foo()
s.play()
sys.modules[__name__].__dict__.clear()
fig.canvas.draw()
x * (x > 0)
loop.run_until_complete(do_work(q))
linesamples.add(int(4 * i + 2))
fig = plt.figure()
df = df.reset_index(level=[0, 1])
fig = plt.figure()
print(os.path.join(root, file))
print(args)
print(match.groups())
self.setLayout(layout)
c.py
A.ravel()[np.random.choice(A.size, c, replace=False)] = np.nan
_ = list(map(lambda x: result.extend(x), res))
b in l[l.index(a):]
text = models.CharField(max_length=200)
b = a[:]
signal.signal(signal.SIGCLD, signal.SIG_DFL)
days = (roundedA - roundedB).days
list(product(*([0, x] for x in stuff)))
print(boop)
func.argtypes = [ctypes.c_char_p, ctypes.c_char_p]
logger.addHandler(fh)
ax = fig.add_subplot(111)
min(i for i in range(len(L)) if L[i:i + len(key)] == key)
Py_Finalize()
file.write(capitalised)
print(b.most_common(1))
print(demo.multiply(2.0, 4.0))
axes[1].plot(x, i * np.cos(x))
datetime.combine(d, datetime.min.time())
palette.append((255, 255, 255))
ax.bar(theta, counts, width=np.pi / 6, color=colors, alpha=0.5)
25.4 / 10 * (1 / 2.54)
t = threading.Thread(target=worker, args=[data])
print(sort_dict_by_list(a, b))
np.random.seed(42)
conf.py
ax.set_yticklabels(people)
web.load(QUrl(url))
y = random.randint(0, walnut.size[1] - 1)
weekly = map(sum, grouper(7, visitors, 0))
cardsdiscarded += 1
id = db.Column(db.Integer, primary_key=True)
{b.pop(0): {b.pop(0) for _ in range(1)}}
driver = webdriver.Firefox()
app.MainLoop()
signal.signal(signal.SIGINT, signal.SIG_DFL)
form = cgi.FieldStorage()
app.logger.addHandler(handler)
my_screenmanager.add_widget(screen2)
print(xcoord)
new_df[df.isnull()] = np.NaN
lxml.etree.Comment
time.sleep(poll_period)
a = dict((hash_counting_int(x), []) for x in range(10))
results.append(make_comp_func(i, j))
array([False, True, True, True, True, True, False], dtype=bool)
conn.connect()
do_something_with_a_and_b
pyglet.app.run()
main()
ax1 = fig.add_subplot(111)
a.withdraw()
s.quit()
498, 410
sys.exit(app.exec_())
httpd.serve_forever()
numpy.linspace(10, 20, 5, endpoint=False)
views.py
zip_longest(fillvalue=fillvalue, *args)
s.get_data()
httpd.shutdown()
result = []
match.group(1)
HttpAuthenticated.__init__(self, *args, **kwargs)
self.get_paginated_response(serializer.data)
a.a().method()
x = collections.deque(5 * [0], 5)
Following.objects.filter(follows=self).count()
print(a, b, c, d, e, f)
waitress.serve(demo_app)
root = Tkinter.Tk()
plt.show()
pool.close()
textbuffer.select_range(match_start, match_end)
G.add_node(1)
self.process = subprocess.Popen(self.cmd, shell=True, preexec_fn=os.setsid)
entry.clear()
fs.start()
result = json.loads(output)
result_dict[x.key].append(x.value)
xi = np.arange(len(x))
print(s1, len(s1))
wx.EvtHandler.__init__(self)
keep.add(onemorevalue)
smtp.sendmail(sender, recipients, themsg)
df.apply(outer_product)
node.update(value)
result.appendlist(key, value)
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cookie_jar))
tornado.ioloop.IOLoop.instance().start()
df.dtypes
processHeader(f.readline())
now = dt.datetime.now()
X /= X.std()
ax.xaxis.set_major_formatter(FuncFormatter(lambda tick, _: get_day(tick)))
b = np.array([2, 1, 1, 1, 1])
print(img.size)
print(repr(line))
b[:, :, (some_mask == 1)]
file.write(part.get_payload(decode=True))
job = Job.objects.get(pk=1)
driver = webdriver.Chrome()
conn.perform()
sizer = wx.BoxSizer(wx.VERTICAL)
df.index[0], v.iloc[-1]
driver = webdriver.Firefox(firefox_profile)
__init__.py
[(5, 6), (6, 7)]
soup = BeautifulSoup(html)
np.array(x.tolist())
self.l.append({})
dateutil.parser.parse(node.value)
self.f = args[0]
logging.Logger.__init__(self, name)
p = Process(target=f, args=(q,))
self.sizer = wx.BoxSizer(wx.VERTICAL)
QtCore.QModelIndex()
df.dtypes
pool = Pool(5)
plt.plot(A, B)
app.run()
__main__.py
a = np.random.rand(n, m)
p(i - 1) / 2 + p(i + 2) / 2
help(module)
Pdb().set_trace()
time.sleep(2)
tex.pack(side=tk.RIGHT)
cettime.isoformat()
content = response.content
self._is_running = False
mask = cv2.bitwise_or(mask1, mask2)
http_server.listen(8080)
len(data) == 0
turtle.forward(size)
new.setdefault(key, []).append(temp)
do_something()
data, addr = sock.recv(1024)
item = list[2][2]
True
contains_vectorized(geo_polygons, geo_points[:, (np.newaxis)])
func(x, y, z, a, b, c)
print(list(keep_n_dupes(lst, 2)))
myobj[5] = 1
values = np.array([4, 4, 4, 4, 4, 4, 4, 4, 4, 4])
myParent.__init__(self)
G.add_edge(1, 2)
im.update()
s.read()
ans = math.factorial(N)
ssh.close()
lines = [line.strip() for line in file]
Py_Initialize()
db = mongo.db
show()
queue.append(clientsocket.recv(1024))
main()
plt.imshow(frames[k], cmap=plt.cm.gray)
a_cursor.execute(sql, (val1, val2))
ti, xi = np.meshgrid(ti, xi)
f.close()
sleep(20)
self.stack.append(len(self.get_item()) - 1)
type(a.tolist())
print(str(uuid.uuid4())[:8])
results.append(a_dict[id])
bin((1 << 7) - 1)
psutil.get_pid_list()
HTMLParser.__init__(self)
print(para_group_demo.sum(df.a, df.b))
DateR = date.compile()
np.random.shuffle(idx)
fig = pyplot.figure()
{k: dict_[k] for k in keys}
self.entry.pack()
imscatter(x, y, image_path, zoom=0.1, ax=ax)
plot(tmp.min(axis=0))
val = int(input, 16)
f_out_intkeys.write(line)
f_out_quot.write(line)
f_out_frb.write(line)
f_out_dtwrld.write(line)
driver = webdriver.Chrome()
foo()
print(sum(map(d.get, itertools.takewhile(lambda key: key != 5, d))))
s = sys.stdout.getvalue()
X, Y = np.meshgrid(x, y)
signal.alarm(seconds)
do_stuff_with_two_lines(previous_line, current_line)
print(json.dumps(doc, default=ComplexHandler))
x = x + c
dict_setitem(dct, key, value)
z.update(y)
self.listbox.insert(0, option)
next(itertools.islice(cpy, index, index + 1))
sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)
values = np.random.rand(len(indices))
self.ProgressBar.SetRange(event.total)
plt.xlim(0, 1)
ui.show()
main()
{{form.errors}}
sns.set(**kwargs)
output.write(line)
[s[i:i + width] for i in range(len(s) - width + 1)]
plt.clf()
logger.addHandler(progress)
self.result_queue.put(result)
logging.Handler.__init__(self)
out = process.stdout.read(1)
plt.tight_layout()
b = int(a)
sys.path.append(YOUR_PATH)
browser.load(QtCore.QUrl(url))
row = np.random.randn(100)
tuple_list[i] = a, new_b
object_id = models.PositiveIntegerField()
data2 = np.asarray(data2)
isinstance(os, types.ModuleType)
df = pd.DataFrame(d)
word[len(word):-len(word) - 1:-1]
box.focus_set()
plt.show()
sum(map(int, item))
len(x)
print(string[i:j])
tree = ElementTree.fromstring(xml, parser)
background_label.image = background_image
print(every6(example_string))
Goodbye
do_stuff()
plt.axhline(i, color=color)
self.nout += 1
widget2.update_idletasks()
print(cv.GetCaptureProperty(stream, cv.CV_CAP_PROP_FRAME_COUNT))
self.update(dict(*args, **kwargs))
Pool()
a = np.vstack((a, np.array([[1, 1, 0, 0, 0, 0, 0, 1]])))
ssh = paramiko.SSHClient()
a + b
driver = webdriver.Firefox()
cur.close()
ax.set_xlim(0, 1.4)
x = random.randint(0, walnut.size[0] - 1)
bar.buzz()
xl.Quit()
response
fd = sys.stdin.fileno()
l.set_option(ldap.OPT_X_TLS_DEMAND, True)
fig = plt.figure()
dict.clear()
events[-1].append(line)
exec(open(filename).read())
sorted(x, key=functools.cmp_to_key(customsort))
plt.show()
draw.line((x1, y1, x2, y2), fill=col, width=1)
testsite_array.append(line)
isinstance(bar, types.UnboundMethodType)
new_list = list(generate_items)
time.sleep(5)
a - b
print(form.instance.id)
print(f2.readline())
print(count_rec(0, 0))
auth.set_access_token(access_key, access_secret)
text = row[1]
python - mfoo.bar
self.thread.start()
form.fileName.file.save(file_path)
handle.flush()
np.repeat(uniques, np.clip(count, 0, 2))
sys.stderr = sys.__stderr__
1 / 0
wx.StaticBitmap(panel, -1, png, (10, pos), (png.GetWidth(), png.GetHeight()))
ax.set_axis_off()
values(np.arange(len(A)))
[(j + i) for i in strings for j in listSubstrings if i.find(j) > -1]
layout.addWidget(self.splitter)
do_something(line)
parser = argparse.ArgumentParser()
x.reshape(zt, -1)[idx.ravel(), np.arange(yt * xt)].reshape(-1, xt)
df.mask(np.triu(np.ones(df.shape)).astype(np.bool))
objectA.delete()
sys.modules[name] = module
json.loads(list_dump)
b = bytes([x])
id = Column(Integer, primary_key=True)
brr.sort()
defaults.update(kwargs)
datetime.combine(date.today(), exit) - datetime.combine(date.today(), enter)
app = Flask(__name__)
s = map(str, numList)
app = QtGui.QApplication(sys.argv)
deleteL[::L[0]]
a = numpy.ones((2, 4))
df.gdp.drop(df.gdp.shape[0] - 1, inplace=True)
[myList[i] for i in sorted(indices)]
self.SetDiagram(self.diagram)
turtle.right(angle)
fh.write(output_from_parsed_template)
dict.__init__(self, *args, **kwargs)
str(1056) is str(1056)
t.start()
plt.legend()
a[arange(2), 0, 0], b[arange(2), 0, 0] = b[arange(2), 0, 0], a[arange(2), 0, 0]
ws.close()
pprint(sorted_dict)
buffer1[pos:pos + len(buffer2)] = buffer2
self.data[key]
np.any(a == 2, axis=0)
self.layout = QtGui.QHBoxLayout()
A.shape
ax.set_theta_offset(np.radians(90))
app.register_blueprint(bp)
web.load(QUrl(url))
self.write(figdata.getvalue())
pool = mp.Pool(processes=1)
options, args = parser.parse_args()
logger.addHandler(file_handler)
[b, c, d, e, f]
print(instance.ip_address)
[1, 0, 1, 1, 0]
cls(wfd, bfd, wildfd, tfd, ffd)
p.start()
it = iter(the_list)
f(6)
t.render(c)
[2, 2, 5, 7, 7]
plt.plot(x_new, ffit(x_new))
im.size
msg.attach(part1)
setattr(cls, key, wrapper(value))
myList = []
print(df)
admin.site.unregister(User)
self.testButton.clicked.connect(self.change_text)
drand48()
s = socket.socket()
time.sleep(1)
list = list + [(0) for _ in range(4 - len(list))]
self.view.setEditTriggers(QtGui.QAbstractItemView.NoEditTriggers)
mlab.show()
image = image.astype(np.uint8)
print(my_list[0])
help(foo.bar)
response = urllib.request.urlopen(url)
heapq.heappush(heap, (row[1], row))
urllib.request.install_opener(opener)
x = list(range(1, 10))
self.assertEqual(forty_two, 42)
ser.close()
ax.errorbar(theta, r, yerr=1, xerr=0.1, capsize=0)
suite.addTest(unittest.defaultTestLoader.loadTestsFromName(t))
df
s.strip()
table.horizontalHeader().setStretchLastSection(True)
self.master.destroy()
a.foo = 2
os.write(fd, data)
idx = where(abs(A[:, (newaxis), :] - B).sum(axis=2) == 0)
screen = pygame.display.set_mode((100, 100))
start_date = timezone.now().date()
x1, x2 = np.nonzero((diffs < tol).all(2))
[random.choice(xs) for _ in range(sample_size)]
serializer.save(user_id=15)
Response(serializer.data)
list(self.__dict__.keys())
result = np.empty_like(arr)
(A != 0).cumsum(1)
models.DateTimeField.to_python(self, value)
print(regx.findall(content))
self.frame.pack_propagate(False)
a = numpy.array(list(range(10)))
A_from_python()
id = Column(Integer, primary_key=True)
fp.close()
self._socket.send(bytes)
np.allclose(a.data, b.data)
print(str(x))
c.save()
self.log_message(format, *args)
len(obj)
line = proc.stderr.readline()
rgb = np.empty_like(hsv)
self.cj = cookielib.CookieJar()
ngrams(string1, n) & ngrams(string2, n)
offset = cet.utcoffset(dt, is_dst=True)
[mylist[cumlist[i]:cumlist[i + 1]] for i in range(len(cumlist) - 1)]
len(L) == len(E)
app.db = db
app.processEvents()
self.get()
[1, 2]
dt = datetime.datetime(2012, 1, 1, 0, 0)
ax1 = fig.add_subplot(111)
pprint(data, indent=4)
sum(array[mask])
x + 1
extension = guess_extension(guess_type(url)[0])
data = data[tuple(ind)]
parser.feed(your_html_string)
print(now + dateutil.relativedelta.relativedelta(months=-1))
ax.set_xticklabels(xlabels)
nanargmax(a)
data = f.read()
[i for i in l if re.search(s, i)]
num * X(X, b - 1) if num > 0 else 1
print(kmeans.cluster_centers_)
print({k for k, v in list(counts.items()) if v >= 2})
msg.attach(plain_text)
driver = webdriver.PhantomJS()
print(my_string)
main()
Response(serializer.data)
row.pop()
time.sleep(2)
img = c.getImage()
string.printable
operator.itemgetter(*b)(a)
os.makedirs(whatever)
img.write(artwork)
data[key]
picture.putpixel((x, y), new_color)
file.seek(0, 2)
result = [foo(p1, p2) for p1 in people for p2 in people]
np.transpose(np.nonzero(b))
factor.P()
whos
print({k: (x.get(k, 0) + y.get(k, 0)) for k in set(x) & set(y)})
app = Eve(auth=globalauth.TokenAuth)
time.sleep(1)
y = tuple(x)
array([[1.0, 1.0], [1.0, 1.0]])
getattr(obj, name)
plt.plot([1, 2])
engine = innodb
app.logger.addHandler(file_handler)
proc = subprocess.call(command, stderr=subprocess.OUTPUT)
ax.set_xticks(ind + width / 2)
f()
lines.append(line)
dates.year
widget.show()
len(bin(10)) - 2
plt.yticks(list(range(y.max() + 1)), labels)
list(self.keys())
r = requests.post(url, data=json.dumps(payload), headers=headers)
response = requests.get(url, params=query)
tree = tree.getroottree()
app = Flask(__name__)
os.rename(original, output)
a = np.random.random(20).reshape(4, 5)
d.setdefault(key, []).append(val)
pool.join()
{{tag}}
NULL
t.total_seconds()
int()
QtCore.QCoreApplication.instance().quit()
mask = np.ones(len(data), np.bool)
slices = [sli for sli in (list(islice(it, 0, i)) for i in seclist) if sli]
print({k: (x.get(k, 0) + y.get(k, 0)) for k in set(x)})
(string_to_expand * (length / len(string_to_expand) + 1))[:length]
my_string = my_string.lower().split()
s = s[::-1]
df1.columns = pd.MultiIndex.from_tuples(new_cols)
Base.metadata.create_all(e)
client.Resolver.__init__(self, servers=servers)
print(is_summer_time(aware))
b = sorted(sorted(a, key=lambda x: x[0]), key=lambda x: x[1], reverse=True)
t.cancel()
map(add, a, itertools.repeat(2, len(a)))
finder1.apply_freq_filter(2)
data = np.arange(100, dtype=np.int)
diff = set(zip(df2.Buyer, df2.Quantity)) - set(zip(df1.Buyer, df1.Quantity))
threading.Timer(1, foo).start()
n[1]
print(kwlist)
a.name()
sleep(1)
p.stdout.readline()
Parent.__init__(self, x)
list(d.items())
pcolor(my_array, cmap=cmap, norm=NoNorm())
r.clipboard_clear()
b = [1, 2, 5]
x = np.lib.stride_tricks.as_strided(y, shape=(A, B), strides=(n, n))
os.makedirs(f)
plt.bar(x[i], y[i], color=cm.jet(1.0 * i / len(x)))
dict((v, k) for k, v in d1.items())[55]
button.setVisible(False)
print(tailq.get())
app = Flask(__name__)
ordered = list([x for x in ordered if x not in unordered])
next(c)
app = Flask(__name__)
self.assertEqual(e.args[0], 42)
result = pool.map_async(task, [(x, q) for x in range(10)])
some_queryset[:length] if length else some_queryset[:]
listmatrixMap(add, a, b)
session = requests.session(cookies=cookies)
new_list.append(v)
list(calendar.day_abbr)
compare_lists(a[1:], b[1:])
msvcrt.getch()
(5)()
np.arange(10)[10:-10:-1]
f.close()
cleaned_list = list(filter(is_not_thing, some_list))
pylab.xlim(xmin=0)
fh.close()
help(f)
sp.stdin.close()
p.communicate(input=str)
print(x)
df.iloc[idx]
MyClass.call_me()
some_value
zeroMatrix = [zeroArray[:] for i in range(Np)]
utc_dt + timedelta(hours=longitude / math.pi * 12)
np.sqrt(val / 2.0 / a.shape[0])
transaction.commit()
self._fp.close()
re.sub(r, replacer, string)
bundle.obj == bundle.request.user
soup = BeautifulSoup(html_doc)
ax.yaxis.set_major_formatter(matplotlib.ticker.ScalarFormatter())
lock.release()
a = np.array([1, 2, 1, 1, 2])
wait()
self.pressed.connect(self.update)
df.index = pd.MultiIndex.from_tuples(df.index)
print(spectra_list[0])
print(t.timeit(5))
fig = plt.figure(figsize=(10, 8))
imp.get_suffixes()
self.seek(0)
views.py
plt.draw()
[i for i in range(2, 25) if f(i)]
print(numpy.array([n.activate(x) for x, _ in d]))
b = ma.masked_array([0, 1, 2, 4], [True, True, False, False])
dict(d)
np.add.reduceat(a, w[:-1]).astype(float) / np.diff(w)
a.symmetric_difference(b)
atexit.register(whatever)
enternum.pack()
config = ConfigParser.ConfigParser()
map(lambda x: x[0] == 1, a_list)
process(line)
time.sleep(SPINUP_WAIT_TIME)
self.master.destroy()
session.commit()
self.button.setContextMenuPolicy(QtCore.Qt.CustomContextMenu)
print(sum((a - i) ** 2, 1).argmin())
print(mywrap(s, 10))
sorted(versions, key=LooseVersion)
a[0] * b[0] + a[1] * b[1] + a[2] * b[2]
c.setopt(c.WRITEFUNCTION, storage.write)
extension = guess_extension(guess_type(url))
show(layout)
temp = temp.reshape(1, -1)
np.delete(myarray, np.r_[tuple(mylist)])
sockOutfile.write(readRequest)
pd.DataFrame((d2 - sums2 / n) / stds2 / n, df.columns, df.columns[k:l])
time.sleep(5)
sys.exit(1)
fig, ax = plt.subplots()
self.setFixedSize(pic.size())
screen = win.get_screen()
print((i[0] + 1, i[1]))
_epoch + timedelta(days=ordinal - 1)
print(a[150001, 2])
A.__init__(self, *args, **kwargs)
data = cur.fetchone()[0]
1, 1, 1, 1, 1, 1, 0, 0, 20160224, 20160226
datetime.datetime.fromordinal(t.toordinal())
D = np.random.random_integers(0, 1, (5, 5))
combs.append((x, y))
print(soup)
{2, 4, 10}.issubset(chain.from_iterable(x))
result.append(s)
a = np.arange(10)
mylist = []
sys.__repr__()
photo = models.ImageField(upload_to=photo_path, blank=True)
print(new_data.shape)
img_file.save(new_image_name)
text.set_text(s)
out[idx, idx] = A[idx, idx]
n_grams = CountVectorizer(ngram_range=(1, 5))
QWebPage.__init__(self)
[0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1]
ax = fig.add_axes([0.1, 0.1, 0.8, 0.8])
[(word[:i] + word[i + 1:]) for i in indexes]
locale.currency(188518982.18)
print(sys.executable)
lambda x: sum(f(x) for f in terms)
sys.__stdout__.write(data)
points = [(i, j) for i, j in zip(x, y)]
inprogress.append(taskindex)
ax.set_yticks(majorticks, minor=False)
ssc.start()
datetime.date(year, month, day)
print([cls.__name__ for cls in X.mro()])
X = [i[0] for i in Counter(df.X).most_common()]
data = [[float(x) for x in y] for y in data]
print(flatten(list))
name = models.CharField(max_length=128)
sio.readlines()
plt.loglog(list(range(100)))
ax.xaxis.set_tick_params(size=0)
out = idx[mask].argsort()[unqID]
time.sleep(0.1)
print(sys.path)
heapq.heappush(self.heap, (pri, d))
print(strings.group(0))
views.py
t.to_pydatetime()
fcntl.fcntl(fd, fcntl.F_SETFL, fcntl.fcntl(fd, fcntl.F_GETFL) | os.O_NONBLOCK)
a[idx]
locals() is globals()
window = NSApp.mainWindow()
tuples = [(x, y) for x in L1 for y in L1 if x != y]
ImageDraw.Draw(halo).text(position, text, font=font, fill=halo_col)
bit_array[25] = 1
self.fd.seek(offset)
foo = Foo()
self.html_file.close()
widget.show()
abs(g(a + b * f(c)) + g(a - b * f(c)) - 1) < 1e-10
min(s[max(0, i - 1):i + 2], key=lambda t: abs(ts - t))
crustFrame.Show()
asyncore.dispatcher.__init__(self)
[x_y_z for x_y_z in a if x_y_z[0] + x_y_z[1] + x_y_z[2] > 6]
statement.parseString(text)
A = np.arange(10)
layout = QtGui.QVBoxLayout()
f1.close()
a = np.array(ulysses.split())
self.model.fetchMore()
demandimport.__file__
a = numpy.random.randn(100, 200)
df[df < 1] = 0
cookies = cookielib.LWPCookieJar()
__init__.py
text = models.TextField()
User[1] == {}
r = requests.get(url)
self.assertAlmostEqual(em(1, 2), 0.2188, 4)
b = tf.square(tf.matrix_determinant(a))
counts = np.bincount(id[mask1] - 1)
elem.clear()
root = tree.getroot()
widget.deleteLater()
parent.remove(elem)
img.resize(width=scaled_width, height=scaled_hight)
id = Column(Integer, primary_key=True)
print(x)
new = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
setp(a, xticks=[], yticks=[])
f.name
data.setdefault(k, [])
print(type((1,)))
copy.deepcopy(self)
self.window.addstr(1 + index, 1, msg, mode)
list.sort()
psutil.virtual_memory()
partials.append([])
BlogComment.save()
url = opener.open(request)
int(self)
instance.new()
args = parser.parse_args()
new_pressures[-1] += p[index]
script.extract()
accum &= np.abs(a[:, (i)] - b[:, (i)].ravel()) < tol[i]
handler.setLevel(logging.CRITICAL)
df
u in G.neighbors(v)
cvtColor(im, imgrey, CV_RGB2GRAY)
self.cam.release()
words.append(random.sample(novel, 100))
{key: tuple(d[key] for d in dicts) for key in common_keys}
{key: obj.__dict__}
a == b
hist(x)
si.imgdata = im.tostring()
{{(game.description | safe | truncatewords): 65}}
(date(2015, 10, 7) - date(1, 1, 1)).days
time.sleep(self.delay)
print(daily_prices[2])
print(resp.status_code)
parser = etree.XMLParser(remove_blank_text=True)
plt.colorbar(im, fraction=0.046, pad=0.04)
osa.communicate(ascript)[0]
velcro.right(90)
print(len(S1), len(S2))
x = json2obj(data)
out[idx[:, (0)], idx[:, (1)]] = vals
QtGui.QWidget.eventFilter(self, source, event)
sys.path.insert(0, os.path.abspath(os.path.dirname(__file__)))
list(self.__graph_dict.keys())
values = np.sum(weights * features + bias)
frame.pack()
f_output.write(file_bytes.read())
A[:, (1)] *= 5.2
unittest.main()
fig = plt.figure()
pd.rolling_mean(pivot, 90, center=True, min_periods=1)
np.vstack((dst[idx], rows[idx], cols[idx])).T
session.add(h)
self.data.config(yscrollcommand=self.scrollbar.set)
ax = plt.gca()
plt.colorbar(sm)
script = sys.argv[0]
values = [is_prime(x) for x in PRIMES]
print(df)
distance = [[[(0) for k in range(n)] for j in range(n)] for i in range(n)]
callable(fn)
sys.exit(0)
browser = webdriver.Firefox()
func(*args)
pprint.pprint(list(collection.aggregate(pipeline=pipeline)))
list(x)
print(readline.get_history_item(i + 1))
self.frame.Show(True)
self.queue.append(data)
print(a, b)
chars.extend(line)
file = jpgs[-1]
sleep(1)
column_label.show()
res0.remove(element)
x = session.query(Foo).all()
Employee.__init__(self, name, salary)
list(filter(filterfunc, l1))
recursion(0, 0)
dict(zip(student_names, average_of_all_assignments))
t.start()
args = parser.parse_args()
sum([True, True, False], False)
705.0, 690.0, 705.0, 680.0, 715.0, 705.0, 670.0, 705.0, 705.0, 650.0
afield = forms.ChoiceField(choices=INITIAL_CHOICES)
screen.fill((255, 0, 0), (self.x, self.y, 10, 10))
draw = ImageDraw.Draw(image)
list(reversed([i[0] for i in l[1:-1]]))
f(a, b).A
list.append(map(itemgetter(1), g))
self.label.pack(padx=10, pady=10)
cursor.execute(SQL)
print(df.reindex(idx))
np.allclose(B.todense(), B2.T)
response
deleteelem.getparent()[0]
[list(i) for i in zip(*theArray)]
fig = pl.figure()
G.add_path([0, 2, 5])
plt.show()
dt = datetime.datetime.fromtimestamp(float(datestring))
func(xy[0], xy[1], data)
print(str(i))
sorted_files.append(f)
json.loads(value)
c, d = np.meshgrid(a, b)
collections.defaultdict(nested_dict)
args = parser.parse_args()
leg = ax.legend()
hash_md5.update(chunk)
pyplot.ylim(ymin=0)
pool.join()
response = urllib.request.urlopen(req)
server.set_debuglevel(1)
self.fn(*args, **kwargs)
x.loc[(x.A >= 2.0) & (x.A <= 4.0)]
np.all(a == a.T)
-1 if not a or a.isspace() else a.index(a.lstrip()[0])
count[letter] = 1
ax = fig.add_subplot(111)
opener = urllib.request.build_opener(handler)
cursor = db.cursor()
foo[somestuff]
dict1.items() ^ dict2.items()
stdv.reset()
key = models.PositiveIntegerField()
shutil.rmtree(dir)
lst[(len(lst) + 1) / 2 - 1]
plt.figure()
a[x] + a[y]
self.cleaned_data
parser.parse_args(args)
df.describe()
integrate.quad(func, a, b, args=(y,))[0]
fig = plt.gcf()
a + (b - a) * self.random()
df
ax.scatter(xs, ys, zs, c=c, marker=m)
m = ctypes.c_int(x.shape[0])
plt.show()
self.window.add(self.image)
ioctl(fd, USBDEVFS_RESET, 0)
zipf.close()
np.random.choice(make_sampling_arr(n_k), m)
s.send(tmsg)
a[20:] = zip(*zip(a[20:], itertools.repeat(0)))[1]
instance.topping_set.clear()
ww.writeframes(new_frames)
ET.dump(root)
[c, d, f]
{{mywidget.css()}}
ConstantFunction(constant)
sum(b << k * 8 for k, b in enumerate(bytes))
plt.clf()
x.append(Foo())
app = QtGui.QApplication(sys.argv)
app.listen(8888)
suffix_array.sort(key=lambda a: content[a:])
Maybe(val)
matrix = matrix[0:100, 0:80]
print(new_url)
found_extensions.add(os.path.splitext(f)[-1])
a = numpy.linspace(-1, 1, 20)
u = np.sin(np.pi * x) * np.cos(np.pi * y) * np.cos(np.pi * z)
chart.Copy()
x = theano.shared(numpy.arange(10))
now += timedelta(minutes=1)
ranges.append((last_start, offset - 1, current_set))
my_dict[key] = indices
xmlOutput += self.dirToXML(os.path.join(root, subdir))
ax = pl.subplot(111)
self.__dict__.update(name_value_dict)
win.setWindowFlags(win.windowFlags() | QtCore.Qt.CustomizeWindowHint)
type(int(s))
[0, 0, 0, 17, 0, 0, 0, 40, 0, 0, 0, 0, 0],
__init__.py
app = QtGui.QApplication(sys.argv)
listWidget.setItemWidget(item, w)
result.update(dictionary)
corpus.sort(cmp=locale.strcoll)
info[1][1] == 4
np.random.seed(22)
df1 = df.iloc[:, :-1]
session.expunge(item)
list(unique_everseen(a, key=set))
hash(dumps(data))
self.__dict__.update(kwds)
[tmp.setdefault(name, len(tmp)) for name in names]
new_points = list(do_something_with(x, y, z) for x, y, z in surface.points)
self.assertAlmostEqual(em(2, 2), 0.4251, 4)
list(b)
z.append(matchobj.group(1))
[foo() for x in range(10)]
time.sleep(4)
plt.bar(list(range(0, 100)), x)
fig = pylab.figure(figsize=(12, 9))
mask = np.ones(len(a), dtype=bool)
lst = [(int(s) if s.isdigit() else s) for s in lst]
sys.stdout = sys.__stdout__
print(numpy.__path__)
random.shuffle(some_list_of_stuff)
type(n) is int
arr = np.dstack((r, g, b, a))
x.update([i])
numpy.arange(a.shape[0])[numpy.in1d(a, b)]
sock.bind((HOST, PORT))
data = pickle.load(fp)
axes[0].legend().set_visible(False)
0.5 * (1 + tsr.erf((x - mu) / (sd * tsr.sqrt(2))))
a.extend(map(add, lst))
print([set(x) for x in bodylist])
-__init__.py
new_db.executescript(query)
b = a[:]
zip_longest(fillvalue=fillvalue, *args)
a[(labels.view(np.ndarray).ravel() == 1), :]
print(sys._getframe().f_code.co_name)
soup = BeautifulSoup(data)
p.wait()
plt.plot(X, Y1, lw=0)
test_module2.py
plt.pause(1e-09)
draw = ImageDraw.Draw(circle)
timeit(lambda : list(assignments(12, 5)), number=1)
serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
file_handler.setLevel(logging.DEBUG)
foo(nonsene=True, blather=False)
ax.set_xlim(0, 5)
os.path.splitext(fn)[1] != ext
a[i, j]
dfs = pd.concat(df_list)
np.random.seed(0)
user = User.objects.get(pk=uid)
cv2.waitKey(1000)
delete_keys_from_dict(v, lst_keys)
tk.Tk.__init__(self)
[y for y in x.split() if len(y) > 2]
time.sleep(1)
a.take((1,), axis=1)
os.startfile(filepath)
self._tunnel()
writer = csv.writer(f)
BeautifulSoup(badString, markupMassage=myNewMassage)
result.append(elem)
fig = plt.figure()
print(p.match(input).groups())
dummy_event.wait()
datetime.datetime(2012, 1, 2, 0, 0, 0),
zeroMatrix = numpy.zeros((Np, Np))
points.append((x, y))
pickle.loads(encoded)
jsonify(x.serialize())
Widget.__init__(self, parent)
s = set(fus_d.keys())
torfile.set_priv(torinfo.priv())
b = [(1 if i else 0) for i in a]
print(sum(1 for _ in takewhile(lambda x: x == l[0], l)))
q = multiprocessing.Queue()
df /= df.max()
form.show()
tk.Tk.__init__(self, *args, **kwargs)
[sum(combination, []) for combination in itertools.product(*outer)]
node
article.author = self.request.user
article.headline_set.all()
data[tuple(ind)]
isinteger(1)
itertools.combinations(items, 2)
server()
L[-1]
np.array([np.bincount(ii, r) for r in a.T]).T
L[:] = [x for x in L if d[x] == 1]
years_dict[line[0]] = [line[1]]
w = Gtk.Window()
os.play()
print(form.username)
req = urllib.request.Request(url)
B = numpy.array(A)
Time.insert(0, time)
print(y, len(y))
print(conn.sock.getpeercert())
type(d)
s.seek(0)
pylab.plot(x)
self.d[index] = [value]
d + datetime.timedelta(days_ahead)
id = models.IntegerField(primary_key=True)
max_value = np.iinfo(im.dtype).max
self.close()
f = open(filename)
d.setdefault(m, []).append(k)
m.getch()
max(L[0], 0)
opener = urllib.request.build_opener(urllib.request.HTTPRedirectHandler)
print((lambda b: Y)(num))
t = xml.fromstring(s)
np.ma.array(x, mask=~bool_arr).argmax()
ax.add_patch(patch)
print(tavnit % tuple(columns))
show()
(alist[i:j] for i, j in pairs)
pathqueue.join()
PyMODINIT_FUNC
root = tree.getroot()
request = requests.get(url, stream=True)
set(c).issubset(set(a))
numbers = [int(w) for line in lines for w in line.split()]
stdout, stderr = p.communicate()
pythoncom.CoInitialize()
painter.rotate(90)
frozenset(some_item for some_set in some_sets for some_item in some_set)
myDict[key] = 20
seen.add(item)
print(values[:, (1)].sum())
self.handle_request()
width = win.winfo_width()
option.NPV()
l2 = [0, 2, 5, 6, 8, 9]
print(statlib.__version__)
cs = axs[1].contourf(X, Y, zdata, levels=[-1, 0, 1])
divmod(c.days * 86400 + c.seconds, 60)
QApplication.restoreOverrideCursor()
myarray[x.group(1)] = [x.group(2)]
do_case0()
self.socket.sendall(length)
peewee.create_model_tables(models)
queue.start()
help(CM)
ynew
((key, mydict[key]) for key in mydict)
profile.options.filter(id=option_id).count()
stack.pop()
np.choose(m, p_vec).sum(axis=1)
transsurface.set_colorkey((255, 0, 255))
B[:, :] = v.dot(A)
a = A[:, (j)]
plt.tight_layout()
not bool(condition)
np.diff(np.r_[0, np.where(np.diff(data) != 1)[0] + 1, data.size])
pl.show()
ax.set_yticks([-0.5, 0.5])
cur = con.cursor()
req.add_data(urllib.parse.urlencode(kwargs))
0 if len(cn) > 1 and cn[0][1] == cn[1][1] else next(iter(cn), [0])[0]
list1[:]
a1Note.play()
array[np.abs(array) < eps] = 0
False
d.get_state()
root.mainloop()
ax = fig.add_subplot(111)
file_handler.setLevel(logging.DEBUG)
thrs.append(threading.Thread(target=targ))
row_ind = [k for k, v in d.items() for _ in range(len(v))]
self.values.remove(item[1])
print(file_type(filename))
tty.setraw(sys.stdin.fileno())
User.__unicode__ = User.get_full_name()
self.blocks.clear()
pool.apply_async(func, callback=callback)
main()
frame.Show()
table = list(itertools.product([False, True], repeat=n))
out = pcorr[np.nanargmax(np.abs(pcorr), axis=0), np.arange(pcorr.shape[1])]
process.start()
len(l)
sys.exit(0)
source.yaml
out[:, (mask)] = B[:, :, ::-1][:, (mask[:, ::-1])]
root.focus_force()
bool(urlparse(url).netloc)
self.wfile.write(f.read())
Py_Finalize()
id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
platform.version()
data = f.read()
print(binascii.b2a_hex(os.urandom(15)))
fn_globals.update(globals())
f()
pycallgraph.start_trace(filter_func=filtercalls)
uniques = npi.intersection(x, y)
print(s[:117])
ifr.ifr_flags |= IFF_PROMISC
pickle.dump(_object, self.transport)
im = cv2.imread(sample)
email = db.Column(db.String(45), unique=True)
len(y[b])
len(result.index.names) > 1
njit(simulator)
box.show()
os.setsid()
cursor = collection.find({})
make_xml().write(sys.stdout)
{{form.name()}}
s = input()
socket.listen(1)
do_something()
show(p)
id = Column(Integer, primary_key=True)
np.where(np.eye(A.shape[0], dtype=bool), A, A.T + A)
[0, 0, 0, 0, 0, 0, 0, 17, 0, 0, 0, 17, 0],
window.show()
lst[out.sum(axis=1) == 1]
res2 = numpy.array(list(zip_longest(fillvalue=0, *a))).transpose()
arr.reshape(-1, la)
sys.exit(-1)
df = pd.concat([df] * 10000).reset_index(drop=True)
print(e.message)
self.__dict__ = self
l = numpy.array(l, dtype=int) * 2
self._is_owned()
a.extend(list(range(0, 1000000)))
obj.do_something()
app = QtGui.QApplication([])
process(f)
np.linalg.det(individual.reshape(self.N, self.N)),
title = models.CharField(max_length=128, blank=True)
print(len(line))
int(value)
sns.barplot(x=data.index, y=data, palette=np.array(pal[::-1])[rank])
np.ascontiguousarray(c)
myFunc()
dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)
yests = []
MyModel.BLAH_GOO_GOO_GAA_GAA
thread = threading.Thread(target=target)
self._server.show()
range_start + int(drand48() * range_size)
text_file.write(contents)
g.__code__ is f.__code__ is creator.__code__.co_consts[1]
len(net.layers[1].blobs)
plt.figure()
button.grid(row=1, column=4)
shutil.copyfileobj(source, target)
print(arr[10])
self.user.delete()
datetime.datetime(2010, 5, 17, 0, 0)
max(string.rfind(s) for s in findees)
self.panel.SetFocus()
print(list(map(tuple, list(od.values()))))
self.features = {k: v for k, v in list(kwargs.items())}
values = np.array([1, 1, 1, 1, 1])
pd.DataFrame(df.values[slc], df.index[slc])
id = Column(Integer, primary_key=True)
self.name = name
stdout, stderr = proc.communicate()
df.ix[0, 0]
dict((k, v.dropna().to_dict()) for k, v in compat.iteritems(data))
(a > 1).all() and (a < 5).all()
print(get_last_non_zero_index([0, 0, 0]))
tk.Tk.__init__(self, *args, **kwargs)
list(set(a).difference(b))[:100]
array([[0, 2, 6], [9, 4, 8], [7, 5, 1]])
print(s.to_string(index=False))
print(score_sum_py(pd.factorize(df.page_id)[0], df.score))
buffer += ser.read(1)
f(*args, **kwargs)
Base.prepare()
f.write(tempfile.read())
plt.show()
a = TestC()
os.rename(renamee, pre + new_extension)
max_index = max_sub[0]
raise ValidationError(self.errors)
setup.py
lst.append(x)
[True, False]
t.show()
ax.set_yticks(np.arange(nba_sort.shape[0]) + 0.5, minor=False)
f.readinto(data)
root = Tkinter.Tk()
[x[0] for x in groupby(L)]
obj.__dict__
fig = plt.figure(figsize=(1, 1), dpi=400)
module_a.py
fake_restaurant.delete()
user = request.user
mpl.rcParams.update(saved_state)
process = subprocess.Popen(cmd, shell=True)
self.b.pack()
sum(map(str.islower, string))
p.cpu_percent(interval=1)
np.bincount(diag_idx.ravel(), weights=a.ravel())
plt.clf()
data = [str(round(float(fractions.Fraction(x)), 2)) for x in data]
bokeh.io.show(p)
my_string = my_string.translate(trans)
d = {}
Potion.all_potions.append(self)
plt.subplot(122)
sum(data) / n
result = list(chain.from_iterable(pattern.split(w) for w in input_list))
Py_Finalize()
fig, ax = plt.subplots()
np.full((10, 5), list(vals))
[x for x in k if x in kDash]
cv2.waitKey(0)
temp = temp[1:]
print(os.__file__)
print(np.squeeze(a))
print(s.format(*x))
np.random.shuffle(ages)
file.close()
plt.ylim(0.5, 4)
candlestick(plt.gca(), quotes)
grid.flat[np.flatnonzero(mask)[second_mask]] = 100
leadingzerocounts[0] += 4
new_df = old_df[list_of_columns_names]
data = data.astype(dt)
response.url
x = np.arange(10)
server.start()
self.obj = obj
int(Decimal(2))
print((f.__name__, timeit.timeit(f, number=1000)))
k[v.index(max(v))]
x = [k] * len(v)
ax = fig.add_subplot(2, 1, 1)
f.truncate()
msg.attach(part2)
shutil.copyfileobj(source, target)
time.localtime(time.time())[2]
web.input(**my_args)
id = db.Column(db.Integer, primary_key=True)
print(response.read())
[1, 2] == sorted([2, 1])
f(0, 1, 0)
print(current_credentials.access_key)
getattr(mod, class_name)
line(res, vertices[0][0], vertices[1][0], color, 5)
Y[X == X.max(axis=0)].reshape(X.max(axis=0).shape)
pdb.set_trace()
[2.29, 47.77]
[2.01, 57.28]
[2.61, 66.82]
[2.49, 85.85]
[2.55, 104.9]
[2.65, 114.47]
sess = tf.Session()
QtGui.QMainWindow.__init__(self, parent)
df = pd.read_csv(data, delim_whitespace=True)
root.mainloop()
not bool
ch.flush()
encapsulated()
deletemylist[:n]
sys.stdout = capturer
procs[-1].start()
p.stdout.close()
np.testing.assert_allclose(res1, res2)
print(i, d[i])
ax.autoscale(False)
self.statusitem.setHighlightMode_(1)
self.table = QtGui.QTableView(self)
os.path.join(directory, filename)
A = np.delete(A, 2, 1)
os._exit(1)
event.Skip()
self.func = func
new_index = random.randrange(0, len(data))
socketIO.wait(seconds=1)
ssh = paramiko.SSHClient()
ax1 = fig.add_subplot(121)
self.client.connect(self.host, self.port)
Py_DECREF(mylist)
HiddenFormMixin.__init__(self, *args, **kwargs)
self._request = urllib.request.urlopen(url)
plt.show()
student.courses[c.title] = form[c.title].data
proc.kill()
mylist.append((pair[0], pair[1]))
print(start.date())
r.wait()
pd.DataFrame(a).fillna(0)
d[key] = value / 2
self.__dict__.update(*args, **kwargs)
print(repr(p.value))
min(min(p[1:]) for p in PlayerList)
solve([sigma * (y - x), x * (rho - z) - y, x * y - beta * z], [x, y, z])
b = [(i + 1) for i, (x, y) in enumerate(zip(s, s[1:])) if y > x + 2]
subplot(4, 1, 4)
f.seek(max(fsize - 1024, 0), 0)
tile_frame.pack()
time.sleep(0.5)
time.sleep(1)
print(type(img_ipl))
x += 1
repr(self.dictify())
print(json.dumps(data, sort_keys=True, indent=4))
a.seek(0)
a = [1, 2]
itemgetter(*wanted_keys)(my_dict)
np.random.seed(0)
print(map(itemgetter(1), g))
get_key(d, 2)
do_something_else()
print(p.stdout.read())
x[1:4:2, 1:4:2]
self.show()
st.norm.cdf(1.64)
ax.set_xticks(np.arange(n) - 0.5)
map(itemgetter(0), sorted(list(dct.items()), key=itemgetter(1), reverse=True))
pprint(combine(l))
opener = urllib.request.build_opener(urllib.request.HTTPHandler)
s = fp.read()
client.server_receive_file(binary_data)
func(**args)
result = db.engine.execute(sql)
r.raw.read(10)
self.items = set(items)
L = [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 2, 2, 2]
biglist1.sort(key=(operator.itemgetter(2), operator.itemgetter(0)))
all(x == items[0] for x in items)
np.where(A > 50)
ax.cla()
pl.show()
s.listen(5)
self.dialog.setFocusPolicy(QtCore.Qt.StrongFocus)
graph = facebook.GraphAPI(ACCESS_TOKEN)
dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)
outputStream.close()
response = requests.get(url, stream=True)
time.sleep(0.1)
time.sleep(1)
hashlib.sha1(s).hexdigest()
biglist[:] = newlist
c.f(2)
plt.xticks([0.4, 0.14, 0.2, 0.2], fontsize=50)
proc.communicate()
{i: l[sum(ind[:i - 1]):sum(ind[:i - 1]) + i] for i in ind}
c.bin
[tag for tag in BeautifulSoup(doc, parseOnlyThese=links)]
self.typename = typename
time.sleep(0.05)
print(url)
loop2()
fig.colorbar(surf, shrink=0.5, aspect=5)
plt.imshow(np.dstack([im, im, im]))
sys.stdout.flush()
new_extpost.save()
self.__dict__[key] = value
fig = pyplot.figure()
a.tostring()
self.i = 1
L.sort(key=lambda x: map(lower_if_possible, x))
time.sleep(5)
turtle.getscreen()._root.mainloop()
wdiplay(img)
your_dict[x]
goodrows.append(row)
int(time.mktime(d.timetuple())) * 1000
parser.add_option_group(group)
uniq.view(data.dtype).reshape(-1, data.shape[1])
sys.exit(0)
self.get_full_name()
logger = logging.getLogger(__name__)
some_module.classinstance = MyClass()
run()
self.client.disconnect()
self._x = value
int_list = [int(i) for i in line.split()]
print(filecmp(sys.argv[1], sys.argv[2]))
self.particles.extend(next(f))
str(lst[0]), lst[1:]
auth.set_access_token(access_token, access_secret)
t.ix[0], t.ix[1] = t.ix[1], t.ix[0]
cj = cookielib.LWPCookieJar()
log(msg, x=5, y=6)
d[k] = v
tfidf[0:1]
ax4.xaxis.set_visible(False)
logging.basicConfig(level=log_level)
[np.mean(model.trace(t).gettrace()) for t in timesteps]
list[i] += 2
show_log_button.Bind(wx.EVT_BUTTON, self._show_log)
conn.close()
plt.yticks(x, x)
xs = np.arange(512)
inner_lst.append(item)
app = web.application(urls, globals())
dc.DrawBitmap(self.bmp, 0, 0, True)
print(line_intersection((A, B), (C, D)))
dill.dumps(lambdified_expr)
print([(val + [i]) for i, val in enumerate(A, 1)])
clf.fit(X[outer_train], Z[outer_train])
listy[2].append(1)
ifaces
root = Tk()
doSomething(x)
data = f.read()
out.writelines(lines)
self._thread.close()
driver = webdriver.Firefox(firefox_profile=profile)
sys.path.insert(0, basePath)
listNew.extend([element, element])
list(set(neighbors))
self.filter(is_vegetarian=True)
L = [([0] * 10) for i in range(10)]
student.save()
client = paramiko.SSHClient()
app = QtGui.QApplication(sys.argv)
np.piecewise(x, conds, funcs)
plt.figure(2)
print(pop_list(nodes, 5, node_list))
sorted(list(s2))
print(list(d.values()))
raise UnwindStack(lambda : _addup(n))
os.stat(path)
self.response.write(template.render())
df[df.columns[5:][ridx]]
os.rename(oldname, newname)
tree = et.fromstring(sxml)
data = [(1, 2), (40, 2), (9, 80)]
cv2.circle(mask, (100, 70), 25, 0, -1)
writer = csv.writer(fout)
f.close()
sum(zip(a, a[::-1]), ())[:len(a)]
raise MyCustomException(str(e))
time.sleep(10)
aDict[key] = value
list(map(func, itertools.zip_longest(*sequences)))
print(b.shape)
newList.append((oldList[i + 1][0], oldList[i][1]))
self.table.setModel(model)
[x.count for x in list(a.keys())]
connection = pika.BlockingConnection()
[(x * 2) for x in L]
hex(chars[0])
np.abs(a - b) <= atol + rtol * np.abs(b)
logger.setLevel(logging.DEBUG)
time.sleep(1)
fig = plt.figure()
l.save()
itertools.chain(do_something(), do_something_else())
mlab.show()
canvas.PrepareDC(dc)
form.save()
self.allClasses.append(instance)
p.stdin.close()
data = sys.stdin.readlines()
v[value].append(key)
platform.release()
data = infile.read()
list[idx] = item
[0, 0, 0, 17, 0, 0, 0, 0, 0, 0, 0, 40, 0],
sum(map(operator.mul, topo[:-1], topo[1:]))
os.remove(small)
mask = (data_with_zeros.a == 0) & (data_with_zeros.b == 0)
self.orange_button.Bind(wx.EVT_BUTTON, self.orange_button_click)
soup = BeautifulSoup(html_to_parse)
plot_graph1()
lst[-1] += st[:left]
line = p.stdout.readline()
print(mystring[0])
db = SQLAlchemy(app)
n * s + m * s == (n + m) * s
id(a[0]), id(a[1])
set(sample_generator(10000)) ^ set(range(10000))
np.array(map(lambda x: round(x) - 1, result), dtype=np.uint64)
result = [[(a * b) for a, b in zip(i, j)] for i, j in zip(list1, list2)]
self.numbers.append(self)
thrd2.start()
nx.draw(G)
zip_ref.close()
result = base64.b64decode(body)
expense.tags.add(*self.tags.all())
len(l)
sys.stdin.readline()
a, b = result
scipy.__version__
dict((k.lower(), lower_keys(v)) for k, v in x.items())
df.where(m, n, axis=1)
a = np.arange(1, 100000.0, dtype=float)
fig = plt.figure(figsize=plt.figaspect(1))
im2.set_data([], [])
new_list.append(x + y)
G.add_edges_from([(x, y) for x in L1 for y in L2])
os.makedirs(tmp)
f()
win.show_all()
df = df[cols]
fig, ax = plt.subplots()
ax.plot(list(range(1024)))
t.start()
pprint(data)
soup = BeautifulSoup(text)
fh.close()
response.close()
lst[i:i + 2] = [nxt, cur]
k = [(ord(x.upper()) - 64) for x in l]
outfile.write(line)
key = models.CharField(max_length=240, db_index=True)
im = np.array(first_subreg * 255, dtype=np.uint8)
usleep(100)
(y != y.shift()).cumsum()
list(int_filter(items))
ax1.set_ylim(*np.log10(olim))
img.show()
PLT.axis([x.min(), x.max(), y.min(), y.max()])
t.seek(0)
self.frame.Show(True)
menu.show_all()
a + b[i:]
self.image = ImageTk.PhotoImage(self.photo)
new_list.append(intermediate_dict[i])
count = len(total) - np.count_nonzero(sum)
os.remove(filename4)
f.seek(0)
shutil.rmtree(tmpdir)
dist = np.abs(X[:, (np.newaxis)] - Y)
print([int(x) for x in a[1:]])
data = cgi.FieldStorage()
results = cursor.fetchone()
d = datetime.date(year=1940, month=1, day=1).year
a2b_hex()
self.assertAlmostEqual(em(1, 1), 0.6765, 4)
x = df.reset_index()
foo[1:2]
print(tokenize.untokenize([(toktype, tokval)]))
axes.set_xticks([])
show()
bob4.save()
bob5.save()
bob6.save()
{{(object | getattribute): field}}
words = line.split()
p.start()
plt.subplot(2, 1, 1)
c.save()
A = array([[0, 1, 2], [0, 2, 0]])
ax0a.plot(x, y)
{{record.c}}, {{record.e}}
s = random.randint(0, n - 1) + 1
get()
decorated.sort(key=lambda v: (v[1], -v[2]))
s.order()
X_train = np.random.randn(6, 2, 2)
x = np.cumsum(np.random.random(1000) - 0.5)
dict((k, vs[x]) for k, vs in self.O.items())
pool = Pool()
readfile.close()
nzsum = mat[ixs[nzmask]].sum(axis=0)
self.gzfile = gzip.open(filename)
datetime.strptime(time1, format)
ax.autoscale_view()
parser.close()
f.close()
df[col] = X[:, (i)]
scipy.stats.norm(0, 1)
psycopg2.extensions.register_type(psycopg2.extensions.UNICODEARRAY)
print(x[:n])
instance = getattr(modul, class_name)()
[1, 20] in a.tolist()
lst.append(arg)
np.random.seed(1977)
cur.execute(query)
ans.append(list(cur_set))
msg.attach(body)
[[[2, 4, 6], [1, 4, 7]]]
cursor.execute(query, data)
out.reshape(np.asarray(shp) * N)
screen.fill(pygame.Color(255, 255, 255))
type(_)
[2.0, 2.0017]
self.view.setModel(self.model)
out_queue.put(test)
root.columnconfigure(0, weight=1)
dff.dropna(thresh=len(dff) - 2, axis=1)
set(a).intersection(b)
pd.Series(a1).isin(a2).any()
output.write(line)
raise Exception()
pp(list(zip(*grid)))
days = (start + timedelta(days=i) for i in range((end - start).days + 1))
time.sleep(10)
value.update((key, 0) for key in all_second_keys if key not in value)
self.text = tk.Text(self)
indices[i] += 1
ax2.imshow(field2, cmap=plt.cm.YlGn, vmin=_min, vmax=_max)
sys.settrace(self.oldtrace)
ax.set_ylim([-0.1, 1.1])
allnames().visit(t)
{b.pop(0): b.pop(0) for _ in range(1)}
string[:idx if idx != -1 else len(string)]
pylab.show()
stopButton.pack()
output.setparams(data[0][0])
df
fig, ax = plt.subplots()
[sum(x) for x in zip(*myTuples)]
YarnLogger.setup_logger()
plt.plot(X, Y, lw=0)
print(a, b, c, d)
s.listen(1)
np.column_stack((unq_x, avg_y, std_y))
df.iloc[df.index.get_loc(window_stop_row.name)]
c = np.ones((2, 6))
sorted(set(a))[-2]
list(range(5)) + list(range(10, 20))
contourf(x, y, H1, levels1, cmap=cmap_nonlin1)
grad * C * tf.transpose(Ainv)
plt.colorbar()
print(x)
resp = requests.get(url=url, params=params)
results = pbex.run()
df = pd.concat(valid(chunks))
model = models.Progress
1.0 * sum(i * w[i] for i in xx & yy) / sum(i * w[i] for i in x)
od.setdefault(a, []).append(b)
object() == object()
cv2.imwrite(face_file_name, sub_face)
x + 2
array = [LoL[i][j] for i, j in product(list(range(*r)), list(range(*s)))]
datalisten_thread.start()
abs((d2 - d1).days)
os.makedirs(dir)
self._value
tk.Tk.__init__(self)
patch_jedi()
source._get_numeric_data()
list(map(lambda x: False if x == 0 or x == 1 else True, map(int, lst)))
s = socket.socket()
b = [(ctr[frozenset(x)] == 1) for x in a]
dt.fit(df.ix[:, :2], df.dv)
x.g(2)
B[:, :, (1)] = 1
{file: any(file.endswith(ext) for ext in extensions) for file in files}
token.get_access_token(uri.query)
plt.suptitle(date)
raise_exception()
pool = multiprocessing.Pool(processes=count)
print(dict(d))
plt.cm.RdYlGn._segmentdata
out = np.split(sidx, np.nonzero(sorted_ids[1:] > sorted_ids[:-1])[0] + 1)
myseries_one.iloc[0:2]
fig = plt.figure()
delta = datetime.timedelta(days=1)
yaml.dump(data, stream, OrderedDumper, **kwds)
list(range(*args))
resp = client.service.Execute(req)
wav_file.close()
p.communicate()
mask = mahotas.dilate(mask, np.ones((48, 24)))
sleep(1)
hmag = np.array(hmag)
python - v
os.remove(path)
sys.path.remove(rundir)
conn.sendall(error)
df1.fillna(1).sort(axis=1).eq(df2.fillna(1).sort(axis=1)).all().all()
fig.colorbar(coll)
[snip]
print(x[y][i][z])
n.getme()
uo_fclose(hFile)
x = [6, 7, 8, 9, 10, 11, 12]
float(n) / (1 << int(log(n, 2)))
pylab.ylim(ymin=0)
time.sleep(1.0)
x = np.array([0, 0, 1, 1, 2, 2])
print(settings.myList[0])
tk.Tk.__init__(self)
f()
ax2.set_ylim([np.amin(image[:, (5), (5)]), np.amax(image[:, (5), (5)])])
plt.imshow(skel)
len(get_file_contents(filename))
True
list(chain(*zip(l, map(partial(add, 1), l))))
data.__dict__.update(json.parse(data))
cursor.close()
f(a, b)
G.add_path([2, 4, 0, 5])
attr(*args, **kwargs)
reactor.do(thing2)
new_data = new_data.reshape((4, 5, 10))
test()
msg.send()
ax.set_xticklabels(lab)
series = series.astype(float)
print(X[0], Y[0], calc_fast(X[0], Y[0]))
self.transitions = transitions
tornado.ioloop.IOLoop.instance().add_callback(self.loop)
sys.stdout.flush()
l[0], l[-1]
fig.autofmt_xdate()
ax = plt.gca()
df.iloc[:, 1:].idxmax(axis=1)
fig, ax = plt.subplots()
str_list = list(filter(len, str_list))
print(objfunc([1.0, 0.0]))
df = pd.DataFrame(data=d)
bool({}) == False
a, b = b, a + b
raise unittest.SkipTest(message)
platform.python_compiler()
numpy.linalg.norm(a - b)
print((len(al), al.get_alignment_length()))
getattr(obj, self.name)
main()
zip(list(range(len(l) - 1, -1, -1)), l)
f(*args, **kwargs)
print(ruamel.yaml.dump(data, allow_unicode=True))
sleep(1)
aList.append([xc, yc])
True
plt.plot(t, f(t))
output = PdfFileWriter()
r = random.sample(list(range(len(x))), 10)
msg.attach(image)
self._list.append(o)
sys.stdout.flush()
sherr.pop(0)
_api_client.ExecuteBatch(batch_request, cells.GetBatchLink().href)
step4.communicate()[0]
{GOOGLE_APP_ENGINE} / dev_appserver.py
print(is_true(x) or is_false(x))
session = Session(key=seshKey)
result = [dict(zip(fields, row)) for row in cursor.fetchall()]
[f(x, fixed) for x in srclist]
print(link.text)
df.columns
fig = plt.figure()
[(x + Ly[i]) for i, x in enumerate(Lx)]
stuff()
n = n + 1
atexit.register(__terminate)
self.browserHandle = webdriver.Firefox(firefoxProfile)
pylab.show()
sys.exit(not result.wasSuccessful())
binascii.unhexlify(x)
id = Column(Integer, primary_key=True)
nodes.CallBlock(call, [], [], [])
output.append(char)
df.sample(frac=1)
x1 = np.linspace(0, 0.4, 100)
shutil.copyfile(source, destination)
word in wordList
fig = plt.figure()
self.ax.relim()
y[0]
elem.clear()
app.exec_()
d = a[1::2]
df1 = pd.DataFrame([dict(x) for x in df.word_prob_pair])
app.register_blueprint(feed)
print(type(element))
s.loc[~np.isfinite(s) & s.notnull()] = np.nan
myFunc(False, False, True)
canvas.setPageSize(width, height)
chimpchat.shutdown()
ssh_client = paramiko.SSHClient()
print((i, key, value))
session.flush()
app = Flask(__name__)
{k: v for d in dicts for k, v in list(d.items())}
layout = QtGui.QVBoxLayout()
fun(ctypes.byref(indata), 5, 6, ctypes.byref(outdata))
self.picture = QtGui.QPixmap(imagePath)
s = pd.Series(np.arange(4) ** 2, index=np.arange(4))
tree = Tree()
fig, axes = plt.subplots(nrows=4, ncols=4)
list(itertools.accumulate(nums))
data.append([c.text for c in row.getchildren()])
child.show()
print(calendar.timegm(utc_dt.timetuple()))
self.panel = wx.Panel(self, wx.ID_ANY)
user = models.OneToOneField(User)
first_list.append(ls[0])
app = Flask(__name__)
print([myround(x) for x in list_num])
pool.join()
scipy.nanmean(b_padded.reshape(-1, R), axis=1)
text = in_file.read()
cnxn.close()
print(Bar().x)
classifier.fit(X_train, y_train)
new_list = []
type(dates[0]) == pandas.tslib.Timestamp
df = df.append(new_rows).sort_index().reset_index(drop=True)
window.show()
a = Counter(your_list)
axs[0].xaxis.set_major_locator(x_major_lct)
line(src, Q4, Q1, Scalar(0, 0, 255), 1, CV_AA, 0)
wn.synsets(word)
reader = csv.DictReader(fh, fieldnames=header)
bar()
os.symlink(target, link_name)
queryset = Simple.objects.all()
fig = plt.figure(figsize=(10, 10))
print(sys.path)
self.data = numpy.delete(self.data, i, 0)
Process(target=loop_b).start()
np.testing.assert_allclose([1], [[1]])
data += np.random.normal(size=data.shape)
call_quack()
a = np.frombuffer(ArrayType.from_address(addr))
df = df.dropna()
dist = np.sqrt(dist)
np.median([0, 1, np.inf])
vdisplay.start()
myqserver.delete_current()
frame = cv2.flip(frame, 0)
leng(s)
multiprocessing.freeze_support()
[i - 1, i + 1]
G = nx.Graph()
plt.register_cmap(cmap=newcmap)
b = fig2.add_subplot(2, 2, i)
int_list = models.CommaSeparatedIntegerField(max_length=200)
Py_DECREF(newobj)
sum(100.0 * (x[1:] - x[:-1] ** 2.0) ** 2.0 + (1 - x[:-1]) ** 2.0)
tornado.ioloop.IOLoop.instance().start()
parser = argparse.ArgumentParser()
plt.plot(x, y)
print(df)
output_notebook()
models.IntegerField.__init__(self, verbose_name, name, **kwargs)
print(tab[i])
permutations(string_copy, step + 1)
self.delta = wx.Point(0, 0)
Matrix.map(lambda a, b, **kw: a - b, self, other)
app.config.from_pyfile(config, silent=True)
self.username
np.triu(out)
os.makedirs(dir)
draw = ImageDraw.Draw(image)
glLoadIdentity()
1 / 2
ax2 = ax1.twinx()
result[i] = func1d(x)
df = pd.Dataframe(dict)
self.mthread = QThread()
self.get(timeout=1000)
cursor.execute(sql, [this_year])
reactor.run()
time.sleep(1)
fig = plt.figure()
max(lo, min(hi, x))
list(grpname.values())
foo()
self.file.close()
allkey.append(key)
l.append(hash((x, y)))
hash(self.a) ^ hash(self.b)
print(myForm.__dict__)
fig.canvas.blit(ax.bbox)
cls.static_method_to_call()
wb.Save()
temp = [(t.count(str(i)) / len(x)) for i in range(1, 5)]
df = pd.DataFrame(np.random.randn(10, 6))
app.register_blueprint(mod)
response
fig, ax1 = plt.subplots()
a = np.random.rand(size, size)
d += timedelta(weeks=4)
isinstance(True, int)
root.mainloop()
array(ranked)
transport.accept()
print(df1.head())
df[1][df[1] == 4]
ax.plot(data1)
any(x in sb for x in a)
self._lock.__enter__()
f()
plt.xlim((0, AUC.shape[1]))
ax2.set_xticks(numpy.arange(x1 - 1, x2 + 1, 0.5))
deleted[id]
df = pd.DataFrame(dict(A=np.arange(70)), tidx)
ax = plt.axes(xlim=(0, 2), ylim=(-2, 2))
smtp.starttls()
lexobj
r = requests.post(url, files=files)
do_something()
foo()
t.render(form=MyForm())
l.append(element)
ax.set_axis_off()
squared = lambda li: map(lambda x: x * x, li)
diff = [(v[0] - v[1]) for v in zip(a[0:-1], a[1:])]
m.group(2)
test(100, 500, 11)
df.describe()
worker.work()
p.start()
parser.parse_args()
f(*args, **kwargs)
sys.exit(1)
platform()
f.close()
NULL
pool.join()
c.showPage()
sheet1.cell(row=row, column=col).value = sheet.cell_value(row, col)
a.transpose(0, 2, 1)
self.driver.get(response.url)
print(indent(text, 4))
avg = avg.replace(microsecond=0)
os.remove(fl)
self.axes.clear()
l = literal_eval(s)
[1, 1, 0, 0]
np.hstack(np.where(a == a.max()))
time.sleep(1)
worksheet1.set_column(1, 1, 25)
PROJECT_ROOT = os.path.dirname(os.path.abspath(__file__))
a.bar
data = np.fromfile(file, dtype=dt)
list(league.items())[0]
raise SystemExit(0)
QtCore.QAbstractTableModel.__init__(self, parent)
str(bar)
time.sleep(0.1)
logging.Formatter.converter = time.localtime
print(firstLine[0], firstline[1], sum(int(x[2]) for x in lines))
print([dict(zip(reader[0], x)) for x in reader])
self.lock.release()
df.ix[dates]
form.populate_obj(student_courses)
plt.show()
result.append(line.upper())
y = np.zeros((yt, xt))
x = np.random.random((100, 100, 100))
np.array([[array2 for _ in row] for row in array1.tolist()])
targetFile.write(contents)
time.sleep(5)
fib(n - 2) + fib(n - 1)
plt.subplot(212)
bool(6)
plt.clabel(CS, inline=1, fontsize=10, manual=manual_locations)
max_idx, max_val = max(enumerate(l), key=operator.itemgetter(1))
plt.show()
float_in[0:16] = list(arr_in[0:16])
plt.show()
b[-1]
mp.scatter(xvals[i], yvals[i], s=rvals[i])
plt.xlim(xmin, xmax)
writer.writerow(row)
s.indices(0)
__init__.py
print((i, el))
self.run()
dosomething()
d = defaultdict(list)
HttpResponseRedirect(redirect_to)
f.__qualname__
stats.f_oneway(a, b)
root.mainloop()
op.outputs[0] * tf.transpose(tf.matrix_inverse(op.inputs[0]))
mail.quit()
print(d[p])
a.set_xticklabels([])
self.e.pack()
screen.keypad(1)
cv2.drawContours(imgBWcopy, contours, idx, (0, 0, 0), -1)
db.close()
f(v, w)
driver.maximize_window()
plt.show()
groups[tuple(row[c] for c in key_columns)].append(i)
dbx.files_upload(f.read(), file_to)
print((repr(group[0]), len(group)))
df.columns[pd.isnull(df).sum() > 0].tolist()
foo()
dict_writer.writeheader()
r = tk.Tk()
sys.exit(app.exec_())
pl.hist(h, normed=True)
np.cumsum(cols, out=cols)
numpy.zeros(height, width)
any(c.isdigit() for c in value)
logger = logging.getLogger(__name__)
pygame.display.update()
print(MyClass.bar)
os.makedirs(mydir)
(p0[0] - p1[0]) ** 2 + (p0[1] - p1[1]) ** 2
newData.append((255, 255, 255, 0))
1, 1, 1
new_list.append(obj)
print(repr(tokzr_WORD(inp1)))
links.append((url, rule.endpoint))
print(delta.days)
(x for x in data if func(x))
name = models.CharField(max_length=50)
sample_object.save()
lines = random.sample(all_lines, 40)
[(2 ** i) for i in range(n)]
result = client.service.methodName(Inputs)
True
print(df)
ax.set_ylim(50, 0)
os.path.walk(your_dir, print_it, 0)
y = np.zeros(data.shape[1:], data.dtype)
b = np.array([1, 1])
plt.show(block=True)
ax2.set_xbound(ax1.get_xbound())
ax2 = plt.subplot2grid((6, 1), (1, 0))
pool.close()
np.argwhere(np.diff(bool_array)).squeeze()
urllib.request.install_opener(opener)
setup(ext_modules=[module])
numpy.roots([2, -6])
atexit.register(interrupt)
b = np.in1d(np.arange(n), np.random.randint(0, n, n))
plt.plot(t, y[0])
sns.set(font_scale=5)
response.iter_lines(chunk_size=1)
time.sleep(self.interval)
a.shape
print(app_info.get_name(), app_info.get_executable(), app_info.get_icon())
sys.exit(11)
d[sku] = price[0]
redirect(rp[:-1])
(x + y) % 12
dynmodule.load(module_code)
[r.pop(1) for r in L]
next(i for i, d in enumerate(lod) if 1 in d)
fig, ax = plt.subplots()
plt.figure()
{e for l in lst for e in l}
ax.imshow(gray_data, cmap=cm.gray)
self._foo
attrs.update({(1): 1})
[k for item in map(lambda x: [g(x) for g in listFunc], ListArg) for k in item]
b2.pack()
help(property)
print(os.getcwd())
(s - np.mean(s)) / np.std(s)
m.drawcoastlines()
[(a, b) for a in res for b in B if a.search(b)]
dis.dis(method2)
user = models.ForeignKey(User)
sub_df.columns = list(range(12))
-(x + a) + b / (1 + np.exp(-(x + c)))
writer.writerow(headers)
isinstance(object, type)
s = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
A[~np.isnan(A)]
Py_Initialize()
gtk.Entry.do_key_press_event(self, event)
fd.close()
second_largest([1, 1, 1, 1, 1, 2])
s.plot(ax=ax)
app = QApplication(sys.argv)
self.setGeometry(800, 400, 250, 80)
(t for t in tuples if all(f(t) for f in filters))
ax2 = plt.subplot(gs[1])
main()
df.stack().idxmax()
b[:, (0), (0)] = t
print(pd.DataFrame(com.convert_robj(r_DF)))
df.C = a
out[mask] = B[:, ::-1][mask[:, ::-1]]
main()
df.mask(outliers_low, down_quantiles, axis=1)
obj.__class__.__dict__[2]
r = requests.get(url, cookies=cookies)
[NOSE_XUNIT_FILE]
np.isnan(a[2])
d1 + timedelta(days=-1)
NULL
s.update(list(fus_s.keys()))
newList = list(convert(oldList))
l1.append([x[1] for x in zip(pattern, facs) if x[0]])
jobs.apply_async()
11
self.edit1 = QLineEdit()
date(year, month, day)
testFunc()
monkey.patch_all()
data = {k.strip(): [fitem(v)] for k, v in list(reader.next().items())}
m = np.ones(len(a), dtype=bool)
ax = plt.gca()
pygame.init()
objects.sort(key=getScore)
observer.start()
print(cell.text_content())
app.debug = True
sorted(student_tuples, key=student_key)
self.panel.SetBackgroundColour(wx.Colour(250, 250, 250))
log = logging.getLogger()
auth.load_session()
np.matlib.identity(n)
df
s.iloc[s.first_valid_index():]
VAR1
quicksort(array, i + 1, end)
print(m.group(0))
result.append(int(item))
name = models.CharField(max_length=1024, blank=True)
b = list(a)
cj = cookielib.CookieJar()
[syndication]
ax2.yaxis.set_major_formatter(ticks_y)
turtle.forward(200)
output = popen.stdout.read()
t = datetime.datetime.now()
shutil.get_terminal_size((80, 20))
f.close()
df.dtypes
driver.set_page_load_timeout(10)
ax = pylab.gca()
zip.extractall()
self.SetSizer(grid_sizer_1)
app.MainLoop()
[item for item in full_list if not omit & set(item)]
f()
a.__dict__
pprint.pprint(data)
product = models.ForeignKey(Product)
my_list = list(range(10))
urllib.request.install_opener(opener)
found = any(matched(line) for line in file)
reader = csv.reader(in_file)
sys.stdout = sys.__stdout__
sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPIDLE, after_idle_sec)
__init__.py
signals.pre_save.connect(User.pre_save, sender=User)
c[:len(b)] += b
[mylist.__setitem__(i, thing) for i, thing in enumerate(mylist)]
args = parser.parse_args()
PyArray_ENABLEFLAGS(arr, np.NPY_OWNDATA)
self.layout.addWidget(self.progressBar)
out = np.empty(len(a), dtype=object)
XXXX
df = pd.concat([df.iloc[:, :4], df.iloc[:, 4:]]).reset_index()
ax.set_ylim(-2, 2)
run.py
content = pdf.getPage(1).extractText()
func(*args, **kwargs)
self.tk.config(menu=self.blank_menu)
b = a.ravel()
print(df.columns[2:5])
time.sleep(1)
args._get_kwargs()
L[i:i + 2] = L[i + 1:i - 1:-1]
frame.Show()
p.wait()
print(item)
(match.group(0) for match in sentence.finditer(text))
data = [rndseries, rndseries, rndseries, rndseries, rndseries, rndseries]
main()
termios.tcsetattr(fd, termios.TCSANOW, attrs)
sq_sum.append((A ** 2).sum(axis=1).mean())
print(line)
np.random.shuffle(arr)
[x for x in string_list if x.isdigit()]
a = np.ones(2)
self.new_names[name] = value
p.get_lines()[0].get_ydata()
print(u.__dict__)
b = array([1, 4, 5])
list(range(0, 0.4, 0.1))
data = np.fromfile(f, dtype=dtype)
Parent.__init__(self, x, y, z)
set(itertools.chain(l1, l2))
entry.focus()
result
Thread(target=receiving, args=(ser,)).start()
f.seek(-pos, 2)
db.session.commit()
cur.execute(query, my_dict)
self.things.append(0)
client.set_options(headers=headers)
sorted(set(xyz).difference(a))
graph.set_xticks(x)
app = Flask(__name__)
self.columnconfigure(1, weight=0)
plt.plot(np.sin(theta), np.cos(theta))
tk.Tk.__init__(self)
f.write(data)
a = [[0, 0], [0, 0]]
genre_count.sort(ascending=False)
raise ValueError(ret)
processes.append((p, f))
print(ipath[i])
plt.plot(x, i * x + 5 * i)
df.delta.apply(lambda x: x.microseconds)
plot(f, p)
ax2.xaxis.set_major_formatter(ticks_x)
model.add(Dropout(0.5))
m = re.search(pat, t)
im.putpalette(mypalette)
self.sleep(1)
count += 1
sys.stderr = sys.stdout
self.functor(*args, **kwargs)
view_pyc_file(sys.argv[1])
ax4.plot(np.linspace(0, len(xp), len(xp)), xp)
os.path.basename(f)
x = dict.fromkeys(list(range(0, 10)), 0)
do_stuff()
math.cos(_ / 2)
my_array[:, (0)] = my_array[:, (1)]
conn.close()
s = s.strip()
root.grid_rowconfigure(1, weight=1)
raise Exception()
list({frozenset(list(Counter(tup).items())): tup for tup in data}.values())
bisect.bisect_left(dates, datetime.datetime(2007, 1, 6))
print(row)
days, hours, minutes, seconds
set(list1) & set(compSet)
logger.addHandler(fileHandler)
manager.start()
total += 1
ax.set_yticks(np.arange(-0.5, height, 1), minor=True)
self.append([])
gray = cv2.cvtColor(image_src, cv2.COLOR_BGR2GRAY)
print(line_count)
combine([9, 8], [2, 1])
myLists.append([122284.8, 111161.8, 106581.1, 141419.9])
self.Show()
pfile.truncate()
req = urllib.request.Request(url, data)
s.sort()
sock.close()
cursor.execute(qry)
self.timeout = timeout
interpreter.process_page(page)
tf.logging.set_verbosity(tf.logging.ERROR)
sum(c, [])
array([0, 1, 1, 2])
self.ax = self.fig.add_subplot(111)
fh.write(text)
f()
self.origstream.flush()
float(2 ** _random_decimal(min_exp, max_exp, 64))
dict(Counter(A).most_common(5))
s = requests.Session()
print(request.error_message)
a_n82_remember_4ever()
len(self._data)
b = random.choice(range(0, a))
body = resp.read()
context_for_rendering_inclusion_tag
bre.close()
c = pymongo.MongoClient()
remote.close()
QtCore.QThread.__init__(self, parent)
datetime.datetime(*t.timetuple()[:-4])
print(hex(i)[2:].zfill(2))
os.path.dirname(os.path.abspath(file))
tf.reduce_sum(x) < 100
collections.deque(itertools.islice(iterator, n))
turtle.left(90)
(recursive_map(f, x) if isinstance(x, tuple) else f(x) for x in it)
cur.execute(sql, (lite.Binary(data),))
tuple(int(entry) for entry in s)
print(G.edge[0][1])
(first_num, first_arr), (second_num, second_arr) = generate_arrangements(data)
os.dup2(0, 2)
dict.__getitem__(self, keys)
type(f)
datetime.datetime(2012, 1, 5, 0, 0, 0),
stats.norm.interval(0.68, loc=mu, scale=sigma / sqrt(N))
stats.normaltest(y)
PyArray_ENABLEFLAGS(arr, np.NPY_OWNDATA)
tf.nn.relu(x + c)
per_column = zip(*per_row)
anotherfunc()
self.left = FibTree(n - 1)
np.array_equal(org_approach(data, reference), vect_approach(data, reference))
fig, axs = plt.subplots(1, 2)
b = collections.OrderedDict(sorted(list(a.items()), key=lambda t: get_key(t[0])))
s.update(list(fus_s.keys()))
sum((a - b) ** 2 for a, b in zip(a, b))
df
func2()
np.column_stack((slope, intercept))
plt.subplot(212)
draw = ImageDraw.Draw(img)
lst.extend(list(range(11, 14)))
ws.run_forever()
sys.exit(0)
token = token_handler.create_token(request, refresh_token=False)
ui.syn()
json.dumps(o)
self.log.removeHandler(self.handler)
self.successors.append(other)
help(math.sin)
root.update()
events.sort(key=lambda x: x[0])
next(key for key, values in list(d.items()) if search_value in values)
self.wrapee = wrapee
rows = iter(csv.reader(file))
np.array(list_).sum(0).prod()
False
f1.close()
driver.switch_to.window(handle)
G.add_edge(1, 2)
listening_socket.listen(backlog)
author = models.CharField(max_length=20)
makeArchive(dirEntries(folder, True), zipname, folder)
print(b.shape)
[x[i:i + chunk_size] for i in range(0, chunks, chunk_size)]
show()
foo.__setitem__(something, bar)
result.reset_index()
data = get_data()
print(df.col.str.split(expand=True))
server.sendmail(fromaddr, toaddrs, message)
lognorm.cdf(x, sigma, 0, mean)
[list(row) for row in zip(*mat)]
print(foo[0:5])
content = f.read()
df
self.auth.username
cluster.setdefault(label, []).append(word)
self.search_list(request, *args, **kwargs)
c = initval
key = lambda x: customlist.index(x)
idx = npi.indices(b, a)
crawler.start()
sys.stdout.write(inp_data)
self.tweet_list.append(json.loads(data))
app.MainLoop()
key = np.array([0, 10])
pygame.init()
G = nx.Graph()
df = pd.concat([df1, df2])
print(i)
data = list(image.getdata())
cym.year, cym.month
print(F.__code__.co_stacksize)
column_widget.show()
print(arr[np.ix_(rows, cols)])
print(matplotlib.colors.rgb2hex(rgb))
KERNEL[1, 1] = 0
app.exec_()
parser = argparse.ArgumentParser()
ax.quiver(x, y, z, u, v, w, length=0.1)
self.b2.pack()
signal.signal(signal.SIGINT, signal.SIG_IGN)
df = pd.DataFrame()
root = tk.Tk()
fig = plt.figure(figsize=(8, 2))
self.assertAlmostEqual(em(2, 1), 0.0584, 4)
c.update(d)
ndata.append([(start + end) / 2.0, np.mean(np.array(within))])
byvalue[x].append(i)
m.indices = (indices - 1) % m.shape[1]
print(filename)
python / path / to / script.py
print(df)
np.issubdtype(float, np.floating)
logger = logging.getLogger(__name__)
time.sleep(0.001)
b = np.array([[4], [5], [6]])
data.append(row)
label_group_bar(ax, data)
r = requests.get(QUERY_URL)
wb = load_workbook(StringIO.StringIO(xlsx))
line = process.stdout.readline()
df = df[df[c].isin(df[c].value_counts()[df[c].value_counts() > m].index)]
c[1, 2]
self.sizer.Add(self.log, 1, wx.EXPAND)
print(func.locals)
regex_compiled.pattern
reducefn(dic1)
pprint(l)
plt.show()
self.file.close()
params = urllib.parse.urlencode(params)
Baz().foo()
l.append(float(rec[col]))
ax.set_xticks(np.arange(nba_sort.shape[1]) + 0.5, minor=False)
p = argparse.ArgumentParser()
b = a + b
{{thing}}
Decimal(1.5).quantize(0, ROUND_HALF_UP)
int(toks[0])
start = urllib.request.urlopen(image_url).read(24)
[0.0, -1.0]
result = a or b or c or default
line = line.strip()
plt.colorbar(p)
list(l)
pylab.hist(A[~np.isnan(A)])
print(p.stdout.read())
soup = BeautifulSoup(urllib.open(url).read())
pool = Pool(processes=4)
plt.show()
[s.split()[:2] for s in strings]
dict.__setitem__(self, key, value)
x = random.random()
pInt[0]
tuple(lst)
f.readline()
x = np.empty((), dtype=object)
name = models.CharField(max_length=200)
app
c.setopt(c.NOBODY, 1)
s.loc[:] = [7, 8]
list(individual(nest))
-24.784805 - 0.927448
print(result.read())
np.cumsum(hist)
output.write(line)
ax = fig.add_subplot(111)
ax.add_patch(arc)
p.join()
[dct for dct in listA if dictA.items() <= dct.items()]
B = np.random.randint(0, 1000, 10000)
print(G.__code__.co_names)
fig = plt.figure()
fig = plt.figure()
f = open(mkstemp()[0])
print([b(5) for b in bases])
cursor.execute(query, params)
df[df.Group.map(df.Group.value_counts().ge(4))]
fig.canvas.draw()
sys.stdout.write(str(time))
sys.stdin.read(1)
[self[i] for i in index]
s.send(query)
print(response.read())
self.d[index].append(value)
float(c[a]) / len(x)
func()
sys.exit(2)
print(indented)
sock.send(data)
s.setDTR(True)
self.ham = dict()
raise ArgumentError(action, msg)
root.overrideredirect(True)
a = [[0, 1], [0, 1]]
print(sys.exc_info()[0])
fig = plt.figure()
fig1 = plt.figure()
result = list(join_unescaped(list_1))
[tuple(y for y in x if y != False) for x in df.to_records()]
nums.insert(index, mean(nums[index - 1], nums[index]))
ax = fig.add_subplot(111)
print(i, line)
conn = listener.accept()
fuse(x, y)
get_nested_list(a[0])
article.save()
grid = [[a, b, c], [d, e, f], [g, h, i]]
painter.drawText(QtCore.QPoint(0, -pen.width()), QtCore.QString(hw[i]))
os.chdir(sys.argv[1])
roi = gray[y1:y2, x1:x2]
array = []
pd.Series(c, u)
pl.plot(x, y)
print(guyGenerator([2, 2, 2, 2, 2], [1, 1, 1, 1, 1]))
y[REPLACE_EVERY_Nth - 1::REPLACE_EVERY_Nth] = REPLACE_WITH
[d[x] for x in a]
signal.alarm(0)
decorator
count[letter] += 1
periodic_task.save()
[dishes[x] for x in crucial if x in dishes]
[random.uniform(low, high) for _ in range(size)]
mylist1.sort(key=sort_order.index)
l = [1, 5, 7]
output.close()
self.cb = self.figure.colorbar(hb)
G = nx.Graph()
l.append(Test(0))
index_list = []
app.add_url_rule(url, view_func=view)
p.stdin.write(data)
gc.get_objects()
print(line)
numpy.set_printoptions(linewidth=160)
self.queue.clear()
sys.exit(ret)
app.exec_()
1, 0, 1, 0, 0, 0, 0, 0, 1
cursor.close()
self.connect((host, 80))
self.start()
t0 = time.time()
x = 4
print((x, y, z))
urllib.request.urlretrieve(link, file_name)
intercepting_func
c = cv2.VideoCapture(0)
[_f for _f in l if _f]
c = pycurl.Curl()
StoppableThread.__init__(self)
layout.addWidget(self.button)
np.add(*np.indices((nrow, ncol)))
print(df)
(datetime.date.today() - date_cand).days
fig, ax = plt.subplots()
DEBUG = False
pylot.draw()
newImage = Image.new(mode, (newWidth, newHeight))
wr.writerow(sheet.row_values(0))
os.unlink(fname)
print(find_eulerian_tour(graph))
w.writerow(a)
server.NOT_DONE_YET
map(list1.__setitem__, indices, list2)
os.remove(f)
compare(a, b)
tag.update()
row_dict[col] = row[i]
df.show()
self.browser.quit()
X.mean(axis=1)
print(repr(object))
print(xml2json.xml2json(s))
print(line)
f(x, (a[x], a[y])), f(y, a[x][0]), f(x, a[x][1])
print(fpp[0])
self.lineedit.selectAll()
script1.py
shout.start()
iso8601(datetime.timedelta(0, 18, 179651))
dumper.represent_dict(iter(data.items()))
b = [[7, 9], [1, 2], [2, 9]]
uchar * uimg
pdb.set_trace()
head[0][0:]
c = Counter(a)
dict(enumerate(df.five.cat.categories))
debuild - us - uc
main()
ts = pd.Series(np.random.randn(6), index=dates)
math.factorial(170)
Category.add(row[1])
next(a)
result = []
ax = f.add_subplot(111, polar=True)
ax.set_xlim(min(x), max(x))
outfile.write(filedata.file.read())
string.ascii_uppercase
mercury.speed(0)
subprocess.popen(command, shell=True)
df.index = list(range(1, n)) + [0] + list(range(n, df.index[-1] + 1))
py.test
parser.parse_args()
self.realnames[name]
NULL
d1.update(b1)
self.line.set_color(self.get_color())
True
c()
b[..., ([2, 2])]
ax = df.plot()
unittest.TextTestRunner(verbosity=2).run(fullSuite)
ts = time.time()
m.fit(X / np.std(X, 0), y)
plt.figure()
self.coconut = coconut
sum(islice(count(1, step=4), 101, 200))
print(d[4])
plt.xlim(0, 20 + i)
dc.SetPen(wx.Pen(self.GetForegroundColour()))
layout.addWidget(self.listview)
x = np.random.random((5000, 5000)) - 0.5
(datetime.date.today() - date_cand.date()).days
process.join()
g.add_edge(6, 7)
self.move(global_point - QtCore.QPoint(self.width(), 0))
pos = pygame.mouse.get_pos()
a = np.zeros((5, 10))
P.figure()
curses.setsyx(-1, -1)
plt.ylim(0, 1)
a1 = np.arange(1, 11)
res.update({k: v for k, v in list(b.items()) if k not in a})
plt.tricontourf(x, y, T.triangles, v)
self.lc = wx.ListCtrl(self, style=wx.LC_REPORT)
now = datetime.now(mytz)
fh.seek(0, os.SEEK_END)
start = end + 1
print(n)
[processed(x) for x in input_array]
base.py
logmod.fit(x, y)
add(*x)
df
mylist = [True, True, False]
print(df)
B.__init__(self)
plot_bars(x_bar, y_bar, angle, ax)
fig1 = plt.figure()
conn.execute(penguin)
abort(401)
sys.stdout = self.stdout
ab[s][np.concatenate(([True], t[1:] != t[:-1]))]
ax = fig.add_subplot(111)
self.strategies = strategies
User.objects.bulk_create(iter(users_iterator()))
doctest.testmod()
y = np.cumsum(x, dtype=np.intp)
np.sin(n * np.pi * x) * g(x)
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
plt.subplot(2, 1, 2)
self.y2 += mh
self.parser.parse_args(namespace=self)
print(xmlFile.toprettyxml())
logger = logging.getLogger(__name__)
proc.wait()
s.mean(level=1)
email.send()
Tup()[1]
itemDict.append(r)
startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
log.close()
print(nltk.tokenize.WordPunctTokenizer().tokenize(german))
win.add(notebook)
orig.update(extra)
result = np.reshape(result, (frames_per_buffer, 2))
now = datetime.now()
[{next(cyc): y for y in x} for x in v]
df.applymap(list).sum(1).apply(set)
conn = boto.connect_ec2()
serializer = AvatarSerializer(data=request.DATA, files=request.FILES)
{{form.as_p}}
pandas2ri.activate()
spawn()
someClass.start()
ss.expon.fit(data, floc=0)
m = np.zeros(size, dtype=np.uint8)
min(timeit.repeat(lambda : {k: v for k, v in zip(keys, values)}))
doubles[x] = x * 2
df.reindex(np.roll(df.index, shift))
Counter.objects.get_or_create(name=name)
p.join()
plt.figure()
IM20010809, IM75550511, CL0700100U
out = vec.cumsum()
plt.gcf().autofmt_xdate()
listbox.insert(0, option)
app = QtGui.QApplication(sys.argv)
raise ValueError
plt.plot(list(range(10)))
plt.imshow(frames[k], cmap=plt.cm.gray)
str(a)
fig, ax = plt.subplots(1, 1)
print(list(itertools.product(*combs)))
chambersinreactor, cardsdiscarded
(a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))
cmd.wait()
len(f.readlines())
fig = plt.figure()
new_dataset.sort(key=lambda item: item[group_by_key])
x * x
main()
asarray(all_data)
writer.save()
parser = argparse.ArgumentParser()
np.dot(np.array(n0), np.array(p) - np.array(p0))
a = dict.fromkeys(iter(a.keys()), 0)
test_list += [([0] + list(x)) for x in itertools.product(*args)]
print(newcorpus.words(newcorpus.fileids()[0]))
{{form.id}}
c.mymethod1()
session1.close()
matrix = sparse.lil_matrix((rows, columns))
list(set(raises))
out.write(b)
sample_object.users.through.objects.create(user_id=2, sample_id=sample_id)
app = QtGui.QApplication(sys.argv)
f.seek(pos)
sys.exit(2)
table.rename(index=str).index[0]
workbook.add_format(dict(list(new_dict.items()) + list(dict_of_properties.items())))
skel_coords.append((r, c))
print(status._json)
my_file.write(a)
b = dict(a)
a = json.loads(s, object_hook=registry.object_hook)
path[:-len(ext)], path[-len(ext):]
print(Timetable([random_row(50) for _ in range(15)]))
file_handler.setLevel(logging.INFO)
module.stuff()
row = next(reader)
[dishes[x] for x in set(crucial) & set(dishes)]
result.append(current.pop())
content = f.read()
self.w.setGeometry(QRect(100, 100, 400, 200))
print(regexp.search(s).group(1))
ax.xaxis.set_ticks([0, tick_limit])
mlab.axes(extent=(0, 1, 0, 1, 0, 1))
(item for item in my_iterable if my_filter(item))
A = [0, 0, 0, 1, 0, 1]
[1.0, 0.0, 1.0, 0.0, 1.0],
results = dict([(i, []) for i in inputs])
db.session.add(p)
xy[-2]
list(df)
using_clump(x)
out.reshape(N, -1)[:, (7)] = sinv
draw = ImageDraw.Draw(image1)
y.append(row[1])
parser = argparse.ArgumentParser()
self.fc1.draw()
rows.nonzero()
cnt == cnt.max()
bokeh.io.show(layout)
[tuple(map(sum, zip(x, y))) for x, y in zip(a, b)]
print(last_lines.pop(0))
form.fields[DELETION_FIELD_NAME].widget = forms.HiddenInput()
q = np.frombuffer(r, dtype=np.float64)
sorted(a, key=a.count)
array([1, 1, -1, 0, 0, -1, 1, 0, -1, -1])
all(c <= indices[i + 1] for i, c in enumerate(indices[:-1]))
t.print_exc()
scipy.stats.poisson(9.2 * 25).cdf(254 - 50)
Foo().ham
ii = np.where(values == searchval)[0]
hypot(x2 - x1, y2 - y1)
self.wfile.write(chunk)
object.__setattr__(self, name, value)
k.lower() in self._s
run.py
soup = BeautifulSoup.BeautifulSoup(html)
lines.reverse()
ax.legend(handles, labels)
func(**filter_dict(kwargs, get_input_names(func)))
list(map(deep_reverse, to_reverse[::-1]))
app = Flask(__name__)
t = pd.to_datetime(t)
end = min(len(list1), len(list2))
master.minsize(width=666, height=666)
ranges[-1].append(oldidx)
listening_socket.close()
nzsum = np.bincount(ixs[nzmask] - 1, minlength=mat.shape[0] - 1).dot(mat[1:])
total += int(string[:j]) + sum_string(string[j:])
setup.py
timeit(lambda : list(fulldict.keys()))
self.log.write(data)
x = np.random.rand(n)
plt.fill(x, y)
a = [1, 1, 5, 1, 1]
myseries_two.iloc[0:2]
pkg_resources.require(dependencies)
flat = [x for sublist in nested for x in sublist]
pdb.Pdb.postloop(self)
Z = np.random.normal(size=N)
my_df.reset_index(inplace=True)
b = pd.Series(data=[4, 5, 6])
pencil.py
value = sa.Column(sa.String, nullable=False)
eventLoopThread.setDaemon(True)
not any(bool(a) ^ bool(b) for a, b in zip(it1, it2))
browser = mechanize.Browser()
remove_if_not_substring(l1, l2)
print(extmodule.makeBalls(1, 2))
parser = argparse.ArgumentParser()
soup = BeautifulSoup(html)
list(range(1, n + 1))
b.append(item)
a[i < 0]
self.nodes.append(node)
any(i in L1 for i in L2)
show(p)
df = pd.concat([ars, che], axis=1)
soup = BeautifulSoup(html)
rows.append(row)
sys.stdout = StringIO()
stdout, stderr = proc.communicate()
ax.set_zticks([])
sum(asum(x) for x in a)
id = Column(Integer, primary_key=True)
raise TimeoutError()
zip(l[::2], l[1::2])
(1000000 * delta.seconds + delta.microseconds) / 1000000.0
print(format_float(1.5e-06))
keyword2func[word]()
testclass().testmethod()
image = Image.open(image)
f.close()
start_date = date.today().replace(day=1, month=1).toordinal()
li.append(x + y)
print(k, od[k])
fig.tight_layout()
print(ndimage.zoom(data, (1, 2, 2)))
send_file(io.BytesIO(image_binary))
ax = plt.axes([0.0, 0.0, 1.0, 1.0], frameon=False, xticks=[], yticks=[])
my_list.insert(index, insert_string)
tree = ET.ElementTree(root)
d[key][k] = v
combined_meta_data._add_table(table_name, table.schema, table)
r[~numpy.iscomplex(r)]
b[1, 1] = 100
fig = plt.figure()
time = datetime.strftime(time, DATETIME_FORMAT)
self.factories = []
self.platforms = []
self.emitter = []
print(foo())
[(1, 2), (2, 4)]
new_list = sorted(mylist, key=lambda x: x[1])
sys.stderr.write(msg)
print(bigmat[:, (x), (y)])
results = self.clickcursor.fetchall()
Test(**fields)
df_crawls.dtypes
send_from_directory(MEDIA_FOLDER, filename, as_attachment=True)
print(type(df.iloc[0, 0]))
id = Column(Integer, primary_key=True)
c = a + b
reactor.listenUDP(Protocol(timeout))
startButton.pack()
self.Bind(wx.EVT_CHAR_HOOK, self.OnKeyUP)
sys.exit(main())
plt.bar(ind, data[0], color=colors[0])
dict[entry[0]] = entry[1:]
zip(*a)
flags = tools.argparser.parse_args(args=[])
timestamp = (utc_date - date(1970, 1, 1)).days * DAY
[x for x in ls if isinstance(x, dict)]
all(a + b == c)
self.addItem(item)
mydict[s[0:1]] + s[1:]
mmc.serial.close()
self.bottom = 0
print(repr(a))
pd.read_csv(io.StringIO(df.to_csv()))
sys.exit(0)
b = numpy.random.rand(N)
conn.close()
Image.open(buff)
math.atan2(0.0, -0.0) == math.atan2(-0.0, -0.0)
print(k, v)
{{encoded}}
os.chdir(search_dir)
subprocess.call
m = re.search(self.BASE_RE, elem.text)
print(d[key])
False
root = Tk()
result = [list(t) for t in l]
df
buffer[:] = bytearray(size)
hfile.seek(0, os.SEEK_SET)
my_list.extend(sorted(my_dict.get(k)))
pos = nx.spring_layout(G)
bar()
df2.mul(np.log(df2)).sum(1)
remove_from[:index + 1] + remove_from[endIndex:]
send_file(image_file)
ax = fig.add_subplot(2, 1, 1)
f.close()
threading.Thread(target=foo).start()
dall.update(d1)
h5file.close()
b = np.array([99999, 99997, 99999])
contour_info.append((c, cv2.isContourConvex(c), cv2.contourArea(c)))
STACKADJ(-oparg)
list1[:next(compress(count(), map(ne, list1, list2)), 0)]
fig = plt.figure()
digits.extend([0] * (sigfig - len(digits)))
insert_into_homefeed.delay(photo_id, user_id, range_limit + 1)
m = __import__(module_name, globals(), locals(), func_names, -1)
json_data[key] = value.strip()
list(filter(partial(foo, 1, c=4), myTuple))
ax.set_xticks([0.5, 1.5, 2.5])
brlxusd.split()[0]
graph[a].append(b)
print(is_arr_in_list(myarr0, mylistarr))
im = Image.fromstdin()
fig = plt.figure()
name = models.CharField(max_length=100)
zip(*rows)
sys.stderr = f
b = np.array([1, 760])
[1]
time.mktime(obj.updated_at.timetuple()) * 1000
np.dot(A.T, B)
d87f7e0c
d2d10e28
print(min(resolutions, key=keyfunc))
final.append(s[x:i + 1])
np.in1d(a, b, assume_unique)
result.extend([int(b) for b in bits])
__init__.py
str(int(matchObject.group()) + 10)
ftp.connect(host, port)
fig, ax = plt.subplots(figsize=(11, 4))
first = [x for x, y in data]
td.total_seconds()
window.stick()
self.page()
run_wsgi_app(application)
time.sleep(waittime)
json.loads(urllib.request.urlopen(req).read())
df.T.apply(lambda x: x.dropna()[n - 1:].index[0])
w.set_foreground()
root = tree.getroot()
x + y * z
s.index = pd.MultiIndex.from_tuples(s.index)
plt.legend()
p.wait()
bv[i] = 1
self.fn(*args)
parser = argparse.ArgumentParser()
rdd = list(sc.wholeTextFiles(input_dir).values())
process.start()
all(ord(l[i + 1]) - ord(l[i]) == 1 for i in range(len(l) - 1))
s.decode(encoding)
time.time(), int(in_bytes), int(out_bytes)
turtle.begin_fill()
pickle.load(f)
print(canvas.find_closest(x, y))
myList = map(gen_rand, myList)
xs.min(axis=0)
do_case1()
do_case2()
httplib.HTTPConnection.__init__(self, *args, **kwargs)
deltas[(deltas < 0) | (deltas > 100)] = 0
f = lambda x, y: x + y
output = data[2] + data[2]
np.where(m.any(1), idx0, np.nan)
zf.close()
lines = tuple(l.rstrip() for l in text_file.readlines())
fig = plt.figure()
print(dict(regex.findall(r, z)))
ax.plot(new_series, your_pandas_dataframe)
fig = plt.figure()
print(tag.string)
os.kill(2405, 15)
c = [True, True, False]
(0.0, [0.0, 0.0, 0.0], [0.0, 0.0]),
zerolistmaker(15)
ax.plot(x1, np.sin(x1))
dev.off()
0, 1, 0, 1, 0, 1, 0, 0, 0
image.thumbnail(size, Image.ANTIALIAS)
pathqueue.put(path)
im = Image.open(image_path)
all(v > 0 for v in pairs.values())
print([x for x, c in list(Counter(chain(*lists)).items()) if c != len(lists)])
vals = np.array(list(d.values()))
data = os.read(self.pipe_out, 1)
pandas2ri.activate()
time.sleep(1)
(self.i, self.k, self.j) == (other.i, other.k, other.j)
x = np.arange(5)
soup.b.contents[0]
channel.basic_consume(on_message, queue_name)
select.select([], [], [])
print(np.all(A[idx_a] == B[idx_b]))
os.fsync(file.fileno())
c.append(random.choice(tmp).pop(0))
re.findall(re1, text)
size += os.path.getsize(os.path.join(path, f))
hxs = HtmlXPathSelector(response)
image.file.seek(0)
img = numpy.zeros_like(img, dtype=numpy.uint8)
new_col.shape
sys.stdout.close()
print(in_nested_list(x, 5))
t = np.arange(0, 0.001, dt)
time.sleep(2)
main()
np.interp(np.linspace(0, tmp.max(), nbin + 1), tmp, np.sort(x))
self.running = True
x, y = Point(0, 1)
print(sum(odd))
my_list
method(**options)
_grow
name = Column(String(20), primary_key=True)
opt.text.clear()
D[key].update(item)
today = datetime.datetime.today()
doc = tree.getroot()
wr.writerow([py_date] + sheet.row_values(rownum)[1:])
print([hex(ord(byte)) for byte in bytes])
turtle.fillcolor(color)
self.stream.start_stream()
file.write(file_data)
print(dict(parse_key_value_list(text)))
pprint(etree_to_dict(e))
print(dishes[key])
self._callbacks.append(callback_ref)
self.create_socket(socket.AF_INET, socket.SOCK_STREAM)
settings.MY_SETTING
id = Column(Integer, primary_key=True)
logger.addHandler(my_handler)
out.append((a, b))
handler = logging.StreamHandler()
random.random() * 6 + 1
arr[offs_x:offs_x + shape[0], offs_y:offs_y + shape[1]]
df.ix[[0, -1]]
ax.yaxis.tick_right()
print(winner.flatten().tolist())
libvirt.virEventRegisterDefaultImpl()
python / path / to / filename.py
t = threading.Thread(target=run_one, args=(source,))
d.append(line)
a = numpy.zeros((6, 6), dtype=numpy.int)
self.user_id == other.user_id
ax = fig.add_subplot(1, 1, 1)
result1.add(j + 1)
outputStream.close()
print(df)
process = Popen(command, stdout=PIPE, stderr=PIPE, bufsize=1)
rank = dict.get(key, 1.0)
c = list(itertools.product(a, b))
log = logging.getLogger()
exec(code, module.__dict__)
hbox.addWidget(self.view)
f.seek(0)
requests.post(url, data=data, headers=json.loads(headers))
df = DataFrame(flattened_records)
d.set_state(gst.STATE_NULL)
subprocess.call(shlex.split(command))
ax = fig.add_subplot(1, 1, 1, polar=True)
x = np.random.rand(25, 4)
output = {k: v for k, v in list(input.items()) if key_satifies_condition(k)}
fn(*args, **kwargs)
X = np.arange(100).reshape(10, 10).astype(float)
plt.colorbar(sc)
data = urllib.parse.urlencode(data)
visited_nodes.update(path)
axicon.set_yticks([])
np.delete(p_a_colors, indices, axis=0)
v[0] = 10
plt.show()
n > 1 and all(n % i for i in range(2, n))
turtle.left(90)
self.__dict__ = self
print((name, add, num))
nosetests
word[len(word):-(len(word) + 1):-1]
print(x)
QSize(200, 200)
print_decimal(b, prec)
counter = db.IntegerProperty(default=0)
f.read(1024)
self.func(*args, **kwargs)
self.openBtn.clicked.disconnect()
bytes([255])
df2.index = pd.MultiIndex.from_arrays(df1.values.T)
self.parse_request()
self.user = current_user()
user = models.OneToOneField(User)
self.hbox.pack_start(self.poles, False, False, 0)
plt.figure()
target.add_edge(1, 2)
result = zip(a, b, c)
driver.get(url)
accept.start()
foo(lcl)
app = QtGui.QApplication(sys.argv)
l1 = [(x, y) for x in range(n) for y in range(n)]
User.objects.filter(active=False)
print(repr(e))
s.close()
index += 1
reader = csv.DictReader(f)
sum(results) / len(results)
metadata.create_all(engine)
fff(train_set_x[index:index + 1])
func()
file = cStringIO.StringIO(urllib.request.urlopen(URL).read())
res = argparse.ArgumentParser.parse_args(self, *args, **kw)
str(lst[0])
nll
send(packet1)
d = dict((v, k) for k, v in list(adict.items()))
user = models.OneToOneField(User)
draw.line([0, center, width, center], green)
Py_Finalize()
fig = plt.figure()
map(float, mystr.split()[:2])
request.session[SESSION_KEY] = user.id
self._printTree(self.root)
b.insert(index, a)
dict_writer.writerows(groupdata)
print((d.get(20), d.get(60), d.get(200)))
Super.__init__
f.seek(0)
curses.noecho()
d = dict(regex.findall(r))
lines = text_file.readlines()
D.update([1, 2])
title = models.CharField(max_length=100, unique=True)
self.wrong_values.clear()
canvas.pack()
logging.root.setLevel(logging.DEBUG)
cv.Flip(frame, flipMode=-1)
new.show()
random.shuffle(l)
d1 = datetime.date.today()
plt.show()
sys.exit(1)
subprocess.Popen(command)
sys.stdout.flush()
os.urandom(10)
im.point(lut * im.layers)
raise IOError
session.expunge(obj1)
ax = plt.axes([0.0, 0.0, 1.0, 0.8], frameon=False, xticks=[], yticks=[])
cursor = conn.cursor(MySQLdb.cursors.DictCursor)
[[-4, -4, -4, -4], [-7, 2, 2, 2], [-1, -1, -1, -1, -1]]
print(child.tag, child.text)
title = models.CharFiled(max_length=1000, blank=True)
str(thing)
result.append(new_t)
df.sort_index(inplace=True)
M = np.random.random((5, 8))
thread.start_new_thread(self.Run, ())
zip(a, b)
plt.show()
self._s.close()
data = data[:75]
b.append(str(z))
process[-1].start()
f.write(chunk)
matches = [mapping[value] for value in a1 if value in mapping]
plt.show()
key = Column(Integer, primary_key=True)
ax.imshow(data.sum(axis=2).T)
sys.exit(1)
plt.show()
fig, ax = plt.subplots(1)
df[df.columns.intersection(col_list)]
float(item)
object.__getattribute__(self, x)
pcap_lookupnet(dev, ctypes.pointer(net), ctypes.pointer(mask), errbuf)
[list(x) for x in {tuple(e) for e in a}]
timestamp = (aware_dt - datetime(1970, 1, 1, tzinfo=pytz.utc)).total_seconds()
ax = fig.add_subplot(111)
time.sleep(0.25)
ws = root.winfo_screenwidth()
X, Y = np.meshgrid(np.arange(N), np.arange(N))
print(df2)
row = cursor.fetchone()
print(L[i])
b.append(c)
ranges = np.vstack((a, b))
self.mylist[i]
cur = conn.cursor()
a.remove(item)
l = [_f for _f in l if _f]
type(z[0])
print([format_string.format(v, i) for i, v in enumerate(a)])
self.right[i - len(self.left)]
print(counts[1])
numpy.nextafter(0, 1)
groups = Group.objects.filter(member=p1).filter(member=p2)
filename = socket.recv(1024)
{{p.first_name}}
arr = numpy.empty([0, 1], dtype=type1)
self.setContentsMargins(0, 0, 0, 0)
list(data)
result.append(i)
urllib.request.install_opener(opener)
B = np.array([2, 4, 6])
set(fruits).intersection(fruit_dict1)
time.sleep(1)
print((df.Symbol1 == df.Symbol2) & (df.BB == df.CC))
browser = mechanize.Browser()
json.load(io)
c.extend(combinations(x, i + 1))
indices[i] += 1
sons.append(son)
urllib.request.urlretrieve(dirpath + file, localfilelocation)
a = np.ma.array(a, mask=False)
print([y for y in (x.giveMyNum() for x in q) if y > 1])
os.kill(os.getpid(), signal.SIGTERM)
admin.add_view(PaidOrderView(Order, db.session))
result = bar(*args, **kwargs)
conn.logout()
redirect(url, code=code)
func(cpy)
xsheet.write_row(0, 0, a)
urlparse.urljoin(url1, url2)
[t for t in targets if t.startswith(prefixes)]
fig.subplots_adjust(left=0.1)
mask = (foo < 40) | (foo > 60)
geocalc(55.071, -6.508, 51.622, -8.886)
getattr(obj, attr_name)[index]
gy = np.zeros_like(f)
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(jar))
sorted(value, key=lambda k: k[0])
bar()
print(json.dumps(dict(data=x.tostring(), shape=x.shape, dtype=str(x.dtype))))
msg.attach(MIMEText(text))
zip(x[0], x[1])
data.append(int(el.text))
p.create_time()
code.interact(local=locals())
dict(e for i, e in enumerate(d.items()) if begin <= i <= end)
HttpResponse()
sys.stdout, sys.stderr = out
datetime.datetime.today()
print(df.head())
max(g(sorted(L)), key=lambda x_v: (len(list(x_v[1])), -L.index(x_v[0])))[0]
pool = mp.Pool(processes=10)
plt.plot(x, L.T)
fig.tight_layout()
get_localizer(request)
sleep(0.1)
self.pack()
app = Flask(__name__)
Cls.foo.__func__ is obj.foo.__func__
deletesys.argv[0]
forms.CharField(required=0),
self.Bind(wx.EVT_PAINT, self.OnPaint)
handlers.append(urllib.request.HTTPCookieProcessor(cookiejar))
result()
[j for i, j in mylist]
fig, ax = plt.subplots()
c.callback()
a, b = map(list, zip(*l))
HttpResponse()
print(my_list[0::2])
self.send_response(200)
rgb = scipy.misc.toimage(np_array)
self.transport.write(message)
item
len(net.layers[0].blobs)
foo()
a = list(filter(partial(ne, [1, 1]), a))
gzf.read()
obj.save(**kwargs)
m.mask = i == j
controlset.a.plot(self.dummyx, self.dummyy, self.dummyz)
app = flask.Flask(__name__)
cap.set(cv.CV_CAP_PROP_FRAME_WIDTH, int(x))
column += 1
initial_list.remove(item1)
df2
cust_dict[row[0]] = row[1:]
name = models.CharField(max_length=50)
files = [f for f in sorted(os.listdir(FileDirectoryPath))]
list1.remove(item)
metadata.create_all(db)
dict()
commatoze(input_str)
event.wait()
idx = np.linspace(0, 2 * np.pi, 100)
print([g.subs(x, k) for k in range(4)])
sys.stdin.readlines()
print(output)
fig = plt.figure()
sa = np.sort(a)[::-1]
seen = set()
np.clip(im[..., (0)], 0, threshold, out=im[..., (0)])
plt.margins(0.1, 0.1)
print(a, b, c)
self.assertEqual(cm.exception.code, 1)
plt.figure()
auth.set_access_token(access_token, access_token_secret)
template = env.from_string(template_string)
app.MainLoop()
process.wait()
[4, 5, 6, 7, 8]
any(check_string(line, word_list) for line in some_file)
fig, axs = plt.subplots(2, 2, figsize=(8, 8))
cursor = cx_Oracle.Cursor(connection)
-1 * np.arange(20)
sleep(0.1)
b = np.array([1, 5, 20, 25])
writer.writerow(dict((h, h) for h in headers))
duration = models.PositiveIntegerField()
inspect.signature(io.BytesIO.read)
np.logical_or.reduce(xyz)
patlist.append(idx)
axins.boxplot(data)
s.sendmail(sender, recipients, msg.as_string())
foo = Foo()
x.most_common(1)
fig = plt.figure()
print(tone2)
__setitem__
pylab.plot(x, psi)
p.terminate()
lines.add(line)
driver = webdriver.Firefox()
Response(status=404)
num2words(1e+25)
print(data)
data = f.read()
np.maximum.reduceat(a, [0, 4, 7])
nested_class()
hxs = HtmlXPathSelector(self.br.page_source)
print(datetime.datetime.now())
[X, L] = octave.eig(A)
data = []
say_hello()
group.to_excel(writer, name)
M = M[:, (M.getnnz(0) > 0)]
self.a = []
line = line.split()
name = models.CharField(max_length=255)
ts = (midnight - datetime(1970, 1, 1, tzinfo=pytz.utc)).total_seconds()
zerolistmaker(5)
Users().save()
True
data = JSONField(db_index=True)
port = sock.getsockname()[1]
array = list(accumulate(rand(100)))
bv.setall(0)
out = coo_matrix((vals, (idx[:, (0)], idx[:, (1)])), dims).toarray()
fact = lambda x: x == 0 and 1 or x * fact(x - 1)
print(list(counter.values()))
print(r.text)
print([x.group() for x in pat.finditer(mystr)])
random.shuffle(list1)
time.sleep(20)
print(my_class.__name__)
sorted(lists, key=lambda x: sorted(x, reverse=True), reverse=True)
giveupthefunc()
turtle.end_fill()
self.server = xmlrpclib.ServerProxy(self.url)
bool(a)
random_sample_output.writelines(random_sample_input)
logger.setLevel(logging.DEBUG)
rtc.BeginTextColour((255, 0, 0))
cb = fig.colorbar(im, cax=cax)
l.pop(0)
ring += 1
imshow(im)
x = self.get_subclass_name()
print(subprocess.list2cmdline(params))
output += np.sum(integrand(b), axis=1)
__import__(module_name)
root = tk.Tk()
setattr(obj, name, value)
driver = webdriver.Firefox()
print(repr(astr))
today = datetime.datetime.today()
True
soup = BeautifulSoup(html_text)
new_array
compare_listcomp(a, b)
print(names_of1(x, locals()))
f.subs(x, 0)
listen_thread.start()
c = 55.6
Book.objects.filter(**filters)
b = np.array([2, 4, 6])
bpy.utils.register_class(customToolshelfPanel)
l[1::2] += 1
x = np.linspace(xmin, xmax, 100)
cursor.execute(query)
new_list = []
print(list(m))
pdf.savefig(fig)
[[item] for item in ll[0]]
l1.remove(item)
str(obj)
keys = [k for k, v in list(my_dict.items()) if v < threshold_value]
self.emitter.daemon = True
Image.objects.all().portraits().small()
buf[i:i + 2] = foo
lines = f1.readlines()
settings.py
time.sleep(10)
wr.writerows(list(Counter(textSorted).items()))
conn.rollback()
request.form
my_file.write(c)
f.write(s)
parser = argparse.ArgumentParser()
ax.add_collection(lines)
result = storage.save(djangofile.name, djangofile)
plot_chart(df, fig, ax)
surface.get_npimage()
df = pd.concat([df] * 1000).reset_index(drop=True)
user = session.query(User).one()
modul.func()
G = nx.DiGraph()
deletelist_of_g[to_idx:]
print(key)
list(itertools.combinations(l, 2))
dosomething()
print(next(t))
angle = atan((neuron2.x - neuron1.x) / float(neuron2.y - neuron1.y))
cur_set.pop()
root = Tk()
method()
print(err.lineno)
solve(sin(z) - 2, z)
{1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0}
result[0]
f(*args, **kw)
counts[x] += 1
sys.stdout.write(processed_line)
zinfo.file_size = file_size
get_object_or_404(queryset, **filter)
plt.show()
iconfile.close()
sys.exit = new_sys_exit
gr1.switch()
console._run()
f = signal.filtfilt(b, a, f)
x = numpy.arange(0, 10)
signal.signal(signal.SIGALRM, signal_handler)
print(myre.group(1))
cur = con.cursor()
z[np.arange(k - i), np.arange(k - i) + i]
self.finish()
sys.exit(app.exec_())
x.pop(0)
fig = plt.figure()
getattr(inst, self.name)
x = numpy.asarray(x)
body = response.read()
app = QtGui.QApplication(sys.argv)
Employee.__init__(self, name, salary)
pygame.display.update()
sorted(names, key=splittedname)
z[np.arange(k - i) + i, np.arange(k - i)]
img = (np.random.rand(200, 200) * 256).astype(np.uint8)
Base.metadata.create_all(e)
print(covered_list)
list(map(lambda x: x * 2, [2, 2]))
cells = [str(i) for i in range(1, 10)]
setattr(p, s, new_value)
AB = map(sum, itertools.zip_longest(A, B, fillvalue=0))
m.tolist()
new = [k for k, g in groupby(data) if len(list(islice(g, 2))) == 1]
print([next(c) for _ in range(4)])
m1 = (pt1.getY() - pt1.getY()) / 1
map_nested_dicts(x, lambda v: v + 7)
sys.path.append(os.getcwd())
obj[name]
list(range(1, n + 1, 2))
sum(f(x) for f in phi)
np.correlate(a, [0, 0] + v + [0, 0])
local_minima.append([i, A[i]])
sorted(list(dct.items()), key=itemgetter(1), reverse=True)
decorator
plt.show()
{}
b = np.vstack((a, a))
app.listen(settings.TORNADO_PORT)
ee.connexion.add(*e.connexion.all())
canvas.tag_raise(firstRect)
layout.addWidget(self.button)
file_.close()
np.add.at(a, b, 1)
df
ax1.plot(pd.Series(np.random.uniform(0, 1, size=10)))
screen.fill(white)
self.linenumbers.redraw()
sys.stdout.write(line)
print(avg_positive_speed([0.0, 0.0]))
doing_fd.truncate()
user = Column(String)
list1, list2 = filterer(list1, list2)
plt.plot(t, s)
count(s, li)
dis.dis(f)
print(line)
cv.SetCaptureProperty(video1, cv.CV_CAP_PROP_FRAME_WIDTH, 800)
etree.tostring(tree)
self.f(obj, *args, **kw)
data = json.load(fp)
lower.append(word)
line(src, Q1, Q2, Scalar(0, 0, 255), 1, CV_AA, 0)
t.pack()
pattern.search(html).group()
list[0] += 1
print(interleave(a, b))
A = np.random.randint(0, 10, 100)
item.setExpanded(True)
reactor.connectTCP(HOST, PORT, factory)
csv_output.writerow(fieldnames)
shmctl(shmid, IPC_RMID, NULL)
display.stop()
p = argparse.ArgumentParser()
distance[0][1]
conn.set_debuglevel(False)
queryset = Profile.objects.all()
{{formset.management_form}}
tree_selection.set_mode(gtk.SELECTION_MULTIPLE)
recurse_matches_py(a, b, alo, blo, ahi, bhi, answer, maxrecursion - 1)
new_nums.append(mean(nums[index - 1], nums[index]))
last_name = models.CharField(max_length=50)
self.ax.figure.canvas.draw()
G.add_nodes_from((n, B.node[n]) for n in nodes)
self.queue.put(message)
[chr(item) for item in range(ord(s[0]), ord(s[-1]) + 1)]
grview.setScene(scene)
send_from_directory(app.static_folder, filename)
conn.rollback()
zip(*theArray)
print(a, b, c, d)
pl.plot(x, dist.cdf(x))
result.reverse()
print(thelog)
session.add(user)
print(max(map(len, inverse_regex.ipermute(data))))
value = random.choice(mylist)
response.set_status(exception.status_int)
ax2.set_navigate(False)
result.fillna(0, inplace=True)
s.say_hello()
RSI2.plot()
wb.Close()
print(m.group(1))
pickle.dumps(ThreadPoolExecutor(1))
random.shuffle(list2)
b = a.copy()
print(item)
i += 1
random.randrange(5, 60, 5)
foo()
root_logger.setLevel(logging.DEBUG)
sqs._endpoint.http_session.close()
unittest.main()
data = json.loads(api_data)
h = HTMLParser.HTMLParser()
dir()
print(get_numbers_from_filename(filename))
print(new.timestamp())
print(e.subs([(a, c), (b, d)]))
df = pd.DataFrame(dict(zip(headers, foo)))
z.append(x[i] + y[i])
print(list(groups.values()))
ax.imshow(A, **kwargs)
sys.stdout.flush()
print(r[0])
sleep(1)
res = [lookupdict[k] for k in arr.tolist()]
a[:2, :2] = np.arange(4).reshape((2, 2))
t.start()
strided.reshape(dim)
print(args)
df = pd.concat([num_df, enum_df], axis=1)
print([a.value for a in arr])
np.divide(sumA, sumB)
op(x, y)
fig, ax = plt.subplots()
G.add_edge((q, r), (q + 1, r - 1))
idx = np.array([0, 0, 0])
model.add(act)
sys.exit(a)
(1.0, [1.0, 1.0, 1.0], [0.0, 0.0]),
dd[key].append(value)
a2Note.play()
submodule1.py
template.format(*x)
df = pd.DataFrame(list(zip(*foo)), columns=headers)
f2.close()
all(item in list(d2.items()) for item in list(d1.items()))
stdout, stderr = proc.communicate()
madata
print(model.intercept_, model.coef_)
R = np.array([0.5, 0.5, 0.5])
x + y
[expression for item in list if conditional]
comm.Recv([data, MPI.CHARACTER], source=0, tag=22)
foo.bar(1, 2)
p.terminate()
root.iconify()
list_list = []
list(self._sa_instance_state.attrs.items())
diff.extend([i for i in range(len(small), len(big)) if i not in ignore])
gy = np.array([[1, 2, 1], [0, 0, 0], [-1, -2, -1]])
type(x[0])
add_subdirectory(name_of_python_app)
df = pandas.DataFrame(x_scaled)
sleep(5)
print(combs(sampleip))
response = br.response()
tests.test_001_func()
hash(b)
mock_sgc_obj.assert_called_once_with(mock_mail_obj)
self.mocks
list(it)
print(pool.map(worker, list(range(5))))
timezone.make_aware(datetime.now(), timezone.get_current_timezone())
metadata = MetaData()
screen.keypad(0)
arr[:n, :n]
plt.ioff()
cursor = conn.cursor()
print(line)
np.all(s == s2)
tour.append(current_vertex)
holes = np.logical_and(cskel, noholes)
print(convert_excel_time(1.4006944444444))
print([group.mean() for group in np.split(x, np.where(np.diff(x) > th)[0] + 1)])
sum(p)
root = Tkinter.Tk()
Response(serialized_student_detail.data)
data.sort(key=lambda r: r[1])
self.argspec = inspect.getargspec(src_func)
q[p] = np.arange(len(p))
self.fptr = fptr
recursiveBinaryChop(value, elementList, min, max)
ranges = zip(cuts, cuts[1:])
self.screen.blit(self.img, (0, 0))
print(line)
self.fig = plt.figure()
{{form.title}}
elem.clear()
self.__dict__.update(self._defaults)
[k[0] for k in d]
isinstance(sys.stdin, file)
list(set(theList).intersection(theDict))
matrix[2][0] = 5
print(line.split()[1])
label.master.lift()
page = str(BeautifulSoup(response.content))
zf.extract(member, path)
my_cmd.cmdloop()
in_memory_file = s.getvalue()
encodings.insert(0, denc)
{{animal.p}}
row_count += chunk.shape[0]
p.join()
a.foo()
srf.blit(f.render(unistr, True, (255, 0, 0)), (0, 0))
self.name = name
print(list(df.keys()))
parser = argparse.ArgumentParser()
numbers_float = [float(x) for x in numbers_str]
print(image.get_rect().size)
ax2 = fig.add_subplot(122)
sw.pack(side=LEFT, fill=Tix.BOTH, expand=1)
dict([[i, j[0]] for i, j in enumerate(x)])
image.show()
bins = bins[:-1] + (bins[1] - bins[0]) / 2
serializer_class = SpeakerSerializer
i = np.argmin(np.abs(df.index.to_pydatetime() - image_time))
word[0].isupper()
crawler.crawl(spider)
array([[0, 1, 0], [1, 1, 1], [0, 1, 0]])
plt.show()
q.try_run()
b = a[:, (np.arange(a.shape[1]) != 50)]
[item for _, item in zip(list(range(items)), list(self.items()))]
self.tristate_parent(parent)
ser.write(theinput)
data = f.read()
arr.shape
list(set(first) | set(second))
self.buttonPanel1.Show(False)
print(type(a))
isinstance(s, str)
reader = csv.DictReader(f)
m.hexdigest()
abs(hash(s)) % 10 ** 8
db.init_app(app)
tk.Frame.__init__(self, *args, **kwargs)
wx.Panel.__init__(self, parent)
it.dropwhile(lambda x: x != 4, it.cycle(l))
data.append(el.text)
parser = HTMLParser()
self.count += 1
threadB.run()
a[np.arange(len(a)), lst]
name = models.CharField(max_length=128)
a is np.asarray(a)
browser = webdriver.Firefox()
np.sqrt(np.sum((v1 - v2) ** 2))
time.sleep(0.1)
d = {part: d}
random.shuffle(listOfItems)
L = L[ndx]
column_names = [row[0] for row in cursor]
print(c.most_common(5))
print(line)
self.children.append(child)
fig = plt.figure()
b()
e.set_alpha(1.0)
np.where(pd.Index(pd.unique(B)).get_indexer(A) >= 0)[0]
pyfoo
getattr(item[1], item[0])()
soup = BeautifulSoup(htmlSource)
np.array(x)
deletelist
f_out_blg.write(line)
f_out_extkeys.write(line)
f(*args, **kwds)
self.name = name
ax.xaxis.label.set_rotation(90)
parser.add_argument()
plt.ylim(np.log10(ilim))
main()
axis.set_major_locator(MaxNLocator())
plt.gca().add_artist(leg1)
myarray[0][:1]
b - b.multiply(a)
self.ax.xaxis.set_major_locator(month)
sys.stdout.write(c)
plt.plot(t, 2 * s, c=seaborn.color_palette()[2])
surface.blit(word_surface, (x, y))
print(fmt.format(*x))
json.dumps(value)
functools.reduce(add, list(range(1, 11)))
data = numpy.zeros((200, 200, 4), dtype=numpy.uint8)
ax = plt.subplot(211)
choices.pop(0)
self.client_tcp_timeout.cancel()
ax.autoscale_view()
r = congruent.index.to_series().map(lkp).values
A()
a, b = b, a
pickle.dump(results, f)
requests.get(queryurl, auth=headeroauth)
b = list(set(a))
run()
a.index(f(a))
sys.path.append(egg_path)
print(string.ascii_lowercase)
file.write(response.text)
df_slcd
d = np.diff(x1.astype(int))
print((lst, sum(lst)))
ax.add_patch(rect)
print(c.most_common(1))
fig.tight_layout()
b.build_platlib
conn.connect((ip, port))
np.add.at(out_count, np.where(mask2)[0], b[:, (1)])
s[n:]
m = np.ma.masked_where(y > 2, y)
new_list = [[x[1] for x in y] for y in the_list]
gprun()
{url.current()}
text.see(tk.END)
cursor = conn.cursor()
count += countit(target, key, count) + 1
new_dict = deepcopy(orig_dict)
c = numpy.repeat(b, a)
self.my_stuff = my_stuff
draw.rectangle((67, 0, 100, 100), fill=(255, 0, 0, 0))
sum(char == c for c in word)
fig = plt.figure()
df
a.py
list(fun(d))
d[item] += 1
plt.draw()
fig = plt.figure()
Response(up_file.name, status.HTTP_201_CREATED)
c = np.arange(10).reshape(5, 2)
np.repeat(np.repeat(A, 2).reshape(2, 4), 2, 0)
c.setopt(c.HEADERFUNCTION, headers.write)
plt.show()
pygame.draw.circle(screen, (200, 0, 0), pos, 10, 2)
self.signal.connect(self.receiver, **self.kwargs)
print(formatdate(timeval=stamp, localtime=False, usegmt=True))
self.image.show()
df = pd.DataFrame(np.random.rand(480, 4000), dates, stoks)
self.rect = self.image.get_rect()
a.append(i)
print((choice_data.i, choice_data.card))
self.damp = damp
counts = Counter((k[1], v) for k, v in dictA.items())
reverseCom([4, 5, 6], 2)
lines = f.readlines()
tick.set_markersize(6)
{valid: true, data: whatyouwanttostore}
print(list(my_splitter))
disable()
key_func()
g.close()
action.click()
[theDict[item] for item in theList if item in theDict]
r = [(a, b) for a, b in itertools.zip_longest(l, l[1:], fillvalue=l[0])]
data = json.load(sys.stdin)
new_nums.append(nums[index - 1])
plt.mlab_source.set(x=x, y=y, z=z)
print(tuple(chain(*base_lists)))
today + relativedelta.relativedelta(weeks=1, weekday=1)
signal.pause()
draw.rectangle((0, 67, 100, 100), fill=(0, 255, 0, 0))
test1.foo()
self.remove(value)
fout.write(fin.read())
a.foo()
print(m.__class__.__name__)
tuple([(x.fptr if isinstance(x, self.__class__) else x) for x in t])
legend = ax.legend()
ctypes.cast(a.ctypes.data, ctypes.POINTER(ctypes.c_float))[0]
b = random.choice(range(a, len(xs)))
ax1.set_xticks(list(range(len(data.columns))))
new_df = pd.DataFrame()
QtDBus.QDBusConnection.sessionBus().send(msg)
server.shutdown()
p1 = subprocess.Popen(args, stdout=subprocess.PIPE)
print(df)
type(self) == type(other) and self.value == other.value
Request(url=self.login_page, callback=self.login)
print(generate(client, sys.argv[1]))
self.queue.add(item)
print(line)
t = Text(root)
glOrtho(0, w, h, 0, 0, 1)
self.assertTrue(wrn)
parser = argparse.ArgumentParser()
print(list(headers.keys()))
self.bttn.grid()
repr(f.__closure__[0])
driver = selenium.webdriver.PhantomJS()
dostufF()
ax.set_yticks(arange(df.shape[0]))
f(test=1)
[4, 5, 10]
app = Flask(__name__)
signal.signal(signum, _kronos)
b.pack()
b_thread.join()
Z = np.zeros((2, 2), dtype=int)
p.append(e)
app = QtGui.QApplication(sys.argv)
ax = fig.add_subplot(111)
myfunc()
d[k] = frozenset(v)
rows = cursor.fetchall()[-10::1]
zip_longest(fillvalue=fillvalue, *args)
lines = f.readlines()
sys.stdout.flush()
print(t.timeit(number=1))
print(f(2))
self.scrollbar.config(command=self.text.yview)
app.exec_()
writer = csv.writer(f)
lst = [0, 1], [0, 4], [1, 0], [1, 4], [4, 0], [4, 1]
d += timedelta(days=1)
self.response.out.write(json.dumps(response))
x, y = [], []
self.button.setIconSize(QtCore.QSize(128, 128))
f.close()
self.__dict__.update(kwargs)
log.start(loglevel=log.DEBUG)
print(stdout)
rd.fit(X, y)
df2 = pd.DataFrame(randn(5, 10))
new_df = new_df.append(view)
cancel(-a * b * exp(a * b * x) / (1 + exp(a * b * x)))
{{comment.comment}}
file_date_tuple_list.sort(key=lambda x: x[1])
f.close()
gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
wait = WebDriverWait(driver, 10)
all(some_list)
count(i + 1, j) + (count(i + 1, j + 1) if seq[i] == sub[j] else 0)
succs[u].add(v)
print(not any(dict1.values()))
[(x, y) for x, y in zip_longest(it1, it2)]
self[something]
root = Tk()
i = int(i)
animate / path / to / animated.gif
self.clear()
view.sel().add(sublime.Region(0, 0))
frozenset(x).intersection(y)
jobs.append(task2())
d = dict(map(reversed, list(a.items())))
random_sample_output.close()
n -= 1
results.put(simulation_result)
self.a.b.c
sum2 = data1[np.in1d(idx1, idx2)].dot(data2[np.in1d(idx2, idx1)])
keys = [r[1] for r in data]
response = requests.get(url)
pyplot.subplot(2, 1, 1)
m.get_server().serve_forever()
it = chain(a, b)
gevent.sleep(1)
dc.SetBrush(wx.Brush(self.GetForegroundColour()))
a = np.arange(2, 10)
fmt.format(msg, lineno, colno, endlineno, endcolno, pos, end)
match.group(1).upper()
file_write.write(r.read())
fp.truncate()
df.loc[~(trans_neg | trans_neg.shift(-1))]
print(df.iloc[i - N:i])
socket.inet_pton(socket.AF_INET6, domain)
file.close()
parsed = json.load(handle)
response
print(type(foo))
acceptable
libvirt.virEventRunDefaultImpl()
pl.show()
QtCore.QCoreApplication.quit()
print((a, b, c, d))
self.uncheck_descendant(item)
sqrt((a.x - b.x) ** 2 + (a.y - b.y) ** 2)
logger.setLevel(logging.DEBUG)
plt.imshow(np.mod(data, 42))
print(dict(**f))
ExampleModel.objects.update(string_field=f)
print((address, networka, networkb))
im.set_data(frame)
fd = os.open(filename, os.O_RDWR | os.O_CREAT)
print(json.dumps(get_classes_from_text(text), indent=4))
res = urllib.request.urlopen(url)
plt.setp(xtickNames, rotation=0, fontsize=40)
data = json.load(open(filename))
recursion(index + 1, result + ls[index])
a = np.sort(a)
[(temp[0] + x) for x in temp[1:]] if len(temp) > 1 else input
srf = pygame.display.set_mode((500, 500))
self.agg_log.addHandler(logging.StreamHandler())
gens.append(gen())
print(round.__doc__)
dict()
print(buff[:-1])
test.cvec()[0] = 0
rs = func(*args, **kwargs)
pygame.init()
print(pd.concat([df.iloc[(0), :], df.iloc[(-1), :]], axis=1).T)
sip.delete(self.widget_name)
a = np.zeros((4, 4))
primerange(a, b)
fig = plt.figure(figsize=(8, 6), dpi=100)
plt.xticks(xvals, xnames)
say_captcha_is_invalid()
numSeq(1, 0, 0)
file_content = f.read()
f = (lambda a, b, c, **rest: lambda x: a + b * c - x)(**locals())
iter(foo.splitlines())
self.root.setLevel(logging.DEBUG)
ax.set_xticks(arange(df.shape[1]))
self.testbed.deactivate()
pb = gtk.gdk.Pixbuf(gtk.gdk.COLORSPACE_RGB, False, 8, sz[0], sz[1])
sys.stdout.write(frame.tostring())
all_same([])
[v for b, v in self._choices if b & selection]
db = SQLAlchemy(app)
self.companion.stdin.write(datum)
type.__new__(self, name, bases, classdict)
controllers / default.py
img = Image.open(sys.argv[1])
draw()
ret = numpy.zeros(data.shape[:2], dtype=numpy.bool)
WSGIPythonExecutable / path / to / python / 2.5 / exe
plt.clf()
d = os.path.abspath(startPath)
fp.close()
poly = PolyCollection(verts, facecolors=(1, 1, 1, 1), edgecolors=(0, 0, 1, 1))
m.groupdict()
self.Bind(wx.EVT_CHECKBOX, self.EvtCheckBox, self.checkbox[i])
ui.syn()
{{animal}}
saved = locale.setlocale(locale.LC_ALL)
example2(x, a, b, D)
s.setsockopt(socket.SOL_TCP, socket.TCP_KEEPINTVL, 1)
deletesys.modules[__name__]
data.sort()
plot(x, y1)
MagicMock.__init__(self, *args, **kwargs)
G.add_node(1, pos=(1, 1))
user = models.OneToOneField(User)
unittest.TextTestRunner(verbosity=2).run(suite())
a = itertools.chain.from_iterable(x)
self.node = Node()
tup[1] << 8 | tup[0]
frame.grid_rowconfigure(0, weight=1)
zip_longest(fillvalue=fillvalue, *args)
self.lock = threading.Lock()
shared_queue_list.append(shared_queue.get())
fig, ax = plt.subplots(figsize=(8, 6))
logger = logging.getLogger(__name__)
digs[0]
confused_array[mask] = 1
child.kill()
c.execute(query, flattened_values)
[list(i) for i in set(map(tuple, (sorted(i) for i in a)))]
person.guilds.append(self.key)
self.master.rowconfigure(5, weight=1)
np.isnan(A)
[l[i:i + n] for i in range(0, len(l), n)]
fig1 = plt.figure()
cj = cookielib.CookieJar()
python - pip
list(islice(missing, 0, count))
PyparsingGrammar.parseString(line)
counts = Counter(a)
os.rename(out_fname, fname)
subprocess.call(cmd)
results.predict(start, end)
{an_object.name: an_object for an_object in object_list}
b = models.ForeignKey(B)
self.buf.read() + self.fileobj.read()
x = SimpleClass()
self.__dict__ = json.loads(j)
plt.xlim(-1, 1)
df.columns = df.columns.droplevel()
time.sleep(timeout)
help(my_list.append)
array[i, j] += 10
output = p2.communicate()[0]
next_file.write(row)
a.add(1)
dosomethingelse
fobj.seek(0)
int(math.floor(math.log10(self.n) + 1))
br.set_handle_robots(False)
ax1.xaxis.tick_top()
time.sleep(5)
os.chown(path, _user, _group)
stage.py
result = list(create(20, dict))
arrays = [np.asarray(x) for x in arrays]
axes_1.axis([-5, 5, -5, 5])
X = np.linalg.solve(A, np.ones((2 * (n - 1),)))
list(db.collection.aggregate(pipeline))
[pypitest]
bpos += blo
loader.write(response.read())
np.prod(c.shape) == np.prod(a.shape) * np.prod(b.shape)
dict2 = dict(dict1)
id, value = zip(*ans)[:2]
max(mywords, key=len)
socket.inet_aton(addr)
[(row[:column] + row[column + 1:]) for row in matrix]
sorted(set(it.chain(*ranks)), key=c.__getitem__, reverse=True)
a[b].mean()
plt.figimage(a, cmap=plt.gray())
spam_list.sort(key=order.get)
fig, ax = plt.subplots()
apply_labels(p1, labels)
browser.close()
cu.save()
print(item.unique())
coo = numpy.random.randint(0, N, size=(M, 2))
self.children.append(node)
print(next(line))
c = conn.cursor()
x = np.linspace(0, 2 * np.pi, 100)
mailServer.close()
project.save()
list()
map(itemgetter(1), sorted(m.groupdict().items()))
win.add(scroll_win)
pylab.gca().add_patch(patches.Polygon(pp, closed=False, fill=False))
[e for e in l if e % 2]
plt.show()
outlist[-1].append(json.dumps({k: d[k]}))
fig = plt.figure()
result_queue.put(res)
pdf = pyPdf.PdfFileReader(p)
matplotlib.__version__
result = [item for item in list_y if item[0:2] not in list_x_set]
res.show()
ax.contour(X, Y, Z)
print(l[i])
self.send_blob(blob_info, save_as=False)
self.__dict__.update(kwargs)
self.doc.getroot()
l[i] = l[i] * 2
print(mydict[alias1])
i += 1
data = np.random.random((N, 7))
ax.set_aspect(1)
getattr(self.obj, self.property_names[item])
res.append(1)
foo(iterable)
joinable.append(mpp)
self.pool = multiprocessing.Pool(processes=N_PROC)
df
c = b.flat
gluOrtho2D(0.0, 1.0, 0.0, 1.0)
plt.show()
ax.figure()
{letter: max(d[letter] for d in dicts) for letter in dicts[0]}
ax.legend()
result = requests.get(url)
rlcn.method2()
resident.ssa_set.all()
i.split()
user = session.query(User).get(someid)
responses.pop()
ax = plt.gca()
print(i)
y[words[0]].append(words[2])
myModule.printY()
fo.close()
[e for e in foo(bar)]
nbr_edgeobjects += 1
foo.bar = bar
target.send((key, n * 10))
__init__.py
handler = logging.StreamHandler()
str.__new__(cls, content.upper())
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj))
response = requests.get(url)
conn = imaplib.IMAP4_SSL(servername)
Queue._put(self, item)
ax.set_zlim([-1, 8])
pdb.set_trace()
2
argsdict.update({argname: argvalue})
plt.plot(list(range(10)))
requests_log.setLevel(logging.WARNING)
html = f.read()
(1.5 < a) & (a < 2.5)
print(list(cm.datad.keys()))
json.dumps(dict(nodes=graph.nodes(), edges=graph.edges()))
c = np.r_[a, b]
(0, 1), (5, 4)
self.window.move(gtk.gdk.screen_width() - 100, 0)
(xdiff.dot(Sigma_inv) * xdiff).sum(axis=-1)
[0, 0, 0, 0, 0],
mat[0] * (len(ixs) - np.count_nonzero(nzmask)) + nzsum
partition(list(range(105)), 10)
opener = urllib.request.build_opener(authhandler)
app.exec_()
self.outstream.write(self.theA)
plt.clf()
cgi.test()
fig = PLT.figure()
1, 0, 0, 0, 1, 0, 1, 0, 0
ranges.append((group[0], group[-1]))
arr = input()
a.insert(2, x)
shutil.rmtree(tmp_dir)
self.SetTopWindow(self.frame)
self._d[self._s[k.lower()]]
print(model.score(X, y))
B = [4, 5, 6]
all(list_of_bools)
root = ET.fromstring(xml_str)
deleted[k, j]
some_value
p.exists()
fig.canvas.draw()
row_ind.extend([k] * len(v))
gcf().canvas.draw()
dicto[ele[0][0]].append(ele)
Fruit.__init__(self, **kwargs)
width = t.winfo_width()
task.retry(queue=task.request.hostname)
hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
print(obj.__class__.__name__)
0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0
pprint.pprint(value)
(a[0], b[0]),
data = numpy.where(selected_indices, [4, 5, 6], data)
pd.DataFrame({n: foo(df.T[row].nlargest(k)) for n, row in enumerate(df.T)}).T
pickle.dump(i, sys.stdout)
df.drop_duplicates().A.value_counts()
self.l.append(Tree(i - 1))
result = urllib.request.urlopen(request).read()
foo(*values)
driver.close()
b = numpy.random.randn(20, 20)
parser = argparse.ArgumentParser()
tree = ET.parse(filename, parser=LineNumberingParser())
print(root.tk.splitlist(filez))
grouped.last()
im = im.resize((int(width / rat), int(height / rat)))
df.groupby(date.values).mean()
ax = plt.subplot(gs[:2, :])
self.nesting += 1
logging.setLoggerClass(Logger)
number += 1
sys.stdout.flush()
imagelist.extend(glob.glob(os.path.join(image_directory, ext)))
deletesys.path[-1]
reader = csv.reader(f)
data.mode
server = smtplib.SMTP()
df[list_of_cols].dropna(thresh=1).head()
sys.modules[__name__] = Wrapper(sys.modules[__name__])
sys.excepthook = debugexcept
[strs[i] for i in list(ret)]
draw.ellipse([left, top, right, bottom], fill=fill)
a.some.__self__ is a
x += np.random.random(size=12)
toc2(False)
print(django.get_version())
print(str(item))
worksheet.update()
pattern = eval(input())
tot += (((data[i + 1:] - data[i]) ** 2).sum(1) ** 0.5).sum()
x = np.arange(100, 1, -1)
h.digest()
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
fig.canvas.draw()
slither / slither / __init__.py
columns = [i[0] for i in cursor.description]
c = [(x + y) for x, y in zip(a, b)]
mail.inbox()
pydevd.settrace(suspend=False)
print(f.read())
driver.set_window_size(1024, 768)
url = s.get_location()
self.close()
ax = subplot(111)
setattr(theclass, x, logging(getattr(theclass, x)))
i = Image.open(sys.argv[1])
a = qt.QApplication(sys.argv)
ax = fig.add_subplot(111)
sys.exit()
datetime.datetime(*t[:6])
cv2.line(vis, (x1, y1), (x2, y2), green)
[[x.strip() for x in row] for row in reader]
fn = (lambda x: x) if True else lambda x: x * x
ax.add_patch(p1)
k, v = t.pop(0)
blih()
bluh()
sys.stdin.readline()
shutil.rmtree(to_path)
ax.plot(list2)
response = urllib.request.urlopen(req)
logging.info(str(item))
fig = pl.figure()
result = [[i for i, row in enumerate(X) if (s == row).all()] for s in S]
mask = np.ones(a.shape, dtype=bool)
print(new_str)
sys.stdout.write(c)
nx.simple_cycles(G)
print(str(d))
np.maximum(x, 0)
self.timer = QtCore.QTimer()
final.append(compound[x - 1])
w, h = map(int, f.readline().split())
re.findall(RE, string)
df[cols].sum(axis=1)
dc.SetBackground(wx.Brush(self.GetBackgroundColour()))
pd.DataFrame(Dict)
module = sys.modules[__name__]
data = urllib.request.urlopen(url).read()
c.release()
key, value = line.split()
parser = argparse.ArgumentParser()
100 * np.round(dfrm, 2)
[2]
result = {}
self.response.write(rv)
self.schedule.cancel(self.event)
win.SetPosition((x, y))
__hello()
word_freq.update(line.split())
foo(a)
self.cursor.close()
cr.set_source_rgba(0.0, 0.0, 0.0, 0.0)
next(func)
s[:i] + s[i:].capitalize()
sys.path.append(os.path.dirname(fullpath))
ax = fig.add_subplot(111)
temp.__setitem__(0, 1)
fig.colorbar(im)
np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)
myset.pop()
self.__dict__.update(*args, **kwargs)
print(key, value)
MyModel2.mymodel1.through.objects
p.open_files()
self.mtx.lock()
test[-1] += 1
ax.yaxis.set_tick_params(size=0)
self.lock = multiprocessing.Lock()
ode15s.set_initial_value(u0, t0)
print(input[indices[indices < 5]])
pwd.getpwuid(os.getuid())[0]
db.collection.find(condition).limit(1).skip(Math.floor(Math.random() * N))
iter([self.instanceA, self.instanceB, self.instanceC])
args.func(**args_for_func)
foo()
myPopy.wait()
SPN[0].shape
QtCore.QObject.__init__(self, parent)
indices = range(len(li) - 1, 0, -1)
self.move(frameGm.topLeft())
nDigits = 1 + floor(log(nmb, base))
print(etree.tostring(root))
p.name()
f(*args, **kwargs)
print(repr(s.getvalue()))
df
Z = inner1d(X, Y)
print(df.columns[np.argsort(-df.values, axis=1)[:, :2]])
a = np.arange(50)[::-1]
ax1 = fig.add_subplot(2, 1, 1)
list(range(10 ** 14, 10 ** 15, 10 ** 14))
form = ModelForm(request.POST, request.FILES)
print(s.rhyme())
self.cumweights.append(cumsum)
copytree(srcname, dstname, symlinks, ignore)
line = input()
pool = multiprocessing.Pool()
df = df.sort()
mylist.pop(0)
f.seek(0)
db = SQLAlchemy(app)
id(np.nan) == id(np.nan)
x[i] = y - 1
sys.exit()
tree = et.fromstring(xml)
user = models.ForeignKey(User, unique=True)
self.tags.add(tag)
data = np.array(im)
c2.setopt(pycurl.PROXYTYPE, pycurl.PROXYTYPE_SOCKS5)
print(e.tag, e.text, repr(e.tail))
G.add_edge(1, 2)
start_thread()
out.write(txt)
self.SetSizer(sizer)
len(answer) - star_len, star_len, len(prediction) - star_len
G.add_edge(4, 5)
plt.figure()
{1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0}
f.set_axis_off()
print(s)
obj = json.loads(s, object_hook=_decode_dict)
zip_longest(fillvalue=padvalue, *([iter(iterable)] * n))
canvas.show()
print(df1.div(len(df.index)))
np.sum(a.dot(b), axis=0)
client.set_missing_key_policy(paramiko.AutoAddPolicy())
df1.update(df1_updater)
sfile.close()
virtualenv - p / path / to / python - anaconda - version
self.run()
fig, axes = plt.subplots(nrows=2, ncols=2)
tf.pack(states)
s.quit()
args = parser.parse_args()
(a[i:] > a[i]).nonzero()[0][0] + i
tar.close()
cr.rectangle((0, 0) + size)
xs = np.random.choice(arr, n - 1)
screen.getch()
opener.open(url).read()
handles, labels = ax.get_legend_handles_labels()
open(path, mode)
wPM.restype = wintypes.BOOL
tokens = [t.lower() for t in tokens]
i = i + 1
out, err = process.communicate()
d.setdefault(k, set())
window.mainloop()
line = proc.stdout.readline()
plt.show()
plt.plot(x, s(x))
df = (df1 - df2).dropna().copy()
array[x, y]
print((date_cand, (datetime.date.today() - date_cand.date()).days))
b = [4, 5, 6]
base64.b64encode(dig).decode()
plt.imshow(image)
pygame.init()
x
self.updateimage(0)
x.bit_length() - 1
result = float(literal_eval(float_str))
d_out.update(d)
self.server_activate()
mvaddch(y, x, ch)
get_func.__func__ is Client.get.__func__
pix[x, y] = value
getattr(self, name)
key in self.data
move_set.add(random.randrange(0, 10))
conn.starttls()
self.table.verticalHeader().setTextElideMode(QtCore.Qt.ElideRight)
self.figure = Figure()
now.date()
browser = mechanize.Browser()
c[:, 1:] == c[:, :-1]
user = User.objects.get(pk=profile.user_id)
set_columns(widget.columnCount(), 0)
plt.yticks([])
print(platform.mac_ver()[0])
self.cdfunc._func(self.obj, *args, **kwargs)
a, b, c, d, e
plt.plot(X, Y)
defaultdict(partial(numpy.ndarray, 0))
f = urllib.request.urlopen(self.url)
nosetests - s
cv2.LUT(image, table)
driver = webdriver.Firefox()
(a - b).days
date += timedelta(days=10)
print(time.time() - start)
csv.writer(fw).writerows(data)
monthrange(2011, 2)
np.random.choice(np.arange(len(b)), 5, p=b / len(a), replace=False)
output.append(line)
myset = set(mylist)
pool.map(process_image, data_inputs)
form = CostForm(request.POST)
print(matches.group(1))
l1 = list(set(l1).difference(l2))
self.left.append(v)
self.entry = tk.Entry(self)
sys.exit(-1)
len(set((t0, t1)))
plt.subplots_adjust(wspace=0)
len(d.stack())
grouped.JobNos.sum().idxmax()
ax.set_xticks(his[1][1:] + offset)
s.close()
transCount % 2 == 0
y[(0), :, (0), :]
nums = [random.randrange(1, 10) for i in range(digit_count)]
{k: set(g) for k, g in itertools.groupby(words_sorted, key=len)}
lock = threading.Lock()
curs.fetchone()
d.div(d.abs()).fillna(0)
tree = ET.ElementTree(root)
tmp_arr.append(float(j) / float(a))
ch = os.read(sys.stdin.fileno(), 1)
printbob.py
list(zip(s, s[1:] + s[:1]))
self.cam.read()
fig.tight_layout()
output.close()
sum(g)
dbs
dx = 0
df = pd.DataFrame(d)
seen.add(item)
self.crawler.install()
plt.xlim(0, X.shape[1])
loglogmod.fit(x, y)
data.append([c.text_content() for c in row.getchildren()])
os.system
self.board[x]
tuple([x for x, y, z in G])
args = parser.parse_args()
print(values[:, (0)].sum())
getattr(self, attr_name)
max(map(len, stringlist))
g.nth(1).dropna()
wx.EVT_UPDATE_UI(self, self.GetId(), self.onUpdateUI)
b = np.zeros((M.shape[0], M.shape[1], M.shape[1]))
df
names = dir(self.__class__)
df.apply(pd.Series.value_counts)
task_postrun.connect(self.task_done)
self.browser.select_form(nr=0)
result.append(key_result)
dis.dis(test6)
df.loc[:, (cols)] = df[cols].where(df[cols].where.ge(0), np.nan)
z.min(), z.argmin()[0], z.argmin()[1]
self.ser.write(packet)
doc.firstChild.appendChild(elem)
sns.plt.show()
d = defaultdict(dict)
modify_legend(numpoints=1)
plt.legend()
sum(bits * u[::-1], 1)
dis.dis(bar)
df
r, g, b = hsv_to_rgb(h, s, v)
d = {}
np.ma.MaskedArray(a, mask=(np.ones_like(a) * (a[:, (0)] == 1)).T)
main()
f(d)
self.date = d.astimezone(pytz.utc)
result = sorted((min_value, result, max_value))[1]
print(element.text)
tmp[i][j] = src[i, j]
print(str(b))
array([lapack_inverse(a) for a in A])
p2 = interpolate.PiecewisePolynomial(x2, y2[:, (np.newaxis)])
array([[True, False], [False, False]], dtype=bool)
G.add_edge(1, 2)
memcache_client.set(key, obj)
s.send(line)
line = input.readline().strip()
time.sleep(0.5)
numpy.sqrt(numpy.sum((x - y) ** 2))
ax.scatter(x, y, z)
logging.Handler.__init__(self)
item.setToolTip(item.text())
sleep(0)
simplejson.dumps(userJSON)
axins.set_xlim(x1, x2)
self._data
print(files.sort(reverse=True))
dominated.append(candidate)
f.write(template.format(df.to_latex()))
lines[:, (-offset)]
foo()
self.layout = QtGui.QVBoxLayout(self)
print(list(squares(20, 90)))
result.resize((64, 64), Image.ANTIALIAS).save(sys.argv[2])
self.data[i]
f.readlines()[line_number - 1]
plt.scatter(x, y, c=z)
[alist[i::sublen] for i in range(numrows)]
map(str.upper, strs)
print(t[1][0])
lines = [line.strip() for line in file if line.strip()]
taskbar.SetProgressValue(self.winId(), 40, 100)
myseries_three.iloc[0:2]
writer.writerow(row)
print(yaml.dump(o1))
pd.DataFrame(arr).groupby([0, 1, 2]).max().reset_index()
root.destroy()
print(response.read())
f(*full_args, **kwargs)
[[map[x] for x in y] for y in input]
my_list = [1, 2, 4, 6, 7]
counts = map(Counter, zipped)
mults.append(1)
g.__name__
subprocess.check_call(cmd, stdout=outputfile, stderr=subprocess.STDOUT)
ax.set_aspect(1)
count += 1
pygame.font.init()
wmctrl - l
worksheet.write(r, c, col)
app.run(debug=True)
df1 = df[~mask].copy()
count += 1
plt.plot(list(range(5)))
print(df)
A.print_x(b)
data = db.query(sql).store_result()
activate(settings.TIME_ZONE)
sorted_li.sort(key=itemgetter(0))
print(sess.run(y, feed_dict={x: data}))
u, array([len(input[all(input == x, axis=1)]) for x in u], dtype=int)
c = Counter(tuple(x) for x in iter(list1))
start += step
conn.commit()
print(df.index.name)
os.seteuid(0)
signal.signal(signal.SIGINT, signal_handler)
print([T(val, [0.29, 4.5]) for val in data[0]])
isinstance(bar, types.FunctionType)
tws.connect()
canvas.setPageSize(11 * inch, 8.5 * inch)
sorted(x * x for x in range(10))
q = Queue()
OrderedDict((newkey if k == oldkey else k, v) for k, v in _.items())
self.some_text.SetLabel(mysql_data)
draw.ellipse((0, 0) + bigsize, fill=255)
a = [sorted(i) for i in a]
root = tree.getroot()
app.exec_()
result.append(x)
wordorder.index(word)
choice = input()
items.append(x)
view.show()
tree = ET.parse(pathToFile, OrderedXMLTreeBuilder())
t.start()
width = img.get_width()
start.focus_set()
random.shuffle(lst)
p.xs(0)
unittest.main()
b = copy.deepcopy(a)
fig.get_size_inches()
ax.legend(bbox_to_anchor=(1.1, 1.05))
root = Tk()
X, Y = np.ogrid[0:sx, 0:sy]
pool = multiprocessing.Pool(processes=6)
ax = plt.subplot(111)
map(lambda e: (e, key), elements)
wrapper
list(data_set.itertuples(index=False))
a = np.ascontiguousarray(a)
{{mywidget.body()}}
self.write(self.request.path)
print(p.findall(s))
args = parser.parse_args()
cols = np.ones(rows.shape[0], dtype=np.int)
r.append(random.choice(a))
pl.show()
self._window.show_all()
sys.stdout = F()
df = sqlContext.createDataFrame(pdf)
height = win.winfo_height()
a.append(1)
j = b.index(p[1])
a = numpy.array([1, 2, 1e1000, 1e1000, 42])
plot(x, y2)
sheet = book.sheet_by_name(name)
self.lock = threading.Lock()
g.map_dataframe(lambda data, color: sns.heatmap(data.corr(), linewidths=0))
c.hello()
ax.plot(theta, mapr(r))
lists.append(lst)
random.randint(1, 100)
array = np.array(list(result.items()), dtype=dtype)
br.select_form(nr=1)
float.hex(6.6)
exit()
a.quantize(b) == b
self.scrollbar.config(command=self.text.yview)
func()
[k for k in list(mydict.keys()) if k >= 6]
self.text.configure(yscrollcommand=self.vsb.set)
layout.addWidget(self.le)
random.shuffle(s)
s.translate(table, string.punctuation)
file.close()
array([0.09, 0.1, 0.1, 0.08, 0.08, 0.14, 0.1, 0.12, 0.09, 0.1])
raise ValueError
df[new_col] += [int(a != 0) for a in df[col]]
_.reshape(-1, ncols)
print(current_credentials.token)
process.start()
s = socket.socket()
print(date.fromtimestamp(d))
self.Layout()
M = np.matrix([[1.0, 0.0], [0.5, 0.5]])
[f(0) for f in fs]
mask = x ** 2 + y ** 2 <= r ** 2
input_thread.start()
p.hello()
print(child.tag, child.text)
os.setsid()
new_list = old_list[:]
print(line)
out.append(s)
f2.write(line)
c.call(1)
repr(tst)
a, b = tee(iterable)
[s for s in students if s[1] == value or s[2] == value]
sys.stdout.buffer.flush()
ax.add_artist(circle2)
ax.add_artist(circle1)
numpy.around(arr, 10, arr)
exec(my_code, mymodule.__dict__)
print(fn(5, 7))
[4]
send_from_directory(app.static_folder, request.path[1:])
bf.close()
object.__cmp__(self, other)
[s for s in strs if s.isalpha()]
app = Flask(__name__)
b = [a] * 5
self._socket = socket.socket()
eggs.parent.bar()
r.connection.close()
event.Skip()
conf.write()
tf.reset_default_graph()
2 - 1.0585
form = YourForm()
button.pack(side=RIGHT)
fpout.write(jsonform)
plt.grid(True)
f(*list(newdict.values()))
print(args.foo)
[0, 8, 8, 8, 8, 8, 8, 8, 8, 8]
Pool(processes, initializer, initargs, maxtasksperchild)
df.index = pd.MultiIndex.from_tuples([tup])
count = count + 1
results = multiprocessing.Queue()
l.remove(x)
fcntl.fcntl(fd, fcntl.F_SETFL, fl | os.O_NONBLOCK)
soup = BeautifulSoup(data)
fo.write(fi.read())
fig, ax = plt.subplots()
C[i][j] += A[i][k] * B[k][j]
new_dict = {}
setattr(cls, name, decorator(m))
b.update({key: (a[key], b[key]) for key in set(a.keys()) & set(b.keys())})
fig, ax = plt.subplots(1, 1)
r.supplier.name
favicon.ico
results[el] = [select(ls2, ii) for ii in [0, 1, 2]]
current_user.append(line[9:].strip())
print(wts[1])
img = cam.get_image()
print(someclass())
layout.addWidget(frame)
source.applescript
net.layers[1].blobs[1].data.shape
app = flask.Flask(__name__)
row[0] + row[1]
self.delays[type].setdefault(key, 0)
req = urllib.request.urlopen(url)
strings = [frozenset(s.split()) for s in strings]
plt.clf()
ax = plt.gca()
len([c for c in word if c == char])
decorator1(decorator2(func))
time.sleep(0)
[0, 0, 0, 0, 0, 0, 0, 0, 162, 2],
df = pd.DataFrame(np.random.randint(4, size=(5, 1)))
now = datetime.datetime.now()
r.append(etree.tostring(item, with_tail=False))
wx.StaticBitmap(panel, -1, gif, (10, pos), (gif.GetWidth(), gif.GetHeight()))
parser = etree.XMLParser(remove_comments=True)
results = [r for r, in results]
plt.plot(pd.Series(data=np.random.randn(100), index=i))
os.fchmod(fd.fileno(), stat.S_IMODE(mode))
(a,) + ((b,) if bret else ()) + ((c,) if cret else ())
res[0] += val
sympy.diff(f, x)
display(yourobject)
Thread(target=print_output, args=(p.stdout,)).start()
df = pd.DataFrame(lst)
ax.plot(data2)
match = re.search(pattern, s)
self.numbers = list(range(1, 10))
B = np.array([0, 0, 0])
pyplot.show()
p = multiprocessing.Pool(processes=4)
csvfile.truncate()
list.__getitem__(self, item)
action()
[isinstance(x, numbers.Number) for x in (0, 0.0, 0j, decimal.Decimal(0))]
parser = argparse.ArgumentParser()
underscoreize(data)
ax.plot(x, np.sin(x) + i)
Planet.VENUS.radius
app.send_static_file(filename)
handler = logging.StreamHandler()
grdevices.dev_off()
df = pd.DataFrame(np.random.rand(15, 5), index=[0] * 15)
AC_PROG_LIBTOOL
plt.legend()
in_tree[0:1] + in_tree[1:][::-1]
print(add(**kwargs))
dir(e.args[0])
[foo]
client_socket.send(strng)
p.kill()
self.items.append(item)
print(stopword_pattern)
self.view.setModel(self.model)
instance = class_()
new_data = ndi.map_coordinates(data, idx)
driver = webdriver.Chrome()
func = lambda x, y: (x, y)
print(f.__defaults__)
print(x.eval())
[ax.add_patch(rect) for rect in rects]
int(argv[2])
Counter(tuple(x) for x in a)
print(df1.combine_first(df2))
logging.Handler.__init__(self)
[next(part for part in path.split(os.path.sep) if part) for path in paths]
plt.plot(h, pdf)
self.ax.set_xlim(xmin, xmax)
k = literal_eval(s)
b_set = set(map(tuple, a))
list(od.keys())
2, [True, False, True, False]
termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)
interpreter.process_page(page)
print(input())
list(globals().keys())
ax = self.figure.add_subplot(111)
plt.show()
do_something(current_file)
dict(next(iter(i.items())) for i in g)
it.operands[-1]
is_const(x) and is_datatype_constructor(x)
num = int(s)
next(zip(*G))
td.seconds / 60
print(line, count)
unattachedvolumes()
newfunc
G.add_edge((q, r), (q - 1, r + 1))
session.query(entity).filter_by(name=name).one()
print(df)
list1[:i]
x, y = screen.get_size()
cur = conn.cursor()
df6[col] = df6[col].astype(dtype)
sorted(set(li))[-(n + 1)]
p2.join()
pattern.findall(data)
output = int(process.stdout.readline())
[r for r in x if not yy.search(r)]
r = [s[i:i + 2] for i in range(0, len(s), 2)]
sublist(a[1:], b[k + 1:])
dt
nat != nat
fig = plt.figure()
thread.start()
np.put(arr, list(range(num)), np.nan)
list(range(item.start, item.stop, item.step))
print(hash.hexdigest())
fig = plt.figure()
x = [True, False, False, True]
f(my_list)
print(len(set(hashes)))
self.window.show()
list(sympy.sieve.primerange(0, 100))
self.urole
b = np.where(a.all(axis=1).any(axis=1))[0]
start_server()
testVar.append(2)
b = models.ForeignKey(B)
df.columns[1:]
append(result, i, j)
df2.name.str.strip().str.upper()
CoverageACol = arange(10).reshape(2, 5)
result = np.vstack((ranges[starts, 0], ranges[ends, 1])).T
s = {n for v in list(my_dict.values()) for n in v}
print(unique_list)
self.__dict__[attr] = value
ax.yaxis.set_major_locator(MaxNLocator(integer=True))
monkey.patch_all()
[1, 2, 6, 7, 8, 9, 10, 11]
start_of_week
temp_data.remove(word)
cv2.drawContours(img, [cnt], 0, (255, 0, 0), 2)
ctypes.pythonapi.Py_DecRef(pyobj)
random.shuffle(lines)
soup = BeautifulSoup(data)
parser.parse_args()
plt.subplot(121)
imshow(mycmap(Z2), extent=extent)
session.cookies.get_dict()
termf.pack(fill=BOTH, expand=YES)
fig.canvas.draw()
timezone.localtime(value)
ldap.set_option(ldap.OPT_X_TLS_REQUIRE_CERT, ldap.OPT_X_TLS_NEVER)
round_to_1(4)
nms[nms.name.notnull()]
a = np.random.rand(500, 500)
parser.parse(strtime)
option.impliedVolatility(11.1, process)
print(k, v)
c = wmi.WMI()
SUDO_UID
self.value < other.value
a[0, 2]
sum(random.permutation(x))
[df[1:]]
set(l1)
A * numpy.exp(-(x - mu) ** 2 / (2.0 * sigma ** 2))
logger.addHandler(handler1)
text(np.mean(s[:, (0)]), np.mean(s[:, (1)]), str(i), fontsize=14)
self.commitData.emit(self.sender())
client = gspread.authorize(credentials)
list(chain.from_iterable(listOfLists))
print(result)
f.write(file_content)
s = paramiko.SSHClient()
tree.write(datafile)
to_product.append([(k, i) for i in v])
ConvertToString(HexString)
app.exec_()
sb.set_palette(cmap, n_colors=8)
HTMLParser.__init__(self)
print(is_int(x))
do_stuff()
main()
self.main_container.grid_columnconfigure(0, weight=1)
sess = tf.Session(config=session_config, graph=graph)
ax2 = pyplot.axes([0, 0, 1, 1], axisbg=(1, 1, 1, 0))
a, b = zip(*z)
config.VAR1
layout = QtGui.QVBoxLayout(self)
file.seek(0, os.SEEK_END)
bool(ImageChops.difference(*imgs).getbbox())
plt.semilogy(xf, 2.0 / N * np.abs(yf[0:N / 2]))
time.sleep(self.interval)
fig = plt.figure(figsize=(10, 6))
Gtk.main_quit()
max_water_heldover([9, 8, 7, 8, 9, 5, 6])
pool = multiprocessing.Pool()
x[ind] = y[ind]
f(l)
pd.DataFrame({d: df[d] for d in df.columns if d not in dupes})
re.findall(pattern, clause)
self.fmt.format(*self.args, **self.kwargs)
z = zipfile.ZipFile(filename)
df.shift(1)
os.remove(f)
sys.exit(1)
salt = bcrypt.gensalt()
coo_matrix(c.multiply(np.dot(a, b)))
plt.ylim(0, X.shape[0])
cls(wfd, bfd, wildfd, tfd)
tostring(element)
sys.path[0] = os.path.dirname(mainpyfile)
update_handler_level(mylogger, logging.StreamHandler)
Books.objects.all()
plt.imshow(result)
f_in.seek(0)
rank = Model.objects.filter(score__gt=obj.score).count()
d = date(year, 1, 1)
soup = BeautifulSoup(page)
str(self.year)
x1 = y1 = x2 = y2 = 0
lst.remove(x)
timedelta(microseconds=1000)
wr.writerow(sh.row_values(rownum))
plt.show()
parser = argparse.ArgumentParser()
hxs = HtmlXPathSelector(response)
parent_dir = os.path.abspath(os.path.dirname(__file__))
print(topological_sort(connections))
plt.figure()
app = recording.appstats_wsgi_middleware(app)
matrices[:, (2), (2)] = c
Polygon([(points_x[i], points_y[i]) for i in range(600)])
True
soup = BeautifulSoup(page)
sorted(string)
idx = np.nonzero(mask[1:] != mask[:-1])[0]
dict(d1, **d2)
grammar.load()
logging.config.dictConfig(D)
data[school].append(datum)
plt.show()
lines_seen.add(line)
axis.set_major_formatter(ScalarFormatter())
sleep(1)
-libpng - dev
tgt.write(uglybuf)
now = time.time()
ax = fig.add_subplot(111)
text_img.drawText(name, 0, 0)
int(argv[2])
Base.metadata
node.render(context)
fig, ax = plt.subplots()
response = FileResponse(os.path.abspath(f.name))
a + b + c
root2.update()
q.task_done()
sys.exit(0)
fig.circle(x, y, color=color, **point_kwargs)
NULL
np.set_printoptions(*args, **kwargs)
z.append(matchobj.group(2))
cursor.execute(insert, (my_point_list,))
print(generate_list(10))
print(my_object.contents)
current.append(x)
print(np.dot(eigenvector.T, np.dot(cov_matrix, eigenvector)))
print(df.index.dtype)
a[0]
print(foo())
lst = list(range(1, 10))
mlab.view(azimuth=45, elevation=60, distance=0.01, focalpoint=(0, 0, 0))
x == n * (n + 1) / 2
asyncio.set_event_loop(loop)
path = os.path.normpath(os.path.expanduser(path))
a = np.arange(125).reshape(5, 5, 5)
[self.classify(x) for x in xs]
threads.append(MyThread(q, args=(t % 2 == 0,)))
True
s.shape
b.sum(axis=2)
new_dict = json.loads(json.dumps(my_dict))
self.connected = True
print(element.firstChild.nodeValue)
p.stdout.close()
print(types[bisect.bisect(points, Point(0.6, 0.6)) - 1])
H = np.meshgrid(np.arange(5), np.arange(5))[0]
y = np.zeros_like(x)
a = NP.empty(shape=(0, 0))
np.sum(a.dot(b), axis=1)
np.put(arr, list(range(num)), np.nan)
print(line)
[str(chr(i)) for i in h]
u = random.random() + random.random()
redirect(self.get_success_url())
Py_Finalize()
[10, 12, 14]
print(df[mask])
[map(first, row) for row in data]
print(resp.status_code, resp.url)
inspect.ismodule(os)
str(x)
ipdb.set_trace()
np.random.seed(1)
print(corn.get_next())
cv2.waitKey(0)
input = sys.stdin.read(1)
print(result[0][4])
out = sidx[np.searchsorted(X1D, searched_valuesID, sorter=sidx)]
self.socket.bind(self.server_address)
some_func(foo, bar, baz, quux)
text = ndb.TextProperty()
g = copy_func(f)
logger.setLevel(logging.DEBUG)
e.submit(slow_work, *args, **kwargs)
fn(*args, **kwargs)
plugged()
f.write(tmplines)
foo()
dates_dict[key].append(date)
self.__dict__[key]
words = input.split()
ax.text(*angle_text)
rect.set_xy((dx.start, dy.start))
time.sleep(2)
plt.setp(ax.get_xmajorticklabels(), visible=False)
next(iterator)
ml.run()
reader = csv.reader(f, skipinitialspace=True)
p = multiprocessing.Process(target=func)
do_something_with(key, value)
print(match.span())
cal_vbox.pack_start(gtk.Calendar(), True, False, 0)
arrayList.append(copy.copy(wM))
driver = webdriver.Firefox()
[mydict[k] for k in list(mydict.keys()) if k >= 6]
plt.plot(X, Y1, lw=4)
t1 = linspace(-50, 50, 100)
ast.literal_eval(d)
Image(path, width=width, height=width * aspect)
print(columns[1])
layout.addWidget(self.button)
id = Column(Integer, primary_key=True)
line = line_data[k]
df.values
result = [copy.deepcopy(result) for _ in range(d)]
os.execv(sys.argv[0], sys.argv)
print(sys.path)
p2 = np.power(np.linalg.det(cov), -0.5)
l2 = [5, 6, 7, 8]
y = np.arange(-5, 5, 0.2)
int(round(n[0]))
line(res, vertices[1][0], vertices[2][0], color, 5)
(a if condition(item) else b).append(item)
client.close()
soup = BeautifulSoup(html)
set(short_list).intersection(long_list)
print(repr(l[0]), repr(int(l[1])))
result = session.query(cls)
conn.setopt(pycurl.DEBUGFUNCTION, test)
plt.show()
t.join()
btn.Bind(wx.EVT_BUTTON, self.changeCursor)
fig = plt.figure()
ret.append(np.zeros(len(tmp)))
plt.gca().invert_yaxis()
set_column(first_col, last_col, width, cell_format, options)
answer = np.linalg.solve(A, b)
startupinfo = subprocess.STARTUPINFO()
solve([0, 10], [12, 20])
a = np.arange(18).reshape(9, 2)
process = Popen(command, stdout=PIPE, stderr=STDOUT, bufsize=1)
line = line.strip()
time.sleep(1)
self.edit = QtGui.QLineEdit(self)
crawler.start()
df_new
main()
self.b2.pack()
colorbar.set_ticklabels(np.unique(data))
axs[1].xaxis.set_major_locator(x_major_lct)
print(s[match.start():match.end()])
all(earlier >= later for earlier, later in zip(seq, seq[1:]))
msg.append(500)
int(hours) * 60 + int(minutes)
mlab.draw()
d2 = dict(list(d.items())[:len(d) / 2])
ax = fig.add_subplot(111)
numpy.percentile(df.a, 95)
out = a + val * np.identity(a.size).reshape(np.append(-1, shp))
f.close()
self.send_response(200)
deleteself.cobj
print(map(lambda x: not x, a))
field.widget = forms.RadioSelect()
glVertex2i(110, 10)
entity_manager.query(Result).filter_by(job_id=job_id).delete()
new_arr.shape
soup = BeautifulSoup(html)
list(product(*[list(range(i + 1)) for i in [x, y, z]]))
a = a.__iadd__(da)
soup_original_1.body.append(element)
data = socket.gethostbyname_ex(x)
plt.grid(True)
canvas = np.zeros((10, 10))
out.close()
fig, ax = plt.subplots()
m.update(f.__class__.__name__)
a.close()
self.root = tk.Tk()
self.transport.loseConnection()
str(self.value)
Py_Initialize()
srf = pygame.display.set_mode((640, 480))
self.video_cap = cv2.VideoCapture(self.device_index)
{y, x, 0}
session.merge(row_data)
root = tk.Tk()
fig = plt.figure()
match.group(1)
gmpy.divm(1, 0, 5)
td.text
root = lxml.html.fromstring(doc)
str(self._list)
math.ldexp(m, e)
ax1 = fig1.add_subplot(111)
self.name = name
np.mgrid[0:6, 1:10, 0:20][1]
mod.doSomething()
max(list(c.items()), key=itemgetter(1))
list(find_creators(f, list(globals().values())))
lens[:-1].cumsum()
ax1.set_yticks(list(range(len(data.index))))
np.bincount(np.arange(mask.size) // 20, mask)
True
plt.colorbar(surf, shrink=0.75, aspect=5)
list.__init__(self, *args)
print(ordered_dict)
instance = forms.ModelForm.save(self)
d = dict.fromkeys(list(range(100)))
command.run(timeout=1)
im = np.array(second_subreg * 255, dtype=np.uint8)
thread.start()
gtk.gdk.threads_init()
datetime.fromtimestamp(ts, tz=pytz.utc)
file.close()
[int(x) for row in inputVals for x in row]
ax.hold(True)
db.execute(ddl)
axes[-1, -1].set_ylim(ylimits)
s = map(int, s.split())
result = sm.WLS(y, exog, weight=w).fit()
x, y = np.linspace(x0, x1, num), np.linspace(y0, y1, num)
yaml.add_representer(anydict, _represent_dictorder)
ax.set_xticks(centers)
obj = MyClass()
p = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
print(df.sort_index())
np.allclose(a[:, :, :, (2)], collapse_dims(a)[:, :, 4:6])
shutil.copyfileobj(f, sys.stdout)
print(gaussian_filter())
NULL
s = MLStripper()
json.dumps(json.JSONDecoder().decode(str_w_quotes))
map(print_node, ts.cursor.get_children())
print(line)
log_message_button.Bind(wx.EVT_BUTTON, self._log_message)
Session = scoped_session(sessionmaker())
help(re.sub)
t.start()
traceback.print_stack()
gdal.ReprojectImage(src, dst, src_proj, match_proj, gdalconst.GRA_Bilinear)
script_dir = os.path.dirname(os.path.abspath(__file__))
plt.ylim(0, 2.1)
x = 10 * np.random.random(100)
mylist = literal_eval(fsock.read())
root = etree.parse(urllib.request.urlopen(url))
axs[i].set_title(str(250 + i))
doc.setHtml(label.text())
a_list[:half], a_list[half:]
irenL.Initialize()
deletea[1]
np.bitwise_or.reduce(c) == c[0]
m_close.Bind(wx.EVT_BUTTON, self.OnClose)
[i_j_k for i_j_k in a if i_j_k[0] + i_j_k[1] + i_j_k[2] > N]
sys.stdout.write(line.lower())
[tuple(g) for valid, g in groupby(init, key=lambda x: len(x) != 0) if valid]
A.sort(axis=1)
root.withdraw()
sum(a * b for a, b in zip(v1, v2))
window.show_all()
gtk.timeout_add(60 * 1000, my_timer)
root = Tk()
l.append(x)
proc = subprocess.call(command, stdout=out, stderr=subprocess.OUTPUT)
self.lift()
driver = webdriver.Firefox(proxy=proxy)
locale.setlocale(locale.LC_ALL, l)
keys = pygame.key.get_pressed()
reactor.run()
reader = csv.reader(f)
d.sort(key=sorting)
plt.bar(ind, data[1], color=colors[j], bottom=bottom[i - 1])
cr.set_line_width(brush.width)
sys.stdout = Logger()
self._age = value
allUuids.append(x.id)
parser = argparse.ArgumentParser()
p.__dict__.update(d)
ax = plt.gca()
excel.Visible = True
y[:, (newaxis)] - x
title = models.CharField(max_length=100)
net.layers[1].blobs[1].diff.shape
cap.release()
metrics.roc_auc_score(y, scores)
r = requests.get(url)
instance.username = username
s.method()
print(numpy.lib.format.open_memmap.__doc__)
ax = plt.subplot(111)
ax = plt.gca()
session.add(object)
data = np.recarray(data.shape, data.dtype, buf=data)
self.y1 += self.speed * math.sin(self.bearing)
foo()
soup = BeautifulSoup(page.read())
line = next(islice(f, line_number - 1, line_number))
pickle.loads(pickled_value)
T = np.zeros((len(x), len(y), len(z)))
q.put((i, url))
filename = models.CharField(max_length=128)
handles, labels = ax.get_legend_handles_labels()
ax.lines
ax2.plot(list(range(10)))
d[x] += 1
Z += np.random.normal(0, noise, Z.shape)
a = np.random.randint(0, 100, 10)
html.document_fromstring(doc)
platform.mac_ver()
pygame.init()
fig.canvas.draw()
n = np.prod([x.size for x in arrays])
self.response.write(template.render(template_values))
print(self.request.id)
max_water_heldover([8, 8, 4, 5])
copy_with_prog(src, dest, lambda pos, total: prog.update(pos, total))
print(request.__dict__)
self.__c = value
s[0:n], s[n:]
res[selfpow + valpow] += selfco * valco
d = datetime.datetime.today().replace(microsecond=0)
get_something(a)
G = nx.DiGraph()
np.apply_along_axis(wrapper, axis, F)
disassemble(x)
proc.start()
tab.add_row(list(row.values()))
wr.writerow(mylist)
fig = plt.figure(figsize=(8, 8))
logger.addHandler(handler)
timeit(easydiff1, easydiff2, 1000000)
a[0]()
ax.set_yticks(np.arange(data.shape[0]) + 0.5, minor=False)
[k.key for k in {IPKey(k) for k in workers}]
soup = BeautifulSoup(urllib.request.urlopen(url).read())
os.chdir(dir)
rChannel.items.append(item)
[1, 8, 8]
print(herp.derp.foo)
M.append(1)
self.list(request, *args, **kwargs)
gca().xaxis.set_major_locator(NullLocator())
pylab.imshow(arr, cmap=cm.Greys_r)
colors = [cm.jet(x) for x in linspace(start, stop, number_of_lines)]
main_str.startswith(check_str) and main_str.endswith(check_str)
s = str(x)
stdscr.getch()
print(H[-1, -1])
pool.close()
print(paramiko.__version__)
outfile.write(line)
root = tree.getroot()
newList.append(oldList[-1])
list.append(sentence.lower())
total = xtabs.stack().sum(1)
self.send(msg.body)
dframe[gindex]
mymodule.MyClass.getImg()
line(res, vertices[2][0], vertices[0][0], color, 5)
g.write(header(delimiter, fields))
output = list(seq[::-1])
f2(1)
int(a ** b)
lol = LoL([list(range(10)) for i in range(10)])
screen.nodelay(1)
a[0].value
send_post(server, data, files)
Hyphenator.run()
df.agg(*exprs).show()
print(someclass.__name__)
str(2.999999999999999)
id = db.Column(db.Integer, primary_key=True, nullable=False)
idx = np.array(list(d.keys()))
x.append(1)
sys.stderr = sys.__stderr__
list2 = [5, 6, 7, 8, 9]
new_data.apply(directionDescribe)
a.goodbye()
result.append(item)
index = np.arange(len(a))
plt.pause(0.001)
total += int(match.group())
curses.echo()
dis.dis(lambda : a < b < c)
lock = threading.Lock()
picture = pygame.image.load(filename)
xml.etree.ElementTree.dump(group)
bytes([a[0] & b[0]])
self.turnnow
fh.seek(file_size - offset)
ser.read(1)
self._x = x
tmp = tmp.apply(lambda x: str(x[0]))
do_something_1()
ax2 = ax1.twinx()
html = urllib.request.urlopen(url).read()
server.sendmail(username, to, msg.as_string())
cherrypy.quickstart(HelloWorld())
x = np.empty([n, 2])
df[df < pd.Timedelta(0)] = 0
sum(l[::2]) - sum(l[1::2])
print(x.toprettyxml())
db = current_app.db
tocrawl.add(link)
a = np.array([0, 1, 0, 1, 1])
pylab.show()
ser.open()
main.show()
logger = logging.getLogger(__name__)
row * (row + 1) / 2 + 1
client.describe_cache_engine_versions()
reversed_dict[value].append(key)
ax.set_zlim(-1.01, 1.01)
os.ftruncate(fd, 0)
len(frozenset(objs)) == len(objs)
print(x)
plt.gca().add_patch(plt.Circle((posx, posy), radius=0.05, fc=color))
df.loc[mask]
plt.yticks(list(range(0, max(yvals), yinterval)))
g.add_edge(5, 6)
{(x + 1): (0) for x in l}
deletelist[index]
print(n)
[20, 40, 60, 80, 100]
inspect.getmembers(parser, predicate=inspect.ismethod)
sns.heatmap(data, linewidth=0, yticklabels=yticks, xticklabels=xticks)
sympy.exp(x)
cmp(adiff, bdiff)
sys.exit(0)
here = os.path.dirname(__file__)
n.append(c)
stats.exponweib.fit(data, floc=0, f0=1)
Euler5(start + 1, end, x)
T.append(df)
self.builder.add_from_file(self.glade_file)
merp[j].append(i)
reactor.run()
logging.shutdown()
ax1.set_title(title)
widget.insertRow(widget.rowCount())
values = heapq.nlargest(2, my_list)
l1.grid(row=0, column=0, padx=(100, 10))
ax.yaxis.set_major_formatter(y_format)
self.setCentralWidget(self.edit)
self.__storage.pop()
print(str.__doc__)
mpl.get_cachedir()
G.data[G.data != 0] = 1
-1 - value
sb.set_palette(cmap)
comment = sh.Cells(1, 1).Comment.Text()
f()
create_table(my_test_db, _create_sql)
cls(reader1, reader2)
ws = wb.get_active_sheet()
r[k][v] += 1
df.join(newFactor.reindex(df.index, level=0))
user2 = User.query.filter_by(id=2).first()
a.start()
hello_world.py
[1.0001]
display.start()
b = [(i * 2) for i in range(1, 10)]
self.ToggleTool(self._NTB2_ZOOM, False)
print(hex(intNum))
r.text
print(A.B.__name__)
main()
print(window.get_name())
df[2].replace(4, 17)
print(s)
plt.show()
g.apply_async()
time.sleep(5)
match.group()
sizer.Add(anotherWidget, proportion=0, style=wx.ALL, border=5)
timeComboBox.currentIndexChanged.connect(self.test)
ax.scatter(x, y)
choose_from_axis(x, 1, 1, 2)
message.pack(padx=8, pady=8)
a[a < 0.7].max()
datetime.timedelta(int(deltatuple))
s = slice(start, stop, step)
ewh.clicked()
session.prepare()
print(pformat(x, formatfloat))
getattr(instance, attr)
df1.foo.isnull().sum() * 100.0 / len(df1)
print(o_form.producetype())
foo = (x * x for x in range(10))
self.my_dict[key] = frozenset(value)
df
[str(x) for x in EmployeeList]
view.set_overwrite_status(True)
display(str(num))
print(list(gen(a)))
id = Column(Integer, primary_key=True)
ymin, ymax = min([i.min() for i in ys]), max([i.max() for i in ys])
csvfile.seek(0)
plt.show()
response
process.stdin.write(modified_line)
multiply_anything(0, 8)
ctypes.addressof(some_long)
len(solns8)
app = QtGui.QApplication(sys.argv)
ax.plot(x, y, lw=2)
test[::-1]
df.apply(lambda s: s[np.isfinite(s)].dropna()).sum()
f2 = f2 * np.max(f1) - np.min(f1) * (f2 - 1)
list(self.__dict__.values())
df.isnull() | df >= threshold
print(df.head())
metadata = MetaData(engine)
Gtk.main_quit()
p = subprocess.Popen([fn], shell=False)
print(l)
self.resize(640, 480)
print(q.cancel())
all(type(i) is int for i in lst)
root.mainloop()
start = time.time()
classifier.fit(X_train, y_train)
ch.setFormatter(formatter)
container.grid_rowconfigure(0, weight=1)
results[i] = urlopen(url).read()
sys.excepthook = my_excepthook
c = cv2.cvtColor(c, cv2.COLOR_BGR2RGB)
array([1, 0])
s.reverse()
GL.glClearColor(0.5, 0.5, 0.5, 1.0)
pp(list(find_days(start, end, 1, 2)))
csvwriter.writeheader()
print(list(accumulate(L)))
self.discard(item)
print(self.correct_response)
data = json.loads(request.raw_post_data)
c.append(solve(new_matrix, size - 1) * matrix[j] * (-1) ** (j + 2))
p.resume()
self.crawler = CrawlerProcess(settings.SCRAPY_SETTINGS)
decisions.complete_workflow_execution()
sys.path.insert(0, cmd_folder)
result.append(offset)
pythoncom.PumpWaitingMessages()
args.value = values.get(args.values)
a[:] += da[:]
print(a[1, 1])
x.reshape(x.shape[0] / 5, 5)[:, :2].flatten()
a[0][1] = 10
node.orth_
d.join(s.split(d)[:n])
{(1): 2} in {1, 2}
textdata.columns - csvdata.columns
result.append(i + j)
print(a, b, c)
random.shuffle(results)
s < t.isoformat()
df.max(1)
value = myDict[key]
session.expunge(inst)
not np.any((a == b).mask) and np.alltrue((a == b).compressed())
array1 = [[0, 0], [0, 0]]
set_value(dict_nested, list_address[:-2], *list_address[-2:])
df = pd.DataFrame(d)
json.loads(dict_str)
soup = BeautifulSoup(html)
a.sort(object_compare)
cleared.append(candidate)
self.get_name()
unfold(lambda y: (y, f(y)), x)
[singleitem] = mylist
yourThread.start()
encoder.encodefile(corpusfile_plaintext, corpusfile)
repr(c)
id = Column(Integer, primary_key=True)
interactive(set_cursor, x=ax.get_xlim(), y=ax.get_ylim())
print(word)
bool_list = [False for item in bool_list]
[(d.month, d.year) for d in rrule(MONTHLY, dtstart=start, until=end)]
layout.addWidget(self.table, 1, 0)
form = RecipeForm(request.form)
L.append(L[i])
signal.signal(signal.SIGALRM, handler)
rootApp.run(debug=True)
print(newcorpus.paras(newcorpus.fileids()[0]))
file.close()
model.load_weights(weights_path)
self.video_out.write(video_frame)
random.shuffle(iters)
groupedby(enumerate(s), key=itemgetter(1), keep=itemgetter(0))
pdb.set_trace()
foo.__annotations__
df.index.get_loc(window_stop_row.name)
csv_reader = csv.DictReader(utf8_data, **kwargs)
tree = ET.parse(source)
amp * np.exp(-(x - cen) ** 2 / (2.0 * sigma ** 2))
type(df1)
m = mp.Manager()
tm.assert_frame_equal(df, df)
output = p2.communicate()[0]
parts = line.split()
expm1(1e-05)
self.pack(side=BOTTOM)
self.view.setModel(self.proxy)
a = [[0, 1, 0], [1, 0, 0], [1, 1, 1]]
s = pd.Series([True, True, False, True])
df2.set_index(np.arange(len(df2.index)))
wr.writerow(sheet.row_values(rownum))
False
doc = lh.parse(urllib.request.urlopen(url))
n = find_words_in_image(open(sys.argv[1]).read())
print(str_list)
self.num = num
out = collections.defaultdict(list)
s.quit()
s.bind((HOST, 0))
result.append(str(s))
(x[i] for x in copies[i])
mylist.sort(key=lambda x: x[1])
sio.reset()
_list.extend(list(range(r[0], r[1])))
self.lom.append(name)
g(1000, y=2000, z=500)
reversed_dict[value].append(key)
d[i].append(x[j])
print(timedelta(hours=time.timezone / 60 / 60))
x = random.choice([left, right])
plt.scatter(delta[idx], vf[idx], c=dS[idx], alpha=0.7, cmap=cm.Paired)
deletesys.modules[name]
pd.concat(frames, keys=dates, axis=1)
getattr(self._instance, attr)
a = [[], [], []]
update_wrapper(result, func)
urlpatterns.append(url(main_view_re, MainView.as_view()))
w = np.fft.fft(data)
self.data[k] = v
print(max(list))
cols = df.columns.values.tolist()
response = urllib.request.urlopen(req)
my_list
data = f.read(1)
inf.seek(0)
np.arange(10)[10:0:-1]
app.debug = True
internet.TCPServer(1025, factory).setServiceParent(application)
a = 2
print(data)
shutil.rmtree(dir)
eval(input())
plt.colorbar(sm, ticks=list(range(4)))
MyClass().id
self.selectedFiles
pdb.Pdb(stdout=sys.__stdout__).set_trace()
cur.execute(query)
gc.collect()
i.update(7)
f.truncate()
my_dict[list[0]] = list[:]
print(f())
duck.quack()
fractExpr.setParseAction(lambda t: sum(t))
h.append({k: td.get(k) for k in get_keys})
plt.clf()
QWebPage.__init__(self)
os.makedirs(outdir)
plt.close()
self.close()
self.assertTrue(parser.long)
pygame.event.wait()
len(x) != len(y) and max([x, y], key=len) or min(x, y)
{{pform.as_p}}
(xdiff.T * lu_solve(Sigma_inv, xdiff.T)).sum(axis=0)
t.refresh()
df = df.astype(int)
{key: [s for s in a[key] if s not in b.get(key, [])] for key in a}
GEN_RUNNING
a.shape
test()
a * c == b * d
sherr.pop()
MULTI()
any(x in myDict for x in myList)
users = User.query.all()
parent.wait(5)
[unicodedata.category(c) for c in a]
path, module_name = os.path.split(module_path)
file.seek(2)
p.start()
Response(serializer.data)
args = parser.parse_args()
ordered[k] = mydict[k]
bar.py
res.append(total_sum - 2 * sum_smaller + x * (2 * num_smaller - i))
tuple(x for x, y, z in G)
plt.matshow(df_confusion, cmap=cmap)
5 < (1, 2)
s = [[0] * 4] * 4
curs.execute(sql_command)
arr[i:] + arr[:size - (len(arr) - i)]
K.set_value(self.model.optimizer.lr, lr - 10000 * self.losses[-1])
s.sendmail(me, you, msg.as_string())
type(b).mro()
logger = logging.getLogger()
kclass.append(min(data_list))
directory = os.path.realpath(directory)
x = np.hstack((x, x[::-1]))
timings.sort()
print(Xc.todense())
datetime.date(first.year, first.month, lastday)
doSomething(line.strip())
p(sys.path)
self.wfile.write(np.array(buf).tostring())
np.isnan(b)
test2(*args, **kwargs)
pairs = {(x, x + 2) for x in primes if x + 2 in primes}
ser.close()
walk_dict(d)
Y = X.reshape(9, 4, 1).repeat(4096, 2)
df = df.stack()[[1, 0]].reset_index(level=2, drop=True).reset_index()
self.table.installEventFilter(self)
t.daemon = True
print(result)
1125, 1125, 1125, 1125, 1125, 1250, 1062, 1250
qq.close()
rest = list(i)
app = QtGui.QApplication(sys.argv)
bigram_measures = nltk.collocations.BigramAssocMeasures()
df1 = df.unstack(0)
ax1.plot(xvals, yvals, linewidth=4)
start_response(status, headers)
ax.add_patch(clip_path)
c = np.concatenate((a, b))
gray = cv.CreateMat(img.height, img.width, cv.CV_8UC1)
print(hashlib.sha1(str(a_sorted_list)).hexdigest())
list(dict(reversed(items)).items())
globals(), pickle.loads(pickled_name), pickle.loads(pickled_arguments)
L = L[::-1]
result = np.zeros_like(b)
y = x
im2, = ax2.plot([], [], color=(0, 0, 1))
r = requests.post(url, files=files)
keys
do_something_with_update(MsUpdate)
df = pd.concat(df_list)
a = np.arange(1, n * m + 1).reshape(n, m)
Repo.clone_from(git_url, repo_dir)
plt.show()
print(urls)
print(delta.total_seconds())
p.print_stats()
results.append(tag)
plt.close(fig)
ax.legend(proxies, descriptions, numpoints=1, markerscale=2)
y = [4, 5, 6]
ax.xaxis.set_ticks(df.index)
df.index
xx, yy = np.meshgrid(x, y)
cur = conn.cursor()
show()
np.column_stack(np.nonzero(result))
Base = declarative_base()
parking_rows.append(ParkingLotRow((1, 20), (496, 41), 25))
sublist.append(i)
y.set_color(label_colors[y.get_text()])
out.flush()
plt.show()
print(repr(combined_astr))
c = a[(ii), :]
ax.add_patch(ellip)
X_train = clf.fit_transform(X_train)
iT += 1
ar = [int(i) for i in input().strip().split()]
gibberish(4)
print(char2, len(char2), len(char2[0]))
textbox.pack()
layout.addWidget(picture)
x = np.isnan(A).ravel().nonzero()[0]
response
contents = output.getvalue()
result = mysql_cursor.fetchone()
set(a) < set(b)
list(query_set)
mark_safe(form_as_div)
help(str.join)
df
self._get_frame_nos()
print_tree(child, indent=next_indent, last=next_last)
dfile.flush()
B()
name = models.CharField(max_length=255)
bullet.DISABLE_SIMULATION
ax.yaxis.set_label_coords(labelx, 0.5)
xs.sort(key=len)
text[-1] + backward(text[:-1])
M.ix[(0, 1), (0, 1)] = 1
ax.set_axis_off()
df2 = pd.DataFrame(d1)
my_path = os.path.abspath(__file__)
session = Session.objects.get(session_key=session_key)
l[n:] = [0] * (n - len(l))
toplevel.update_idletasks()
img = filedescriptor.read()
root = tk.Tk()
do_pre_install_stuff()
ax = plt.gca()
Base.metadata.create_all(engine)
getattr(self.obj, key)
soup.root.contents[0].name
result.append((k, length, index))
serv.start()
print(df.to_csv())
G.add_edges_from((i, j) for i, j, sim in edges if sim >= THRESHOLD)
pipe = Popen(command_2, shell=True, stdin=PIPE, stdout=PIPE)
lines = set(f)
model = Sequential()
my_dict[key[-1]] = value
bc.as_datetime()
print(cell.text_content())
s.cookies.save()
ax = plt.subplot(111)
data = [np.arange(8).reshape(2, 4), np.arange(10).reshape(2, 5)]
f.write(line)
print(len(s))
proc.start()
print(np.exp(-(A + B)))
now = datetime.now()
admin.site.register(Author, AuthorAdmin)
pos = nx.spring_layout(G)
plt.figure(4)
idx = np.clip(idx, 1, len(A) - 1)
my_map.etopo()
pd.notnull(np.nan)
print(random_list)
self.assertEqual(target.int(), b10)
gevent.spawn(test)
setattr(self, attr_name, fn(self))
num if start < num < end else start if num <= start else end
app = QtGui.QApplication(sys.argv)
plt.imshow(imgmap, zorder=4)
vline.set_xdata((x, x))
ax1 = fig.add_subplot(221)
fig, ax = plt.subplots()
c = p.stdout.read(1)
cap1.set(4, 120)
df
cursor.close()
groups = Group.objects.filter(player=p1).filter(player=p2)
myArray.__len__()
gevent.joinall(jobs)
result_queue = Queue()
parser.parse_args()
convert_dict(v)
theList[4:7] + theList[12:18]
A[1] = previous_A[1]
plt.colorbar()
print(list(dd.keys()))
manager.start()
im = Image.open(filename)
msmdsrvini.close()
array_c.append(x)
ogl.CGLSetParameter.argtypes = [ctypes.c_void_p, ctypes.c_int, ctypes.c_void_p]
sess.run(init_op)
csv2.readline()
pool.close()
setattr(self, k, v)
np.take(x, lin_idx)
time.sleep(1)
data = f.read(BUF_SIZE)
logger.removeHandler(logger.handlers[0])
img.save(filename)
itineraryArray.itinerary.append(itinerary0)
np.complex(0, 1)
print(len(your_list))
pylab.xticks(list(range(len(allinterests))), allinterests)
db = SQLAlchemy(app)
f = f.simplify()
ax2.set_ylim(0, ax2.get_yticks()[-1])
sorted_KP.remove(item)
mask = array1 == array2
layout.addWidget(self.button)
g = gevent.spawn(urllib.request.urlopen, url)
d = (1 + math.sqrt(1 + 8 * len(condensed_matrix))) / 2
example[4:1] = [122]
t.start()
self._db = db
print(line)
operator.add(1, 2)
xml.sax.xmlreader
self.serve_forever()
self.txt = ScrolledText(self.root, undo=True)
initdelorean()
initfoo()
print(data)
time.sleep(0.1)
time.sleep(0.5)
c = t[2]
worksheet.set_column(i, i, column_len)
max(0, -n.as_tuple().exponent)
args = parser.parse_args()
co.co_code, co.co_consts, co.co_names
ax.barh(ind, vals, width, color=colors)
first_name = models.CharField(max_length=50)
itertools.combinations(stuff, 4)
file.close()
[10, 4, 1]
print(resp.read())
clusters.setdefault(v, []).append(k)
df1.apply(assign_metric_vals, 1)
ax.plot(x, y)
y_train = np.random.randint(0, 10, [50])
random.uniform(float(start), float(start + width))
s.sendmail(me, you, msg.as_string())
fig, axes = plt.subplots(nrows=2, ncols=2, sharey=True, sharex=True)
fig = plt.figure(figsize=(9, 9))
pprint.pprint(gc.get_referrers(l))
x + y
A[:, (0)] = A[:, (D2 - 1)]
s.recv_info(q)
self._bar
diff = np.empty_like(img1)
time.sleep(0.5)
b.max()
x[1][0:2][2]
ser.close()
asyncore.dispatcher.__init__(self)
L = [0] * 10
fig = plt.figure()
ax.xaxis_date()
(2 ** i for i in range(n))
timer.start()
model1.objects.create()
colors = np.linspace(0, 1, N)
result = Image.fromarray((visual * 255).astype(numpy.uint8))
f2.write(Lines[i])
gram_matrix
pd.read_clipboard()
print(res.first_name, res.last_name)
myDict[key] += value
timediff.total_seconds()
eval.__text_signature__
np.allclose(diam, dam_out)
ax.set_yticks(np.arange(0.5, 10.5, 1))
ax2 = plt.subplot(1, 2, 2)
engine = create_engine(dbconninfo)
value = cache[key] if key in cache else cache.setdefault(cache, func(key))
B.objects.create(a=some_a)
tuple(sum(base_lists, []))
df1 = pd.DataFrame([x for x in df2.teams])
asyncore.loop()
min(list(res.items()), key=itemgetter(0))[1]
Image.composite(img, blurred_halo, ImageChops.invert(blurred_halo))
x, y, z = z, x, y
sum_digits(1969)
t.start()
out.close()
main()
p = webdriver.FirefoxProfile()
genn(igap, igap + 1)
toolsmodule.printdatabase()
buffer.append(line.strip())
figure.show()
plt.plot(list(range(10)), x, next(linecycler))
print(type(f))
self.harmstat = harmstat
map(lambda t: t.start(), tlist)
print(df.values)
c = nprect(1, x)
gmpy.divm(1, 4, 8)
self.particles = []
fig, ax1 = plt.subplots()
app = QtGui.QApplication(sys.argv)
[(x, list(y)) for x, y in groupby(mylist, get_field_sub)]
selobj.path
out.append(int(n))
print(A[i, j, B])
a, x, b = np.asarray(a), np.asarray(x), np.asarray(b)
results = map(process_file, [os.path.join(dirname, name) for name in names])
doc = etree.parse(f_source, parser)
curses.noecho()
s.connect((host, port))
plt.figure()
ax.coastlines()
ax1 = fig.add_subplot(111)
print(response.status_code)
lst.sort(key=MyStrOrder)
list(sum(tupleOfTuples, ()))
pet.say()
thread.start()
util.log_to_stderr(level=logging.DEBUG)
arr[mask] = np.nan
c = db.cursor()
httpdkenlogger.addHandler(fh)
print(str.isdigit.__doc__)
c = array([a, b])
pilimg.show()
r = requests.get(url)
sys.exit(0)
self.finish()
pyl.clabel(CS, inline=1, fontsize=10)
print(A.func1.__doc__)
words = my_string.split()
binary_f(lambda x: f(x) != val0, list)
c.setopt(c.WRITEFUNCTION, data.write)
GPS_EPOCH + datetime.timedelta(seconds=t1_seconds, microseconds=t1_us)
myThread.join()
D = sorted(C, key=lambda x: x[1])
[dict(e) for e in set(lst).difference(dups)]
[0, 0, 0, 0, 0, 0, 0, 162, 1, 164],
dict(form=form)
root.mycontainer.myattr
a.start()
channel = connection.channel()
np.cross(a, b, axisa=0, axisb=0)
setp(ax.get_xticklabels(), fontsize=8)
t.start()
json.dump(row, sys.stdout)
self.output_logger
boundaries = [i for i in range(1, len(x)) if x[i] != x[i - 1] + 1]
temp[0] = 1
p = subprocess.Popen(args, stderr=sys.stdout.fileno(), stdout=subprocess.PIPE)
self.initial_parameternameX = self.parameternameX
x = f.readline()
hash_md5.hexdigest()
print(tuple([a]))
a = np.asarray(a)
timerthread[0].start()
bisect_right(a, x)
sys.stderr.write(highlight(tbtext, lexer, formatter))
result.addFailure(self, sys.exc_info())
[(i * i) for i in range(5)]
im = Image.open(StringIO(fd.read()))
a.replace(b, c)
Base.metadata.create_all(self._conn)
pool.close()
self.transport.write(data)
a.sort(key=lambda x: x[1], reverse=True)
print(channel.recv(1024))
ax.legend_.remove()
self.deletecommand(funcid)
C = np.searchsorted(A, B)
df.iloc[-6:-1]
ssh.load_system_host_keys()
x = np.arange(20)
isect.append([event[0], 0])
deletedictionary[oldkey]
print(a - b)
print(x.most_common())
print([row for row in r if row])
print(args)
root.config(menu=menu_bar)
print(list(solve(x)))
result_s.casefold() == result_s.casefold()[::-1]
df = pd.concat(df)
pdb.Pdb.setup(self, f, t)
sum(i for i in x if i in y) * w[i] / sum(i for i in x) * w[i]
print(sys.path[0])
buffer += ser.read(ser.inWaiting())
self.request.user
test2 = pd.concat(data, ignore_index=True)
print(key, my_dict[key])
ax1.set_xticklabels(data.columns)
self.driver = webdriver.Firefox()
db_crsr.close()
p.start()
inotify.close()
zipfile.ZipFile(memory_zip)
min(cluster, key=lambda t: abs(ts - t))
window = MainWindow()
f.seek(0)
pprint.pprint(data)
plt.show()
here = os.path.dirname(os.path.realpath(__file__))
s.setsockopt(socket.IPPROTO_IP, socket.IP_HDRINCL, 1)
a.to_frame().join(b.to_frame())
q.shape
dict.__init__(self, *args, **kwargs)
output.addPage(page)
table.insertRow(rowPosition)
piechart[0][i].set_hatch(patterns[i % len(patterns)])
print(repr(y))
server.starttls()
func(*params)
print(count)
f = {x: make_func(x) for x in range(10)}
now = datetime.now()
bcut.ax.patch.set_visible(False)
data = sys.argv[1]
print([dict(zip(list(options.keys()), p)) for p in product])
image.set_from_pixbuf(handle.get_pixbuf())
result()
sympy_exp.evalf(subs={a: 6, b: 5, c: 2})
foo = lambda x, y, z: x + y + z
[[1, 1], [1, 2], [2, 2]]
A[j], A[k] = A[k], A[j]
get_current_fig_manager().window.raise_()
plt.subplot(211)
A.resize((D1, D2 - 1), refcheck=False)
self._current_browser()
result = []
app.register_blueprint(chat)
[1, 4, 7, 10]
dic[keys[-1]] = value
matchingVals = [x for x in a if x > 2]
ax1.get_xaxis().set_major_formatter(ticker.FuncFormatter(my_formatter_fun))
pylab.setp(ax.get_xticklabels(), visible=True)
file.seek(line_offset[n])
{i: zip(*np.where(z == i)) for i in np.unique(z) if i}
p = Process(target=f, args=(d,))
print(ned)
setattr(inst, self.name, value)
True
columns.append(cd[0])
[foo, bar]
A = np.random.randint(0, 1000, 10000)
x = random.randrange(0, maxx)
print(x)
set(l1) | set(l2)
logging.Formatter.converter = time.gmtime
decimal.Decimal(-1200).exp()
sum(i * i for i in range(5))
ax.plot(x, y)
ng.append(history[_id])
fig = plt.figure()
help(math)
cat.head(15)
pool.join()
df = pandas.DataFrame(dfdict)
today = date.today()
help(Assignment)
sys.modules[name] = module
b = a[:]
print(func(x))
lines = [l for l in r]
a = np.empty((1,), dtype=np.object)
a[1:1] = [6, 7]
os.path.join([conf.TEMPLATES_UPLOAD_DIR, filename])
print(C.b.__doc__)
self.axis = self.figure.add_subplot(111)
testsite_array = f.readlines()
print(reverse_cumsum(array))
max(files, key=filetimestamp)
print(vc[vc > 2].index[0])
instance = Child.do_something(instance)
f.write(br.response().read())
top.after(1000, start, False)
sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
img = Image.open(image)
deletev[:-1]
client.service.GetWeatherInformation()
show()
page = f.read()
pvt.apply(lambda x: x / pvt.sum(1))
norm = matplotlib.colors.Normalize(vmin=10.0, vmax=20.0)
self.value.increment()
f()
print(x)
df.append(row)
ax = fig.add_subplot(111)
res = f(*args, **kwargs)
4 / float(100)
timestamp = d - datetime(1970, 1, 1, tzinfo=pytz.utc)
gtksink.props.widget.show()
print(mail.unread())
ax.get_yaxis().set_major_formatter(ticker.FuncFormatter(comma_format))
b = a + b
api / __init__.py
df = pd.concat([df] * 10000).reset_index(drop=True)
output = f.read()
map(np.max, np.split(v, np.where(mask)[0] + 1))
arr = np.empty(shape, dtype=object)
result = []
local_filename
--startas / tmp / testdaemon.py
fig, ax = plt.subplots()
draw.line((0, 0) + im.size, fill=128)
plt.gca().add_patch(plt.Circle((posx, -posy), radius=0.1, fc=color))
fliers[i].set_data([fdata[0][id], fdata[1][id]])
b.clicked.connect(self.processButton)
linesamples.add(int(4 * i + 0))
719529
a = np.arange(10)
transaction.rollback()
K[K.argsort()[-5:]]
writer = csv.writer(outfile)
[item[0] for item in d1.items() if item[1] == 55][0]
get_value(dic, 70)
(2 ** 52) ** (log(b, 2) - log(a, 2))
print(list(flatten_group(a)))
ylim(ax1.get_ylim())
print_matrix(matrix, size)
B.nbytes
g in df.index.values
pandas.concat(df_l)
t.start()
result
show_url.allow_tags = True
print(string)
[row[cols] for row in self[rows]]
m = (1 << bits) - 1
funcs.append(func)
print(np.unpackbits(xp))
[2, 2, 2]
imouto.name
numpy.column_stack((a, b))
print(item)
X[0] - a
sum([0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1])
plt.pcolor(X, Y, f(data), cmap=cm, vmin=-4, vmax=4)
pygame.camera.init()
sock.connect((host, port))
a_set
(np.expand_dims(a, -1) == np.expand_dims(b, 1)).sum(axis=-1).sum(axis=-1)
sched.start()
map(functools.partial(add, y=2), a)
[tdgi(item) for item in theList if tdin(item)]
a.set_yticklabels([])
pool.close()
os.getcwd()
print(better_uc)
deleteself._x
ax = fig.add_axes([0, 0, 1, 1])
message = email.message_from_string(email_data)
yaml.add_representer(collections.OrderedDict, dict_representer)
a.pop(2)
consumer.start()
curses.initscr()
self.manager.start()
dlclose(handle)
ws.send(msg)
comprehended.repeat()
list(reorder(a))
soup = BeautifulSoup(html, convertEntities=BeautifulSoup.HTML_ENTITIES)
len2 = math.hypot(x2, y2)
metadata.append(row)
ax1.set_title(title)
doc = html.fromstring(content, base_url=url)
plt.draw()
warnings.showwarning = customwarn
print(D[key])
self.pw.pic = ImageTk.PhotoImage(image)
fig.subplots_adjust(left=0.25, bottom=0.25)
img = image.resize((188, 45), Image.ANTIALIAS)
current.start()
sorted(structure, key=keyfunc)
df_s.groupby(cols).apply(Full_coverage_nosort)
os.mkdir(dirname)
1, 2
ssh.close()
pp([dict((attr.tag, attr.text) for attr in el) for el in et.fromstring(xs)])
x | y
x * np.sqrt(y)
app.MainLoop()
self.model = QtGui.QStandardItemModel()
self.__key__() < other.__key__()
print(A[np.searchsorted(A[:, (0)], I)])
self.sizer.Add(self.button, flag=wx.EXPAND | wx.ALL, border=5)
RenderJSON(your_json)
getattr(object, f)
a.read()
()
c = [(a[i] + b[i]) for i in range(len(a))]
columns = [m.key for m in model.__table__.columns]
root = tk.Tk()
pickle.dumps(picklable)
[average(n) for n in zip(*l)]
thread = threading.Thread(target=server.serve_forever)
self.deletecommand(funcid)
ax = plt.gca()
UPPER[LOWER.index(s)]
tup[:ix] + (val,) + tup[ix + 1:]
bokeh.io.save(layout)
house_list.append(House(str(new_house)))
db.session.query(Vehicle).filter(str(Car.id) == Vehicle.value)
print(textwrap.fill(str(collections.Counter(chars)), width=79))
key = operator.itemgetter(0)
time.sleep(polling_interval - work_duration)
sys.exit(app.exec_())
HttpResponse(simplejson.dumps(user.toJSON()))
t1.save()
sess.query(Tag).distinct(Tag.name)
dc = wx.ClientDC(self)
sess = tf.InteractiveSession()
self._classes = {}
net._setParameters(new_params)
fig = plt.figure(1)
raise Http404()
axes_2.axis([-5, 5, -5, 5])
x = 2
display.popen.kill()
print(cell.text)
df
pd.read_csv(io.StringIO(t), header=0)
process2.wait()
f.write(data)
plt.plot(X, Y2, lw=4)
pandas.get_dummies(input_df)
print(check_for_triangle(tri2, lines))
self.mainframe.columnconfigure(column, weight=1)
b = TestC()
cm.print_stats()
result = [foo(p1, p2) for p1 in people for p2 in people if p1 != p2]
z = np.array([False, False, False, False])
isdefarg()
max(sum(tableData, []), key=len)
self.cowButton.grid(row=0, column=0)
br.form.fixup()
x = list(df1.columns.values)
plt.show()
self.close()
dbconn.commit()
a = []
uppers.append(word) if word[0].isupper() else lowers.append(word)
urllib.request.urlopen(req)
t = tuple(reader)
self.image.set_from_pixbuf(self.loader.get_pixbuf())
id = Column(Integer, primary_key=True)
self.lineedit.clear()
out = np.asarray(out).reshape((xsize, ysize))
connection = engine.connect()
c1.setopt(pycurl.PROXYTYPE, pycurl.PROXYTYPE_SOCKS5)
print(list(iter(root)))
img = Image.open(FILENAME)
print(ned)
wx.Panel.__init__(self, parent=parent)
a[1].value
file.close()
print(df.types)
cb = fig.colorbar(surf)
inspect.isclass(o) and issubclass(o, A)
d.close()
fig, ax = plt.subplots()
curl.setopt(pycurl.WRITEFUNCTION, buff.write)
user1 = forms.ChoiceField(choices=[])
t.play()
deleteL[i]
pprint.pprint(l)
print(a[:, (2)])
win.refresh()
layout = QtGui.QVBoxLayout(self)
count += 1
time.sleep(1)
df1
np.exp(-z) * np.sin(t - z)
self.timeout = timeout
body = models.TextField(null=False, max_length=1024)
s = s.lower()
self.i += 1
isinstance(obj, tuple)
foo.close()
result.append((g[0][0], g[-1][-1], k))
listWidget.insertItem(item)
G.add_node(2, pos=(2, 2))
list(Counter(words).keys())
self.handle_read_callback(self)
sess.run(init_op)
fig = plt.figure()
count = (sums.reshape(-1, s1.shape[1]) == 0).all(1).sum()
p1 = Thread(target=process_output, args=(dcmpid,))
html = urllib.request.urlopen(url).read()
p.start()
x = copy.copy(x)
parse_qs(parsed_url.query)
fig, ax = plt.subplots()
array([2, 0, 1])
regex.match(data.getvalue())
perms.append(map(list, zip(*tables)))
desks
all(some_func(x) or True for x in some_list if x > 5)
window = tk.Tk()
[1, 0, 2, 1]
ws.column_dimensions[col].width = value
print(data)
self.assertEqual(2, 2)
glEnd()
b = random.randint(0, 20 - a)
u.save()
cal.save()
count = (array_1d == row_scalar).sum()
any(s in l for l in lines1 for s in search_strings)
fig = plt.figure()
b * X(X, b - 1) if b > 0 else 1
instance.save()
np.isnan([nan, nan])
y = np.concatenate(y)
accept.stop()
line = line.rstrip()
celery.init_app(app)
A(1, 2).asdict()
a if len(a) < len(b) else b
plt.show()
sys.__excepthook__(type, value, tb)
filename = os.path.basename(path)
print(i)
df.replace(eq, 1, inplace=True)
self.running = False
getattr(os, s)()
print(x)
Thread(target=process_output, args=[process]).start()
prices[:-1] / prices[1:].values - 1
math.ceil(4500 / 1000.0)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
a + b
list(kw.values())[0]
x + y
clf.fit(X, y)
help(__future__)
fig, ax = plt.subplots()
reactor.stop()
df = df.stack().reset_index()
print(str(some_delta))
imgaxes.set_xlim((x1, x2))
np.sin(theta, out=x[:, (1)])
socket.setdefaulttimeout(60)
text.set_color(color)
self.worker.flag = True
row.append(np.array(list(range(0, num_rows))))
self.select_range(self.position, Tkinter.END)
a.count(item) == 1
print(hello())
[_f for _f in pattern.split(s) if _f]
np.place(dat, np.in1d(dat, old_val), new_val)
os.killpg(os.getpgid(pro.pid), signal.SIGTERM)
patcher.start()
data = np.arange(1, 7)
print(b.z)
person = find_person(people_list, name)
f(n)
print(line)
ax.invert_yaxis()
indices = tf.constant([0, 2])
dict((c, getattr(model, c)) for c in columns)
s = f.getvalue()
isinstance(0, collections.Sequence)
self.neighbours = 0
app = QApplication(sys.argv)
vol += [volume[key] for key in sorted(volume)]
soup = BeautifulSoup(page)
(a, rec[a]), (b, rec[b])
w.maximize()
x, y = np.meshgrid(X, Y)
obj.user.save()
current_user.append(line[6:].strip())
doc = BeautifulSoup.BeautifulSoup(req.content)
group.delete()
cursor = con.cursor()
max_index = np.argmax(a[inds][mask])
obj.starts += timedelta(days=1, hours=2)
a + b + c
df.columns
tcp_send(pickle.dumps(dict))
output = os.rename(infilename, newname)
f.read()
html.format(model=model, content=data, theaders=theaders)
[convert(i) for i in obj]
max(map(len, line.split()))
f.close()
plt.legend(recs, classes, loc=4)
opener = urllib.request.build_opener()
next(f)
print(sum(1 for x in l if my_condition(x)))
DBSession.commit()
ax2.set_yticklabels(new_labels)
set(chain(*list(obj.values())))
M[row, col]
list(d.values())
m.drawcoastlines()
random.choice(self.items)
[1, 2, 1]
os.makedirs(save_path)
print(len(f.read()))
arr.reshape(arr.size / 2, 2)
rev_multidict.setdefault(value, set()).add(key)
self.lock = threading.Lock()
glViewport(0, 0, width, height)
diff = [round(abs(x / float(y)), 1) for x, y in pairwise(your_iterable)]
self.conn = MySQLdb.connect()
d[item[0]].append(item)
a[0] = c
df
ax.set_xticks(np.arange(data.shape[1]) + 0.5, minor=False)
pyplot.plot(x, y)
p.start()
n % k == 0
setattr(self, k, v)
Example().run()
interned
_odbcinst_UserINI(szFileName, FALSE)
request.finish()
plt.figure()
pl.plot_surface(X, Y, Z, alpha=0.4)
p.join()
a = np.zeros((2, 2))
process(line)
df = pd.DataFrame(dict(zip(*v)) for v in vals)
print(data)
pprint(stiff.subs({(-nuxy - 2 * nuxz ** 2 + 1): m}))
self.setGeometry(100, 100, 500, 190)
any(i in setA for i in rng)
prefixes[key[:-1]].append(key)
plt.tight_layout()
self.tree.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
math.sqrt(x * x + y * y), math.atan2(y, x)
self.currentStack.append(obj)
ax.plot(x, y)
a = []
time.sleep(0.01)
isinstance(Ham2(), Ham1)
c.setopt(c.URL, url)
security_adapter.set_enable_user_folders(True)
print(list(a))
divisors.append(i)
X[:, start:end] = x
next(tuesdays_of_february)
result = []
interruptable_get(q)
print(nextmatch)
newroot.insert(0, root)
df.diffs[idx] = df.value[idx].diff()
HTMLParser.__init__(self, *args, **kwargs)
writer = csv.writer(f)
tool.stdout.close()
dists.dot([1, 1, 1, 1])
ax = plt.subplot(111)
plt.show()
print(resp.read())
soup = BeautifulSoup(html)
m.load()
plt.show(False)
result.add(tuple(sorted(factors)))
instance.save()
pythons_psutil[0].memory_info()
mask = np.isnan(arr)
cur = con.cursor()
new_dict[k] = filmswiththisname
tkinter.createfilehandler(file, mask, callback)
np.fromiter(v[0] for v in data)
funcs[0]()
prev.next = tmp.__next__
print(df1)
plt.hist(numpy.log2(data), log=True, bins=bins)
time.sleep(60)
os.getcwd()
ax.loglog(x, y)
sys.stderr.write(s)
ax.add_patch(patch)
content = wiki2plain.text
print(a.shape, b.shape)
(x < 255 * p).reshape(shape)
collection.save(res)
tmp.write(line)
main()
_, max_value = max(data, key=lambda item: item[1])
reactor.run()
Gtk.main()
ax.set_yticks(k)
i.active()
main()
locals().update(main())
B = [b for _, b in sorted(zip(order, sorted(B)))]
client = Client(url)
img_temp.write(urllib.request.urlopen(url).read())
a = np.arange(27)
self.ax.xaxis.set_minor_locator(day)
self.stop()
ax2.yaxis.tick_right()
B.T[r, c] = B.T[c - r, c]
m.start()
re.findall(pattern, string, flags=0)
[X, Y] = np.meshgrid(x, y)
os.setsid()
df.ix[row, key] = val
[0, 0, 1, 1, 1],
link.pack()
{k: sum(map(itemgetter(k), dict1)) for k in dict1[0]}
new_queue[key] = queue[key]
main()
ax.legend()
bpy.ops.transform.translate(value=(0, 0, v.length / 2))
parser = argparse.ArgumentParser()
db = SQLAlchemy()
self.noisycount += 1
self.quietcount += 1
content
text += elem.strip()
os.chdir(directory)
json.loads(data)
print(m.group(2))
__init__.py
any(keyword in string for string in c_lst for keyword in k_out)
df.columns.levels[0]
self.status.configure(text=message)
self.scrollbar.config(command=self.data.yview)
all(x.count(value) == number for x in lst)
net.stop()
self.Bind(wx.EVT_LEFT_UP, self.on_left_up)
dir(__builtins__)
self.suggestions = []
opener = urllib.request.build_opener(auth_handler)
out.write(f.read())
self.text = tk.Text(root)
plt.xticks(rotation=90)
x.normalize().to_eng_string()
list(a)
self.treeview.collapse_row(row.path)
otherfoo.bar()
df.index = [np.arange(len(df.index)), df.index]
data = []
ghostscript.Ghostscript(*args)
a + b
print(type(b))
X[k, k] = exp_diag[k]
self.__dict__.copy()
e.foo()
p.data
self.cache[key] = self.func(*args, **kwargs)
plt.bar(idx, c[0], color=hexencode(c[1]))
conn = cx_Oracle.connect(conn_str)
sock.close()
fig.colorbar(im, ax=axes.ravel().tolist(), shrink=0.5)
print(a, b)
PyObject_HEAD_INIT(NULL)
reader = csv.reader(ifile)
time.sleep(0.5 * random.random())
my_copy = {key: value[:] for key, value in list(my_dict.items())}
app = QApplication(sys.argv)
print(list(d(myset)))
btn2.pack()
A[i], A[j], A[k] = new_values
emp.save()
get_stuff(d, get_value, get_subitems)
d[0]
l.extend((21, 22))
np.exp(a * np.log(x) + np.log(b))
d.pop()
print([x for x in thing])
out = np.hstack([xyzcols, eyecols])
[1, 2]
plt.show()
stream = cStringIO.StringIO()
print(Counter(data).most_common())
writer.writerows(enumerate(word_features, 1))
y = np.zeros(yshape, data.dtype)
x = np.linspace(-5, 9, 10000)
f2.write(f1.read())
self.root.clipboard_append(self.msg)
abs(a - b) <= chosen_value
(0.25).as_integer_ratio()
alist = [(1, 6), (2, 5), (2, 4), (7, 5)]
self.logger.info(data)
ssl._create_default_https_context = _create_unverified_https_context
x = np.linspace(0, 1, 50)
float_array.tofile(output_file)
sys.modules[__name__] = MyReprModule(sys.modules[__name__])
val ^ 1
df.some_property
colors.extend(mpl.cm.jet(np.linspace(0, 1, N - 1)))
etree.tostring(root)
form = EditProfile(obj=user)
partition = lambda p, xs: (list(filter(p, xs)), [z for z in xs if not p(z)])
parser = argparse.ArgumentParser()
print(string.format(**dictionary))
isgenerator(), istraceback(), isframe(), iscode(), isbuiltin()
print(get_extension_id(sys.argv[1]))
self.obj[name] = value
_list.extend(list(range(r[0], r[1], r[2])))
func(*args, **kwargs)
data[:i]
next(obj for obj in objs if obj.val == 5)
exec(f.read())
cv2.drawContours(convexI, [ConvexHull], -1, color=255, thickness=-1)
out = np.column_stack((out_id, out_count))
[]
output[token.lower()][line[t + 1].lower()] += 1
rgb = hsv_to_rgb(hsv)
print(match.start(), match.end())
writer = csv.writer(outfile)
self.doc.build(pdf)
tot.append(get_count(data, binmin, binmax, inclusive))
A = numpy.array([(a, 0, 0), (c, d, 0), (0, 0, 1)], dtype=np.float64)
pd.Series(dic)
cap = cv.CaptureFromCAM(0)
fig = plt.figure(figsize=(xinch, yinch / 0.8))
plt.boxplot(x + i * 2, vert=0)
1
setattr(obj, field_name, sub_object)
app.add_url_rule(url, url, redirect_url)
keys.sort()
fileHandler.setLevel(logging.FATAL)
ent.delete(0, END)
l1.extend(l2)
df
list(json_object[0].items())
writer = csv.writer(g)
c[key] = list(set(a[key]).difference(b.get(key, [])))
execlist[i][1] = myctype
time.time.__name__
df = pd.DataFrame()
print((df[0] == 0).idxmax())
document.openProtection(spm)
self.model = QtGui.QStandardItemModel(self)
()
Example().run()
json.dumps((i * i for i in range(10)), iterable_as_array=True)
dfy.apply(lambda x: x.between(df.FIRST.dt.year, df.LAST.dt.year)).astype(int)
Bar.bar()
print(colorful_json)
all(it1) or not any(it2)
form.instance.author = self.request.user
driver = webdriver.Firefox()
data[0](*data[1:])
L = list(L[0]) if len(L) == 1 else L
pi.save()
img.paste(source, mask=border)
startupinfo = subprocess.STARTUPINFO()
interact(set_cursor, x=ax.get_xlim(), y=ax.get_ylim())
int(list(filter(str.isdigit, repr(nums))))
soup.body.clear()
i = len(s)
ax = fig.add_axes([0.1, 0.1, 0.7, 0.85])
x = x + 1
dialog.setFileMode(QtGui.QFileDialog.ExistingFile)
type(d)
A.__init__(self, x, y)
res = func(*args, **kwargs)
z = np.sqrt(x ** 2 + y ** 2) + np.sin(x ** 2 + y ** 2)
True
c = [a[i] for i in b]
root.grab_set()
self.textLayout.addWidget(text)
t.start()
im.draw(x=0, y=0, z=0, width=fig.width, height=fig.height)
t = np.linspace(0, 4 * np.pi, N)
f()
cr.set_operator(cairo.OPERATOR_OVER)
divisibleBySeven = [num for num in inputList if num and num % 7]
app.register_blueprint(my_view)
is_equal(df, using_precomputation, using_apply)
print(t.render(c))
writer.writerow(Digi_Results)
[2, 499]
np.eye(1, size, index)
fig = pl.figure()
d[9].append(100)
browser = mechanize.Browser()
cap = cv2.VideoCapture(0)
t = np.hstack((np.zeros_like(a), np.ones_like(b)))[s]
img = Image.open(filename)
ax.margins(0.05)
fig = pylab.figure()
parts[i] = re.escape(parts[i])
zip(*args)
a.append(1)
p.close()
t1 = threading.Thread(target=task1)
background = pygame.Display.set_mode()
L = [15, 16, 57, 59, 14]
ylim(0, 10)
get_monotonic_nums(2, reverse=True)
0
settings.init()
self.qa.save()
fileSet.add(os.path.join(root[len(myFolder):], fileName))
d.shape
self.label.installEventFilter(self)
self.root.mainloop()
t.start()
main()
self.caddr = caddr
Person.first_name
s.value_counts()
fp.close()
out_im.putdata(list(image2cga(inp_im)))
pygame.init()
xmin, xmax = kde.get_xlim()
type.__init__(cls, name, bases, dct)
type(a)
p.map(f, range(m1.shape[0]))
unique_combs(A, 4)
date = parse_date(date_str)
axes.set_yticks(list(range(10)))
part.get_payload(decode=1)
ax.set_xlim(xmax=100)
main()
g = partial(f, 1, 2)
isinstance(P, (collections.Sequence, np.ndarray))
print(i, Counter(clf.predict(X[50:])))
{k: v for k, v in list(locals().items()) if k in args}
os.dup2(test.fileno(), 1)
all_pixels.append(cpixel)
pygame.draw.circle(screen, (50, 0, 0), p, 10, 2)
b = B()
d = dict(((k.lower(), j), v) for (k, j), v in list(d.items()))
sorted_df = df.T.sort(columns=last_row_name).T
df
files = [os.path.join(search_dir, f) for f in files]
b.myfun()
j = np.random.randint(0, 5)
Py_DECREF(array)
redemption_date.month
myFunction()
im.thumbnail(thumbnail_size, Image.ANTIALIAS)
m = np.array([7, 6, 5, 4])
img = Image.open(filename)
_ = sock.recv_into(mview, AMOUNT)
sess = tf.Session()
opener = urllib.request.build_opener(cookie)
fig, ax = plt.subplots()
add_patch(axes[2], rasterized=False)
print(line)
a2[a2[:, (1)] > 10]
time.sleep(0.1)
print(df)
result = a[indices]
QtGui.QSystemTrayIcon.__init__(self, icon, parent)
seconds = seconds % 60
fig = plt.figure()
df = pd.DataFrame(testdict)
d1 = dict(list(d.items())[len(d) / 2:])
1.0 / np.linalg.det(a)
client.sd[0].service.setlocation(new_url)
fig = plt.figure()
handle.set_visible(False)
G[1][2]
log.setLevel(logging.DEBUG)
print(docopt(__doc__))
values = np.random.rand(10000)
print(count)
print(m.group())
grid = dask.array.zeros((100, 100), chunks=(50, 50))
[x for x in user_list]
map(sum, l) == [n] * len(l)
wdb.set_trace()
a = pickle.loads(s)
df = df.reset_index()
PLT.show()
column_view.set_widget(column_widget)
random.shuffle(lists)
obj = model_class.objects.get(product=model.product, comment=model.comment)
[str(chr(i)) for i in h]
obj.__reduce__()
entry2.grid(row=1, column=2)
x = np.array([[1, 0], [0, 1]])
next(itertools.islice(self.it, index, index + 1))
print(datetime.now() - startTime)
id(ax), id(fig.axes[0])
c = list(zip(a, b))
button.pack()
parser = argparse.ArgumentParser()
title = models.CharField(max_length=256)
NotImplemented
self.orig_method(*args, **kwargs)
fig.savefig(buf)
sorter = np.argsort(b)
df.iloc[0]
average = session.query(func.avg(sums.subquery().columns.a1)).scalar()
driver = webdriver.PhantomJS()
[6, 15, 24]
my_array = numpy.empty(length)
print(datetime.datetime(1970, 1, 1) + datetime.timedelta(seconds=tt))
ax = fig.add_subplot(111)
parser.print_help()
list(zip(word_list, itemgetter(*word_list)(cnts)))
a, b in x
t = np.linspace(0, 1, n)
parser = argparse.ArgumentParser()
print(lines[i + 7])
print(a, b, c)
False
clf = linear_model.LogisticRegression()
p = argparse.ArgumentParser()
chunkfile.close()
cursor = cnxn.cursor()
f1()
f = np.vectorize(f)
rows = cur.fetchall()
name = models.CharField(max_length=50)
Py_XDECREF(cls)
q = session.query(Post).join(s, Post.id == s.c.key).order_by(s.c.sort_order)
player.play()
wordslist = line.split()
nonRepetitive_x.append(x[-1] + 1)
self.pigButton.grid(row=0, column=1)
[[item[0] for item in data] for key, data in groups]
self.response.out.write(data)
client.close()
dict_writer.writerow(dict(zip(fieldnames, fieldnames)))
print(parts[1])
fn(self, *args, **dict(self.gen_args, **kwargs))
print(line)
df2.combine_first(df1)
data = fp.read()
parser = argparse.ArgumentParser()
print(a.shape)
a, b, c
s.close()
server.ehlo()
my_c_func(py_object(my_list))
ax4.set_xlim(x1[0], x1[-1])
Tk.__init__(self)
L.sort(key=f)
app = QApplication(sys.argv)
h.request(req.get_method(), req.get_selector(), req.data, headers)
random.shuffle(a_list)
tuple(z)
all_data.dtype.names
ax.yaxis.set_visible(False)
max_val = max(l)
p.start()
br.set_handle_equiv(True)
fig = plt.figure()
help(gdal.ReprojectImage)
event.SetInt(0)
((d.month, d.year) for d in rrule(MONTHLY, dtstart=start, until=end))
sys.path.insert(0, mypath)
logger.setLevel(logging.DEBUG)
myList.append(1)
print(df)
print(b.calculate(1))
plt.subplot(122)
X = numpy.random.random((N, n))
json.dumps(xmljson.badgerfish.data(xml))
task2.start()
task1.start()
+bcolors.ENDC
self.photo = Image.open(file)
cache.init_app(app)
reader = csv.reader(f)
os.rename(tmppath, filepath)
merge_dicts(d1, d2)
im = img[:, 0:50, (0)]
s.unstack()
self.im.seek(0)
n = int(x)
gx = np.array([[1, 0, -1], [2, 0, -2], [1, 0, -1]])
urlparse.parse_qs(o.query)
reader = list(csv.reader(f))
lambda realf: f(realf, *args, **kwargs)
objects = UserManager()
self.children.append(node)
p = argparse.ArgumentParser()
self.Bind(wx.EVT_LEAVE_WINDOW, self.on_leave_window)
group.append([year, 0])
self.recipe.name
ax2 = fig.add_subplot(2, 1, 2)
Gtk.CellRenderer.__init__(self)
main()
foo()
thread1.start()
doi_file.close()
f()
func(self, *args, **kwargs)
[k for k, g in groupby(a) if len(list(islice(g, 0, 2))) == 2]
cv.update()
2142
func2b()
x = r * np.cos(t)
dx = 1
print(v.key, v.values[0].value)
print(elem.text)
y.sort()
np.hstack((vector1, matrix2))
plt.xlabel(ax.get_xlabel(), rotation=90)
c = np.linalg.solve(a, b)
alist2.append(alist[x][:])
item = item.strip()
br.open(url)
end_date = start_date + timedelta(days=1)
run(host=aserver, port=aport, debug=True)
p = subprocess.Popen(cmd, stdout=subprocess.PIPE)
print(B[np.searchsorted(B[:, (0)], I)])
sys.getsizeof(test_dict)
pprint(d)
sys.exit(app.exec_())
globals()[c] = Variable(c)
app = QApplication(sys.argv)
result.append(tree.pop())
df.loc[~((lengths % 2 == 1) & (grouped.cumcount() == lengths - 1))]
draw = ImageDraw.Draw(image)
df.loc[criteria, ser.index] = ser[(np.newaxis), :]
print(cross_val_score(clf, X, y, cv=skf))
traceback.print_tb(err.__traceback__)
fig = matplotlib.pyplot.figure()
mask = np.random.randint(2, size=(500, 500))
i.append(0)
print(x)
plt.show()
plt.ioff()
myA.myattribute = 9
(c == loop(x)).all()
{{form.as_p}}
leg = ax.legend()
print([(k, mydict[k]) for k in ordering])
fig = plt.figure()
driver = webdriver.Firefox()
NULL
pool.close()
s = pygame.Surface((1000, 750), pygame.SRCALPHA)
tuple(np.hstack(np.where(a == a.max())))
cursor.execute(query, (AsIs(c),))
order_array.shape
set(permutations(x * 2))
arr = list(arr)
print(list(func()))
print(test[selected(test[:, (1)])])
f.close()
a = A()
print(max(node.y for node in path.nodes))
a = np.linspace(-2, 2, 5)
love_ctx.add((charlie, loves, bob))
wrapped_func(*args, **kwargs)
df2.index = df2.index.map(lambda x: difflib.get_close_matches(x, df1.index)[0])
ssh = paramiko.SSHClient()
sys.exit(1)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
result[cols] = result[cols].div(result[cols].sum(axis=1), axis=0)
ax.relim()
{key: foo(value) for key, value in list(d.items())}
self.frame.pack()
self.SetAcceleratorTable(tbl)
random.sample(bigset, 1)[0]
chunk = [next(gen) for i in range(lines_required)]
u = [x for x, y in valCount(lst).items() if y > 1]
dict = {x: 2 * a + 1, (x ** 2): 1}
solve(set(range(2 ** N)), set())
im = Image.fromarray(img)
axes[0].title.set_size(40)
self.stream.close()
pprint.pprint(parse_message_to_tree(s))
self.addHandler(console)
np.set_printoptions(suppress=True)
funcs.append((lambda i: lambda x: f(i, x))(i))
f.seek(-4, 2)
im = Image.open(im)
sorted(data, cmp=cmpnan)
pylab.show()
self.inner_test = inner_test
self.observer.start()
appengine.monkeypatch()
boom(x, y)
foo()
image.seek(0)
int(v)
df1.join(df2)
deletesys.modules[key]
z = np.polyfit(x, y, 1)
print(max(abs(clf.coef_ - w)))
fig = plt.figure()
gif.seek(1)
self.cformat = cformat
index = bisect.bisect(a, value)
ssh = paramiko.SSHClient()
f.close()
run_func()
line = doSomething(line, next(infile))
[word for word in words_seq if pat.match(word)]
a[::2]
G = nx.Graph()
lastHourDateTime = datetime.datetime.now() - datetime.timedelta(hours=1)
data = cursor.fetchone()
self.name = name
len(s)
Base.metadata.drop_all(bind=db.engine)
filtered_word_list.remove(word)
ax.plot(grouped.get_group(key))
a = numpy.empty((1, 10), dtype=object)
print(data[1])
PREDICT(FOR_ITER)
time.sleep((0.1 + random.random() / 10.0) / float(speed))
Z = np.exp(-(X ** 2 + Y ** 2))
QNetworkAccessManager.__init__(self)
c = np.core.defchararray.equal(a, b)
log.addHandler(JournalHandler())
all_data = pd.concat(dfs, ignore_index=True)
SOAPpy.__path__
t.ix[1], t.ix[2] = t.ix[2], t.ix[1]
cv.SetData(cv_img, img.rotate(180).tostring()[::-1])
x_sorted = [x for y, x in yx]
listbox.autowidth(250)
dx = [size1, -size1, -size1, size1, size1]
pool.join()
cb = plt.colorbar(im)
wx.Frame.__init__(self, parent, id, title, size=wx.DisplaySize())
pd.rolling_std(s, window=5).head(10)
browser.open(url)
yticks(linspace(ylim()[0], ylim()[1], numSteps))
user.save()
root = tree.getroot()
zip(*l)
opener = urllib.request.build_opener(urllib.request.HTTPHandler(), cp)
plt.close()
True
self._reader1 = reader1
response.status = falcon.HTTP_200
a * c + b * ~c
d[i].extend(j)
df2.Date = pd.to_datetime(df2.Date)
pprint.pprint(ll)
counter = collections.Counter(a)
isitIn(char, aStr[len(aStr) // 2:])
dict.__setitem__(self, key, value)
model = Whatever
False
ax.set_ylim(0, 5)
ax.xaxis.set_minor_formatter(plt.FuncFormatter(show_only_some))
closedir(dir_p)
Frame.__init__(self)
msg = MIMEMultipart()
print(s1[s1.index(s2) + len(s2):])
print(line)
do_something_with(node.value)
df = pd.DataFrame(np.random.randn(100, 2))
self.before.append(descendent)
Frame.__init__(self, master)
print(groups.aggregate(lambda x: np.mean(x[x > 0.5])))
os._exit(0)
admin.site.register(SomeModel, SomeModelAdmin)
outdict[tmp[0]].append((tmp[1], float(tmp[2])))
dt.datetime.fromtimestamp(timestamp)
next(b)
Base.prepare()
log()
a.append(d)
d = dict([(i, [a, b, c]) for i, a, b, c in zip(df.ID, df.A, df.B, df.C)])
repo.index.add(file_list)
gc.collect()
root.update()
difflib.SequenceMatcher(a=c, b=d).ratio()
length = a.shape[0]
n = len(s)
[0.0, 0.0] / np.float64(0)
sorted(personArray, key=lambda a: a.age)
datenow -= timedelta(days=datenow.isoweekday() - 5)
has_permission(permission, resource, request)
self.serial = serial.Serial(self.inport)
sys.exit(0)
Thread.currentThread().interrupt()
df = pd.DataFrame(columns=list(range(8)))
[(k, list(g)) for k, g in evens_odds_grouped]
job.start()
np.eye(2, dtype=int)
out.reshape(len(arrays), -1)
print(f.read())
fout.write(lines)
g.get().read()
row_dict[col] = row[columns.index(col)]
client_sock.send(response_body_raw)
p.close()
lpr.stdin.write(data_to_send_to_printer)
json.loads(json_data, object_hook=ascii_encode_dict)
p12.get_certificate()
top5 = array[:5]
self.__dict__ == other.__dict__
[LOGGING]
logger.addHandler(sh)
print(match.group(1))
reader = csv.reader(f)
self.session.add(entity)
print(team([1, 1, 1, 1, 1, 1, 1, 1, 1, 9]))
setups.append(comb)
objectify.deannotate(root, cleanup_namespaces=True, xsi_nil=True)
f.read(1854)
ax2.contour(theta_edges, r_edges, H)
process.start()
d = collections.defaultdict(list)
dt = datetime.datetime.fromtimestamp(secs)
soup = BeautifulSoup(html_doc)
result.write(line)
label1.pack()
my_new_list.close()
self.ax.xaxis.set_major_formatter(timeFmt)
view.overwrite_status()
print(max(p for p in lst1 if p < 0))
circle1.remove()
res = []
zip_file.close()
baz()
fig, ax = plt.subplots()
axs[i].contourf(np.random.rand(10, 10), 5, cmap=plt.cm.Oranges)
humansize(18754875155724)
offset = datetime.timedelta(days=0)
window.configure(stack_mode=X.Above)
values = np.sum(weights * features) + bias * weights.size
indata = (ctypes.POINTER(ctypes.c_double) * 5)()
print(sys.argv[2])
filter.uniform_filter(a, size=5)
g = rdflib.Graph()
print(df)
dreload(module)
dict.__init__(self)
M = np.random.rand(N * 10 * 10).reshape(N, 10, 10)
show()
prof.dump_stats(datafn)
setpath(d[p[0]], p[1:], k)
display.start()
redis.set(key, pickle.dumps(value))
print(_get_column_letter(1))
i += 1
arr[x] = x * np.ones(M)
df = pd.DataFrame(data)
nextprime(n)
django.db.transaction.commit()
PyErr_Print()
arr[i] = -arr[i]
cPickle.dump(root.sclX.config(), f, -1)
response = urllib.request.urlopen(request)
session.run(trainer, {feed_dict})
self.left[-(i + 1)]
p.join()
[x for x, _ in sorted(enumerate(a), key=lambda i: i[1])]
df
text.get_window_extent().width
response.render()
linecache.clearcache()
os.dup2(self.streamfd, self.origstreamfd)
print(list1[:5])
L = L[n:] + L[:n]
fp.close()
Fraction(58, int(X))
df = df.reset_index()
hex(_)
np.rollaxis(a, -1, 2).reshape(a.shape[0], a.shape[1], -1)
G = nx.Graph()
ax.grid(True)
self.reset()
generate_random_data()
a_shared_task(self, *args, **kwargs)
f()
im.show()
ax1 = ax0.twinx()
end_date = date(2015, 6, 2)
file.seek(os.stat(filepath).st_size - 1)
self.lst = []
print(count)
a = numpy.arange(25).reshape((5, 5))
pool = ProcessPoolExecutor(max_workers=1)
res = s.translate(remove_digits)
setattr(K, name, eval(name))
Foo().bar.__get__
self.lock.release()
pylab.yticks(list(range(len(names))), names)
a[..., ([True, True])]
plt.show()
b.update({key: a[key] for key in set(a.keys()) - set(b.keys())})
print(type(folder))
[0, 0, 0, 1, 0],
obj = MyModel.objects.get(pk=id)
ax.set_title(str(d))
app = QtGui.QApplication(sys.argv)
start_time = time.time()
arr = np.array([list(map(int, line.strip())) for line in f])
weights = np.ones_like(x) * mass
client = paramiko.SSHClient()
server_ssl.sendmail(FROM, TO, message)
inner1d(A, B)
d1.split()[0]
col.set_expand(True)
sorted(result.items())
total = sum(get_numbers(input_string))
data = [2, 2, 2, 2, 2]
topsublist[i] = list(L)
dct[p[0]].append(p[1])
dis.dis(test2)
type(logging.INFO)
plt.show()
client = mqtt.Client()
keys = list(Digit.keys())
self.setLayout(layout)
plt.figure()
C = np.where(cond, A, B)
combined = defaultdict(lambda : defaultdict(lambda : defaultdict(int)))
image = np.zeros((height, width, 4), dtype=np.uint8)
server_sock.close()
fd = sys.stdout.fileno()
all_ids.sort()
output.write(line)
file.truncate()
f.write(s)
f.close()
self[key]
x = np.linspace(start, end, N)[:, (np.newaxis)]
int(round(scipy.optimize.fmin(f, 100, args=(4, 100), xtol=0.5, ftol=0.5)[0]))
django.VERSION
strc_view[0, [0, 1]] = x
sess = tf.Session()
results = pool.map(convert, images[i:i + chunk_size])
index = random.randint(0, len(a) - 1)
list(d.values())
scipy.version.version
{k: v for k, v in list(a.items()) + list(b.items()) if k in symm_diff}
Session.add(user)
main()
self.lbl.pack()
map(lambda x: x % 2 == 0, l)
G.add_weighted_edges_from(cur)
d = np.arange(1, 21, dtype=np.float)
list(map(d.update, extras))
im.set_data(next(rw))
coords = np.stack(np.meshgrid(x, y), axis=-1)
startupinfo = subprocess.STARTUPINFO()
self.items.append(item)
c = [(a[x] + [b[x]]) for x in range(len(b))]
check(sys.stdin)
ax.set_xticks(x_ticks[::2])
[0, 0, 0, 0, 11, 12, 0, 0],
lineno = i + 1
self.server_close()
flush()
int(max(solve(a * x ** 2 + b * x + c, x)))
-0.5 * (x - mean).dot(inv(C)).dot(x - mean)
self.irenR.Render()
app = QtGui.QApplication(sys.argv)
np.array([a.tolist(), b.tolist()])
image.set_data(self.image_data)
args = parser.parse_args()
ax2.plot(xvals, yvals, linewidth=4)
EMAIL_USE_TLS = True
ax.plot(x1, np.sin(x1 / 2.0))
cumsum([0.2, 0.2, 0.2, 0.2, 0.2])
print(b(a, 10))
processBody(line)
foo.stop()
path = db.Key(opaque_id).to_path()
newlist.extend(l)
all_potions[self.name] = self
map(id, b)
pdb.set_trace()
h, s, v = rgb_to_hsv(r, g, b)
flask_login.login_user(user)
ref_to_func()
do_something_else(object_list[0])
sorted(items, key=key())
self.clear_widgets()
y[0][1] = 4
time.sleep(2)
offs -= 1
myset = set()
df
results = defaultdict(list)
b.append(foo())
flipped[value].append(key)
serializer = TaskSerializer(tasks, many=True)
dt.datetime(1970, 1, 1) + dt.timedelta(seconds=int(timestamp))
random.random() < p
hug(a)
cgitb.enable()
parking_rows.append(ParkingLotRow((1, 222), (462, 240), 22))
ax.add_artist(pol2)
lst = [10, 10, 20, 15, 10, 20]
app.run()
client = pymongo.MongoClient()
f.close()
ch.start()
fig = plt.figure()
parsed_url.geturl()
a, b, c
Counter(string1) == Counter(string2)
t.join()
application = QtGui.QApplication(sys.argv)
self.runButton.clicked.connect(self.callProgram)
x = np.linspace(0, 1, 1000)
parser.parse_args(extra_args, namespace)
X, Y = np.meshgrid(x, x)
self.groups.clear()
process = subprocess.Popen(cmd, shell=True)
sympy.solve(exp)
os.chdir(dir_of_your_choice)
re.findall(re2, text)
x = np.asarray(x)
idcord.append(x1)
s.listen(0)
client.service.SomeMethod()
print(p.sub(repl, s))
print(len(argspec.args))
ndates = (regx.split(date.strip()) for date in dates)
defaultdict(lambda : 1)
gencache.Rebuild()
frame = cv.QueryFrame(capture)
root = tk.Tk()
[n for n in dir(f) if isinstance(getattr(f.__class__, n), property)]
data[my_list].mean(axis=1)
cell = xl.ActiveSheet.Cells(1, 2).Text
snake.update()
l.append(num)
d.setdefault(parts[0], []).append(parts[1])
metafunc.addcall()
app = Flask(__name__)
a.writerows(data)
html += str(tag)
jsonpickle.decode(jsonpickle.encode(Goal(), unpicklable=False))
numpy.arange(25).reshape((5, 5))
root.mainloop()
args = parser.parse_args()
link = soup.find_all(**kwargs)[0]
fig, (ax1, ax2) = plt.subplots(ncols=2, sharey=True)
__all__.append(module_name)
source / opt / python / current / env
plt.show()
itertools.combinations_with_replacement(list(range(min, max)), num)
model.fit(X, y, nb_epoch=1, batch_size=data.batch_size, verbose=0)
solution = driver.find_element_by_css_selector(css)
print(line)
answer.append([new_list[0][0], new_list[1][0]])
QtGui.QWidget.__init__(self, parent)
narray[i] = NULL
np.array([tuple(values)], dtype)
{{(blog_date | timesince): comment_date}}
a.sort(key=id, reverse=True)
bundle.obj = self._meta.object_class()
foo.bars.add(1, 2)
mux_fn(a, b)
type(value)
df = pd.read_csv(StringIO(text), delim_whitespace=True, dtype=str)
main()
reactor.stop()
decorator(arg)
app.mainloop()
matrix = []
A = np.array([0, 1, 2])
OrderedDumper.add_representer(OrderedDict, _dict_representer)
the_canvas.save()
sig1 = sin(t1 / 2) + np.random.normal(scale=0.1, size=len(t1))
end_date = time.strptime(end_date, fmt)
print(nuc[frame:].translate(table))
self.mock_requests = Mock()
row.append(a[i][j] + b[i][j])
print(df[col_list[2:5]])
b = np.array(zip(a.T, a.T))
soup = BeautifulSoup(new_text)
CornerHarris(gray, harris, 5, 5, 0.1)
readline.set_completer(tab_completer)
Qapp.exec_()
print(s % tuple(x))
unpackbits(arange(2, dtype=uint16).view(uint8))
d = {x: a.count(x) for x in a}
fig.subplots_adjust(hspace=0.75)
setup()
ascii_lowercase.find(letters) != -1
l[:] = first_found(l)
ax.gridlines()
foo.__getitem__(something)
background.paste(overlay, overlay.size, overlay)
self.a + self.b
res = [lookupdict[k] for k in list(arr)]
print(str(100).zfill(2))
f.write(text)
some_long_task.delay(x, y)
myDict = defaultdict(int)
Foo().bar
norm.ppf(0.95)
pprint([(k, list(g)) for k, g in groupby(strs)])
plt.show()
Maybe(func(self.val))
a = np.random.rand(4, 4)
particle.kill()
ax.zaxis.set_rotate_label(False)
result_dict[str(len(word))].add(word)
r = Image.fromarray(numpy.uint8(r_array * 255.999))
same_structure(a[1:], b[1:])
Watchdog(1)
user = User()
raise NotImplementedError
d.setdefault(i, [])
ax.grid()
application = get_wsgi_application()
curr_points = [(x, y) for x, y in zip(first_points, second_points)]
main()
[(not y) for y in x]
time.sleep(sleep_time)
a = np.array([0, 47, 48, 49, 50, 97, 98, 99])
A.print_x.__func__(b)
rand_x_digit_num(10, False)
f.seek(0)
0.1 * randint(int(min_time * 10), int(m_time * 10))
logging.Handler.close(self)
print(longest_sum([1, 1, 1, 1, 1, 1, 4], 0, 0, 6))
print(calculateDistance(2, 4, 6, 8))
df.reindex(df.b.abs().sort(inplace=False).index)
[[b.pop(0), b.pop(0)] for _ in range(1)]
(1.0 + erf(x / sqrt(2.0))) / 2.0
im = scipy.misc.imread(filename)
z = np.arange(-5, 5, 0.2)
masked_diff.argmin()
myA[(myA > 5).nonzero()[0][:2]] = 0
self.clientSocket.send(data)
[(1, 2), (2, 0)]
remove_odd([4, 5, 4, 7, 9, 11])
fd.write(request.content.read())
self.next_chunk = self.next_chunk[n:]
Py_Finalize()
browser.open(login_url)
evt.Skip()
ssh = paramiko.SSHClient()
contribution.filter()
handle_last_line(remaining)
zip(x, y)
p.start()
hscrollbar.config(command=canvas.xview)
np.random.seed(100)
ret = f(*args, **kwargs)
print(label.get_text())
result = []
session.flush()
df.apply(lambda x: d[x.name].transform(x))
foo(bar)
time.sleep(sleeping_time)
Question.objects.filter(test_id=fr).update(test=test_obj)
t.sort()
mlab.figure(size=(1024, 768), bgcolor=(1, 1, 1), fgcolor=(0.5, 0.5, 0.5))
print(res.getheaders())
second.nonzero()
newlist.append([a, numlist[key]])
pygame.quit()
offset += len(line)
np.amax(a[mask])
msg = queue.get()
print(entry.title)
testclassa().testmethod1()
foo = lambda x, y=2: x + y
sys.exit()
sock.connect((self.host, self.port))
options = webdriver.ChromeOptions()
fcntl.fcntl(w, fcntl.F_SETFL, old_flags | os.O_NONBLOCK)
item1.setBackground(QtGui.QColor(255, 128, 128))
a = MyModel.objects.get(id=1)
thread = threading.Thread(target=target)
file = forms.FileField()
v = -np.cos(np.pi * x) * np.sin(np.pi * y) * np.cos(np.pi * z)
start = time.time()
primepi(n)
timestamp = time.mktime(ntuple)
t = Thread(target=print_updates, args=(q,))
self.panel_sizer = wx.BoxSizer(wx.HORIZONTAL)
json_string = json.dumps(data, ensure_ascii=False)
plt.imshow(np.random.random((10, 10)))
t.start()
plt.figure(figsize=(6, 5))
np.testing.assert_almost_equal([x, x, x], [y, y, y], 5)
p.remove(c)
emitted.append(name)
pygame.init()
sizer = wx.BoxSizer(wx.VERTICAL)
plt.show()
now = dt.datetime.now(timezone)
root = dict()
[idx for idx, el in enumerate(foo) if type(el) == type(arr)]
max(map(int, MyCount))
words.append(ipta)
client = oauth2.Client(consumer)
self._server.running = True
a[:, (1)] *= 5.2
utf8_fh.readlines()
my_answer.append(my_array[i])
Counter(get_all_k_mer(s, k=2))
output = PdfFileWriter()
MainWin().main()
sqlContext.createDataFrame(rdd, schema)
raise OSError(e)
t.start()
NP.cumsum(A[:, (1)])
p.start()
ts = (utc_date - date(1970, 1, 1)).days * 86400
quad(integrand, 0, 1000, points=[750])
l.set_rotation(0)
s.unstack()
ax.grid(False)
df.set_value(i, j, value ** 2)
sys.exit(main(sys.argv[1:]))
np.where(y == 0, 0, x / y)
title = models.CharField()
threading.Thread.__init__(self)
L[:next(n) + 1] = []
ax.xaxis.tick_top()
pool.apply_async(worker, (item,))
Pear
datetime.datetime.now()
G.add_edge((q, r), (q, r + 1))
print(instance[0].instances[0].start())
sizer = wx.BoxSizer(wx.VERTICAL)
corpus = Corpus(documents=[Document(x) for x in lst])
words.remove(word)
pool.terminate()
random.shuffle(indices)
sock.setsockopt(socket.IPPROTO_IP, socket.IP_MULTICAST_TTL, 2)
display.set(ast.literal_eval(display.get()))
isinstance(instance, User)
Food._meta.get_all_related_objects()
dist = hamdist(trans[i][:-1], trans[j][:-1])
obj.get_object()
root = Tkinter.Tk()
Frame.__init__(self, root)
soup = parser.parse(text)
plt.contour(X, Y, T[:, :, (round(len(z) / 2))], 64)
data = numpy.random.normal(size=10000)
iterator.__iter__()
word = match.group(0)
numbers = [x for x in range(length)]
a[~mask]
top_matrix.nullspace()
self.treeview.append_column(self.tvcolumn1)
math.exp(-x)
tox - -tests / test_loader.py
partial(_update_filename, path=path)
sympy.solve(d)
X = sparse.lil_matrix((100, 100))
signal.alarm(seconds)
plt.scatter(x, y)
self.func_count += 1
cols = df.columns.tolist()
a = np.ones(y[-1], dtype=np.intp)
app = Flask(__name__)
(lambda x: lambda : x)(value).__closure__[0]
max.append(-1 * q.get())
p.get_children()[1].get_paths()
A = [[INFINITY for i in range(n)] for j in range(2 ** n)]
do_something_awesome(lines_of_interest)
self.master.rowconfigure(r, weight=1)
request = QNetworkRequest(QUrl(url))
writer.commit()
print([t[1] for t in Formatter().parse(s) if t[1]])
n = int(input())
next(it)
sleep(5)
base_start += timedelta(days=1)
_cell.style.fill.start_color.index = Color.DARKGREEN
max(left_depth, right_depth) + 1
self.queries = []
lambda x: exp(x)
heapq.nlargest(5, A, key=A.get)
root = Tk()
d = d.reshape(partitions.shape[1], -1)
x[0].append(1)
line = f.readline()
[item for item in list(set(L)) if L.count(item) > 1]
sess = tf.InteractiveSession()
ax.set_yticklabels(df.index, size=20)
csvfile.close()
y = np.asarray(y, dtype=np.uint8)
inverted_dictionary[new_key] = [key]
[x for x in List1 if x in Set2]
time.sleep(2)
self.add(button)
app = webapp.WSGIApplication(url_map, debug=False)
ax1 = plt.subplot2grid((6, 1), (0, 0))
line = line.rstrip()
ax.legend(handles=handles, labels=labels)
y.append(contour[0][1])
fig, axes = plt.subplots(ncols=2, sharey=True)
db.session.add(post)
wd.implicitly_wait(10)
[False, True]
self.args[i]
self.crawler.configure()
[i[1] for i in l]
a + b
table.horizontalHeader().setResizeMode(0, QHeaderView.Stretch)
fig, ax = plt.subplots()
child.close()
self.f.flush()
pprint(list(all_doublet_tuples(n)))
len(df.index) == 0
c[0] += 1
app = Flask(__name__)
model = gensim.models.Word2Vec(sentences)
loop.close()
res = numpy.empty_like(a)
p.start()
d = {k: default_to_regular(v) for k, v in d.items()}
rfc822.parsedate_tz(date)
f.seek(i * line_len)
xmin, xmax, ymin, ymax = x.min(), x.max(), y.min(), y.max()
queryset = Question.objects.all()
response = urllib.request.urlopen(req)
p = subprocess.Popen(cmd, stdout=subprocess.PIPE)
log.setLevel(logging.DEBUG)
time.sleep(seconds_till_future)
post[0].tags.clear()
print(calculateDistance(2, 4, 6, 8))
parameter_setting.save()
print(x)
self.name = name
srf.blit(f.render(unistr, True, (255, 255, 255)), (0, 0))
labels = np.array([1, 2, 0, 0, 2])
Tk().withdraw()
print(f.read())
answer.extend([k for _ in range(counts[k])])
self.timer.Start(8000)
plt.hist(results, bins=bins)
HTML(style + df.to_html(formatters=frmt))
np.vstack([A[i:i - len(A) + width] for i in range(len(A) - width)])
inset.set_yticks([y_min, y_min + (y_max - y_min) / 2.0, y_max])
False
match.group(2)
s.getId(), s.getName(), s.getCustomer().getId()
wrapper
G.add_edge((q, r), (q, r - 1))
a = ndimage.interpolation.zoom(a, 0.5)
pyplot.show()
colorama.init()
print(sys.argv)
G.add_edge((q, r), (q - 1, r))
print(b[0])
np.set_printoptions(2, threshold=100, edgeitems=10, suppress=True)
driver = webdriver.Firefox(capabilities=caps)
datastream.read(2)
print(calendar.month(2011, 9))
aList = [Entry(**vals) for vals in values]
c, b = hashlittle2(data, initval, 0)
ax = plt.figure().gca()
i += 1
foo = Foo()
int(time.mktime(value.timetuple()) * 1000)
p.wait()
pool = Pool(2)
PROJECT_PATH = os.path.dirname(os.path.abspath(__file__))
results = multiprocessing.Queue()
ax = fig.add_subplot(1, 1, 1)
plt.gca().add_collection(lc)
display(fig)
worksheet.write(row, col, key)
a, b = b, a + b
outdict
self.set = set()
m.append([int(x) for x in input().split()])
root.mainloop()
contrived.foo()
keys.sort()
print ()
numpy.power(x, a + 1.0) - b
arr = [[0, 0, 0, 0] for i in range(5)]
time.sleep(0.2)
stdout = sys.stdout
b = numpy.array([100, 100, 100])
print(f)
logging.Handler.__init__(self)
new_dic[1] = {(2): 5}
A = np.arange(100).reshape(25, 4)
print(parser.parse_args())
plt.tight_layout()
(evens, odds)[i % 2].append(i)
print(mmc.serial)
fig.tight_layout()
threading.Thread(target=show_progress_A, args=(win,)).start()
a = list()
d = dict((v, k) for k, v in r.items())
df = pd.DataFrame(dict(time=tidx, value=np.random.rand(smp_n)))
res = dict(sorted([(k, v) for k, v in list(L.items())], key=lambda x: x[1])[-2:])
G.add_edge((q, r), (q + 1, r))
math.atan2(-0.0, -0.0)
array = (ctypes.c_double * 100)()
print(tuple(f))
ax1 = fig.add_subplot(111)
df
surface.fill((255, 255, 255))
file.delete()
X[:, (idx0)]
raise KeyError(key)
print(A[ind])
csv_writer.writerow([x[y] for x in hello])
imgplot = plt.imshow(img)
sorted(a)
abort(404)
l.index(a) < l.index(b)
layout.addWidget(self.DataPlot, 1)
irenL.Start()
index = [0, 2]
cj = cookielib.LWPCookieJar()
get_greenlet_status(greenlets)
db.create_all()
result = func(*args, **kwargs)
self.pipeline.send(self)
cnx.close()
sound.play()
self.documents.append(QTextDocument(self))
m = len(list)
self.c = cv2.VideoCapture(0)
client = Client(wsdl=wsdl)
result = collections.Counter(sixgrams)
M.set_value(index, column, new_value)
Two().f()
ast.iter_child_nodes(node)
f.write(inp)
thread.join()
self.drain()
print(tag.nextSibling.__class__)
manager.run()
years_dict[line[0]].append(line[1])
l.add(1)
main.py
len(s)
rex.match(my_string)
self.setCentralWidget(self.window)
print(list(itertools.chain([peek], gen)))
print(np.random.dirichlet(np.ones(10), size=1))
url = opener.open(request)
fig = plt.figure()
points.sort()
ax.grid()
y.append(b.pop(0))
format_to_year_to_value_dict[format_str][year].append(value)
min(c for c in s if c.isalpha())
A.sort()
y = []
float(s)
arr = np.array(img)
setattr(obj, self.name, types.MethodType(f, obj, obj.__class__))
pickle.load(f)
help(a.assign)
main()
parser = argparse.ArgumentParser()
A.combineAdd(-B)
zf.close()
d = locals()
ct.iloc[:10, :10]
((x + y, x - y) for x, y in data)
canvas.setLineWidth(0.5)
print(m.groups())
Counter(h.split())[n]
diff = filter(lambda x: x not in b, a)
web.show()
draw = ImageDraw.Draw(mask)
ax[1] = data.boxplot()
zip.extractall(path, get_members(zip))
x = np.linspace(0, 16, 1000)[:, (np.newaxis)]
bar = relationship(Bar, uselist=False)
b = np.random.randint(0, size_a, size_b)
x = [0] * 100000000
json.loads(json_str)
random.shuffle(my_list)
indices[val].append(i)
df = pd.DataFrame(existing_data, columns=cols)
count
map(lambda t: t.start(), threads)
c = nprect(a, np.deg2rad(b))
res = cv2.bitwise_and(res, mask)
m.group()
f.close()
print(html)
self.window.show()
TP, FP, FN, TN
html = urllib.request.urlopen(req).read()
random.seed()
x.sort()
d = datetime.datetime.now()
vc.release()
np.set_printoptions(threshold=np.inf)
test_func(*args, **kwargs)
print(np.nanargmax(a))
app = wx.PySimpleApp()
str(jinja2.escape(a))
df1 = func(df)
seen.add(x)
_foobar.argtypes = [ctypes.c_int, ctypes.c_int, _doublepp, _doublepp]
pd.concat(los, axis=1)
self.queue.get(block=True)
self.fig = plt.figure()
fn(*args, **kwargs)
self.mysignal.connect(self.mySignalHandler)
os.__file__
plt.pie(values, labels=labels, autopct=make_autopct(values))
child.expect(pexpect.EOF)
plt.imshow(sample_images[(i), ...])
session.commit()
plt.gcf().gca().add_artist(circle1)
plt.clf()
logging.basicConfig(level=0)
module.py
loop.run_forever()
output[line[1].strip()] = line[2].strip()
sess = tf.Session()
self.browser.get(self.live_server_url)
self.pack()
a.a = a.a
print(key, myNames[key])
do_something()
data = {}
ana(lambda x: (x, f(x)), lambda _: False)(x)
print(line)
Parallel(n_jobs=2)(delayed(foo)(i ** 2) for i in range(10))
output.seek(0)
str(tst)
name = models.CharField(max_length=255)
lines = f.readlines()
self.canvas.draw_idle()
self.assertEqual(request.responseCode, 200)
df1
d2 = {x: sorted(d1[x]) for x in list(d1.keys())}
tk.Frame.__init__(self, *args, **kwargs)
df.mask(criteria).fillna(ser)
print(pattern.search(input, start).span())
main()
raise GracefulExit()
soup = BeautifulSoup(html)
C.u4_sort(begin, arr.size)
job = Job.objects.filter(client_id=pk)
ax.bar(list(range(5)), rand(5), color=my_cmap(my_norm(my_data)))
result = json.loads(s)
f.writelines(data)
content = fd.getvalue()
self._callback(self._value)
(listScore == [2, 0]).all(1).sum()
value += sum([int(i) for i in str(value)])
ny.append(y[-1])
_nonbmp.sub(_surrogatepair, text)
print(temp_re.findall(data))
rdd2 = sc.parallelize(range(5))
self.txt.see(END)
yaml_parse.py
response = urllib.request.urlopen(request)
entity.before_put()
start_response(status, headers, exc_info)
np.hstack([a[:k] for k in x])
print(calendar.isleap(1900))
sys.executable
print(k, v)
tuples = tuple(set(d.items()) for d in dicts)
print(tuple(a))
wb = Workbook()
deletemylist[:17]
linprog(c, A_ub, b_ub, A_eq, b_eq, options=dict(bland=True))
ax.scatter(xData, yData)
new_array = np.array(means).reshape(new_shape)
assert_frame_equal(csvdata, csvdata_old)
Parent.__init__(self, list(args))
f = open(filename)
print(m.group(2))
d[key] = d.get(key, []) + [value]
sock = urllib.request.urlopen(url)
pool.close()
self.sock.connect((host, port))
blocks[-1].append(line)
counts = collections.Counter(patterns)
dt = datetime.datetime.fromtimestamp(nanos / 1000000000.0)
sum_max(L[1:], accum, max(max_value, accum))
ax = fig.add_subplot(111)
print(__file__)
session = create_session(bind=e, autocommit=False, autoflush=True)
True
len(_)
str(self.mylist)
print(len(inspect.getargspec(sum)[0]))
run_benchmark()
p.sort()
ax1.plot(x, y)
s.listen(1)
myapp.models
f(*args, **kwargs)
np.square(df)
y_rev[x.argsort()] = np.arange(x.size)[::-1]
x, y, z
console.setLevel(logging.ERROR)
sys.path.insert(0, dirname)
{k.name: v for k, v in list(g.items())}
urllib.request.urlopen(req)
app = Flask(__name__)
m.span()
Z = append([[(1) for _ in range(0, len(Z))]], Z.T, 0).T
print(tf.__version__)
np.dot(a, b)[[0, 0, 1999, 1999], [0, 4999, 0, 4999]]
matrix = []
linecache.checkcache(filename)
key = ndb.Key(urlsafe=string_key)
xml.display()
print(filename)
message[i] = (digest[i] ^ message[i - 1]) * 129 % 256
a.upper() == b.upper()
self.latest(limit=1, public=True)
os.dup2(si.fileno(), sys.stdin.fileno())
foobar.foo()
self.view_items.sort(key=key_func)
Y.append(y)
x, y = np.meshgrid(np.arange(10), np.arange(10))
scipy.argmin([scipy.inner(q - x, q - x) for x in X])
[(2, 4), (4, 5)]
m.scatter(data.Lon, data.Lat, c=data.Z, s=100, vmin=zi.min(), vmax=zi.max())
self.foo.fset(5)
yip()
allocate(temp(dsize))
admin.site.unregister(Site)
a + b
plt.imshow(img)
process_directory(dirName=os.path.join(dirName, f))
d.weekday() == 4 and 14 < d.day < 22
list_a = [(1, 2), (1, 2), (1, 2)]
plt.show()
job.delete()
app = QtGui.QApplication(sys.argv)
list(chain(*[sorted(g) for k, g in groupby(sorted(lis, key=len), key=len)]))
reverseCom([4, 5, 6], 1)
os.dup2(devnull, 1)
df = df.reset_index(level=0, drop=True)
self.assertTrue(result)
idx = b.reshape(a.shape[0])
id(b[0])
gransons.append(grandson)
ax.set_ylim(0, 1)
architecture / techstack
deployment / installation
deployment / licensing
check_for_duplicates(sys.argv[1:])
data = {h: v for h, v in zip(str(range(number_of_columns)), zip(*values))}
test_debug_json()
datetime.datetime.now(pytz.utc).isoformat()
opcode, dest, src
ax.boxplot(df[column], positions=[position])
print_time_range(train_likes_df.time.dt.time)
os.chdir(command[raw_input][0])
Decimal(1)._isinteger()
lint.py - -generate - rcfile > standard.rc
conn.close()
fig = plt.figure()
print(f.bar.__name__)
app = Flask(__name__)
Thread.__init__(self)
[list(g) for _, g in groupby(numbers, grouper)]
0
outf.seek(0)
pool = Pool(4)
driver = webdriver.Chrome()
self.opn[op](op1, op2)
logging.getLogger(name)
clf.fit(train_features, train_labels)
df
dict(map(reversed, t))
(self.arr == other.arr).all()
self.f_(obj)
ax.yaxis.label.set_rotation(0)
a = np.sort(arr, axis=1)
output = (lambda x: x + x)(data[2])
capture = cv.CaptureFromCAM(0)
Cl.__init__.__defaults__
list(d.items())
print(is_shifted_copy([1, 2, 1], [2, 1, 1]))
fum.bar
chr(int(x[2:-1]))
module_name = os.path.splitext(os.path.basename(__file__))[0]
lgnd.legendHandles[0]._legmarker.set_markersize(6)
fd.seek(0)
geturl()
db = SQLAlchemy(app)
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
print(r.content)
using_mapper_options(save_on_init=False)
fig = plt.figure()
deletesomelist[i]
show()
pprint.pprint(root)
print(a[(1), :].toarray())
Example.foo(self)
xmlrunner.XMLTestRunner().run(suite)
parser.add_argument(*args, **kwargs)
print(sys.version_info)
x.astype(int)
layout.addWidget(self.tab)
tree = ElementTree()
bid = int(bid)
plt.show()
pdf = distr.pdf(abscissas, *param)
sum([48 * 0.1, 1 * 0.2, 0 * 0.5, 0 * 1, 0 * 2, 0 * 5])
plt.plot(x, y)
patches[i].set_facecolor(jet(i))
ax = fig.add_subplot(111)
print(df.columns.str[0].unique())
plt.show()
print(my_array)
names.remove(name)
c = boto.connect_ec2(ec2_key, ec2_secret)
doc = lxml.html.fromstring(s)
image = image.resize((250, 250), Image.ANTIALIAS)
x[:] = np.ones((2, 2))
print((e, L[i - 1], L[(i + 1) % len(L)]))
self.f.flush()
data = [int(p) for p in image.read().split()]
items = [parse_item(line.strip()) for line in infile]
gems.sprites()
zip(*lis)
screen.fill(BGCOL)
self.value = value
mail.get_payload()
print(x)
self.__name__
self.layout().removeWidget(self.child)
main()
int(log(n, 256)) + 1
thing.put()
list(range(item.start, item.stop, item.step))
set(myList)
list(find(l))
processor.terminate()
test.py
app.MainLoop()
text = file.read().lower()
type(test.make_fptr())
server.join()
G.add_edge(x[0], x[1], weight=x[2])
remainder.append(group[0])
driver = webdriver.Firefox()
plt.xlim([-4, 4])
self.response.write(pic.read())
d = collections.Counter(dict(your_list))
s.feed(html)
lines = f.readlines()
fh.stream.name
b = np.ones(5)
p.start()
plt.subplot(122)
pd.read_csv(io.StringIO(df.to_csv()), index_col=0)
writer = csv.writer(f)
print(current_credentials.secret_key)
df[~mask]
x = np.array([1, 2, 1, 0, 1, 2, 1, 0])
datetime.date(*datetuple)
plt.show()
f.close()
h = np.array(hamiltonian)
t.render(c)
docs.append(yaml.load(raw_doc))
self.after(100, self.read_bytes)
d = np.diagonal(np.tensordot(a, b, axes=()), axis1=0, axis2=2)
ds.addSample(myList[ind - n:ind], myList[ind + 1])
fig, ax = plt.subplots()
s.close()
locals()[choice]()
parser = argparse.ArgumentParser()
theta = 2 * np.pi * np.random.random_sample(n)
x.subs([(x, y), (y, z)])
toast()
opener.open(login_url)
list(d.items())
data1.shape, masks1.shape
ax = fig.add_subplot(111)
ax = fig.add_subplot(gs[1])
sum(calc_matrix(l1, l2) for l1, l2 in zip(x1, x2))
cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
pprint(data_copy)
pl.show()
self.__block.wait()
print(self.__hidden)
sys.exit(update(opts))
pygame.mixer.music.load(file)
result = np.apply_along_axis(mahalanobis_sqdist, 1, d1, mean1, Sig1)
Rect(l, t, w, h)
c = random.randint(10, 25)
print(list(csv_reader))
list(intersection.elements())
plt.setp(ax2.get_yticklabels(), visible=False)
client.connect(host, port, username)
diff(n[i], n[j])
app = QtGui.QApplication(sys.argv)
platform.platform()
[1, 2, 10]
[0, 8, 0, 0, 0, 8, 0, 0, 0, 8, 0, 0, 0],
new_list
child.tag, child.attrib
dt = datetime.datetime.now()
deletedata[key]
out = np.split(df1.index[c], np.flatnonzero(r[1:] > r[:-1]) + 1)
pygame.time.Clock().tick(10)
session.add(a)
pd.DataFrame(MM, dtype=int, columns=Col)
mydict = dict((k[1], v) for k, v in list(mydict.items()))
fig = plt.figure()
int(mktime(dt.timetuple()))
fig, axes = plt.subplots(ncols=2, sharey=True, sharex=True)
bar.baz()
child.grid_configure(padx=5, pady=5)
listen.stop()
plt.subplot(212)
frame.pack(padx=10, pady=10)
w = wfloat.mean(2)
f.__code__.co_names
sys.exit(app.exec_())
b = np.matrix([[2, 2], [2, 2]])
list(zip(keys, values))
image_list.append(im)
input_list = string_input.split()
a[:-1, :-1]
panel.configure(image=img2)
line.rstrip()
self.transaction.append((name, self.database.get(name)))
df2 = df1.copy()
np.dot(np.arange(len(x)), np.power(x, 10)) / np.sum(np.power(x, 10))
paranoid[:]
print(opts.some_option.decode(sys.stdin.encoding))
vbar.config(command=canvas.yview)
tk.Tk.__init__(self)
data = f.read(4)
data = conn.recv(1024)
a.T
df = df.reset_index()
window.show()
res.append(0)
self.ui.dragDataEdit.close()
logger.addHandler(hdlr)
print(k, v)
session.execute(u)
rle(np.array([5, 4, 4, 4, 4, 0, 0]))
psutil.net_connections()
print(i)
aList = [random.randint(1, 11) for i in range(100)]
__path__ = extend_path(__path__, __name__)
C = A[:, ([1, 2])]
form.save()
pool = multiprocessing.Pool(2)
l.__code__.co_argcount
conn.select()
my_randoms.append(random.randrange(1, 101, 1))
array = np.zeros((8, 8))
UserSerializer
df.apply(using_mstats, axis=0)
suite = unittest.TestSuite()
TrueXor(1, 0, 0)
app = Flask(__name__)
buttons[-1].pack()
print(f.getvalue())
plt.show()
Category.append(row[1])
dill.detect.badobjects(f, depth=1)
foo.method1()
soup = BeautifulSoup(html)
tree = lxml.html.fromstring(html)
t.start()
self.clients.append(client)
parent = Parent()
getattr(obj, name)
----APP2
----APPX
foo()
df2 = df.ix[:, 12:24]
x.extend([4, 5])
lst.sort(key=operator.itemgetter(1))
getFromDict(dataDict, mapList[:-1])[mapList[-1]] = value
plt.close(fig)
x * x
SecondBase.__init__(self, *args, **kargs)
print(time.ctime())
b = np.array([2, 4, 6])
[list(i) for i in set(map(tuple, a))]
mat2.append(temp)
filtered_numbers = [n for n in numbers if predicate(n)]
x = object()
l[start:end:step]
myList = [0.0, 0.0, 0.0, 2.0, 2.0]
q = Queue.Queue()
self.setInitialBreakpoints()
X.__rmul__(2)
list(_f(s, n))
plt.plot(x[(i), :], y[(i), :])
tuple.__new__(cls, (x, y))
date = dateutil.parser.parse(date)
choice([4, 5, 6])
self.created_at = datetime.now()
expected.difference(found)
df = pd.read_csv(StringIO(txt), index_col=0)
msg = email.message_from_string(msg_string)
print(list(dd.items()))
rgb_values += [(r, g, b)]
ax.scatter(x, y, marker=m, c=c, s=SIZE, vmin=VMIN, vmax=VMAX)
dataframe.to_excel(writer, sheet_name=sheet, startrow=0, startcol=0)
children[child] += np.ones(len(children[child]))
hist(b.ravel(), bins=255)
list(enumerate(s))
output = [(a[i] + a[i + 1]) for i in range(len(a)) if i < len(a) - 1]
clf.fit(X_train[:, :-num_feats_to_remove], y_train)
f = imageFile.read()
time.sleep(0.1)
result = cv2.matchTemplate(image, template, cv2.TM_CCOEFF_NORMED)
sprite.set_position(sprite.body.position.x, sprite.body.position.y)
render_template_string(name_template, name=name)
x, y = starmap(operator.isub, zip((x, y), (1, 2)))
fig = plt.figure()
print(status.author, status.user)
df.index.isin(df.index[df.index.slice_indexer(start_remove, end_remove)])
foo(iterable, isiterable=False)
x = f(x)
print(r.content)
content = render_to_string(template_name, dictionary, context_instance)
transport.close()
print([n.ID() for n in node.fullPath()])
server_socket.close()
-2 * x ** 2 + 4 * x
df[col] = pd.get_dummies(df[col])
tuple(recursive_map(complex_list, lambda x: x.__class__.__name__))
self.names.add(node.id)
self.setFileMode(self.ExistingFiles)
cursor.execute(sql)
driver = selenium.webdriver.Firefox()
ax.cla()
cursor.close()
ax2 = fig.add_subplot(2, 1, 2)
job.join()
self.items[-1:][0]
hash = hashlib.sha1()
db.myCollection.insert(records)
self.__getitem__(slice(i, j))
print(string)
listbox = tk.Listbox(master, selectmode=tk.SINGLE)
new_points.append((x, y, z))
effectslist.append(mod)
plt.grid()
writer = csv.writer(self.response.out)
HttpResponseServerError()
d = datetime.date(1970, 1, 1)
sys.getsizeof(0)
DNS.DiscoverNameServers()
df
not Counter([1, 2, 2]) - Counter([1, 2])
f.write(line)
A.dtype
test.close()
ax2.set_ylim((0, 2.7))
(datetime.strptime(x[0], fmt) - d).total_seconds() > 0
yertle.hideturtle()
log_file.write(fmt_str % tup)
next(blah)
0
plt.fill_between(x, y_old, y_new, color=color)
theA.methB(params)
print(md.myfx(arg2))
self.Bind(wx.EVT_KEY_DOWN, self.KeyDown)
p = psutil.Process(os.getpid())
datetime(*timetup[:6]).isoformat()
pylab.show()
df.iloc[np.roll(np.arange(df.shape[0]), shift)]
copyStruct(inputList, iter(flattenedResults))
root = etree.fromstring(xml_str)
pairs = zip(it, it, nons)
{{another}}
pform2.as_table()
writer = csv.DictWriter(outfile, fieldnames=fieldnames)
numpy.interp(quantiles, weighted_quantiles, values)
min(timeit.repeat(lambda : {keys[i]: values[i] for i in range(len(keys))}))
invoker(test)
results.append((i, j, ret, vol))
getpwuid(stat(filename).st_uid).pw_name
G.add_edge(x[0], x[1], weight=x[2])
app = QtGui.QApplication(sys.argv)
f.write(data)
b = np.array([1, 0, 2, 1])
print(line)
p = multiprocessing.Pool()
lol[i] = [sublist[j] for j in indices]
sum(lists, [])
time.sleep(1)
cb = lambda : self.resp(items, iteration)
print(name[i:] + name[:i])
divtdi(td1, td2)
t.test()
plt.plot(x, [(offset + math.sin(float(i) / 10)) for i in range(len(x))])
pool.close()
mark_safe(json.dumps(list(object)))
sys.stderr = self.sys_stderr
response
()
data
df1.join(df2)
con.close()
dct[id(lst)] = lst
print(is_all_true(a, b, c))
gona[:, (1)]
comp.remove(x)
print(timeit.timeit(lambda : [s.strip() for s in rsplit(TEST)]))
fig, axes = plt.subplots(nrows=2, ncols=2)
main()
time.sleep(0.1)
id = Column(Integer, primary_key=True)
conn, addr = s.accept()
self.conn.close()
C = p1[0] * p2[1] - p2[0] * p1[1]
X.tocsr().nonzero()
payload = json.loads(message, object_hook=as_payload)
raise ValidationError()
nosetests
key_name
print(repr(c))
value = float(value)
gradient.setColorAt(1, QColor(255, 255, 255, 0))
dt.astimezone(pytz.utc).time(), dt.utcoffset().total_seconds()
name = db.StringProperty()
next(gen)
ax.loglog()
a[k] = b[k]
out.reshape(6 * N, 6 * N)
yest
result = []
lst[i] = func(item)
initializer(*args)
walk(tree.getChild(0), ast)
db.session.add_all(list(my_new_posts.values()))
funcs.append(functools.partial(f, i))
b = np.array(b)
words = nltk.Text(coded)
result = pool.apply_async(f)
list1.append(int(digit))
np.allclose(out_ein, out_dot)
NUMBER_OF_EXCEPTIONS = 0
myList.append(2)
d = datetime.datetime.fromtimestamp(ts)
app = Flask(__name__)
l = [[0]] * 4
outfile.write(line)
result = pd.concat([a, b])
self.button.setMinimumSize(QtCore.QSize(128, 128))
self.parser.parseString(s)
grid.addWidget(button, row, col)
a2 = np.arange(10).reshape(2, 5)
my_new_list = [(x + string) for x in my_list]
np.s_[:, :2, :, :540]
ftp.login()
results.append((letter, 1))
x = np.linalg.solve(a, b)
OrderedDict.__init__(self, *args)
self.data = data
seconds = duration.total_seconds()
print(f(1))
line.split()
{arg: multi(*args[1:]) for arg in args[0]}
mf.grid(column=0, row=0, sticky=(N, W, E, S))
item.setTextAlignment(QtCore.Qt.AlignCenter)
adapt(proxy._get_current_object())
x = np.linspace(0, 1, 100)
loop.run_until_complete(do_request())
p.interact()
cur = connection.cursor(dictionary=True)
print(df.apply(lambda x: sorted(x, key=lambda y: y == 0), axis=1))
d[c] += 1
ax = fig.add_subplot(111)
raise StopIteration()
n.increment()
pathlib.Path(*p.parts[2:])
seen.add(x)
print(response.content, response.status_code)
reader = csv.reader(f)
layout.addWidget(button)
f, ax = plt.subplots(2, 1, figsize=(12, 6))
sess.run(init)
plt.scatter(x[mask], y[mask], marker=um)
today = datetime.date.today()
signal.alarm(0)
self.view_items.sort(key=attrgetter(*fields))
dfnew.join(dfnew.apply(func, axis=1)).dropna()
render_to_response(template_name, c)
id(sys.modules[foo.__module__]) == id(sys.modules[foobar.foo.__module__])
self._setter(obj, value)
self.sa_grid.removeWidget(widget)
array[idx]
type.__new__(mcls, cls, bases, d)
glfw.Init()
p.start()
print(IPython.sys_info())
r = [a, b, c]
print(moneyx)
print((val, k))
import_submodules(__name__)
ax.yaxis.set_major_formatter(mtick.FuncFormatter(ticks))
app.exec_()
token = models.CharField(max_length=100, blank=True)
path.reverse()
[(key, OrderedDict.__getitem__(self, key)) for key in self]
np.array(l, dtype=pd.Series)
dx, dy = statemap[dx, dy]
repr(soup)
result = wx.BitmapFromImage(image)
self.setCentralWidget(self.centralwidget)
myset = set(mylist)
angle = np.linspace(0, 6 * np.pi, 1000)
req = urllib.request.Request(url, data)
key = bucket.get_key(key_name)
x.append(a.pop(0))
print(o.hostname)
data_frame.iloc[:100]
jsonify(username=g.user.username, email=g.user.email, id=g.user.id)
self.__class__(*args, **kwargs)
a = np.array([[1, 5, np.nan, 6], [10, 6, 6, np.nan]]).transpose()
dd_process.stdout.close()
cursor = conn.cursor()
connection.connection.ping()
fig.canvas.draw()
parser.feed(res.read())
foo()
lut.append(n / step)
sanitised_path
instance = Example()
threading.Thread.__init__(self)
add_element_to_database(record)
ax.set_xticks(ax.get_xticks()[1:])
scopes.add(s.strip())
ax.scatter(x, y, z, c=scalarMap.to_rgba(cs))
fig, ax = plt.subplots()
x = 0
G = matrix([[2.0, 1.0, -1.0, 0.0], [1.0, 2.0, 0.0, -1.0]])
QtCore.QCoreApplication.exit()
output = PdfFileWriter()
y * (y.groupby((y != y.shift()).cumsum()).cumcount() + 1)
print(hex(id(x)))
time.sleep(2)
conn = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
self.buttonPanel1 = wx.Panel(self)
deletetest[5]
module_name
canvas.grid(row=1, column=0, columnspan=100)
index = np.unravel_index(arr.argmin(), arr.shape)
timeout.start()
plt.colorbar(img, cmap=cmap, norm=norm, boundaries=bounds, ticks=[0, 5, 10])
process.wait()
page = urllib.request.urlopen(url)
[sum(values) for values in zip(a, b, c)]
matcher(l1[1:], l2[1:])
x.reshape(r * b1, c * b2)
o5.magic
log.startLogging(sys.stdout)
axes[1, 0].hist2d(x, y, bins=nbins)
my_stdout_file.write(line)
initlibwrap()
pylab.subplot(122)
stderr_thread.start()
list1[1::2] = [(x + 1) for x in list1[1::2]]
x_new = x[bool_arr]
plt.autoscale(False)
np.random.seed(0)
x, y = zip(*data)
next(nextword)
self.dictset.update(iterable)
print(line)
my_list = [1, 2]
first_line = next(csv_reader)
unittest.TestCase.__init__(self, *args, **kwargs)
os._exit(0)
root = tk.Tk()
id = db.Column(db.Integer, primary_key=True)
[apply(op, *items) for items in zip(*iters)]
[a, int(b), int(c)]
FancyArrowPatch.__init__(self, (0, 0), (0, 0), *args, **kwargs)
Chainable(list(self.method(args[0], self.data, **kwargs)))
(a == b).sum()
result = process.wait()
pygame.mixer.init()
opener = urllib.request.build_opener()
plt.show()
[True, True]
c = b[1:]
self.mainLayout.addWidget(self.scroll)
plt.plot(sub_data)
src_dt = dt.replace(tzinfo=src_tz)
a[:, (0), (0)] = b[:, (0), (0)]
job.join()
a = np.append(a, x)
now = datetime.datetime.now()
screen = Xlib.display.Display().screen()
c = conn.cursor()
a = 1
newList.append(temp)
browser = webdriver.Firefox()
session.starttls()
e = Egg()
self.x + other
axHistx.hist(x_vals[i], bins=bins, histtype=histtype, color=colors[i])
y = y.A.squeeze()
df.loc[2] = a
fp.close()
f.close()
query = query.filter(condition)
im = Image.open(infile)
contents = fp.read()
singular
ax2.set_xlim([x[1], x[2]])
lgnd.legendHandles[1]._legmarker.set_markersize(6)
foo.write(os.path.join(root, f))
df = pd.read_csv(fn)
unittest.TestLoader.sortTestMethodsUsing = lambda _, x, y: cmp(y, x)
self.num_terms = 1 + max([-1] + list(self.id2word.keys()))
parts = line.split()
ax.set_xlim(-100, 100)
form = ContactForm()
[j[i] for k, g in groups for i, j in enumerate(g)]
plt.show()
data = json.load(f)
copy + copy_to_depth(item, depth - 1)
pygame.mixer.init()
print(t.timeit())
dict(results)
parser = argparse.ArgumentParser()
np.array([0, 0]).any()
df
count[key] = len(values)
ax = fig.add_subplot(gs[0])
print(datetime.datetime.now(tz))
p = multiprocessing.Process(target=parallel)
-your_code.py
isinstance(x, numbers.Integral)
NULL
db.session.commit()
pprint(lod, width=40)
titled.append(word) if word.istitle() else lower.append(word)
wb.Save()
print(to_s(dt.astimezone(pytz.utc)))
x = np.random.randn(100)
main()
x = np.zeros((n, n))
locals().update(obj.__dict__)
new_text.append(text[i])
a.clip(max=2)
plot(draw, img, xpxl2, ypxl2, rfpart(yend) * xgap, col, steep, dash_interval)
peers.append(dict())
self.clients.add(client)
print(inspect.currentframe().f_code.co_name)
window.show_all()
G = nx.Graph()
x = etree.parse(f)
l.append(1)
b.pack()
(d < 0).sum()
connection.send_command(*args)
result.update({j: result[j] + [i]})
print(args)
itertools.product(range(self.numrows), range(self.numcols))
map(ingredients.delete, ingredients.get_children())
tailq.put(line)
fig, axes = plt.subplots(ncols=2, nrows=2, sharex=True, sharey=True)
b = [[0, 0, 0], [0, 0, 0], [0, 0, 0]]
p = random.randint(0, j)
sum(max(die().roll_until(6) for i in range(5)) for i in range(n)) / float(n)
df.addCallback(results, name=name)
list(range(f, L + 1))
tokenize.untokenize(res)
json.dumps(value)
list1 + list2
zerolistmaker(4)
time.sleep(2)
counts, bins = np.histogram(X, bins=50, density=True)
df.reindex(index, fill_value=0)
self.transport.write(towrite)
result = [{k: v} for v in vs]
tornado.ioloop.IOLoop.instance().start()
line = line.split()
self.text.pack(expand=YES, fill=BOTH)
df[ws] = pd.read_excel(excelFile, sheetname=ws, parse_cols=c)
my_list.append(json.loads(line))
os.mkdir(dirname)
data = b.getvalue()
db.run_in_transaction(_tx)
main.py
print(r.text)
print(len(points))
axes[-1, -1].set_xlim(xlimits)
iter(self.books.values())
d = {}
self.panel.Bind(wx.EVT_MOTION, self.OnMouseMove)
getattr(self.ham, name)
today = date.today()
loop.run_until_complete(main())
User.drop_collection()
a = np.arange(10)
msg = conn.recv()
dict((k, dikt[k]) for k in keys.split())
df
gca().set_axis_off()
{{field.label_tag}}
df.head()
any(map(s.__contains__, substring_list))
painter.drawLine(x1, y1, x2, y2)
results = []
draw()
P = np.zeros((N, N), dtype=int)
user = Channel
fp.close()
html = html.format(**d)
print(gmpy2.sqrt(2))
print(sp.stdout.read())
sys.exit(app.exec_())
PROJECT_ROOT = abspath(os.path.dirname(__file__))
df = pd.DataFrame(d)
print(np.all(a0 == a1))
a_button.pack()
source.gruntfile.coffee
source.gulpfile.coffee
html = requests.get(url).text
self._concordance_index.print_concordance(word, width, lines)
mousemove(int(currentpos.x), int(currentpos.y))
self.c.add_section(SERV_SECTION)
cv2.drawContours(cimg, contours, i, color=255, thickness=-1)
options = parser.parse_args(arguments)
inputs = list(it.product([0, 1, 2], [0, 1, 2]))
_winapi.CreateJunction(source, target)
doSomething(x, i, j)
insert(cur[list[0]], list[1:], value)
set_spyder_echo(False)
print(func.__name__)
l2.append(i)
i += 1
merged_list.sort()
True
labels = np.array([[1, 1, 1, 0, 0]]).transpose()
self.__pList.append(Person(name, number))
do_something()
pygame.font.init()
time.sleep(2)
Foo.square(2)
dialog.show()
s = socket(*args, **kw)
do_something(a1, a2, b)
sum(dct[k] for k in lst if k in dct)
f(x)
parent.kill()
json.dumps(ids_list)
copy
a[subset_b] += 2
channel.send(command)
print(list(kwargs.keys()))
out[:, :, na:] = b
print(df[val_cols].max())
f.close()
cmd.Cmd.__init__(self)
B.__init__(self, z)
self.browser.open(url)
channel.queue_declare(queue=queue_name)
driver = webdriver.Firefox()
plt.show()
dis.dis(add_url_rule)
df2 = df2.reset_index()
df.dtypes
list(range(len(list1)))
fig, ax = plt.subplots()
[idx for idx, item in enumerate(seq) if item in seen or seen_add(item)]
do_something_else()
x += np.random.normal(loc=0, scale=0.1, size=200)
root = tree.getroot()
self.server.running = False
p.save()
print(generate_list(100))
foo = np.random.rand(20).cumsum()
print(df)
pd.to_numeric(s)
root.mainloop()
mvv_list[0]
admin.site.register(Car, CarAdmin)
sa, sb, sc = map(str, (a, b, c))
handlers.append(HTTPSClientAuthHandler(somekey, somecert))
sys.exit(ret)
print(len(cycles))
ax = f.add_subplot(1, 1, 1)
take(4, iterate(lambda x: x + [len(x) + 1], [1]))
a.multiply(nmask)
stream.seek(0)
root.clear()
x = test()
p.stdin.write(someInput)
csvout.writerows([row[2:4] for _ in range(count)])
prices[:-1].values / prices[1:] - 1
do_something()
imp.reload(scriptname)
sess.run(m1)
self.thread.join()
random.shuffle(x)
q.join()
print(a.compressed())
deletex, y
pd.to_datetime(out_ar)
btn.grid(row=row_index, column=col_index, sticky=N + S + E + W)
b = [[], []]
fp.close()
values = [max(item) for item in array]
any(el in sb for el in a)
repr(self.__dict__)
eav.register(Patient)
A = np.arange(16).reshape(4, 4)
s = QtCore.QString()
instance.uuid = uuid.uuid4()
f.seek(-1, os.SEEK_CUR)
plt.subplots_adjust(left=0.1, right=0.9, top=0.9, bottom=0.1)
root.mainloop()
self.update({element.tag: dict(list(element.items()))})
print(cls.x)
indices[elem].append(i)
generator() is generator()
logging.basicConfig(level=logging.INFO)
print(counter[0])
collections.deque(iterator, maxlen=0)
pixels[i, j] = data[i][j]
imgplot = plt.imshow(lum_img)
fig, ax = plt.subplots()
model = QStandardItemModel()
tree = et.parse(datafile)
print(df[df.apply(lambda x: x.A in x.B, axis=1)])
root = Tk()
self.bar % 2 == 0
print(pp.pformat(my_dict))
logging.Handler.__init__(self)
vbl.addWidget(self.fc2)
np.vstack((a, b, c))
c.setCompletionMode(QtGui.QCompleter.UnfilteredPopupCompletion)
set(zip(df.number, df.letter))
request.args.getlist(key)
isinstance(result, collections.Sequence)
dst_im.paste(rot, (50, 50), rot)
print(list(compress(A, B)))
sess.run(apply_placeholder_op, feed_dict=feed_dict)
sys.argv[:] = sys.argv[1:]
self.figure.set_edgecolor((1, 1, 1))
ax.set_xticks(list(range(position + 1)))
np.log(a) + b * np.log(x) + c * np.log(y)
ax = plt.gca()
plt.axvline(x=0.5)
self.connect((server, server_port))
path = list(backwalk(predecessor_map, destination, origin))
sess = tf.Session()
n = ctypes.c_int(x.shape[1])
type(a.get_value())
str(self.id)
d = np.random.randn(1000, 1)
open_tags.insert(0, tagname)
dict[key] = value
sys.exit(1)
plt.title(v)
self.member_names.append(key)
ax.set_ylim(0, 15)
d.toJSON()
list(accumulate(lis))
some_list[0] is some_list
obj.save(force_insert=True)
x[0]
some_func(something)
func()
p._set_cloexec_flags(p.stdin)
existing.merge_result([task_from_json(slug, **task) for task in taskdata])
fig.subplots_adjust(hspace=1e-05)
ax.set(xticks=np.linspace(0, 10, 6), yticks=np.linspace(0, 10, 6))
y = tf_spiky(x)
fd.close()
x = x + 1
root = Tk()
x = np.random.rand(N)
denormalized_rgb_color
print(json.dumps(result, indent=4))
df.groupby((df.Grp != df.Grp.shift()).cumsum()).Nums.groups
url = models.URLField()
a = conn.cursor()
list = [[]] * 2
i, j = i + 1, j + 1
g = nx.Graph()
Record.objects.filter(**my_queryset_filters)
ax.pcolor(T, R, Z)
cmd()
round_up_to_even(2.25)
print(r.shape)
t = datetime.datetime.today()
self.axes.scatter(self._x_data, self._y_data, picker=5)
p = p.add(1).cumprod()
matplotlib.pyplot.scatter(n.predict(nfeatures), targets)
path = os.path.abspath(os.path.expanduser(path))
print((x, y, element))
raise ValueError()
triples.append((i, j, k))
bool.mro()
next(itercars)
a.fly()
os.makedirs(dst)
sess = tf.InteractiveSession()
foo.start()
{0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0}
p1 * np.cos(p2 * x) + p2 * np.sin(p1 * x)
len(self.directory)
loop.run_until_complete(asyncio.gather(*tasks))
Page.query.filter_by(name=name).first()
n * s + 0 * s == (n + 0) * x == n * s
job.join()
length = len(string)
dictonary[k].append(i)
browser.set_handle_robots(False)
sys.exit(0)
a = fig.add_subplot(2, 2, i)
im = Image.open(file_path)
print(repr(Dump(1245427)))
client.load_system_host_keys()
console.setLevel(logging.DEBUG)
str(datetime.timedelta(hours=10.56))
mpu.complete_upload()
a[1, 1] = np.nan
print(a, b, c)
seen.add(item)
patches.append(mpatches.Wedge(center, we.r, we.theta1, we.theta2))
cur = conn.cursor()
A()
bool([])
cp.close()
response(environ, start_response)
fcntl.fcntl(fd, fcntl.F_SETFL, flags | os.O_NONBLOCK)
plt.step(Xs, n)
root = Tk()
soup = BeautifulSoup(html)
main()
os.rename(self.dest, self.src)
a[i] = 5
values.append(elem.text)
print(f)
metadata = Base.metadata
self.close()
sftp.get(file, os.path.join(localPath, file))
print(list(divisorGenerator(100)))
hist, bins = np.histogram(data, bins=50)
i[b], i[a] = i[a], i[b]
arr = np.random.random_integers(5, size=(N_rows, 12))
print(list(group))
inspect.getsource(_)
di[key].append(value)
print(lst[-1])
lst.append([1])
getattr(self._decoratee, name)
binary_f(lambda v: works(v) != val0, list)
beaker.session.key = appname
self.ui.setupUi(self)
result = np.abs(diff)
A = np.arange(5 * 7).reshape((5, 7))
count += 1
print(repr(cell))
glFlush()
cls.initialized = True
NotImplemented
s = cStringIO.StringIO()
print(q.get())
append(Button(i))
thread.start()
frame.show()
str(d)
fig = plt.figure()
main()
index.append([keyword, [url]])
text.split()
t[v] = t[2 * v] + t[2 * v + 1]
self.current += 1
edge_list.update([(x, a), (a, b), (b, x)])
grammar.load()
contents = f.readlines()
(b.x - a.x) * (c.y - a.y) == (c.x - a.x) * (b.y - a.y)
r.render()
np.sum(~a)
x.subs(ordereddict.OrderedDict([(y, z), (x, y)]))
addr = ctypes.addressof(a)
exit()
user.save()
content_type = models.ForeignKey(ContentType, null=True)
result = []
fig1.show()
a = random.randint(1, b - 1)
self.members[i] = NULL
[198.40560401][198.4049081][198.4056042]
[7917.75662561][7917.75682048][7917.75662578]
[6056.87496151][6056.87452659][6056.87496175]
sum(my_sparse_matrices[1:], my_sparse_matrices[0]).todense()
round(float(self) / other)
int(value), True
Variance(X).doit()
socket.inet_aton(addr)
os.rename(self.src, self.dest)
time.sleep(num)
b = random.randint(5, 20)
np.random.seed(42)
self.config(menu=menubar)
myclass = MyClass()
plt.bar(his[1][1:], his[0], width=1)
m.drawcounties()
np.minimum(a, 255, a)
values[quality < threshold] = value
print(i)
pylab.plot(y)
ax.set_yticks(np.arange(0, 6, 1))
c[tuple(x)] += 1
out = np.empty((A.shape[1], b.shape[1]))
fig = plt.figure()
myprocess.wait()
p1 = ctypes.c_int(1)
float(m.group(0)), pos + m.end()
files = os.listdir(path)
print(response.read())
d = np.empty(a.shape[0])
arr.append([])
a[0:5:-1]
l.add(2)
queue.put(ii)
socket.inet_pton(socket.AF_INET, domain)
t.start()
c = MyClass()
ser[len(ser)] = ser.iloc[-1]
db.put(counter)
im = Image.open(infile)
self._s.setblocking(0)
doc.Close()
df = pd.DataFrame(np.random.random((5, 5)))
plt.show()
d = datetime.date(2015, 1, 5)
print(data.getvalue())
label.show()
jpeg.read(2)
FinalList.append(set(x))
set(rhymes)
ax.yaxis.set_label_coords(*axcoords)
ax = fig.add_subplot(111)
[item[0] for item in list(d1.items()) if item[1] == 55][0]
setup.py
print(cutit(name, 2))
self.assertEqual(v1, v2, msg)
x = np.array([1, 1, 1, 2, 2, 2, 5, 25, 1, 1])
parser = argparse.ArgumentParser()
A.__class__ = np.ndarray
__import__, (module.__name__,)
User.__table__.create(migrate_engine)
filtered = [strip_punctuation(word) for word in input]
time.sleep(0.1)
d = list(data)
B = [4, 5, 6]
hxs = HtmlXPathSelector(response)
print(my_func0(1, 2))
x = 4
w.show()
frame.pack()
a = np.random.rand(l, n, m)
x = (list(v) for k, v in groupby(data, lambda x: x < 0))
reactor.stop()
plt.ylim(-2.5, 6)
now = datetime.now()
lis.append(lambda : 2)
element = WebDriverWait(driver, secs).until(find)
(mydict[key] for key in mydict)
objects = [object_map[id] for id in ids]
print(dns.__repr__(), dns.qd[0].name)
conn.send(data)
print(sub_tree.childNodes)
df = pd.concat(chunks)
serversocket.bind((socket.gethostname(), 7557))
list_of_tuples = [(1, 2), (4, 5)]
[c for c in s2]
counter[word] += 1
curses.endwin()
ls[0] + listSum(ls[1:])
img.load()
out.reshape(cols, rows).T
oftype[item.__class__].append(item)
venus_thread.start()
earth_thread.start()
mars_thread.start()
excel.Application.Quit()
decor
_quicksort(array, pivot + 1, end)
initialize_db.py
any((a + b == c, a + c == b, b + c == a))
admin.site.unregister(User)
a = datetime.datetime.now()
df.dtypes
ip = self.request.remote_addr
vertices, np.hstack((bary, 1 - bary.sum(axis=1, keepdims=True)))
mylist = list(range(10000))
new_user.save()
f.close()
fig = plt.figure()
comments.extract()
image.save(output)
signal.signal(signum, receive_signal)
tf.Variable(initial)
f.close()
out.write(prg)
_base.py
app = Flask(__name__)
x.append(5)
X, Y
printArray(data, m, n)
a.append([])
new_body_text = re.sub(pattern, make_footnote_counter(), text)
self.setPlainText(text)
C.run()
api = tweepy.API(auth)
cv2.waitKey()
session.add(question)
func(*args, **kwargs)
plt.gcf().add_subplot(421)
np.concatenate(([88], a, [77]))
len([k for k, _ in groupby(a) if k == 1])
suite = unittest.TestSuite()
name, age = the_string.split()
d = dict(globals())
ax = fig.add_subplot(111)
log.err()
print(list(l))
f.close()
edge_list.update([(a, x), (x, b), (b, a)])
[x for x in subsequences if len(x) >= min_length]
do_something(wrapped_dictionary[key])
delta = (mdate1 - rdate1).days
response.body = json.dumps(error_dict)
df
self.initial.update(form.initial)
testCount()
repr(key)
s.setblocking(0)
ax[1].legend(handles=[b1, b2])
foo.main()
now = datetime.now()
list_of_substrings
10 * np.cos(x * 2 * np.pi * cycle)
s.append([number])
L.append(li)
extension = os.path.splitext(os.path.splitext(filename)[0])[-1].lower()
print(foo, foo.bar)
print(data)
poll_twitter()
asps.append(file)
self.add_widget(Cell(i))
fo.write(line)
inds[mask][max_index]
now = datetime.now()
out = np.argsort(reference)[pos]
time.sleep(pollinterval)
self.autocomplete(1)
ctypes.memset(data, 0, size.value)
os.kill(p.pid, 1)
bins.insert(0, 0)
data = json.dumps(data)
type(Foo.spam)
{{localtime(item.date)}}
f.write(new_txt)
lines = f.readlines()
frozenset(frozenset(p) for p in l)
index.date
[job2]
list1 = [dict1[k] for k in commons]
print(str.isalpha.__doc__)
writer.writerow([req.date, req.time, req.user])
print(a, f, b)
conn.close()
r = random.randint(0, 100)
self._whatever
session.add(i0)
sleep(2)
WSGIHandler()
raise ValueError(bcp_identifier)
handles, labels = ax.get_legend_handles_labels()
scipy.stats.norm(0, 1).pdf(0)
print(age.total_seconds())
s.send(msg)
ax = fig.add_subplot(1, 1, 1)
frame = inspect.currentframe()
opt = tf.train.AdamOptimizer(self.learning_rate)
lst[idx - p]
dill.detect.badtypes(f, depth=1)
df = pd.DataFrame(dict(amount=[0, 1] * 10))
pipeline.set_state(gst.STATE_NULL)
setattr(self, key, kwargs[key])
out = input[binary_matrix.ravel()[idx[:, (0)] * lat_len + idx[:, (1)]] == 1]
data.append(tag.next_sibling.string)
print(nx.pagerank(G, max_iter=200))
factors(n)
print(df)
isinstance(P, (list, tuple, np.ndarray))
scheduler.enqueue_in(timedelta(hours=6), after_6_hours)
x + y
sum(x)
self.setItemIndexMethod(QtWidgets.QGraphicsScene.NoIndex)
h.close()
np.triu(np.outer(x, x), k=1).sum()
coords = list((x, y) for x in range(100) for y in range(100))
getattr(actuator, attr_name)
fig = plt.figure()
order_by(Article.created.desc()).limit(7)
mylist[:] = map(func, mylist)
X_train = X[train_indices]
print([s.get_text() for s in axarr[0].get_xticklabels()])
map(operator.sub, a, b)
self.md5.digest()
[0.0, 1.0, 0.0, 1.0],
mac.upper()
pp.show()
ax2.set_xticks(X2tick_location)
session = smtplib.SMTP(server)
im.set_extent((-5, 5, -5, 5))
os.remove(filename)
deleteself[i]
map(lambda x, y: x + y, a, b)
result = [s for s in data if len(s) == len(data[0])]
val = hex(val)
email = models.CharField(max_length=100)
df.head()
self.canvas.delete(self.zimg_id)
channel.close()
frame.update_idletasks()
deleteresponses[-1]
pairs = [(i, j) for i in range(n) for j in range(i + 1, n)]
s.send(tsr.encode())
d = defaultdict(lambda : -1, d)
fn(*args, **kwargs)
self.treeview.expand_all()
input = raw_input
main()
str(bin(7))[2:]
s[last_index + 1:]
abs(1 - 2)
screen.blit(my_image, position)
QtGui.QWidget.__init__(self, parent)
logging.FileHandler.emit(self, record)
Thread(target=startProcess).start()
time.sleep(wait_time)
conn.close()
mod = imp.load_source(name, path)
self.panel.Bind(wx.EVT_LEFT_UP, self.OnMouseUp)
result = [sum(l) for l in a]
c[tuple(x)] += 1
sys.exit(app.exec_())
self.deletes.add(obj)
t.start()
a[np.where(a[:, (-1)])]
page.mergePage(new_pdf.getPage(0))
print(d[1])
print(max(valids) if valids else False)
fig = plt.figure()
opener = urllib.request.build_opener(auth_handler, NoOpHandler())
cosx * signx
x = [np.random.random((10, 10)) for _ in range(5)]
log_file.write(line)
atexit.register(module.deinit)
m = X.mean(axis=1).reshape(-1, 1)
timer.start()
A[idx]
pylab.draw()
cv2.circle(cimg, (i[0], i[1]), i[2], (0, 255, 0), 2)
i.scheduled()
worker.join()
main()
{{content | safe}}
matplotlib.axes.Axes.__init__(self, *args, **kwargs)
found.difference(expected)
layout = QVBoxLayout(self)
d = os.path.join(dir, d)
sizer.Add(self.cb, 0, wx.ALL, 5)
xlim([-6, 6])
grequests.map(rs)
a[b != 0]
Base.metadata.create_all(e)
points = np.array([[-2, -2], [2, 0], [-1, 2]])
coords = zip(a.ravel(), b.ravel())
result = cv2.matchTemplate(img, template, cv2.TM_CCORR_NORMED)
sys.exit()
M = np.matrix([[2, 2, 2, 2], [2, 2, -2, 2], [2, 2, 2, 2], [2, 2, 2, 1]])
self.driver = webdriver.Firefox()
session.commit()
s.sendmail(me, [you], msg.as_string())
im = Image.fromarray(rescaled)
array([27, 26, 26, 26, 27, 26, 26, 26, 26, 27])
print(workdaycount(date(2011, 8, 15), date(2011, 8, 22)))
logging.basicConfig(level=logging.INFO)
v = [(t[i + 1] - t[i]) for i in range(len(t) - 1)]
form.save()
sudo(command)
ctx.fill_preserve()
today.weekday()
x = someModule.someClass(list(range(1, 5)))
np.apply_along_axis(multi_slice_max, 1, cond, arr)
s.shutdown(socket.SHUT_WR)
g.LgRnk.apply(lambda x: x / len(x))
p = multiprocessing.Process(target=csvreader, args=(string_array[i], q))
atomized
name = models.CharField(max_length=50)
process.send_signal(signal.SIGINT)
olist.append(otest)
[iplocationc]
c.__class__.__mro__
ax = axes([0.1, 0.1, 0.8, 0.8])
g = g.sortlevel()
self.beta = tf.Variable(tf.constant(0.0, shape=[depth]))
apps.get_models()
virtualenv / home / my_envs / env_for_projectname
[[1], [1, 2]]
im.set_clim([0, 1])
print(key, value)
img = Image.open(picture)
pdb.set_trace()
plt.figure(1)
res = opener.open(req)
plt.legend(handles=[NA, EU, AP, SA], loc=2)
h = ax.hist2d(x, y, bins=40, norm=LogNorm())
paint()
mp.active_children()
my_companion.close()
[0, 0, 0, 17, 0, 0, 0, 40, 0, 0, 0, 40, 0],
pprint(list(ws.iter_rows()))
self.driver = webdriver.Firefox(self.profile)
cursor = connection.cursor()
sys.exit(NO_PYTHON_LIBRARY_ERROR)
axx.xaxis.set_major_locator(ticker.FixedLocator([xx]))
list(zip(a, itertools.cycle(b)))
subprocess.Popen([python_bin, script_file])
instance.some_method(data)
other_object.add(obj)
print(list(interleave(range(1, 5), range(5, 10), range(10, 15))))
Mixin.__init__(self)
thread.run()
self.c.set(SERV_SECTION, SERV_NAME, SERV_NAME_DEFAULT)
ax1.plot(xvals, data)
data = models.HStoreField(db_index=True)
handler = logging.StreamHandler(sys.stdout)
re.sub(pattern, repl, text, flags=re.DOTALL)
self.model.transform(X, self.threshold)
run(command)
track.duplicateTo_(newPlaylist)
run_wsgi_app(application)
p = pyaudio.PyAudio()
ax1.yaxis.set_major_formatter(fmt)
self.factory._send(data)
c = np.empty((a.size + b.size,), dtype=a.dtype)
matrix = ss.coo_matrix((ones, (rows, cols)))
print([id(y) for y in new_strs])
ax = fig.add_axes([0.15, 0.15, 0.7, 0.7])
PyMouseEvent.__init__(self)
pyrodaemon.shutdown()
show()
self.list_of_tweets = []
i = i + 1
output.append(list[prev:index])
callthecommandhere(blablahbla, filename, foo)
plt.xticks(np.arange(0, 25, 5), [0, 25, 50, 75, 100])
checkDict(subword)
pd.DataFrame(records, columns=list(columns.keys()))
out.write(fixed)
a = TestB()
cls.__init__ = instrumented_init
num_seen.setdefault(v, []).append(k)
p1 = N * np.dot(B.T, A)
log.start()
random.sample(randset, 100)
server.quit()
x, y = x + dx, y + dy
nf.close()
fig = plt.gcf()
dict.__setitem__(self, key, val)
application = QtGui.QApplication(sys.argv)
timeit(set(a).intersection(b))
deletelst[i]
b = a[:, (idx)]
print(sample.collect())
list(string.Formatter().parse(s))
all_pixels.append(0)
exit(0)
df.div(df2.iloc[0])
main()
self.client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
conn.send(msg)
t = zip(a, b, c)
final_ensemble.n_estimators = len(final_ensemble.estimators_)
print(repr(fin.readlines()))
result = mygetter(tup)
self.name
ax = fig.add_subplot(1, 1, 1)
plt.contour(X, Y, F - G, [0])
user.Getinfo()
d = defaultdict(list)
mercury.circle(58, 1)
int(binary, 2)
fcs.append((random.random(), random.random(), random.random(), 0.6))
pdb.set_trace()
axes[0, 1].set_ylim(0)
random.seed()
glEnable(GL_POLYGON_SMOOTH)
self.grid_1 = wx.grid.Grid(self.window_1, -1, size=(1, 1))
ax.set_title(str(temp))
user = fields.ForeignKey(UserResource, user, full=True)
globals().setdefault(name, [])
print(pwd.getpwuid(os.getuid()))
patcher.stop()
t.run()
self.canvas.draw()
of.write(l)
{word: list(neighbours(word)) for word in words}
sys.exit(app.exec_())
stdout_redirected(to=sys.stdout, stdout=sys.stderr)
client = oauth.Client(consumer)
print(i0.id)
time.sleep(0.5)
list.__setitem__(self, key, value)
out = [d[k] for k in sorted(d.keys())]
print(paths[2][6])
app.MainLoop()
print(item)
x, y = fsolve(equations, (1, 1))
pd.MultiIndex.from_product([letters, letters]),
s = pd.Series(np.arange(10))
matplotlib.pyplot.scatter(Xs, Ys.flatten(), color=cs)
s += random.randint(1, y)
sock.settimeout(10)
cosetCoding.cosetCoding(10, 11, asarray([0, 0, 0, 0, 0, 0, 0, 0]), 0)
writer.UpdatePipeline()
df
(10 - s % 10) % 10
self.data[key] = value
np.savez(filename, row=row, col=col, data=data, shape=shape)
s[offset:offset + amount]
window.show_all()
j = json.loads(your_json)
mutex.acquire()
query = urlparse.parse_qs(url.query)
{{companyForm.company_name()}}
dict(new_d)
plt.show()
sys.stdout = sys.__stdout__
post_save.connect(Activity.cancellation_occurred, sender=Cancellation)
kOUT = kOUT.tolist()
session.add(f)
print(s.groupby([s.index // k]).mean())
outFile.close()
foo = POINTER(temp_foo)
fig, ax = plt.subplots()
f2.write(Lines[i + 2])
isinstance(s, str)
help(str.find)
Thread(target=read_stderr, args=[process]).start()
print(exceptions.html_error_template().render())
myarray[myindexlist]
fig, axes = plt.subplots(1, 4, figsize=(10, 5))
zip(itertools.repeat(prefix), iterable)
x = random.randrange(box[0][0], box[1][0])
ax.yaxis.set_major_formatter(tick.FuncFormatter(adjust_y_axis))
os.path.join(self.path, filename)
f(*args, **kwargs)
cv.Threshold(grey_image, grey_image, 70, 255, cv.CV_THRESH_BINARY)
f
ndimage.map_coordinates(data, [zi, yi, xi], cval=-999)
E += potential(np.sqrt((x[i] - x[:i]) ** 2)).sum()
any(sublst == lst[i:i + n] for i in range(len(lst) - n + 1))
self.t1 = time.time()
pyplot.hist(e_data[selected_values])
func_py.restype = ctypes.c_double
float(self.val)
window.show_all()
list_size_2.append(row)
c = np.arange(24).reshape((4, 6))
window.show()
block.draw()
greet_command()
print(i, chr(i))
c = np.hstack((a, b))
br.set_handle_referer(True)
req = urllib.request.Request(url)
plt.yticks(np.arange(0, len(ax1) / r - 0.1, 1 / r), ax1_ticks)
print(is_shifted_copy([1, 1, 2], [2, 1, 1]))
ax = fig.add_axes([0.05, 0.1, 0.9, 0.85])
data.splitlines()
self.__class__.set_x_class(10)
results = [r.get() for r in results]
sys.exit(1)
allFoos()
ax1 = fig.add_subplot(111)
df.append(h, ignore_index=True)
self.old_func1 = module1.func1
dict[key] = value
msvcrt.getch()
y = [p._replace(probability=round(p.probability, 2)) for p in y]
decompressor.close()
main()
fig, axes = plt.subplots(nrows=2, ncols=2)
plt.plot(x, y2)
sys.stdout.flush()
profile.save()
plt.ylim((0, 100))
x.sort(key=lambda item: (len(item), item))
len(self.data)
connection.setblocking(0)
arr.tocsr()
res = [lookuplist[k] for k in arr]
print(l[:-1])
main.py
random.shuffle(combined)
root = tk.Tk()
obj.image.url
s.listen(1)
print(len(main()))
p = subprocess.Popen(some_cmd, stdout=subprocess.PIPE, stdin=subprocess.PIPE)
d = {}
server.ehlo()
lst.sort()
cap.release()
plt.show()
plt.xlim(-2.5, 12)
raise SystemExit
axes.set_ylim(0, math.ceil(max(logcdfy)))
plt.setp(labels, rotation=0)
n ^ 1 << k
models.User.query.get(user_id)
self.assertEqual(expected.lower(), actual.lower())
[2] + [(2 * i + 1) for i in range(1, n // 2) if sieve[i]]
plt.scatter(x1, y1, label=str(pointset1))
tree = [Node() for _ in range(10)]
self._fileobj.seek(oldposition, os.SEEK_SET)
cj.set_cookie(c)
fh.setLevel(logging.INFO)
plt.imshow(im)
f.write(s)
list(bucket.list())
m.digest()
idx = np.abs(array - value).argmin()
tree = lh.fromstring(content)
fh.setLevel(logging.INFO)
[e.text for e in sel(h)]
print(df1.to_csv())
fig.clear()
fig = plt.figure()
setattr(self, b, button)
ax.add_artist(ell)
print(ast.literal_eval(escaped_str))
col.domain[0].name, pd.Series(col.to_numpy()[0].flatten())
print(self.invalid_response)
myapp.show()
w1.append(words[0])
survival_table = pd.Series(index=make_category_multiindex(categories, names))
dfUnstacked2
heapq.heappop(heap).x
cj = cookielib.CookieJar()
CS = plt.contourf(xi, yi, zi, 15, cmap=plt.cm.jet)
msvcrt.setmode(sys.stdout.fileno(), os.O_BINARY)
word_list.sort(key=lambda i: i[1], reverse=True)
self.func.__call__(*args, **kwargs)
cnxn.commit()
print(highlight(json_str, JsonLexer(), TerminalFormatter()))
app = QtGui.QApplication(sys.argv)
nbrs.fit(X, Y)
{{my_model.slug_field_name}}
l = sorted(l, reverse=True)
testnum == num
adate -= timedelta(days=1)
ax.grid(True)
d = defaultdict(list)
screen = pygame.display.set_mode((800, 600))
ax.set_ylim(0, 61)
self.inverse.setdefault(value, []).append(key)
list(filter(condition_check, l))
list(map(sum, zip(a, b, c)))
print(psutil.net_connections())
soup.td.contents
filter(good, combinations(list(range(1, n + 1)), r))
(d in set1) == (newd in set2)
whatever
sys.exit(-1)
coo_matrix((data, (c.row, c.col)), shape=(a.shape[0], b.shape[1]))
A = np.zeros((M, N))
self.buffer = [1] * size
a[1:4] = [9, 7]
a = next(i for i in userInput if i in wordsTask)
print(id(x))
B[mask] = A[1][B[mask]]
im.set_clip_path(clip_path)
A = NP.array(A)
list(d)
print(cross_validation_group(test_data, train_data))
df = pd.DataFrame([0])
exit()
a.T
listB = [0, 1, 2, 1, 2, 1, 0]
ax.scatter(x[mask], y[mask])
inqueue.put(i)
name = models.CharField(max_length=100)
root
pygame.mixer.init()
main()
d = cv2.cvtColor(c, cv2.COLOR_RGB2BGR)
cv2.rectangle(img, pt, (pt[0] + tw, pt[1] + th), 0, 2)
x ** 2
sample_size += len(rn)
ax.plot(t, fun(t))
layout = QtGui.QVBoxLayout(widget)
l.append(i % 10)
c = [a[index] for index in b]
hold(True)
f(n)
df = df.reindex(columns=unused_cols + list(chain(*fill_missing)))
nil
random.shuffle(each)
sample = random.sample(item_names, 2)
[gu(i) for i in range(len(uo))]
retval, img = cv2.threshold(img, 254.0, 255.0, cv2.THRESH_BINARY)
type(c)
fill_between(x, height - l[1], height, color=colors[1], alpha=alpha)
data2[:, (0, -1)] = np.nan
mycmd().cmdloop()
type({})
print(ObjectJSONEncoder().encode(tree))
tfact(n - 1, acc * n)
item.append(len(item))
map(lambda k_v: k_v[0], L)
sleep(0.5)
deletecursor
reactor.run()
window.show()
print(a)
mapper(Something, select([sometable], sometable.c.deleted == False))
time.tzset()
do_something_2()
df
b = array([2, 4, 7])
f = urllib.request.urlopen(link)
results.append(string[split_points[-1][1] + 1:])
(list(range(5))[6:7] + [999])[0]
values.append(value)
App().run()
d = {x: (x, y, z) for x, y, z in tuples}
pylab.show()
QApplication.setOverrideCursor(QCursor(Qt.WaitCursor))
d = R * sqrt(x * x + y * y)
app.SetTopWindow(frame)
Job.objects.get(client=client)
print(result.get(timeout=1))
ax.set_ylim(-75, 75)
list(hi_obj.__dict__.keys())
now = datetime.now()
foo = np.random.rand(2000000).cumsum()
a = a.__iadd__(b)
html = browser.open(url)
XS = np.asarray(XS)
np.roll(sa, -np.count_nonzero(np.isnan(a)))
exit()
getattr(mod, attr)
app = Flask(__name__)
fcntl.lockf(doing_fd, fcntl.LOCK_EX)
img = cam.getImage()
fig = plt.figure()
pixels = list(im.getdata())
False
lxml.etree.tostring(r.item)
sleep(5)
self.finish()
form = MyForm(request.POST)
proc = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)
myfile.close()
browser = webdriver.Firefox()
frame = cap.read()[1]
do_plot(ax)
print(line)
ax1.plot(xvals, xvals, linewidth=7)
show()
print(lt_obj.get_text())
out.write(g.read())
parse(new_str)
result = np.c_[original[v[1:-1], v[:-2]], original[v[1:-1], v[2:]]]
min(l[0] + best_choice(l[1:]), l[1] + best_choice(l[2:]))
resp = opener.open(req)
do_stuff(a, b)
list(B.items())
canvas.print_png(sio)
writer.writerows((title, intro + tagline) for title, intro, tagline in grouped)
a = np.exp(np.random.randn(5, 10)).astype(theano.config.floatX)
time.sleep(alarm1)
sys.stdout.write(inline)
df
seen.add(key)
plt.xticks(x, my_xticks)
d = date(year, 1, 1)
c = np.array([0, 1, 2])
n = int(temp) * 2
server.shutdown()
conset.add(x)
plt.yticks(list(range(len(labels))), labels)
self.render_change_form(request, context, form_url=form_url, add=True)
isinstance(x, collections.MutableSequence)
y = x.T.tolist()[0]
args = parser.parse_args()
sys.meta_path.insert(0, importer)
self.window.show()
fig = plt.figure(figsize=(10, 9))
print(row[column_number])
a = A()
res = im.crop((0, 0, MAXSIZEX, MAXSIZEY))
xml_output
len(r.content)
copyfile(srcname, dstname)
print(table)
mpf(200) + mpf(2e-26) + mpc(1j)
plt.show()
f.close()
splittedname(s1) > splittedname(s2)
np.abs(df.time - image_time)
user = User.objects.get(pk=user_id)
d = {i: x for i, x in enumerate(a)}
lst.extend((8, 9, 10))
df = pd.DataFrame(cols)
fb.authenticate()
attachment.set_payload(fp.read())
main()
str(self.__dict__)
self.Artwork.pack()
pdf.add_page()
df[1] == 4
t = datetime.datetime.now()
pix = im.load()
result = np.array(result)
data = conn.recv(1024)
exit()
os.system(x)
print(new_str)
crawler.start()
results = sorted(list(results.items()), key=lambda x: x[1])
int(x.split()[0])
confused_array[~mask & (numpy_array == 0)] = 0
result.append((t, c1 + c2))
(a * d).todense()
ninety - nine
vector / np.linalg.norm(vector)
text[len(prefix):]
WebDriverWait(driver, timeout).until(element_present)
fig = plt.figure()
result += count(haystack[pos + 1:], needle[1:])
{{l.form.city}}
[abs(j - i) for i, j in zip(minmax[:-1], minmax[1:])]
deletedict[key]
print(response.registers[2])
print(arr[local_minima_locations])
gukan(0)
plt.bar(ind, OY, width=width)
audiolab.play(x, fs)
self.a.append(numpy.hstack((numpy.ones((input.shape[0], 1)), input)))
True
outfile.close()
self.d[k]
key.delete()
monkey.patch_all()
uuid.uuid1(random_48_bits)
xmldoc = minidom.parseString(xml_str)
m.sort(key=str.isdigit)
print(rect.PyRectangle(0, 0, 1, 2).getLength())
pst.close()
columns[i].append(l)
monkey_patch_B()
img.close()
self.loadFinished.connect(self._loadFinished)
bytes([97, 98, 99])
pyplot.gca().add_patch(circle)
today = datetime.date.today()
env = Environment()
some_func()
p.pretty(obj[key])
time.sleep(0.5)
p[pair[0]] += 1
merged.update(add_obj)
timeit(numpy.array(hugeequal1), numpy.array(hugeequal2), 10000)
print(spectra_list[1].dispersion)
fig.tight_layout()
a.sort_index(1, inplace=True)
func()
fig.delaxes(ax)
code = func.__code__
np.array(scipy.stats.chi2.interval(0.95, 2 * data)) / 2 - 1
X[[0, 1], [0, 1]]
[dingdong]
ax.xaxis.set_ticks(np.arange(min_x, max_x, int((max_x - min_x) / len(labels))))
sum(v)
buf.readline()
l = map(lambda x: x + 2, l)
metadata.read()
soup = BeautifulSoup(html_doc)
ax.clear()
sys.stdout = Discarder()
conn.setopt(pycurl.USERNAME, username)
window.show()
t[0].start()
plt.vlines([0, 4, 6], -10, 10)
a is a.astype(int, copy=False)
ssh = paramiko.SSHClient()
now = datetime.datetime.now()
conn.send(some_data)
file_name = f.name
T2.method_three()
self.loadFinished.connect(self.on_loadFinished)
self.h2Box.addWidget(self.cmbox)
args = parser.parse_args()
today = datetime.date.today()
df[cols].mean(axis=1)
csvout.write(wstr)
np.interp(width_S, S_values_2, F_values_2)
b = np.linspace(-2, 2, 5)
np.concatenate((new_face, M), dim)
self.file_pointer.seek(0, os.SEEK_END)
form.save_m2m()
print(merge(lst))
regex.split(s)
f(*args, **kwargs)
book = xlwt.Workbook()
self.screen.fill((255, 255, 255))
ax.add_collection(p)
h.request(url, method=method, body=body, headers=headers, **kwargs)
{v: k for k, v in enumerate(calendar.month_abbr)}
parser = argparse.ArgumentParser()
sess = tf.Session()
db.session.commit()
cam.start()
sax.parse(locstm, Handler())
t1 = time.time()
gs.tight_layout(fig)
response
sleep(0.1)
r = re.compile(result)
print(sum(range(49999951, 50000000)))
types = [col.type for col in q.columns]
etree.tostring(otree)
print(json.dumps(root, indent=4))
print(result.key().id())
sockobj.listen(5)
result = [o for o in list1 if o not in set2]
print(t.render(c))
excel.Application.Quit()
sleep(1)
result.append([t[j + 1]])
foo_from_bar(self.bar_impl(x))
list(s)
line.set_xdata(r[:, (0)])
out.close()
sys.argv[0]
s = requests.session()
print(np.intersect1d(a, b))
df
df.dtypes
main()
print(f.data)
f.write(os.linesep)
app = QtGui.QApplication(sys.argv)
user.auth_ids.append(email)
form = AnimalForm(request.POST)
ast.literal_eval(value)
pool.join()
a, b = 0, 1
df1
y, x = np.ogrid[-m:m + 1, -n:n + 1]
plt.show()
conn = pymongo.MongoClient()
btn.clicked.connect(self.buttonClicked)
self.scat.set_offsets(data.transpose())
m.group(1)
f.write(line)
df.dtypes
hash(x)
out_file.writelines(unique_everseen(f))
response
fig.add_subplot(111)
p.start()
plt.hist(myarray, weights=weights)
os.makedirs(path)
print(fresult)
[sample[i * n:(i + 1) * n] for i in range(count)]
f = urllib.request.urlopen(url)
b = cast(s, POINTER(c_ubyte * 20))[0]
print(df.groupby(df.index).apply(tmpFunc))
ax.set_xticks(np.arange(0, 8) - 0.5, minor=True)
pixels = img.load()
pyplot.show()
c = np.searchsorted(a, b)
types = [col.type for col in res.context.compiled.statement.columns]
libxxx.foo(data, len(data))
order.append((dist, i))
ymin, ymax = kde.get_ylim()
list(self).count(obj)
result = set(p[0])
type(x)
regressor.fit(X, y)
self.y -= 1
self.Bind(wx.EVT_CHAR, self.KeyDown)
json.loads(value)
socket.setTimeout(SERVICE_TIMEOUT_IN_mS)
False
self.b = 0
[(k1[0], k1[1], k2) for k1, k2 in zip(itertools.chain(*dge), nde)]
socket.setdefaulttimeout(60)
mydic[key].append(value)
raise Exception()
numpy.clip(A.astype(int) - B.astype(int), 0, numpy.iinfo(int).max)
p.communicate()
sort_idx = np.argsort(a)
c, f = divmod(your_number, 256)
results = {input_list[0]: [input_list[0]]}
arr[idx]
u = numpy.linspace(0, 2 * numpy.pi, 100)
self.loop.call_soon_threadsafe(task.cancel)
print(f.read())
sorted(items, key=inner)
main()
out = a[idx, np.arange(a.shape[1])]
color = np.array(color)
future += datetime.timedelta(days=1)
df[df < 0] = 0
idx = np.random.randint(10, size=2)
section_sums = np.bincount(np.arange(mask.size) // 20, mask)
ax1.set_yticks(numpy.arange(y1 - 1, y2 + 1, 0.5))
stdout, stderr = process.communicate()
Platform.__init__(self, x, y)
self.callback()
A[np.arange(2), B.T].T
print(visit_element.tag, visit_element.text)
self.pages.append(dict(self.__dict__))
b = a[random.randint(0, len(a) - i)]
driver = webdriver.Firefox()
set(listas[0]).intersection(*listas[1:])
print(xee.tostring(doc))
print(x)
str.__getattribute__(self, attr)
bytes([bstr[0] + 1, 98, 99])
df.info()
pdf.image(image, x, y, w, h)
restart()
l.add(i)
idx = np.argsort(df[df.columns[5:]].values)[0]
handle_the_error()
model1.py
sys.path.insert(0, cmd_subfolder)
map(bin, bytearray(st))
(x + y).subs(reversed(reps))
s[-6]
response = urlopen(request).read()
html.strip_tags(htmls)
output = p2.communicate()[0]
print(response.getRegister(2))
chain.from_iterable(combinations(s, r) for r in range(len(s) + 1))
subject = models.CharField(max_length=100)
hl.set_xdata(numpy.append(hl.get_xdata(), new_data))
f1.save()
flask.render_template = _my_render_template
print(response.read())
(k for m in self.maps for k in m.keys())
test2()
count += 1
GetSum(arrs[-1], arrs[:-1])
plt.setp(labels, rotation=0)
self.setSelectionMode(QtGui.QAbstractItemView.MultiSelection)
results = serializers.SerializerMethodField()
filtered_numbers = list(filter(predicate, numbers))
datetime(1970, 1, 1) + timedelta(seconds=local.timestamp())
X, Y = np.meshgrid(xvals, yvals)
random.shuffle(object_list)
self.write(data)
np.where(arr >= threshold)
driver = webdriver.Firefox(firefox_profile=fp)
self.put(item)
plt.plot(x, y1)
(b[c] == a).all()
pi = (a + b) * (a + b) / (4 * t)
tcpcounter += 1
udpcounter += 1
loop = asyncio.get_event_loop()
field = self._fields.get(name)
self.log.write(s)
self.failed_urls.append(response.url)
os.symlink(linkto, dstname)
r = fv(a[:, (numpy.newaxis)], b)
unittest.main()
blocks.shape
writer = csv.writer(f)
layout = QtGui.QVBoxLayout()
print(json.dumps(json_data, indent=2))
len(FinalList)
A = np.random.random((5, 5, 5))
print(s)
data.sum()
final.append(str(seq[0]))
main()
app.MainLoop()
browser = webdriver.Chrome()
[0, 1, 2]
index_list
decorator
indices[:-(n - 1), (5)] = np.arange(n - 1, m * n)
ax = plt.gca()
C[i, j] = np.dot(A[:, (i)], B[:, (j)])
post_save.connect(ping_handler, sender=MyModel)
wavwriter.setnchannels(1)
canvas.saveState()
print(list(best_range))
a[np.ix_(n1, n2)]
self.__dict__[key]
a = pd.Series([pd.to_datetime(date) for date in date_stngs])
fig1 = plt.figure()
md5.digest()
b1 = np.array([[5, 6], [7, 8]])
Py_Finalize()
a = [1, [2, 2, [2]], 4]
a.set_yticklabels(a.get_yticks(), fontProperties)
json.loads(raw_post_data, object_pairs_hook=dict_raise_on_duplicates)
allatt
fig = plt.figure()
sorted(players, key=lambda player: player.rank)
print(query2.all())
f.close()
setenv(foo)
iter(relatives.items())
df_smooth.plot(ax=axs, alpha=0.7)
contents = Path(file_path).read_text()
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj))
strong.append(value)
fout.close()
ax2.add_line(copy.copy(line2))
serversocket.bind((host, port))
frame = pd.read_csv(path, names=columns)
X, Y = numpy.meshgrid(list(range(sz[0])), list(range(sz[1])))
self.stream.write(msg)
res_list[i].append(float(val))
cos(x) + cos(y)
s.listen(10)
session.flush()
sk.push(x509)
hash(s) % 256
MyUser.objects.get(pk=self.pk)
c = C()
panel = Label(root, image=img)
logger.addHandler(hdlr)
f.close()
list(cor[cor > 0.9999].to_dict().keys())
ys = [ys[i] for i in sorted_index]
result += match.group(1).upper() + match.group(2).upper()
print(cron5)
print(k, sys.getsizeof(v))
a.close()
ax2 = fig.add_subplot(2, 1, 2)
zip_list = zip(A, B)
result_dict
reader = csv.reader(infile)
pool.shutdown()
f.x
server.shutdown()
lines = f.readlines()
r.url
args.type()
{l: set(words) for l, words in groups}
print(procname)
[0, 0, 0, 17, 0, 0, 0, 17, 0, 0, 0, 17, 0],
sizer.Add(self.cbBG, 0, wx.ALL | wx.CENTER, 5)
dataset.withColumn(out_col, udf(f, t)(in_col))
background.fill((250, 250, 250))
f()
today = datetime.date.today()
sns.heatmap(df)
pprint.pprint(content_json)
func = getattr(modulename, funcname)
ax1 = fig.add_subplot(111)
fig, (ax1, ax2) = plt.subplots(nrows=2, sharex=True)
len(one_set & set_of_150kwords)
button.pack()
atexit.register(root.mainloop)
decorator
len(word)
np.random.shuffle(p)
subject = models.CharField(null=False, max_length=128)
_getdents.restype = ctypes.c_int
page = BeautifulSoup.BeautifulSoup(html.text)
r = urllib.request.urlopen(url)
s.send(CRLF.join(request))
self.layout.addWidget(self.button)
f.seek(256, os.SEEK_SET)
self.__class__.__call__ = lambda x: x
t[0] = t[0]
f = scipy.interpolate.interp2d(x, y, data)
mask = np.zeros_like(arr, dtype=np.bool)
image_data = get_image_data_from_blob()
btn.set_sensitive(True)
start = time.time()
time.sleep(2)
title = Column(String(20), primary_key=True)
eval(s, {}, {})
a.append(i)
x.change()
list(f.keys())
post = models.ForeignKey(Blog)
future = asyncio.ensure_future(coro)
x + 1
Test.calc_x.__code__.co_names
out.write(re.sub(pat, s_after, line))
pygame.init()
m = hashlib.md5()
driver = webdriver.Firefox()
self.session.commit()
plt.show()
driver = webdriver.Firefox()
self.assertRaises(models.BadFooError, foo.full_clean)
next(self._iter)
curses.echo()
[i]
append_record(my_dict)
type(a)
print((start, end))
myfast()
myFunc(1, 2)
os.remove(filename)
y.append(np.random.random_integers(0, 10, 20))
self.files = {}
text_file.close()
print([x for v in list(anagrams.values()) if len(v) > 1 for x in v])
time.sleep(0.1)
time_keypresses(pygame.event.get())
driver = webdriver.PhantomJS(desired_capabilities=caps)
row.delete()
self.videoSink.set_xwindow_id(hWnd)
print(list(islice(primes(), 0, 1000000)))
proc = subprocess.Popen(cmd, stdin=subprocess.PIPE)
wb.save(response)
make_sine(freq, data_length, fname)
c.seek(0)
help(sys.getsizeof)
b.py
np.array(x.shape).tofile(f)
l.addWidget(self._tv)
list(User.__mapper__.columns)
count = 0
sys.stdout.flush()
df2
s.cookies.save(ignore_discard=True)
ax.set_xlabel(label)
clean_table_grouped.join(for_df)
f.close()
slices = list(takewhile(bool, (list(islice(it, 0, i)) for i in seclist)))
(0, 0, 128), (255, 0, 255), (255, 255, 0), (0, 255, 255), (128, 0, 128)
pd.read_csv(io.StringIO(df.to_csv(index=False)))
leg.draggable()
list(d.items())
tt.Index(0).Set(ea)
numpy.ones((2, 2), dtype=bool)
fcond.wait()
fa[0]()
field = Model._meta.get_field(field_name)
y, d + math.hypot(y[0] - x[0], y[1] - x[1])
user.get_profile().whatever
Exception.__init__(self, message)
self.list.SetItemData(index, key)
os.system(cmd)
mychain.apply_async()
d = np.diag(a)
w = gtk.Window()
interpreter.process_page(page)
graph.add_edge(node_number, random.choice(graph.nodes()))
a()
chessboard.get_king_moves()
print(text.text)
index.create()
setattr(self, key, l)
A.append(B)
D[word] += 1
l = [random.randrange(0, 5) for _ in range(50)]
my_tuple = [], []
list.__setitem__(self, *args)
print(get_overlap(s1, s2))
response = urllib.request.urlopen(url)
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj))
setattr(namespace, self.dest, dest)
task.cancel()
result = []
print(max(s), max(s, key=str.lower))
DEBUG = False
i = np.random.choice(list(range(0, n * n)), size=m)
[s for s in mylist if not myregex.search(s)]
time = time.time()
fig = plt.figure()
timezone.make_aware(yourdate, timezone.get_current_timezone())
print(elem.split()[-1])
L.sort(key=getvals)
self.SetShape(wx.Region())
line[:i]
do_something(line)
imp.load_compiled(name, path)
dfall.head(6)
login(request, user)
merger.write(output_file_path)
text = urllib.request.urlopen(url).read()
painter.drawControl(QtGui.QStyle.CE_PushButton, self.getSyleOptions())
pyplot.show()
[zxcv, zxcv]
type(d.values())
self.observer.stop()
self.photo.save(os.path.basename(self.url), File(open(result[0])))
df1 = pd.DataFrame(lst, columns=cols)
im.set_data(mat)
print(ruamel.yaml.dump(data, Dumper=ruamel.yaml.RoundTripDumper))
data = data.drop(data.index[[0]])
os.kill(pid, 0)
np.allclose(Y1, Y2)
n = minn if n < minn else maxn if n > maxn else n
ax1.minorticks_on()
response.close()
f.writelines(res)
thirdpartymodule_b.dosomething()
output.addPage(page)
col_sums[:, (j)] = row_sums[:, (j)]
r = regex.search(string)
logger2.addHandler(log_handler2)
a.searchsorted(b)
dictionary = {}
self.__dict__[attr] = str(value)
connect.close()
wr.writerow(sh.row_values(rownum))
c.setopt(pycurl.FOLLOWLOCATION, 1)
dot(Phi, R)
ax2.yaxis.set_major_locator(MultipleLocator(0.25))
signal.signal(signal.SIGQUIT, term)
c = np.arange(2, 9)
print(df.d.tolist())
print(match.groups())
print(pattern.findall(txt))
output = process.communicate()
self.deque.append(x)
x + (y if isinstance(y, tuple) else (y,))
data = np.random.normal(size=1000)
yaml.add_representer(MyClass, MyClass_representer)
x * np.sin(y)
re.sub(findthe, lambda matchObj: replacement.pop(0), sentence)
driver.set_window_size(1400, 1000)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
c = [(a[i] + [bi]) for i, bi in enumerate(b)]
t.set_axis_off()
show_float(x)
keys[0] if len(keys) == 1 else keys
cj = cookielib.LWPCookieJar()
hash(list(self.items()))
r = lambda : random.randint(0, 255)
file = cStringIO.StringIO(urllib.request.urlopen(imageUrl).read())
print(pos)
IOLoop().run_sync(func)
graph = facebook.GraphAPI(token)
a = b[0]
canv.pack()
handler = logging.FileHandler(file_name)
df
r = conn.cursor()
http_server.listen(8888)
consumer_lock_object.release()
zip(*alist)
cast(col, Float)
np.column_stack(np.unravel_index(idx, lon.shape)).tolist()
fig = plt.figure()
print([c.b[i] for i in range(5)])
[s.lower()[i:i + 2] for i in range(0, len(s) - 1, 2)]
self.stop()
test = Test()
fig.add_subplot(211)
a = MyClass()
True
_zip.write(in_file)
bool([]) == False
suite
numpy.nonzero(a.max() == a)
bool(obj) and all(isinstance(elem, str) for elem in obj)
bd.sort(key=lambda d: (d.month, d.day))
lis = [1, [2, 2, 2], 4]
s.listen(1)
print(s[:index])
b = random.randint(0, 20)
z < t.isoformat()
print(dec_num == 511)
plt.plot(np.random.random(20))
self.send_response(200)
df
contexts
self.left.pop()
root = Tk()
shape.append(len(l))
a.set_ylim(-1.1, 1.1)
plt.scatter(x, y, zorder=1)
ax = fig.add_subplot(1, 1, 1)
new_list1.append(i[0])
-g595x842
w.seek(8)
self.root.clipboard_clear()
atexit.register(close_database)
owner = serializers.IntegerField(required=False)
print(magicInput[2:4])
newlist.append(i)
path.append(parent[path[-1]])
df = pd.DataFrame(a.T)
b[:, (0), (0)] = t2
df2.letter.unique()
plt.setp(cm.ax_heatmap.yaxis.get_majorticklabels(), fontsize=6)
map(itemgetter(1), groupby(iterable, key))
random_numbers()
a.append(1)
print(row[0], row[1], row[2])
query = users.select().order_by(-users.c.id.desc())[:5]
conn.setblocking(0)
print(line)
dom = ET.parse(io.BytesIO(content))
plt.axis([x.min(), x.max(), y.min(), y.max()])
value = getattr(value, v)
ax = fig.add_subplot(111, aspect=1)
solution = [int(x) for x in solution]
layout.addWidget(self.plot)
random.shuffle(results)
example[4:0]
len(j) - len(set(j))
print(output)
normed.mean(axis=1)
_quicksort(array, start, right)
tree = html.fromstring(text)
rows = [row for row in reader]
axes[1, 1].pcolormesh(xi, yi, zi.reshape(xi.shape))
TRUE
self._reader2 = reader2
total += 1
len(l)
[[1][0][0]]
self.send_blob(blob_key)
self.maxSlider.SetValue(self.minSlider.GetValue() + 1)
all(type(i) is int for i in my_list)
p.map(Processor(credentials), list_of_data)
pool.join()
fig = PLT.figure()
self.label = QtGui.QLabel(self)
print(get_jsonparsed_data(url))
val += 1
ax.legend(scatterpoints=1)
today = datetime.date.today()
df.a.quantile(0.95)
p2.start()
globals()[attr] = getattr(foo, attr)
plt.show()
arr[0]
post_save
time.sleep(1)
meta.reflect(bind=engine)
title, ext = os.path.splitext(os.path.basename(pathAndFilename))
e.delete(0, END)
cmp(list1, list2)
screen = pygame.display.set_mode((800, 600))
nums.pop(i)
manager.shutdown()
pylab.show()
print(h.name, h.hexdigest())
np.bitwise_and.reduce(b) == b[0]
str(counter - 1)
f.close()
True
d = {v[0]: (v[1:] if len(v) > 2 else v[-1]) for v in list(d.values())}
a.show()
heapq.heapify(items)
self.label.setPixmap(myScaledPixmap)
[1, 2]
Test - app
form.field(**attrs)
print(config.CONF_VAR1, config.CONF_VAR2)
np.ix_([0, 1], [0, 1])
cursor = self.connection.cursor()
self.updateGUI()
now = np.datetime64(datetime.datetime.now())
df = df[cols_of_interest]
DictInsensitive(csv.DictReader.next(self))
Unpickler(file).load()
self.log.append(data)
data[0, 0]
[0, 1, 1, 2, 4]
fp.write(part.get_payload(decode=True))
foo(*pair)
sys.getsizeof(a)
__init__.py
self.submitButton.grid()
itertools.zip_longest(fillvalue=fillvalue, *args)
print(df)
mydict = {k: v for k, v in key_value}
print(timer.timeit())
reader = csv.DictReader(f)
print(np.array_str(x, precision=2, suppress_small=True))
gobject.threads_init()
host.set_ylim(0, 2)
print(tostring(e, encoding=str))
print(soup.html.contents[0])
p = Process(target=do_work, args=(work, results))
line = self.buf.readline()
func(*args)
entry_list = (entry.title.text for entry in feed.entry)
idx = np.where((A > 2) & (A < 8))
ws.column_dimensions = {}
conn.perform()
p.setopt(pycurl.WRITEFUNCTION, devnull.write)
process = BlackScholesMertonProcess(S, q, r, sigma)
self.socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
self.send_response(200)
dist = min(dists)
data = file.readlines()
print(sum(muls))
s = socket(AF_PACKET, SOCK_RAW)
[type(i)() for i in lst]
L = sorted(list(d.items()), key=lambda k_v: k_v[1][1])
dbapi_con.commit()
x = tup[0]
fig, ax = plt.subplots()
writer = csv.writer(f)
plt.colorbar()
opener.open(a_url)
self.timer = QTimer(self)
list(bucket.list_versions())
l2 = [1, 4, 5]
f = open(f)
fig, ax = plt.subplots()
plt.plot(list(range(10)))
HttpResponseRedirect(reverse(contact_details, args=(new_contact.pk,)))
pickle.dump(network, p_output)
urllib.request.urlretrieve(each, filename)
m = Model1.objects.filter(desadder=1)
foo.__doc__
self.runner = QProcess(self)
config_path = get_xdg_config_home()
nosetests()
script_dir = os.path.dirname(__file__)
plt.show()
do_someting()
df[(df.one == 1) | (df.two == 7)]
lowest_dirs.append(root)
socket.send(me, zmq.SNDMORE)
self.connect()
NULL
1, 0, 2
obj.main()
s.indices(len(t))
self.outstream.write(self.theB)
list(range(ifnone(item.start, 0), item.stop, ifnone(item.step, 1)))
yourbutton.pack()
math.pi.as_integer_ratio()
module_b.py
phonenumbers.format_number(parsed_number, phonenumbers.PhoneNumber())
dish.id = restaurant_dish.dish_id
B[i] = elem
np.median([0, 0, 2, 6, 5])
print(urlobj.readlines())
ip = IPython.get_ipython()
print(probs.sum())
0.47685844, 0.44894925, 0.50727844, 0.45076198, 0.44977095, 0.41455029
dom = ET.parse(xml_filename)
x = arange(0, 2 * pi, 0.01)
primes.append(i)
m[1, 2]
[[1.0][1.0][1.0][1.0][1.0][1.0][1.0][1.0][1.0][1.0]]
b = np.array([1, 4, 5])
z = x.add(y)
pool = Pool(processes=4)
App.get_running_app().stop()
outputStream.close()
lambdas_list.append(build_lambda(obj))
ax.plot(theta, r)
df
tags = django.forms.MultipleChoiceField(choices=known_tags, required=True)
f.close()
p.start()
myFile.close()
setattr(self, key, FakeSudsNode(value))
path = os.path.join(path, word)
app = QtGui.QApplication(sys.argv)
result[i].append(next(iterator))
fig.multi_line(x_err_x, x_err_y, color=color, **error_kwargs)
print(parser.parse_args())
self.cookie.load(string_cookie)
MyDiccoSorted = sorted(list(MyDicco.items()), key=myKey)
print((foo, bar))
stext.focus_set()
deletedict_del[k]
rows.append(data[field])
thefile.seek(0, 0)
toYearFraction(dt.today())
str(BeautifulSoup(html[:length]))
np.where(abs(arr_f - a) < t)[0]
fig = plt.figure()
print(a.__code__.co_firstlineno)
sys.stdout.write(line[1:])
cb.formatter.set_powerlimits((0, 0))
genn(igap, igap - 1)
ret = [row[0] for row in ret]
sizer.Add(self.fileTextCtrl, 1, wx.EXPAND | wx.ALL, 5)
self.losses = [1, 1]
obj = db.get(obj_key)
groups.apply(lambda x: count_consec_dates(x, start_date))
any(isinstance(e, int) and e > 0 for e in [0, 0, 0])
r = redis.StrictRedis()
root.lift()
print(2 * p)
y.append(dict(list(i.items()) + list(j.items())))
outlist.extend((i, other[0]) for i in ids - known)
ax.xaxis.set_visible(False)
f = urllib.request.urlopen(url)
profile = webdriver.FirefoxProfile()
print(i, j, k, v)
ax.set_xlim(date_min, date_max)
res = [np.array([f1(1, 5), f2(2, 6)])]
label.setPixmap(p)
signal.signal(signal.SIGALRM, signal.SIG_IGN)
next(f)
can.place(x=200, y=200, anchor=NW)
reset_index()
re.split(regexPattern, string, maxsplit)
key, value = map(int, line.split())
id = Column(Integer, primary_key=True)
tree.add(8)
sys.exit(app.exec_())
size = models.IntegerField(blank=True, null=True)
seed(42)
output = mp.Queue()
data.append(random.random())
arr[np.ix_(rows, cols)]
A = matrix(A)
minimal(s, len)
self.settimeout(10)
g.apply(lambda x: g.loc[~x.isin(df1[x.name]), x.name])
print((x.itemsize, x.nbytes))
predicted = classifier.predict(X_test)
m.EM(data, 40, 0.1)
p1.stdin.close()
print(groups.mean())
architecture / architecture
a = 1 / (2 * std1 ** 2) - 1 / (2 * std2 ** 2)
X = pd.concat([X.iloc[-shift:], X.iloc[:-shift]])
np.set_printoptions(precision=2)
csv.writer(output).writerow(x)
h = np.exp(-(x * x + y * y) / (2.0 * sigma * sigma))
print(df)
func = getattr(self, func_name, func_not_found)
venues.sort(key=getRanking, reverse=True)
False
list(range(first_number, last_number + 1, step))
signal.alarm(5)
strcat(greeting, excla)
0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0
plt.ylim((0, 10))
QWidget.__init__(self)
os.open(os.devnull, os.O_RDWR)
df.High.cummax()
print(np.argmax(a))
self.response
a = [True, True, True, True]
id = Column(Integer, primary_key=True)
my_date = date.today() - timedelta(days=days_to_substract)
index.indices(self.size)[:2]
print([[k, c_sum[k]] for k, v in c_len.items() if v > 1])
classifier.fit(X_train, Y)
buffer.close()
_harden_stdout()
[_f for _f in map(func, collection) if _f]
cleaned_data.update(form.cleaned_data)
fig.set_size_inches(18.5, 10.5)
start_date = datetime.datetime(year=2010, month=1, day=4)
tornado.web.Application.__init__(self, handlers)
a.all_coeffs()
C[1::2, :] = B
l._legmarker.set_ydata(l._legmarker.get_ydata()[1:2])
top5 = itertools.islice(array, 5)
df2
names = pd.append(names, frame, ignore_index=True)
words = list(text.split())
counter = np.sum(id_arr.cumsum())
r[ind1].append(v)
K = [1, 10, 2, 4, 5, 5, 6, 2]
fn = os.path.join(path, name)
plt.xlim(0, complete_longest)
output = fp.getvalue()
root_logger.addHandler(root_log_handler)
out = json.dumps(error_dict)
b = a.reshape((5, 2))
app.login_manager.unauthorized()
foo = urllib.request.urlopen(url, data)
os.remove(fname)
{word: list(neighbours(word)) for word in words}
fig = plt.figure()
l.append(o)
X = data[:, 1:]
types.MethodType(func, obj, type)
my_ints[i] = a[i]
np.repeat(x, arrivals)
[4, 5, 6]
inspect.getargspec(foo)
newZip.writestr(attr, os.readlink(filePath))
sess.run(max_norm_ops)
a = [1, 1, 2, 4, 4]
(db.table.field1 == x) & (db.table.field2 == y)
plt.ion()
process(line)
ukol1.SummaryFormula()
c.setopt(pycurl.WRITEFUNCTION, b.write)
C.append(b_item)
imputed_array
time.sleep(10)
deletedf[df.columns[0]]
y, x = np.ogrid[-a:n - a, -b:n - b]
pd.DatetimeIndex(df.date) + pd.DateOffset(1)
response
print(chessgame.get_moves())
print(dict(zip(headers, values)))
obj.username == request.user.username
test = [([0.0] * 10) for _ in range(10)]
myPlot.set_ylim(1, 5)
print(mappings)
any(map(partial(contains_nested, elmnt=elmnt), some_iterable))
np.arange(N).reshape(shp).T.ravel()
self.val = 1
print(user.message)
self.response.out.write(jsonpickle.decode(encoded).__class__)
logging.getLogger().setLevel(logging.DEBUG)
df = pd.DataFrame(X, columns=vect.get_feature_names())
shared_settings.py
Py_XDECREF(instance)
X, Y = np.meshgrid(x, y)
L = [1, 2, 1, 1, 1, 1, 1, 1]
s[:match.start()]
self.edit = QtGui.QTextEdit()
m.update(f.__name__)
time.sleep(1)
print(np.dot(x, y).shape)
self._chips = 10
file.close()
list(NestedDictValues(a))
x, y = map(int, matchobj.groups())
parser = argparse.ArgumentParser()
fig = plt.figure()
ptr[0] = color[0]
partials[-1].append(element)
self.__dict__[key]
setattr(Test, name, mark)
f_new.write(add_text)
self.d[num] = 1
list(zip(x, d))
gen = (x for x in xyz if x not in a)
i += 1
locals()
print(base.__name__)
fig.colorbar(surf, shrink=0.5, aspect=5)
getattr(self._ref1, name)
print(sys.getsizeof(mydict_as_string))
os.chdir(curdir)
sleep(0.01)
df.set_index(df.select_dtypes(include=[np.datetime64]).columns.tolist())
self.i = i
raise StopIteration
r = requests.post(login_url, cookies=jar, data=acc_pwd)
partial(evalsymbexp, symbexp=symbexp)
stdout, stderr = p.communicate()
signal.signal(SIGTERM, SIG_DFL)
mapper(ActualTableObject, table_object)
self.assertTrue(row[1][0] == counts[index_row][1])
self.serv.close()
foo, bar = zip(*sorted(zip(foo, bar)))
print(repr(pBuf.value))
wrap_process(i)
form = br.form
NULL
root.text_content()
Foo.instance_count += 1
result = [o for o in list1 if o in diff]
platform.uname()[4]
browser = webdriver.Firefox()
readline.set_startup_hook()
lib.stringfree(p)
self.cbar.draw_all()
int(aString)
o.close()
child.expect(pexpect.EOF)
f()
file.close()
pythoncom27.dll
pool = mp.Pool(mp.cpu_count() + 2)
self.Destroy()
f.write(urlopen(tempurl).read())
s = f.read()
sqrt(x ** 2 + y ** 2)
db.create_all()
print(text)
plt.figure()
x, y = np.linspace(x0, x1, length), np.linspace(y0, y1, length)
out = x.reshape(zt, -1)[idx.ravel(), np.arange(yt * xt)].reshape(-1, xt)
width, height = image.size()
print(is_true(y) or is_false(y))
prop1 = db.string
t2.test()
tree = ElementTree.parse(StringIO(string))
stat.S_ISREG(os.fstat(sys.stdout.fileno()).st_mode)
os.getuid() == 0
sp.communicate()
p.wait()
[6, 5, 4, 5, 6, 7, 6, 5],
result.append(foo(x))
user = models.ForeignKey(User)
os.close(in_fd)
msvcrt.setmode(sys.stdin.fileno(), os.O_BINARY)
row = []
d = Image.objects.filter(**kwargs)
fig = plt.figure()
credentials = session.get_credentials()
list1, list2
br.set_cookiejar(cj)
mylist.insert(0, last_el)
root = tk.Tk()
print(settings.INSTALLED_APPS)
aClk.start(), numpy.power(c, 2), aClk.stop()
list(d.items())[0]
user = User.objects.create(**validated_data)
m.search(line)
re.sub(to_be_replaced, lambda x: random.choice(items), string)
myList.append(name)
parseXMLFromLink()
bool(set(a) & set(b))
counts[n] += 1
setattr(self, k, v)
outputfile.writelines(data_parser(line, reps))
sys.exit(app.exec_())
p = Point(x, y)
v = mahotas.convolve(r - w, pattern)
self.value = value
map(lambda x: x * 2, args)
contents = f.read()
db = SQLAlchemy()
widget.show()
Ainv[i] = np.linalg.solve(A[i], identity)
plot([40, 50, 60])
df = DataFrame(np.random.randn(10, 2))
fig = plt.figure()
tm += datetime.timedelta(minutes=5)
data = np.random.random((height, width, numframes))
a.insert(lo, x)
DD = datetime.timedelta(days=90)
gevent.sleep(0.5)
[x for x in self]
string = remove_last_line_from_string(string)
xl.sheet_names
soup.html.findAll(text=True, recursive=False)
succs[u].append(v)
unmatched.remove(element)
doc = etree.ElementTree(root)
self.sslobj = ssl.wrap_socket(self.sock, self.keyfile, self.certfile)
L.insert(index, object)
ax.axis([min(x) - 1.0, max(x) + 1.0, min(y) - 1.0, max(y) + 1.0])
jpgs.sort()
ordered = [e for e in ordered if e in unord]
time.strftime(locale.nl_langinfo(locale.D_T_FMT), time.localtime())
html_source = browser.page_source
args.append(parser.parse_expression())
min(max(bottom, num), top)
conn.close()
archive.close()
self.assertGreater(value, 0)
n == n[::-1]
logger.addHandler(logging.StreamHandler(sys.stdout))
f.seek(p)
s.commit()
fig = plt.figure()
writer.writerow(rowinprot)
size = screen.GetSize()
sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
wx.Icon(sys.argv[0], wx.BITMAP_TYPE_ICO)
temp_dict[values[1]] = 1
base = os.path.splitext(thisFile)[0]
root.mainloop()
print(df2)
df.ix[0] = df.ix[2]
X = np.array(X)
update_list(a)
test_suite.addTest(userservice_test.suite())
surf2.set_colorkey(TRANSPARENT)
requests.post(url, data, headers=headers)
seen = set()
g = tf.get_default_graph()
isinstance(N, int)
self.crawler.crawl(self.spider)
True
print(yaml.load(f))
l.__code__.co_argcount
joystick.init()
fig = plt.figure()
start_time = time.time()
fsb_frame.Show()
driver.get(web_address_desired)
str(s)
sentence_dict[word].append(prev)
reg = line.split()[2]
isinstance(X, type)
p.start()
a = [0, 0, 15, 17, 16, 17, 16, 12, 18, 18]
driver = webdriver.PhantomJS(service_args=service_args)
a = zeros((6, 8))
Session.add(target)
raise Exception()
L.append(a)
len(list(iterable)), -L.index(item)
Base.metadata.create_all(source_engine)
s.close()
data = json.loads(data)
coords = np.vstack([item.ravel() for item in [xi, yi, zi]])
groups[word[:-1]].append(word)
(m + np.random.randn() * s for _ in iter(int, 1))
ans = x / y
m = sock.recvfrom(1024)
queue.append(multiprocessing.Queue())
self.obtainingparams(df, tau_1, tau_2, residuals)
wb = xlwt.Workbook()
ax.xaxis.set_major_locator(copy.copy(Locator))
cur.executemany(insert_query, data)
a = 1
r[:6, :6]
sorted_B = numpy.sort(B)
a = np.arange(10)
print(grades.most_common())
curl.perform()
self.button.pack()
ax = fig.add_subplot(111)
process.crawl(EPGD_spider)
plot_res(fig)
f.__call__()
curdict[last_item] += 1
p.wait()
y = np.arange(10)
b = [2, 4, 2]
driver.get(url)
M = M[M.getnnz(1) > 0][:, (M.getnnz(0) > 0)]
ax = fig.add_subplot(111)
b.append(a[i])
np.array(U).argsort().argsort()
http_request = AbstractHTTPHandler.do_request_
bad_emails.append(email)
smtp_server.close()
np.nanargmax(b, axis=0)
asyncore.dispatcher.__init__(self, socket)
newNums = (i for i, x in enumerate(nums) if x == 12)
print(s[0])
g.close()
print(array(data).reshape(*length))
data = f.read()
list(os.environ.keys())
df = pd.read_csv(filename, index_col=0)
soup = BeautifulSoup(data)
lis[0]
self._max_workers += 1
f_old.close()
A[1][1] = 0
sys.getdefaultencoding()
d = os.path.getmtime(x)
pd.DataFrame(df.values[ge_start & le_end], df.index[mask], df.columns)
df.mask(mask)
cache.init_app(app)
myFile.myFunction()
suite.addTest(suitefn())
delta - datetime.timedelta(microseconds=delta.microseconds)
df = pd.DataFrame(d)
x = np.random.randn(100, 100, 100)
df.drop(rows_to_drop_indices, inplace=True)
output_df.sort_index(inplace=True)
main()
pandas2ri.ri2py(r[name])
value = blob_reader.read()
parentdir = os.path.dirname(currentdir)
abortable_async_result.abort()
pos = nx.spring_layout(G)
print(x)
self._dictionary[key]
j2 = [x for x in j if x >= 5]
x1[np.where(x1 == input_array.shape[0])] = x0.max()
a = datetime(2011, 11, 24, 0, 0, 0)
sess.run(outputs, feed_dict=feed)
plt.show()
print([x for x in g if x[2] >= 1.5])
print(myconstants.MY_CONSTANT * 2)
sheet = book.sheet_by_index(0)
np.round([6.50000001, 6.5], 0)
driver = webdriver.Firefox(profile)
l.append(5)
b = [4, 5, 6, 7]
fib(1000)
documentation.rst
i[1] * 256 + i[0]
print(textwrap.fill(text, width=40))
ocsp_url.strip()
df.drop(df.columns[-1], axis=1)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
s.send(dst_addr + src_addr + ethertype + payload + checksum)
gc.collect()
[(lambda x: np.square(np.dot(x, -1 * x)))(x) for x in items]
print(df)
Z.append((a, B[i % len(B)]))
self.queue = mp.Queue()
inputs = tf.nn.embedding_lookup(embedding, input_data)
root = Tk()
mux41(0, 1, 1, 0)(a, b)
java.awt.Toolkit.getDefaultToolkit().beep()
arr = numpy.zeros((50, 100, 25))
bk.show(p)
fig, axes = plt.subplots(nrows=2, ncols=2)
print(l)
str(self.val)
raise Error(key)
a.pop(e)
match.group(2) + match.group(4)
some.dothis()
render_response()
app = Flask(__name__)
main()
s = np.sqrt((dp ** 2).sum(axis=0))
mongo.init_app(app)
fig.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)
print(im.size[0], im.size[1], white, black)
print(unicode_obj)
f = urllib.request.urlopen(url)
n, b, v = j[4:7]
self.f.write(data)
day_list.index(inp)
x, y = mask.nonzero()
df.y[0].shape
item.son = sons
a = [[1, 2], [4, 5, 6], [], [7, 12, 14, 16]]
time = np.linspace(0, 10, 2000)
shutil.rmtree(tempdir)
output = ps.communicate()[0]
ax = plt.subplot(111)
self.hide()
c = [i for i in range(len(A) - n + 1) if (b == A[i:i + n]).all()]
bucket.delete_key(version.name, version_id=version.version_id)
fig = plt.figure()
print(files)
numpy.fromstring(s)
parser.feed(line)
f.seek(0)
repr(0.1)
A = np.random.rand(5, 2)
glist.sort()
df.dot(df.columns)
f.write(copied_file)
plt.show()
i.close()
1 - np.array([[pearsonr(a, b)[0] for a in M] for b in M])
Fraction(0.25)
df
f = plt.figure()
conn.close()
len(s2)
x.append(5)
m.group(1)
app = Flask(__name__)
x.append(contour[0][0])
len([x for x in myList if x in myDict]) > 0
adjustment_writer.write()
MyShell().cmdloop()
args = opt.parse_args()
self.hello()
self.y_list[i] + self.slopes[i] * (x - self.x_list[i])
f.pack_propagate(0)
plt.subplots_adjust(right=0.8)
xc(os.path.join(dirpath, f))
fig, ax = plt.subplots()
headers.append(header)
ser.update(df)
os.chdir(tmpdir)
logger.addHandler(handler)
[(a[-i // 2] if i % 2 else a[i // 2]) for i in range(len(a))]
codeop.compile_command(line)
count += 1
dlg.Show()
np.hstack((first, rest))
b = dict(zip(*reversed(zip(*list(a.items())))))
d[index]()
configParser.read(configFilePath)
any(x in sbigger for x in smaller)
response
max_idx = l.index(max_val)
scons - -pymod
output += 2 * np.sum(integrand(a + h * np.arange(2, num - 1, 2)), axis=1)
print(key, value)
sha5sum
temp.remove(item)
s.setsockopt(socket.SOL_TCP, socket.TCP_KEEPIDLE, 1)
first.replace(month=first.month + 1, day=1) - datetime.timedelta(days=1)
self.z.append(self.a[-1] * weight)
random.shuffle(l)
response = HttpResponse(f.read())
print(pivot[:5])
sys.exit(app.exec_())
sys.getrefcount(x)
data.append(data_item)
functools.partial(self, obj)
sum(_counter(d))
np.random.seed(101)
els[0]
gr2.switch()
self.map(lambda x: x * x)
writer = csv.writer(response)
dd = copy.deepcopy(d)
a.dump()
output = stdout.read()
tf.logging.set_verbosity(tf.logging.ERROR)
df = pd.concat([df] * 10000).reset_index(drop=True)
self.edges = {}
x[np.mod(np.arange(x.size), M) < N]
collections.defaultdict(tree)
result = func(*args, **kwargs)
form
p.terminate()
self.setSizePolicy(QSizePolicy.Preferred, QSizePolicy.Preferred)
t.getroot().text
[x for x in lst if x.isalpha()]
blocks.append(f.read(block_end_byte))
p = subprocess.Popen(cmd, stdout=subprocess.PIPE, shell=True)
print(sys.version)
self.after(1000, self.onUpdate)
conn = db.get_connection()
thread = threading.Thread(target=process)
p1 = ctypes.c_int(1)
arbiter.stop()
a[:], b[:] = zip(*combined)
ast.literal_eval(a)
model.Bar()
mainloop()
my_thread.start()
arr.resize((k, M))
self._writecheck(zinfo)
sys.exit(main(sys.argv))
plt.show()
input.close()
fileMenu = tk.Menu(menubar, tearoff=False)
print(next(x))
result = np.empty((2 * N + 1, 2 * N + 1))
pyglet.app.run()
len(perms)
print(paths[0][0])
result[key] = value
do_stuff_with(slog)
df.stack().nlargest(1)
title = Column(String(200), nullable=False)
burroughs_wheeler.test(100)
g.bar(1)
print(tn.read_all())
setattr(self, n, v())
raise ValueError(modname)
a = np.array(a)
signal.alarm(0)
ax2.set_ylabel(ylabel)
self.splitter.addWidget(self.inspector)
self.sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
match = [x for x in range(len(l) - 1) if l[x] == 165 and l[x + 1] == 90]
plt.plot(list(range(10)))
obj[key]
b = [2, 4, 2]
fig, ax = plt.subplots()
mydict[search_age]
print(save_data.value)
len(spam)
map(lambda x: f(fixed, x), thelist)
help(obj.myfuction)
m = myre.match(s)
[c for c in col_names if all(f not in c for f in filter_array)]
a = np.arange(10)
self.assertEqual(42, self.widget.foo())
result
f.write(value)
x = df[pd.isnull(df[col])].index.astype(float).values
easydiff2[0] = 0
arr.T.shape
data.head()
list(range(diamond - 1, -1, -1))
self.setLayout(self.vbox)
time.sleep(15)
list(pair_iter)
new_lists[list_index].append(i)
painted_map.save(sys.argv[2])
df = pd.read_csv(StringIO(txt), delim_whitespace=True)
json.loads(text)
f.close()
t.start()
a * b
cur = con.cursor()
id = Column(Integer, primary_key=True)
lib.find_vertex(vertices, len(vertices), lower, higher)
plot(img50_order1[(50), :, (1)])
response
DBSession.begin()
sample.sum()
delta.total_seconds()
print(df_concat.mean())
settings.configure()
print(new_list)
parser = argparse.ArgumentParser()
str(output[0])
c.close()
func(s)
cap = cv2.VideoCapture(0)
Base1.bar()
sio.close()
f = urllib.request.urlopen(req)
demandimport.enable()
self.frame = wx.Frame(parent, title=title, size=size)
r = scipy.sqrt(x ** 2 + y ** 2 + z ** 2)
func_results.append(child(*args))
self.assertGreaterThan(len(foo.config.getboolean(str(), str())), 0)
print(myutilities.gen_hex_colour_code())
hello()
sys.stderr = dummyStream()
im = Image.open(sys.argv[1])
root = Tk()
a[:len(idx)] += idx
plot(f(a, b))
df = DataFrame(dict(x=[0, 0, 1, 0, 1], y=[1, 0, 1, 1, 0], z=[0, 0, 1, 0, 1]))
cursor = conn.cursor()
print(hello())
pl.show()
img.seek(n)
cv2.line(img, (x1, y1), (x2, y2), (0, 0, 255), 1)
print((x, y))
stdin, stdout, stderr = channel.exec_command(command)
print(list(next(it) for it in itertools.cycle(iters)))
d[row_key][idx] = col
np.vstack((rlin * first, np.power(rlin, second)))
open(path).readlines() if opath.exists(path) else []
self.__setitem__(key, value[key])
column1.append(column.split(data_separator)[0])
r += 1
page.SetSashGravity(0.5)
result.setdefault(value, []).append(value)
a.get_x(True)
result = []
nosetests - -help
c.showPage()
test()
print(longest_sum([1, 1, 1, 1, 1, 1, 4], [], 6))
a[0][1] = 9
f.seek(-4, 2)
scipy.sparse.csgraph._validation
print(iorf.fup(2.5))
AB = map(sum, zip(A, B))
file.truncate()
login(request, user)
do_quit(args)
main.py
vobj.prettyPrint()
my_dict
self.type.get_declaration().is_anonymous()
np.all(np.all(arr == arr[(0), :], axis=1))
merge(a[key], b[key], path + [str(key)])
self.console.close()
audio.save()
print(cookie.name, cookie.value, cookie.domain)
Example.__subclasses__()
ical_atch.set_payload(ical)
f = requests.get(link)
print(line)
self.driver.get_screenshot_as_file(file_path)
out.append(item)
cPickle.dump(self.__dict__, f, 2)
d.seconds + d.days * 86400
cls._current_instance
next(f)
plt.show()
self.name = name
word = list(word)
bisect.bisect == bisect.bisect_right
self.hello()
[(x + num) for num in y]
bytearray(f.read())
row_count = len(data)
d = np.random.randint(n, size=k)
df.dtypes
len(s) != (s.add(x) or len(s))
print(sys.stdin.fileno())
a1, b1, c1 = (a[i] for i in idxs)
plt.plot(x_val, y_val)
self.cool_dict[attr] = value
print(model._meta.db_table)
print(chr(c))
parser = argparse.ArgumentParser()
Thread.__init__(self)
print(result)
parser = argparse.ArgumentParser()
dy = 0
list(links).sort(key=lambda x: (x[1] - 1) / (x[2] + 2) ^ 1.5)
self.transport.write(msg)
results = p.map(do_work, payloads)
root.withdraw()
resp.read()
scalify([(a + 1) for a in args])
self._running = True
multiprocessing.freeze_support()
df.dtypes
df = df.ix[:, (cols)]
Base.metadata.sorted_tables
print(fmt.format_map(data))
plt.hist(bootstrapped_scores, bins=50)
view_func(request, *args, **kwargs)
widget.show()
profile = graph.get_object(user)
validate(yaml.load(good_instance), yaml.load(schema))
i = df.index.values
x.boxplot()
od[a].append(b)
types.TypeDecorator.__init__(self, length=self.impl.length)
hash((self.x, self.y))
velcro.left(90)
r = [[i for i in d[x]] for x in list(d.keys())]
print(L)
fig, ax = plt.subplots()
platform.machine()
name = models.CharField(max_length=25)
df
k.fit(X[:, (i)])
nbrs.kneighbors(X)
print(i)
channels = session.query(Channel).all()
draw = ImageDraw.Draw(image)
len(cPickle.dumps(a > 10))
np.column_stack(np.unravel_index(idx, lon.shape)).tolist()
Maemo5Spec()
df = pd.concat([df.iloc[:, :4], df.iloc[:, 4:]], keys=(1, 2), axis=1)
self.text.grid(row=0, column=0, sticky=(N, S, E, W))
self.data.append(node.name)
plt.plot(x)
fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(8, 8))
a = np.array([2, 6, 12, 20, 24, 40, 42, 51])
fd.close()
line = p.stdout.readline()
n.activate((2, 2))
fig = plt.figure()
stdout = sys.stdout
fig, ax = plt.subplots(1)
inverted_image = PIL.ImageOps.invert(image)
parser.parse_args(cmdline, namespace=namespace)
plt.scatter(x, y, zorder=2)
axes[0, 1].hexbin(x, y, gridsize=nbins)
bins = np.linspace(math.ceil(min(data)), math.floor(max(data)), 20)
sum(list(takewhile(lambda x: x < 4000000, evenfibs)))
log_file.close()
pygame.camera.list_camera()
self.label.installEventFilter(self)
print(df2.CET.dtype)
[x[:-1] for x in test]
tex.see(tk.END)
lists.append(line.rstrip().split())
sys.exit(1)
print(value)
random.getrandbits(64)
proc.wait()
[v for group in list(result.values()) for v in group]
de.clicked.connect(self.clicked)
merged = merge(string1.lower().split(), string2.lower().split())
process_event(e)
self.__dict__ == other.__dict__
axes = fig.add_subplot(1, 1, 1)
ard.flush()
d[i] += 1
str.__new__(cls, arg)
y = []
panel = wx.Panel(frame, -1)
self.scrollbar.set(*args)
print(pd.concat([df[mask], df[~mask]]))
table.sort(reverse=True, key=Team.getGoalDifference)
mysend(s, str(i))
Thread.__init__(self)
dt = utc_dt.astimezone(tz)
a = np.array(a)
pool.close()
plt.show()
setattr(self, key, True)
print(data.shape)
requests_api(uri, params=params, cookies=cookies, headers=headers)
ax.plot(np.arange(0, i * 4, i))
react(main)
draw = ImageDraw.Draw(im)
soup = BeautifulSoup(response)
a[abs(a) <= 100]
plt.xlim([-l / 2, l / 2])
im_rgb.putpixel((x, y), (b, g, r))
Thread.__init__(self)
book = xlwt.Workbook()
new_list = np.delete(myList, toRemove)
self.form_invalid(form, **kwargs)
line = proc.stdout.readline()
conn, addr = server.accept()
numpy.random.shuffle(all_idxs)
f2()
map(operator.itemgetter(0), L)
df = pd.DataFrame(c)
len(y)
gunicorn_django - c / path / to / gunicorn_settings.py
User.objects.all()
a = np.array([[1, 2], [1, 2]])
year % 4 == 0 and (year % 100 != 0 or year % 400 == 0)
mask = np.ones(A.shape[1], dtype=bool)
width, height = im.size
[programs[k] for k in result_keys]
print(l.data)
ax2.set_ylim(miny + dy, maxy + dy)
np.add.reduceat(a, [0, 4, 7])
do_something()
y = np.sin(x) + np.random.random(100) * 0.2
email.send(to, headers, body)
_install.run(self)
np.sin(x + y)
isinstance(99 ** 10, int)
rows.append((id, sc))
main()
df
locations = numpy.argsort(A)
b = p.map(func, a)
df
cursor = conn.cursor()
self.runner.start(command)
i += 1
soup = BeautifulSoup(xml_string)
sorted(list(range(len(vector))), key=vector.__getitem__)
str_list = [_f for _f in str_list if _f]
[(x - 1) for x in constrained_sum_sample_pos(n, total + n)]
time.sleep(5)
sys.settrace(tracefunc)
max(sqrt(stddev / mode), 1) <= x <= sqrt(stddev / mode) + 1
mask[mask] &= x[mask] < -1000
gui.mainloop()
self.conditions = [helper(c, type, params) for c in self.conditions]
MULT(z, z, z)
df
da.focus_set()
pickle.dump(dictname, f)
s.lstrip()
mymodule.py
true
next(iter(d.items()))
d = d.get(k)
func(*args, **kwargs)
soup = BeautifulSoup.BeautifulSoup(htstring)
words = frozenset(chain(wordList[:1], wordList[2:]))
-W15 - -ignore < catalina.log
ax1.legend(h1 + h2, l1 + l2, loc=2)
parsed = urlparse.urlparse(url)
a = np.arange(10)
f(*args, **kwargs)
start_response(status, response_headers)
G.add_edge(1, 2)
poi.reset_index().plot.scatter(0, 1, ax=axes)
p = Popen(args, stdin=PIPE, stdout=PIPE, stderr=PIPE)
fp.close()
dict.__getitem__(self, closest_key)
browser.select_form(form_name)
main()
result[header.value].append(col.value)
main.py
log_auth_token(user.get_auth_token())
print(i)
layer
self.grammar = self.multilineCommands
f.seek(0)
plt.draw()
seen.add(obj.thing)
iren.TerminateApp()
c[0] is c[1]
l2.grid(row=1, column=0, padx=(10, 100))
d[c] += 1
print(enumerate(words))
fig = plt.figure()
C.shape
mask = np.array([True, False, True])
numpy.frombuffer(bytestream.read(4), dtype=dt)[0]
print(a_set.add(1))
names.add(func.__name__)
print(response.body)
a += b
os.makedirs(dirmk)
next(combs)
text = f.read()
m = numpy.random.random_integers(0, 1000000, (1000, 500))
app = wx.App(False)
result = [w for w in vocab if rx.match(w)]
mydict[mykey]
G.edges()
print([r for r in process_row(row)])
serversocket.bind((socket.gethostname(), port))
df[cols] = df[cols].ffill()
self.canvas.itemconfig(self.idImage, anchor=NW)
plt.show()
s.shutdown(1)
response = self.opener.open(url)
self.bar = bar
plt.hold(True)
type(s)
print(s.recv(256))
self.show_frame_in_display(image_path)
ax2.plot(xvals, xvals, linewidth=7)
Py_Initialize()
timeit[Model.objects.filter(date_created__gte=today)]
f.savez(array)
placemark.save()
df = pd.read_json(sys.stdin)
win.show()
handler.serve_forever()
self.transport.write(msg)
server.sendmail(FROM, TO, message)
response.write(xlsx_data)
iwantthis
frozenset(chain.from_iterable(L))
HttpResponse(str(deserialized))
signal.signal(signal.SIGALRM, handler)
reader = csv.DictReader(f)
foo.whatever()
x.hexdigest()
self.value = 1
tree = defaultdict(lambda : defaultdict(lambda : defaultdict(list)))
self.new_attr = 2
ax.set_xlim(min_x, max_x)
count.most_common()[1]
X_train = np.concatenate((X_train, catVar), axis=1)
self.bell()
word.append(char)
lambda : _addup(n)
print(type(1, 2))
os.rmdir(dirname)
main()
row[:] = [row[i] for i in new_order]
file.seek(pos, os.SEEK_SET)
user.save()
ax = fig.add_subplot(111)
mask = np.random.randint(0, 2, size=Y.shape).astype(np.bool)
soup = BeautifulSoup(urllib.request.urlopen(url).read())
print(newurl)
ax.bar(x, y, width, color=c, label=lb)
-settings.py
result.append(attracted_point(p, attractor, f))
result
console_handler.setLevel(logging.DEBUG)
memoryview(s[0:]) < memoryview(s[1:])
bundle
len(self._list)
fh.setLevel(level)
print([(a + b) for a, b in itertools.product(A, B)])
datetime(tzinfo=utc_offset(x), *args)
values = [f.get() for f in fields]
arr.append(x)
self.members.append(person)
loop.close()
f.close()
Year.append(row[0])
t2.start()
im = Image.open(StringIO(r.content))
items = deque([1, 2])
time.sleep(2)
db.session.add(user)
t1.start()
compressor.close()
a = np.zeros(shape=(5, 5), dtype=float)
panel = tk.Label(root, image=img)
ndarray = np.PyArray_SimpleNewFromData(1, shape, np.NPY_INT, self.data_ptr)
pool = Pool(processes=4)
L.append(i)
n // 1
result._fields
fig = plt.figure()
element_list.append(json.dumps({key: element[key]}))
numpy.core.records.recarray
np.dstack((a1, b1)).transpose(2, 0, 1)
out_list.append([row.lat, row.long])
outGroup.append(n)
views.py
i += 1
y = np.random.randint(0, 10, size=(10, 2))
ax.plot_date(ts.index.to_pydatetime(), ts.data)
i += 1
outcsv.writerows(cursor.fetchall())
print(it[2:12:2])
word_list = [s.translate(remove_punctuation_map) for s in value_list]
cmp(x, y)
pycallgraph.start_trace()
print(row.to_frame().T)
keys = list(d.keys())
self.view.form_valid(self.form)
str_list = list(filter(bool, str_list))
wavwriter.setframerate(fs)
file_name = sys.argv[0]
a.f = types.MethodType(f, a)
all(x == y for x, y in zip(pattern, sequence))
raise exc_info[0](exc_info[1]).with_traceback(exc_info[2])
result = [productcode, amountentered]
used.extend(set(x) for x in combinations(c, 2))
path = sys.argv[0]
outfile.write(infile.read())
print(id(S2))
fig, ax1 = plt.subplots()
sys.setrecursionlimit(10000)
new_dict[key] = recursive_dict_eval(evaled_value)
plt.show()
list1 = list(map(int, list1))
sorted(strings, cmp=strcoll)
queryset = get_books()
curs.execute(create_table_stm)
alexander2().sum()
c = Counter([i for j in trainY for i in j])
pdb.set_trace()
self.SetTopWindow(self.fr)
type(MyClass)
up.save()
app = Flask(__name__)
x = pd.DataFrame(np.random.randn(20, 5))
self.canvas = Canvas(self, -1, self.figure)
print(x.format(42))
len(data) - len(list(filter(is_surrogate, data)))
foo = pointer(temp_foo)
[0, 1, 0, 0, 0],
inverted_dictionary[new_key].append(key)
print(list(reader))
show()
ax.plot(t, s)
pid = os.fork()
print(line)
m = numpy.zeros((N, N))
sublime.set_clipboard(data)
ax.margins(0.1)
self.setGeometry(0, 0, 1024, 768)
print(x)
x += 1
schedule_once(tasks.some_task_b, interval=120)
ax.set_xticks(xticks_minor, minor=True)
self.cond.wait(self.mtx)
boxintprinter(value)
boxstringprinter(value)
boxsequenceprinter(value)
conf.py
s.close()
numpy.argsort(row)[-6:]
nukedir(path)
cPickle.dump(root.config(), f, -1)
result = func(*args, **kwargs)
plt.contourf(data, cmap=cmap, levels=[1, 4, 8])
sorted(tuples, key=lambda x: x[2])
[0.09558515, -1.96982215, -0.58196525],
df
html = str(soup)
test.reshape(-1, 2)[::2]
df.dtypes
imshow(im)
index.exposed = True
self.fn(*args, **kwargs)
a = np.arange(20)
to_product.append([(k, i) for i in process(v)])
book = xlwt.Workbook()
c.save()
print(json.dumps(c, cls=AlchemyEncoder))
self.window = stdscreen.subwin(0, 0)
Depends(report, speed)
x1, x2, y1, y2 = 0, 0, 0, 0
termios.tcsetattr(file.fileno(), termios.TCSADRAIN, old_attrs)
ssh_handler(server, command=mycmd)
globals().update(pubattrs)
print(x[2])
s[end_of_leader:start_of_trailer]
query = query.filter(~table_a.id.in_(subquery))
labels = labels.reshape(c)
item2node[node].add_child(ch)
ws = wb.active
data_with_zeros.apply(divide, args=(data_with_zeros,))
json.dumps([dict1, dict2])
[map(counter.__getitem__, all_features) for counter in counters]
urllib.request.urlopen(*args, **kwargs)
lambda x: x.lower() not in stopwords
result.extend(flat(item))
ax = pyplot.subplot(111)
dumper.represent_dict(list(data.items()))
main()
id = Column(Integer, primary_key=True)
out_2.read()
os.kill(os.getpid(), signal.SIGTERM)
plt.grid()
results = table1.objects.exclude(field1__in=inner_qs)
ax.plot(xi, yi)
worksheet.write(row, col + 1, item)
object.__setattr__(self, attr, value)
urllib.request.install_opener(opener)
cur = con.cursor()
settings.setSupportZoom(True)
heap = [(v, k) for k, v in list(some_dict.items())]
fig.add_subplot(ax)
fp.close()
NotImplemented
findsubset()
t1 + pd.datetools.relativedelta(months=k)
stophttp.start()
m = hashlib.md5()
print(random.sample(d, num))
pylab.subplot(121)
x, y = np.mgrid[:nr, :nc]
df = pd.concat([df for _ in range(100)], axis=1, ignore_index=True)
instance = session.query(model).filter_by(**kwargs).first()
root = tk.Tk()
[apply(op, *items) for items in zip(*elements)]
json.dumps(final)
ax = plt.figure(figsize=(10, 6)).add_subplot(111)
population = [a for n, a in allele_freqs for _ in range(n)]
numpy.frombuffer(bytestream.read(4), dtype=dt)
plt.semilogx(f, phase)
[i for i in mysites if i in list(sites.keys())]
response = urllib.request.urlopen(request)
print(rd[5])
sys.stdout.write(str(result))
this_list.index(sub_list[0]), len(sub_list)
q.bind()
plt.imshow(X_digits[1778].reshape((8, 8)), cmap=plt.cm.gray_r)
app = create_app()
print(result)
numpy.nan is numpy.nan
myapp.run()
pool = mp.Pool()
x = np.array([True, True, False, False])
norm = mpl.colors.Normalize(vmin=valmin, vmax=valmax)
ax.set_yticks(scipy.arange(-1.5, 1.5, 0.25))
L[a:a + span2] = tmp
print(Counter(yourtext.split()))
c = [1, 2]
db.session.add(user_from_factory)
L = np.logspace(1, 2, N)
repeat(partial(bar, 42))
self.doc.build(pdf, canvasmaker=NumberedCanvas)
()
print(url + urllib.parse.urlencode(getVars))
a.lower() == b.lower()
a.append(visdel())
fig = plt.figure()
conn.close()
json_data_rdd.flatMap(f)
Logger.propagate
os.chdir(sys._MEIPASS)
othercube[i, j, k] = some2d
stack.pop()
t = threading.Thread(target=wrapped_f, args=(q,) + args, kwargs=kwargs)
p = argparse.ArgumentParser()
a = np.array([[8.0, 9, 7, 0], [0, 0, 5, 6]])
parsed_response
result
f.read()
plt.show()
os.remove(link_name)
print(numpy.linalg.norm(x, axis=1))
name = models.CharField(max_length=128)
self.cookies.append(cookie)
json.dump(record, f)
L = pd.concat([data[x[0]].eq(x[1]) for x in list(tmp.items())], axis=1)
map(globals().get, fxnOfInterest)
hashlib.sha512(s + d).hexdigest()
k = np.random.randint(4, 16)
X.nonzero()
f.flush()
soup = BeautifulSoup(html)
count_mers(s, k=2)
M[(rownumber), :] *= scalar
a1 = a
user = User.objects.get(email=username)
matrix
print(x)
plt.draw()
sys.modules[pkgname]
a, b = f[:i + 1], f[i + 1:]
sorted(set(li))[-n]
s += timedelta(days=1)
httplib.HTTPConnection.send(self, s)
ax2.bar(x, y)
signal.signal(signal.SIGALRM, self.raise_timeout)
pprint(a)
opener = urllib.request.build_opener(urllib.request.HTTPHandler)
a()
myFunction()
pixmap = QtGui.QPixmap.fromImage(qimg)
descendents_ancestors.add(ancestor)
__import__(module)
Maybe(maybe.calc(lambda x: x ** 2))
np.row_stack((a, b))
django.db.transaction.rollback()
y = np.random.rand(10) * (X.shape[1] - 1)
browser = webdriver.Firefox()
dom0.create()
out.write(line.replace(LASTKNOWN, CURRENT))
b = np.transpose(a)
keys.append(word)
session = smtplib.SMTP(server)
result = func(*args, **kwargs)
im.size
print(vectors.T / norms[:, (newaxis)])
handler2.setLevel(logging.ERROR)
list(a)
self.__dict__[key]
img.putdata(new_list_of_pixels)
plot_point(xp, yp, sym)
self.process.start()
list(words_in_string(word_list, a_string))
data = requests.get(u).json()
start_time = time.time()
feature_names = vectorizer.get_feature_names()
plt.colorbar(sst_contour, cax=cbar_ax)
mock_redis_get.side_effect = get
tmap.setdefault(t, len(tmap))
connection.execute(q)
events.sort()
name = Column(String(50), nullable=False)
np.nonzero(x)
(x for _, x in zip(list(range(n)), generator))
parser = argparse.ArgumentParser()
lines = f.read()
[inner for outer in x for inner in outer]
obj._meta.concrete_model
out, err = cproc.communicate(input)
input.isdigit()
print(t.strftime(fmt))
driver.execute_script(script, *buttons)
college = models.CharField(max_length=40)
pause.until(datetime(2015, 8, 12, 2))
print(i)
zip_file.extract(i, dirname)
u /= math.sqrt((u ** 2).sum())
print(sys.exc_traceback.tb_next.tb_frame.f_locals)
exception_list.extend(traceback.format_tb(sys.exc_info()[2]))
numbers.append(i)
sess.run([train_op, loss, global_step])
options, args = parser.parse_args()
vbox = gtk.HBox()
logging.error(e, exc_info=True)
f.close()
filename = sys.argv[1]
str(eval(self.expression))
print(G.number_of_edges())
print(df.loc[np.sort(idx)])
parser = argparse.ArgumentParser()
print(locale.getlocale())
np.sin(y * x)
[list(range(x)) for a in selection]
channels = f.getnchannels()
pygame.image.save(game.screen, image_path)
db.session.rollback()
sheet = pygame.image.load(file).convert_alpha()
df.A.plot()
11111111111111111111111111110101
funcs.append(partial(lambda x: x, x))
list = [self.queryQ.put(query) for query in queries]
found = next((i for i in mylist if predicate(i)))
round(num / res) * res
root = Tk.__init__(self, *args, **kwargs)
bar()
result = []
print(channel[0])
main()
plot(x[i:i + 2], y[i:i + 2], linewidth=width[i])
res = res.reset_index()
ar.flatten()
name = StringField()
time.sleep(1)
cell = [title1, title2]
plot(data)
df_both.swaplevel(0, 1).sort_index()
z = bar(foo())
ax.add_patch(Polygon(xy))
print(list(common))
asyncio.get_event_loop().run_until_complete(async_getter())
img = MIMEImage(memf.getvalue())
om.grid(sticky=W + E, padx=5, pady=5)
query = query.decode(charset) % conn.escape(args)
f.seek(0, os.SEEK_END)
s[-1] *= -1
self.selection
response
Session = sessionmaker(bind=engine)
fig = plt.figure()
print(pd.concat([dm] * df.shape[1], axis=1, keys=df.columns))
sigma = np.std(array)
circmask * anglemask
name = models.CharField(max_length=100)
Base.__init__(self)
data = list(img.getdata())
self.root.after(1000, self.poll)
fig.canvas.draw()
print({a, b})
Question.objects.filter(test_id=fr).update(test_id=to)
app = QtGui.QApplication([])
set_spyder_echo(True)
self.d[k] = v
count = len(words)
counts = Counter(value[1] for value in mydict.values())
foo()
df
word.lower() in english_words
list(range(5))[6:7]
request.GET.urlencode()
ax.autoscale(False)
conn.status
csvout.writerow((country, year))
udf(_in_last_5_minutes, BooleanType())
data = self.conn.recv(1024)
self.ui.setupUi(self)
len(entries), sum(entries)
sum += int(num_str[i])
writer = csv.writer(csv_file)
print(help(b))
self.data[key] = item
pl.xticks([1, 2], labels)
f.subs({x: 10, y: 20})
self.queue = set()
list = [1, [2, 2, 2], 4]
my_copy = my_dict.copy()
items = list(yourdict.items())
ax = fig.add_subplot(1, 2, 2)
django.get_version()
f_old.close()
h, w = tpl.shape[:2]
confused_array
ax = plt.gca()
print(x)
print([j for i in spamreader for j in i])
log = logging.getLogger(__name__)
obj.get_id
pl.subplots_adjust(wspace=0)
element = driver.find_element_by_css_selector(locator)
app.show()
gen().__name__
flask.g.breadcrumbs.append(BreadCrumb(path, title))
smtp.quit()
Fruit(5)
worksheet.getCellByPosition(x, y).getString()
calculate_something.call_args_list
s[:]
d2 = dict((v, k) for k, v in d.items())
os.remove(filepath)
dt.replace(year=dt.year + 1)
k = arr.shape[0] / n
primes = [i for i in range(R + 1) if sieve[i] == 0]
B.add_nodes_from(inmates_list, bipartite=0)
args = parser.parse_args()
masked.sum(axis=1)
os.system(self.get_command(file, **options))
self.button.grid(row=2, columnspan=2)
npreds[v] += 1
n == 0 or GetSum(n, arr[1:]) or GetSum(n - arr[0], arr[1:])
axes.scatter(cdfx, logcdfy, s=4, linewidths=0)
nhb
func(*args, **kwargs)
fig = plt.figure()
numbers = [float(x.strip()) for x in input_list]
md5.update(data)
c.writerow(row)
deletet[4:]
instance.method(argument)
grpA[mask] = sortedA[:, (-1)]
X = np.array([[1, 1], [2, 1], [2.5, 1]])
sum(min(ac[key], bc[key]) for key in ac)
axm.set_xlim(0.0, 1.0)
map(operator.itemgetter(1), L)
fig = plt.figure()
walk(tree.getChild(i), temp)
close_button.set_relief(gtk.RELIEF_NONE)
decoder.start_utt()
data = np.arange(200).reshape((4, 5, 10))
myDict[newKey].append(value)
f(*args)
result = cv2.matchTemplate(img, template, cv.CV_TM_SQDIFF)
print(df2)
numbers = (int(character) for character in input_string if character.isdigit())
a_test.__name__
self.listWidgetB.currentItemChanged.connect(self.item_clicked)
fib(n)
df1.fillna(-999) == df1.fillna(-999)
one.py
print(row[0])
numpy.random.seed(1)
painter.drawImage(0, 0, self.mQImage)
self.command()
(a != b).sum() / float(a.size)
numpy.atleast_2d(x[x[:, (1)] == 21])
foobar(1)
base * power(base, exponent - 1)
list(filter(list1.__contains__, list2))
web.show()
logger.addHandler(handler)
ax = plt.axes()
app = QtGui.QApplication(sys.argv)
True
win.set_keep_above(True)
-Wl, -rpath, your_path
lines = file.readlines()
options = webdriver.ChromeOptions()
Matrix(M.T * M)
sys.stdout.write(line)
logger = logging.getLogger()
q.all()
self.setLayout(layout)
dict(zip(*([iter(S)] * 2)))
datetime.now().weekday()
app = QtGui.QApplication(sys.argv)
Greeter().greet()
s = re.search(regex, line)
df.index = index
print([list([_f for _f in x if _f]) for x in df.values.tolist()])
app.MainLoop()
value = datetime.timedelta(0, 64800)
f.close()
ax1 = fig.add_axes((0.1, 0.4, 0.8, 0.5))
s = eval(input())
d.foo()
print(cell.value)
print(dict(mergedicts(dict1, dict2)))
AC_PROG_CXX
AC_FUNC_MALLOC
reader = csv.DictReader(csvin)
sys.getsizeof(s)
dir(func)
print(yaml.dump(data))
now = datetime.datetime.now()
backend.py
result[-1].append(t[j + 1])
self.axe.clear()
p1.func == p2.func and p1.args == p2.args and p1.keywords == p2.keywords
print(R.shape)
ax = fig.add_subplot(111)
LETTER, LEGAL, ELEVENSEVENTEEN
button.setMenu(menu)
pickle.dump(lists, f)
id(foo[0])
env = Environment()
print(first_day)
Book.query.with_entities(Book.id)
self.rect.left = p.rect.right
tab.header(list(row.keys()))
self.assertEqual(name, expected_name)
setattr(toclass, attr, cls.__dict__[attr])
print(draft.playernumber)
df == df
x = np.concatenate((x, x))
template = cv2.imread(sys.argv[2])
MULT(z, a, z)
values = [random() for i in range(20)]
df = pd.concat([df] * 10000).reset_index(drop=True)
input = wx.TextCtrl(self, -1, style=wx.TE_MULTILINE)
d = {}
response = connection.read_response()
i = len(A)
inset.set_position([x_fig, y_fig, x2_fig - x_fig, y2_fig - y_fig])
s = socket.socket()
cur = conn.cursor()
zip(*a)
list(itertools.permutations(l, 2))
instance.work.save()
print([p for p in range(101) if aks_test(p)])
fileDirectory()
child.setExpanded(True)
img = Image.open(image)
line.interpolate(0.1, normalized=True)
self._points.append(coordinates)
HttpResponse(output)
img = Image.open(image.file)
sleep(10)
ax1.yaxis.set_major_formatter(yticks)
l = [copy.copy(x) for x in [[0]] * 4]
_my_whole_freaking_module()
{{p.age}}
ssh = paramiko.SSHClient()
EMAIL_USE_TLS = False
print(fooPy())
tar.close()
print(x.max())
admin.site.register(Poll)
d = d[k]
result = urllib.request.urlopen(request)
painter.save()
print(s.recvfrom(65565))
num += 1
tmp = arr.reshape(2, 2, 2, 2).swapaxes(1, 2)
cj = cookielib.CookieJar()
df1.reindex(columns=dummies_frame.columns, fill_value=0)
area([[0, 0, 0], [1, 1, 1]])
self._async_init().__await__()
list(product(x, deepflatten(y, ignore=str)))
np.arange(lllat, urlat, 2.0),
print(k, v)
plt.xticks(list(range(len(labels))), labels)
f.close()
help(map)
r = requests.get(url, stream=True)
left = A[idx - 1]
self.log_file = log_file
powerset_abs_file.close()
inner = types.FunctionType(myFunc.__code__.co_consts[1], globals())
print(date_by_adding_business_days(datetime.date.today(), 10))
myList.append(random.randint(0, 1))
term.start()
df2 = pd.DataFrame(df1, copy=True)
sum(10 ** pos * val for pos, val in enumerate(reversed(test)))
rv_continuous.fit(gamma, x, floc=0, fscale=4)
l[2]
time.sleep(0.1)
now = datetime.now()
np.flatnonzero(np.random.multinomial(1, p, 1))[0]
print(bin(v.value))
print(list([x for x in words if len(x) > avg]))
choices = [(item.pk, item.some_other_method()) for item in some_queryset]
[[2][0][1][0][1][0]]
b = OuterTest()
self.assertEqual(10, result, result)
MyThread(parent=self)
object.__new__(cls, value)
self.func(*args, **kw)
c.x.append(1)
fig = plt.figure()
os.kill(signal.CTRL_C_EVENT, 0)
set(list1).intersection(compSet)
queue.put((False, exc_info()))
os.remove(tempFile)
count += 1
next(key for key, value in d1.items() if value == 55)
output = p2.communicate()[0]
ax.autoscale()
c.start()
t = np.linspace(0, 1, 200)
print(title.firstChild.data)
ax2.set_ylim(0, 1)
self._lock.acquire()
self.assertEqual(len(self.seq), 1)
models.py
existing_category.put()
example().cmdloop()
new_df = df.iloc[only_once.index // len(df.columns)]
list_of_list.append(list(map(float, list_)))
a, b
[4, 5]
B = scipy.sparse.diags([A[:, (0)], A[:, (1)]], [0, 1], [4, 5])
BaseTest.__init__(self, *args, **kwargs)
print(line)
plt.show(block=False)
os.system(filename)
self.b = a
tmp = np.random.rand(np.random.randint(1, 100))
print(q.get())
ax2 = ax1.twinx()
print(f.read())
cr.set_source_rgb(0, 0, 0)
self.btn.pack()
parser = etree.XMLParser(ns_clean=True, recover=True)
Transform.__init__(self)
next.focus()
p = Process(target=f, args=(child_conn,))
arr[:, (np.newaxis)]
lambda x: x(r)
sock.close()
id = Column(Integer, primary_key=True)
plot_date(timeSeries, data)
self.assertEqual(r.status_code, 200)
result.append(x)
[int(full.split()[-1] in B) for full in A]
listbox.autowidth()
[str(i) for i in range(1995, time.localtime().tm_year + 1)]
G.remove_edge(edge[0], edge[1])
liba.hello()
lines = [screen.display[i].rstrip() for i in range(last + 1)]
zip(a, b)
smallfile.close()
self.bar(arg)
app.Yield(True)
data = f.read().strip()
cache.set(cache_key, result)
print(data)
print(sum(v == dt.hour and dt.weekday() == day for dt in dates))
os.environ[k] = v
file.truncate(10 ** 10)
result = [s for s in all_words if pat.match(s)]
description = models.CharField(max_length=255, blank=True, null=True)
(df == a).all(1).any()
print(arg_str)
name = models.CharField(max_length=100)
lst = [1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0]
setattr(obj, parts[-1], value)
points.intersects(poly.unary_union)
self.resize(600, 400)
a = [4, 5, 0, 0, 6, 7, 0, 1, 0, 5]
l = []
post[0].tags.remove(posttag)
sorted(l, key=os.urandom)
abstracts.append(abstract)
out.close()
d.cards.append(Card(1, 1))
img = img.resize((size[0] * multiplier, size[1] * multiplier), Image.BICUBIC)
_addup(n - 1) + n
fig = plt.figure()
compare_intersect(a, b)
sizer = wx.BoxSizer(wx.VERTICAL)
xml = Node.toxml()
df_one.show()
np.ma.all(np.ma.masked_invalid(a) == np.ma.masked_invalid(b))
list(d.items())[0]
[os.sep.join(p) for p in product(*matching) if _in_trie(path_trie, p)]
deleteself.__dict__[key]
zi = np.ma.masked_equal(zi, 0)
writer = csv.writer(f)
outf.seek(0)
id = Column(Integer, primary_key=True)
root.withdraw()
reader = csv.reader(f, delimiter=d)
t = threading.Thread(target=read_stdout, args=(p.stdout, q))
decorator
self._list.index(value)
acc.extend(inner(x, []))
test_foo.py
self.x = 5
match = re.match(pattern, s, re.UNICODE)
parentNode.removeChild(element)
person_list.append(person)
original_tag.append(new_tag)
table = Table(domain, [map(str, row) for row in df.as_matrix()])
pipe(list(range(4)), map(lambda i: repeat(i, i + 1)), concat, list)
a.f()
zipped_file.writelines(orig_file)
s.sendmail(sender, recipients, my_as_string(msg))
main(sys.argv)
r, nil
result.map(lambda x: row(DenseVector(x))).toDF(schema)
arr[accmask] = np.nan
y[4:6, 1:8] = 1
out = list(df.T.to_dict().values())
new_list = []
list(sympy.primerange(0, 100))
A1s[([0, 1, 2]), ([0, 1, 0]), :, ([0, 1, 1]), :]
fig, ax = plt.subplots()
self.diagram.SetSnapToGrid(True)
b = a.copy()
c.point(x, y, color=sp.pixel(x, y))
main.py
shutil.copyfileobj(req, f)
timestamp = (dt - epoch) / timedelta(seconds=1)
label_image.place(x=0, y=0, width=image1.size[0], height=image1.size[1])
non_transparent.paste(image, (0, 0), image)
a2.append(int(data[1]))
dict.__delitem__(self, key)
print(df)
array([0.91262442, 0.67247516])
fig, ax = plt.subplots()
self._tv.openPersistentEditor(self._tm.index(row, 0))
zip(t[::2], t[1::2])
E.append(np.sqrt(((last - out) ** 2).sum()))
os.read(r_fd, 1)
plot(x[indice], y[indice])
foo = np.array([0.0, 1.5, 1.0])
parsed = ET.fromstring(xml_string)
y = y.reshape(-1, 1)
file.close()
df.loc[4]
widget.setLayout(QVBoxLayout())
(df.foo != df.foo.shift()).cumsum()
self.setCentralWidget(self.cw)
specifics()
eq_y.subs([(x, c), (y(c), y_c), (y(x).diff(x).subs(x, c), dy_c)]),
transaction.commit_unless_managed()
f.close()
df != 0
sympy.__version__
a = np.where(img != 0)
p = widget.grab()
raise NotImplemented
sock.close()
a[a < 0] = -1
print(response.status, response.reason)
signal.alarm(0)
output = PdfFileWriter()
Foo.bar()
a[1]
a = np.array([2, 56, 4, 8, 564])
ax = fig.add_subplot(1, 1, 1)
fig = plt.figure(dpi=100)
form.show()
info = [data[i:i + 2] for i in range(0, len(data), 2)]
print((dirpath, len(todays_files)))
session.add_all([tableRow(row) for row in listOfRows])
self.generator_outputs.append(tf.clip_by_value(x_gen, -1, 1))
x.append(item)
fig, ax = plt.subplots()
quicksort(array)
map(lambda x, y: x * y, l1, l2)
d.setdefault(key(item), []).append(item)
do_stuff(match)
os.chdir(directory)
ax.set_yticklabels(ax.get_yticks())
Z = X ** 2 + Y ** 2 + np.random.rand(*X.shape) * 0.01
thread.start_new_thread(input_thread, (list,))
root.grid_rowconfigure(2, weight=1)
sys.exit(1)
api = tweepy.API(auth)
grokster.grok()
ax.set_position([0.1, 0.1, 0.85, 0.85])
f.read()
sys.stdin.read()
json_string = urllib.request.urlopen(url).read()
pool = multiprocessing.Pool(processes=4)
[x for x in data if key in x and x[key] in allowed]
cmap = matplotlib.cm.jet
result.append((0, 0, values))
self.timer.cancel()
fig, axes = plt.subplots(nrows=1, ncols=numdatasets, figsize=(12, 6))
func(*args, **kwargs)
a[i].append(x)
scipy.math.factorial, numpy.math.factorial, math.factorial
channel = ssh_client.invoke_shell()
G.add_edge(1, 2)
data = file.read()
words.most_common()
br.select_form(nr=currentForm)
print([(x ** 2) for x in lst if x % 2 == 0])
exit(0)
x = __import__(module_name)
p = session.query(Parent).get(pid)
bar(list(range(10)), list(range(10)))
[pingpong]
Column(_f(_to_seq(sc, [col], _to_java_column)))
root.mainloop()
t2 = time.time()
f.close()
proc.kill()
y = x + y
print()
app = QtGui.QApplication(sys.argv)
self._c = c
self.Bind(wx.EVT_SIZE, self.OnSize)
sleep(2)
np.bincount(i, weights=d)
print(np.argmax(spect), np.max(spect))
client = gdata.analytics.client.AnalyticsClient()
pprint(ddiff)
plt.show()
lst = [[0, 1], [0, 4], [1, 0], [1, 4], [4, 0], [4, 1]]
w.wcs.naxis
mc.Property1
localized_time.astimezone(pytz.utc).strftime(fmt)
numpy.float64(numpy.nan) is numpy.float64(numpy.nan)
admin.autodiscover()
sums = a[:-1, :-1] + a[1:, :-1] + a[:-1, 1:] + a[1:, 1:]
B[:, :, (0)] = A
datetime(1582, 10, 15) + timedelta(microseconds=uuid1().time // 10)
print((i, lcm20 % i))
p.terminate()
hex(a)
coords = np.stack(np.meshgrid(x, y, z), axis=-1)
reader = csv.reader(infile)
os.close(fd)
ng.get_name()
foo()
print(df)
plt.ion()
[]
p = multiprocessing.Process(target=start_child, args=(server_program,))
prevprime(n, ith=1)
credentials = storage.get()
datetime.datetime(*structTime[:6])
name = models.CharField(max_length=100)
ax.add_collection(lc)
seen = set()
l.pop(i)
plt.colorbar()
collections.defaultdict(list)
myObject.doStuf()
httpd.serve_forever()
result = []
t = threading.Thread(target=batcher, args=(app.queue,))
getattr(self.child, attr)(*args, **kw)
print(remove_none(data))
s.describe()
print(df)
img.show()
np.random.seed(0)
pairs.append((k, v))
G.nodes()
Intersection(self, other)
float(m.group(1))
cols = [x[0] for x in cursor.description]
os.mkdir(blues_sounds_path)
int(v)
se2lib._current_browser()
os.chdir(cwd)
lst = [a, b, c, d, e, f, g]
args = parser.parse_args()
fig = plt.figure()
q = multiprocessing.Queue()
self._num_expectations += 1
local_dt = utc_dt.replace(tzinfo=pytz.utc).astimezone(local_tz)
min(t, key=lambda e: (e[1], -e[2]))
luckynumbers.append(item)
ax = fig.add_subplot(111)
self.position = len(self.get())
heapq.heappop(pqueue)
data = file_to_check.read()
self.x = math.cos(a) * original_x - math.sin(a) * original_y
count += 1
method()
res[k].append(j)
queue = Queue.Queue()
competitors.save()
self.Bind(wx.EVT_SIZE, self._onSize)
fig = plt.figure()
reader = csv.reader(f)
m = [x for x in dictionary[i] if len(x) == l]
ret.extend(flatten(v))
ssh_client = paramiko.SSHClient()
r = requests.get(url)
name = models.CharField(max_length=50)
server.shutdown()
s = socket(AF_PACKET, SOCK_RAW)
py > matrix[-1][2]
app = Flask(__name__)
lettered.append(subx)
df1.letter.unique()
axs[0].xaxis.set_major_formatter(x_fmt)
mask = ~np.isnan(x)
list(itertools.takewhile(lambda x: x != 412, even_numbers))
df.Date = pd.to_datetime(df.Date)
img.putdata(newData)
dt = datetime.datetime(*parts[:6]) - datetime.timedelta(seconds=parts[-1])
nx.draw(g1)
print(df1)
ispower(2, 1)
n.close()
self.bmp = wx.BitmapFromImage(image)
end = time.time()
pickle.dump(d, filehandler)
{name: input_zip.read(name) for name in input_zip.namelist()}
register = template.Library()
print(line.rstrip())
a, b, c, d
msg = email.message_from_string(response_part[1])
t.append(t[-1] + 1)
print(now_time.strftime(fmt))
p.map(lambda m: merger(*m), mergelist)
obj.save()
activation.prepare()
f.restype = ctypes.POINTER(ctypes.c_int * 10)
print(s)
sleep(1)
x[i], x[j] = x[j], x[i]
binary_search([1, 5, 8, 10], 0)
print((a, b))
print(list(counter.keys()))
ax.plot(t, y1)
exec(mycode)
test = serial.Serial(baudrate=9600, timeout=0, writeTimeout=0)
print(100 * (b - a) / a)
atexit.register(savecounter)
(17.5).hex()
p.map_async(g, [slice(i, i + step) for i in range(stop_f, N, step)])
hex(65)
wb.Close()
pyautogui.click(100, 100)
a = random.randint(0, 20)
list(fields_660.values())
output = [x for x, y, label in L]
self.__dict__.update(profile)
log.addHandler(fh)
writer.writerows(reader)
print(iterator(lambda x: x / 4 + 12, 100, 5))
m.hexdigest()
dict_del
self.right = FibTree(n - 2)
store.close()
local_dt = datetime.fromtimestamp(timestamp)
test.close()
isinstance(v, property)
out.extend(np.where(nonzero)[0][[0, -1]])
main_loop.start()
Session = scoped_session(sessionmaker(bind=engine))
ax.figure.autofmt_xdate()
df.loc[(df[0] == 0).idxmax(), 0] = 100
plt.bar(bins, probs, 1.0 / num_bins)
fig = plt.figure()
test_df
select.select([], [B], [])
mylist2.sort(key=sort_order.index)
plt.subplot(221)
x[k]
print(list(powerreps(X, Y)))
self.holding = item
self._writecheck(zinfo)
signal.signal(signal.SIGALRM, original_handler)
b = np.array([4, 5, 2])
print(x)
print(find_matches(d, item))
c.setopt(pycurl.FOLLOWLOCATION, 1)
_bar.__exit__()
ax.errorbar(theta, r, xerr=0.5, yerr=0.4)
ds.addSample((-1, -1), (0,))
p1.start()
self.send_blob(blob_info)
now = time.time()
stream.stop_stream()
a[0:2] = b
r.dot(y.reshape(1, -1))
plt.plot(f, ps2)
p.start()
sigma = numpy.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0])
ax2.contour(theta_centers, r_centers, H)
opt = argparse.ArgumentParser()
np.where(np.all(np.equal(w, b), 1) == True)[0]
ob.stackoverflow(2)
QNetworkAccessManager.createRequest(self, operation, request, data)
print(repr(f.read()))
window = gtk.Window(gtk.WINDOW_TOPLEVEL)
d[l[0]] = d.get(l[0], {})
y = math.sin(4 * 2 * math.pi * x / POINTS)
seen = set()
image = Image.open(cStringIO.StringIO(image_data))
res.set_value(index, previous_df_no)
atexit.register(removeFile, path)
node.set_next(node.get_data() + sum(int(i) for i in str(node)))
conn.close()
F = np.random.rand(n, n)
my_dict = json.loads(dict_str, object_pairs_hook=dict_clean)
x + 1
c = list(chain(*zip_longest(a, b[::-1])))
libxxx.foo.argtypes = [ctypes.POINTER(ctypes.c_float), ctypes.c_size_t]
date = parser.parse(x)
my_buffer[:] = itertools.repeat(0, len(my_buffer))
tmp()
print(response.content)
print(sess.run(loss, feed_dict={x: input_x, y_: input_y}))
self.left
pa_stream_peek(stream, ctypes.byref(null_ptr), ctypes.c_ulong(length))
self.clients.append(client)
Blob.__init__(self, width, height, color, emphasis, highlight)
t = linspace(0, 2 * np.pi, n, endpoint=False)
print(svg.get_width(), svg.get_height())
proc = subprocess.Popen(cmd, stdout=subprocess.PIPE)
canvas.create_image(image.size[0] // 2, image.size[1] // 2, image=image_tk)
count += 1
list(ordered_dict.keys())[2]
foo = np.random.rand(20000000).cumsum()
print([v for v in map_words(sentence)])
b = list(b)
result = np.zeros(len(colors), dtype=np.int)
text = soup.get_text()
print(self.right.PreOrder())
score = sum(i * w(i) for i in xx & yy) / sum(i * w(i) for i in x)
os._exit(0)
plt.plot(x, f(x))
sum(pow(x1 - x2, 2) for x1, x2 in zip(x1s, x2s))
result.update(request)
current_chunk.append((token, tag))
root.mainloop()
event.Skip()
a.a()
gona[:, (0)]
os.dup2(to_file.fileno(), stdout_fd)
parser = argparse.ArgumentParser()
ns[cls.__name__].mocked_method
list(RNA_dictionary.values())
print(strip_tags(html, invalid_tags))
answer[c].append(b)
self.__class__.x = x
track2.play_forever()
AV[j] = n
listD.append(listB[num])
a = [1, 1, 1, 1, 1]
layout = QVBoxLayout(self)
xticks(list(range(1, 40)), list(range(1, 40)))
keyset.update(d[k])
print(pivotdf.head())
s = m.group(1)
parser = argparse.ArgumentParser()
splitter.findall(s)
l.append(id(arg))
conn, addr = s.accept()
print(foo[(np.newaxis), :])
df = pandas.DataFrame(x, columns=column_labels, index=row_labels)
print(oct_num == 511)
y.close()
process.append(multiprocessing.Process(target=wrapper, args=argtuple))
hanoi(n - 1, aux, start, target)
excel.Worksheets(2).Activate()
zip.save()
list.__setitem__(self, key, value)
iterator(lambda x: x / 4 + 12, 100, 5)
book = open_workbook(file_path)
print(Bar().get_counter())
bins.setdefault(key(value, step), []).append(value)
pid = os.fork()
foo(C(), B())
fcntl.fcntl(fd, fcntl.F_SETFL, fl | os.O_NONBLOCK)
result = [str[sp[0]:sp[1] + 1] for sp in split_points]
time.sleep(2)
plt.hold(True)
[0, 0, 7, 8, 0, 0, 0, 0],
X = numpy.zeros([10, 4])
print(linecache.getline(file, line))
h = hog.compute(im)
print(self.AsyncResult(self.request.id).state)
groups.append(list(map(itemgetter(1), g)))
values = [0, 1, 2]
pyplot.gcf().autofmt_xdate()
q = session.query(col).order_by(col)
zipfile.ZipFile.__init__(self, *args, **kwargs)
list(desired_cols)
data = np.array(data)
fig = plt.figure()
sheet = book.sheet_by_index(0)
event.Skip()
cursor.execute(query)
dirname, filename = os.path.split(os.path.abspath(__file__))
session.add(u2)
ip.release()
word = word.strip()
[[i[o] for ix, i in enumerate(a) if l[ix] > o] for o in range(max(l))]
task.delay(arg1, arg2).get()
seen.add(n)
(seq[pos:pos + size] for pos in range(0, len(seq), size))
self._rooms = {}
module = sys.modules[module_name]
thread.start()
print((key, list(group)))
login_button.click()
b = np.indices(a.shape)
print(video_url)
os.chdir(our_home_dir)
obj.method()
plt.show()
sys.__excepthook__(exc_type, exc_value, exc_tb)
np.argmin(A1[1])
l.append(b)
list(group_660.keys())
1, 1, 0.526015021, 0.581905971
CA
self.initUI()
sys.stdout = old_stdout
flist.append(funcC(i))
stats.print_stats()
main()
particles[i].fitness = fitness
rs = (grequests.get(u, headers=header) for u in urls)
context = RequestContext(request)
st = os.stat(filename)
self._server.handle_request()
makesomenoise()
client.start(container)
print(a)
elem.send_keys(Keys.PAGE_DOWN)
resource.setrlimit(rsrc, (1024, hard))
False
data = dict()
A = np.asarray(A[indices])
print(is_int_value(x_))
myShelve.close()
pd.concat(frames, keys=user_ids)
total = model.fee_total(model)
x.dot(x) + sin(np.linalg.norm(x) * np.pi)
result.extend(flatten(el))
wx.FileDropTarget.__init__(self)
right.put(n[0::2])
print(reg_m(y, x).summary())
position[-1] += 1
socket.inet_aton(address)
d[DateK] = val
ehandle.close()
a.salutation(*arg, **kw)
pktdump.write(pkt)
raise ValueError
result[np.arange(len(x)), inv] = 1
subplot1.plot(x, y)
exit(0)
a0 * alpha ** np.arange(n).reshape(-1, 1)
df
xi = np.linspace(-1, 1, ngrid)
str(self.name) == str(other.name)
node_depth_first_iter(self)
HttpResponseBadRequest()
head[:, (0)] = 16
f_out.close()
ftp.dir(parse)
DF + DF.shift()
df = pd.read_csv(input_file, header=0)
stdout.close()
self.update(request, *args, **kwargs)
pool = multiprocessing.Pool()
result = client.service.addPerson(person)
self.store.close()
data = db.BlobProperty()
arr2.extend(np.split(z, indr, axis=0))
logger = logging.getLogger()
count = ((listScore[:, (0)] == 2) & (listScore[:, (1)] == 0)).sum()
pnts.append((i[1], i[2]))
data = request.body.readline()
print(((n0, n1), (d0, d1)))
df.loc[0] = np.nan
True
K = [1, 2, 2, 4, 5, 5, 6, 10]
queue = Queue.Queue()
type(instance)
csv1.close()
globallock.release()
x = linspace(0, 1, 1000)
print(response.authority)
t.start()
dc.DrawLine(x, y, x + self.gridsize, y)
self.previewImage.setPixmap(pixmap)
print(x_str)
count += 1
G.add_nodes_from(L1)
a.__dict__
ax = fig.add_subplot(111, rasterized=True)
loop.close()
start = DT.datetime(1970, 1, 1),
sum(len(l) for l in self.src)
timeit(stmt2, setup2, number=100)
print(dict_merge(d1, d2))
counts = [(i, year_month_pairs.count(i)) for i in unique]
df = df.astype(int).astype(str)
start()
f.write(fmt.format(*row))
logdet = add.reduce(absd, axis=-1)
root.mainloop()
self.server.serve_forever()
data = file_object.read(chunk_size)
d.show()
plot.show()
urllib.parse.urlencode(params)
wn.lch_similarity(dog, car)
a[i].append(i + j)
b = x.read(1)
pool = mp.Pool()
utc_dt = datetime.utcfromtimestamp(posix_timestamp).replace(tzinfo=pytz.utc)
layer2.append(j)
self.assertEqual(mock_boo_obj.d.call_count, 1)
show()
print(new_filename)
plt.ion()
cur.execute(qry)
ax1 = ax1 = fig.add_subplot(1, 2, 1)
df = pd.DataFrame(values, index=index)
print(row)
sample = np.random.lognormal(mu, sigma, size=1000000)
sock.send(self.postdata)
e.args[0]
count = 0
rows = np.arange(N)
t2 = threading.Thread(target=task2)
G = nx.Graph()
data = np.asarray(df)
print(k, v)
axr.yaxis.tick_right()
fig, ax = plt.subplots()
array = np.random.randint(500, size=(4, 2000))
serializer_class = MyModelSerializer
f = lambda x: np.cos(x) - x
session.close()
df1.reindex(date_range2)
current_dir.append(args[0])
r[~np.all(r == 0, axis=1)]
self.addr = addr
curses.start_color()
port = int(sys.argv[1])
deque(pool.imap_unordered(f, itertools.product(pairs, repeat=16)), 0)
self.x.configure(state=NORMAL)
book = models.ForeignKey(Book)
self.setLayout(layout)
app = Flask(__name__)
Py_DECREF(pname)
zip(range(len(l) - 1, -1, -1), l)
self.index += 1
model = pm.modelcontext(model)
request.finish()
sum(topo[x] * topo[x + 1] for x in range(len(topo) - 1))
text = f.read()
a_test.method_one()
response
p.kill()
process.stdin.close()
fruits = ast.literal_eval(fruits)
datetime.datetime = patched_datetime
print(line)
time.sleep(60)
__import__(mname)
sleep()
plt.hist2d(x, y, bins=(50, 50))
plot_window.control.resize(400, 400)
cursor = connection.cursor()
B = np.zeros_like(A)
data = [[] for col in cols]
figure()
l.append(x)
temp = numpy.zeros(len(x))
app = QtGui.QApplication(sys.argv)
pb = gtk.gdk.Pixbuf(gtk.gdk.COLORSPACE_RGB, False, 8, sz[0], sz[1])
f()
y = np.hsplit(x, temp_array)
a[a == 0] = np.nan
ax1.set_ylim([0, 1])
x = [p[0] for p in points]
f.close()
plt.figure()
[next(it) for it in islice(cycle((iter(a), reversed(a))), len(a))]
next((c, s.count(c)) for c in s if s.count(c) > 1)
next(self.it)
print(x1, x2)
print(repr(x)[1:-1])
unsearched.put(newdir)
sum([True, False, False, True, False])
a = [[0, 1], [0, 4], [1, 0], [1, 4], [4, 0], [4, 1]]
x = [[] for _ in range(n)]
smtpserver.send_message(msg)
d = dict.fromkeys(keys)
handler(request, *args, **kwargs)
print(sess.run(result))
fig = pyplot.figure()
values = [0, 1, 2]
plt.plot(y)
w.write(f, wordpx)
self.add(elem)
fmt.Println(zip(a, b))
result = str(soup)
application_path = os.path.dirname(__file__)
print(mm[:])
self.__message = message
handles, labels = axes.get_legend_handles_labels()
A()
sys.stdin, sys.stderr, sys.stdout = self.saved
list(dct.keys())
app = QtGui.QApplication(sys.argv)
f = cStringIO.StringIO()
widget.show()
self.validate_unique()
raw_img = urllib.request.urlopen(img).read()
fig.text(0.1, 0.1, txt)
file.close()
sys.exit(1)
zip(lst1, lst2)
p = multiprocessing.Pool(processes=10)
df = ds.to_dataframe()
start = time.time()
soup = BeautifulSoup(html)
fn(args[0])
plt.setp(plt.gca(), xticklabels=[])
body = part.get_payload(decode=True)
pylab.show()
platform.platform()
self.window.set_type_hint(gtk.gdk.WINDOW_TYPE_HINT_DOCK)
nsmallest(4, s, key=len)
Book.query
[dict(l) for l in product(*to_product)]
self.collector
yaml.Loader.__init__(self, *args, **kwargs)
print(df.groupby(df.A // 2).A.nlargest(2))
g.set_xticklabels(rotation=45)
print(repr(ba))
print(L)
np.dstack([vec_data_mag, vec_data_angl, vec_data_avg])
fp.close()
func(d, d1, d2)
browser = webdriver.WebDriver(firefox_profile=profile)
lambda x: a * x + b
s.query(Demo).get(1).value
repr(x)
w.female.replace(to_replace=dict(female=1, male=0), inplace=True)
root = ET.fromstring(s)
print(aList)
input_str = input_str.strip().lower()
self.daemon = True
content = models.TextField(blank=True)
print(min(dates[ind], dates[ind - 1], key=lambda x: abs(x - date)))
UnsortableList(OrderedDict.items(self, *args, **kwargs))
[lst[i:j] for i, j in zip(sec, sec[1:])]
x.argmin(axis=0)
fig.colorbar(lines)
raise ValueError(msg)
categories = Category.objects.all()
res.set_value(index, 0)
data = self._file.read()
z = density([x, y])
exec(file.read())
print([arr2[i][-1] for i in range(len(arr2))])
menu = Menu(root)
canvas.create_window(0, 0, anchor=NW, window=frame)
date += datetime.timedelta(1)
p = multiprocessing.Pool()
csv_writer.writerow([str(random.random()) for i in range(cols)])
keys.insert(a)
print(repr(cell_value))
print(x)
print(a)
print(df)
fig.tight_layout(rect=[0, 0, 0.9, 1])
size = np.bincount(label.ravel())
self.fields.pop(field_name)
pformat(obj)
shutil.copyfileobj(r.raw, f)
print(print_path(root_node))
app.logger.setLevel(logging.INFO)
child_process.terminate()
data = np.array(data)
div(numericoperand(1), operand)
[list(i[1]) for i in it.groupby(l, key=key)]
sum(y > el for el in x)
np.array(l) ** np.arange(1, len(l) + 1)
shout.stop()
args = parser.parse_args()
ds.addSample((1, -1), (1,))
print(pat.findall(mystr))
all(nested_equal(x, y) for x, y in zip(a, b))
rect.set_height(h)
help(f_with_good_sig)
a = tuple(a)
counts = collections.Counter(words)
inf.close()
(close.where(starts).ffill() * signals).fillna(0)
cmap = plt.cm.jet
y = np.array([True, False, True, False])
ax.imshow(X, cmap=cm.gray)
c = b.reverse()
datetime.date.fromtimestamp(stamp)
fig = plt.figure()
arg
c = dict([(col, j) for j, col in enumerate(df.columns)])
lst.append(datum)
x = np.linspace(0, 10, 100)
fname.close()
self.mygraph.set_xydata(t, self.ydata)
l.sort()
dict(data=rv)
df.head()
np.random.seed(2)
(np.array(old_set) + np.array(new_set)) / 2
func()
False
[field_value(field.field, item) for item in value]
logger.setLevel(logging.INFO)
plot_window.control.show()
tree.add(str(result[0]))
rect.set_height(h)
self.assertEqual(self.nu.test_marshal(), self.nu.FORMAT % self.nums)
print(html_to_text(n))
opener = urllib.request.build_opener(handler)
print(string)
str(b)
i = random.choice(list(range(len(l))))
msg = MIMEMultipart()
fig, ax = plt.subplots(1, 1)
False
float(x)
plt.show()
page = opener.open(url)
clips.PrintFacts()
os.remove(logfilepipe)
items.append((last_seen_date, headline, link))
date_to_datetime(d)
screen.refresh()
self.func.__repr__()
l.sort()
plt.subplot(121)
time.sleep(4)
indices = defaultdict(lambda : defaultdict(set))
self.children = []
np.sin(x)
resultlist.append(item)
print(so.lower())
collections.defaultdict.__init__(self, list)
d = dict(p1=1, p2=2)
ax.yaxis.set_major_formatter(y_format)
sub_dict = {}
activity.approved = True
random.shuffle(randomRange)
g.__dict__
ax.set_xticks(data2[ndays[1], 0])
print(word[:j] + word[j + 1:])
cursor = connection.cursor()
CV_Assert(img.depth() != sizeof(uchar))
print(s)
counts.most_common(len(counts))
opener = urllib.request.build_opener(NoRedirectHandler())
hash.update(str(time.time()))
t.to_datetime()
doc.Close()
tuple(sum(base_lists, []))
map(poison, L)
_empty(*args, **kwargs)
event.categories.count()
test(a)
value.split(char)[index]
func()
p + geom_histogram(binwidth=1)
mvnorm.pdf(x)
s[np.searchsorted(b, a, sorter=s)]
n = int(input())
df
(self.name, self.location) == (other.name, other.location)
self.stdout.write(output)
queryset = Foo.objects.all()
do_something()
obj.delete()
my_data = np.array([json_string, json_string, json_string])
run_bash(submit_cmd)
df[cols].apply(lambda values: sum([(v ** 2) for v in values]), axis=1)
self.view.resizeColumnsToContents()
print(df.dtypes)
soup = BeautifulSoup(page)
net.addConnection(FullConnection(bias, hidden1))
doctest.testmod()
Y = np.dstack([X] * 4096)
df[k] = pd.eval(v)
b[not_index.reshape(-1, 1), not_index] = a
output = p2.communicate()[0]
p.terminate()
db.commit()
self.next_chunk = self.next_chunk + next(self.it)
random.shuffle(control)
len(parser.parse_known_args(option.split())[1]) != 2
c[firstname] += 1
array[idx]
image = Image.open(sys.argv[1])
new_data = next(tail)
o.many2many.add(ModelA.objects.get(id=1))
syslog.setFormatter(formatter)
(4,) + (7,) * 12
dict((k, to_dict(v)) for k, v in list(d.items()))
signal.signal(signal.SIGALRM, _handle_timeout)
text = f.read()
words = (line.strip() for line in f_in)
print(m.result.group(1))
f(*arg_tuple)
days.setdefault(dt.toordinal(), []).append(dt)
result.append((x[0], x[1], step))
grouped.first()
print(network)
[0, 0, 5, 6, 0, 0, 0, 0],
r = csv.reader(v)
my_func.foo = new_foo
handle.set_visible(True)
print(len(headers))
datetime.datetime.fromtimestamp(2047570047)
[1.0, 0.0, 0.0, 0.0, 0.0, 1.0],
g = file(path_to_bigfile)
d = {e: (0) for e in s}
mpp.start()
app = QtGui.QApplication([])
app = QtGui.QApplication(sys.argv)
original(list(a), list(b))
reader = csv.reader(f)
print([mean(cluster) for cluster in cl.getlevel(1.0)])
z1[np.where(z1 == input_array.shape[2])] = z0.max()
data = pd.DataFrame(raw_data)
z = self.im.get_array()[int(y), int(x)]
set(second_list).difference(dic)
print(os.readlink(__file__))
bigList2.append(bigList2.pop(0))
platform.version()
self.pp.transport.write(data)
self.top.destroy()
gbl[moduleToImport] = importlib.import_module(moduleToImport)
axis.set_minor_locator(mpl.ticker.AutoMinorLocator())
date -= timedelta(days=7)
g(x=1, y=2)
self.cells.append(Cell(self, i))
print(len(tweets))
[1.0, 0.0]
clock = pygame.time.Clock()
print(np.allclose(res1, res2))
x[0] += 1
df = pd.DataFrame()
parser = argparse.ArgumentParser()
remote_file.write(in_string)
a[indices]
new_dict = old_dict.copy()
soup = BeautifulSoup(response.get_data())
arr = np.linspace(0, 50, 100).reshape((10, 10))
seq_type().join(filter(seq_type.isdigit, seq))
print(nums.count(1))
loudness_of_chunks.append(chunk.rms)
results = cursor.fetchone()
line_offset.append(offset)
match.group(1), match.start(1), match.end(1)
self.transport.loseConnection()
plt.show()
Y += np.random.normal(scale=0.1, size=Y.shape)
names.append(codegen.to_source(node))
lines = ax.get_lines() + ax.right_ax.get_lines()
pl.xticks(X, list(d.keys()))
win.setCoords(0.0, 0.0, 10.0, 10.0)
type.__new__(cls, name, bases, dct)
plt.show()
x = np.linspace(0, 2 * np.pi, N)
instance = forms.ModelForm.save(self, False)
addch(ch)
print(min(map(min, Q)))
path.reverse()
root.mainloop()
process(line)
print(student.name)
a / n * (x / n) ** (a - 1) * np.exp(-(x / n) ** a)
phases = numpy.random.uniform(0, 1, 10)
timestamp = int(nanoseconds / 100) + 122192928000000000
df
db_field.formfield(**kwargs)
print(str(correctDate))
fig, ax = plt.subplots(1, 1)
model.sims(replace=True)
s.quit()
fd.write(hash_string)
[job1]
math.acos(0)
df.apply(lambda x: x.set1.union(x.set2), axis=1)
print(str(most_common))
set.union(*list(obj.values()))
numpy.vstack((a, b)).T
z1.close()
(x + pad_by * (max_len - length) for x, length in zip(lst, lengths))
user = query(User).filter_by(id=1).one()
response = urllib.request.urlopen(URL, parameter)
my_field.my_filter = True
X.add_nodes_from(list(pos.keys()))
key_list.append(td.text)
[2, 2, 2]
req.get_remote_host(apache.REMOTE_NOLOOKUP)
result.delete()
data = stream.read()
figure(1)
l = sc.recv(1024)
list1.append(dict1.get(key))
os.path.splitext(fname)[0][8:]
json.loads(a)
d = {}
p.join()
do_something()
df
id = db.Column(db.Integer, primary_key=True)
self.Bind(wx.EVT_BUTTON, self.onButton, btn)
self.value[0](*args, **kwargs)
words = t.split()
print(df[years_month])
Base.metadata.drop_all(engine)
a = x[0]
self.setAttribute(Qt.WA_TranslucentBackground)
User = get_user_model()
Image.fromarray(np.asarray(image)).show()
len(syllables)
a = C()
logout_user()
arbiter.start()
frame.grid_rowconfigure(2, weight=1)
self.items.append(item)
cursor = connect.cursor()
cron2.every_reboot()
y = np.sin(50.0 * 2.0 * np.pi * x) + 0.5 * np.sin(80.0 * 2.0 * np.pi * x)
screen = curses.initscr()
li = [-1, -1, 2, 2, -1, 1, 1, 1, 1, 1, -1, -1]
func.current_date(type_=types.Date, bind=engine1)
i += 1
deletenew_image, image
(self - _EPOCH).total_seconds()
im = Image.open(filename)
title = models.CharField(max_length=50)
sys.exit(0)
cur.executemany(query, values)
sequence, best[-1]
application = django.core.handlers.wsgi.WSGIHandler()
flt = float(random.randint(0, 100))
sftp.close()
trel
keys.insert(b)
lineNum += 1
x = tf.constant([0.2, 0.7, 1.2, 1.7])
self.table.itemClicked.connect(self.handleItemClicked)
[False, False, False, False, False],
Yf[0]
ax.set_aspect(1)
os._exit(255)
fig, ax
srv.serve_forever()
scf_1104442824510(987)
txn.commit()
tool.stderr.close()
str(1)
ndtri(0.95)
driver = webdriver.Firefox(firefox_profile=firefox_profile)
hello()
e = cv2.cvtColor(c, cv2.COLOR_BGR2RGB)
np.intersect1d(av, bv).view(a.dtype).reshape(-1, a.shape[1])
pagehandle = urllib.request.urlopen(theurl)
print(repr(track))
mailserver.starttls()
print(get_selected_text_from_front_window())
chars.extend([digit, symbol])
thirdList.append(listName.index(y))
print(args.cmd)
time.tzset()
1.0 / (1.0 + np.exp(-z))
a[0].shape
array([46]), array([62]), array([61])
cgi.test()
app = QtGui.QApplication(sys.argv)
uuid.uuid1().hex
my_list1 = [i[1] for i in my_list]
x[i], x[j] = x[j], x[i]
results = [output.get() for p in processes]
resp = conn.getresponse()
Chainable(list(self.method(self.data, *args, **kwargs)))
response.read()
time.sleep(1)
root = Tk()
Alias / media / opt / django / site1 / media / statics
a = pd.Series([1, 4, 5, 7, 8], index=index)
print(fib(n))
s.upper()
-cr.fetchall()
plt.show()
editor.setCurrentIndex(int(index.model().data(index)))
y = y1 + (y2 - y1) * t
_.group(1)
print(r.text)
df.ix[0] - df.ix[1]
wx.Frame.__init__(self, *args, **kwargs)
session._new = {}
plt.show()
ax.lines.remove(wr())
f.close()
start = datetime.datetime.now()
print(path)
old = sys.stdout
request = urllib.request.Request(url)
max_y = np.log10(max(y))
process = [do_with_line(line) for line in f]
print(a, b)
funcList.append(lambda m=m: callback(m))
ax.xaxis.set_major_formatter(plt.FixedFormatter(names))
self.csock.setblocking(False)
df
plt.contourf(data, cmap=cmap, levels=[1, 4, 8, 10])
{{file}}
dict(re.findall(pattern, val))
gca().add_patch(rect)
__all__.append(name)
self.constant
mydict[i] += 1
path = os.path.join(settings.MEDIA_ROOT, dir_name)
print(tuple(choice(choices) for _ in range(4)))
Results.objects.all()
json_object = json.loads(json_string)
codeOut.close()
execlist[i][2] = myx
frame.Show()
ax.plot(x[i * 6:(i + 1) * 6], y[i * 6:(i + 1) * 6])
new_queryset
f = cv2.cvtColor(c, cv2.COLOR_RGB2BGR)
self.right.append(v)
result.append([])
b[-1][1] = max(b[-1][1], end)
foo[0][0] is moo
indices = np.argpartition(arr.flatten(), -2)[-2:]
ndimage.map_coordinates(data, [zi, yi, xi])
k = [str(x) for x in list]
cache = [next(it) for i in range(n)]
u.save()
sys.path = sys.path[:]
node0.start()
c = db.cursor()
tuple((m, m) for m in MONTHS)
ax = fig.add_subplot(1, 1, 1)
view.sel().clear()
df.loc[:, :] = stacked.unstack()
print(line)
nx.draw_networkx_labels(G, pos, labels=node_labels)
pylab.draw()
func()
grid.flat[ind] = 100
curs.close()
c.update({k.upper(): v})
print((x + y)(1))
print((id(n), id(n1), id(n2)))
now = datetime.now()
form = cgi.FieldStorage()
locale.setlocale(lang)
chunk = len(data)
Counter(strs)
do_something_else(lines_of_interest)
len(self.crawler.engine.slot.inprogress)
plt.colorbar()
plt.show()
Parent.__new__(cls, value)
x = np.arange(2 * np.pi, step=0.01)
line
do_stuff()
widget = QtGui.QWidget(self)
pyassoc
self.webview.clearHistory()
f(*args, **kwargs) + 1
inner2()
compose(f, f)
freq, bins = numpy.histogram(values, bins)
DEBUG = True
type(s)
x = [[1, 2], 1, 1, [2, 1, [1, 2]]]
x = np.asarray(x)
canvas.grid(row=0, column=0, sticky=N + S + E + W)
ccw(A, C, D) != ccw(B, C, D) and ccw(A, B, C) != ccw(A, B, D)
np.setdiff1d(a, a[mask])
l.sort(key=getvals)
person = models.ForeignKey(User)
print(settings.fileName())
a = np.arange(16).reshape((8, 2))
df2 = pd.concat(yearly_month_stats, axis=1, keys=years)
writer.writerow(row)
filtered = img.copy()
cap.set(cv2.cv.CV_CAP_PROP_POS_FRAMES, pos_frame - 1)
docker.wait(contid)
model.docvecs[0]
methodReference.__self__
gtk.main()
response
signal.alarm(10)
min_kmeans.fit(vectors)
fig, ax = pl.subplots(figsize=(12, 4))
b.select_form(nr=0)
x[0] -= D[n - 1] * np.sqrt((x * x).sum())
conn.setopt(pycurl.WRITEFUNCTION, body)
aMethod.__code__.co_argcount
print((line1, line2))
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
AtoCIm.append(Image.open(image))
log.start()
imshow(threshold, cmap=cm.Greys_r)
getcontext()
print(Rational(1, 2) in i6)
p.communicate(value)
a[:0] = [4]
u[i] = len(item)
now = pytz.utc.localize(datetime.utcnow())
ax.xaxis.set_major_formatter(mtick.FuncFormatter(ticks))
image.show()
sum(b, a)
cert = X509.load_cert(sys.argv[1])
ax2.set_xticks([])
self.put()
name = models.CharField(max_length=50)
plt.draw()
result.extend(list(range(int(x), int(y) + 1)))
sum([(1) for ch in s if ch.isalpha()])
df = df.transpose()
c1.commit()
b = np.tile(a, 1000)
reader = csv.DictReader(fp)
circles = cv2.HoughCircles(gray, cv.CV_HOUGH_GRADIENT, 1, 10)
tornado.ioloop.IOLoop.instance().add_callback(client.watch_queue)
app = QApplication(sys.argv)
os.isatty(fd)
pdb.Pdb.__init__(self, completekey, stdin, stdout, skip)
sys.exit()
x, y = 0, 6
y = random.randrange(box[0][1], box[1][1])
xml_files.sort(key=os.path.getmtime)
self.request.sendall(self.data.upper())
window = gtk.Window(gtk.WINDOW_TOPLEVEL)
main.py
out.release()
globals()[key] = my_shelf[key]
f(*args, **kwargs)
fig.clf()
args = parser.parse_args()
thing.__init__.__func__.__closure__[0].cell_contents
X, Y = np.meshgrid(x, y)
http = httplib2.Http(cache=memcache)
results.append((numbers[0], numbers[1:]))
nelangs.append(nelang)
matcher(l1, l2[1:]) or matcher(l1[1:], l2)
print((ca.key[0], ca.values[0], ca.values[1], ca.title[0], ca.index))
[0.0, 1.0, 0.0, 0.0, 0.0, 1.0],
et.write(sys.stdout, pretty_print=True)
start_ipython()
new_list = map(f, it.takewhile(condition, l))
numpy.core._dotblas.__file__
X.reshape(X.shape[0], -1)[:, (0)].sum()
result.append(prods)
iter(item)
np.in1d(aView, bView)
self.layoutVertical.addWidget(self.label)
f.write(data)
result = {name: result}
max(l)
root.clear()
line = line.strip()
match.groupdict()
SocketServer.TCPServer.allow_reuse_address = True
p = Popen(cmd, shell=True, cwd=newpath)
element = wd.find_element_by_link_text(self.locator)
plt.grid(True)
rect(ctx, (0, 0), (width, height), stroke=False)
cursor.execute(sql, params)
os.dup2(desired_output_file.fileno(), sys.stderr)
df.loc[df.index.is_quarter_end]
LOOKNEXT = False
plt.bar(his[1][1:], his[0])
print(item)
admin.site.register(Report, ReportAdmin)
app = flask.Flask(__name__)
app = QtGui.QApplication(sys.argv)
pic.setGeometry(10, 10, 400, 100)
left.put(n[1::2])
messages = q.get_messages()
tk.Canvas.create_oval(self, *args, **kwargs)
results = api.retweets(firstTweet.id)
print(data.read())
result = list(Blog.objects.values())
self.config(width=width + w)
plt.plot(bins, mlab.normpdf(bins, mu, sigma))
image /= image.max() / 255.0
new.append(new_word.lower())
self.factory.echoers.append(self)
arr = np.empty(find_shape(my_list))
QLabel.__init__(self, parent)
queue.put((-priority, item))
np.dot(np.sum(bidule, axis=1).T, betas)
print(random_with_N_digits(2))
np.degrees(angle)
sec_perf.reindex_axis(secs, 1)
ax = fig.add_subplot(111)
scipy.stats.norm(100, 12)
msg.attach(part)
pruned
apply(operator.itemgetter, tuple(b))(a)
sshcon.set_missing_host_key_policy(paramiko.AutoAddPolicy())
print(data)
1, 0, 0.572864624, 0.725615079
1, 0, 0.578792198, 0.100698871
plt.xticks(rotation=0)
p12.get_ca_certificates()
l = QtGui.QVBoxLayout(self)
func(*cargs)
x[~I]
writer = csv.DictWriter(fout, fieldnames=fields)
print(pandas.__version__)
p.join()
sys.stdout.write(str(squared(x)))
b.__dict__
type.__new__(cls, name, bases, dict(classdict))
get_lerp_factor(2, list(range(8)), 6)
x * arr[:-1] + y * arr[1:]
print(pd.DataFrame(ser).T)
int(offset.total_seconds() / 60 / 60)
values = map(lambda key: d[key], list(d.keys()))
sess.run(init)
q.register(stdout, select.POLLIN)
csv_from_excel(sys.argv[1])
MyFrame().mainloop()
pool.close()
print(headers.getvalue())
self.count += 1
print(df.groupby(df.A // 2).A.nsmallest(2))
sorted(x)[len(x) // 2]
wx.Panel.__init__(self, parent)
serializer(obj)
nat_check(nat)
x = np.arange(20).reshape(2, 10)
wrapper
smtp.quit()
v.set(garbage)
merge(a, b, lambda in_a, in_b: in_a and in_b)
user.save()
d = dict(key_value() for i in range(1000000))
bins = np.linspace(df.a.min(), df.a.max(), 10)
opener = urllib.request.build_opener()
_f_array[:, (b)]
fig, ax = plt.subplots(1, 1)
raise AttributeError
pipe.stdin.write(result_1)
f2.save()
lv.sort()
b = np.append(a, [4])
browser = webdriver.Firefox(firefox_profile=profile, capabilities=capabilities)
print(sequence2)
time.sleep(1)
l.append(id(v))
sys.exit(main(sys.argv))
d.replace(hour=0, minute=0, second=0, microsecond=0)
cursor.close()
map(lambda x: x - 1, args)
x = np.linspace(-1, 1, 500)
client.send(response)
print(G.edges(data=True))
items[0]
globals.default()
c[key] = list(set(a[key]) - set(b.get(key, [])))
A = np.vstack([A, newrow])
M[:, (1)] *= 2
main()
print(list(igroups([])))
words = text.split()
[iter(List)] * 2
data = data.reshape(data.shape[:-1])
reader = csv.reader(f)
self.loop.call_soon_threadsafe(task.cancel)
metadata = MetaData()
offsets = [94.0, 95.0, 96.0, 97.0]
fit.apply(lambda x: d[x.name].inverse_transform(x))
classifier.fit(data[:n_samples / 2], digits.target[:n_samples / 2])
cv.SetCaptureProperty(video1, cv.CV_CAP_PROP_FRAME_HEIGHT, 600)
groups = IT.groupby(zip(*idx), key=operator.itemgetter(0))
dis.dis(lambda : Foo().bar.add(1, 2))
b[the_slice]
a[:-1, 1:]
A.__init__(self, 4)
[[value for i, value in enumerate(l1) if j == l2[i]] for j in set(l2)]
attr(random.randint(1, 100), *args, **kw)
dis.dis(take2)
df = pd.read_csv(StringIO(text), index_col=0)
self.x + other
print(len([item for item in values[:, (0)] if item == 0]))
main()
method(*args, **kwargs)
len(b)
c = stdin.read(1)
y = np.array([5, 20, 4, 18, 19, 18, 7, 4])
a = np.random.rand(20)
mask = np.zeros(img.shape[:2], np.uint8)
self.axes = self.figure.add_subplot(111)
a = np.arange(9)
wp.A.plot()
Response({}, template_name=template.template.name)
print(japanese)
ctx.set_font_size(font_size)
wilma.delete()
reader = csv.reader(f)
psutil.get_pid_list()
featureSelector.fit(X_train_data, Y_train_data)
pool.close()
zook.myfunc()
im = Image.open(image)
defaultdict.__init__(self, *args, **kwargs)
conn.sendall(output)
c = np.max(b, axis=0)
word = line.rstrip()
pak[TCP].remove_payload()
os.setresgid(0, 0, -1)
clf.fit(X[train_idx], y[train_idx])
f.flush()
b = np.random.randint(0, 50, 1000.0)
print(td.get_text())
utc_offset = fromtimestamp(ts) - utcfromtimestamp(ts)
self._values.append(value)
value
input = sc.textFile(inputFile)
self.quit(file)
y = data[:, (1)]
csr.eliminate_zeros()
google - cloud
os.path.dirname(f)
p = sns.kdeplot(data, shade=True)
node.set_data(node.get_next())
print(cython.typeof(a))
print(resargs)
soup = BeautifulSoup(data)
entry2.grid(row=1, column=0)
slice(start, stop, step)
max(get_segstarttime(), get_jobstarttime())
plt.figure(1)
fig = plt.figure()
cmap = mpl.cm.jet
k += 1
et = etree.ElementTree(root)
value = 1
vscrollbar.config(command=canvas.yview)
np.random.shuffle(ar)
p.start()
all_module_names.extend(additional_module_names)
a[2] += [5]
setup(**setup_args)
x = np.arange(100)
cheesiness = models.IntegerField()
sum(log(stats.weibull_min.pdf(x, p[1], 0.0, p[0])))
nonlinsolve([x ** 5 + x ** 2 + 1], [x])
print(foo.myfunc.__doc__)
os.unlink(file_path)
id = Column(Integer, primary_key=True, autoincrement=True)
qapp.exec_()
_curried_func(*(args + moreargs), **dict(kwargs, **morekwargs))
a + b
combo = gtk.combo_box_new_text()
a = A.objects.get(pk=A_pk)
0.6411, sym2, 5, 5, 10, 10
inf.close()
a = np.ones((10, 5))
0.250478029251
os.kill(os.getpid(), signal.SIGUSR1)
now = datetime.datetime.now()
plt.yticks([])
f
tk.Frame.__init__(self, parent)
now_aware = pytz.utc.localize(unaware)
screen = pygame.Surface((width, height), flags, depth)
streak += 1
app.MainLoop()
str(timedelta(seconds=elapsed))
[1, 42] in a.tolist()
result.append(s)
stream.close()
my_array = np.empty((2, 2), dtype=float)
ax = plt.figure().add_subplot(111)
print(merged_dict)
output = np.zeros((N, N))
pyplot.legend()
sys.exit(main(sys.argv))
lists([12, 4, 15, 11])
plt.axis([0, 7.02, 7 / r, -0.5])
parser = etree.HTMLParser()
str = base64.b64encode(imageFile.read())
print(test.somevalue, id(test))
b = copy.deepcopy(a)
print(df)
parent.get_toplevel().child_focus(gtk.DIR_TAB_FORWARD)
math.pow(-i, 4)
print(df.shape)
szr.Add(self.button_1, 0, wx.TOP | wx.BOTTOM | wx.ALIGN_CENTER_HORIZONTAL, 5)
string[:i + 1]
self.assertFieldsEqual(self.nums, self.initFields)
False
p = Process(target=f, args=(lst,))
sock = socks.socksocket(socket.AF_INET, socket.SOCK_STREAM)
self.driver.close()
x.b
raise socket.gaierror
plt.scatter(x, y, alpha=0.1)
mfun
a = np.arange(start, stop + step, step)
self.setPos(pos)
menu.addAction(exit)
session.add(c2)
np.random.shuffle(indices)
doc = Study(**data)
s[4]
import_delorean()
as_strided(b, shape=b.shape, strides=strides)[a.shape[0]:]
fig.subplots_adjust(bottom=0.2)
seen.add((x, y))
coords = np.vstack((xi, yi))
output.append(json.dumps(item))
sig2 = sin(t1 / 2) + np.random.normal(scale=0.1, size=len(t1))
items.append(lambda i=i: dump(i))
d = defaultdict(int)
w.write(f, s)
self.worker.join()
dictionary = {}
ax = fig.add_subplot(iplot)
l1 = [x for x in l1 if x not in l2]
map(a.__getitem__, b)
canvas.pack()
ids.append(map(lambda tup: tup[0], c[0:K]))
[991]
[997]
pool = multiprocessing.Pool(4)
list(chain.from_iterable(new_lis))
print(df)
a[0][0] = 1
app = App()
do_something()
c[1::2] = b
files = glob(sys.argv[1])
unsearched.put(path)
fig = plt.figure()
{{x.y}}
nested_list = map(partial(map, str.upper), nested_list)
data = f.read()
result = [w for w in vocab if len(w) >= 8]
part.get_payload()
False
besseli_vec(0, A)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
print(os.getuid())
print(page_source)
k = plot((0, 1), (1, 1))
self.stopButton.clicked.connect(self.simulRunner.stop)
image = gtk.image_new_from_stock(gtk.STOCK_ABOUT, gtk.ICON_SIZE_DIALOG)
my_list[7:10], my_list[2:4] = my_list[2:4], my_list[7:10]
index = numpy.argmin(nplats)
list_dir()
drives
False
zip_longest(fillvalue=fillvalue, *args)
Wizard.Finish.Click()
myplt.setmydefaults()
x = np.random.randn(5000, 200)
sys.stdout.flush()
df = df.groupby(by=df.columns, axis=1).mean()
func2()
sys.stdout = sys.stderr
cv2.rectangle(im, (x, y), (x + w, y + h), (0, 255, 0), 2)
DIRNAME = os.path.abspath(os.path.dirname(__file__))
df = pd.DataFrame(np.fromstring(arr, dtype=np.uint8).reshape(-1, 8) - 48)
q = session.query(Foo)
main()
b.index[b.argmax()]
G = np.vstack([np.ones_like(x), x, y, z]).T
print(lilfoo.bar)
mask = np.zeros((nrows, ncols), dtype=bool)
bar()
print(local_tz.localize(datetime(2012, 1, 15)))
ax2 = ax1.twinx()
main()
sys.excepthook = excepthook
A = np.random.random((10, 2)) * 100
x.loc[(x.date.idxmax()), :]
process(data.get())
grid(True)
arr[ind]
w.write(list(map(lambda j: i + j, list(lambda j: i in j, listStrings))))
l[0] += 1
gpsgvqsbixtwyakp
self.ssh = paramiko.SSHClient()
d = {k: recur_dictify(g.ix[:, 1:]) for k, g in grouped}
dict_writer = csv.DictWriter(output_file, keys)
help(datetime.datetime.replace)
self.someValue = value
Response(api_result)
x = np.arange(n)
outer.append([e for i, e in g if e != N])
self.Destroy()
Counter(str1)
br.set_handle_refresh(False)
a = numpy.arange(-10, 10)
mask = np.eye(out.shape[0], dtype=bool)
layout = QtGui.QVBoxLayout(self)
toss = np.random.randint(0, 2, 100)
number = int(line)
s = str(i)
sys.getsizeof(a)
A.setdiag(list(range(1, 11)))
do_stuff()
np.random.seed(1)
parsed = urlparse.urlparse(url)
self.matrix.__getitem__(index)
ff = webdriver.Firefox()
output.close()
cal_window.add(cal_vbox)
parser = etree.XMLParser(remove_blank_text=True)
binary_erosion(D, kernel2, border_value=1).astype(int)
soup = BeautifulSoup(open(sys.argv[1]))
self.assertEqual(message, send_message)
learn(Xtest, Xtrain, Ytest, Ytrain, 5)
list(map(cube, list(range(1, 11))))
im2 = Image.new(im.mode, im.size)
L = [x for i in range(n)]
x[:] = [(not y) for y in x]
print(result.group(0))
encodings.idna.ToASCII(label)
n = len(nums)
pattern[i::4] = -1
self.instance.project_set.add(project)
str(lst[0]), []
print(url_string)
ax.add_patch(circle)
name = models.CharField(max_lenght=255)
print(table_row.format(**row))
my_list = sys.argv[1].split()
x = np.arange(10)
a, b, c, d, e, g, h, i, j = (True,) * 9
output.write(aes_engine.encrypt(input.read()))
print(vectorizer.get_feature_names())
print(args.columns)
plt.hist(nd, normed=True, bins=n_bins0, alpha=0.5)
req = urllib.request.Request(uri)
print(line_num)
fn(decoratee, *args)
{key: [subdict[key] for subdict in ds] for key in ds[0]}
sort - Vu
urlpatterns += staticfiles_urlpatterns()
db.session.merge(provider)
iter = [random.randint(0, 1000) for i in range(100)]
path = urllib.parse.unquote(path)
w.writerow([id] + list(rest.values()))
[(list1[i], list1[j - 1]) for i, j in zip(list2, list2[1:])]
cursor = conn.cursor()
print(row[1])
ax.set_frame_on(False)
(df == pd.Series(conditions)).all(axis=1)
path = os.path.join(dest_dir, file_name)
self.frame.Destroy()
df.filter(df.dt_mvmt.isNotNull()).count()
dict(form=crud())
time.sleep(1)
s.setsockopt(socket.IPPROTO_IP, socket.IP_HDRINCL, 1)
sys.exit()
list(dict(list(grouped)).values())
x.sayHello()
cv2.bitwise_and(d1, d2)
print(mymodule.__repr__())
(np.diff(np.sign(my_list)) != 0).sum()
gc.collect()
opener = urllib.request.build_opener(no_proxy)
fig = plt.figure()
[i for i, j in zip_longest(my_list, my_list[1:]) if i != j]
b = [[1, 5], [8, 12], [15, 18], [20, 24]]
app
i = np.array([0, 0, 1, 2, 2])
conn.executemany(query, test.to_records(index=False))
output[item] += 1
plt.gray()
names.append(name)
print(now2.strftime(fmt))
results = pool.map_async(foo, list(range(40))).get()
items.append((new_key, v))
print(get_python_lib())
self.put_async().get_result()
(220921999, 2427),
x = numpy.linalg.solve(a, b)
user = models.ForeignKey(User)
self.assertItemsEqual(v1, v2, msg)
graph = nx.Graph()
self.border.Add(self.sizer, 1, wx.ALL | wx.EXPAND, 5)
self.out_queue.put(path)
RNA_integers.append(RNA_dictionary[i])
f()
win.setCentralWidget(vispyCanvas.native)
print(json.dumps(pairs))
heatmap = ax.pcolor(data, cmap=plt.cm.Blues)
reactor.stop()
o = json.loads(n)
pool = multiprocessing.Pool()
lst = [a, d, b, a, c, e, e, f, g]
print(stdout.readline())
repo = Gittle.init(path)
self.crawler.start()
print(a[mask])
opener = build_opener(HTTPCookieProcessor(cj), HTTPHandler())
confused_array[~mask & (numpy_array != 0)] = 2
scipy.stats.poisson.ppf([0.025, 0.975], 10)
{b.pop(0): b.pop(0) == 0}
threading.Thread.__init__(self)
yi = np.linspace(-1, 1, ngrid)
self.Bind(wx.EVT_KEY_UP, self.KeyDown)
self.server.serve_forever()
print(df)
index = letters.index(letter)
p.show()
type(len(x))
group = map(itemgetter(1), group)
noise = np.random.normal(0, 1, 100)
math.sqrt(x + y)
id = db.Column(db.Integer, primary_key=True)
numpy.nextafter(-0.1, 1)
np.count_nonzero(a[mask])
f.read()
p.apply_async(f, args=(i,), callback=adder)
r = np.linalg.lstsq(np.c_[x, np.ones_like(x)], y)[0]
imshow(grey, cmap=cm.Greys_r)
print(f())
queue.append(new_path)
self.updater.timeout.connect(self.update)
Fun.dynprop
s.shutdown(socket.SHUT_WR)
main()
cache[key]
layout.addWidget(self.button)
[0, 0, 0, 0]
conn.quit()
self.table = QtGui.QTableWidget(rows, columns, self)
print(add_time(datetime(year=2015, month=6, day=19), relativedelta(months=+1)))
df.index[0]
result = dict(cursor.fetchall())
stdin, stdout, stderr = self.client.exec_command(command)
cv2.rectangle(im, (x, y), (x + w, y + h), (0, 0, 255), 2)
vscrollbar.pack(fill=Y, side=RIGHT, expand=FALSE)
print(sum((Counter(dict(x)) for x in input), Counter()))
A = np.cos(a) * np.cos(b) - np.sin(a) * np.sin(b) * np.sin(c - d)
map(operator.add, first, second)
word, s[end + 1:]
__builtin__.raw_input()
66666666, 44444
True
slice_consc(df2, 5)
A.instances.append(self)
data = file.read()
print(root.text_content())
np.lexsort((b, a))
1, 1, 8, 8
file.close()
locations = Location.objects.all()
np.log2([-1, 2, 4])
np.column_stack((which_in_a, where_in_b))
out.value_counts().head()
new_image.image.save(slug_filename, File(handle_upload_url_file(url)))
m[50:56, 50:56] += scipy.ones((6, 6))
output.write(key)
yaml.dump(test2, stream=sys.stdout)
value
self.STDIN_FILENO = sys.stdin.fileno()
print(tag.getArtist())
ax.plot(x_values, data.iloc[i])
self.wfile.write(content)
groups.rds | intersect(groups.development) | first
C = A[len(A) / 2:]
c.play()
self._thread = threading.Thread(target=self.run)
print(etree.tostring(document, xml_declaration=True))
seconds = float(seconds)
[(x, y) for x, y, label in data]
f.close()
h1.setLevel(logging.DEBUG)
k = keyfunc(item)
l
axis.set_visible(False)
main()
title = models.CharField(max_length=100)
print(turnthis)
result.append(el)
ax = plt.gca()
Thread(target=foo())
self.table.setItem(row, column, item)
mask = df.eq(df.iloc[0]).all()
fp = urllib.request.urlopen(request)
dict = {}
result = []
d = defaultdict(list)
result = new_array[0] & new_array[1]
multiprocessing.freeze_support()
help(django.utils.dateformat)
hm.HookKeyboard()
text = text.strip()
output.addPage(page)
True
utc_dt = dt.replace(tzinfo=pytz.utc)
plt.matshow(A, alpha=0.5)
response.read()
poly = GeoSeries(Polygon([(0, 0), (0, 2), (2, 2), (2, 0)]))
timer.cancel()
sleep(0.5)
Traversal.description()
d = {k: list(f.ix[k].index) for k in f.index.levels[0]}
json.JSONEncoder.default(self, obj)
print(tidx + pd.offsets.Day(15))
print(convert_excel_time(0.4006944444444))
Py_Initialize()
y_pred = [0, 0, 0, 0, 1, 1, 0, 2, 2]
ButtonTestApp().run()
dt = datetime.date(2010, 6, 16)
list(closed_range(10, 1, -2))
l_qa.append((k, m.groupdict()[k]))
self.label.setFrameStyle(QtGui.QFrame.Box | QtGui.QFrame.Plain)
np.std(image)
s.set_debuglevel(0)
parentNode.insertBefore(doc.createComment(element.toxml()), element)
root.wm_iconbitmap(tempFile)
time.sleep(0.5)
df.mean(axis=0)
f()
main()
c.add(datetime.datetime.now())
edges.sort(key=lambda tup: tup[0] + tup[1] / 10.0)
np.allclose(a.indptr, b.indptr)
result = list(clean(flatten(lst)))
row[set_col] = val
name = models.CharField()
data = data[:-data[-1]]
print([i.type.func.id for i in raises])
MyUser.tags.all()
data = [json.loads(row) for row in data]
sys.stdout.write(line)
self.Destroy()
y = dict(a=2, b=2)
string = string[:-len(to_strip)]
ax = f.add_axes([0.17, 0.02, 0.72, 0.79])
json_data_rdd.flatMap(processDataLine(arg1, arg2))
df
cursor = db.cursor()
rx.match(w)
np.random.shuffle(b[ndx])
cPickle.dump(mat, f, -1)
result
self.proc.kill()
l_qa.append(m.groupdict()[k])
plt.xlim((0, AUC.shape[1]))
{{body}}
fig.savefig(img)
random.choice(seq)
redemption_date.year
my_plot_2(ax2)
test = Test(1)
np.eye(M.shape[1]) * M[:, (np.newaxis), :]
browser = webdriver.Firefox()
self.q.put((False, -1, msg))
self.handleError(record)
pool = Pool(4)
np.bincount(h, weights=x)
x, y = randint(0, len(grid) - 1), randint(0, len(grid[0]) - 1)
preincrement(it)
ax.set_color_cycle(colors)
list(s)
g = globals()
print(l)
browser.set_cookiejar(cookiejar)
numpy.allclose(c[:-1], d)
deletelist_1[int(i)]
a = ctypes.cdll.LoadLibrary(source)
main()
logging.basicConfig(level=logging.INFO)
x = np.atleast_1d(np.array(x))
self.x
urllib.parse.urljoin(url1, url2)
globals()[module] = importlib.import_module(module)
self.rabbit_connect()
df = pd.concat([prd_df, prc_df], axis=1)
fig = plt.figure()
l2 = [[1], [2]]
t.start()
a[b]
list.insert(2 * i + 1, list[2 * i])
foo()
idx = np.concatenate([[0], 1 + np.diff(g).nonzero()[0]])
seq == list(range(seq[0], seq[0] + len(seq), 1))
self.sock = socket
p.parse_args()
setattr(someobject, foostring, value)
obj.__dict__
[i for i in l if s in i]
platform.python_implementation()
out = subprocess.check_output(args, startupinfo=startupinfo)
dlfile(url)
cursor = conn.cursor()
fig, ax = plt.subplots(nrows=nrow, ncols=ncol)
plt.imshow(img)
df.apply(pd.Series.nunique)
logger.addHandler(log_handler1)
res = [0] * (len(_s) + len(_v) - 1)
object_list.sort(key=lambda x: key_precedence.get(x.key, default))
b.save()
df.drop(df.std()[df.std() < threshold].index.values, axis=1)
self
print(sum(1 for _ in next(groupby(l), [[], []])[1]))
data_frame.to_csv(file_path, index=False)
start_date = self.start_date + add_days
z = hstack2((x, y))
opener = urllib.request.build_opener(proxy_handler)
root = Tk()
a = np.random.random((100, 100, 100))
m.select()
values = set(map(lambda x: x[1], list))
ax.add_patch(r2)
print(cleansed)
json.dumps(*args, **kwargs)
response = urllib.request.urlopen(crawling)
parser = xml.sax.make_parser()
new_list.append(list[i])
pygame.quit()
self.queue.task_done()
intervals.sort(key=lambda x: (x.end, x.end - x.start))
this_array[indices[0]:next_i].fill((before + after) / 2)
same(cont1, cont2, value_same)
layer.draw()
f.read()
pygame.init()
L = []
a = list(range(1, 6))
{{field.field}}
print(NSScreen.mainScreen().frame())
task.delay(arg1, arg2)
ser = pd.Series(np.random.normal(size=1000))
(k for k, _ in self._list)
sys.exit(app.exec_())
xi = np.array([0.0, 0.5, 1.0])
dir()
session.add(w)
array(1)
img = img.quantize(palette=palette_img)
sys.argv.pop()
output_dict[int(key)] = [int(item) for item in value]
(lambda : x).__closure__[0], set_cell
module = loader.find_module(name).load_module(name)
arr = [int(num) for num in str_arr]
print(Foo())
math.exp(result)
bins.append(x1)
x = v[-1:]
self.handler.flush()
logger.addHandler(mh)
norm = np.linalg.norm(v)
print(list(myDict.keys())[i])
ps_process.stdout.close()
deleted[k]
self.button.pack()
a = np.hstack([88, a, 77])
print(words.count(word), word)
np.nan == np.nan
k = arr.shape[0] / 2
all(values == 0)
divider = make_axes_locatable(ax)
-a * (np.exp(-t / c) - np.exp(-t / b)) / (b - c)
a = np.random.random(100)
self.send_error(500)
myNames.append(line.strip())
self.i += 1
x = np.linspace(0, 1, 100)
tweets.append(json.loads(line))
i = np.arange(0, len(pts))
timeout_timer.cancel()
np.where(x > y, x + y, x - y)
ax.add_patch(r1)
y[::REPLACE_EVERY_Nth] = REPLACE_WITH
fig.canvas.draw()
modules.clear()
results = results.exclude(published=False)
o.x = o.x.__iadd__(5)
fig, axs = plt.subplots(1, 2, figsize=(8, 5))
ax.quiver(x, y, z, u, v, w, length=0.1)
tcflush(sys.stdin, TCIOFLUSH)
it = iter(iterable)
diff = np.diff(a, axis=0)
l1.append(l2)
excel.Application.Quit()
out = process.stdout.read(1)
ax1 = fig.add_subplot(5, 4, 1)
plt.hold(False)
res = ((t, nt(*t)) for t in pairs)
xs = dict.fromkeys(list(range(2)), a)
app = QApplication([])
pairs.append([i, list1.index(elem)])
soup = BeautifulSoup(data)
wordbank[word] += 1
somelist[:] = filterfalse(determine, somelist)
arq.close()
rpy2.robjects.numpy2ri.activate()
self.PrepareDC(dc)
A = np.zeros((6, 6))
width = measure.winfo_width()
mainwin.add(notebook)
True
st.seed.widget.clamp_to_bounds = False
self.audio = pyaudio.PyAudio()
print(r.name)
print(parser.parse_args())
numpy.extract(choice, a)
group.append(item)
a.n
root = Tk()
width, height = image.size
writer.writerow(fieldnames)
plt.plot(df[c])
self._driver = WebDriver()
[2, 1, 8, 7, 6, 5, 4]
json_data = json.loads(data)
P.show()
print(response.geturl())
assertSequenceEqual(seq1, seq2)
x = np.random.rand(5, 2)
parser = argparse.ArgumentParser()
out = p.stdout.readline()
quitjupyter
now - then > timedelta(hours=1)
writer = csv.DictWriter(f, fieldnames=headers)
loop.run_until_complete(main())
newList.append(oldList[i])
result = numpy.empty((len(r), r.max()), data.dtype)
d = datetime.date(2011, 7, 2)
window.set_size_request(200, 100)
color_list.sort(key=get_hsv)
ax = plt.gca()
decompressed = zlib.decompress(data)
self
f.seek(offset)
type(name, bases, attrs)
ax1 = fig1.add_subplot(111)
list1[:position] + list2 + list1[position:]
matching.append([subpattern])
self.delete(*a, **kw)
ch = logging.StreamHandler()
self.resize(minimumSizeHint())
print(repr(line))
print(cron4)
plt.subplot2grid((4, 4), [0, 1], 2, 2)
m.group(0)
{parts[0]: pack(parts[1:])}
P.drawOn(canvas, 10, 10)
a = np.arange(1, 4)
h.start()
-hound
opener = urllib.request.build_opener(*handlers)
False
indices = [idx for idx, value in enumerate(a2) if value in wanted]
a, b
d = {k: d2[v] for k, v in list(d1.items())}
colnames = colnames[-1:] + colnames[:-1]
fig, ax = plt.subplots()
b = np.random.randint(n, size=k)
device.close()
response
data[i] = row
data = f.read()
self.inner_sizer.Add(self.tin, 1, wx.LEFT | wx.RIGHT | wx.EXPAND, 50)
layout.addWidget(buttons)
df = pd.DataFrame(np.random.random((5, 5)))
lambda x: x + n
print(repr(e))
mylist = sorted(mylist, key=keyfunc)
print(n)
lowers.append(word) if word.islower() else other.append(word)
cbar_ax.set_axes_locator(get_ax_loc)
x[0].upper() + x[1:]
name = models.CharField(max_length=200)
np.random.seed(0)
int(s, 16)
print(dict(urlparse.parse_qsl(qs)))
print(token.access_token)
s(*args, **kwargs)
self._a = A()
float(x)
plt.show()
url_queue.join()
clf = svm.SVC()
list(self.values())
bg.paste(im, im)
x = [1, 1, 1, 2, 2, 2, 1, 1, 1]
app = Flask(__name__)
(df > 2) & (df < 10)
tornado.web.Application.__init__(self, handlers)
fig.set_size_inches(8, 11)
setup(ext_modules=ext_modules())
canvas.config(width=interior.winfo_reqwidth())
f()
destinition.put_data(data)
max(k for k in d if k < key)
list((Counter(a) - Counter(set(a))).keys())
plt.axis([-2, 2, -1, max(len(set1), len(set2)) + 1])
a = y(aVariable, bVariable)
print(numpy.bincount(B.ravel(), weights=A.ravel()))
print_x()
q.queue.clear()
stringer.esc_statuses[name]
self.timeout = loop_time
tree = {}
counter = Counter(list(d.values()))
__builtins__.list
data.dtype
a[b] = a, b
mv[0], mv[1], mv[2]
G.add_node(child)
data.commit()
parser.feed(data)
a * b
df.T.fillna(s).T
[model]
root = Tk()
test = re.compile(pat(self.__MEMBER_TYPES), re.IGNORECASE)
list((expected - found).elements())
numbers = [random.randint(a, b) for i in range(10)]
HTML(play_beep)
self.name = name
first_name, last_name = get_name()
print(fig.canvas.get_supported_filetypes())
approximate_fraction((1 + math.sqrt(5)) / 2, 1e-05)
deleteordered_dict[i]
result = (count * phyQP + 1) / float(pubKeyExpo)
clf.fit(X_train.values, y_train.values)
hello()
form = SomeForm(request.POST, request.FILES)
plt.plot(np.cumsum(np.random.randn(1000, 1)))
f = plt.figure()
lookup_list.append([lookup[l].index(v) for l, v in zip(labels, msg)])
c = np.equal(a, b)
print(args.options)
time.sleep(2)
len(lst) - 1 - r_idx
ax.scatter(x, y, color=rgb)
self.app(environ, start_response)
s.format(x=1)
self.ax = self.fig.add_subplot(1, 1, 1)
print(item.text)
water_held
sorted(value)
[]
matrix[0][2]
s.count(s[0]) == len(s)
print(event.widget.find_closest(event.x, event.y))
df.dtypes
p = subprocess.Popen(cmd, shell=True, stdout=subprocess.PIPE)
rslt.append((x + dx, y + dy))
hdf5_file.close()
myseries_one.iloc[0]
ga.login()
PLT.show()
[([0] * n) for _ in range(m)]
swin.pack()
list_size_1.append(row)
print(random_date(d1, d2))
sdl2.SDL_SetRenderDrawColor(renderer, 255, 255, 255, alpha)
deactivate
user = oauth.get_current_user(SCOPE)
f.read(128)
reactor.listenUDP(8000, EchoUDP())
node_count = sum(1 for _ in db.getAllNodes().iterator())
main()
self.queue = Queue(1)
print(target_list[~numpy.in1d(list(range(len(target_list))), to_exclude)])
func(self.val)
loggify(Working)
result += sorted(sublist, key=g)
smallfile.write(line)
plt.show()
df
__f
self.listener.close()
df.replace(to_replace=to_replace, value=vals, regex=True)
pageContent.readline()
wb.Close()
minval = min(a)
a + b * 2 > 5
self.root.lift()
newkeywords.update(fkeywords)
deletet[5:]
obj = someClass()
self.__dict__.update(tmp_dict)
dict.__getitem__(self, key)
logger.addHandler(fhan)
ax.scatter(data[:, (0)], data[:, (1)], c=point_values)
path = urlparse.urlparse(url).path
Sets[userID].add(rowID)
newdict[0].append(100)
self.audio_frames.append(data)
print(a == b)
pyplot.gca().add_line(line)
f.seek(0, 2)
print(x, y)
sample = np.random.rand(n, 1)
sm = plt.cm.ScalarMappable(cmap=my_cmap, norm=plt.Normalize(vmin=0, vmax=1))
answer = [item[0] for item in counter_list if item[1] == max_occurrences]
con.rollback()
data[(-1), :]
f = os.open(filename, os.O_RDWR)
win.window.input_shape_combine_mask(bitmap, 0, 0)
os._exit(0)
coordinates = [(c for c in l.split()) for l in f]
self.clicked.connect(self._handle_click)
GST_REGISTRY
some_object
b[:, :, (1)]
img = adobe_to_srgb(img)
server.rcpt(toaddrs[0])
print(evil_vals[0] in dict_with_evil_keys)
parser = argparse.ArgumentParser()
execute()
f.write(page.read())
self.__dict__.update(state)
printTable(curPG.fetchall(), [c.name for c in curPG.description])
reverse[value].append(key)
form = ModelForm(request.POST, request.FILES, instance=obj)
plt.imshow(img, zorder=0, extent=[0.5, 8.0, 1.0, 7.0])
b().mymethod()
unittest.main()
[x for x in lst if x.isalpha()]
decorator
create_dict()
type(BT)
new = np.repeat(old[jump_indices], repeats)
list(set(a).intersection(set(b)))
port = server_sock.getsockname()[1]
_draw_points(i, 0)
self.members = 0
(-4) ** 2
cache[object_to_cache_as_string] = object_to_cache
ax.set_ylim(bottom=0)
(np.arange(n) - dfill(b))[i]
a = A()
somedict = dict.fromkeys(somelist, 1)
classes[name] = type(name, bases, {})
print(output)
tokens = list(tokenize(stream))
f[0](f[1:])
datetime.fromtimestamp(local.timestamp())
args = parser.parse_args()
fft_axes.set_ylim([0, 1000])
surf2.fill(TRANSPARENT)
Row(1.0, Vectors.sparse(4, Seq((0, -1.0), (2, 0.5))))
your_template.render(timesince)
print(args)
print(type(img_str))
a.shape
time.sleep(N)
print([n for n in map(test.giveMyNum, q) if n > 1])
soup = BeautifulSoup(html)
self.data.append(s)
parser.print_help()
screen = pygame.display.get_surface()
matrix = np.zeros((5, 5))
all(c in it for c in x)
kmeans_m.fit(X_hat, max_iter=100, number_of_runs=10)
my_func.foo
a = Test()
ndata[0] = 2
form = MicroForm(request.POST)
newfunc(*args, **kw)
b = dict([next(iter(x.items())) for x in bar])
df = DataFrame(books).T.fillna(0)
p2 = Polygon(ring2.coords)
wr = csv.writer(csvfile, quoting=csv.QUOTE_ALL)
fig = plt.figure()
print([i for i, (a, b) in enumerate(zip(it1, it2), 1) if a != b])
run(reloader=True)
next_message.save()
self.finished.emit()
get(remote_path, fd)
s, img = cam.read()
A = np.array([[2, -1, 0], [-1, 2, -1], [0, -1, 2]])
register_blueprints(app)
mark_safe(template % substitutions)
lines = file.readlines()
print(str(soup))
count = lambda x: collections.Counter(c for c in x.lower() if c.isalpha())
c2.setopt(pycurl.PROXYPORT, 8081)
plt.tight_layout()
ax = plt.gca()
line.set_ydata(sin(x + i / 10.0))
divmod(10.5, 1)
shutil.move(file, destination)
my_list[1]()
pygame.quit()
Map(fold=lambda f, g: g(x), bimap=lambda f, g: Right(g(x)))
x = Obj.objects.create(name=foo)
Thread(target=runCommand, args=(command,)).start()
stdout, stderr = process.communicate()
angle = np.linspace(0, 2 * np.pi, arclen * 2, endpoint=False)
grouped.get_group(False)
os.getpid()
req = QNetworkRequest(QUrl(url))
fmap
self.hbox.addWidget(self.label)
debug(str(s))
mod = sys.modules[name]
p = bokeh.plotting.figure(x_range=(0, 4), y_range=(0, 4), plot_height=200)
args = parser.parse_args()
s == c_string
im = sess.run(img_tf)
print(generate_list(1000))
print(list(M.values()))
show(p)
df = pd.DataFrame(new_data)
gtk.main_quit()
fh.close()
d[parts[0]] = d.get(parts[0], []) + [parts[1]]
code = models.CharField(max_length=255)
np.polynomial.polynomial.polyfit(x, y, 4)
fig = plt.figure()
print(neighbors(A, 0, 0))
decorator
print(parsed.getroot())
sys.stdout.write(msg.ljust(minwidth))
pickle.dump(member, f, pickle.HIGHEST_PROTOCOL)
x.append([x] * 5)
plt.show()
tcpCliSock.send(outputdata[i])
df[df[cols] < 0] = np.nan
issubclass(QuizForm, forms.Form)
a_thread.start()
x = np.arange(2)
my_dict = defaultdict(dict)
f()
print(row0)
self.a = a
f.close()
writer.writerows(data)
rght += 1
root = Tk()
self.xlBook.Close()
myList
x = x[:, (np.newaxis)]
np.less_equal(abs(x - y), atol + rtol * abs(y))
s2 = zlib.decompress(s1)
p2.stdin.close()
worksheet.write_string(1, 0, name_entry)
wb.save(response)
array_foo(a)
fig, ax = plt.subplots()
self.append(PoiData(lat, lon))
obj = MyClass()
data = cur.fetchall()
fullname = os.path.join(path, filename)
connection.engine.execute(myClass.__table__.insert(), l)
x = np.arange(10)
parent_parser = argparse.ArgumentParser(add_help=False)
MyThread(self.on_thread_finished).start()
output_header.append(input_header[column_index])
f.write(text2save)
self.central.deleteLater()
os.close(out_fd)
prev_weekday(date(2012, 8, 20))
popt, pcov = optimize.curve_fit(func, x, y, sigma=sigma, maxfev=10000)
[v for _, v in sorted(zipped, key=key)]
crsr.execute(sql)
key[index].reshape(a.shape)
self.stream.write(msg)
ax.get_yaxis().set_visible(False)
print(lucky(50))
f = urllib.request.urlopen(req)
walkDict(myDict, filterFor)
B.date.apply(lambda x: in_range(x, A.start, A.finish))
root = tree[0]
loop.run_until_complete(main())
object_id = models.PositiveIntegerField()
instance.work.save()
plot_implicit(goursat_tangle)
b.append(4)
client = Client(host, port)
e + hyperbola(xcos - hsin, *pars) * np.cos(th) + xcos - hsin
seen.add(x)
self.already_computed.extend(itertools.islice(self.it, n))
fig = plt.figure()
temp_list.append(np.nan)
result = np.empty_like(X)
answer.append((key, length(iter)))
f1.seek(0)
os.remove(csvfile)
string.decode(i)
foo(z) + 1
python - V
output = sorted([1] * k + [0] * (n - k), key=lambda k: random.random())
nearness[min(nearness.keys())]
m = np.array([[1, 0, 1], [0, 1, 0], [1, 0, 1]])
plt.plot(np.arange(10) + i)
file_path = os.path.join(folder, the_file)
session.flush()
zf.close()
exit(0)
0, 1, 8, 27
a2[:x], a1[:x] = a1[:x], tmp
result
next(it)
print(b.__dict__)
context = {}
func
ax1 = fig.add_subplot(111)
arr2 = np.arange(10).reshape(2, 5)
fig, ax = plt.subplots(1, figsize=(16, 16))
soup = BeautifulSoup(xml)
Z.data *= Y[Z.indices]
result.append(idx)
exit(0)
setence_list.append(word)
os.close(fout)
de.show()
main()
sorted(tuples, key=lambda x: x[2])[:10]
sys.getsizeof(w)
mask[1:] |= mask[:-1].copy()
s = a[:, (np.array(second).reshape(-1, 1)), (third)]
importlib.reload
table = cur.fetchall()
setattr(Something, name, decorator(fn))
self.saver.restore(self.session, fn)
self.send_response(401)
asyncore.dispatcher.__init__(self)
pprint(mindict)
[0, 1, 2],
[1, 5, 5, 5, 5]
id = db.Column(db.Integer, primary_key=True)
f()
sys.stdout = logger
spam.update()
my_time_list
plt.subplot2grid((4, 4), [2, 2], 2, 2)
set(myDict) & set(myList)
pl.show()
sys.path.append(os.getcwd())
print(retrieve_name(y))
os.path.normpath(mypath) + os.sep
redistributed_points.extend(attracted_point_list(g, a, f))
output[item] = line[i + 1] = i
c = [value for pair in zip(a, b[::-1]) for value in pair]
print(r[numpy.isreal(r)])
df
filename = sys.argv[1]
fin.seek(0)
np.nan
output_queue.put(process_me)
Maybe(maybe.calc(lambda x: x * 2))
556, 27.0
s.close()
d = OrderedDict([a, b, c])
print(type(fresult.col1.iat[1]))
session = requests.session()
print(urlparse.urlunparse(newurl))
run_wsgi_app(application)
b().mymethod()
zip(list, list)
x = [0, 0, 1, 1, 2, 2]
s = etree.tostring(root, pretty_print=True)
arr[unconverged] -= f_g[new_unconverged] / fp(arr[unconverged])
((a > 0) & (a < 1)).sum()
print(urlparse.urljoin(testurl, urlparse.urlparse(cleaned).path))
plt.show()
plt.colorbar()
l2 = [4, 5, 6]
result = [separator.join(map(str, r)) for r in result]
client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
parser = argparse.ArgumentParser()
today = datetime.now(tz).date()
foo.__code__.co_argcount
datetime.fromtimestamp(value)
fout.close()
self.fh.close()
self.hbox.addWidget(self.txted)
f.truncate()
True
printArray([str(Array[i][j]) for j in j_indices])
a, b = min(a, b), max(a, b)
print(make_hash(foo.__dict__))
widget = QWidget()
l[1]
self.stdout = sys.stdout
print((letter, count))
df.columns = df.columns.swaplevel(0, 1)
tuple(sorted(a.items()))
np.tril(df.unstack().values, -1).sum()
d[type(x)].append(x)
im1 = im.resize((tilesize, tilesize), Image.BILINEAR)
heapq.heapify(a)
x[1] - x[0]
parents[b].append(a)
a /= a.sum()
print(info.get_content_subtype())
db.session.expunge(product_obj)
generalizedEuclidianAlgorithm(b, a)
print(q.get())
print(ttaken)
print(dectest.test(a))
sum(abs(a - b) for a, b in zip(A, B))
201412
counts = collections.Counter(map(tuple, c))
deleteself.right[0:x]
out = np.split(list1.ravel()[sidx], cut_idx[1:-1])
dates.hist()
members.append(target.id)
print(repr(dest))
b = numpy.array([0, 0, 0, 0, 1, 1])
type(s)
result += str(r)
print(key.hash())
power(lambda x: x * 2, 0)(9)
pp.pformat(my_dict)
test(**dicC)
self.finished.emit()
painter.draw_box(*args, **kwargs)
vbox.addWidget(self.previewImage)
foo(a + b + c)
path.append(k.id_or_name())
sum(s[idx] == j for idx, j in enumerate(s, 1) if idx != len(s))
b = np.array([False, True, True, False])
ll = list(chain.from_iterable(repeat(e, 2) for e in l))
i += 1
print((i, j))
item
print(access_token)
conn, addr = s.accept()
count.most_common()
user_input = []
print(__file__)
app = Flask(__name__)
rpath
[False, True, False, True]
window.show()
Post.objects.filter(userBy__id__in=friends_and_user)
f = lambda x: Series(np.histogram(x, bins=bins)[0], index=bins[:-1])
nextList.append(newString)
today = datetime.now()
res = requests.get(URL)
os._exit(1)
html = template.render(Context(data))
view.resize(600, 400)
x = [], []
self.Bind(wx.EVT_BUTTON, self.OnOkayCanButton, canButton)
fs.delete()
print(sorted(flatten(structure)))
hand = random.sample(DECK, 5)
shape = np.array(arr.shape * 2)
print(len(y))
Graph().setThis(self._this.read(pathbytes))
HTML(style + df_html)
dis.dis(make_adder.__code__.co_consts[1])
cur = conn.cursor()
val = map1[key]
print(len(list))
a = bar.a
indices = [1, 4, 5, 6, 7]
-0.11112
plt.gca().xaxis.set_major_locator(plt.NullLocator())
mutex.release()
[(1, 5), (8, 11), (200, 202)]
pool.join()
array = np.zeros(10)
x + y
content = fd.read()
[int(0.5 + 10 ** (i * 2 / 19.0)) for i in range(20)]
x.strftime()
memset(location, 0, size)
window.show()
image_file.write(chunk)
sys.stdout = codecs.getwriter(output_encoding)(sys.stdout, errors=errors)
print(list(find_ref_names(b)))
a.write(f, os.path.relpath(f, root))
n = random.uniform(0, weight_total)
GO
self.lineedit.setFocus()
mask1 = logical_and(arange(10) > 5, arange(10) <= 8)
math.acos(inner_product / (len1 * len2))
s[s == 12]
urllib.request.urlopen(req)
mlab.outline(extent=(0, 1, 0, 1, 0, 1))
data[line[0]].extend(line[1:])
isinstance(f, numpy.float64)
ax.xaxis.set_major_formatter(ticker.FixedFormatter(ticklabels))
self.page.loadFinished.connect(self.save)
y = x[mask]
e = list(zip(*d))
ax = fig.add_subplot(111)
tcpSerSock.listen(5)
env.Depends(target[i], out)
plt.show()
sys.getsizeof(frozenset((1, 2)))
main()
fig, ax = plt.subplots()
ret = np.array([])
print(df.iloc[(-1), :])
m = np.arange(len(df))
f(x) + 1
f.close()
print(result.shape)
out[-1].append(element)
app = Flask(__name__)
a2 = np.split(a, [2, 4])
plt.show()
[joiner(words) for words in sixgrams]
OrderedDict.__init__(self, *args, **kwargs)
axes.set_frame_on(frame)
mycsv = csv.reader(f)
[(a, b) for i, a in enumerate(lst) for b in lst[i + 2:]]
self.rect = Rectangle((0, 0), 1, 1)
transsurface.set_alpha(50)
print(str)
merged[k].add(d1[k])
result = {}
app = Flask(__name__)
result[line_number].append(line.strip())
plt.plot(list(range(10, 20)))
print(df1.reindex(columns=comb, fill_value=0))
output.append(pformat(environ))
c = np.hstack((a, b))
print(json.dumps(sample))
fake_writer.writerows(data)
data = []
ids.extend(list(range(1, int(x[1:]) + 1)))
self.assertEqual(1, c.count)
(df - df2).combine_first(df).reindex_like(df).astype(int)
print(str(node))
ax = fig.add_subplot(111)
resampled_values.diff()
popen.wait()
trimmed.pop(0)
data = numpy.array([0, 0, 0, 2, 2, 0, 2, 2, 2, 0])
h = hexbin(x, y, gridsize=10, mincnt=0)
self.button = QtGui.QPushButton(self)
form.save_m2m()
stream.write(data_to_write)
len(flows[maks]), maks
dill.detect.badtypes(f)
termios.tcsetattr(file.fileno(), termios.TCSADRAIN, new_attrs)
ar(a) | ar(b) | ar(c)
f(50, 50)
self.causes
a * np.sqrt((b * c) ** 2 + (x - d) ** 2) / b + e
self.clients.remove(client)
classifier.show_most_informative_features()
document.prettify()
func(*args, **kwargs)
print(row)
s.partition(delim)[2]
print(heapq.nsmallest(2, list1))
self._list.insert(index, item)
fig.colorbar(im, cax=cax)
idcord.append(y1)
print(hi.bye)
raise SystemExit
kernel = np.array([[-1, -1, 1], [-1, 1, 1], [-1, -1, 1]])
signal.Signals(2).name
raise AttributeError(msg.format(type(self).__name__, name))
Maybe(100)
im = numpy.array(img)
im = Image.fromarray(A)
d = np.searchsorted(a, np.setdiff1d(a, b))
s.ioctl(socket.SIO_RCVALL, socket.RCVALL_ON)
gen = (i for i in range(10))
self.user.username
eval(str, os.__dict__)
method(*args, **kwargs)
dict(zip(columnNames, args))
key.set_contents_from_filename(object_name)
screen_width = root.winfo_screenwidth()
suite.addTest(suitefn())
y + np.abs(y.min())
self.name
today.year - born.year
pprint.pprint(d)
print(list(merge(tup)))
mix_arrays(A, B)
Concate[A[i]] += B[i]
pts = [(1, 1), (1, 10), (10, 10), (10, 1)]
l = list(range(1, 100, 4)) + list(range(2, 100, 4))
value.append((node_key, node_value))
body = models.TextField()
func
cache.get(self.COUNTER_CACHE_KEY)
type(name, bases, dict)
self._pixels.append((x, y))
B = np.array([2, 4, 6, 8])
myBoxLayout.addWidget(self.listWidgetB)
img[:, :, (0)] = numpy.ones([5, 5]) * 64 / 255.0
(array[:-1] * array[1:] < 0).sum()
l = s.split()
print(self.left.PreOrder())
cache[key]
conn, addr = socket.accept()
plt.scatter(xAsInts, y, color=color)
a = np.sqrt(d)
earth = 6e+24
main(sys.argv)
word.Quit()
file.write(pickle.dumps(df))
print(i)
soup = bs4.BeautifulSoup(f)
self.assertEqual(self.flushLoggedErrors(ValueError), 1)
out.start()
mock_last_transaction.assert_called_once_with()
cpick.set_array([])
g1.intersects(poly.ix[0])
frame = inspect.currentframe()
print((i, h, j))
HTMLParser.HTMLParser.__init__(self)
result[d[0]][d[1]] += 1
self.x2 += self.speed * math.cos(self.bearing)
sleep(1.5)
print(response.read())
p = subprocess.Popen(command, stderr=subprocess.PIPE)
main()
(1 == 1) & (2 == 2)
main()
d = dict(list(l.items()))
self.root = Tk()
self.setLayout(layout)
print(sentence_dict)
driver.get(self.login_page)
scrollby.grid(row=7, column=5, rowspan=2, columnspan=1, sticky=N + S + E)
phrase.upper()
tagger = nltk.tag.UnigramTagger(model=model, backoff=default_tagger)
ax.set_xticklabels(xlabels, rotation=20)
f(*args, **kwargs)
c1.my_numpies.append(mn2)
df = df.reset_index()
numpy.array(strings)
p.stdout.close()
writer = csv.writer(outcsv)
s = gtk.gdk.Pixbuf(gtk.gdk.COLORSPACE_RGB, False, 8, w, h)
message = cipher.decrypt(ciphertext)
my_file.write(b)
db.session.commit()
id = Column(Integer, primary_key=True)
list([t for t in list(d1.items()) if t[1] == max(d1.values())])[0][0]
image.set_at((x, y), (255, 255, 255, 0))
d = np.ones((100,))
y = np.random.normal(0, 1, num).cumsum()
PyQt4.QtCore.QPoint(90, 6)
num = num / 2
pd.DatetimeIndex(df.date).normalize()
raise cherrypy.HTTPRedirect(redirect_url)
gtk.CellRendererPixbuf.__init__(self)
a.remove(5)
queryset = MyModel.objects.all()
outbuff.append(line)
exns.append(name)
ax = plt.subplot(111)
df = df.copy()
print(something)
sys.stdin = sys.__stdin__
mahotas.features.haralick(img).mean(0)
a[:] = a[:].__iadd__(da)
ax.set_xlim([np.min(X), np.max(X)])
pd.isnull(df)
print(df)
json.dumps(json_d)
x, y = im.size
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
print((key, value))
ser.open()
a.sum()
new_list = []
print(eval(t))
count += len(chunk)
Py_Initialize()
[capitalize_nested(s) for s in t]
Response(response_data)
labels = ax.get_xticklabels()
body.append(rv)
newlist2.append(s)
[_heappop_max(h) for i in range(len(h))]
result = result.astype(np.float64)
y1[np.where(y1 == input_array.shape[1])] = y0.max()
lclosure
fb[:] = 0
44718
fig.show()
someDictionary[zipped[0]] = zipped[1]
plt.show()
self.delta += 1
imshow(img_result)
indata = f.read()
max(mul(*heapq.nsmallest(2, l)), mul(*heapq.nlargest(2, l)))
write_line(of, n, [0.1, 0.1, 0.1, 0.1])
m = df.Col1.str.len().max()
col = get_column_letter(col)
union(jName, kName)
path = os.path.normpath(path)
NULL
aw1.show()
rdd.take(5)
1 == True
np.exp(rebased_q - np.logaddexp(-max_q, np.logaddexp.reduce(rebased_q)))
reader = java.io.BufferedReader(java.io.InputStreamReader(stream))
cur = db().cursor()
data[k].append(i[1])
[n[0] for n in sorted(zip(sorted(B), order), key=itemgetter(1))]
M[numpy.where(M == 0)] = 1000
getcontext()
test()
sorted_list = list(myDic.keys())
rcsplit(np.array(i))
figure()
l.set_option(ldap.OPT_X_TLS, ldap.OPT_X_TLS_DEMAND)
df
self.setLayout(layout)
d[x].append(i)
bucket.delete_keys(delete_key_list)
lines = f.readlines()
user = int(user)
main()
json.dumps(namedtuple_asdict(a1))
pprint(foo(10, depth=2))
sys._getframe(back + 1).f_code.co_name
func
y = vfunc(x)
indices = [i for i, x in enumerate(ar) if re.match(pattern, x)]
ax = fig.add_subplot(111)
True
result.extend(itertools.combinations(x, len))
self.panel.SetFocus()
out.append(np.median(y[mask]))
np.unique(salesdata.Outlet_Size.dropna().values)
mdata
response = urllib.request.urlopen(request)
{7, 8, 9, 10},
combinations.append(x)
httpd.serve_forever()
reader = csv.DictReader(f)
plt.subplot(222)
t[v] = min(t[2 * v], t[2 * v + 1])
data[i].some_key
print(df)
y = np.linspace(0, 2 * np.pi, ny)
logger.setLevel(logging.INFO)
e = int(e_str, 16)
plt.plot(list(range(10)))
value = models.CharField(max_length=100)
console_handler = logging.StreamHandler()
serializer_class = UserSerializer
self.x + other.x
heapq.heappush(heap, (-p1, x - 1, y))
this_year = str(this_year)
soup = bs(root)
deletesys.modules[k]
self.f.write(x)
args.func(args)
self.label.setMinimumSize(QtCore.QSize(450, 40))
print(df.iloc[:, (rng)])
args = parser.parse_args()
print(perfect_numbers(n=5))
do_something_with(line)
fnan < pinf
current_node.valid_subword
copylist.append(singleobj)
print(i)
us1 / us2
linspace_y = np.linspace(y_range[i], y_range[i], 100)
screen = curses.initscr()
alllists.append(addlist)
w = w / 2
new_tagged_words
setattr(Cls, key, value)
packet1.show()
__future__.with_statement
os.chdir(destination)
object_id = models.PositiveIntegerField()
timeit(easydiff1, easydiff2, 10000)
m, b = np.polyfit(x, y, 1)
p = Presence()
obj1[0], max(obj1[1], obj2[1]), min(obj1[2], obj2[2])
print(item.key, item.doc_count)
+globals().update(yak)
df = pd.read_csv(tempfile)
file, pathname, description = imp.find_module(name)
p.haslayer(IP)
__init__.py
stdscr.getkey()
print(x[i], y[i + 1], x[i + 1], y[i])
self.counter = 0
results.append(task.get())
list(self._odict.keys())
x = numpy.ones(5)
self.growChunk()
p = ctypes.cast(void_p, ctypes.POINTER(ctypes.c_char))
print(value)
self.n = n
s.cookies
print(pool.map(f, list(range(10))))
[0.0, 0.2, 0.4, 0.4, 0.0]
p = im.getpixel((x, y))
glfw.SetTime(0.0)
DataDocumenter.add_directive_header = add_directive_header
result = re.sub(p, subst, test_str)
interpreter.process_page(page)
angle = NumericProperty()
values.append(value)
message = messages.GetLast()
x.stdin.close()
np.arange(1, stop, step)
self.write(json_encode(obj))
result
merged.append((k, sum(e[1] for e in g)))
results = mp.Queue()
browser.save_screenshot(img)
canvas.setPageSize((lWidth, lHeight))
plt.semilogx(f, mag)
self[key]
Z.data *= Y.repeat(np.diff(Z.indptr))
set(list1) | set(compSet)
lock.release()
host_data.append(host.serialize())
new_list.append({expression})
app.exec_()
frec(word[1:], values + [word[0]])
os.waitpid(pid, 0)
x - x.mean(axis)[ind]
Time.place(x=0, y=0)
y = np.array([0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1])
self.label.lift(self.frame)
len(wordorder)
dd[item].append(idx)
User.__unicode__ = User.get_full_name
self.canvas = Canvas(self.tk, width=500, height=500)
point_list.sort(key=lambda point: point[axis])
b = 2 * N - 1
funcs.append(lambda x, i=i: f(i, x))
list(UndefinedSilently().items())
menu.show_all()
delta.total_seconds()
int(round(math.log(v, 2), 0))
print(freq_distribution.most_common(10))
iterator.__iter__()
result = proc.stdout.read()
df[0].count()
a.sum(axis=0)
register = template.Library()
result[nJ] = fun2(zeta[nJ])
[list(x) for x in zip(*lis)]
s = plt.subplot(1, 1, 1)
canvas.pack()
PyBUF_FULL_RO
id = Column(Integer, primary_key=True)
print(cmap(0.5))
print(dftot.fillna(filldf))
fig = plt.figure()
res = list(message.DESCRIPTOR.fields.keys())
df[2].replace(4, 17, inplace=True)
plt.subplot(122, polar=True)
p = mp.Pool(processes=2)
x = np.random.rand(50)
do_somethin(cell)
df
sum(v for v in args if args.count(v) == 1)
slug = models.SlugField(max_length=255, unique=True)
print(result)
nx.append(x[-1])
mask.dtype
conn.end_request()
device.close()
c.execute(query)
termios.tcsetattr(fd, termios.TCSANOW, new)
is_staff = True
x.set_visible(False)
f.close()
reallocate()
np.tensordot(a, a, (1, 1))
print(self.__dict__)
list(islice(preresult, 100))[-10:]
result = pool.apply_async(worker, args=())
divmod(elapsedTime.total_seconds(), 60)
code.interact(local=locals())
print(uniqify(2))
mylist.append(x)
x = dict()
out.writelines(lines)
self.session.query(entity_type)
main()
B[X] = A
a[1]
axes.set_ylim([0, 70])
a = 1 if b else a
result = self._client.gremlin(script, params).one()
main.show()
Rect(p1.x, p1.y, p2.x, p2.y)
offset += font.getsize(line)[1]
message = headers + body
f.seek(0)
ws.set_panes_frozen(True)
json.dumps(json.load(str_w_quotes))
bar()
datetime.datetime.fromtimestamp(float(time_in_secs))
print(diff.total_seconds())
skipsdist = True
urllib.request.install_opener(opener)
print(line)
deleteself._this
x.do_foo()
os.makedirs(path)
Matrix[0][0] = 1
M.ix[0, 0]
identity = np.identity(A.shape[2], dtype=A.dtype)
deletetrees[i]
endforeach()
img = MIMEImage(fp.read())
list(product(*[permutations(grp.index) for name, grp in age]))
b = np.array([list(w.center(wid)) for w in a])
logging.basicConfig(filename=LOG_FILENAME, level=logging.DEBUG)
result = []
print(np.allclose(Z1, Z2))
plt.minorticks_off()
str[:index] + str[endIndex:]
aCash.sum() == (aCash & bNull).sum()
os.waitpid(p.pid, 0)
lock.acquire()
yaml.load(stream, OrderedLoader)
self._queue.cancel_join_thread()
plt.cla()
json.dump(d, o)
[term_appearance.update(x) for x in texts_list]
dict.__getitem__(self, item)
newarray = [0] * n
hash(tuple(sorted(self.__dict__.items())))
socket.send(empty, zmq.SNDMORE)
violin_plot(ax, data, pos, bp=1)
Tr
plt.subplot(121)
map(lambda x: x.start(), threads)
m[i] = False
W = tf.Variable(tf.zeros([784, 10]))
x = np.zeros((depth, size, size))
print([p.spelling for p in file_nodes])
myDict[newKey] = [value]
str(delim.join(result))
self.Bind(wx.EVT_PAINT, self.OnPaint)
print(x)
print(df)
print(b[:, :, (1)])
html.fromstring(broken_html)
print(item)
array += [myNumber]
myDict[temp] = myFunctionThatReturnsData()
self.Meta.model(**validated_data)
i += 1
p1.wait()
print(item)
sys.path.append(dir_of_interest)
spl[-1].extend(y)
fig, ax = plt.subplots()
df2 = df1.reset_index(drop=True)
abs(x - y) < epsilon
self.session_store.get_session()
np.allclose(Z1, Z2)
threading.Thread.__init__(self)
8881 % 2
form.show()
values = list(d.values())
sys.stdout.write(buffer)
signal.signal(signal.SIGHUP, lambda signum, frame: manager.stop())
t.cancel()
elementwiseProd(a, b)
print(s)
stack.append([element])
line = f.readline()
b.start()
bitarray.bitarray(l)
zip(map(tuple, idr), map(tuple, idc), out)
tasks[key]()
df.index
n1 = np.random.random(N)
jsonpickle.encode(myObject, unpicklable=False)
min(x, y)
z = delrc(i)
dict(union(list_dictionaries))
fig = plt.figure()
[ind_sorted[x[i]:x[i + 1]] for i in range(N - 1)]
t2.append(t[0] + t[-1])
show_times()
df = pd.read_csv(f)
list(fields_from_list(keys, values))
c = np.hstack((a_t, b_t))[:, (np.argsort(np.hstack((a, b))))]
new_modules
datetime.strptime(date, date_format)
result * result
x = array([[1], [1]])
im = axs[0].imshow(Z, cmap=plt.cm.Greys_r)
React.createClass.toString()
os.mkdir(dir)
A.subtract(B, fill_value=0)
np.array(NumNonZeroElementsByColumn)[0]
req = urllib.request.Request(url)
self._list.__setitem__(key, item)
t.seek(0)
self.setSelectionMode(QtGui.QAbstractItemView.ExtendedSelection)
tk.Canvas.itemconfigure(self, *args, **kwargs)
np.seterr(**eset)
template_rendered.connect(add_template_name_to_context)
result = func(*args, **kw)
data = data[2:]
mydict = args.my_dict
plt.imshow(data)
x == 2
x[0] = 0
res = NP.hstack((my_data, new_col))
result = []
concurrent.futures.wait(fs)
x = o
ctx.select_font_face(font, *args, **kwargs)
self.dictionary[key][1]
arr[j][i] = round(arr[j][i], 10)
img = cv2.imdecode(array, 1)
print(tmr.timeit(number=1))
ax.add_artist(anchored_text)
k * math.exp(s * (x - mu) * (x - mu))
name = models.CharField(max_length=100)
parser.feed(text)
G = nx.Graph()
zlib.decompress(part)
pipeA.send(10)
renderer.props.wrap_mode = gtk.WRAP_WORD
self.src[i].append(self.src[i + 1].pop(0))
Z[test[:, 0:2].T.tolist()]
q = Queue()
lines = f.readlines()
a[:] = [x for x in a if x <= 4]
combined = dict(union(dict_list))
print(key, value)
Foo.objects.all().delete()
(arr * cond).argmax(1)
angles.append(angle)
sys.stdout = buffer
ax.plot_wireframe(xx, yy, z)
fig = plt.figure()
F()
writer.writerow(row)
next(i for i, (el1, el2) in enumerate(zip(l1, l2)) if el1 != el2)
time.sleep(60 * alarm1)
c.append(a[0])
r = requests.head(url)
int(round(b / 5.0) * 5.0)
[0.0, 0.0, 1.0, 0.0, 1.0, 0.0],
frame.rowconfigure(1, weight=1)
self.patcher1 = patch(path)
self.population[bisect.bisect(self.cumweights, i)]
soup = BeautifulSoup(page)
first, rest = unpack_nfirst(seq, 1)
perform_other_actions()
AHIJ
DGIJ
AZ
BC
plt.vlines(x_median, 0, y_median)
driver = webdriver.Firefox(capabilities=capabilities)
olleh
stack[-2].append(stack[-1])
p = bokeh.plotting.figure(x_range=[0, 10], y_range=[0, 10])
atexit.register(endlog)
[replacer(s) for s in strings if len(s) > 2]
json.dumps(value, cls=DjangoJSONEncoder)
l[a], l[b]
test()
self.circle1.grid()
pool = Pool(5)
df
pixels.append(img[x + opx][y + opy])
array([[0, 1, 2], [0, 1, 2], [0, 1, 2], [0, 1, 2]])
deletedf[col]
Node.writexml(f)
print(directory_list)
leg = ax.get_legend()
self.verticalLayout = QtGui.QVBoxLayout(self)
item_dict[sample[1]]
print(line)
xml.write(escape(data))
names[nickname][weighted_choice_sub([x[1] for x in names[nickname]])][0]
x += 1
self._applecount = 0
plt.show()
self.br.addheaders = self.old_headers
getattr(instance, self.name)
gdi.GetPixel(h, 1024, 767)
numpy.mean(arr, axis=0)
wb = Workbook()
(top_matrix.T * top_matrix).det().factor()
qproc.join()
subset = table[np.array([(i in id_list) for i in table.IDs])]
ax1 = plt.subplot(gs[(0), :])
print(Crypt.find_crypts(706))
fig.tight_layout()
df = pd.concat([df1, df2])
combinations.append(accum)
ax = plt.gca()
new_list = list(itertools.chain(range(1, 6), range(15, 20)))
arr = np.fromiter(chain.from_iterable(combinations(x, 2)), dtype=x.dtype)
self.box.pack_start(self.canvas.draw_area, True, True, 0)
file.seek(here, os.SEEK_SET)
image = image.convert_alpha()
job[1].kill()
drawCirc(ax, 1, 1, 1, 0, 250)
self.monad = monad
widget.deleteLater()
toggle()
np.logical_and(x > -2, x < 2)
line = m.readline()
print(int(floor(f2)))
setattr(Foo, name, make_binding(name))
x = cos(radians(i))
r.raise_for_status()
t = threading.Thread(target=drain_pipe)
[shuffle_word(word) for word in L]
app.run(port=5000)
codecs.register(cp65001)
s = spline1dbuildakima(x, y)
True
seen.add(k)
a = [dict(zip(header, map(int, row))) for row in reader]
func(*fargs, **fkwargs)
foundwords
df = pd.concat([df, new], axis=1)
print(type(p))
SomeClass.some_class_method()
ii = np.array([1, 1, 0])
results = json.load(response)
conn.commit()
sys.exit()
print(tostring(fromstring(data, parser=parser)))
self.d[key] = value
[0, 0, 1, 0, 0],
stack[-1].append(element)
json_util.dumps(MyDoc._collection_obj.find(MyDoc.objects()._query))
result.append(i)
words = s.split()
self._matches(found.string, self.text)
ax.set_ylim(ymin=0)
l = func(X, Y, Z)
stdin.flush()
parser = xml.sax.make_parser()
a.shape
msg = socket.recv()
[val(x) for x in a]
request = urllib.request.Request(url)
xmin, xmax = x[mask].min(), x[mask].max()
X_train = np.array(descs_train)
print(bar)
diff = [(a[i] - a[i + 1]) for i in range(len(a) - 1)]
dic.pop(k)
audio_thread.start()
labels = [item.get_text() for item in ax.get_xticklabels()]
fig = plt.figure()
b[5, 6, 7, 8]
newY[x] += 1
data = [random_data() for x in range(0, 10)]
print(list)
parse_qs(urlparse(url).query)
final_df
y_true = [0, 0, 1, 1, 2, 0, 1]
base, str = int(sstr[0]), sstr[1]
setattr(cls, methodname, newmethod)
a_order = numpy.argsort(a)
x0 = x_indices.astype(np.integer)
a = np.in1d(np.arange(m), np.random.randint(0, m, m))
print(i)
p.wait()
self.statusitem.setMenu_(self.menu)
print(first_column, third_column)
app = App()
print(q.all())
name = models.CharField(max_length=16)
A = [[1, 1, 0, 0], [0, 1, 0, 1], [1, 0, 1, 0], [0, 0, 1, -1]]
foo = Bar()
print(df2)
log.start()
df2[col] = c
map = mmap.mmap(f.fileno(), 0)
self.x
print((freqs.min(), freqs.max()))
session = requests.session()
app = wx.PySimpleApp()
n = np.arange(10, 1000, 10)
foo(*args)
xi, yi = np.meshgrid(xi, yi)
G = nx.DiGraph()
t.objects.all()
ret.sort(axis=0)
oldmodule.__dict__.update(newmodule.__dict__)
self.cntrlPanel.SetSizer(sizer)
bools = [success_condition(r) for r in results]
self.appname = appname
d[i[0]] = i[1]
random.seed(seed)
fnew
items[item].append(i)
xyB[:, (1)] *= widthB / (xyB[:, (1)].max() - xyB[:, (1)].min())
self.toolbar.Bind(wx.EVT_MENU, self.OnTool, id=tool_id)
t = time.time()
ax.yaxis.grid()
df.head(5)[df.columns[0:4]]
sc.close()
td.dt.days
axes[0].plot(x, i * (x - 10) ** 2)
print(image.shape)
[dict(zip([col[0] for col in desc], row)) for row in cursor.fetchall()]
self[key].extend(value)
fig = plt.figure()
p = subprocess.Popen(args, startupinfo=startupinfo)
x = some_text % tuple(s)
buf.seek(0)
aapl_50ma.plot(legend=True)
self.nested_whatever_id = nested_object.id
fig = plt.figure()
response.render()
real_decorator
dataframe.plot(ax=f.gca())
df.head(1)
d = collections.defaultdict(list)
StandardPyGTKSpec()
rows = cursor.fetchall()
dict[firstName] = 1
unique[maxpos], counts[maxpos]
print(string.Template.pattern.pattern)
list(compress(fruits, (f in s for f in fruits)))
root.deiconify()
sum(islice(count(1, step=4), 100))
curdir = os.getcwd()
f.write(line)
q = q.prefetch(Supplier)
dot_product = tf.reduce_sum(tf.multiply(x, y))
ar = cur.fetchall()
print(self.data)
layout.addWidget(self.runButton)
asyncore.loop(timeout=5.0)
Console.ReadKey()
c[:a.shape[0], :a.shape[1]] -= a
df.combine_first(df.T)
self.addItems(self.list_one)
self.l.pack()
q.get()
ctx.set_source_rgb(0, 0, 0)
mask = [any(tup) for tup in zip(a, b, c)]
num_int = int(num_int / 2)
dfa = df.ix[:, ([1, 0])].copy()
b.T
plt.plot(x1, y1)
pic.seek(0)
time.time() - os.stat(pathname)[stat.ST_MTIME]
hn.setLevel(logging.DEBUG)
mark_safe(simplejson.dumps(object))
df = df.reindex(columns=cols)
pixbuf = gtk.gdk.Pixbuf(gtk.gdk.COLORSPACE_RGB, False, 8, 1, 1)
s.diff()
dictionary[len(i)] = 1
xi, yi = np.meshgrid(xi, yi)
pygame.init()
self.cur2.executemany(query, self.rows)
np.random.seed(0)
print(newlists)
b = a[new_names]
plt.plot(time[:-1], scipy.integrate.cumtrapz(signal, x=time))
ind = r * cols + c
QWidget.__init__(self, parent)
data = np.random.random((100, 100))
abs(a - b)
fh.writelines(output)
print(os.__file__)
array[0] = 1
alert(msg.data)
m.contourf(xi, yi, zi)
outputfile.close()
tree = doc.getroottree()
connection.test.foo.find_one()
G = nx.MultiGraph()
argparse.ArgumentParser.__init__(self, *args, **kwargs)
g[key] = getattr(file_one, key)
r.status_code
args = parser.parse_args()
sorted(chain(*allrows))[-20:]
self.web_view.page().setViewportSize(frame.contentsSize())
session.quit()
idx = np.array([0, 1, 2])
extent = [xbnds[0], xbnds[1], ybnds[0], ybnds[1]]
HttpResponseNotModified()
time.sleep(0.2)
[1, 4, 9]
ax.set_xlim([-4, 4])
extractDefines(TEST2)
os.chdir(working_dir)
fig, ax = plt.subplots()
data = json.load(jsonFile)
cj.set_cookie(ck)
cursor.execute(query.format(station_id=id))
M[:, (i)] *= -1
do_stuff()
[5, 199]
writer.writerow(values)
plt.plot(x, y, zorder=1)
session_crumbs.pop(0)
log.addHandler(handler)
sys.exit(app.exec_())
G = [list(g) for _, g in groupby(A, key=scientific_notation)]
EMAIL_USE_TLS = True
profile = webdriver.FirefoxProfile()
cat / proc / 12992 / status
SimpleHTTPServer.SimpleHTTPRequestHandler.do_GET(self)
self.data.extend(subpickle.data)
x[np.ix_([0], [0, 1, 2], [0, 2])]
ET.tostring(node)
t.start()
ax.xaxis_date()
fig = plt.figure()
d = {}
print(instance.Field2)
print(year + 1)
top = Tk()
plt.show()
X.append(x)
os.remove(self.local_file)
foo.append(df.columns[df.ix[i] == 1])
dict.__setitem__(self, key, val)
result = g.delay()
print(type(ax.get_xminorticklabels()[0]))
Vector([(s + o) for s, o in zip(self.data, other.data)])
y.append(words[2])
parser.parse(s)
print(mystr[mystr.find(char1) + 1:mystr.find(char2)])
s.seek(0)
print(list(itertools.product(input1, input2)))
pylab.xticks([(i / 10.0) for i in range(0, 12)])
print(binascii.hexlify(os.urandom(16)))
ents.entitydefs[m.group()[1:-1]]
results.append(lambda i=i, j=j: nodes[i].value() == nodes[j].value())
s = set(filelist)
a.show()
c = pycurl.Curl()
root = Tk()
b.append(a)
[2, 4, 5],
self.f.close()
a[0] + a[1] * 0.1
root = Tkinter.Tk()
b = a - int(a)
cls.__name__
print(t.myStuffs.all())
content = f.read()
print(x * x)
request = urllib.request.Request(url)
c = Variable(n, 2)
self.x, self.y
text = [ast.literal_eval(line) for line in f]
arr = np.ones((10, 10)) * 10
npi.indices(unique, A)
A = numpy.random.randint(1, 6, size=(1000, 12))
self.assertItemsEqual(a, list(range(0, 4)))
dist = math.sqrt(dx * dx + dy * dy)
pivot.fillna(0, inplace=True)
cj.set_cookie(ck)
mask = np.kron(np.eye(len(L)), np.ones(shp)) == 1
n = len(a)
d = dict(zip(keys, vals))
files.append(i)
ax1.plot(dates, list(range(10)))
curs.execute(sql)
app = QApplication(sys.argv)
self.extend(self._stringio.getvalue().splitlines())
True
df
output_rs = tf.transpose(output, [1, 0, 2])
platform.system()
run(command, pty=False)
dataframe[cols]
print(match.group())
same.append((i, j, string_b[j]))
C = C.view(A.dtype).reshape(-1, ncols)
df
processes.append(p)
print(make_hash([func.__code__, func.__dict__, func.__name__]))
write.writerow(i)
result = [[t[0]]]
prod, x, y = heapq.heappop(heap)
root = Tk()
print_node(root)
df.eq(0).dot(days_in_month)
nprint(polyroots(taylor(lambda x: legendre(n, x), 0, n)[::-1]))
print(k, val)
line
sys.exit()
app.mainloop()
help(assign)
line = line.strip()
a = np.hstack((a[:, ::2], a[:, 1::2]))
a, b = tee(iterable)
yscroll.grid(row=0, column=1, sticky=N + S)
new_cols = df.columns.values
triple(x) + square(x)
df
hash(str(self.name))
reactor.listenTCP(8080, factory)
0
self.i = min(self.im.shape[2] - 1, self.i + 1)
c = list(b)
f.seek(0)
btwo.on_clicked(two)
itertools.product(a, b)
s.starttls()
self.make_a_fake_request_to_myself()
False
line = line.rstrip()
data.append(row)
print(elementwise_product(list1, list2))
input_wave_file.close()
True
self.sizer = wx.BoxSizer(wx.VERTICAL)
os.rmdir(dir)
xticks[i].set_visible(False)
self.tree.pack()
draw = ImageDraw.Draw(img)
ids.append(map(lambda tup: tup[0], sorted(c, key=lambda tup: tup[1])[0:K]))
requests.__version__
theother(item)
all_zeros = not a.any()
True
genn(igap, igap - 2)
process.stdout.close()
handler1.setLevel(logging.INFO)
Base.metadata.create_all(e)
response.render()
self.value = Value()
request.write(c.name)
p = psutil.Process(pid)
ws = wb.worksheets[0]
spec.drawComboBox()
regex.pattern
name = models.CharField(max_length=50)
self.buffer.append(next(self.iter))
rslt.drop(n, axis=1, inplace=True)
fig = plt.figure()
ret = int(s)
process = Popen(command, stdout=PIPE, stderr=PIPE)
new_func
obj.save()
urls = [url5, url5, url10, url10, url10, url5, url5]
L[::-1]
result_pic.seek(0)
keys = set(l1).intersection(set(d1.keys()))
draw = ImageDraw.Draw(im)
print(df.apply(lambda x: x.A in x.B, axis=1))
a = np.array([1, 0, 0, 1, 0, 0])
print(i)
print(offset_map[key])
mail = email.message_from_string(email_body)
a.dtype
print(itemgetter(*b)(a))
nx.draw(gr, node_size=500, labels=mylabels, with_labels=True)
xx, yy = np.meshgrid(x, y)
archive.close()
sizer.Add(stc2)
M = scipy.sparse.diags([degs], [0]) - A
self.__c
print(m.group(0))
G.nodes()
foo()
np.allclose(C, out)
dataArray.reshape(enc[2])
ax.margins(0, 0)
key.make_public()
_location.gsm_location()
print(s.translate(translator))
self.panel = wx.Panel(self, wx.ID_ANY)
os.close(qq.fileno())
d = collections.OrderedDict()
mf.columnconfigure(0, weight=1)
main()
textwrap.wrap(string, 15)
__delitem__
print(solve(5 * x ** 2 + 5 * x + 5))
a = [1, 2, 4]
lst = [a, d, b, c, e, f, g]
line = f.readlines()[7]
array([[1.0, 0.0, 0.0], [0.0, 1.0, 0.0], [0.0, 0.0, 1.0]])
min(player(l[:-1]), player(l[:-2])) + l[-1] if l else 0
1000111001100111100111000010111101011110010001010000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000
f(*args, **kwargs)
f = float(s)
arr[0][1]
1
[(i >> p & 1) for p in range(length - 1, -1, -1)]
w = watcher.Watcher(dir, callback)
nonlinsolve([x * y - 1, 4 * x ** 2 + y ** 2 - 5], [x, y])
btn.set_sensitive(False)
driver = webdriver.Firefox(capabilities=firefox_capabilities)
app = wx.App(False)
self.setIconSize(QtCore.QSize(124, 124))
console.log(i.toString(2))
urllib.request.urlopen(uri).read()
b / foo.py
fileToSend.close()
n = a.shape[0]
bool(strtobool(str(arg)))
ans[k1].append({k2: v2})
True
time.sleep(10)
x = pd.DataFrame(np.random.randn(10, 5))
urllib.request.HTTPHandler.__init__(self, debuglevel)
output.append(list[indexes[-1]:])
bus = dbus.SystemBus()
do_my_work()
print(thedict)
self.ax.grid(True)
delta = dt.timedelta(hours=12)
Py_INCREF(p_eigen_python_error)
X, Y = np.meshgrid(x, y)
reader = csv.DictReader(infile)
str.__new__(cls)
chr(int(x.group(1), 16))
self.__class__(**d)
record.put()
plt.close(fig)
daemon_cartman.start()
A = NP.random.randint(10, 100, 100).reshape(10, 10)
setup.py
array = file.readlines()
example.insert(4, 122)
root.mainloop()
fig.subplots_adjust(wspace=0.1, hspace=0, bottom=0.05)
app.MainLoop()
lib.foo.restype = c_char_p
main()
draw_ellipse(image, ellipse_box, width=20, antialias=1)
parent.add_widget(GearTick(range=(0, 100)))
req = urllib.request.Request(post_url, json.dumps(postdata), headers)
max(d1, key=lambda k: d1[k])
print(final)
stat(my_filename).st_uid
Button.__init__(self, parent)
cursor = collection.find({})
self.origstreamfd = self.origstream.fileno()
foo = Foo()
-num_decode(s[1:])
key0 += 1
serializer = CommentSerializer(data=data)
sudokupossibilities
[0, 0, 0, 0, 0, 0, 15, 16],
d.setdefault(a, []).append(b)
f = plt.figure()
my_dict = {key: set(value) for key, value in list(my_dict.items())}
example()
s[:1, (1)]
res[k] += l[0:len(l) - n + 1]
angle = np.deg2rad(angle)
status = p.wait()
chunk = proc.stdout.read()
com.convert_robj(a)
f.set_pasv(0)
ax.set_yticklabels(labels)
fig, axes = plt.subplots(1, 2, sharey=True)
Ainv = tf.matrix_inverse(A)
name = models.CharField(max_length=45)
plot(x_av, y)
top = Tkinter.Tk()
plt.draw()
axis[:set_ylim](-1, 1)
H, xedges, yedges = np.histogram2d(x2, y2)
sys.stdout = StringIO.StringIO()
os.umask(0)
x = {(1): 2}
x = np.outer(np.sin(theta), np.cos(phi))
sock.bind(address[0][-1])
lines = (line.strip() for line in text.splitlines())
df = pd.DataFrame(list(ds2.difference(ds1)), columns=df2.columns)
print(np.matrix(A))
data = yaml.load(stream)
values = [col.text for col in row]
transaction.leave_transaction_management()
notebook.set_tab_reorderable(page1, True)
norm = plt.normalize(min_v, max_v)
print(pd.DataFrame(d))
0.6044, sym2, 2, 5, 10, 10
print(item)
self.data.pop()
mask[col] = True
out = np.zeros((N, N))
True
data = urllib.request.urlopen(url)
print([x for x in list(globals().values()) if isinstance(x, FunctionType)])
code.interact(local=locals())
f = np.poly1d([1, 0, 0, -1])
func1()
next(mat)
data_files.append((directory, files))
[atup[n:n + 4] for n, i in enumerate(atup) if n % 4 == 0]
self.arguments = {}
print((r[0], r[1]))
XGBClassifier(**grid)
val = func(self.val)
p.communicate(msg.as_string())
panel = tk.Label(window, image=img)
os.remove(f.name)
grid[i, j] = z
endclass
w.show()
fig.patch.set_visible(False)
msg = MIMEMultipart()
df.clip(lower=0)
value, key = key[:size], key[size:]
zip(*[(lft[i] + board[i] + rgt[i]) for i in range(n_rows)]),
args = parser.parse_args(preprocess(sys.argv))
multi_line_word << (word | split_word + multi_line_word)
marshal.dump(f.__code__, funcfile)
shutil.copyfile(source_path + filename, dest_path + filename)
entry1.grid(row=1, column=1)
sess = tf.Session()
TestCase.setUp(self, *args, **kwargs)
self.label.pack(padx=10, pady=10)
A[(idx), :]
self.SetTransparent(50)
ip = self.request.remote_addr
admin.site.unregister(Group)
x.__name__
threads.append(t)
somescript.py
df
self._final_queue.put(self._get_final_result())
os._exit(0)
listen()
PyRun_SimpleString(pycmd)
reduce(np.logical_and, map(pred, list(range(a.shape[1])))).any(axis=1)
result.append(job.get())
id = Column(Integer, primary_key=True)
w = np.asarray([0, 4, 7, 10])
ax.scatter(x2, y2, s=100, lw=0, color=[alpha, alpha, 1.0])
gen_move(list(range(10)))
a = []
key = m[0][0] + m[0][1]
stmt.to_unicode()
glLoadIdentity()
concatenate_per_row(A, B)
FO.write(line)
msmdsrvini.write(msmdsrvText)
self.windowSizer.Add(self.panel, 1, wx.ALL | wx.EXPAND)
self.session_store.save_sessions(self.response)
print(TR8(c))
columns[i].append(h)
nbr_edgeobjects
list(~numpy.array(mylist))
self.assertTrue(flag)
[x for x in range(*s.indices(10))]
ds.addSample((-1, 1), (1,))
Frame.__init__(self, master)
self.callback()
sys.stdout.write(s)
f.sum()
str(self(*args, **kwargs))
hash = random.getrandbits(128)
out = f.getvalue()
self.doMP()
self.fp = open(self.file_or_path, mode)
A = x.todok()
x = np.linalg.lstsq(a, b)[0]
window1.show_all()
fig, ax = plt.subplots()
a.indices(100)
pd.Series(L)
ret.append(line[:-1])
result = jobs.apply_async()
summarized_info
a = a.reshape(nx, ny, nz)
f.close()
b.build_base
f(**kw)
programmer1.info()
1
isinstance([], list)
line, = ax.plot([], [], lw=2)
g[c] = i
np.vstack([bins[:-1], bins[1:]]).mean(axis=0)
fig, axes = plt.subplots(nrows=2, sharex=True)
counts = pd.value_counts(values)
l = []
func(arg1)
grid[-1].append(value)
objs.append(obj)
self.sizer.Layout()
A().B(1, 2)
lines = f.read().splitlines()
query = query.filter(filt)
dill.dump(t, f)
Blob.__init__(self, width, height, color, emphasis, highlight)
self.selected
threading.Thread.__init__(self)
device.open()
glVertex2i(110, 110)
channel.stop_consuming()
[(x, y) for x in a for y in b]
float(s)
reader = csv.reader(f, delimiter=d)
today = datetime.datetime.now()
x = sum(int(digit) for digit in str(n))
entity.before_delete()
self.setLineWidth(0.5)
ax.add_patch(Circle(point, 0.1))
self.log.write(message)
print(your_array[index_array[:10]])
arr.reshape(dim, (n_bins,) * dim)
os.remove(output)
a = numpy.arange(25).reshape((5, 5))
print(G.number_of_nodes())
t.start()
im.putalpha(alpha)
print(b)
inspect.getargspec(members[2][1])
self._callbacks = []
winsound.Beep(17000, 100)
B[~B.client_id.isin(A.client_id)]
np.sqrt(1 - X ** 2 - Y ** 2)
c = y * np.exp(-1j * 2 * n * np.pi * time / period)
f(*args[0])
output.index = output.index.to_datetime()
session.commit()
operator.itemgetter(*b)(a)
self.setAutoFillBackground(True)
Vector(self.x + n.x, self.y + n.y)
temp_file.seek(0)
cache.set(self.COUNTER_CACHE_KEY, 1, self.PERIOD_LENGTH_IN_SECONDS)
(mask * prior_reci + ~mask * (0.1 * prior_reci)).sum(1)
sys.stdout = tmpout
fn(*args, **args)
print(df.columns.tolist())
{a: 1, b: 2}
server.serve_forever()
pool.close()
y = np.random.randn(10000, 10000)
plt.plot(xnew, power_smooth)
app = MyApp(sys.argv)
loop.run_forever()
f1.close()
c.drawImage(Image, cm, cm, inch, inch)
sys.excepthook = myexcepthook
c.wait()
(fwd[:-2] + back[2:]) / 2.0
a = np.eye(N)
pygame.init()
valued.append(int(suby))
a = np.hstack(np.array(a))
s = pickle.load(f)
sort_index
app = wx.App(False)
print(final_regex)
root.withdraw()
doc = lxml.etree.XML(data)
other and self.a == other.a and self.b == other.b
count(x)
PyErr_Print()
t = Tkinter.Text(w)
plt.show()
res.reverse()
print(point.distance(line))
my_dict = {}
numpy.vstack([test, test[::-1]]).T[:(len(test) + 1) // 2]
clock_gettime.argtypes = [ctypes.c_int, ctypes.POINTER(timespec)]
plt.cm.gist_ncar(np.random.random())
G = nx.Graph()
auth_login(request, form.get_user())
b = np.random.rand(5, 4)
any(char in digits for char in value)
print(Counter(alist))
i = iter([(1, 11), (2, 22)])
mylist += [(tup[0], tup[1], list_of_signs[idx1][idx2])]
func()
date_joined = models.DateField()
(lambda x: x).__get__
print(arreqclose_in_list(myarr1, mylistarr))
print(str(selection))
sys.exit(0)
fig, ax = plt.subplots()
print(df)
self.window.show_all()
self.get_db_prep_value(value)
data = {}
self._thread_id
pool = multiprocessing.Pool()
adate - timedelta(days=_offsets[adate.weekday()])
log.addHandler(noop)
V.ravel()
_nextafter(x, y)
numpy.dtype(t)
f2.pack(side=LEFT, fill=Y)
pprint.pprint(dict(os.environ), width=1)
self.figure.delaxes(self.figure.axes[1])
df + 1
dt = numpy.linspace(-t[-1], t[-1], 2 * nsamples - 1)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
new_list.append((elem, input_dict[elem]))
svc.fit(X_train, y_train)
k, self.mapping[k]
df[1] = df[1].apply(lambda x: 1 if x else 0).cumsum()
writer.writerow(writenames)
win.window.move_resize(x, y, w, h)
all_pixels.append(255)
print(df)
self.setCentralWidget(self.tree)
t.__sizeof__()
x[0]
json.load(f)
today = datetime.date.today()
PaginationFormSet
c = cv.WaitKey(7) % 256
mech.submit()
print(x[:, :, (5)])
x[0][0][0] = 11
result.intersection_update(s)
X[-1]
print(is_int_value(x))
print(Example(1))
print(np.std(X, 0) * m.coef_)
[scipy.argmin([scipy.inner(q - x, q - x) for x in X]) for q in Q]
form = formset.form
df.where(~is_duplicate, 0)
x.split()
thread.start()
self.window_is_fullscreen = False
seen.add(k)
ax.set_xticks(pos + width / 2)
[(resMag * (math.cos(a) + math.sin(a) * 1j)) for a in resArg]
r = {}
self.textLayout.setMargin(10)
f = np.poly1d([1, 0, 0, -1])
print(l[i])
s = f.read()
btn.pack()
x = np.arange(0, len(data))
fig, ax = plt.subplots(ncols=2, figsize=(5, 2.5))
print(a)
out.reshape((n, n))
fig, ax = plt.subplots()
a = b[n]
dill.detect.errors(f)
tree = etree.parse(metadata, parser)
word in is_word.words and len(word) > 1
frame.grid_columnconfigure(0, weight=1)
cov / np.dot(s_x[:, (np.newaxis)], s_y[(np.newaxis), :])
fig = plt.figure(figsize=(4, 5))
A[index]
json.dumps(d)
[bar.set_height(hist[i]) for i, bar in enumerate(b)]
upload_file(path)
mysignal.connect_via(app)(listener)
indices = numpy.arange(a.shape[0])[numpy.in1d(a, b)]
dict.__setitem__(self, k, v)
df
pd.__version__
self.src.append([self.src[-1].pop(-1)])
print((r.status, r.reason))
plt.xlim([startTime, endTime])
signal.append(c + corr * signal[-1] + np.random.normal(0, sigma_e))
magneturi
result = solve(m1, m2, std1, std2)
plt.plot(t, s)
lock = mp.Lock()
f.pack(side=LEFT, expand=1)
input.close()
pipe.close()
data.append(float(item.split()[take_col]))
parser = argparse.ArgumentParser()
wb = openpyxl.Workbook()
slither / slither / tests.py
f[2].lower()
np.random.seed(0)
L[a:a + span2] = L[b:c]
r = list(range(start_day, end_day + 1))
df
dt = numpy.arange(1 - nsamples, nsamples)
C()
ranges.append([val, index])
proc.start()
img = np.vstack((c, np.hstack((a, b))))
dt = datetime.datetime.now()
mylist.remove(value)
print(list(d.items()))
f(*args)
q.put(name)
print(x)
fields.insert(bisect(fields, value), value)
ax.add_patch(patch)
vals = [sinval(i) for i in range(quarter)]
dict_writer.writeheader()
context.set_source_surface(self.image, 0.0, 0.0)
input()
tar.close()
np.hstack(lst)
parser = argparse.ArgumentParser()
font = cv2.FONT_HERSHEY_PLAIN
Concate.update({A[i]: B[i]})
self.output.write(result)
print(mylist)
ax.hist(nd, normed=True, bins=n_bins0, alpha=0.5)
response
s.connect((hostname, port))
plt.hist(random_from_cdf, 50)
CATC - ATCAGCATCGACATGCGGCATACG
position = NX.spring_layout(Gh)
p.join()
self._fn(*arg, **kw)
f(1, 1, 1)
d[key] = True
FunctionFlow.start.run(**some_kwargs)
print(repr(array))
cax.pcolormesh(t, r, c.T)
plt.plot([0, 1])
print(l[:N])
print(str(matches))
initialize_necklace()
print(data)
r = redis.Redis()
self._name
self.assertIn(key, set(response.data.keys()))
file.flush()
obj = [line[0].strip(), line[1].strip()]
sm = sys.modules.copy()
decorated_func
app
a[:, :, (i), :] *= v[i]
found.add(relation)
word1word2
word2word1
ax.set_xlim(-10, 10)
skew *= ((m - 1) * m) ** 0.5 / (m - 2)
t.append(yourstring[i * 8:(i + 1) * 8])
obj = getattr(obj, attr_list.pop(0))
logging.getLevelName(10)
self._conn
app = Flask(__name__)
some_b.delete()
print(self.__name__)
cap.release()
app.install(log_to_logger)
decorator
digits = map(str, digits)
date = dt.datetime.today() - dt.timedelta(days=1)
cPickle.dump(gnb, fid)
self.ui.PoseBtn_GridLayout.addItem(spacerItem1, 1, 0, 1, 1)
self.main()
CS = plt.contour(X, Y, Z)
mat = np.random.random((100, 100))
io.StringIO
box.pack_start(combo, False, False)
logger.propagate = False
testdataframe[col].plot(style=style, lw=lw, ax=ax)
ax.figure.canvas.draw()
item.append(10)
d = dict()
sleep(1)
x[:, 1:2, :]
locations = FieldList(FormField(LocationForm), min_entries=2)
person.make_statement(20)
ax.set_yticklabels(nba_sort.index, minor=False)
np.where(states)
moo._min_or_max_axis
b = a[::2].copy()
df.index = pd.DatetimeIndex(df.index)
np.where(a > 5)
ax.set_xlim([xmin, xmax])
{{form.non_field_errors}}
freq.update(line.split())
ax.plot(x, y)
self.fit(X, y).transform(X)
ax.set_ylim(-100, 100)
module1.func1 = self.my_new_func1
t.start()
deleteself.list[-1]
cstring.value
kernelapp.start()
url = urlparse.urlparse(address)
arr = np.roll(arr, num)
f = scipy.signal.lti([1], [1, 1])
print(a.qsize())
array2 = [e for e in array2 if e not in set1]
print(n)
X_train = vectorizer.fit_transform(X_train)
app = QtGui.QApplication(sys.argv)
b = TestB()
f = hstack2((a, b))
b = sorted(a, reverse=True)
reverse_dic[v].append(k)
str2.count(str1)
session.add(g)
signal.signal(signal.SIGUSR1, handle_pdb)
df = df.append(sum_df)
f(*args, **kwargs)
array[0]
G.add_edge(1, 2, weight=7)
colorbar.set_ticks([-0.667, 0, 0.667])
max(l_one + l_two)
result = {}
image = Image.all().fetch(1, offset)[0]
message.save()
sidx = X1D.argsort()
M.dot(M)
pprint(res)
root.mainloop()
a = np.array([1, 0, 0])
list_.append(line[2])
frame1.axes.get_xaxis().set_ticks([])
Something.objects.filter(data__a=1)
m, n = x.shape
self.setLayout(grid)
abs(value)
axs[1].xaxis.set_major_formatter(x_fmt)
pythoncom.PumpMessages()
sp.add_source_from_line(ppa_name)
someFunction(**theDictionary)
mask = np.zeros(img.shape, np.uint8)
lst[num] *= 2
xml.sax._exceptions
a[0][0] = 2
myMap[n] += 1
print(nx.simple_cycles(G).pop()[:-1])
pri = gllhs[0]
fig, axes = plt.subplots(nrows=1, ncols=2)
values = list(select.stripped_strings)
User.client_1_query.filter(User.id == 1).all()
0
dis.dis(b)
nbr_edgeobjects = 0
textwrap.wrap(s, 4)
id = Column(Integer, primary_key=True)
fig = plt.figure()
print(linalg.solve(A, x))
x in range(cls.k)
out = data[np.in1d(tags, goodIDs)]
im = img.load()
res = [key for key in list(freq_count.keys()) if freq_count[key] == high]
plt.plot(list(range(10)))
description = models.CharField(max_length=250)
new_cols = df.loc[:, (cols)] / df.loc[ii, cols].values
cv.Threshold(a, a, 0.5, 1, cv.CV_THRESH_BINARY)
adate - timedelta(days=delta)
p.join()
writer.writerow(combined_row)
fig = plt.gcf()
last_name = models.CharField(max_length=100)
next(second)
self.dot.set_offsets((x, y))
df
print(sublist([5, 90, 2], [90, 20, 5, 2, 17]))
result.pop()
plt.colorbar(im, cax=cax)
ax.scatter(x, y, z, alpha=0.1)
__init__.py
result_dict[len(word)].add(word)
layout.addWidget(self.edit)
result[nI] = func2(zeta[nI])
setattr(foo, k, v)
now = datetime.now()
console_client.cmdloop()
value = Column(String(100))
raise OSError(errno_, os.strerror(errno_))
self.driver = webdriver.Firefox()
v.extend(list(i.items()))
parsed.pprint()
workssheet2.write(row, col, cell_value)
min2(x)[1]
arguments = locals()
content = f.read()
args.func(args.newstate)
i += 1
QtCore.Qt.Unchecked
plt.ylim((-limit, limit))
print(df)
sum(n * 10 ** i for i, n in zip(count(0, -1), a))
ns.extra_file = ns.extra_file if ns.extra_file else ns.filename
(t - B) / A
QTimer.singleShot(200, self.load_content)
ax = fig.add_subplot(111)
extension = entrypoint.load()
dome_something(obj)
handles, labels = pyplot.gca().get_legend_handles_labels()
print(np.array_str(x, precision=2))
main()
get_color(0.5)
original_open(filename, mode)
kmer2count[kmer2] += initcount[kmer1]
np.insert(a, 1, 5, axis=1)
mean += (x - mean) / n
fig = plt.figure()
(1.0).is_integer()
crawler.crawl(spider)
myCards.append(cardList)
wrapped_f
array([0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9])
map(session.refresh, iter(session))
L[0] + listSum(L[1:])
le.setStyleSheet(ss)
out.close()
print(p2.communicate())
a.ravel()[flat_index]
response
np.add.at(out_count, b_idx, b[:, (1)])
A[c1, r1], A[c2, r2] = A[c2, r2], A[c1, r1]
f.__defaults__
new_strs.append(str_record[x])
ebks.append(p1 / p2)
cum = np.hstack((np.zeros((a.shape[0], 1), dtype=a.dtype), cum))
16.6644029617
print(drw)
pmf /= pmf.sum()
pr.enable()
main()
p.print_stats()
out, err = pipe.communicate()
pattern = np.random.rand(PATLEN)
x, y
f.write(tempfile.read())
merged_df
b = [4, 5, 6]
a = np.equal.outer(vect, vect)
curses.flushinp()
print((resp.status, resp.reason))
r = q.T.reshape(-1, 2, 2)
patient_list.sort(key=by_unit_room_bed)
p.put()
_test()
fp.seek(-BOMLEN, os.SEEK_CUR)
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
arr = np.zeros((nrows, ncols))
s = requests.Session()
columns = df.columns.values.tolist()
buf = stream.read(1024)
lst[i:] + lst[:i]
reordered = l[-1:] + l[:-1]
client_connection.close()
b = np.random.rand(6, 5, 4)
httpretty.disable()
mydict.setdefault(key, list())
b = zip(*a)
pubkey.verify_init()
print(_string)
f2 = f2 * np.max(f1) + (1.0 - f2) * np.min(f1)
loop = asyncio.get_event_loop()
[s[i:i + 4] for i in range(0, len(s), 4)]
ax = fig.add_subplot(2, 2, a + 1)
m = graphlab.recommender.create(data)
bucket.configure_versioning(True)
tree_dict = {}
do_something_5()
print((key, value))
ax1 = fig.add_subplot(111)
pd.Series(b[1], df.columns, name=df.index[-1])
a[a.argsort()[-10:]]
distutils.util.strtobool(some_string)
index = d * (d - 1) / 2 - (d - i) * (d - i - 1) / 2
msg.attach(msgAlternative)
v = np.random.normal(size=d)
process = Process(target=greet, args=(string,))
sys.exit(main())
obj.put()
datetime.datetime.fromtimestamp(obj[0][1])
processes.remove(p)
arr = numpy.array(numpy.round(arr), dtype=numpy.uint8)
q = np.empty_like(p)
w.show_all()
bokeh.io.output_notebook()
stdscr.clrtoeol()
os.sys.path.insert(0, parentdir)
plt.hist(data, 50, normed=True)
a = np.arange(10)
result = service.resource().method([parameters]).execute()
x /= x[2]
s.append(im[x - 1:x + 2, y - 1:y + 2])
result.reset_index(inplace=True)
DataMatrix(data, index=dates)
np.maximum.accumulate(mask, axis=1, out=mask)
{{names | safe}}
p2.rotate(angle)
print(sys.argv)
fo.close()
a = list(range(1, 50))
self._handle_request_noblock()
print(root)
regex.sub(lambda mo: dict[mo.string[mo.start():mo.end()]], text)
plt.imshow = my_imshow
print(chambersinreactor)
pattern = np.ones((24, 16), float)
main()
a + b
masterlist.update((x, False) for x in exceptions if x in masterlist)
self.columnconfigure(1, weight=1)
a, b, c, d = result
self.lc = task.LoopingCall(self.announce)
print(hex(id(a)))
copy(args[0])
cherrypy.config.update(confdict)
pathqueue.join()
gibberish(5)
Astars.append(s)
fig, ax = plt.subplots()
np.vstack((a[(0), :], a[1:, :] + a[(0), :] * 1j))
records = Record.objects.filter(project_id=1)
list()
os.kill(int(ps_output), signal.SIGTERM)
x[0]
docfile.close()
print(m.group(6))
a = os.stat(os.path.join(directory, i))
self.clearLayout(layout)
new_class
print(line)
data = s.recv(1024)
abs(2 - 1)
reader = csv.reader(f1)
ax1 = plt.gca()
length = len(text)
self.init_app(app, db)
ax.legend()
main()
print(myline)
ax0a.set_xticklabels([])
ts = np.arange(0, 1, 0.01)
b = np.random.randint(0, 9, (2, 1)).ravel()
n *= 2
r = min(r, n - r)
Base = declarative_base()
print(msg)
main()
1, 8, 8, 8
arr = np.roll(arr, num)
self.write(somedata)
s.mean(axis=0)
vbox.add(image)
grouped = df.groupby([times.hour, times.minute])
start_urls.append(url)
plt.scatter(x, y, c=t, cmap=cm.cmap_name_r)
a = a + 1
ax1.view_init(*init_view)
zip(new_lists, overflows)
num_rejects += 1
transport.close()
window.show()
np.sum(~(a ^ b))
pprint(dict(di))
result = next(x for x in (a, b, c, d, e, default) if x)
app.exec_()
sum(Fraction(1, d) for d in range(1, n + 1))
homebrew / science / opencv
main.run()
md5.update(chunk)
self._b = [A() for x in range(5)]
print(result.get(timeout=1))
result[result.size / 2:]
plt.plot(x, y, zorder=2)
{}
sct_subscript
choices = list(chain(self.choices, choices))
result[key] = row[1:]
x = range(10)
do_something_4()
size = ctypes.c_int()
fruitDB.close()
y[i] += A[i, j] * x[j]
overlap(0, 100, 0, 20)
B = get_A()
deletethe_map[i]
[1, 1],
cv.CvtColor(difference, grey_image, cv.CV_RGB2GRAY)
self.obj[self.key] = val
self.root = Tk()
(1 if text[0] == char else 0) + count(char, text[1:])
y = tf.Variable(tf.zeros([]))
i += 1
ssc.start()
p = [(len(str(x)) + 1) for x in l]
connection.close()
cur_set.append(A[index])
print(doc.xml.web.offset.string)
today = datetime.date.today()
self.reverser = dict()
view.show()
list(takewhile(lambda date: date.year < 2014, tuesdays_of_february))
canvas.config(xscrollcommand=hbar.set, yscrollcommand=vbar.set)
A = pd.Series(list(range(1, 5)))
Session = sessionmaker(bind=engine)
self.closedmax = closedmax
self.slidermax = slidermax
self.slidermin = slidermin
self.closedmin = closedmin
remain += int(i)
json.dumps(d, sort_keys=True)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
main.mainloop()
getMappingsNode(n, nodeName)
df = pd.DataFrame(np.ceil(np.random.rand(1, 10) * 1000))
cj = cookielib.CookieJar()
print(tree.getpath(element))
random.shuffle(a)
handler = logging.handlers.RotatingFileHandler(file_name, maxBytes=10 ** 9)
reader = csv.reader(f2)
label.set_rotation(45)
self._copy_attrs(df)
array.remove(array[0])
dlist.append(d.copy())
Base.metadata.create_all(engine)
parent.insert(parent.index(element) + 1, new_element)
print(str(count).ljust(10), conv)
content = response.read()
print(data)
e.__traceback__
[0.0, 0.95510649, 0.0],
dt = datetime.datetime.fromtimestamp(ts).replace(tzinfo=tz.tzutc())
Base.metadata.create_all(e)
SPECIAL_RULES[name]()
a * b
frame = cv.QueryFrame(capture)
plt.hold(False)
help(module)
mask = numpy.in1d(numpy_array, repeat_set).reshape(numpy_array.shape)
VERSION,
conn.execute(tb_create)
os.fstat(f.fileno())
L[:] = [(i[:1] + i[2:]) for i in L]
sess.run(train_step, feed_dict={learning_rate: 0.1})
zip_longest(fillvalue=fillvalue, *args)
s.format(**d)
False
parser.feed(pstring)
PySys_SetArgv(argc, argv)
self.Artwork.destroy()
server.serve_forever()
matplotlib.matplotlib_fname()
p = multiprocessing.Pool()
self.quit()
app.register_blueprint(account_api)
print(df.loc[idx])
lambda x: x % i == 0
buttonList.append(new_button)
ax.figure.canvas.draw()
lines = f.readlines()[:-5]
args = [4, 5, 6]
threads.append(threading.Thread(target=process, args=(items, start, end)))
model = LinearRegression()
keys = (list(x.keys()) for x in d.values())
plt.bar(counts.index, counts)
z_surface[where(ma.getmask(Zm) == True)] = numpy.nan
server.start()
yaml.add_representer(folded_unicode, folded_unicode_representer)
Decimal(1).exp()
d2[k] = f(v)
ctypes.memmove(ctypes.addressof(self), bytes, fit)
inner
cmap = plt.cm.gray
data = [(x, k) for k, x in enumerate(data)]
d.close()
a[b][0] is a
driver = webdriver.Firefox(firefox_profile=profile)
[1, 1, 1, 1, 1, 1, 1]
myShelve.close()
qs = self.model.autocomplete_queryset()
line1 = f.readline()
outfile.flush()
random.shuffle(choose_from)
np.all(xdiff[0] == xdiff)
self.x2 - self.x1 + self.y2 - self.y1
pp.savefig()
output.append(curr_date)
argmax(enumerate(values))
background = pygame.Surface(screen.get_size())
lst.sort()
max([len(format_field(row[index])) for row in table])
i += 1
g.write(got)
sys.modules.update((mod_name, Mock()) for mod_name in MOCK_MODULES)
lines = list(f)
a2 = a[:]
a ^ b
list(pair(oldList))
x.min(0)
w, h = im.size
d[tup[0]] = {}
cj = cookielib.CookieJar()
sys.getsizeof(sys.getsizeof)
np.argsort(mapper_a), np.argsort(mapper_b)
print(s.query(a_alias, b_alias).all())
do_something()
counts = collections.Counter(test)
np.random.seed(479)
print(win.get_name())
l.append(make_foo(r))
min, max = min(x, y), max(x, y)
root.focus_force()
stdscr.keypad(1)
test(0, 10, 11, 12, 14, 16)
orig_save(self, *args, **kwargs)
y = collections.Counter(x)
f.close()
print(Counter(a) == Counter(b))
img = np.zeros((height, width, channels), dtype=np.uint8)
self.end_headers()
hsv(float(i) / (len(data) - 1))
print(type(node).__name__)
print(ax.get_xlim())
a = []
[50, 51, 52]
all(line in lines or line[::-1] in lines for line in lines_needed)
self.rows = numpy.delete(self.rows, i, 0)
labels.append(line)
f = Foo()
mark_safe(json.dumps(object))
asyncio.get_event_loop().run_until_complete(meth(*args, **kwargs))
next(b)
do_something_5()
print(s1.zfill(5), s2.zfill(5))
B = rand(10000)
print(traceback.format_exc(), file=sys.stderr)
port = int(sys.argv[1])
cameraR.SetPosition(0, 0, 200)
conn.close()
word = line.strip()
line = f.readline()
subplot(212)
G.add_edge(2, 4)
all(c in hex_digits for c in s)
f.seek(0)
ax1 = plt.subplot(1, 2, 1)
random.shuffle(iters)
ex.args = (msg,) + ex.args[1:]
first_name = models.CharField(max_length=50)
fo.close()
font.configure(size=size)
np.transpose(np.array(X.T * (y - X * b)))[0]
app = wx.App(False)
context = self.get_context_data()
q = q.filter(User.id == uid())
print(leaders(xs))
theta = 2 * np.pi * np.random.rand(n)
one.click()
radii * exp(1j * angles)
tunnel._rport
pdb.set_trace()
pipe.execute()
build()
self.lock.release()
self.do_egg_install()
data.most_common()
y = np.array([(0, -5), (1, 0), (2, 5), (5, 20), (6, 25)], dtype=dtype)
pool.close()
rec_split(s)
exit()
ts.to_pydatetime()
list(in_order(x))
queryset.query.__str__()
server_A_thread.start()
os.wait()[0]
sysconfig.get_platform()
cur.close()
row = next(csv.reader([line]))
one_array.append(5)
r.status_code
deepest_list, max_depth
baz.__doc__
app = Flask(__name__)
print(datetime.datetime.now())
ax.margins(0.05)
browser = webdriver.Firefox()
print(key, item[key])
list(filter(invent_some_convoluted_name, list(range(10))))
Base.metatada.bind = op.get_bind()
stations[w] = i
-24.1529840248
-7.87165586175
-24.9012815104
-7.44222705099
-6.25705487929
-7.141616656
-15.0906961724
sd.sleep(duration * 1000)
sys.__stderr__ = dummyStream()
self.SaveSettings()
print(i.get())
new[k].extend(v)
plt.imshow(im)
msg.set_payload(zf.read())
curs.execute(sql, dates + [id])
data = json.loads(json_string)
img.view(np.uint8)
fig = plt.figure()
s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
self.other_field = other_field
merged = pd.concat(dfs, axis=1)
bits = int(max(8, math.log(num, 2) + 1))
x = [(i, i * i) for i in range(5)]
new_list = []
tk.Frame.__init__(self, *args, **kwargs)
add.apply_async(args, kwargs, task_id=i)
int_list
a[2] = 55
culled_list
iter([item])
cb.stateChanged.connect(self.changeTitle)
m.drawcoastlines()
self.nout = 0
print(list(kwargs.keys()))
writer.writerow(new_row)
student_tuples.sort(key=itemgetter(2), reverse=True)
Clothing | Menswear | Pants | Pajamas
rs = (grequests.post(u, data=params) for u in urls)
print(p.x, p.y)
df
funcfile.close()
do_something_4()
print(df)
bucket = conn.get_bucket(your_bucket)
a = np.array([5, 4])[np.newaxis]
text.translate(tbl)
display(Image(filename=imageName))
allkey = {key for dictio in alldict for key in dictio}
print(nx.topological_sort(g))
B = lfilter([a], [1.0, -b], A)
foo.py
p.join()
cursor.execute(cql_statement, rename_dict)
self.triangle_down_color = 1, 0, 1, 1
matched.append(dict(group))
__file__
n, d = divmod(n, 256)
dst.SetProjection(match_proj)
self._queue.join_thread()
x = np.linspace(0, 6, 200)
b = np.zeros((N, N + 1))
print(repr(isanything))
c = Counter({k: v for k, v in list(c.items()) if k not in bad_words})
print(soup)
path = os.path.join(basepath, fname)
ctx.set_source_rgb(1, 1, 1)
self.web_view.loadFinished.connect(self._load_finished)
print(a)
df.ix[(df.num - x).abs().argsort()[:5]]
self._array[self._index]
f = Foo()
print(books[i].price)
blocks[1][0]
pickle.dump(biverses, arquive)
self.data.__setitem__(key, value)
[k.key for k in set(IPKey(k) for k in workers)]
print(page.mediaBox.getUpperRight_x(), page.mediaBox.getUpperRight_y())
file_path = filename.split(os.sep)
help(zip)
print(line)
tree[x][y][z].append(value)
conn = engine.connect()
print((date, enumerate(events)))
mat = lil_matrix((len(arr), len(arr)))
ZS.append(row)
self.taskLogger.__exit__(status, retval, task_id, args, kwargs, einfo)
soup = BeautifulSoup(string)
seq.set_seqs(a.lower(), b.lower())
sys.exit(application.exec_())
rows = cur.fetchall()
print(leadingzerocounts)
print(datetime.now() - startTime)
new_genpost.save()
G.add_edges_from([x, temp.pop()] for x in L2)
print(list(result_strings))
self.Show(False)
self.update(dict(list(parent_element.items())))
mylib.Add.argtypes = [c_int, c_int]
float(op)
reader = PdfFileReader(f)
np.unique(a)
self.response.out.write(self.dump_csv())
pool = multiprocessing.Pool()
tmp = tmp.reshape(2, 2, 4)
hide_spines()
fig.show()
header = {k: v[0] for k, v in header.items()}
YOOOO
print(d[keyList[i + 1]])
fig = plt.figure()
S = myfile.read()
raise MyCustomException()
gtk.main()
plt.show()
sum(x1 * y2 - y1 * x2 for (x1, y1), (x2, y2) in pairs) / 2
struct.unpack(fmt, astr)
pdf_reader = PdfFileReader(f)
ax1.set_ylim(0, 1)
m = np.tril(a) + np.tril(a, -1).T
combined[1::2] = pos
client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
fig = pyplot.figure()
df = ts.reset_index()
plt.plot(b, a2)
arr = numpy.array(arr)
print(os.path.abspath(fullname))
print(a.T)
app.exec_()
X = X.T
print(data)
d = json.loads(text)
p = argparse.ArgumentParser()
self.vLayout = QtGui.QVBoxLayout()
foo()
data = resp.read()
newfunc
pool = Pool(num_items)
p.acquire()
title = models.CharField(max_length=40)
x, y, z = int(x) + 1, int(y) + 1, int(z) + 1
sys.stderr = UTF8StreamWriter(sys.stderr)
res = client.get_job_status(jr)
p.stdin.write(the_input)
f, x, y, z = generate_data(nobservations, a, b, c)
ax.set_xticklabels(row_labels, minor=False)
True
tornado.ioloop.IOLoop.instance().start()
A[:, (0)] = np.log(x)
setattr(cls, attr, prop)
soup = BeautifulSoup(tidy_document(browser.response().read())[0])
[lst[round(division * i):round(division * (i + 1))] for i in range(n)]
temp_csv.seek(0)
signal.alarm(0)
0
print(len(x.tostring()), len(dumps(x)))
type(float(s))
plt.title(title)
A.__init__(self, *args)
Doc.images.all()
problems = False
ax.plot_surface(xx, yy, z, alpha=0.2, color=[0, 1, 0])
newImage.paste(im, (x1, y1, x1 + old_width, y1 + old_height))
xyB[:, (0)] *= lengthB / (xyB[:, (0)].max() - xyB[:, (0)].min())
screen_height = root.winfo_screenheight()
x = np.random.random(1000000)
unicode_text = f.read()
print(msg.SenderName)
sel = Selector(response)
MySerializer
_(calendar.day_name[0])
GL.glLoadIdentity()
request.add_data(data)
deleteself.thisptr
grouped_cc[ki].add(kj)
grouped_cc[kj].add(ki)
True
pd[0].append(1)
s.any()
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
isinstance(val, int) or isinstance(val, float) and val.is_integer()
main()
nw[0]
sum(a, [])
b[:, :, (2)]
val = d[key]
types.FunctionType(new_code_obj, f.__globals__)
x = np.random.randn(1000)
data[row[0]] = row[1:]
x.shape += 1,
root.withdraw()
ArgumentParser.add_subparsers()
output
clf()
fig.show()
x = numpy.array([Foo(), Foo()])
print(x)
platform.version()
columns = zip(*cursor.description)[0]
result = cache.get(cache_key)
print(M.shape, Msmall.shape)
clientsocket.send(msg)
self.table = QtGui.QTableWidget()
s.add(a)
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
vals = np.array([color1, color2], dtype=np.uint8)
instance.put()
print(msgpack.loads(x))
self._bar
e.extract()
result = recursive_dict()
self.oldText.tokens.clear()
app = Flask(__name__)
control.SetPosition((10, 10))
print(data)
individuals.append(individuals.loc[1])
self.x += 1
sizer_1.Add(self.panel, 1, wx.EXPAND | wx.ALL, 0)
self.workers.release()
self.queue[index]
session.query(Beard, Moustache).select_entity_from(stmt)
self.assertEqual(99, s)
a = np.array(a)
f.seek(n)
index[:-1] = groups[1:] != groups[:-1]
x = np.arange(-5, 5)
plt.ylim((1e-20, 1e-10))
x, y = [], []
some_code()
id = Column(Integer, primary_key=True)
y, x = np.histogram(df, bins=bins, normed=True)
logger.propagate = False
pool.join()
x()
html - page - context(app, pagename, templatename, context, doctree)
app.exec_()
print(content)
pypitest
user = request.user
print(tmp.index(K[-N]))
elem.send_keys(Keys.RETURN)
server_socket.listen(1)
df
self.figure, self.ax = plt.subplots()
gdb.start_event_loop
cur = [[14, k, j] for j, k in zip(rows[14], list(range(15)))]
output, error = sp.communicate()
html = response.read()
y = list(max_elements.values())
s = socket.socket()
self.image = gtk.Image()
scipy.nan
i += 1
example()
self.a[-1] = self.z[-1]
fig, axs = plt.subplots(2, 1)
self.mplvl = QtGui.QWidget(Form)
root = tk.Tk()
df.min(axis=1)
stack.append((prev_indent, prev_tree))
ipython - -no - banner
dis.show_code(a_long_tuple)
blo += 1
dic.get(key)
os.chdir(savedir)
------models.py
b = a.copy()
df[1]
print(i)
i = 0
map.close()
test.reshape(-1, 2)
PrintLn(i)
out, err = proc.communicate()
_curried
sys.argv[1]
random.choice(list(open(WORDS_FILENAME)))
counts[char] += 1
db.init_app(app)
os.symlink(target, symlink)
file.flush()
temp_rdd.toDF(schema).printSchema()
len(sall)
df = pd.DataFrame(rows, columns=cols)
rsp.raw._connection.sock.getpeername()
set([y, x, 0])
zip(a, b)
configs / __init__.py
self.after(4000, self.draw)
sigmoid(0.458)
fig = plt.figure()
smtp.ehlo()
savetext(filename, a.reshape(1, a.shape[0]))
setattr(namespace, self.dest, values)
comb = itertools.product(uk_rock_stars, uk_pop_stars, us_stars)
h = np.zeros((2, 2, 1))
ax.plot(matrix[(i), :])
foo = timeit(foo)
logger = logging.getLogger()
output_files[i].close()
setup_environ(settings)
10 * -1
paw_code[diff.argmin()]
self.dependency.__enter__()
pygame.event.pump()
session.visit(my_url)
model = Sequential()
False
default_font.configure(size=48)
crawler.start()
output.append(x)
outfile.write(line)
data = heapq.nlargest(2, enumerate(my_list), key=lambda x: x[1])
L.extend([some_mutable_object for x in range(10)])
c.setopt(pycurl.MAXREDIRS, 5)
text
ax.set_position(ax._orig_position)
N = data.shape[1]
output = np.zeros_like(foo)
header = [next(f) for _ in range(header_len)]
ax = plt.subplot(122)
self.image.url
delete_bar
yaml.dump(d, yaml_file, default_flow_style=False)
myimages.append([imgplot])
next(iterator)
but.pack()
y_true = np.array([0, 1, 0, 0, 1, 1, 0, 1, 0])
func(*args, **kwds)
result = [(item, count(item)) for item in set(the_list)]
model = model.fit(X, y)
result = []
sys.stdin.read()
m = numpy.rot90(m, k)
db.commit()
[0] * -1
self.flush()
create_browserid_user(kwargs)
a = [7, 14, 0, 9, 19, 9]
theta = np.linspace(0.0, 2 * np.pi, N, endpoint=False)
[number] * int(factor)
plt.annotate(annotation_string, xy=(0.5, 0.5))
l.count(True) == 1
hashlib.sha1(url).hexdigest()[:10]
PyErr_Clear()
my_array.append(e)
ax.add_line(line)
(x < 0).sum()
out = np.zeros((N, shp[0], N, shp[1]), dtype=int)
image = Image.open(image_string)
c.close()
print(args)
leng.count = 0
plt.subplot2grid((4, 4), [2, 0], 2, 2)
urlparse.urlunsplit((scheme, netloc, path, qs, anchor))
len(self._choices)
ax = fig.gca()
axes[2].hexbin(x, y)
counts = defaultdict(int)
main()
self.toolbar.addAction(action)
o.close()
x, y = x.difference(y), y.difference(x)
f.write(png_recovered)
h = np.zeros((2, 2, 2))
img = np.array(img)
fcntl.fcntl(fd, fcntl.F_SETFL, flags_save)
ax.set_xticks(xlabels)
fig = plt.figure()
tf.add_n([tf.nn.l2_loss(t) for t in list_o_tensors])
soup = BeautifulSoup(r.text)
print(row)
i += 1
print(next(csv.reader([c])))
self.store.append(data)
self.setLayout(layout)
apps2
len(L1) == len(L2) and sorted(L1) == sorted(L2)
df.ix[row_pos]
list.focus(items[0])
subprocess.check_call(cmd.split())
self._bar = value
[[next(it) for c in g] for k, g in grouped]
unquote(unquote(s))
newlist = []
ip.release()
logging.basicConfig(stream=sys.stderr)
image_y[:, :] = image_yuv[:, :, (0)]
ip.close()
any(it) and not any(it)
x = numpy.linspace(0, len(y) + 2, 100)
openlist.put((heuristicf(neighbor), node(neighbor, current.g + 1, current)))
a = np.array([True, True, True, False, False])
q.append(next(i))
main()
print(a)
rpy2.robjects.vectors.DataFrame(od)
ex[0]
urllib.request.urlopen(quoted_url)
sys.path.insert(0, parentdir)
self.searchobj
os.remove(path)
self.deal()
string.Formatter().parse(s)
l.append(self.gears[x][index])
user_input = default
plt.rgrids(list(range(5, 20, 5)), angle=290)
b = b.add(1).cumprod()
sum(utf8_char_len(c) for c in s)
math.hypot(p1[0] - p2[0], p1[1] - p2[1])
n += 1
os.setresuid(0, 0, -1)
exit()
print(dot(M0, v))
cr.set_source_rgba(0, 0, 0, 1)
result = joiner.join(result)
results = model.fit()
ax.set_ylim(-10, 10)
print(cur.fetchall())
df2 = df1.div(df1.sum(1), axis=0)
sys.__stdout__ = dummyStream()
thefile.seek(-len(line), 1)
dict.__setitem__(self, key, self.default_factory(key))
result = func(*args)
print(json.dumps(d))
client = paramiko.SSHClient()
response = HttpResponse()
self.add(data)
self.save_m2m()
output = StringIO.StringIO()
process = multiprocessing.Process(target=foo, args=(to_self,))
df
print(len(cj))
fig = plt.figure()
print(row[1:12])
a = np.random.uniform(0, 10, size=10)
doSwim(where, why, **kwargs)
result.append(word)
sys.exit(1)
y = numpy.array(x)
f = StringIO.StringIO()
shmdt(shmid)
{buildout: software - parts}
c = b.copy()
self.button1.clicked.connect(self.handleButton)
abs((d2 - d1).days)
ax = plt.gca()
self.lock.release()
print(line)
self.tstore.clear()
Mailbox.user(user)
Image()
cache[object_to_cache] = object_to_cache
df.t.dt.normalize()
deletegraph[i]
print(isinstance(MyClass(), MyClass))
print(type(fresult.col1.iat[2]))
count2 += 1
u = np.sin(np.pi * x) * np.cos(np.pi * y) * np.cos(np.pi * z)
parser = ElementTree.XMLParser(recover=True)
handle.write(block)
pylab.show()
app = Flask(__name__)
z = [0, 0, 0]
ax.margins(0.01)
words = sum(c.isalpha() for c in s)
cv.SetImageROI(newCanvas, (image.width, 0, img0.width, img0.height))
a.call_me()
L = list(range(0, 101, 10))
print(np.max(a, axis=axis))
result = np.empty((27, 27))
plt.show()
ax.set_yticks(T)
print(sess.run(parsed, feed_dict={raw: my_data}))
r = np.sqrt(x ** 2 + y ** 2)
soup = bs(html)
a[2] is b[-2]
now = time.mktime(time.gmtime())
self.cursor.close()
reverse_d[value] = key
cursor = connection.cursor()
output.extend(seq[1:])
btn.Bind(wx.EVT_BUTTON, self._onShowCntrls)
pprint.pprint(dict(groups))
b, c = indices = np.sort(np.random.randint(size + 1, size=(2, size)), axis=0)
datetime.now()
s += A[k] * B[k]
the_dict
self.failureResultOf(self.o.failure()).trap(ConnectionRefusedError)
output = [(0) for x in range(6)]
_.flatten()
fruits[1]
code_object.co_stacksize, code_object.co_flags, code_object.co_code
print(mail.getwelcome())
df.groupby(0).mean()
pythons_psutil.append(p)
r = [ran.random() for i in range(1, 100)]
t, y = scipy.signal.dstep(sysd_ss)
self.locator.sub(self._doreplace, s)
socketIO.wait(seconds=1)
time.sleep(10)
start = time.clock()
self.fields.pop(field_name)
main()
fig, ax = plt.subplots()
foo(*args, **some_args)
reader = csv.DictReader(csvfile)
fig, ax = plt.subplots()
process.stderr.close()
username = models.CharField(max_length=100)
b = a[:]
timezone.make_aware(date, timezone.utc)
text.see(END)
env = Environment()
self.__copy__()
p = Pool()
data = data.reshape(len(data) / num_channels, num_channels)
today = date.today()
column_entry.show()
self.local_storage._save(filename, content)
line = sys.stdin.readline()
wrapper
plt.gray()
bSizer.Add(button5, 0, wx.ALL, 5)
print(data[np.r_[np.diff(id), True].astype(np.bool)])
a = datetime.datetime(2015, 10, 1)
my_list.append(float(item[0]))
tabrows.append(row)
self.thread.setDaemon(True)
temp = scaler.transform(temp)
time.sleep(5)
pprint.pprint(res)
df = DataFrame(d)
PyErr_SetString(p_eigen_python_error, msg.c_str())
writer.writerow(row + [message])
X, Y = np.meshgrid(x, x)
utc_dt = datetime.utcfromtimestamp(ts)
app.internalerror = myinternalerror
d[i] += 1
print(len(s))
Py_DECREF(py_string)
heapq.heappop(self._data)[1]
br.set_cookiejar(cj)
os.remove(os.path.join(root, name))
print(scapy.__file__)
z = np.tensordot(p2, x, axes=([0, 2], [0, 1]))
h.setdefault(x, []).append(y)
x = np.arange(W)
Subscript
samples[random.randint(0, n_samples - 1)] = line
notifier.loop()
test = df.drop(train.index)
sorted([1, N, 0, 9999, sys.maxsize])
tuple(a)
qlock.acquire()
proc.terminate()
X = np.random.normal(size=N)
g = f()
print(x)
diffs = (df.sign.diff() != 0).cumsum()
pylab.show()
zip(a, b)
NSERC_CB04_A0401
session.commit()
[line.strip() for line in foo if not line.isspace()]
julia > ma.is_masked(x)
49800000000
4000000000000000000000000000000
frame = inspect.currentframe()
print(list(multi_d.items()))
geocalc(-6.508, 55.071, -8.886, 51.622)
self.username = username
a = np.arange(10)
data = etree.parse(fname)
filename = traceback.tb_frame.f_code.co_filename
plt.draw()
interpreter.process_page(page)
p = Process(target=multiply, args=(5, 4, queue1))
d.year
print(np.array(data))
self._name
array([math.atan2(y, x) for y, x in zip(diff(y1), diff(x1))])
cap.set(cv.CV_CAP_PROP_FRAME_HEIGHT, int(y))
print(a % tuple(b))
r = np.linalg.norm(R)
file.close()
time.sleep(6)
demo_kalman_xy()
a += b_ext[start_idx[j]:start_idx[j] + n]
count(0, 0)
sets.append(x)
a.py
self.handlers[event].add(callback)
sys.exc_clear()
self.__initialized = True
ax = plt.gca()
A[:, (1)] = 1
b = np.array([0, 1, 0, 1, 0, 1])
print((a, b, c))
sc = proprocessing.StandardScaler().fit(X)
main()
ax = plt.gca()
self.md5.update(o)
print(df.max(axis=1))
signal.signal(signum, _gogentle)
item.setPos(position.x(), position.y())
print(byall())
fig = pyplot.figure()
self.dictList[item][self.key]
d[k] = d[k][0]
string[i:i + len(keyword) + 5]
df.show()
callback(req)
util.run_wsgi_app(application)
int(text) if text.isdigit() else text
plt.grid(True)
cur = con.cursor()
TextConverter.__init__(self, *args, **kwargs)
ax.add_patch(patch)
cs.send(c + 1)
self.thisptr.getA()
self.addItems(self.list_two)
self.splitter.addWidget(self.view)
stringFrom(v)
print(list(splitter(str, split_points)))
p.save()
my_thread.join()
first_day = dt.replace(day=1)
df1 = df1[~dupe_rows]
items.sort(key=keys.__getitem__)
print([(r / s) for r in raw])
generate_random_data(latitude, longitude, 5)
app = Flask(__name__)
C = M.T.reshape(1, ncols, 1, nrows) * M.T.conj().reshape(ncols, 1, nrows, 1)
x = np.ma.array(x, mask=mask)
m = l + [(i + 1) for i in l]
self.value
fig = plt.figure()
x, y = np.meshgrid(np.arange(10), np.arange(10))
func(*args, **kwargs)
print(m.groups())
r = requests.get(login_url, cookies=jar)
setup(**configuration)
freqs = np.fft.fftfreq(len(x))
cursor = cnxn.cursor()
soup = BeautifulSoup(resp.get_data())
np.diff(np.where(np.diff(np.hstack([False, a, False])))[0])[::2]
qs = cgi.parse_qs(urlparse.urlparse(url)[4])
parseLog(sys.argv[1])
location, (latitude, longitude)
print(match.groups())
x * x
tz.normalize(dt.astimezone(tz)).time()
self.axes.plot(t, s)
np.abs(A[:, (np.newaxis)] - B)
print(list(Squares(5, 50)))
reader = unicode_csv_reader(open(filename))
cal_window.stick()
result = []
image.save(output, format)
keys.add(entity.getKey())
list(test)
-ntrees
[]
out_file.write(in_data)
os.close(fin)
int(x)
abs(new - old).max()
print(func())
logger.setLevel(level)
i, j = np.ogrid[0:5, 0:5]
sess.run(train_step, feed_dict={learning_rate: 0.01})
self.child.start()
pubkey.assign_rsa(rsa)
sorted(files, key=numericalSort)
fig = plt.figure(figsize=(5, 5))
pool.apply_async(f, args=(i,))
client.settimeout(60)
B().a1()
{k: (x.get(k, []) + y.get(k, [])) for k in set(x).union(y)}
response
src_dt = src_tz.localize(dt)
pylab.colorbar()
pdb.set_trace()
y = lab[:, :, 1:]
print(t.timeit(1000))
E(X, X > Y, evaluate=False)
[tuple_array[i] for i in range(0, array.len)]
index, word = line.split()
tk.Frame.__init__(self, parent)
df
list.append(self, a)
do_something_with_connection(b)
print(bv)
driver = webdriver.WhatEverBrowser()
print(char, char.isalpha())
writer.write(tup)
result = seq.index(first_val)
NULL
self.layout.addWidget(self.listWidget)
json_data = json.dumps(response)
cand[i] += 1
cipher = AES.new(self.key, AES.MODE_CBC, iv)
len(s)
c = db.cursor()
self.pushes
draw.ellipse((0, 0, rad * 2, rad * 2), fill=255)
ax1 = fig.add_subplot(111)
model = model.fit(X, y)
opener = urllib.request.build_opener(authhandler)
df2 = pd.DataFrame(values, index=index, columns=columns)
genes_dict[row[0]] = row[1:]
form = UploadFileForm(request.POST, request.FILES)
a = datetime.datetime(2011, 8, 1)
df.head()
workbook.add_worksheet(sheet_name)
True
ax.text(p.get_x() + 0.05, height + 1, df.columns.levels[1][i])
fig.tight_layout()
g = df.columns.to_series().groupby(df.dtypes).groups
_find_root(os.path.dirname(start), stop)
diff = difflib.ndiff(open(file1).readlines(), open(file2).readlines())
NULL
PythonEngine.Shutdown()
decorator
time.sleep(wait_time)
s.set_xticks(ind + 0.5)
cols = tuple(df.columns)
a = dict([next(iter(x.items())) for x in foo])
ceiling_key(d, 2)
f.read()
offset += len(line)
f.close()
(np.arange(n) >= arr[:, (np.newaxis)]).astype(int)
fd = sys.stdin.fileno()
main()
s = pd.Series(hourly_data.flatten(), index=new_ind)
set_lang(LANG, pylons_config=conf)
1, 2, 1
remote_api.get_cached_name(user.id)
colors = plt.cm.jet(np.linspace(0, 1, 10))
irenL.SetRenderWindow(renWinL)
c = a / (b * 1.0)
numpy.save(f_handle, arr)
plt.contourf(data, cmap=cmap, levels=levs)
lst.append(d)
logger = logging.getLogger(__name__)
[conv(val) for conv, val in zip(castings, line)]
dis.dis(make_adder)
[0.67008007, 0.65984005]
self.loop.run_forever()
p = Process(target=do_work, args=(work, results))
[i for i, j in enumerate(x[:-1], 1) if j != next(i_x)]
a = np.arange(size_a)[::-1]
time.sleep(5)
app = QApplication(sys.argv)
my_field = models.CharField()
nx, ny = np.array(ndata).T
out = np.split(C, np.flatnonzero(R[1:] > R[:-1]) + 1)
m = np.max(lens)
signal.signal(signal.SIGINT, self._handle_SIGINT)
[(c.name, c.get_items()) for c in forms[4].controls]
e == N or i > 0 and L[i - 1] == N or i < len(L) and L[i + 1] == N
self.obj = obj
row.Add(m_close, 0, wx.ALL, 10)
test(*args, **kwargs)
strings.sort()
d = {}
inputElement.send_keys(Keys.ENTER)
print(a, b, c)
f.close()
print(max_seq_len)
lookup.sub(lambda x: trans[x.group()], string)
self._table.append(self._dealer.nextCard())
changes.extend(valchange(d1[k], d2[k], k))
x.max(0)
rPM.restype = wintypes.BOOL
it = heapq.nlargest(20, enumerate(allrows), key=lambda x: x[1][2])
i += 1
print(list(reversed(astr.translate(deleter).split())))
handles, labels = ax.get_legend_handles_labels()
sum(1 for i in range(1000000) if str(i) == str(i)[::-1])
cal.events.add(event)
rsa = RSA.load_pub_key_bio(bio)
plt.plot(x, p)
d = dict(zip(a, b))
(1 + erf(x / sqrt(2))) / 2
oodict[line[0:7]] = line[12:]
process(chunk)
self.NEWATTRS = []
self.HTMLDATA = []
a = 2
np.concatenate(ar)
soup = BeautifulSoup(html)
y = [1, 2, 0, 1, 1, 2]
people = list(people_dict.values())
x[slice1][slice2]
c.sum() / c.size
decorator
min(i.number for i in iList)
seen.add(line)
plt.axis([-50, 50, 0, 10000])
GetLogicalDrives.call()
print(f())
a.get_position().bounds
out_view[i] = in_view[i]
self.panel.SetSizer(sizer)
print(random_numbers(5, 100))
a.str
shutil.move(source, destination)
self.lock.release()
globals()[k] = my_decorator(v)
NULL
reader = csv.DictReader(StringIO(testdata))
output = json.load(sys.stdin)
random.seed(42)
help(png)
fields = list(fields)
files = [open(file, mode) for file in files]
self.load(buffer, size)
device.close()
iter([])
self.layout.add_widget(self.canvas_widget)
response = urllib.request.urlopen(req)
result = p.wait()
lines, labels = ax1.get_legend_handles_labels()
print((fully_qualified(f), f.location))
print(ted1(df))
y = scipy.signal.lfilter(h, 1.0, x)
print(i, elem)
multiprocessing.active_children()
web.input(**kwargs)
lines = []
a = numpy.zeros(lnum.bit_length() // 8 + 1, dtype=numpy.uint8)
True
mat1.append(temp)
func(*arg, **kwarg)
np.sum(v[r <= 10])
print(line)
use_setuptools()
print(np.real(roots[i]))
foo.b
a = Fraction(1, 2)
foo = Foo()
encoded = base64.b64encode(image_binary_data)
im = Image.fromarray(np.uint8(cm.gist_earth(myarray) * 255))
write_f.close()
next(iterator)
self.threads[i].start()
data = np.fromfile(file=fd, dtype=np.double).reshape(shape)
array[i, j] = 0
word1 in rhyme(word2, 1)
point(self.x + oth.x, self.y + oth.y)
app.exec_()
canv.pack()
ax.plot(list1)
p[2] = q[2]
sums = data_in_group.sum(axis=1)
plt.show()
sorted(strings)
todatetime(endtime) - todatetime(starttime)
ax2.set_yticks(numpy.arange(y1 - 1, y2 + 1, 0.5))
[(0, 4), (22, 6)]
c = a.cumsum()
stdscr.keypad(0)
a = list(range(10))
result[length] = dict((k, v) for k, v in groups)
numpy.sin(value)
objects = CustomManager()
self.buffer.write(data)
diff = zfit[:, :-1] - zfit[:, 1:]
out = 100 * np.nansum((a[:, (R)] - a[:, (C)]) / a[:, (C)], 0)
print(datetime.utcfromtimestamp(ts))
df
cursor.execute(query_string, query_args)
list(itertools.zip_longest(*uneven))
self.__getitem__(key)
[1, 2]
print(x)
f1.flush()
axe.set_xticks((np.arange(0, 2 * n_ind, 2) + 1 / float(n_df + 1)) / 2.0)
q.put(ret)
main()
t.start()
dis.dis(foo.__code__.co_consts[1].co_consts[2])
tour
id = db.Column(db.Integer, primary_key=True)
map(lambda range: a[range[0]:range[1]], zip(start, end))
ch1.send(ch2)
t = np.arange(10)
set(first).intersection(*others)
pool.join()
file.seek(here, os.SEEK_SET)
sleep(0.1)
tokens = a.split()
dict(map(ascii_encode, pair) for pair in list(data.items()))
table.setColumnWidth(1, 80)
s.connect((HOST, PORT))
mask.shape
conn.begin()
query.split()
nk = set(a).intersection(b)
content = f.read()
pygame.quit()
resp.geturl()
p.map(processChunk, li)
time.sleep(1)
print(s)
i = np.array(list(range(4))[::-1] * 6).reshape(a.shape)
df2 = df.loc[np.repeat(df.index.values, df.n)]
result = pd.DataFrame(names_and_values)
layout.save()
self._tunnel()
find_nearest_above(np.array([0.0, 1.0, 1.4, -2.0]), -1.5)
print((i, count_nicematrices(i, i)))
aux = matriz
x + 1
self.test = record_log(self.logs)(self.test)
self.inspector.hide()
foo = Foo(mock_helpers)
sys.exit(-1)
[1, 0, 0, 0, 0],
f()
rsa = RSA.load_key_bio(bio)
clientSocket.send(msg.encode())
v[:] = v - 1
t = Team.objects.get(pk=168)
fig = plt.figure()
print(domain.group())
painter = QtGui.QStylePainter(self)
this.all()
aw2.but.clicked.connect(update_plot)
cb.move(20, 20)
print(tag.text)
qs = MyClass.objects.all()
map(lambda index: get_column(pyQueryRow, index), range(0, 12))
r.findall(x)
doc = etree.fromstring(xml)
print(x[i])
p.tags.all()
p = [sum(p[:i]) for i in range(len(p))]
d = deepcopy(d)
any(x in MyDict for x in MyList)
cython < cython_file > --embed
print(line)
k, self.__dict__.pop(k, d)
sys.exit(app.exec_())
df.info()
data[0]
self.reporter.on_close(self.stats, {})
c = np.array([element for i, element in enumerate(a) if mask[i]])
xlock.release()
writer = csv.writer(ftmp)
skel = np.uint8(skel)
self.window.show()
first_digits[number]
a.get_x()
print(htmldiff(doc1, doc2))
result.update(mult_comb(tuple(factors2)))
parser = argparse.ArgumentParser()
QtCore.QRectF(0, 0, w, h)
df = pd.DataFrame(np.random.random((4, 4)))
plt.figure()
cls()
tostr(toval(s) + 1, minlen)
it.ifilter(lambda x: unique([b.c for b in x]), combos)
viewer.kill()
loop.run_forever()
b = mechanize.Browser(history=NoHistory())
_HEXDEC[triplet[0:2]], _HEXDEC[triplet[2:4]], _HEXDEC[triplet[4:6]]
fp.close()
rdd.filter(lambda line: line != header)
setup_envion(settings)
hessian(x)
window = Tk()
cls.change_mro = True
output = po.communicate()[0]
r.url
bool(aware_dt.dst())
id = Column(Integer, primary_key=True)
pypi
print(dt.item())
s
form = QuestionForm(request.POST, instance=question)
stack.append([i])
day_list.index(inp)
client.close()
AC_PREREQ([2.69])
signal.signal(signal.SIGALRM, signal.SIG_IGN)
webbrowser.open(fetchUrl)
myOjbect.doStuf().doMoreStuf().goRed().goBlue().die()
all_messages.extend(rs)
application = config.make_wsgi_app()
print(0)
source.close()
pool.close()
data.sort()
ind = np.argpartition(a, -4)[-4:]
str(timedelta(seconds=c.seconds))
output, err = p.communicate()
jsonify(results=d)
print(best1)
self.__output, self.__error = cmdp.communicate()
y = np.linspace(0, 2 * np.pi, 100).reshape(-1, 1)
print(repr(line))
texts = (x[1] for x in posts)
r.request.send(anyway=True)
a._log
exec(f.read(), globals(), locals())
duration(video_file_path)
cvtColor(src, gray, CV_BGR2GRAY)
df2 = pd.DataFrame(df)
df
HttpResponse(t.render(Context()))
main()
timeout.run()
profile = user.get_profile()
self.wfile.flush()
np.PyArray_ITER_NEXT(ito)
t.start()
g(f(*a, **k))
print(s)
triplets[iT].append(listB[-1])
t * p / c
my_list.append(func)
print(df)
new_inlist.sort(key=lambda x: x.split(separator)[1])
root = logging.getLogger()
server.shutdown()
my_dict = {}
--Important
df
yourThread.cancel()
Testing(2 / 2)
B = [0, 0, 1, 1, 1, 1]
print(output_dict)
problem.main()
fig = plt.figure()
pd.Series(s.values[z], s.index.values[z], name=s.name)
C = np.array([[np.linalg.eigvals(m) for m in v] for v in B_blocks])
print(browser.page_source)
print(seq[1::2])
results = DataFrame(results, index=df.columns, columns=df.columns)
stdout, stderr = p.communicate()
filename = sys.argv[2]
queue.put((tag, line), block=True, timeout=60)
csX.m = X.shape[0]
sorter = np.argsort(perm[::-1])
f.seek(start + 1)
self.de.setText(str(self.current))
f.close()
list(combinations(A, 2))
file_path = os.path.dirname(__file__)
type.__new__(cls, name, bases, dct)
wb = Workbook()
fig = plt.figure()
raise NotImplementedError
getcontext().prec = 100
next(g)
imp.load_source(name, path)
driver = webdriver.Firefox(firefox_profile=fp)
y = data[:, (1)]
server.sendmail(FROM, TO, message)
Py_DECREF(module_name)
cursor = cnx.cursor(named_tuple=True)
rank += permutation_rank(seq[1:]) if seq[1:] else 0
os.rmdir(dir)
print(a_list)
print(np.array(sums).shape)
mylist = ListField()
d[y].append(x)
data.append((batting[1], player, batting[0], batting[2]))
figure(figsize=(8, 8))
parser = argparse.ArgumentParser()
urlparse.parse_qs(urlparse.urlsplit(url).query)
str(self.name) == str(other.name)
treeview_column.set_widget(label)
my_list = flat(d)
numpy.array([x[xs], x[ys]]).T
logger.setLevel(logging.NOTSET)
plt.plot(np.arange(100))
ax1 = fig.add_subplot(1, 2, 2)
p = mp.Process(target=Simulation, args=(inqueue, output))
canvas.restoreState()
plt.show()
ax.grid()
gpsgvqsbixtwyakpgefrhntldsjqlmfvyzwjoykhsapcmvjmar
p.terminate()
stdin.close()
opener = urllib.request.build_opener()
self.ClickedLB.move(200, 100)
win.idlok(True)
win.leaveok(True)
object._meta.verbose_name
next(v for k, v in self.items() if x in k)
df.head()
L = [1, 2, 1, 1, 1]
self.process = QtCore.QProcess(self)
df
cardsdiscarded += 1
df
t512.timeit()
p = subprocess.Popen(some_cmd, stdout=subprocess.PIPE)
print(buffer.getvalue())
scatter(X, Y, c=cycol())
page_source = browser.page_source
a = np.arange(100).reshape(10, 10)
ssc.awaitTermination()
f_out.writelines(f_in)
f.write(raw_img)
screen.refresh()
logfile.flush()
loop = asyncio.get_event_loop()
self.received_buffer.seek(0)
a = np.arange(2000).reshape(20, 100)
DEBUG = True
json_output
x = dict(a=1, b=2)
plt.contour(y, x, T[:, :, (round(len(z) / 2))], 64)
self
reader = csv.reader(data)
ui.show()
type(a)
sys.stdout.flush()
m.show()
widget.show()
signal.alarm(0)
self.get_sub_instance().get_individual()
gevent.monkey.patch_socket()
self.wfile.write(pymjpeg.boundary)
new_bar.update(extra)
set(Ol[:l])
myseries_two.iloc[0]
[ss[i:i + 6] for i in range(0, len(s) - 1, 6)]
HttpResponse()
map(str, a)
xs = [xs[i] for i in sorted_index]
math.floor(f * 10 ** n) / 10 ** n
os.close(fd)
print(keywordlist)
self.setFormatter(formatter)
GetWindowTextW(hwnd, win_name, win_len + 1)
y = [(k, v) for v, k in list(d.items())]
views.py
heapq.heappush(heap, (-p2, x, y - 1))
print(isPower(10, 1))
root = Tk()
b = np.empty(a.shape)
self.root.remove(child)
print(local_tz.localize(datetime(2000, 1, 15)))
self.data[key] = NotifyList(item, self, str(key))
app = Flask(__name__)
app.ActiveDocument.Close(SaveChanges=True)
pubkey.verify_update(message)
np.random.shuffle(x)
time.gmtime(year_ago * 1000)
pprint(service)
file.truncate(0)
gs - q - dQUIET - dPARANOIDSAFER - dBATCH - dNOPAUSE - dNOPROMPT
math.acos(inner_product / (len1 * len2))
factors[i] += 1
Lt - -titlecase
Lm - -modifier
crawler.start()
bins = np.linspace(0, 1, nbins + 1)
print(mse(model_1.predict(xg_test), y_test))
Gtk.ScrolledWindow
work.start()
pl.xticks(np.linspace(0.0, 100.0, 11, endpoint=True))
test_1_12_example_name.py
np.sum(n * np.diff(bins))
self.file_saving.child.join()
decorator
x = time.time()
xlApp.Quit()
cursor.execute(query_str)
time.sort()
np.put(x, y, 1)
handler404 = NotFoundView.get_rendered_view()
self.ui.PoseBtn_GridLayout.addItem(spacerItem, 1, 1, 1, 1)
len(self.__dict__)
x1 = np.hstack([[False], x, [False]])
ax.set_yticklabels(ax.get_yticks(), fontproperties=font)
app = Flask(__name__)
d[i] += 1
print(list(c.items()))
self._x
lambda *args, **kw: self.method(cls, *args, **kw)
signal.signal(signal.SIGTERM, cleanup)
self.failureResultOf(self.o.failure(), ConnectionRefusedError)
df.query(query_expr)
f(n) / f(r) / f(n - r)
df.rolling(n).sum()[-1::-k][::-1]
grouped.get_group(True)
ax.plot(x, y)
test_data = [str(x) for x in range(20)]
city = models.CharField(max_length=50)
frame = DataFrame(list_of_dicts)
pd.options.display.max_colwidth = 100
print(get_drive_size(0))
self.threads.append(self.makeThread(particles[i]))
self[key] = value
[]
plot_confusion_matrix(df_confusion)
{tree_list[0]: build_tree(tree_list[1:])}
boxplot(list(mydict.values()), labels=list(mydict.keys()))
df
ids = [row[0] for row in cursor.fetchall()]
index.tpl
ans = np.mgrid[0:1:100j, 0:1:100j, 0:1:100j]
raise TypeError
my_model.MyClassName
np.random.shuffle(rows)
getcontext().prec = 60
a = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
plt.legend(flip(handles, 2), flip(labels, 2), loc=9, ncol=2)
print(a[0, 2])
a[2](), b[2](), c[2]()
edges[i, j - 2].append((i, j + 2))
print(response.text)
a[1:, :-1]
b = random.sample(a, len(a))
fig, ax = plt.subplots()
a = numpy.arange(1, 21).reshape(4, 5)
(a[2], b[2]),
math.log(x)
c = socket(AF_INET, SOCK_STREAM)
gradient.setColorAt(0, QColor(255, 255, 255, 127))
print(line)
fig = plt.figure()
(time.astype(np.int64) / 1000000.0).astype(np.int64)
contents = output.getvalue()
keys = set(dol1).union(dol2)
result = result()
min(list_date, key=func)
resultList[-1].append(item)
soup = BeautifulSoup(data)
time.sleep(1)
a.__dict__
q.task_done()
rec(tf2, rest_paths[1:])
palette.append((i, 0, 0))
model = Sequential()
print(r.text)
bins = np.arange(min_bin, max_bin + 1)
sock.send(chunk)
self.assertEqual(0, len(message))
type.__new__(metacls, name, bases, dct)
fig = plt.figure()
print(data)
exit()
cause = []
a = np.random.randint(0, 200, 100)
getattr(self.m, n)
self.update(*args, **kwargs)
mask = (1 << bitlen) - 1
print(a)
width, height = img.size
print(intlist(10))
df = df[::-1].fillna(0).cumsum()[::-1]
x, y = sat(81.299, 0, radians=False, errcheck=True)
pylab.show()
reader = csv.DictReader(fin, fieldnames=fields)
[Arthur]
df
f.close()
shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)
self.reverser[mo.group()]
child.grab_focus()
api = tweepy.API(auth)
X00X
print(type(x).__new__(x.__class__))
fig, ax = pl.subplots(nrows=2)
data = ECD.read()
duck.walk()
pylab.xlim(0, 5000)
[(j, is_even(j)) for j in range(10)]
ser.readline()
-deadsnakes
np.column_stack((a, a, a))
print((i, max(dict[i])))
isect.append([val, 0])
soup = BeautifulSoup(html)
data = sorted(data, key=keyfunc)
f(20)
type(ids)
self.loop.call_soon_threadsafe(task.cancel)
self.ftp_h.cwd(path)
numpy.corrcoef(data)
Departure_Date.objects.extra(where=[where])
frame1.axes.get_xaxis().set_visible(False)
new_list = []
m.shape
self.transport.setTcpKeepAlive(1)
sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM, socket.IPPROTO_UDP)
arr = np.array([])
nx.draw(X, pos)
c.execute(query, keys)
view.setRenderHint(QPainter.Antialiasing)
r.append(blocktag[0])
df1 = pd.concat([df1, pd.DataFrame(columns=list(range(8)))])
pygame.display.update()
xs = np.random.randn(n).cumsum()
self.dx = dx
out.append(line)
label.pack()
----models.py
json.dumps(a)
aa = json.loads(j, object_hook=AttrDict)
print(nth(lucky(), 100))
nx.draw_networkx_edges(G_pc, pos, alpha=0.01)
req = urllib.request.Request(url)
res2 = cv2.cvtColor(res, cv2.COLOR_GRAY2BGR)
b[unified_mask[(np.newaxis), ...]] = 0.0
popt, pcov = curve_fit(gaus, x, y, p0=[1, mean, sigma])
self._notify()
cv2.normalize(hist_item, hist_item, 0, 255, cv2.NORM_MINMAX)
points = [(2, 2), (4, 4), (7, 7), (8, 8)]
board.append([])
allocate(y(j))
out = np.zeros(np.asarray(shp) * len(L), dtype=int)
Gtk.main()
print(a)
print(a)
self.createWidgets()
s.ioctl(socket.SIO_RCVALL, socket.RCVALL_OFF)
dd = {k: v for k, v in list(dd.items()) if len(v) > 1}
f()
subprocess.Popen(args, shell=True)
df = MyDF(*args, **kw)
self.name = name
os._exit(code)
n, ext = os.path.splitext(f)
timings.append((result, fname))
seen.insert(i, x)
list(f.values())
self.s = str(*args, **kwargs)
t.start()
df = df.sort()
allspiders.append(makespider(domain, urls))
print(len(s))
doSomething(b)
gray = cv2.threshold(gray, 4, 255, cv2.THRESH_BINARY)[1]
f.bar()
x * 2
plotter2.binding_plotter_with_ui()
id = db.Column(db.Integer, primary_key=True)
print(guess_seq_len(list(range(500))))
spelling_dict.get(word, word)
data[index] = new_list
p = Process(target=f)
threading.Thread.join(self)
print(rechunk(ner_output))
plt.figure()
rect = np.array([[bx1, by1], [bx1, by2], [bx2, by2], [bx2, by1], [bx1, by1]])
self._queue.get(False)
print(fexprefix)
names = [row[0] for row in cursor.fetchall()]
lst = [pd.DataFrame(), pd.DataFrame(), pd.DataFrame()]
ax = plt.gca()
b = [a, a]
setattr(namespace, self.dest, values)
stdout, stderr = proc.communicate()
cam = cv2.VideoCapture(0)
ar[:-sum(1 for i in takewhile(lambda x: x, reversed(ar)))]
average = scipy.signal.convolve2d(matriz, kernel)
r = csv.reader(open(filename))
b = a[1:]
fcond.notify_all()
_int(istart + _int(self.random() * width))
self.flag = False
pool.append(p)
self.name = name
atexit.register(cleanup)
wn.lch_similarity(dog, cat)
conn = pycurl.Curl()
Variance(X).doit(evaluate=False)
-W900
self._cards.append(card)
line = gca().get_lines()[n]
deleteself.Ans[-1]
self.a = 0
etree.ElementTree._write(self, file, node, encoding, namespaces)
len(msg.get_payload())
args = parser.parse_args()
sys.stdin = sys.stdout = sys.stderr = self.desc
values.append([v, [k]])
outf.close()
zip_longest(fillvalue=fillvalue, *args)
array[values] = list(r.values())
plt.plot(Vecpoints, np.exp(logkde))
w, x, y, z
u = np.sin(np.pi * x) * np.cos(np.pi * y) * np.cos(np.pi * z)
print(filename)
linsolve(system, x, y, z)
print(msg.subject, msg.id)
tokens = [_f for _f in map(myfilter, tokens) if _f]
a.isalpha(), b.isalpha()
client = paramiko.SSHClient()
self.my_attr == other.my_attr
author = models.ForeignKey(Author)
tempList.append(rowDict)
pl.figure()
fig, ax = plt.subplots()
data = json.load(data_file)
[action_to_apply(row) for row in X]
Exception.__init__(self, *args, **kwargs)
name = db.StringProperty()
do_something(weapons)
turtle.right(angle)
out[product_name].append((bike_number, list_of_parts))
print(cmd())
f(1)
dt + datetime.timedelta(microseconds=us)
root = Tk()
subprocess.call(cmd, stdin=sin, stdout=sout, startupinfo=startupinfo)
format(theList)
axs[i].scatter(pts[i][:, (0)], pts[i][:, (1)], c=colors[lbls])
[sum(1 for _ in group) for key, group in itertools.groupby(condition) if key]
np.putmask(arr, arr >= T, 255.0)
log.addHandler(console_handler)
triples += ((i, j, k) for k in K[K > i])
of.close()
Tk().withdraw()
callback(*args, **kwds)
a = 1 if i < 100 else 2 if i > 100 else 0
dllname = os.path.split(self._welu.__file__)
cv2.imshow(img)
instance = form.save(commit=False)
self.__dict__[key]
setones_between_triggers(A, 2, -2)
f = lambda r: sp.j1(r) ** 2 / r
sys.stdout = sys.__stdout__
[1]
cap.open()
np.random.seed(seed)
{r[key] for key in r if 42 in key}
self.after(100, self.poll_serial_port)
self.co.send(*args)
x = collections.Counter(l)
send_from_directory(UPLOAD_FOLDER, filename)
rescaled = np.mean(rescaled, axis=ind + 1)
do_something(my_object)
[0, 0, 0, 100]
result.save(sys.argv[2])
l = [4, 5, 6]
self.count += 1
doc = le.parse(f)
self.value = 1
sys.modules[__name__] = _MyClass.instance
handle_error()
fig = plt.figure(figsize=[7, 5])
print(v)
cursor = cnx.cursor()
g.ax_marg_y.set_axis_off()
self.feed += 1
print(data)
last_name = models.CharField(max_length=50)
sleep(1)
message, settings.SERVER_EMAIL, [a[1] for a in settings.MANAGERS]
retval
frame.Show()
center = int(x), int(y)
{NULL, NULL, 0, NULL}
self.adjective_count[a] += 1
print(post.text)
res[v].append(k)
results = [result_queue.get() for mc in montecarlos]
my_date = date.today() - timedelta(days=days_to_subtract)
self._connection.close()
img = mahotas.imread(imname)
print((data, data.GetType()))
fig, ax = plt.subplots()
print(max_dir, max_file)
arr = np.arange(16).reshape(4, 4)
fig = plt.figure()
u[np.argsort(ind)]
z = request.GET.copy()
a[..., (0)] + a[..., (1)]
subprocess.call(cmd, shell=False)
jj = np.where(ii)[0]
redirect(success_url)
numpy.finfo(numpy.float64).min
s = s.append(b, ignore_index=True)
p = Pool(number_of_processes)
name = models.CharField(max_length=100)
rand2.seed(0)
DerivedClass().do_it()
line = file.readline()
[1.0, 0.0, 0.0, 1.0, 0.0, 0.0],
n &= n - 1
[G.edges(subgraph) for subgraph in subgraphs]
os.close(fi)
session_crumbs.append((flask.request.path, view_title))
palette.setColor(palette.Dark, QtGui.QColor(0, 255, 0))
self.response.out.write(images.image)
new_col = NP.zeros_like(my_data[:, (-1)]).reshape(-1, 1)
result.extend(s)
np.count_nonzero(x != y)
a._A__foo()
cython.int
self._x = value
foo.MyClass()
daemon_cartman.join()
print(df1.equals(df))
z.nonzero()
d = json.load(json_data)
self.listbox.insert(0, option)
stdout.write(str(i))
a = b[:]
db.session.add(sg)
rounding_swig / testrounding.cpp
pool = multiprocessing.Pool(5)
django.db.connection.user = user
lambda x: bool(int(x))
func(self)
cols.append(col)
connection.close()
doTaskB()
ax2 = ax.twinx()
print(twodarray.shape)
type((100,))
self.dbobject = all()
hash(b)
second_largest([2, 2, 2, 2, 2, 1])
list(my_mapping.keys())
pygame.display.update()
print(f.__code__.co_consts)
mock_http_client.get.assert_called_with(url)
os.path.isfile(os.path.join(*path_segments))
bottom.paste(top, (0, 0), mask)
print(a, b, c, d)
np.concatenate([a[offset:offset + length] for offset, length in offset_length])
canvas.saveState()
map_nested_dicts_modify(x, lambda v: v + 7)
threads[i].start()
f.seek(0)
df = df.transpose()
print(np.dot(rotation_matrix(axis, theta), v))
mydict[str(key)] = mydict[key]
print(concatd(a, b, c))
tree = lxml.etree.XML(DOC)
v[(-1), :-1] / -v[-1, -1]
self.fields.update(form.fields)
self.dict[self.last]
client.disconnect()
B = np.random.random((10, 4))
f
ax.yaxis.set_major_formatter(mtick.PercentFormatter())
elements.append(itertools.repeat(iter))
c = df.columns.values
f = os.path.join(dirName, f)
themin, themax
i += 1
gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
self.assertEqual(4, myObj.getDataLength())
a[inds[:, (0)], inds[:, (1)]]
[d1[key] for key in set(d1) - set(d2)]
print(r.cookies)
x = mydict[k]
print(i)
my_saved_data
df.dt = pd.to_datetime(df.dt)
ax = fig.add_axes([0.1, 0.2, 0.85, 0.7])
logutils.set_up()
img = np.zeros(Arr.shape, dtype=bool)
print(sum(sub == s[i:i + ln] for i in range(len(s) - (ln - 1))))
{k: (v - 1) for k, v in list(c.items())}
new_im = f(new_x).T
a.many_b.add(*list_of_b)
file.flush()
df
bbox = self.legend.get_window_extent()
s.bind((MY_ADDRESS, port))
argparse.ArgumentParser.add_argument(self, *args, **kwargs)
df1.join(df2).columns
pairs.append(new_pair)
req = urllib.request.Request(url, urllib.parse.urlencode(params))
regex = re.compile(re.escape(old), re.I)
mod1.py
fileWriter.writerow(row)
self.html = self.mainFrame().toHtml()
im = ImageOps.invert(im)
collections.OrderedDict.fromkeys(x for x in a if x not in b)
df1 = df.groupby([a, b]).count()
my_string = my_string.lower().split()
F(1, 2)
driver = webdriver.Firefox()
wb.save(out)
xmax, ymax = a.max(axis=0)
chunk.append(line)
deployFiles()
tree = BeautifulSoup(bad_html)
logger = logging.getLogger()
b = np.random.random_integers(2, size=(4, 4))
np.irr(np.r_[-n, cashflow])
conn = http.client.HTTPSConnection(myDestination)
response = urllib.request.urlopen(request)
self.allowed_domains.append(hostname)
psutil.cpu_count()
Function(lambda x: self(x) / other)
sum(sum(i) == 100 for i in itertools.product(range(100), repeat=100))
timeit((df == df2) | (df != df) & (df2 != df2)).values.all()
smtp = smtplib.SMTP(smtp_host, smtp_port)
worksheet.set_column(i, i, header_len)
pprint.pprint(sys.path)
fig, ax = plt.subplots()
sizer.Add(lbl, 0, wx.ALL, 5)
seen.add(char)
sys.exit(a.exec_())
usage()
gen_random_decimal(99999999999, 999999999999)
a.append(dict(b))
B = defaultdict(lambda : defaultdict(int))
gameMap[0:2, 0:2] += piece
fig = plt.figure()
random.sample(xs, sample_size)
time.sleep(-time.time() % 1)
print(type(lengthy_thingy).__len__(lengthy_thingy))
file.close()
self.photo.load()
es_logger.setLevel(logging.INFO)
dis.dis(foo)
result.append(string)
result = df.loc[df_mask]
dbConn.close()
powLF(n)[1]
df_with_x4.show()
country = models.ForeignKey(Country)
clf.fit(train[cols], train.targets)
os.path.relpath(google.__file__, here),
print(myString[0])
D = dict((k, v) for v, k in enumerate(albums_yesterday))
notebook.set_tab_reorderable(child, False)
z.extractall()
client_socket.close()
d = {}
session.commit()
decorated_func
request = urllib.request.Request(url)
L = list(reversed(list(range(100))))
self.cost += tf.reduce_mean((x_train - y_train) ** 2)
parser.exit()
X = scale(X, axis=0, with_mean=True, with_std=True, copy=True)
numpy.dot(A_col0_sorted, perfect_fit)[:, (0)],
angle = atan((neuron2.x - neuron1.x) / float(neuron2.y - neuron1.y))
plt.plot(np.arange(10) * (i + 1))
self.columnconfigure(0, weight=1)
result.append(word)
A = pd.Series(list(range(10)))
signal_axes.plot(xs, rawsignal)
1, 2
csv_writer = csv.writer(csv_file)
cursor.execute(statement)
c = a
results.append(obj)
y = mlab.normpdf(bins, mu, sigma)
Py_DECREF(initresult)
self._alpha(context) * self._backoff.prob(word, context[1:])
rep_shape(a, (4, 2))
new_data = data[np.in1d(arr1, arr2)]
x.extend(y)
name = models.CharField(max_length=25)
A = np.array([5, np.nan, np.nan, np.nan, np.nan, 10])
nw[0] = nw[0] + 1
f.close()
df = df.sortlevel(0)
a[a < 0] = 0
p = np.empty((n, 2))
match.start()
setattr(TestSequense, test_name, test)
image[coordinates] = 1
canvas.delete(ALL)
str(Fraction(0.25))
cv2.circle(out, (int(x1), int(y1)), 4, (255, 0, 0), 1)
message = Column(String(2000), nullable=False)
data = urlencode(values)
plt.imshow(im.T, cmap=cmap, extent=xr + yr)
p = pyaudio.PyAudio()
df.Date = pd.to_datetime(df.Date)
cols = np.arange(len(df.columns))
m()
{{language.name_local}}
decoder.end_utt()
print(df)
count(1)
f = figure(figsize=(6, 6))
fig = plt.figure()
index[count][1].append(url)
m = hashlib.md5()
fig, (ax1, ax2) = plt.subplots(1, 2)
map(tdgi, list(filter(tdin, theList)))
data_json = json.dumps(data)
loop.run_until_complete(do_work(q))
50 + sum(x * next(cyc) for x in lis[0])
events = events.exclude(eventitem__isnull=True)
asyncio.set_event_loop(self.loop)
colors.insert(index, mean_color([colors[index - 1], colors[index]]))
ax = plt.gca()
ax = plt.gca()
print(tree.find(10))
print(x)
string.lowercase[:14:2]
func(*args, **kwargs)
{k: dd[k] for k in list(dd.keys())[:10]}
array2[:] = array1
np.random.seed(1977)
self.causes[node.name] += self.extract_cause(b)
aux = copy.deepcopy(matriz)
[c.send(val) for val in generator1()]
sys.exit(1)
out.reshape(R, -1)[:, (valid_mask)]
root = Tk()
f.write(templateString.format(**d))
sum(1 if i == j else 0 for i, j in zip(w1, w2)) / float(len(w1))
q = Queue()
f.__code__ is creator.__code__.co_consts[1]
root = etree.fromstring(s)
np.random.seed(seed)
heavy_computation(X, param_1, param_2, arg)
ax.set_xlim([0, 5])
output.append(line)
page = urllib.request.urlopen(url)
df
self._log(text)
model = models.MyModel
rng.random()
pixel_value += polygon_shape.intersection(pixel_shape).area * value
deleteTrue
models.py
c = cdll.LoadLibrary(LIBRARY_NAME)
h[x] = h.pop(x, []).append(y)
msg = msg[:-2]
unittest.main()
mapper(tableClass, table)
proc = subprocess.Popen(cmd, shell=True)
i == len(B) or B[i] != a
df[df > df.quantile(0.8)].dropna()
response = self.opener.open(url, data)
b = Test()
self._s.bind((host_address, port))
a.write(f, relpath(f, root))
id = db.Column(db.Integer, primary_key=True)
plt.show()
tuple(p.stdout.fileno() for p in processes)
self.__doc__ = callable.__doc__
input()
object.__ne__(self, other)
int()
print(groups.mean().b)
path = os.path.join(folder, filename)
s = pd.Series(list(range(10)))
getattr(self.get_query_set(), name)
output.write(outputStream)
cs = plt.contour(x, y, vel, levels)
deletemydict[key1]
client_socket.connect((server_address, port))
self.worker.measure_msg.connect(self.showRslt)
f = expr(f)
j = ((x - x0) / dx).astype(int)
a[0:4]
conn.autocommit(True)
created_at = models.DateTimeField(auto_now_add=True)
block.move()
a = numpy.array([[0, 0], [0, 1], [1, 0], [1, 1]])
foo = input()
text.insert(END, output)
parts[0].strip(), int(parts[1])
crypto.dump_privatekey(PKey)
frob(self.b)
float(s)
df2[ser1.name] = ser1
proc.stdin.write(c)
0.550000000001
result.append(nopreds)
a.a().method()
wx.PostEvent(self, event)
sum(x is False for x in arr)
ax = plt.axes()
df1
cPickle.dump(d, out)
sum(sorted(dice)[1:])
mydtype = np.dtype((np.void, a.dtype.itemsize * a.shape[1] * a.shape[2]))
dt = datetime.datetime.now()
os.dup2(se.fileno(), sys.stderr.fileno())
ser.write(byte_signal)
np.array(y.shape).tofile(f)
row = wx.BoxSizer(wx.HORIZONTAL)
Request(url, dont_filter=True)
protocol = QNetworkProxy.Socks5Proxy
print(lda.print_topic(i))
random.random() * 5 + 10
self.tvcolumn1.set_cell_data_func(self.toggle, self.set_status)
print(np.in1d(values, data))
os.execv(sys.executable, sys.argv)
user = models.OneToOneField(User, parent_link=True, blank=True, null=True)
b = a[names]
print(x, y)
print(eval(code))
rep_shape(a, (5, 8))
help(ttk.Notebook)
cr.set_source_rgb(1, 1, 0)
__init__.py(empty)
pl.colorbar()
form = UserCreationForm(request.POST)
a[i] = f(v)
Py_Initialize()
wynik[i] += 1
self.panel.show()
print(id(argv[0]))
df
x = mystuff()
print(rem == [0, 1, 2, 1, 0])
self.assertEqual(1 + 1, 2)
d2.update(d1)
logger = logging.getLogger(__name__)
plt.axes().yaxis.set_minor_locator(ml)
d = collections.defaultdict(set)
ctypes.c_int,
r.findall(s2)
keys = set(chain(*[list(d.keys()) for d in dicts]))
plt.show()
rel.save()
print(x[ind], y[ind], z[ind])
out = np.zeros(dims, dtype=int)
matrix.append(list(vals[x * size:x * size + size]))
b = np.array([[5, 6], [7, 8]])
cur = con.cursor()
callback(args[0])
c.diff().fillna(math.max(0, values[0] - ALLOWANCE))
lst1[0:1] + interleave(lst2, lst1[1:])
[1, 1, 0]
b = np.concatenate([[0], np.where(a[:-1] != a[1:])[0] + 1, [n]])
Bar.bar()
a[-2:] = [0, 4]
stateA()
screen = pygame.display.set_mode((SCREEN_X, SCREEN_Y))
self.data = dict(*args, **kwargs)
a.f()
soup = bs4.BeautifulSoup(html)
hSplitter.SetSashGravity(0.5)
a.sort(key=Vector.__key__)
1, [True, True, False, False]
egg2(a, b)
sorted([x for x in p if x < limit])
main_loop.start()
r = requests.post(url, files=files)
df.head()
print(len(puppies.getdata()))
server.login(USERNAME, PASSWORD)
a.add_child(a)
next(c)
flat = [[(k, v) for v in vs] for k, vs in list(kwargs.items())]
print(df1)
groupby(a, [0])
t = name,
user_func()
workbook = load_workbook(filename, use_iterators=True)
lst = [1, 5, 4]
nopreds = set()
logging.exception(e)
stext.mainloop()
ax.set_ylim([-4, 4])
self.login(response)
etree.fromstring(f.read(), xmlparser)
dall.update(d2)
worksheet.column_dimensions[column_cells[0].column].width = length
x
dictionary.setdefault(x, []).append(y)
print(driver.title)
f.get_prep_value(d.numbers)
qproc.start()
Foo.newmethod = newmethod
list(chain.from_iterable(zip(l[:-1], repeat(0)))) + l[-1:]
time.sleep(secs)
Job.objects.get(client__id=1)
otherfunc()
help(dict)
print(line)
a.__str__()
button1.configure(command=lambda widget=button1: DoSomething(widget))
s.capitalize()
start = tk.Tk()
myThread.daemon = True
self.buf.seek(0)
my_list = list(range(10, 17))
frame.Show()
pl.show()
pool.close()
yaml.dump(self.object, file)
dectheclass
self._protected()
ax.scatter(x, y, label=l, s=50, linewidth=0.1, c=c)
main()
print(k, curve, [angle(p1, p2) for p1, p2 in zip(curve, curve[1:])])
len([is_true for is_true, _ in groupby(a, lambda x: x != 0) if is_true])
print(p.pid)
db.get_conn().ping(True)
cmp(self.s[x + l], self.s[y + l])
750069.25, 750069.25
application = app
self.module = locals
print(m.groups())
type(counts_df)
f.close()
heapify(A)
print(data)
tf.close()
logger.addHandler(fileHandler)
math.log(math.exp(logA) + math.exp(logB))
result = func(*args)
doc = fromstring(html)
p[1]
attribute(*args, **kwargs)
ns = parser.parse_args()
print(i, get_hotp_token(secret, intervals_no=i))
repr(self.i)
sys.exit()
names = pd.DataFrame()
print(client.fetchAll())
foo().y
k = a[0:2]
br.submit()
j.do()
print(df.values)
X = R * np.cos(THETA) + 5
-cmp(self.x, other.x)
allocate(fullData(nR, nC))
main.py
math.isnan(item)
n1.add(n12)
Person.__init__(self, name, phone)
arr.reshape(h // nrows, -1, nrows, ncols).swapaxes(1, 2).reshape(h, w)
app = wx.PySimpleApp()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
list(a)
s = sorted(s)
max_idx, max_val
figure()
self.write(repr(self.request))
names = names.append(frame, ignore_index=True)
words.append(word)
final_l
result += letters[index - shift]
result = df.copy()
tk.Frame.__init__(self, root, *args, **kwargs)
print(line)
self.text = tk.Text(self, height=10, width=40)
os.dup2(t.fileno(), self.fd)
order = np.argsort(x)
d1 = datetime.date.today()
b = np.random.rand(5, 6)
bokeh.plotting.curplot().plot_width = 800
logging.basicConfig(level=logging.INFO)
print(x.reshape((x.shape[0], 1)).type)
print(self.obj.f1(2))
D = ((a - v[i]) ** 2).sum(axis=-1)
plt.xlim([0.0, 9.0])
self.level = logging.DEBUG
cursor.execute(query)
len(a)
ax = fig.add_subplot(111)
table.insert_data(simple_dataframe)
delete_keys_from_dict(v, the_keys)
time.sleep(1)
pool = mp.Pool(NPROCESSES)
count += 1
f = a[0:1]
D = spatial.distance.pdist(A, lambda u, v: getDistanceByHaversine(u, v))
zf._writecheck(zinfo)
bagel
stdout, stderr = proc.communicate()
images[idx].shape
row, column = map(int, line)
display.display(plt.gcf())
print(list((b - a).elements()))
np.linalg.norm(a * c - b)
test_set[i] = flatten_image(matrix_image(test_images[i]))
x[words[0]].append(words[1])
print(cpy_list)
path.split(os.sep)
self.inner_test = inner_test()
print(regressor.predict(X))
ax = fig.add_subplot(111)
print(sys.path)
print(a_list.sort())
output.close()
a = np.arange(10)
next(reader)
print(dir(module))
print(x)
string.whitespace
request.user == obj
arr[i] = 0
app.MainLoop()
self.geodata_image.blit(0, 0, 0)
snake.foo()
self.f = Foo()
outfp.close()
a[b]
two_array.append(6)
print(applyParallel(df.groupby(df.index), tmpFunc))
self.label = QtGui.QLabel(self)
words = set(f)
edges.add((left, right))
len2 = max(len(el) for el in list(chain(*my_list)))
self.get_user_from_cookie()
self.q_in.delete_message(self._current_message)
api = tweepy.API(auth)
outputlist.append(current)
self.release()
result = func(*args, **kwargs)
min(chain(l_one, l_two))
doc.build(text)
self.stopFunc()
d.extend(g)
matches.append(x)
files.append(d)
my_dict = defaultdict(list)
list(Foo.__dict__.keys())
B = np.array([2, 4, 6])
server.shutdown()
self._data = data
opener = urllib.request.build_opener(ValidHTTPSHandler)
session.expunge(i0)
action.perform()
cur.close()
resultList.append([item])
df
self.model.query.filter(self.model.owner == g.user)
im = Image.open(file)
fast_xor(b, 256)
person = re.findall(regex, line)
y = x[indices]
line = f.readline()
ciso8601
ujson
workalendar
mask.sum()
tmp = pd.Series(np.array(list(col)).flatten())
sys.path.insert(0, flaskfirst)
instance.test_method(instance.sample_method)
print(extract_names(s))
rows = np.arange(a.shape[0])
ax.annotate(c, xy=pos)
app.url_map
temp = int(temp)
ReligiousSerializer(instance=instance).data
LaySerializer(instance=instance).data
grp.reindex(mux, fill_value=0).reset_index()
G.add_edge(4, 5)
np.ix_(mask1, mask2)
print(test_Dict[obj].name)
pd.DataFrame([dict((x, r.count(x)) for x in r) for r in d]).fillna(0)
power(2, 5)
win = gtk.Window(gtk.WINDOW_TOPLEVEL)
hxs = HtmlXPathSelector(response)
module_name = os.path.basename(module_filepath)
True
deleted[i]
name = models.CharField(max_length=20, unique=True)
list(d.items())
print(newcorpus.paras())
x = remove_values_from_list(x, 2)
plt.show()
v = CountVectorizer(ngram_range=(1, 2))
out.getvalue()
Clock.schedule_interval(self.change_color, 1)
myFunction(*args)
ax.xaxis.get_ticklines()
sys.stdout.write(line)
a = np.array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=np.bool)
res = []
raise TransportError(e.msg, e.code, e.fp)
plt.axes().yaxis.set_minor_locator(ml)
h.close()
[(u.value, u.meta) for u in set([a, c, e]).intersection(set([b, d]))]
stdscr.refresh()
df.index.dtype
out.append(s[i - k:i])
plt.legend()
plt.xticks(x, xticks)
p.close()
[[sum(1 for _ in g), v] for v, g in itertools.groupby(l)]
-gfortran
l.append(read_from(toks))
start = time.time()
wrapper2
cmake
i = 0
after_setup_logger.connect(initialize_logstash)
print(dir(B))
r[i] = (a * 67108864.0 + b) / 9007199254740992.0
random.shuffle(d)
print(df)
globals()[k] = test.__dict__[k]
next(values())
ax.xaxis_date()
endif
df = pd.read_table(io.BytesIO(data), delim_whitespace=True)
data = next(reader)
from_date.replace(month=2, day=28, year=from_date.year - years)
sys.stderr = sys.stdout
float(a)
dict(map(ascii_encode, pair) for pair in list(data.items()))
f.integral()
self.save_file.append(json.loads(tweet))
print(x, y)
ax2 = plt.subplot(gs[(0), 2:])
self.setup_test_data()
self.append(next(self._gen))
[]
fill_array(subarr, subseq)
{{message}}
result
df.isin([1, 2]).any(1)
fabric.state.connections[host].get_transport().close()
filename = sys.argv[1]
self.adjacencyList = adjacencyList
self.drawWidth, self.drawHeight
results = collections.Counter(the_string)
do_sth_with(i, somearray[i])
elements.append(Paragraph(content, style))
abs(-1)
result = custom_sort(allsites)
smtplib.SMTP_SSL.__init__(self, host, port, **kwargs)
wx.TheClipboard.Close()
main()
self.canvas.draw()
wr.writerows(csv.reader(f))
QtGui.QColor(rgb).getRgb()[:-1]
s = socket.socket()
json.dump(d, fileout)
print(utmless_url)
frame.set_border_width(2)
process(elt.mylargecontent)
newFile.writerow(row)
array([[1.0, 4.0], [2.0, -1.0]])
list(self._consumers.keys())
next(f)
unittest.main()
application_path = os.path.dirname(sys.executable)
self.set(value)
int(self.x)
test = lambda m: min(timeit.repeat(m, setup))
count[0] += 1
query = users.select().order_by(users.c.id.desc()).limit(5)
conn = MySQLdb.connect(**params)
self.func = func
print(list(diff.elements()))
help(f)
socketIO.wait_for_callbacks(seconds=1)
result = a.format(name=b)
self.DISTRICT
self.lb2 = tk.Listbox(self.root, yscrollcommand=self.vsb.set)
reactor.stop()
self.managed
txt = f.read()
self.zfile = zipfile.ZipFile(self.z)
r = requests.get(url)
plt.xlim(0, 5)
[x for x in k if tuple(x) in stuff_in_kDash]
plt.subplots_adjust(hspace=0.4)
print(GLOB_VAR)
print(eval(code))
c = Counter(chain.from_iterable(list(d.values())))
h1 = logging.StreamHandler(sys.stdout)
ax2.add_line(line)
hxs = HtmlXPathSelector(response)
print(x.dot(y).shape)
type(x)
B.sum()
plt.ioff()
s[::-1]
plt.subplot(212)
logging.root.addHandler(console_handler)
n = X.shape[0]
A.shape
create_app()
{tuple(e) for e in a}
p = multiprocessing.Process(target=f)
d2 = dict(a=1, b=2)
inds = np.ravel_multi_index((rows, cols), arr.shape)
r.json
ascends.append([i + 1, i + 1])
print(roster)
atan_in_degress(2)
object.__ge__(self, other)
[1.0, 4.0, 9.0]
any(test(x) for x in L)
print(xmp_str)
leg.get_frame().set_linewidth(0.0)
app.MainLoop()
stdin.flush()
resp = views.my_view(req)
val
pairs_by_number_and_list[pair[0]].append(pair)
trees.extend(parent.children)
self.queue.append(item)
list.append(val)
cv2.circle(vis, (x1, y1), 2, col, -1)
plt.tight_layout()
gb(pt[0], pt[1], 0, 0)
something_else()
HexDump()
a[i][:] = np.concatenate((z, a[i][:][np.nonzero(a[i][:])]))
pprint(_)
results = list(ex.map(len, fl))
fig = plt.figure()
NP.c_[(0.2), 1:10, (60.8)]
k.set_contents_from_string(r.content)
ptr[1] = color[1]
im.paste(255, mask)
print(item)
defaultdict(factory)
print(rowselected[c].value())
plt.plot(x, y, label=label, color=cmap(color), lw=5)
self.x == other.x and self.y == other.y
txt = f.read()
s.quit()
a1 = np.arange(2)
file_size = 0
print(results[entry])
filter.children.pop()
c = connection.cursor()
notifier.loop()
self.key = key
http_server.serve_forever()
elem.pop(elem.index(match))
print(rpy2.__version__)
user = User.objects.get(username=username)
print(hex(id(y)))
i = random.randint(0, len(self.data))
d = random.randint(5, 15)
startupinfo = subprocess.STARTUPINFO()
df_with_cat.show()
dataframe.to_excel(writer, sheet_name=sheets, startrow=row, startcol=0)
client.close()
models.Field.formfield(self, ObjectListField, **kwargs)
line = models.CharField(max_length=12)
hashes.append(hash_dir(os.path.join(path, dir)))
logger = logging.getLogger(__name__)
plt.hist(x, bins=n, range=(minval, maxval), weights=weights)
sys.stdout.flush()
print(tb_last.tb_frame.f_locals)
a = np.arange(1, 11)
print(r.content)
self.diagram.SetCanvas(self)
parser = argparse.ArgumentParser()
dt.now()
urlpatterns += staticfiles_urlpatterns()
count += 1
df
print(values)
tree = objectify.parse(xmlPath, parser=parser)
a + b
X.sum(axis=0)
pdb.set_trace()
signal.signal(signal.SIGINT, cleanup)
sys.stdout, sys.stderr = oldout, olderr
next(reader)
fig, ax = plt.subplots()
curdoc().add_root(page_logo)
b[:, :, (4)]
plt.show()
xml.parsers.expat
a = np.array([0, 0, 15, 17, 16, 17, 16, 12, 18, 18])
links = Post.objects.filter(link__tag__instancemodel=instance)
sess = tf.Session()
deletelst[0]
lines = [line.strip() for line in f]
s = set(fus_d.keys())
exit
unpad(cipher.decrypt(enc[16:]))
sum(summands)
np.column_stack((a, b))
pl.imshow(im_array, cmap=cm.Greys_r)
ts = time.timetuple()
num2 = int(argv[2])
print((hex(num), num))
type(c)
stuff()
print(i)
self.file.close()
description = Column(String)
{NULL}
One().f()
joinstr.join(t.queryString() for t in self.tokens[0::2])
QtGui.QDialog.__init__(self, parent)
random.choice(largest)
groups = dict(list(gb))
print(my_test.name)
self.t2 = time.time()
out = np.bincount(id_arr.cumsum(), np.take(data, np.concatenate(contribs)))
shortcut.Save()
pygame.init()
self.worker.daemon = True
d[key] = d2[key]
driver = webdriver.PhantomJS(*args, **kwargs)
new_l.append(d)
length = len(lists[0])
meas.append((x, y))
{0, 7, 8, 9, 10, 0, 0},
wmp.Open.Open.Click()
yagmail.SMTP().send(contents=contents)
list(ln).index(1)
diags.append(A[x][x] * B[x][x])
A.nbytes
csv_reader = csv.reader(f)
[1.5, 0.8660254]
x.append(row[0])
sys.stdout = dummyStream()
a.__setitem__(x, a[x][1])
mydict = dict((s[0], s[1:]) for s in myseq)
iconfile.write(icondata)
self.statusBar.show()
deactivate
aDict[name].append((int(startTime), int(endTime)))
csv_out.write(output_line)
dictionary[parts[0]] = 1
x[0, 0, 0] = value1
now = datetime.now()
[0, 0, 0, 1, 0],
[(a, b) for a in A for b in B if a in b]
bf.flush()
df2 = df.copy()
df[2]
self.values = set()
subprocess.check_call(params)
b = dict(enumerate(a))
object.__str__(self)
element.findall(search)
next(m)
True
found = False
df.columns = my_columns
d[k] = v
b.pop(0)
df = df[df.C == c_maxes]
c = muX - b * np.dot(muY, T)
array([2, 4])
response.raise_for_status()
main()
b()
a.shape
self.button.show()
temp = np.cumsum(X, axis=0)
l = [k for k in h]
print(dict[key])
cameraR.SetFocalPoint(0, 0, 0)
np.sqrt(val / 2.0 / a.shape[0])
canvas.restoreState()
property_asel = [a for a, truth in zip(property_a, good_objects) if truth]
b().mymethod()
plt.title(title)
x, y = sp.coo_matrix(df.isnull()).nonzero()
Vector(self.x + n, self.y + n)
out = arr.copy()
parser = argparse.ArgumentParser(formatter_class=argparse.RawTextHelpFormatter)
print(darr.min())
df.columns = pd.MultiIndex.from_tuples(df.columns, names=cols)
v = Vector((x, y, z))
out = np.empty((ma, mb, na + nb), dtype=a.dtype)
counts = [(chr(i), v) for i, v in enumerate(counts) if v]
self.panel = wx.Panel(self)
hxs = HtmlXPathSelector(response)
chord(207.652)
chord(195.998)
unittest.main()
type(x)(y)
bin(y)
list(gen)
Html.fromHtml(html).toString()
[1, 5, 9]
handle.set_missing_host_key_policy(ssh.AutoAddPolicy())
driver.get(URL)
soup = bs.BeautifulSoup(content)
print(p)
word[:-1]
self.queue = multiprocessing.Queue(-1)
[record[0] for record in cursor]
ax.view_init(elev=elevation_angle, azim=azimuthal_angle)
print(ElementTree.tostring(thing))
line.set_color(label)
x = d[x]
result.append(map(decimal.Decimal, line.split()))
img = scipy.misc.imread(fname)
traceback.print_exc()
np.log(a) / (k + 1) * x ** (k + 1)
gevent.joinall(jobs, timeout=2)
r = csv.reader(f)
type(seen.add(10))
k, v
sets = np.array_split(arr, 4)
next(g)
df
after_setup_task_logger.connect(foo_tasks_setup_logging)
plt.close(fig)
plt.xlim(1.0, 2.2)
pd.DataFrame(dict(birdType=someTuple[0], birdCount=someTuple[1]))
competitors = Competitors.objects.all()
out = process.stdout.read(1)
fig, ax = plt.subplots()
set(n for val in list(periodic_gs.values()) for n in val.nodes())
generator.workbook.close()
q[0, 0] = 5
result = [[k, da[k] + db[k]] for k in da.keys() & db]
main()
result = min_value if result < min_value else result
list(samples2)
body = resp.read()
parse(string)
line = m.readline()
render2Dstuff()
self.assertEqual(mock_boo_obj.e.call_count, 1)
subprocess.call(kill_command, shell=True)
cur.close()
writer = csv.writer(fo)
target.write(str(source.read(), sourceEncoding).encode(targetEncoding))
c.stop()
predict_on_batch(self, x)
m.drawcoastlines(linewidth=0.5)
X = np.random.uniform(0, 1, size=(nx, dim))
find_planar_subgraph(G)
response = request.urlopen().read()
draw.ellipse((x_pos, y_pos, x_pos + box_edge, y_pos + box_edge), fill=255)
grow(m, r, c)
ax = fig.add_subplot(111, polar=True)
len(df) == 0
library(rjson)
x = np.array([True, True, False])
b = bytearray()
sys.exit(0)
output = process.communicate()[0]
len(set(x))
line_num += 1
offset += len(i) + len(delimiter)
plt.plot(x2, y2)
width, height = np.shape(img)[0:2]
df2
deleteself.d[k]
isinstance(12, retype)
request.session.save()
os.remove(fullpath)
wb = Workbook()
print(G.edges())
print(line)
ptree.productions()
example[[1]]
d.hexdigest()
r = pd.DataFrame(X.toarray(), columns=vect.get_feature_names())
csv_writer.writerows(rows)
dflist.append(df)
event.process()
print(zzz())
parser.parse(s)
a = Yd()
self._x
a.A
f(2)
axis.set_visible(True)
os.execv(sys.executable, args)
t = datetime.datetime.today()
full_path = os.path.join(directory, name)
print(line)
result.append(tree)
n = len(array)
isinstance(thing, str)
mf.seek(0)
os.path.basename(urlparse.urlsplit(url)[2])
a, b, c = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()
index = find(target, key, start_index)
translate(coding_dna, to_stop=True)
k.extend(a)
main()
output.close()
vdisplay.stop()
love_ctx.add((alice, loves, bob))
df.to_csv(combined_file, index=False)
t.remove(elem)
time.sleep(x)
thread.start()
cls(_hours, _minutes, _seconds)
alist2 = []
nl.append(uniq(base, i))
id = Column(Integer, primary_key=True)
B = np.random.rand(100, 2)
a, b = temp_tuple
result = pd.DataFrame()
ax1.set_aspect(1.0)
my_main_func()
soup = BeautifulSoup(html)
b = [x for x in a if x not in itemsToRemove]
uniq = list(uniq.values())
data = request.get_json()
fkwargs.update(gkwargs)
d2 = date(2012, 1, 1)
list(repeat(100, randint, 1, 100))
y = np.arange(W)
df = df[cols]
pd.DataFrame(np.fromstring(arr, dtype=np.uint8).reshape(-1, 8) - 48)
pool.join()
height = int(cv.GetCaptureProperty(cap, cv.CV_CAP_PROP_FRAME_HEIGHT))
print(np.all(b == d))
print(line.strip())
member.value
df.ix[df.Col1.isin(search_list) & (df.Col4 > 40)]
G_pc.add_edges_from(edges_2212)
length = len(s)
layout.addWidget(self.pb)
print(np.allclose(A1, A2))
logger.handlers[0].stream.close()
xml2.getroottree().write_c14n(xml_string_io2)
os.rename(path, newpath)
plt.ylim([-l / 2, l / 2])
proxy._get_current_object()
print(args)
self.config(image=self.frames[self.idx])
line = line.rstrip()
print(leapyr(1900))
self.brushes.append(brush)
words = (w for line in f for w in line.split() if is_difficult(w))
x[()]
main(sys.argv)
mod = __import__(module_name, fromlist=[class_name])
f.close()
print(count)
__init__.py
print(filename)
aList.pop()
sorted(set(a))[-1]
print(df)
lines = file.readlines()
unittest.main()
ignored
cls.change_mro = False
object.__new__(A)
max(PlayerList, key=lambda p: max(p[1:]))
result = conn.execute(sql)
random.shuffle(z)
self.__dict__.update(kwargs)
curs = conn.cursor()
self.thread.start()
print(d[4])
print(results)
B[:, (n)] = np.random.randn(N)
dlg.EndModal(0)
H = H / np.std(H)
arr = np.zeros((200, 20, 10, 20))
legline.set_linewidth(lw)
logOutput.setLineWrapMode(QTextEdit.NoWrap)
app = QApplication(sys.argv)
[n for n, d in list(G.in_degree().items()) if d == 0]
self.setZValue(-1)
print(arr[:])
line1.set_ydata(np.sin(x + phase))
False
data = json.loads(json_text)
args = argparse.ArgumentParser.parse_args(self, *args, **kw)
type.__init__(cls, name, bases, classdict)
df2 = merge(df1, csv2, **kw2)
df
fig = plt.figure()
tasks.append(c.delay(a))
country = CharField(max_length=200)
j.environment.filters.update({})
cur = con.cursor()
dis.dis(f)
fig = plt.figure()
print(foo[0:2])
opener = urllib.request.build_opener(handler)
label1.grid(row=i, column=0)
words = text.split()
soup = BeautifulSoup(html)
self.include_dirs.append(numpy.get_include())
len(vals)
n += 1
path += iter(lambda : predecessor_map[path[-1]], origin)
x.__setitem__(0, 100)
[id(i) for i in a]
isinstance(y, (np.ndarray, np.generic))
f.seek(offset)
etree.tostring(doc, xml_declaration=True)
biggest = mylist[-2:]
calculation()
np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)
f()
cls()
plt.plot(p, x, c=(0, 0, 0, 0.1))
print([x for i, x in enumerate(f) if 1 <= i <= 15])
self.tstore.append([osp.basename(f)])
b = np.unpackbits(bitmap[np.packbits(a, axis=1)], axis=1)
process.kill()
input = raw_input
s.headers.update(headers)
yEstArray.append(yEst)
NULL
merged_list.append((x, index1, index2))
18.28165417900891
print(dirichlet([1] * n))
image_file = Image.open(img_path)
self.chambersinreactor += 1
m.drawcoastlines()
y = numpy.array([numpy.array(xi) for xi in x])
int(mktime(obj.timetuple()))
mydict = {k: v for k, v in list(mydict.items()) if k != val}
_quicksort(array, begin, pivot - 1)
fn = os.path.join(dir, name)
[line.draw(color=(255, 0, 0)) for line in lines]
any(map(lambda c: c.isdigit(), value))
_, s = min((len(values[s]), s) for s in squares if len(values[s]) > 1)
x = np.arange(-1, 1, 0.1)
fig = plt.figure()
dict.__setitem__(self, key, val)
g.db.close()
a.pop(0)
self.tck = fitpack.bisplrep(x, y, z, kx=kx, ky=ky, s=0.0)
self.file_name = file_name
cj = cookielib.LWPCookieJar()
x = np.arange(16).reshape(4, 4)
ax.xaxis_date()
plt.figure(2)
dist = sum(dict[i] for i in range(1, input_key))
str(carray)
df = pd.DataFrame()
animal.save()
p.start()
server = tornado.httpserver.HTTPServer(application)
lambda *a: func(*(a + args))
d = defaultdict(int)
[buildout]
a = Apples()
__init__.py
set(ast.literal_eval(line))
a * c
Base.metadata.create_all(engine)
net.addModule(hidden0)
TerminateProcess.restype = ctypes.wintypes.BOOL
list = yaml.load(file)
my_c_func(values.ctypes.data_as(c_void_p), c_long(values.size))
[_f for _f in lis if _f]
result.update(list(range(int(x[0]), int(x[-1]) + 1)))
axes.set_xticks(ticks[::n])
plt.imshow(img)
now = datetime.now()
result
total = numpy.sum(x + y)
readFrom(stream_proxy.stream())
form = PersonForm(request.POST)
sniff(prn=makecap)
face_list.add((a, x, b))
j += 1
df.columns = df.columns + 1
user.save()
[0.0, 0.0, 1.0],
first_name = models.CharField(max_length=100)
lst.append((start, length))
arr = np.fromiter(itertools.chain(*it), int).reshape(-1, 2)
xy[:, (1)]
ax = fig.add_subplot(211)
red.setTo(Scalar(255), mask_red)
cursor = db.cursor()
print(a([1, 2, 9999, 4, 9999, 9999, 12], 0, 0))
q.put(getattr(a, target)(*args, **kwargs))
print((np.linalg.det(A) - a.det()) / a.det())
stdscr.keypad(1)
pp(expr, use_unicode=True)
show(p)
object_id = models.PositiveIntegerField(null=True)
y.start()
lock = multiprocessing.Lock()
sum(a * b)
intermediate_list.append(td.findNext(text=True))
update_screen()
c = np.setdiff1d(a, b)
Qt.QWidget.__init__(self)
outfp.getvalue()
self.assertFalse(flag)
cv2.waitKey(5)
A = X, Y
datetime.datetime(*map(int, mat.groups()[-1::-1]))
timeit(set(a) & set(b))
pd.DataFrame(dict(columns=box(a).tolist()))
json_data = json.load(json_file)
print(match[0])
self.things_lock = threading.Lock()
d1[k] -= v
t = datetime.time(0, 0, 0)
print(df)
res = np.array_equal(A, B)
h, status = cv2.findHomography(pts_src, pts_dst)
background.paste(img, offset)
path = sys.argv[1]
Y = np.random.uniform(0, 1, size=(ny, dim))
Matrix.map(lambda a, b, **kw: a + b, self, other)
self.response.write(self.jinja2.render_template(template, **context))
f(*args, **kwargs)
image.thumbnail(size, Image.ANTIALIAS)
+1 + 1 + 1 + 1 + 1 + 1 - 1 - 2 + 1 - 1 - 1 - 2
response.close()
q_in.delete_message(qmessage)
print(dict(zip(p, i)))
s = json.dumps(foo)
parser.parse_args()
plt.show(block=False)
print(Example.Variable)
dictionary[new_key] = dictionary[old_key]
sys.stdout = sys.__stdout__
img2 = cv2.imread(img2_path, cv2.CV_LOAD_IMAGE_GRAYSCALE)
print(m.group())
vals[bisect.bisect_right(keys, 0.5)]
sysconfig.get_python_inc()
a = [5, 8, 9]
self.channel = self.connection.channel()
custm.cdf(2.5)
ax.set_axisbelow(True)
[doc for doc in db.units.find()]
len(rg.findall(regexp))
0
ax = plt.gca()
Canvas.__init__(self, parent, **kwargs)
self.__class__(res)
monkey.patch_all()
run_daemon()
pool = Pool(4)
nodes.extend(n.comparators)
print(np.tensordot(v, A, axes=(0, 2)))
wget - q - O - icanhazip.com
crawler.start()
signal.alarm(1)
str.__new__(cls, *args, **kw)
plt.contourf(d)
count += flatten_count(item, element)
os.close(fh)
ax2.yaxis.label.set_color(plot_ax2.get_color())
e1 = tk.Entry(self)
new_dict = dict(zip(keys, initial_list))
img.paste(wmark, (0, 0), wmark)
fig = pylab.figure()
A.__init__(self, 1, 2)
print(r.status_code)
classifier = nbc.train(feature_set)
screen.force_update()
plt.show()
number = random.randrange(10)
item.patch.set_visible(False)
print(unique_rows(data))
sess.run(init)
messages.append(message)
self.d = {}
print(bare_argspec)
now = datetime.datetime.utcnow()
relaxng.validate(doc)
np.random.seed(1977)
[1, 2, 1]
[0.09558515, 0.0, 0.0],
self.Destroy()
fhan.setLevel(logging.DEBUG)
plt.show()
admin.site.register(User, UserAdmin)
[w for w in wordlist if regex.match(w)]
t = numpy.array([0.24])
sock.listen(5)
s[0][0] += 1
self.scrollbar.config(command=self.yview)
new_dict[pair[1]].append(pair[0])
self.connection.shutdown()
print(s.query(A, B).select_from(subq).all())
r[0].tag
setattr(obj, self.private_name, value)
t = TestModel.objects.all()
opener = urllib.request.build_opener(*handlers)
new_foo = []
print(df)
stream.write(self.terminator)
ax.scatter(x, y, s=200, facecolors=rgb)
loc = image.get_rect().center
plt.clf()
df
sess = tf.Session()
p4 = ctypes.cast(id(tb), ctypes.POINTER(ctypes.c_uint))
fig = matplotlib.pyplot.figure()
name = models.CharField(max_length=60)
counts = np.bincount(a)
plt.xticks(xticks)
idx = np.floor(input).astype(np.int)
spotify.playpause()
UTF - 8
width, height = fig.canvas.get_width_height()
sorted(output.items())
loop.run_until_complete(do_work())
g.add_legend()
print(map(etree.tostring, x))
self.inner_sizer.Add(self.test_panel, 1, wx.LEFT | wx.RIGHT | wx.EXPAND, 50)
self.errorcall = errorcall
self.buttonPanel2.Show(False)
all(type(n) == str for n in f)
url, len(page)
new_driver.set_window_size(800, 450)
response = br.submit()
help(list.__contains__)
Queue.interruptable_get = interruptable_get
next(inf)
self.A = np.arange(1000)
content = models.TextField()
df.idxmin(axis=1).values
scopes = list(scopes)
root = tk.Tk()
print(list(round_robin(teams, sets=len(teams) * 2 - 2)))
width, height = orig_image.size
self.layout = QVBoxLayout(self)
rect(x, 0, dx, y, color)
x = np.arange(0, 10, 0.01)
self.start()
dict.fromkeys(s)
string = string[1:-1]
result.append(i)
results.append(i[1])
tostring(root)
sh = book.add_sheet(sheet)
keypoints = detector.detect(imthresh4)
{{secrets | to_nice_yaml(width=50, explicit_start=True, explicit_end=True)}}
c1.setopt(pycurl.PROXYPORT, 8080)
e.bark()
print(imsi)
s = binascii.unhexlify(a)
session2 = SessionDST()
self.serialc.start()
indices = np.arange(9)
plt.plot(X_plot, X_plot * results.params[0] + results.params[1])
tornado.options.parse_command_line()
print(line)
browser = webdriver.Firefox()
db.close_connection()
z.close()
f(b=2, **example)
print(b[:, :, (0)])
f, ax = plt.subplots(1, 1)
data.values[bool_indices]
print(t.overlap((-10, 10)))
str(b)
self.update(dict(*args, **kwargs))
shutil.copyfileobj(r.raw, f)
plt.ylim([-8, 8])
l.append(a)
self.ready.emit()
self.treeview.set_search_entry(self.search_entry)
plt.close()
x = random.choice([a, b])
(x + h & m) - h
values = [item[1] for item in items]
a[:nonzero(a != b)[0][0]]
app = wx.App()
print(cumsum(array))
b = a
[key for key, group in groupby(li) if sum(1 for i in group) == 1]
response = requests.get(newUrl).text
x - np.roll(x, 1)
{key: tuple(d[key] for d in dicts) for key in common_keys}
_odbcinst_SystemINI(szFileName, FALSE)
form.populate_obj(person)
len(self._inner)
cPickle.dumps(object())
self.b.clear_cookies()
logger.setLevel(logging.DEBUG)
venus.circle(108, 1)
print(cmp(list_2, list_1))
max_value = max(sentiment_dict.values())
chain(list_, _foo_suffix())
stopped.set
True
value = process_value(raw_value)
print(doc.prettify())
bar()
G = nx.Graph()
d = defaultdict(list)
set([6])
color = QtGui.QColor(0, 0, 0)
unittest_main()
ax.figure.canvas.draw_idle()
sys.exit()
x = np.array(x)
print(contents)
_f_values[a][b]
print(count)
self.canvas.widgetlock(self.lasso)
signal.alarm(1)
user1 = forms.ChoiceField(choices=choices)
Encoders.encode_base64(ical_atch)
ax.add_collection(lines)
s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
b = np.array([4, 5, 6])
ax.set_zlim(-1.01, 1.01)
data = {}
_jobs[jobname].apply_async(args=args, kwargs=kwargs)
Y = np.matrix([[1, 0, 1, 1]]).T
crawler.crawl(spider)
numpy.random.shuffle(index_array)
cerr << endl
text.pack()
self.setLayout(v_box)
response = urllib.request.urlopen(request)
time.sleep(1.0)
data = s.recv(1024)
print(df[col].value_counts(dropna=False))
fibm(x - 1) + fibm(x - 2)
self.data.pop()
cursor = con.cursor()
False
pairs[mask]
result.extend(sublist)
w.wcs.cdelt = numpy.array([cdeltX, cdeltY])
print(groups.median())
funcs.append(c)
app.exec_()
next(self.iter)
self.window.get_toplevel().show()
os.makedir(sdsd)
defaultdict(int)
increments[n - 1] += 1
os.chdir(tmp_location)
file_handle.write_to(text)
print(re.escape(s))
[4, 1, 1]
yolk - l
string.format(*diff, **some_date)
layout = QtGui.QVBoxLayout(self)
A[:, (j)] = x ** j
someList.append(copy.copy(foo))
res = NP.append(my_data, new_col, axis=1)
S2 += len(set(ids))
print(line)
obj = json.loads(encoded)
a = np.arange(10)
df.year = df.year.astype(int)
callback(self._global_wealth)
res.extend(res_females.get())
max_index = np.argmax(a[inds[:, (0)], inds[:, (1)]])
sound.stop()
response.write(bytes)
root = Tk()
print(f[1])
print(elt.eltid)
some_other_func(something_else)
traceback.print_exc(file=sys.stderr)
print(add_time(datetime(year=2015, month=12, day=25), relativedelta(months=+1)))
count += 1
id = db.Column(db.Integer, primary_key=True)
idx = np.where(a)[0]
print(model.__name__, [x.name for x in model._meta.fields])
self.hbox.pack_start(self.button, False, False, 0)
new_items = {str(item) for item in items}
browser.add_handler(auth_NTLM)
mask = X ** 2 + Y ** 2 + Z ** 2 < radius ** 2
idx = random.choice(list(range(num_outcomes)))
groups.append(newGroup)
cr.rectangle(0.0, 0.0, *widget.get_size())
waw - 0.464188
x.item()
fp = os.path.join(dirpath, f)
data = response.json()
d = collections.defaultdict(list)
data = grouped_count.apply(as_perc, total=df.my_label.count())
os.unlink(filename)
example[4:0] = [122]
[atlas]
counts = collections.Counter(l.strip() for l in infile)
mvnorm.pdf(x, mean=0, cov=1)
G.add_edge(u, v, weight=w)
peasant.knock_over()
self.f_ = f
obj.__class__ = type(base_cls_name, (base_cls, cls), {})
pythoncom.PumpWaitingMessages()
b.delete_key(k)
instance = reservation.instances[0]
d = {}
ceiling_key(d, 0)
print(difft2(time(20, 40, 0), time(22, 41, 0)))
debian
key = bytes([19, 0, 0, 0, 8, 0])
attachment.get_content_type()
print(C)
print(type(unicode_text))
out.writerow(data)
json.dump(r.json, sys.stdout, indent=4, ensure_ascii=False)
ind1[cx1:cx2], ind2[cx1:cx2] = ind2[cx1:cx2].copy(), ind1[cx1:cx2].copy()
plt.plot(x, kd_vals)
y = np.random.randn(N)
install.run(self)
cell.value = 1
axs[i].get_yaxis().set_ticks([])
self.num = foo.num + 1
a = []
plot(x, y)
set(main_array) - set(second_array)
sportDict[ransport].append(name)
numpy.nextafter(1, 0) > 1 - sys.float_info.epsilon
s.dt.components
self.send_blob(blob_info, content_type=type1, save_as=save_as1)
print(np.intersect1d(B, ind))
f0(s(t))
writer.writeheader()
name = models.CharField(max_length=200)
print(list(text.get()))
self._start = start
d = OrderedDict()
relative = os.path.relpath(path, directory)
a.resize(len(b), refcheck=0)
main()
i[0]
locations.append(locationx)
float(1.0).is_integer()
root = Tkinter.Tk()
post_save.connect(my_post_save_handler)
lambda : user_is_admin(cherrypy.request.login)
M[index]
player.clearCards()
mask1 = np.in1d(out_id, a[:, (0)])
signal.alarm(0)
print(sc.parallelize(list(range(i * 10000))).count())
x = np.random.randn(10000, 10000)
arr = i * np.ones((2, 4))
{NULL, NULL}
dumper.represent_int(hex(data))
browser.submit()
lengths = Counter(len(v) for v in list(testdata.values()))
legend_fig.canvas.draw()
mod1.pxd
print(line, line2)
x.pop(0)
stdscr.clear()
d = dict(zip(keys, groups))
X = np.hstack((X, AllAlexaAndGoogleInfo))
0.7105, sym2, 6, 5, 10, 10
self.Bind(wx.media.EVT_MEDIA_LOADED, self.song_is_loaded)
s = df.sum(axis=1, level=[0, 1]).T
self.f1 = MethodType(f, self, self.__class__)
q.put_nowait((url, host))
[_ for _ in iterable if not _.isdigit()]
x = [1, 2]
df = pd.concat([df, dummies], axis=1)
c = a + b
data_rows.append(row)
user = models.ForeignKey(User)
np.import_array()
Py_Initialize()
t.show()
f.z
deletenum_list[0]
worker.finished.connect(self.thread.quit)
alchemy / bin / bpython
xlim(0, 10)
self.sock.settimeout(self.timeout)
pattern = url[0][1]
archives[-1]
print([int(bn[i:i + 8], 2) for i in range(0, len(bn), 8)])
root.mainloop()
print(merge_to_couples(new_list))
df = pd.DataFrame(data2)
print((y, z, bigmat[:, (y), (z)]))
expr.subs({x: 10, y: 5})
self.label
list_of_numbers.append(float(val))
dt = parser.parse(s)
A[(0), :, :]
print(line)
difflib.get_close_matches(dud[0], pc_dud)
print(df1)
df1 = df1.reset_index()
CharField.__init__(self, *args, **kwargs)
sck = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
to_modify[indexes[index]] = replacements[index]
pickle_test()
import_module(moduleName)
m = numpy.random(100, 100) > 0.5
f.write(str_object2)
B = np.reshape(A, (A.shape[0], A.shape[1], np.prod(A.shape[2:])))
f1.seek(start)
V = numpy.dot(X.transpose(), X)
mask = tf.placeholder(tf.bool, shape=(n, n))
a = wrp_testchar(byref(steps), byref(in_data), in_char)
print(elem.text)
result = [[(e - 1) for e in i] for i in n]
print(mag(data))
mars.speed(1)
ndb.put_multi(model_dbs)
test.columns = pd.MultiIndex.from_tuples(index_tuples)
data = array([[1.766, -1.765, 2.576, -1.469, 1.69]])
{{form.name()}}
handle_last_line(previous)
array([[1.0, 4.0], [2.0, -1.0]])
[bins[k] for k in np.searchsorted(bins, my_series)]
stack.pop()
shape = [x.size for x in output]
dct = obj if isinstance(obj, dict) else obj.__dict__
self.mainLayout.addWidget(self.scroll)
tree = dict()
a[:, (b)].T
_diff -= timedelta(days=1)
self.tin2.SetLabel(self.tin.GetValue())
y = np.array([2, 1, 5, 10, 100, 6])
p = mp.Pool(processes=4)
[5, 6, 7]
bp.show()
soup = BeautifulSoup(s)
callable(obj)
yaml.dump(d, default_flow_style=False)
np.allclose(a, collapse_dims(a))
print(jsons_data)
plt.figure(i + 1)
reactor.run()
thread.join()
w = Tkinter.Tk()
t = numpy.linspace(t_start, t_end, t_len)
canvas.itemconfig(item, fill=self.on_color)
ax2.set_xlim(-5, 5)
shutil.copyfileobj(sys.stdin, sys.stdout)
pprint.pprint(result)
elements.extend(namedElements)
A = A.view(dtype=np.float64)
print(square(double(Maybe(5))).unwrap())
Data[..., (0)] + 1j * Data[..., (1)]
X.append(x)
locale.setlocale(locale.LC_TIME, l)
m.show()
d.foo()
x.T
im.size
print(user.addresses)
transport = ssh.get_transport()
signal.signal(signal.SIGINT, handle_signal)
li2.extend(sublist)
fd.write(t)
print(df)
some_code()
myView.setItemDelegateForColumn(columnNumber, myItemDelegate)
main()
self.register_errors(result)
f2.write(line)
shutil.copy(str(self), str(target))
result
map(complex, c)
self.hof[0].reshape(self.N, self.N), log
self.d[num] = d[num] + 1
mydict[repr(key)] = mydict[key]
array_by_hand.tostring() == array_from_layers.tostring()
list.__setitem__(self, i, 10)
self.data = np.append(self.data, row)
tmp_dlls.append(os.path.join(cdir, dll))
cur = self.connection.cursor()
SimpleHTTPServer.SimpleHTTPRequestHandler.do_GET(self)
True
df2.reindex(df1.index, level=0)
acc[0]
kNN_classifier(train_data, k, distf)
new_list = []
NotImplemented
seen = set()
capture = cv2.VideoCapture(0)
wx.Panel.__init__(self, *args, **kwargs)
cv2.polylines(vis, [corners], True, (255, 255, 255))
print(cache1.value.groups())
layout = QHBoxLayout(self)
foo.__defaults__
self.write(prompt)
counter = counter + 1
a, b, c, d = unpack_list(*sub_list)
print(convert(0))
5, [False, True, False, False]
self.checkWeight()
isclose(1, 1.00001)
ax = fig.add_subplot(111)
exit(0)
plt.ion()
Interleave(A, B)
uniquekeys.append(k)
ImageQuerySet(self.model, using=self._db)
data = get_data()
method(*args, **kwargs)
self.button.clicked.connect(self.start_thread)
logger = logging.getLogger()
db = create_session()
float(n) / (1 << p)
print(x)
QtGui.QFrame.__init__(self, parent)
i += 1
indices = np.arange(y.shape[0])
self.children = []
self.server.sendMessage(message[::-1])
diff[y, x] = img2[y, x] - img1[y, x]
filehandle.seek(-1, os.SEEK_END)
b = np.roll(b, shift[j], axis=0)
integers = [int(x) for x in fileStr if x.isdigit()]
data = f.read()
mcastsock.bind((mcast_addr, port))
file.close()
self.update(*args, **kwargs)
req = urllib.request.Request(url=url, data=request_data, headers=headers)
self.canvas = FigureCanvasQTAgg(self.figure)
proc.join()
O(n)
foo.__code__.co_consts[1].co_consts[2]
examined_modules.append(calling_module_name)
df = pd.concat([s, rolling_dd], axis=1)
y2 = np.random.rand(10) * 20
unique_list = list()
f.seek(1, 1)
~np.isnan(A)
afile.close()
add5(4)
log_handler.setFormatter(formatter)
db.session.add(self)
GL.glViewport(0, 0, 200, 200)
_cell.style.font.bold = True
main()
True
print(df.loc[list_of_values])
base.all()
dis.dis(lis[2])
x = [((2, 1), (0, 1)), ((0, 1), (2, 1)), ((2, 1), (0, 1))]
filehandler.close()
[objid_to_idx[id(obj)] for obj in lst]
cur.execute(sql, (pyodbc.Binary(data),))
self.sizer.Add(self.lblname, (1, 0))
list(splitclusters(a))
form.tags.process(request.form)
map(operator.add, A, B)
print(p.map(minimize, args))
filecount += 1
self.result.append(word)
result = [lines[0][x] for x in unique0] + [lines[1][x] for x in unique1]
HttpResponseRedirect(e.response)
print(len(s))
print(expandtabs(input, 10))
im.thumbnail(size, Image.ANTIALIAS)
path = request.get_full_path()
b.pack()
array([1, 2])
s.shutdown(0)
ax = fig.add_subplot(1, 1, 1)
memcache.set(request.my_name, value)
bar.set_alpha(0.8)
xlim(0, 10)
list()
listener.join()
result[index] += 1
print(args)
self.s_out.close()
b = [4, 5, 6]
plt.figure(1)
df = df[df[group] != group_name]
ax.add_patch(patch)
response = urllib.request.urlopen(req)
id = db.Column(db.Integer, primary_key=True)
z = np.outer(np.cos(theta), np.ones_like(phi))
app = Flask(__name__)
N = len(list_of_lists)
x + x
token.get_access_token(code)
output.close()
logging_test()
foo = [(a + 42) for a in foo]
response = conn.getresponse()
os.unlink(f.name)
new_df = my_instance.load_dataframe()
ifconfig
{{other_content}}
NULL
fig = plt.figure()
print(newDict)
timer1.start()
np.put(a, np.where(a == 0.0)[0], np.nan)
user = request.user
reader = csv.reader(f)
x = np.random.randint(0, 10, size=(10, 2))
font = ImageFont.load_default()
response = mechanize.urlopen(request)
update(message)
s = stru()
C = np.linalg.eigvals(B)
c = pd.read_csv(StringIO(s))
np.mean((np.dot(X, W) - y) ** 2) + alpha * np.sum(np.abs(W - W0))
csr_matrix(M1).dot(M2)
stdin = sys.stdin
print(m.as_string())
np.unique(np.concatenate((a, b)))
totaldict = defaultdict(list)
{4}.issubset(chain.from_iterable(x))
grid.fig.set_figwidth(6)
word.Repaginate()
a = [0] * 8
df
min(triplets, key=distance)
numpy.random.shuffle(data)
a.todense()
1 + 1
dests.add(node)
cities.append((city.name, int(distance)))
pygame.display.flip()
wn.synsets(word)
print(i)
func(value)
outputStream.close()
self.autocomplete(-1)
self.de = QtGui.QPushButton(str(self.current))
xy[:, (1)] > 0
test()
nltk.download()
a = np.random.random_integers(2, size=(4, 4))
z / (1 + z)
plt.contour(Y, X, T[:, :, (round(len(z) / 2))], 64)
self.show()
colors = np.linspace(0, 1, len(patches))
plt.pause(1)
module = loader.find_module(module_name).load_module(module_name)
np.array([d[x] for x in u])[inv].reshape(a.shape)
[10, 10, 9, 7, 4]
c += a + b
pairs_by_number_and_list[pair[1]].append(pair)
t = Timer(10, lambda p=p: p.terminate())
offset = cet.utcoffset(dt)
f.write(text)
dat = pd.DataFrame(np.random.randn(5, 5))
d = defaultdict(dict)
pylab.show()
root = Tk()
book.save()
f()
print((sectorsPerCluster.value, bytesPerSector.value))
result[i] = cpmethod(i)
dir(int)
x = np.reshape(x, (4, 4))
print(type(img))
matches.append(m.group(0))
ax.yaxis.set_minor_formatter(matplotlib.ticker.FormatStrFormatter(format))
k = np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]])
self._data = data
DEBUG = True
self.send_my_headers()
mailServer.starttls()
img = PhotoImage(width=WIDTH, height=HEIGHT)
s.listen(backlog)
module = __import__(k)
atexit.register(shutil.rmtree, test_area)
hops.insert(0, url)
aware = datetime.datetime(2011, 8, 15, 8, 15, 12, 0, pytz.UTC)
user = models.ForeignKey(User)
root = gtk.gdk.get_default_root_window()
ps.line(lineFrom, lineTo)
self.assertEqual(expected, list(map(str, sorted(versions))))
tuple(mydata.transpose())
self.out_queue.put(result)
holtwinters(y, 0.2, 0.1, 0.05, 4)
l = logging.getLogger(__name__)
response
a = np.random.randint(2, size=(10000, 100))
urllib.request.HTTPSHandler.__init__(self)
time.sleep(1)
ws.set_vert_split_pos(1)
layout.addWidget(self.button)
parser = argparse.ArgumentParser()
app.register_blueprint(routes)
df1
output
fig = plt.figure()
p1.wait()
data = numpy.array([[0, 0, 1, 0, 1], [0, 1, 1, 1, 0], [1, 0, 0, 0, 0]])
remove(file_path)
pr.disable()
t = datetime.now()
df[col] = df[col].shift(periods)
keys = {k for d in all_dicts for k in d}
today = datetime.date.today()
self.addLine(0, yc, width, yc)
UDBG.enable_pdb()
int((time.time() + 0.5) * 1000)
data = fin.read().splitlines(True)
a[::-1]
chr(ord(match.group(0)[0]) + 1) + match.group(0)[1:]
b = np.matrix(np.ones((2, 4)))
salt = str(random.getrandbits(256))
seq_in[:] = (x for x, k in seq)
widget1.grid(row=0)
G = nx.Graph()
im.size
ax.grid(False)
browser._wait_load()
plot(x, y2)
a / (sqrt(2) * inverseErf(P))
mask = np.random.uniform(size=(4, 4))
fn(**kwargs)
time.sleep(self.sleep_time)
points.append((xs[i], ys[j], v))
self.root.after(10, self.Inputs)
{(0): 0, (1): 1, (2): 2}
metadata = MetaData()
text = file.read()
p = Pool(4)
B -= B.mean()
[(i[1:] * int(i[0]) if i[0].isdigit() else i) for i in l]
False
print(bisect(list_, item))
fig, ax = subplots()
net.sortModules()
line = proc.stdout.readline()
fullname = os.path.join(dirpath, fname)
np.array_split(x4D, x.size / (p * q), axis=0)
np.array_split(x2D, x.size / (p * q), axis=0)
next(self._it)
Series(result, index=labels)
stdout.flush()
p.terminate()
mylist.extend(get_more_data())
app = Flask()
output += os.read(fd, 4096)
ax = plt.gca()
l = [0, 0, 1, 1]
obj.foo.__func__ is Cls.foo
clf.set_params(**grid)
nn.activate([0, 1])
query = query.decode(charset) % escaped_args
self.__dict__.update(x)
c, a = s.accept()
D = np.delete(np.arange(np.alen(A)), C)
print(a.get())
asymmetric_enc(session_key, pubkey), symmetric_enc(message, session_key)
B_process.wait()
ax = plt.gca()
response = urllib.request.urlopen(req)
runner.run(mySuit)
print([x for x in list_dirs if os.path.basename(x) not in unwanted_files])
dt.year
raise StopIteration
mask = ~np.in1d(unqID, np.where(count > 1)[0])
nonzero(r_[1, diff(st)[:-1]])
s.str[:2]
ax = plt.gca()
count[word] = 1
show()
df
print(escaped_string)
newser.plot(ax=axes[0])
input = PdfFileReader(packet)
[DRIVER_ISSUE]
reader.Update()
dict((key, round_floats(value)) for key, value in o.items())
[2, 2, 1, 1]
sys.stdout = unbuffered
inspect.getgeneratorstate(a)
ax2 = ax.twinx()
self.application.save()
list(islice(iterable, n))
print(inputoutput[ii])
res = df.astype(bool).astype(int)
obj = MyClass()
ndx = orig_indices[numpy.searchsorted(xs[orig_indices], ys)]
h2, l2 = ax2.get_legend_handles_labels()
images = scrapy.Field()
all(c in string.printable for c in hello)
print(item)
print(repr(b))
time.sleep(10)
urllib.request.install_opener(opener)
self.window.show()
s.values
all(A[p] < A[i] for i in get_neighbors(p, len(A)))
app = Flask(__name__)
self.file.flush()
d = datetime.date(2011, 9, 1)
t.setdefault(keyList[-1], value)
do_something_with_o(r())
(lambda d: lambda : self.root.change_directory(d))(d)
print(segment.min(), segment.max())
df1 = df.copy()
print(is_png(data))
l = [1, 5, 7]
do_something()
server.socket.close()
hash2 = hash2.hexdigest()
self.button.draw()
True
file = os.path.join(temp_path, baseFile)
self._x == other._x and self._y == other._y
y = sparse.csr_matrix([[0, 1], [1, 0]])
results = []
print(key_val, key_val.etag)
doc = lxml.html.parse(res.content)
glClearColor(0.0, 0.0, 0.0, 0.0)
file_a.write(new_a_buf.getvalue())
plt.close()
image = image_response.read()
ranges[:, (1)] - ranges[:, (0)]
row = cursor.fetchone()
a.append([])
print(save_virtual_workbook(wb))
alist = [0, 0, 0, 0, 0, 0, 1]
sum_sum_digit(1969)
fig1 = plt.figure()
parse_qs(urlparse(url).query, keep_blank_values=True)
self.myq.put(THEEND)
df.Seatblocks
print(l)
start + timedelta(seconds=random_second)
st[:i + 1]
foo.bar - foo.baz
doc = html5parser.fromstring(body)
f(v)
root = Tk()
self.removeItem(line)
raise FileNotFoundError(filename)
self._from2scomplement(self.__next__)
do_something_with_stdout(line)
plt.xticks(np.array([]))
graphs_sizer.Add(chart_canvas, 20, flag=wx.EXPAND, border=5)
urlopen(req)
self.sizer.Layout()
plt.hist(random(1000), 100)
df = df.ix[:, :1]
thing.close()
setattr(module, symbol, obj)
x[-1] = binascii.hexlify(x[-1])
[1, 10], [1, 10]
System.out.println(sum)
cam = pmb.expanding(min_periods=1).apply(lambda x: x.argmax())
print(x, y)
self.stack[-1] += 1
name = models.CharField(max_length=200)
K = np.arange(n - 1)
lens = np.array([len(i) for i in ll])
data = json.loads(line)
torfile.add_node(node)
stack[0]
data
data = chunks[-1]
DT.time(hour, minute, second, microsecond)
zipped.sort()
foo(20, 4)
raise KeyError(key)
x = dict([(k, list(l)) for k in range(1000)])
cur.close()
b.f()
dfs.append(df)
conn.close()
print(_.strip())
s = cv2.SURF()
Food._meta.get_all_related_many_to_many_objects()
width = int(cv.GetCaptureProperty(cap, cv.CV_CAP_PROP_FRAME_WIDTH))
mylist = [(a, b), (c, d), (e, f)]
self.item = item
n1 = dt.datetime.now()
self.load_data()
diffs = dict((k, k2.index(k) - k1.index(k)) for k in dict1)
fig = pylab.figure()
self.create_dummy_request()
p.start()
d = {v: [i for i, x in enumerate(materials) if x == v] for v in set(materials)}
next(a)
d[text_idx, np.arange(len(text_idx))] = 1
l.insert(i, Y)
print(result)
array[idx - 1]
fcntl.fcntl(s, fcntl.F_SETFL, os.O_NONBLOCK)
nx.path.bidirectional_dijkstra(G, 1, 5)
print(C(1, 2).__dict__)
func(**kwargs)
[hex(x) for x in e]
process(line)
driver = webdriver.Firefox()
fig = PLT.figure()
fun(args)
a[::2]
type(x) == my.object.kind
r[i, j, x[i, j], y[i, j]] = c[i, j]
print(fun1(1, 2))
counts = Counter(word for line in f for word in line.split())
provided.add(item)
d.addCallback(lambda _: reactor.stop())
self._array[self._index[index]]
now = datetime.now()
main()
im.load()
ZZ[t]
c = a.copy()
[0, 1, 1, 1]
os.fchmod(fd.fileno(), mode & 4095)
Base.metadata.create_all(bind=engine)
getattr(p, s)
x = [elt[0] for elt in y]
ax.set_xticks([1.5, 4.5, 7.5])
dict_x[key] = [value]
self.x1, self.y1 = _rot(self.x1, self.y1)
sio.truncate(0)
font.setPointSize(10)
Window.pack()
plt.ylim([log10(0.1), log10(10)])
b = np.zeros((n_b, n_b), dtype=a.dtype)
time.sleep(0.01)
len(file_content) > 0
y = points[:, (1)]
df
model = create_model()
print(sum_shells(b))
matching_lines = list(filter(filter_func, string_list))
dt = mytz.normalize(mytz.localize(dt, is_dst=True))
False
phone = models.CharField(max_length=100)
print(data.values[np.in1d(data.ages, desired_ages)])
plt.subplot(6, 6, i + 1)
decoded = cipher.decrypt(base64.b64decode(encoded))
reactor.listenTCP(8080, site)
Y = np.random.normal(size=(10, 5))
renL.SetActiveCamera(cameraL)
pclose(helper)
[list(a), list(b)]
win.addstr(0, 0, root)
cert = OpenSSL.crypto.load_certificate(OpenSSL.crypto.FILETYPE_ASN1, key)
sys.exit(1)
p = mp.Process(target=some_long_task_from_library, args=(1000,))
ax.plot_surface(x_surf, y_surf, z_surf, cmap=cm.hot)
foo = timeit(foo)
dict(string)
img = erode(img, kern_size)
output = np.empty(indices[0].shape)
pivots = zeros((n,), fortran_int)
i = np.arange(len(pts))
result[i] = cpmethod(cpargs)
new_strs.append(x)
a = numpy.arange(1000000)
plt.xlim([log10(0.1), log10(10)])
frame.pack(fill=BOTH, expand=1)
sum(dct.get(k, 0) for k in lst)
config = configparser.ConfigParser()
ebks, ks
tree = ET.parse(file_path)
print(x.reshape((1, x.shape[0])).type)
ax.set_xticks(np.arange(AUC.shape[1]) + 0.5, minor=False)
args = sys.argv[1:]
d1 += timedelta(days=mdays)
b = np.random.rand(6, 5)
print(ddiff)
d = xml.sax.parse(PseudoStream(), SAXHandler())
self.assertEqual(6, s)
window.show()
foo.method2(foo.method1)
self.set_default_size(100, 100)
help(combinations)
ax = fig.add_subplot(1, 1, 1)
plt.plot([1, 2], [1, 2])
x = np.arange(1000)
queue = Queue()
self.assertTrue(any(set(lst) <= e for e in self.merged))
104.405 - -hochl
5.018 - -katrielalex
dis.dis(f)
settings.configure()
bus = dbus.SessionBus()
x = np.random.normal(0, 1, 1000).cumsum()
NP.insert(T, 0, c, axis=1)
ax.draw_artist(line)
df = pd.DataFrame(data)
myseries_three.iloc[0]
[syndication]
file_open.close()
g = Github(token)
plt.yticks(np.arange(0.5, 10.5), list(range(0, 10)))
print((step, sess.run(W), sess.run(b)))
app = QApplication(sys.argv)
time.sleep(60)
print(url1, url2)
i.interact(message)
event.ignore()
a = np.zeros((100, 100, 10))
name = forms.CharField()
lfun
self.mySub()
repo.commits
traceback.print_stack()
instance = MyClass()
choices = Choice.objects.filter(poll__in=polls)
[1, 2, 2]
0
CALLBACK(func)
self.model.query
print(A.indptr)
browser.select_form(nr=1)
logger = logging.getLogger()
answer = [i for i in range(1, 1001) if isSumOfSquares(i ** 2)]
hexagon(50)
A * exp(-(x - mu) ** 2 / 2 / sigma ** 2)
r.content
print(arr[(cond), :])
B = np.concatenate((A, A), axis=1)
func
im = np.asarray(Image.open(filename))
restart_line()
a = float(x)
1 / 1024.0 / 1024.0
possibles = [x for x in remaining if x[:1] == start[-1:]]
dir(object)
int(s)
app
s = serial.Serial(5)
setattr(instance, attr, value)
df.a.quantile(0.95)
self._value + n
PorterStemmer().stem_word(word)
[0, 1, 1]
rows.append(row)
test = this_friday + timedelta(weeks=-1)
select.select([sys.stdin], [], [], 0) == ([sys.stdin], [], [])
self.pubsub.close()
print(result)
s.translate(str.maketrans(dict.fromkeys(rem)))
propdict[attrname] = getattr(a, attrname)
stopButton.pack()
sys.stdout.write(output)
items.append(item)
root = Tk()
print(v.__dict__)
print(f.as_integer_ratio())
a = date(2011, 11, 24)
fo.close()
ax.set_rgrids(list(range(1, 6)), angle=angle, labels=label)
num = float(num)
foo = MyClass()
self.scrollbar = Scrollbar(self.data, orient=VERTICAL)
Clock.schedule_once(self.set_attributes)
print(offs)
x = np.linspace(-2, 2, num=20)
print(np.asarray(curve.intersection(hline)))
self.request = request
conn.setopt(pycurl.VERBOSE, True)
xdiff = line1[0][0] - line1[1][0], line2[0][0] - line2[1][0]
df
self.children.append(myChild(name, self))
self._result_queue = result_queue
a = bytearray(5)
child_midpoints.append(child_end + width // 2)
setOverlays(cfloats)
show(layout)
x, y = [[] for x in range(2)]
plt.grid(True)
print(item)
end = datetime.datetime.combine(today, end)
x = np.random.random(10)
id = np.append([0], np.any(np.diff(sorted_Ar, axis=0), 1).cumsum())
pre_save
BaseObject._initialize()
x, y = ogrid[0:img.shape[0], 0:img.shape[1]]
pkcs11.load(libacospkcs)
existing.merge_result(task_from_json(slug, **task) for task in taskdata)
words = sentence.split()
print(a.parent)
x * (a + d + g) + y * (b + e + h) + z * (c + f + i)
colorama.init()
event_box.window.set_cursor(gtk.gdk.Cursor(gtk.gdk.HAND1))
L.sort()
pp.plot(ar)
parser = argparse.ArgumentParser()
f = func()
wn.ADV
wn.VERB
self.conn.commit()
y = np.random.randint(0, 10000, size=5000000)
largest, second_largest, third_largest
print(list(sub_findre(s, substring, 2)))
to_product.append([(k, v)])
tmp = ax.transData.transform([(0, 0), (1, 1)])
slice = myarray[..., (i)]
isitIn(char, aStr[:len(aStr) // 2])
db_thread.start()
psyco.full()
email = Column(String, unique=True)
ax.set_xlim([0.1, 0.8])
dis.dis(foo.__code__.co_consts[2].co_consts[2])
dest.write(line)
pd.to_datetime(date_time)
app = Flask(__name__)
C = [B.popleft() for _i in range(4096)]
z = itertools.chain(x, y)
do_some_ather_thing()
p = PatchCollection(patches, cmap=matplotlib.cm.jet, alpha=0.4)
image = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2RGB)
v[:, (0)]
args = parser.parse_args()
print(df1)
sleep(2)
edges[i, j + 2].append((i, j - 2))
top = tk.Tk()
sys.exit(1)
os.remove(os.path.join(root, name))
b = a[:5, :5]
data = np.random.random((10, 10))
data = f_input.read()
Parent.__init__(self)
main()
num_fatals += 1
a = 0
plt.imshow(lab)
awesome_dict
clf()
df_a.join(df_b)
globals()[name] = value
b = np.zeros_like(a)
desired_list = [x for x, _ in tuple_list]
driver = webdriver.Firefox()
ax.set_xticks([])
print(self.name)
logging.basicConfig(level=logging.INFO)
b[:, :, (0)]
array([1]),
line = input()
cls
run_initialization_stuff()
logger.addHandler(hdlr)
fd = sys.stdout.fileno()
date(2011, 1, 15) - date.today()
print(hex(agency))
c = threading.Thread(target=consumer, args=[q])
sys.getrefcount(astrd)
axis([0, 25, 0, 10])
Results.objects.saved_once().all()
address = models.CharField(max_length=200)
lines = fp.readlines()
p.join()
d = defaultdict(lambda d=d: d)
print((i, j))
len(counts)
content = models.TextField
p = kde(x)
r = csv.reader(file_b)
d = datetime.datetime.utcnow()
set(chain.from_iterable([word.lemma_names() for word in synonyms]))
pl.show()
print(np.mean(l))
print(xyzzy)
v_box.addWidget(self.box_one)
func(self, *args, **kwargs)
self.f.write(data)
ii = np.nonzero(y)[0]
peers[i].send(chunk)
list(chain.from_iterable(summ_neg(x)))
d = defaultdict(list)
b = np.where(a == 9)
gx, gy, gz
self.fp = self.file_or_path = file
debug = False
combo.addItems(li)
plt.show()
app.logger.addHandler(logging.StreamHandler())
process.terminate()
time.sleep(1)
c.set_visible(vis)
print(df)
x_ = np.linspace(0.0, 1.0, 10)
listy[1] = [1, 2]
sleep(1)
locals()[name] = a.__dict__[name]
id(1 == 1)
R, C = np.where(mask.T)
funcs.append(lambda x=x: x)
pd.DataFrame(listOfNewRows)
cherrypy.config.update(conffile)
con = pyodbc.connect(odbcstring)
n2 = dt.datetime.now()
handle_line(line)
p.wait()
a = asarray(a)
ax = fig.add_subplot(111)
a, b, c = final(a, b, c)
s.push(10)
self.load_picture()
exp(-(x - mu) ** 2 / (2 * s ** 2))
ylim = ax.get_ylim()
indices = [numpy.where(a <= x)[0][0] for x in b]
match.groupdict()
df
cursor = connection.cursor()
self.button.setMaximumSize(QtCore.QSize(128, 128))
queryset = Person.objects.all()
obj.get_related_deltas(epk)
[(sum(x) / float(n)) for x in partitions]
fh.write(header)
print(f.method())
code = func.__code__
app.exec_()
any(phrase in text for phrase in word_list)
pd.Series((df.values * (df.columns.values + sep)).sum(1)).str.split()
w2.append(words[1])
not sum([(not i in A) for i in B])
horse_frog
out, err = proc.communicate()
str in [type(entry) for entry in example]
B().update()
form = ModelForm(request.POST)
startupinfo = subprocess.STARTUPINFO()
user = UserProfile.objects.get(pk=1)
result = pool.map(worker, groups)
self.assertTrue(1 + 1 == 2)
d = defaultdict(lambda : defaultdict(list))
a[0] + a[1] / float(10 ** (int(log(a[1], 10)) + 1))
print(y.shape)
loop.run_forever()
response
print(cmp(list_1, list_2))
order = list(perm)[::-1] + [n]
heapq.heappop(heap)
print(np.random.dirichlet(np.ones(10) / 1000.0, size=1))
p = pyaudio.PyAudio()
hxs = HtmlXPathSelector(response)
ax = fig.add_subplot(111)
lock = multiprocessing.Lock()
entity = query[0]
ret = func(*args, **kwargs)
sum(zip(res, args), ())
np.arange(k - i) == ix[:-i]
b = [9, 8, 7, 6, 5]
help(str.replace)
len(read_file(filename))
res = service.cse().list(q=search_term, cx=cse_id, **kwargs).execute()
A.__init__(self)
count = 0
word_len_dict[len(word)].append(word)
parse_with_lxml()
ax.invert_yaxis()
map = random.randrange(1, 10)
datetime.datetime(2000, 1, 1).replace(**fields)
[v for v in list2 if v in list1]
print(mse(model_2_v2.predict(xg_test), y_test))
print(n)
[result.extend(sublist) for sublist in lst]
root = lxml.etree.fromstring(x)
product = models.ForeignKey(Product)
print(df1)
path = os.path.abspath(sys.executable)
print(num)
oldest = max(people, key=lambda p: p.age)
app = QtGui.QApplication(sys.argv)
f1(f2(*args, **kwargs))
Py_DECREF(str)
raise KeyError(key)
notebook.set_tab_reorderable(child, True)
score = IntegerField(validators=[required])
Fader.update()
print(mention.user.screen_name)
import_array()
mod
r.content
line = lines.pop(0)
fig, ax = plt.subplots(1, 1)
self.assertEqual()
csock.close()
ax.set_xticks(ind + width / 2)
print(s[sl])
dates = [dt for dt in rrule(MONTHLY, dtstart=strt_dt, until=end_dt)]
server.serve_forever()
streng
fn(*args, **kwargs)
instance = form.save(commit=False)
B = np.empty_like(A)
print(combine_dicts(a, b, operator.mul))
window.open(url)
fesetround(FE_TOWARDZERO)
fesetround(FE_UPWARD)
fesetround(FE_DOWNWARD)
ax.add_collection(coll)
mp.complete_upload()
b = a
stmts.append(s)
[y for x in lst for y in untuppleList2(x)]
cmath.sqrt(-0j) == -0j
self.panel = wx.ScrolledWindow(self, wx.ID_ANY)
length = len(input_string)
b = tf.Variable(tf.zeros([10]))
ax.plot(list(range(5)))
ax.mouse_init()
self.line = self.ax.scatter(self.x, self.y)
do_totally_different_thing()
self.buttonPanel2 = wx.Panel(self)
Test.test_call
self.stream.write(data)
indices, vals = zip(*data)
mod.doSomething()
max_index = len(row) - 1
tk = Tk()
rolled = np.roll(y, -1, axis=0)
[4, 5, 6],
setattr(self, item, args_dict[item])
image = cv2.imread(path_to_image, cv2.IMREAD_UNCHANGED)
print([vertex.label for vertex in x])
name = Column(String(20))
data.append(float(line))
schema_doc = etree.parse(f_schema)
config.readfp(source)
id = db.Column(db.Integer, primary_key=True)
d = d.replace(c, sep)
sqs.meta.client._endpoint.http_session.close()
[(x - 1 - i, n) for i, n in enumerate(range(x))]
a = 2
manager = multiprocessing.Manager()
print(locals())
fout.write(line)
fixed = s[0:pos] + s[pos + 1:]
MyClass.__dict__ = {}
self._port = port
x = tf.Variable(tf.ones([]))
self.thread = threading.Thread(target=self._wait)
keyfunc = lambda x: len(x)
print(listD)
K.mean(K.square(y_pred - y_true), axis=-1)
x, y
x, y
print(getSubStrings(a, 2))
assign(subarg, subvalue)
l = np.sqrt(6 * (a + c + np.sqrt(b ** 2 + (a - c) ** 2)))
sys.stdout = sys.__stdout__
df
process_a.start()
b.append(sublist)
b.extend(a)
heappush(self.queue, item)
k.set_contents_from_filename(testfile, cb=percent_cb, num_cb=10)
kOUT[0]
hash.hexdigest()
print(tostring(elem))
t = threading.Thread(target=work, args=(name,))
tf.start_queue_runners()
app = Flask(__name__)
[]
model = linear_model.LogisticRegression()
[5, 8]
slice(start, stop, step)
series1 = np.arange(10)
i += 1
help(re.sub)
pool.map(fn, list(range(10)))
draw.ellipse((25, 25, 75, 75), fill=(255, 0, 0))
deletei
x[::-1]
results = []
ax[0].legend()
self.func(*args)
tuples = zip(string.printable, itertools.repeat(0))
a.argmax()
result.append([])
B = numpy.array()
ax.ticklabel_format(useOffset=False)
[1, 0]
df.idxmax(1)
[(u.value, u.meta) for u in set([b, d, f]).intersection(set([a, c, e]))]
model = Sequential()
mainloop.run()
a = np.zeros((nx, nz))
face_list.add((x, a, b))
s.commit()
widget.bindtags((tag,) + widget.bindtags())
self.vtkPolyData.GetPointData().SetScalars(self.vtkDepth)
newlist.append(x)
api = tweepy.API(auth)
tv.set_search_column(1)
self.x = np.linspace(0, 5 * np.pi, 400)
ceiling_key(d, 4)
2 - (B, C, F, E)
set(l1)
np.dot(output, slicevol) / 2
bool(1)
app = QApplication(sys.argv)
next(other)
writer.writerow([4, 5, 6])
url = db.Column(db.String(2048))
raise ValueError(HELPING_EXPLANATION)
dis.dis()
ceiling_key(d, 1)
agent_list = [list(ast.literal_eval(line)) for line in f]
my_array = numpy.empty([1, 2], dtype=object)
requests_log.setLevel(logging.DEBUG)
rescaled.shape = newshape
numbers = [1, 2]
queryset = User.objects.all()
result.extend(node._values)
print((root, name))
p.join()
(s[i:j] for i in indexes(s) for j in indexes(s[i:], i + 1))
label.set_visible(not win.is_fullscreen)
axes[0].pcolormesh(x, y, z)
[item.upper() for item in arg]
p.poll()
main()
QtCore.QThread.run(self)
cv2.imwrite(os.path.join(dirname, name), frame)
np.random.seed(24)
t1 = time.time()
a[:, (non_index)] = b
sys.stdout = sys.stderr
br = mechanize.Browser()
print([list(items) for g, items in groups])
run()
e = a[0:1]
print(count.most_common())
b = a[::2]
result.append(msvcrt.getche())
printcake()
listener.handle_event(event)
print(df)
True
v.append(len(item))
cv2.imwrite(sys.argv[2], skin_ycrcb)
r = np.sqrt(xdist ** 2 + d ** 2)
time.sleep(1)
row[1] = row[1]
app = Flask(__name__)
--nogroup
do_stuff()
print(cob.x)
fig.subplots_adjust(top=0.9)
data = np.fromfile(file, dtype=dt)
result
sorted(enumerate(sample), key=lambda n_v: abs(n_v[1] - pivot))[:k]
self.assertEqual(d1, d2)
ADO.csv
AFG.csv
figure()
data = json.load(o)
logger.log(f.__name__, args, result)
shutil.copyfileobj(f, response)
d = np.diff(np.asarray(a, dtype=int))
map(itemgetter(0), groupby(L))
self.rotate()
app.register_blueprint(bp)
y = np.zeros((yt, xt))
scat.set_array(data[i])
self.SetMinSize((100, 100))
twitter = Twython(APP_KEY, APP_SECRET, OAUTH_TOKEN, OAUTH_TOKEN_SECRET)
self.sprockets = set()
b = np.hstack(np.array(b))
f.save()
BaseHTTPRequestHandler.__init__(self, *args)
df.reindex(df.b.abs().order().index)
print(replace_item(lst, to_replace, replace_with))
Table.append(temp)
_func()
d = dict((n, i) for i, n in enumerate(e[0] for e in l))
print(line)
result = urllib.request.urlopen(request)
ipaddress.ip_address(ipv4invalid)
plt.plot(b, a1)
lr.set_params(params)
x = np.arange(2)
Console.Write(result)
deleteli[i]
print(a[:, (np.newaxis), :].shape)
M = X * A + (W * B).T + Z * G
my_generator.is_just_started
start_time = time.time()
signal.signal(signal.SIGALRM, inputTimeOutHandler)
compact_ranges(comp)
a.sort(numeric_compare)
requests.get(uri)
serial.Serial(dev, *args, **kwargs)
fig.axes.get_xaxis().set_visible(False)
d = {t.tag: {k: (v[0] if len(v) == 1 else v) for k, v in list(dd.items())}}
print(df)
cv2.circle(vis, (x2, y2), 2, col, -1)
df.printSchema()
Py_DECREF(mymodule)
print(root.nodes.node[1].PCDATA)
convert_to_dict(my_dict)
sorted(strings)
my_dict[k] = v
self.root.after(527, self.readSensor)
proc = Popen(cmd, shell=True, bufsize=1, stdout=PIPE)
A[:, :1] = x
fig = plt.gcf()
self.start_urls = get_start_urls()
free(cfloats)
then = datetime.now() - timedelta(hours=2)
G.add_edge(1, 2)
z.close()
plt.xlim((-limit, limit))
fig = plt.figure()
max(curr, subs, key=len)
gevent.spawn(read_stream, p.stdout, stdout)
self.func()
frame.Show()
get_object_or_404(queryset, pk=1)
df
yvalues = 0.1 + np.arange(len(ylabels))
self.cls = cls
content = resp.read()
idx = np.where(indices < arr.shape, indices, clipping_value)
fileobj.write(response.read())
log.setLevel(logging.DEBUG)
blobstore.delete([item.blob_key])
imshow(Iopen)
d = datetime.date(int(y), int(m), int(d))
do_something_6()
self.canvas.mpl_disconnect(self.cid)
_SHGetFolderPath(0, csidl, 0, 0, path_buf)
_Lappend(_normal(0, 1))
random.shuffle(shuffled)
self.buttonPanel2.Show(True)
blank_image.paste(fluid128, (400, 0))
datetime.datetime.now
ax2.bar(dates, list(range(10, 20)))
self._start_worker(pair)
print(node.render(Context()))
difflib.get_close_matches
f()
print(value)
sys.modules.update(old_modules)
print(pizza.toppings.all())
cam = Camera()
X, Y = np.meshgrid(x, y, copy=False)
pprint.pprint(response)
ax2.set_ylim(-5, 5)
print(delta.days)
i = int(s, 8)
thread1.join()
l = [0, 2, 4, 5, 9]
True, True, True, True, False, False, False, False, False
mask = np.isfinite(lg)
[True, True, True, True, True],
print(df)
c(a, b)
suite = unittest.TestSuite()
i += 2
a = [list(i[1]) for i in itertools.groupby(data, key=lambda i: i == 0)]
a[a == 0]
label = Label(f, *args, **kwargs)
data = csvfile.read()
button2.configure(command=lambda widget=button2: DoSomething(widget))
file_handles.append(open(file))
json.dumps(object)
con.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)
list2 = list(map(itemgetter(0), grouped))
reverse(view_name, kwargs=kwargs, request=request, format=format)
conn.send(finalLine)
root = tk.Tk()
t.start()
a[(i), :] = line.split()
im = ax.imshow(dat, vmin=0, vmax=2)
keys = [x for x, y in list(dic.items()) if y == maxx]
w.mainloop()
foo()
print(fmt.format(*row))
print(line)
self._running = False
app.run(processes=8)
r = requests.get(send_url)
f(map(rec, iterable))
value
time.sleep(2)
df = df.T
plt.rcParams.update(params)
self.__storage.append(p)
data = f.read()
hash(test(10)) == hash(test(10))
stream.write(msg)
application.listen(config.tornadoport)
self.login()
out = a[mask]
fs = [(lambda y: lambda x: x + y)(i) for i in range(10)]
stdin.flush()
print(regx.split(string))
b = a.groupby(level=0).cumsum().groupby(level=0).shift(1)
ax2 = ax1.twinx()
fout.write(line)
process(m)
r.status_code
Base.metadata.create_all(e)
f(1, 0, 1)
print(i, rec_fib(i))
index_list.sort(reverse=True, key=int)
dupl.append(j)
[i.number for i in li]
imgplot.set_clim(0.0, 0.7)
substring in string_
df
metadata = MetaData(bind=engine)
TemplateResponse(request, template_name, context)
xlab.set_size(10)
ylab.set_size(10)
n = sum(1 for line in csv.reader(filename))
G = nx.Graph()
b = [2, 6, 4, 5, 6]
myFunc()
ax.set_xlabel(wrap(ax.get_xlabel()), rotation=90)
response
now = datetime.datetime.now()
li = [-1, -1, 2, 2, -1, 1, 1, 1, 1, 1, -1, -1]
x, y = xs[i], ys[i]
nx.draw_networkx_edge_labels(G, pos, labels=edge_labels)
foo + bar
SHAhash.update(hashlib.md5(buf).hexdigest())
A = np.arange(0, 20.0)
s[0]
a = list(a)
b.extend(c)
np.clip(c, a, b)
parser = ET.XMLParser()
events.sort()
name = models.CharField(max_length=255)
a[0:5:1]
msg.attach(part)
print(a[0, 0])
ax = pyplot.subplot(1, 1, 1)
chambersinreactor, cardsdiscarded
print([next(i2 if x else i1) for x in [0, 1, 0, 0, 1]])
MyConcreteClass()
_singleton.foo_func()
MyAbstractClass()
rotated = list(reversed(zip(*original)))
a.insert(0, a.pop(-1))
not bool(search(strg))
mylist = [True, True, False]
df[col_zscore] = (df[col] - df[col].mean()) / df[col].std(ddof=0)
type(a[1])
request.query_string
s = signal.signal(signal.SIGINT, signal.SIG_IGN)
pickle.dump(object, f)
fig1 = plt.figure()
queryset = ModelName.objects.all()
print(str(table))
result = _PySequence_IterSearch(seq, ob, PY_ITERSEARCH_CONTAINS)
NULL
int(s)
django.core.management.setup_environ(settings)
check_matr(b, 0)
self.increment()
fig = plt.figure()
{{group.users}}
f(A)
hxs = HtmlXPathSelector(response)
self.assertEqual(1, 1)
ans.append(letter)
os.mkfifo(pipe_name)
_PyUnicode_NONCOMPACT_DATA(op)
result = getattr(self.contained, item)
paths.append(split[2:-1])
deletea[k]
ax.set_zlim(0, 10)
session = session()
b = pandas.DataFrame(np.arange(1000, 1025, dtype=np.float16).reshape(5, 5))
myFunc(2, 5)
numpy.genfromtxt(*args, **kwargs)
print(i)
gobject.timeout_add(5000, set_mask, win)
cbar.ax.tick_params(labelsize=5)
[1]
2 * a
B[y:y + N, x:x + N]
A = [0, 0, 0, 1, 0, 1]
my_shelf[key] = globals()[key]
permstr
train_test_split(a, b)
byte_array[i] = (val << 16 >> 8 & 16711680) >> 16
self.textinput.bind(text=self.on_text)
set_a - set_b == set_b - set_a
InetAddress.getByName(IP)
df.fillna(s)
fig = plt.figure(figsize=(8, 6))
my_dict = {k: some_func(k) for k in input_list}
print(st[-m.start(1) - len(m.group(1)):-m.start(1)])
proc.wait()
results.extend(tmp_results)
T = np.dot(V, U.T)
QVariant()
w, h = [int(x) for x in next(f).split()]
i += 1
db.BeginTrans()
x = dict((row.SITE_NAME, row.LOOKUP_TABLE) for row in cursor)
json.dump(dict(value=True), sys.stdout)
output = proc.stdout.read()
pca.fit(df)
result = grouped.agg(combine_it)
s = wx.BoxSizer(wx.HORIZONTAL)
print(row[0 + i:chunckLen + i])
asyncio.run_coroutine_threadsafe(coro, self.loop)
d.utcoffset()
generateFoos()
output = scipy.signal.convolve(signal_in, h)
numpy.all(x == x.T)
f2 = [(2 * x) for x in range(100)]
driver = webdriver.Firefox()
self.Count += 1
GEOIP.country_name_by_addr(ip)
np.int(x)
cls.create_table()
InitializeComponent()
request = urllib.request.Request(url)
print(my_data[x], my_data[x + y])
new_x
opener = urllib.request.OpenerDirector()
temp = []
items = [item for item in soup.contents if isinstance(item, bs4.Doctype)]
result = df2.reindex(np.union1d(df1.index, df2.index))
app = QApplication([])
t.create()
layout = QGridLayout(self)
self.__dict__[name] = value
set(A) - set(subset_of_A)
fig = plt.figure()
output.close()
xdebug.remote_port = 9000
pylab.imshow(arr)
print(v)
float(strg)
plt.plot(np.arange(10, 1, -1) + i)
data = np.arange(10, dtype=np.int)
session.expunge_all()
time.clock() - start
opener = urllib.request.build_opener()
shortcut.save()
print(first16)
ax.set_xticklabels(empty_string_labels)
np.average(meanNumbers)
finish()
self.sa = [l[2] for l in L]
os.rmdir(dir)
b.start()
name = Column(String, primary_key=True)
signal = np.cos(5 * np.pi * time) + np.cos(7 * np.pi * time)
tagged.sort(lambda x, y: cmp(x[1], y[1]))
dG.add_edge(word, next_word, weight=maxint - 1)
print(list(fun(iterable)))
list_common.append(a)
loop.run_forever()
conn.Open(dsn)
Z.__init__(self)
self._storage[key].add(word[len(key):])
print(node.render(Context()))
re.sub(pat, replace, txt)
element = np.ones((5, 5)).astype(np.uint8)
name = db.Column(db.String(255), primary_key=True)
zf.write(modfile, os.path.relpath(modfile))
w = list(s)
self.im_data_lock.release()
dict(dd)
{}
worksheet = workbook.add_worksheet()
first, second = tee(f())
dir(l1)
np.random.seed(1001)
img.putpalette(palette)
x = list(range(1, 10))
reactor.stop()
w2.set_keep_above(True)
cb = plt.colorbar(s)
print(data[index] == values)
G.add_nodes_from(L2)
data2 = data1.reset_index()
req.send_response(200)
dis.dis(foo)
print(line)
fig, ax = plt.subplots()
dq.append(next(reader))
self.setter(instance, self.name, value)
im1.save(tilefilename, self.tiledriver)
sorted(pairs)
r = follow_redirections(r, s)
fn()
(0, 10, 11, 12, 14, 16) == 0, 10 - 12, 14, 16
b = np.delete(a, np.s_[-1:], 1)
strprime += str(x % 10)
deletePoint.__init__
min(a for sub in Q for a in sub)
out = [float(f_interp(XX, YY)) for XX, YY in zip(X, Y)]
print(months(11, 2010, 2, 2011))
systemtest_1.py
{k: list(v) for k, v in list(ret.items())}
canvas.Canvas.save(self)
len(lst) - i - 1
Base.metadata.create_all(engine)
hm.UnhookMouse()
temp.append(0)
f.baz()
False
specgram(signal)
arrayName.byteswap(True)
s.feed(html)
G.add_edge(2, 6)
df.reindex(ind & ind2).join(df2.reindex(ind & ind2))
fh.readline()
self._age = value
l2 = [4, 5, 6]
my_table.add(tr([th(i, style=header_style) for i in data.columns]))
sys.modules[themodname] = themod
marshal.dump(g.__code__, funcfile)
primes = [x for x in primes if x == i or x % i]
axes = plt.subplot(111)
plt.xlim(0, 600)
button.grid()
x = np.linspace(0, 100, num)
result[0], result[1]
entity_manager.commit()
sorted(set(x), key=x.index)
my_data
self._observers.append(callback)
plus(n)
ipList.append(str(IPAddress(ip)))
True
ax = plt.gca()
cur = con.cursor()
ret.append(t)
np.unique(np.concatenate(x))
soup = BeautifulSoup(html)
fig, ax = plt.subplots()
np.fill_diagonal(mask, 0)
fig.set_size_inches(w, h)
Grid.rowconfigure(grid, y, weight=1)
a, b
view.setModel(model)
self._check_size_limit()
print(map(timestamp, fridays))
np.equal(np.mod(x, 1), 0)
con.row_factory = my_row_factory
[(k, sum(1 for _ in i)) for k, i in it.groupby(L)]
mask = np.ma.masked_array(a)
id = models.UUIDField(primary_key=True, default=uuid.uuid4, editable=False)
twitter = Twython(APP_KEY, APP_SECRET)
ax = plt.gcf().axes[0]
True
a = [1, 2]
what_bson_type([1, 2])
start_time = time.time() + 20
count += 1
s = pd.Series([True, True, False, True])
print(formatdate(timestamp))
zf.filelist.append(zinfo)
hash((self.name, self.location))
cursor = connection.cursor()
item = myset.pop()
Ml
print(df)
doSomethingWith(instance)
self.mygraph.set_xydata(self.xaxis, self.data[-1])
ns = parser.parse_args()
flipcase | othercommand > ouput.txt
es = ES.Elasticsearch()
good, bad = [], []
f = plt.figure()
self._popup.destroy()
result = []
df
driver = webdriver.Firefox()
print(string)
plt.show()
new_list2.append(i[1])
print(hex(id(v)))
x.append(x_center)
y = array([1, 1, 1, NaN, NaN, 2, 2, NaN, 0])
s.add(y)
group = map(itemgetter(1), g)
a = numpy.random.randint(100, size=100).reshape((10, 10))
n, mod = divmod(n - len(first), len(digits))
self.assertTrue(ip2.ip in result_ips)
Dummy().a
(i - j) % 9 == 0
[c for c in foo if c not in temp and (temp.add(c) or True)]
u, v = np.mgrid[0:2 * np.pi:20j, 0:np.pi:10j]
self.layout = QtGui.QVBoxLayout(self)
rpy2.robjects.conversion.py2ri = conversion_pydataframe
g._group_actions.sort(key=lambda x: x.dest)
print(sorted(L, key=Key))
print(floor(d * 100) / 100)
queue.append([start])
out.write(result)
primes[:bisect(primes, n)]
test.main()
pool.join()
c = func(*args, **kwargs)
answer += s[:-1]
sql.add(customer2)
self.__age
out = list(df.b[final_mask])
u = set.intersection(*setlist)
u = random.uniform(0, 1)
deleteseq[index]
x = np.array([-2, -1, 0, 1, 2])
print(diff.total_seconds())
state.commands.update(callables)
words = words[:]
txt.set_color(line.get_color())
pdb.set_trace()
f.config(width=5)
8
bar = Bar.objects.get(pk=target_pk)
f.write(chunk)
today = datetime.now()
x = np.random.normal(size=(number,))
uniq[index.argsort()]
[factorial(n) for n in nums]
zip(*iterators)
arr[left:right]
metadata = MetaData()
ss.genextreme.fit(data, floc=0)
cls.num += 1
deactivate
dict(zip(list(row.keys()), row))
ax = plt.subplot(111)
wrapper
application = get_wsgi_application()
values = numpy.random.randint(6, size=(6, 10))
cv.ReleaseCapture(cap)
df.dtypes
c = dbconn.cursor()
y = keypoints[i].pt[1]
source.clojure
source.cmake
source.coffee
source.disasm
source.dockerfile
source.dosbatch
source.erlang
source.gdbregs
source.gradle
source.groovy
source.haskell
a[ix_(Xinds, Y2inds)]
func(that, session, *args, **kwargs)
old_settings = termios.tcgetattr(fd)
event_box.set_border_width(10)
ws.insert_bitmap(file_out, 0, 0)
image[..., (0)] = np.minimum(image[..., (0)], threshold)
cmyk_im
dictionary = json.loads(data.getvalue())
mults.append(int(np.ceil(inShape[i] / finalShape[i])))
plt.bar([1, 2], [4, 5])
root = Tk()
CV_Assert(img.channels() == 1)
print(compare(expand(a)))
xml.writexml(out)
step = (end - start) / (N - 1)
_.shape
f.close()
x = float(sys.argv[1])
inspect.getsource(f)
fig.show()
fig, ax = plt.subplots(1, 1)
frame.grid_columnconfigure(1, weight=1)
s = requests.session()
df.dtypes
myfuncs[0]()
tuple(h - t for h, t in zip(head, tail))
next_emitted.append(name)
self.stepsize = stepsize
inspect.getmembers(Foo, inspect.ismethod)
x1 = x[:, 1:-2]
k.set_contents_from_file(resized_photo)
contents = urllib.request.urlopen(request).read()
self.scrollToItem(self.item(visible.row(), column))
print(enumerate.__doc__)
u = array([array(x) for x in set(tuple(x) for x in input)])
turtle.begin_fill()
list(g)
mat_csr[(idxs), :] = 2.0
self.server.server_close()
df1.shape
do_something()
gcc
cmake
setting2 = somesetting
print(sum(x ** 2 for x in lst if x % 2 == 0))
getFoos()
time.sleep(5)
min_value = min(new_array)
df = df[df[c].isin(df[c].value_counts()[df[c].value_counts() > m].index)]
row.append(token)
window = gtk.Window()
df2.loc[1:] = [list(s1), list(s2)]
keys.append(k)
y = numpy.array([2.56, 4.79, 6.21])
df.index = df.index[::-1]
br = mechanize.Browser()
updatebins(bins, binsize, x)
f = lambda i=i: i
gtk.main()
a = a - 1
deleteglobals()[name]
[n, m]
full_path = os.path.join(dirpath, filename)
f = pd.read_csv(file, index_col=0)
ob.stackoverflow(2)
q = queue.Queue()
result
x * x
f
c = np.vstack(b)
start = time.time()
format(value, spec)
result = f(*args, **kwds)
self.client.close()
tableWidget.setColumnCount(len(entries[0]))
root = etree.parse(f, parser=parser)
d = mat.shape[1]
z = np.zeros((2, 1), dtype=int64)
records = csv.DictReader(f)
ax.scatter(x1, y1, s=100, lw=0, color=[1.0, alpha, alpha])
[0.0, 1.0, 0.0],
x.sort(key=custom_key)
thread2.start()
letters.remove(chr(letter))
task.interrupt()
print([(key, median(val)) for key, val in list(data_dict.items())])
ax.set_xlim(-2, 2)
termios.tcsetattr(self.fd, termios.TCSAFLUSH, self.old_term)
a.dot(b)
renWinL.AddRenderer(renL)
self.ax = self.fig.add_subplot(111)
pool = multiprocessing.Pool(4)
self.f.do_it()
a[2:4, 2:4] = 1
log_file.write(line)
sum((i.time_spent for i in self.intervals), timedelta(0))
cv.SetData(image, tiff.tostring())
do_something(line)
c = tensordot(a, b, axes=(0, 0))
self.thread.join()
print(url)
li = st2.split()
_run_finalizers(0)
n = len(G.nodes())
sorted(list(range(len(a))), key=a.__getitem__)
logging.getLogger().addHandler(logChannel)
df
form = ForgotPassword(data=request.POST)
d(10) ** d(10) ** d(10)
dict(zip(a.names, list(a)))
urllib.request.build_opener(proxy_handler, proxy_auth_handler)
ax.semilogy(x)
n
curs = orcl.cursor()
mylist = list(d.values())
HTML_with_style(df.head(), style)
regex = re.compile(pattern, flags=re.MULTILINE | re.DOTALL)
print(list(makerange(s)))
dict(keyValList)
self._data.columns.size
[0, 4, 5, 1],
gtk.main_quit()
fp.seek(i)
print(line)
node = node.getNext()
l2 = l[:c_index]
self.data.append(r)
turtle.fillcolor(color)
m.Blit(0, 0, w, h, s, 0, 0)
a, b = next(g)
image = np.fromstring(im_str, np.uint8).reshape(h, w, nb_planes)
cursorObj.connection.commit()
dict(zip(a.names, map(list, list(a))))
help(np.core._dotblas)
print(twrv.join())
ax = fig.add_subplot(1, 1, 1)
groups = groupby(sorted_input, key=itemgetter(1))
xx, yy = np.meshgrid(np.linspace(2000, 2200, 10), np.linspace(540, 740, 10))
B = [1, 2]
print(df.iloc[(0), :])
count += 1
PyObject * PyEval_GetGlobals()
csv_writer = csv.writer(my_new_list)
print([sum(aa[i:i + w]) for i in range(len(a))])
request.end()
list(range(args[0], args[1], 1))
sheet.write(cell, value, cell_format)
_draw_point(i, j - 1, fade_amount_i)
self.helpers = helpers
k.set_contents_from_string(out_im2.getvalue())
print(enclosing)
root = tree.getroot()
connection = httplib.HTTPConnection(req.get_host())
delattr(instance, self.name)
[0, 1, 2, -5, 4, 5, 6, 7, 8, 9]
specgram(signal)
mycoll.insert(stop_dict)
outputStream.close()
iter(input)
np.all(z == x)
profile = UserProfile.objects.get(user=request.user)
sheet.set_clip(pygame.Rect(sprt_rect_x, sprt_rect_y, len_sprt_x, len_sprt_y))
print(line)
print(roundPartial(9.75, 0.1))
print(roundPartial(9.76, 0.1))
plt.xlabel(ax1_label)
lxml.html.document_fromstring(e)
simulate(image, text)
d[k] = v.lower()
print(e)
self.setCellWidget(row, col, image)
csr_matrix(coo)
pl.yticks(np.linspace(0.0, 1.0, 11, endpoint=True))
plt.plot(yvalue)
sleep(5)
file.seek(-count, 1)
plt.show(block=False)
np.cos(theta, out=x[:, (0)])
threads = [threading.Thread(target=worker) for _i in range(20)]
script2.run(filename)
pool.join()
a = np.arange(10).reshape(2, 5)
round_to(n, 0.05)
dic[k].append(v)
print(x1.dtype, x1.nbytes)
d[k].append(v)
self.num_vertices = self.num_lines * 2
deleteself.dictionary[key]
w.writerow(list(somedict.keys()))
results = Model.objects.filter(pk__in=pks)
writer.writerow(fields)
twitter = Twython(APP_KEY, APP_SECRET)
d = {}
m_1.append(line)
contents = sourceFile.read(BLOCKSIZE)
self.fp2.close()
lines = list(reader)
np.array([[1, 0], [0, 1]]).__array_priority__
x = np.array([1, 2, 0, -2])
monthrange(2012, 2)
freeMem.argtypes = [ctypes.c_void_p]
sheet = workbook.sheet_by_index(0)
self.button = []
f.write(att.content)
now.microsecond
print(sp.pixel(0, 0))
rows = cur.fetchall()
self.lda[bow]
inputs.append(conn)
name = Column(String(64), nullable=False)
posts = Post.query.all()
f(*args, **kwargs)
np.array(-0.0) == np.array(+0.0)
big_table[nchunks].update({hash: file.filename})
self.process.kill()
nextelem = li[idx]
wr = csv.writer(your_csv_file, quoting=csv.QUOTE_ALL)
zip(A, cycle(B))
app = create_app()
non_blank_lines = (line.strip() for line in fd if line.strip())
np.apply_along_axis(wrapper, axis, F)
queue.close()
shpinfo.append(shapedict)
points.set_data(x_c, y_c)
y.__reduce__()[1]
line = sys.stdin.readline()
c[2]
todays_files.append(original_file)
x = 2
A = A.apply(np.sort, axis=1)
self.CalculatePopularity()
print(item.name, item.birthday)
sum_sum_digit(sum_)
root.destroy()
self.mainFrame().load(QUrl(url))
print(sc2().get_subclass_name())
df.dtypes
list(dic.items())
p = figure(plot_width=400, plot_height=400)
show()
writer.save()
{{page.title}}
result = collections.defaultdict(int)
[rand_vector() for _ in range(length)]
self.response.out.write(f.read())
self.allowed_domains.remove(hostname)
sector_el = [x[1] for x in remaining]
a = A()
all(x[0] == y for y in x)
self.stdin_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
plt.figure()
simplejson.load(f)
grid_sizer_1.Add(self.tree_ctrl_1, 1, wx.EXPAND, 0)
main_loop.start()
objects = InheritanceManager()
func()
new_name()
print(hit.contents[6].strip())
plt.figure()
np.isfinite(diff_images).all()
b = np.array([0, 1, 0])
yi = np.array([0.0, 0.5, 1.0])
value[2:4]
alltests = unittest.TestSuite()
np.diagonal(a.dot(b))
ax = np.histogram2d(x_data, y_data, bins=bins)
v = enumerate(printmylist(mylist))
out = np.split(sorted_a, shift_idx)
print(b[0])
[4, 5, 6, 7],
application = app.wsgifunc()
mylist = []
p = figure(x_range=(0, 1), y_range=(0, 1))
reader = PdfReader(input_file)
self.do_open(httplib.HTTPConnection, req)
os.umask(oldmask)
(x >= 0).sum()
np.argmax(aa > 5)
s = str(a).zfill(prec + 1)
self.coconut = coconut
base64.b64decode(data[1])
extmodule.override()
self.c.config(width=w, height=h)
input_file = args[0]
p = multiprocessing.Pool()
cmdutils
json.dumps(f(*args, **kwargs))
plt.xticks(np.arange(0.5, len(df.columns), 1), df.columns)
writer.writerow(row)
self.i += 1
cr.set_line_width(10)
layout.addWidget(self._listview)
p.start()
obj.__class__.set_x_class(15)
gc.set_debug(gc.DEBUG_UNCOLLECTABLE | gc.DEBUG_COLLECTABLE | gc.DEBUG_STATS)
session2.merge(obj1)
title[::-1]
pd.Series([timedelta(int(i)) for i in d])
new_x = np.linspace(x.min(), x.max(), new_length)
Y = Y[list(range(n / 2))] / max(Y[list(range(n / 2))])
print(str(newdom))
[(mappend(str(x)) if y else unmappend(str(x))) for x, y in d.items()]
request = urllib.request.Request(url)
print(r.findall(line))
x.append(i * 2)
print(pool.map(f, list(range(10))))
queue.get()
xi, yi = np.meshgrid(xi, yi)
mask = np.isnan(arr)
nx.draw_networkx(gr)
db.init_app(app)
fig, ax = plt.subplots()
x = np.arange(10, 1, -1)
print(link.tail)
func = CALLBACK(lambda x: myPythonCallback(x))
stack.append(msg)
c = Counter(item for dct in my_list for item in list(dct.items()))
[item for items in zip(first, second) for item in items]
print(parser.format_help())
data = {k: [v] for k, v in list(dr.next().items())}
c._Z15writePixelsRectP8JoxColoriiii(data_array, 0, 0, WIDTH, HEIGHT)
os.stat(fullname).st_ctime
queue.join()
ax = fig.add_subplot(1, 1, 1)
self.progress_bar_lock.release()
a, b = zip(*c)
hi_file.write(hi_web.read())
self.rematch = re.match(regexp, self.matchstring)
d = {}
self.ClickedLB2.move(200, 150)
cs = axs[0].contourf(X, Y, zdata, levels=levels)
QWebView.__init__(self)
print(link.string)
t.cancel()
self.parser = create_parser()
b = a + b
L = [1, 2, 1, 1]
[a.pop(2), a][1]
plt.clf()
keys = {k[0]: (0) for k in list(d.keys())}
self.window = gtk.Window(gtk.WINDOW_TOPLEVEL)
fig, ax = plt.subplots()
sorted(list(kwargs.items()), key=itemgetter(0))
line = line.rstrip()
buffer = buffer_from_memory(y, 8 * array_length)
filehandler.close()
request = self.initialize_request(request, *args, **kwargs)
[7500, 7500]
url = models.CharField(max_length=255, unique=True)
self.l = iter(l)
numpy_fillna(data)
pool = Pool()
imshow(im)
findAll(tagname, recursive=False)
print(fmtpairs(list(string.ascii_uppercase)))
a[perm]
parsed_output.close()
start, end = datetime(2015, 11, 2), datetime(2015, 12, 14)
parser = PullSuggestions()
self.assert_equal(mocked_handler.call_count, 1)
content = gzip.GzipFile(fileobj=StringIO(content_raw)).read()
hash((self.value, self.meta))
temp = np.argpartition(-test, 4)
out = np.array([f(i) for i in range(1, n - 1)])
x.a
result = ast.literal_eval(response[1])
inverted_image = PIL.ImageOps.invert(rgb_image)
data = json.load(json_data)
[0, 0, 0, 0, 0],
self.foo()
out[i] = np.count_nonzero(dists < Rsq)
ax.axis([-4, 4, -4, 4])
[1, 1, 1]
ii = np.random.randint(0, 10, (a.shape[0],))
self.flush()
window.show_all()
self.session.flush()
person = models.ForeignKey(Person)
fig = plt.figure()
self.__dict__.update(dict(zip(properties, pslList)))
QtWidgets.QMainWindow.__init__(self)
G = nx.DiGraph()
heappush(heap, item)
np.random.seed(42)
handler = logging.StreamHandler(sys.stderr)
self.successors.remove(other)
self.viewport.add(self.img)
len(get_file_contents(filename).splitlines())
upform = UserProfileForm(instance=user.get_profile())
x[np.logical_and(*b)]
self.func(*args, **kwargs)
dict(id=self.identity, data=self.data)
my_svc.fit(x_training, y_trainc)
s[6]
y, x = np.mgrid[-5:5:100j, -5:5:100j]
df = pd.DataFrame(data)
my_list[0] = my_list[2] = my_list[0] + my_list[2]
triplets[iT].append(listB[0])
results = [data[i:i + n] for i in range(0, len(data), n)]
session.add(c1)
user = models.ForeignKey(User)
worksheet.set_column(idx, idx, max_len)
sess.run(init)
id = Column(Integer, primary_key=True)
f()
sys.exit(1)
ax = fig.add_subplot(111)
wrapper(**mydict)
itertools.zip_longest(fillvalue=fillvalue, *((iter(itr),) * n))
t.hour * 60 * 60 + t.minute * 60 + t.second
A[j] = (A[j] - factor * A[i]) % q
k = list(d.keys())
a[0][0]
path = os.path.abspath(path)
concatenation.append(selection.pop())
y = ax.get_yaxis().get_clip_box().y1
dir(x)
print(np.all(x2[find_map(x1, x2)] == x1))
pl.show()
endfor
time.sleep(1.0)
log.Date = pd.to_datetime(log.Date)
random.uniform(0.1, 2.7)
queue.put(line)
sum(coeff / (i + 1) for i, coeff in enumerate(reversed(coeffs)))
HttpResponseRedirect(post_url)
logging.basicConfig(filename=LOG_FILENAME, level=logging.DEBUG)
display.display(pl.gcf())
result.append(i)
form = UserprofileForm()
self.root = logging.getLogger()
print(pkl)
slice_coords_by_x(arr, xmin=2, xmax=4)
width, height = img.size
char = ord(char)
client = app.test_client()
form = MyForm()
frame.Show(False)
bool(self.match)
output_file.write(l)
seen = set()
next(self)
w = np.sqrt(6 * (a + c - np.sqrt(b ** 2 + (a - c) ** 2)))
a.sort()
df
print(self.recv(8192))
(d.day - 1) // 7 + 1
el2.extend([numpy.nan] * (len2 - len(el2)))
m.groups()
self.command_table[command]()
np.exp(exp_A, out=exp_A)
str(x)
xx, yy = numpy.mgrid[:200, :200]
index = dict(zip(lis, list(range(len(lis)))))
html = template.render(context)
SetValue(reg, pythonkey, REG_SZ, pythonpath)
min(alist, key=lambda x: abs(x - target))
output = popen.stdout.read()
sys.path.insert(0, pth)
down.append(up.pop())
add_to_the_class < AnotherClass > ()
HttpResponse(t.render(c))
arr = np.arange(10)
NotImplementedError
lst = map(int, str(num))
[a], [b]
self.children.append(node)
y = np.rollaxis(y, -1)
a + a
print(f(2))
unittest.TestCase.__init__(self, methodName)
xs = np.linspace(0, 2 * np.pi, 25)
self._init_extra(*args, **kwargs)
cpp.MyClass * _obj
list(group_660.values())
gb.count()
list1[i] = v
map.plot()
[to_nltk_tree(sent.root).pretty_print() for sent in doc.sents]
self.ax.set_ylim(ymin, ymax)
listmix.TextEditMixin.__init__(self)
output = proc.communicate()[0]
lines = f.readlines()
rolled = np.roll(y, 1, axis=1)
gc.disable()
itertools.product(iterable, repeat=2)
x.columns = x.columns.droplevel(0)
str(bin(7))
Counter(k for k, g in groupby(strs))
conn = urllib.request.urlopen(url)
ActionChains(context.browser).send_keys(Keys.ENTER).perform()
df = pd.DataFrame()
unittest.TextTestRunner(failfast=True).run(suite)
thread.join()
title_tag.string
a.append(i)
result = [C for C in with_distances if C[0] < limit]
main()
Queue.get(self, False)
player_thread.start()
print(s)
plt.show()
group.append(line)
response
client.send(data)
find_green_times(sg_status)
a = numpy.recarray(num_stars, dtype=dtype)
str(path)
print(x)
DEBUG = True
yag.send(contents=message)
already_inserted = all(bitfield)
ftpobj.cwd(dirname.name)
p.i, p
timedelta(**dict((key, int(value)) for key, value in list(d.items())))
WeakList(list(self) * n)
binary_search([1, 5, 8, 10], 5)
suite = unittest.TestSuite()
stream.close()
mask = (df[0] == 0).cumsum().cumsum()
f
allocate(array(gridsize, gridsize, gridsize))
bynweekday + byweekday
len(cls.__instance)
p = Person()
nose.run()
df
df2
session.add(x)
dc.SetBrush(wx.Brush(wx.Color(0, 0, 0), wx.TRANSPARENT))
output.write(output_compressor.flush())
bokeh.io.output_notebook()
print(u, repr(u))
[0.0, 0.0, 0.0, 0.0],
self._value
commatoze(s, p + 1)
list[0]
p.close()
logger = logging.getLogger(record.name)
G = nx.DiGraph()
theArray.tofile(f)
exit(1)
self._close_all_temp_files()
str(self.__dict__)
stdscr.addstr(str(i), curses.color_pair(i))
s[start:end]
f2.Show()
s = pd.Series(vals, index=dates)
canvas.saveState()
root = tk.Tk()
self.myfunc(self)
count = multiprocessing.cpu_count()
data.put()
value = models.CharField(max_length=200)
print(a * b)
print(key.name)
a = A()
[age for age, person_id in mylist if person_id == 10]
self._coconut = coconut
src = gdal.Open(src_filename, gdalconst.GA_ReadOnly)
asyncio.set_event_loop(loop)
os.close(fd)
frame.groupby(idx).sum()
self.name = name
text_link.string = text
self.step()
df2
n = len(seq)
new_tasks.append(result.args[0])
print((cookies, content))
print(my_data)
bar()
clean = [_f for _f in lis if _f]
arr[len_:] = np.nan
turtle.end_fill()
conn = psycopg2.connect(db_conn_str)
cherrypy.quickstart(Band())
p = Process(target=myfunc, args=(child_conn, command))
df1 = df[mask]
print(parser.config.read(parser.files))
main_dir = os.path.dirname(sys.executable)
subplots_adjust(top=0.8)
root = tk.Tk()
print(__name__)
d = collections.defaultdict(list)
y.boom()
sizer.Add(log, 1, wx.ALL | wx.EXPAND, 5)
print(filetime_to_dt(ft_dec))
n = len(s)
plt.xticks(ind + width / 2, OX)
print(A[0])
fd = os.open(filename, os.O_RDONLY | os.O_NONBLOCK)
my_socket.bind((bind_address, lowest_port))
print(corn + 1)
wrapper
print(n)
key, score = line.split()
print(list(pairs(xs, ys)))
self.builder = Gtk.Builder()
already_inserted = all(bitfield[i] for i in indexes)
len(my_str) != len(set(my_str))
curl.setopt(pycurl.HEADERFUNCTION, hdr.write)
data[:, (0)] = np.random.randint(0, 200, 400000.0)
hoist(e, subexpr(e), c)
app = QtGui.QApplication(sys.argv)
print(driver)
row = row.copy()
y.append(y_center)
f(n)
id = Column(Integer, primary_key=True)
print(A.shape)
print(alist[k], statement.split(k)[1:])
lol = df.values.tolist()
html = lxml.html.parse(url)
print(submission)
bpy.utils.register_class(customToolshelfPanel)
fig = plt.gcf()
ax[1].legend()
chosen_templates.append(template_name)
f_output.write(data.translate(reverse_table))
plt.show()
startButton.pack()
restaurant_dish.restaurant_id = restaurant.id
sys.exit(0)
file_contents = re.sub(regex, subst, file_contents)
sys.exit(app.exec_())
print(weights.get_shape().as_list())
sheet.cell(row=r + 2, column=c + 2).value = data_table[r][c]
gmpy.is_square(x ** 7 + 1)
adic[i] = adic.get(i, 0) + 1
GLX.glXSwapBuffers(d, w)
other()
f = interpolate.interp1d(theoryX, theoryY)
session = requests.session()
pari.pari_init(4000000, 2)
sel.start()
unsearched.join()
print(repo.name)
smtp.ehlo()
name = models.CharField(name, unique=True)
data_entry.file.save(filename, fid)
a + b + c
a, b
print(sess.run(c))
c = boto.connect_dynamodb()
plt.plot(x, f(x))
item = QtGui.QStandardItem(str(index))
bools = [True, True, False, True, True, False, True]
filename = askopenfilename()
[(x + y) for x, y in zip(result, self._nmin)]
df_test = pd.concat([df] * 100)
len(self.datatable.columns)
df.groupby(idx2).sum()
reader = csv.reader(file)
self.nametowidget(widget.string)
print(arr.dtype)
Base.metadata.create_all(e)
idict.setdefault(sub_type, {})[sub_name] = sub_dict
self.instance.project_set.clear()
q_out.put((i, f(x)))
func1()
self.data[start:stop].mean()
pool.apply_async(Simulation, (i,), callback=handle_output)
b
df.shape
gtk.Window.__init__(self)
nx.draw_networkx_nodes(Gcc, pos, node_size=20)
True
list1.extend(value)
DEBUG = False
print(type(df))
close_window(iren)
logger = logging.getLogger()
print(depth, traceback.print_stack())
forward(size_length)
{{loop.index}}
type(data)
G.add_edge(i, j)
p.close()
{{uform.as_p}}
d = datetime.date.today()
f.tell()
self.yearLength.get(planetName)
reducedQs
halt_thread.start()
send_from_directory(directory=uploads, filename=filename)
self.callback(data)
z[0, 0] = 0
update_x([(1,)], (2,))
[(id(x) == id(y)) for x, y in zip(lis, new_lis)]
ax.hist(np.log(np.arange(1, 10, 0.1)), facecolor=color)
nn.activate([1, 0])
print(df)
nnz = np.prod(partitions.shape)
monkey.patch_all()
cmap = cm.jet
t.start()
time.sleep(0.1)
self.__class__ = GEOS_CLASSES[self.geom_typeid]
show(p)
value = getdict(value)
datetime.datetime.now().strftime(fmt).format(fname=fname)
b = [[] for _ in range(N - 1)]
self.assertEqual(self2.x, SOME_CONSTANT)
print(k)
self.untoggle_mpl_tools()
x = np.outer(np.cos(lons), np.cos(lats)).T
a.hello()
print(minidom.parseString(ElementTree.tostring(tree1)).toprettyxml())
amounts.append(int(multiplier) * float(amount))
Path(__file__).parent
func = classmethod(func)
r = np.kron(np.arange(ni * nj).reshape((ni, nj)), np.ones((xi, xj)))
time.sleep(rest_time)
True
a = np.zeros(5)
v = np.array([0, 0, 1, 1, 1, 0, 0, 0])
bottle.run(app)
self.projectiles.add(p)
myList = [random.randint(0, 1), random.randint(0, 1), random.randint(0, 1)]
np.asarray(ans)
wx.EVT_TIMER(self, self.timer.GetId(), self.OnExorcize)
cls(newName, s)
imgdata.seek(0)
np.array(result)[::-1]
self.response.out.write(jinja.render(template_path, new_context))
r = parse_timestamp(v)
stack.pop(0)
{l[0]: l[1]}
print(num)
doctest.testmod()
new_dic[1] = {}
dict(ChainMap(*reversed(ds)))
self.NameToInfo[zinfo.filename] = zinfo
[0, 1, 0, 0]
proc = mp.Process(target=handle_output, args=(output,))
mylist = [(0 if x != x else x) for x in mylist]
dc.SetFont(f)
all(np.diff(x) == 1)
app.SetTopWindow(frame)
np.random.seed(0)
frame = rotateImage(frame, 180)
plt.imshow(z)
out.seek(0)
map(func, range(0, L))
result = p.communicate()[0]
int.__add__(self, other)
get_factorizations_of_all_numbers(1, n, 2)
list(range(0, args[0], 1))
x, y = X
attrvalue.name = attrname
list(it.islice(it.dropwhile(lambda x: x != 4, it.cycle(l)), 10))
literal_eval(obj[1:-1])
a = np.array(mymatrix)
print(response.headers)
int(s[8:16])
np.random.seed(987467)
ax.contourf(DATA[:, :, (i)])
df.loc[max_loc:max_loc + N - 1]
result.append(g[0][-1]) if result else result.append(g[0])
print(string1 == string2)
conn, addr = s.accept()
test(100, 50, 5)
value = value + 1
{k: makedict(v)}
fig.add_subplot(212)
sparse.coo_matrix((sparse_mult(A.T, B, coords), zip(*coords))).tocsc()
print(descend_list)
config.readfp(StringIO.StringIO(test_ini))
cumprobs.append(cumprob)
results = model.fit(train_X, train_Y)
file_handler.setFormatter(formatter)
df
stdout.flush()
df[i] = df[i - 100].apply(lambda x: x * i)
names = array_type()
f.root.data.append(x)
find_closest(A, target)
ax = fig.add_subplot(111)
a[a == 0] += epsilon
server1.handle_request()
example.test_generic_uint8(numpy.int8(42))
plt.xlim(xmin, xmax)
self.queue.enqueue(line.strip())
root = tk.Tk()
object = MyStatefulModel.objects.get(id=object_id)
execlist[index][1] = myctype
[]
PyQt4.QtCore.QPoint(1468, 50)
sunburst(sequences)
getattr(self.func, attr_name)
arrow.now().isoformat()
has_index_in_slice(indices, a, b)
b = a[:-1] + (a[-1] * 2,)
n = len(a)
print(str(proc.communicate()))
print(format_to_re(layout))
logger.addHandler(fh)
self.last_headers = result.headers
9.465419146697968
11.504781467840075
11.625461496878415
9.265848568174988
deletelist[i]
print(x)
pool = ThreadPool(5)
print(help(xyz))
type(a).__module__ == np.__name__
print(foo())
test(100, 5, 11)
np.random.seed(1)
hash(round(6.84, 1))
button = Button(frame, text=b.title(), command=self.callback)
items[1]
print(result)
urllib.request.install_opener(opener)
time.sleep(0.01)
df
c = [list(set(sublist).intersection(set(b))) for sublist in a]
p.wait()
tree[parent].append(msg)
DISPATCH()
self.result.append(chr(codepoint))
response
print(c.shape)
u = np.linspace(0, 2 * np.pi, 100)
b = numpy.array([x for x in a], dtype=numpy.character)
print(x[max(with_idx)[1]])
print(new)
setattr(cls, n, wrapit(cls, method))
sys.tracebacklimit = 0
func2d(arr1d.reshape((n, m)))
my_list
self.finish_progress()
simplejson.dumps(list(people))
print(line)
show()
list(X())
data = f.read(4096)
dest = os.path.join(dest, filename)
data = r.content
q.get()
Py_XDECREF(g_stdout)
df -= df.min()
{i: (randint(0, 4) + input) for i in range(10)}
client = OSC.OSCClient()
p.wait()
d.append(block)
print(html)
a = np.arange(25).reshape(5, 5)
hex(buffer.rd(0))
ax1.set_xlim(-5, 5)
plt.show()
plt.subplot(152)
sys.stdout.buffer.write(line)
app = QtGui.QApplication(sys.argv)
z[i] = paste0(x[i], y[i])
x /= copy(x[2])
start = time.time()
sentences = sentence_splitter.tokenize(text)
ax.yaxis.tick_right()
type(my_decoded_str)
self._pcapw.writepkt(self._ethernet)
width, height
basecost += tax.calculate(basecost, othertaxes[:i])
pymc.close()
fout.close()
a[1] = 2
print(f.read())
request_headers[header] = request.META[header]
random.shuffle(a, lambda : r)
font = ImageFont.truetype(fontname, textsize)
arr = np.arange(100 * 100 * 100).reshape(100, 100, 100)
start_time = datetime.datetime.utcnow()
ax.yaxis.set_visible(False)
value
arrow2.remove()
f(args[0])
p.kill()
print(df.reset_index(drop=True))
result[-1].append(word)
e.selection_get()
wrpcap(pname, pkts)
numpy.bincount(x[keep], weights=w[keep])
df
data.rename(columns=str.lower)
canvas.showPage()
self.tab.addTab(widget, widget.windowTitle())
result = [([0] * size) for _ in range(size)]
dt + datetime.timedelta(0, rounding - seconds, -dt.microsecond)
base = ndpointer(*args, **kwargs)
sys.modules[().__class__.__bases__[0].__module__].open
set(l1) | set(l2)
True
total += sum(map(int, row))
im = Image.open(filepath)
map.add_child(feature_group)
c = conn.cursor()
thisTable.open(mode=dbf.READ_ONLY)
i += 1
plt.clf()
self.lines.set_ydata(ydata)
remaining = np.cumsum(colors[::-1])[::-1]
notify_another_process()
{{comment | safe}}
tk.Tk.__init__(self)
self.initialize()
files = list(filter(os.path.isfile, os.listdir(search_dir)))
tlist[max(0, i - 1)], tlist[i]
run(quiet=True)
plt.subplot(224)
http = credentials.authorize(http)
output.close()
n = s.num_constructors()
sorted(sample, key=lambda i: abs(i - pivot))[:k]
-1
last = paw
a = []
items = list(d.items())
inlines = [LinkedItemAdmin]
subprocess.Popen([program] + params)
make_array_proxy(T & array)
self.setHandshakeOp(handshaker)
client = paramiko.SSHClient()
q = Queue()
frame = inspect.currentframe()
another_obj.save()
f.seek(0, os.SEEK_END)
sys.exit(1)
h.update(block)
print(lines[0].shape)
b = np.ones((2, 4))
self._stream.flush()
f.write(user_code)
find_nearest_above(np.array([0.0, 1.0, 1.4, 2.0]), 1.5)
sys.stdout = sys.__stdout__
response = HttpResponse()
foo = Foo()
self.response.write(template.render(template_values))
values[~valid_mask] = np.min(values) - 1.0
print(foo.X)
Grid.columnconfigure(root, 0, weight=1)
fig, ax = PLT.subplots()
Post(*args, **kw)
myfunc()
file.truncate()
f()
self.tstart = time.time()
soup = BeautifulSoup(r.content)
l = np.random.randint(0, 10, size=n)
data = sys.stdin.read(1)
FileApp(filepath)
print(shared_stuff.a)
np.transpose(np.nonzero(x))
instance = MyClass()
pipeA.send(20)
print(json.dumps(output, indent=4))
sys.exit(0)
print(np.max(np.abs(slow_result - fast_result)))
labels = labels[::2]
hanoi(pegs, 0, 1, 4)
command = lambda : mod.add_to_queue(self.ea1_ent.get)
output_file.write(d[syllable])
setattr(p, s, new_value)
app = wx.PySimpleApp()
self.external_method(arg1, arg2)
response
msg.attach(part2)
new_a.test()
server.serve_forever()
file_path = os.path.dirname(__file__)
self._stop.isSet()
popt, pcov = curve_fit(fit, x, y)
signal.signal(SIGCHLD, SIG_DFL)
sys.stdout.write(line)
fig = plt.figure()
data = data.transpose()
print(child.tag, child.text)
df2.head().T
mask[:, (~np.in1d(np.arange(mask.shape[1]), A))] = 0
a = np.random.rand(6, 5, 4)
serializer = UserSerializer
print(img.shape, img.dtype)
(dx * dx + dy * dy) ** 0.5
main()
hi()
result = -temp[:4]
results = defaultdict(set)
extent = im[0].get_extent()
char = sys.stdin.read(1)
list1, list2 = map(list, zip(*origlist))
background.paste(foreground, (0, 0), foreground)
os.setuid(0)
N = 1000000
it.starmap(func, it.repeat(args, times))
stream.feed(data)
4 / 100.0
10007, 10008, 10007, 10008, 10008, 10008, np.nan, 10010, 10010, 10010
print(random.choice(a))
print(lucky(500))
total += nested_sum(i)
frame = cv.RetrieveFrame(capture)
np.round(ccn.todense(), 2)
l = [group[:] for group in list_of_groups]
key = Column(Integer, primary_key=True)
print(poly.intersects(p))
l = [1, 5, 8]
f()
f.write(jpgtxt)
pylab.plot(f, Xdb)
True
a = np.random.randn(S, S, N)
sys.stdout = StringIO.StringIO()
df.truncate(before=d1, after=d2)
self.dictList.__len__()
mod = sys.modules.get(name)
temp_list = []
b = [4, 5, 6]
b = a.copy()
p = a[100:].ctypes.data_as(ctypes.POINTER(ctypes.c_double))
NULL
db = SQLAlchemy()
[x for i in range(1)]
block = np.array(block)
numpy.linalg.det(numpy.dstack([a, b, c]))
print(datetime(2008, 12, 2))
all_found.append(founds)
a = a.astype(float)
list(filter(set(b).__contains__, a))
result[0]
result = tree.xpath(path)
mat[list(range(n)), list(range(n))] = 0
indata = numpy.ones((5, 6))
y = np.exp(-x * x)
list(self.__iterPerson(**kwargs))
w = QtGui.QWidget()
p.join()
app = QApplication(sys.argv)
np.mean(arr, axis=0)
r = tf.mod(x, 1)
browser.select_form(nr=2)
module.workflow_set.filter(trigger_roles=self.role, allowed=True)
count += 1
self.index += 1
consumer_lock_object.lock()
heapq.heappush(r, (-x * y, x, y))
e = Tkinter.Entry(w)
print(repr(f))
ax2.yaxis.tick_right()
self._lines = []
data.domorestuff()
print(sample2.count(True))
fig = plt.figure()
s.close()
pprint.pprint(z)
zfile = zipfile.ZipFile(zipsrc)
self.canvas.SetBackgroundColour(wx.Colour(0, 0, 0))
screen = pygame.display.set_mode((250, 250))
A = numpy.array()
b[0][0] = 1
tree = et.ElementTree(root)
app.MainLoop()
window.set_border_width(5)
np.concatenate([(element_offset + x) for x in range(a.itemsize)])
response = urllib.request.urlopen(url)
t.start()
store_last_lineprocessed(last_line)
decdeg2dms(dd)
x = __import__(module)
new_file.write(data)
n = len(my_list[0])
np.sum(seq, axis=0)
z = np.empty((100, 1, 4), dtype=float)
mount(prefix, app, **options)[source]
dt = datetime.datetime.now()
print(result)
load_json_file(filename)
proc.wait()
lg = np.log(pdf)
cbar = plt.colorbar()
p = math.exp(-delta / T)
m.end()
NotImplemented
next(iterator)
print(repr(__bar))
orig_py_compile(file, cfile=cfile, dfile=dfile, doraise=True)
count[0]
r.mainloop()
sess.run(train)
print(r.groups())
A = NP.random.rand(8, 5)
ax1 = fig.add_subplot(121)
False
lock = multiprocessing.Lock()
cols = [c.copy() for c in table.columns]
res = np.zeros_like(a[0])
df.sortlevel(0).index.lexsort_depth
print((s, found, tail))
id = Column(Integer, primary_key=True)
widget.queue_draw()
rows = cur.fetchall()
bucket = conn.get_bucket(BUCKET)
contents = f.read()
r = requests.get(settings.STATICMAP_URL.format(**data), stream=True)
files = [name for name in tar.getnames()]
bp.show(fig)
d = datetime.datetime.utcnow()
time.sleep(0.1)
ax.barh(ind, data, color=color, left=left)
pl.show()
uuid.uuid4().int & (1 << 64) - 1
my_dict = dict((k, []) for k in keys)
array([4, 9, 7, 9, 2])
donecounter += 1
c = conn.cursor()
parser = argparse.ArgumentParser()
json.dump(hugeData, f)
set(x + 1 for x in aset)
s[ind1 + 1:ind2]
ax.yaxis.tick_right()
key = rev[value]
root = tk.Tk()
EMAIL_USE_TLS = False
numpy.nextafter(0, 1)
remove.add(index)
daemon_cartman.setDaemon(True)
e.foo()
self.widget.see(tk.END)
self.setUpClass()
pd.Timestamp.max
k in self.__dict__
result = set()
list_of_lists[0][0] = 7
n = len(lst)
result = sum(x, [])
solve(equations, [a, t, vi, vf, d])
d.update({k: v})
G.add_edges_from(node_edges)
rows = cursor.fetchall()
frame.pack()
browser.set_handle_refresh(False)
print(repr(m))
client = oauth2.Client(consumer, token)
print(a)
df1 = s1.reset_index()
a * x ** n + b * x - c
xp = np.linspace(-1, 6, 100)
self.treeWidget.addAction(self.treeAction)
isdefarg(5, 7)
print(item)
c = a[:] + b[:, (np.newaxis)]
app.MainLoop()
dt + datetime.timedelta(0, rounding - seconds, -dt.microsecond)
a()
cur = [[14, k, j] for j, k in (rows[14], list(range(15)))]
print(tds[0].string, tds[1].string)
f.close()
print(getitems(bleah))
stream._add_io_state(state)
[p.start() for p in proc]
log.removeHandler(ch)
rename_code_object(wrapper, f.__name__)
print((k, v))
self.searchobj = searchobj
filenames = [n for n in filenames if not fnmatch(n, ignore)]
dst.SetGeoTransform(match_geotrans)
requests.head(url, allow_redirects=True).url
x, y = y, x
print(a[i])
reactor.iterate()
raise StopIteration()
Testing(1 / 1)
print(meds)
asyncore.dispatcher.__init__(self)
drive, path = os.path.splitdrive(test)
f.seek(0)
A = np.arange(n * m * k, 0, -1).reshape((n, m, k))
L[a], L[b] = L[b], L[a]
str(document)
output.getvalue()
f.write(data)
post_syncdb.connect(add_view_permissions)
plt.colorbar(m)
fig = plt.figure()
matrix = [([0] * ncols) for i in range(nrows)]
grid.fig.set_figheight(4)
d = {}
model_to_dict(instance)
c.flags.owndata
self.__class__.PARAM
count2[i] += 1
t = df2.unstack(level=0)
[0, 1, 1, 0]
root = tree.getroot()
right = A[idx]
MyImplementation.do_stuff(self.lookup_string(request.something))
os.umask(0)
{{render_class(subclass)}}
lookup(dic.get(key, {}), *keys)
self.origstream.write(self.escape_char)
img.write(data)
max(left, right, left_half + right_half)
logging.getLogger().addHandler(ch)
l[t] = something
column2.append(column.split(data_separator)[1])
self.i = value_of_self_i_before_itervalues(X) + len(X) % N
ax.set_xticklabels(xticklabels, minor=False)
[row for row in reader]
documents = map(itemgetter(0), documents)
df = pd.DataFrame(dict(col=a))
print(my_min([0, 2, -1]))
print(sum(1 for _ in next(groupby(l))[1]) if l else 0)
A = np.zeros((x.size, ndim + 1), dtype=float)
model_tunning.fit(iris.data, iris.target)
regressionmodel(X, Y, Z)
list1 = [1, 1, 1, 1, 1]
OrderedDict(zip(self._fields, self))
0
browser.open(post_url, data)
axis([0, 1500, 1000, 0])
name = db.Column(db.String())
print(grouplist(l, 4, 2))
answer.append(elem)
self.ClickedLB2.resize(400, 20)
opener = urllib.request.build_opener(auth_handler)
mod = __import__(os.path.splitext(i)[0])
deletemxd, df, newlayer
dbb.autocommit(True)
pprint(result)
np.empty(arr1.shape, result_type(arr1, arr2))
df = pd.DataFrame(np.random.randint(0, 2, (2, 8)))
pygame.init()
False
now = time.time()
file1.write(toFile)
q.create_queue(1)
self.errors.update(form.errors)
strcpy(save_path, SYSTEM_FILE_PATH)
d = feedparser.parse(feed)
alltests = unittest.TestSuite()
a.shape
a.extend([random.random() for _ in range(10)])
y = np.array([(i ** 2 + random.random()) for i in x])
psutil.network_io_counters(pernic=True)
my_logger.addHandler(handler)
session.add(w_2)
start_date = end_date - datetime.timedelta(days=8)
fig = plt.figure()
xs = np.exp(-((ts - 0.4) / 0.1) ** 2) + 2 * np.exp(-((ts - 0.8) / 0.1) ** 2)
decorator(fn)
fig = plt.figure()
t = tuple(d.items())
locals()
b.capitalize()
df = pd.DataFrame(data1)
print(fibonacci(10))
sys.stderr.write(s)
k = quaternion(0, 0, 0, 1)
parser = argparse.ArgumentParser()
max_value = df[feature_name].max()
OffsetTime(offset).localize(datetime.strptime(value, format))
df[col] = df[col].ffill()
self.a + self.b
b = list(a)
list(range(x1, x2 + 1))
r = int(numeric(s))
G = nx.Graph()
synchIntervall = datetime.hour(10)
arr = numpy.row_stack((arr, row))
x = np.random.random(num)
c = Kls()
int(err.split()[-2])
ax.boxplot(data, notch=1, positions=pos, vert=1)
fig = plt.figure()
1
st = os.stat(filepath)
order = {item: i for i, item in enumerate(presorted_list)}
q = multiprocessing.Queue()
ax.set_ylim(yl[0] - (yl[1] - yl[0]) * pad, yl[1])
do_some_database_stuff()
width, height = result.size
f.close()
print(inspect.getmembers(mymodule, predicate=is_subclass))
zi = z[x.astype(np.int), y.astype(np.int)]
print(queue.get())
r.withdraw()
apsched.add_interval_job(checkFirstAPI, seconds=5)
apsched.add_interval_job(checkSecondAPI, seconds=5)
theFile.close()
session.add(TS1(datetime(2001, 1, 2, 2), 1))
size = fig.get_size_inches() * fig.dpi
w = copy.deepcopy(x)
QtGui.QTableWidget.__init__(self, *args)
random.shuffle(randomized_list)
b = list((i, j) for (i, _), (j, _) in itertools.combinations(enumerate(a), 2))
manager.connect()
extra_files.append(filename)
random.shuffle(x, lambda : r)
twitter = Twython()
mail = email.message_from_string(email_body)
sys.exit(main(sys.argv[1:]))
ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
soup4.html.__next__
stext.pack(fill=BOTH, side=LEFT, expand=True)
h.split().count(n)
g.sum()
data = f.readlines()
engine = sa.create_engine(DSN, convert_unicode=True)
res = np.array_equiv(A, B)
matches[0].fromy, matches[0].fromx
z()
print(key, value)
server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
height = db.IntegerProperty()
b = np.swapaxes(a, 2, 0)
arr = np.roll(np.roll(arr, shift=-x + 1, axis=0), shift=-y + 1, axis=1)
name = db.Column(db.String(100))
S = n(n + 1) / 2
sound.play()
split.append(([], []))
print(traceback.format_exc())
df[col] = numpy.roll(df[col], 1)
bin(1 << 7)
stdout, stderr
self._value = v
trimmed.pop()
uno.systemPathToFileUrl(os.path.realpath(path))
w = csv.writer(sys.stdout)
np.fill_diagonal(corr_table.values, np.nan)
allobjc
data = np.random.random(size=(50, 50, 50))
self._mqpush(request)
(x0, y0), (x1, y1) = rect.get_bbox().get_points()
fig = plt.figure()
results = (c_char_p * 4)(addressof(create_string_buffer(7)))
x = np.where(x < 0, 0.0, x * 10)
match.group(0)
gen()
np.mgrid[:4, :5].transpose(1, 2, 0)
j = np.arange(2, -1, -1)
cache[s1, s2] = 1 + lcs(s1[:-1], s2[:-1])
stream.close()
deletea
self.current.append(token.strip())
Pdb
os.linesep.join(helplines)
setattr(args, self.dest, values)
environment = jinja2.Environment(whatever)
o.one()
r, g, b, a = np.rollaxis(arr, axis=-1)
points = np.concatenate([points[:-1], points[1:]], axis=1)
Z = np.sin(X) * np.sin(Y)
id(df2._data)
c.write(sys.stdout)
tree = ElementTree.fromstring(response.content)
self.assertListEqual(expected_urls, css_urls)
B.shape
user = models.OneToOneField(User)
inspect.getmembers(OptionParser, predicate=inspect.ismethod)
[A[b] for b in range(end, start, stride)]
model_instance.image_field.save(uniquename, ContentFile(upload.read()))
setattr(destination, key, value)
bounding_boxes.append((x, y, w, h))
plt.show()
li = line.strip()
[0, 1, 0, 1]
isinstance(yourNumber, numbers.Real)
data.append(listofgroups)
ax.set_aspect(5)
self.order = datetime.now()
Ainv[j] = (Ainv[j] - factor * Ainv[i]) % q
self.func(obj)
gtk.widget_set_default_colormap(colormap)
x[:] = np.where(norms != 0, x / norms, 0.0)
wx.ListCtrl.__init__(self, parent, ID, pos, size, style)
out = np.take(x, lin_idx)
err = np.abs(a - b) / b * 100
kks[0] = 1.0
np.triu(A.T, 1) + A
main()
opener = urllib.request.build_opener(proxy_handler)
json.dumps(data)
zip(a, b)
p.terminate()
self.L.append(k)
server.login(SERVER_EMAIL, EMAIL_HOST_PASSWORD)
res = np.split(idx_sort, idx_start[1:])
axes.set_yticklabels(labels)
pool.close()
OC.check_output(self, want, got, optionflags)
bool({})
set_item(9)
workbook = Workbook()
a, b = 1, 2
x = np.random.random(10)
ds = datetime.date.today()
f(a)
line_split.append(annos.pop(0))
server.sendmail(fromMy, to, msg)
map(lambda x: x >= 4, a)
data = np.ones(N, dtype=int)
time.strftime(format, time.localtime(ptime))
pool.join()
d = np.abs(data - np.median(data))
print(F.__code__.co_consts)
pool.close()
mycsv = csv.DictReader(f)
z = np.empty(ind.shape, dtype=x.dtype)
print(repr(better_uc))
headers = dict(req.headers)
po.close()
print(date)
os.fsync()
Unicode(500)
new_dict[v] = k
temp = numpy.copy(my_array[:, (0)])
driver = webdriver.Firefox()
print(list[i])
window = Gtk.Window()
np.array([res])
print(scores.mean())
doctest.run_docstring_examples(f, globals())
html = render_to_string(template_name, context)
m.close()
self.property_names = list(names)
selection.set(selection.get_target(), 0, iter_str)
plt.show()
x[1][0][0] = 21
print(dykSuperstring(deqs))
func(*func_args, **func_kwargs)
logger.addHandler(fh)
x, y = zip(*points)
myfile.write(chunk)
c = zip(*a)[0]
chunk = f.read(4096)
burroughs_wheeler.test(1000)
data = json.loads(open(file).read())
print(x.foo)
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj))
Thread(target=reactor.run, args=(False,)).start()
block.text = hilited
set(df1.x).symmetric_difference(df2.y)
print(f(2))
self.pool = multiprocessing.Pool(processes=processes)
r_server.ping()
tex.insert(tk.END, s)
pos == len(b)
b = (a * b).sqrt()
test_dict = autoparts()
Py_Initialize()
print(np.allclose(q, t))
A.add_edges_from(G.edges())
df.sort_index(inplace=True)
event.setDropAction(QtCore.Qt.CopyAction)
x.append(temp)
logging.getLogger().addHandler(ch)
Py_DECREF(name)
a = array((1, 0, 0, 1, 1, 0, 0))
render_window.Finalize()
t.join()
tar.addfile(tarinfo=info, fileobj=string)
p = Polynomial.fit(x, y, 4)
clf = sklearn.tree.DecisionTreeClassifier()
text = doc.toPlainText()
cv2.floodFill(result, maskborder, seed_pt, (255, 0, 0))
lst[-1] += old_d[key][i]
indices = list(g)
x % 1000
handles, labels = ax.get_legend_handles_labels()
FAQ
print(tavnit % row)
a / foo.py
path = sys.argv[1]
next(wood)
termios.tcsetattr(fd, termios.TCSAFLUSH, old)
gdal.UseExceptions()
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
MenuItemComponent.objects.filter(menuItem=menuitem)
[chr(n & 255)] + to_bytes(n >> 8) if n > 0 else []
x1, x2, y1, y2 = ax.axis()
HttpResponseRedirect(redirect_url)
jsonify(data=cursor.fetchall())
print(arr.shape)
print_one()
all_matches = [matches(list2, v) for l in list1]
hex_data
loop.run_forever()
mail.list()
prof.print_stats()
df1 = df.loc[pd.MultiIndex.from_arrays(edge_subset2.T)]
data = sockfilefile.readline()
dfasamplefive = dfa[5:]
node.val = some_val
print(base_url)
print(matchResult.group(1))
HexDump()
print(inspect.stack())
self.valid_keys.remove(key)
print(args.f)
lowest_values.append(x)
CalculatorUI.__init__(self)
func2()
metadata = MetaData(bind=engine)
sys.exit(1)
float(num)
os.path.dirname(path)
print(df.drop(idx))
new_body_text = re.sub(pattern, make_create_footnote_numbers(), text)
cdvirtualenv
{{message | safe}}
repo = Gittle.clone(repo_url, repo_path)
text = f.read()
x, y = get_point(foo)
my_user.username
{protocol, internal_ip, internal_port, foreign_ip, foreign_port}
globals()[name]
serializer_class = UserSerializer
ax = fig.add_axes(ax_size)
df
ax2 = ax.twinx()
username_field.send_keys(self.user.username)
-W15
data[i] = random.random()
d = {(1): 1, (2): 2}
ser.setDTR(level=0)
os.chdir(workingdir)
__init__.py
lookup[l].add(v)
func
time.sleep(0.1)
plt.pause(0.5)
c = canvas.Canvas(file, pagesize=landscape(letter))
logger.setLevel(logging.DEBUG)
root_logger.setLevel(logging.DEBUG)
self.builder.connect_signals(self)
type(b)
order = np.argsort(x)
s = socket()
widget.configure(foreground=color)
ordered(a) == ordered(b)
xy[xy[:, (1)] > 0]
sorted(animals, key=lambda animal: animal[2])
d[v].append(k)
ranges = [(1, 5), (10, 20), (40, 50)]
x = np.arange(16).reshape((4, 4))
csv_writers[k].writerow(row)
np.cross(a, b)
now = datetime.utcnow()
globallock.acquire()
server = SocketServer.TCPServer((HOST, PORT), MyTCPHandler)
numbers.append(current)
print(list(gen))
[0, 0, 1]
G.edges(data=True)
y = v[:, (1)]
print(foolib.__file__)
b = [x for x in a if a.count(x) > 1]
m = re.match(regex, s)
paw_number += 2
weights.append(W - sum(weights))
print(np.argsort(-df.values, axis=1)[:, :2])
[x for n in getNeighbors(vertex) for x in getNeighbors(n)]
ranges[i:i + 2] = [[ranges[i][0], ranges[i + 1][1]]]
ax1 = fig.add_subplot(211)
main()
4.0 / 100.0
xi = np.array([0.0, 0.5, 1.0])
ax.set_yticks(minorticks, minor=True)
self.timer.timeout.connect(self.updateClock)
sorted((minval, value, maxval))[1]
Tkinter._test()
self.fail(self._formatMessage(msg, standardMsg))
_f(*args)
bar = forms.ModelChoiceField(queryset=Bar.objects.none())
power(5, 2)
wrapper
print(data)
signal.alarm(0)
self.input_queue = mp.Queue()
tmp += int(sline[1])
im.set_transform(im_trans)
random_sample_output.writelines(random_sample_input)
Test.calc_a.__code__.co_names
sys.meta_path.append(MyImporter())
cur_list.append({keys[i]: values[i][j]})
(x + y).subs(reversed(100 * reps))
hfile.seek(pos, os.SEEK_SET)
queryset = User.objects.all()
sys.stdout = capturer
self.e = Entry(top)
pic = QtGui.QLabel(window)
os.dup2(0, 1)
u = f.read()
t = ssh.get_transport()
s.plot()
fig.set_figheight(96)
Gtk.init([])
foo.map(lambda x_y: (x_y[0], [x_y[1]])).reduceByKey(lambda p, q: p + q).collect()
exit(1)
pd.Series(sm.OLS(y, x).fit().predict())
run_main()
out[i, j] = lst[i] in lst[j]
image.save(pic, image.format, quality=100)
self.view.setModel(self.treeModel)
queryset = Widget.objects.all()
cursor = conn.cursor()
Py_Initialize()
a = list(range(1, 101))
diam = np.zeros(len(seed))
A[0, 1] *= 0.5
x1, x2 = np.nonzero(accum)
chain.from_iterable(map(f, seq))
signal.alarm(10)
f.write(binary_representation)
lines = []
res = split(cols, inverse_rows[1:])
left = random.randrange(0, x1)
answer += str(i)
data = json.loads(json.dumps(data))
a = np.array([])
novel.append(word)
tuple()
fig = plt.figure(figsize=(8, 6), dpi=80)
x, y
process.stdin.write(data)
print(next(reader))
DO_STUFF
loop = asyncio.get_event_loop()
output = output[:-1]
output = [x for x in L]
Py_Initialize()
simplejson.dumps(finalObj)
{k: dct[k] for k in keys}
zipFile.close()
scores = cross_val_score(clf, X, y, cv=cv_custom)
app = QtGui.QApplication(sys.argv)
0
os.unlink(db_fname)
browser = webdriver.Firefox(capabilities=firefox_capabilities)
self.shutdown()
im = Image.open(im_file)
foo = Foo()
ssh = paramiko.SSHClient()
c = cs.send(c + 1)
stringbuilder_test.py
answer.append(d)
sorted(x)
fig, ax = plt.subplots()
fig, ax = plt.subplots()
network.add_layer(1)
myl[myl.index(item)] = 44
df = pd.DataFrame(np.random.randn(4, 4))
dict.__getitem__(self, key)
p1.conversations.filter(participants__in=p2)
bool(a) ^ bool(b)
Z = VV / WW
wait_for_element_visibility(welcome_button).click()
s.close()
P = np.array(mean_data)[:, (1)]
df = pd.concat([df] * 1000).reset_index(drop=True)
dictlist.append(temp)
p = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
self.f = f
4015
im = np.zeros((imsize, imsize), dtype=float)
df_a.div(df_b)
Z = np.random.random((500, 500))
rows = np.arange(y.size)
swap_rows(my_array, 0, 2)
uniquifier.uniquify(a_timestamp)
cb = pyplot.colorbar(cs)
print(set(c) <= set(a))
plt.plot(lowess[:, (0)], lowess[:, (1)])
tuple(v)
main()
np.random.seed(1977)
self.fp.seek(position, 0)
1 + countit(target, key, where + 1)
color = image.getpixel((x, y))
printTree(myTree)
pyplot.bar(histo[1][:-1], cumulative_histo_counts, width=bin_size)
MyObject()
f is f()
grequests.map(rs)
ax.set_ylim(-0.6, 0.6)
Alias / media / opt / django / site2 / media / statics
print(text)
-1
False
ax = plt.gca()
print(letters_in_order_of_frequency(string))
unittest.TextTestRunner(verbosity=2).run(suite)
s = requests.session()
a = np.array([1, 5, 50, 500])
lst_intensities.append(img[pts[0], pts[1]])
cmd.Cmd.__init__(self)
o.__dict__
s2 = sum(x * x for x in samples)
results = list(foo())
self.user
scene.camera.location.z = tz
decoded_data = chan.decode(sample_data)
method = possibles.get(method_name)
fig = plt.figure()
timeit(hugeequal1, hugeequal2, 1000)
{{form.csrf_token}}
ax1.set_yticklabels(data.index)
data = open(filename)
Base = declarative_base()
InfoDF = pd.DataFrame()
love_ctx.add((bob, hates, charlie))
print(bar())
args = [iter(iterable)] * n
d(a, b)
data = {x: y for x, y in zip(df.columns, df.iloc[0])}
cardsdiscarded = 0
count += 1
data = reader.GetOutput()
response = browser.open(request)
a = np.random.randint(1, 5, (500, 500))
bool(match)
some_func(l, 5)
ax.set_zlim([0, 4])
stck.append(crnt)
df = pd.DataFrame(s)
a / b
print(Temperature.identifier)
a.get(1)
self.webview.setWebViewClient(self.wvc)
d.hexdigest()
ax = fig.add_subplot(111)
len(data)
df = df.append(h, ignore_index=True)
photo = models.ImageField(upload_to=photo_path, blank=True)
index = self.model.index(0, 0, QtCore.QModelIndex())
bins.append(x0)
myfile = open(os.path.join(MEDIA_ROOT, f.Audio.path)).read()
parsed = urlparse.urlparse(url)
b = np.array([5, 6])
x + 1
signal.alarm(0)
b = np.dot(X.T, (mask * Y).T)
df = pd.DataFrame(ls).set_index(0)
sizer.Add(self.log, 1, wx.ALL | wx.EXPAND, 5)
cc = Country.objects.all()
s = pickle.dumps(lambda x, y: x + y)
newax.imshow(im)
266248
sys.path.insert(0, pluginsDir)
diff(nges_uneval, n[5]).doit()
self._window = gtk.Window()
m = pat.match(s)
listener.bind((HOST, PORT))
G = nx.DiGraph()
freqs = np.fft.fftfreq(len(w))
request
items = re.findall(itemfinder, html)
Py_DECREF(key)
logging.root.addHandler(file_handler)
print(dp(n, left)[1])
index += 1
self.sock.connect((self.host, self.port))
urllib.request.install_opener(opener)
X[np.abs(X) < 0.1] = 0
exit(1)
b.fly()
address = ws.Cells(row, col).Hyperlinks.Item(1).Address
data[:, (1)]
args = sys.argv
r = [(i / s) for i in r]
print(id(a))
df
result = max(iter(d.items()), key=lambda x: x[1])
kthsmallest(A[:i], B[j:], k - j)
digs[0]
c.setopt(c.URL, host_url)
a = Addressbook()
print(allimports.sum(1, 1))
df.id.apply(str)
True in ((start < date) & (date < finish)).unique()
myFunction()
ax = plt.axes(projection=ccrs.PlateCarree())
exec(urllib.request.urlopen(x), globals())
fig = plt.figure()
categories.extend(animal.categories.all())
IT.chain.from_iterable(IT.combinations(s, r) for r in rvals)
perm(prefix + [rest[i]], rest[:i] + rest[i + 1:])
db.close()
plt.subplot(121)
it.chain.from_iterable(it.repeat(i, i) for i in range(1, 5))
idx = np.argmin(np.abs(sw - sCut))
z = np.ones((nr, nc))
args = parser.parse_args()
GL.glRectf(-0.8, -0.8, 0.8, 0.8)
ticks = np.linspace(0, 1, num_ticks)
a = np.array([[5, 4]])
CE, BD, BE, BF, BC
v = list(d.values())
f.set_axis_off()
self.root.destroy()
parser = argparse.ArgumentParser()
fn(*args, **kwargs)
clf.estimators_
partitions.append([e])
a = [Foo(), Foo(), Foo()]
queue = collections.OrderedDict()
self.glade = gtk.Builder()
ax.bar(x, y, log=1)
len((a > 10).tostring())
sum += distance(randoms[offset][0], randoms[offset][1])
session.execute(i)
self.x = x_
final_image = Image.fromarray(np.uint8(im.clip(0, 255)))
pyqt5.vext
MasterObject.__init__(a, b, c)
(Sxy * N - Sy * Sx) / det, (Sxx * Sy - Sx * Sxy) / det
f.write(content)
np.mean(counts)
image = Image.open(buffer)
f.write(l)
my_list = list(N.values())
client = paramiko.SSHClient()
res = [(-1) for i in range(len(myLists))]
A = diag(arange(0, 10, 1))
subsymbtree
print(item)
N = np.logspace(2, 5, 4)
w = csv.writer(f)
print(soup)
plt.plot(t, s, c=seaborn.color_palette()[2])
fig, ax = plt.subplots()
print(query)
self.show()
cur = con.cursor()
local_dt = timezone.localize(dt)
result = defaultdict(int)
r = s.post(URL, data=login_data)
print(list(roundrobin(*groups)))
print(string)
df = pd.DataFrame()
doc = xee.fromstring(data)
sc = SparkContext(conf=sconf)
out[:, (0)] = np.repeat(arrays[0], m)
data = dict(zip(labels, [int(x) for x in starf]))
p.start()
print(lst2[0])
my_engine.commit()
t1.stop()
weekly = numpy.sum(by_week, axis=1)
memory_file.seek(0)
f[i] = 0
p = np.array([[1.5, 0], [1.4, 1.5], [1.6, 0], [1.7, 1.8]])
result.append(str[last_end:])
self.gravity = 982.0
parser.print_help()
check(my_list[:start], tracking=tracking)
idx = np.where(m.any(1), idx0, np.nan)
b = np.zeros(a.shape, dtype=a.dtype)
_sum(iterable, start)
days.index(inp)
df2 = pd.concat([df, df1], axis=1).sort_index(axis=1)
data = f.read(block_size)
results = {}
AppHelper.runEventLoop()
Process.__init__(self)
grid()
foo = Foo()
django.db.transaction.leave_transaction_management()
type(self) == type(other) and self.value == other.value
yaxis.set_minor_locator(MinorSymLogLocator(0.1))
fig = plt.figure()
data = np.random.random(numdense)
lis1, lis2 = map(itemgetter(0), my_list), map(itemgetter(1), my_list)
Base.metadata.create_all(engine, tables=[DeclarativeTestModel.__table__])
Bar() < Foo()
Z = np.arange(2000).reshape(20, 100)
print(str(obj.node))
group = groupby([1, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1])
np.log(gev.pdf(data, *fit0)).sum()
PyQt4.QtCore.QPoint(1509, 549)
process_f()
help(re)
sleep(1)
sIO.__init__(self, *args, **kwargs)
b.sum(axis=1)
clock.tick(20)
v_box.addWidget(self.box_two)
object.__eq__(self, other)
digits = len(foo.split(dec_pt)[-1])
ax.add_patch(patch2b)
attr = getattr(self.obj, name)
a1.yaxis.tick_left()
B_process.stdin.close()
self.iterator = iter(generator)
response
plt.show()
name = models.CharField()
time.sleep(1)
conn.send(data)
[nan] == [nan]
image.load()
do_something_here(*args, **kwargs)
fig = plt.figure()
fp = np.polyder(f)
F[np.triu_indices(n, 1)] = 0
self.root = Tkinter.Tk()
transport = TTransport.TBufferedTransport(socket)
X = np.random.rand(100)
compile(expr, filename, mode, PyCF_ONLY_AST)
append()
form.instance.created_by = self.request.user
[l]
lattice[i] = mksite(pair[0], pair[1])
[]
Base = sqlalchemy.ext.declarative.declarative_base()
print(df_means.head())
obj2.decrypt(ciphertext)
self.changeLayout(QtCore.Qt.Horizontal)
tagger = nltk.UnigramTagger(nltk.corpus.brown.tagged_sents())
ax = fig.add_subplot(111)
print(result[0])
values.append([a, a + 200])
e.sum(axis=0).shape == (2, 2)
g()
br = mechanize.Browser()
b = B()
a = [1, 2]
launchVim()
existing(self, *args, **kw)
rnd = 2.0 * np.random.rand(n)
root = elem.getroot()
zip(*(islice(cycle(elem), max_length) for elem in inputs))
print(a)
numpy.lib.stride_tricks.as_strided(stacked, shape, strides)
new_url
fig = plt.figure()
print((i, j, k))
print(hex(id(w)))
arr = np.array(im)
os.path.relpath(datastore.__file__, here),
B = [2, 6, 5, 4, 2]
[0, 0, 0, 0]
print(a)
a().method()
items = map(dicttolatex, items_to_clean)
csv_in.close()
cv.WarpPerspective(cv.fromarray(im), out_2, cv.fromarray(h))
print(b)
t[:] = np.arange(4).reshape(2, 2)
abs(gTob(a) - gTob(b)) == 1
fig = plt.figure()
list(gexpr)
full = np.random.randint(1, 99, size=(8, 8))
d.groan()
print(x)
obj.get_object()
arcpy.RefreshActiveView()
x = np.random.standard_normal(n)
print(item)
fig = plt.figure()
rows = np.array([0, 1]).reshape(-1, 1)
my_task.delay()
c = [_f for _f in [list(set(sublist).intersection(set(b))) for sublist in a] if _f]
b = a[:]
f.close()
c = ctypes.cast(pBuf, ctypes.POINTER(ctypes.c_char))
list(deque(fin, n))
[1, 1, 2]
gc.collect()
node = character.ENodeId(int(node + 1))
client = paramiko.client.SSHClient()
new_a * b
parser.print_help()
app = Flask(__name__)
hax2.set_axis_off()
pickle.dump(obj, file, protocol=4)
print(line.strip().upper())
x = 0
self.pkwargs = pkwargs
N = A.shape[0]
foo(1, 2)
re.findall(notes + accidentals + chords + additions, line)
self.memo[id(obj)] += 1
sub_df
stream.stop_stream()
(b - a).days
ax.xaxis.set_minor_locator(plt.FixedLocator([50, 500, 2000]))
new_a = np.empty(a.shape)
sizer = wx.BoxSizer(wx.VERTICAL)
msg.attach(attachment)
setattr(cls, k, v)
avgs.append(total / count)
print(line)
sys.setrecursionlimit(10 ** 6)
visited.add(self)
stop_event.wait(random.randint(0, 5))
action.visit(this)
print(testfunc(1))
arr[i][j] = numpy_arr[i][j]
a = np.array([True, True, False])
logging.Handler.__init__(self)
plt.xticks(rotation=90)
sympy.nextprime(50)
slice(n if k > 6 else k)
zip(a, b)
s.sort(reverse=True)
sys.stdout.encoding
setattr(self.obj, self.method, self.orig_method)
ax.set_yticklabels(yticklabels, minor=False)
res.sort()
img = Image.open(sys.argv[1])
some_exit_code
False
self + [fillvalue] * (n - len(self))
os.path.exists(sys.stdin.name)
tuple(flatten(args))
mock(*args, **kwargs)
new_arr.shape
cpy.seek(0)
datetime.utcfromtimestamp(dt64.astype(int) * ns)
os.setpgrp()
df
data = self._fp.read()
a = np.zeros((N, N), a.dtype)
b.append(i if i else b[-1])
data = json.load(f)
logging.getLogger().setLevel(getattr(logging, FLAGS.logging_level))
ax.set_xticks(ind + width)
self.refresh()
parser = etree.XMLParser(remove_blank_text=True)
filename = os.path.basename(url)
writer = csv.writer(output_file)
df = DataFrame(resoverall.fetchall())
root = tk.Tk()
list([t for t in list(d1.items()) if t[1] == m])[0][0]
df
threading.Thread.__init__(self)
loop.close()
sock.sendall(msg)
title = title_search.group(1)
gf.seek(-4, 2)
print((k, g))
self.testbed.deactivate()
process = Popen(command, stdout=PIPE, stderr=PIPE, bufsize=1)
print(t.getvalue())
conn.shutdown(2)
print(dollars)
output.addPage(page)
axes[0].imshow(z)
sh.setLevel(logging.DEBUG)
locale.atof(num)
EAGAIN or EWOULDBLOCK
app.run(port=9001)
le.inverse_transform([0, 0, 1, 2])
switch_path if sum(switch_path) < sum(stay_on_path) else stay_on_path
retval = ser.readline()
mydb.commit()
print(response1.text)
sqrt(2, precision(100))
print(s.unpack_from(y))
args.command(subparsers.choices[sys.argv[1]], args)
a[:] = da[:]
subcats.extend(dirnames)
self._ssh = paramiko.SSHClient()
tree = ET.fromstring(content, parser=ET.HTMLParser())
value = getattr(self, key)
self._s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
s.head(10)
ax.set_yticks([])
o.a
desk.picture.set(mactypes.File(f.name))
lines = proc.stdout
label = gtk.Label()
self.master.after(1000, self.change_label)
x = np.linspace(-5, 5, 100)
op.pow(a, b)
getattr(self, name)
options = parser.parse_args()
arrayList.append(wM)
utils.formatdate(nowtimestamp)
sum(it.imap(doSomething, originalList), [])
data = [(1, 2), (40, 2), (9, 80)]
Base = declarative_base()
a.registerCallback(listener2)
post_data = urllib.parse.urlencode(post_data)
self.beep.emit(i)
print([(elem * 2 if elem % 2 == 0 else elem) for elem in a_list])
pool = Pool(processes=8)
print(b.shape)
ax.grid(False)
time.sleep(1)
kill(proc.pid)
mt.roundrobin(*([iter(list1)] * (n - 1) + [list2]))
next(self.it)
method(**keywords)
table.create()
1
out = np.count_nonzero(m[1:] > m[:-1]) + m[0]
w.resize(600, 400)
new_list.pop()
chunk = fp.read(BUFSIZE)
to_search[NAME]
TEST_RUNNER.run(TEST_SUITE)
sorted([x for x in res if x < limit])
t = threading.Thread(target=f)
water_held += (pos - stack[-1].pos) * well_height
d.cards.remove(card)
[0, 0, 1, 1]
help(distutils.version)
out.close()
bpy.utils.unregister_class(customToolshelfPanel)
id(s.index), id(s.values)
plt.title(slope)
{}
pprint(ddiff, indent=2)
other_f(other_f(s[1:])) + s[0]
time.sleep(4)
data = collections.defaultdict(list)
list(self.data.keys())
word = s[:end + 1]
raise urllib.error.URLError(err)
self._choices = []
df2 = df.copy()
print((c.id, c.title, c in u.channels))
print(df.groupby(df.A // 2).A.apply(pd.Series.sample, n=1))
HiPRIOpoller.register(socket_0_pull, zmq.POLLIN)
fig, ax = plt.subplots()
bins = [0, 0.1, 0.9, 1]
handler[cookie[0]] = cookie[1]
[2] + [(2 * i + 1) for i in range(1, n // 2) if sieve[i]]
{1} & {1}
urllib.request.install_opener(opener)
bool(-1)
some.development.host
print(d[str])
point_buffer[:, (0)] * 0.5
[(1 / egg) for egg in eggs if egg != 0]
self.src[-1].insert(0, itemtoshift)
0.6625, sym2, 8, 5, 10, 10
f(d, name)
[any(t) for t in zip(a, b, c)]
main()
[0, 1, 0]
first, rest = list[0], list[1:]
print(sys.argv[0])
result.append(a_class)
x = np.array(x)
stack.append(s)
p = psutil.Process(somepid)
rolled = np.roll(y, 1, axis=0)
sys.exit(1)
self.connection.channel(self.on_channel_open)
response = requests.get(my_url)
fig.autofmt_xdate()
self.web_view = QWebView()
print(in1d(b, a).all())
start, end, step = len(out) - 1, -1, -1
mime_msg.get_payload()
print(sys.argv)
self.x, self.y = x, y
do_something_else_2()
max(chain(l_one, l_two))
list(x)
res = A[:, (B)][(B), :]
b.decode()
a = np.arange(10)
self.pushButtonSimulate.clicked.connect(self.on_pushButtonSimulate_clicked)
s = set(fus_d.keys())
data = {}
b.build_purelib
results.append(common)
is_equal(df, using_precomputation, using_index)
print(df)
fig.patch.set_alpha(0.7)
(min(r1.end, r2.end) - max(r1.start, r2.start)).days + 1
do_something(line)
os.startfile(command[input][4])
tuple(gen(d) for d in deques)
tornado.ioloop.IOLoop.current().start()
a + -1 / L * math.log(1 - u * (1 - math.exp(-L * b) / math.exp(-L * a)))
decorator
df = DataFrame(np.random.randint(0, 10, size=100).reshape(10, 10))
Y = X[:, (j)].reshape((N, 1))
{{analysis.simple_info}}
a = b + a
raise MyCustonException(attr)
self.current += 1
locals()
line = p.stdout.readline()
list(dep.triples())
x[i], y[i], z[i] = data.GetPoint(i)
QtCore.QThread.start(self)
self.arg1 = arg1
print(line)
pylab.ylim([len(names) - 0.5, -0.5])
isinstance(f, types.FunctionType)
x[:, 1:2] * y[:, 1:2]
l[i] = bar
Year.add(row[0])
self.write(File.read())
zip(*lines[1:])
log_capture_string.close()
print(child.read())
outfile.close()
k = np.tile(k, (1000, 1))
distutils.log.set_verbosity(distutils.log.DEBUG)
g = g.map_diag(sns.kdeplot)
index[1:] = groups[1:] != groups[:-1]
app = web.application(urls, globals())
number = next(iterator)
lambda : arg() if callable(arg) else arg
[0.0, 0.0] / 0
end = lst.index(item, start + 1)
out = a[np.sort(sortidx[valid_ind])]
test(name)
_assertSquareness(a)
self.dataChanged.emit(index, index)
max(iter(c.items()), key=itemgetter(1))
C = np.cumsum(lens)
i = i + 1
node = row[0]
mask = np.cumsum(np.isnan(arr), axis=1).astype(bool)
[5, 6, 0, 1, 2]
cycles.append(list(c))
self.setAcceptDrops(True)
r = random.randint(0, 10)
[Fraction(n) for n in (degrees, minutes, remainder * 60)]
FancyArrowPatch.__init__(self, (0, 0), (0, 0), *args, **kwargs)
h = logging.StreamHandler()
column_widths = []
[0, 0, 0, 1]
requirements.txt
setheading(180)
result.append(-1)
model.update(**kwargs)
authorization = DjangoAuthorization()
df = pd.DataFrame(sample)
time.sleep(0.0001)
joined.fillna(-1, inplace=True)
print(tokens.asDict())
page = urllib.request.urlopen(urls).read()
map(lambda e: urlparse.urljoin(base, e), es)
dir = os.path.basename(filepath)
x = my_list.pop()
b = np.logical_not(a)
self._value = value
dodgy.append(i)
logging.Handler.__init__(self)
self.data.config(yscrollcommand=self.scrollbar.set)
browser.set_cookiejar(cookies)
self.timer.start()
i += 1
self.lom = []
self.is_active
lambda x: x
crsr.close()
[reduce_num(num) for num in list1]
[blas]
bson_obj.decode()
urllib.request.install_opener(opener)
S = P_i.sum(axis=1)
WSGIApplicationGroup % {GLOBAL}
f.read(bom_len)
li[-1]
myArray[i] = [i, i + 1, i + 2]
temp = models.IntegerField()
b2.grid(row=1, column=4)
print(sorted(z, key=lambda x: x[1])[-2:])
widget.setGeometry(200, 200, 100, 50)
r.push(bests[best[1]])
t = QtGui.QTableView()
groups.append((test_size, train_size))
cap = cv2.VideoCapture(0)
X, Y = np.meshgrid(x, y)
n = mat.shape[0]
self.memo[str]
mismatches.append(seqloc)
final_list.append(tuple_item)
c[i, j] = b
pos += 1
f.__name__
QItemDelegate.__init__(self, parentView)
m.span()
root = Tkinter.Tk()
a = numpy.array(l)
line = next(i)
import_array()
app = Flask(__name__)
thefile.flush()
print(cmp(list_1, list_1))
self = Foo()
0
np.array(tuple(it.islice(it.cycle(arr), length)))
flags = fcntl.fcntl(fd, fcntl.F_GETFD)
elem.append(match)
the_table.set_zorder(10)
context.set_source_rgb(0, 0, 0)
self.type.get_object_for_this_type(id=self.id)
self.id
self.callback()
p.text()
f.vals[0] = 10
draw = ImageDraw.Draw(img)
result += [(v + p) for p in perms(s[:i] + s[i + 1:])]
profile.print_stats()
sys.stdin = dummyStream()
a = [(lambda x: x * i) for i in (1, 2)]
name = event.GetEventObject().myname
self.b = b
a = np.ma.zeros((500, 500))
q.put(item)
cls.x = 1
pprint(output)
fig, ax = plt.subplots()
count[0] += 1
z = pickle.loads(s)
self.method(key)
im = Image.fromarray(cm.jet(s, bytes=True))
np.abs(a - val) < tol
print(n)
forms.remove((form, question))
object.__new__(cls, *args, **kargs)
str(self.list)
fh.write(str([data]))
levels = np.linspace(-1, 1, 40)
x[0] = Decimal(1)
handle.close()
indices = rows.nonzero()[0]
getchar()
MyException, (self.arg1, self.arg2)
self.cursor = self.connection.cursor()
a.test()
raise web.nomethod(cls)
t = np.mean(t, axis=2)
X = u.dot(np.diag(s))
list.__delitem__(self, key)
result
hash - r
name, path, args, kwargs
email = Column(String)
myqserver = Qserver()
print(a)
Foo.__init__(self)
result.update({j: [i]})
__init__.py
print(cube(-8))
category[key].append(i)
getLogger().addHandler(StreamHandler(stream=logfile))
os.mkdir(dir)
s == json.loads(t)
content.append(info)
plt.plot([1, 2])
A[idx[0]]
f, ax = plt.subplots(2, 1, figsize=(12, 6))
df1.div(df1.sum(1), axis=0)
lst = literal_eval(string)
dict.__setitem__(self, val, key)
t.stop()
[i for i in range(5)]
dates.append(date)
time.sleep(10)
self.assertEqual(expect, result)
BananServer, GulServer, SolServer, RymdServer, SkeppServer
df
im = cv2.imdecode(np.asarray(bytearray(im_data), dtype=np.uint8), 1)
fig = plt.figure()
logger.addHandler(sh)
plt.colorbar(im)
imarray
get_type_hints(__main__)
tree = KDTree(numpy.array(ecef_cities))
ax.add_collection(lc)
nn.activate([0, 0])
layout.addWidget(self.datetime)
pd.Series(np.tile(c, n), [i.repeat(m), v.ravel()]).unstack()
image = wx.ImageFromStream(sbuf)
BOOST_PYTHON_MODULE(__main__)
self.ToggleTool(self._NTB2_ZOOM, False)
pipe = subprocess.Popen(args, stdin=subprocess.PIPE, stdout=subprocess.PIPE)
fig = plt.figure()
os.makedirs(dest)
H = np.random.randn(n, n)
get_index(lst, num, index + 1)
print([x for x in g2 if x[2] >= 1.5])
ax2.add_artist(bbox_image)
text = f.read()
points.intersects(poly.ix[0])
sns.heatmap(data=df2, annot=True, alpha=0.0)
self.__dict__ == other.__dict__
s = s.strip(string.punctuation)
poly = np.polynomial.Polynomial(np.random.rand(d + 1))
os._exit(0)
dc.SetBackground(wx.Brush(self.GetParent().GetBackgroundColour()))
start_response(status, response_headers)
B = numpy.lib.stride_tricks.as_strided(A, shape=newshape, strides=newstrides)
aa = N.zeros((len(br), 2))
print(somelist[index])
rectangles.add(new_rectangle)
print(myFunction(myCount))
element = etree.Element(CDATA)
x, y = np.meshgrid(np.linspace(-2, 2, 200), np.linspace(-2, 2, 200))
str(self.karma_delta)
AppHelper.runEventLoop()
sys.stdout.buffer.flush()
any(d for d in self.digits)
new_df = df.where(df.date >= last_week)
next(a)
df
data = urllib.request.urlopen(url).read()
now = time.time()
sys.stdout = os.devnull
print(datetime.date.timetuple(t1))
log.addHandler(ch)
count += 1
newlist.append(l[(i + j) % d])
myX, myY = text_center[0] + height / 2, text_center[1] - width / 2
client.set_string(key, str(val))
g = Group.objects.get(id=1)
self[key]
app = Flask(__name__)
d1[k].append(v)
client_sock.send(response_headers_raw)
locations = Location.objects.all()
self.process_events()
index = [0, 2]
response
t.extend(t2)
sns.set()
args = parser.parse_args()
p2 = np.tensordot(p1, w, axes=([0, 2], [0, 1]))
df1 = df[swapidx]
id, value, _ = zip(*ans)
f.write(s)
print(form.errors)
main()
r, c = np.unravel_index(np.argmin(a), shp)
a, b, c, d, e, f, g = [object() for i in range(7)]
x, y, z = zip(*data)
sum([(i - 1) for i in list(c.values()) if i > 1])
self.lock.acquire()
wrapped_decorator
c.append(itemgetter(len(b) - i - 1)(b))
kmeans.labels_
X, Y = np.meshgrid(xi, yi)
module.init()
np.choose(x > 0, [-1, 1])
self.Layout()
(i for p, i in l1 if p), (i for p, i in l2 if not p)
fig = plt.figure()
wait = WebDriverWait(driver, 10)
fd = set(d.items())
HttpResponse(json.dumps(result))
pool = Pool(processes=4)
max(0, min(b, d) - max(a, c))
response.status = falcon.HTTP_404
df
socket.send(toAddr, zmq.SNDMORE)
x = ClassName()
table_name.addParseAction(noWhitespace)
logger.console(s)
critical_code()
index = pd.MultiIndex.from_tuples(list(product(individuals, time)))
MySQLdb.__version__
f = open(input_file)
dict(scores)
items = len(list(group))
all(l)
setattr(self, klass.__name__, DummyClass())
cur.execute(query)
result.append((int(k), na_list[0]))
your_application_main()
test_suite
ret = func(*args, **kwargs)
win.scrollok(True)
self.queue = set()
root.mainloop()
a = np.arange(50)
app.login_manager.init_app(app)
encoded.hexdigest()
self.canv.drawImage(self.img, 0, 0, height=-2 * inch, width=4 * inch)
[l[0] - 1] + decr(l[:1])
len(ws.strip())
t.save()
w / w.sum().astype(float)
y = np.arange(100)
mailserver.quit()
print((name, seq))
h.hexdigest()
d = dict(l)
list_a[k][j][i]
a[0:][::2]
canvas.setPageSize(landscape(letter))
[-2.0, 0.0, -2.0, 4.0, 10.0, 4.0]
model.py
[tuple[1:] for tuple in temp]
d = Naughty()
fig = plt.figure()
unknown = set(data.keys()) - set(self.fields.keys())
doc = html.fromstring(body)
df = pd.DataFrame(sample)
gs1 = gridspec.GridSpecFromSubplotSpec(1, 1, subplot_spec=outer[0])
naive_dt = datetime(2020, 10, 5, 15, 0, 0)
s = inspect.getsource(func)
pygame.draw.rect(*self.stim[stimType])
counter = Counter.objects.get_or_create(name=name)
p.print_help()
inputdict[key] = newvalue
self.destroyed.connect(self.handleDestroyed)
sys.stdout = f
f_out.write(block)
new_lis.sort(key=len)
print(date.to_ical())
npage = pdf_im.getNumPages()
outputs.remove(s)
plt.colorbar(sm, cax=cax)
j = json.loads(s)
subclass2.bar()
result.remove(a)
df_new
yag.send(contents=contents)
self.s = s
WSGIPythonHome / path / to / python / 2.5 / exe / directory
Response({})
foo.x = 0
self.cj.save()
list(triangle(100, 0.5))
self.data.insert(END, str(i))
root = pomFile.getroot()
s = requests.Session()
pygame.event.pump()
mat[x].append(random.random())
msg = MIMEMultipart()
row_count = sum(1 for row in fileObject)
A = np.array(np.random.randn(N, N))
f(10, 20)
myfunc()
c = np.mean(c, axis=0)
print(value, array2[i])
users = db.session.query(User).join(sub, sub.c.ml == User.numLogins).all()
print(outaction.default)
deploy()
bbox = np.min(a[0]), np.max(a[0]), np.min(a[1]), np.max(a[1])
b.index[b.argmax()]
max(v1 - v0 for v0, v1 in zip(values[:-1], values[1:]))
name = models.CharField(max_length=255)
s.push(20)
len(first)
source / usr / local / bin / virtualenvwrapper.sh
self.sizer.Add(self.editname, (1, 1))
ax.grid(True)
len(A)
newfunc
[-2.0, -1.0, 0.0, 1.0, 2.0],
d.update(buf)
a[out.sum(axis=0) == 1]
any(equals)
list_y.remove(ely)
fig = figure()
f.seek(pos)
data = np.random.random((4, 10, 10))
root.deiconify()
self.__is_shut_down.wait()
self.axes.set_xlabel(xlabel)
pprint(A)
position = fin.tell()
U = np.zeros((N, N))
line = next(infile)
c.most_common(1)
pdq.append(x1)
user = django.contrib.auth.get_user(django_request)
nose.main()
array([0, 2, 5, 9])
result = numpy.empty(data.shape[0])
ts = pd.to_datetime(str(date))
s = socket.socket()
label.set_fontproperties(ticks_font)
palette.setColor(palette.Light, QtGui.QColor(255, 0, 0))
count += 1
surf = ax.plot_surface(X, Y, mat)
print(cluster2)
1 + max(-1, min(a.dateEnd, b.dateEnd) - max(a.dateStart, b.dateStart))
df
x = list(range(5))
plt.subplot(121)
a.test()
print(m.__name__)
print(traceback.format_exc())
print(driver.current_url)
name = os.path.basename(os.path.abspath(filepath))
self.newString
_list.append(data)
result = [foo(x) for f in seq if bar(x)]
main()
barbarbar
do_something(cell)
b = np.reshape(a, (np.product(a.shape),))
print(PlaintextWriter.write(doc).getvalue())
sys.stdout.isatty()
print(x)
title = models.CharField(max_length=100)
plot(x, y1)
np.array(y)
application.listen(8888)
df
i, o, e = select.select([sys.stdin], [], [], 1)
b = [0, 2, 4, 5]
ax.plot(x, y, color=col_dict[class_col[i]], **kwds)
chardet_detector.result
dict(y=a.y, z=a.z)
map(type, a).count(int)
fig.canvas.draw()
pb.run()
bs = BeautifulSoup.BeautifulSoup(data)
signal.signal(signal.SIGALRM, lambda a, b: sys.exit(1))
n.parent
cache[s1, s2] = max(lcs(s1[:-1], s2), lcs(s1, s2[:-1]))
f.close()
len(rng)
fig = plt.figure()
newpath, tail = os.path.split(path)
server.serve_forever()
tree = {}
plt.show()
aDict.update(dict(list(element.items())))
points.append((cos(radians(startAngle)), sin(radians(startAngle))))
ax.set_xlim(-0.6, 0.6)
a = np.ascontiguousarray(a)
lambda x: f(g(x))
d.quantize(Decimal(1)) if d == d.to_integral() else d.normalize()
a, b, c
ax.hist2d(x, y, bins=(xbins, ybins))
logging.getLogger().addHandler(fh)
result = curs.fetchall()
draw.flush()
lines.append(line)
x = [1, 0]
result
ET.tostring(root)
description = Column(String(100))
sum(sum(l))
[15, 8, 9, 6]
obj._meta.concrete_model._meta.app_label
blob_key = files.blobstore.get_blob_key(zip_file)
method = getattr(my_cls, method_name)
jsonf.write(data)
raise KeyError()
result = days[days.index(weekday):] + days[:days.index(weekdays)]
fig, ax = plt.subplots()
[Arthur]
sock.bind((source_ip, 0))
opener = urllib.request.build_opener(urllib.request.HTTPSHandler(debuglevel=1))
s[-amount:]
app = wx.App(redirect=False)
soup = BeautifulSoup(page)
o.__hasattr__(a)
random.shuffle(words)
print(found[0].text)
call(*args, **kwargs)
df.dtypes
df
w, -x, -y, -z
self.configMap[key]
o.many2many.add(ModelB.objects.get(id=2))
ax = fig.add_axes([0.12, 0.12, 0.68, 0.78])
result_dict = collections.defaultdict(list)
self.right = right
method.__class__
self._callback(self._value)
setattr(self, item, value)
s[s.map(type).ne(str)]
result = [value_if_false, value_if_true][condition]
list(find_creators(f, builtins))
d = {}
pygame.draw.circle(srf, color, (x, y), radius)
username == line[1].strip()
bar = Foo()
xs = np.linspace(0, 8, 200)
print(test.__dict__[a_string])
parent = elem.getparent()
np.diff(s.values)
ModelA.objects.instance_of(ModelB)
ax.set_xticklabels(ax.get_xticks(), fontproperties=font)
self.request.send(self.data.upper())
float(v)
yi = np.array([0.0, 0.5, 1.0])
[{(1): 2}]
time.sleep(1)
chapters += 1
5 / 2
i
USE_TZ = True
y = np.matrix(x)
print(myre.group(0))
freq4[char] += 1
pprint(FW)
self.n += 2
distance_matrix_np = np.array(distance_matrix)
indices = np.empty((sizes[-1],), dtype=np.intp)
res.append(t)
cbar = plt.colorbar(surf)
t.left(90 * random.randrange(4))
screen = pygame.display.set_mode((200, 200))
out = process.stdout.readline(1)
app.debug = True
soup = BeautifulSoup(response)
b = np.random.rand(4)
new_d = pickle.load(file2)
crawler.crawl(spider)
r = session.post(URL, data=login_data)
jsonify(**request.json)
allocate(tmp(gridsize, gridsize, gridsize))
x[y] += 10
height = GetSystemMetrics(1)
print(k)
unhexlify(s)
self.list.setIndexWidget(index, button)
product = models.ForeignKey(Product)
regressor.score(X, y)
upload_directory(path, upload_file)
a = 42
w.start()
columns = [list() for i in range(10)]
f = Foo()
plt.contourf(grid)
extractor.runInParallel(numProcesses=2, numThreads=4)
sys.exit(app.exec_())
deactivate
df.columns = columns
setattr(targetCls, name, closure(name, func))
line_contents_expr.runTests([sample1, sample2])
request.start_time = time.time()
output = proc.stderr.read()
root = Tk()
os.close(fileHandle)
raise NotImplementedError
init()
self.view.setScene(self.scene)
summary[s] = [int(x) for x in list(set(summary[s]))]
target_dict[key1][key2] = val
self.results = {}
my_set
self.children.append(kiddo)
print(key)
element = WebDriverWait(driver, 10).until(find)
loop1()
fd = os.open(os.ctermid(), os.O_RDONLY)
label.set_fontsize(15)
y = np.outer(np.sin(theta), np.sin(phi))
count += 1
df.replace(to_replace, np.nan)
show()
t.append(z)
source_key.copy(dest_bucket_name, dest_key_name)
dict(zip(*([iter(List)] * 2)))
f.write(raw_img)
line_number -= 1
MyClass.defaults[key]
b = Boo()
cls()
v[:len(tmp)] += tmp
s2 = s1.index.to_series().shift(-1).loc[idx].astype(int)
self.SetSizeHints(minW=-1, minH=hsize, maxH=hsize)
i += 1
markx, marky
Thread(target=guiloop).start()
df
ax = plt.gca()
lab.pack()
ax2 = plt.subplot(122)
fig, ax = plt.subplots()
xx, yy = np.meshgrid(x, y)
print(list_of_strings)
np.cov(data.T)
ret.reserve(funs.size())
plt.setp(g.ax_heatmap.get_yticklabels(), rotation=0)
console.start()
mantissas[fixmsk] *= 10.0
visited.append(rule)
np.random.seed(1)
print(tn.read_eager())
y.nonzero()
ax.axis((0, 2, 0, 2))
np.testing.assert_almost_equal(x, y)
df = pd.concat([df, pd.DataFrame(np.tile(np.nan, [len(df), 50]))], axis=1)
self._byhour
self._byminute
self._bysecond
df[sum_columns] = df.groupby(axis=1, level=1).sum()
ax2 = plt.subplot(2, 1, 2, sharex=ax1)
decorator1(f)
self.name = name
b = int(x)
print(t.get(timeout=1))
sublime.get_clipboard()
self.updater.setInterval(10)
print(m_swapped.shape)
sleep(5.0)
df.index += 17
r = requests.post(endpoint, data=request_parameters, headers=headers)
np.count_nonzero(y == 1)
file.close()
print(self._concrete_method())
d = sum(li[:4])
[(x + y) for x in xs for y in ys]
dis.dis(lambda x: str(x))
h.feed(page)
value = dictionary[key]
all(map(somePredicate, somIterable))
u.close()
print(res.status, res.reason)
args = docopt.docopt(_(__doc__))
print(data)
array[1]
print(obj.number)
sess.run(D)
f.close()
clientSocket.send(data.encode())
output.append(tmp)
print(i)
print(data[4].text)
sum(ord(c) for c in L)
fig, ax = plt.subplots()
os.write(out_fd, PASSPHRASE)
x, y = zip(*points)
help(newImg1.save)
a = handle.readlines()[1:]
plt.xticks(list(range(ncols)), col_labels)
driver = webdriver.PhantomJS()
set([pd.Categorical(x, l[::-1], True).max()])
res.setdefault(k, [])
ha.plot_surface(X, Y, data)
main()
result = client.service.IsHealthy()
tf.truncated_normal_initializer(stddev=stddev)
self.session = Session()
Y = numpy.repeat(X[:, (j)], n).reshape((N, n))
print(x.bar())
a.pop(0)
results = [line.strip().lower() for line in f if line]
print(pir(df))
type = models.CharField(max_length=255)
A[0].shape
mercurial.__file__
fig = plt.figure()
print(hash.name, hash.hexdigest())
self.observer.join()
leng(s[1:], count)
root = tree.getroot()
fig.colorbar(im1)
self.readonly_fields
seen.add(found)
cls
partition(a_, equiv_)
soup = BeautifulSoup(br.response().read())
origlist.append(t)
app = Flask(__name__)
print(t.timeit())
a = np.empty(0)
data = json.loads(json_str)
hline.set_ydata((y, y))
ax = plt.subplot(111)
get_result()
c = conn.cursor()
client = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
afun
s.close()
a(your_list)
self.gamma = tf.Variable(tf.constant(1.0, shape=[depth]))
z = np.linspace(1.0, 2.0, 20)
lock.acquire()
matplotlib.pyplot.yticks(yint)
self.op = op
s.post(url, data=user_data)
fl.close()
comment.save()
john.save()
tile_array(a, 2, 2)
AlwaysCallable(self.__class__)
fig = plt.figure()
max(0, min(x, 255))
pool = Pool(8)
self.grid.CreateGrid(25, 8)
self.vline.set_xdata((x, x))
now = datetime.now(timezone.utc)
len1, len2 = len(string1), len(string2)
time.sleep(0.1)
print(c.fetchall())
pythonbrew_install
list(d.items())
n = len(l)
pylab.legend()
np.random.shuffle(cols)
files = pattern.findall(str)
XmlStream.__init__(self)
screen = curses.initscr()
x = [0] * 51
self.testbed.init_user_stub()
architecture / webservice_tech
print((n, sorted(p)))
path.append(lastnode)
data = response.read()
self.lbl.grid()
db.tbl.insert(**db.tbl._filter_fields(newRowAsDict))
p1.join()
Py_XDECREF(module)
list_of_tuples.append((x, y))
a = np.random.rand(6, 4)
array = [([0] * len(Split_Line[1])) for i in Split_Line[0]]
win.unmaximize()
app = Flask(__name__)
to_stream.write(processed_buf)
print(d[0])
next_down(x)
command = lambda i=i, j=j: update_binary_text(i, j)
print(path_buf.value)
weights.dot(features) + bias * len(weights)
here = lambda x: os.path.abspath(os.path.join(os.path.dirname(__file__), x))
g = sns.pairplot(iris)
fig = plt.figure()
image = Image.open(filename)
not [v for v in list(remaining_weights.values()) if v != 0]
ax.set_ylim(ymin, ymax)
unixtime.days * 24 * 60 * 60 + unixtime.seconds + unixtime.microseconds / 1000000.0
f.close()
endif
ax.set_xticklabels(xlabels)
seen = set()
dic = {x: [] for x in lis}
win2.destroy()
print(x)
gray = cv2.medianBlur(cv2.cvtColor(img, cv2.COLOR_RGB2GRAY), 5)
a = np.empty(guess.shape, dtype=int)
result = pipe.stdout.read()
self.sys_stdout = sys.stdout
now = datetime.now()
cv2.drawContours(close, [cnt], 0, 0, -1)
print(new_dict)
int(0.5 + 10 ** ((n - 1) * K))
matched_data.append(d)
zf.close()
{{}}
8595000
A = A.view(A.dtype[0]).reshape(-1, len(A.dtype))
i, WSSSE
cursor = conn.cursor()
os.abspath(os.path.join(__file__, os.path.pardir, file_name))
p.start()
reader = csv.reader(f)
numpy.subtract((10, 10), (4, 4))
str(h)
os.startfile(filepath)
csv.writer(f).writerows(list_of_lists)
wb.ActiveSheet.ExportAsFixedFormat(0, path_to_pdf)
ax = fig.add_subplot(212)
cap.release()
zipped = [list(t) for t in zip(x, y)]
print(e.__traceback__)
noise = np.random.randn(100)
CS = ax.contourf(xi, yi, zi, 60, cmap=plt.cm.jet, zorder=1)
print(songs[song_index])
len(self.nodes)
s = requests.Session()
options, args = parser.parse_args()
infile.close()
ws.add_image(img)
reader.Update()
False
print(link)
[1, 2, 0]
x = a[:i]
E += potential(np.sqrt(np.sum((x[i] - x[j]) ** 2)))
a = np.array([2, 6, 4, 8])
matches = (i for i in range(len(b), 0, -1) if b[:i] == a[-i:])
content = forms.CharField()
nomwe_corpus.append(nomwe.split())
f, ax = plt.subplots(1, 2)
match = match_obj.group(0)
ax = fig.add_subplot(111)
seen.add(first)
writer.writerow(row)
self.__str__()
bundle
d = np.diff(np.asarray(b, dtype=int))
app = Flask(__name__)
device.close()
seq = chain[:]
k0.lst.append(1)
host = req.get_host()
False
next(result)
max(map(commonprefix, pairwise(suffixes)), key=len)
max(hand, key=lambda c: rank_cards_map[c[0]])
df = df.replace(nan, 0)
fp[(i), :] = fp[(i + 1), :]
p = Pool(1)
keybd_event(Key, 0, 1, 0)
df2.L = df2.L.str.strip()
setattr(instance, attr, value)
sess = tf.Session()
1 == 1 + 0j == 1.0
nums = np.array([1, 1, 1, -1 - 1, 1, -1, 1, 1, -1, -1, -1, 1, -1])
raise AttributeError
out = out[::-1]
app = Flask(__name__)
p.save()
B = dataset[where[~a_idx]]
df.groupby([df.Type, isnull]).size().unstack()
mydict[k] = mylist.count(k)
value
[(c in this.d and this.d[c] or c) for c in this.s]
yaml.Loader.yaml_constructors
[row[column_number] for row in array]
year = int(yourString[0:4])
data = np.arange(n_data)
p.children.append(Child(loc=cloc, status=cstat))
port
x + y.todense()
(1, 2) == 1, 2
[True, False, False],
buff = f.read()
Y[-fc:], alpha, beta, rmse
np.sum(-p * np.log2(p) for p in probs if p > 0)
sys.stdout = St_ampe_dOut()
p.close()
x.append(2.2)
f.read(8)
y = a[2] * b[0] - a[0] * b[2]
abs(z.T - z)
len(self._data.values)
object_class = models.CharField(max_length=20)
x1 = np.random.normal(0, 10, 100000)
sorted(s, key=lambda t: -t[0] * t[1])
pcolor(df1.T)
type(unicodecontent)
install_hooks.post_install()
threadB.join()
1 + x + x ** 2 / 2.0
Base = declarative_base()
Story.append(paragraph)
palette.extend((v, v, v))
print(difft(time(20, 40, 0), time(18, 41, 0)))
line_num += 1
self.id == other.id
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
a = models.CharField(max_length=42)
color = QtGui.QColor(value)
im.thumbnail(size_maxi, Image.ANTIALIAS)
something()
self._fail(self.failureException(msg))
meds = df2.median().sort_values()
np.nan
response
{offset(k, base): v for k, v in list(dct.items())}
reactor.listenTCP(8001, server.Site(root))
print(result.column_name)
self.lock = threading.Lock()
mdb.connect(**connectParams)
root = LH.fromstring(text)
soup = BeautifulSoup(html)
headers = {}
result = can_count_a * a + can_count_b * b
print(f.upper())
logger2.addHandler(logfile)
print(key, word_dict[key])
self.treeview.append_column(self.tvcolumn0)
vals_array.fill(np.nan)
my_dict = defaultdict(list)
out = input[binary_matrix.ravel()[lin_idx] == 1]
PolarAxes.LogPolarTransform(self._axis, self._use_rmin)
iter([data])
print(df1.T)
pool = mp.Pool()
fig, ax = plt.subplots(2, sharex=True)
pp.savefig(plt.gcf())
self.happiness = self.wealth / global_wealth
self._intersections[a][b] += 1
{{login.login_date}}
child.join()
heapq.nlargest(n, iter)[-1]
set(l1) & set(l2)
process.join()
items = Item.objects.filter(created_date__gte=aMonthAgo)
PyType_FastSubclass(Py_TYPE(op), Py_TPFLAGS_LIST_SUBCLASS)
b = [a]
b = arr(a)
name = Column(String)
link.next_sibling.next_sibling
Clock.schedule_once(self.quit_screen, 0)
db.session.add(group_from_factory)
word.lower()
ws = wb.get_active_sheet()
self.parent = weakref.proxy(parent)
X = np.random.randn(10, 4)
app = QApplication(sys.argv)
list1 = [[-2.0, 0.0, -2.0, 2.0, 10.0, 2.0], [-1.0, 0.0, 2.0, 1.0, 5.0, 4.0]]
pylab.draw()
self.connect((host, 80))
[(10 ** (i * 2 / 9.0)) for i in range(10)]
a * x + b + c * np.exp((x - d) / e)
self.grid(sticky=N + S + E + W)
0
module1.func1 = self.old_func1
spam._original(testcon)
socks.setdefaultproxy(socks.PROXY_TYPE_SOCKS5, ip, port)
cv.WriteFrame(video_out, frame)
isinstance(50, list)
plt.hist((a, b, c), **common_params)
ser = serial.Serial(s_name)
list(filter(exists, L))
object.__new__(cls, *args, **kw)
query_set.filter(active=False)
b = [45, 42, 0, 1, -1, 0]
getattr(obj, name)
GetCurrentProcessId() == GetWindowThreadProcessId(wnd)
self._a
new_cmap
lines[0]
parsed = urlparse(url)
A.foo()
response.headers
top.after_cancel(job1)
[0, 0, 1, 0]
t = time.strptime(line, fmt)
ax1.add_line(copy.copy(line1))
h.file.read()
resultFyle.close()
b = c_[a, c]
ax1.set_ylim(-5, 5)
df[df != 0].cumsum(axis=1).min(axis=1)
tree = etree.parse(response, htmlparser)
print(html)
out = dat[top_left[0]:bottom_right[0] + 1, top_left[1]:bottom_right[1] + 1]
[f(0) for f in fs]
print(child.tag, child.text)
pos = nx.spring_layout(G)
self.__dict__.update(x.__dict__)
d = distances[clust[i].id, clust[j].id]
a[2:7 + 1] = b
response
N = len(perms[0][0])
asyncore.loop()
s = s.replace(hit, chr(entnum))
float(s)
f = Foo()
pet_food.save()
response
set(array1) & set(array2)
fnew[0]
count
conn = engine.connect()
logistic.cdf(0.458)
worksheet.fit_num_pages = 1
X[np.arange(len(Y)), Y] = 1
dist = udist.data
text.draw(fig.canvas.get_renderer())
funcs[2]()
root = Tkinter.Tk()
result
reader = csv.reader(f)
fig = plt.gcf()
parser = etree.XMLParser(schema=schema)
raise MemoryError()
m_action.add(action1, action2)
img = img[c1:c1 + 25, r1:r1 + 25]
bot.configure(yscrollcommand=vsb.set, xscrollcommand=hsb.set)
w, v = np.linalg.eig(A)
writer.writerow([name, membership])
result = res.pop(0)
result
httplib.HTTPConnection.__init__(self, *args, **kwargs)
anobj.amethod(x)
loop = asyncio.get_event_loop()
fig = plt.figure()
0
print(GetUserInput(listOfOptions, True).getInput())
l[0]
xcode - select - -install
self.server.shutdown()
print(datetime.datetime.fromtimestamp(time.time()))
result = [[] for i in range(n)]
conn.endheaders()
img = Image.open(StringIO.StringIO(file_body))
AMOServer.Restore(AMORestoreInfo)
True
df
self.transport.loseConnection()
self.window.add(self.button)
actions.move_to_element(element)
points.append((xs[i], ys[j], zs[k], v))
data
show_banner()
isinstance(9, int)
d2.year - d1.year + (d2.month - d1.month) / 12, (d2.month - d1.month) % 12
right_thresh[:, :w - i] += img[:, i:]
setattr(self, kw, arg)
config = tf.ConfigProto(log_device_placement=True)
signal.alarm(10)
plt.imshow(g)
soup = BeautifulSoup(f.fp)
self.content_length = content_length
d[k].append(v)
l_counts.sort(reverse=True)
a = numpy.empty(shape=(4,), dtype=object)
example.print_value_2(s)
iter(self._choices)
a[mask] = 10
response = requests.get(URL.format(**params))
parent = elem.getparent()
f.close()
jsonObj = json.load(f)
unq_count = np.bincount(id)
Doc.update(set__VAR=Val, set__VAR2=Val2)
fig = plt.figure()
self.button1.pack()
print(p.sub(lambda mo: d[mo.group(1)], mystring))
x = np.random.randint(0, 4, size=(8, 10))
treeaslist.extend(self.makeList(aNode.rChild))
np.allclose(pi[0, 0, 0], np.linalg.pinv(b[0, 0, 0]))
os.close(1)
r = requests.get(url)
plt.ion()
self.__dict__.clear()
fig, ax = plt.subplots()
result = df2.reindex(np.union1d(df1.index, df2.index))
elem.clear()
f = scipy.linspace(0, fs, N, endpoint=False)
posts = db.ListProperty(db.Key, indexed=False)
ax.plot([1, 2], [1, 2])
transitions == 2
signal.alarm(0)
print(partsChild.childNodes[0].nodeValue)
name.ljust(15)
dct = json.loads(my_json_str)
print(USAGE)
True
fig = plt.figure()
self.crawler_process.start()
len(set(y))
pd.Series(1, set(x))
foo = Foo()
gc.collect()
m = len(df)
mask = np.ones(len(array), dtype=bool)
ax.set_yticks(np.arange(AUC.shape[0]) + 0.5, minor=False)
_generate_range_values(start, end)
cb = fig.colorbar(cf, cax=cax)
plt.barh(yvalues, xvalues, figure=fig)
a = a[:, ::-1]
non_list_items.append(item)
suite = unittest.TestSuite(l)
myParent.__init__(self, customParam)
A -= A.mean()
fig = plt.figure()
soup = BeautifulSoup(urllib.request.urlopen(url).read())
print(len(seq_record))
itertools.compress(d, map(lambda x: x > 4, a))
app = QtGui.QApplication(sys.argv)
plt.pause(0.02 * 200)
os.remove(temporarylocation)
log.addHandler(custom_logger.MyHandler())
user = request.db.query(User).filter_by(id=userid).first()
print(self.a, self.b)
cls.funky = 1
x = np.array([u0, phi0])
parser.print_help()
b.sum(axis=0)
n, mod = divmod(n - 1, len(digits))
list_1 = [item for item in list_1 if f(item)]
cv2.waitKey(0)
server.sendmail(emailfrom, emailto, msg.as_string())
df1.dot(t)
q.task_done()
p = readdir(dir_p)
len(x)
a = np.array([list(range(1, 10)), list(range(1, 10))])
heapq._siftup(h, i)
bundle
full.paste(img, (x * w, y * h))
self.accept_imports()
False
df
random.shuffle(l)
np.median([9, 2, 0, 1, 0])
text = text.replace(key, value)
plt.plot(t, s, color=c)
pylab.plot(t, s)
print(self.x)
res.append(tasks.process_read_pair.s(r1, r2))
gevent.sleep(0.5)
self.assertEqual(self.expected, isEven(self.num))
db.session.add_all(items)
json_object = json.load(response)
self.conn.set_isolation_level(0)
app = wx.PySimpleApp()
{{element.product}} - {{element.price}}
data = s.recv(1024)
figure()
initquacker()
sys.getsizeof(2 ** 99)
self.__dict__.pop(*args)
zi = ml.griddata(x, y, z, xi, yi)
print(nCr(4, 2))
string = json.dumps(lst)
df.iloc[-6:-1, (2)]
pprint.pprint(list(chunks(list(range(10, 75)), 10)))
print(NL)
m = np.random.randint(20, 100)
x.astype(int)
buffer.open(QtCore.QIODevice.WriteOnly)
print(f.readline())
serializer_class = WdigetSerializer
work.join()
df.dot(v2)
fooarray[key1, key2] = value
d = OrderedDict({x: x for x in range(10)})
v = -np.cos(np.pi * x) * np.sin(np.pi * y) * np.cos(np.pi * z)
Quota.extend(lstnans)
random.sample(list(range(100)), 20)
c.append(a[k])
root = tk.Tk()
cli.cmdloop()
array = array[mask]
log.addHandler(handler)
f(i)
dt = datetime(2008, 1, 1, 0, 0, 0, 0)
D = NP.random.randn(10000 * 10).reshape(1000, 10)
app = Flask(__name__)
w.close()
search_response = urllib.request.urlopen(url)
deleteL[write_i:]
d = np.diff(condition)
http_server = tornado.httpserver.HTTPServer(application)
self.f()
i += 1
W = nx.DiGraph()
response
ax.imshow(gray_data, cmap=cm.gray)
area += x[i] * y[i + 1] - x[i + 1] * y[i]
print(i, repr(time.time()))
self.finish()
len(self.m[0])
id = Column(Integer, primary_key=True)
f = lambda x: x * math.cos(x - 4)
json_data = data.dumps()
do_stuff(line)
heapq.heappop(gens)
out_f.getvalue()
g.ax_joint.plot(row[0], row[1], color=colors[i], marker=markers[i])
display.stop()
request = mechanize.Request(url)
profile = webdriver.FirefoxProfile()
f = inspect.currentframe()
screen.fill((200, 100, 200))
print(data)
ax2.plot(dates, data)
self.rowconfigure(0, weight=1)
self.sck.recv()
b = a[:]
[0, 1, 2]
name = models.CharField(max_length=100)
math.pi
1, 8, 1, 8
{func: result.get() for func, result in list(results.items())}
result = self.func(x)
sys.getsizeof(foo1.__dict__)
fig = plt.figure()
gf.seek(0)
fig, ax = plt.subplots()
count += 1
nltk.__version__
session.add(w_1)
test.plus(1)
console = logging.StreamHandler()
db.session.add(group_from_factory)
self.sock.connect_ex(self.socketpath)
points = np.random.random((10, 2))
b[a > 80] = funcC(a[a > 80])
Fraction(1, int(xc) + 1)
r = list(range(-int(n / 2), int(n / 2) + 1))
fcntl.fcntl(fd, fcntl.F_SETFL, flags_save & ~os.O_NONBLOCK)
self.idImage = self.canvas.create_image(0, 0, image=image1)
s.connect((host, 9))
l.sort()
product.append(i * 5)
a = [4, 6, 12]
data = [[x.text.strip() for x in row] for row in table.getchildren()]
os.path.join(sys._MEIPASS)
app = Flask(__name__)
request.user and request.user.is_authenticated()
form = Product(request.form)
i, j = np.indices(A.shape)
decompressor.decompress(part)
Vote.objects.filter(choice=self).count()
kOUT[i] = func(TempLake[i], Z)
type(foo)
gui.show()
columns = [list() for i in range(len(headers))]
do_final_thing_with(obj)
pickle.dump(somedata, f)
distance(a, c) + distance(c, b) == distance(a, b)
foo(depth + 1)
X.tocsc()[:, (unique_columns)]
deque(f, maxlen=n)
csv_contents.append(line)
pd.io.json.dumps(summary)
numC = random.randint(1, 100)
stdout.read()
self.output.reset()
window.reserve_space(0, 0, height, 0)
data = sorted(data) + [100000]
label.show()
data_loaded = json.loads(data)
killasgroup = true
name = db.Column(db.String(100))
text[text.startswith(prefix) and len(prefix):]
stack.pop()
base_pic.save(file=result_pic)
out_queue.put(result)
print(repr(points))
result
parse(InfiniteXML())
self.f.flush()
plt.imshow(im_out)
i += 1
x &= ~(1 << index)
sm.stats.lillifors(x)
handler = logging.FileHandler(filename)
self.dataChanged.emit(QtCore.QModelIndex(), QtCore.QModelIndex())
self.extend(list(args))
print(info.groups())
window = MainWindow()
img.show()
self.player.add(self.source, self.scaler, self.fvidscale_cap, self.sink)
jfile = json.loads(line)
l = [1, 5, 7]
print(Ellipse((1.0, -1.0), (2.0, 0.5)).distance_from_origin())
cls
self.__dict__
buf.append(data)
app.register_blueprint(admin)
d.my_attr
wrapper
isinstance(f, io.IOBase)
s = socket.create_connection(*args, **kwargs)
print(x.data)
findex.fromfile(f, findex[0])
{{department.product_count}}
func(**kwargs)
self.a.b.c = value
print(np.roll(v2, -rot)[:v.size])
brush.add_point((event.x, event.y))
seq.ratio()
split = [l[i:i + len(l) / cols] for i in range(0, len(l), len(l) / cols)]
arr = [(a * 2 if a < b * 10 else -a) for a in arr]
x = bar(x)
delattr(Dummy, attrname)
computed[n]
d[c] += 1
rows = [row for row in reader]
data = json.load(data)
ind = np.arange(0, 12, 2)
False
do_your_subprocess_stuff(temp_file)
seen = set()
self.conn.set_isolation_level(old_isolation_level)
dis.dis(lambda : str(100000))
keys.sort()
opener = urllib.request.build_opener(proxy_support)
y = np.interp(t, np.arange(len(y)), y)
id(df.index), id(df2.index)
plt.show()
Base = declarative_base()
self.get(username__iexact=username)
x = np.linspace(np.min(roots) - 50, np.max(roots) + 50, num=1000)
parse()
soup = BeautifulSoup(content)
a = np.random.randint(N, size=n)
x = np.ravel(A).reshape((9, 1))
foo.method1()
list(A.__dict__.keys())
[0, 0, 0, 1]
w = gtk.gdk.get_default_root_window()
arg_dict[o] = ast.literal_eval(arg)
list(range(start, stop + step, step))
lst.append(old_d[key][i])
delta = n / 10
l = []
i += 1
jsonf.close()
len(self._od)
print(i, foo())
self.Add(self.buttonPanel2, 0, wxALL | wxALIGN_LEFT, 5)
next(bar)
funcs.append(lambda : x)
fig = plt.figure(1)
hxs = HtmlXPathSelector(response)
d[keys]
json_data = open(json_file)
handler.response.write(content)
pprint.pprint(L)
response
self.open(self.host, self.port)
self.my_class = my_class
print(response)
fig, a = plt.subplots()
x + x
wrapper
[1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0]
f.read()
outfile.write(file1.read())
plt.plot_date(dates, y_values)
digits = (character for character in input_string if character.isdigit())
map(lambda k: nthRootOfr * exp((t + 2 * k * pi) * 1j / n), list(range(n)))
plt.scatter(group.x, group.y, s=sizes[i], alpha=0.5, label=labels[i])
df
ipc_event_cmd.buffer.add(data_str)
print(i)
self._tarobj = tarobj
sample.index = pd.MultiIndex.from_tuples(list(product(list(range(100)), time)))
my_mesh.SetControlPointAt(v, 0)
d[i].append(x[i])
L.remove(M)
self.value
obj = MyModel.objects.create(val=1)
self.list_one.setGeometry(0, 0, 500, 100)
threading.Thread(target=op).start()
p = Pool(5)
matplotlib.__version__
d1.update(d2)
self._test = get_initial_value()
tests.append(make_test(i))
bio_tagged_sent.append((token, tag))
[1, 1, 0, 1]
app = Flask(__name__)
ax.xaxis.set_major_locator(plt.FixedLocator(x_coordinates))
print(re.sub(pat, repl, str))
list(x.values())
lengths = {key: len(value) for key, value in d.items()}
next(generator)
pprint.pprint(fruit)
self._stdout.close()
self.setPath(path)
existing_item.put()
li.append(li[-1] + 1)
type(0)
B[2, inverse[A[1] == 2]] = A[2, A[1] == 2]
self.submit_form(login_form)
data = []
indices[tuple(column)].append(index)
a = []
max(stats, key=stats.get)
test()
math.ceil(4500 / 1000)
my_handler.setFormatter(log_formatter)
[(x + [nan] * (max_lenght - len(x))) for x in l]
lst.append(i + 1)
fileobj.close()
d = np.arange(1, 21)
print(args.a, args.b)
print(sorted(finder.nbest(bigram_measures.raw_freq, 2), reverse=True))
plt.xlim(1.8, 9.2)
plt.plot(data2)
s.bind((HOST, PORT))
a += 1
self.template = self.template.lower()
Thread.run(self)
os.fstat(g.fileno()).st_nlink
merged = collections.defaultdict(list)
sample_func()
a = [[0] * 10] * 10
mydict = recursivedict()
do_something(line)
parser = argparse.ArgumentParser()
[7, 0, 7],
y, x = np.nonzero(img)
chars.append(escaped_str[i + 1])
permissions[0].id
pool.join()
sum((w[i] * (y[i] - s(x[i]))) ** 2, axis=0) <= s
dict(form=g)
list(calendar.day_name)
fh.close()
print(str(1).zfill(2))
[1, 1, 1, 0]
subplot(121)
sock.settimeout(0.01)
merged = pd.concat(df_list, axis=0)
np.array(data[:]).reshape(shape[:])
data = np.tile(data, (50, 50))
self.list.insert(i, v)
c = array([[1, 1, 1]])
print(row)
count += 1
file, line
glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR)
d
self._window.add(vbox)
foo_noniterable(noniterable)
validate_email(email.strip())
session.add(new_prod)
p(1) / 2 + p(1) / 2 + 1 / 2
self.proxy.setSourceModel(self.model)
setattr(self, key, value)
l.append(foo)
cls(list(datadict.items()))
my_list = json.loads(data[0][1])
f = x & 255
username = db.Column(db.String(80), unique=True)
b.extend([0] * (minlen - len(b)))
self.layers += [NeuronLayer(self.n_outputs, self.n_neurons_to_hl)]
m = regex.match(s)
[i for i in eq2.atoms(Pow) if i.base == a]
ispower(50, 5)
dftmtx = np.fft.fft(np.eye(N))
response = urllib.request.urlopen(request_object)
[]
count += 1
a = np.array([0.1, 0.2, 1.0, 1.0, 1.0, 0.9, 0.6, 1.0, 0.0, 1.0])
colors = np.r_[np.linspace(0.1, 1, 5), np.linspace(0.1, 1, 5)]
print(df)
page.mergePage(new_pdf.getPage(0))
Foo.x = range(1, 4)
format_to_year_to_value_dict = defaultdict(dict)
m = [0] * (N ** 2 + 1)
sendSock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, True)
lock.release()
lxml.version
row in self.data[column]
keys = list(dictionary.keys())
bin(a & b)
extension = mimetypes.guess_extension(content_type)
app = Flask(__name__)
r = q.T.reshape(-1, k, n)
logger.propagate = False
print(f.root.data[1:10, 2:20])
list(islice(set(a).difference(b), 100))
out[0]
main()
splits = list((m.start(), m.end()) for m in re.finditer(pattern, string))
w.setLayout(layout)
self.properties = {}
self._close_database()
ipshell()
response = br.submit()
ctx.stroke()
oldmodule.__dict__.clear()
poller.register(client_receiver, zmq.POLLIN)
ax = plt.subplot(111)
print(np.dtype(float).itemsize)
output_notebook()
log.error_log.addHandler(h)
outputfile.write(line)
log.msg(response)
plt.show()
print([word for word in lst if word in test])
s = Search.from_dict(body)
LB[i] <= x[i] <= UB[i]
logging.config.fileConfig(_log_config_location)
a * x * x + b
chars += len(word) + 1
columns = list(set(columns))
pixel = walnut.getpixel((x0, y0))[:-1]
as_strided(A2[0], shape=(2, 2, 2), strides=(8, 8, 4))
HttpResponseBadRequest()
object_list.filter(user=request.user)
com.convert_robj(rdfrm)
p(10)
fig, ax = plt.subplots(1, 1, figsize=(9, 5))
print(s)
y = np.cos(angle)
result.result
dates = [df.index[i] for i in row_pos]
app.MainLoop()
v_box.addWidget(self.list_one)
plt.colorbar()
threading.Thread(target=tail_forever, args=(fn,)).start()
a.argsort()
timestamp = time.mktime(foreign_dt).astimezone(pytz.utc).timetuple()
L = sorted(zip(x, y), key=operator.itemgetter(0))
new_df = multiindex_me(mydf)
False
bytearray(content[current_pos:final_pos])
spamwriter.writerow(row)
list(islice(iterable, n))
-0.0121994
result = [(item * item) for item in get_list() or []]
[1, 2]
newImage.paste(im, (x1, y1, x1 + old_width, y1 + old_height))
image = ImageGrab.grab()
mymodule.myfunc()
mng.resize(*mng.window.maxsize())
print(parser.parse_args())
patch_distutils()
self.set_positions((xs[0], ys[0]), (xs[1], ys[1]))
words = string.split()
keys = A.keys() & B.keys()
data, addr = sock.recvfrom(1024)
dis.dis(fr.f_code)
thingys.append(x)
wrapper
loop = asyncio.get_event_loop()
line = line.rstrip().split(delimiter)
count_2.most_common()
f = mux41(0, 1, 1, 0)
b = [4, 5, 6, 7]
self.number_of_employee = number_of_employee
print(f.read())
data = f.readlines()
cls.D[t]()
get_something(a)
root.lift()
dy = [0.5, 0.5, 0.5]
self.obj = obj
print(df1)
filehandle.truncate()
fig.subplots_adjust(hspace=0.1, wspace=0.1)
-ea
gram_matrix
a.append(5)
df.Name.str.contains(pat)
df1 = pd.DataFrame(d)
print(f())
pimage.putpalette(PALETTE)
{}
opener.add_handler(my_handler)
self.scrollbar.grid(row=0, column=1, sticky=(N, S, E))
customer = models.CharField(max_length=150)
pyplot.show()
frame.pack()
random.shuffle(target)
arg(a, b, c)
Process(target=loop_a).start()
app = QtGui.QApplication(sys.argv)
grid = np.random.random((10, 10))
self.typemap = {}
s.close()
idx = np.argmax(means)
root = tree.getroot()
min(later, key=lambda d: get_datetime(d[0]))
self._add(val, self.root)
self.view.setDragDropMode(QtGui.QAbstractItemView.InternalMove)
_decorator
histo = gg.apply(lambda x: x.count())
arr[i] = get_something_from_database()
X = np.arange(size)
fn = sys.argv[1]
print_size(**dict)
signal.signal(signal.SIGHUP, handler)
L = [1, 1, 2, 2, 2, 2]
A * x
clf = linear_model.LinearRegression()
counts, bins = np.histogram(x, bins=num_bins)
np.vectorize(d.__getitem__)(a)
print(clusters.shape)
ElementTree.dump(root)
W = DFT_matrix(N)
os.mkdir(newdir)
req = urllib.request.Request(path, mydata)
_autoargs
False
admin.autodiscover()
x = dict((row.SITE_NAME, row.LOOKUP_TABLE) for row in cursor)
f.subs({x: 0})
conn.commit()
title = models.CharField(max_length=100)
df = df[df.date1 == df.date2]
a[a > 0.7].min()
p.close()
B = pd.Series(list(range(1, 5)))
numpy.unravel_index(a.argmax(), a.shape)
y, x = find_image(im, tpl)
frame.Show(True)
self.parser.set(self.name, attr, str(value))
logger.addHandler(ch)
df = pd.read_csv(io.StringIO(temp), names=list(range(10)))
mapping = dict(zip(lookup[:, (0)], list(range(len(lookup)))))
index += 1
arr[i, j] += 1
base_value * 1.0 / 2.54
pos = nx.spring_layout(G)
print(is_new_style(old_style))
A = np.random.uniform(0, 2 * np.pi)
x = [[]] * 4
x.add_to_one(b=9)
self.console.pack(fill=tk.BOTH)
df
obj.foo
os.path.normpath(path1) in list_of_paths
self.button.clicked.connect(self.handleOpenDialog)
root.mainloop()
profiler.runcall(self._handle, *args, **options)
self._advance()
m.set_array([])
children.append(node.keys[i])
print(os.strerror(e.errno))
s.ix[x:y].asfreq(BDay())
graph = fig.add_subplot(111)
sys.exit(1)
random.random() >= p
f = interpolate.interp1d(x, y)
false
self.matrix.__setitem__(index, item)
stackstr
title = models.CharField(max_length=50)
[snip]
help(foo.myfunc)
t2start, t1end
t1start, t2end
t1start, t1end
sys.stdout = orig_stdout
result.append(item)
print(estimate_pi(s1, s2))
data = socket.gethostbyname(d)
plt.imshow(polar_grid, extent=(theta.min(), theta.max(), r.max(), r.min()))
ctx.load_verify_locations(capath=sys.argv[2])
t = Thread(target=getabit, args=(pobj.stdout, q))
httpd.serve_forever()
c.append([(A - B) for A, B in zip(a[i], b[i])])
profs.append(user)
print(result)
self.arrays[j][i + shift]
byte = f.read(1)
finder.apply_ngram_filter(creature_filter)
sleep(5)
app = QtGui.QApplication(sys.argv)
new_user
vals = sorted((sinval(i), i) for i in range(1024))
sys.argv.insert(1, name)
thread.start()
array2.max()
print([i for i in sentence.lower().split() if i not in stop])
a, b, c = [fgen(n) for n in L]
self.fn(*sub_args)
increment()
K = np.arange(n - 2)
s.send(l)
dt_sec = helper(dt)
print(json.loads(thing, object_hook=object_hook))
writer.save()
mktime(gmtime())
im = ax.imshow(data)
container.__iter__()
print(repr(dt))
foo[1]
NEWLIST.append(i)
self.saver.save(self.session, fn)
output.write(left + new_delimiter.join(row) + right + newline)
s.add(i)
lc.set_linewidth(2)
self.temperature += 1
globals()[name] = __import__(name)
b.extend(s)
[0, 0, 1, 1]
ax2.xaxis.set_major_locator(copy.copy(Locator))
self.exec_()
[list_to_int(l) for l in combine(xs, ys)]
logger.info(__name__)
Test.A
dist = np.sum(dist, axis=1)
tree = {}
match = pattern.match(s)
result.put(target(*args))
width = self.canvas1.winfo_width()
ax2 = fig.add_subplot(222)
f.write(next(rbg))
output.write(line)
self[self.nearest_key(key)]
x = MyClass(*args, **kw)
afile.close()
ax2 = plt.subplot(gs[2])
self.setPen(QPen(Qt.red, 1.75))
head = models.BooleanField(default=True)
xml = doc.toprettyxml()[len(declaration):]
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
p.append(tuple(k))
seen_add(element)
url = urllib.parse.urlunsplit(url)
inst.__dict__[self.name]
post.save()
(a + b + c ^ 2 - (a ^ 2 + b ^ 2 + c ^ 2)) / 2
df = DataFrame(data=list(result), columns=list(result.keys()))
x -= 1
do_something_with(out)
l = [0, 1, 1]
plot(1)
fruit[1] = int(fruit[1]) + 1
tree = parse(BytesIO(some_byte_string))
logger = logger.YarnLogger()
2 - 1 < 0
print(result.get())
data = [sheet.cell_value(0, col) for col in range(sheet.ncols)]
y = np.random.random(10)
a.set_xticklabels(a.get_xticks(), fontProperties)
True
True
saver = tf.train.Saver(sharded=True)
instance.save()
b = copy.copy(a)
user = oauth.get_current_user(SCOPE)
ax = fig.add_subplot(111)
arr = numpy.arange(10)
result = []
product.listing.save()
output.addPage(page)
ax = fig.add_subplot(111)
dt = nofrag_dt.replace(microsecond=int(frag))
pos = np.arange(len(alphab))
self.save_object(sub_object)
ax.scatter(x, y)
more_settings.modify(globals())
result.update({k: v})
deleteself.left[0:x]
line_dic[last].append(x)
OrderedDict()
print(user.id, user.email)
os.utime(path, (accessed_time, modified_time))
line = line.lower()
func.current_timestamp(type_=types.Time, bind=engine2)
False
individual_dict[a.individual].append(a)
np.abs(stats_z) > 2
result = pickle.load(infile)
parser._actions[0]
-libxml2 - dev
-libfreetype6 - dev
test.sin_2_(byref(x))
pairs = set(frozenset((w1, w2)) for w1 in words for w2 in prefixes[w1[1:]])
console.log(String(i), String(i / 10))
intercept = np.ones(mX.shape[0]).reshape(mX.shape[0], 1)
Base = declarative_base()
touch(os.path.join(root, filename))
results.append(line)
df[filter_col]
state = models.CharField(max_length=100)
pp.imshow(matrix)
print(sum(1, 1))
list(choice(j[user_input]).values())[0]
ofp.write(line)
[(part1 + part2) for part1, part2 in zip(xs[1::2], xs[2::2])]
greetings.hello()
a = np.array([[1, 5, np.nan, 6], [10, 6, 6, np.nan]])
soup = Soup(open(filename))
df
screen = curses.initscr()
app = current_app._get_current_object()
fig = plt.figure()
db = SQLAlchemy(app)
test = Test()
map.seek(0)
print(type(self))
fig.canvas.draw()
print(a[167])
out.println(msg)
app = QtGui.QApplication(sys.argv)
dfs_rec({Sequence1: [Translate], Translate: [Sequence1]}, Sequence1)
print(jsbeautifier.beautify(script.string))
session = Session()
my_list = in_list[:]
random.seed(seed)
print(repr(profile))
contourf(X, Y, out)
capture = cv.CaptureFromFile(filename)
x = np.zeros(N, N)
c = pycurl.Curl()
B.shape
np.linalg.matrix_rank(a)
print(match_obj.group(1))
dmap[d] != dmap[newd]
raise TimeoutException(message)
x[-1]
d[k].append(v)
self.store.append(self.key, df, data_columns=True)
-next_up(-x)
enc.n_values_
a, b, c, d = np.ogrid[:n, :n, :n, :n]
s.setsockopt(socket.IPPROTO_IPV6, socket.IPV6_V6ONLY, 1)
print(ind[A[ind] == value])
t = currT
y.groupby((y != y.shift()).cumsum()).cumcount() + 1
c.setopt(pycurl.TIMEOUT, 10)
categories_w_rand_books.append((category, collection[category.id]))
logging.info(line)
argrelmax(y)[0]
print(roundPartial(11.12, 0.25))
print(roundPartial(5.24, 0.25))
print(roundPartial(9.76, 0.25))
bodylist.append(tempset)
res
items = db.get(random_keys)
a, b, c = int_list
bins = bins[:-1] + (bins[1] - bins[0]) / 2
pixbuf = loader.get_pixbuf()
AT & F0
time.sleep(0.1)
[p.stdout, p.stderr],
sys.stdout.buffer.write(os.urandom(1000000).translate(tbl))
exampleName(row, column, name)
print(x)
queryset = User.objects.all()
myfunc(*mylist)
[0, 2, 1]
set_.update(list(dict_.keys()))
plt.legend(loc=0)
pythoncom.PumpWaitingMessages()
print(k, v, x)
a = np.random.random(100)
canvas.itemconfigure(interior_id, width=canvas.winfo_width())
False
print(res)
[]
instance = SomeClass()
widget.hide()
configure_blueprints(app)
mail.quit()
self.lines.append(self.addLine(xc, 0, xc, height, pen))
self.Bind(wx.EVT_TIMER, self.onTimer, timer)
[1, 0, 1]
print(a)
ax2 = fig.add_subplot(122)
df.columns = cols
repr(d)
ftp_handle.cwd(name)
cr.paint()
[0, 0, 0, 0, 0, 0, 162, 1, 162, 2],
ET.ElementTree(root), ns
test_suite.addTest(suiteFilter.suite())
[False, True, True, True, True],
print(files)
[1, 1, 0, 0]
x = np.random.rand(m, n)
print(df1.date.dtypes)
InterfaceClass(iface.__name__, (iface,), fields)
b = Counter(0, 1, 1)
t.daemon = True
scraps.save()
t.join()
numpy.fix(a).astype(int)
print(df)
do_work()
a.attr.append(1)
print(a + b)
slither / setup.py
np.fill_diagonal(b, 0)
dis.dis(use_floordiv)
print(retrieved_body)
groups.size().unstack()
setattr(cls, name, op_hook)
response = self.client.get(url)
print(string2[match.b:match.b + match.size])
X, Y = np.meshgrid(x, y)
X = np.random.normal(size=(10, 5))
numpy.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)
y.groupby((y != y.shift()).cumsum()).cumcount()
print(word)
extractDefines(TEST4)
x.f()
y = np.arange(-1, 1, 0.2)
chapter = form.create(parent=book)
c()
line = linecache.getline(filename, lineno, traceback.tb_frame.f_globals)
layout = QtGui.QHBoxLayout()
client = client(url)
idx = [val] + df.index.drop(val).tolist()
request.GET._mutable = False
mydic[key] = [value]
list == [1, 2]
a()
Py_Initialize()
my_content.append(data)
args = parse.parse_args()
x = np.arange(0, size, 1, float)
create_ranges(start, stop, 5, endpoint=False)
col_ind = [i for ids in list(d.values()) for i in ids]
indices = [i for i, x in enumerate(ar) if fnmatch.fnmatch(x, pattern)]
l2 = [a[:i + 1] for a in l1 for i in range(len(a))]
cipher = AES.new(key, AES.MODE_CBC, IV=iv)
df
not array[0]
g += a
dG.add_node(word)
str(n)
res1 = numpy.array(list(zip(*zip_longest(fillvalue=0, *a))))
print(len(ids))
scene = bpy.context.scene
collection.set_facecolor(face_color)
spl.append([])
points = [(random(), random()) for _ in range(1000)]
vectors = np.random.rand(100, 25)
raw_data += bytes
curses.setsyx(-1, -1)
od.setdefault(ele[0], []).extend(ele[1:])
z.close()
heapq.heapify(self._data)
False
check_token
ax1 = plt.subplot(2, 1, 1)
recvSock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, True)
cursor = self.db.cursor()
out.append(A[0][::-1])
session.expire_all()
forced_managed = True
x = np.array([6.4, 6.500000001, 6.5, 6.51])
x.append(5)
result.append(word)
conn.quit()
start = time()
f.cwd(DIRN)
a = []
x += mydict.get(count, 0)
x, y
value = df.iloc[5]
word_list2 = sorted(word_list2, key=itemgetter(1), reverse=True)
print(i + --+i)
tuple(v)
adobe_to_srgb(image)
QObject.__init__(self, *args, **kwargs)
fig = plt.figure()
self.queue.put(message)
int(number / interval) * interval
plt.draw()
np.all(x[idx, J, I] == y)
v = [1, 4, 5]
root = Tkinter.Tk()
my_secure_rng.randrange(n, m)
a[inds][mask]
lib / nark
cashflow
p.print_help()
application.main.show()
map = mmap.mmap(f.fileno(), 0, prot=mmap.PROT_READ)
print(list(squares(5, 50)))
worksheet = workbook.add_worksheet()
plotlyjs
split_string.append(identifier[previous:match.start()])
d[x[4]]
f.seek(0)
self.app = MyApplication(param1, param2).getApplication().test_client()
example()
requests_logger.setLevel(logging.DEBUG)
packet = ip.assemble(ip_packet, 0)
df1.columns = df1.columns.droplevel(level=1)
sim.start()
url_pattern.findall(urls)
print(df)
dataframe[column].value_counts().index.tolist()
z = list(zip(t, t2))
lookup[key(item)].append(item)
dt = nofrag_dt.replace(microsecond=int(frag))
b = np.array([a])
fig = plt.figure()
2 * x
json.dump(data, jsonfile)
self.end_headers()
part_number = models.CharField(max_length=10)
print(df)
main(sys.argv)
args = [iter(iterable)] * n
__file__
img = img.smooth()
b = np.random.randint(l, size=k)
lay.addWidget(le)
lst.sort(key=weight_key)
response
defaultdict(ddict)
pprint(data)
b = [4, 5, 6]
server = BaseHTTPServer.HTTPServer(server_address, TestHandler)
s = requests.Session()
[mysqld]
r = list(csv.reader(file_obj))
B.shape
match = re.match(regex, thestr)
dct = {}
self.a = a
out_csv.writerows(in_txt)
results.append(word_length)
self.__fill_left()
p.join()
result += Data[..., (0)]
app = QtGui.QApplication([])
ax.add_patch(sea_patch)
buf = StringIO.StringIO(req.read())
[fn(*args, **kw) for x in range(count)]
~reduce(np.logical_and, map(pred, list(range(A.shape[1])))).any(axis=1)
successed += 1
curses.endwin()
movie = input()
d2[key] = d1[key]
Py_XDECREF(result)
trainer = DeepBeliefTrainer(net, dataset=dataSet)
HTTPFound(location=request.application_url)
daemon_runner.do_action()
[1, 0, 0, 0]
count = 0
newlist.append([alist[i]])
X = np.c_[x, np.ones_like(x)]
a = np.random.rand(N, N)
zip(*args)
d = json.loads(j)
sum_chunk(a, 2)
ax.hold(True)
curses.resizeterm(y, x)
print(int_no)
rtn_words.append(word_without_exclamation)
plt.bar(bins[:-1], hist, widths)
Response(url, response.status_code, {}, response.content)
mm.stop()
zipwrite.writestr(item, data)
layout.addWidget(self.output)
print(a)
random.choice(animals)
JSONEncoder().encode(YourModel.all().fetch())
combs = []
print(test.vec()[0])
(t ** 2 + 4.0) ** 2 / 16.0
ret
items = []
etree.tostring(t)
df.as_matrix()
M = M[M.getnnz(1) > 0]
Z2 = [np.dot(X[k], Y[k]) for k in range(10)]
fixed = [(pos, item) for pos, item in enumerate(items) if item.freeze]
group = Group.objects.get(pk=1)
seen_add(k)
temp = my_array[:, (0)]
getline(cin, input_line)
list.__setitem__(self, i, x)
f.close()
data = client.recv(1024)
ax.add_patch(clip_path)
a[slice(*a.nonzero()[0].take([0, -1]))] = True
f = numpy.vectorize(f)
char = screen.getch()
game.main()
d[key].append(word)
resp = urllib.request.urlopen(req)
word.lower() == word.lower()[::-1]
app = QtGui.QApplication(sys.argv)
fig, ax = plt.subplots(1, 1)
results = [list(islice(c, length)) for length in b]
time.sleep(5)
mainDlg.Show()
result = f(*args, **kargs)
layout.addWidget(vline)
y = np.array([-2, -1, 0, 1, 2])
count = 0
n = s * (zp + z) ** 2 / d ** 2
main()
axis = fig.add_subplot(111)
value = 4294967295
app.py
p.start()
outfile.write(format % ([i] + row))
ch.setLevel(level)
Counter(chain.from_iterable(linewords))
self.fields[str(f.id)] = forms.BooleanField(initial=False, required=False)
http = httplib2.Http()
file.close()
total = 0
print ()
page = opener.open(uri)
self.alertParent(str(key), str(item))
btn.bind(on_press=partial(self.foo, btn))
vals = list(range(1, 2000))
quad(integrand, 0, 1000)
writer.writerow(newrow)
df = DataFrame(dict([(k, Series(v)) for k, v in list(food2.items())]))
buffer = f.read(1024)
data = pandas.DataFrame(y)
shlex.split(text)
print(tds[0].text)
pprint.pprint(d)
plt.close(fig)
mime_msg = email.message_from_string(msg_str)
result = dict(mainDict)
number = sorted(number, reverse=True)
name = cls.__name__
layout.addWidget(picture)
fs.add_file(file)
c = np.zeros((a.shape[0], b.shape[1]), dtype=DOUBLE)
df = pd.DataFrame(my_data, dtype=str)
print(foo)
bytes.close()
os.chdir(command[input][0])
new_im_vec = new_im.flatten()
False
t = threading.Thread(target=self.receive)
old_init(self, *args, **kwargs)
l = []
print(Counter(contents))
string
L.__code__.co_filename
smtpd.SMTPServer.__init__(*args, **kwargs)
dis.dis(afunc)
options, args = parser.parse_args()
output.add(x)
ptr[2] = color[2]
print(i)
frame = pd.DataFrame()
word.capitalize() if len(word) > length else word
ax = fig1.add_subplot(111)
self._bymonthday + self._bynmonthday
print(name)
all_keys = set(chain.from_iterable(dict_list))
sys.exit()
typing.get_type_hints(Node.__init__)
a.size
updated = request.GET.copy()
counts, bins = numpy.histogram(a, bins=100, density=True)
loop = asyncio.get_event_loop()
cv2.drawContours(mask, [best_cnt], 0, 255, -1)
y = x[1:5]
conn, addr = s.accept()
root = tk.Tk()
print(df)
response
my_df.reset_index(inplace=True)
print(stealth_check[stealth_roll])
arr.keys
SimpleXMLRPCServer.SimpleXMLRPCServer.__init__(self, *args, **kw)
self.load_results()
np.dot(x, y) / (np.linalg.norm(x) * np.linalg.norm(y))
print(totals.argsort())
n - 1
numOfRuns += 1
plt.subplot(211)
parser = argparse.ArgumentParser()
b.foo()
self.window = gtk.Window(gtk.WINDOW_TOPLEVEL)
print(get_image_info(data))
dir()
IedConnection_getServerDirectory.restype = c_int
seen = {(row[0], row[2]) for row in r}
show_strings.visit(root)
print(df.dtypes)
df
1128
last_inner_append(cont[-1], el)
object.__setattr__(self, attr, value)
panel.draw()
sys.exit(1)
df
print(random_list)
[1, 0, 1, 1]
db.session.commit()
print(pos, word.lower())
pipdeptree
n % lcm20 == 0
ax.xaxis.set_major_formatter(EpiCycleScalarFormatter())
print(msg)
ctx.set_verify(VERIFY_PEER | VERIFY_FAIL_IF_NO_PEER_CERT, self.verifyHostname)
atexit.register(cleanup)
a = sin(x)
self.assertCountEqual(self.result, self.expected)
print(time.time() - start)
root = Tkinter.Tk()
H, xedges, yedges = np.histogram2d(x_axis, y_axis, bins=10, weights=z_axis)
lens = np.array([len(i) for i in data])
list(islice(c, size))
[func(group) for group in np.split(S.data, S.indptr[1:-1])]
gc.enable()
2 - 1.781216
print((first_string, second_string, third_string))
np.set_printoptions(1)
plt.plot(xf[1:], 2.0 / N * np.abs(yf[0:N / 2])[1:])
a is a.astype(int)
fig = plt.figure()
s[0] * s[1] + s[2]
print(isCircular(bigList, bigList2))
toss2 = np.array(toss)
image.paste(outline, mask=mask)
dist = sqrt(sum([(x * x) for x in hist_sel - hist]))
jar = cookielib.CookieJar()
self._data_filter.update(attr_dict)
max(SubDirPath(d), key=os.path.getmtime)
PySys_SetArgv(argc, argv)
xmlhttp.send()
-1
self.get_year_sales(datetime.now().year)
retval, img = cv2.threshold(img, 200.0, 255.0, cv2.THRESH_BINARY_INV)
df2 = df.apply(pd.to_timedelta)
l = list(range(1, 10))
check(my_list[start + 1:], tracking=tracking)
a = numpy.float64(numpy.nan)
Xi[0] = Yf[0]
d = defaultdict(int)
1,
channel = connection.channel()
_unpickle_method, (func_name, obj, cls)
self.peercert = self._connection.sock.getpeercert()
ax.plot([-1, 0, 1, 2], list(range(4)))
foo.db
f.write(req.content)
s.close()
present - datetime(2000, 4, 4)
{2, 4}.issubset(chain.from_iterable(x))
data.boxplot()
all(x in mystr for x in ls)
buffer
print(row[col])
self.previewImage = QtGui.QLabel(self)
menu.addAction(a)
t1.start()
group = np.zeros((len(values[0]),), dtype=np.int64) - 1
Session.query(Record.id, Record).filter(Record.id.between(chunk[0], chunk[-1]))
array([100, 1000, 10000, 100000, 1000000, 10000000, 100000000, 1000000000])
root.attrib
process(chunk)
f = list([l for l in a if t[0] <= int(l[0]) < t[1]])
print(f)
np.ndarray(arr.shape, dtype2, arr, 0, arr.strides)
name = db.Column(db.String, nullable=False)
np.bitwise_and.reduce(c) == c[0]
f.flush()
regex = re.compile(regex_txt, re.IGNORECASE)
User.delete_auth_token(user_id, token)
b = np.array([2, 4])
self.thread.start()
z = np.logical_or(y, rolled)
process.start()
surf.write_to_png(image_file)
fig = figure(figsize=(6.5, 12))
example()
top = curses.newwin(1, 10, 0, 0)
html = browser.open(url)
prod = [(i * 5) for i in lst]
parser.print_help()
print(wow)
id = sa.Column(sa.Integer, primary_key=True)
cb = plt.colorbar(im)
bv[0] = 1
d = {}
[k for k in list(d.keys()) if not d[k]]
update_index.Command().handle()
cursor.execute(query_string, query_args)
self.old_handler(*self.signal_received)
ax.legend()
dataBitMap.CreateCompatibleBitmap(dcObj, w, h)
cmyk[i][x, y] = cmyk[i][x, y] - gray
x + 1
max_indices.append(i)
env = Environment()
foo = threading.Event()
ax = plt.gca()
loop.run_until_complete(client_handler(CTX))
cont, = ax.contourf(x, y, z, 500)
self.root = tk.Tk()
doWork()
d = QtGui.QDialog(self)
od.setdefault(n, []).append(s)
process.communicate()
ax = fig.add_subplot(111)
dill.detect.trace(True)
g.output(index)
test(100, 50, 11)
np.array([np.cos(r), np.sin(r)])
output = [6, 4, 2, 2, 1, 1]
atexit.register(DataBase.close_database)
False
l[t[0]] = {}
help(cv2.HOGDescriptor())
main()
f = self[name]._fields.get(ftmp)
print(get_decorators(Foo))
lons.append(float(row[2]))
u, s, v = np.linalg.svd(a)
psutil.Process(doc.pid).get_children()[0].kill()
f()
data = np.where(df.sign == 1)[0]
Employee.__init__(self, name, wage * 26)
axes = plt.subplot(gs[1, 0])
np.array([ax2_cid[axs] for axs in x2_Kaxs_2.flat], dtype=object).shape
soup = BeautifulSoup.BeautifulSoup(s)
self.flush()
date = datetime.now(tz=pytz.utc)
obj = c()
ax = fig.add_subplot(111)
(),
self._dynprop = value
view1[1] = 5
sum_a = list(map(sum, a))
writer = csv.writer(outfile)
ax = s.cumprod().plot()
user = request.user
seq[start:end] = replacement
f.write(opener.open(request).read())
math.floor(1.5)
req = urllib.request.Request(starturl, datagen, headers)
print(Dog().speak())
ssh = paramiko.SSHClient()
np.array(lst)
queryset = models.Bloop.objects.all()
socket.setdefaulttimeout(timeout)
np.arange(n)[b[:-1]].repeat(np.diff(b))
True
self.SetSizer(box_sizer)
self.finish()
g.edges()
email.send()
plt.show()
chunk = next(self)
s.add(el)
pool.close()
ys[0] + (x - xs[0]) * (ys[1] - ys[0]) / (xs[1] - xs[0])
pl.imshow(z2, extent=[-5, 5, -5, 5], alpha=0.5)
self.map = {}
sys.modules[name] = mod
hdu.writeto(filename)
bool(0)
sign * np.exp(logdet)
calendar.day_name[my_date.weekday()]
server_B_thread.start()
res.append((x - 1, x, x + 1))
df
signal.alarm(0)
shutil.rmtree(instance.repo)
data = self.leftover
self.increment_counter()
print(int((t2 - t1).seconds))
bytes(c ^ mask[i % lmask] for i, c in enumerate(byt))
l.append(b)
y, x - a / b * y
Line2D([0, 1], [0, 1], color=color, **kwargs)
self.rect.top += self.dir.y * SPEED
k.press_key(k.left_key)
loop.run_forever()
self.count = 0
print(response.code)
a[index]
self.allClasses = []
reportlab.platypus.Flowable.__init__(self)
res = df[df.cluster >= 0]
pytz.all_timezones
set([8, 9]) & a
print(slice_coords_by_x(2, 4, coords))
Dict[wn + 1] = [(d + timedelta(days=k)).isoformat() for k in range(0, 7)]
_chord.AsyncResult(callback_id), r
logging.getLogger(LOG_AREA1).addHandler(stdoutHandler)
pdf.savefig()
list(gen)
pprint.pprint(build_structure(jdata))
t.start()
lcms.cmsCloseProfile(outprof)
print(sum(x / 2 for x in sq_inc))
df
node = node.__next__
args = parser.parse_args()
plt.show()
print(name_age.name)
sum(bool(e) for e in l) == 1
result += int(i)
np.core.defchararray.add(a1, a2)
self.i
print(a)
output.stdout
hash(s)
z2.namelist()
opener = urllib.request.build_opener(urllib.request.HTTPHandler(debuglevel=1))
my_mesh.EndPolygon()
zip(a, b)
text += elem.strip()
fig, (ax1, ax2) = plt.subplots(1, 2)
print(data)
view.show()
f.close()
row = curs.fetchone()
result.save()
do_things(test_image)
zip_longest(fillvalue=fillvalue, *args)
takewhile(lambda x: x <= max, numbers)
arr[mask] = np.nan
pyplot.gca().add_patch(circle)
set(l1).difference(l2)
server_socket.listen(5)
Method(self, key)
print(r.content)
self._canvas.place_forget()
email_body = data[0][1]
a = argparse.ArgumentParser()
[0]
(u - v) ** 2 * self._norm
a, b, rest = list[0], list[1], list[2:]
code = Column(String(20))
register = template.Library()
map(lambda p: myFunc(p, additionalArgument), pages)
unittest.main()
start = len(my_list) // 2
str(self.to_dict())
s = str(n)
time.sleep(0)
Model.objects.filter(Q(m2m_field=1) & Q(m2m_field=2))
ZZ.old_poly_ring(x).quotient_ring([x ** 2])
plt.plot(*zip(*testList2))
1 << len(self.array)
b = np.arange(10)
sleep(0.5)
_iterencode(o, 0)
self.files = []
self.city = city
t.start()
ax1 = fig.add_subplot(211)
root = Tk()
p = subprocess.Popen(cmd, stdout=subprocess.PIPE)
print(data)
layout.addWidget(self.label)
queryset = User.objects.all()
b = np.random.rand(1000)
ax.plot([1], [1])
model.sample(10000)
p = Process(target=f, args=(num, arr))
client.on_message = on_message
df = df[~(df == 0).any(axis=1)]
slug = models.SlugField(max_length=255)
ax = fig.add_subplot(111)
np.take(np.cumsum(np.log(np.arange(1, m + 1))), n - 1)
print(k)
queue.put(line)
print(line)
G.add_edge(subject_id, object_id, weight=1)
result = list(some_complex_algo(source_data))
plt.plot(x, y)
x = np.arange(9)
fig = plt.figure()
aa = arr.ctypes.data_as(ctypes.POINTER(ctypes.c_ubyte * len(str_bytes)))
self.__dict__.update(new_self.__dict__)
newlist = mylist[2:-2]
self.widget(field, **kwargs)
mask = np.hstack((True, np.diff(lid[sidx]) != 0, True))
turtle.goto(x, y)
BaseObject.initialized
main()
im.wcs
col.set_color(color)
lst[:] = list(range(1, 4))
x = np.linspace(-1, 2, 151)
digits.append(digs[x % base])
seen = set()
df = DataFrame(index=list(range(5)))
leglines.append(legline)
ax.set_ylim(y_min, y_max)
db.session.commit()
random.seed(x[0][0])
print(sqrt(diag(cov)))
fp.close()
cls(**d)
r.close()
mat[:, (diag[0]), (diag[1])] = numpy.nan
min_value = df[feature_name].min()
module
setattr(cls, name, wrap_method(cls, name))
writer.add_document(spelling=item.Title)
f.readline()
lines = [(int(row[0]), row[1]) for row in lines]
s = List()
self.object.get_absolute_url()
setattr(obj, self.name, result)
pool.close()
path, _ = self._treeView.get_cursor()
links = linkregex.findall(str(msg))
func()
vline.set_xdata((x, x))
b1.pack()
[1, 1]
mf.close()
author = models.ForeignKey(Author)
batch.add(service.animals().list(), callback=list_animals)
print(ftp.getwelcome())
x = x.rstrip()
obj = self.__dict__.get(key)
ID = Column(types.Integer, primary_key=True)
s = ttk.Style()
shutil.rmtree(d)
numpy.flatnonzero((lst > a) & (lst < b))[:10]
print(item)
cookies = driver.get_cookies()
Session.begin()
Test.static_method()
df[df.B == B_maxes]
df.dtypes
content_type = models.ForeignKey(ContentType)
self.show()
t[-1][1]
XGBClassifier(grid)
pickle.dump(obj, fh)
x.add(2)
ordered.append(t)
np.argsort(p)
obj.user_set.count()
array2 = np.empty((20, 20) + array1.shape, dtype=array1.dtype)
self.store.insert(i, (key, value))
a1 = A.objects.create()
print(df)
ids.append(int(x))
Grid.columnconfigure(frame, 0, weight=1)
event.accept()
logger = logging.getLogger(__name__)
self._value = val
x = [k for k in list(d.keys()) if d[k] == 1]
P.show()
output.write(outputStream)
lines = my_file.readlines()
health < max_meath or armor < enemy.attack < attack > enemy.defense
d = datetime.utcnow()
a = [str(f) for f in range(n)]
a = np.random.randint(2, size=(10000, 6))
a = []
foo == bar
pyplot.show()
config = configparser.ConfigParser()
cmd.Cmd.__init__(self)
xidx = (raw[:, (0)] - xrange[0]).astype(int)
keys = pygame.key.get_pressed()
k = (k + 1) % len(l)
zip(*([chain(iterable, repeat(padvalue, n - 1))] * n))
print(npdata)
window = Gtk.Window()
BOOST_PYTHON_MODULE(get_dir_list)
b = [numpy.vstack((a.real.T[i], a.imag.T[i])) for i in range(a.shape[2])]
a is a[0]
self.x = 0
plt.show()
repo.heads[0].commit.message
event = models.ForeignKey(Event)
change_request.save()
a + b
outputStream.close()
log.put()
x + y
freq += lemma.count()
y = data[:, (1)]
result = pd.DataFrame.from_records(data).mean().to_dict()
self.user = user
X = np.ascontiguousarray(X)
t * b + a
memset(id(s) + offset, 0, len(s))
total = sum(counts.values())
sum(c * x ** (n - i) for i, c in enumerate(self.coef))
print(datetime.datetime.now())
self.__dict__[key] = item
result = []
print(df)
print(asizeof.asizeof(list(range(N))) / N)
list(x)
retcode = cmdp.wait()
min(bar)
app.deleteLater()
root = Tk()
boo = Boo()
particles1.move()
a = numpy.array([-128, -1, 0, 1, 127], dtype=numpy.int8)
dists = sklearn.metrics.pairwise.manhattan_distances(r)
rv.append((labels[x[0]], x[1]))
s.commit()
key = pygame.key.get_pressed()
self.buttons.rejected.connect(self.reject)
x, y = minloc
key = cv2.waitKey(20)
db = SQLAlchemy(app)
fig.colorbar(cax)
here = os.path.dirname(os.path.abspath(__file__))
len(_)
df1.sort_index(axis=1, level=1, inplace=True)
print([([k] + val) for k, val in list(od.items())])
df
sns.heatmap(df)
app = QtWidgets.QApplication(sys.argv)
writer = csv.DictWriter(csvfile, fieldnames)
b = cv2.erode(b, element)
fn
max(seq)
s = requests.session()
os.dup2(so.fileno(), sys.stdout.fileno())
args = parser.parse_args()
settings.py
np.argsort(arr + np.random.rand(*arr.shape))
self._list = list()
vec = DictVectorizer()
c = a[b]
dot(v1, v2)
user_lon > this_lon - omega and user_lon < this_lon + omega
root.mainloop()
main()
print(t.timeit())
root.withdraw()
print(dt.timedelta(seconds=hms.seconds % resolution.seconds))
response = conn.getresponse()
print(x)
print_node(node)
one_week = 604800
items.issubset(set([1, 2]))
base_classes.Bookcollection = Bookcollection
observer.start()
False == 0
self.server.shutdown()
b = np.cumsum(a)
df
self.idle()
i, j = np.mgrid[:10, :10]
item = db.get(key)
kl.setMath(f.getBody())
row.append(mapper[row[1]])
now = datetime.now()
x[1:] *= m[:-1] < m[1:]
self.takeItem(self.row(item))
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cookiejar))
True, s[1:]
a[(0), :, :] = b
x = -1.1111
values = [random.randint(1, 100) for _ in range(n)]
opener = urllib.request.build_opener(BindableHTTPHandler)
self.setFlag(QGraphicsItem.ItemIsMovable)
pd.DataFrame(data=dct).T.reset_index()
[x[0]] + f([m for m in x if len(m) != len(x[0])])
cursor = connection.cursor()
f.seek(0)
t = list(range(len(x)))
prepdf.xs(sheet).to_excel(writer, sheet_name)
dx, dy = x2 - x1, y2 - y1
time.sleep(snooze)
print(l)
q = multiprocessing.Queue()
n = sum(1 for line in pd.read_csv(filename))
print(log_contents.lower())
deleteself.thisptr
soup = BeautifulSoup(htmlstring)
i += 1
b = np.arange(10)
df_new
TaskBase.__call__(self, *args, **kwargs)
a.sum()
self.local_storage._save(name, content)
func(b)
test = sess.run(e)
print(b.get())
log = logging.getLogger(__name__)
lines = df.plot(ax=ax)
tree = ET.fromstring(data)
term_appearance = Counter(chain.from_iterable(l))
serializers.ModelSerializer.to_representation(self, data)
f.read().splitlines()
foo(a)
print(A[ind] == value)
self.x = 1
sums = np.add.reduceat(a, reductions)[::2]
f()
os.setpgrp()
d.update(b)
os.kill(pid, signal.SIGKILL)
plt.figure()
f = urlopen(url)
[0, 0, 1, 0]
json.dumps(_)
tree = ElementTree.ElementTree()
validate(request.json, current_app.config[schema_name])
deleteinst.__dict__[self.name]
b = np.array(a)
b = json.dumps(json.dumps(a))
print(sh1.col_values(1))
c.save()
pattern_obj.sub(replacement_string, originalstring)
u = numpy.linspace(0, 2 * numpy.pi, 100)
result
plt.legend(loc=0)
self.exit()
ax.set(aspect=1)
root = Tkinter.Tk()
myList = np.random.random(100)
print(x)
queryset = queryset.all()
garbage.append(line)
data.apply(lambda x: dump_sframe_to_dict(x, a))
print(CreateTable(table))
sys.stdout.write(reader.read())
colors = plt.cm.rainbow(np.linspace(0, 1, 20))
fig.set_size_inches(w, h)
epoch = datetime.datetime(1991, 9, 1, 0, 0, 0)
self.name + str(self.age)
a_polygon.contains(a_point)
self._results.append(result)
document2.body.append(copy.copy(element))
b = datetime.now() - a
req = urllib.request.Request(starturl)
time.sleep(5)
newopen.write(line)
print([v, w])
func = functools.partial(self.on_button, name=name)
request = urllib.request.Request(url, data=data)
b = zip(*a)
input = default
a = [0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1]
item
result = list(toposort2(dep_dict))
M[4, 1]
self.free.append(seq_num)
new_list = []
s = s.replace(hit, chr(htmlentitydefs.name2codepoint[name]))
h.endheaders()
yaml.dump(d, f, default_flow_style=False)
worker_thread.start()
data
help(getattr(dict, me))
background_label.place(x=0, y=0, relwidth=1, relheight=1)
d1 = {x: x for x in range(1, 6)}
b = a.reshape(s)
[mindist, (x_coord, y_coord)]
data = np.loadtxt(input_filename)
4 / 100
1 + (n - 1) % 9 if n else 0
some_method(my_data)
session.connection().commit_prepared(xid, recover=True)
ascii_fh.readlines()
i.seek(0)
item
sh.write(m, 1, e2)
app.Dispatch()
Object(self)
cardValue = card[0]
df
{}
new = interpolate.splev(np.linspace(0, 1, 500), tck)
py > matrix[2][4]
b = a.compress(logical_not(z), axis=1)
len(subs)
down_thresh[:h - i, :] += img[i:, :]
sys.stdout = writer
main()
r.delete(key)
mask = cv2.GaussianBlur(mask, (BLUR, BLUR), 0)
print(Counter(L))
print(xopt)
f(1, 0, 0)
epoch = datetime(1970, 1, 1, tzinfo=timezone.utc)
form = playlistform(request, request.POST, instance=playlistmodel)
(1 - coeff * z ** -2)([0, 1, 0, 0, 0, 0, 0]).take(inf)
default_mro[1:2] + default_mro
compressor.add(file)
d[text[i:i + n]].append(i)
data2 = np.empty((h + 2, w + 2))
result = data[:data.size // width * width].reshape(-1, width).mean(axis=1)
timeout = 60
d = {i: [] for i in x}
fieldnames.extend(reader.fieldnames)
my_db.close()
df.loc[g.groups.get(1, [])]
self.cnt += 1
libadd.Add.argtypes = [ctypes.c_int, ctypes.c_int]
ax.plot(x, y, color=col_dict[class_col[i]], label=label, **kwds)
unittest.main(testLoader=loader, verbosity=2)
index = np.argsort(x)
time.sleep(random.uniform(0, 0.02))
vocab_tage = {value: key for key, value in list(tag_vocab.items())}
shutil.copyfileobj(source, temp_file)
pb = gtk.gdk.Pixbuf(gtk.gdk.COLORSPACE_RGB, False, 8, sz[0], sz[1])
server_thread.start()
m = defaultdict(lambda : defaultdict(list))
matplotlib.hatch._hatch_types.append(CustomHatch)
sum(1 for row in matrix for cell in row if cell == WATER)
second_smallest([a, b] + rest)
NULL
loop.run_until_complete(asyncio.gather(*pending))
data[index]
B = np.asarray([A] * N)
Test.objects.filter(id=fr).update(id=to)
np.unique(_25.index.get_level_values(1).dayofweek)
stack.insert(0, x)
output.write(field.ljust(fieldlength))
{{spygames / games | length * 100 | round(0) | int}}
c.clip(a, b)
t = int(list[i])
now = datetime.datetime.now()
stdin = subprocess.PIPE
Variance(X)
print(user.name)
t.setDaemon(daemonic)
consumer.run()
server.ehlo()
plt.pause(delay)
i += 1
flask.session.modified = True
print(a + b)
popt, pcov = curve_fit(goal.__call__, xdata, ydata)
result = count(l, 4)
item, = []
linprog(c, A_ub, b_ub, A_eq, b_eq, options=dict(bland=True, tol=1e-15))
print(l)
datafile.save()
registered_plugins.append(shortname)
BDF.to_excel(writer, sheet_name=B, index=False)
a2.yaxis.tick_right()
ss.connect((host, int(port)))
theList.append(4)
zip(*((x,) * n))
s = map(sum, zip(*([iter(s)] * 2)))
d = np.eye(foo.shape[1]) * foo[:, (np.newaxis)]
self.foo = functools.partial(__, self)
print(e.headers)
mask = np.zeros(len(ar1), dtype=np.bool)
connection = engine.connect()
plt.tight_layout()
new_data = []
sock.send(chunk)
stdout, stderr = p.communicate(scpt)
port = self.mailport
D = D[:, :-2]
[]
v = -np.cos(np.pi * x) * np.sin(np.pi * y) * np.cos(np.pi * z)
decorator
uncompyle2.uncompyle_file(sys.argv[1], f)
model.metadata.create_all(engine)
html = BeautifulSoup(html)
self.worker = Worker(self)
isclose(a, b, rel_tol=1e-09, abs_tol=0.0)
A(self.value + other.value)
line = line.rstrip()
Fraction.from_float(1 / 2.54)
hsv[:, :, (2)] += value
file_two.seek(0, 2)
n += 1
queue.append(obj)
user.save()
writer.close()
ymin, ymax = y[mask].min(), y[mask].max()
popt, pcov = curve_fit(func, x, yn)
mylist = [1, 2, 5, 4, 7, 8]
self.p.stdin.close()
yaml.add_representer(str, unicode_representer)
logging.Handler.__init__(self)
SlicableDict(items[index_slice])
f = test.make_fptr()
poly = PolyCollection(verts, facecolors=fcs, closed=False)
chr(_)
text.pack()
P[idx_tuple]
print(Fraction(0.25))
[0, 0, 0, 0]
egg2(*argList)
x = np.random.uniform(high=maxi, size=ntot)
any(i > 10 for i in range(19))
self.parser.result.append(word)
self._initializeStream()
print(list(sec))
groups.append(list(g))
map(partitioner, data)
self.stop_process = True
registry.add_field(cls, self)
self.container[self.item]
endfor
plt.imshow(data)
end_time = datetime.datetime.utcnow() - start_time
[(1 if is_cjk(ch) else 0) for ch in text]
[v for v, ret in [(a, True), (0, bret), (0, cret)] if ret]
obj = json.loads(encoded)
shuffle(seq)
d[n].update(g.values.tolist())
fn(self)
result = np.zeros(reference.shape)
local_filename
from_date = datetime.now()
cmp(a[10:], b[10:])
do_error()
pool.close()
print(get_deep_text(element_of_interest))
hllDll.wrp_testchar.restype = c_int
sys.getsizeof(aStrOBJECT)
axes.xaxis.grid(False)
self.show()
new_list[jj].append(some_tuple)
im = Image.open(old_image_path)
json_dict[self._KIND2_PARAM] = self._reader2.to_json()
engine.start()
print(df)
arr.resize(shape, refcheck=False)
order = {A.index(j): i for i, j in enumerate(sorted(A))}
myA.myattribute = 9
grid = np.vstack((grid, np.ones((1, grid.shape[1]))))
unique_features.sort()
SOAPpy.__file__
a = MyOrderedField(0)
handler = logging.StreamHandler(sys.stdout)
i = 0
kOUT = np.zeros(N + 1)
p.join()
Fx = np.random.rand(100, 50, 10)
csvfile.seek(0)
m = T.matrix(dtype=theano.config.floatX)
t = time.time()
a = np.column_stack((x.ravel(), y.ravel(), z.ravel()))
a == b
data = []
session.flush()
pid = os.fork()
range_list.append(i)
print(response.json())
arr = np.delete(arr, np.arange(0, arr.size, 4))
fig, ax = plt.subplots()
board = [1, 1, 2, 1], [0, 2, 1, 1], [2, 2, 2, 1], [1, 0, 0, 1]
{}
1
source / opt / python / run / venv / bin / activate
cmap = mpl.colors.ListedColormap(colors)
axes.set_ylim(-0.5, 9.5)
it = random.choice(iters)
log.setLevel(loglevel)
p = zip(t[::2], t[1::2])
data = json.loads(source)
r, c = np.where(N[row_idxs] == 6)
print(csv2)
e.execute(ins)
result
sys.getdefaultencoding()
angle = math.atan(float(dx) / float(dy))
userhome + path[i:]
root.withdraw()
client.close()
K.argsort()[-5:]
print(key, value)
garbage.append(line)
self.grid()
self.server_bind()
HAVE_CURSES = False
func(*args, **kwargs)
data.sort(key=key)
main()
print_two()
x = NP.arange(0, t.shape[0])
points.append((px, py))
deletedict[k]
Dummy.a
ax4 = plt.subplot(gs[(1), 2:])
fs = [(lambda x, _i=i: x + _i) for i in range(10)]
x = object()
sublist.reverse()
x[x.first_valid_index()]
self.list1[i], self.list2[i]
fig = plt.gcf()
fp.seek(BOMLEN, os.SEEK_CUR)
self._setup_widgets()
seq = [1, 4, 6, 9, 11]
glClearColor(0 / 255, 0 / 255, 0 / 255, 0 / 255)
sys.path = old_path
newopen.write(line)
bytearray(data[i] ^ key[i % l] for i in range(0, len(data)))
np.set_printoptions(precision=17)
mask = np.zeros(gray.shape, np.uint8)
tree = etree.ElementTree(root)
key = self.window.getch()
pool = Pool(processes=numProcesses, initializer=initPool)
d = {x: i for i, x in enumerate(t)}
result_dict[key] = list(value)
inner
output = PdfFileWriter()
len(get_file_contents(filename).split())
df = df[reordered]
tck, u = interpolate.splprep(data)
end_date = time.strptime(end_date[:-ulr], fmt)
self.Close()
a = map(int, [(x ** 0.5) for x in range(20)])
1, int(x)
pygame.init()
self.resize(frame.contentsSize())
ax = fig.add_subplot(111)
self.grid = gridlib.Grid(self, style=wx.BORDER_SUNKEN)
np.ix_([0], [0, 1, 2], [0, 2])
list.append(num)
tt.tm_year * 1000 + tt.tm_yday
inlines = [BookInline]
x = np.arange(8.0)
raise Timeout()
a = [1, 2]
df = df.iloc[idx]
print(type(inputList))
matcher.a[match.a:match.a + match.size]
rcount(a)
self.sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
result = thirdparty.go()
sys.stdout = old_stdout
process_count -= 1
meta.add_tags()
parser = argparse.ArgumentParser()
m = re.search(r, s)
df[df1.columns.unique()] = df1.groupby(df1.columns, axis=1).sum()
sys.modules[newk] = sys.modules[k]
locals()
q.join()
p.get_device_info_by_index(4)
window.show()
newList.append(list(range(r[0], r[1] + 1)))
d = defaultdict(dict)
btn.set_style(style)
any(i) and not any(i)
print(int_list)
lst.append(i)
Base.metadata.create_all(engine)
print(a)
alpha.paste(circle.crop((0, 0, rad, rad)), (0, 0))
A = np.array([1, nan, nan, 2, 2, nan, 0])
br.open(url)
print(SequenceMatcher(a=s_1, b=s_2).ratio())
fig, ax = plt.subplots()
print(i)
auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
print(posneg([-1, 1, -4, 5]))
pygame.init()
self.func(self, *args, **kwargs)
a = a[:-1]
y += 0.5 * y.max() * np.random.random(num)
f = urllib.request.urlopen(req)
ax.set_ylim(-2, 2)
profile.save()
asin(2).rewrite(log)
print(get_long(b, 1))
formset
created_at = models.DateTimeField(auto_now=True)
np.sqrt(g, out=g)
print(a)
app = Flask(__name__)
index.reshape(-1, k)
float_to_str(0.1)
s = requests.session()
window.add(frame)
soup = bs4.BeautifulSoup(html)
stdscr.addstr(i, 0, line)
libc.cprogram(wts, res, kks, n, ex)
df.columns
print(s)
df1 = merge(csv1, csv2, **kw1)
digit_product2()
count = len(s)
doc = minidom.parse(myXmlFile)
True
func(*args, **kw)
cur_set.pop()
result_list.append(queue.get())
ax = fig1.add_subplot(111)
sum(s[i] != t[i] for i in range(len(s)))
t.start()
smtp.starttls()
{k: [max((a for a in s if n in a), key=len) for n in v] for k, v in list(my_dict.items())}
w = gtk.gdk.get_default_root_window()
data = []
self.data[key].add(element)
found_dates.append(m.group(1))
self.timer.Stop()
deleteself.all[self._key]
rect = plt.Rectangle((i, -0.5), 1, 1, facecolor=col)
sum(y)
data
rand_x_digit_num(10)
p = mp.Process(target=twitter, args=())
wb = Workbook()
n -= 1
o.pull()
A.setdiag(b[:-1], k=1)
ipsh()
mask = np.isnan(arr)
val = np.asarray(imgTk)[x, y]
content_type, width, height
sys._getframe(back + 1).f_code.co_filename
df
ll = [[(x * N) for x in y] for y in hh]
msg = str(_sys.exc_info()[1])
a[1](1)
a = datetime.now()
max_val = max(l)
print(x)
True
cur = con.cursor()
print(asubkey)
user_id = 142187
page = urllib.request.urlopen(request)
close(child2father_pipefd[0])
pyautogui.moveRel(0, 10)
to_product.append([(k, list(l)) for l in c])
self.assertRedirects(response)
raise TypeError
new_stack
uniq.append(x)
self.foo = foo
x.start()
result = []
Counter(map(tuple, a))
self._find(val, self.root)
llslice[1][1:2] = [10, 11, 12]
pd.concat([sales, pd.DataFrame(hours, index=sales.index)], axis=1)
max_value = max(scores.values())
res
print(cookie.name, cookie.value)
sidx = a.argsort()
i += 1
[]
lst = [list(grp) for i, grp in groupby(lst, key=len)]
value[:2]
pylab.ylim(-1.5, 2.0)
v = float(s) if pattern.findall(s) else int(s)
p = multiprocessing.Pool()
x[0] = 100
data.splitlines()
self.queue.put_nowait(s)
[1, 0, 0, 0]
ax.set_yticks(list(range(0, 9000, 1000)))
v = float(s) if any(c in chars for c in s) else int(s)
x[1] < seq[end - 1][1]
minutes, seconds = divmod(seconds, 60)
serializer.save()
Thread(target=write_input, args=(file, process.stdin), daemon=True).start()
rabbit_frog
rabbit_horse
offset = (today.weekday() - 2) % 7
print(a, b, c)
print(integrate.quad(func2, -pi / 2, pi / 2, args=(-pi / 2, pi / 2))[0])
height = rect.get_height()
spam(5).__closure__[0].cell_contents
f = urllib.request.urlopen(url)
self.val = val
fig = plt.figure()
start = pyqtSignal(str)
[c for c in s]
n += 1
print(np.ma.MaskedArray(Z, mask=~mask).sum())
print(lucky(10))
struct.unpack(format, frame_data)
self.func(*self.args, **self.kwargs)
indices = numpy.arange(a.size)
[26.7, 8.0],
t2.close()
random.shuffle(combined)
client, address = self.sock.accept()
self.body = body
all_data = pd.DataFrame()
type.__new__(meta, classname, bases, newClassDict)
layout.deleteLater()
m.captures(4)
Session.commit()
b = a[:, (np.newaxis)] * np.ones((1, 7, 1))
df = pd.DataFrame(np.random.choice([1, np.nan], (100000, 150), p=(0.01, 0.99)))
children.add(ast.children.get(i))
glMatrixMode(GL_MODELVIEW)
c.execute(q)
termios.tcsetattr(fd, termios.TCSADRAIN, old_settings)
method(self, *args, **kwargs)
c.append(a[index])
self.L.sort()
Swallow.i += 1
mlab.pipeline.volume(grid, vmin=min, vmax=min + 0.5 * (max - min))
self.view = QtGui.QTreeView()
MI.Open(directory + file)
a[a < 0] = 0
edgar.database.load(quarters)
new_s += chr(n)
pool = mp.Pool(processes=4)
pl.imshow(z0, extent=[-5, 5, -5, 5], alpha=0.5)
counts = Counter(list1)
app = web.application(urls, globals())
1 / 0
base64.b64encode(aes.encrypt(message)).decode()
self.yvel -= self.jump_speed
app = Flask(__name__)
set([t.farm for t in qs])
result = {}
print(stored_file.content_type)
h
do_error()
validate(input, schema)
channel.exec_command(remote_command)
r = redis.StrictRedis(connection_pool=pool)
x = np.ones((5, 1))
self.window_list = []
p, e = optimize.curve_fit(piecewise_linear, x, y)
print(bar())
np.sort(data.reshape(N, -1))
print(o.foo())
cPickle.dump(root.sclX.config(), f, -1)
pickle.dump((a, b), f)
soup = BeautifulSoup(str(response))
ax = fig.add_axes([1, 1, 1, 1])
match = matchre.match(character)
verts.append(zip(xs, ys))
ipshell
x[:, (0), (0)]
root.mainloop()
total += int(col)
ranges.append(s)
0
do_something(arr)
ax4.xaxis.tick_bottom()
dialog.ui = Ui_MyDialog()
J.append(np.arange(start, end))
next(g)
pickle.dump(d, f)
row.pop(6)
np.array(result)
table(ax, df)
fig = plt.figure()
l = [x for x in l if x[0] != last[0] and x[1] != last[1]]
IPython.Cell.options_default.cm_config.lineWrapping = true
num_chars += len(line)
self.show_file(self.save_image(image), **options)
x
img = LoadImage(sys.argv[1], 1)
fo.close()
s = sorted(zip(list_2, list_1), reverse=True)
print(a, b)
n = 0
app = QtGui.QApplication(sys.argv)
worker.start()
self._timeCreated = time.time()
print(thing)
opener = urllib.request.build_opener(proxy, auth, urllib.request.HTTPHandler)
rndseries.head()
html.title
power(base, exponent - 1, result * base)
image = image.resize(size, Image.ANTIALIAS)
[[]]
logger.setLevel(logging.ERROR)
self.f.write(x)
a[~((a < -100) | (a > 100))]
train, test = mylist[0]
np.vstack((unq, unq_avg))
foo()
response
window.add(image)
f(*a, **kw)
data.append(m.groups())
ax.pole(*mplstereonet.vector2pole(x, y, z))
print(repr(process.stdout.readline()))
b = [4, 5, 6]
random.seed()
[1, 0, 1, 1]
conn.close()
array([46, 62, 61])
data = zipread.read(item.filename)
m = stats.trim_mean(X, 0.1)
arr = np.array(some_sequence)
size = f.tell()
e = ET.ElementTree(ET.fromstring(xml_string))
list(sum(list_, ()))
ancestor.before.remove(descendent)
func(ret, *args)
ax = fig.axes[0]
it.chain(*mt.roundrobin(mt.chunked(list1, n - 1), list2))
minutes = utc_offset / timedelta(minutes=1)
store_file(new_file, nchunks, hash)
matrix[4][4] = 2
Testing(4 / 4)
pool.map(worker, list(range(10)))
Test.__init__
df = df._get_numeric_data()
repr(bar)
plt.xticks(rotation=90)
colors = img.getcolors(256)
scat = ax.scatter(x, y, c=z, s=200)
outfile.write(doc.prettify())
ax.set_ylim([0.1, 0.8])
n, k = int(eval(input())), int(eval(input()))
Row(*A)
x[np.nonzero(x)]
print(k, list(v))
from_date = datetime.datetime.today()
turtle.right(90)
nums[1]
particles = [Particle(i) for i in range(100000)]
do_something_else(arr)
id(a[1])
command = sys.argv[1]
np.random.seed(2015)
ranked = sx.expanding().apply(lambda x: ranking(x))
ccv1
ccb1
print((der_a.a, der_a.z))
results.extend(result.groups())
print(args)
print(r.findall(s))
print(temp)
dt = dt.replace(hour=0, minute=0, second=0, microsecond=0)
mask = np.zeros(image_src.shape, np.uint8)
file_path = request.url[7:]
plt.setp(ax.xaxis.get_gridlines(), clip_path=circle)
df
b[-1] = b[-1][0], end
form.permissions.data = [p.id for p in user.permissions]
threading.Thread(target=self.listenToClient, args=(client, address)).start()
_lazyprop
results = (c_char_p * 4)(addressof(create_string_buffer(7)))
file.seek(0)
curses.wrapper(main)
kernel[1, 1] = 2.0
decorator(fn_or_output)
self.logwindow.AppendText(msg)
ab = np.where(a[:, (np.newaxis)] == b[(np.newaxis), :])
process = subprocess.Popen(command, shell=True, stdout=subprocess.PIPE)
arr = np.array([False, True])
l = sc.recv(1024)
0
f.write(DATA)
params = {}
output = capturer.getvalue()
s = pylzma.compressfile(i)
decoded = decode_columns(out.indices).reshape(X.shape)
counter.most_common()
lengths = Counter(len(v) for v in list(userIdDict.values()))
w.start()
f(0, 0, 0)
self.assertEqual(expect, foo)
B_out[:, (col_idx)] = np.add.reduceat(A[:, (sidx)], grp_start_idx, axis=1)
tcpCliSock.close()
self.d = self.m.dict()
my_instance = MyClass()
cert_path
t.daemon = True
myapp.run()
y = list([0, 1])
[1, 0, 0, 1]
l = list(range(20))
self.loginPage()
wrapped
self.sizer = wx.BoxSizer(wx.VERTICAL)
np.sum(x != y)
k = np.array([True, False, False, True, False])
self.start()
event.fire(*args, **kargs)
jsonify(u.get_public())
sample_object.users.through.objects.create(user_id=1, sample_id=sample_id)
data = inf.read(BLOCKSIZE)
dateData.append(end)
poly = np.poly1d(coeffs)
worksheet = workbook.add_worksheet()
r = list(range(1000))
manage.py
sparsemax(X, Y)
df = pandas.DataFrame(data)
func(that, session, *args, **kwargs)
im.blit(0, 0, window.width, window.height)
c[c < 0] = 0
pprint(get_driver_name_from_guid(x))
words = line.split()
ar.reshape(ar.shape[0], 1)
toolz.valmap(f, my_list)
colorama.init(autoreset=True)
f = lambda x: map(neg, x)
self.left = left
A = scipy.delete(A, 1, 0)
isinstance(obj, str)
df.index = df.index.get_level_values(0) + df.index.get_level_values(1)
key = operator.itemgetter(0)
t = np.linspace(0, 4 * np.pi, N)
print([i for i in lib.make_array().contents])
fibonacci(n - 1) + fibonacci(n - 2)
noVow(seq[1:])
seclist = [2, 4, 6]
tk = tkinter.Tk()
serializer_class = SpeakerSerializer
wedding_obj
df = pd.DataFrame(df)
H, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0
r1 = Range(start=datetime(2012, 1, 15), end=datetime(2012, 5, 10))
t.render(context)
(1 - coeff * z ** -2)([1, 0, 0, 0, 0, 0, 0]).take(inf)
result = np.empty((4, 2), dtype=int)
df = df[df.TMP.notnull()]
timer1.stop()
traceback.print_exc()
str(root)
plt.boxplot(weighted_appearances)
list(spam.items())
x = np.empty(len(a))
ax2.autoscale(False)
b.flags.owndata
Foo.py
d[str(k)] = v
self.optionmenu_b.pack()
ax1 = fig.add_subplot(221)
col.append(row[i])
lst.extend(words)
w, h = win.GetSize()
triplets = [[a] for a in listA]
lines.append(self.context)
[1, 1, 0]
jobscheduler.configure(jobstores=jobstores)
arr.copy()
mask = ~np.any(np.isnan(x), axis=1)
ax2.scatter(bins_mean, n)
repr(dict)
self._task_handler.start()
s.dropna().plot()
button.Bind(wx.EVT_BUTTON, func)
file.__init__(self, *args, **keyws)
self.mainLayout = QtGui.QVBoxLayout(self)
print(line)
plt.subplot(122)
writer.writeheader()
func(*func_args, **func_kwargs)
x = np.arange(10)
print(c)
plt.plot(x, intg / fullpower)
b1 = np.random.randint(0, 100, 50)
self.func(*args, **kwargs)
a.take((1,), axis=0)
self.qa.save()
ax.set_title(label, size=20)
self.head = tmp.__next__
s.ioctl(socket.SIO_RCVALL, socket.RCVALL_ON)
print(True)
self.b_set.add(b)
[_f for _f in map(self._func, collection) if _f]
contents = fp.readlines()
id(my_dict)
can.place(relx=0.5, rely=0.5, anchor=CENTER)
sorted(iterable, key=natural, reverse=reverse)
print(len(shared_items))
inds = np.triu_indices_from(a, k=1)
lines = stdout.readlines()
gmm.delta = 0
f.getvalue()
dt = datetime.datetime.fromtimestamp(jsts / 1000.0)
b = a
count += 1
random.shuffle(listOfItems)
client2.close()
Whatever().dosomething()
np.where(cnt, hi[ind[cnt - 1]], initial)
dic = dict(zip(lis, lis[1:]))
c = lambda a, b: [list(c) for c in zip(a, b)]
s.ioctl(socket.SIO_RCVALL, socket.RCVALL_ON)
L.append(results.get())
sys.stdout = old
k.release_key(k.alt_key)
a.clip(0)
print(sum(res))
i += self.shape[0]
r = np.minimum(np.arange(n)[::-1], np.arange(n))
dis.dis(greet)
print(list(Foo().foo()))
self.d = {}
print()
fig = plt.gcf()
m.group(2)
do_some_thing()
t = timeit.Timer(foo)
session2.close()
zip(table, list)
tmp2[:, (0)] *= -1
main.write(ccode)
print(b.shape)
display.display(pl.gcf())
fw.close()
inMemoryOutputFile.seek(0)
process.get_memory_info()[0] / float(2 ** 20)
plt.imshow(image)
num += cur.execute(sql, arg)
client = docker.Client()
test2.reshape(-1, 2)[::2].reshape(-1, 4)
k = [(x, l.count(x)) for x in set(l)]
sum(1 for k in ks if k_v1s.get(k) != k_v2s.get(k))
n, p = map(int, input().split())
picked.append(random.choice(data))
print(test_unicode)
d = {}
root = Tk()
a[i] = x + 4
x + y
print(poly.containsPoint(QPoint(1, 1), Qt.OddEvenFill))
response = urllib.request.urlopen(request)
app.exec_()
connection.execute(ins, values)
self.pack()
clf = linear_model.LinearRegression()
string.split(divs[0])
print(list(recurse(dirDict)))
sum(row) > 0.5
ordered = OrderedDict()
QtGui.QSystemTrayIcon.__init__(self, icon, parent)
df = pd.DataFrame(invs)
s = q.get()
chrome_options = webdriver.ChromeOptions()
all(ord(c) < 128 for c in s)
inputs = [1, 1, 0, 2]
x = np.linspace(data.min(), data.max(), 100)
tree = etree.parse(testf, parser=parser)
[hyde]
obj_list.append(obj[i])
list(range(lowerBound, upperBound + step, step))
fig.autofmt_xdate()
foo = np.array(foo_array)
count += 1
a[row, col] = a.sum(axis=1) - a[row, col]
MonkeyDevice.__init__(self)
Signal.send(sender, **kwargs)
print(a % np.sign(a))
copyfileobj(fsrc, fdst)
max(chars, key=chars.count)
print(i1 & 16777215, i2)
surf = pg.Surface((200, 200), flags=HWSURFACE)
dct[elem_name]
keys = sorted(sorted(shaders_dict), key=shaders_dict.get)
tick.set_markeredgewidth(2)
parser.argparse.ArgumentParser()
timeit(stmt1, number=100)
u, v = np.mgrid[0:2 * np.pi:20j, 0:np.pi:10j]
cols = df.columns.values
has_add_permission(self.request.user, self.request)
print(data)
index, item
a[0] + a[1] * 0.1
print(repr(packet))
Py_Initialize()
cv2.line(out, (int(x1), int(y1)), (int(x2) + cols1, int(y2)), (255, 0, 0), 1)
dict_of_lists = defaultdict(list)
sum = 0
dllname = os.path.split(dllname[0])
expr.setParseAction(Expr)
print(REGEX.findall(test_string))
ax = fig.add_subplot(111)
setattr(mod, attr, value)
pubs[0].num_books
do_something(obj)
json.dump(testarr, test_file)
output.close()
screen.fill((159, 182, 205))
self.nout = a
tmp = np.zeros((height, width))
data.update(a_dict)
t = np.floor(x)
ans.extend([(a, x) for x in l2[b:e]])
print(polygon(4, 100))
fd.write(data)
f.writelines(lines[-LIMIT:])
qcookiejar.setCookiesFromUrl(qnetworkcookie_list, QUrl(requested_url))
httplib.HTTPConnection.putheader(self, header, value)
foo = Foo()
fbhandle.close()
dir(test)
pd.__version__
cnxn = pypyodbc.connect(conn_str)
print(arguments[i].value)
pool = multiprocessing.Pool(1)
result
value
merged.update(obj)
Py_Initialize()
s.append(item[0] + item[1])
result_data[mask] = np.mean(values[mask])
True
print(list(all_combos(ceiling=6, target_sum=12, num_cells=4)))
im_out = (im_out * 255).astype(np.uint8)
op.__dict__.update(locals())
PyErr_Print()
train_data[:, (indexes[0])]
plot(times, sin(2 * pi * freq * times))
palette_img.putpalette(flat_palette)
img = feature.canny(img).astype(np.uint8)
print(type(node), node)
dictionary[x].append(y)
image.save(file_obj, ext)
file.write(i)
output[parts[1].strip()] = parts[2].strip()
line = plt.plot(t, y)[0]
c.stop()
x1 = np.random.permutation(100000)
splits = list(m.start() for m in re.finditer(pattern, string))
{{response | safe}}
result = re.sub(p, subst, test_str)
existing_alias.put()
df = pd.DataFrame(data, columns=mux)
show(p)
obj = get_object_or_404(CustomModel, id=some_id)
0.6942, sym2, 7, 5, 10, 10
req = urllib.request.Request(url, stream)
np.nanmax(grouped_2Darray, 1)
print(a.__dict__)
print(line1.intersection(line2))
locale.nl_langinfo(locale.RADIXCHAR)
ranges.remove(i)
deploy(hosts, command)
base_value * (1.0 / 2.54)
browser = mechanize.Browser()
self.names = set()
df
cur = con.cursor()
a = numpy.array([[2.0, 0.0, 0.0], [0.0, 2.0, 0.0], [0.0, 0.0, 4.0]])
popularity = sorted(set(a), key=lambda x: -a.count(x))
result.groups() if result else []
self.delete()
account.objects.get(pk=42).accounttypeb
out = x[idx[count == 1]]
lockedmethod.__name__ = methodname
x.visit(t)
print(property.content)
h = 1 << bits - 1
comment_tree.append(create_tree(record, comment_set))
client, address = s.accept()
b = 1
Counter(s) == Counter(t)
expressions.append(list(itertools.product(o, v)))
ipshell.mainloop()
np.percentile(data, percents)
attrs
m = s.str.len().max()
gevent.spawn(read_stream, p.stderr, stderr)
df = df.fillna(0)
d2 = myfun(d)
name = models.CharField(max_length=50)
print(a)
type(b)
a = len(may_a)
user = form.save()
pool = ThreadPoolExecutor(max_workers=40)
y = (lambda x=x: [(x + i) for i in range(1)])()
L = dot(diag(D ** -0.5), dot(A, diag(D ** 0.5)))
lib.test.argtypes = POINTER(darray), POINTER(darray)
f(5)
curses.endwin()
S = pd.Series(np.random.normal(size=200))
print(l)
regex.sub(repl, string)
main()
root.mainloop()
fig = figure()
print(foo, bar)
triples.append((i, t1, t2))
A()
out = zip(r, c, a[r, c])
ctypes.sizeof(ctypes.c_uint16)
L = [1, 1, 2]
array([6, 8])
flab_nickers,
x = np.random.random((M, N))
row = line.split()
result = [idx for idx, item in enumerate(a) if item in a[:idx]]
max_value = a[mask].max()
rs = (grequests.get(u) for u in urls)
nrange = np.arange(n)
mat[0][0] = 1
np.set_printoptions(linewidth=1000, edgeitems=5)
Base = declarative_base()
random_sample(data, timesteps=2, batch_size=2)
b.getDouble_B()
e = Environment(loader=fileloader, autoescape=True)
d(10) ** d(10) ** d(10) == d(10) ** d(10) ** d(10) + 1000000
xml.sax.parse(f, ch)
df_test.loc[idx]
d.update(value)
arr = (i >> nxn) % 2
numpy.asarray([my_list]).shape
http_server.listen(8080)
self.identity.do_something()
plt.grid(True)
new_list.extend(letters[start_index:start_index + n])
self.func(*func_results)
print(yaml.dump(d))
print(a[(np.newaxis), :, :].shape)
gca().add_patch(rect)
FirstBase.__init__(self, *args, **kargs)
plt.semilogy(xdata, ydata)
print(prng.random())
df
i, j = 0, 0
self.setLayout(layout)
row_names.append(name)
slices = sorted(random.sample(list(range(0, len(index))), 2 * n))
self.heap = []
d = defaultdict(list)
load_file(self.md5)
logging.error(self.headers)
write_and_close_docx(word_doc, tree, new_word_doc)
Lv = np.append(Lv, [last])
lst = list(range(4))
data = json.loads(elevations)
Pdb
print(page_html + news_script_output)
td = datetime.timedelta(hours=2)
cmp(v1, v2)
dtype2 = np.dtype({name: arr.dtype.fields[name] for name in fields})
arr = np.arange(2000).astype(float)
A.__dict__
self.add_widget(widget)
s1.erase(*iter)
histogram[img.getpixel((x2, y2))] += 1
loop = asyncio.get_event_loop()
arr
out = np.zeros((maxt, maxdimx, maxdimy))
list(seen2)
a = []
matches = my_regex.findall(string)
searchlines = f.readlines()
print(df[inds].to_string())
button.pack()
df.B.ix[:4].last_valid_index()
R.append(psi)
print(stringtest)
stars1 == stars2
True
[gdb.Breakpoint(m) for m in method_names]
A = np.zeros((nr - 1, nr))
plt.plot(x, delay)
stdoutdata, stderrdata = p.communicate()
Notification.objects.exclude(pk__in=objects_to_keep).delete()
line.setOpacity(opacity)
last_index = -1
print(k[2])
db.run_in_transaction(txn)
ans = x / y
dis.dis(a_long_tuple)
discoverer = Discoverer(sys.argv[1])
execute_from_command_line(sys.argv)
np.array([5.6]).dtype.num
outfile.write(mystring)
item
t = t + (1,)
parser = argparse.ArgumentParser()
_render_template(*args, **kwargs)
sh = wb.get_active_sheet()
i = 0
x += 1
size = len(value)
print(sql)
conn.close()
True
random.shuffle(b, lambda : r)
{{YOUR_CUSTOM_SETTING}}
test(1000, 50, 11)
ax = ax.ravel()
double_to_hex(-17.5)
x = np.interp(t, np.arange(len(x)), x)
list(csv.reader(inf))
fn = sys.stdin.fileno()
alpha = 2 * math.pi * random.random()
config = ConfigParser()
frame = sys._getframe(1)
skyscrapers[building_number] = AIR
output.write(encrypted_secret_key)
deleteelem.getparent()[0]
x = arange(0, 1, 1.0 / POINTS)
[1, 0, 0]
mydict = {}
labels = [item.get_text() for item in ax2.get_xticklabels()]
main()
result[i]
1 + len_recursive(s[1:])
to_dict(y)
App().root.mainloop()
y = (i for i, v in enumerate(l) if is_odd(v))
QtGui.QSystemTrayIcon.__init__(self, icon, parent)
Department.objects.raw(sql)
asyncio.set_event_loop(self.loop)
pd.DataFrame(dict(l1=lp1, l2=lp2))
globals()[name] = ClassFactory(name, params)
renWinL.Render()
generate_n_primes(10)
print(item)
str(m)
minutes, seconds = divmod(remainder, 60)
sys.getsizeof(n)
ax1 = fig1.add_subplot(1, 1, 1)
os.waitpid(pid)
time.sleep(0.1)
getattr(self._parent, name)
df.head()
results = sorted(lists, key=lambda x: (x[0], int(x[1]), int(x[2])))
order = np.lexsort((data, groups))
show_graph(adjacency)
t5.join()
cfd(treebank.tagged_words())
s = dff.isnull().apply(sum, axis=0)
response = urllib.request.urlopen(crawling)
s = set([4, 5, 6])
fh = logging.FileHandler(LOG_FILE)
np.asarray([a[(n), :, (p)] for n, p in enumerate(b2)])
pd.get_dummies(s, drop_first=True)
self.fn(*args, **kwargs)
filehandler.write(image_data)
self._s.bind((self._host_address, port))
setup2DstuffModelview()
G = nx.Graph()
curs.close()
c[:, (np.concatenate(([True], c[(1), 1:] != c[(1), :-1])))][0]
w, h = Image.open(imlist[0]).size
count_list = list(range(1, N + 1))
f = Foo()
print(minimal_dims.shape)
sys.stdout.encoding
df = DataFrame(d)
ba = bytearray(fh.read())
mask = np.hstack((mask1, mask2))
title = models.CharField(max_length=255, unique=True)
article = Article.objects.all()[random.randint(1, 15)]
f.close()
shutil.copy2(src_file_name, tf.name)
out.append(d)
print(message.format(value))
print(help(a))
mylist = []
a is b, a is c, a is d, c is d
self.pack()
record.append(line)
n = np.prod(shape)
divider = make_axes_locatable(ax)
full_name.strip()
print(list(p))
contents = f.read().split()
t = Thread(target=self._run, args=[self])
f = [0] * nfactors
keys = sorted(d.keys())
self.get_year_sales(datetime.now().year - 1)
build_matrix(f1, (A, B))
self.assertItemsEqual(lst1, lst2)
response = urllib.request.urlopen(request)
p.append(1)
shell.interact()
collections.defaultdict(tree)
ax = df.plot()
transport = paramiko.Transport((ssh_host, ssh_port))
a.dtype.type is np.string_
ssl.__file__
position = center[0] - 10, center[1] + 10
value = self._get_val_from_obj(obj)
True
form = YourForm(data)
mythread.start()
foo.x
sess = tf.InteractiveSession()
form.category.choices = categories
text = f1.read()
result = cur.fetchone()
a = df.values
urljoin(url, quote_plus(term))
ax.spines[pos].set_edgecolor(color)
{{formset.management_form}}
f = tempfile.NamedTemporaryFile(delete=False)
_init_func()
handles, labels = ax.get_legend_handles_labels()
out.close()
d = feedparser.parse(url)
True
main()
ax.contourf(xs, ys, zs, cmap=cm.autumn)
ax.set_ylim(0.5, max(y))
t = Thread(target=newFunc)
string.seek(0)
self.send(s)
draw.rectangle(transparent_area, fill=0)
draw.text((0, 50), txt)
contents = output.getvalue()
plt.show()
b = [4, 5, 6]
s = pylzma.decompressobj()
np.linalg.det(a)
a, b = pickle.load(f)
zf.close()
results = proc.stdout.readlines()
math.floor(-1.5)
result
mpp.join()
my_dict = dict(list(tmp.values()))
book.py
out = my_array[cond]
req = urllib.request.Request(url)
numpy.searchsorted(a, v, side=numpy.CONSTANTS.SIDE.RIGHT)
print(elevation)
threads.append(thread)
file = os.path.abspath(file)
good = np.where(np.isfinite(A))
self.parent.Iconize()
output_wave_file.setparams(input_wave_files[0].getparams())
config.get(section, name)
pickle.dump([obj0, obj1, obj2], f)
action.triggered.connect(self.mapper.map)
tar.addfile(tarinfo=info)
docs.append(raw_doc)
df
foo = 1
page = f.read()
print(df)
BOOST_PYTHON_MODULE(example)
sum([(1, 2), (1,), ()], ())
-[a, b, c]
filepath = os.path.join(path, filename)
max(self.root.left.height(), self.root.right.height()) + 1
dW[:, (y[ii])] -= XX[(ii), (jj), (ii), :].transpose((2, 0, 1))
t.start()
X = pd.DataFrame(data)
response.peer = self.sock.getpeername()
db.put_async(self)
fp.close()
doStuff()
e.property
surf.fill(BGCOL)
ax = plt.subplot(111)
u = User.objects.get(id=1)
unittest.TestSuite.run(self, testResult)
plt.tight_layout()
split_ip(item[0])
line_count += 1
my_module
vbox1.addWidget(self.edit1)
Thread(target=loop).start()
print(len(results))
i = np.argsort(a, axis=1)
maxlen = max(map(len, data))
np.multiply(normal, -1)
ax.get_xaxis().set_visible(False)
log = logging.getLogger()
doStuff(self.model.documents)
L[left:right]
C = np.random.rand(N, N)
draw = ImageDraw.Draw(mask)
DeckForm.__init__(self, *args, **kwargs)
Evaluation.EXCLUDE_AND_CONTINUE
getPermutations(string[:i] + string[i + 1:], prefix + string[i])
main(args)
app = Flask(__name__)
self.labels = self.ax.get_xmajorticklabels()
abs(x) / abs(y) * cmp(x, 0) * cmp(y, 0)
worksheet = workbook.sheet_by_name(workbook.sheet_names()[0])
self.serversocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
dist / hello.app / Contents / MacOS / hello
[f.name for f in matplotlib.font_manager.fontManager.afmlist]
print([(r / psum(raw)) for r in raw])
len(b)
2 - 1
box.pack()
self.a = a
x = y[0] * y[1]
iter(self._inner)
sys.stdout = file
root = lxml.html.fromstring(html)
cur = conn.cursor()
d.a[i:i + k] == d.b[j:j + k]
words_found.append((k, v))
xml.sax.expatreader
res.append(Gap(min(random.randint(1, 5), l - t)))
print(args)
auto_generate_test_cases(Tester, Testee)
row.append(DataReader[j].ToString())
line += next(f)
inner_nodes.sort(key=lambda n: len(subtree[n]))
fig = plt.figure(figsize=(6, 6))
bi_tag.evaluate(cess_sents[train + 1:])
notebook.set_tab_reorderable(page2, True)
register = Library()
max_x = scipy.optimize.fmin(lambda x: -f(x), 0)
os.mkdir(newDir)
response
y = np.outer(np.sin(lons), np.cos(lats)).T
self.src[i].insert(0, itemtoshift)
l, = ax.plot(x, y)
sys.stdin = sys.stdin.detach()
self.path = path
ws = wb.active
list(date_range(begin, end, 4))
matches[1].fromy, matches[1].fromx
print(funcs[1]())
print(unrooted_tree)
end_date = datetime.datetime.utcnow()
time.sleep(8)
then = now - datetime.timedelta(days=90)
print(json_data)
self.__init__(self.sl)
tuple(a.tolist())
root.grid_columnconfigure(1, weight=2)
self.fault = fault
ax4.legend(loc=5)
lines = lines[-10:]
self.handleFontChanged(self.font())
self.buf.seek(0, 2)
self.a = a
[1, 0, 1, 0]
response.status
r = re.search(lun_q, s)
lines = file.readlines()
[truncate(f, n) for n in range(7)]
hash(True)
result.append((longest_keyword, ()))
c = conn.cursor()
r = list(range(1, loopcount))
True
resultset.append(dict(row))
main()
et = ET.ElementTree(document)
type(a)
np.sum(arr ** 2)
bool(set(fruit_dict2).intersection(fruits))
start = time.time()
self.destinitions_list.append(destinition)
file.write(dictionary_content)
PrintLn(f)
print(myset)
all(nested_equal(a[k], b[k]) for k in list(a.keys()))
sock.close()
zip_write.writestr(item, data)
timeit[n / 100, n / 10 % 10, n % 10]
self.cntrlPanel.SetPosition((0, 0))
a()
a = [4, 2, 1, 5]
x[i] = x[i] + 1.0
array.sort(lambda L, R: -1 if R is 0 else 0)
os.dup2(self._devnull, 1)
self._bar = bar
re.sub(findthe, lambda m, r=iter(replacement): next(r), sentence)
offset += 1
profile = webdriver.FirefoxProfile()
result.append((1, record.id, values))
d2 + datetime.timedelta(calendar.monthrange(d2.year, d2.month)[1])
self._func(*args, **kwds)
datetime.time(hour, minute, second)
print(nsmallest(4, indices(), key=keyfn))
results[key] = params[key]
PyErr_Print()
aa.set_axis_off()
False
print(result)
os.kill(p.pid, signal.CTRL_C_EVENT)
self._session
png_formatter.for_type(Image.Image, display_pil_image)
p = argparse.ArgumentParser()
_generate_range_values(value, end)
add_colorbar(im)
logger = logging.getLogger(__name__)
print(df)
emonth1.insert(10, 1)
title = models.CharField(max_length=255)
[nest(x, n - 1)]
url = url_test.format(i)
method_to_be_executed_in_case_of_exception_or_pk_is_false()
Foo.y
foo.bar = types.MethodType(partial(foo.bar, qux=1), foo)
groups = list(groups)
np.ix_(rows, cols)
x = np.arange(16).reshape((4, 2, 2))
D = {k: v for v, k in enumerate(albums_yesterday)}
session = dryscrape.Session()
result = {}
print(msg.Subject)
print(A.T)
self.after(100, self.updateimage, (sprite + 1) % self.num_sprintes)
foo.num += 1
time.sleep(0.2)
chambersinreactor += 1
ret = np.concatenate(ret)
pd.DataFrame(self.values.copy(), self.index.copy(), self.columns.copy())
rStandalone.reassign(7)
original = cv2.cvtColor(original, cv2.COLOR_BGR2RGB)
threshold(imgrey, imgrey, 100, 255, 0)
raise KeyError(key)
plt.subplot(2, 1, 1)
user_email = db.Column(db.String(128), unique=True)
zinfo.CRC = CRC
writer = csv.writer(out_f)
idx = arr[arr.hour >= 17] + pd.offsets.Day(1)
surf1.set_alpha(100)
surf2.set_alpha(100)
print(longest_common([a, b, c]))
soup = BeautifulSoup(markup)
u = [np.zeros((n, n)) for i in range(N)]
sum(counts)
print((m, b))
app
print(categorize(event))
addlist.append(item)
np.take(bins, np.digitize(a, bins, right=True))
my_set = set(my_list)
self.panel = wx.Panel(self, wx.ID_ANY)
all_features.sort()
ax.broken_barh([(midpoint - 0.1, 0.2)], (perc[1], perc[2] - perc[1]))
print(p.stdout.readlines())
instance = RemoveNoise()
app = Flask()
inlines = [PageFileInline]
[operation(n) for n in list]
self.listbox.pack()
test_settings(self.request.user)
wiringpi2.wiringPiISR(4, wiringpi2.INT_EDGE_BOTH, my_int)
pl.show()
print(df)
chain(*(map(iter, self.children) + [isingle(self.value)]))
good = df.ix[df.index - sub.index]
vals = data_rvs(k).astype(dtype)
ax = plt.gca()
print(df1)
graph.set_ydata(Y)
my_set.add(5)
f(150, 150)
root = Tk()
np.testing.assert_almost_equal(x, y, 5)
str(soup)
Y = np.dot(beta, X.T)
q.put(line.strip())
piexif.insert(data, path)
self.fileobj.seek(offset, whence)
ret.append(i ** 2)
rec += connection.recv(1024)
ax.yaxis.set_minor_formatter(matplotlib.ticker.ScalarFormatter())
main()
0
processBody(line)
self.items.pop()
ipc_event_cmd.execute()
indexes.append(idx)
m_t.bind()
self.connection.settimeout(self.timeout)
[0, 2, 2]
cssutils.log.setLevel(logging.CRITICAL)
myTurtle.done()
print(df[order])
df.to_html(out, float_format=fmt)
node0.join()
block_list.extend(sequences[::-1])
list(range(df.EVALUATION_GRADE.min(), df.EVALUATION_GRADE.max() + 1)),
timeout = Timeout(seconds, exception)
gram_matrix[i, j] = K(x, y)
d = defaultdict(list)
np.vsplit(a, 2)
alpr.is_loaded()
channel.exec_command(COMMAND)
os._exit(1)
result.append(item)
log.err()
QtCore.Qt.CopyAction | QtCore.Qt.MoveAction
button.setIcon(icon)
self.arrays[j][i - shift]
is_sum_of_numbers(18, numbers)
csvout.writerows(repeat(row[2:4], count))
cache.get(key)
list_a = ModelA.objects.all()
seen = set()
ax.plot(list2)
idx = mask[xarr, yarr].astype(bool)
iter(obj.items())
scatter(X, Y, c=next(cycol))
map.remove(coord)
_cell.style.alignment.wrap_text = True
fp.close()
color = px[x, y]
len(a)
counter = collections.defaultdict(int)
s[d[i]] = rearranged_data[i]
a[2:]
req = urllib.request.Request(url_2, data)
[0, 2, 0],
results = cursor.fetchall()
self._callfunc = lambda s: s
self.appExeCB = QtGui.QComboBox()
ret, gray = cv2.threshold(gray, 10, 255, 0)
handles, labels = ax.get_legend_handles_labels()
c = mkunion(a, b)
fig.savefig(filename)
msg.send()
response.peercert = resp.peercert
f(a)
app.debug = True
do_something(vals[key])
event = pygame.event.wait()
tree[0].text
thread.start()
name = file.filename
sympy.__version__
df
start_date.replace(year=start_date.year + 1)
print(result)
fig = plt.figure()
self.nodes.append(n)
any(some_list)
mylib.Add.restype = c_int
a = numpy.arange(1000.0)
print(line)
[plt.plot(i, 0, marker=markers[i], ms=10) for i in range(16)]
BrotliCompression.Decompress(input, output)
threads[t].start()
type(self)(self.default_factory, copy.deepcopy(list(self.items())))
type.__setattr__(cls, attr, value)
list2 = list1.split()
[0, 2, 0]
f.seek(2, 1)
print(f)
layout = QtGui.QVBoxLayout(w)
binary.insert(0, bit)
foo(**args_dict)
[(i, z) for i in [1, 2] for z in itertools.filterfalse(lambda x: x in ys, xs)]
f = pickle.loads(x)
True
loggerCent.addHandler(ce)
wrapper_object.close()
content = conn.getresponse().read()
print(data)
parser = argparse.ArgumentParser(usage=usage)
plt.plot(x, f2(x))
df1
res.get()
d = datetime.timedelta(days=21)
hasher.update(block)
dict.__setitem__(self, key, val)
Review.objects.filter(venue__pk=2)
b()
sleep(1)
items = [i.items() for i in items]
f.write(html)
print((table, field, row[field]))
new_list
input = input()
res.head(10)
self._ngrams.add(ngram)
p2.stdin.write(data)
tick.label1 = tick._get_text1()
fig = plt.figure()
view.replace(edit, sublime.Region(0, view.size()), text)
p = Popen(cmd, stdout=PIPE)
green_list.append(s[0] - green_start)
doc = docx.Document(filename)
device.close()
fliplr(flipud(m))
im.show()
self.assertEqual(untrusted, res)
a.sort_index(1, inplace=True)
explain.my_selfexplaining_method()
client = paramiko.SSHClient()
z = np.zeros((5, 5))
replace(list, 1, 7)
foo = lambda x: pd.Series(pd.qcut(x, 10, labels=False), index=x.index)
ADOMDConn.Open()
sentencecount += 1
self.worker = Worker()
alist.sort(key=natural_keys)
result = pool.map_async(task, list(range(10)))
print(sess.run(b))
D()
X = [np.sin(e) * np.cos(a), np.sin(e) * np.sin(a), np.cos(e)]
df = pd.DataFrame(np.random.randn(10000, 10000))
feedparser.parse(url)
self.window.setWindowFlags(QtCore.Qt.Widget)
second += timedelta(days=1)
result = []
srn(my_number)
circle[0]
main()
User.master_query.filter(User.id == 1).all()
do_something(fname)
a1 = np.array([[1, 1, 1], [1, 1, 1], [1, 1, 1]])
a = np.random.random((10, 10))
self.assertEqual(1 + 1, 2)
a = Article.objects.all()[0]
+b * cos(u) * sin(v)
cc.get_violating_points()
g = g.reset_index()
horizontal.sort(key=lambda x: x[1])
start = time.time()
table[i][W - 1]
print(Crypt.find_crypts(0))
self.view = QtGui.QTreeView()
response = connection.getresponse()
print(authentry.parseString(text).dump())
layout = QtGui.QHBoxLayout()
sources[:MAX_SOURCES]
time.sleep(0.7)
writer.writerow(newline)
self.centralwidget = QtGui.QWidget(self)
np.where((abcd <= data2a) & (abcd >= data2b), 1, 0).sum()
items[bisect.bisect(added_weights, random.random() * last_sum)][0]
can.pack()
d = {}
a = np.array(quantized)
z = zipfile.ZipFile(some_source)
print(outputStr[:-1])
print(cert.prettyPrint())
process.start()
df[columns]
ord(hashlib.md5(s).digest()[0])
PyErr_Print()
S[col] = int(homescore) - int(awayscore)
style = wx.DEFAULT_DIALOG_STYLE | wx.RESIZE_BORDER
i = np.where(mask)[0][0] + 1
A = np.random.randint(1, 5, (N, N, K))
ax2.set_xlim(51, 56)
self.reader.__iter__()
edges[i - 2, j].append((i + 2, j))
self.creation_date = datetime.datetime.now()
x = 1
primes = []
__bootstrap__()
[self[i] for i in range(*idx.indices(len(self)))]
writer = csv.writer(fp)
[1, 2] in {1, 2}
r, w, e = select.select(r, w, e, timeout)
ax.plot(scipy.randn(8))
model.add(Dropout(dropout))
soup = BeautifulSoup.BeautifulSoup(html)
n_lsb(n) & ~n_lsb(m)
counts = Counter(chain(*map(set, mylist)))
b.shape
self.b.clicked.connect(self.clickHandler)
figure()
nltk.__version__
crawler.signals.connect(reactor.stop, signal=signals.spider_closed)
wp.interpolate()
b = np.matrix(b).T
i += 1
salt = bcrypt.gensalt()
fig, ax = pl.subplots()
result = list(camel.camel_search(text, search_words))
a.getSingle(), b.getSingle(), b.getSingle_B()
M = Matrix(([x, y], [a, b]))
plt.figure()
[1, 0, 0, 1]
a = datetime.now()
train_op = optimizer.apply_gradients(capped_gvs)
self.portfolio.append(entry)
plt.show()
col = np.tile(ii, (a.shape[1],))
price2
start = end + 1
print(cur.fetchall())
a = representatives[a]
process()
p.close()
result
data = conn.recv(1024)
repo.index.commit(commit_message)
False
print(selected_option.text)
self.fp.write(buf)
test2.timestamp = datetime.datetime.now() - datetime.timedelta(hours=1)
x = []
stack.pop().append(element)
data = mmap.mmap(f.fileno(), 0)
pylab.xlim([min(lefts), max(rights)])
print(fin.read().strip())
cause.append(n.id)
bool([x for x in list(results.values()) if set(x) == match])
dfs.append(psql.read_frame(sql, cnxn))
111111
[p.join() for p in proc]
self.remoteuser = remoteuser
self.remotehost = remotehost
resized_file = orig_image.resize(scaled_size, Image.ANTIALIAS)
x * y
window = np.asarray(window)
self.statusItem.setHighlightMode_(TRUE)
fftf = scipy.fftpack.fftn(f)
self.recv_buf_i += 4
today = datetime.datetime.now()
do_something()
-cr.fetchone()
time.sleep(1)
print(unpickle_regexes(pkl))
value
d = dict(l)
len(self._list)
urls.py
os.utime(fileName, (orgTime, orgTime))
print(out)
[(not b) for b in x]
line = f.next().strip()
powers.append(i)
object_session(self).query(Foo).filter(Foo.bar == self).count()
a = A()
loop.run_until_complete(run())
fig.set_size_inches(1, 1)
h2o.auc(best_model, valid=TRUE)
current = datetime.date(2010, 8, 1)
set(deletes + transposes + replaces + inserts)
dict(zip(it1, it2))
session.configure(bind=engine)
kill_proc_tree(me)
value = count_list.pop()
AxesWidget.__init__(self, ax)
self.sprockets.remove(spr)
km.load_connection_file()
f.write(counter)
df[df.ge(0)].fillna(-9999).where(df < 0, df.eq(df.max(1), 0).astype(int))
a.foo()
canvas.create_polygon(*coords)
sleep(0.1)
1
self.__offset = timedelta(minutes=offset)
setattr(TestSequence, testmethodname, testmethod)
draw_ellipse(image, ellipse_box, width=20)
df
channel = connection.channel()
self.update(rawdata)
user = User.objects.get(username=username)
myseries_one.loc[0:2]
logger.setLevel(logging.INFO)
print(myglobal)
result
print(f.__defaults__)
f()
i -= 1
print(df)
cbar_ax.set_position([posn.x0 + posn.width + 0.01, posn.y0, 0.04, posn.height])
dict(ChainMap(*a))
processBody(line)
line = line.strip()
Function(lambda x: self(x) / other(x))
self.stdout = sys.stdout
ax1 = fig.add_subplot(111)
date = dt.datetime(1970, 1, 1)
df[subset.isin(myList).rolling(2, axis=1).sum().max(axis=1) >= 2]
eval(method_name2)
1
m.group(1)
counts[i] = counts.get(i, 0) + 1
counter[0] -= 1
archive.write(path, relname)
users = api.lookup_users(user_ids=ids)
cj.load()
df.dtypes
ax = fig.add_subplot(111)
L[a + span2:c] = L[a:b]
main()
nl.append(base)
list(zip(a, b))
ax.yaxis.set_major_formatter(FixedOrderFormatter(-9))
s = open(filename).read(512)
p.insert(0, a)
Test.method_two()
file.close()
self.layoutVertical = QtGui.QVBoxLayout(self)
iter1, iter2 = [x[0] for x in compound_iter], [x[1] for x in compound_iter]
logging.config.dictConfig(LOGGING)
g.readinto(q)
ret = float(s)
_a(cos(p[0]) * p[1], sin(p[0]) * p[1])
df
k = k[k != test].reshape(-1, 2).astype(float)
bs = BeautifulSoup(html)
t.set_priv(True)
retval += chr(node[1][0][1][0])
z = np.logical_or(z, rolled)
np.dot(L1_sums, L2_sums)
data = s.recv(1024)
list = [7, 6, 5, 7, 6, 7, 6, 6, 6, 4, 5, 6]
pygame.time.Clock().tick(10)
reader = csv.reader(f)
ax.add_collection(col)
sock = socket_create(AF_INET, SOCK_STREAM, 0)
plt.plot(ipl_t, x_i)
d[k] += v
[7, 8, 9],
raise ConnectionError(err, request=request)
dict(d)
distutils.log.set_verbosity(-1)
fig, (ax, ax2) = plt.subplots(1, 2, sharey=True, tight_layout=True)
aut.add_word(s, s)
mins.sort()
self.bar % 2 == 0
unquote(value)
new_arr.append(new_val)
session.flush()
image = Image.open(data)
func.__get__(obj, cls)
nx.draw_networkx_edges(Gcc, pos, alpha=0.4)
ax.set_ylim(-0.5, 0.5)
settings.MYAPP_SETTINGS_1
save(random.choice(classes), arg)
[self[x] for x in range(i.start, i.stop, i.step or 1)]
Object.__getattr__(self, name)
print(len(x))
sys_exit.assert_called_with(1)
pylab.plot(list(range(10)))
df
threads.append(t)
atexit.register(web.quit)
print(sdi)
plt.yticks(np.array([]))
match = [0] * (len(s) + 1)
timeout.cancel()
session.flush()
print(time.clock())
client_socket.send(size)
df[~df.stack().between(0.1, 1).unstack()].dropna(axis=1)
a + b
True
subprocess.check_output(command).strip()
isinstance(p, list)
print(lst)
o = Object()
print(match)
self.delete(self.index(Tkinter.INSERT), Tkinter.END)
self.tgtkey = self.currkey = self.currvalue = object()
session.add(new_bike)
setattr(obj, accessor_name, object_list)
m = a[k]
message = self.queue.get()
c = formC.save(commit=False)
print(platform.python_version())
dest.blit(tmp, (0, 0), dest.get_rect().clip(maskrect))
fmt_values
self.store.remove(key)
divider = make_axes_locatable(ax1)
pd.crosstab(df.Event, df.Status)
a += [4]
clusters[-1].append(point)
tmp.seek(0)
branch[1].append(path[-1])
progress.setValue(100)
x * 2
merge_Sort(list1, list2, new_list)
Z.data *= Y[Z.row]
d[c] = i
args, subargs
self.factory.echoers.remove(self)
video_window.destroy()
sct.norm.ppf(q=0.05, loc=60, scale=40)
string[string.find(substring) + len(substring):]
response = requests.get(_GOOGLE_TRENDS_URL % term)
0, [True, True, True, True]
wx.Panel.__init__(self, parent)
L = [0, 8, 5, 6, 4, 5, 6, 14, 8]
myTurtle.forward(size)
myObject.die()
file.seek(currentReadPos)
scene.objects.active = lamp_object
result[key] = value
f1 = lambda x: np.sum(x) - 1
nested.__closure__[0]
ax = fig.add_subplot(111)
G.add_edge(parent, child)
self._conn.timeout = timeout
df
jsondata = JsonData(**result)
file_list.extend(join(root, f) for f in files)
b = np.random.randint(N, size=n)
image = Image.open(stream)
print(soup.contents[0].string)
x.cumsum()
print(count.most_common())
print(len(match_foo))
result = task.get()
db.put(fu_list)
idx = list(df.index)
print([x for x in words if len(x) > avg])
os.dup2(fd_stdout, 1)
print(type(value))
{{block_of_text | nl2br}}
html
ast.dump(node)
fig = plt.figure()
idx = cutoffs.searchsorted(np.random.uniform(0, cutoffs[-1]))
s.intersection(*ip)
heapq.heappush(pqueue, (-atime, fsize))
result[-1].append(s)
self.set_weights([random.uniform(0, 1) for x in range(0, n_inputs + 1)])
self.min_value, self.max_value = min_value, max_value
im = np.vstack((im[1:], im[0]))
n = len(x)
self.rematch.group(i)
B[idx[1]]
generate_random_data(latitude, longitude, 5, file_n)
l2 = [4, 5, 6]
t = threading.Thread(target=worker)
x2 = np.linspace(0, 2, 100)
B = np.rollaxis(A, 2)
draw = ImageDraw.Draw(image)
id(gb1.a)
ax.set_ylabel(label, size=20)
data.append(group)
self.view = QtGui.QTableView(self.centralwidget)
(x.index if isinstance(x, arg) else -1 for x in pargs),
titled.append(word)
a
content = urllib.request.urlopen(url).read()
self._list = list(data)
df
d.hexdigest()
s.kill()
memoizer
obj.companyid.name
my_dict = MyDict()
session = sessionmaker(binds=binds)()
json.dumps(data, indent=2)
X, Y = np.meshgrid(row, row)
child_list.append(child)
self.oldglobals = {}
f(**kwargs)
xmin, xmax, ymin, ymax = x.min(), x.max(), y.min(), y.max()
b = B()
x = np.linspace(np.min(sample), np.max(sample))
total = 0
True
buffer.seek(0)
stat2[k] += v
all(lst) or not any(lst)
C = []
array = getarray[i]
print(np.outer(x[(10), :], y[(10), :]))
BeautifulSoup(badString, markupMassage=myNewMassage)
somefile.seek(0, os.SEEK_END)
prev, current = current, next(self.__iter)
query
df[df.columns[1:]]
context = {}
group = models.ForeignKey(Group)
nones.append(ind)
setattr(self, name, float(x))
template.format(userinfo)
s = np.argsort(b)
k = json.dumps(m)
n = sum(1 for row in csv.reader(filename))
io.show()
+models.py
x = np.arange(1.0 * 2 * k).reshape(2, k)
pprint(h)
atexit.register(save_history)
libcap.cap_to_text.restype = ctypes.c_char_p
cols = np.array([1, 2])
pprint.pprint(codes)
wnl.lemmatize(greatest)
self.value.__str__()
print(A.method_c.__func__.__code__.co_firstlineno)
pl.imshow(z1, extent=[-5, 5, -5, 5], alpha=0.2)
print(list(rand_days))
a = ctypes.create_string_buffer(lnum.bit_length() // 8 + 1)
ax1.grid(True)
screen.blit(sys_font.render(l, 0, hecolor), (x, y + fsize * i))
np.stack(np.where(df.values)).reshape(-1, 2)
thread.start()
w.head()
buf = (c_char * n).from_address(p)
s = pd.Series(words, index=idx)
data[i] = valuej
client_sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
A.shape
data = f.read()
template = env.get_template(templatefile)
p = subprocess.Popen(filepath, shell=True, stdout=subprocess.PIPE)
layout.addWidget(de)
f.write(chunk)
parser.write(f)
y = [4, 5, 6]
Foo.instance_count += 1
self.name
line = eval(input())
self.oparg = oparg
start = dt - timedelta(days=dt.weekday())
app = wx.PySimpleApp()
cls.__old_init(self, *a, **kw)
set([(d1 + timedelta(days=i)) for i in range(delta.days + 1)])
y = [4, 5, 6]
app = wx.App(False)
pos = nx.spring_layout(G, fixed=list(fixedpos.keys()), pos=fixedpos)
c.persist()
delta = timedelta(days=-delta_days, weeks=delta_weeks)
print((my_num, my_string))
x = x.__iadd__([4, 5, 6])
check(float(sys.argv[1]), float(sys.argv[2]))
out, err = p.communicate()
X[([10]), :]
self.old_handler = signal.getsignal(signal.SIGINT)
excel.Visible = 0
print((x[N], y[N]))
regr.fit(chntrain_X, chntrain_y)
kwargs = dict(kwargs)
stream.close()
self.files += 1
texter.setPlainText(infile.read())
ss.sort(key=lambda a: a[1].order)
a.a = 2
print(temp.weekday())
destination.set_contents_from_file(myfile)
my_map.bluemarble()
filename = sys.argv[1]
rowspans[daynum] -= 1
b = [0, 2, 4, 5]
output = ps.communicate()[0]
n = b.shape[0]
child.close()
self.inverse.setdefault(self[key], []).remove(key)
print(x)
repr(test.f_call)
NULL
width, height = self.width, self.height
dG.add_node(next_word)
f.__closure__
self.Bind(wx.EVT_LIST_BEGIN_LABEL_EDIT, self.OnBeginLabelEdit)
doc = etree.parse(fp)
logger = logging.getLogger()
v = numpy.diff(t)
m_action.perform()
print(combs(sampleip1))
print(combs(sampleip0))
data = pd.read_csv(filename, names=headings)
df = pd.DataFrame.from_records(t, columns=t.columns)
print(c)
new_button.configure(command=callback_factory(new_button))
z
filepaths.sort(key=lambda filename: filename[1], reverse=reverse)
base = np.arange(size)
tuple(self.construct_sequence(node))
df
parser.parse(d)
res.append(defaults[f])
log.startLogging(sys.stdout)
now = datetime.now()
c[1, 2] = 5
print(i + 1)
self.response.write(gcs_data.gcs_read_blob(dyn))
x = np.linalg.solve(a, b)
src = driver.page_source
draw = ImageDraw.Draw(img)
a = s[0:24].uintle
site = self.request.db.query(Site).filter_by(id=key).first()
self.process.finished.connect(lambda : self.runButton.setEnabled(True))
utc_offset = local_dt.utcoffset()
print(g(x))
[1, 2] == [1, 2]
self
current_line = my_file.readline()
datetime(date.year, date.month, day)
print(max(list(kmer2count.items()), key=lambda k_v: k_v[1]))
map(operator.itemgetter(1), L)
repl += repl_pattern[len(match_str):]
ax = plt.subplot(111)
list(chunker(x, 2))
t.join()
serializer.object
angleInDegrees = atan2(deltaY, deltaX) * 180 / PI
dx = x2 - x1
result = []
self.axes = self.figure.add_subplot(111)
pickle.dump(value, f)
grid()
CustomPaginateNode(paginator_class, objects, **kwargs)
tally[item].append(i)
myDict = {x.index: x for x in xs}
key = row[1], row[2]
group_by(input, 1)
g.usersview.render()
s.sum(level=1)
header = gtk.HBox()
z.insert(0, z.pop())
np.random.shuffle(mask)
lambda cls: make_threadsafe(cls, methodnames, lockfactory)
idx = np.random.choice(np.arange(len(x)), 1000, replace=False)
Py_DECREF(index)
lst = sorted(iter(d.items()), key=itemgetter(1))
http = httplib2.Http()
tuple(getattr(self, slot) for slot in self.__slots__)
app = wx.App(False)
print(string[6])
br.geturl()
temp.append(i)
name, age = noglobaltest()
self._waitready = set()
w = w.translate(table)
print(folder.name)
views.py
deleted[1]
data[:, (0)]
stdin, stdout, stderr = ssh.exec_command(prepare_command(command))
self.name = name
print(json.dumps(d, indent=2))
print(self.treeWidget.currentItem().text(0))
fexdata = {}
print(z)
s = a.argsort()
E = np.array((xp, yp, zp))
a = Decimal(str(a))
rs = q.get_messages(10)
start = time.time()
downloadFiles(source, dest)
self.rect.left += self.dir.x * SPEED
self.ax = self._fig.add_subplot(111)
client.remove_flags(msg_ids, [SEEN])
NSScreen.mainScreen().frame().height
data = literal_eval(f.read())
self.count += 1
args = parser.parse_args()
result.append(dict(type=key, items=list(v[0] for v in valuesiter)))
data = np.zeros([N, 4114])
logging.disable(logging.CRITICAL)
conn = pycurl.Curl()
{{forms.render_field(field)}}
raise ndb.Return(buildings)
np.random.shuffle(col0)
print(response.msg)
print(page.read())
Pdb
a = [4, 5, 0, 0, 6, 7, 0, 1, 0, 5]
aList.pop(0)
np.nonzero(b)
me = np.zeros(n.shape[0])
main()
p.join()
QtGui.QDirModel.setData(self, index, value, role)
print(x)
print(pandas_select(df, select_dict).to_string())
myShape.translate(Base.Vector(2, 0, 0))
(df == window_stop_row).all(axis=1)
lambda self, *args: getattr(self.num, name)(*args)
time_series.append(forecast_append)
q = manager.Queue()
t2 = threading.Thread(target=thread2, args=(2, t2_stop))
self.cursor.execute(sql, (reason, id))
logging.getLogger().addHandler(fh)
x.append(words[1])
self.ax.set_thetagrids(self.angles, labels=titles, fontsize=14)
grid = np.arange(100).reshape((10, 10))
base_string % values
PersonQuerySet(self.model)
iter(list(itr)[1:])
a, b = list[0], list[1]
parser.print_help()
map(x.count, x)
appended_data.append(data)
A.T
p.append(2)
[atleast_2d(_m) for _m in tup]
input.close()
mx = np.matrix(x)
self.layout = QtWidgets.QVBoxLayout()
imp.find_module(module_name)
cursor = conn.cursor(cursors.SSCursor)
{{number}}
tmp.blit(mask, destpos, maskrect, special_flags=pygame.BLEND_RGBA_MULT)
widget.layout().addWidget(label)
n = int(math.sqrt(2 * x))
cc.run()
r = requests.get(url)
logging.FileHandler.__init__(self, filename, mode, encoding, delay)
env = jinja2.Environment()
print(result.get(timeout=1))
f.read(1)
params.append(filtervalue)
self.weight = weight
heatmap = plt.pcolor(data)
b = int(a)
consume(some_func(x) for x in some_list if x > 5)
r = pd.Series(list(range(len(df))))[::-1] + 1
value = line.split()[-1]
l[i] += 1
transactions.sort(key=operator.itemgetter(0))
a + 0
output = PdfFileWriter()
combined[key1].append(key2)
screen = pygame.display.set_mode([100, 100])
counts = np.zeros(shape=arr.shape)
setattr(obj, proxy.value_attr, value)
self.read_events()
self.inner_test = InnerTest()
plt.tight_layout()
df[keys] = df[j] - df[from_joint]
h2.setLevel(logging.WARNING)
seen.add(x)
cap = cv2.VideoCapture(0)
A, B, C = np.polyfit(x, np.log(y), 2)
[(grouper, list(values)) for grouper, values in my_groupby_generator]
count[word] += 1
ax.w_zaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))
obj_a.my_method()
axis1.plot(list(range(10)))
blank_image[:, 0.5 * width:width] = 0, 255, 0
[1, 0, 1, 0]
self.__dict__[name]
print(foo.args)
N = col.shape[0]
FIN.seek(random.randrange(length), 0)
[2, 0, 1],
float(timedelta.days) + float(timedelta.seconds) / float(86400)
setattr(obj, self.private_name, result)
dir(parrot.Norwegian)
c1.say_my_name()
ctx.set_line_width(1.5)
signal = wave_file.read_frames(wave_file.nframes)
v = A[position:][:length]
self._build_calendar()
self._fileobj.tell() - self._offset
PyErr_Print()
output.write(input.readline())
mplrun()
A[(_), :]
b = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
table[n - 1] if n else 1
a = 1
1, 1, 1, 8
p.join()
axes = plt.subplot(gs[0, 1])
edges = np.reshape(edges, (edges.shape[0] / 2, 2))
print(Dog.__bases__)
print(primeslt(int(i)))
D = set()
min(compress(my_lookup, my_list), key=my_lookup.get)
n == 1
root = Tk()
p.join()
r = requests.get(url)
df = json_normalize(data)
ser.plot(ax=axes[0])
d1 = pd.concat([d1.loc[[1]].rename(index={(1): 0}), d1])
sys.stdout = stdout
result = list(product(all_files, all_files))
print(x == 247)
d = date.today()
items = sorted([(k.lstrip().lower(), v) for k, v in list(d.items())])
self._result = result
app = QApplication(sys.argv)
k1 = 0
node = lxml.html.fromstring(node)
y = np.outer(x, k) + b + np.random.normal(size=(50, 1000), scale=1e-10)
type(name, (Parent,) + bases, dict)
20000000000
list(range(0, len(list1)))
self.transport.write(self.factory.text)
lapack_routine(n, n, tmp, n, pivots[i], 0)
self.value = value
entry = menu.addAction(item)
print(type(p))
json.loads(data)
image = open(filename)
socket.inet_aton(address)
p.apply_async(f, (np.random.rand(1000, 1000), np.random.rand(1000)))
a = numpy.float64(42.0)
a = csv.writer(b)
print(mo.group(0))
(0, 1)[1]
p.hello()
True
title = models.CharField(max_length=255)
new_row.append(row[column_index])
count(6)
getattr(self.get_query_set(), name, *args)
alice.toys = toys
soup = BeautifulSoup(page)
my_model = MyModel.objects.all()
data = os.read(fd, 1024)
x, y = new_x, new_y
name = models.CharField(max_length=255)
DBListings()
hash((self.x, self.y))
process.stdout.readline()
self.DataPlot.draw()
p.close()
dict[firstName] += 1
y = canvas.canvasy(event.y)
reader = csv.reader(infile)
socket.gethostbyname(i.strip())
actions.perform()
lines = lines + 1
P.figure()
list(all_but_n_last(data, 1))
driver = webdriver.PhantomJS(service_args=args)
A = scipy.io.mmread(sys.argv[1])
b = pickle.load(handle)
select.order_by(func.random())
sys.exit(app.exec_())
callUponTimeout(*args, **kw)
Py_Initialize()
s = s[n:]
b = min([n for n in list2 if n > i])
print(folder.name)
print(soup)
max = len(lst)
soup = BeautifulSoup(r.text)
dollars += 1
root = tk.Tk()
key = row[0]
self.stream.write(msg.encode(self.stream.encoding))
top.mainloop()
logger.addHandler(someutils.null_handler)
render_to_csv_response(qs)
fig, ax = plt.subplots()
self.__setattr__(key, value)
a[:], b[:] = zip(*combined)
next(f)
x = np.array([1, 1, 1, 2, 2, 2, 5, 25, 1, 1])
frec(word[len(s):], values + [s])
print(fileinput.filename(), fileinput.lineno(), line)
fW.flush()
session.add(user2)
curs = conn.cursor()
__slots__ = ()
df
output.append(number)
gona[(1), :]
pool.apply_async(test, (k, multi_d))
arr.view(np.dtype((np.void, arr.dtype.itemsize * arr.shape[-1])))
logging.basicConfig(level=logging.INFO)
standard_scalerX.fit(X_test)
leng(s[1:], count + 1)
b = [5, 6, 7, 8, 9]
str(r)
log.addHandler(journal.JournaldLogHandler())
user_id
ax1 = plt.subplot(gs[(0), 0:2])
a.get(0)
figure = np.random.uniform(size=(4, 4))
5 - 0.464188
addvec2(mat, vec)
self.append(text)
b = a + b
self.d = {}
df = df[::-1]
new_array = array[mask]
a = np.array([[1, 0, 1], [0, 0, 1]])
f.__setitem__((slice(5, 10), 100), 2)
print(poly.intersection(merged_cells).area)
tf.get_default_graph().finalize()
result = defaultdict(int)
help(enumerate)
0
child.expect(pexpect.EOF)
n = len(archive.getnames())
diff(nges, n[5])
self._fill(index)
list(range(start_val, start_val + 10))
cursor = connection.cursor()
MyPickler(output).dump(thingee)
dic = dic.setdefault(key, {})
ret, mask = cv2.threshold(result_grey, 10, 255, cv2.THRESH_BINARY)
self.properties.update(attr)
xmlFile.childNodes[0].appendChild(newScript)
shutil.copy(os.path.join(source, fname), os.path.join(dest, fname))
self.transport.loseConnection()
result = []
A = np.arange(24)
key, val = list(e.items())[0]
sel = Selector(response)
self.name = name
it = zip(*([iter(L)] * 2))
ui.write(e.EV_KEY, e.KEY_LEFTSHIFT, 1)
c = c.ravel()
content = f.read()
print(new_items)
ans = (x - y) ** 2
df = df.loc[mask]
PrintLn(Abs(vi))
script.extract()
print(str(msg))
newargs = list(funcsig.parameters.values())
g.get_all_shortest_paths(0, 15)
w = gtk.Window()
self.type
ax.set_ylim((-1, 1))
time.sleep(1)
print(arg)
d1.keys() & d2.keys()
result.append(dict(zip(recordset.column_names, row)))
msvc9compiler.VERSION = 11
email = Column(String, primary_key=True)
x()
list1, list2 = list2, list1
print(k, v, highest_values, len(highest_values))
dirname, filename = os.path.split(name)
inner
driver.switch_to_default_content()
big = np.arange(Nbig * Nbig).reshape([Nbig, Nbig])
logger.addHandler(file_handler)
True
x, y
test2.test()
df.reindex(t.index)
[int(round(i)) for i in net.activateOnDataset(ts)[0]]
print(line)
plt.legend()
q = multiprocessing.JoinableQueue()
driver = webdriver.PhantomJS(*args, **kwargs)
d = sqrt((y2 - y1) * (y2 - y1) + (x2 - x1) * (x2 - x1))
soup = BeautifulSoup(html)
connection = engine.connect()
a, b = itertools.tee(iterable)
swap_cols(my_array, 0, 1)
type(f())
screen.blit(px, px.get_rect())
0
mercury_thread.start()
np.round(dfnum)
y = poly(x) + np.random.rand(n) - 0.5
print(add_odd_numbers(10))
c.start()
next(mygen)
value = Column(String)
f.close()
ax.w_xaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))
response
seq[0] + listSum(seq[1:])
TRY
copy
funcs.append(makeFunc(x))
lons = np.array([102.5, 5.5, 116.2, 102.5, 5.5, 116.2, 102.5, 5.5, 116.2, 100])
V.reshape(V.shape[:len(D.shape)] + (-1,))
stack.append(n)
Py_Initialize()
it = iter(seq)
df
self.filename = filename
nameserver
doctest.testmod()
opts = {}
mybucket / files / pdf / abc4.pdf
array = [array[i:i + s] for i in range(0, len(array), s)]
data = [2, 2]
self.func = func
audio / mpeg
reader = csv.reader(input_file)
pickle.dump(dictname, f)
random.shuffle(x)
labels.reshape(data.shape)
a = [[], [], []]
ax = plt.subplot(gs[(2), :])
print(dir(data))
print(npstr)
-1
decorator
temp_csv.flush()
print(newcorpus.raw().strip())
values = [r[1] for r in result]
rows = array.shape[0]
a - b * 4
[np.sum(x ** 2 + a), 2 * x]
results.append(res)
soup = BeautifulSoup(file_h.read())
self.ses.get(URL).text
Shell_NotifyIcon(NIM_ADD, nid)
x += b
df = df.stack().reset_index()
t = np.linspace(0, u.max(), 20)
-__init_.py
chars.append(escaped_str[i])
web.setDisabled(True)
callwith5(setanitem)
sizer.Add(self.comboBox1, 0, wx.ALL | wx.CENTER, 5)
root = tk.Tk()
s
values = Value.objects.filter(record=record).select_related()
x = somequeryset.query
params[:n + 1]
s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
self.opt.kill()
print ()
pool.close()
d[k] += v
t[2]
ax1.scatter(list(range(10)), list(range(10)), c=list(range(10)), alpha=0.2)
application = bottle.default_app()
fig = plt.figure()
new_stdout1.seek(0)
math.sqrt(0.241 * r ** 2 + 0.691 * g ** 2 + 0.068 * b ** 2)
result[mask] = 0
print(set(list2) - set(list1))
zip(a, b)
stderr = ferr.getvalue()
pb = pb.get_from_drawable(w, w.get_colormap(), 0, 0, 0, 0, sz[0], sz[1])
perform_some_action()
common.get_users()
s.close()
print(i)
signal.signal(signal.SIGINT, term)
print(line)
split_string
np.arange(n) >= m
idx = np.random.permutation(4)
self.list_two.setGeometry(0, 0, 500, 100)
ax = fig.add_subplot(111)
soup = BeautifulSoup(file)
df = dfA[dfA.index.labels != -1]
data = [map(int, row) for row in csv.reader(f)]
arg.upper()
s = s[k:]
df1 = pd.read_csv(StringIO(df1_text), delim_whitespace=True)
print(next(product(count(1), count(1))))
self.z = z
example1(x, a, b, D)
plate_chars += str(chr(results[0][0]))
sys.stdout = StringIO.StringIO()
df
wx.Panel.__init__(self, parent, size=wx.Size(806, 450))
position.append(0)
f(name)
hist, bin_edges = np.histogram(np.random.randint(0, 10, 100), normed=True)
self.get_card(card_id).invert()
ranges = ((n, n + step) for n in range(start, stop, step))
next(self)
timeit[Model.objects.filter(date_created__contains=today)]
start = sum(range(n)) + 1
lists = f.readlines()
new_list = sorted(playlist, key=lambda L: next(by_artist[L.artist]))
interp([9, 10], x, y)
client.send(msg)
t1, t2 = tee(iterable)
root = Tk()
A = A.reshape(4, 6)
parser = argparse.ArgumentParser()
os.system(c)
plt.grid(True)
my_instance.c()
self.is_active = True
sum(1 if c1 != c2 else 0 for c1, c2 in zip_longest(w1, w2))
match = pattern.match(line)
new_contact = form.save(commit=False)
[self.list[i] for i in range(key.start, key.stop, key.step)]
G.add_node((0, 0))
g = lambda a, b=b: f(a, b)
e1.pack()
contents = f.read()
self.rowconfigure(0, weight=1)
f, ax = plt.subplots(1)
text = p.stdout.read()
list(theDict.keys() & theList)
pandas.core.frame.DataFrame
self._parent.AppendUpdate(self.myproc.stdout.readline())
c[k] += a[j] * b[k + j * K]
readme.close()
new.append(a[i])
w[[a, a + 1]] + np.array([0, -2])
main()
arr
start = time.time()
hash(self.name)
f.seek(start)
len(md5bytes)
dict_out
new_grammar._productions.append(nltk.grammar.Production(lhs2, [lhs]))
ax.set_zlim(-1, 1)
cursor = conn.cursor()
reader = csv.reader(f)
print(res.read())
output[words[0]] = words[-1]
s.sort()
root = lxml.html.fromstring(response.body)
tmp[(2), :, :] = np.ones((sy, sz))
f2.write(line)
print(result)
shuffle.append(newEl)
self.execute(sql)
cursor = conn.cursor()
self.x1, self.y1 = int(event.x), int(event.y)
names.append(i)
print(cf.read(99))
xmin = logdata.min()
fd = self.process.stdout.fileno()
self.setCentralWidget(self.text)
print((date_cand, (datetime.date.today() - date_cand).days))
print(r.raw._original_response.peer)
print(x)
log_observer.start()
d = dict(l)
b = [str(f) for f in range(n)]
list1.remove(item)
self.cond.wait()
self.buf.seek(0, os.SEEK_END)
self.panel.top()
Grid.append([])
print(my_array + [e])
group = models.ForeignKey(Group)
calendar.monthrange(2012, 1)
m = pattern.search(line)
n = 10
np.exp(np.dot(mX, vBeta)) / (1.0 + np.exp(np.dot(mX, vBeta)))
0
newList = map(lambda x: x / myInt, myList)
main.destroy()
to = len(list)
self.markdown.htmlStash.store(self.unescape(element))
clf.predict(iris.data[125])
+apache2
main()
z = zipfile.ZipFile(io.BytesIO(r.content))
self.released.connect(self.update)
self.f.setsampwidth(sampwidth)
d[k].append(v)
datetime = dt.datetime.combine(date, time)
self.avail_ranges.remove(ip_network)
bSizer.Add(button1, 0, wx.ALL, 5)
print(c.html.strip())
_triple_file.close()
str(d)
pip - -version
add(1, [])
mask = np.all(np.isnan(a) | np.equal(a, 0), axis=1)
print(dict(filter_dict_path(old_dict, sub)))
my_dict[x] = 4
print(repr(tokzr_QA_non_canonical(inp1)))
print(input[a])
self.assertListEqual(self.result, self.expected)
data = f.read().strip()
lst = numpy.array([random.uniform(0, 5) for _ in range(1000)])
method = getattr(foo_obj, command)
print(args.doh)
newlist = []
columns.append([7, 7, 7])
plt.subplots_adjust(left=0.2)
distribution = scipy.stats.norm(loc=100, scale=5)
vals[mask].reshape(-1, out_shape[1])[:out_shape[0]]
any(map(bool, list(d.values())))
left_thresh[:, i:] += img[:, :w - i]
print(hex2.neighbors())
dirname, basename = os.path.split(filename)
arr_2 = np.array(multidim_list2)
transaction.rollback()
print(window.get_name())
48.1145061659
time += 1
self._async_interrupt.wait_for_receive()
a = A()
x[2:10]
df = s.reset_index()
print(self.companies[index])
0
result1.append(x)
file = sys.argv[1]
help(Test)
self.data.extend(list(other))
c = a * b.reshape((b.size, 1))
children.append(node.values[i])
tokens = nltk.word_tokenize(text)
line = line.strip()
assert_array_compare(operator.__eq__, x, y, err_msg=err_msg)
sdl2.SDL_SetRenderDrawColor(renderer, 255, 255, 255, sdl2.SDL_ALPHA_OPAQUE)
list.__getitem__(self, index)
number = models.CharField(max_length=50)
print(any(list_item in fruit_dict1 for list_item in fruits))
root = tix.Tk()
self.edit = QtGui.QLineEdit(self)
lines.append(linecache.getline(filename, curline).rstrip())
salt = bcrypt.gensalt()
opener = urllib.request.build_opener(cookies)
a = np.random.normal(0, 1, N)
print(element)
pos = entry.get_position()
self.children = []
a, b = [iter(x)] * 2
print(o.foo())
br = mechanize.Browser()
print(x)
formatter = logging.Formatter(LOG_FORMAT)
b.sort()
print(files)
os.close(rpipe)
s.set_debuglevel(1)
blob_reader = blobstore.BlobReader(blob_key)
print(gitpath.root())
np.isnan(x)
code_to_profile()
work.append(nope)
request = Request(url, headers=headers)
print(d[int])
main()
curses.noecho()
smprint()
test_dict = {}
retDirs.append(os.path.join(root, i))
setattr(namespace, self.dest, value)
f = Foo()
self.data = data
print(etree.tostring(tree.getroot()))
min([(x, distance(word, x)) for x in lst], key=itemgetter(1))
first.request.SetInParent()
entry = tk.Entry(self)
sleep(0.001)
self.name
self._fileobj.seek(offset)
nx.draw(G, with_labels=False)
proc = mp.Process(target=worker, args=[q, arr])
hax.set_position([0.1, 0.1, 0.8, 0.8])
obj = Try()
d[k].append(v)
L = fo.readlines()
os.rename(tmp, myfilepath)
twitter = Twython(APP_KEY, APP_SECRET, oauth_token, oauth_token_secret)
[0, 2, 0, 1, 0, 1, 0, 1, 1, 1, 2, 0]
sys.exit(app.exec_())
print(Type[x][x], len(Type[x][x]))
GameApp().run()
driver.get_screenshot_as_file(screenshot_file_path)
driver.switch_to_frame(iframe)
dt = datetime.datetime.now()
a[:, (0)] == 1
r[v].append(k)
reader = csv.reader(file)
t.start()
tokens = text.split()
calendar.timegm(utc_timetuple)
cax = ax.matshow(cm, cmap=cmap)
[[[0, 1]]]
sum(c.isalpha() for c in s)
app = Flask(__name__)
arg_list
x += 1
b1.grid(row=0, column=0, pady=10, padx=10, sticky=Tkinter.SE)
d = dict(foo=1, bar=2)
input_list = set([0, 1])
dct = json.loads(json_string, object_hook=datetime_parser)
thisRDD.count()
root = etree.fromstring(broken_xml, parser=parser)
result = list(islice(it, n))
list(dates)
df1
df2 = pd.DataFrame(data2)
list(unique_everseen(items))
fig, ax = plt.subplots(figsize=(20, 10))
deepReduce(f, f(y, xs[0]), xs[1:])
splittime / parsetime
app = Flask(__name__)
exec(self.raw)
s
palette.append((0, 0, 255 - i))
filters.append(Q(tree_id=n.tree_id, lft__gt=lft, rght__lt=rght))
friendList.append(self)
[l[0] - 1] + recurseDecrMap(l[1:]) if l else []
Queue.__init__(self, maxsize)
some_heavy_calculations()
i = a.index(p[0])
print(cv2.isOpened())
timeit.timeit(lambda : bytearray(os.urandom(1000000)), number=10)
form = forms.ChapterForm(request.POST)
json_str = json.dumps(data)
env = _Env()
crsr.fetchall()
id(a[1])
a = Example()
app.config_from_object(Config)
map = base_map.set_a_map()
cont = ax.contour(X, Y, Z)
unittest.TestSuite([DataTestCase(n) for n in numbers])
result = []
merged
d = datetime.datetime(2011, 8, 29)
os.makedirs(dirmk)
execlist[index][2] = myx
list(range(10, 20))
manager = urllib.request.HTTPPasswordMgrWithDefaultRealm()
S.remove(10)
newlist
expire_events.py
response.replace(body=new_body, encoding=self.encoding)
proc.start()
self.list[index], self.list[-1] = self.list[-1], self.list[index]
redis - cli
echo.py
plot(x, z)
a[I, J]
tuple.__new__(cls, initialValue)
mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, se2)
setup_func(a_cxx_foo)
seq.insert(i, item)
sleep(time)
--enable - pythoninterp
print(c)
results.append(tuple([row[i] for i in headers]))
plt.plot(data1)
ax.add_collection(coll)
fs.visititems(callback)
self._pred_map[self]
client_tcp[1].send_data_to_tcp(self.data)
L1 = [i for i in L if i in L1]
logger.addHandler(handler)
clf.fit(X_, vector)
f = f.reshape(())
test = math.inf
diff = ImageChops.difference(im2, im1)
g()
M = M[M.getnnz(1) > 0, M.getnnz(0) > 0]
y = lambda u: u ** -2 + 8
func.__get__(instance, cls)(*args, **kwargs)
crawler.crawl(spider)
options = ChromeOptions()
print(len(list(filter(is_div_three, r))))
print(etree.tostring(tree))
widget1.update_idletasks()
count
hello()
self.timer = QtCore.QTimer()
request.session.cycle_key()
self.title, self.artist, self.album, self.source, self.dest
x = np.linspace(data.min(), data.max(), 100)
np.repeat(arr, rep.flat)
self.type = type
connection.endheaders(request_body)
q = Queue()
print(r(-1, 1))
referrer.append(x)
round(base * round(float(x) / base), prec)
Py_DECREF(pystdout)
y2.append(random.randint(1, 100))
sympy.randprime(0, 100)
kde = stats.gaussian_kde(data)
Base = declarative_base()
np.hstack((np.zeros(shape), data))
print(g[first_row:last_row + 1, first_col:last_col + 1])
print(user_postition)
ftp.login()
data = json.load(f)
now = datetime.datetime.now()
hamming_distance(a, b)
auth.save_session()
main.show()
hash(self.name)
frame.Bind(wx.EVT_WINDOW_DESTROY, self._unregister)
english_dict[word]
y += np.random.randn(6) / 10
deps.append(str(name))
np.bitwise_and.reduce(a) == a[0]
r.terminate()
dsolve(eq)
a.insert(0, i)
sys.stderr = sys.__stderr__
confusion_matrix(y_true, y_pred)
list(f(doc))
print(num)
idx = np.argsort(a)
newMethod.__get__(a, A)
table.show()
result.append(x)
subs = [set(j) for i in range(len(s)) for j in combinations(s, i + 1)]
name, score = line.split()
srf.blit(f.render(unistr, True, (255, 255, 255)), (0, 0))
recall
len(bin(100)) - 2
print(inspect.signature(f).parameters)
sys.stdin = s
fun(indata, indata.size, outdata)
mod.HelloWorld()
meta = MetaData(bind=migrate_engine)
logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)
pl.plot(x, us(x))
(2, 1)(2, 1)
propfaid.set_cache(*settings)
A[:(A < np.percentile(a, 90)).argmin()].sum()
mins.append(i)
bool(self.value)
self.__add__(-i)
triplets = list(permutations(lst, n))
x = True
s.indices(10)
dothat(item)
print(list(my_range(4, 20, 2)))
d.bar
fig, axes = plt.subplots(nrows=2, ncols=1, sharex=True)
self.do_something(name, value)
object._state.db
time.sleep(self.interval)
self.output_queue = mp.Queue()
parent = Parent()
cat / etc / nginx / sites - enabled / myapp.conf
bool_arr = np.array([True, True, False])
index = random.choice(list(range(len(MY_LIST))))
p[0] + p[1] * x ** p[2]
type(-maxint - 2)
draw.line((i, 0, i, 100), fill=random.randrange(256))
self.crawler.stop()
out = x.truncate(before=datetime.datetime(2015, 12, 2, 12, 2, 18))
print((val, k))
b = a[(0), (1), ::2]
sys.exit(1)
a.add(1)
txt = self.proc.stdout.readline()
tag = node.tagName
spider
lines = []
show()
result = []
match.group(1)
persist_file.Save(shortcut_path, 0)
r.append(blocktag[1])
np.poly1d(p)(x)
render_user(request)
browser = spynner.Browser()
ax.matshow(m[(0), :, :, (j)], cmap=cm.gray)
sequence[0:len(sequence):2] == sequence[:len(sequence):2] == sequence[::2]
self.close()
print(self.value, self.foobar)
xmldoc = minidom.parse(usock)
list_magicInput.append(letter)
array([5, 7])
s.rollback()
QtGui.QMainWindow.__init__(self)
np.may_share_memory(X2, X2.reshape(X2.shape[0], -1)[:, (0)])
print(tokenize.untokenize(output))
x = new_array()
b = numpy.array([0] * n + [1] * 2)
reactor.callLater(1.0, heartbeat)
fig, ax = plt.subplots()
next(gen)
output = requests.get(url).text
os.dup2(oldstderr, sys.stderr.fileno())
ax1 = fig.add_subplot(gs[0, 0])
result = {k: [expand_string(s, all_strings) for s in v] for k, v in list(my_dict.items())}
worksheet = workbook.add_worksheet()
setattr(self.obj, self.method, self.called)
unique.append(obj)
auth_handler = urllib.request.HTTPBasicAuthHandler()
print(x)
data = parser.parse_args(contents.split())
model_subklass(**kwargs)
parser.parse_args(args.split())
ys.append(y)
f(1)
date.day
app.jinja_env.globals.update(can_access=can_access)
raise PartialImport(locals())
MIGRATION_MODULES = DisableMigrations()
np.log10(df.timeLength)
fp[:, (i)] = fp[:, (i + 1)]
curs.execute(sql)
n = 0
signal.pause()
profile = webdriver.FirefoxProfile()
self.base.foo = f
df.dtypes
a = models.CharField(max_length=5)
x = numpy.random.randint(0, 1000, 1000000)
do_stuff(level_lookup[key])
df.loc[mask == 1, 0] = 200
worksheet.setRowCount(worksheet.getRowCount() + 1)
quicksort(array, start, i - 1)
1 if S == 0 else 0
print(list(inverse_regex.ipermute(data)))
foo(args)
s = self.fileobj.read(1)
x if x % 100 == 0 else x + 100 - x % 100
result = []
setofcols.add(tuple(column.A1.tolist()))
todayDate += datetime.timedelta(7)
req.has_data()
print(df1)
logger = logging.getLogger(__file__)
scene.objects.link(lamp_object)
test = coo_matrix((val, (row, col)), shape=(nele, nbus), dtype=complex)
dict.__delitem__(self, self[key])
bar.__doc__
print(line)
importer.find_module(RUN_MODULE).load_module(RUN_MODULE)
np.bincount(ids, weights=data)
self.parsedData.append(dataRow)
plt.imshow(H)
output = proc.stdout.readline()
B, C = split_list(A)
print(browser.html)
cur = con.cursor()
a = numpy.random.random(size=100) * 100
results = pool.map(process_line, source_file, 4)
df_no
sizer.AddSpacer(10)
image_field.seek(0)
r = r[0].isoformat() + tz
serializer_class = UserSerializer
result = tocontainer(result)
plt.plot(x, -y)
c = array([1, 1, 1])
application.listen(8888)
True
sheet.write(cell, value)
0.16515994072
body = part.get_payload(decode=True)
mainwin.set_default_size(200, 200)
wb = Workbook()
print(T(lambda : fj(controls)).repeat(number=REPS))
[]
self._cards[card_ID].invert()
numbers = [d.setdefault(i, next(c)) for i in names]
x = ax.get_xlim()
self.assertEqual(42, s2)
Area2(a, b, c) < 0
f
self.byName[person.name].append(person)
xi = np.linspace(X.min(), X.max(), 1000)
data = urllib.parse.urlencode(params)
{4}
np.fill_diagonal(product, 0)
self.Bind(wx.EVT_CLOSE, self.OnCloseWindow)
response.close()
eroded = binary_erosion(data, structure, border_value=1).astype(int)
fig.canvas.print_png(ram)
name = db.Column(db.String())
cr.set_source_rgba(0.5, 1.0, 0.0, 1)
fig = plt.figure()
gtk.main()
main()
sm = plt.cm.ScalarMappable(cmap=my_cmap, norm=plt.normalize(vmin=0, vmax=1))
host
exit(0)
print_sorted(filename, sort_col)
y.append(ind_2)
library(SnowballC)
print(p.ne(p.shift()).cumsum())
df
input = [server, sys.stdin]
sys.stdout = StringIO()
config = configparser.ConfigParser()
signal = np.sin(50 * 2 * np.pi * x)
ax1 = fig.add_subplot(111)
b = np.array(b)
p_values = scipy.stats.norm.sf(abs(z_scores))
f(1)
Frame.__init__(self, master)
pylab.rcParams.update(params)
list(it)
new.append(recursivereverese(k))
print(x)
c = orcl.cursor()
X -= np.mean(X, axis=0)
contained(a, b)
id = row[0]
x + self.y
stdout.write(x)
self.img_id = self.canvas.create_image(x, y, image=self.img)
sess.run(training_net, feed_dict={inputs: batch[0], labels: batch[1]})
Py_XDECREF(self.members[i])
x.append(y)
print(row)
tbl[-1].append(str(td.text_content()))
plt.figure(2)
l.set_option(ldap.OPT_DEBUG_LEVEL, 255)
s.dt.days
f = f_wrapper(_f_call, _f_ptr)
command = os.path.realpath(command)
count = 0
response = urllib.request.urlopen(req)
response = requests.get(url)
my_instance.save()
data[header].append(value)
grouped.size()
pprint.pprint(result)
print(ulst)
L.reverse()
Base * get_other_base()
print(out_str)
data = ser.read(4)
sys.exit()
yappi.start()
today = date.today()
count = len(values)
DD = datetime.timedelta(days=-90)
print(saber)
min(Mylist)
ceo.greets(emp)
data = pandas.DataFrame(np.transpose(df_std))
data = string[0]
t, y, x = numpy.indices(J.shape)
print(get_size())
sentence_dict[word] = []
result = f(*args, **kargs)
db.run_in_transaction(txn, cat_alias.keyname_for_category())
s.listen(5)
plot = ax.plot_surface(X, Y, soln, **plot_args)
list(chain(*[([x] * i) for i, x in zip(A, B)]))
operator.itemgetter(*b)(a)
print(1)
arr = array(arr, copy=False, subok=True, ndmin=2).T
ser = serial.Serial(port, 9600)
w.show_all()
result = []
os.unlink(f.abspath)
dis.dis(f)
wide
pool.map(worker, [(i, array) for i in range(n)])
keys = [wx.WXK_LEFT, wx.WXK_RIGHT, wx.WXK_UP, wx.WXK_DOWN]
pymongo.version
np.array(*args, **kwargs).view(myarray)
cr = csv.reader(f)
wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)
tokenizer.tokenize(text.strip())
A = A.astype(int)
im1.set_clim([smin.val, smax.val])
self.name = name
x = np.linspace(0, 2, N)
p.terminate()
arr = np.empty(len(lst), dtype=object)
print(a.shape)
it = iter(iterable)
cw.writerows(csvList)
deactivate
ans.append(s[0])
self.readonly_fields
p = x.pop()
pat.match(s)
sh.write(n, 1, col2_name)
self._thread_id = tid
results.append(out.toString())
keys = list(myDict.keys())
pickle.dumps(cycle)
line2 = f.readline()
print(df1.fillna(df2))
x.shape
axis[:set_xlim](0, 10)
p = psutil.Process(1694)
msg = next(myproducer)
b.append(i)
vec = numpy.zeros(num_rows)
main.py
r = np.arange(X.shape[0])
id(a[2]), id(b[-2])
myDict = {}
print(id(string[0:5]))
False
[freetds]
terminator.cancel()
line.set_ydata(sin(x + i / 10.0))
f.write(decodestring(imagestr))
print([num, diff])
data = f.read()
kernel.execute(command)
len(df[np.isclose(df.R, 0.9)])
r
data = np.ascontiguousarray(data)
_to_etree(v, ET.SubElement(root, k))
print(b[0].dtype)
ax = fig.add_subplot(111)
name = models.CharField(max_length=100)
_array[::][1:]
ax.invert_yaxis()
tb.show()
queue.append(item)
img = Image.fromarray(maxi)
print(update_doc(b))
this_prize
(v for m in self.maps for v in m.values())
globals()[key] = value
self.test(*self.arg)
print(r)
self.co = self.sink()
assertTrue(True)
p = multiprocessing.Pool(2)
nz = np.nonzero(cells)[0]
str.__new__(str, arg=1)
app.register_blueprint(child2.child2)
n = float(n)
print(handle_csrf.__doc__)
f.close()
(y, m) if m else (y - 1, 12)
self._1d_array = np.arange(10)
self.output += data.strip()
col = array([0, 2, 2, 0, 1, 2])
out = {}
df.index = list(range(len(df)))
m.update(string)
B.add_nodes_from(cells_list, bipartite=1)
int(s)
print(self.a)
X = StandardScaler().fit_transform(X)
PyLong_AsByteArray(lnum, a, len(a), 0, 1)
mask = np.in1d(pairs1D, positions1D).reshape(-1, 2)
new_list = list(filter(keep_this_element, l))
g = (i for i in range(100))
min(results, key=test_string.index)
execute_from_command_line(sys.argv)
y = y[mask]
d = {}
stackless.tasklet(a)()
ax.broken_barh([(midpoint - 0.01, 0.02)], (perc[0], perc[1] - perc[0]))
sys.excepthook = handle_exception
ret = os.popen(cmd + file).readline().strip()
df
x = random.choice([left, right] * adjpx + [withinx])
print(df)
now = datetime.utcnow()
di[pos][1].append(listb[i])
colors = [(color * (0.5 + norm(v) * 0.5)) for v in shade]
self.bar(**args)
L = list(range(0, 101, 10))
n
out[2]
link = self.br.find_element_by_link_text(month)
p = QPixmap.grabWindow(widget.winId())
b = a[:-4]
ax4 = plt.subplot(gs[-1, 0])
collection[obj.category_id].append(obj)
dis.dis(test4)
[length] = set(map(len, list_of_lists))
b = a + 1
b = np.linspace(0, 1, 16, endpoint=False).reshape(4, 4)
app.installEventFilter(win)
r, g, b = im.getpixel((i, j))
conn = engine.connect()
data.append(integers)
path = os.path.realpath(path)
flatten(something, a)
raise StopIteration
ard.write(setTemp1)
formData.append(name, val)
self.seek(-blocksize, 1)
width = label.fontMetrics().boundingRect(label.text()).width()
somemodule.someclass = debug_signals(somemodule.someclass)
[gb.get_group(x) for x in gb.groups]
out = [float(f_interp(*p)) for p in points]
p.map_async(func, iterable).get(timeout=10000000)
a.update(b)
es = Elasticsearch()
[(string + repr(i)) for i in range(11)]
driver.get(url)
self.text = tk.Text(self, width=40, height=20, yscrollcommand=self.vsb.set)
ax = plt.subplot(111, polar=True)
print(str(x))
i = patch_instance(x.get_instance())
f(*arg)
seq[int(self.random() * len(seq))]
result = np.array([[f(i, j) for j in b] for i in a])
type, value, tb = sys.exc_info()
swap(xs, a, b)
self.foo = foo
self._global_wealth = 10.0
test_data = tf.Variable(1000)
main()
x.append(ind_1)
canvas.Canvas.save(self)
ret[ret > 0].sum()
times[-1]
b = object()
f.truncate()
sum(base_lists, [])
sys.stderr.write(u)
i += 1
ax = plt.gca()
list(x) is x
shutil.rmtree(apppath)
new_user.save()
0
out[k].append(recursive_asdict(item))
df
image = image.resize((nw, th), Image.ANTIALIAS)
print(line)
b = values(numpy.arange(100))
locals().update(adict)
root = lxml.html.fromstring(driver.page_source)
deleteself.weapon
fp.write(chunk)
iter(iterable.items())
loop.add_timeout(time.time() + seconds, callback=gen.Callback(some_unique_key))
listbox.pack()
b = np.append(a, [False])
txt = wx.TextCtrl(self)
self.data = [[(0) for c in range(cols)] for r in range(rows)]
self.noload = unpickler.noload
main.show()
pprint.pprint(lines_to_dict(d))
type(dates[0])
self.frame = Frame(self.root)
--__init__.py
t = np.linspace(-10.0, 10.0, 100)
df
data = []
plt.plot([(x * x * curvature) for x in range(0, 11)])
print(inspect.getsource(Tester))
a = models.ForeignKey(A)
self._cards[card_ID].invert()
words = sentence.split()
solution[1], sum(oldmoves[solution[1]]), oldmoves[solution[1]]
decorated.sort()
True
axarr[0].plot(x, y)
sys.stdout = stdout
result = []
lst = [(val * 2) for val in lst]
y = [(max(k), v) for v, k in list(d.items())]
sess.run(init)
date = parser.parse(text)
ser.str.isdigit().sum()
[(key, [self[key]]) for key in self.order]
diff[y, x] = img1[y, x] - img2[y, x]
json.loads(raw_post_data, object_pairs_hook=KeyWatcher)
result = set()
Py_DECREF(result)
value = list(value)
contour = numpy.array([[[0, 0]], [[10, 0]], [[10, 10]], [[5, 4]]])
register = template.Library()
ax = fig.add_subplot(111)
do_first_thing_with(obj)
PyArray_Descr * descr
i = np.array([0, 0, 1, 2, 2])
fr.f_code.co_name
e = pygame.event.poll()
graph.append([])
b[x].append(x)
cx2
n = len(txt)
result1 = pool.apply_async(solve1, [A])
nums = [6, 10, 4, 8, 2, 12, 10]
self.optionmenu_a.pack()
session.add(doc)
gplt.show()
app = wx.App(False)
pagination_serializer_class(instance=page, context=context)
question = session.query(Question).first()
members[index]
linepos.append(offset)
user = models.ForeignKey(User)
canvas = numpy.zeros((12, 12), dtype=int)
df.set_index(rng, inplace=True)
pprint.pprint(w.fields)
ax2 = fig.add_subplot(5, 4, 2, sharex=ax1)
[t[:2] for t in data]
df = pd.DataFrame(np.random.choice([1, np.nan], (1000000, 15), p=(0.01, 0.99)))
a[(a >= -100) & (a <= 100)]
print(res)
lmul(ll[0], [[item] for item in ll[1]])
np.random.seed(0)
c = np.intersect1d(a, b)
t = et.fromstring(df.to_html())
lines = file.read().splitlines()
db.create_tables([Person])
self.ui = Ui_MainWindow()
tuple(prime_factors(100))
createIndex(row, column)
a(4, 5)
value, count = c.most_common()[0]
ax.set_xticklabels(())
arr.tocsr()
real_f.close()
actions.move_by_offset(x_to, y_to)
-setup.py
proc = multiprocessing.Process(target=wrapper, args=(queue, bob))
mkl_rt.mkl_set_num_threads(ctypes.byref(ctypes.c_int(48)))
df = df.reset_index(drop=True)
parsed = json.loads(your_json)
True
a = x.copy_with(y=4)
hash1 == hash2
a.clip(0, 10)
print(user.username)
sums = itertools.accumulate(seq)
type.__new__(meta, classname, bases, newClassDict)
tree.query_ball_point([london], r=euclidean_distance(100))
np.putmask(array, numpy.random.rand(array.shape) < prob, np.logical_not(array))
fig1 = plt.figure()
os.rename(outfile.name, inpath)
ax2 = ax1.twinx()
l = []
print(parse(test))
self.draw()
lib.a.A()
lst.sort()
tick.label.set_fontsize(14)
[[1], [4, 5, 6], [10], [15, 16, 17, 18], [22], [25, 26, 27, 28]]
data
nt = etree.ElementTree(root)
[f for S in s for f in [FunkyFunction(a[S])] if f > 0]
result = []
print(data)
contents = output.getvalue()
m = np.median(foo[foo > 0])
self.mainframe = ttk.Frame(self.root, padding=(6, 6, 12, 12))
Dy = L1[0] * L2[2] - L1[2] * L2[0]
oFig1.add_subplot(4, 4, 11)
print(filename)
sums = a.sum(axis=1).A1
print(filename)
{{modelform1}}
{{modelform2}}
my_command.py
p.join()
mp_handler()
sorted_files = []
out[1:-1]
Map(fold=lambda f, g: f(x), bimap=lambda f, g: Left(f(x)))
x, y, p
set(lst1 + lst2)
lines_counter += 1
s = slice(2, 4)
values = [5, 10, 15, 20]
d1 = date(2008, 9, 26)
f1 = lambdify(x, diff(f(x)))
print(line)
glClear(GL_COLOR_BUFFER_BIT)
float(s)
tokens = nltk.word_tokenize(raw)
a = Counter(0, 1, 2, 1)
f.writelines(datum + os.linesep for datum in data)
myClass.py
image.thumbnail((256, 256), Image.ANTIALIAS)
response = unirest.post(url, headers=headers, params=params)
pprint(result.data)
b = a[index, index]
sys.getsizeof(test_ordered_dict)
print((u[i], i, u, len(u)))
f.set_figwidth(15)
a += 1
vec /= np.linalg.norm(vec, axis=0)
sys.stdout = StringIO.StringIO()
orig_import(name, *args)
Ainv
strcat(greeting, name)
traceback.print_stack(file=self.stdout)
self.fn(*args, **kwargs)
form = ArticleForm(request.POST, instance=article)
np.random.shuffle(indices)
cls
a[1:2]
mydict[currentid].append(currentvalue)
stefan.append(list(args))
self.__do_layout()
print(sys.version)
[a]
data = request.GET.copy()
ax = plt.axes(projection=ccrs.Robinson())
result = dict(pool.map(f, inputs))
filepath = os.path.join(root, names)
output_wave_file.close()
[(x / sum_samples) for x in samples]
y -= 2
models.Field.formfield(self, StringListField, **kwargs)
cols = cols[-1:] + cols[:-1]
platform.release()
t = np.arange(-0.5, 1, 1e-05)
Y = np.array([2, 0, 1, 1])
value = 1
ExampleModel.objects.filter(some_datetime_field__range=[start, new_end])
pause(1)
l[x] = l[x][1024:]
file.write(data)
zipfile = ZipFile(StringIO(url.read()))
self.listWidgetA.currentItemChanged.connect(self.item_clicked)
mat.close()
U = np.random.rand(n, n)
dict_[methodname] = lockmethodfactory(methodname, lockattr)
loop.run()
todayDate = datetime.date.today()
result.x
wb.save(output)
shortset.add(seq[i:i + shortlen])
print(b.base is a)
z = np.polyfit(x, y, 1)
A[[0]].shape
all(map(lambda x: x == l[0], l))
a[i] = int(a[i][::-1])
data = globals()
raise NotImplementedError
a = numpy.empty((ix.sum(), h5_array.shape[1]), dtype=float)
print(avg_positive_speed(speed))
p = lambda x, y: x + y
self.width = width
string.punctuation
plt.ylim(0, 2500)
meth
self.extend(db.get(key, []))
wf.close()
gevent.Greenlet.__init__(self)
bpy.ops.transform.rotate(value=rot.angle, axis=rot.axis)
fig, (ax1, ax2) = plt.subplots(1, 2, sharey=True)
pool.close()
B = csr_matrix((5, 2), dtype=int)
mail.check()
keys, values = zip(*list(my_dict.items()))
print(ctypes.get_last_error())
m = np.ma.masked_where(y > 5, y)
sys.stdout = devnull
os.mkdir(corpusdir)
db.add(marker_type)
p = figure()
l = []
cv.SetData(image0, rotated_image.tostring())
self.stack.append(0)
text_link.insert_after(is_my)
i = j + 1
gtk.main()
grid = [0, 5, 10, 15, 20]
result[-1].append(text)
self.columnconfigure(2, weight=1)
A = A.T
mask = np.tril(np.ones((4, 4), dtype=bool))
fig2 = plt.figure()
total = sum(el for el in list(val.values()))
d = datetime.datetime.utcnow()
writer.writeheader()
m.move(x, y)
br.set_handle_redirect(True)
self.__dict__ = kwargs
PyEval_AcquireThread(myThreadState)
pop_conn.quit()
new_matrix = []
d = {}
p = Point(1, y=2)
form = CustomerInfoForm(request.POST)
img = filedescriptor.read()
dyna_join(df, [0, -2])
print(config_file[opt_name])
print(list(build_notes(DF)))
list(someDict.keys()) & someSet
self.dummy.x = value
n % 10 + digitalSum(n // 10)
root = Tk()
idx = numpy.random.choice(len(choices), 4)
res = [test[(i + 1) * i // 2:(i + 1) * (i + 2) // 2] for i in range(bound)]
EMAIL_USE_TLS = True
new.append(graph[i])
d.nonzero()
st.norm.cdf(1.64)
decoder.decode(s)
dict(add=_add)
output[lake] = lake.sum() < 6
self.hair = hair
data.text
count[0] += 1
print(b - a, len(numbers))
self.i += 1
df
s = requests.session()
some_thing_that_fails()
print(e.findall(data))
odict[key]
req.setRawHeader(k, v)
M = np.random.randint(2, size=(h, n))
fig.autofmt_xdate()
attachedvolumes()
self._async_interrupt.interrupt()
conn = engine.commit()
p.start()
now = datetime.utcnow()
finalizebins(bins, binsize)
os.kill(int(pid_str), sig)
result = collections.defaultdict(list)
print(i)
df[1] = df[0].diff() > 600000000000.0
keys = list(d.keys())
results = pool.map(do_work, work)
y.byteswap()
lines.append({})
w.add(a)
hashes.append(sha1OfFile(os.path.join(path, file)))
res_lst.append(out_queue.get())
print(result)
generations.append(generations[-2] + generations[-1])
b.py
t.start()
plt.legend()
m = pd.Series(to_filenames.values, from_filenames.values)
char * saveptr
axes = plt.subplot(gs[0, 0])
System.err.println(tmpFunction.getClass())
bin(x)
c = wmi.WMI()
p.start()
s = map(set, g)
self.broken = True
some.unrelated.development.host
picture.putdata(colors)
session.expunge_all()
test()
job.get()
s.astype(np.datetime64).fillna(pd.NaT)
self.size = max(self.size, self.position)
t = datetime.date.today()
ispower(625, 5)
0
print(str(err))
fig = plt.figure(figsize=(ncol + 1, nrow + 1))
f = StringIO()
x, y, z
subprocess.call(commandline)
X_test = np.array(descs_train)
cursor = db.cursor(cursor_class=MySQLCursorDict)
a2.remove(e)
A[row] = [data]
test2()
lib.TessBaseAPIGetUTF8Text.restype = ctypes.c_char_p
s = sys.__stdin__.readline()
data = Column(String(20))
gcf().canvas.draw()
self.happiness = self.wealth / self.data.global_wealth
driver.execute_async_script(load_jquery_js, jquery_url)
7, array([4, 5, 6]), array([8, 9])
timedelta.days * 86400 + timedelta.seconds
result = pipe.stdout.readline()
x[:, (x_range), (y_range)]
n >>= 8
queryset = Location.objects.all()
a = A()
root = tkinter.Tk()
json.JSONEncoder.default(self, obj)
a1.append(int(data[0]))
print_tree(d)
np.fromiter(dropwhile(lambda x: x, ar[::-1]), dtype=bool)[::-1]
print(a, b)
result, index = arraysums_recursive((a, b), lower=5, upper=6)
sys.stdout = f
ax = plt.gca()
print(now.strftime(fmt))
fig = plt.figure()
r1 = np.hstack((b, w, b, w, b, w, b))
nx.draw(G, pos, alpha=0.75)
requests.get(url, auth=auth)
new_dic = {}
print(p, p.is_alive())
b.set_clip_on(False)
np.array(signal)
self.tree_filter.refilter()
response.append(line)
vertices, np.hstack((bary, 1 - bary.sum(axis=1, keepdims=True)))
values = np.random.rand(1000)
connection = pyodbc.connect(connection_string)
n[i] = next(iterators[i], done)
g.draw()
edges[i + 2, j].append((i - 2, j))
model._meta.verbose_name
sums.append(data[groups == group].sum())
letters.remove(chr(part[1]))
dict(one=1, two=2)
b[x] = 1
ctypes.pythonapi.Py_IncRef(pyo)
fig.delaxes(fig.axes[2])
module_a.py
k = k + 1
len(self.buffer) > 0
output = process.communicate()
outfile.write(outline)
outlist.append([])
ssh = paramiko.SSHClient()
print(n.predict(B))
x()
output = PdfFileWriter()
array([[0.5, 2.5, 4.5], [0.5, 2.5, 4.5], [0.5, 2.5, 4.5]])
main()
set_state(args.state)
print(ensure_datetime(x))
pygame.camera.init()
diff = datetime.now() - birthday
app.run(debug=True)
cv2.drawContours(mask, [best_cnt], 0, 0, 2)
print(value)
found = False
main_window.setCentralWidget(enable_window.control)
print(line)
values = np.hstack([np.random.normal(0, 1, 10), np.random.normal(10, 1, 100)])
plot(row, x, y)
glEnd()
ax.draw_artist(col)
fin[i[0][0]] = i[-1]
dd = dd.replace(year=dd.year - 100)
img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)
Matrix(final).expand()
ui.setupUi(Form)
sys.stdin = progA.stdout
main()
self.send_response(200)
webbrowser.open_new(url)
data[:-(data[-1] if type(data[-1]) == int else ord(data[-1]))]
ws.send(json.dumps(dict(received=message)))
set(b).issubset(set(a))
print(date_dict.get(date, []))
df = pd.DataFrame([[y[0] for y in x] for x in outputdata], columns=Molecule)
b, c = zip(*zipped)
x = np.arange(xmax)
self.should_run.clear()
complex_process(df.ix[idate], idate)
self.src[-1].append(item)
np.not_equal(c[1:], c[:-1], out=flag[1:])
myList[-1]
d = hashlib.md5()
current_class.append(node.tag)
s = fh.read(40256)
times = pd.to_datetime(df.timestamp_col)
print(df_final)
self.__or__(other)
sys.exit(2)
im.set_ylim((125, 1000))
points = np.random.rand(15, 2)
entropy
img = cv2.merge((r, g, b))
fake_csv.seek(0)
matrices.append(np.random.random_integers(100, size=(1000, 1000)))
y = 10 * np.random.normal(mu, sigma, 5000)
pprint(soup.find(text=pattern).__dict__)
print(my_globals.thing)
help(Foo.bar)
tables = connection.introspection.table_names()
plt.imshow(green_img)
app = Flask(__name__)
ax1.set_xticks([])
lambda : reqd_email == cherrypy.request.login
column_widths[i] = len(cell)
l[-1] += s[:r]
usage()
data = urllib.request.urlopen(str(i)).read()
points = np.mgrid[1:6, 2:5, 8:10]
newlist[-1].append(alist[i])
vec < -vector()
stdscr.refresh()
self.counter += 1
pl.show()
issubclass(instance.__class__, object)
mask = np.zeros((all_i.shape[0],) * n, dtype=np.bool)
print(mystring.format(wash_clothes, clean_dishes))
self.user = auth_user
fig = plt.gcf()
self._body = self.read()
yaml.add_representer(str, str_presenter)
max(pairs, key=lambda x: x[1])[0]
gobject.idle_add(discoverer.discover)
path = sys.argv[1]
results[i % 2].append(e)
driver = webdriver.Firefox()
content = response.read()
float(m(256))
dest.addPage(PDF.pages)
dir(Foo)
dis.dis(empty)
rdd.mapPartitionsWithIndex(remove_header)
wsgi.py
plt.xlim(ax, bx)
idx = [(np.ones(len(a)) * i) for i, a in enumerate(arrs)]
le.fit([1, 2, 2, 6])
now = datetime.datetime(2009, 5, 5)
fig = plt.figure()
found.append(word)
index += match.group(1)
posts.fetch()
intersection = max(a[0], b[0]), min(a[1], b[1])
set().union(*(x.nodes() for x in list(periodic_gs.values())))
sys.stderr.flush()
label.setPixmap(pixmap)
dict_writer.writeheader()
1.0 / 2
p = re.compile(regex, re.U)
nb.train(v)
IS_SETUP = False
img = ImageTk.PhotoImage(Image.open(path))
fig.set_size_inches(18.5, 10.5)
uexpr.doit()
idx = [1, 4, 8, 10, 22]
[(self._min_x, self._min_y), (self._max_x, self._max_y)]
job.start()
cv.Copy(img0, newCanvas)
ax = fig.add_subplot(111)
out[R, C] = A[R].multiply(B[:, (C)].T).sum(1).ravel()
logger.addFilter(dup_filter)
r.append([d, f])
print(tfidf.todense())
entry.configure(show=random_char())
shape = tf.shape(image)
datetime.datetime(*dt_args)
self.foo_impl(x)
rows, cols = np.triu_indices_from(arr, k=k)
f = float(s)
ax = plt.axes()
indices = [i for i, v in enumerate(a >= 4) if v]
meta = MetaData()
logger
lock.acquire()
hash(self._vals())
print(posneg([6, 44, 1, -7, -6, 19]))
b[2] += 7
ax0 = plt.subplot(gs[0])
dump(indata, 5, 6)
min(points, key=self.compute_distance_to)
SublimeLauncherApp().run()
get_color(0.2)
hash(str(self))
self.cells[index] = new_value
print(df)
file.seek(position)
np.allclose(out1, reduce_after_multiply(M1, M2))
output = StringIO.StringIO()
df.shape
dict(iterableOfKeyValuePairs, **dictOfKeyValuePairs)
A = p1[1] - p2[1]
root = ET.fromstring(xml, parser)
plt.grid(True)
print(new_list2)
hours = sales.index.hour
-libjpeg - dev
xy = (np.random.random((10, 2)) - 0.5).cumsum(axis=0)
print(get_script_dir())
f.close()
hashes[newhash] = newurl
li = st.split()[::-1]
print(result)
ax.plot(list(range(10)))
df2 = df.copy(deep=True)
X = np.reshape(lena, (-1, 1))
a = pandas.DataFrame(np.arange(25, dtype=np.float16).reshape(5, 5))
print(result[0])
ax = plt.subplot(111)
f(*arg, **kw)
self.index += 1
f = Foo()
self._attr_value_to_obj_set[attr_value].add(obj)
[(f[::-1] if needs_flip[f] else f) for f in orderless_faces]
sys.modules[mod_name] = Mock()
self.tabs[index].append(CQWebView(self))
subset[subset.isin(myList)].stack().duplicated().unstack()
axis.set_ylim(y_min - 0.1, y_max + 0.1)
cj.save(ignore_discard=True)
pprint.pprint(my_structure)
a2.eliminate_zeros()
email = db.Column(db.String(120), unique=True)
ax.plot(list1, list2)
{{answer.someattribute}}
self.panel.hide()
context.set_source_rgb(1, 1, 1)
gen.close()
a[5:0:-1]
matching_solutions.append(sol)
user.save()
p1.stdout.close()
ya.set_major_locator(MaxNLocator(integer=True))
mask = np.isnan(a)
print((item.subject, item.body, item.attachments))
ans[-1] += letter
__contains__
CM = CM.sum(axis=1)
print(line)
--tasks
[ax4.plot(i, j) for i, j in graph_data]
p.start()
raise NotImplementedError()
logging.Handler.setFormatter(self, fmt)
cls.__items[item]
next_up(x)
a.getDouble(), b.getDouble()
math.hypot(self.x, self.y)
print(i)
temp = np.random.randint(1, 10, 10)
print(nltk.sem.relextract.show_raw_rtuple(rel))
cursor = db.cursor()
response
pipeline.set_state(gst.STATE_PAUSED)
ind = np.lexsort((a[:, (1)], a[:, (0)]))
(1 if text[i] == char else 0) + count(char, text, i + 1)
a.data
k = bucket.new_key(full_key_name)
print(len(dodgy))
sorted(a)
ax.set_xlim(min(x) - offset, max(x) + offset)
print(X_train_tfidf.shape)
print(x.size)
foo(node, p.copy())
my_data = [list(range(5)) for i in range(5)]
app = tornado.web.Application(Router.urls, debug=settings.DEBUG)
np.dot(m, prior_reci) + np.dot(1 - m, 0.1 * prior_reci)
p.terminate()
key = bytearray([19, 0, 0, 0, 8, 0])
b = pd.DataFrame(a)
print(data)
self.current = next(self.__gen)
TTY / dev / ttyS0
container[key].update(values)
lF.grid()
kl.getFormula()
print(my_random_string(6))
tree.left = self.left
dictfetchall(cursor)
self.doc = ET.parse(fname)
d.append(t)
Main()
data = conn.recv(1024)
x, y, w, h = x - 2, y - 2, w + 4, h + 4
width = db.IntegerProperty()
output.flat[ind] = res
dir = os.path.dirname(path)
conn.setopt(pycurl.WRITEFUNCTION, response.write)
a[0, 0]
new_list = [(x + str(y)) for x in the_list for y in range(n)]
output.addPage(pdfOne.getPage(i))
df = pd.read_csv(StringIO(txt), skipinitialspace=True)
Counter(x) == Counter(y)
ex.show()
keyValues[key].append(value)
client = app.test_client()
fig.axes.get_yaxis().set_visible(False)
types.FunctionType(self.func.__code__, new_globals)
copyData(data, arr)
c.executescript(query)
self.print_usage(sys.stderr)
dict2 = copy.deepcopy(dict1)
any(elem in test2 for elem in string)
models.DateTimeField(blank=True)
B = NP.array([0, 1, 0, 1, 0])
True
self.response.write(g.text)
print(itertools.permutations.__doc__)
url = key.generate_url(expires_in=0, query_auth=False, force_http=True)
driver = webdriver.Firefox()
print(str(10).zfill(2))
output[-1] += char
fnan < 0
True
header[key] = [x.strip() for x in header[key]]
client.close()
sigma = np.matrix([[4, 10, 0], [10, 25, 0], [0, 0, 100]])
i += 1
raise ValueError
parser = argparse.ArgumentParser()
app = QApplication(sys.argv)
d = d[k]
axis2.plot(list(range(10, 20)))
squre_pts.push_back(R4)
plt.plot(x, y)
print(first(l for l in lettfreq if lettfreq[l] == 1))
reader = csv.reader(f)
k.delete()
is_linear(eq1, [a, d])
i = np.random.randint(0, nrows - 1, numdense)
axis([-1.5, 1.5, -1.5, 1.5])
dfs = [df1, df2]
d = {}
print((fit_alpha, fit_loc, fit_beta))
plt.contour(np.log(r))
key = Key(bucket, filename)
b = [(10, 40), (40, 60), (60, 90), (90, 100)]
filename = os.path.join(dirname, basename)
result.append(mofile)
print(res[0])
f.diff(x).diff(x) < 0
x = np.linspace(0, 2 * np.pi, 100)
show(ptr, 0)
c = np.hstack((a, np.atleast_2d(b).T))
fig.canvas.draw()
self.__dict__[key]
c.perform()
np.lib.stride_tricks.as_strided(arr, shape=shape, strides=strides)
0
map(operator.itemgetter(0), L)
self.__dict__.update(state[0])
X.tocsc()[indices]
Y[..., (1)] = np.clip(np.abs(X) / absmax, 0, 1)
round_total_digits(x)
IOLoop.add_timeout(deadline, callback)
hist, xedges, yedges = np.histogram2d(x, y, (xedges, yedges))
[([x] + p) for x in [4, 5, 6] for p in product(*seqs[1:])]
img = ImageTk.PhotoImage(Image.open(path))
part.speed = [random.uniform(smin, smax) for _ in range(size)]
print(sys.getsizeof(x))
send_from_directory(directory, filename)
seed = np.zeros(data.shape, dtype=bool)
help(sys)
print(numpy.nanmean(A))
plt.contour(X, Y, F, [0])
r = np.sqrt(x ** 2 + y ** 2)
fig.show()
b = r_[a, c]
all(i is a[0] for i in a)
print(map(tuple, output_sent))
k = cv2.waitKey(0)
self.z = z
b = [a, a]
X = np.linalg.solve(A, y)
t = set([1, 2])
self.listOfVideo
data
np.random.seed(0)
rec.set_clip_on(False)
series2 = series1[::-1]
pygame.init()
content = result.read()
self._oldstdout_fno = os.dup(sys.stdout.fileno())
fd.floatarr.argtypes = [POINTER(c_int), POINTER(POINTER(c_float))]
utils.py
total.finish()
a = [1, 2]
ind = np.column_stack(np.unravel_index(idx, lon.shape)).tolist()
YourTask.apply_async(args=[some, args, here], eta=when)
a = list(a)
all_keys = set(chain(*[list(x.keys()) for x in dd]))
v = np.arange(0, original.shape[0], 0.5).astype(int)
tree.body[1].names[0].name
ssh.load_system_host_keys()
np.dot(arr, arr)
myNewList[i] += math.copysign(0.01, n)
d.x
mw.show()
fig.colorbar(surf, shrink=0.5, aspect=5)
t = datetime.datetime.fromtimestamp(float(s) / 1000.0)
image = Image.open(image_file)
color = sns.color_palette()[5]
dt_aware = pytz.timezone(tz).localize(dt_naive)
[tensor.name for tensor in tf.get_default_graph().as_graph_def().node]
cscope - R
FlakyClient.call()
os.seteuid(os.getuid())
tree = ET.parse(newfile)
print(funcs[0]())
datetime.date(2012, 11, 22), datetime.date(2012, 12, 25), datetime.date
strcpy(cpy, str)
results.append(line)
int(self) > int(other)
d = dict(zip(val_old, val_new))
True
reader = csv.reader(fin)
output = pandas.DataFrame(index=outDates, columns=strData)
self.tapDetected()
signal.alarm(timeout)
df
Vector([(s + other) for s in self.data])
name = models.CharField(max_length=255)
handler = logging.StreamHandler()
from_date - relativedelta(years=years)
j += 1
result = []
array = list(range(10))
raise
mysql_cn.close()
objects = PersonManager()
self.pk
word = word.strip()
cv.SetData(cv_im, pil_im.tostring(), pil_im.size[0])
print(string_numbers)
print(sys.argv[1])
plot(xdata, ydata)
fp = webdriver.FirefoxProfile()
zip(list(range(start, stop)), collection)
finalinfo[s] = finalinfo.get(s, 0) + t
new_dict
np.multiply(d, d, out=g)
a.indices(1)
signals.pre_save.connect(update_timestamp, sender=Post)
print(doc.to_json())
print(x)
x = random.random()
xx = np.linspace(0, 1, 1000)
os.close(self.pipe[1])
h2o.init()
d = p.dirname(somepath)
table[i - 1][j - 1] = data[str(i)][str(j)]
result += [i for i in range(len(values)) if values[i] == sv]
res = cursor.fetchall()
a, b, c, d = np.ogrid[:n, :n, :100, :n]
concurrent_suite.run(testtools.StreamResult())
ylim(10, 17.5)
print(key, my_dict[key])
random.seed(newseed)
im = numpy.random.randint(0, 50, (5, 7))
print(sub_toks)
ui.write(e.EV_KEY, e.KEY_A, 1)
ax.plot(xdata, ydata)
test_greet()
t.start()
abspath(getsourcefile(lambda : 0))
10.0 ** 10 ** 10
1, 1, 8, 1
[(16, -16), (40, -40)]
main()
list(closed_range(1, 10, 2))
[(l == value) for l in lst]
ax.scatter(x, y, marker=symbol[sign(chg)], s=175)
print(first_day + relativedelta(months=1))
y = y + y
time.sleep(0.2)
time.sleep(50.0 / 1000.0)
fig, axs = plt.subplots(1, 1)
self.rop = rop
print(data)
module = __import__(module, fromlist=[name])
obj.actor.scale = [0, 0, 0]
data = np.array([6])
other + str(self)
outputmapping[idx] = val
new_stack.append(old_stack.pop())
a_thread.join()
customer.save()
stack.extendleft(reversed(node.children))
a = numpy.arange(10000, dtype=numpy.double)
self.dot.set_data([[value], [value]])
df = DataFrame(columns=list(range(100)), index=list(range(1000)))
next(op)
results = []
self.b = b
self.update()
self.session_store = sessions.get_store(request=self.request)
self.systemTrayIcon.setVisible(True)
dict = {}
Container(result)
scalemap[:] = scale * xmap
x == y
copy_of_a = a[:]
emails.append(email.fetch())
map(id, a)
line = line.rstrip()
legs = 0
a = a[0]
no_vow(seq, index)
axes.bar(x2, y, facecolor=getCycledColor())
df = concat(tp, ignore_index=True)
axes = plt.subplot(111)
locals()
df.update(df_small)
dropped_copies.append(x[i] for x in copies[i])
Log.setLevel(level)
x = np.linspace(-1, 1, 500)
t /= np.linalg.norm(t)
poison(spam)
logger = logging.getLogger(__name__)
pool.join()
self.value
only_words = [token for token in my_list if token.isalpha()]
y_test = np.random.randint(0, 10, [50])
self.value = value
b = a()
data = xmltodict.parse(data)
DEBUG = True
object_list.filter(username=request.user)
fig.canvas.draw()
logger.py
f.__closure__[0].cell_contents
self.hide()
t.stop()
float(s)
bval[q - 1] ^= 1 << r
loop.close()
np.diff(np.sort(a))
g = io.BytesIO(f.read())
seconds = value.total_seconds()
self.Bind(wx.EVT_MENU, self.OnMinimize, id=minimize.GetId())
[0, 1, 1]
im = Image.open(img)
print(rows[len(ray) - idx])
self._index += 1
self.img_label.pack(side=tk.TOP)
np.hstack((arr.reshape(x * y, z), indices))
client_receiver.RCVTIMEO = 1000
print(utc.localize(test2))
mask = np.ones(a.shape, dtype=bool)
res = a[0] * b[0] + a[1] * b[1] + a[2] * b[2]
self.collector = collector
msg = xmpp.Message(self.request.POST)
form = UsersForms.UserImage(request.POST, request.FILES)
foo = my_func(your_func(their_func()))
bus = dbus.SessionBus()
metadata.drop_all()
filt1(signal) * line(dur, 0, 1) + filt2(signal) * line(dur, 1, 0)
j = np.array([[0, 0, 0], [1, 1, 1]])
display = Xlib.display.Display()
main.show()
print(result)
line = line[:-1]
print(p1.x.x)
print(total)
options = parser.parse_args()
cvtColor(img, img_bw, COLOR_BGR2GRAY)
path = os.path.join(dir, name)
print(name)
seen.add(item)
a_test.method_two()
UserSerializer(user).data
logger.removeHandler(handler)
df = df.applymap(format)
self.flush()
setattr(self, field.name, new_filename)
TextWidget.focus_set()
print(finder.nbest(trigram_measures.likelihood_ratio, 10))
path = os.path.join(dirpath, filename)
store.close()
False
digit_to_char(m)
decorator
self.y += 1
keyValues[key].append(value)
pickle.load(f)
CM_tilde = np.mean(data, axis=1)
itertools.chain(f(reversed(a[:i])), [a[i]], f(a[i + 1:]))
time.sleep(SECONDS_TO_WAIT)
new_path.append(current_neighbour)
code.interact(banner=banner, local=namespace)
self._a = a
CALLS += 1
list = []
plt.yticks(yvalues, ylabels, figure=fig)
app = Flask(name)
f = urllib.request.urlopen(req)
self._heartbeat = heartbeat
list(iterable.keys())
StartDance(*list(range(5, 9)))
driver.get(url)
literal_eval(x)
[1, 8, 6]
C = A.dot(B)
dir(img)
C.copy(ffi.from_buffer(arr_in), ffi.from_buffer(arr_out), 16)
frequencies[character.lower()] += 1
b = set(a)
itertools.groupby(list(range(10)), lambda x: x < 5)
a = [2, 7, 9]
serverSocket.bind((HOST, PORT))
print(str)
0
BOOST_PYTHON_MODULE(s)
p.start()
B = [[0, 0, 1, 0], [1, 0, 1, 0], [1, 1, 0, 0], [1, 0, 0, 1], [1, 0, 0, 0]]
found = False
tasks = multiprocessing.Queue(1)
print(test(15))
main()
False
oss.str()
parser
screen = pygame.display.set_mode((800, 600))
x = np.zeros(2, dtype=dt)
search(s)
self._cache = {}
sys.exit(app.exec_())
b[a]
plt.figure(figsize=(15, 5))
{}
deleteself.list[i]
x, p = set(range(2, n)), 2
x.A.count() * (x.A.count() - 1) * 2
imframe.putpalette(palette)
current_dir.pop()
done.add(row[0])
j2.sort()
ax0 = fig.add_subplot(1, 2, 1)
[t for t in grouper(s) if t[0] in vowels]
config = ConfigParser.ConfigParser()
result = PyClass()
print(doc.reprJSON())
wave_file.close()
ext = os.path.splitext(path)[1]
subprocess.Popen(args1)
subprocess.Popen(args2)
x[1::2]
diff = [(a[i + 1] - a[i]) for i in range(N - 1)]
f.close()
t.set_axis_off()
print(str[:6] * 2)
a = np.transpose(a)
{0, 1, 0, 0, 0, 0, 0},
b1 = np.array([[5, 6], [7, 8]])
d[date] = {}
self.kNN = initializekNN()
server = urllib.request.build_opener(ph)
a * b
m.predict([1, 1, 1])
print(df)
QtCore.QAbstractListModel.__init__(self, parent)
date_joined = models.DateField()
result.append((longest_keyword, all_occ[longest_keyword][0]))
write(file)
sys.path = sys.path[:4]
it = iter(it)
a = np.arange(10)
fig2 = plt.figure(figsize=(4, 4))
white = np.array([255, 255, 255])
pprint(offset_keys(dct, datetime.date(2015, 7, 12)))
self.print1()
cc = np.load(f)
wr = csv.writer(your_csv_file, quoting=csv.QUOTE_ALL)
plt.hist2d(new_x, new_y, bins=(50, 50))
pygame.init()
resp
plt.plot(x, norm_vals)
clients += 1
p.start()
x, y = x + dx, y + dy
np.random.seed(1977)
p4 = ctypes.c_int(0)
getattr(urlparse, method).append(scheme)
[5, 2, 2, 1, 4, 1],
my_user.save()
cv2.drawContours(close, [cnt], 0, 255, -1)
pool.join()
f = eval(s)
b.T
events = (a[0] + a[-1] + sum(a[i] != a[i - 1] for i in range(1, len(a)))) / 2
self.maps = maps
0, 1, [t]
menu = Menu(root, tearoff=0)
db_field.formfield(**kwargs)
test = [[0.0] * 10] * 10
b[:, (a)]
deleteposix
print(image.shape)
echo((foo + bar) * baz / (bar + foo))
scipy.stats.norm(100, 12).cdf(98)
printTree(tree, child)
findex.fromfile(f, 1)
args = parser.parse_args()
len(self.datatable.columns.values)
version[0] == 6 and version[1] == 0 and version[8] == VER_NT_WORKSTATION
ModClass.class_method()
f_new.close()
button.pack()
print(root.getprevious())
cr.set_source_rgb(1, 1, 1)
df1 = pd.DataFrame(data1)
split = shlex.split(s)
data = urlopen(info_url).read()
out.write(buf[0])
cyclic_equiv(a, b)
ctx.push()
inF.close()
uniq = list(OrderedDict.fromkeys(lst, 0))
False
count += 1
dtype.append((field, object))
c = Counter(list(d.values()))
b = int(sys.argv[1])
cv.ResetImageROI(newCanvas)
print(form.errors)
str(s)
wx.CallAfter(self.frame.Close)
repr(d)
print(network)
driver.maximize_window()
result
app.main()
print((c.x, c.y, c.z))
t = threading.Thread(target=do_work, args=(work, results))
(10, [2, 5]),
print(m.group(1))
usernametoken.insert(uname)
self.delete(save=False)
plt.imshow(np.random.randn(100, 100))
df
print(a)
setattr(foo, generatedClass.__name__, generatedClass)
img[data[i, 0], data[i, 1]] += 1
a[1] = np.ma.masked
timeit.Timer(myTImedClass.square).timeit()
queue.put([e, traceback.format_exc(e)])
id(a[0])
p = np.poly1d
result[k] = result.get(k, 0) + v
self.index += 1
f, x, y, z
qbtn.move(50, 50)
app.debug = True
df[cond1 | cond2]
generations.append(generations[-2] + generations[-1] - 1)
src = inspect.getsource(target)
self.assertTrue(element in self.seq)
self.transport.loseConnection()
a = models.ForeignKey(A)
result.append(p[:i] + [l[0]] + p[i:])
bind_layers(PPPoE_Tag, Padding, tag_type=0)
f.close()
mydict.setdefault(currentid, [])
suite.run(defaultTestResult())
dir(nodebox)
founds.append((inters, list_number1, list_number2))
cell.value = 2
self.renderer0 = gtk.CellRendererText()
asyncio.wait(self._set)
app.wsgi_app = LoggingMiddleware(app.wsgi_app)
fd, path = tempfile.mkstemp()
current += 1
self.tearDown()
main()
event.fire(*args, **kargs)
self._q.put(self.o)
name = Column(String, primary_key=True)
df = df[df.apply(lambda x: x.A in x.B, axis=1)]
array2 = np.broadcast_to(array1, (20, 20, 2, 4))
min(lis2, key=func)
sys.stdin.read(1)
sp.solve(lst)[0][x]
self.label = QLabel(self)
dis.dis(lambda : True == True != False)
elapsed = time.time() - now
p.join()
f2.close()
cls._bar = value
nhb if random.random() < p else x
y = ax.get_ylim()
self.index += 1
z.close()
meta.reflect(bind=someengine)
5 - +-+-+2
module = import_module(module_name)
a * 2.0
X = np.ma.masked_equal(X, 0)
1 << 100
address = models.ForeignKey(Address, blank=True, null=True)
print(author.first(), author.last())
uri, tag
[[(x + y) for x, y in zip(*row)] for row in zip(outgoing, incoming)]
y = y.reshape(-1, x.shape[0])
array = [random.uniform(1.5, 12.4), random.uniform(0, 5)]
foo(A(), A())
p = Process(target=MP_Stuff, args=(self, id))
p.map(worker, nums)
ilabel.grid(row=1, column=1)
print(mondays[-1])
items = list(some(**m) for m in dl)
f = staticmethod(f)
self._conn = self._pool.get()
line = file_obj.readline()
out, err = process.communicate()
fp = webdriver.FirefoxProfile()
do_whatever_else()
connection.commit()
car2 = pygame.transform.rotate(car1, 20)
foo * a + str(bar)
file.close()
__builtin__.object = orig_object
fig.colorbar(qmesh, ax=ax)
img.seek(0)
L[i] = L[idel]
proc.join()
z = np.outer(np.ones(np.size(lons)), np.sin(lats)).T
lines = np.empty((len(x_range) + len(y_range), 2, 100))
response = self.client.get(some_url)
tree = []
deleteself.z[-1]
print(platform.python_version())
print(r.text)
setCustomWidth(2)
result = []
x + y + z
traceback.print_exc()
[1.000051]
x.split()
print((key, list(grp)))
stdout, stderr = p.communicate()
c = np.concatenate((a, b))
driver = webdriver.Chrome()
doc = ET.parse(xmlfile).getroot()
pprint.pprint(zip(chain.from_iterable(expressions), results))
f(*args, **kwargs)
{}
p.map(e.op2, arg_list)
new_t = [names[item] for item in t]
my_list[7:10], my_list[2:4] = my_list[2:4], my_list[7:10]
new_lst = [sorted(sublist) for sublist in lst]
im = imclearborder(im)
dc = wx.WindowDC(window)
b.shape
xlim = ax.get_xlim()
print(utc_date)
np.trapz([-1, 0, 1])
item
spreadsheets_client.ProgrammaticLogin()
self._inner[index]
self.update(*args, **kwargs)
loop = asyncio.get_event_loop()
moneyx = float(l)
main()
echoer.transport.write(data)
i += 1
composed
(vmax - vmin) * np.random.rand(n) + vmin
print(arr.columns)
df
session = requests.session()
my_urls + urls
M = np.random.rand(N * 10 * 10).reshape(N, 10, 10)
res = np.zeros(reslen, dtype=a.dtype)
obj = mlab.imshow(img)
self.panel.SetScrollbars(1, 1, 1, 1)
ii = np.where(a[:, (0)] == b.reshape(-1, 1))[1]
print(sorted(product(xs) for xs in itertools.product(*values)))
a.helloThere()
biglist[:] = unique(biglist)
A = 1e-07
rows.append(row)
rows = cursor.fetchall()
n = int(line)
self.renderer(name, str_value, final_attrs, choices)
np.set_printoptions(2, threshold=100, edgeitems=5, suppress=True)
1 - 1 - 1
[6, 6, 6, 6, 6]
a[:] = b
temp = [key, value]
leg = ax.legend()
self.assertEqual(2 + 2, 4)
L[:][1]
print(result)
output.write(chunk)
exit(0)
width = 2 * np.pi / N
s.hist()
print(map(applyEpsilon, inputList))
print(lh.tostring(doc))
print(item)
a * np.exp(-c * (x - b)) + d
fullDict.setdefault(row[0], []).append(row[1])
Console.ReadLine()
X[mask1.nonzero()[0], mask2.nonzero()[0]]
sidx = a.argsort()
counts = np.diff(a.indptr)
request.user = User.objects.get(id=1)
end = time.time()
chunks = [bin_string[i:i + 6] for i in range(0, len(bin_string), 6)]
p.suspend()
height = len(data)
runrec(new_src, level + 1)
inds = np.arange(A.shape[0])
r.div(r.sum(1), 0).plot.bar()
repr((self.name, self.grade, self.age))
x, y
fig = plt.figure()
n += 1
min(PlayerList, key=lambda p: min(p[1:]))
sum((xa - xb) ** 2 for xa, xb in zip(a, b))
x = np.random.random(10)
df
r = b * sympy.sin(c)
mro = inspect.getmro(self.__class__)
next(f)
plt.pcolormesh(gridx, gridy, grid)
df2 = pd.read_table(io.BytesIO(content2))
b.String()
self.render()
print(type(fh.read(100)))
x = [1, 7]
store.append(tabular_key, store.get(key), data_columns=True)
buf = f1.read(1024)
data_pipeline.close()
closing(inner())
list(join_unescaped(list_1))
self.data
i += 1
a = [1, 1, 2, 1, 1, 4, 5, 6]
t1 = threading.Thread(target=thread1, args=(1, t1_stop))
x = linspace(0, 2 * pi, 20)
total = next(it)
app.update_template_context(context)
self.setResizeColumn(0)
soup = Soup(htmlFile)
signal.alarm(0)
self.n = 1
val = f.f_back.f_locals[x]
x[2], x[1] = x[1], x[2]
matplotlib.hatch.Shapes.__init__(self, hatch, density)
not sum([(not i in data) for i in data2])
df
d = calendar.monthrange(dt.year, dt.month + 1)[1]
self.flush()
forks.append(Fork(names, goal, success))
value
xs.sort()
r = np.random.randint(rows, size=100)
a, b = 0, 1
example()
loop.run_until_complete(user_func())
print(list(m))
sh.write(n, 0, v_desc)
W = W.reshape(8, 10)
Area2(a, b, c) == 0
raise NotImplementedError()
height, width = image.shape[0:2]
list(bcdDigits(characters))
x -= 0.5 * (bins[1] - bins[0])
[self.cousinitt(x) for x in self.gomez * n]
df.b.loc[s & (s != s.shift(-1))].tolist()
my_button1.bind(on_press=self.changer)
func
resultlist.append(M)
sklearn.feature_selection.f_regression(X, Y, center=False)
result = {}
items = [conv(val) for conv, val in zip(converters, vals)]
deletex
splitList.pop(0)
rgb_values.pop(i)
print(infer_spaces(s))
signal.signal(signal.SIGALRM, alarmHandler)
gevent.spawn(read_stream, p1.stdout)
decay_rate = 5e-06
exec(code, m.__dict__)
soup.original_1.body.append(b)
self.canvas.repaint()
myOjbect.doStuf().doMoreStuf(arg1, arg2).goRed().goBlue().die()
indices = list(range(N))
b = [4, 5, 6]
session = sessionmaker(bind=engine)()
print(network)
self.a()
item = item.lower()
df
app = QApplication(sys.argv)
seps
self.connections.append(self)
sentences.append(sentence)
print((val, ty.currentLevel()))
quantiles = numpy.array(quantiles)
record._cache.update(record._convert_to_cache(values, update=True))
k = i * len(b) + j
a[x] = a[x][1]
eday1.insert(10, 10)
arg in arg2value
panel.SetSizer(sizer)
M = np.random.randint(2, size=(h, n))
index = clang.cindex.Index.create()
x.extend(item)
foo(parent2)
layout = QHBoxLayout(self)
Tools | SublimeREPL | Language
lines = ax.plot(list(range(10)), pylab.randn(10), list(range(10)), pylab.randn(10))
root_logger.setLevel(logging.INFO)
len(frozenset(objs)) == len(objs)
outdata = numpy.empty((5, 6))
files.finalize(zip_file)
count_helper(len(text) - 1)
df.index = df.index + pd.DateOffset(days=15)
username = Martin.Thoma
np.array(y)
b = datetime.datetime(2015, 10, 29)
self.fig = pylab.figure()
l = list(map(itemgetter(0), g))
page = page[n:]
test2 = test1.astype(int)
endif
outfile.write(line)
new_instance.put()
total += 1
X = np.arange(-2, 2, dx)
splitext(path)
data = fin.read(end_index - start_index)
df.dtypes
thing.getSecret()
s.get_matching_blocks()[:-1]
logger.addHandler(handler)
sum += x
write_lamb(sys.argv[1])
print(x)
foo().baz()
response = requests.post(url, params=data, headers=headers)
tuple(l)
y[0]
print(df)
uniques[col] = uniques[col].union(chunk[col].unique())
text = first_td.renderContents()
q, r = divmod(q, l)
listSum(ls[1:], result + ls[0])
print(ignore_upper(a, skip_rows=1, skip_cols=2))
item.setEditable(False)
get_key(d, 10)
df
console.setFormatter(formatter)
NULL
created_at = models.DateTimeField(default=timezone.now)
any(map(my_dict.__contains__, my_list))
frame = sys._getframe()
a[get_x()]
df
y = np.array([1.5e-10, 1.5, 1500])
mask = np.random.random_integers(0, 1, N * M).reshape((M, N))
carray[:5]
arr[:] = lst[:]
f.__setitem__(Ellipsis, 100)
s.bind((HOST, 0))
myLib.RegisterNofityCallback(45454, 0, self.getCallbackFunc())
print(list(find(l)))
print(item)
setattr(instance, self.name, min(self._max, max(value, self._min)))
transf1d(f, x, y, out)
System.out.println(value.scriptResult)
QMainWindow(parent)
x.__reduce__()[1]
Counter(str1)
log_file.write(line)
a = A(b)
endif
signal.alarm(5)
parser.delete_first_token()
module
s.get(url)
frame = inspect.currentframe()
plt.errorbar(x, y, yerr)
httplib.HTTPConnection.debuglevel = 1
L = [15, 16, 57, 59, 14]
ts = time.mktime(time.gmtime())
ax.imshow(data)
driver = webdriver.PhantomJS()
fig.savefig(fname, dpi)
bins.append([min])
newImage.save(new_image_path)
fig.set_dpi(dpi)
-1
self.planet = Planet.EARTH
urllib.request.HTTPSHandler.__init__(self)
l = len(s)
wi.food(2.5)
len(empty)
output, error = someprogram.communicate()
connection.close()
df = xl.parse(xl.sheet_names[0])
node.start()
app.register_blueprint(main)
ol.add(1)
isinstance(result, (collections.Sequence, collections.Iterator))
groups.setdefault(key(sub), []).append(sub)
points = np.vstack([x, y]).T.reshape(-1, 1, 2)
xs, ys = zip(*sorted(zip(xs, ys)))
visited.add(path)
collections.Counter(df[0])
print(i[0], list(i[1]))
self.skipTest(MyTestCase)
1, 1, 0
count += 1
self.ui.setupUi(self)
1, 8, 8, 1
M = sparse.lil_matrix((10, 10))
app = QtGui.QApplication(sys.argv)
a.__class__
clientSocket.send(endmsg.encode())
os.remove(tmp_filename)
max_index = index
plt.imshow(image)
root.withdraw()
a * b
set(a)
self.username
print(result)
df.index.slice_indexer(start_remove, end_remove)
print(content)
p.apply_async(e.op1, arg_list)
mapper.SetScalarVisibility(1)
soup = BeautifulSoup(doc)
type(g._productions[-1])
stream.getvalue()
self.send_response(200)
groups.setdefault(len(e), []).append(e)
df[~df.stack().between(0.1, 1).unstack()]
np.abs(a[2] - a).max(axis=1)
K = abs(A - C) < abs(B - C)
print(stderr)
BaseHandler.__init__(self)
fn()
new_list = []
arr.fill(np.nan)
plt.figure()
t = np.arange(0, 40000, 4000)
print(model_tunning.best_params_)
main()
print(find_subimage(screenshot, subimg_path))
c = C()
img[:, :, (1)] = 50
print(id(text))
f = open(path)
ax1 = fig.add_subplot(111)
d = d.month + 1
arr[slices]
self.value = value
_wrapper
connection.start()
s.listen(10)
_authentication_required
logger = sc._jvm.org.apache.log4j
dingo
f
model.load_weights(weights_path)
n - 1
settings.py
filename = os.path.splitext(os.path.basename(sys.argv[0]))[0]
block = f.read(bufsize)
copytree(srcname, dstname, symlinks, ignore)
fig.colorbar(surf)
print(C())
f.close()
os.linesep
a = np.arange(1000)
cls.open_files()
pdb.set_trace
type(z)
fp.close()
print(pool.map(f, list(range(10))))
print(word)
p[0] > p[1] > p[2]
result
idx = np.where(a[i] > 0)
data = source.get_data()
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
type(name, bases, new_dict)
any(x % 2 == 0 for x in mylist)
img = PIL.Image.open(file_like)
foo.__code__.co_consts[1].co_consts
print(item)
CD, BF, BE, BC, BD
2, 2, 2, 0.1
query = query.filter(table_a.id == table_b.id)
print(itertools.__doc__)
myFunc(2)
data2[(0, -1), :] = np.nan
result = match.group(1)
p = Process(target=editDict, args=(mlist[i], mlist, i))
name in dir(__builtins__) + kwlist
children = {}
data = df.loc[(mask), :]
self.a = a
im = ImageGrab.grab()
type(k)
x[-1:4, -1:4]
np.allclose(a[:, :, :, (0)], collapse_dims(a)[:, :, 0:2])
sorted_a = a[np.argsort(a[:, (1)])]
self.axes.draw_artist(self)
image = Image.open(source_path)
table = [[(0) for x in range(count)] for x in range(count)]
pdb._runscript(mainpyfile)
main()
np.bitwise_or.reduceat(m, ind.ravel())[::2]
a[1:4]
b
next(lines)
point[0] + k * vec[0], point[1] + k * vec[1]
print(time.clock() - start)
response = urllib.request.urlopen(urllib.request.Request(self.pubmed_url))
fW.write(y)
self.verbosity
self.log.removeHandler(handler)
regressions = np.polyfit(X, A2, degree)
[X, Y] = meshgrid(x, y)
myseries_two.loc[0:2]
form = form_class(data)
--start
list = []
file_content = f.read(1)
sys.exit(app.exec_())
exit(0)
c[0].set_color(time_color)
result = cv2.warpPerspective(img2, Ht.dot(H), (xmax - xmin, ymax - ymin))
zsum, areasum
res = [dict(zip(res1, t)) for t in zip(*list(res1.values()))]
data = line.split()
self.assertGreaterThan(len(foo.config.mock_calls), 0)
s = list(iterable)
field = QtGui.QLabel(text, self)
response.url
pool.join()
dict(zip(spec.args[-len(spec.defaults):], spec.defaults))
s[pd.isnull(s)] = n
nmask = sparse.csr_matrix(~mask.A)
ax = fig.add_subplot(1, 1, 1)
time.sleep(0.25)
delta = numpy.eye(5)
self.c.set(SERV_SECTION, SERV_DESC, SERV_DESC_DEFAULT)
dir(string)
b.ques_type
jar = Cookie.SimpleCookie()
results = mysql_cursor.fetchone()
ax1 = fig.add_axes([0.05, 0.8, 0.9, 0.15])
compose(compose(f, f), f)
a, b = tee(iterable)
plt.hold = True
ax = plt.axes()
t2 = datetime.now()
ax = fig.add_subplot(n_rows, n_cols, n + 1)
name = self.aliases.get(name, name)
print(df)
s = requests.Session()
item.save()
inspect.getargspec(foo)
response
sys.exit(segmentation.exec_())
df = df.join(s)
p.pop()
locals().update(f())
pylab.show()
print(root_tree)
f = lambdify(t, a)
login(self.request, new_user)
x = 1.2876
print(sline[-1])
self.left = []
kernel /= kernel.sum()
list_result
form = FooForm
self.response.out.write(template.render(path, template_values))
y = np.arange(100).reshape(10, 10)
p = Pool()
sqrt(v1[0] ** 2 + v1[1] ** 2 + v1[2] ** 2)
list(d.items())
django.db.transaction.managed(True)
plt.figure()
NULL
ax.yaxis.get_major_locator().base(2)
print(lst[0])
ceiling_key(d, 6)
po.apply_async(mine_page, (filepath,), callback=save_data)
s = np.argsort(ab)
form.instance.author = self.request.user
top = np.argpartition(myBigArray, num, axis=1)[:, :num]
_get_elements_by_tagName_helper(node, name, rc)
index = self.get_index()
overlay_pic.close()
PyErr_Print()
tk.LabelFrame.__init__(self, root, **options)
pprint_on()
matches = {}
getattr(obj, attribute)
atexit.register(cleanup)
__init__.py < ---empty
arr = random.random(N)
product(L[1:], tmp + [i])
print(random.choice(verb_list))
x = np.arange(1, 15.1, 0.1)
setattr(self, member[0], withx(member[1]))
a = np.argsort(dist, axis=1)
ex.show()
l._legmarker.set_xdata(l._legmarker.get_xdata()[1:2])
not sys.stdin.isatty
fff(index)
timezone.utcoffset(dt)
description = models.TextField()
show()
id = Column(INTEGER, primary_key=True)
tmp.seek(0)
args = parser.parse_args(args, namespace)
path = os.path.join(root, fname)
graph.add_edge(node_number, random.choice(graph.nodes()))
np.log2(x)
{{your_python_data | as_json}}
x + y
self.timer.start()
library.func.argtypes = [c_void_p]
file_like_io.seek(0)
plt.ion()
A = np.random.random_sample(10000.0)
screen.nodelay(False)
ctx.move_to(-x_bearing, -y_bearing)
cax = fig.add_axes([0.12, 0.1, 0.78, 0.8])
type(myObj)()
colmax += i
file.close()
result = rec(a)
stream.close()
CHECK_RE.match(mystring)
result = np.vectorize(operator.le)(lhs, rhs)
slice(0, 0, 1)
zip(*([chain(iterable, repeat(padvalue, n - 1))] * n))
X, Y = np.meshgrid(x, y)
str(self.contract)
task = AsyncResult(task_id)
pdb.gimp_image_delete(image)
df.a = df.a.astype(float)
draw.text((10, 25), txt, font=font)
matches = list(filter(fulfills_some_condition, lst))
False, False, False, False, False, False, False, False, False
self._store_aggregation_timer.cancel()
self.append(self._fx())
x = plot(t, x)
lock = threading.Lock()
svc.fit(X_train, y_train)
newdata = json.loads(myData.text())
start = time.time()
print(line)
self.SetBackgroundColour(wx.Colour(0, 0, 0))
city = models.CharField(max_length=75)
buff = StringIO.StringIO()
new_list1 = [v[0] for v in decorated]
print(i)
print(urllib.parse.urlencode(params, True))
df = df.set_index(index_name)
print(df)
find(query)
app.setQuitOnLastWindowClosed(False)
c.setopt(c.HEADER, 1)
x = int(input())
c = Counter([letter for letter in message if letter.isalpha()])
cursor = dbapi_conn.cursor()
self.clients.remove(client)
cv2.circle(out, (int(x2) + cols1, int(y2)), 4, (255, 0, 0), 1)
chrome = webdriver.Chrome(chrome_options=chrome_options)
f.writelines(res)
shortcut.save()
old_stdout = sys.stdout
link = f.read()
logging.debug(pprint.pformat(ds))
self.size += 1
num *= 1
deque.extend(words[:n - 1])
self.newText.tokens.clear()
q.put((key, count))
fp.close()
plt.semilogy(x)
im2 = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)
s = socket(AF_INET, SOCK_DGRAM)
set(c) < set(b)
print(adam)
self.driver = WebDriver(firefox_profile=profile)
x.run()
count = 1
proc = pool.apply_async(processfile, args=[filename, cursor, end])
print(key)
v = [random.gauss(0, 1) for i in range(0, n)]
True
Base = declarative_base()
message = models.CharField(max_length=100)
{{formset.management_form}}
value
logger.addHandler(stream_handler)
raise
Py_Finalize()
particle.speedy = int(circle.speedy)
self.data += [val]
exec(fh.read())
f.__code__ = g.__code__
print((x, timeit.timeit(lambda : h.update(data), number=100)))
mat = pat.search(os.path.split(x)[-1])
inds = np.where(np.isnan(a))
5.8
fig.canvas.manager.window.raise_()
myList = []
self, self.__class__(other)
resp = make_response(f(*args, **kwargs))
getcontext().prec = 6
job.hour.every(4)
png.load()
pprint(get_connection_name_from_guid(x))
x.extend(compress(a, a))
test.eval.restype = ctypes.c_double
t.write()
ax.set_ylim(bottom=0)
driver.get(url)
bucket = conn.get_bucket(bucket_name)
ax.yaxis_date()
env.use_ssh_config = True
signal.alarm(0)
sline = i.split()
plt.clim(-4, 4)
v = tk.StringVar()
s[-2:]
[0, 0, 2, 1]
fig = plt.figure()
y = a * t ** alpha + b
page = br.open(base_url, timeout=10)
logger.setLevel(logging.INFO)
plt.show()
server.serve_forever()
A = np.asarray(AList)
df = pd.DataFrame(s, columns=heirIndex)
cache[key] = fun(*args, **kwargs)
self._logger
exit()
pyplot.gca().add_line(line)
print(overall_structure.parseString(test).asList())
output = list(range(input + 1))
xi = np.linspace(xmin, xmax, numx)
result = [(x + [y]) for x in result for y in pool]
print ()
print(os.path)
y1.append(random.randint(1, 100))
csv_w.writerow(columns)
register_openers()
fig.colorbar(surf, shrink=0.5, aspect=5)
list((y - x).elements())
d = defaultdict(list)
df
setattr(self, key, value)
fig.set_size_inches([5, 5])
result.append([])
intArray_getitem(mylibrary.V, 0)
app = Flask(__name__)
local_dt = datetime.fromtimestamp(expiration_utc_ts)
k = k.parent()
x = etree.fromstring(body)
i += 1
os.chdir(file_path)
CS = plt.contourf(xi, yi, zi, 15, cmap=plt.cm.rainbow, vmax=zmax, vmin=zmin)
deletesprocket
glLoadIdentity()
mkstring(10)
sorter = numpy.argsort(values)
[a] + li
self.dealloc_cb_p(self.p, self.l, self.dealloc_cb_arg)
arr[:, 1:] = float(10)
db_crsr.execute(_stmt)
df = PD.concat(data, axis=1, keys=[s.name for s in data])
t = np.linspace(0, 2 * np.pi, 100)
print(myfun(l, 0))
nlargest(1).reset_index()
id = ndb.ComputedProperty(lambda self: self.key.id())
table = {}
grouped = df.groupby(lambda x: x.day)
root = lh.tostring(sliderRoot)
x2 = np.random.permutation(100000)
self.send_response(200)
t1.join()
where = [m.start() for m in re.finditer(sub, string)][n - 1]
self.msgs.add(record.msg)
time.sleep(0.2)
Py_DECREF(myfunc)
print(result)
fileHandler.setFormatter(format)
s[4:6]
s = [item.capitalize() for item in s]
plt.imshow(data)
mySet = set()
stdin = sys.stdin.read()
self.data = {col: set() for col in columns}
str(my_uuid)
t = datetime.now()
full = np.random.random((1002, 1004))
plt.ylim(1e-06, 1)
letters.lower() in ascii_lowercase
parser = argparse.ArgumentParser(description, usage)
test(0, 10, 20)
result = re.sub(pattern, substitute, string)
print(df.loc[mask])
data = list(reader)
new_stepListB.extend([pathList[n][0], pathList[n][2]])
t = my_date.weekday()
inv = ax.transData.inverted()
objects = models.GeoManager()
B = np.where(np.isfinite(A), A, f(inds))
G.add_nodes_from(rank_of_nodes)
print(a, b, c, d)
fig, ax = plt.subplots()
df
json_str = json.dumps(json_object, indent=4, sort_keys=True)
globals()[name] = some_decorator(getattr(some_module, name))
something.jpg
print(user.screen_name)
req = con.getresponse()
img = Image.open(infilename)
color_bar.draw_all()
MyTimeDelta(hours=12) / MyTimeDelta(hours=2)
region_dict[a.region].append(a)
datetime.timedelta(**{interval_type: interval_num})
r(a[:i] + m + a[i + 1:])
df_possible_dup.apply(lambda x: worker(x, fuzz_ratio))
self.currentStack = []
app.request_class = MyRequest
foo.mymethod = mymethod
xv, yv = np.meshgrid(x, y)
result = tuple(islice(it, n))
ctr = Counter(frozenset(x) for x in a)
df
choice = get_input()
tck = interpolate.splrep(x, y, k=2, s=0)
master = Tk()
0
text_file.seek(os.path.getsize(filename) - len(os.linesep))
self.set_val(val)
print(new_list)
b = a
x, y, w, h = cv2.boundingRect(c)
django.setup()
lock.acquire()
fit_result[-1]
deleteself._cache[self._job]
my_array[my_array > 255] = 255
cw.writerow(one_line_of_data)
thefile.seek(0, 2)
im.set_data(data)
np.allclose(a[:, :, :, (1)], collapse_dims(a)[:, :, 2:4])
print(x, y)
ln - s / proc / self / fd / dev / fd
y()
writer.writerow(data)
x, y = l.split()
list(range(5))[4:5]
False
self.axes.set_ylabel(ylabel)
a.foo()
print(list(merge(times)))
inputfile.close()
time.sleep(2)
newList = []
np.dot(mX.T, logit(mX, vBeta) - vY)
i = Image.open(StringIO(r.content))
vect = TfidfVectorizer(vocabulary=emoticons)
self.draw_figure()
decorator
app.Documents.Open(word_file)
ax.add_collection(lines)
print(list(spamreader))
image_without_exif.putdata(data)
workbook.Close()
zerostr(s)
start()
np.median(rdd.collect()), quantile(rdd, 0.5)
print(sys.argv)
zip_longest(fillvalue=fillvalue, *args)
y = np.random.random(10)
s += x
Color(255, 255, 255)
anadict.sort()
d2 = datetime.datetime.strptime(d_string, fmt)
c = a.astype(float).cumsum()
glLoadIdentity()
shutil.rmtree(dirname)
f.close()
(np.diff(np.sign(data)[np.nonzero(data)]) != 0).sum()
self.all_items.add(item)
dict(zip(I, I))
[pypi]
print(find_matches(im_haystack, im_needle))
df.shift(1).min(1),
coords = np.stack(np.meshgrid(*args), axis=-1)
fig, ax = plt.subplots(1, 1)
dct = dict(splt(item) for item in lst)
test_login()
module = sys.modules[thing.__module__]
loss(y, y_pred)
x /= numpy.linalg.norm(x, axis=1)[:, (numpy.newaxis)]
next_link.__class__.__name__
i.save()
handle.write(sort_by)
menu.appendItem(fileItem)
o.first_item()
env = Environment(ENV=os.environ)
app.mainloop()
print(x)
[int(item == max_val) for item in my_list]
output_logger.error(line)
result = {}
dset.resize(row_count + chunk.shape[0], axis=0)
round_to_1(19)
new.append(num)
p.map_async(f, [slice(stop_f)] * M)
coo = coo_matrix((data, (row, col)))
print(a.value)
1062, 1062, 1062, 1062, 1062, 1125, 1000, 1125
sess.run(train, feed_dict={X: batch[0], y_: batch[1]})
a = b
h[a, b, c].append(value)
log.start(loglevel=log.DEBUG)
daemon.restart()
out = optimize.leastsq(errfunc, pinit, args=(logx, logy), full_output=1)
nk = min((k for k in self), key=lambda k: NearestDict.__dist(key, k))
now()
x = df[cols].ix[0] > 0
d = date(year, 1, 1)
self.func
plt.draw()
list(thedict.keys())
age = int((date.today() - birth_date).days / days_in_year)
HttpResponseRedirect(reverse(contact_details, args=(new_contact.pk,)))
normalizedscores[u] = float(l) / maxscore
{{inner2()}}
os.close(fd)
fig, ax = plt.subplots(1)
inds = np.ones(rng[-1], dtype=np.int)
ax = fig.add_subplot(111)
a.__dict__
result = []
[]
Second / Third / Fourth / Fifth
d = {}
restart()
url = urljoin(response_url, url)
move(y, x)
myDict[key] = 10
ax = fig.add_subplot(111)
type(cls.__name__, tuple(classes), dict(cls.__dict__))
print(X[0], Y[0], calc_slow(X[0], Y[0]))
print(checksum, hex(checksum), chr(checksum))
files = [os.path.join(os.getcwd(), f) for f in files]
printFoo()
print(mm.filled(np.nan))
sleep(random.randint(10, 1000) / 1000.0)
main.show()
NULL
root.mainloop()
colors.remove(c)
cursor.execute(query, station_id=id)
result = []
print(line)
opener = urllib.request.build_opener(handler)
total / (len(items) - 1)
b = np.zeros((nx, nz))
q.join()
o.close()
x = np.array([6, 1, 7, 6, 9, 0, 8, 2, 1, 8])
print(fmt.format(*container[0]))
a = numpy.random.random(100)
state = self.__dict__.copy()
numpy.vstack([test, test[::-1]])
htmlcolor(0.1, 1.0, 0.9)
self._filename = filename
[2]
soup = BeautifulSoup(html)
root = Tkinter.Tk()
sum(i != j for i, j in i.izip(s_1, s_2))
name = models.ForeignKey(School)
self.process.terminate()
pool = list(Content.objects.all())
columns = line.split(column_separator)
autorestart = true
f.close()
colors = [(0, 0, 255), (0, 255, 0), (255, 0, 0)]
tableWidget.setRowCount(len(entries))
x.add_row(row)
print(e.args)
list(common_entries(da))
end = datetime.datetime(2009, 2, 10, 16, 0)
a = [somestuff]
cv.GetQuadrangleSubPix(image, output_image, map_matrix_cv)
b[i] += x[i]
value &= ~(1 << 10)
name = models.CharField(max_length=100)
mls.geom_type
df.values[mask] = s[s.index.searchsorted(df.index)].repeat(mask.sum(1))
fig = plt.figure()
deleteresult[-1]
output.append(s)
ax1.plot(np.array([1, 5]) * i, label=i)
libc.syscall(186)
sum(cents_list) == 500
nx.draw(G)
math.atan2(0.0, 0.0) == math.atan2(-0.0, 0.0)
type(y[0])
self.counter += db.run_in_transaction(_tx)
dates1[mask]
labels = np.arange(1, num_labels + 1)
therest.append(para)
unrooted_paths.append(path)
y = np.ravel(B).reshape((9, 1))
d[k] += int(v)
triang.vertices
map(csv_writer.writerow, json_dict[entity])
ax2.set_ylim(0, 1500)
fig = plt.figure()
ax = fig.add_subplot(111)
ax.add_patch(p)
print(request.error_code)
1
pool.join()
deletedict_del[k]
df
result.append(c)
linspace_x = np.linspace(x_range[i], x_range[i], 100)
result.append(position)
predictions = results.predict(data[half:])
cert.decode(der)
True
lookup = collections.defaultdict(list)
sys.stdout.write(frame.tostring())
self.__dict__ = somearg.__dict__.copy()
os.makedirs(dir_name)
i += 1
increment()
(t[0], ()) + t[2:]
func
filename[len(root):].lstrip(os.path.sep).lstrip(os.path.altsep)
aList[i] = 0
date_before_leaps - timedelta(seconds=leap(date_before_leaps))
C[x, y, z] += A[x1, y1, z1] * B[x2, y2, z2]
a[:] = [(x + 2) for x in a]
print(tags)
takewhile(bool, (list(islice(stream, size)) for _ in count()))
f(add, 10, 7)
axis(2)
is_separately_linear(eq1, [a, d])
result = cv2.matchTemplate(image, template, method, mask=transparent_mask)
tornado.auth.TwitterMixin.get_authenticated_user(self)
print(username)
oba.name
target.append(idx)
data = clientsocket.recv(1024)
count += 1
glLoadIdentity()
self._mod.__dict__[attrname]
h1 = hyst(y, -0.5, 0.5)
resp = json.loads(json_str)
temp = {v[1]: ([k] + v) for k, v in list(rays_starters.items())}
_mkdir(miniature)
df
blockwise_times.append(best)
D = L1[0] * L2[1] - L1[1] * L2[0]
PyEval_InitThreads()
f[0].data
student = form.save(commit=False)
a = np.random.random_integers(low=0, high=1 << 10, size=2 * n).reshape(-1, 2)
endfun
img.im_feeling_lucky()
vertices.clear()
self.ser.read()
os.killpg(pro.pid, signal.SIGTERM)
hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)
y = (x + 1) // 2
self.master.bell()
root.mainloop()
values.append(float(value))
a.remove(b)
people = Person.objects.all()
m = X.mean(axis=1, keepdims=True)
t = TestClass()
poly = GeoSeries([Polygon([(0, 0), (0, 2), (2, 2), (2, 0)])])
out = np.zeros(x.shape, dtype=int)
data = []
match = re.search(regexp, str)
datarows.append(row)
print(get_nesting_level())
heapq.heappop(heap)
{{docimage.image.url}}
xi = np.linspace(0, 5, 10)
12568
df
dict(ChainMap(*ds))
x[x < 0] = new_value_for_neg
unique_rows(a)
self.foo = 5
d_next += datetime.timedelta(weeks=1)
my_list.append(abe)
self.request_log.append(suffix)
predicted = classifier.predict(X_test)
result = []
open_cv_image = numpy.array(pil_image)
self.nesting = 0
z = numpy.array([[0.1, 0.1, 1.0], [1.0, 0.1, 0.09], [0.1, 1.0, 0.2]])
dct = OrderedDict()
self.show_progress(test_progress_bar.value)
print(b[0])
print(frames_to_timecode(26))
df
encoded = base64.b64encode(cipher.encrypt(msg_text))
grandFather.removeChild(father)
setattr(obj, k, v)
ipaddress.ip_address(ipv6)
x = 1
a.flat[idx]
self.datadex = {f: (42) for f in foo}
self.parent.iadd_x(val)
f(**{kw: True})
t.daemon = True
decorator(method_or_name)
br = mechanize.Browser()
name_son1.parents_backref.append(name_father1)
timediff = datetime.datetime.now() - time_posted
s = p.stdout.readline()
destination_ou.com_object.MoveHere(str(user.as_string()), str(user.Name))
A[:, (second), (third)].flatten()
time.sleep(x)
y = numpy.random.rand(2)
x, y = intersections(a, b)
err = random.randint(0, 4)
print(x[0])
Dx = L1[2] * L2[1] - L1[1] * L2[2]
result = ImageOps.colorize(gray, (0, 0, 0, 0), color)
cax.get_yaxis().set_visible(False)
s[1:] + s[:1]
xs = s.strip()
UTF - 8
a180 = a[..., ::-1, ::-1]
c = pymongo.MongoClient()
field1 = models.TextField()
seq[:i], seq[i:]
audio.add_picture(image)
root = Tk()
lambda x: func(rec_func(x))
ends = np.hstack((nonoverlapping, [-1]))
entries = nltk.corpus.cmudict.entries()
dict(message=message)
s1.is_valid()
foo.method(2)
a[5:7]
s = np.cos(t)
y[1] = 4
exch(k, k / 2)
device.send_command(CMD_BLINK, 100)
message = messages.GetFirst()
content = self._request.read()
cb = plt.colorbar(p, shrink=0.5)
result = self.output.getvalue()
count = 1
ax1 = plt.figure(1).add_subplot(211)
k = json.loads(j)
print(f.data)
x = np.linspace(0, np.pi, 100)
config_parser.read(config_files)
parser = argparse.ArgumentParser()
df
process1.wait()
df
print(check_for_triangle(tri1, lines))
p.join()
frame.f_locals.clear()
form = MyForm
self.log.SetBackgroundColour(self.bgColor)
[Request(x, callback=self.parse_link) for x in links]
print(line)
result = []
batch.delete()
groups[len(e)].append(e)
address = models.ForeignKey(Address)
result.append(sorted_intervals.pop())
meta = MetaData(bind=engine)
data = Column(String)
y[:, (0)] = 0
Xcum[(t - H), :] = np.sum(X[t - H:t, :], axis=0)
buffer = cStringIO.StringIO()
timerthread[0].cancel()
print(a, b, c)
its = [iter(l) for l in lists]
rlist.append(tuple((k, tuple(gg[1:][0][0] for gg in g))))
print(df)
print(data)
time.timezone
signal.connect(self._checkSignal)
print(img_tf.get_shape().as_list())
self[key] = self.__class__()
active = models.BooleanField(default=True, editable=False)
C[:, :, (0), (0)] = a[:-1, :-1]
m[i] = int(row[0]), int(row[1])
arry.append(-1)
a = [1, 0, 0, 2, 0]
print(L)
s.connect((host, int(port)))
[argv[i] for i in range(start, argc.value)]
df2
response
print(datetime.datetime.now())
x[0]
L = [1, 2]
self.dataobj = dataobj
name, extension = os.path.splitext(self.file.name)
aux = matriz[:]
foo = df.groupby(level=0).mean()
serializer_class = EstablecimientoSerializer
-Evan
fields
p[:i] + [l[0]] + p[i:]
d = pd.DataFrame(randint(1, 10, (n_rows, 8)))
print(repr(process_line(line).strip()))
list2 = np.zeros(len(lis))
i += 1
attrnames.append(name)
min_distance = min(min_distance, distance(p0, p1))
SSL_CTX_set_options(ctx, flags)
abc = myFunction
response
b.int
ii = np.where(a[:, (0)] - b.reshape(-1, 1) == 0)[1]
doctest.testmod()
(person for person in self.__pList if person.match(**kwargs))
df_l.append(pandas.DataFrame([val], index=MI))
sess = tf.Session()
Page.objects.public()
plt.show()
2 * 11 - (2 + 10)
dna.lstrip(string.uppercase)
doc.close()
dict[1] = a[0]
settings.INSTALLED_APPS += app_name,
plt.yticks(list(range(nrows)), row_labels)
B = np.zeros(A.size)
self.text.append(data)
next(next_lines)
img = Image.open(imlist[i])
x = [x]
print(ax.get_xticks())
self.func = func
f1.close()
item
m.groups()
arr = coo_matrix((data_f, (row_f, col_f)), df.shape, dtype=np.float64)
np.random.seed(1)
cnxn = pyodbc.connect(databasez)
False
a + b
arr.append(inner)
s2 = pd.Series(new_items)
result = np.reshape(result, (chunk_length, channels))
L[i] = result
result = MyTask.AsyncResult(task_id)
date = datetime.strptime(date_string, fmt).replace(tzinfo=tzinfo)
round(2.500000001)
pid = os.fork()
coll = db.test_collection
df = pd.read_csv(filename[0])
keyPub = RSA.importKey(keyDER)
print(df)
q.put([list(range(200)) for j in range(100)])
createIndex(sourceIndex.row() + 1, sourceIndex.column())
print(value)
a = Foo()
body = f.read()
print(args.foo)
parser = argparse.ArgumentParser()
pattern = np.ones(N, dtype=int)
time.sleep(4)
second_largest([10, 7, 10])
t.join()
my_dict = recursively_default_dict()
f.show()
c = getattr(cls, c)
imgray = cv2.cvtColor(aframe, cv2.COLOR_BGR2GRAY)
QAbstractTableModel.headerData(self, section, orientation, role)
print(stdout)
mem.Blit(0, 0, size[0], size[1], screen, 0, 0)
f = Foo()
image = cv2.resize(image, dim, interpolation=cv2.INTER_AREA)
circle1.destroy()
trace.text = str(a_numpy_array)
f.close()
self.a.b.c = 10
self.lda[self.tfidf[bow]]
[0, 0, 1]
0 < ------------------------------------8 < -9
myDict = defaultdict(int)
test_printFoo()
Y[..., (2)] = np.clip(np.abs(X) / absmax, 0, 1)
b[-1] = b[0] + b[1]
now - then > timedelta(days=1)
plt.scatter(x, y, c=z)
m.drawcountries()
s.getvalue()
keys = [i.strip() for i in keys]
result.extend(v * v for v in vals)
p.join()
g()
self.z = z
Z2 = np.abs(np.cos(2 * Y ** 2 + X ** 2))
remove_common(x, y)
1 - 1
last = MyModel.objects.count() - 1
sigma = np.matrix([[20, 10, 10], [10, 25, 1], [10, 1, 50]])
ax = fg.add_subplot(1, 1, 1)
scores.append(subcheckio(nstones, left, rite + stones[0]))
plt.title(date)
Image.open(strio)
raise ndb.Return(True)
df
[(letter, matches.count(letter)) for letter in letters]
dill.dumps(f)
self.rect = Rectangle()
parser.print_help()
f(2, range(5))
pprint(get_info(soup.li))
self._rooms.clear()
x, y, z = np.ogrid[-10:10:20j, -10:10:20j, -10:10:20j]
a = []
self.value = value
1 - 10
{{form.content}}
{{form.as_p}}
a = []
linecache.clearcache()
-betaln(1 + n - k, 1 + k) - np.log(n + 1)
matches = tokens[1::2]
a_label.pack()
print_tree(tree)
self.response = app.get(*args, **kw)
print(type((1,)))
print(s.strip())
p = Popen(shlex.split(job), stdout=PIPE)
self.wordList = list(wordList)
print(f.read())
[(x + (z.get(x[0]),)) for x in l]
foo(A(), B())
list_size_2 = []
p.map(f, itertools.chain(((0, x) for x in females), ((1, x) for x in males)))
formfield.queryset = Cars.objects.filter(owner=person)
b = a.copy()
np.count_nonzero(np.eye(4))
table.style = style
classifier.predict(datum)
prodmap[:] = np.memmap.dot(xmap, ymap)
plt.plot(a)
Qt / QtGui / __init__.py
df
foo().wrong
interpreter.process_page(page)
vbox.addWidget(linetext)
x - x.mean(axis)
mask = np.ones(a.size, dtype=bool)
c = np.array([np.linspace(i, j, 12) for i, j in zip(a, b)])
print_ephemeris_for_month(year, month, bodies)
row = array([0, 0, 1, 2, 2, 2])
d.rectangle([(80, 0), (150, 20)], fill=(220, 0, 0))
True
logger.addHandler(gm)
x = np.sin(angle)
df
w.setEditable(True)
app = wx.App(False)
soup.contents[0].name
result = func(*args)
print(bar.a)
form
mynums = [int(i) for i in s.split()]
input_with_timeout(5)
q = Comment.query.filter(any_(11, Comment.path))
sample_func()
self.map.key
z1.namelist()
r < -raster(mat, xmn=0, xmx=n, ymn=0, ymx=m)
print(n)
shuffle(x)
M = max(max(x) for x in list(foo.values())) + 1
m.drawcoastlines()
print(item)
generate([list(range(1, 11)), list(range(10, 21))], 100)
my_dictionary = json.loads(args.my_dict)
paths[T]
self.assertTrue(user.username == iunicode(testuser.upper()))
iter(x)
datetime.datetime.utcfromtimestamp(u)
{0, 0, 0, 0, 0, 0, 0}
b[-2] += [10]
inverted_dict.add(actor)
self.store.save()
data = urllib.parse.urlencode(forms, doseq=True)
print(df)
xx, yy = np.meshgrid(np.linspace(-7, 7, 500), np.linspace(-7, 7, 500))
print(np.asarray(testdataset).shape)
pylab.plot(tst_xdata, tst_ydata)
df = df.convert_objects(convert_numeric=True)
out = out.reset_index()
process_b.start()
print(file.character_count())
row = dict((name_map[name], val) for name, val in row.items())
bytes is str
c = BinominalCoefficient(2 * n, n)
tags = django.forms.CharField(required=True)
session.add(obj1)
print(A.shape)
sock = socket(AF_INET, SOCK_STREAM)
s.close()
lock.release()
os._exit(0)
parser.print_help()
df
indices = np.nonzero(X)
cursor = self.conn.cursor()
my_list = []
f.write(data)
gmpy2.isqrt((10 ** 100 + 1) ** 2 - 1)
d[key].append(word)
holes.append((int((x1 + x2) / 2), int((y1 + y2) / 2)))
self._observers = []
b = numpy.array([conv[x] for x in a], dtype=numpy.uint8)
self._insert(bisect.bisect_left(self, value), value)
tree.printTree()
m = numpy.swapaxes(m, 2, axis)
exec_globals.update(frame.f_globals)
PyObject_HEAD_INIT(NULL)
created = models.DateTimeField(auto_now_add=True)
x = [65] * 9999999
name = traceback.tb_frame.f_code.co_name
[list(permutations(grp.index)) for name, grp in age]
self.RUNNING = JOBSTATE_RUNNING
self.FINISHED = JOBSTATE_FINISHED
proc.wait()
file.seek(position, 0)
Py_XDECREF(pFunc)
self.test_panel.SetSizer(self.panel_sizer)
x = kbfunc()
reader = csv.reader(csvfile, dialect)
m.drawstates()
utc_date = date(2008, 1, 1)
test()
instance.is_initialized = True
i += 1
ax = plt.subplot(111)
close(father2child_pipefd[1])
triplets[iT].append(listB[iB + 1])
pool = multiprocessing.pool(args)
f, ax = plt.subplots(figsize=(7, 7))
list.append(calc)
s = pd.Series(test)
dates = [nextdate(i) for i in range(value)]
x = []
Z = tf.pow(Z, 2.0)
stdout.write(beeString)
[[x] for x in seqs[0]]
offset = values[0][1] - datetime.fromtimestamp(values[0][0] * factor)
exec(pyCode, global_namespace, lobaca_namespace)
x = np.arange(0, 10)
m_list
self.bind(a=self.set_c)
sizes = np.concatenate(([0], np.cumsum(sizes)))
x = np.linspace(0, 50, 100)
i < len(self._list) and self._list[i][0] == k
proxy.ProxyRequest.process(self)
cache[args]
c = np.random.randint(m, size=k)
num = int(line)
p.start()
raise StopIteration()
self.map = {}
code_obj.co_stacksize, code_obj.co_flags, code_obj.co_code
plt.figure(dpi=dpi)
print(sub_k_list(a, k))
df_dict[col_index[j]].append(cell.value)
sorted_dict = SortedDict(**unsorted_dict)
isinstance(Ham1(), Ham2)
results = Result.objects.all()
L.append(a)
self.rtype = rtype
INSTALLED_APPS += ()
n -= 1
CONVERSION_DICT[source](temp)
s[start:end]
points_unique[:, (0)], points_unique[:, (1)]
ax.set_xlim(xmin, xmax)
fhandle.seek(0)
print(n)
print(k, mydict[k])
print(a[2, 1])
left = a[max(0, index - num_neighbor):index]
0 - 0
sorted(ordered(x) for x in obj)
overlap(0, 50, 0, 50)
new_stepListA.extend([pathList[n][1], pathList[n][2]])
print(L)
logger_1.addHandler(hdlr_1)
b = (a[..., (np.newaxis)] > np.arange(n)).astype(int)
processor.start()
res.append(arr)
readline.set_pre_input_hook(rl_autoindent)
conn.set_debuglevel(False)
body = json.loads(request.content.read())
max_depth.update({i: find_depth(dep, MyDict[i])})
matplotlib.rcsetup.validate_backend(name)
main(*sys.argv[1:])
frame = inspect.currentframe()
mutex.acquire()
sys.exit(1)
[2, 2, 1]
result = []
y = np.array([int(i[0]) for i in data])
f + f
get_all_object_keys(bucket, prefix, last_key, keys)
arr = numpy.array(list(itertools.zip_longest(fillvalue=numpy.nan, *lst)))
now = datetime.datetime.now()
ts2[0] = 99
plt.xticks(indexes + width * 0.5, labels)
parts_dict, list_of_parts
os.getcwd()
self.assertEqual(handler.request.recv.call_args[0], 1024)
result = defaultdict(list)
self._locals
bodylist.append([edge[0], edge[1]])
foo = models.ForeignKey(Foo)
self.sum = 0
print(string_set(string_list))
result.get()
print(x, y, z)
cls._instances.append(instance)
filterfalse(pred, t1), list(filter(pred, t2))
self.table.setHorizontalHeader(HeaderView(self.table))
B[0, 0]
self._format(object.foo, stream, indent, allowance + 1, context, level)
self.adjacencyList = []
Repeat.count += 1
vbox1.addWidget(self.button)
np.hstack((vector1[:, (np.newaxis)], matrix2))
self.fp.write(zinfo.FileHeader())
writer.writerow(payload)
f(**args)
deletemylist
f.close()
root.withdraw()
ax.set_xlim(x_min, x_max)
cast(v.vendorName, c_char_p).value[7]
loop.run_until_complete(asyncio.wait(tasks))
fig.subplots_adjust(hspace=0)
print(df)
g.write(new_entry)
indptr = np.zeros((2,), dtype=np.intp)
print(line)
serializer_class = UserSerializer
self.assertEqual(12 * 12, 144)
x = np.arange(0, n * len(A), n)
body = response.read()
w
t.seek(0)
m[0][0] * m[1][1] - m[0][1] * m[1][0]
security.insert(usernametoken)
byweekday = (TU, WE),
self.name.lower()
chunk = f.read()
start, end = L[0], L[-1]
lines = text_file.readline()
t = type(x)
fn(*args, **kwargs)
pool = multiprocessing.Pool(processes=pool_size, maxtasksperchild=4)
out[mask] = np.concatenate(L).ravel()
heapq.nlargest(2, x)
print(repr(m_float))
print(isPower(1, 1))
greet_self()
DistutilsInstall.run(self)
ax.set_ylim(ymin, ymax)
d1 = pd.concat([df.loc[[1]].rename(index={(1): 0}), df])
self.size -= 1
l = threading.Lock()
np.count_nonzero(y == 2)
x = np.random.rand(50)
[4, 4]
best[n][1]
bk.show(p)
print(c.Pear)
print(c.Fish)
self.canvas.move(oid, dx, dy)
cPickle.dump(root.config(), f, -1)
f2()
c = np.dstack([r, g, b])
r1 = Range(start=date(2016, 1, 1), end=date(2016, 2, 5))
cr.fill_preserve()
count = 0
A[i], A[j] = A[j], A[i]
y = np.array([2, 4, 6])
self.popitem()
merged = merge(string1.lower(), string2.lower())
y = np.sin(x) + np.random.random(100) * 0.2
[0, 1, 0],
Test().__init__
dec
np.linalg.matrix_rank(b)
GPIO.setup(7, GPIO.IN, pull_up_down=GPIO.PUD_DOWN)
dic = dict((x, 0) for x in lis)
df
df_out = pivoted.cumsum() + (pivoted == -1)
print(res)
z = eval(y)
df = pd.read_json(json.dumps(dictionary_example)).T
t.daemon = True
fig = plt.figure()
shutil.rmtree(tempdir)
array = np.tile(np.arange(1, 4), (N, 1))
f2 = lambda x: np.dot(x, P) - 760
all(i > 10 for i in range(19))
pylab.grid(True)
res = defaultdict(lambda : defaultdict(lambda : defaultdict(list)))
self.name = name
self._buf += next(self._file).strip()
self.qux()
print(response)
float(n) / 1 << n.bit_length() - 1
column.append(row[key])
((days * 24 + hours) * 60 + minutes) * 60 + seconds
app = wx.App()
all_rosters.append(roster[:])
pool = multiprocessing.Pool(processes=numthreads)
HttpResponse(data, **response_kwargs)
self._dict[key]
plt.plot(a)
new_string += char
print(xquery.execute())
flush()
p.close()
f
print(min(matches, key=len))
filtered = [i for i in full if not regex.search(i)]
xi = np.linspace(0, 2, 10)
timestamp = calendar.timegm(utc_dt.timetuple())
output[contig] += 1
value
loop = asyncio.get_event_loop()
parser = etree.XMLTreeBuilder()
session.flush()
sess.run(training_op, feed_dict={X: X_batch, y: y_batch})
globals()[k] = MyDict(v)
country = models.CharField(max_length=100)
gtags - f / tmp / list
self.assertEqual(user.username, testuser)
strs[ind:ind1]
min(r1.end - r2.start, r2.end - r1.start).days + 1
np.maximum.at(diam, data[:, (0)], dist_to_center)
show_all.set(True)
Node.__init__(self, identifier)
self.parent().setCursor(Qt.PointingHandCursor)
a = randint(0, 10)
splitted = my_string.split()
samples, labels = zip(*data)
img = misc.imread(fp)
new_dict = {}
self.detach_webview()
app = wx.App(False)
abclass
Nfeval += 1
User.create_table()
theta = np.arctan2(y, x)
s - set([4, 5])
s = pd.Series(t2.index.get_level_values(1), t2.index.get_level_values(0))
driver = webdriver.PhantomJS()
idx, val = s.index.get_level_values(0), s.index.get_level_values(1)
values[1] = values[:]
self._assert(cap)
old_a.f()
a = numpy.zeros(10, dtype=str)
x.subs(ordereddict.OrderedDict([(x, y), (y, z)]))
y = x.swapaxes(-1, -2)
command = os.path.abspath(command)
ax.contourf(np.random.rand(10, 10), 5, cmap=plt.cm.Oranges)
print(add2(10))
partition(X, my_relation)
f = fileinput.input(filename, inplace=1)
nlines += 1
dis.dis(foo)
show()
ax = fig.gca()
print(queue1.get())
len(self.inner) < len(other.inner)
self.mainLayout.setMargin(10)
ax = fig.add_subplot(111)
G = nx.DiGraph()
comp = wmi.WMI()
print(np.ma.compressed(m))
object_id = models.PositiveIntegerField()
os.dup2(0, 1)
[unrank(list(range(5)), 2, i) for i in range(20)]
x_train = np.array([i[1::] for i in data])
diff_idx = np.where(np.any(np.diff(sorted_arr, axis=0), 1))[0]
result.append(item)
county_colors.append(colors[idx])
time.clock()
myList = list(f)
process.start()
df
c = wmi.WMI()
xml.sax.saxutils
year = sorted(set(map(lambda x: x[0], file_contents_values)))
pool = mp.Pool()
x = np.random.randn(N)
plt.show()
exit(a)
print(new_d)
socket = context.socket(zmq.PUB)
True
figure(1)
pool.close()
lis.append(lambda : 1)
e2 = tk.Entry(self)
f.close()
platform.platform()
x = np.array([0, 1, 2])
gtk.main_iteration(False)
ws.set_panes_frozen(True)
sleep(10)
Thread(target=begin).start()
values = np.random.uniform(low=0, high=1, size=ages.shape)
print(sub.recv(zmq.NOBLOCK))
d = {tuple(i): a.count(i) for i in a}
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cj), authinfo)
(nonzero_array[:-1] * nonzero_array[1:] < 0).sum()
print(parser.format_help())
tar.addfile(info, data)
sys.exit(1)
self.numbers[-i - 1] = 0 if num == 9 else num + 1
self.c = cv2.VideoCapture(0)
res_ols.params
B = np.random.randint(k, size=(n, m))
daemon_kenny.start()
vals = np.empty(len(s))
print(lst)
output = subprocess.check_output(command_line)
xlmodule.CodeModule.AddFromString(strcode.strip())
print(len(chuck))
plt.title(title, figure=fig)
print((first, second, third))
self.Artwork = Label(self.frame, image=self.photo)
notify_another_process()
print(s)
print(a[167])
date_of_appointment = models.DateField()
Point(other.x, other.y)
plt.savefig(outputname, dpi=80)
print(screen_name(api.lookup_users(i)))
sizer = wx.BoxSizer(wx.VERTICAL)
print(content)
wavfile.write(WAVE_OUTPUT_FILENAME, RATE, result)
maxm = np.array([])
minm = np.array([])
print(Expression(4))
setattr(self, attr, val)
A.sort()
draw = ImageDraw.Draw(img)
a = np.arange(10)
self.flush()
worksheet = workbook.add_worksheet()
numbers.append(my_alphabet.index(letter))
[4, 8, 7]
my_dict = {}
data = EXIF.process_file(f)
__import__(sys.argv[1])
thread.join()
line_list = list(self.readlines())
id = db.Column(INTEGER(unsigned=True), primary_key=True)
walk(path)
app = Flask(__name__)
train_op.run()
urls.append(page.url())
opener = urllib.request.build_opener(auth_handler)
b = date(2011, 11, 17)
stdout_lines.append(line)
question.id = str(question.key().id())
A = np.zeros((5, 100))
stack[-1].append(item)
True
self.timer = QtCore.QTimer()
L = list(range(-10, 10))
colors = np.outer(0.5 + norm(shade) * 0.5, color)
d = collections.defaultdict(int)
pattern = re.compile(regex_txt, re.IGNORECASE)
window = screen.get_active_window()
queryset = Experiment.objects.all()
doit()
[0, 0, 2, 0]
worker = Worker()
lines = [span.get_text() for span in spans]
N[row_idxs[r], c] = 0
logsum += log(x)
data = f1.read(chunk)
w.join()
fh.setFormatter(formatter)
stream.truncate()
self._num_expectations = 0
GObject.threads_init()
now = datetime.now()
print(df1)
shlex.__init__(self, *args, **kwargs)
wb = excel.Workbooks.Open(doc)
print(sum(a for a in fibonacci_iter(4000000.0) if not a & 1))
thirdpartymodule_b.dosomething()
h.pop()
request = scrapy.Request(url=url, callback=callback)
response = request.execute()
transaction.commit()
serial.flushInput()
p.send(message)
foo = Foo()
fig, axes = plt.subplots(nrows=2)
True
self.test(*self.arg)
print(encoded)
arr_1 = np.array([False, False, True, True])
self.scroll.setWidgetResizable(True)
sb.palplot(sb.color_palette())
pool = Pool(4)
pattern = re.compile(format_to_re(layout))
flt = lrg[lrg == 0]
parseHTML(curRes)
cheese = make_cheese(Goat().milk())
bool(regex.match(s))
warnings.show_warning(message, category, filename, lineno, file, line)
f.readline()
figure(1)
541
cov[i, j] = calculate_value(i, j)
sizer = wx.BoxSizer(wx.VERTICAL)
False
dict.__getitem__(self, x)
y0 = y_indices.astype(np.integer)
pypreprocessor.parse()
run(app=myapp)
self.br
b = [4, 5, 6, 7]
print(choice)
ax = fig.add_subplot(2, 2, i)
print(df.query(qry))
time.sleep(24 * 60 * 60)
words = x.split()
q.put(item)
os.chdir(destination)
self.stack.pop()
wrapper_object.open()
anotherfile.isatty()
gs = gridspec.GridSpec(4, 4)
self.__class__.count += 1
d2 = {x: x for x in range(1, 6)}
print(df1)
root = tk.Tk()
print(r.cookies)
self.date = self.evaluation_id.date
end.time()
nextlevel.append(n.right)
bokeh.io.show(grid)
textview.modify_font(fontdesc)
do_it_lots()
X = np.matrix([[0, 0], [1, 0], [0, 1], [1, 1]])
do_generator_empty()
sys.exit(0)
n -= 1
img = pygame.image.load(filepath)
abstrapz([-1, 0, 1])
pylab.show()
ts = time.time()
cummax(a)
plt.ion()
client.sendPreparedMessage(preparedMessage)
self.name
handler.setFormatter(formatter)
cls.initStuff()
TextWidget.pack()
f()
your_plot.set_xticklabels(ticks)
store_to_request(request)
self.put(data)
builder.connect_signals(LoseFocusHandler())
network[x][y] = common
render_template(template, mydict=mydict)
self.A = np.asanyarray(A)
login(request, user)
list1 + list2
a > 2
df.idxmin(axis=1)
stackless.tasklet(b)()
out = np.lib.stride_tricks.as_strided(x, shape=shp, strides=(M * n, n)).ravel()
net.layers[1].blobs[0].diff.shape
out = np.empty_like(y)
test_timing()
mpl.rcParams.update(pgf_with_pdflatex)
list(partitions(s))
x * self.z
layout = QVBoxLayout(self)
print(result)
logfile.write(output)
libraries[:10]
status = models.CharField(max_length=25)
len(unequal_pos[0])
np.save(f, a)
f(*args)
np.random.seed(8)
a = list(range(10))
out.write(line)
bokeh.io.show(layout)
b = b - 1
np.any(count > 1)
connection.cursor()
print(x)
f(xv, yv)
i = int(f)
c.append(map(sub, a[i], b[i]))
Pdb(def_colors).set_trace(sys._getframe().f_back)
data = np.random.normal(mu, sigma, 10000)
self.U[:, :n] * self.d[:n]
print(keyword, x.strip()[:5])
next(i)
deleteyshape[axis]
mat1[1][i] = 1
Node.__init__(self, identifier)
print(lt_obj.get_text())
self.doSomething(Notification)
pygame.mixer.music.load(wav_path)
self.dict[self.first]
print(df.dtypes)
x = (i for i in range(10))
data = socket.gethostbyname_ex(d)
T = tri.Triangulation(x, y)
ax1 = plt.subplot(gs[1], sharey=ax0)
print(len(zero_crossings2))
max(i.arity() for i in s)
root.grid_columnconfigure(2, weight=1)
-Flask - Testing
self.toolbar = self.CreateToolBar()
width, height = img_padded.size
func1(gen1)
[lambda : 2][0]()
line_count = 0
f.write(line)
replchars[i] = replchars[i].upper()
prod(list)
self.__dict__[attr_name]
pp.show()
addresses = [address.strip() for address in addresses]
A = Matrix([[5, 6], [7, 9]])
attachment = msg.get_payload()[1]
http_server.listen(8888)
self.src.append([item])
self.save_object(related_item)
lines[-1] += segment
soup = BeautifulSoup(response.body)
raise IndexError()
self.__ntrue
ax.set_xlim(0, 9)
cj
lst.append(sp.Eq(i, j))
app = Flask(__name__)
self.data[self.start + idx]
self.window.set_border_width(10)
print(Foo.objects.in_a_number_order())
tkmc.set_timeout(timeoutSp)
old_settings = termios.tcgetattr(fd)
a
preallocate_file(fn, size)
201112
iter(lookup.items())
x = 10 * np.random.normal(mu, sigma, 5000)
print(merge(d1, d2))
show()
x = np.arange(100).reshape(10, 10)
print(b)
{{body}}
coords = nx.spring_layout(G)
lines.set_facecolors(cm.jet(np.random.rand(1)))
self.df.log(request, self.spider)
result = [s + timedelta(days=(calendar.FRIDAY - s.weekday()) % 7)]
words = s.split()
a, b, c = myfunc()
self.layoutVertical.addWidget(self.canvas)
conn.sendmail(fromaddr, toaddrs, msg.format(txt))
atexit.register(exit_handler)
b = a
a, b = b, a
rs = [grequests.get(url, hooks=dict(args=print_url)) for url in urls]
y = [0, 0, 0]
self.func, self.args = func, args
self.iterator
s.into_raw()
self.wfile.write(message)
l.sort(key=alphanum_key)
im.size
lines.append(line.strip())
signal.signal(signal.SIGINT, signal.SIG_DFL)
href
to_modify[index] = replacement
ra.append(float(line.split()[0]))
False
df[start:end]
vote.delete()
os.setuid(471)
dict(zip(p[:100], p[100:]))
random.sample(WeightedPopulation(population, weights), k)
df.index[-1] + pd.offsets.MonthEnd(0)
self.restart_celery()
foo.error
re.sub(r, replacer, string)
result = dict()
print(c)
averages = [([k] + [(sum(x) / len(v)) for x in zip(*v)]) for k, v in list(d.items())]
[1]
self.worker.moveToThread(self.thread)
show()
rv = self.next_chunk[:n]
filesystem.GetFileAttributes(filepath).hidden
ind = np.indices(myarray.shape)[0]
self.axes.hold(False)
sum((ea - eb) ** 2 for ea, eb in zip(ka, kb))
work.join()
total += ampl * math.cos(cosarg * math.pi / 180)
ff = [functools.partial(lambda i: i, x) for x in range(100)]
self._compare(other, segment=-1)
sign *= np.multiply.reduce(d / absd, axis=1)
c.update(set(v))
foo_noniterable(thing)
points = np.hstack((p1, p2, a, b))
DataFrame(self.model.predict(X))
soup = BeautifulSoup(source_code)
b.burn(library, lighter)
results.append(option)
obj
soup = BeautifulSoup.BeautifulSoup(content)
f_old.seek(0)
items = [i.strip() for i in items]
pool = multiprocessing.Pool(1)
max(v1 - v0 for v0, v1 in zip(values[:-1], values[1:]))
int(gmpy2.mpz(12))
Application().Run(MyWindow())
data_dict = json.loads(data)
sys.exit(4)
copy_file(src, self.target_dir)
setattr(self, key, value)
plt.xticks(list(range(width)), alphabet[:width])
f.seek(0)
im = im.crop((left, top, right, bottom))
n_samples += int(self.smooth_idf)
dt + (datetime.min - dt) % delta
next(gen())
result.append(buff)
self.host = host
print(repr(e))
[-2.0, 0.0, -2.0, 2.0, 10.0, 4.0]
loop.run_until_complete(example())
k.open()
r1 = conn.getresponse()
time.sleep(0.1)
n2 = np.random.random(N)
self.username
ax.bar(pos, vals, width=width, label=cond, color=cm.Accent(float(i) / n))
match.index[0]
df.T
can.save()
str(digit)
output = []
c += 1
fig, ax = plt.subplots(1, 1)
old_settings = termios.tcgetattr(sys.stdin)
clipboard.SetText(data)
module1.Relay(GPIO)
l += 1
server.bind((host, port))
dictionary[parts[0]] += 1
dd[v].append(k)
argsdict[arg].append(val)
Base.metadata = metadata
print(len(allkitties))
show(p)
N = int(sys.argv[1])
zip(a, b)
self._ref2 = ref2
self.my_setting = my_setting
Y.__init__(self)
a = A()
matches.append([value, values[x]])
layout.addWidget(button)
dmin = len(trans[0])
df
sys.stdout.writelines(merge(key=second_column, *sorted_files))
process.poll()
[]
yaml.load(_)
fh.flush()
{NULL, NULL}
YourObject.id.generation_time
session = sessionmaker(bind=engine)()
self.tag = tag
sleep(0.1)
df.dot(s)
file1.write(toFile)
o = Observable()
client_sock.close()
two_d[np.ix_(first, second)]
[1, 1, 1]
count += 1
diag = np.arange(M.shape[1])
[a, b]
i += 1
tidx + pd.Timedelta(days=15)
timeit(lambda : list(fulldict.keys()))
self.current - 1
L = Linitial
replace(l, 1, 7)
os.remove(new)
m.add(k, dict1.get(k))
d1[1]
parser = argparse.ArgumentParser()
self.__keys.append(key)
X.toarray()
b[a[:, (0)], a[:, (1)]] = 10
b = np.random.normal(0, 1, (N, M)).mean(axis=1)
print(sheet[0][0])
df.value1 = df.value1.round()
dis.dis(a)
fh.write(str(buf))
screen.blit(draw_me, backdrop)
average = total / count
sum
fig.subplots_adjust(hspace=0, wspace=0, top=0.925, left=0.1)
pprint(d)
df
tksupport.install(root)
sys.path.insert(0, mysite)
hours = df_energy2.index.hour
img1 = cv2.imread(fn1, 0)
picklable.append((r, p, code))
self.s_in.close()
print(t, expr.parseString(t).asList())
a.x
lists = sorted([sorted(x) for x in lists])
print(i)
h1 & 4294967295
st.norm.interval(0.95, loc=np.mean(a), scale=st.sem(a))
X = np.ones((n, 2))
print(p.mass, p.position, p.velocity, p.force)
proc.start()
clf.fit(X.iloc[(train_idx), :], y[train_idx])
groups = list(groups)
print(self.bar)
start_time = timeit.default_timer()
actcount += 1
d = {key: a.rx2(key)[0] for key in a.names}
python - i
output = p.communicate()
results.append(result)
p.communicate()
print(ET.fixtag(some_node.tag, NS_MAP))
cookies = requests.utils.cookiejar_from_dict(pickle.load(f))
child = pexpect.spawn(ssh_cmd, timeout=timeout)
id = Column(Integer, primary_key=True)
sparse + 0.228869672266
fig = plt.figure()
self.fed.append(d)
eventloop.run_forever()
f(x) ** 2
a = [(lambda : i) for i in range(5)]
str(self.value)
print(mat.A)
a += b
my_mesh.BeginPolygon()
process = sp.Popen(shlex.split(cmdline), stdout=sp.PIPE, stderr=sp.PIPE)
os.makedirs(dirmk)
d = collections.defaultdict(dict)
outcsv.writerow(x[0] for x in cursor.description)
cmd.append(command)
axes = fig.add_axes([0.1, 0.1, 0.8, 0.8])
clf = AdaBoostClassifier(n_estimators=2)
ipython - noconfirm_exit
loop.run_until_complete(main())
print(parser.print_help())
A2[mask] = 0
res = urllib.request.urlopen(req)
a = [4, 5, 0, 0, 6, 7, 0, 1, 0, 5]
lines = f.readlines()
seq[start], seq[end - 1] = seq[end - 1], seq[start]
random.shuffle(sequence_containing_z_vals)
tree = chunker.parse(postoks)
get_color(0.7)
q = int(a / b)
open_file.close()
content = f.read()
multiprocessing.Process.__init__(self)
keys.append((h, r))
sys.getsizeof({})
print(pd.factorize(np.hstack(df.values)))
[babel.extractors]
L = Linitial[:]
self.root = tk.Tk()
Py_Initialize()
my_view
raise StopIteration
pylab.grid(True)
frame = bytearray()
line = plt.plot(list(range(10)))
np.random.seed(1)
self.errors = errors
sys.path.insert(0, project_dir)
z = (df != 0) * 1
bool(p)
a[0] = 7
[flake8]
print(s)
request = urllib.request.Request(my_url, data)
context = cairo.Context(surface)
(i & (1 << length - 1) - 1) << 1 | i >> length - 1
thedir = sys.argv[1]
print(x)
d = defaultdict(int)
data = [tuple(x) for x in frame.values]
print(IOB_to_tree(sentence))
A.__init__(self)
y()
self.sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
len(self.data)
test_func()
request.response.headerlist.extend(headers)
cv2.putText(out, string, (x, y + h), 0, 1, (0, 255, 0))
ranges.pop(0)
idx = c.index((1, 4))
a = math.cos(theta / 2.0)
result = {}
output = StringIO.StringIO()
1, 0, 1
f = figure(figsize=(6.2, 5.6))
ret.append((point[0], point[1] - 2 * (point[1] - BOTTOM_LEFT[1])))
self.q = Queue(1)
draw.text((5, 0), title, font=font, fill=(0, 0, 0))
ax.set_yticks([])
cache = Cache()
db.run_in_transaction(_tx)
fig = plt.figure()
drvs
cv.WriteFrame(writer, frame)
lambda x: a * x + b
base_close += timedelta(days=1)
mouseclickdn(60, 100)
queue = collections.OrderedDict((key, queue[key]) for key in keys)
type(xml.__loader__) in CUSTOM_LOADERS
xs, ys = np.meshgrid(x, y)
np.sum(np.abs(x - y) > 1)
gene = this_re.group(1)
self.view.setSortingEnabled(True)
next(b)
layout = QtGui.QHBoxLayout()
parser.config_files.extend(values)
y = np.arange(len(x))
spl = [func(x) for x in inputText.split()]
instance.app.amqp.queues.select_add(queue)
output += cssin.read()
print(pruned)
y = np.linspace(0, 100, 100)
writer = csv.writer(fl)
print(b, repr(b))
print(list(generator_overlap_split_list(l, s)))
mySocket.connect((SERVER_IP, PORT_NUMBER))
print(response.read())
f(kw)
qry = session.query(Parent)
diff = np.diff(a, axis=0)
self.wrong_values = []
method = getattr(self.data, name)
datetime.datetime.strptime(s_date, pattern).date()
[4, 2, 9]
print([toHex(x) for x in numbers])
print(value)
out = merge(left, right)
print(gen_hex_colour_code())
parent = Parent()
args = parser.parse_args()
urlretrieve(image_url, outpath)
xml_dict(childnode, name, dic)
index = np.searchsorted(data, values)
print(s)
dwg.save()
ax1 = np.histogram2d(x_data, y_data, bins=bins)
b = set([9, 7, 6, 5, 1, 0])
sum_a[i] += x
l_y.append(s[-1])
list1 = [[-2.0, 0.0, -2.0, 2.0, 10.0, 2.0], [-1.0, 0.0, 2.0, 1.0, 5.0, 4.0]]
find_intersect(x_down, y_down, x_up, y_up)
Deidre
Felicity
Harriet
Craig
Greg
Edward
Andrew
numbers = sum(c.isdigit() for c in s)
sudokupossibilities[1][1][1] = 2
predicted = classifier.predict(X_test)
[7, 2, 6]
fig, axes = plt.subplots(1, len(df.columns))
pow(2, 2)
LR_Multi.fit(X_stack[:, :half], y_stack[:, :half])
do_something_with(line)
print(i)
print(bool(Something()))
theta %= 2 * np.pi
print(x.format(42))
f.write(s)
ax = plt.gca()
xyz = [0, 12, 4, 6, 242, 7, 9]
t()
fig = plt.figure()
python - V
net.layers[1].blobs[0].data.shape
humansize(1049)
groups[groupcol].add(col)
self.obj[frozenset((idx,))]
myseries_three.loc[0:2]
self.inspector.setPage(self.view.page())
tri = qhull.Delaunay(xyz)
print(team([1, 1, 50, 50, 50, 1000]))
label_height, label_standoff, label_text_align, label_text_alpha
setterific(larry) == setterific(moe)
a = numpy.arange(1, 15)
zip_longest(fillvalue=fillvalue, *args)
frame = Tkinter.Frame(root)
a
x[1][2]
soup = BeautifulSoup(str(content))
sleep(time)
raise ImportError(msg)
attr(*args, **kwargs)
__all__ = []
DEDENT
f.close()
next(reader)
b = np.array([1, 2, np.NaN])
ax2.xaxis.set_major_formatter(FuncFormatter(fmt_zToEta))
console_handler = logging.StreamHandler()
app = create_app(logger)
threading.Thread(target=show_progress_B, args=(win,)).start()
df
decimal.Decimal(-1200)
PyArray_Descr * descr
stream.render(out=f)
Xc.setdiag(0)
l[0]
s = requests.Session()
print(config_root.log_file)
plt.colorbar(im)
c = Counter(elem[0] for elem in list1)
minm = argrelextrema(y, np.less)
print(itteration)
m1 += np.bincount(a + m.shape[1] * b, minlength=m1.size)
itertools.cycle.__init__(self, self._iterable)
[0, 1, 0]
(4, 1)(4, 1)
most_frequent(y for x, y in Ns[:self.k])
round(f)
df
word_counts
good.append([m])
plt.scatter(roc_x, roc_y)
view.setRootIndex(model.index(QDir.homePath()))
response = opener.open(request)
pstack.append(i)
newlist.append([val])
Base * get_base()
print(dsum(x, y))
arr = [[[(i + j + k) for i in range(5)] for j in range(5)] for k in range(5)]
HOST = socket.gethostbyname(socket.gethostname())
l = [list(g) for k, g in groupby(x, lambda x: x.isalpha())]
_to_etree(e, ET.SubElement(root, k))
rpath = rpath[4:]
module = new_module(name)
df1 = df1.stack()
self.fig = f
l = l[1:]
self.button.customContextMenuRequested.connect(self.on_context_menu)
view.setModel(model)
print(key, mydict[key])
colormap.SetHueRange(0.667, 0.0)
context[self.attr_name]
f.write(bitbuf)
com.open()
widget.set_size_request(200, 200)
data.shape
seaborn.set()
pygame.draw.rect(windowSurface, self.color, self.rect)
df
foo.set_a_to_three(globals(), locals())
rdd = sparkdf.rdd.zip(new_col).map(process)
im = Image.open(image_io)
HAVE_CYTHON = False
plt.xlim(0, 8000)
print(b.text)
user = oauth.get_current_user(scope)
pylab.ion()
flat_for(a, lambda x: x + 5)
user = User.objects.get(email=email)
[-1, -1, -1, -1, -1]
np.save(f, b)
number % 2 != 0
foo()
self.data = str
CELL_LIST.append(Cell(v == 1, x, y))
ax = plt.subplot(111)
callable(object) == True
e[0]
obj[key] = mod.__dict__[key]
b = list(a + i for i in range(10))
b[:] = 0
self._name = name
m, n = len(seq) + 1, len(sub) + 1
path = str(path, sys.getfilesystemencoding())
w = wmi.WMI()
self.db = db
fmstr.format(*args)
easy_csv.append([row_preprocessed])
[(splt[0], splt[1]) for s in strings for splt in [s.split()]]
f.write(output_from_parsed_template)
primeList.append(num)
7, 8, 9
counts[name] += 1
a = object()
traceback.print_exc()
x = np.eye(2)
a, _, _ = numbers()
mask[indices] = False
PQRGQQGTSQEGEQKLQNILEIAPRKASSQPGRFCPFHSLAQGATSPSRKDTMSTESMIRDVELAEEALPQKMGGFQNSRRCLCLSLFSFLLVAGATTLFCLLNFGVIGPQRDEKFPNGLPLISSMAQTLTLRSSSQNSSDKPVAHVVANHQVEEQLEWLSQRANALLANGMDLKDNQLVVPADGLYLVYSQVLFKGQGCPDYVLLTHTVSRFAISYQEKVNLLSAVKSPCPKDTPEGAELKPWYEPIYLGGVFQLEKGDQLSAEVNLPKYLDFAESGQVYFGVIAL * REWVFIHSLPSPHSDPFTLTPLLSTPQSPQSVSF * LRKGIMAQGPTLCSELSTTTQKHKMLGQ * PGLWASHAPPSRTQMGFPNSLEPRMSIPEFCKGRVVRLPLSQNEAG * DLRPSYLQTFPDSSLRCNAQPSSQSQPPSIYICTYYLLFIYYLFICL * MYLFGRPGCPGGPSVGSCLQTDMFSVKTELSCPHLASLPCCLLFCLCLKQNIYLTQLS ** R * FGDQAVATSLNLCSPREP * L * SPYGSLREI
indexes[i] = reference[data[i]]
df.index.dtype
x = 2
os.startfile(command[myIraw_inputput][1])
self.trell.append([word, copy.deepcopy(temp)])
element.tag
p.start()
a = tf.Variable(init_a)
table[0]
data = np.genfromtxt(f, usecols=list(range(5, num_cols)))
2
licenses.add(get_plate())
self.my_table.insert(dict(item))
s.add(2)
loop.run_forever()
wrapper
o.date = datetime(2012, 4, 15, 1, 0, 2)
False
[data[b:e] for b, e in [(spl[i - 1], spl[i]) for i in range(1, len(spl))]]
dsp.setparameters(AFMT_S16_NE, nc, fr)
x = data[:, (0)]
AB = [(A[i] + B[i]) for i in range(min(len(A), len(B)))]
{{YOUR_CUSTOM_SETTING}}
zlib.decompress(strobj, 15 + 16)
ret.insert(0, r)
f.read()
plt.hist(data, 50)
np.uint64
chart_toolbar.SetSize(wx.Size(fw, th))
b[0]
SIGN_CHARACTER + num_encode(-n)
fn.__dict__.update(f.__dict__)
plt.show()
counts.update_point(r, 1)
DEBUG = True
print(self.a * self.b * self.c)
self.socket.listen(128)
blobs = BlobInfo.all().fetch(500)
s = pd.Series([np.NaN, np.NaN, 1.0])
writer = csv.writer(foutput)
index = bisect([i.lower() for i in my_list], insert_string.lower())
app_log.removeHandler(hdlr)
items = collections.defaultdict(list)
True, s[2:]
print(args)
np.where(data[:, (1)] == yr + 72)
print(data)
print(row[1])
server.close()
start = dt.datetime.now()
foo.bars = [1, 2]
df
plt.show()
main_loop = tornado.ioloop.IOLoop.instance()
win.show_all()
bcut.on_clicked(_yes)
length = len(list1)
indices.sort(axis=axis)
self.a = a
f1.close()
print(df)
self.wfile.flush()
session.add(prod)
a = np.rint(x)
d.clear()
PROJECT_PATH = os.path.realpath(os.path.dirname(__file__))
A2 = np.random.randint(-4, 10, size=(100000, 100))
True
ZZ.old_poly_ring(x).ideal(x ** 2 + 1)
mask = np.tile(np.any(im, axis=0), (2,))
the_files.append(target_file_name)
x = int(x)
ret.append((point[0] - 2 * (point[0] - BOTTOM_LEFT[0]), point[1]))
self.widget.see(END)
app.quit()
fn
list(a)
group = list(group)
k, v = s.split()
a = np.random.randint(0, 100, 100000)
time.sleep(SECONDS)
odd.append(num)
a = df.t.values
fh.level = logging.WARNING
print(row)
self.render_to_response(context)
sys.exc_info()[1]
number = int(eval(input()))
do_some_stuff(k, v)
fitfunc = lambda params, x: params[0] * x
self.data[dataKey].remove(item)
PCO_api.PCO_OpenCamera(ctypes.byref(camera_handle), 0)
np.array(list(itertools.zip_longest(fillvalue=0, *v))).T
count += 1
d = np.empty(n)
tree = etree.HTML(doc)
name[0][0]
btn.Bind(wx.EVT_BUTTON, self._onShowHelp)
fig = Figure()
client = oauth.Client(consumer)
suite = indentedBlock(stmt, indentstack, True)
mydict[index] = +1
mw.ui.plotWidget.setGeometry(1, 1, s.width() - 2, s.height() - 2)
functools.update_wrapper(wrapper, fn[0])
obj.b()
is_new_style_class(int)
nodes.append(Node(ndx[k], []))
J = sparse.coo_matrix((np.ones_like(ixs, int), (np.zeros_like(ixs, int), ixs)))
fig, ax = plt.subplots()
m1.create_all(conn)
random_array = np.array(random_array, dtype=np.uint8)
raise sqlalchemy.exc.DisconnectionError
weeks.count()
d1[start:end].value_counts().index[0]
x[1, 0, 2]
hash(self.item1) * hash(self.item2)
G.add_edges_from(megalist)
row = next(itertools.islice(csv.reader(f), row_number, row_number + 1))
cj = cookielib.CookieJar()
first_list = [1, 2, 2, 5]
user = User()
print(df_expanded)
ax.w_xaxis.line.set_color((1.0, 1.0, 1.0, 0.0))
pygame.quit()
number = eval(input())
1, 1, 0
o_func1()
set([t.id for t in prerequisites_complete]) == set([a.id, b.id])
new_lock.acquire()
abspath = os.path.join(dirpath, f)
_PIDS.append(pid)
print(f)
self._inner.insert(index, item)
w.wcs_pix2world(100.0, 100.0, 1)
value_to_key[v].append(k)
len(bin(1000)) - 2
do_something_with(line)
l[:] = (i for i in l if counts[i] == 1)
a.sort(reverse=True)
ipaddress.ip_address(str)
wnd.show_all()
data = Column(String)
print(d.pop(min(d, key=d.get)))
y = np.add.accumulate(x)
ax2 = np.histogram2d(x_data, z_data, bins=bins)
self.session.query(self.model).filter(self.model.paid == True)
DF.columns = DataFrame(np.matrix(cursor.description))[0]
db.create_all()
app.exec_()
splitS.append(s[start + 1:end])
self.subframe.Close()
fig, ax = plt.subplots()
self.b.follow_link(link)
float(n_ab) / (n_a + n_b - n_ab)
opener = urllib.request.build_opener(auth_handler)
plt.subplot(2, 1, 2)
data = json.load(infile)
idx = a.cumsum()
time.sleep(1)
fig, ax = plt.subplots()
diff[key] = merge(lhs[key], rhs[key])
f(*[v for _, v in sorted(newdict.items())])
show(fig)
a = [1, 2, 5, 1, 6]
Ihmf = (Ihmf - np.min(Ihmf)) / (np.max(Ihmf) - np.min(Ihmf))
fig.add_subplot(axes=self.traceax)
parent_map = dict((c, p) for p in tree.getiterator() for c in p)
d = collections.defaultdict(list)
dict_out[key] = value
d.dtype.names
s.value_counts()
self.smtp.close()
print(x.format(42))
g(*args)
raise NotImplementedError()
Py_Initialize()
tokens = nltk.word_tokenize(text)
fig = pyplot.figure()
print(list(squares(4, 16)))
results = zip([x[0] for x in results], smoothed)
words += len(wordslist)
parse.py
self.__fpointer
a = a[::-1]
str(self.author)
fig, ax = plt.subplots()
isinstance(value, CheckboxInput)
x += N
array([10, 14, 15, 56]),
original_rows = [[1, 0, 1], [0, 0, 0], [1, 0, 0]]
state = models.CharField(max_length=25)
b = np.array([4, 5])
row.append(DataReader[j])
writeFileObject.close()
(1 << x) - 1
func()
num = 9
a1_edit.textChanged.connect(lambda text: self.TxtChanged(a1_edit, text))
ypos = np.searchsorted(x[xsorted], y)
self.sizer.Add(self.button, (2, 0), (1, 2), flag=wx.EXPAND)
self.log_queue.append(self.format(record))
print(name)
print(args_values)
scores.append(subcheckio(nstones, left + stones[0], rite))
signal.signal(signal.SIGTERM, term)
retstr.close()
print(x, y, x * y)
ax.set_xticks(ind + width)
instance.save()
__builtins__.max
os.chdir(SCRIPT_DIR)
po.join()
random.shuffle(sequence_containing_y_vals)
print(gpsp.get_current_value())
req.write(resp.data)
beta = cov[1, 0] / cov[0, 0]
coskew(df)
es_logger.addHandler(es_logger_handler)
plt.show()
self.data = self.request.recv(1024).strip()
plt.show()
out.append(sum)
c.style
i = row[0]
chr(ord(c) + x)
driver.set_window_size(1400, 1000)
geom.LineString(((1.1, 2.0), (0.1, 0.4))),
sftp.stat(path)
x.date()
self.children.append(Tree(child, self))
df
json.JSONEncoder.default(self, obj)
rows.append(row)
array[0]
mylist = list(myiterator)
self.queue = []
xml_file.seek(0)
print(20)
buf = f.read(1024)
fig = plt.figure()
df = pd.read_csv(StringIO(temp))
dialog.ShowModal()
s.close()
end = len(lst)
raise RuntimeError(msg.format(this.db_name))
parser = argparse.ArgumentParser()
os.unlink(f.name)
app = QtGui.QApplication(sys.argv)
W = np.random.normal(size=(X.shape[1], 1))
age = models.IntegerField()
type.__new__(cls, name, bases, dict_)
pool = mp.Pool(num_processes)
results = []
l.append(k)
words = [line.strip() for line in open(WORDS_FILENAME)]
self.session_store = sessions.get_store(request=self.request)
wx.EVT_TIMER(self, self.belltimer.GetId(), self.OnBellTimer)
x
consumer.start()
height = math.sqrt(max(outer_radius * outer_radius - i * i, 0))
ls[1] = int(ls[1])
print(self.layers[2][0].value)
print(A * x)
layout.addWidget(button)
formdata.update(data)
b = np.random.choice(vals, size=w)
4, 5, 6
b.sort()
images = ImageItem.objects.filter(user=user)
rng[argunsort(np.argsort(l))]
all(a == z)
self._store_aggregation_timer.start()
x._get_numeric_data().apply(axis=0, func=np.log2).mean()
ax = fig.add_subplot(1, 1, 1)
pad(a, b, offset)
c = Cl()
filename = os.path.abspath(sys.argv[1])
errors.append((srcname, dstname, str(why)))
DataFrame(simpleObject.exe(), ssqlContext)
plt.show()
self.addLine(xc, 0, xc, height)
path = self.args[0]
s.index = s.index.droplevel(-1)
p.terminate()
values = map(float, f2.read().split())
X, Y = np.meshgrid(np.linspace(0, 5, 100), np.linspace(0, 5, 100))
print(c)
self.xoo = x
os.path.dirname(os.path.realpath(sys.argv[0]))
im = Image.open(old_image_path)
thread = threading.Thread(target=your_code)
result.append([l])
l[0]
f(1, 2)
self
result[i] = np.random.hypergeometric(colors[i], remaining[i + 1], m)
a[0].append(7)
N(h, 6, 9)
Q.set_UVC(U, V)
setattr(instance, key, value)
print((event.x, event.y))
p = ProcessPoolExecutor(2)
json.loads(responseJSON)
ax = pylab.gca()
cnx.close()
content = json.load(file_handler)
df2[needed_columns] = df.reindex(index=df2.index, columns=needed_columns)
timestamp1 = time.mktime(datetime.now().timetuple())
driver.get(pageLink)
d = collections.defaultdict(list)
func(self, *args, **kwargs)
dict = pickle.load(file)
x, y = cluster[:, (0)], cluster[:, (1)]
links.append(t.post_set.distinct())
QtGui.QMainWindow.__init__(self)
odict[key] = odict.pop(key)
self._rooms = {}
Atomic.register(str)
True
self.errors = np.ndarray(0)
np.bincount(r, dists < R ** 2, minlength=tot_vec)
p = Process(target=start_server)
nextelem = next(licycle)
second.append(4)
n = np.random.randint(400, 800)
--main.lua
result.append(prev)
log.close()
a = read_dict_from_file()
reactor.callLater(timeout, sendelayed, data)
x_new = np.linspace(np.min(x), np.max(x), x.shape[0])
output.append(letter)
arr[97][99][98]
node_data.append(node_to_dict(lnode, {}))
numpy.mean(a), numpy.std(a)
d.update(buf)
sh = shape[0], a.shape[0] // shape[0], shape[1], a.shape[1] // shape[1]
self.socket.sendto(data, self.address)
elem.clear()
res = np.zeros_like(arr, int)
print(self.x)
ans = []
math.factorial(arg)
self.window.set_border_width(10)
X = np.random.randn(1000.0, 5)
pubkey.verify_init()
sys.__excepthook__(type, value, tback)
sizer.Add(btnGreen, 0, wx.ALL | wx.CENTER, 5)
ax.plot(np.sin(x))
reader = csv.DictReader(csvfile, dialect=dialect)
data = urllib.parse.urlencode(values)
a.printout()
print(some_list)
False
items = match.groups()
pre_save.connect(do_something, sender=MyModel)
(14, 20)[14, 15, 16, 17, 18, 19]
bri.close()
iter(list(range(expecting(offset=0))))
self.request = request
print(yaml.dump(data))
a[tuple(idx.T)] = [5, 10, 15]
strings = [x for x in listEx if isinstance(x, str)]
parser = xml.sax.make_parser()
newlist = [newdata[v] for v in ordering]
tail = list(it)
list_a = np.array([1, 2, 4, 6])
self._sub_results[key]
p = pyaudio.PyAudio()
someModule.init(NECESSARY_DATA)
out = np.zeros((m, n))
x = pattern.sub(lambda i: substitutions.pop(0), some_text)
data = np.random.normal(0, 1, (1, 5))
cleaned_url
C = list(Concate.keys())
concurrent.futures.wait(futures)
_value
data = image.load()
o = urlparse(url)
k.release_key(k.left_key)
math.pi
i += 1
json_obj = json.loads(res.content)
stuff()
(x1 + x2) / 2.0
t.set_position((shift, 0))
colors = cm.RdYlBu(np.linspace(0, 1, n))
L = [sample(xr, 5) for each in xr]
app.run()
zip_longest(fillvalue=fillvalue, *args)
df2.iloc[0, 0] = 42
True
cursor.execute(some_statement)
it = iter(data)
slices = [sli for sli in (list(islice(it, 0, i)) for i in seclist)]
list(d.items())
a * np.exp(-b * x) + c
MyList = [d[k] for k in [x, y, z]]
exch(k, j)
iters.remove(it)
socket.listen(5)
a[2] = 4
sd.append(step_decay(len(self.losses)))
scat = ax.scatter(x, x, s, c)
count = 0
plt.legend()
df = pd.concat([df, pd.read_csv(file)])
example.get_time()
Child.do_something()
current.append(line.text)
print(item)
query = select(e for e in MyEntity if e.attr > f(x, 200) and g(x, e))
dec(f, *args, **kwargs)
v.clear()
numpy.dot(a.T, numpy.cross(b, c))
globals_.update((name, modict[name]) for name in names)
results = []
myData.close()
print(multiprocessing.current_process())
someDict.keys() & someSet
app = web.application(urls, globals())
items.append((lambda i: lambda : dump(i))(i))
first_loop()
deleteArtofWarCounter[word]
scoreB += 1
xs, ys = (x[0] for x in xs), (y[1] for y in ys)
np.bincount(binNum)
values.append(value)
hxs = HtmlXPathSelector(response)
o.writebits(ord(c), 7)
db = conn.test
alist == sorted(alist)
mask = series1 > series2
get_pickling_errors(K)
ax.set_xlim(0.0, width_of_im)
self.process = self.process.load()
self._box.close()
response = br.submit()
print([(int(col) if type(col) == float else col) for col in df.columns])
self.errorcount = 0
self.noisycount = 0
x ** 2
raise SystemExit(0)
groups = df.groupby(np.digitize(df.a, bins))
mydict = {}
target_f.write(_bytes)
d1[k] = v2
cartesian(a, b)
gen = (x[0] for x in tups)
yertle.end_poly()
ModelAdmin.__bases__ = (CustomModelAdmin,) + ModelAdmin.__bases__
self.lock = Lock()
myList.append(random.randint(0, 1))
id(foo.__code__) == id(foobar.foo.__code__)
db.create_all()
0, 0, 4, 1, 0, 48, 8, 1, 64, 48, 7
self.rectangle = numpy.hstack((self.pos, self.size))
table.setdefault((w1, w2), []).append(word[0:-1])
np.minimum(b, np.maximum(a, c))
arg_test()
swap(i, 0)
object.__new__(Parent._children[k])
f / 2.0 ** (len(b) - s) if s else f
print(args.xDate)
channel = self.ssh.invoke_shell()
StringIO.__init__(self, stdout)
temp = map(str, L[j:])
dis.dis(x)
response = urllib.request.urlopen(req)
deletetest[1]
output = {}
lis.append(x + y)
False
plt.subplot(211)
m[int(y) + (x - 1) * N] = 1
draw.line((0, i, 100, i), fill=random.randrange(256))
crawler_process.start()
primfac.append(n)
b = np.diff(a)
crawler.configure()
print(p.map(lambda x: (lambda y: y ** 2)(x) + x, range(10)))
t = f()
df = DataFrame(table, columns=headers)
imshow(mycmap(Z1), extent=extent)
a_sorted = a[idx]
text
exit(i)
axes.plot(rx(t), ry(t), t)
food_ctx.add((alice, likes, chocolate))
mail.login(SMTP_USERNAME, SMTP_PASSWORD)
new_command
a.value
draw()
plt.show()
self.text1.pack(side=TOP)
client.add_flags(msg_ids, [SEEN])
a * math.exp(-(x - b) ** 2 / (2 * c ** 2)) + d
buf = f.read(8192)
outputData.append(str(i))
threshold(gray, bin, 127, 255, THRESH_BINARY_INV)
df.Tm.cat.set_categories(sorter, inplace=True)
clf.estimators_[1]
dt = numpy.dtype(dt)
logger.addHandler(ch)
len(self.datatable.columns.values)
formatted(1e-21)
self.lock = threading.Lock()
print(solve([fCamel, fCamel, fCamel, gap, bCamel, bCamel, bCamel]))
new_list = remove_empties(new_list)
self.figure.canvas.flush_events()
punkt.train(fin.read(), finalize=False, verbose=False)
bucket = conn.get_bucket(bucket)
print(q.get())
im = [np.zeros((nums + 1, nums + 1)) for i in range(len(xs))]
WORKDIR / srv
deletea[k]
socket.__file__
os.seteuid(501)
foo.BAR
id = fields.String()
self.close()
m_list[i] = v.union(m_list.pop(j))
mfg / recommend
ax = fig.add_subplot(111)
print(self.data)
bg.close()
b = models.CharField(max_length=5)
idx = bisect(fst, 2)
[0, 0, 2]
s[1:] + s[0]
foo = Foo()
sortToFile.write(line)
numbers = list(range(1, 11))
p.leading = 120
list(closed_range(10, 1, -1))
d = visdel()
km.fit(some_data)
print(result)
xy = np.vstack([x, y])
memory_zip.write(parent_zip.open(child_zip_path).read())
print(item)
ws.set_paper(9)
gx, gy = np.gradient(Z, 0.05, 0.05)
beta = scipy.solve_triangular(R, Q.T.dot(y))
diff[key] = list(set(a[key]) - set(b.get(key, [])))
c1 = Counter(l1)
fig, axs = plt.subplots(1, 2)
n = len(archive.getnames())
youtube_regex_match.group(6)
self.src[-2].insert(0, itemtoshift)
pinf == ninf
sh.write(m, 0, e1)
a = [True, False, True]
results.append(point)
base64.decodestring(self._data)
n = a.shape[0]
seen.update(b)
self._jrdd_deserializer = rdd._jrdd_deserializer
func(*a_b)
fig, ax = plt.subplots()
instance.do_stuff()
self.textLayout.setMargin(10)
name, ext = os.path.splitext(os.path.basename(os.path.normcase(FILE_NAME)))
diff.append(all)
number = models.IntegerField(default=0)
execute_from_command_line(sys.argv)
self.roomManager.set_handlers()
plt.savefig(*args, **kwargs)
curl.setopt(pycurl.PROXYTYPE, pycurl.PROXYTYPE_SOCKS5)
cls.INVITE_MESSAGE
mail.send(fail_silently=fail_silently)
-54.5
-51.9
data = self.fd.read(size)
test(re)
platform.python_compiler()
PLT.show()
f = figure(figsize=(10, 10))
ind = np.nonzero(lo_or_hi)[0]
data = connection.read()
Makefile
pl.show()
indata[i] = (ctypes.c_double * 6)()
l = [0] * n
c = np.concatenate((a, b), axis=1)
address = models.CharField(max_length=50)
oldWindow.get_child().reparent(newWindow)
next(f)
isinstance(n, numbers.Number)
results = []
sys.stdout = s
plt.yticks(np.arange(0.5, len(df.index), 1), df.index)
kwargs.update(dtype=float128)
print(any(list_item in fruit_dict2 for list_item in fruits))
print(F)
application.listen(8888)
name = models.TextField(max_length=100)
s = frozenset([1, 2])
transitions = (array[1:] != array[:-1]).sum()
q = q.prefetch(Order.supplier)
sign(self.predict(inputs))
list.selection_set(items[0])
self.reader = csv.reader(self.f)
x = x + K * y
[1, 0, 2, 0]
print(hello_world)
queue.append((key, result))
raise TimeoutError(error_message)
fout.write(line)
QtGui.QBrush(QtCore.Qt.darkBlue)
np.random.seed(1)
bar = staticmethod(foo)
value = df.loc[5]
Py_DECREF(pName)
x = canvas.canvasx(event.x)
[0, 1, 1, 1, 1],
wrapper
lens = np.array([len(item) for item in v])
pf.close()
array([4, 6])
heatmap, xedges, yedges = np.histogram2d(x, y, bins=50)
d[keys[-1]] = value
key, val = line.split()
[mo.group(1), mo.group(2)]
w = dict((x, i) for i, x in enumerate(a))
y = [(k, v) for k, v in x if d[v] == k]
image.deleteThumbnail()
ret = np.maximum.reduceat(csr_mat.data, csr_mat.indptr[:-1])
c.my_property
datetime.date(self.year, self.month, self.day)
b = [[(y if y == max(x) else 0) for y in x] for x in a]
start = time.time()
print(test.f(666))
print(x[5], x[8], x[9])
--allow - all - external
a = (10 * np.random.randn(10, 10) + 127).astype(np.uint8)
do_three()
roi = cv2.bitwise_and(source, source, mask=mask)
PyErr_Print()
self.addCleanup(patcher.stop)
raise argparse.ArgumentError(self, message)
G = nx.DiGraph(input_data.values)
dict([(c, 0) for c in strg])
y = np.repeat(y, 100, axis=0)
data = json.loads(json_txt)
0 - 0 - 0
sparse_mult(a, b, [(0, 0), (0, 4999), (1999, 0), (1999, 4999)])
c[:len(a)] += a
self.regularization = j
oldval = oldval * random()
nums = map(bin, map(int, _in.read().split()))
match = sm.find_longest_match(0, len(answer), 0, len(prediction))
string
a = []
d = np.delete(a, np.where(mask == False))
main()
data = np.random.rand(nrows, ncols, nframes)
response = urllib.request.urlopen(req1)
X_train = Xy_train[:, 1:]
msg
(np.array(pts) ** 2).sum()
df.AVG_GRADE = list(map(list, zip(df.HOUR, df.AVG_GRADE)))
df
np.savez(filename, **attributes)
bytes = input()
raise ValueError()
df = pd.DataFrame(np.random.choice([1, np.nan], (10000, 1500), p=(0.01, 0.99)))
doc2vecmodel.train(sentences)
print(data.text)
form = FooForm
n ^ 1 << k
print(elb.getInput())
df = pd.DataFrame(data=np.random.normal(0, 1, (20, 10)))
XmingProc.wait()
print(item)
obj.__set__(self, value)
zip(a, b)
print(test.__defaults__[0])
config = tf.ConfigProto(allow_soft_placement=True)
print(mystring % (wash_clothes, clean_dishes))
sys.exit(2)
user_input = input()
l.append(id(x))
ord1[0] += 1
sorted(indices)
print(queryset.query)
data = f.readline()
r = urllib.request.urlopen(urllib.request.Request(url))
fig = PLT.figure()
[output]
libraries.append(arg[2:])
Tools > Prefences > General
line.set_data([], [])
plt.figure(figsize=(18, 6))
df = df.astype(int)
print(new_grammar.productions()[-1])
app = main(settings)
self.cleaned_data
ax = fig.add_subplot(111)
tableWidget.setCellWidget(0, 1, ImgWidget1(self))
key = self.rel.get_related_field().name
a.A
cmap = matplotlib.cm.jet
i += 1
main()
wx.Bell()
result = df.loc[(first[0]), first[1]:last[1]].min()
self.sum += value
file_B.do_B_stuff
b.append(j)
deleteordered[tN]
value = str(int(value))
threadLimiter.acquire()
response
tn = telnetlib.Telnet(HOST, PORT)
element.text = text
self.FileModel.setCondition(text)
hash(x)
root.destroy()
yet_to_run += 1
soup.span.renderContents()
a.sum()
head[(0), :] = 16
f.seek(step, os.SEEK_END)
num = np.array([1.0])
redis.Redis.RESPONSE_CALLBACKS[command](response)
self.__func__(self.__self__, *args, **kwargs)
print(self.x)
results = Result.objects.filter(id__in=obj.result_set)
pyplot.savefig(sio, format=format)
plt.xlim(0, 47)
self.i = 0
a = numpy.array([d, d, d], dtype=numpy.dtype(decimal.Decimal))
result = [m.group() for m in matches]
inner()
print(myformat)
7, [False, False, False, False]
Counter(y) - Counter(x)
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
win.add(bro)
iter(f.readlines())
print(tuple(exp.findall(st)))
df
reps.append(rep)
self.assertEqual(t.render(c), output)
self.is_running = True
cls(key_name=key_name, delete_when=deadline)
plt.show()
libraries[4:12]
set_request(request)
req = urllib.request.Request(url, data)
p.join()
logger = logging.getLogger(__name__)
frequency_list.sort(reverse=True)
d.most_common()
bytes += stream.read(1024)
arr = np.empty((initial_guess, M))
1
self.children = children
print(data[0])
ws.set_horz_split_pos(1)
t[2] += AddIDemo([5, 6])
names = Employee.objects.filter()
self.text_area.grid(row=1, column=1)
df2 = df1.copy()
d.setdefault(x % 10, []).append(x)
brr[:] = brr[sort_indices]
dt = datetime.fromtimestamp(posix_timestamp, tz)
ss.dtype
sm.OLS(y, X)
print([f(k) for k in range(4)])
result[i][j] = result[j][i] = val
print(my_content)
old_stdout = sys.stdout
plot(y1[1])
json_obj = json.load(response)
d[key].extend(flatten_group(preserve_path(value)))
q += 1
File.close()
self.right.sillywalk()
X, Y = np.meshgrid(x, y)
list1.extend(map(str, value))
logging.basicConfig(format=FORMAT)
log.addHandler(handler)
size = os.stat(fn).st_size
fig = oldfig(*args, **kwargs)
pd.DataFrame(arr)
neighbors.remove(parent)
g.__name__
C = numpy.swapaxes(temp, 1, 2)
n += 1
b = a.reshape(-1, N)
pylab.close(fig)
fmt.Println(s)
s = requests.session()
args = parser.parse_args()
self._lock = threading.Lock()
b = pd.Series(pd.np.random.randn(100000))
cap.set_markeredgewidth(10)
thread.start()
cols = [2, 2]
objects = models.GeoManager()
ax2 = ax.twinx()
Foo.f = f
result = Image.composite(background, foreground, mask)
form = BlogForm(request.POST)
h, l, s = colorsys.rgb_to_hls(r, g, b)
1, 8, 1, 1
a = np.where(np.isnan(a), b, a)
a = 1
print(rPM(PROCESS, ADDRESS1, ADDRESS2, 64, ctypes.byref(bytes_read)))
stdscr = curses.initscr()
b2.grid(row=0, column=1, pady=10, padx=10, sticky=Tkinter.SE)
a = 6.75
line = infile.readline()
print(i)
False
new_array = a == b
print(x)
df2
Queue(maxsize=0)
print(normalized(A, 2))
self._bymonth
M.append(counter)
print(df)
asyncio.get_event_loop().run_until_complete(wait_first())
a = A()
auth_handler = urllib.request.HTTPBasicAuthHandler()
node = path[-1]
flattened = np.array([x_data[i].flatten() for i in range(0, numImages)])
print(get_title())
l1[:target_index]
outf.write(int(line, 16))
i = 1
print(driver.current_window_handle)
log.write(message)
t.start()
yi = np.linspace(Y.min(), Y.max(), 1000)
ast.parse(code)
b = [6, 7, 8, 9, 10]
cur = con.cursor()
fit.params[1], fit.params[0]
data = np.arange(-50, 50).reshape(10, 10)
agf(2)
print(out.decode())
curdir = os.getcwd()
env.AddPreAction(target, action)
s.indices(sys.maxsize + 2)
paw = models.CharField(max_length=2, choices=paws)
self._post_init(srid)
execute(task, hosts=hosts)
Delete()
print(x, y)
self.close()
n = len(lst)
t.start()
print(s)
FigureCanvasWxAgg.__init__(self, parent, -1, self.figure, **kwargs)
w.writerows(data)
self.crawled_urls.update(x[0] for x in cur.fetchall())
json.dumps(dudette.json())
df[cols]
set(a).intersection(set(b)) == set(a)
output.close()
result = {}
q = session.query(myClass)
root.mainloop()
print(slugify(text))
transaction.get().addAfterCommitHook(redirect_to_trial, kws=kwargs)
main()
gtk.main_quit(*args)
input = [server]
print(line_with_keyword)
dict_del
sb.palplot(sb.color_palette(n_colors=8))
today.year - born.year - 1
yacc.yacc()
globals().update(borrowed_globals)
a = [-2, -2, 0, 0, 0, 0, 0]
df.index = pd.to_datetime(df.date)
[5]
testfunc()
np.random.seed(0)
gc.collect()
question = Question.objects.get(pk=id)
ax, _ = mpl.colorbar.make_axes(plt.gca(), shrink=0.5)
print(len(Example))
main()
f.write(content)
driver = webdriver.Firefox()
print(yaml.dump(a))
X_test = np.concatenate((X_test, catVar), axis=1)
np.ndarray(arr.shape, dtype2, arr, 0, arr.strides)
lg = numpy.where(lg == -numpy.inf, 0, lg)
ReturnStatement().act()
256 * tup[1] + tup[0]
importlib.import_module(module)
_f_array[a, b]
b = attrdict()
a = pixels[:num_pixels]
s.close()
f.read()
c.close()
big_array[chosen_slice][chosen_part]
self.mouth = 1
start = datetime(start_year, start_month, 1)
G_mean1.append(G)
self.setLayout(self.hlayout)
print(df2)
prod, x, y = heapq.heappop(heap)
hxs = HtmlXPathSelector(response)
response = client.get_spot_price()
print(serializer.getvalue())
type.__new__(metacls, name, bases, dct)
df
d[x] = []
N = int(eval(input()))
self.window = gtk.Window(gtk.WINDOW_TOPLEVEL)
fit0 = gev.fit(data)
print(sum)
x = 5
x = sum(starmap(similarity, product(a, b)))
_compile(pattern, flags).findall(string)
self.request.send(self.data.upper())
process(arg)
f(a)
sb.toString()
pil_im = Image.fromarray(cv2_im)
response = requests.post(url, data=data, headers=headers)
laparams = LAParams()
V = (1 / r).sum(axis=1)
tornado.ioloop.IOLoop.instance().start()
result = {}
chr(97)
text
cell = sheet.cell(r, c)
self.add_widget(my_box1)
x_decor.sort(key=lambda itm: itm[1])
f.close()
self._list.__delitem__(key)
cursor = conn.cursor()
args = parser.parse_args()
_clients[name]
data = np.ones(N, dtype=dtype)
heapify()
codecs.unicode_escape_decode(x)[0]
plt.plot(xx, piecew(xx))
net.addConnection(FullConnection(hidden0, hidden1))
loc = ax.xaxis.get_major_locator()
print(op(1, 2))
y = defaultdict(lambda : defaultdict(lambda : 0))
a == b
out = []
x
request.user.is_authenticated() and request.user.is_admin
Logger.manager.getLogger(name)
plt.colorbar()
M.sum((0, 1))
self.left.sillywalk()
eigvals, eigvecs = np.linalg.eig(np.cov(xy))
d = json.loads(h)
activation.undo()
do_something(server.local_bind_port)
cups_lib.cupsFreeDests(num_dests, dests_p)
scheduler.start()
ids.extend(list(range(int(xr[0]), int(xr[1]) + 1)))
ax = fig.add_subplot(111)
table.wrapOn(c, width, height)
(a == b) | (a != a) & (b != b)
dir(parrot)
a = A()
child_count = instance.children.count()
self.stream.write(msg.encode(self.stream.encoding))
_members_[key] = value
root.wait_visibility()
nums = [1] * n
image = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
tree.parse(source, parser)
client.auth_token = gdata.gauth.OAuth2TokenFromCredentials(credentials)
t.join()
B = np.where(A == value)[0]
points = [(0, 10), (10, 20), (20, 40), (60, 100)]
b = randint(0, 10)
arr = [[]]
np.array([u[1], -u[0] + np.sqrt(u[0])])
list(range(len(list1), 2))
True
out = (mask * prior_reci + ~mask * (0.1 * prior_reci)).sum(1)
BaseObject.x
canvas.create_image(image.size[0] // 2, image.size[1] // 2, image=image_tk)
df[numeric_cols].apply(zscore)
tk.Tk.__init__(self)
c[c < 0] = 0
order_array.dtype
self.i = i
x, y, z = np.ogrid[0:500, 0:500, 0:500]
style = window.get_style()
b = numpy.power(a, 2)
self.write_cell(sheet_name, cell, existing_value, updated_format)
src / Makefile
ax1 = fig.add_subplot(212)
min(start1, start2), max(end1, end2)
array_of_strings[0, 0][0, 0]
print(list(zip(x, y)))
new_dic_defaultdict[1][2] = 5
df
sys.modules[module_name] = module
T = numpy.linspace(-10, 10, 100)
not True == 0
event.Skip()
print(d)
original_init(self, a)
data = {h: v for h, v in zip(header, zip(*values))}
entropy(data) - weighted_ent, subset1, subset2
new_string
df = pd.DataFrame(data2)
frame = cv.RetrieveFrame(cap)
sift(0, i)
a[1:4] = [9, 7]
jython
C = np.dot(A, B)
hist, bins = np.histogram(data, bins=50)
c = list(zip(*b))
deletesieve[::item]
my_dict = dict((k, some_func(k)) for k in input_list)
screen.nodelay(True)
http = cred.authorize(httplib2.Http())
result = _addup(n)
hets.append(1 - pf)
fh.write(bytes)
t = threading.Thread(target=self.handle_request, args=(c,))
s.truncate(0)
self.background_color = [1, 1, 1, 1]
self.logger.error(error.message)
pp.show()
plt.gca().add_collection(coll)
l1[:target_ibdex + 1]
x ** (m * n)
work_with_cube(array[x, y, z])
globals()[module_name] = m
auth = OAuthHandler(consumer_key, consumer_secret)
print(number_string[:2])
source = urllib.request.urlopen(url).read()
times = list(range(8, 21, 4))
bool(())
print(felf.__name__, felf.__doc__)
d = datetime.datetime(2011, 2, 28)
Py_DECREF(args)
print(sys.version)
pl.figure(figsize=(10, 5))
event.canvas.draw()
ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
print(match.group())
ax2.grid(False)
print(calendar.month(2011, 8))
Contexts
app = QtGui.QApplication(sys.argv)
file_handle.write(text)
index.append([keyword, [url]])
suite = eval(sys.argv[1])
xyz = np.array((x, y, z))
self.members.append(person.key)
sites[parts[0]].append(fname)
r = tf.reduce_sum(A * A, 1)
y = random.random()
faction
True == 1
object.__new__(cls, *args, **kwargs)
self.height = height
celery.current_app.control.inspect().ping()
df2.A.plot()
self
match = regex.match(line)
obj = Test()
img1_k.append(0)
conn.send(chunk)
d.append(x.kpc)
word.istitle()
B = np.array([[7, 8, 9], [10, 11, 12]])
readline.clear_history()
total += nested_sum(item)
channel = client.invoke_shell()
print(x)
folder = FTPTree()
smtp.connect(mx[1])
b = A(20)
self._seed = int(x) + 1, int(y) + 1, int(z) + 1
print(thetd.string)
b = a + (4, 5, 6)
x = foo()
writer = csv.writer(fin)
x.pop(l - i)
ax.invert_yaxis()
Decimal.__round__
t = np.arange(0.0, 1.0, 0.001)
B.append(a)
client.set_missing_host_key_policy(AllowAllKeys())
Page.__init__(self, *args, **kwargs)
self.assertDictEqual(dict1, dict2)
print(d)
print(Xfit_mono)
matches = [x for x in lst if fulfills_some_condition(x)]
np.sum(v)
int(argv[1])
angle += 2 * math.pi
axes = fig.add_subplot(1, 1, 1)
print(f.__dict__)
us.append(dict(zip(fs, t)))
print(a is b)
result = doc.getvalue()
minList.append(a)
deletepak[IP].chksum
self.show()
name = StringField()
pr.disable()
m = int(n * (log(n) + log(log(n))))
[False, True, False],
x = frozenset(x)
L = [list(range(5)) for each in range(5)]
self.thisobj = obj.thisobj.clone()
ax = plt.gca()
print(converted_value, type(converted_value))
data = json.loads(st)
author_id = models.AutoField(primary_key=True)
db.collection.update(criteria, objNew, upsert, multi)
a[j, i]
cdf.append(total)
email
A = 0.5 * ((1 - s) * np.cos(a - b) + (1 + s) * np.cos(a + b))
self.object_list = self.get_queryset()
np.maximum.at(diam, data[:, (0)], dist_to_center)
y = numpy.array([4, 5])
n = ord(b)
fd = sys.stdin.fileno()
regex = re.compile(regex_string, re.MULTILINE)
logger.handlers.pop()
print((item, others))
hours, minutes, seconds
view_func(request, authenticated_by_ip, *args, **kwargs)
df.sum()
data = [math.sin(2 * math.pi * freq * (x / frate)) for x in range(data_size)]
X = np.array([(n.x, n.y, n.z) for n in cell])
result = [i for k, g in groupby(lst, f) for i in (g if k else (sum(g),))]
print(sys.version)
module = __import__(module_name)
dreload(myCoolModule)
print(server.div(10, 2))
type(filt)
resize_canvas()
raise ValueError(msg.format(a, b, c, len(L)))
cache.product_part_number
config
self.axes = self.fig.add_subplot(111)
pygame.init()
list(OrderedDict([frozenset(list(Counter(tup).items())), tup] for tup in data).values())
K.mean(K.pow(y_true - y_pred, 2) * W)
calculator.show()
today = date.today()
index += 1
beeper()
fig = plt.figure()
rows, cols
exampleItem.exampleName(row, column, name)
dot(self.Vt[:n].T, (self.dinv[:n] * p).T).T
NULL
soup = BeautifulSoup.BeautifulStoneSoup(s)
server_url = app_identity.get_default_version_hostname()
print(line)
print(word)
x, y = a[b], a[mask]
set.add(item)
names = np.random.choice(np.arange(N), size=100, replace=False)
print(repr(strs))
AFMT_S16_NE = ossaudiodev.AFMT_S16_LE
self.countdown(10)
print(browser.url)
ret[l[1]].add(l[0])
l.append(v)
self.y_without_NaNs = y.copy()
a = np.random.randn(100, 2500)
a = np.random.randint(0, 100, 1000)
plt.subplot(122)
0
metadata = sa.MetaData()
self.right.pop()
soup = BeautifulSoup(HTML)
Foo.initStuff()
index.sort()
D = C.reshape((1, 8))[0]
print(pd.DataFrame(d1))
input_file = sys.stdin
now = dt.datetime.utcnow()
ax.yaxis.set_major_formatter(EpiCycleScalarFormatter())
item_q.put(StopIteration)
data = file_.read()
values = [e.value for e in CommonNames]
a = [0] * 10
print(x[(0), :])
draw = ImageDraw.Draw(im)
print(key, value)
print()
ax.axis([1, 10000, 1, 100000])
b = jpeg.read(1)
readline.set_completer(MyCompleter().complete)
A - mean
something
work()
self._log_handler
schema = etree.XMLSchema(schema_root)
p = figure(width=400, height=400)
self.app.exec_()
G = (list(x) for _, x in groupby(enumerate(L), lambda i_x: i_x[0] - i_x[1]))
found = False
yaml.load(s)
fhandle.seek(1, 1)
np.sum(r ** 2 - r) * 4
a.__dict__
logger = logging.getLogger(__file__)
basis = [(lambda x, n=n: n * x) for n in [0, 1, 2]]
im.set_data(arr)
canvas = Canvas(master)
os.path.splitext(fname)[0][8:]
temp = [line.split() for line in datfiles[0]]
print(list(l))
a[key] = b[key]
keybd_event(Key, 0, 2, 0)
f.encoding
conn = session.connection()
print(key, value)
fig = plt.figure()
df = grouped.aggregate(lambda x: tuple(x))
time.sleep(5)
self.bcount = 0
current += os.path.getsize(path)
outputStream.close()
grouped = df.groupby(keys)
x[-1]
y = list(range(h))
a.dtype
event.accept()
count += 1
xcen, ycen
pickle.loads(pickle.dumps(x))
pos = available[random.randint(0, len(available) - 1)]
idx = a.cumsum()
G = nx.DiGraph()
sleep(0.1)
tf.random_uniform_initializer(-init_range, init_range)
event.canvas.draw()
os.lseek(fd, 0, os.SEEK_END)
self._global_wealth = value
s[positives].mean()
i = 0
length = len(string)
listOf[elem].append(idx)
b = a.ravel()
plt.setp(ax2.get_yticklines(), visible=False)
sys.exit(app.exec_())
True
w.start()
self.b = b
True
fig = pyl.figure()
a = collections.OrderedDict()
HTMLParser().unescape(s.get_data())
out = np.bincount(id[mask1] - 1, x[mask1])
im.putalpha(mask)
asyncore.loop()
explore()
print(repr(s))
next(f)
secondTest()
pd.isnull(y)
list(A.instances)
x = [[1, 2], 1, 1, [2, 1, [1, 2]]]
signal.alarm(seconds)
app = Application(__name__)
2, 2, 2, 2, 2, 2, 2, 2
types_dict[t].setdefault(k, []).append(v)
getattr(self, name)
f(x=2)
myDict = defaultdict(int)
self.delete_async().get_result()
degrees(acos(distance)) * 69.09
v1 = e.args[0]
998
to_translate.translate(translate_table)
myfile = opener.open(myurl)
h, yedges, zedges = np.histogram2d(y, z, bins=50)
df = df.reset_index()
g()
ax2.grid(False)
L[i] += L[i - 1]
print(random_array.dtype)
self.queue = queue
l.append(42)
print(p, np.nonzero(rowsum == p)[0])
seenstrings.add(s)
result = input(msg).strip()
x = np.random.random(50)
stuff()
user_sessions.append(session.pk)
unittest.TestSuite(MyTest(num, expected) for num, expected in data)
ax.xaxis.major.formatter._useMathText = True
(1)(a, c)
analytics_data
g.add_edge(p, from_p)
A = sp.lil_matrix((5, 5))
print(foo.output)
numbers = [d[ni] for ni in names]
result = []
total_count += 1
round(2.4)
dill.detect.badtypes(f, depth=1)
self.current += 1
self._app = app
any(x > 4 for x in mylist)
r_getname()
bad.getparent().remove(bad)
q.task_done()
now = datetime.datetime(2009, 5, 5)
{t.tag: map(etree_to_dict, t.iterchildren()) or t.text}
myapp / __init__.py
gen = ((x, y) for x in a for y in b)
r = requests.get(get_url, auth=auth)
font = ImageFont.truetype(font_path, font_size)
agf(1)
numpy.save(memfile, a)
np.power(x1, x2)
self.setFocus()
keys = list(d1.keys()) & l1
browser = webdriver.Chrome()
Evaluation.INCLUDE_AND_PRUNE
y = np.load(filename)
client.logout()
t.cancel()
stack.append([])
self.output_pipe.close()
cipher = AES.new(key, AES.MODE_CBC, iv)
self.sock = sock
writer.writerow(row)
main()
set_children_clip_box(cbar_ax, hdl.get_clip_box())
print(group_names(names, num_pages))
white = 255, 255, 255
tz._transition_info
print(N, i, sum / (N * 2 ** i))
logger.addHandler(fh)
sorted(value, key=sort_by, reverse=reverse)
newarray[ivec[j]] = averank
a + b
box = 70, 70, 100, 100
now += datetime.timedelta(days=7)
a[a == 255] = 1
new_time = time.time()
output = buf.getvalue()
Y[i] = Y[i - 1] * decay
driver = webdriver.Firefox(firefox_profile)
imgdata.seek(0)
np.rec.fromarrays(test2.T, mytype)
p = Pool(1)
list_.append(df)
u = np.array([1, 0, 0])
print(item)
self._initialize(result)
print(core.publish_string(text))
opener = urllib.request.build_opener(urllib.request.HTTPCookieProcessor(cookie_jar))
self._queue.put(line)
page.mainFrame().load(QUrl(url))
outf.truncate()
p = pyaudio.PyAudio()
print(df2)
abort(404)
response = self.browser.submit()
app = QApplication(sys.argv)
any(t.start() for t in threads)
a = tf.Variable(a0)
pent_new(i)
1 - y | 2 - n | 1 - n | 1 - n
d1 = {key: value for i, (key, value) in enumerate(d.items()) if i % 2 == 0}
plt.show()
log(e)
self.__dict__, self.__class__.PARAM
z = r * cos(phi)
(fn(x + delta) - fn(x)) / delta
w = QtGui.QWidget()
self.sys_stderr = sys.stderr
set(larry) == set(moe)
c[0]
kwargs.append(params)
sentence = []
s[::2] + s[-1 - len(s) % 2::-2]
driver.quit()
found.add(item)
os.dup2(self.prevfd, self.fd)
doSomething()
hash = hashlib.md5()
df.date2 = pd.to_datetime(df.date2)
application = QtGui.QApplication(sys.argv)
self._succ_map[self]
print(oct(stat.S_IMODE(mode)))
user
B[:, (I)] = A[:, (L == I)].sum(axis=1)
cmd, call(cmd, stdout=outputfile, stderr=STDOUT)
test
response = br.submit()
self.filter(age__gte=min, age__lt=max)
test()
item = self.listWidget.takeItem(self.listWidget.currentRow())
self.get_queryset()
_a(arctan2(c[1], c[0]), (c ** 2).sum(0) ** 0.5)
mat.reshape(m, -1)[:, (np.arange(r) * (r + 1))] = np.nan
array
type.__new__(mcs, name, bases, dict)
shlex.split(command)
10 < a < 20
int(argv[1])
seconds = int(time.time() - time_start) - minutes * 60
matrix = np.array([i for i in range(24)]).reshape((6, 4))
Atomic.register(bytes)
fd.floatarr(pointer(ip), pointer(fpp))
d = np.sqrt((n - n.T) ** 2 + (m - m.T) ** 2)
gray = cv2.equalizeHist(gray)
x = 0
cax.get_xaxis().set_visible(False)
lSongs.append(info)
D.__bases__
print(format_exception(e))
x = numpy.arange(20).reshape((4, 5))
w.setCompleter(c)
self.submit.grid(row=1, column=2)
instance.project = Project.objects.get(title=offset)
df = DataFrame(np.arange(25).reshape(5, 5))
[self.from_db_value]
json_dict = json.load(f)
print(instance.Field1)
{0, 0, 0, 0, 0, 0, 0},
WSGIScriptAlias / khdx / home / galdosd / khdxweb / rel / khdx / apache / django.wsgi
plot(arange(44))
a.__setitem__(x, (a[x], a[y]))
setattr(obj, name, value)
w.close()
x + y + z
vals = redis.hgetall(key)
fig, axes = plt.subplots(nrows=2, ncols=2)
plot(dayswanted, y, label=label)
s = socket.socket()
client.service.Method(parameter)
list(upper[upper.index(strs[0]):upper.index(strs[-1]) + 1])
add(a, b)
plt.plot(a)
item_q.put(item)
axes.set_xlim(min(latencies), max(latencies) * 1.01)
print(i, l[i])
l[i] += 10
print(xml_files[-1])
data = numpy.random.random((nx, ny))
datetime.datetime.fromtimestamp(dt).isoformat()
A = np.unique(A)
shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)
[locals()[arg] for arg in inspect.getargspec(foobar).args]
cols = df.columns.tolist()
d = {k: dict(x[1:] for x in g) for k, g in groupby(data, key=itemgetter(0))}
c.notify_all()
root = tk.Tk()
self.loop.start()
M.add_edge(1, 2, weight=7)
cv.WriteFrame(writer, frame)
endwhile
df1 = df.copy()
q = Queue.Queue()
print(self.path)
ch.setLevel(logging.ERROR)
print(words)
seed += 1
random.shuffle(unfrozen_set)
A = next(rng1)
d[i] += 1
cmp(self.value, obj.value)
list(dic.values())
print(test.class_method())
a.x, a
self.a = 1
logging.basicConfig(level=logging.INFO)
b1 = B.objects.create()
ast.literal_eval(max(lengths, key=len))
cursor.execute(cmd)
plt.setp(ax.yaxis.get_gridlines(), clip_path=circle)
raise KeyError
root = tk.Tk()
i += 1
self.height * self.width
subplot(122)
map(itemgetter(0), _)
process(line)
z = np.random.random((len(ra), 1))
i += 1
ax2 = fig2.add_subplot(1, 1, 1)
D[i, j] = abs(x[i] - x[j])
collection.append(item)
left = int(input())
url
processes.append(row[2])
MyMixin.__mro__
a[8:9]
print(c.fetchall())
ret[l[1]].add(l[1])
d1 = p[1] - b[1]
b = [i for i in range(20) if i % 2 == 0]
img2 = cv2.merge([r, g, b])
help(itertools)
d1[k_d1] = b1[k_d1]
s = date(d.year, d.month, 15)
a * x * x + b
self.append(next(self._num_gen))
request = urllib.request.Request(url)
client_socket.shutdown(1)
x_fit = np.linspace(x[0], x[-1], 1000)
browser = Firefox()
result = [productcode, amountentered] + changecoins
self.create_main_frame()
raise NotImplementedError
_realssl.sslwrap_simple(sock, keyfile, certfile)
g = s.groupby([s.index.year, s.index.month]).mean()
df2
path = sys.path.copy()
np.apply_along_axis(nGauss, -1, x1, mu, cov)
result.append(perfect_corr)
buf.append(line)
self.mps_in_process.remove(kill_id)
[1.85, 9.6]
key
gb = df.groupby(group)
response = memcache.get(request.my_name)
img.size = tuple(i * 10 for i in img.size)
a = np.random.rand(dim, dim)
random.shuffle(sequence_containing_x_vals)
cols = [ele.text.strip() for ele in cols]
np.array(set.union(set(a), b))
f.seek(block_number * BLOCK_SIZE, 2)
b = [x for x in a if l.count(a[x]) == 1]
findContours(maskCirc.clone(), vertices, CV_RETR_LIST, CV_CHAIN_APPROX_NONE)
row.append(model.get_value(dragged_iter, i))
print(o.x + 5)
globals()[targetclass]()
self.widget.bar()
mask[sample_indexes] = 0
get_long_path_name(str(short_path_name), buffer, BUFFER_SIZE)
b = [2, 6, 7]
jinja2.Markup(scrubber.Scrubber().scrub(text))
self.data.__getitem__(key)
norm(5, 5).pdf(7)
j = Job.objects.get(pk=1)
raise ctypes.WinError()
sidx = ids.argsort()
self.initialized()
plt.subplot(121)
count = sum(os.path.splitext(f)[-1] in extensions for f in files)
self.start_urls.append(urllib.parse.unquote_plus(link[0]))
d2 = threading.Thread(target=dep2)
model = Sequential()
ret.append((point[0], point[1] - 2 * (point[1] - TOP_RIGHT[1])))
self.__dict__[key]
indices = rng.random_integers(0, len(y_pred) - 1, len(y_pred))
ax.yaxis.set_major_formatter(y_format)
1, 0, 0
args = parser.parse_args(argv[1:])
self.buffer = [1] * size
bar = [4, 5, 6]
self.start_urls = start_urls
{x: -y - 1, z: 2}
loop.close()
self.get_queryset().hard_delete()
z = 2.0 * round(y / 2.0)
print(the_matrix[0][1][2])
screen.blit(circle_surface, POS)
root = Tk().withdraw()
board = []
url = sel.select(item_url_xpath).extract()[0]
children.append(parse_inner(toks))
response
nums = [float(x) for x in sys.argv[1:]]
print(title.text)
lcms.cmsDoTransform(xform, byref(inbuf), byref(outbuf), 1)
newRow.append(row[i])
output = {}
data_string = json.dumps(data)
dss.delete(keys)
a, _, _, _ = np.linalg.lstsq(x, y)
print((a, b, c))
myfoto.write(block_of_data)
forward_tunnel(local_port, remote_host, remote_port, transport)
main.show()
flags = FLAG1 | FLAG8
print(request.path)
a = np.array([1, 2, np.NaN])
a = []
{{inline_admin_form.pk_field.field}}
b = np.zeros((N, n), a.dtype)
glViewport(0, 0, self.width, self.height)
self._fileobj.__exit__(*args)
string = fp.read()
ATE0
primes.append(a[0])
s.index = pd.DatetimeIndex(s.index)
to_translate.translate(translate_table)
cgitb.enable()
p.join()
grp.div(grp.shift(-1)).groupby(level=0).nth(0)
df = pd.DataFrame(data=data[1:], columns=data[0])
self.should_run.set()
len(self.__dict__)
q.put(e)
y = array([[[2.5]], [[6.5]]])
fig, ax = plt.subplots()
filename = wget.download(url)
self.stream.write(self._convert_row(row))
b = len(may_b)
a.b
func.__code__.co_argcount
insert(d, keyList1, value1)
ylim([0, 25])
parentView.setMouseTracking(True)
ax2.yaxis.set_tick_params(size=0)
False
x += 1
print(ret[-2][6:])
a = pd.Series(pd.np.random.randn(100000))
reader = csv.reader(f)
obj_as_dict
print(len(connection.queries))
ax2 = ax1.twinx()
np.append(xs, remain)
Func(lambda x: self(x) - other(x))
i += 1
f.write(data)
stack[-1][-1][-1] += token
getattr(self, self._attr_name)
print(findItem(a, b))
pathqueue.put(path)
True
f.quit()
collatz(12)
next(it)
ch.setLevel(logging.DEBUG)
np.percentile(S, [0, 100])
a = [7, 14, 0, 9, 19, 9]
----APP1
self.inbox = self.outlook.Folders(folderindex)
np.maximum(one, two)
print(user.last_message_time)
print(char)
next(it)
5 - 0.5615
plt.show()
writer.writerow(line)
print(x[::-1])
d = {}
start_date.replace(month=start_date.month + 1)
attr(*args, **kw)
extension = os.path.splitext(file_name)[1]
now = datetime.now()
start = time.time()
t.join()
window.show()
wx.lib.pdfwin
client.set_options(wsse=security)
local.py
self.logger.log(self.level, message)
r / np.sqrt((r * r).sum(0))
result[nearest].append(demand)
a == b
root.mainloop()
self.ui.PoseBtn_GridLayout.setColumnMinimumWidth(4, 4)
x
soup = BeautifulSoup(html_google)
self.value
print(x)
Py_DECREF(result)
print(new_arr)
a = np.array([np.array(list) for _ in y])
getattr(self.__class__, method).__code__.co_argcount - 1
p.close()
print(soup.prettify())
self.__dict__.update(dill.loads(obj).__dict__)
f = s.makefile()
resp = make_response(df.to_csv())
ind = np.array(list(range(59022)))
loop.call_soon(watch_for_file, args.file_path)
b = Counter(a)
f = urllib.request.urlopen(req)
j.set_color(colors[i])
your_file.py
y = np.cos(x)
app = Flask(__name__)
paths.extend(find_all_paths(graph, node, end, path))
session.add(f)
sorted(strings, key=collator.getSortKey)
x = 12
app = Tk()
letters.reverse()
item
ctrlText.SetBackgroundColour(wx.BLACK)
hist, bin_edges = np.histogram(datas, bins)
rconsole
writer.write_table()
show(layout)
ax = plt.gca()
doSomething(a)
results.append(list(itertools.product(allfiles, allfiles)))
df_list = pool.map(reader, file_list)
self.zimg_id = self.canvas.create_image(event.x, event.y, image=self.zimg)
a * b
print(df.apply(assign_metric_vals, 1))
size = len(data)
dis.dis(haskey)
a = np.arange(11)
result = []
fn(Af, rc1f, rc2f)
data = urllib.parse.urlencode(forms)
x = np.mgrid[-2:5:120j]
os.strerror(2)
True
PyMODINIT_FUNC
user = cursor.fetchone()
q.append(item)
ax.autoscale(True)
tag.update()
count += 1
div(self.rop, self.lop)
1, 2
[1, 2, 1]
{i: j for i, j in zip(data, data[1:]) if i[:-1] == j[:-1]}
f[1].data
cls.x = value
print(str(keys))
subprocess.call([cmd, your_executable_to_check_here])
Foo.__class__ = Base
replaced.append(text[pos:m.start()])
self._table = []
print(item)
info = {}
a(1, 2, x=10, y=20)
notify.uninit()
word_list.append(line.rstrip())
B[i][j] = [i, j]
l = sc.recv(1024)
dis.dis(my_fun)
prctl(PR_SET_PDEATHSIG, SIGHUP, 0, 0, 0)
manager.start()
Author.objects.all()
water_held = 0
ipca.partial_fit(data[i * chunk_size:(i + 1) * chunk_size])
partition(list(range(105)), 10)
obj = jsonpickle.decode(result.content)
pool.apply_async(parallel_worker)
database.py
print(end_date)
x = np.arange(-1, 1, 0.2)
X, Y = np.meshgrid(x, x)
page + strplus(1)
df
result.add(now)
print(num)
f.readline()
fib(x - 1) + fib(x - 2)
python - V
[2, 4, 6, 8]
tree = html.fromstring(page_as_string)
myservice.listen()
4
OrderedDict().monkey()
outputFile.close()
output = check_output(cmd, shell=True, stderr=STDOUT).lower()
self.transport.write(line)
print(a)
points.set_data(x, y)
obj.isoformat()
fut.set_exception(e)
center = vor.points.mean(axis=0)
a | b | (x | y)
set1 = set(list1)
event.widget.tk_focusNext().focus()
img_file = BytesIO()
libfile.py
n = np.empty_like(df)
response
ax2.yaxis.tick_right()
values = list(i.values())
a_list = list(map(int, query.split()))
imp.load_module(name, f, path[0], info)
mat2[1][i] = 0
sock.close()
[]
deletetokens[:]
is_even(0)
button.grid(**buttons[b])
x = min(((key, abs(value - v)) for key, value in list(d.items())), key=lambda k_v: k_v[1])[0]
self.daemonize()
celery.worker.job.RESULT_MAXLEN = 1048576
count[letters] += 1
thread.interrupt()
wb = load_workbook(filename, use_iterators=True)
u = json.loads(s, object_hook=json_util.object_hook)
columnindex += bytechunk / sizeof(double)
self.value
dir(foo)
res = res.add(c, fill_value=0)
pprint.pprint(r.__dict__)
cropped_example.show()
do_sth_with(i, item)
delattr(this, n)
s[s != 0]
list(d)
print(pix[x, y])
b = [float(x) for x in b]
re(integrate(1 / (x - y + I * eta), (x, -1, 1))).simplify().subs({eta: 0})
out = [(x, y) for x in a for y in b]
a = [4, 5, 0, 0, 6, 7, 0, 1, 0, 5] * 1000
pairwise.fill(np.nan)
sh.write(n, 0, col1_name)
self.assertEqual(val1, val2)
self._validate_unique(self)
r = n - len(s)
data = sorted(data, key=keyfunc)
df = pd.DataFrame(ts)
(1 + 1 + 1) * 1.0 / 10
im = Image.open(sys.argv[1])
print(list(split_text(d)))
df.a = df.a.astype(float).fillna(0.0)
r(sys.argv[1])
A[::2] += 0.1
ax.zaxis.label.set_rotation(a)
M[(i), :] *= -1
colNameList.append(desc[0])
f()
self.buffer = [1] * size
self.clear_cache()
db.system.users.find()
print(len(content))
result = func(*args, **kwargs)
s = set(val for dic in lis for val in list(dic.values()))
Counter(dict(zip(vocab, counts)))
sys.excepthook = info
self.data4undo = [rowstart, colstart, text4undo]
print((dict1, dict2))
fig = plt.figure()
self.overrideredirect(True)
r = csv.reader(f)
labels = [item.get_text() for item in ax.get_xticklabels()]
functools.reduce(lambda x, y: str(x) + sep + str(y), x)
np.diff(np.insert(np.where(np.diff(a) == 1)[0] + 1, 0, 0))[::2]
lat.iter().zip(lon.iter())
True
foldl(f, f(head, acc), tail)
student.save()
filename = askopenfilename()
True
plt.show(plot)
self._lock.release()
doc = QtGui.QTextDocument()
m = np.ma.masked_where(np.isnan(array), array)
print(x)
show(p)
bar = models.CharField()
x = [0.1, 0.2, np.nan, 0.4, 0.5]
0
mix_matrices(A, B)
form = cgi.FieldStorage()
y = np.sin(u) * np.sin(v)
mylist = [(0 if math.isnan(x) else x) for x in mylist]
p.name
idx = np.where(mask.ravel())
sum += value
x = [0] * a.count(0)
data = vals[8:]
print(resp.status)
Package - 2 / namespace / __init__.py
x = Foo()
print(Foo().get_counter())
app
products = models.ManyToManyField(Product, through=ProductQuantity)
d = {(1): [1]}
ax = plt.axes(polar=True)
irenR.Initialize()
pylab.figure()
target_path = os.path.join(TARGETDIR, member.filename)
result.append(array[mask])
do_action()
a, b = tee(iterable)
keys = sorted(keys)
created = models.DateTimeField(auto_now_add=True, db_index=True)
x += np.random.randn(6) / 10
pixels = pygame.surfarray.pixels2d(srf)
y = x
self.feed(data)
pickle.dump(d, f1)
df.dtypes
ax.xaxis.tick_top()
print(custom_sort(population))
self.before.append(other)
1, 1, 1
circles1.detectcollision(particles1)
args = parser.parse_args()
dists = np.sqrt(((data_sorted[:, 1:] - seed_ext[:, 1:]) ** 2).sum(1))
time.sleep(1 + random.random() * 5)
queryset = User.objects.all()
f = urllib.request.urlopen(link)
print(x)
h, w = a.shape
title = models.CharField(max_length=225)
columnNames = [d[0].lower() for d in cursor.description]
print(df)
self.start()
resource = WSGIResource(reactor, reactor.getThreadPool(), app)
print(s.recvfrom(65565))
ulst[j], ulst[i] = ulst[i], ulst[j]
frame.Show()
each.make_noise()
n += 1
smtp.connect()
srf.blit(f.render(unistr, True, (0, 0, 0)), (0, 0))
date
r = requests.get(url)
l.extend(other)
map(int, strnumbers)
timeit(lambda : list(fulldict.keys()))
suds.client.Client(URL, transport=https)
zip(*([iter(seq)] * n))
httpd.serve_forever()
self.check_all()
np.bincount(c)
self.model.fit(*args, **kwargs)
True
count[x] += 1
self.num = num
image = image.resize((1000, 800), Image.ANTIALIAS)
p.join()
height = max_height * len(lines)
Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
func()
not CHECK_INV_RE.search(mystring)
xticks = ax.xaxis.get_major_ticks()
font.setPointSize(20)
start_urls = []
self.con.write(data)
plt.figure()
a and b or c
runUntil(end)
c[1].append(2)
comb_dict.setdefault(key, 0)
A, B = B, A
output
bins = np.arange(256).reshape(256, 1)
counts = Counter(x)
f[0]
1.1 - int(1.1)
seen = set()
random.random()
words = line.split()
iter(self.list)
socks.setdefaultproxy(socks.PROXY_TYPE_SOCKS4, proxy_ip, port, True)
d.append(Distance(_, unit=u.kpc).value)
im = cvt2cga(imgfn)
BOOST_PYTHON_MODULE(hello)
a = cyclicallist([0, 1, 2])
f()
file.close()
self.kNN.fit(X2, y2)
l = [1, 0, -2, 0, 0, 4, 5, 0]
cursor = cnxn.cursor()
sys.excepthook = exception_handler
p.search(s).group()
1.0 / (i % 2)
s = socket.socket()
bin(a | b)
result.append(element)
c = 0
df = pd.DataFrame.from_dict(d_collapsed)
parser = xml.sax.make_parser()
plt.xlim(0, 160)
l = list(s)
timeout_timer.start()
beats.reverse()
jobs.append(p)
app.debug = True
ts2.head()
map.put(i, i)
args[0], args[1], args[2:]
a = Swallow()
NP.insert(T, 4, c, axis=1)
reader = csv.reader(f)
changewriter.writerow(result)
widget.layout().addWidget(label)
hist, bins = np.histogram(x, bins=20, density=True)
sh = logging.StreamHandler()
relaxng.validate(doc2)
callback(arg, self)
transport.close()
s1 * s2.values
listy = [item[1] for item in data]
do_something(logf)
print(name)
s
self.model = cv2.SVM()
first = np.mean(arr[:toslice].reshape(-1, stride), axis=1)
clear_mappers()
section.insert(0, table)
pyplot.show()
result = []
print(sys.maxsize)
type(b)
outputs.set_shape(inputs.get_shape())
self.a = a
int(val)
fig = figure()
t.close()
fig = plt.figure(figsize=figsize, dpi=dpi)
myset = set()
False
sorted_list = sorted(my_list)
file_toload.close()
t2 = [(a + b) for a, b in zip(t, t[1:])]
yacc.restart()
minmax = [(min(v) if k else max(v)) for k, v in groupby(lst2, lambda a: a < 0)]
base.extend([ii] * count)
plt.yticks(list(range(len(corr.columns))), corr.columns)
aaB
self.flush()
brr = np.reshape(arr, arr.shape[0] * arr.shape[1])
it = lambda : list(chain(*tupleOfTuples))
True
parser = argparse.ArgumentParser()
np.where(np.any(np.isnan(df.convert_objects(convert_numeric=True)), axis=1))
my_trigger()
y2 = np.array([f(t, 50).real for t in time])
game.process()
r = self.build_response(request, resp)
1 | MD5
Column(_groupConcat(_to_seq(sc, [col], _to_java_column)))
x = datetime.timedelta(hours=hours, minutes=minutes, seconds=seconds)
help(plt.ylim)
self.assertLengthIsOne(self.seq)
Frame.__init__(self, parent)
757
760
761
pygame.draw.circle(surface, (0, 0, 0), (10, 10), 15, 0)
Al = [0, x, x, x, x, x]
times = [800.0, 790.0, 780.0, 770.0]
example[1:5, 10:15]
print(urow_avg)
t = threading.Thread(target=task, args=(sc, i))
characters += len(word)
theta, r = np.meshgrid(thetas, radii)
plt.grid()
results = parse_jid(sys.argv[1])
plt.show()
print(render_user(userinfo))
Z[test[:, 0:2].T.tolist()] = test[:, (2)]
pprint(_)
type(my_set)
np.concatenate(out)
self.Bind(wx.EVT_TIMER, self.NextFrame)
_ * 2 - math.pi
b = formB.save(commit=False)
minutes = int(secs / 60) % 60
self.send_response(500)
self.subplot.clear()
print(signed_url)
result = []
self.send_response(200)
s2 = df.groupby([lambda x: x.year, lambda x: x.month]).sum()
Z = tf.sqrt(Delta_tilde)
float * cfloats
getsizeof(json.dumps(my_dictionary))
d = {x: i for i, x in enumerate(set(a))}
a = A()
fig = plt.figure()
print(len(binary_split_array.tobytes()))
page = bokeh.plotting.gridplot([[fig], [current_selection]])
fd.write(data)
data = clientsocket.recv(1024).decode()
self.loop.stop()
module = REVERSE_MAPPING[module]
self._set(**kwargs)
new_list.append(item + 10)
names.append(name)
a[np.isnan(a)] = b[np.isnan(a)]
y = object()
decorator
print(alist)
image = tf.cast(image, dtype=tf.uint8)
dill.detect.badtypes(f)
generate_n_primes(10, 1000)
count = max(0, len(sequence) - n + 1)
cls
self.sync_string(node)
x = np.linspace(0, 2 * np.pi, 10)
metadata = MetaData()
grayed_rgb_color
fdst.write(buf)
self.f = f
self.item_id = item_id
curOuter = db.cursor()
plt.close(fig)
adjlist_find_paths(a, n, m)
result = contains_sequence(test_iterable, search_sequence)
goto(x, y)
cxt.mount()
{{message}}
os.dup2(0, 2)
C = zip(A, B)
p.line(50, 660, 560, 660)
clips.Reset()
s += l[i]
print(ret.read())
deletions.append(keepers[key][0])
path = os.path.join(directory, fl)
counts = Counter(zip(predicted, gold))
a[1] = 4
process_messages()
tar.addfile(tarinfo=info, fileobj=string)
plt.close(fig)
scrollbar.config(command=self.data.yview)
phrase.capitalize()
results = q.fetch(10)
pl.ylim(-1.2, 1.2)
[8, 9, 10, 11],
float(s)
plt.plot(b)
__metaclass__ = ModelBase
df.plot(ax=ax1)
((n,) + t for n, t in enumerate(zip(*iterables), start))
schedule_once(tasks.some_task_a, interval=60 * 5)
log.append(p.url)
print(a[0, 1])
df.dtypes
A = np.random.randint(2, size=(n, n))
yaml.add_representer(folded_unicode, represent_folded_unicode)
file.close()
render_to_response(renderer, values)
new_image.show()
manager = mp.Manager()
fig = figure()
queryset = Company.objects.all()
plot(t, s1)
fig = plt.figure(1, figsize=(figwidth, figheight))
eigs(A, n)
Thread(target=read_stdout, args=[process]).start()
triplets[iT].append(listB[iB])
f.write(z)
cursor = connection.cursor()
x ** (m * m)
csv_reader = csv.reader(count_file)
request = urllib.request.Request(url)
x * x * x
file_size = values[0]
textlist.append(str(a))
people = result.fetchall()
app.exec_()
n = np.empty((1,), dtype=object)
R = dot(u, vh)
messages = Message.objects.all()
R = random.randint(1, 8)
np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)
list(gen_all_substrings(string))
test_file.write(bytearray(binary_data))
1, 2
numpy.logspace(0, 2, 10)
self.current - 1
print(a + b + c)
canvas.tag_raise(object)
start = pd.datetime(2016, 5, 22, 8, 0, 0)
b = set(counts.keys())
print(i, line.strip())
json.JSONEncoder.default(self, obj)
d[key] = {}
lst.append(element)
self.fc2 = FigureCanvas(self._fig)
foo(bar)
mean, sigma = a.mean(), a.std(ddof=1)
round(x, sig - int(floor(log10(x))) - 1)
pd.DatetimeIndex(df.t).normalize()
prime_form(11, 1, 0)
plotter(im, i)
print(new_a)
a.run()
b = datetime.timedelta(minutes=1, seconds=1)
n = len(points) - 1
m = random.randint(0, 1000000)
blocks.append([])
P.show()
foo + bar
print(l)
msglist.append(chunk)
node = Node(node, category, name)
setattr(F, name, TextField(name.title()))
sess.run(init)
gevent.spawn(read_stream, p1.stderr)
list.append(self, x)
print(np.all(rs[(find_map_sorted(r2[:-10], rs)), :] == r2[:-10]))
deleteresult[key]
plt.plot([(x * slope) for x in range(0, 11)])
now = datetime(datetime.now().year, datetime.now().month, 1)
chr(26)
x = np.asanyarray(x)
train_idxs.append(X_train_1[i_1:i_1 + 1].index)
f1 = plt.figure()
response = HttpResponse(content_type=mimetype, status=206)
arr = np.empty([len(a) for a in arrays] + [la])
plt[:show]()
rank, v[rank:].T.copy()
now = datetime.now()
fp.write(decompressor.decompress(chunk))
self.result = []
time.sleep(1.0)
tb = e.__traceback__
print(type(b))
subnets
main()
Tkinter.Text.__init__(self, parent, cnf, **kw)
gs = gridspec.GridSpec(1, 2, width_ratios=[10, 1])
d = {}
persons = [re.match(pattern, x).groups()[0] for x in my_strings]
y = np.empty((Ndown, Ndown))
myfunc()
theta = x[1]
models.Model.__new__(cls, *args, **kwargs)
ingredient_list.append(ingredient)
expanded = os.path.expanduser(dirpath)
client(clientsocket, address)
y[:] = np.where(mask, np.nan, np.log(r) * np.sin(t))
log = logging.getLogger()
a[index] = 1.0
a.show()
line = line.strip()
sleep(1)
l = p.stdout.readline()
self._val += 1
os.chdir(curdir)
plt.boxplot(data)
a[1:4, 1:4] = np.nan
print(df1)
print(a.calculate(1))
ax.draw_artist(ellip)
pixels = img.load()
print(find_centroid(im, 1))
self.x + other
time = rrdMetric[0][0]
n * fact(n - 1)
A = np.linspace(0, 100.0, 200)
zip(a, b)
plt.bar(ind, dat, color=col, bottom=bot)
deleteoutputter
a = int(part)
child.interact()
do_something_else()
b.B()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
a.denominator
labels = ax2.get_xticklabels()
webElement.clear()
x = [[1, 2], 1, 1, [2, 1, [1, 2]]]
self.app(environ, start_response)
self.col0 = [1.0, 0.0, 0.0, 1.0]
print(x[n - 1])
F = treecomp(T, L)
[(L[i] + L[i + sep]) for i in range(len(L) - sep)]
r.content
self.nodes[self.get_index(key)]
ret.append((point[0] - 2 * (point[0] - TOP_RIGHT[0]), point[1]))
q.put(i)
args.insert(0, sys.executable)
print(textwrap.dedent(s))
foo.__new__(foo, arg=1)
d4.update(d2)
time.sleep(self.timeout)
data.pop(word[i - 1:i])
rest = [factors[i] for i in range(len(factors)) if i not in which_is]
token.authorize(client)
s.upper()
~Q(Q)
test = np.random.normal(0, 1, 1000)
f(f, *p, **kw)
system / __init__.py
ax[1].plot(dates, list(range(10)))
self.quit(file)
BisBigger.data = np.where(BisBigger.data < 0, 1, 0)
sum
ax = fig.add_subplot(111)
new_list1, new_list2 = zip(*create_matchs(list1, list2))
swap(L[:])
plt.figure()
client = Client(url)
user_input = eval(input())
form = ImportExcelForm(request.POST, request.FILES)
s.ix[x:y]
w = png.Writer(len(s[0]), len(s), greyscale=True, bitdepth=1)
result = input(s)
connect_signal2_to_slot2()
self.page = QWebPage(self)
data[i].pop(pos)
np.allclose(method1, method2)
x.extend(a)
columns = len(next(reader1))
sum += number
pool.join()
self.assertEqual(Foo.query.count(), 0)
foo.do_interesting_stuff()
tcpcounter = 0
udpcounter = 0
sums = [sum(tab[i:i + 4]) for i, v in enumerate(tab) if i + 4 <= len(tab)]
d = {}
y[1:] = x[1:] - x[:-1]
f.write(FOOTER)
flags = re.MULTILINE | re.DOTALL
glMatrixMode(GL_MODELVIEW)
new_df = new_df.fillna(0).astype(int)
True
logging.basicConfig(stream=sys.stderr, level=logging.DEBUG)
field2 = models.TextField()
d = {}
pattern.search(t)
pd.DataFrame({cn: cv for cn, cv in zip(colnames, col_iterator)})
System.out.println(i)
self.worker = Worker(self.spinbox.value())
result = list(zip(*withspaces))
b = [(10, 40), (40, 60), (60, 90), (90, 100)]
print(hex2(-1))
arr = eval(repr(([[0] * 5] * 10)))
self.name = name
basicConfig(level=log_level)
df2 = df1.copy()
last = row[1]
44.44444444444444, 55.55555555555556, 66.66666666666667
size -= len(data)
img.save(file_out)
a.update(b)
x = np.arange(10 * 10).reshape((10, 10))
print(shortcut.Targetpath)
json.dumps(serialize(obj))
days = df.groupby(diffs).size()
df
df1 = df.copy()
rectangle.draw()
True
iterate_file(file_name)
dev1 == dev2
rows = results(exec_immediate(connection, sql))
start_date.replace(month=1)
data = res.read()
document.write(xmlhttp.status + xmlhttp.statusText)
gen = get_line()
b.f()
frame.Show()
red = np.random.hypergeometric(nred, ngreen + nblue, m)
p = pyaudio.PyAudio()
dst.copy_key(k.key.name, src, k.key.name)
a2 = A.objects.create()
self.__getattribute__(key)
acos(cos_x) * EARTH_RADIUS_IN_MILES
self.value = 1 / (1 + math.exp(-x))
p.join()
a = np.random.rand(10, 10, 10)
os.makedirs(self.cache_location)
func(*args)
r = view(request, *args, **kwargs)
root.after(0, download_chunk)
fig = matplotlib.pyplot.figure()
filename
ax.set_xticks(ind + width + width / 2)
a2.append(s)
new_row = row
self.comovingdist(z) / (1 + z)
triple(square(x))
print(path)
response = opener.open(request)
result.append(current_string_split)
plt.legend()
fig = plt.figure()
print(self.__ordered_fields__)
desired_list = list(d.values())
app = QtGui.QApplication(sys.argv)
{k: (v[0] if len(v) == 1 else v) for k, v in list(items.items())}
characters.append(char_image)
secondbut.pack()
x + y
self._load()
extract_file.write(bytearray(binary_data))
do_stuff
c.save()
self.tin = wx.TextCtrl(self, size=wx.Size(600, 400), style=wx.TE_MULTILINE)
A = np.random.randn(1000, 2000)
pdf = FPDF()
t.setDaemon(True)
lens = [max(map(len, col)) for col in zip(*s)]
result = set()
type.__call__(A)
d = {}
self.tab.removeTab(index)
listofzeros
frags.append(items[0])
create_object(form_class=FooForm)
abcba
abcdcba
abcdedcba
items.append(lambda i=i: dump(i))
x = []
print(v)
{{formset.empty_form.as_p}}
4, [False, True, True, False]
binop.setParseAction(lambda t: ops[t[1]](t[0], t[2]))
pool.join()
elements = (len(xedges) - 1) * (len(yedges) - 1)
cache[args] = f(*args)
ax2.plot(list(range(1, 10, 1)))
mydict = dict()
app = QtGui.QApplication(sys.argv)
cur = fromdb.cursor()
print(df)
p.html()
OrderedDict(sorted(l))
len(str(name))
list1 = []
infilename = os.path.join(path, folder, filename)
x * x
[1.000049]
len(n)
a = numbers()[0]
utc_date = date_aware_la.astimezone(pytz.utc)
self.assertEqual(FooCycle.query.count(), 0)
df = df[col_order]
self.indexdict[r]
chunks.append(chunk)
num += 1
df
self.irenL.Render()
1.0 / (x + 1)
iter(self.__dict__)
currdir = os.getcwd()
model.setItem(row, column, item)
sys.meta_path.append(self.collector)
track1.play_forever()
merged = dict()
time.sleep(wait)
root.quit()
flist.append(func)
b = models.CharField(max_length=42)
print(mylist)
out = check_output(args, stderr=t)
print(np.arange(100).itemsize)
logger.addHandler(fhandler)
print(a, b)
o.join()
print(x)
index = nanargmin(zfit, axis=1)
sess.run(init)
f.close()
instance._prefetched_objects_cache[instance.children.prefetch_cache_name]
locals().update(d)
queue.put(result)
a = time.time()
self.cub2 = cub2
self.setPixmap(pic)
self.exns.add(node.name)
my_module.my_reload()
name in self.archive.getnames()
p = Process(target=instance.start_listener)
traceback.print_exception(type, value, tb)
f(**kwargs)
u = np.linspace(0, 2 * np.pi, 50)
a = 5
vector
grid_x, grid_y = np.mgrid[min(x):max(x):100j, min(y):max(y):100j]
Package - 1 / namespace / __init__.py
i += 1
merged = pd.concat((df1, d_teams), axis=1)
bind(myfn, arg(1), 17, arg(0))(19, 14)
fig = plt.figure()
row.append(SchemaTable.Rows[i][j].ToString())
client = paramiko.SSHClient()
f.seek(4, 1)
ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])
gc.disable()
model = QtGui.QStandardItemModel(rows, columns, self.table)
cursor.close()
a = A.__new__(A, *args, **kwargs)
serialize(obj.__dict__)
xlim, ylim = axis.get_xlim(), axis.get_ylim()
root, ext = os.path.splitext(filename)
s = [i for i in range(100)]
plt.xlim(bin_edges.min(), bin_edges.max())
str(int(other).__add__(self))
al.spline1dcalc(s, val), func(val)
lines = file.readlines()
now = datetime.now(tz=timezone(zonename))
kOUT = np.zeros(N + 1)
timeout_decorator.timeout(GLOBAL_TIMEOUT)(unittest.main)()
nodes[0] = 1, 2
d = {}
writer = csv.writer(outfile)
batch = [val for i, val in enumerate(my_deque) if i in idx_batch]
[False, False, False],
dis.dis(lis[0])
main()
wb.SaveAs(newFileName, constants.xlHtml)
self.items.append(item)
self.__pList = []
re.search(self.regex, text)
print(tempfile.gettempdir())
print(data)
a[np.in1d(np.mod(np.arange(a.size), 5), idx + offset)] = 100
t = urllib.parse.unquote_plus(s)
setattr(targetCls, name, closure())
cumsum = lambda a: [sum(a[:i + 1]) for i, x in enumerate(a)]
780000
txnbkwrfkpkmiexloxrifdsnjumkex
xlnmlhobtsswjvmqnjupaybkspptpo
[] if S == [] else [S]
curs = conn.cursor()
df
f.levels
data = json.loads(obj.to_ecma())
setattr(args, self.dest, strategy)
M[:, (j)] *= s
mutex.release()
widget.setLayout(layout)
l.pack()
response
deleteself[key]
json = urlopen(request).read().decode()
B().do_something()
HttpResponse(tmplt.render(context))
print(rd[4])
dis(f)
t.show_all()
turtle.done()
q.put(1)
shuffle(numbers)
print(f(a))
df.values
list(one_duplicate(4))
C - 0.120282
r = np.empty(n, dtype=np.int64)
rIndex.reassign(9)
df
self.aws.send(data)
cleanfile.append(line)
pool.close()
d[t[0]] = d.get(t[0], 0) + int(t[1])
context
email = EmailField(required=True)
b = np.array([int])
x1 = (x - x0) * cos(theta) - (h - y - y0) * sin(theta)
self.data = []
HttpResponseNoContent()
features = [feature_names[i] for i in tree.tree_.feature]
Point(1, 2)
abort(404)
score_pairwise(seq1, seq2, blosum, -5, -1)
df
content = db.StringProperty(multiline=True)
my_func(42)
x()
somelist.remove(x)
nth_element(my_list, 4, key=f)
x[0, 1, 1] = 111
col = scipy.array([2, 4, 6, 8, 10])
f.write(decodestring(b64data))
socket.inet_ntoa(unpacked)
[[], []]
y[1][0] = 4
{{link.href | escape}}
df.b.loc[s & (s != s.shift(-1))]
df = pd.DataFrame(rslt[0])
C = np.hstack(C)
row.pop(4)
img2 = ImageTk.PhotoImage(Image.open(path2))
df
root = Tk()
app = Bottle()
print(fileSystemNameBuffer.value)
turtle.forward(n)
print(render())
request = response.wsgi_request
print(QWidget)
res = func(*args, **kwargs)
data = list(range(4000000))
[0, 0, 0, 0, 164, 1, 161, 2, 161, 4],
pt.plot.bar()
getattr(prototype, name)
matrix = [np.random.rand(N) for _ in range(M)]
ax2 = ax1.twiny()
Area2(a, b, c) > 0
strmap[string]
button1.pack()
stdscr = curses.initscr()
w[i] = -1
f
logOutput.setReadOnly(True)
z = [[(0) for _ in range(8)] for _ in range(8)]
print(results[0])
data.append([name] + [dct[key] for key in obs_keys])
True
reader = csv.DictReader(csvfile)
index = letters.index(letter)
[7, 14, 21],
bins.append([min, max])
fly.rect.y += fly.vspeed
zz = file.readline()
frame1.axes.yaxis.set_ticklabels([])
self.button.clicked.connect(self.handleTest)
sc = ax.scatter(x, y, *args, **kwargs)
queue.append(new_path)
plt.plot(x, y)
os._exit(0)
print(row)
s.shutdown(socket.SHUT_WR)
print(msg.Body)
result.append(next_third_friday(result[-1]))
weights
money = price.quantize(cents, decimal.ROUND_HALF_UP)
print(x)
test[0][0] = 1.0
vals == (0, 1)
[(row[:j] + row[j + 1:]) for row in m[:i] + m[i + 1:]]
dict.fromkeys(range(4000000))
follow(open(filename))
myThread.setDaemon(true)
df
serializer = self.get_search_pagination_serializer(page)
A = np.cos(a) * np.cos(b) - np.sin(a) * np.sin(b) * np.sin(c - d)
import_array()
x_max = tf.reduce_max(weights)
[]
row = len(row_names) - 1
getattr(self._wrapped, attr_name)
stdout
display = Display(visible=0, size=(800, 600))
pyobj = json.loads(json_str, object_hook=as_python_object)
z = 10 * np.random.normal(mu, sigma, 5000)
visited_ids.add(node_a_id)
b[0] = -1
sns.reset_orig()
reraise_with_context(key=key)
new_df = pd.DataFrame()
pp.pprint(tup)
html = markdown(some_html_string)
[num for num in range(n) if A[num]]
x = [1, 1, 0, 0, 0]
set_time_limit(0)
observer.start()
a == 2
result[feature_name] = (df[feature_name] - min_value) / (max_value - min_value)
pFact.append(num)
result = float(node.text_content().lower().count(word))
y1 = scipy.sqrt(1 - (abs(x) - 1) ** 2)
print(df2)
print(df)
hold(True)
1, 0, [t]
self.connected = True
ix = [i for i in df.index if i not in blacklist]
k = 0
d = -np.dot(np.array(point), np.array(normal))
app.url_map.strict_slashes = False
dis.dis(foo.__code__.co_consts[1])
p.move()
y0 = self.canvas.canvasy(0)
oct_num = oct(int(oct_string, 8))
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
output = [[]]
value
Session.add(f)
fig.canvas.draw()
gray = im.sum(axis=-1)
obj.reprJSON()
zip(a, chain(b, [next(b)]))
np.dtype(float)
g = g[(g.date >= g.beg_date) & (g.date <= g.end_date)]
delattr(mod, modname)
thefile.write(replacedText)
self.setSelectionMode(QtGui.QAbstractItemView.ExtendedSelection)
0
sizer.Add(btnRed, 0, wx.ALL | wx.CENTER, 5)
b = np.bincount(a)
ax.w_zaxis.set_major_locator(LinearLocator(10))
request.notifyFinish()
packetcount
writer.grab_frame()
show()
ret, frame = cap.read()
self.assertEqual(user.username, testuser.upper())
zip(*([iter(iterable)] * n))
z().visit(t)
x = plt.colorbar(ticks=v)
writer.writerow(line)
x = X()
bmpf.seek(start)
self.set_encoding(encoding)
event = threading.Event()
print(cls)
Pagination(query, page, per_page, total, items)
sleep(0.1)
ret.append(work_on)
+---__init__.py
cbar = fig.colorbar(CS, ax=ax)
A.__init__(self, a)
df_list.append(f)
response = urllib.request.urlopen(req)
f.write(res)
True
sys.version_info
button = QtGui.QPushButton()
conn.connect()
django.db.transaction.enter_transaction_management()
itergroup([0, 0], 0)
ax.plot(xx, yy, zz)
print(q)
fig, ax = plt.subplots()
sps_a.toarray()
tix.Label.__init__(self, parent, **kwargs)
X, Y = np.meshgrid(x, y)
a[(i), :] = map(float, line.split())
print(list(M.keys()))
server = smtplib.SMTP(smtpserver)
print(self.crawler.stats.get_stats())
items_view.show()
map(second_lowest, lst)
result = [tuple([(item + minval) for item in tup]) for tup in result]
employee = json.loads(j, object_hook=class_mapper)
create_grid(4, 5)
formset = QuoteFormSet()
wb.save(output)
whos
dict.__init__(self)
rows * array_shape[1] + cols
count += 1
x < 1
print(df1.assign(sum=df1.sum(axis=1)))
8, 1, 8, 8
df1.T.max() - df1.T.min()
mask = (B == i).astype(int)
res[v] += 1
roots.add(target)
my_date = datetime.strptime(test_date, date_format)
a[x], a[y] = a[y], a[x]
QListIterator(self)
add_str_to_lines(f_name=f_name, str_to_add=str_to_add)
os.mkdir(folder_location)
job.delete()
tableWidget.setCellWidget(1, 1, ImgWidget2(self))
BaseHTTPServer.test(CORSRequestHandler, BaseHTTPServer.HTTPServer)
json.dump(doc, fw, indent=4)
f = itemgetter(0)
print(r.getc)
a.extendleft(b[::-1])
handles, labels = plt.gca().get_legend_handles_labels()
count = diff.nonzero()[0]
df.dic.apply(pn.Series)
name = models.CharField()
json.dumps(self._items)
s
test.tell()
matrix = [([0] * size) for i in range(size)]
__builtins__[attr] = getattr(module, attr)
self.output_pipe.close()
result[np.arange(len(x)), inv] = 1
l.sort(key=lambda x: x.lower())
sizer.Add(btn)
result.append(current_set)
your_csv_file.close()
msg
print(inputList)
letters = [chr(i) for i in range(97, last_letter)]
fd = sys.stdin.fileno()
all_other_cases(param)
to_translate.translate(translate_table)
ls = [1, 7, 0, 4, 9, 6, 150]
start = start + math.log(random.random()) / i
logging.basicConfig(level=logging.INFO)
a = np.arange(1, 10000.0, dtype=int)
queryset = queryset.filter(name=name)
out[int(n)].append((val, v))
log_add2(logB, logA)
len(output)
id(a.bar)
np.diff(data.value.index.values)
desired_ages = np.array([1, 4, 16, 29, 80])
print(char1, len(char1), len(char1[0]))
i.append(x)
stdout, stderr = process.communicate()
index_list.append(i)
y = a[2] * b[0] - a[0] * b[2]
xedges = np.linspace(0, N, nbin)
c = cv.WaitKey(10)
deletetag[attribute]
[x] + xs
f[:]
a = numpy.random.randint(0, 10, 10) * 1.0
merge(a, b, lambda in_a, in_b: in_a or in_b)
a = NoBCArray([[1, 2]])
stock_values[stock][days]
interpolator((lats, lons, alts, time), data, point)
tree = etree.iterparse(xml_file)
y[:, ::2] = 0
driver.close()
y.append(x)
p.stdin.close()
indices.append(idx)
data_dict[regNumber] = details
response = urllib.request.urlopen(req, timeout=int(TIMEOUT))
args = tuple([CallableWrapper(args[0])])
int(key)
ax.yaxis.set_major_formatter(ptick.ScalarFormatter(useMathText=True))
axe = fig.add_axes([0.4, 0.4, 0.2, 0.2])
func()
cv_image = img_as_ubyte(any_skimage_image)
Rule(SgmlLinkExtractor(process_value=delete_random_garbage_from_url))
client.service.GetServiceById(arg1, arg2)
packet = f.read()
find_merged_group(date_time - 1, date_time + 1)
df
f_myfile.close()
sio.seek(0)
ax2.imshow(Z)
print(user.screen_name, user.followers_count)
self.op._getsymbols()
do_something(i)
df = [DataFrame(e) for e in data]
response = urlopen(url)
groups = conn.get_all_security_groups()
ax1 = fig.add_subplot(111)
pydevd.GetGlobalDebugger().setExceptHook(Exception, True, False)
cimg = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
post_save.disconnect(my_post_save_handler)
natsorted(x, key=lambda y: y.lower())
Python - virtualen
pool.join()
new_cipher.append(letters[letters.index(letter) - shift])
_Py_ReleaseInternedStrings()
a1 = sheet.cell_value(rowx=0, colx=0)
ax.plot(np.cos(x))
print(dict(zip(headers, values)))
foo[:]
res = np.split(idx_sort, idx_start)
os.remove(str(file_path) + xfile)
sympy.simplify(Lagrange(Lx, Ly))
parser = argparse.ArgumentParser(formatter_class=CapitalisedHelpFormatter)
regex = re.compile(re.escape(before), re.I)
ch = logging.StreamHandler()
a = int(round(a * 255))
self._metadata = MetaData()
list(parser)
digits = digits[1:]
-(-x // 500) * 500
result = np.empty((m, n), dtype=np.float)
pos = nx.spring_layout(G, fixed=[1, 2])
print(int(floor(f1)))
res.append(0)
temp.append(i[0, j])
[get_column(pyQueryRow, index) for index in range(0, 12)]
writer.writerows(row + [0.0] for row in reader)
inner()
calendar.timegm(aprilFirst.timetuple())
html = response.read()
mod = getattr(mod, comp)
m.load()
ax = fig.add_subplot(111)
line_segments.append([(x, y) for x, y in vor_.vertices[simplex]])
X, Y = np.mgrid[:2 * np.pi:0.2, :2 * np.pi:0.2]
out = np.zeros(tot_vec, dtype=int)
cum.tail(1)
py26
self.func = func
ss = s.split()
self.sTitle = os.path.basename(self.fileName)
a + b
height = self.canvas1.winfo_height()
h = [(i[0], int) for i in c.description]
logger.setLevel(logging.DEBUG)
end[r[1]].add(r[2])
l.append(val)
self.statusItem.setEnabled_(TRUE)
unittest.main(argv=unittest.sys.argv)
df = df.append(dff)
waitKey()
y = 10 + np.sin(50.0 * 2.0 * np.pi * x) + 0.5 * np.sin(80.0 * 2.0 * np.pi * x)
concat(dict(A=A, B=B), axis=1)
print(longest_common([b, c]))
list(range(5))[5:6]
conn = SSH2()
user = models.OneToOneField(User)
f = Foo()
info = json.loads(urllib.request.urlopen(url).read())
process(line)
self = self.setdefault(key, {})
objects = getattr(a, link).all()
stream.close()
server.test(*[1, 2])
getattr(self, self.object_class)
Model.objects.filter(m2m_field=1)
serializer_class = UserSerializer
L.sort(my_cmp)
raise TypeError
app = config.make_wsgi_app()
print(arr)
MyModel2.mymodel1.through
q = m.Queue()
list_2_sorted = [e[0] for e in s]
f.__add__(f)
i, card
print(df)
p.parse_args()
-Xmx800m
dynamic_import_hack(__name__)
import_foo()
print(dingo)
curs = conn.cursor(MySQLdb.cursors.SSCursor)
fig = plt.figure()
fn(val1, val2)
max(sum(tableData, []))
callback(file, mask)
clf.tree_.value
p = np.cumsum(np.append(0, z))[:-1]
_nextkey = 0
result.sort()
print(row)
b = a[:]
d[x] += 1
data.show()
args.append(value)
A[np.maximum.accumulate(~np.isnan(A))]
yappi.get_func_stats().print_all()
df2 = (df.ix[:, 1:] - df.ix[:, 1:].mean()) / df.ix[:, 1:].std()
fig = Figure()
models.CharField(blank=True)
fig, ax = plt.subplots()
set(data) == set(data2)
result
loss.eval({input: x, label: y})
a.UID
ax.scatter(df.index, df.AdjClose)
raise ImportError
unfiltered = [(myFunction(C), C) for C in originalList]
new_test
self._init_B()
main(sys.argv)
numpy.genfromtxt(io.BytesIO(x.encode()))
ax.set_aspect(1)
a.argmin()
0
curses.echo()
self.cj.load()
df.shape
deleteself._dict[key]
Decimal(0.2)
a = 1
A()
mask = np.random.randint(0, 2, a.size)
i += 1
indices = heapq.nsmallest(10, np.nditer(arr), key=arr.__getitem__)
data = fi.readlines()
l = s.length
self.delete(name)
base64.encodestring(s)
value
ax2 = plt.subplot(gs[1])
ax.plot(plots[curr_pos][0], plots[curr_pos][1])
__metaclass__ = ValidateType
data
x = x + A.__class__((xj[w], (w, tempj[:len(w)])), shape=b.shape, dtype=A.dtype)
self.a = a
items = Item.objects.all()
cub_left.append(points[0])
l = s.split()
x, y = np.unravel_index(indices, full.shape)
kwargs
y = np.cos(x)
s.quit()
y.insert(0, y0)
newList = json.load(infile)
ans.append(cur_set[:])
sys.stdout.flush()
out = np.zeros(x.shape, dtype=int)
ranges.append(middle)
Console.WriteLine(test.GetTest())
{{form.as_p}}
print(word)
im.thumbnail(size, Image.ANTIALIAS)
ax = plt.gca()
s.groupby(level=0).value_counts().unstack(fill_value=0)
True
time.sleep(delay)
print(oct_num)
[4, 1],
self.word_type = str(i)
stream.close()
srand48(100)
yTrain = np.array([[1], [0], [0], [0]])
nk = not_allowedclass()
nopreds.discard(v)
A = M.sum(0).sum(0)
id = Column(Integer, primary_key=True)
print(data)
grouped = df.groupby(groupbycol)
pool = Pool(processes=4)
pig
data = f.readlines()
words.append(teens[u])
value = dirty_data[key]
print(next(reader))
res = requests.get(url)
print(u)
p = figure()
summer_funcs(arguments)(1)
response
union_set.update(*l)
user = User.objects.get(username=username)
gen = (len(lst) - 1 - i for i, v in enumerate(reversed(lst)) if v == elm)
chunk_file.writelines(sorted_chunk)
array = img.get_array()
current[name] = {}
1, 2
ret = np.array(arr)
clusters.append([])
[Frameworks]
self.fmt.format(*self.args, **self.kwargs)
res.append(item)
[a for a, m in mapped if m == minVal]
app = QtCore.QCoreApplication(sys.argv)
pprint.pprint(type)
myDict[tupleItem[1]] = myDict.get(tupleItem[1], 0) + tupleItem[2]
pool = Pool(processes=5)
v = np.ma.array([10.0, 11, 0], mask=[0, 0, 1])
Py_INCREF(IorFError)
timeit(lambda : iter(fulldict.keys()))
graph = GraphAPI()
False
records = cursor.fetchall()
text = Column(String)
counter += 1
newFile.writerow(midterm1Scores)
struct.unpack_from(fmt, self.recv_buf, self.recv_buf_i - sz)
con = pymongo.MongoClient()
res = set()
sA = sparse.csr_matrix(A)
item = list(item)
f[keep_col]
print(marker.group(1))
next(tokens)
todict(X)
[0, 0, 1],
not Counter([1, 2]) - Counter([1, 2])
uniq = np.unique(data.view(data.dtype.descr * data.shape[1]))
alt.write(content)
print((dirpath, count))
f.close()
A = 2 * np.arange(10)
app = QtGui.QApplication(sys.argv)
sys.modules[borkenmod.__name__].__file__
idx = np.hstack((X.nonzero(), Y.nonzero()))
False
print(boo, boo)
self._fileobj.__enter__(*args)
id = Column(Integer, primary_key=True)
fig, ax = plt.subplots()
tmp.add(tuple(i))
words = line.split()
r.text
p.join()
dic1.keys() | dic2.keys()
client = oauth2.Client(consumer, token)
b = [4, 5, -10]
rescaled = (255.0 / data.max() * (data - data.min())).astype(np.uint8)
B.do_your_stuff()
max_val = l[max_idx]
self.master.mainloop()
a = np.hsplit(x, np.arange(12, 129, 12))
_fake_tb()
p = Popen(cmd, bufsize=1, stdin=open(os.devnull), stdout=PIPE, stderr=STDOUT)
root = Tk()
browser.visit(url)
myarray = numpy.zeros((N, M))
string = df.to_string(header=False, index=False, index_names=False)
equal.append(x)
c1 = conn.cursor()
testsuite.addTest(unittest.defaultTestLoader.loadTestsFromModule(module))
file
isclose(100, 97.1, rel_tol=0.02)
s += fh.read(SOME_CHUNK_SIZE)
lookup[(a[:, (0)] - 1), :]
list(RecursiveList.flatten(self))[index]
new[i, j] = xy[i][j]
argsdict[arg] = [val]
imputed_array
print(parser.parse_args())
getCards(subList)
definition = models.TextField()
ax.bar(x_values, log_y_values)
results = list(csv.reader(inputfile))
bar_from_foo(self.foo(x))
http_server = tornado.httpserver.HTTPServer(Application())
result.append([])
char_counts[char] += 1
temp = os.walk(sys.argv[1], topdown=False)
activity.setContentView(self.webview)
subject = email_message.subject, body = email_message.body,
c = [[np.s_[i:j] for i, j in zip(r[:-1], r[1:])] for r in rgen]
buffer = QtCore.QBuffer(array)
print(text)
string = string[len(to_strip):]
self.handlers = collections.defaultdict(set)
x.executemany(q, itemBank)
self.libc.freelocale(self.ctx)
infile = open(sys.argv[1])
p.join()
A_process.wait()
test_set = set(string_to_teat)
root = ET.fromstring(TEST)
itertools.product(*list(rc.values()))
print(cell_value)
A[0, 1, 2]
print(img_tag)
numpy.repeat(vec_row.toarray()[0], numpy.diff(mat_row.indptr))
self.filter(group_set__pk=group.pk)
print(b1.to_array())
self.create_test_data()
self.height = height
pre_save.disconnect(pre_save_callback, sender=models.MyModel)
im = np.vstack([x] * len(x))
self.element_tree.write(xml_file)
ax.plot_surface(xx, yy, zz, alpha=0.5, color=cmap(c))
ax.yaxis.get_major_formatter().base(2)
dispatcher.connect(self.dont_close_me, signals.spider_idle)
-1
y = np.random.rand(20, 10)
j = np.lexsort(a.T)
pylab.imshow(img)
fig = pylab.figure()
cmp(self.number, other.number)
response
value & ~(1 << bit)
Particle[i].AddNeighbor(Particle[j])
args = parser.parse_args()
pil_img = PIL.Image.open(StringIO(data))
stack.pop()
cursor.execute(query, params)
idx = np.argmax(np.abs(w))
print(body_content)
test(n)
print(word)
print(row)
a, b = select(L, 2, 5)
t.sort()
print(numbers)
a = list(range(10))
path = unsearched.get()
print(x)
soup = BeautifulSoup(html_doc)
f()
self.__dict__.update(kwds)
count = 0
s = list(range(5))
result[key] = value
True
palette = img.getpalette()
data = [10.01, 5.001, 4.89, 5.1, 9.9, 10.1, 5.05, 4.99]
hash = hashlib.sha1(object_to_cache_as_string).hexdigest()
l = [4, 5, 6]
raise StopIteration
arr2d = np.meshgrid(np.linspace(0, 1, 6), np.linspace(0, 1, 11))[0]
render_mpl_table(df, header_columns=0, col_width=2.0)
self.change_label()
output = [(len(new_string[0]), new_string) for new_string in output]
print(key)
description = models.CharField(max_length=12)
fields = urlparse.parse_qs(field_data)
args = sys.argv[2:]
self._hash
box = x, y, x + w, y + h
np.random.seed(42)
waitKey()
d = {}
parser = argparse.ArgumentParser()
wave_file.writeframes(sample_str)
remainder = proc.communicate()[0]
A = A.astype(np.float64)
tbl.append(list())
array.ravel()[step:-step:step]
customAction
a.indices(10)
fout.close()
response = my_view(request)
show(p)
rows = [(d, random.random()) for i, d in enumerate(dates) if i not in omit]
app = QApplication(sys.argv)
print(neighbors(5, 5))
curdir = os.getcwd()
show()
list(map(set, out))
B = expm(A).view(matrix)
[1, 2]
project_points(x, y, z, *calc_plane_bis(x, y, z))
sys.exit(0)
a / b
stdout, stderr = process.communicate()
rect = self.addRect(r, Qt.white, gradient)
fig, ax = plt.subplots()
check = np.logical_or(a[:, (1)] == 4, a[:, (1)] == 6)
cur = [[14, k, j] for j, k in zip(rows[14], list(range(15)))]
sys.stdout.flush()
list[:] = newlist
print((i, item, len(line)))
X = np.arange(1, 17).reshape(4, 4)
np.random.seed(0)
im = ax.pcolormesh(phi_itp, theta_itp, d_itp, cmap=plt.cm.coolwarm)
cft2.append(t.timeit(number=reps))
factory = ParentFactory()
hello.hello.restype = ctypes.c_char_p
x, y = points.get_data()
df.dtypes
True
result = is_abbrev(abbrev, text)
t = Test()
df
d1.update(d)
print(nx.pagerank(D, max_iter=200))
a, s = s[:n], s[n:]
row = np.array([5])
ax.plot(list(range(100)))
links.append(recursiveUrl(link, 0))
set([OriginalExampleObject[A][1], OriginalExampleObject[C][2]])
df[col] = preprocessing.StandardScaler().fit_transform(df[col])
a = [1, 2, 4]
self.location = 0.0
df
p = ggplot(dat, aes(x=x, y=y, fill=z)) + geom_tile()
output = np.copy(arr)
1
fin.close()
5.88199996948
args = opt.parse_args()
comp.compile()
agacatacagagacatacagagacatacag
form = ProjectAdminForm
sorted(s)
x = datetime.datetime.combine(today, x)
c.join()
[setattr(j, col.name, getattr(i, col.name)) for col in i.__table__.columns]
user = User.objects.get(username=username)
first = word[0]
self.setIconSize(QtCore.QSize(124, 124))
root = Tk()
get(remote_path, fd)
path
img = ImageTk.PhotoImage(image)
PyMODINIT_FUNC
self.setLayout(QtGui.QFormLayout(self))
rectangle.erase()
j = np.unravel_index(i, a.shape)
list(ips_data.keys())
x = (np.random.random((10, 10, 20)) + 0.5).astype(np.int)
frame = inspect.getouterframes(frame)[1]
print(dist.squareform(dist.pdist(data, lambda x, y: ss.pearsonr(x, y)[1])))
user = g.get_user()
d = datetime.date(2010, 12, 5)
next(it)
print(format_table(L_in_columns))
logging_thread.start()
functools.update_wrapper(_d, d)
sleep(1)
output_csv.close()
signal.signal(signal.SIGTERM, handle_signal)
fig.subplots_adjust(bottom=0.2)
rows.append(row)
self._dump()
ax = fig.gca()
x.lower()
print(tag.getAlbum())
signal_handler(*args, **kwargs)
t = numpy.arange(81.0).reshape((9, 9))
worksheet.hide_gridlines(2)
x = math.floor((-b - math.sqrt(b ** 2 - 8 * i)) / 2)
b, c = [e[0] for e in zipped], [e[1] for e in zipped]
l = [(k, process(v)) for k, v in list(stuff.items())]
cls.__name__.lower()
self.left = tree
text.partition(left_identifier)[2].partition(right_identifier)[0]
data = {}
fclose(retclam)
pool.waitall()
sum(c * x ** p for p, c in enumerate(arr))
fig, ax = plt.subplots()
show()
mean = cv2.mean(bottom)[0]
c1 = Cookie.SimpleCookie()
qs = self.model._default_manager.all()
autostart = true
p.set_array(colors)
vals[i]
listB[0][1]
c = a + b
cameraL.SetPosition(40, 0, 200)
p.start()
helpers.bulk(es, actions)
index[axis] = z2.argsort(axis)
chr(pos + 97)
logger = get_task_logger(__name__)
print(item)
print(date.toordinal(date(1971, 1, 2)))
d = {}
main()
df
d[parts[0]] = d.get(parts[0], []) + [parts[1]]
con = pymongo.MongoClient()
counts = idx[1:] - idx[:-1]
self.msg = msg
a = np.linalg.inv(np.dot(X.T, X))
print(datetime.datetime.utcnow())
X, Y = np.meshgrid(x, y)
out = [x[0] for x in gona]
form = CreateUserForm.new()
slcs1[i] = slice(0, -1)
ten
sum(c1 != c2 for c1, c2 in zip(string_1, string_2))
func(*args, **kwargs)
func
[2] + [(i * 2 + 1) for i, v in enumerate(sieve) if v and i > 0]
self._data[self._keys[key]]
parseXMLFromString()
make - j4
reader = csv.reader(f)
(16, [2, 2, 2, 2]),
self.name
self._realOutput.write(text)
colors = (np.random.random((N, 4)) * 255).astype(np.uint8)
pyplot.show(one.plot())
self.write(text)
b[0]
A = sc.parallelize().map(partial(worker, V=V))
mkl_rt.mkl_set_num_threads(ctypes.byref(ctypes.c_int(cores)))
sizer = wx.BoxSizer(wx.HORIZONTAL)
countup(N, n + 1)
my_thread.start()
sys.getwindowsversion()
string[:string.index(suffix) + len(suffix)]
self.response = app.post(*args, **kw)
print(b.Pear)
out = s.index[maxidx + np.arange(maxidx.size)]
np.broadcast(*args).shape
addArray(array)
result
log_file.write(s)
raise Exception((status, reason))
L.append(a)
res.append(np.diag(vif))
the_data_model.delete()
suite = unittest.TestSuite()
func_globals.update(_namespace)
v.shape
line = line.strip()
d = {}
[cleaned(x) for x in re.finditer(WORD_REGEX, s)]
ClassA.__init__(self)
words = str_.lower().split()
d = {}
frame.pack()
PyArray_ITER_NEXT(it1)
self.SetSizer(sizer)
root = html.fromstring(encapsulated_text)
Tkinter.Tk().withdraw()
raise Exception()
forms[1].controls[0].name
dict = {}
a.x
self.sock = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM)
words = sorted(counts, key=lambda word: (-counts[word], word))
mylist = [random.randint(0, 1500) for _ in range(10000000)]
json.loads(json.dumps(members))
driver = webdriver.Firefox()
index2count[i] += 1
print(line)
sleep(1)
print(foobar.__name__)
x = np.arange(10)
pool = Pool(16)
self.func(v1, v2)
soup = BeautifulSoup(f)
self.nstep = nstep
self.form_valid(form, **kwargs)
{}
column = int(sys.argv[2])
20, 20, 2, 2, 18, 5
records = list(json.loads(df.T.to_json()).values())
1 - (A, B, E, D)
grids[idx[i, 0], idx[i, 1]] += 1
plt.pcolormesh(xi, yi, zi)
self.d[k] = v
f.name
print(sum(map(lambda x: x ** 2, [x for x in lst if x % 2 == 0])))
r.headers
n = x.shape[0]
msgBox.exec_()
A[0, 1]
res
plt.sca(ax)
transport.open()
sys.stdout.write(screen_code)
cython.long
plugin.plugin_main(*args, **kwargs)
dst.copy_key(k.key, src.name, k.key)
can.save()
path, filename = os.path.split(path)
ax.plot(list(range(10)), rd.random(10))
value = blob_reader.read()
Makefile
app = WSGIApplication()
print(s.getvalue())
MI.Close()
np.allclose(old, new)
user = models.ForeignKey(User)
l = [2, 6, 5, 4, 2]
s.lower() in keywords
temp_path
val = np.sum(1.0 - np.cos(a - b))
count += 1
ax2.set_ylim([-200, 200])
dic = dic[key]
raise ctypes.WinError(ctypes.get_last_error())
result.append(opv)
extend_nums(nums, 5)
r = {}
print((len(perms), perms[0:10]))
a = np.arange(90).reshape(10, 9)
view_fields(a, keep_names)
plt.plot(x, y)
termf.pack(fill=BOTH, expand=YES)
now = np.datetime64(datetime.datetime.now())
mask = np.arange(images.shape[0]) % 6 != 0
print(serial_ports())
plt.contour(np.log(r / 1.2))
list(clusters.values())
pygame.time.wait(100)
row.append(field[k][i])
C[1::2] = B
inspect.getargspec(aMethod)
url = key.generate_url(expires_in=0, query_auth=False)
ipdb.set_trace = f
result
res = self.func(*args, **kwargs)
checker.validate(data, schema)
self.points = [Point(random(), random()) for _ in range(numpoints)]
sample_weight = np.array([(5 if i == 1 else 1) for i in y])
process_count += 1
file.seek(pos_dec + word_len)
styles = getSampleStyleSheet()
npreds[v] -= 1
fig, ax = plt.subplots(figsize=(9, 5))
temp.append(num)
print((location.latitude, location.longitude))
counter[0] += 1
p = Process(target=self.proc, args=(i,))
True, True, True, True, True, True, True, True, True
activation.done()
heapq.heappush(gens, succ)
filteredKeys = (key for key in list(myDict.keys()) if userInput in key)
ax1 = plt.subplot(gs[0])
layout = QtGui.QVBoxLayout()
INS
x = list(range(0, 7))
f = sys._getframe()
self.end_headers()
cur.execute(string)
res = __import__(mod)
p1 = os.path.join(path, p)
mfun
repr(self.__dict__)
connection.text_factory = str
nx.draw(G, with_labels=True)
script_elt.extract()
G = C_abs + C_abs.T
ordered = sorted(iter(colour.items()), key=itemgetter(1))
chardet.detect(s)
line_list[-lines_2find:]
np.exp(x) + np.sin(y)
True
cls
out[k].append(item)
choice(seq)
rms = sqrt(mean(square(a)))
zip.close()
p.join()
self.assertFailure(d, ValueError)
C.shape
app.start()
c = sys.stdin.read(1)
data = []
print(row)
sys.exit(1)
results = a[np.triu_indices(len(x), 1)]
lab = color.rgb2lab(io.imread(each_file))
d = 2
thread.start()
dupl = []
print(nonlinear_invert(f, x, y, z))
m = r.search(str1)
endfun
now = datetime.datetime.now()
pool.close()
a = int(a) if int(a) % 2 == 0 else int(a) + 1
np.random.seed(101)
[(ord(x.lower()) - 96) for x in string.letters]
ascript
xa.execute()
globals()[k] = self.oldglobals[k]
print(arr)
draw.text((0, 0), text, font=font)
functor()
username = db.Column(db.String(80), unique=True)
x, y = np.random.random((2, 10))
response = urllib.request.urlopen(request)
program.py
p = etree.HTML(r.text)
is_sub(b, a)
dlg.Destroy()
bob0.save()
x()
self.assertTrue(result > 0)
d = datetime.date.today()
xlock.acquire()
b = [False, False, True]
com_instance.Quit()
raise TypeError(node)
resultList = [item for sublist in resultList for item in sublist]
install_all_the_things()
overlap(0, 10, 80, 90)
aes.decrypt(base64.b64decode(encrypted))
df
self.grid()
send_from_directory(UPLOAD_FOLDER, filename)
capital = models.CharField(max_length=50)
my_model
in_.seek(-min(size, chunk_size), 2)
l = [4, 5, 6]
data = list()
login(request, user)
wb = Workbook()
bin(2)
z = np.random.random((len(r_test), 1))
t = plt.gca().transData
base.__dict__[name]
qproc.join()
plt.show()
rsum.append((x[0], rsum[-1][1] + x[1]))
pool.close()
p.join()
self._channel.basic_ack(basic_deliver.delivery_tag)
numbers = [number for number in numbers if number % results[-1] != 0]
print(imgray.shape[:2])
print(a[:4])
foo.run_static_method()
out = write()
[2, 4, 6]
parent_map = {c: p for p in tree.iter() for c in p}
x + 1
self.callback()
outputfile.write(*args, **kwargs)
start_urls = [URL]
stack.extend([v for v in self.graph[vertex]])
obj.pop(i)
sig2 = numpy.interp(t, t2, sig2)
mutex.release()
image = np.array(image, copy=True)
[y ** (1 / 2), -y ** (1 / 2)]
xx = np.linspace(0, 10)
s.format(**d)
n = uniform(0, weight_total)
print(cell)
samples = [[0, 0], [0, 1], [1, 0], [1, 1]]
df5 = df.ix[:, 48:60]
listbox.insert(0, myTkObject.clipboard_get())
writer.add_document(title=item.Title, content=item.content, url=item.URL)
print(y)
ip
z.argmin(1)
res
res.append(1)
l[1]
result.append(p)
a.append(99)
wildfd.inc((w1, w2))
output = proc.communicate()[0]
name
df
test(constrained_combinations)
rv = self.parse_statement()
p4[8], p4[9] = tb.tb_frame.f_lasti, tb.tb_frame.f_lineno
stripped_line = line.strip()
soup = BeautifulSoup(s)
self.traceback.append(self.col_seq[j - 1].lower())
a = np.ascontiguousarray(A).view(rowtype).ravel()
print(repr(obj), obj.__dict__)
fl.close()
s += n % 10
list(d.keys())
[name for name in namespace if namespace[name] is obj]
np.array([p for i, p in enumerate(A.flatten()) if i > i / N * (1 + N)])
new = list(it.imap(int, old))
plot_visible(ax.azim, ax.elev)
numpy.add.reduceat(a, [0, 2, 4])
print(data)
sorted(personArray, key=compare_person)
gc.collect()
b = np.zeros(100, 10)
login_user(user, remember=True)
plt.show()
bar = Entry(master).grid(row=1, column=1)
item = self.combo.model().item(row)
print(config_root.server.version)
render_template_string(template_form, form=form)
print(request.command)
dict(t)
HTMLParser.__init__(self, strict=False)
d[0] += 1
pprint.pprint(Y)
b = np.ma.masked_where(mymask, a)
inqueue.put(sentinel)
sys.exit(1)
b = [4, 5, 6]
myTurtle.goto(0, 250)
phi, theta = np.meshgrid(phi_array, theta_array)
self.initSearch()
foo(line)
m = X.mean(axis=1)
sys.stdout = out
ax.plot(np.arange(0, i * 4, i))
n.bit_length() - 1
a, b = 1, 1
print(my_func(1, 2))
shutil.copyfileobj(open(infile), outfile)
print(listbox.selection_get())
LM2ML(vecs[:k])
nodes = draw_networkx_nodes(G, pos)
self.is_running = False
byte = f.read(1)
n & 1 == 0
pool = Pool(16)
as_strided(b, (n - 1, n + 1), (b.itemsize * (n + 1), b.itemsize))[:, 1:]
[6, 5, 4],
path[0]
res = pd.Series()
rows = itertools.product(df1.iterrows(), df2.iterrows())
self.initialized()
result = result.difference(dateRange2[b])
a.write(str(f) + os.linesep)
result = d.groupby(level=0).apply(lambda x: pd.value_counts(x.values.ravel()))
Y[:, (1)] = 1
fig = plt.figure()
soup = bsoup(r.content)
print(x)
yourproject / yourapp / middleware
to_remove.append(index)
executor.submit(submit_to_gui, f.result())
list(map(set, out))
self._db = db
x += 1
br = mechanize.Browser()
nums = [int(i) for i in line.strip().split()]
epoch = datetime.datetime.fromtimestamp(0)
p = itertools.permutations(l)
pool.append(p)
modules.append(thing)
True
cur.append(c)
loop = asyncio.get_event_loop()
str(datetime.now())
Create(Path.Combine(directory, Path.GetRandomFileName()))
response = HttpResponse(wrapper, content_type=mime_type)
new_string += escape_dict[char]
glob.iglob(pathname)
cur = con.cursor()
self._cards[card_ID].shift(amount)
columns = defaultdict(list)
simplejson.dump(data, outfile)
print(my_date)
summary_dict = {col: [] for col in new.columns[1:]}
r.sendline(line)
a = a & b
max(s, key=len)
f1 = [(x + 20) for x in range(80)]
canvas = Canvas(root, width=640, height=480, bd=0, highlightthickness=0)
int(aString, 8)
vals[bisect.bisect_right(keys, 0.464897)]
id(self._obj)
sum(map(operator.mul, *pairwise(l)))
True
print(regx.sub(repl, ss))
mask = np.array(out.sum(axis=0)).ravel() != 0
figlegend.show()
row_count = chunk.shape[0]
doit()
leng.count
r1.shutdown()
subfn
attempt(attempt_something, lambda : foo(bar))
pairs = []
print(names)
a[not_indices] = 888
x, n = np.mgrid[0:20:0.01, 1:100:1]
procs.append(p)
x = np.linspace(0, 10 * np.pi, 1000)
start = dt.datetime.now()
self.typemap = {}
last_name = models.CharField(max_length=40)
table.setdefault((w1, w2), []).append(stopword)
a == b
min_time.replace(hour=hour, minute=minute)
ax.add_collection(PC)
d = dict(self.__dict__)
a = np.asfarray(a)
value = func(self)
s.close()
UTF - 8
print(ldamodel.print_topics(num_topics=2, num_words=4))
[buildout]
defaults.update(kwargs)
a = BitArray(6000000)
current = []
start_new_thread(task, ())
y = [4, 5, 6]
main()
x = not x
cherrypy.engine.block()
raise TypeError
client = Client(url, transport=ntlm)
sys._getframe(back + 1).f_lineno
args = p.parse_args([])
pos_list.append(item)
closedir.argtypes = [c_dir_p]
True
getattr(__builtins__, name)
pylab.plot(f, Xdb)
first_col = np.where(cols == False)[0][0]
c = get_config()
raise
_f
app = QtGui.QApplication([])
df2
data = {k: [convert(v, float)] for k, v in list(dr.next().items())}
p_surplus += 1
wiringpi2.wiringPiSetupGpio()
sp.Popen([programName, fileName])
filtered.append(line)
f = gen2()
print(significant_1(0.45))
n = df.shape[0]
baz()
bode(f)
[(a + b + a) for a, b in matches]
A[subset][j] = min(A[subset][j], A[subset ^ 1 << j - 1][k] + get_dist(j, k))
a in {0, 1}
logger.propagate = False
{x, 0, y}
out[1]
500000000000000, 600000000000000, 700000000000000, 800000000000000
new_matrix[t, conv[t, z, y, x], y, x] = temp[t, z, y, x]
r.url
sorted_ab = list(zip(*sorted(chain(keyed_a, keyed_b), key=lambda t: t[0])))[1]
d[k] += v
b = [4, 5, 6]
prev = date.today().replace(day=1) - timedelta(days=1)
{{key}}
shared_time += (min(t1_stop, t2_stop) - t1_start).total_seconds()
doc_dict.update(doc.attrib)
print(testme, len(testme))
base.summary(my_pandas_dataframe)
keyword.kwlist
a = [(aa if i < 20 else 0) for i, aa in enumerate(a)]
print(c)
x / blub10.txt
y = np.random.normal(0, 1, num).cumsum()
flask.jsonify(time=time.time(), value=value)
xmin = data.min()
confirmed = get_object_or_404(EmailConfirmed, user=request.user)
self.archive = py7zlib.Archive7z(fp)
imgB = imgB.astype(float)
l2 = [2, 1]
p.map(unpack_wrapper(merger), mergelist)
sess.run(init_op)
myTurtle.speed(0)
i += 1
x = np.linspace(10, 110, 1000)
rows = cur.fetchall()
c = ChessBoard()
dumper.represent_dict(data.convert_to_yaml_struct())
self.multiply(self.x, self.y)
print(nestedExpr().parseString(data).asList())
getattr(logging, key)
fig, ax = plt.subplots(1, 1)
self.pred(obj)
characters = splitre.split(credits)
df
b = bytearray(f)
df1 = df.T
stream = cStringIO.StringIO(value)
1, 2, 0, 0
V = (np.arange(M * N) / (M * N)).reshape(N, M)
easygui.egdemo()
print(funcs[2]())
x = 1
dic[a] += b
p_values = scipy.special.ndtr(-z_scores)
df.index = df.index * 10
names = list(row.keys())
timeit(lambda : fulldict.keys())
deq.append(p)
newlist = []
bin(1)
print(test.g(666))
options = webdriver.ChromeOptions()
read = p.stdout.readline()
lg.string
is_invertible(b)
xx = np.arange((len(A) - 1) * n + 1)
options.remove(current_option)
filelist = ftp.nlst()
namedict[key] = val
v = [[1], [1, 2]]
print(name)
shared_time += (min(t1_stop, t2_stop) - t2_start).total_seconds()
vbox.addWidget(button)
r = np.zeros((rows, rows))
c.join(l)
self.get_nowait()
print(str(err))
json_object = json.loads(myjson)
serializer_class = serializers.UserSerializer
print(theQ.get())
print(status)
((np.cumprod(x) - 1) * p)[-1]
i = df.index.values
self.left.insert(othernode)
process_data(data)
composed
q.put(x)
show(p)
self.color = color
[serialize(item) for item in obj]
b.set_list(list(range(5, 10)))
screen = pygame.display.set_mode((640, 480), FULLSCREEN)
index = []
seen_add(element)
auth = OAuth1(API_KEY, API_SECRET, ACCESS_TOKEN, ACCESS_TOKEN_SECRET)
hash(self.x)
i, self.store[i][0]
f = (lambda a: lambda x: x ** a)(a)
console_handler.setLevel(logging.DEBUG)
result[1::2] = list2
print(parse(stream))
a.save()
newfile.write(line)
print(json2xml(j))
plt.grid(True)
v = x * np.cos(5) + y * np.sin(5)
b = [4, 5, 6]
f(1, covered_list)
app.MainLoop()
im_data = np.ndarray(shape=(cols, rows), dtype=np.uint8)
y = np.sin(x)
loop.close()
vfoo(I, J, K)
df[0] - df[1]
v = [7, 4, 5]
f.close()
d = dict()
A[j] = n
self.f.write(text)
url, len(response)
output_notebook()
file.tell()
self.deadline = self.env.cr.fetchone()[0]
Y = np.arange(size)
ppc
cholupdate(R1_, u.copy())
delattr(mod, symbol)
request = cherrypy.serving.request
p = [l[i:i + 2] for i in range(0, len(l), 2)]
print(msg_str)
out.flat[np.ravel_multi_index(data.T, dshape)] += 1
current_string.append(chr(inkey))
t.render(c)
obj = ref()
foo(42)
decorator
first_name
main()
cols = df.iloc[:, 2:].columns
dateData.append(date)
br.submit()
split_list
B[:, (col)] = np.prod(A[:, (mask)], 1)
self.assertEqual(Foo.query.count(), 1)
tmv[i, j] += 1
total += os.path.getsize(path)
frame.Show(True)
list({gameId: bitrate for _, gameId, bitrate in reversed(myListOfTuples)}.items())
libadd.Add.restype = ctypes.c_int
lons, lats = numpy.meshgrid(lons, lats)
logging_handler_out.setLevel(logging.DEBUG)
dict(user=g.user)
tuple_foo(t)
print(json.dumps(x, indent=2))
ys = np.sin(xs) + np.random.normal(0, yerrs, xs.shape)
self.fig.axes[0].set_title(self.line_edit.text())
q.put(s[-4:])
writer.write_array(output, pixels)
lines = islice(f, 0, 2 * N - 1)
main()
print((d - epoch).total_seconds())
csr.indptr[1:] = np.cumsum(nnz_per_row)
img_temp.flush()
hosp_info
xy = 10 * np.random.random((chunksize, 2))
conn, addr = s.accept()
ax.view_init(elev, azimuth)
f.close()
b = np.random.randint(0, 5, size=(6, 4))
logger_2.addHandler(hdlr_2)
losses.append(b.eval())
result[i, j] = a[i] * b[j]
self._n = n
idx = random.choice(indices)
d = d[partial_key]
cv2.rectangle(char_mask, (x, y), (x + w, y + h), 255, -1)
df.iloc[:, (i)] = i * df.iloc[:, (i - 100)]
G = nx.Graph()
transaction.savepoint_rollback(sid)
r = random.randint(0, i)
loop.create_task(do_work(envelope, body))
isitIn(char, b[:len(b) // 2])
name = models.CharField(max_length=128)
weights.pop()
nums = (b for a, b in zip(a, count(a[0])) if a != b)
table.row_cells(r)[c].text = cell
all_data = numpy.hstack((A_noisy, B_noisy))
out = np.repeat(tmp12, color_occupations.ravel())
data.sort(key=lambda c: c[1])
rows = np.isnan(g).all(axis=1)
main()
print(i)
text[:text.index(c)].rstrip()
renWinR.AddRenderer(renR)
print(line)
n = len(a)
NewClass
map(print_node, node.get_children())
np.random.seed(seed=0)
[set(v) for v in arr]
a = np.arange(1.0 * 2 * 2 * k * k).reshape(2, 2, k, k)
dom = ET.parse(os.path.join(cd, xmlfile))
b.argsort(1)
self.dialog = QtGui.QDialog(self)
a = Column(Integer, primary_key=True)
set(b) in set(a)
data = np.array([line.strip() for line in f.readlines()])
self._x = value
f
response.json()
self.given_server_is_offline()
matches = [r.match(s[i:]) for i in range(len(s))]
csvwriter = csv.DictWriter(outf, fieldnames)
json = response.body
ax = fig.add_subplot(221)
sess = tf.Session()
np.nan_to_num(data)
self.pop(i)
lsb_release.get_lsb_information()
urllib.parse.urlencode(z)
cost = [int(i) for i in cost]
self.mysignal.emit(text)
self.check_object_permission(request.user, obj)
pool.apply(locale_aware_sort, [strings, loc])
bodylist.append(body)
key = row[0], row[1]
arr = np.array(img)
list.add(1)
p.register(f.stdout)
d[1]
self.__setstate__(s)
x = S1()
ax = plt.gca()
my_decorator
NULL
sample = np.random.uniform(0, 1, 50)
result
self.trayIcon.show()
keys.sort()
Foo().spam
size = sys.getsizeof(string) - 20
(list(map(sub, chain(s, e), chain(b, s))) for s in splits)
self.broken = False
sess.run(init_op)
test.foo(x)
dir = frob
indexing_with_clipping_v2(arr, indices, clipping_value=2)
str(soup)
r.encoding
tor_process.wait()
grouped = df.map(lambda row: (row.a, (row.major, row.cnt))).groupByKey()
print(item)
result = result.astype(np.bool_)
a.insert(i + 1, [0, 0])
im = rgb2gray(im)
celery.start()
mock(), mock()
print(test.data)
pool = Pool(processes=8)
mat[i, j] = random.randrange(2)
fig, ax = plt.subplots()
f.seek(0, 2)
self._cookies = pickle.loads(string)
c = s[:, ([i, j])]
numpy.hypot(d0, d1)
sys.exit(0)
x = np.linspace(-20, 20, 500)
x, y = m(lon2, lat2)
path = os.path.join(savedir, filename)
mask = np.random.random((10, 10)) < 0.2
data[start:start + size]
false
img.paste(face, tuple(coord[::-1]), mask=face)
print(list([w for w in wordlist if prog.match(w)]))
{}
A = np.array(a.data).reshape([4, 4])
idx = (A[:, (0)] > from_date) & (A[:, (0)] <= to_date)
fig.add_axes(ax)
topbottom[(0), 0:im.shape[1]] = np.argmax(im, axis=0)
numpy.add.reduceat(data[f], i)
a[:, (1)]
x = np.array(np.random.normal(size=(4, 4)))
n = sum(int(d) for d in str(n))
result
c.head()
num_overlap = sum(1 for t in zip(list1, list2) if all(t))
setattr(random, f, our_decorator(getattr(random, f)))
list(self._sections[section].keys())
fig = plt.gcf()
canvas.pack()
OrderedDict(sorted(list(d.items()), key=lambda t: len(t[0])))
print(D.x)
thread.daemon = True
email.utils.parseaddr(email_address)
np.ma.masked_array(np.interp(value, self._levels, self._normed))
matrix = vect.fit_transform(traindata)
queue.append(x)
filtered1.append(leftData[i])
output.append(new_output)
lol(x, 7)
serializer_class = MyModelSerializer
x = a, b, c
show()
df_test.update(df_update)
self.__f(x + 1)
imgplot = plt.imshow(img)
ax = fig.add_subplot(1, 1, 1)
df
shell()
i += 1
x, x + 2
xedges = np.linspace(-10, 10, 100)
a = asarray(list(s), dtype=h)
logging.basicConfig(stream=log_stream, level=logging.INFO)
2 + 2
load(a)
left = randint(0, len(L) - 1)
L[c] += 1
Base.metadata.drop_all(engine, tables=[DeclarativeTestModel.__table__])
date = dt.datetime(date.year, date.month, date.day) + dt.timedelta(hours=10)
repr(0.1000000000000999)
new_dc_files.append(dc)
print(numbers)
x = next(stack[0])
print(f.subs(n, 6))
output.append(row)
fig = plt.figure()
data = json.loads(request.data)
main()
autodoc.add_documenter(DocsonlyMethodDocumenter)
train_text[11]
vdisplay.stop()
print(columns[1])
html = file.read()
fibpy(x - 1) + fibpy(x - 2)
ws = excel.Workbooks.Add().Worksheets(1)
sorted(globs)
os.close(output_fd)
results = []
plt.clf()
print(b.x)
df == pd.Series(conditions)
x = s[1] - s[0]
ws = wb.active
Tree()
q1m0[k] = -q0m1[k]
f.seek(randint(10, 250))
d = len(l)
result.update(self._attr_value_to_obj_set[attr_value])
result = result[::-1]
print(significant_1(1999))
print(significant_1(1945.01))
items = list(d.items())
li = iter(object_list)
print(net.num_addresses)
seen = set()
b()
print(new_random)
ind = ind[third_mask]
self.func = func
data = [cmap[i] for i in img1_k]
diags
plt.ylim(ymin, ymax)
logging.warning(message, extra=extras)
levels.pop()
t.join()
self.redraw()
group = models.ForeignKey(Group)
dosomethingelse(),
slice(2)
smtp.starttls()
roundup(101)
print(node.getData())
result = job.apply_async()
data = json.load(response)
M = np.arange(1500 * 2000).reshape(1500, 2000)
self.b = b
self._add(val, node.l)
q = Queue()
partition.append(justseen)
width, height = img.size
pymysql.install_as_MySQLdb()
start = datetime.now()
data.append(0)
show_children(parse_root(tokenize(example)))
a, N - a * a
iterateFinitely(lambda y: [f(y)] if y else [], x)
a * (not p) or [sub_k_list(a[:p], k), sub_k_list(a[p:], k)]
root = tk.Tk()
module = __import__(modulename)
z = func((x, y), a, b, c) * 1 + np.random.random(101) / 100
ip = models.CharField(max_length=200, blank=True)
m[1, 1]
print(df1)
[D, [[B, A, C], [F, E, G]]]
find_file(drive, rex)
item.wickets[10] *= 2
number = Wire.read()
self.dock1.setWidget(QtGui.QTextEdit(self.dock1))
csX.nzmax = X.data.shape[0]
self.field4price = msg.price
b = []
result
sleep(2)
args = parser.parse_args()
err()
data[tuple(ind)]
A = np.random.rand(20, 20, 2, 2, 18, 5)
mp_handler()
res.get()
print(a.shape)
r += (x[i * DIM + d] - x[j * DIM + d]) * (x[i * DIM + d] - x[j * DIM + d])
next(r)
print(s % x)
auth.refresh_token()
self._count += 1
print(parser.parse_args(c.split()))
ui[1:] = (diff != 0).any(axis=1)
df1.columns = df1.columns.values.astype(str)
bSizer.Add(button2, 0, wx.ALL, 5)
cpy.write(pgcopy.tostring())
print(df2)
req = urllib.request.Request(url_1)
raise Error(key, context=ex)
some_list[start:end:step]
timer = Timer(timeout, timeout_handler)
solve(equations, P, Q, S, T)
job.start()
time.sleep(0.1)
thefile.seek(0, 2)
test()
self.set_list(list(range(n)))
cherrypy.engine.start()
z = np.ceil(x)
False
t = threading.Thread(target=my_thread, args=[a_stop_event])
entryFrame.grid_propagate(False)
(list(range(5))[4:5] + [999])[0]
self._worker_handler.daemon = True
response.raise_for_status()
self.assertEqual(99, s1)
img = np.zeros((256, 256))
serializer = self.get_serializer(page, many=True)
self.parse,
Type[int(RNumX + 0.5)][int(RNumY + 0.5)].append((RNumX, RNumY))
(x >> power2 - 1) + 1 >> 1
ab = [o for o in itertools.chain.from_iterable(genny(x) for x in y)]
get_user_model().objects.get(pk=username)
conn = xmpp.Client(jid.getDomain())
print(QtCore)
punkt.train(abbrv_sent, finalize=False, verbose=False)
a = 0
buf[:] = names
random.choice(lists[category])
pl.show()
print(StudentTCI(1, 2, 10, 0.99))
self._subs_list(sequence)
tmp = [os.path.join(root, f) for f in files if f not in exc]
1 * p(x)
client = Client(url)
now = datetime.datetime.now()
bins[1] = bins[1] - bins[1] / 2
lft -= 1
A[:] = {1, 2}
print(repr(instance.method))
splitter.show()
result = urllib.request.urlretrieve(image_url)
data = infile.read()
print(next(spamreader))
result
d.astimezone(est)
B = A[:, (np.newaxis)]
register = template.Library()
sorted_list = sorted(initial_list, key=move)
clock = pygame.time.Clock()
combo = QtGui.ComboBox()
do_stuff_with(b)
self.draw_counter += 1
out[start:end] = a.reshape(-1)
m = np.random.random((6, 6))
x = np.random.rand(10, 10)
im = ax.imshow(z, *args, **kwargs)
b[b < 0] = 0
self.list = QtGui.QListWidget(self)
[F(N), F(N - 1)]
a[indices]
[buildout]
fig.autofmt_xdate()
self.s = s
xyz = [0, 12, 4, 6, 242, 7, 9]
tocall(*args)
print([data])
new_modules
r = random.random()
print(find_skew(list(range(256 - 256 % 26))))
x, y
print(tag.name)
contact_form = ContactForm(instance=my_contact)
cursor.skip(4000)
r = requests.get(zip_file_url, stream=True)
new_list.append(0)
merged = collections.defaultdict(set)
False
self.timestamp = time.time()
parser.add_argument(args1, args2, help=desc, **options)
target_file.write(line.translate(trantab))
output = []
dic = {randint(0, 100): x for x in range(10)}
selected = [names[bisect.bisect(cumprobs, random.random())] for i in range(N)]
logger = logging.getLogger(__name__)
i = np.append(np.where(y), n - 1)
x, y, z = arr.shape
lat, lon = radians(lat), radians(lon)
print(span.text)
show_messages()
c[i].append([])
sess.run(init)
buf = buffer.buf
print(tag.__class__)
t = numpy.linspace(0.0, tmax, nsamples, endpoint=False)
subset[subset.isin(myList)].stack().duplicated()
True
max(community.membership)
name, val = line.split()
header = f.read(4)
child.setText(0, str(key))
pp(list(sections()))
print(response.registers)
groupdict[key].append(dict([(k, v)]))
dt = datetime.datetime(year=2012, month=2, day=9)
self.img_label.configure(image=imgtk)
print(table.name)
df = df.T.stack()
[(51 * ((int(c) + 25) // 51)) for c in colour]
console.setFormatter(formatter)
curr_num += 1
S = np.sign(dY)
print(i)
layout.addWidget(self.custom_widget)
i = a.intersection(b)
myseries_one.loc[0]
inputs = []
r2 = requests.post(post_url, cookies=r.cookies, data=payload)
lines = []
page.mergePage(new.getPage(i))
self._type = classtype
d[k] = ddict2dict(v)
MainWindow.setCentralWidget(MainFrame)
rows = [line.split()[1:] for line in fp if line.strip()]
a.e()
tuple()
comp.compile()
a = A()
p = Person.objects.get(pk=x)
a[:, (0)]
solutions.append(copy.deepcopy(board))
current_string_split.append(s[j])
radar.ax.legend()
main.show()
self.copy()
a = np.sum(np.abs(xs), axis=1)
aframe.iloc[locs]
active = models.BooleanField()
draw = PIL.ImageDraw.Draw(image)
plot(time, y)
f.format(fmt, **d)
print(x)
leg = ax.get_legend()
host, port = self.client_address[:2]
self.x += 1
r.write_results()
res[k].append(v)
original_convert(str)
self.buttonCalc.clicked.connect(self.handleCalculate)
book.authors.add(george_author.id)
[tb.format_exc()]
print(diffl, lev, sor, jac)
img = cv2.imdecode(arr, -1)
[output]
data = np.random.random(shape)
print(a)
a = list(range(10))
m[i - 1, j - 1] = 1
df
f(numpy.array([[[1, 2]]]))
ip_range = netaddr.iter_iprange(ip_start, ip_end)
funs[eggs]()
os.open(name, flag | os.O_TEMPORARY, mode)
exec(my_code, mymodule.__dict__)
print(config.DEBUG)
deltas = [(a - b) for a, b in zip(zones[1:], zones[:-1])]
cursor.add_option(8)
self.spawn()
print(intify(maybeLst))
session_start()
ret, gray = cv2.threshold(gray, 250, 255, 0)
x += y,
app = Flask(__name__)
my_array.append(str(i))
file = forms.FileField()
scipy.version.full_version
[[0] * len(coef)]
self.id = id
locals()[k] = getattr(module, k)
style = xlwt.easyxf(style_string)
PyArray_Descr * descr
imgBothH.shape
-pypy
p.findall(s)
[11.4, 4.0],
res = numpy.empty_like(arr)
module = sys.modules.get(name)
session.delete(a)
x * x
readline.write_history_file(historyPath)
notebook = gtk.Notebook()
scores.update({key: int(score)})
self._value = value
p.waitFor()
s = json.dumps(data, indent=4)
next(g)
list(unique_everseen(a, key=chained(sorted, tuple)))
wb = Workbook()
fig, ax = plt.subplots()
tuple(pixbuf.pixel_array[0, 0])
browser = webdriver.Firefox(firefox_binary=binary)
luns = [int(lun) for lun in luns]
sys.stdout.write(out_str)
arr = arr.T
S.Sixth.ABs.Eighth
tagger = nltk.TrigramTagger(train_sents, backoff=default_tagger)
user = models.OneToOne(User)
list(map(list, out))
logging_handler_err.setLevel(logging.WARNING)
parent_mock._kids[1][2] is child_mock2
print(generate_chain(409, 5))
x + y
G.add_edges_from(edges)
result[k] = result.get(k, []) + [v]
list(_)
bundle
x_c = np.linspace(4, 6, 15)[1:]
b = [6, 1, 0]
self.d[self.key].value()
df_out
[int(s.endswith(t)) for s in A]
gevent.joinall(tasks, timeout=12.0)
msg.attach(basemsg)
msg.attach(signmsg)
dictionary = json.load(response)
count = 0
self.threads = []
df
main()
r = requests.post(url, data=data, allow_redirects=True)
b[5, 6, 7, 8]
A = np.random.rand(M, N, R)
self.tag_test(template, context, output)
fig = plt.figure()
ax = f.add_subplot(111)
d[b]
a, b = 0, 1
self.left.reverse()
etree.XML(xml)
n = 2
probability = np.sum(kd_vals * step)
b = np.array([[4, np.inf], [np.nan, -np.inf]])
bin_n = bin(n)[2:]
pprint.pprint(root, width=1)
x_sorted = x[order]
g.user = user
graphs_sizer.Add(chart_toolbar, 1, flag=wx.ALIGN_CENTER, border=5)
np.random.seed(0)
print(x)
fig = bokeh.plotting.figure()
self.x = x
start = random.randint(0, len(partition) - k)
response
699
L = list(itertools.repeat(10, 20))
dest.update(extra)
(comp.string.encode(enc) % tuple(params)).decode(enc)
self.__dict__[name] = value
print(X_train == X_train_init)
plt.xlim([min(xvals) - 0.5, max(xvals) + 0.5])
set(zip(*[string[i:] for i in range(n)]))
person_dict[person.last_name].append(person)
dy = [size2, size2, -size2, -size2, size2]
print(a.shape)
crawler.configure()
to_del.append(y)
p.start()
temp = np.partition(-test, 4)
image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
capture = cv.CaptureFromCAM(i)
frame = inspect.currentframe()
self.value = value
result_dict = {}
main()
sent = BooleanField(default=False)
print(i)
stats.kendalltau(B[col1], B[col2])[0]
print(m.headers)
id = Column(Integer, primary_key=True)
True
print(max(multiples, key=lambda a_b: a_b[0] * a_b[1]))
d.seconds
sig1 = numpy.interp(t, t1, sig1)
a = np.arange(1, 11)
print(i, word)
result = []
plt.show()
Py_DECREF(result)
ydata.append(np.exp(-x ** 2) + 10 * np.exp(-(x - 7) ** 2))
ax.set_xticks(arange(len(genres)))
plt.plot(x, y, x, -0.5 + h1, x, -0.5 + h2)
print(result)
fig = plt.figure()
input = [input]
session = create_session(bind=engine)
DG.add_edge(stnode, ennode, name=edge)
b = datetime.datetime(2011, 8, 29)
sock.settimeout(prev_timeout)
[-2, -1, 0, -1, -2],
data.repeat(5)
event.widget.master.focus_set()
env = jinja2.Environment()
rescaled
subprocess.Popen([program]).wait()
tempcreator.__exit__()
self.le = QLineEdit()
print((x, y))
bucket = conn.get_bucket(your_bucket)
DEBUG = 1
new_dict[length][mykey] = name_num[mykey]
self.dictionary[key][1] = value
x = T.dmatrix()
freq4.timeit(10)
logger.setLevel(logging.DEBUG)
torfile.add_url_seed(url_seed)
ignore[np.ma.maximum(y11, y12) < np.ma.minimum(y21, y22)] = True
HttpResponseRedirect(url)
a[~mask] = 999
bins = np.histogram(np.hstack((a, b)), bins=40)[1]
rle([True, True, True, False, True, False, False])
self.aws.__aexit__()
True
[i for i in range(amount)]
tree = etree.parse(metadata, parser)
blob_info = upload_files[0]
print(str(a))
model = Bilag
tester.dothis()
d = dict(t)
time.sleep(0.001)
b = time.time()
list.append(self, item)
fig = plt.figure()
output = tf.transpose(tf.pack(outputs), perm=[1, 0, 2])
con = pool.get_connection()
ff(x, y)
paths = [os.path.abspath(path) for path in paths]
game_score / max_score * 0.7 + game_score / total_hits * 0.2 + game_score_per_life / hits_per_life * 0.1
numpy.nextafter(1, 0) - (1 - sys.float_info.epsilon)
o = TestObj2()
self.cur2.executemany(query, self.rows)
plot(times, freq)
lib.test(darray.fromnp(a1), darray.fromnp(a2))
fig, ax = plt.subplots()
print(e.extra_info)
login_form.full_clean()
sentence.append(newword)
upload_fd.write(read_slice)
pagenos = set()
klass = getattr(mod, name)
os.seteuid(471)
self.dictionary[key] = [index, value]
max_list.append(s)
b.initialize_options()
models.signals.pre_init.connect(self.pre_init, sender=cls)
acc.extend(items)
lines
self.running = False
self.assertTrue(ip1.ip in result_ips)
grp.nlargest(2).div(grp.shift(-1), level=1).groupby(level=0).first()
print(current_line)
True
value, params = cgi.parse_header(header)
lst.remove(v)
print(linetext.text())
context = ssl.SSLContext(ssl.PROTOCOL_TLSv1)
df
db.session.delete(self)
doc.build(story)
df
Base.metadata.drop_all()
cPickle.dumps(d)
arr.count(0)
text = Text(root)
a = A(4)
U, S, V = np.linalg.svd(sigma)
g = tf.Graph()
p = Process(target=f, args=(child_conn,))
m = [csr_matrix(x) for x in m]
intersection = np.all((params >= 0) & (params <= 1), axis=(-1, -2))
cursor.execute(query_str)
params = dict()
can_delete = False
config = bucket.get_lifecycle_config()
u = urlparse(url)
print(line)
diag_T = T.diagonal().copy()
df.irow(loc - 1)
print(i)
order_by(t1.c.time)
sys.getrefcount(b[-2])
ranges.append(new_range)
(dates - dateshift).fillna(0).dt.days.cumsum().describe()
b = np.repeat(888, a.shape)
dst = cv2.bitwise_and(image_src, mask)
list(reversed(counts.most_common()[-to_find:]))
keys = d.keys() | d1.keys()
x, y = np.mgrid[0:a.shape[0], 0:a.shape[1]]
key in self.g
form = self.get_form(form_class)
print(my_string[my_interval])
x | x << 1
app = Flask(__name__)
create_archive(paths, arc_paths, archive)
string.digits
head, tail = os.path.split(os.path.split(pathname)[0])
buffer.close()
newest_file
np.isnan(y)
print(str(is_visible_1(link)))
stop = datetime.datetime.now()
seq[int(self.random() * len(seq))]
d = BidirectionalDict()
print(l)
urllib.request._urlopener = AppURLopener()
a = zeros((2, 5))
a = A(1)
lcd.setPalette(palette)
self.members.add(member)
[0.0, 1.0, 1.0, 1.0, 1.0, 0.0],
m = [inner_list] * rows
NoStringWrappingPrettyPrinter().pprint(yourobject)
time.sleep(24 * 60 * 60)
x.loc[(x.date.idxmin()), :]
one_day = timedelta(days=1)
letters = set(string.ascii_letters)
print(first_user.email)
result.append(str[last_end:sp[0]])
int(whole) + fractions.Fraction(frac)
res = conn.getresponse()
print(value)
total_loss = l2_loss_sum([layers[j].weights for j in range(self.n_layers)])
mpz_set(modulus, n)
pprint(data)
print(string.punctuation)
d = {}
mapper(Orders, orders_table)
tree = etree.parse(StringIO(text), parser)
ss = ssl.wrap_socket(s)
a = np.arange(16).reshape(4, 4).astype(float)
plt.plot(t, cos(w * t))
re.sub(pattern, replacer, text)
append((word, word_offset, running_offset - 1))
request = opener.open(url)
np.allclose(out1, out2.toarray())
print(said)
middle = len(strg) // 2
np.vstack((rlin * first, np.power(rlin, second)))
locals().update(somedict)
ax2 = fig.add_subplot(212)
f, a = plt.subplots(1)
parser = etree.XMLParser(remove_blank_text=True)
bar()
print(q.statement.compile(dialect=postgresql.dialect()))
result = self.contained[item]
field_name = funct()
0
row = numpy.array([(0.0001, 0.002)], dtype=type1)
pool = mp.Pool()
p.x = 5
a = np.array(a)
soup = BeautifulSoup(html)
value = args[int(key)] if key.isdigit() else kwds[key]
n[0]
df_test = df_test.append(rows_list)
print(df)
multiset[bin_] += 1
app = wx.PySimpleApp()
d2 = datetime.date(2012, 1, 1)
self.clientSocket.send(data)
setattr(instance, _UNSAVED_FILEFIELD, instance.image)
list(binomial_choice(list(range(5)), 1))
keynames[i] = k[1:]
tf.import_graph_def(basegraph.as_graph_def())
ROOT_PATH = os.path.dirname(__file__)
s = al.spline1dbuildakima(x, y)
x[1:] = x[:-1]
print(df_b)
[d[k] for d in ds for k in d if match(k, pat)]
nondirectories.append(filename)
all(i == first for i in it)
soup = BeautifulSoup(s)
to_remove = [n for n in outdeg if outdeg[n] == 1]
new_list = []
self.listener.close()
i = self.obj_type.__mro__.find(self.obj_type)
i = 1
results = pool.map(cube, list(range(1, 7)))
self._data_filter
wb = o.Workbooks.Open(wb_path)
b = copy(a)
self._storage[key].has_prefix(word[prefix_index:])
im = img_padded.load()
exec(code, module.__dict__)
output = PdfFileWriter()
my_set.update({6, 7})
nf.close()
print(list(l))
edges = collections.defaultdict(list)
ax = pylab.gca()
f.close()
tree = etree.XML(content)
cls(value)
app = Flask(__name__)
new1
total = 0
d1.update(d2)
l[0] is l
print(a, b)
B = copy.copy(A)
mail.set_debuglevel(debuglevel)
r < -reduce(Intervals(cbind(start, end)))
word = Column(String)
cython.int
worksheet = workbook.add_worksheet()
x = df.values
num1 = int(argv[1])
time[i], signal[i] = q.get()
bisect_iter_to_list(str.isalpha, iter(l))
c()
old_init(self, *k, **kw)
self.array_pool[i] = np.frombuffer(buf, dtype=self.dtype).reshape(self.shape)
numbers = [10, 20, 1, -11, 100, -12]
np.log(gev.pdf(data, *fit)).sum()
k, v = build(r, v)
self.toolbar.Realize()
a = s.split()
df
clf = ensemble.RandomForestClassifier().fit(X[:100], y[:100])
value_counts = df[col].value_counts()
app.MainLoop()
glLoadIdentity()
df
a = A()
print(regx.split(DATA))
self.data[index]
result = getattr(image, method)
fig = plt.figure()
fig, ax = plt.subplots()
print(next(d(myset)))
self.transport = transport
data = urlopen(push_url).read()
FormRequest(url, formdata=payload, callback=self.parse_stores)
sess = tf.Session()
f = tar.extractfile(member)
tuple(s[i:i + 4] for i in range(0, len(s), 4))
ds = SupervisedDataSet(2, 1)
logging.basicConfig(level=logging.DEBUG, filename=logfile)
timestamp = db.DateTimeProperty(auto_now_add=True)
print(Point(1, 2))
sudo / usr / bin / somecommand
lines.append(str(self.context_mark))
y = [(x + i) for i in range(1)]
a[i - 1]
t = threading.Thread(target=self.server.shutdown)
mimetypes.guess_type(path, strict=False)
mydict[e] += 1
print(is_admin)
end_date = dateutil.parser.parse(end)
df = pd.concat([df, df2])
overlap(0, 50, 40, 90)
print(res)
pytz.__version__
u, urlparse.parse_qs(q)
data = np.random.random(n)
m = Mock()
prop.__set__(entity, ref_entities[ref_key])
widget.setGeometry(widget.geometry())
False
result = [(x + [y]) for x in result for y in pool]
instance = cls(*args, **kwargs)
groups = df.groupby(pandas.cut(df.a, bins))
respawn
result = [x for k in sorted(d) for x in k * d[k]]
epoch = datetime.datetime.utcfromtimestamp(0)
{1, 0, 0}
permstr += permtype.lower()
G.add_node(n1, obj=n1)
A = array(a).reshape(len(a) / 2, 2)
line = f.readline()
st = os.stat(filename)
x = np.random.rand(10, 6, 7)
m.add(k, dict2.get(k))
signal.alarm(2)
mapper.SetInputData(self.vtkPolyData)
session.add(ed_user)
session.save()
b = numpy.array(list(range(5)))
W = tf.Variable(tf.random_uniform([d, 1], -1.0, 1.0))
g = map(set, g)
c = C(2)
print(a)
self.val
df
1
parser.config_files.append(values)
p.join()
tags = exifread.process_file(f)
retval = self.my_class.__call__(*args, **kwargs)
patch.set_facecolor(color)
print((a, b, c))
df = pd.concat([X] * 10 ** 5, ignore_index=True)
Py_XDECREF(pName)
two - 0.444106
df
print(names[i])
self.queue.put(f)
new_tokens.append(translated)
prefixes.sort(key=lambda s: len(s))
h = matrix([[-0.02], [0.05]])
print(result)
coords = (0, 0), (0, 2), (2, 0), (2, 2)
ax = f.add_subplot(1, 1, 1)
g.series(x, y, 0, 0)
self.selenium = webdriver.Chrome(desired_capabilities=CHROME)
x = create1m()
x = create1g()
self._c = c
old_window[0] = gdk_window.get_screen().get_active_window()
df1.columns = df1.columns.droplevel(1)
func = lambda x: x + 1
fd.seek(0)
self.loop.call_soon(self.event.set)
print(optimization.curve_fit(func, xdata, ydata, x0, sigma))
utc_dt = datetime(1970, 1, 1) + timedelta(seconds=timestamp)
output.append(str1)
app = QtGui.QApplication([])
p2 = Popen(cmd, stdin=p1.stdout, stdout=PIPE, stderr=tempFile)
areaofpolygon(polygon, i + 1)
subplot2.plot(y, x)
result
sock.setproxy(*self.proxy_info.astuple())
print(match)
self.it = iter(range(10))
G = nx.DiGraph()
substrings = [a[i:i + n] for i in range(len(a) - n + 1)]
grouped = defaultdict(list)
True
workers.append(child)
plot = fig.add_subplot(111)
data = cursor.fetchall()
c = conn.cursor()
pool.close()
print(chambersinreactor)
print(cardsdiscarded)
sqlContext.createDataFrame(temp_rdd, schema).printSchema
pic.seek(0)
noisycount += 1
quietcount += 1
client.loop()
q = db.Query(PC_Applications, keys_only=True)
_data[k] = hex(v)
atexit.register(functools.partial(kill_children, c_pid))
plt.show()
monotone_increasing(lst) or monotone_decreasing(lst)
fig, ax = plt.subplots()
nx.draw(G, pos=coords)
a = a[:-1]
Bar()
pool = multiprocessing.Pool(n_workers)
a = A()
proc = subprocess.Popen(lstrun, close_fds=True)
start.insert(0, ind)
print([i for j in zip(start, repeat(0)) for i in j][:-1])
ch = sys.stdin.read(1)
time.sleep(random.randrange(4))
rtn.append(a)
countup(N, n + 1)
self.response.out.write(utils.GqlEncoder().encode(results))
y_train = self.y[train_mask]
self.key
l = mpl.pyplot.gca().legend_
self._add(attr.get(), obj)
tty.setraw(sys.stdin.fileno())
plt.colorbar(c)
result.append((curr[2], self[curr[2]]))
d = defaultdict(dict)
file_obj.seek(0)
rand_x_digit_num(5, False)
df
bytes = str.encode(my_str)
time = time_xpath(row)[0].strip()
a = []
request = urllib.request.Request(url)
installer.install(options)
d
tree = lambda : defaultdict(tree)
f1 = f.subs(b, 10)
panel = wx.Panel(self, wx.ID_ANY)
x = 2
d[k] = [dictionary[k][column_name] for column_name in column_order]
b = copy(a)
Pdb
self.buf.read(*args, **kwargs)
node = node[char.upper()]
print(df)
mixer.init()
datetime.datetime.utcnow()
arr.put(ind, [a, b, c])
data = request.data
numbers.append(i)
self.x = 2
print(a[0, 0])
print(L)
y = np.exp(-x / 2.0) * np.sin(2 * np.pi * x)
combs = set()
log.flush()
z = np.array((old_val, new_val)).T
df.index[9:], df.columns
idx = np.argsort(dst)[:f]
list(d1.keys())[v.index(max(v))]
cos += (-1) ** n * x ** (2 * n) / math.factorial(2 * n)
cov.load()
cookies = urllib.request.HTTPCookieProcessor()
f.close()
X = np.repeat(X, 100, axis=0)
parser.parse(a_datetime).astimezone(tz)
value
session.expunge(stud)
ws = wb.worksheets[0]
f = ET.fromstring(data)
F = np.array(list(itertools.product([0, 1], repeat=n))).T
print(l)
cvMerge(realInput, imaginaryInput, NULL, NULL, complexInput)
r, c = a.shape
serializer.is_valid(raise_exception=True)
print(i, f)
np.linalg.norm(sortedA[1:] - sortedA[:-1], axis=1)
Particle[j].AddNeighbor(Particle[i])
chars = []
death_year = death_data[2]
adj = gtk.Adjustment(1, 1, 99, 1, 1, 1)
z0 = z_indices.astype(np.integer)
do_something(line)
print(docopt.docopt(__doc__))
putstr(prompt)
summary[entry[0]] += entry[1:]
yaml.add_representer(literal_unicode, represent_literal_unicode)
diff = np.setdiff1d(b, a)
pylab.show()
schema = etree.XMLSchema(schema_doc)
result = np.ma.array(yindex, mask=mask)
index.create(engine)
(1 - -1) * np.random.random() + -1
print(i)
urls.append(url)
[n for n in list_to_test if isinstance(n, type_of)]
self.on_message = on_message
self.d[k]
print(is_png(data))
os._exit(0)
width, height = image.size
data = plt.cm.jet(data[x_data, y_data])
cv2.polylines(h, [pts], False, col)
np.dot(af, af).astype(int)
my_list[0][0] = 5
y = list(x)
self.write(line)
c = Counter(s)
axis.set_minor_locator(NullLocator())
df1 = df1.apply(closest, axis=1)
candidates[index] = bases[index] * nums[candidates_indexes[index]]
signal.alarm(5)
ax = plt.gca()
iregex
cache[method_name]
a = np.asanyarray(a)
vbox.pack_start(self.button, False, False, 0)
ind = (posx > 0) & (posx <= bins[0]) & (posy > 0) & (posy <= bins[1])
pl.hist(data, bins=10 ** np.linspace(np.log10(MIN), np.log10(MAX), 50))
C = A * B
x.foo()
np.exp(x)
pseudocolor(80, 0, 100)
self.assertRaises(exc, f, *args, **kwargs)
self.index -= 1
decimal.getcontext().prec = 6
self.click_positions.append(event.pos())
a()
remove(argv[0])
b = list(a)
a.x
datos.append(float(item))
l.append(g.name)
ax.invert_yaxis()
something()
contents = self.buf.read(size)
max(S)
a = np.zeros(42)
srcname = os.path.join(src, name)
x / y
dt = datetime.utcnow()
z = exp(-x)
i += 1
a = []
cur = conn.cursor()
rows = json.loads(x)
print(old_s)
reduce(lambda d, k: d[k], keys[:-1], result)[keys[-1]] = value
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
fig = plt.figure(frameon=False)
dragged_iters.append(model.get_iter_from_string(iter))
data = np.random.randn(N)
print(df)
config.read_string(s_config)
sqr = col.copy()
outThread.start()
len(dir(aStrOBJECT))
(7, 10)[7, 8, 9]
self.x = x
view
screen.blit(treeImage, pygame.rect.Rect(0, 0, 128, 128))
end_date - start_date - datetime.timedelta(days=number_of_weekends * 2)
print([v for v in list(anagrams.values())])
y = np.arange(-5, 5, 0.25)
print(repr(testObject))
a = np.array(list(range(1, 10)))
struct.unpack(fmt, data)
groups = df.groupby(cols)
fig.tight_layout()
today = date.today()
self.clientSocket.close()
output += markdown2.markdown(mkin.read())
res = {}
m, n = len(seq), len(sub)
True
self.page.mainFrame().load(self.currentUrl())
print(longest_sum([1, 2, 7, 8, 11, 12, 14, 15], 0, 0, 10))
db.delete_async(self)
files = []
mask = np.in1d(np.arange(np.max(out_id) + 1), out_id)
area
painter.drawPixmap(event.rect(), self.pixmap)
n
output
[TYPECHECK]
User()
www.myurlnumber1.com
dic[4]
x[a][b].update(C)
book.user == bundle.request.user
sqrt(y - (p[0] + x * p[1]) ^ 2 + (x - (pinv[0] + y * pinv[1])) ^ 2)
print(recv5.decode())
lock.release()
print(decimal.__version__)
self.width = self.winfo_reqwidth()
tree.takeTopLevelItem(tree.indexOfTopLevelItem(i))
MyTestResult(self.stream, self.descriptions, self.verbosity)
func(request, *args, **kwargs)
y, x = np.mgrid[:10, :10]
c1, c2
im.seek(len(seq))
pixmap = QPixmap.fromImage(image)
fmin = (N + f2 - 1) / f2
df2 = pd.DataFrame(index=idx, columns=idx)
columnNames.append(str(SchemaTable.Rows[i][0]))
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
set(itertools.product(s1, s1, s1))
print((25.4 / 10.0 * (1.0 / 2.54)).__repr__())
True
p.terminate()
4, 5, 6
data = np.loadtxt(file, skiprows=8)
token = gdata.gauth.token_from_blob(saved_blob_string)
soup = Soup(handler)
qs.filter(is_active=1)
json_object = json.loads(myjson)
self.a = a
output = PdfFileWriter()
np.array(B)
Model.objects.filter(m2m_field=1).filter(m2m_field=2)
print(df)
cj.load()
sheet = book.active
print(a._x, a._y)
opener = urllib.request.build_opener(authhandler, urllib.request.HTTPHandler(debuglevel=1))
tmp()
ax.autoscale_view()
d[value].append(key)
not any(d.values())
a = [1]
obj.set_x_self()
queryset = Game.objects.all()
p.feed(xhtml)
sum += random.randint(0, 100)
x.append([x] * 5, ignore_index=True)
my_thread = QThread()
A1 = [[A[i][j] for j in new_order] for i in new_order]
a = list(range(10))[::-1]
A = A - A.mean(1)
D = list(Concate.values())
l = fnmatch.filter(string_input.split(), pattern)
b.ndim
self.check_word_type(self, self.filename)
tlist += ttlist
template_globals.update(render=render_partial)
hash(self.s)
x2 = np.random.normal(size=N)
axes[0, 0].set_ylim(0)
dis.dis(myfile)
print(i)
a // 1
print(line)
ax = plt.gca()
os.chdir(destination[0:len(destination) - 1] + path)
merge(a, b, lambda in_a, in_b: in_a and not in_b)
axs[i].get_xaxis().set_ticks([])
dt = utc_dt.astimezone()
s.boot
print(result.fetchall())
16777215
type.__new__(mcs, classname, bases, dictionary)
self.f.flush()
client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
-Bob
() < []
x = {row.SITE_NAME: row.LOOKUP_TABLE for row in cursor}
a = Fraction(1, 2)
zlib.decompress(compressed)
print(f_x([9, 10]))
0
screen.clear()
[a.insert(i, a.pop()) for i in range(1, len(a) + 1, 2)]
hashlib.sha512(s).hexdigest()
lines = f.readlines()
worksheet.update_cell(1, 2, form_value_1)
print(uuid.uuid4())
subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)
d1 = datetime.date(2008, 8, 15)
root, extension = os.path.splitext(filename)
-1, -2
print(f.func_count)
my_node.think()
raise TypeError(node)
a.fn()
print(df)
Orange.data.Table(tdomain, tinsts)
True
c = 1
conn = httplib.HTTPConnection(proxyHost, proxyPort)
self.finish()
{{fqdn}}
self.child_pipe.send(result)
x = len(self.left) // 2
man.start()
len(self.text)
check_matr(a, 0)
self.addButton = Gtk.ToolButton()
df
pickle.dump(db, f)
file.seek(seek)
rect = rect.move((x, y))
inside_points.append(point)
print(line)
self.x -= 1
d = datetime.datetime.fromtimestamp(posix_now)
cir.draw()
print(field)
start = datetime.datetime(2009, 2, 10, 14, 0)
self.type = type
z = np.random.random(10)
NAMES.append(name)
thread.stop()
words = line.split()
x = np.arange(12).reshape(2, 6)
[e] = S
thread = threading.Thread(target=read_from_port, args=(serial_port,))
full_path = os.path.join(root, fname)
plt.plot(xi, yi)
result[key] = [item for item in group]
cur.execute(sql)
func(*args)
y = np.ma.masked_where(x == 0, x)
egg2(*argList)
foo.foo()
inp.setchannels(1)
a = np.arange(4)
resonator.default
print(sp.coo_matrix(m.where(m.notnull(), 0)))
471
n = datetime.now()
any(filter(someDict.__contains__, someList))
v = -np.cos(np.pi * x) * np.sin(np.pi * y) * np.cos(np.pi * z)
plugin.do_work()
sys.settrace(globaltrace)
p = multiprocessing.Pool(np)
curPG.execute(sqlCmd)
animal_proxy.make_noise()
d.addCallbacks(callback, errback)
regex.sub(lambda match: conv[match.group()], text)
stdscr.clear()
loop.run_until_complete(task)
c = Counter(list1)
pickle.dump(data, outfile, pickle.HIGHEST_PROTOCOL)
multiprocessing.cpu_count()
pkg_resources.require(requirement)
s.listen(1)
context.enter_context(session)
r = [x.sum() for x in y2d]
print((x, y))
numpy.__version__
ofh.seek(0)
util.run_wsgi_app(application)
logger = logging.getLogger()
print((test.a, test.b))
end = time.clock()
globals.update(frame.f_globals)
self.stop()
hm.HookMouse()
name = forms.CharField(max_length=100)
print(next(c))
form.fileName.file.save(PATH + myFile)
x = [0.2, 0.2, 0.8]
[1, 1, 1, 1, 1],
clf = RandomForestClassifier(n_jobs=-1, random_state=42, oob_score=False)
f(*args, **kwargs)
writer = csv.writer(f, dialect=SomeDialect)
environment[k].update(v)
zip_longest(*(islice(l, i) for i in range(n)))
inner_sum += dk * f_big(A, k, 1e-05, 1e-05)
dest = bytearray(10)
X = vectorizer.fit_transform(lectures)
txt_frm.grid_propagate(False)
install.run(self)
self.request.close()
print(thefile.cleaned_input())
print(name_or_id)
io.clear()
print(sess.run(correct_prediction, feed_dict={x: test_images, y_: test_labels}))
matches = matches.reshape((rows, cols, cols))
d.append(val)
my_array = rand(int(50000000.0), 1)
dis.dis(foo)
soup = BeautifulSoup(s)
nli.get_item()
weights = np.array([16, 4, 2])
index = np.searchsorted(colkeys, keys, sorter=sorter)
block(chr(2944))
f.seek(-offset, os.SEEK_END)
p = ss.expon.fit(data, floc=0)
curs.close()
print(s)
sns.set(font_scale=0.8)
out[product_name] = []
country = models.CharField(max_length=150)
print(inst.id)
plt.figure(figsize=(10, 5))
fig = plt.figure()
fp.close()
alembic.config.main(argv=alembicArgs)
inspect.getsource(myfile)
d = defaultdict(list)
df1.div(df2squeeze())
app.run(use_reloader=False)
columns = [column.key for column in mapper.columns]
painter.restore()
new_rows = []
result.insert(0, l)
len(b)
df = sc.parallelize(row(chr(x)) for x in range(97, 112)).toDF()
a = test.Array()
print(search_result.group())
sock = socket.socket()
reverse(x)
scikits.audiolab.play(data, fs=44100)
x[(0), :, :][:, ([0, 2])]
data
Y = R * np.sin(THETA) - 2
objs.append(parse_obj())
c = concatenate((a, b))
product = models.CharField(max_length=150)
print(newer_grammar.productions()[-1])
object.__getattribute__(self, x)
data.shape = -1
0
curdict[item] = {}
print(proc.pid)
lockup
crackdown
result.append(option)
plt.show()
COMPRESS_ENABLED = True
permutations_helper(elements, [0] * n, n - 1)
chars = list(chain.from_iterable([list(set(word)) for word in l]))
print(args.n)
expr
col_names = first_reps.columns.get_level_values(2)
print(list(generate_digits_permutation()))
print(mse(model_2_v1.predict(xg_test), y_test))
ip = get_ip(request)
[2, 2, 2]
print(list_to_html(toc))
temp.append(j)
min_kmeans.fit(vectors)
[]
y - fitfunc(p, x)
a[2][1] = a[2][1] + 5
self.name = name
False
print(a.x, a.y)
a.add_rule(phyrule)
dates_dict = defaultdict(list)
print(resp.read())
pickle.dump(a, handle, protocol=pickle.HIGHEST_PROTOCOL)
response
g.writelines(ss + line for line in f)
wrapper.__doc__ = func.__doc__
print(match)
a = matrix(n)
print(True)
set.seed(1)
parser = argparse.ArgumentParser()
arr = df1.values[:, :-2]
all_subclasses.extend(get_all_subclasses(subclass))
lang.terminology
pprint(dict(year2students))
x2 = np.random.normal(-15, 7, 100000)
scr.exitonclick()
d = {}
a.insert(0, 1)
pid = sys.argv[1]
list_.append(lines[i + j][2])
os.close(fd)
diffs = array1 - array2
p.cpu_times()
kernel = np.zeros((2 * radius + 1, 2 * radius + 1))
loop.run_until_complete(run(loop=loop))
lista = [df.columns[:,].values.astype(str).tolist()] + df.values.tolist()
x = sin(pi * t)
Py_DECREF(keywords)
out += ser.read(1)
print(b.shape)
my_date.setTime(time_t * 1000)
self.errorcall(E, *args, **kwargs)
a = [4, 5, 6]
cv2.circle(img, center, radius, (0, 255, 0), 2)
self.__dict__ = dict(module.__dict__)
foo.something
print(s, sense2freq[s])
issubclass(p2, p1)
ogl.CGLGetCurrentContext.restype = ctypes.c_void_p
dt.replace(tzinfo=self)
mydriver.get(baseurl)
A.setdiag(b)
pyplot.grid()
repr(self.val)
G.add_edges_from(edges)
dict.__setitem__(self, key, value)
gevent.sleep(0)
results = api.lookup_users(user_ids=page)
plt.title(str(i))
X.foo = 67
num_array.append(int(n))
self.figure = Figure()
print(type(first_arg_unicode))
l_x.append(len(s) - 1)
infile.write(text)
result = (x for x in l if f(x))
values.append((frame, row, col, data[row, col, frame]))
[1, 0, 0],
a = np.random.randint(0, 5, size=(6, 4))
mask
myList = [gen_rand(item) for item in myList]
True
f(l)
weights = np.array(initial_weights)
arr = []
main(sys.argv)
out = np.empty((m, n, 2), dtype=int)
toks_with_adjectives.extend(adjs)
do_something_with(self._implementation())
watcher.start()
reader = csv.reader(f)
np.add.at(grids, (idx[:, (0)], idx[:, (1)]), 1)
print(len(stack))
x = mu + sigma * np.random.randn(N)
drawdown.plot(legend=True)
tag = db.ReferenceProperty(Tag)
first, rest = ks[0], ks[1:]
self.c += 1
time = np.random.random(10)
a = [0]
data = {}
files.sort(key=lambda x: os.path.getmtime(x))
df
in_file.seek(seek_offset, os.SEEK_END)
type(test.f)
df = df[::-1]
x += 1
R1 = numpy.linalg.cholesky(V1).transpose()
total = 0
swig_wrapper.py_copy(img, mem, length)
vol.append(volume[start:end])
wrapper
client.load_system_host_keys()
parent.append(self)
new_grammar._productions.append(singapore_production)
gobject.timeout_add(60 * 1000, my_timer)
x, y if x <= y else y, x
tornado.web.Application.__init__(self, handlers, **settings)
deleteoutlook, msg
text = open(path).read()
window.add(box)
new_values.append(value)
leftfile2rightfile2
user = myuser
print(is_int(x_))
name = person.key().name()
b = int(round(time.time() * 1000))
print(b)
setattr(namespace, self.dest, list)
manager = multiprocessing.Manager()
statinfo.st_size
loop.close()
self.output = QtGui.QTextEdit()
register = template.Library()
manager.operations.util.build_filter = brcd_build_filter
s = list(range(10))
b = numpy.random.randint(0, 10, 10) * 1.0
list(range(item.start, item.stop))
demo[0][0] = 1
inst.__dict__[self.attr]
1 << 8
o1 = np.lexsort(arr1.T)
x = scipy.arange(size)
loop.stop()
Customer.objects.create(**validated_data)
self.loop.stop()
strings = [str(i) for i in range(10)]
print(mytuple[2])
print(i)
b.join()
do_two()
t += 1
_recursivePop(tree, nodes[1:])
duplicate_shaders_dict
f = itemgetter(0)
c.pop(0)
self.value = min(self._max, max(value, self._min))
writer = csv.writer(buffer)
l1.append((result1, result2))
a = 4
x, y = 1, 2
print(id(object()))
value
print(bilinterp(22000, 2))
test = models.ForeignKey(Test)
values = self.request.get_all(argument)
strio.write(buffer.data())
df[df.T.convert_objects().dtypes != object]
dcObj.DeleteDC()
res2 = np.sum(a * b, axis=1)
fig, ax = plt.subplots()
c = np.random.randint(cols, size=100)
context.push()
[item.serialize for item in self.many2many]
print(json.dumps(obj, cls=MyEncoder))
print(x)
df.AVG_MINUTES = list(map(list, zip(df.HOUR, df.AVG_MINUTES)))
self.write(str(i))
np.exp(-x ** 2)
sh.setFormatter(formatter)
plt.scatter(xx, yy)
getattr(self, self.map[cb])()
app = Flask(__name__)
d = defaultdict(list)
l.insert(0, x)
a = np.array([[2, 4], [1, 2]])
print(n_neighbor(G, 1))
outputs.append(s)
print(sm2.getName())
args = parse.parse_args()
dst[0] = tmp
curl.perform()
indices = numpy.indices(shape)[axis]
found = re.findall(patbase % x, ss, re.DOTALL)
self.validate(parser, value)
rs.get()
idx = df.index.str[0]
atexit.register(exit_handler)
out.write(line)
data = np.array(data)
A[np.isnan(A)] = np.interp(x, xp, fp)
d = [c.isdigit() for c in r]
reverse.py
print(repr(decoded))
answer2 = func(remaining_map2)
groups = [df.customer, df.invoice_nr, df.date, df.amount.abs()]
self.functor = functor
queue.add(my_func, False, somearg, somekwarg=someval)
self.editname = wx.TextCtrl(self.panel, size=(140, -1))
self.request.send(data)
median = partial(quantile, p=0.5)
self.__dict__ = dict
1 + max(depth(exp[0]), depth(exp[1:]))
PP.pprint(x, width=len(x))
np.random.seed(101)
Response(status=status.HTTP_205_RESET_CONTENT)
t.join()
print(df)
b.shape
self.current = range_list[0]
f.flush()
my_data[my_data == 0.0] = numpy.nan
l.remove(l)
self.lst.append(x)
input = raw_input
auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
match = p.search(s)
n
count += 1
[(i, 100, 1000), (i, 100, 1001), (i, 100, 1002), (i + 1, 101, 1001)]
self.fnames.append(name)
loaded_mm.close()
Point(0, 1).wkt
map(lambda x: 1 if x else 0, testList)
a_frame.pack()
paw_number = np.arange(len(paw_coords))
print(hpattern % tuple(headers))
print(mystring)
B = scipy.delete(B, 2, 0)
self.console.configure(state=tk.DISABLED)
type(a)
print(f.upper().newMethod().lower())
a = a.astype(float)
pix[x, y] = value
k = np.asarray(keys)
s = im.tostring()
x = scipy.linspace(0, pi, 100)
self.camera.input_queue.put(self.idle_data_buffers.pop())
setattr(self, special_attr, value)
image = pyexiv2.Image(file_path)
result[0, 0, 0, 0, 1]
list(grps(l, 4, 2))
angle = 0.5 * np.arctan(2 * u11 / (u20 - u02))
starts = np.where(d == 1)[0]
self._meta.db_table
data = file.read()
q = Queue.Queue()
ignore[np.ma.minimum(y11, y12) > np.ma.maximum(y21, y22)] = True
dd[v].add(k)
hops
cout
ctx.move_to(0, 0)
unittest.TextTestRunner().run(suite)
root = Tk()
demo(1)
retcode = proc.poll()
t = np.linspace(0, 2 * np.pi, 20)
results = defaultdict(lambda : defaultdict(dict))
new_file.save()
time.sleep(1)
instance = BillboardTracker.objects.get(id=some_id)
find([])
rank = tf.rank(x)
f.seek(8, 1)
my_list
raise StopIteration
sleep(0.1)
False
content = sock.read()
d.setdefault(k, [k]).append(v)
formatted(10000000000)
list_of_bools = [True, True, True, False]
print(Bar.get_counter())
JM1, JM2
f(4)
self.parent().viewport().mapFromGlobal(QCursor.pos())
self.done = True
root = Tk()
test(1, 2)
seen = set()
next(reader2)
buckets = sorted(buckets, key=get_index)
set(d.items()) - set(d2.items())
self.xaxis.set_zorder(0.5)
func.value
browser = mechanize.Browser()
[comment.extract() for comment in comments]
result = numpy.sin(a)
repr(fs2)
C = [6, 8, 7, 9, 6]
lambda *a, **kw: self.command(attr, *a, **kw)
user = client_form.save()
Ti.UI.setMenu(menu)
ax1 = fig.add_subplot(111)
f.free_symbols
print(nltk.sem.relextract.rtuple(rel))
print(i.name, i.pid)
repr(obj)
seq = itertools.takewhile(lambda x: x < MAXNUM, itertools.count(2))
r[np.all(r == 0, axis=1)]
df
user1.friends[0].added_by
qp.waitForFinished()
args = parser.parse_args()
serversocket.close()
traceback.print_stack(sys.stderr)
response
autorestart = true
sys.excepthook(*sys.exc_info())
out.append(word)
df
Surface.fill((255, 255, 255))
c = db.cursor()
max(set.intersection(*matches), key=len)
py.test.cmdline.main(args)
fig.clf()
app = Flask(__name__)
chr(65)
data = f.read(8192)
1 - 10 < 0
frame = cv2.flip(frame, 180)
self.list[i]
print(df1)
self.pt_plot.set_xdata(x)
logging.captureWarnings(True)
x = np.arange(start=0, stop=5, step=0.1)
leaf[lst[-2]] = lst[-1]
first, last = [], []
user_ids.append(user_id)
self.assertResultEqual(expected, s)
img = cStringIO.StringIO(fp.read())
data = json.loads(data)
[MYSERVER]
html = response.read()
X ** 2 + Y ** 2 + Z ** 2 < radius ** 2
item_dict[sample[0]]
s = sum(ind[:i - 1])
form = ItemForm(request.POST)
a = np.random.random((10, 10, 10, 10, 10, 10, 10))
print(my_tz.normalize(my_tz.localize(dt + delta)))
mouse_tooltip.show()
[ascends.pop() for _ in range(idx)]
{1} in x
signal.siginterrupt(signal.SIGHUP, False)
df.sum()
self.pipewritestreams = []
rec.levelno in (logging.DEBUG, logging.INFO)
[1]
register = template.Library()
STOCK_ORIENTATION_REVERSE_PORTRAIT
np.nan != np.nan
self.right = []
db.session.add(user1_from_factory)
idx = np.argmax(a[i])
self.received_cookies.get(key)
s[:amount]
root = tkinter.Tk()
[a, b - a, c - b, 40 - c]
y = deepcopy(x)
print(isinstance(b, A))
glClearColor(0, 0, 0, 0)
a[::-1][200] = 6
self.view.teasers = self.prepare_teasers()
self.dg.DataContext = self
b = np.random.random((2, 5))
list_1_sorted = [e[1] for e in s]
f(x, A)
msg, address = s.recvfrom(1024)
data = numpy.zeros((x, y))
s = str(d)
data = list(range(1, 11))
happy(vs.unhappy)
y = 500 + r * math.sin(theta)
best = [1.0] + [0.0] * n
m = sorted(l)
plt.waitforbuttonpress(0)
list((found - expected).elements())
sdict
f.close()
g.write(q)
(list(range(5))[5:6] + [999])[0]
n11, n10, n01, n00
b(2, 5)
address = StringField()
names = []
d[word] += 1
HttpResponseNotAllowed(list(table.keys()))
list2 = [(i, i * 2, i) for i in list1]
bus = dbus.SessionBus()
cgi.escape(site_title), cgi.escape(URL)
label.mainloop()
w.update()
print(md.myfx(arg1))
collections.Counter(l)
mpl.show()
result
dt_aware = pytz.utc.localize(dt_naive)
i = bisect.bisect_right(intvals, x)
s = s[:20]
a = random.randint(0, 20)
nosetests - -exe
df2 = s2.reset_index()
q.set_message_class(RawMessage)
args = parser.parse_args()
flist.append(partial(func, i))
b = []
data[name(row)].append(row)
df
internet_set_option(0, self.INTERNET_OPTION_SETTINGS_CHANGED, 0, 0)
lst = [x, y, numberofcolumns, numberofrows]
self._file.close()
dict([(k, v) for k, v in list(self.items()) if fnmatch(k, match)])
y = sin(x * 2) + sin(x + 1)
print(list(od.values()))
mu, sigma = stats.norm.fit(np.log(x))
mpu.upload_part_from_file(stream, partCount[0])
print(s)
print(row)
ax = fig.add_subplot(222)
display(bg_img)
FG().f()
myfile = get_file(path)
series1 = df.iloc[(0), :]
a,
hdf.close()
txet
sigmoid(W * (x1 + x2) + B)
r = NumericProperty(0)
l = l.split()
nodes_nummpy_array[:, (2)]
sys.float_info
wn.wup_similarity(dog, car)
print(columns[0])
a = int(sys.argv[1])
print(i)
len(list(range(max(x[0], y[0]), min(x[-1], y[-1]) + 1))) > 0
points = np.linspace(x.min(), x.max(), N)
classmethod(bar).__get__(foo)()
A = [np.random.random((5, 5)) for i in range(4)]
root = tk.Tk()
print(repr(a))
print(df)
l = list(range(1, 10))
name = cls.__name__
total += i
lens = np.array(map(len, a))
print(sql)
temp.append(v)
items = ((x,) for x in sorted(ps, reverse=True))
a = numpy.arange(5)
self.updates.add(obj)
json.loads(self.data)
pprint(dict(busbar._asdict()))
self.apply_async(func, args, kwds).get()
dt = datetime.datetime.combine(d, t)
[1, 2]
the_dict[b.pop(0)] = b.pop(0)
[k]
ser = serial.Serial(0)
stream.map(model.MyClassifier.do_something).pprint()
check_for_use(True)
csv_reader = csv.reader(utf8_data, dialect=dialect, **kwargs)
s.close()
ranges.append(group[0])
pyplot.axis(ex2)
deleteself.__dict__[name]
df.join(cs)
self.__dict__.update(kw)
setattr(cls._meta.get_field(field), prop, val)
axes = all_data[ASK_PRICE].plot(figsize=(16, 12))
escapesequence = matchobj.group(0)
print(buffer(s, i, j - i))
A = np.zeros(p)
i = len(string) - 1
start = time.clock()
error()
m = A.mean(axis=1)
pp(expr)
pandas.concat(ret_list)
install_python_dependencies
app = QApplication([])
self.session_store.save_sessions(self.response)
df
self.clients.remove(client)
random.random()
A = [[1, 0, 1, 1], [0, 1, 1, 0], [0, 1, 0, 1]]
print(repr(0.1))
user = models.ForeignKey(User)
self.inner_sizer = wx.BoxSizer(wx.HORIZONTAL)
self.cells.append(Cell(self, i))
a = np.array([2, 4, 6, 8])
numloss
wx.App()
x.add(j)
[0.5, -1.0, 0.5, 0.0],
A = np.zeros((2 * (n - 1), 2 * (n - 1)))
req
print(data)
x == y
addChild(image2)
S = np.cumsum(c[1:] ** 2)
x += y
print(self.foo)
hande_file(file)
df
plt.show()
l = [(0) for i in range(n)]
fig, ax = plt.subplots()
x = mu + sigma * np.random.randn(10000)
print(new_text)
parts.append(path)
self.p.stdin.write(image.tostring())
print(normalized(A, 1))
sys.stdout.flush()
Gtk.main()
f.write(t)
x = T.dmatrix()
serializer = MyPhotoSerializer(data=request.data)
self.items
mpl.ticker.ScalarFormatter.__call__(self, value, pos)
grammar.load()
data = fh.read()
msg = MIMEText(content, text_subtype)
self.wfile.close()
time.sleep(1)
ei = sys.exc_info()
ip
19921.8126944154,
flush_transaction()
destination.write(chunk)
Base.metadata.create_all(engine)
name = models.CharField(max_length=80)
tmr.stop()
setattr_func(self, attr, value)
image = Image.open(path)
len(ln) - list(reversed(ln)).index(1) - 1
type(parsed_tree)
v = np.array([10.0, 11, np.nan])
args = parser.parse_args()
pp.savefig(plot2)
mlab.axes()
f.write(source)
pa - p0, pb - p0, pc - p0
a = Question.objects.create()
print(fcst_serie)
a = np.array(a)
self._format(object, self._stream, 0, 0, {}, 0)
type = models.ForeignKey(ContentType, editable=False)
driver.switchTo().window(curWindow)
command = os.path.normpath(command)
ax = plt.subplot(111)
f.write(text)
type(self)(self + val)
x = np.zeros((200, 2000), float)
type(obj) in (type, type)
listening_sockets.append(listening_socket)
response
b = tf.Variable(tf.zeros([1]))
angle = 2 * math.pi / s
mylist = [a, b, c]
os.nonexisting()
print(h.getresponse().read())
picture.pictureClicked.connect(self.anotherSlot)
display(self.fig)
instance = object.__new__(cls, *args, **kwargs)
data = urllib.request.urlopen(url).read()
self.lines.append(self.addLine(0, yc, width, yc, pen))
client.load_system_host_keys()
idx = np.random.randint(0, 10, (yt, xt))
print(hash(foo))
f = urllib.request.urlopen(req)
chainCalling(funcs[0](arg), funcs[1:])
lock.acquire()
residuals(p_guess, x, y)
dict((k, sorted(v)) for k, v in list(result.items()))
main()
data = {}
lock.acquire()
print((MyEnum.a, MyEnum.b))
test()
formatqn.allow_tags = True
a.append(x)
admin.site.unregister(User)
y = x ^ 1 << j - 1
sys.stderr.write(message % self.pidfile)
get_model(app_label, model_name, seed_cache=False).objects.count()
self._odict.__repr__()
session = cluster.connect()
total = total + int(n)
True
insert_many(l)
df
grid = mlab.pipeline.scalar_field(xi, yi, zi, density)
m = mmap.mmap(fh.fileno(), 0, access=mmap.ACCESS_READ)
os.remove(sockfile)
created = db.Column(db.DateTime)
print(text)
content = f.read()
result = ws.recv()
self.request_roster()
self.itemChanged.connect(self.changeBG)
btree_container.setdefault(Gnodes, []).append([Hnodes, score, -1])
delattr(self, name)
matcher = re.compile(myExpression, re.IGNORECASE)
s += element.tail
x1, y1 = np.random.random((2, 10))
combined = list(zip(a, b))
David
s += a
df
print(x)
plt.show()
rospy.spin()
self.spider = MySpider()
value = int(eval(input(prompt)))
lock.release()
words = s.split()
fig = plt.figure()
f
2 == True
api = tweepy.API(auth)
a = i & 1
print(result)
results.append(row)
df = pd.read_sql_query(sql, con)
uple1[1][0]
deletesys.argv[1]
s.bind((HOST, 0))
ax.fill_between(x, low, high, alpha=0.2, color=palette.pop(0))
f = io.StringIO()
print(i + ++i)
a = asarray(a)
x(r)
fig, ax = plt.subplots()
partslist = good_histograms(nballs, nboxes, minballs, maxballs)
columns = zip(*original_rows)
print(ceil(lgamma(100000 + 1) / log(10)))
root.clear()
nosetest
cache[args] = obj(*args, **kwargs)
mat[list(range(n)), list(range(n))] = list(range(n))
rounding_swig / testrounding.py
data = conn.recv(1024)
ax1.plot(yp, np.linspace(0, len(yp), len(yp)))
r, g, b = im.split()
map = dict(list(token.tok_name.items()) + list(symbol.sym_name.items()))
datetime.datetime(**values), tz
print(i)
i.start()
inmap(lambda x: x ** 2, a)
all(any(c == ch for c in it) for ch in x)
result[element] = result.get(element, 0) + 1
obj.isoformat()
x = A
self.window.setCentralWidget(QtGui.QTextEdit(self.window))
gevent.spawn(self.counter_loop)
db.init_app(app)
x[i] = i
out[0] = X[0] ** 2 - X[1] ** 2 + params[0] * X[0] + params[1] * X[1]
temp = sorted(list_of_medals, key=itemgetter(0))
print(cache.value.groups())
distances = pdist(X, wminkowski, 2, [1, 1, 1, 10])
mask = np.ones((rows,), dtype=np.bool)
s2.difference(s1)
self.process.terminate()
x, y = arr.shape[0], arr.shape[1]
1
json.dumps(value)
i += 1
list(data.keys())
app.run(ssl_context=context, **kwargs)
print(re.sub(expr, replace_by, mystr2))
print(myDict)
w = numpy.random.random(ndims)
top = random.randrange(0, y1)
i += 1
print(a)
x = np.linspace(0, np.pi, nx)
file.readinto(buff)
kth_order_statistic2(r, k - len(l) - len(m))
greeter.greet()
self.start()
r.clipboard_clear()
data = np.sqrt((x - s / 2) ** 2 + (y - s / 2) ** 2 + (2 * z - s / 2) ** 2)
age = FloatField()
np.random.seed(1)
INVENV = 1
result
ps = Popen(cmd, shell=True, stdin=PIPE, stdout=PIPE, stderr=PIPE)
conf.check_python_version((2, 4, 2))
[[counter[feat] for feat in all_features] for counter in counters]
root = Tk()
L = np.array([1, 1, 1, -1, -1, 1, -1, 1, 1, -1, -1, -1, 1, -1])
offset = time.clock()
d = AtomicDict()
AbortSavepoint(self, transaction.get())
1, 4, 5, 6, 12
t = np.arange(25, dtype=np.float64)
df[0] = list(range(15))
metadata = MetaData()
bar1.__class__.num
-dtrflow - mdmbuf
A = np.asmatrix(np.arange(N)).T
self.show()
time.sleep(10)
df.to_dict()
ax = plt.subplot(111)
q.set_callback(cb)
pinot_noir
help(ContextManager)
hsh.set_http_debuglevel(1)
s.mode()[0]
line.set_xdata(x1)
self.x = x
self
Foo.bar()
literal_eval(i)
Serial.println()
g = df.groupby(lambda x: x / 60)
plt.xticks([]), plt.yticks([])
self = int.__new__(cls, *args, **kwargs)
clientSocket.send(subject.encode())
myfilter.is_safe = True
eval(input())
print(get_ax_size(ax2))
int(str(num)[::-1])
self.timer = wx.Timer(self)
query
w = UICPS()
quad(f, 0, 1, args=(T,))[0]
time.sleep(i)
raise MemoryError()
print(e.args[0])
(X - xmin) / (X.max(axis=0) - xmin)
result = result.filter(or_(*_filters))
self.server = Flask(__name__)
object.__new__(cls)
plt.subplot(212)
[account2]
im_hsv = cv2.dilate(im_hsv, element)
site = request.context
ignore_list.append(file)
isinstance(other, cls)
json.dump(self.object, file)
cb()
self._value
self.data[item]
print(item)
string = repr(lst)
lst = anything
idx = np.zeros(len(m), dtype=np.int)
A.func = classmethod(func)
logger = logging.getLogger()
obj.timestamp = current_time()
r = s.get(URL)
writer.save()
logger.addHandler(sh)
sm.ReadConfig(Filename=sys.argv[1])
self._c.public()
renL.AddActor(actor)
thread = Thread(target=handler, args=(result,))
print(a.text)
cursor
new_list = []
deque(enumerate(itertools.accumulate(x), 1), maxlen=1)
pprint(mydict)
y = random.choice([top, bottom])
sys.settrace(tracefunc)
evnt.ignore()
bin8(6)
self.fed.append(d)
neighbors.remove(parent)
2
lst = []
data = np.random.randint(1, 5, 20).reshape(10, 2)
c[:] = a + b
time.sleep(5)
print(df)
df
date_ceased_to_act = models.DateField(blank=True, null=True)
1, 0, 1
conn.read()
loss = tf.reduce_mean(tf.square(y_ - y))
axs[0].xaxis.set_minor_locator(x_minor_lct)
b = np.array([9, 8])
QCoreApplication.processEvents()
raise ValueError
cursor = connection.cursor()
self.yaxis.set_zorder(0.5)
s.sort()
L.reverse()
chunk = bytes_to_int(f.read(2))
last_name = models.CharField(max_length=40)
ora_conn.close()
sm = plt.cm.ScalarMappable(cmap=my_cmap, norm=plt.normalize(min=0, max=1))
soup = bs(r.text)
out_dict[row[0]] = float(row[1]), float(row[2])
print(e)
b = a.ravel().view(dt)
any(elem in test for elem in string)
print(types.IntType())
print(circle.popleft())
s = sub.stdout.readline()
PyObject * a
temp = tempfile.NamedTemporaryFile(delete=False)
cls.x
root = tk.Tk()
menu = QtGui.QMenu()
True
out = np.concatenate(np.take(a, uind))
print(i.leaves()[-1])
Msg.Attachments.Add(attachment2)
omega = det(dstack([a, b, c]))
x += a
signal.alarm(timeout)
pd.options.display.max_colwidth = 100
result = []
sys.getrefcount(i)
firefox_profile = webdriver.FirefoxProfile()
indices = scores.argmax(axis=1)
neighbours.remove((i, j))
g * u + h * v + i * w + g * x + h * y + i * z
s = m.group()
np.sum(na, axis=0)
next((start, end) for start, end in regions if start < x < end)
len(context.products) == length
index += 1
full_path = os.path.join(dirname, fname)
x += 1
itertools.permutations(stuff, 4)
buffer.append(duo)
ax.add_artist(ab)
func_new(a)
divide(2, 7, 70, True)
X, y = datasets.make_circles(n_samples=200, factor=0.5, noise=0.05)
c = Constants()
df.power200c[7]
tempFileObj.seek(0, 0)
source[PATH_TO_YOUR_ENVIRONMENT] / bin / activate
Decimal(1).exp()
len(self.data)
cur = conn.cursor()
x = np.random.rand(N)
result += text.upper()
pyfiles
sys.stdout = sys.stderr
a2 = np.array([[2, 2, 2], [2, 2, 2], [2, 2, 2]])
print(word)
collect()(0).getInt(0)
print(next(test))
self.indexdict = {}
feet_entry.grid(column=2, row=1, sticky=(W, E))
True
fs = fluidsynth.Synth()
result.append(s_copy[:index])
self.values = []
f.seek(random.randint(0, int(unc_size[0])))
a[len(a) // 5 * 5:][1:4] = 100
(4, [2, 2]),
resp = make_response(f(*args, **kwargs))
df = df[col_list]
pool.apply_async(func=worker, args=(i,), callback=callback)
self.then_client_receives_connection_refused_error()
a.data /= np.repeat(norm_rows, nnz_per_row)
result = f()
ipy
x * y
1 / Fraction.from_float(2.54)
p = Process(target=myfunc, args=(child_conn, commands))
sess.put(url, data=xmlfile, headers=headers)
output_list
m.logout()
l.sort()
ts.tm_sec
file.write(line1)
data = self.cleaned_data
self.stackVals.pop()
self
start = datetime.strptime(start_date, date_format)
df.loc[(df.val1.shift(1) != df.val1) | (df.val2.shift(1) != df.val2)]
ret = df.loc[start:end]
start_time = Column(Integer)
[a0[start[i]:stop[i]] for i in range(len(start))]
output_lambda = df.apply(ratio).to_dict()
soup = bs(urlopen(url))
n > 0 and n & -n == n
i = arange(len(a)).repeat(a)
plt.close(plt.gcf())
s = string[0:i]
pdf = file.read()
worksheet = workbook.add_worksheet()
ax = fig.add_subplot(111)
vc = cv2.VideoCapture(0)
{}
A = zeros(D.shape)
print(u.screen_name)
median = np.median(points, axis=0)
ser = ser.sort_values()
list(d.values())
distance = np.sqrt((ix - center_x) ** 2 + (iy - center_y) ** 2)
n * n
data[slcs2][repmask] = data[slcs1][repmask]
data[slcs1][repmask] = data[slcs2][repmask]
start, stop = np.flatnonzero(x[:-1] != x[1:])
dt = a.dtype
reader = csv.reader(hosts)
print(str(tab.render()))
menu.append(menu_item)
final.append(word if word in exceptions else word.capitalize())
x = np.random.normal(i, 0.04, size=len(y))
sys.stdout = sys.__stdout__
users = group.user_set.all()
t = np.linspace(0, len(x), M)
ctx.text_extents(text)
json.dumps(mydict, cls=DjangoJSONEncoder)
D = sparse.csc_matrix(np.diff(np.eye(L), 2))
x, y = 1, 1
c = randint(0, 10)
sys.exit(app.exec_())
len(data)
result += str[start:]
logging.Formatter.__init__(self, msg)
x = np.array([random() for x in range(100)])
fs, data = wavfile.read(filename)
candidates_indexes[index] += 1
(2 << n - 1) - 1
add_timeout(deadline, callback)
p.wedge(x=0, y=0, radius=1, start_angle=starts, end_angle=ends, color=colors)
count.most_common()[0]
model = Item
print(out)
self.clear()
d.update(child.dictify())
print(date)
mod = sys.modules[module]
lines = i.readlines()
ans = [random.choice(c) for c in constraints]
output_file.close()
lcl = zzz()
row = [item.decode(encoding) for item in row]
self.parse_response(connection, command_name, **options)
a = test(a)
dtypedict.update({i: sqlalchemy.types.DateTime()})
out.truncate(1024 * 1024 * 1024)
v
plt.xticks(ind, a)
t.render(c)
df
a[index] = item + 1
mats.append(sps.lil_matrix(np.array(df2)))
matches.extend(filenames)
y = list(range(100))
pool = mp.Pool()
aClk.start(), c[:, :] * c[:, :], aClk.stop()
cb = functools.partial(self.resp, items, iteration)
r = a + b
ax1 = fig1.add_subplot(111)
1 - ab_sum / sqrt(a_sum * b_sum)
some_object.save()
i, j = np.unravel_index(a.argmax(), a.shape)
double_to_hex(17.5)
quote_swap(json.dumps(quote_swap(s)))
dataBitMap.SaveBitmapFile(cDC, bmpfilenamename)
x[f:] + x[:L + 1]
django.setup()
a = 1
t5 = MyObject()
id(a[0])
ax.add_collection(p)
e2.pack()
now = datetime.now()
print(jvdata)
browser.webframe.load(req, QNetworkAccessManager.PostOperation, data)
print(last_index)
len1 = math.hypot(x1, y1)
bar
f.close()
file = models.ImageField(upload_to=settings.FILE_PATH)
queryset
url = request.url
indices, data = zip(*data_items)
SHAhash.hexdigest()
a.data.nbytes
listOfElements[:] = [el for el in listOfElements if el.MeetsCriteria()]
matches.append(st.find(needle, i, i + len(needle)))
stack[-1].append(x)
result = list(camel.word_emitter(text))
os.chown(filepath, uid, gid)
layout = QVBoxLayout(self)
50, 0.057658, 0.114725
sys.stderr = LoggerWriter(log.warning)
t -= p * (a - an) * (a - an)
tokenizer.tokenize(txt)
x[:100, :100] = np.random.random(size=(100, 100))
red = pygame.Surface((200, 100))
print(x)
parser.disable_interspersed_args()
Feed.drop_collection()
print(b)
min_x = image_src.shape[1]
A.Multiply(False, V, B)
d[key]
f(x=0)
cc = Counter(l)
deletes[-10:]
job = models.ForeignKey(Job)
bisect.insort(r, i)
np.fill_diagonal(a, -np.inf)
print(reverse_pat.format(**matches.groupdict()))
12954124
my_bigdict.lookup()
newclass
fig, ax = plt.subplots()
LR.fit(X1[:half], y1[:half])
f(20, b=10)
self.server_id = server_id
(df.a < bval).sum() / len(df.a)
sys.meta_path[-1]._suffix = sys.meta_path[-1]._c_ext_tuple[0]
conn.close()
self._values[self._key_to_index[key]]
self.assertEqual(actual_output, expected_output)
conn = psycopg2.connect(conn_string)
clean_users.close()
do_stuff(line)
w2n, n2w
pd.Series(x).rank(pct=True).values[-1]
result = []
a * b
lst2 = line.strip()
odo(df, db.myCollection)
found.append(name)
plt.plot(x, y, out[0], out[1])
img1 = numpy.asarray(img1)
filepath = os.path.join(dirpath, filename)
X = ma.mask_rowcols(X)
print(r.headers)
string.lowercase[:14]
print(list(the_subset))
self._waitready.add(sender)
time.sleep(0.5)
main()
name = Column(String)
self.initialize(request, response)
math.atan2(-0.0, 0.0)
nones = []
t = threading.Thread(target=dummy)
remove_your_temp_file(temp_file)
print(guess_seq_len(list_b))
d[j] = j
ax.plot(x, y, color=color, **kwargs)
self.Refresh()
random.choice(self.possible_strings)
original_string.replaceWith(BeautifulSoup(text))
result.append(self.format_option_help(formatter))
arr -= arr.min()
self.path = path
c.acquire()
[num, num]
v1 = {x2 - x1, y2 - y1}
ax.broken_barh([(midpoint - 0.1, 0.2)], (perc[4], perc[5] - perc[4]))
self.thread.start()
wf.setframerate(RATE)
self.root = Node(element)
utc_dt = pytz.utc.localize(datetime.utcnow())
opt = parser.parse_args()
winsound.PlaySound(memory_file.getvalue(), winsound.SND_MEMORY)
start
body = response.body
x = (x + apositiveint // x) // 2
PyObject_Print(obj_ptr, stdout, 0)
print(map(lambda x: x ** 2, [x for x in lst if x % 2 == 0]))
x * 100 + y
all(n % j > 0 for j in range(2, n))
im.putalpha(mask)
ax.yaxis.labelpad = 50
(2)(1)
print(result)
k, v = next(iter(list(d.items())))
im = im.crop(0, 0, int(height_count * width / width_count), height)
dirs.remove(d)
print(x)
shutil.copyfileobj(f1, f2)
modules = map(__import__, moduleNames)
print(line)
sys.argv.remove(args[0])
self.subplot = self.figure.add_subplot(111)
d = OrderedDict()
rand_x_digit_num(5)
sess.run(init)
main()
res[0] = 1.0
match.b
interleave(s, t, res + s[i], i + 1, j, lis)
result = []
order = np.argsort(groups)
any()
process(newfiles)
Y = np.zeros(1000)
a.first()
b[0] = 0
output.write(new)
start = time.clock()
output
raise AttributeError(attr)
self.__dict__[key] = item
memory_file.close()
[as_row(v) for v in obj]
print(i)
idx = np.array([True, False, False, True])
[]
r = urllib.addinfourl(fp, hdrs, req.get_full_url())
myHist = ax.hist(data, 100, normed=True)
x, y, z = d[key]
builder = Gtk.Builder()
y = np.linspace(-10, 10, npts)
webelement.text()
index = -1
next(I2)
curl.setopt(pycurl.PROXYPORT, SOCKS_PORT)
r = csv.reader(file_obj)
epoch = int(time.mktime(time.strptime(d, p)))
self.loader = gtk.gdk.PixbufLoader()
y = np.random.rand(N)
cj = CookieJar()
o[-1].append(x)
response = requests.get(token_url).content
result = []
N = data.shape[1]
result = c.fetchall()
doctest.testmod()
myArray = []
formatdate(time.time())
time.sleep(10)
im[i, j] = im[i, j] + 1
x, y = generalizedEuclidianAlgorithm(b, a % b)
pix = Pix.from_rgba(image)
Serial.println(value)
data -= np.mean(data, axis=0)
pdf_contents.file.write(pdf)
(array(mat) for mat in combinations(nvectors(n), m))
i += 1
unpack_list(*list(range(100)))
fb_[i] = zeta[i] / (np.exp(zeta[i]) - 1.0)
str(d)
l[i + 1] = l[i] + n // 2
s = socket(AF_INET, SOCK_DGRAM)
print(df)
keys = tuple(data)
cols = np.isnan(g).all(axis=0)
df = pd.DataFrame([1])
h2.encode()
latest = MyObject.latest()
self.setCentralWidget(self.table)
iter.open()
prefix_match(s, taglist)
self.__ParseString(rawdata)
r = fileobj.read_into(buf)
self.crawler = CrawlerProcess(settings)
window.show()
q.submit()
self.logger.log(self.level, message)
main()
fig.add_subplot(ax)
client = Client.objects.get(pk=1)
x_range = list(range(-5, 6))
s = b.total_seconds()
list(_)
a[tuple(l.T)] = b
inner()
wb = Workbook()
m, se = np.mean(a), scipy.stats.sem(a)
self.width, self.height = width, height
self.__dict__.update(attrDict)
print(S1, S2)
up = upform.save(commit=False)
print(patient_element.tag)
dyn.put()
request.response.status = 400
y = reversed(x)
print(df)
print(x.get())
False
self.stream.write(data)
plt.yticks([])
1, 0, 0
mask = np.random.choice([True, False], size=df.shape, p=[0.2, 0.8])
fig = plt.figure()
plt.imshow(train_x[0].reshape((28, 28)), cmap=cm.Greys_r)
line = f.readline()
self.clients = []
A = np.arange(n).reshape(n // 4, 4)
HTTPServer.serve_forever(self)
p[np.diag_indices(p.shape[0])] = np.ones(p.shape[0])
self.data[0:key[1] + 1] + list(key[0].indices(key[1]))
self._content.seek(i)
+i
self.delta
my_list[0]()
Wizard.Minimize()
n + u
fd.close()
data = ff.read(4)
piecew(np.asarray([2.1]))
print(p.wait())
[list(group) for is_key, group in itertools.groupby(l, key) if not is_key]
df.date_time
foo(1, 11)
df.dtypes
print(WEEKDAYS.fri)
l = list(s)
conn = engine.connect()
client = socket.socket()
flt = [[x, 0] for x in sorted(keys, key=len, reverse=True)]
list(set(first + second))
x = np.random.normal(mu, sigma, 10000)
train_data = tf.Variable(999)
xmlfile.close()
logging.config.dictConfig(logging_config)
image = pygame.image.load(name)
grid_x, grid_y = np.mgrid[0:1:100j, 0:1:200j]
n += 1
self.aws.receive()
store.append(key, df)
np.mean(arr)
hxs = HtmlXPathSelector(response)
self._reqId += 1
print(data)
temp_dict[values[1]] = temp_dict[values[1]] + 1
ext = os.path.splitext(f)[1]
ax.legend()
(1, 1)(1, 1)
d.setdefault(j, []).append(i)
df2[i] = 0
print(a_new)
self.tiles = tiles[:4] + tiles[5:]
members = []
0.0
[L[i] for i in slice_indices(len(L), start, stop, step)]
self.ref_object.method()
print(lst[f])
all_items(get_location(get_creators(get_surrounding_cities(printer()))))
word_counter[word] += 1
step(dates, counts)
print(type.text)
url = urllib.request.build_opener(HTTPSClientAuthHandler(self.key, self.cert))
self.name = name
x[a.argmin(0), np.arange(a.shape[1])]
s = str(n)
ax2 = ax1.twinx()
data = [random.choice((0, 1)) for _ in range(2500)]
instance.user = request.user
b = np.sqrt(e)
list(compress(arr, mask))
m2.save()
x = patricia()
yaml.add_representer(str, represent_str)
self.memory[key].append(value)
counts = [0] * n
set_color(b, initcolor)
fig = plt.figure(figsize=(2, 2))
x + y
i = iter(list(d.items()))
images = mat2cell(im, size(im, 1), split_point * ones(5, 1))
print(next(g))
phone_book[name].append(number)
np.random.seed(101)
jsonpickle.encode(Goal(), unpicklable=False)
plot.append(axMiu)
chunk = tuple(itertools.islice(it, size))
struct.unpack(format, buffer)
print([i for i in df])
s & 1 << x
density = gaussian_kde(data)
element, = myset
print(a, b, c)
np.clip(out, 0, 255)
df[good]
result.append(element)
app = QtGui.QApplication(sys.argv)
x = linspace(-1, 1, n)
print(field.name)
2868466484
1649599747
2670642822
1476291629
self.get_solr_results(solr_sort)
y.remove(item)
output.close()
rows, cols = arr.shape
self._devnull = os.open(os.devnull, os.O_WRONLY)
adjs.append(tok)
data = json.dumps(options.__dict__)
i = 0
fh.setFormatter(f)
now = time.time()
self
new.append(new[i - 1] * df.A.values[i] + df.B.values[i])
wins[name] += 1
a = np.vstack(([im], [im.T])).T
print(tab.draw())
l1 = [0, 1, 0, 0, 1]
total += 1
[start] + maxchain
self.__dict__[key] = value
self.sqsregion = sqsregion or SQSREGION
list_of_numbers.reverse()
[]
transmission_array.extend([rand_num] * 400 * duration)
crawler.crawl(domain_pk)
vectors = np.array([[0, 1], [0, -1], [1, 0], [-1, 0]])
i = np.arange(M)[:, (np.newaxis)]
coords[:, 1::2, :] = coords[:, 1::2, ::-1]
soup = Soup(xml)
d += 1
16 ** (1.0 / 2)
u = np.sin(np.pi * x) * np.cos(np.pi * y) * np.cos(np.pi * z)
row += 1
tree = dict(name=os.path.basename(path), children=[])
True
row.append(SchemaTable.Rows[i][j])
api / views.py
data = np.zeros((len(ax1), len(ax2)))
result = self.a + self.b + self.c
p.connections()
print(better_uc_hex)
k = inkey()
(np.inner(a, a) - n) // 2
wtr = csv.writer(result)
p = ThreadPool(1)
s.__dict__
args[0]
print(df)
newText[:-1]
a and b
ends.reset_index(drop=True, inplace=True)
results = np.empty((4, 5), int)
tmp = np.append(b, [[clipping_value], [clipping_value]], axis=1)
b = s.post(url, data=payload, headers=headers, allow_redirects=1)
dt = datetime.now()
0
appList.add(line)
total_cost += self.session.run((self.cost, self.train_step), feed_dict)[0]
toc()
r.url
name = Column(String)
BASE_DIR = os.path.dirname(os.path.dirname(__file__))
sidx = np.argsort(searchvals)
[11, 5, -12]
merge(r1, r2, lambda a, b: a != b)
self.showNormal()
r = [s for s in sentence if s.lower() not in hello_dic]
line = sys.stdin.readline()
print(traceback.format_exception(type, value, tb))
41149
filename = sys.argv[1]
self.f.close()
dates = matplotlib.dates.date2num(list_of_datetimes)
+__init__.py
L.reverse()
myFile.close()
type(x[()])
bool(i)
tabulate(grouplist(list(range(1, 11)), 4, 2))
MyClass().ff[0]
net.addModule(output)
result = im.copy()
s = json.dumps(u, default=json_util.default)
ctx = krbV.default_context()
redirect(to, *args, **kwargs)
self.sleep_time = value
m = mmap.mmap(f.fileno(), 0, prot=mmap.PROT_READ)
func()
b = Decimal(str(b))
plt.plot(time, signal)
terminator.start()
c = ntplib.NTPClient()
threads.append(threading.Thread(target=play_audio))
funcs.append(lambda x=x: x)
0
ax.set_ylim(0, 7)
gr.add_edges_from(edges)
print(line)
print(args)
myFile.writerows(rows)
self.stopped = True
current = []
instance.register_signals()
result = (a - p) * (b - p) % p
all_pixels.append(bw_value)
Member.objects.in_group(one_group).not_in_group(another_group)
values[~valid_mask] = np.min(values) - 1.0
func(np.array([1, 2]))
self.help
self.i == other.i
s.write(urllib.request.urlopen(self.creative_url).read())
res = [value] * (2 * len(seq) - 1)
self.matplotlibWidget.axis.clear()
preprocessed = process.read()
root = Tk()
idx = np.searchsorted(sw, sCut)
b = np.ma.masked_array(a, mask=mask)
x[0] += 1
a[s]
print(result)
NULL
print(xml)
fig = plt.figure()
n
g._productions[-1]
window = pygame.display.set_mode((800, 600))
LIN[:, :d], e_values, e_vectors
data.seek(0)
ag012456789
next(iterator)
m[0] is m[1] is m[2]
norm = tf.sqrt(tf.reduce_sum(tf.square(x), 1, keep_dims=True))
setattr(self, column.name, column.default.arg)
lst.sort()
context = self.get_serializer_context()
a = list(chain.from_iterable(npa))
print(arr[(5), :])
self.it = iter(it)
Point(midx, midy)
J.sum(axis=0) * mat
self.stream.close()
plt.title(cat)
alphabet[0]
app = QApplication(sys.argv)
main()
print(MySpider.start_urls)
evenmorestuff
print(df)
frame.pack()
a.intersection(b)
self.user.save()
word = matchobj.group(0)
result = []
wrapper
p = Pool(processes=2)
input = PdfFileReader(f)
gm.setLevel(logging.ERROR)
self.q.put(new_item, *args, **kwargs)
self.finish()
result.extend(replace_with)
self._replace(x=self.y, y=self.x)
self.instance(*args, **kwargs)
self.days = days + 7 * weeks + self.seconds // 86400
s.iloc[first_valid:]
url = url.strip()
plt.hist(a, 9, weights=b)
driver.close()
np.__version__
email = db.Column(db.String(120), unique=True)
self.assertTrue(mock_warnings.called)
a == b
h1, w1 = img1.shape[:2]
msg = email.message_from_string(j)
self._attr_value_to_obj_set.pop(attr_value)
print(replchars.sub(replchars_to_hex, inputtext))
ohandle.close()
addr = ctypes.addressof(c.contents)
library(sunburstR)
loop = asyncio.get_event_loop()
result = dict(dol1, **dol2)
print(data)
A.a()
now_epoch = calendar.timegm(now_tz.utctimetuple())
name = Column(String)
print((pp + 1).year, (pp + 1).month)
100000010000
d[1] = 5
print(line.strip())
pprinttable([data])
ax1.view_init(-10, 45)
doc = docfile.read()
f = lambda x: Decimal(np.mean(x))
numpy.random.shuffle(shuffled_points)
df2.index = df2.index.map(lambda x: get_closest_match(x, df1.index))
P = mp.Pool()
do_stuff()
True
words = sentence.split()
self.id = self.num
settings.setAttribute(QWebSettings.PluginsEnabled, True)
index.append([keyword, url])
signal.connect_via(app)(listener)
print(distance(ListOfCoordinates[0], ListOfCoordinates[i]))
window.show()
threads.remove(thread)
[]
transport.open()
obj.bar = obj.foo
total_distance = sum(distances)
old = sys.stdout
year += 1
self.pack_start(gtksink.props.widget, True, True, 0)
bar().baz()
print(row.rstrip(), repr(row))
array(array(1))
a(4)
print(eval(input()))
utc_dt = datetime.now(timezone.utc)
fig.append_trace(trace2, 2, 1)
ax = [plt.subplot(g) for g in gs]
iren.start()
U.fromstring(B)
a.coeffs()
root = tk.Tk()
b.A
letters += 1
self.sizer.Add(self.result, (0, 1))
map(d.update, extras)
st = np.mgrid[1:101, 1:101]
df
self.d[k]
D().f()
thread.start_new_thread(flaskThread, ())
values = numpy.array([0, 1, 1, 0, 0])
table = [int(x) for x in table_[1::2]]
plt.plot(b, a)
results.set_value(i, j, v)
self.result = re.search(pattern, text)
g = nx.DiGraph()
dst = tk.PhotoImage()
coll = db.dataset
self.f.write(e.strip())
cursor = connection.cursor()
((key, locs) for key, locs in list(tally.items()) if len(locs) > 1)
self.f = f
data._get_numeric_data()
cache[n]
c = b.upper()
n.bit_length()
subplots_adjust(bottom=0.14)
print(type(data_for_browser_retrieverd.json))
foo = args.one
a * np.sin(2.0 * np.pi * f * t + p)
region_el = [x[0] for x in remaining]
multiprocessing.Process(target=uploader, args=(filenames,)).start()
print(row[1:12])
headers = [col.text for col in next(rows)]
keys = [k for k in list(self.keys()) if value in k]
self.func = func
freq = Counter(tuple(s[i:i + n]) for i in range(len(s)))
sys.stdout = self._stringio = StringIO()
np.sum(A, axis=0)
tmp = [a] * len(a) + [b] * len(b)
winsound.Beep(FREQ, DUR)
date
print(list_2)
type.__new__(cls, clsname, bases, dct)
c = Counter(words)
parts = urlparse(url)
print(last_wednesday)
M[0, 0]
a = {}
text.set_font_properties(font)
int(self.selenium.is_element_present(xpath1))
img.close()
HOME / anaconda / bin
p.join(DURATION - time_waited)
tv.set_rules_hint(False)
new_list
getattr(module, className)
height = GetSystemMetrics[1]
print(line)
t1 + pd.DateOffset(months=k)
pixel_at(25, 5)
self.lists[row].append(value)
sys.stdout = actualstdout
strobj2 == strobj
[p for p in database if p.y == 2]
doWalk(where, why)
foo_view(request)
new_list = [item.lower() for item in old_list]
self.name = name
(listScore == listScore[ind]).all(1).sum()
b[1:2, 1:2] = False
arr[0:2] += someVector
set_alpha_color(alpha_max)
g = parser.add_mutually_exclusive_group()
x = np.random.randn(100, 200)
os.dup2(devnull.fileno(), 1)
matches = [(t, p) for t, p in product(targets, prefixes) if t.startswith(p)]
1
a.min()
glLoadIdentity()
parsed = pool.apply_async(Process1, [largefile])
x0 = np.array([-0.72, -0.64])
A = NP.random.randint(0, 10, 100)
print(str_repr)
abc = lambda : myFunction()
user = models.OneToOneField(settings.AUTH_USER_MODEL)
ss.communicate()
pir(df.x.values)
Qt / __init__.py
item
some_template_functor < double > some_template_functor_double
values
a = [partial(lambda x: x, i) for i in range(5)]
MessageBox.Show(str(self.value.value))
ps = pandas.Series([tuple(i) for i in x])
a, b, c
f.write(string_to_write)
root = tk.Tk()
self.recent.append(mod)
funny_stuff()
temp.extend(m)
l = [(x[0], list(x[1])) for x in g if x[0] == 9]
x.reshape(x.shape[0] / 5, 5)[:, :2]
q.put(random.sample(points, 1)[0])
print(len(test.vec()))
print((index, second))
self._thread.start()
request.args[key]
csvwrite.writerow(row)
urls = []
loop = asyncio.get_event_loop()
self.x = x
{{team.name | e}}
WSGIRequestHandler.log_request(*args, **kw)
self.append(next(self.gen))
screen = pg.display.set_mode(SIZE, HWSURFACE | DOUBLEBUF)
p = Popen(cmd, stdout=PIPE, stderr=PIPE)
curses.curs_set(0)
s = json.dumps(arr.tolist())
x += 1
nges_uneval
threadLimiter.release()
l.append(2)
ax.set_xlim(xmin=-0.5)
os.waitpid(pid, 0)
self.parent._fsb_controllers.remove(self)
print(sum([(x ** 2) for x in lst if x % 2 == 0]))
data = yaml.load(text)
zlib.decompress(unknown_compressed_data)
result
x = numpy.array([[9.5, 7.5], [10.2, 19.1], [9.7, 10.2]])
duplicates = [i for i in c if c[i] > 1]
iter(M)
print(fsolve(func, guess, args=(a, b, c, n)))
Grid.columnconfigure(frame, x, weight=1)
self.wfile.write(line)
toc()
i += 1
self.__dict__ = original.__dict__
results[i] = []
sim = np.sqrt(0.5 * ((np.sqrt(dense1) - np.sqrt(dense2)) ** 2).sum())
print(b.x, b.y)
stream.filter(locations=GEOBOX_GERMANY)
p4.connect()
output.write(outputStream)
t1 = time.time()
True
html = url.urlopen(s.url).read()
actions.perform()
print(line, name)
raise AssertionError(message)
some_date.replace(day=1, hour=0, minute=0, second=0, microsecond=0)
df.count()
max = numpy.max(numpy.abs(T))
np.sum(tmp[:, i::col_sp] for i in range(col_sp))
show(p)
self._x
self.canvas.widgetlock.release(self.lasso)
ind = ind[second_mask]
main()
add_method(e, bark)
fig = plt.figure()
a, b = c[:, (0)], c[:, (1)]
form.submit()
object_list = list(list(Content.objects.filter(foo=bar).values())[:100])
write_file(data)
int(n)
Y = np.fft.fft(y) / n
i += 1
bus = dbus.SystemBus()
set(random.randint(0, 100))
[5, 6, 1, 17, 9, 18, 1, 16, 17, 10]
df
value = getattr(struct, field)
list1 = [2, 7, 8, 5]
sys.exit(main())
val = int(userInput)
food = OrderedDict((v[0], (v[1], i)) for i, v in enumerate(foods))
len(s) != l
duos.append(duo)
list(range(len(iterable)))
self.b = 2
toAdd = xyzCoord[i][:]
format_to_year_to_value_dict[format_str][year] = value
a.attr2
Models.my_model.MyClassName
order = models.IntegerField()
csvwrite.writeheader()
result[offset].append(name)
ucd.name(u2[1])
proc.kill()
data = df.values
ax = plt.subplot(gs[x, y])
print(file.line_count())
tornado.options.parse_command_line()
(10 ** 0.5) ** 2 == 10
dis.dis(fun)
test_n(n)
m = sparse.lil_matrix((100, 100))
self.updater.setSingleShot(True)
abort(401)
fmt.format(msg, lineno, colno, pos)
test(regex)
time.sleep(60 * 5)
self.fp.__exit__()
imp.acquire_lock()
a = np.arange(1, 10, 0.5)
point(self.x + oth.x, self.y + oth.y)
x
c.append([])
groups = df.groupby(df.L)
list(filter(operator.isNumberType, list_1))
self.ui.gridLayout.removeWidget(self.ui.dragDataEdit)
print(output)
(s.map(type) != str).any()
ufmt_str.format(**kwargs)
line = input()
widget = event.GetEventObject()
os.remove(tempfile)
base.metadata.create_all(engine)
b = partial(a)
self.app = Flask()
cbar = fig.colorbar(mappable=plotted)
self.forest.append(tree)
mymodule.foobar2
x = np.arange(-5, 5, 0.25)
dispatcher.connect(self.spider_error, signal=signals.spider_error)
my_own_magic(foo)
pycallgraph.stop_trace()
df.show()
a = np.array([[1, 0], [0, 1], [-1, 1]])
vals[i] = abs(np.dot(u, m2))
plt.imshow(zz, extent=(x.min(), y.max(), x.max(), y.min()))
curl.setopt(pycurl.SSL_VERIFYPEER, 1)
ordered.ordered_fields
False
g.LgRnk.rank(pct=True)
[0]
output = p.stdout.read()
main()
f.write(data)
diff = abs(results[i] - value)
valuesCopy.update({state: convergedValue})
res = urllib.request.urlopen(starturl)
self.fp.close()
pdb.gimp_file_save(image, drawable, file, file)
arr = np.asarray(bytearray(req.read()), dtype=np.uint8)
child = models.ForeignKey(Child)
fig = plt.figure()
t2.__sizeof__()
df = pd.DataFrame(data)
print(type(1))
child = pexpect.spawn(cmd)
temp.append(k)
o.two()
print(t)
self.date_start_processing = timezone.now()
result
data = csock.recv(1024)
post_save.connect(create_user_account, sender=User)
cwd = os.getcwd()
require(selectr)
main()
PyErr_Print()
exec(c, m.__dict__)
next(fo)
ipdb.set_trace()
scatter(X, Y, c=Z, **scatter_kwargs)
print(A().a1())
outputList.append(os.path.join(root, f))
im2 = im.crop(im.getbbox())
handles.append(mpatches.Patch(color=c, label=labels[i - 1]))
pts = [(np.linalg.norm([x - w, y - v]) - r) for x, y in zip(X, Y)]
print(np.sum(primes, dtype=np.int64))
self.points = [Point(i, self.coords) for i in range(numpoints)]
count += 1
hash.update(block)
w.pack()
self.user_id = user.id
sheet1 = book1.get_active_sheet()
print(row)
reader = csv.DictReader(theFile)
result = connection.getresponse()
self._metadata.reflect(bind=self._conn)
new_btn.pack()
__import__(module_name)
br = mechanize.Browser()
input = sys.stdin.read(1024)
grid = scipy.sparse.coo_matrix((weights, xyi), shape=(nx, ny)).toarray()
self.do_stuff()
timeout = time.time() + 60 * 5
print(cmd())
d = defaultdict(int)
loss = tf.square(x - y)
summation += int(letter)
lambda x: exp(x)
sct.norm.cdf(x=50, loc=60, scale=40)
m.captures(1)
img_grand.readMetadata()
ss.listen(2)
is_sum_of_numbers(5, numbers)
posts.insert(post)
f.close()
X = np.arange(200) - 100.0
connect_signal1_to_slot1()
print(res)
os.execl(python, python, *sys.argv)
L = [1] * 5
layout.addWidget(ipyConsole)
pool.close()
devnull = open(os.devnull)
outFile.close()
a = np.random.random((20, 22))
count += len(mapping[y])
--docstrings
rows = []
self.session.Logon()
np.ones(10 ** 9, dtype=np.bool)
objects = models.Manager()
message = mailer.Message()
B = np.where(A < 0.1, A, 0).astype(float)
gs = goslate.Goslate()
d.setdefault(word, []).append(i)
loop.run_until_complete(main())
i += 1
tb.activate()
c = [(lambda i=i: i) for i in range(10)]
os.remove(batch_filename)
elem.send_keys(ARROW_DOWN)
foo = Foo(list(range(10)))
points.append((-1, -0.5))
print(a)
b = a[4]
startupinfo = subprocess.STARTUPINFO()
df.info()
line = handle.readline()
out = timeobj.astimezone(pytz.utc)
index += 1
frame.pack()
loop = asyncio.get_event_loop()
print(sympy.__version__)
self.handleError(record)
pl.plot(x, dist.pdf(x))
0.0, 0.0, 0.0, 0.0, 0.0
keys[key[0]] = keys[key[0]] + d[key]
count[s] += 1
client = paramiko.SSHClient()
row.extend(sixplus(previous_row))
x = np.linspace(0, 10, 100)
user_registered.connect(user_registered_callback)
iter.destroy()
worker.moveToThread(self.thread)
print(f)
{{i}},
Xs = np.average(Xi)
True == 1
mtime = os.stat(filename).st_mtime
(x + y).subs(reps)
imagem = 255 - imagem
ts2 = ts[datetime(2011, 1, 8):]
print(id(Point(1, 2)))
key1 = models.IntegerField()
fs.program_select(0, sfid, 0, 0)
p = Pool(5)
res.append((s[i], j - i))
fig = plt.figure()
tn = telnetlib.Telnet(HOST, PORT)
df
hash(self._key())
j += self.shape[1]
Py_Initialize()
main_program.py
alist = [arr[(0), :-1], arr[:-1, (-1)], arr[(-1), ::-1], arr[-2:0:-1, (0)]]
intersections
print(df1)
dx, dy = NORTH
df
elem = ElementTree.parse(file)
data = list(tuple(i) for i in data)
int(builtins.round(number))
b = itertools.zip_longest(*a)
t = np.linspace(0, 4 * np.pi, 100)
d[v] = [i]
cap = cv2.VideoCapture(fn)
self.do_open(self.http_class, req)
True
attrs.update(list(get_choices(attrs)))
__init__
self.setFlags(QGraphicsItem.ItemIsSelectable | QGraphicsItem.ItemIsMovable)
X = np.linspace(0, 10, 100)
res.asList()
pool = Pool(pool_size)
gona[0:2, (0)]
jobs.append(job)
x = min(x, 1)
print(read_pipe())
sqrt(6 * s)
first.nonzero()
openers.append(opener)
name = models.CharField(max_length=100)
plt.legend()
d[int(key)] = val
output = [x.reshape(s0[:i] + (-1,) + s0[i + 1::]) for i, x in enumerate(args)]
mtime = os.path.getmtime(name)
g.series((x, y), (0, 0))
fs.release()
bounding_boxes.append((center, (x, y, w, h)))
mpl.rcParams.update(mpl.rcParamsDefault)
profile = user.get_profile()
i += 1
print(sli)
list(g(arr, 8))
b = np.arange(0, 25, 1).reshape((5, 5))
layer1[:] = layer2
lines = f.read_lines()
print({elem: get_linked_list(elem, d, [])[1:] for elem in list(d.keys())})
spampwriter.writerrow((s1, item, i, list1[item - 1], er1))
df
HTT += HTTflips
print(df)
n = mat.shape[0]
count = collections.Counter()
ax.broken_barh(xranges, yrange, facecolors=facecolors, alpha=1.0)
foo = Foo()
Lv = []
result = [[]]
polygon = mplpl.Polygon([(x1, y1), (x2, y2), (x2, 0), (x1, 0)], color=c)
center = xy.mean(axis=-1)
list(b.values())
row, col = im.shape[:2]
r = s.get(url)
numpy.dot(a, a)
result = np.sum(corr_time2(t_output, JM1, JM2), axis=(1, 2))
encoded = json.dumps(obj)
method()
HttpResponseRedirect(secure_url)
results = DataFrame(results, index=df.columns, columns=df.columns)
self.omega = omega
os.chdir(curdir)
f.write(chunk)
dx = POINT2[0] - POINT1[0]
arr = [bitarray(50) for i in range(10)]
type(100)
print(repr(test.read()))
print(item)
print(ascend_list)
d = df.column1.diff()
count = (cdist(listScore, np.atleast_2d([2, 0])) == 0).sum()
self.setParams(**kwargs)
print(x)
s = stdscr.getstr(0, 0, 15)
sys.path.append(basepath)
new_dict = defaultdict(list)
themsg.attach(msg)
proxy_handler = urllib.request.ProxyHandler({proxyscheme: proxyurl})
eval(command)
s.add(Math.abs(n))
Py_DECREF(pName)
False
data = json.loads(response)
7.12802865169
print(a.MY_CONSTANT)
grades[i]
math.sqrt(2) * erfi(2 * p - 1)
easy_install - -always - unzip
ws.set_remove_splits(True)
self.session.startRunning()
print(response.status_code)
cur.rowcount
plt.subplot(2, 2, 1)
print(item)
self._whatever = whatever
endpoint(*args, **kwargs)
Simbad.reset_votable_fields()
cv2.waitKey()
x = x + 5
y * y
d[k] = round(v)
logger = logging.getLogger(__name__)
self.start()
ax.set_yticklabels(yticklabels, minor=False)
assert_equal(foo, 10)
incsv.read()
ax = fig.add_subplot(224)
p.map(mp_worker, data)
fig = plt.figure()
psutil.wait_procs(children, timeout=5)
pl.plot(x, blue)
df = pd.DataFrame(y, index=x)
self.webview.getSettings().setJavaScriptEnabled(True)
math.degrees(math.atan(x))
sys.getrefcount(sys)
print((name, score))
result[..., (0)] = np.clip(im[..., (0)], 0, threshold)
df = pd.DataFrame(arr)
vault.set_vault_notifications(vault, notification_config)
[11, 14, 15, 16, 17, 18]
self.setAcceptDrops(True)
a = np.empty(10)
6, [False, False, True, False]
arr = arr[~mask]
pyaudio.pa.__file__
n
data[:] = [data[i:i + 50] for i in range(0, 2500, 50)]
cython.float
days, hours, minutes = map(int, (days, hours, minutes))
print(x, y)
pickled_state[0], pickled_state[1], new_state
d[i] = l[s:s + i]
shape = len(arrays) * a.shape[0], a.shape[1]
print(type(first_arg))
DEBUG = True
img2 = converter.enhance(0.5)
a[2, 4] = 1
mat.move(-7, -2, 0, r=True)
k = np.random.rand(1000)
lst.append(1)
print(output)
qs = self.get_filtered_queryset(qs)
list2 = [2, 2, 2, 2, 2]
{{form}}
matrix = np.random.randint(0, 10, (5, 5))
groups = dict()
fields.append((name, field.clone()))
parser.read([filename])
x = np.cos(u) * np.sin(v)
sorted(list(s1)) == sorted(list(s2))
counter += 1
next(generator)
module_name = inspect.getmodule(f).__name__
mapper.SetColorModeToDefault()
self.port = port
[([x] + []) for x in seqs[0]]
data = bytearray(os.path.getsize(FILENAME))
subcheckio(stones, 0, 0)
lock.release()
results.extend(result)
self.assertEqual(delta(9, 7), 2)
self.initfunc = initfunc
img.autoscale()
print(url)
this_array
exit(1)
np.clip(X, self.loclip, self.hiclip, out=X)
book.unload_sheet(name)
a = A()
random.shuffle(unfrozen_indices)
(128, 0, 0), (0, 128, 128), (0, 0, 255), (0, 204, 255), (204, 255, 255)
streamHandler.setFormatter(formatter)
n = int(math.ceil(math.log(abs(x2 - x1) / epsilon) / math.log(2.0)))
p = pyaudio.PyAudio()
mu, sigma = norm.fit(datos)
pool = Pool(CONCURRENCY)
Node.tree.filter(q)
x = 0
ret[np.diff(csr_mat.indptr) == 0] = 0
form = CostForm()
self.window = gtk.Window(gtk.WINDOW_TOPLEVEL)
data = self.page.mainFrame().toHtml()
self._data.columns.size
out[..., :outlen].copy()
print(df)
os.unlink(filename_larry)
fig, ax = plt.subplots()
self.filter(is_public=True)
t = threading.Thread(target=IOLoop.instance().start)
self.setBrush(Qt.green)
print(client.fetchAll())
w.pack()
result2 = pool.apply_async(solve2, [B])
words = [pair[0] for pair in v]
A = A[1:][::-1].T
title = models.CharField(max_length=255)
h[i] = h[-1]
mu = np.array([0.0, 0.0])
print(CatalanNumbers(511))
image = Image.open(filePath)
rec.levelname
v = np.linspace(0, np.pi, 100)
low, pivot, high
print(Foo.foo_string)
replaced.append(text[pos:])
app = QtGui.QApplication(sys.argv)
bets = 2 ** np.cumsum(toss2)
myResponse.raise_for_status()
self.main = MainWindow()
im.set_data(tmp)
[(-value) for value, key in smallest]
[coslat * math.cos(lon), coslat * math.sin(lon), math.sin(lat)]
print(line)
power(lambda x: x * 2, 1)(9)
context.update(extra_context or {})
start_response(status, response_headers)
result[1:4] = np.floor(result[1:4])
artist.add_reviews(review_id)
out = []
print(F[1])
bins = NP.array([0.0, 20.0, 40.0, 60.0, 80.0, 100.0])
row.pop(5)
lengths = map(len, lists)
sheet = doc.sheets[0]
transactions.sort(key=lambda date_data: date_data[0])
f = urllib.request.urlopen(req)
l1 = []
layout.set_font_description(font)
process.join()
ids = [row[0] for row in cursor.fetchall()]
food
d = {}
insanelib.xyz = myxyz
self.queryset = queryset
x, y, z = observation_points
X = 2 * X
b[0] = 97
ax.add_patch(p)
pl.xticks(x, xticks)
ret.reshape(self.shape)
print(b.shape)
[(i if t else v) for i, (t, v) in enumerate(each)]
L.append(np.log(gev.pdf(data, *fit)).sum())
deps.func()
print(line)
fileHandler.setFormatter(formatter)
copy[i], copy[j] = copy[j], copy[i]
qproc.start()
rank = list(p.values())
line = line.strip(os.linesep)
test()
self.x = x
s.send(CONNECT)
total += num
layer.paste(mark, ((im.size[0] - w) / 2, (im.size[1] - h) / 2))
a, b = tee(iterable)
a = A()
count = 0
val += int(w)
samples = np.random.lognormal(mean=1, sigma=0.4, size=10000)
v = np.exp(2 * mu + sigma ** 2) * (np.exp(sigma ** 2) - 1)
random.seed(0)
startTime = time.time()
print(tags.tag, tags.text)
b = np.corrcoef(a)
print(n[-1])
classdecorator
result[i] = foo(data[i])
deletez[2:-1]
channel.shutdown_read()
doc = etree.ElementTree(page)
nltk.data.path
result = self._result_queue.get()
profiler.stop()
pprint.pprint(solution)
p /= numpy.sum(p)
print(values[ind])
x = 0
fig = plt.figure()
posts = FacebookFeed.get_posts(user=user)
o.write(line)
d = {x: [] for x in l1}
self._x
rgb = io.imread(filename)
best = [(0, []) for _ in range(n + 1)]
line = canvas.create_line(0, 10, width, 10, width=4)
f(arg_a=0)
bool(collections.Counter())
graph.html(data)
test(B())
pix = im.load()
[-5, -5]
pdb.Pdb().set_trace(frame)
print(threading.currentThread().getName(), self.receive_messages)
setattr(args, self.dest, [strategy, path])
my_list.append(key)
print(info.st_mtime)
my_dict = defaultdict(dict)
print(f(X, Y))
color + vector * percent
target = random.uniform(0, total)
pyplot.legend(newHandles, newLabels)
setattr(self, self._attr_name, value)
A[0, 1] * 0.5
df.values[[np.arange(5)] * 2] = 0
M[num_nonzeros != 0]
process_byte(b)
hash(self.name)
bins = algos.quantile(np.unique(ser), np.linspace(0, 1, 11))
jsonify(count=counter.value)
list_of_all_primes(start, end)
context = etree.iterwalk(root)
print(timeit.timeit(lambda : split(TEST, SEPS)))
d = yaml.load(s)
tt = dt.timetuple()
sys.settrace(self.func)
pp.imshow(paw)
self.context = context
print(len(holes))
data[k] = int(v)
min_y = image_src.shape[0]
edges = cv2.Canny(gray, CANNY_THRESH_1, CANNY_THRESH_2)
data + (chr(length) * length).encode()
zorder_images.sort(key=lambda x: x[0])
username
writer.writerow(window.popleft())
string
print(l)
out += arr[:-2, 1:-1]
oldget(key)
d.callback(0)
out = np.nanmax(grouped_2Darray, 1)
self.queue = Queue()
self.regenTree()
x + y + z
cax = ax.contourf(theta_mid, r_mid, H.T, 10, cmap=plt.cm.Spectral)
a.append(1)
da.destroy()
mat = IndexedRowMatrix(traindf.map(lambda row: IndexedRow(*row)))
blahblah
top[0].reshape()
B.func()
d.wup_similarity(g)
print(df)
node_data.append(node[key])
self[key]
axs[1].plot(clust_data[:, (0)], clust_data[:, (1)])
548, 410
566, 424
print(sess.run(x_max))
ex.args = (msg,) + ex.args[1:]
0.000158164
x + 1
data = list()
app.py
M.add_edge(1, 2, weight=19)
self.a = a
diffs = map(ptdiff, zip(pts, pts[1:]))
result
f.write(response.content)
newImage.save(new_image_path)
r = R * cuberoot(u)
name = ndb.StringProperty()
print(timeit(lambda : pool.map(mmul, matrices), number=20))
opener = urllib.request.build_opener()
form = ClientForm(request.POST, instance=client)
len(host_bytes) == 4 and len(valid) == 4
image = image.convert()
plt.plot(np.arange(10) + i)
self._stream.write(text)
parser = nltk.RecursiveDescentParser(lgrammar)
ds = audiere.open_device()
nx.__version__
P(func)
m = a.reshape((a.shape[0], -1))
plt.figure()
guess_type(filename)[0]
list2.append(t)
close()
G.add_path([10, 11, 12])
-1
cv2.cvtColor(self.cvImage, cv2.COLOR_BGR2RGB, self.cvImage)
print(synset.lemmas[0].name)
item.created.year, item.created.month
f.close()
two.py
root = ET.fromstring(data)
[2011, 5, 8]
a[np.isneginf(a)] = inf
sys.stdout = buffer
blah()
print(root.filename)
print(e.__context__)
writer = csv.writer(output_file)
name = name.lower()
pseudocolor(20, 0, 100)
[6, 7, 8],
Parent.__init__(self, args[0].x, args[0].y, args[0].z)
archive.close()
print(pos[vertex])
client = oauth.Client(consumer)
fp.close()
self.data = data
result
foo.foo()
image = image.resize((tw, nh), Image.ANTIALIAS)
sys.getsizeof(anIntOBJECT)
pygame.quit()
ax2 = fig.add_axes([left, bottom, width, height])
query = parse_qs(str[1:])
zip(a, b)
print(get_diagonal(m, 1, 4, -1))
q.urlencode()
raise KeyError(key)
translation.activate(self.old_lang)
m = np.array([([i] * 4) for i in range(4)])
chars.extend([digit, next(symbols)])
result = []
print(et.tostring(r.getroot()))
fullname = os.path.join(root, f)
lambda *a: cls(method(*a))
r = s[-1::-1]
pylab.show()
h2 = logging.StreamHandler()
deletelines[i]
print(link)
popt, pcov = curve_fit(func, x, y)
cbar = plt.colorbar()
xv = numpy.linspace(0, 100, 200)
t.start()
extruded[list(range(N)), cords[:, (2)], cords[:, (0)]] = 1
print(x)
self.webview.clearCache(True)
Py_Initialize()
calendar.day_name[0]
start += len(sub)
xs.sort()
fill_array(arr, my_list)
content_type = models.ForeignKey(ContentType)
(i for i, _ in enumerate(seq, start=start))
data
f = Foo()
a = 2
fig = plt.figure()
value
doc = lxml.html.parse(s)
Qux.java
f(x=1)
template = self._lookup.get_template(self.template())
(dates - dateshift).fillna(0).dt.days.cumsum()
np.fromiter(x, int)
False
extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]
item = heapq.heappop(items)
a = (10 * np.random.randn(200, 200) + 127).astype(np.uint8)
aa.indices[aa.indptr[0]:aa.indptr[1]]
print(jo.key1)
Python - execnet
zeros_and_ones[x, y] = 1
s = StringIO.StringIO()
s = np.sin(x_axis_rotations)
random.randint(1, self.sides)
np.multiply(ray_point, 0)
x[r] = x[s]
merged = {}
d = dict(a=a)
dir(li)
pkt = pkt[IP]
search(parser.ast2list(st))
imap_utf7.decode(imap_utf7.encode(x))
array = np.asarray(array)
func1()
print(s)
b = klass()
sum(answer) / 2
window = Tk()
mainloop.run()
show()
self.app = app
q.set_message_class(RawMessage)
f = NamedTemporaryFile(delete=False)
eventlet.monkey_patch()
form = TestForm()
delta = A[nhb] - A[x]
n = sparkdf.rdd.getNumPartitions()
turtle.update()
p = x.ctypes.data_as(ctypes.POINTER(ctypes.c_double))
schema = f.read()
pool = Pool()
interact(set_cursor, x=(1, 9, 0.01), y=(0, 5, 0.01))
pyximport.install()
np.int8(128)
floor(0, 1)
raise suppress_context(TheErrorClass())
ax = plt.gca()
print(a, b)
res.sort()
other[0][0] = True
window = Window(root)
hold_lines.append(row)
p = np.asarray(prior)
row = []
ids = [row[0] for row in cursor.fetchall()]
json_dict = json.loads(json)
self.instance = MyAbcClass()
fig, axes = plt.subplots(nrows, 2)
self.ren.GetRenderWindow().Render()
pp.savefig(plot1)
sum(1 / k ** 2 for k in range(1, n + 1))
args = [iter(iterable)] * n
tasks.register(PowersOfTwo)
len(left), len(sep) + len(right)
l = LineString([(0, 0), (10, 10)])
float(sum) / n
zip(*results)
i.close()
chunk = stringio.read(256)
print([i for i in generator_overlap_split_list(l, s)])
df = df.astype(int)
1, 1, 0
d[key1] = sheet.cell_value(row_index, column_index)
sorted.__text_signature__
db.fleas.truncate()
z = numpy.arange(4 * 4).reshape(4, 4)
print([next(iters[i]) for i in dx_combo])
y[1, 1, 2]
arr = np.arange(5)
plt.sca(axes[1, 1])
x[:, ([2, 1])] = x[:, ([1, 2])]
result.append(result[-1] + 1)
print(traverse(re.sre_parse.parse(regex).data))
leng.count += 1
-Xms128m
self.dropbox_fn(filename)
dir(newImg1)
ipdb.set_trace()
dis.dis(swap_xy)
df = df.reset_index()
repr(eval(self.expression))
global_list.append(x)
self.button.clicked.connect(self.reset_counter)
Electronics | Computers | Laptops
b = [2, 5, 6]
time.sleep(i * 10)
print(i.geoms[0].coords[0])
root.iconbitmap(default=datafile)
(d.day - 1) // 7 + 1
d = MyDict(a=1)
self.assertTrue(mock_subproc_popen.called)
a = []
fig = plt.figure()
self.template = template
[(k, OrderedDict.__getitem__(self, k)) for k in self]
wrapper
print(numpy.linalg.norm(y - clf2.predict(X)))
print(xl.__module__)
urlparse.urlsplit(url)
h[0]
c = a_type(b)
output = printme.format(user=x, date=y, User=x.capitalize())
help(numpy.sin)
self._b = b
self.button.setIcon(self._icon)
json.dump(data, outfile)
login_manager.unauthorized()
client.set_missing_host_key_policy(paramiko.AutoAddPolicy())
data = self._fp.read(size)
l = logging.getLogger(logger_name)
x.sort()
soup = BeautifulSoup(res)
number_of_tries += 1
BOOST_PYTHON_MODULE(example)
array.append([])
head, rest = split_list(my_func())
baz.func()
print(counter.value)
print(list(unpack(data, 11)))
col_i += 1
n -= 1
response.text
draw()
filename = db.StringProperty()
[f.name for f in self.model._meta.fields]
cor.loc[:, :] = np.tril(cor, k=-1)
foo.func(bar)
cr = func(*args, **kwargs)
libc.prctl(15, byref(buff), 0, 0, 0)
s += 1
fout.writelines(g)
print(table_name)
print(longest_sum([1, 2, 7, 8, 11, 12, 14, 15], [], 10))
help(setattr)
ax = plt.gca()
dt[(hr >= 10) & (hr <= 16)]
process.crawl(MySpider)
self.input.GetValue()
sess.run(init_op)
a.method2()
g[:] = (elem[:2] for elem in g)
os.chdir(app_root)
_features[name]()
ret.append(link[0])
System.Security.AccessControl
C().f()
b = object_array(a, a, a)
print(df)
x = np.random.randn(5)
order_cheese()
max_idx, max_val
sku_dict[color_id].append(sku)
n = len(df[mask])
app = Flask(__name__)
log_file.write(s)
a + b == c
self.layers = [NeuronLayer(self.n_outputs, self.n_inputs)]
conn = MySQLdb.connect(**db_params)
x
self.parser = ArgumentParser()
can.create_image((x_coordinate, y_coordinate), img)
diam_out = np.maximum.reduceat(dists, shift_idx)
l.sort()
raise Exception(stdout)
best, n1, n2 = a[i] * b[j], a[i], b[j]
rows = cursor.fetchall()
data2 = pickle.load(pkl_file)
print(cell.value)
d = datetime.date(tgtdate.year, tgtdate.month, i)
print(list(ip_to_datum_map.values()))
pt2.getX() == pt1.getX()
print(sums(listgen(), 20000))
self._x = a._x
a.__private()
wrapper
txt = txt.replace(k, v)
results.append((i, li[i], j - i))
self.delays[type] = self.manager.dict()
ax.add_patch(circ)
inp = alsaaudio.PCM(alsaaudio.PCM_CAPTURE, alsaaudio.PCM_NONBLOCK)
self.app(environ, start_response)
qs.none()
self.data = self.request.recv(1024).strip()
get_language()
save_uploadfile_to_disk(a_path, file)
s.bind(i[4])
b.attr
download_thread.start()
imap.logout()
image *= 255.0 / image.max()
db_session.add(parent)
fig = plt.figure()
[pri, sec, tot]
Gtk.init([])
rv = self.next_chunk
server.mail(fromaddr)
f2 = partial(f, 42.0)
ii = np.argsort(maxvi[:, (-1)])
self._attr
start_response(status, response_headers)
newlist = []
handles, labels = ax.get_legend_handles_labels()
i += timedelta(1)
fig, ax1 = plt.subplots()
eq_(0, len(instances))
new_array = np.empty((len(uinqPos), 4))
print(fp.read())
df = pd.read_fwf(data_file)
writer = csv.writer(results)
self[key]
d[year].append(month)
style = ttk.Style()
original(*args, **kwargs)
msg = MIMEMultipart()
pool = Pool(processes=4)
set_color(w, newc)
file = sys.argv[0]
surface = pygame.surfarray.make_surface(base)
self.src[-1].extend(items[:remainder])
a.a
d = json.loads(response.get_data())
self._data.columns[col]
chunked.append(word_pos)
self.spawn(self.listener, get_your_channel_label(message))
self.request.close()
print(numpy.argwhere(a == 4.0))
logging.root.addHandler = tracer(old_addHandler)
x.stdout.close()
fig = plt.figure()
response_body = str(int(request_body) ** 2)
QtCore.QEvent.__init__(self, InvokeEvent.EVENT_TYPE)
mGui.mainloop()
optionmenu.config(width=width)
cv2.line(frame, pred[i], pred[i + 1], (0, 0, 200))
fig, ax = plt.subplots()
smbus_read_byte.argtypes = [c_void_p, POINTER(SMB_REQUEST)]
lens = [len(list(g)) for k, g in groupby(sorted(l1, key=key), key=key)]
results[i, ind] = val
response
a = [1, 4, 8]
printRecur(root)
plot([0, 1, 5, 2, 9])
dictionary = dict(zip(*([iter(List)] * 2)))
parser.feed(buffer)
plt.plot(xs)
arr = np.asarray(points)
result += 1
[n][n - 1][n - 1]
current_dict = current_dict[letter]
self.omega.append((int(round(event.ydata)), int(round(event.xdata))))
cpid = os.fork()
A.shape
df
theta = np.concatenate((theta1, theta2))
fn = os.path.join(base, file)
pygame.quit()
dt.timestamp()
t = cv2.cvtColor(cam.read()[1], cv2.COLOR_RGB2GRAY)
raise KeyError(key)
res = c.fetchall()
count[0]
NULL
x = a[1] * b[2] - a[2] * b[1]
i = 0
y = func(x)
seen = set()
article = models.ForeignKey(Article)
count[1:] = count[1:] - count[:-1]
print(key, value)
dt = datetime.datetime(year=2014, month=5, day=2)
deleter(root)
plt.show()
result = {}
[i for i in original if i > lower and i <= upper]
datetime.utcnow() + timedelta(days=1)
fig = plt.figure()
print(sp.width, sp.height)
values[1:] = values[1:] - values[:-1]
yaml.add_constructor(_mapping_tag, dict_constructor)
L = []
list(mem.keys())
f = 440.0
r = requests.post(url, data=postdata)
q = Queue(maxsize=1)
t = set([7, 8, 9])
gtk.rc_parse_string(_gtk_styles)
Function(lambda x: self(x) / other)
widget.clear()
col.append(np.array(num_rows * [i]))
main()
start = time.time()
resp.group()
results = multiprocessing.Pool(number_of_processes).map(createpdf, data)
self.form.save.assert_called_once_with(owner=self.request.user)
upper_white = np.array([180, sensitivity, 255])
Languages | LANGUAGES
groups = [data[strt:stop] for strt, stop in zip(strts, stops)]
plt.plot(x, c)
sys.exit(a.exec_())
text = node.text.encode(encoding)
user = models.ForeignKey(settings.AUTH_USER_MODEL)
width, height = fig.canvas.get_width_height()
defaultdict(type)
self.it, self.nextit = itertools.tee(iter(it))
raise AttributeError
self.app.exec_()
0, 2, 1
tk.Frame.pack(self)
application = Cling(get_wsgi_application())
cursor = connection.cursor().execute(sql)
grid = np.arange(100).reshape((10, 10))
total += (i / j).sum()
handle.read()
tree = html.parse(url)
yy = np.hstack([-1 * y[::-1], y])
words = list(map(process_group, groups))
pic = cStringIO.StringIO()
print(StudentTCI(1, 2, 10))
X, X().foo()
deferred.defer(count_colors)
self.upper()
x_test = np.array([i[1::] for i in test_data])
sess = tf.Session()
d = pd.to_datetime(df.last_updated)
emit(doc.location, [meta.id, doc.location])
print(i.geoms[1].coords[0])
self.i = 0
self.zipfile.extractall(tmp_dir)
plt.colorbar(myplot, format=ticker.FuncFormatter(fmt))
p.join()
imp.reload(module)
M[sorter[index]]
print(cur.getDatabases())
ascii_counts[ord(c)] += 1
cur.close()
self.theWholeList.append(x)
np.maximum.reduceat(dists, shift_idx)
a.difference(b)
t = threading.Thread(target=target)
data = np.random.randn(100, 10)
np.mean(values_sorted[[median_index, next_median_index]])
c = Console.getconsole()
print(respose.headers)
self.baseDict = baseDict
unique_word_count = len(set(words))
big_df = big_df.append(df)
smean.on_changed(update)
print(h.unescape(s))
popt, pcov = scipy.optimize.curve_fit(vcurve, xdata, ydata, p0=[2.0])
test1.timestamp = datetime.datetime.now() - datetime.timedelta(hours=2)
last_name = models.CharField(max_length=80, blank=False, null=False)
f.headers.headers
canvas.delete(ALL)
bg_img.composite(fg_img, left=100, top=100)
answer.append(flatResults.pop(0))
result = result.intersection(s)
ax = subplot(111)
cx1 = self._gen.random_integers(0, self.N - 2)
self.menu.addItem_(menuitem)
col_size[i] = max(col_size.get(i, 0), len(col))
width, height = im.size
logger.addHandler(fh)
x_min = tf.reduce_min(weights)
c = np.dot(a, b)
now = datetime.datetime.now()
process = subprocess.Popen(command, stdout=writer)
mlab.close(fig)
form = ContactForm(request.params)
x * x
a2 = np.empty((M, 2, 2))
cnt[word] += 1
h1, l1 = ax1.get_legend_handles_labels()
x = np.random.rand(1000) * 10
o = json.loads(s, object_hook=as_person)
arr = np.vstack(values)
d == 1
fields = [val for val in form._fields]
xfiltered
opener = urllib.request.build_opener()
poly = np.polynomial.polynomial.Polynomial(poly_coeff)
df.columns
newMtx = Mtx[:, ((s.A > 0)[0])]
image.set_from_pixbuf(pixbuf)
args = parser.parse_args()
test2 = Test()
handler = MyHandler
cls.from_buffer(a, aligned - addr)
tabWidget.load(QtCore.QUrl(url))
Frame.__init__(self, master)
sm_obj.set_x509_stack(sk)
print(one_array, two_array)
unixtime = dt - datetime.datetime(1970, 1, 1)
a1 = A[..., (1)]
foo.__code__.co_argcount
idx[0] -= 1
self.base = Base()
op = s.pop()
1
cols.insert(0, x)
print(combination)
self.thisptr.calculate(a)
c = [(i[1] - i[0]) for i in zip(a[:-1], b)]
Child().access_eclipsed()
wait = WebDriverWait(driver, 10)
reader = csv.DictReader(inf)
z = a[0] * b[1] - a[1] * b[0]
fd.close()
s.send(pickleData)
pixels = []
a = [4, 5, 0, 0, 6, 7, 0, 1, 0, 5] * 1000000
column_names = []
do_something_else_2()
hashtags.append(name)
ndarray = np.array(array_wrapper, copy=False)
l[t] = something
filechecker()
page = response.read()
data = StringIO.StringIO(data)
temp_list.append(a)
main()
d.append(new_row)
individuals.append(individuals.loc[1]).dtypes
plt.plot(*p.linspace())
rows, cols = np.nonzero(img)
_f = sc._jvm.com.blu.bla.MySum().apply
f.close()
nll = -lg[mask].sum()
instance.is_initialized = False
print(row)
request.write(values)
f = lambda x: 2 * x
res.append(func(*args))
print(lt.tm_gmtoff / (60 * 60) - (1 if lt.tm_isdst == 1 else 0))
d = json.load(json_data)
time.sleep(60)
tree = etree.parse(data)
self.setWindowFlags(Qt.Popup)
im = Image.open(buf)
[item for sublist in lst for item in sublist]
q += 1
n = n - 1
new_list = [x for x in filled_list(src_list, 100)]
text = sys.argv[1]
item += [1]
self.db[self.collection_name].insert(dict(item))
print([x for x in roundrobin(*list(group.values()))])
G = nx.MultiGraph()
result.append(next(g))
cnx._open_connection()
b = np.array([line for line in a[:, (0)]])
the_dict
email = models.EmailField(max_length=50)
father.appendChild(tag)
stdout.write(choice(ascii_lowercase))
len(self.object_list)
traceback.print_exception(type(cause), cause, cause.__traceback__)
streak = 0
flag.Parse()
image = cv.CreateImageHeader(tiff.size, cv.IPL_DEPTH_8U, 1)
newdf = df.select_dtypes(include=numerics)
rows = np.array([1, 100, 1000])
perf_func(child, func, level + 1)
w = 2 * np.pi * r
sin(x) + cos(x)
d = datetime.date(2011, 7, 2)
z = np.array([[0.0 + 0j, 2.0 + 1j, -1.0 + 4j]])
app = Flask(__name__)
pilImage = Image.open(inputImage)
a[a > 0] = 255
Counter(pop_flat).most_common()
list(helper(parts))
shape = np.sqrt(np.log(sol))
getattr(handler.request, method).add()
np.clip(dat, 0, 1, out=dat)
B.ham == A.ham
print(x)
cherrypy.quickstart(HelloWorld(), config=conf)
data = json.loads(response.body)
found = set([])
my_func_called_inside_a_task(celery_callback=True)
print(data)
args = docopt(__doc__)
self.comboBox.currentIndexChanged.connect(slotLambda)
ax.add_artist(plt.Circle((xvals[q], yvals[q]), rvals[q], color=[0, 0, 0]))
ret = ipcap.geterror()
indices = np.arange(y.shape[0])
self.children = []
dom = minidom.parseString(xml)
string.Template(tem).substitute(m)
self.axes = fig.add_subplot(111)
Tk.after(parent, 1000, change)
t1.join()
pool.apply(func=update, args=(counter, i))
data[i - window:i + window + 1].mean()
-1
cls._metadata = get_class_metadata(cls)
log.addHandler(txt_handler)
driver.find_element_by_id(id).click()
assets = []
fig, (ax1, ax2) = plt.subplots(nrows=2)
s.any() == 1
z = map(float, z)
s[:2]
print(key, value, d2[key])
db = _get_db()
fig = plt.gcf()
recv2 = clientSocket.recv(1024)
recv4 = clientSocket.recv(1024)
lst
soup = BeautifulSoup(response)
self.dependency.__exit__(exc_type, exc_val, exc_tb)
pg.QtGui.QGraphicsPathItem.__init__(self, self.path)
n = _nbits[c].sum()
ch = logging.StreamHandler(sys.stdout)
p(2) / 2 + p(2) / 2 + p(4) / 2
self.data = list(data)
wlist.append(proc.stdin)
raise KeyError(key)
a = C()
t.set_visible(False)
my_set = set(first_list)
print(StringIO(file2.read()).getvalue())
first, rest = unpack(*seq)
d = {(0): l}
json.dumps(d)
ax5 = plt.subplot2grid((6, 1), (4, 0), rowspan=2)
age = db.StringProperty()
hub.wait(watcher)
b += [c]
abs(n - m)
translater.install(str=True)
user = User.objects.get(pk=user_id)
SubClassWithoutDocstring().__doc__
fly.rect.bottom = hit.rect.top
levels = np.linspace(vmin, vmax, 200, endpoint=True)
data
datetime.min + (q + 1) * delta if r else dt
final_ensemble
results.append(left[0])
df
-1 // 2
datetime.min + math.ceil((dt - datetime.min) / delta) * delta
plt.scatter(xc, yc, c=cols, label=cla)
fout.write(line)
a[:len(b)] = b
self.queue.put(event)
print(foo)
foo1()
print(repr(path), (newpath, tail))
print(canonical_form([1, 1, 1, 0, 0, 2, 6]))
fig, ax = plt.subplots()
(x + (n,) for x in seq for n in f(x[-1]))
socket = pyudt.pyudt_socket()
others = l[:index] + l[index + 1:]
item = Item()
a = A()
print(a.current)
writer = csv.writer(output_file_handle)
lines.append(string[i:i + every])
tid
ser = pd.Series([-1, 1, np.nan])
f.__name__
x = np.linspace(-5, 5, 101)
_f
systems.append(system)
x + 1
CrawlSpider.__init__(self)
print(arrayT(data[0], [0.29, 4.5]))
raise ConcurrentModificationError(cls.__name__, self.pk)
df
ctx.select_font_face(font, *font_args)
plt.fill_between(x, 0, s)
self.Gender = Gender
str(attribute)
print(getmembers(clf.tree_))
deleter(data)
DEBUG = True
file
df = df.stack()
reps = []
Expression(body=BinOp(left=Num(n=2), op=Add(), right=Num(n=2)))
s = set([0, 1])
_[0]
two[0, 0, 0] = np.array([[2, 2]])
arr = np.asarray(str_bytes)
g, x, y = egcd(a, m)
points = data[:, 2:4]
query = users.select().order_by(users.c.id.desc())[-5:]
new_array[i, Y[i]] = 1
0
thread.start_new_thread(do_it, ())
a = [1] * 50
datasets[-1].append(stripped_line)
x = y
crawler.crawl(RaEventSpider())
norm = matplotlib.colors.Normalize(vmin=np.min(Z), vmax=np.max(Z), clip=False)
print(result)
w = pyglet.window.Window()
d[j].append(i)
Py_Initialize()
spam_lite.update()
self.__dict__.pop(k, d)
fly.rect.top = hit.rect.bottom
raise
g.logout()
sizer = wx.BoxSizer(wx.VERTICAL)
self._protected()
C1.__init__
M[(1), :] *= 2
print(globals() is locals())
d = {}
mailserver.ehlo()
person = Person()
__init__.py
cls._registry.append(cls)
centroids[i][m] += row[m] / len_best
application = app
my_dict = dict(string)
time.sleep(0.1)
int(s)
array[0]
self.pipereadstreams.append(readStream)
a = [[]] * 10
socket.setdefaulttimeout(new_timeout)
app = Flask(__name__)
outFile.write(buf)
MyModel.timestamp._auto_now = False
random.shuffle(pool)
print(resource_path)
item.firstChild.replaceWholeText(data[name])
print(df)
print(config_root.server.name)
indicies_nonzero.append(index)
print(df)
self.canv.restoreState()
o.write(line + plat[platform])
files = os.listdir(directory)
print(df.reindex(cum.index))
dset_y.append(y_chunk)
row = df.iloc[0]
p[0]
self.create_response(request, game.start())
plt.matshow(plot_matrix, cmap=colormap)
predictions = model.predict(gaussianKernelGramMatrix(Xval, X))
message.attachments = [(attachment_name, attachment.value)]
out = os.read(proc.stdout.fileno(), 10)
data_md5 = hashlib.md5(bencode.bencode(data)).hexdigest()
df2[column] = list(map(diff, df[column], ref[column]))
fig, ax = plt.subplots()
dstname = os.path.join(dst, name)
print(property.name)
print(addsf1)
print(str(datetime.datetime.now()))
new_time = time.time()
queue.write(json.loads(line.strip()))
self.saturated()
see(x)
data * 2
driver.get(target_url)
True
X, Y = NP.meshgrid(x, y)
newI()
page.close()
other[0][0] = False
1024.0
print(row)
arr[0, -1] = 100
interpolator(x)
a.sort()
result += letters[index - shift]
type(my_pandas_frame[100])
pointCloud.addPoint([0, 0, 0])
plt.xticks(np.arange(min(bins) + bin_w / 2, max(bins), bin_w), bins, **kwargs)
self.song1.setVolume(1 - fadevalue)
any(value in x for x in self.sets)
crawler.queue.append_spider(another_spider)
arr = np.split(arr, indc, axis=1)
j += 1
result = copy(dateList)
results = sorted(results_dict.items())
Z = X * Y.T
event_date = models.DateField()
singles.append(p)
self.file, self.filename
sprites.append(sprite)
QApplication.clipboard().setImage(QImage.fromData(buf.getvalue()))
Y = EY + np.random.normal(size=n) * np.sqrt(20)
x, y = line.split()
processes[i] = multiprocessing.Process(target=child_process.run, args=(i,))
u = np.empty(n, dtype=np.int64)
self._queue = q
df = pandas.DataFrame(df, dtype=str)
self.alist.extend(args)
err_ys.append((y - yerr, y + yerr))
profile = Profile.objects.create(user=user, **profile_data)
update.alters_data = True
crawler.configure()
--report_task.py
l
pr.enable()
new_path = list(path)
c // (n + 1)
i += 1
Clock.schedule_interval(self.add_string, 0.5)
print(outQ.get_nowait())
conn.sendto(some_data, MY_SERVER)
cron.write()
df.Date = pd.to_datetime(df.Date)
{song.album for song in self.allSongs}
hstack((B2, D))
flask.jsonify(error=404, text=str(e)), 404
getattr(self, method)()
tokens = deque(f.read().split())
update_object(form_class=FooForm, object_id=object_id)
get_stems_recursive(list(all_stems.items()), list(), result)
transferData.upload_file(file_from, file_to)
Book.objects.filter(**filters)[:limit]
self.goal.field.add(new_field)
is_word.words = {word.strip() for word in f}
output.flush()
a[l[i][0]][l[i][1]] = b[i]
cal = France()
pygame.init()
print(len(parts))
print(MyClassFactory.theWholeList)
plt.figure()
self.ready.notify_all()
M.ix[0]
tf.concat(0, data)
test()
r.delete(key)
doc.build(text)
output.write(string_fin)
a = A()
[(ay + be) for ay, be in zip(a, b)]
print(maximal_sum(M))
main_parser.parse_args(replace_dashes_from_args(sys.argv[1:]))
time.sleep(wait)
owner.what = owner.what.__iadd__(2)
dict_writer = csv.DictWriter(fou, fieldnames=fieldnames)
any(isinstance(e, int) and e > 0 for e in [0, 0, 1])
Wizard.NextButton.Click()
[np.arange(s, e) for s, e in zip(start, end)]
res
gevent.sleep(0.1)
cols = list(set(result.dtype.names).intersection(a.dtype.names))
foo[0] is boo
PyEval_RestoreThread(mainThreadState)
self.__dict__.update(decoratee.__dict__)
DataFrame
s.blit(alpha_img, (0, 0), special_flags=pygame.BLEND_RGBA_MULT)
[1, 24, 4, 5] in a
gb = df2.swaplevel(0, 1, 1).sort_index(1).groupby(level=0, axis=1)
prefix = decPrefixes[-1]
root.mainloop()
self.sender.disconnect(self.handle)
plt.colorbar()
do_something(my_value)
n / 1 << n.bit_length() - 1
mask1[idx1], mask2[idx2]
counter += 1
print(a)
tmp = a2[:x].copy()
string[0]
rmin, rmax = np.where(rows)[0][[0, -1]]
d = OrderedDict()
dill.detect.trace(False)
parsed_result[name].append(value)
self.connected = False
cookies = cherrypy.response.cookie
print(results.get())
int(21 / 5) + (21 % 5 > 0)
True
list(fields_660.keys())
years = collections.defaultdict(list)
s = io.BytesIO()
tk = tkinter.Tk()
clientSocket.close()
foo = d[x]
not all(row)
gst.element_link_many(self.source, self.scaler, self.fvidscale_cap, self.sink)
keep.append(item)
m[1][0] = 99
df = pd.read_csv(StringIO(txt1))
seq.append(next(it))
setattr(cls, name, decorator(m))
entity.after_put()
a = numpy.random.random((10, 10))
print(add5(10))
file_handler.setFormatter(formatter)
ctx.restore()
selected.append(perm)
r = requests.put(post_url, auth=auth, headers=headers, data=json.dumps(doc))
self.wv.webview.getUrl()
tag.replaceWith(s)
n, bins = np.histogram(samples, bins=int(np.sqrt(N)), density=True)
data = [float(v) for v in line.split() for line in file]
[s]
pprint.pprint(d)
m_to_M[1:, (0)] = -nrange[1:-1].reshape((n - 2, 1))
proc.start()
self.data = data
d = datetime.date(2011, 9, 28)
print(list(k))
y[0] = 5
a + b
self.__class__(**arguments)
s.update(list(range(4)))
source = s.get_source()
start = time.time()
d = date(year, 1, 4)
Base = declarative_base()
fig.add_axes(ax)
formset = QuoteFormSet(request.POST, request.FILES)
x = 1
[2, 1]
a[idx]
type(True)
x2 = np.interp(width_S, S_values_2[-1:idx - 1:-1], F_values_2[-1:idx - 1:-1])
addChild(image)
a, b = tee(iterable)
tree = etree.fromstring(XML)
self.client = redis.Redis(connection_pool=self.connection_pool)
new_lists.append([])
print(content.readlines())
opener = urllib.request.build_opener()
False
np.allclose(cdist_split(pairs, positions), XYZ_merged(pairs, positions))
b = a + b
mask[y:y + h, x:x + w] = 255
fig = figure(width=500, plot_height=500)
dates = [20020514, 20020515, 20020516, 20020517, 20020520]
print(a[(1), :])
overlaps < -int_overlaps(int[index[1,]], int[index[2,]])
ob.stackoverflow()
webcode.html
a = foo()
fig = plt.figure()
cursor.batch_size(1000)
output = StringIO()
data = globalsfiltered()
proc.terminate()
include_dirs.append(arg[2:])
pos = nx.spring_layout(Gcc)
mystrategy.example()
w = wave.open(wave_file)
num = 1
setattr(self.instance, name, value)
i += 2
days, hours = divmod(hours, 24)
self.totalsize
len(self.data)
raise AttributeError()
a = b[:, (0)].copy()
len(sys.argv) > 1 and scan(sys.argv[1])
print(ws.cell(rx, cx).value, ws.cell(rx, cx).ctype)
print(count_common(l1, l2))
raise AttributeError(attr_name)
df = pd.DataFrame(d.T)
print(myList)
m = multiprocessing.Manager()
content = urllib.request.urlopen(base_url + symbol).read()
a = [(float(val) / pow(2, 15)) for val in a]
name = models.CharField(max_length=255, blank=False, null=False)
s.describe()
line.replace(self.ind, self.outd)
print(the_matrix[0])
a = np.arange(24)
test_module1.py
a.name, b.name = b.name, a.name
hanoi(n - 1, start, target, aux)
key.make_public()
master_writer.save()
transaction.savepoint_commit(sid)
tag, body = next(iter(list(d.items())))
mask = x ** 2 + y ** 2 <= radius ** 2
self.lop._getsymbols() + self.rop._getsymbols()
t
1
b.values.argmax(1)
unpickler = cPickle.Unpickler(f)
protocol = QNetworkProxy.HttpProxy
d = collections.defaultdict(int)
out = np.zeros((A.shape[0] + len(cut_idx), 2), dtype=A.dtype)
v[:] = [0, 0, 0]
x = f.read()
bin_array.append(int(byte, 2))
re.split(regexPattern, example)
a = np.ndarray(shape=(N, 0))
themodule_foo(PyObject * self, PyObject * args, PyObject * keywds)
print(eastern.localize(test2))
p.wait()
im.axes.figure.colorbar(im, cax=cax, **kwargs)
self.sock.connect(self.host)
seen.update(rn)
P.drawOn(canvas, doc.leftMargin, 10)
np.save(f, c)
stats.binom_test(500, 10000)
self.song2 = song2
ax = fig.add_subplot(1, 1, 1)
context = {}
split[-1][-1].append(r)
idx = np.flatnonzero(flags)
print(val)
username = user.username
text = subprocess.check_output(command)
a.apples()
False
results.append(string[last_stop:start])
attr_name_to_attr[attr_name].set(attr_value)
res1 = np.dot(A, B)
dictpsl[key] = []
obj = np.asarray(input_array).view(cls)
first_a.test()
dataframe = pd.DataFrame(data=mat.astype(float))
self.foriterator(self.start, self.stop, self.step)
res[i, j] = dot_product(Aview[i], Aview[j], A.shape[1])
print(df)
foo.bar = partialmethod(foo.bar, qux=1)
result[0], result[-1]
username = models.CharField(max_length=256, null=True)
df = pd.io.json.json_normalize(d)
ordered = OrderedDict(pairs)
seconds = dhms_to_seconds(*convert_timedelta(duration))
os._exit()
a.sort()
a, b, c, d
u.load()
print((x, len(seen)))
fig = plt.figure()
print(key, count[key])
lock.acquire()
id(a) == id(b)
[], 1
xx, yy = np.meshgrid(list(range(-1, 1)), list(range(-1, 1)))
msvcrt.fflush(msvcrt.stdout)
out = []
util1.py
data = np.arange(k ** n).reshape((k,) * n)
x1 = np.random.normal(size=N)
pylab.show()
path = self.in_queue.get()
print(list(l))
new_matrix
x, y, w, h = win.get_allocation()
blob_info = blobstore.BlobInfo.get(resource)
res
fig = plt.figure(figsize=(ypixels / dpi, xpixels / dpi), dpi=dpi)
print(avg)
ind = np.arange(len(data)) + window
arrays[0].__array_wrap__(numpy.hstack(arrays))
v = numpy.linspace(-1 * numpy.pi / 2, numpy.pi / 2, 100)
b = c_ulong(2)
print(a)
print(combineArs(dict1[dimmKey], dict2[pwfs2Key]))
json.dumps(self)
scipy.misc.imshow(extracted_filter)
22.152261
0.284024
7.580967
Bar(income_df, notebook=True).show()
print(x * 10)
plt.legend()
a = binascii.hexlify(bytes([1, 10, 15, 16, 255]))
ax.scatter(data.Lon, data.Lat, c=data.Z, s=100, vmin=zi.min(), vmax=zi.max())
a = a + 10
print(df2)
portfolio.append(entry)
lock = threading.Lock()
recurse()
df.index.inferred_freq
time.sleep(15)
str(dict(self))
green = pygame.Surface((100, 100), 0)
test_updates(my_dict)
plt.imshow(pic)
root = tk.Tk()
encoded = ohe.fit_transform(orig.reshape(-1, 1))
l, d = foo()
tmp = np.zeros((n + 1, n + 1), bool)
read = p.stderr.readline()
l = [8, 10, 4, 5, 7]
print(date.toordinal(date(1970, 1, 1)))
t, p = f_oneway(*list(data.values()))
d = NP.digitize(A, bins)
print(merge([L1, L2]))
data = np.abs(data)
A = A[1:].T[::-1]
cimage.seek(0)
c()
y = np.asanyarray(y)
heapify(i, 0)
__all__.append(name)
total = np.sum(values[mask])
im = Image.open(fn)
req = requests.post(url, data=my_json_data)
collections.OrderedDict.__init__(self)
xy = np.random.random((2, num)) + 0.01 * np.arange(num)
print(i)
out, err = p.communicate()
dx, dy = dy, dx
b = copy.copy(a)
print(msg.SentOn)
df[col] = df[col].ffill()
crypt.mksalt(crypt.METHOD_SHA512)
y
tpool.execute(m)
False
IPython.embed()
p.join()
self.stream.send(p)
Thread(target=volume_switcher).start()
print(mode(data, axis=0))
df.FREQ = pd.cut(df.FREQ, bins=bins, labels=labels)
f_inrange
raise
x, y
array([7, 11])
Q_UNUSED(parent)
Spam.update(self)
x[0] = 10
increments_sum += increments[i]
newfunc.func = func
shared_str.value
client_to_server(messag, host, port, size)
font.configure(size=max(size, 8))
app.run()
root = tk.Tk()
b = 2
self.vtkDepth.Modified()
[5, 0],
xnew = np.linspace(x.min(), x.max(), num=41, endpoint=False)
a = my_class()
i += 1
y = np.random.normal(0, 1.0, 100)
df.loc[:, (cols)] = df[cols].where(df[cols].ge(0), np.nan)
0
Base = declarative_base()
doc.build(text)
plt.plot(x, val, alpha=0.05)
termios.tcsetattr(fd, termios.TCSAFLUSH, attrs_save)
print(date)
cnt.send_msg(data)
stud = session.query(Student).first()
print(v.data)
correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))
description = Column(Text)
opts = parser.parse_known_args()
n * factorial(n - 1)
deletetokens[-1]
json_object = json.load(response)
num2 = int(argv[2])
value = root.A[0].B[0].C[0]
parsed_url = list(urlparse(url))
obj.__reduce__()[1]
julia > pytype_query(x)
rectangle(maskRoi, roi, Scalar(255), CV_FILLED)
ax.legend_.remove()
cmap = {(1): (255, 255, 255), (0): (0, 0, 0)}
pre_save.connect(pre_save_callback, sender=models.MyModel)
plotter()
key in self._info_axis
result.append([v])
m.shape
arr1 = np.arange(10000).reshape(20, 10, 50)
a + b + c
index = items.index(item)
self.edit.setText(text)
procs.append(subprocess.Popen(ARGS_GO_HERE))
fig.set_size_inches(6.4, 5.12)
self.queue.put(item)
Response(e.message, status=400)
Fraction(1, int(yc) + 1)
int(aString, 16)
id_arr.cumsum()
print(type(domain))
seen = set()
X, Y = np.meshgrid(x, y)
i += 1
by_bins.get(True, ()), by_bins.get(False, ())
r.mainloop()
my_worker.moveToThread(my_thread)
fig = matplotlib.pyplot.figure()
suite.addTest(unittest.makeSuite(Class1))
_f
a = np.random.rand(N, N)
b = datetime(2010, 12, 7)
A1 = Al.tobsr()
print(list(o))
c += 1
redirect(list_)
defaultdict(nested)
self.spider = spider
path = os.path.dirname(path)
randomword(10)
os.mkdir(path)
i, i + len(small)
sys.stdout.write = inner
seen = set()
d = {}
output = ctypes.c_int()
curr_num = int(temp_fh.readline().strip())
self.data = data
try_one(downloader, 15)
[item for item in vqs]
log.setLevel(logging.ERROR)
g.ax_marg_x.set_axis_off()
s = list(iterable)
it = iter(iterable)
print(result[1])
s.run()
data = file.read()
np.cumsum(inds, out=inds)
self._content.seek(0)
str
l1 = [1, 1, 1]
print(len(retval))
Queue.get(self, False)
mantissas *= 10.0
print(basis[0](1))
i - len(list2)
find_leading_zeros(14)
new_result
glMatrixMode(GL_MODELVIEW)
wr.writerow(RESULT)
print(valchange(a, b))
print(platform.python_implementation())
d = lambda a, b: map(list, zip(a, b))
x[ix_i, ix_j]
output.addPage(cover_pdf.getPage(0))
min_z, max_z = z_surface.min(), z_surface.max()
cls.instances.add(instance)
parsed_result
MyModel.BLAH_FOODALLY_BOOGALY
b = [4, 5, 6]
z = np.zeros(700)
e.set_sensitive(False)
ei = (1 - math.pow(1 - e * e, 1 / 2.0)) / (1 + math.pow(1 - e * e, 1 / 2.0))
val = label_map[int(x)]
dict(name=self.name, firstname=self.first, address=self.addr)
self.fields.update(fields_for_model(User, _fields))
ser.isOpen()
print(Sentence.translate(rep_dic))
x_series.append(int(x))
Worker(request_queue).start()
list(range(max(a.start, b.start), min(a.stop, b.stop), 1))
a = np.arange(4)
fd.close()
x, y = np.meshgrid(np.arange(nx), np.arange(ny))
last_index = word.index(letter, last_index + 1)
here = os.path.dirname(__file__)
db.session.commit()
words = string.split()
city = db.StringProperty()
words[i] = word_list[words[i]]
start = np.where(A == T1)[0]
h = plt.plot(x, rv.pdf(x), lw=2)
[tuple(g) for k, g in groupby(init, delimiter.__eq__) if not k]
zip(*([chain(iterable, repeat(padvalue, n - 1))] * n))
{members}
cell_value = worksheet.cell_value(row - 1, i)
self.wtree.start()
print(result)
sC.on_changed(update)
cw = boto.cloudwatch.connect_to_region(Region)
t.join()
D = np.prod(C[..., 1:], axis=-1)
os.chdir(cwd)
b = str(a)
merge(list1, 0, 1)
app = QtGui.QApplication(sys.argv)
abcde
arr
1
pool.imap(func, images)
b = [a]
data = client_socket.recv(1024)
lst.remove(what)
pygame.display.update()
slots[s] = next(it_B)
timer = QTimer()
q = queue.Queue()
wrap(text, 16)
print(output)
print(result)
len(read_file(filename).splitlines())
values = pd.Series(df.values, index=index)
a.update([1])
new.append(a[j])
array[index].append(int(item))
parser = argparse.ArgumentParser()
patches[2]
sys.exit(0)
b = np.arange(10, 20).reshape(2, 5)
n = len(l)
[0, 0, 0, 1, 1],
c = ws.cell(row=5, column=5)
ssc.stop()
worker.dowork(lock, processes)
-1 * p(x)
x
defaults.update(kwargs)
numbers = input[2:]
main.py
get_user_model().objects.all()
x = ET.fromstring(a)
turtle.penup()
children = [n for n in nodes if n.parent == parent]
dx = r * np.cos(angle)
result.pop()
p = json.loads(x)
print_ephemeris_for_date(datetuple, bodies)
axes[0].append(string1.index(i))
saver.restore(sess, fileName)
show_views_channel[1]
worksheet.write_string(r, c, col)
self.close()
nums[-1]
l[index] = item.strip()
allowed_domains.append(hostname)
ret[key].append(item)
powerpoint.Visible = 1
print(output)
df2 = df.copy()
stats = pstats.Stats(profile, stream=stream)
do_something_further_image_processing_to_decrease_size
d[partial_key] = dict()
answer = []
self.not_full.notify_all()
d[x.tag] = x
print(self.id)
print ()
security.tokens.append(userNameToken)
output = p2.communicate()[0]
i = 1
ax = fig.add_subplot(111)
computed[n] = fib(n - 1, computed) + fib(n - 2, computed)
stack.extend(iter(v.items()))
x()
cap.release()
lst.append(0)
actions.move_by_offset(x_from, y_from)
{key: self.schema[key] for key in fields}
tcpCliSock.send(buff[i])
conn.close()
l = {}
entries_of_interest.choose(a.T)
p = np.poly1d([1, -1, 0, 0, -(stddev / mode) ** 2])
ax.set_xticklabels(xticks)
y = py_func(x)
ogl.CGLSetParameter(context, 222, ctypes.pointer(v))
main()
print(args[0], args[1])
a = df.append(pd.DataFrame(mydict, index=[0]))
globals()[funcname] = func
data = np.zeros(num, dtype=dtype)
sys.stdin = s
print((step, sess.run(W)))
df.iloc[4:6, (1)] = np.nan
logfile.write(f.read())
np.random.seed(2015)
thelist = [(key, genreOptions[key]) for key in genreOptions]
model = mc.MCMC([mean, std_dev, custom_stochastic])
t = threading.Thread(target=workon, args=(h,))
self.array[arr.mylog2(index + 1)]
pylab.plot(x)
repr(1)
(0.01).hex()
matrices[:, (0), (0)] = 1
cursor = con.cursor()
df.index = [[i] for i in tup]
User.objects.get(pk=user_id)
x0, y0, z0, w0 = np.split(quaternion0, 4, axis=-1)
cjson.decode(obj)
t = Thread(target=enqueue_output, args=(p.stdout, q))
sys.exit()
s = df.a[:5]
False
print(tone1)
click(10, 10)
s
print(all_steps(pathList))
instance.method()
dests = [dest[1] for dest in list_of_all]
visited.add(node)
Thread.sleep(500)
root = ET.parse(urllib.request.urlopen(requestURL)).getroot()
path = os.path.normpath(path)
c = np.tensordot(A, B.T, 1)
map(chars.extend, fd)
o = RelatingModel.objects.create()
d1 = date(2008, 8, 15)
barbar
self.GetEventHandler().ProcessEvent(event)
month = calendar.monthcalendar(2010, 7)
print(repr(obj), obj.__dict__)
np.put(s, p, i)
cr.fill()
p1.poll()
request.user = user
secrets.randbelow(n)
self.body
print(names[idx])
dll.myfunc(ca_array, len(ca_array))
index += 1
p.join()
exiting
prefix = commonprefix((a, b))
print((left, right))
country = models.CharField(max_length=50)
l = []
lang.install()
choice
axes[0].imshow(img)
s.sendto(NTP_QUERY, (host, port))
output.append((first, last))
http_server.listen(options.port)
draw_line(event.xdata, event.ydata)
col = np.array([7])
parent = Tkinter.Tk()
l = s.split()
replacement.seek(0)
print(sample_dict)
subparsers = parser.add_subparsers()
df.show(5)
L.append(chr(i))
result = output.getvalue()
ax.set_xlim(-1, 11)
o = urlparse.urlparse(self.path)
obj_list = []
k = np.arange(n)
print(z, x, c, v)
chain.from_iterable(combinations(s, r) for r in range(1, len(s) + 1))
user = ReferenceField(User)
print(b)
a[a == 0] = -1
c = congruent.columns.to_series().map(lkp).values
bool_arr = [True, True, False]
np.linalg.norm(np.asfarray(p1) - np.asfarray(p2))
loop = asyncio.get_event_loop()
fig.clear()
np.nan == np.nan
True
print(cmd.group())
cookies = driver.get_cookies()
self._d = d
main.show()
complex(x, y)
u, s = n, n + 1
s1.difference(s2)
print(self.state)
d = deque(s)
ax.legend()
y = list(range(200))
os.close(devnull)
foo = Foo()
stream.write(data)
my_string
diff = dict((k, n - k2.index(k)) for n, k in enumerate(k1))
d = dict(a=1, b=2)
lookup = iD - iB - iC + iA
container = np.zeros((N, 2))
output.append(item)
plt.imshow(img2)
result = method(self, *args, **kwargs)
p.process()
deallocate()
foomodule.alist.append(1)
soup = BeautifulSoup(txt)
res
ax = plt.subplot(grid[0, 0])
conn = l.accept()
self.send_response(200)
self.quit_button.clicked.connect(self.capture.quitCapture)
dic
jj = [ii[i] for i in range(1, len(ii)) if dd[i - 1] > 2]
animal.save()
self.errorcount += 1
print(c)
x, y
a = df.values
a[(2), :2, 2:]
gc.get_referents(some_list)
n2w[narrow].add(wide)
soup = BeautifulSoup(html)
SimpleHTTPServer.SimpleHTTPRequestHandler.do_GET(self)
iter.close()
df = pd.DataFrame(M).convert_objects(convert_numeric=True)
res[accmap[i]] += a[i]
[string for string in string_list if len([x for x in string_list if string in x]) == 1]
filtered = MyObject.objects.all()[start_point:inc]
opts = dict(page=context)
{}
plt.plot(x, y_fft)
col_index = {j: cell.value for j, cell in enumerate(row)}
opener = urllib.request.build_opener(cert_handler)
pts = [(1, 1), (1, lim), (lim, lim), (lim, 1), (1, 1)]
shutil.rmtree(name)
L
unconverged[unconverged] = new_unconverged
data = np.random.randn(10, 10)
m_to = db.ReferenceProperty(reference_class=UserModel)
sys.stderr = mystdout
Thread(target=reader, args=[process.stdout, q]).start()
set()
chunk = response.read(CHUNK)
self.ax = plt.gca()
some_bad_code()
values = [col.text for col in row]
b[1, 2] = 999999.0
self._a = a
result[i].append(e)
betweenness_centrality(G, k=k)
self.b
kwargs = {}
rv = self.jinja2.render_template(_template, **context)
ax.ticklabel_format(useOffset=False)
shape = []
df.info()
raise StopIteration()
f.truncate()
s1.values.append(1)
root = tk.Tk()
plt.show()
print(foo_q.__str__())
1 if text[i] == char else 0
writer = csv.writer(fout)
right = other.reindex(index=common, copy=False)
print(c.Bread)
credentials = GoogleCredentials.get_application_default()
t1 = timeit.timeit(closure, number=10 ** 4)
figure(figsize=(10, 10))
files = glob.glob(fullpath)
print(s.before)
c.setopt(pycurl.SSL_VERIFYPEER, 0)
self.id < other.id
print(point.x, point.y)
copy.copy(self.pred)
self.X == other.X and self.Y == other.Y
console = logging.StreamHandler()
QNetworkAccessManager.createRequest(self, op, request, device)
ax = plt.axes()
print(isinstance(b, B))
BASE_DIR = os.path.dirname(os.path.dirname(__file__))
test.debug()
array1.tolist()
r = conn.getresponse()
c1.acceptor_id = c2.donor_id
self.update(n=starting, b=birthrate, i=imrate, e=emrate, d=deathrate)
c1.acceptor_id = c2.acceptor_id
m = np.random.normal(0, 1, size=(5, 2))
True
getattr(mod, kls_name)
a[index] = float(value)
kde = stats.gaussian_kde(values)
color_segment(polygon_coordinates)
print(dir(p))
deleteself.indexdict[index]
to_sequence(range(5))
x = 0.0
sj.load(f)
subprocess.Popen(console + cmd)
print(roundPartial(9.74, 0.1))
GeeElem(self.doc.getroot())
print(next(results))
True
gunicorn == 18.0
C = np.outer(A, B)
print(v)
self.memoized = {}
tuple(i / inch for i in tupl[0])
fig.clf()
sct.norm.isf(q=0.05, loc=60, scale=40)
print(common_dict(json1, json2))
qmessage
resp = conn.getresponse()
doSomething(value)
min_val = min(d.values())
self.period, frozenset(list(self.dimensions.keys()))
start, end = match.span()
merge(main, 0, 1)
key
filepath = os.path.join(root, name)
cap.destroyAllWindows()
start = time.time()
bar = request.args.to_dict()
self._results = []
a = [5, 8, 9]
out[i] *= 2
args = parser.parse_args()
word = models.CharField(max_length=255, unique=True)
pdb.post_mortem(traceback)
val = d2.get(k, 0)
salt = models.CharField(max_length=40)
print(start.dt)
res = collections.defaultdict(lambda : 0)
cd / System / Library / Frameworks / Python.framework / Versions
filtered_array[area_mask[id_regions]] = 0
d[s]
rows[i].pop(pos)
printTree(tree, child, nodeMap)
sleep_for_a_bit()
print(self.name)
do_something_with(database)
pyobj = ctypes.py_object(obj)
x = np.linspace(0, 4 * np.pi, 100)
(1)(1, 40020)
serializer = UserSerializer(queryset, many=True)
p = random_derangement(N)
ret.append(result)
serializer_class = PurchaseSerializer
XGBClassifier(max_depth=10)
print(in_[0][i], out[0][i])
observer.join()
print(k, tally[k])
plt.figure().show()
p = Pool(12)
not len(unique_list) == len(set(unique_list))
d[t] = [next(iterator) for _ in range(n)]
MyModel(number=i).save()
df = pd.DataFrame(l, columns=l[0]._fields)
self.celery.wait()
a[:, (0)]
minm = np.append(minm, i)
df
df
x % m
min(list_date, key=func)
categories = [d for d in os.listdir(root) if isdir(join(root, d))]
model = db.StringProperty()
generator_fn.__code__.co_flags
print(row)
gevent.spawn(read_stream, p2.stdout)
df = pd.DataFrame(dict(A=np.arange(len(tidx))), tidx)
legline.set_transform(trans)
pywintypes27.dll
total = sum(amounts)
count += 1
sess = tf.Session()
d[k] = v
names = os.listdir(src)
x[x < -1000] = np.nan
self.pargs = pargs
messages = inbox.Items
task = getattr(self, next_task_name)
print(columns[0])
es_tracer.setLevel(logging.DEBUG)
set.union(*l)
users.insert(1, users.pop())
d = defaultdict(list)
curses.use_default_colors()
g = lambda x: x + 5
do_something_with(start_date, list(group))
values = np.asarray(values)
args
l[i]
a = []
print ()
root = Tk()
file.write(b)
res = urllib.request.urlopen(req)
ax.barh(arange(len(x)), x, 1)
f.seek(pos)
old = np.concatenate([x[b:e] for b, e in zip(start, stop)])
math.sqrt(dot(v, v))
server_socket = socket.socket()
a ^ b
name = MyClass.__DefaultName
A += F[i, j] * V[(i), :] * V[(j), :]
print(df)
False
lengthB *= unitPpix[0, 0]
out[nr - 1:] = col2_2D
pool.close()
print(d.get(42, default))
outF.write(inF.read())
context = inspect.currentframe().f_back.f_locals
random.seed(4)
x[-9]
Y, X = np.mgrid[y.min():y.max():20j, x.min():x.max():20j]
locale.setlocale(locale.LC_TIME, lc)
num = abs(num)
A = np.arange(N)
instance = form.save()
stream_handler.setLevel(logging.INFO)
ctx = cairo.Context(surface)
ax.cla()
idx = np.argsort(r)
y = int(line.strip()) + int(line.strip())
print(s.model())
t = name,
ax.add_line(self)
str.upper(m.group(0))
server.start()
print(json_files)
print(somelist[start:stop])
np.allclose(a[:, :, :, :, (0)].ravel(), collapse_dims(a)[:, :, :200].ravel())
solve([Eq(int_fx, m), Eq(int_gx, m)], (a, b))
print(myunique(a))
wrapper
PyUnicode_IS_COMPACT(op)
sm.stats.normal_ad(x)
doc = libxml2.parseMemory(content, len(content))
x = np.linspace(0, 20, 100)
second = itemgetter(1)
df
curline += 1
print(obj.value.T)
np.clip(out, 0, 255)
hash(str(self))
timer = threading.Timer(timeout, thread.interrupt_main)
C.__mro__
self._setup_queues()
result = []
BY = np.take(B, y + 1)
self._list[index]
treeaslist.extend(self.makeList(aNode.lChild))
wrapper.__dict__ = func.__dict__
my_namedtuple(final, first_step, second_step)
print(sorted(permutations(L), key=space_sum, reverse=True)[:100])
print(line)
x0 = self.canvas.canvasx(0)
c + 1
d.a[i:i + k]
field2 = forms.IntegerField(required=False)
s.f2()
result.clear()
FACTORY_FOR = User
print(data)
df.loc[index_list]
-W900 - -ignore < catalina.log
alns_list.append(aln)
print(item)
tabin = [ord(char) for char in tabin]
raise KeyError(key)
print(first_user.name)
self._log.close()
v1_api.register(UserResource())
desired_capabilities.update(options.to_capabilities())
c = csv.writer(f)
scenario.skip(require_not_executed=True)
test_suite.addTest(unittest.makeSuite(UserServiceTest))
app = wx.App()
print(enu.count)
Thread.__init__(self, group, target, name, args, kwargs, Verbose)
testit
print(wx.GetDisplaySize())
os.umask(0)
do_some_other_thing()
p.data = np.random.choice(np.arange(20) - 10, len(p.data)) / 10
print(b.shape)
fh.setLevel(logging.DEBUG)
x = np.random.random(100)
gg.plot(graph.data.values(x=dt, y=xcorr), plotstyles)
self.assertEqual(testuser, user.username)
NotImplemented
[comment.extract() for comment in comments]
pool = Pool(4)
df = s.groupby([s.index.weekday_name, s.index.hour]).sum().reset_index()
idx = np.arange(m.shape[1])
ignore[np.ma.maximum(x11, x12) < np.ma.minimum(x21, x22)] = True
USE_TZ = True
(df.location != df.location.shift()).cumsum()
post_save.connect(invalidate_portfolio_index, sender=Entry)
func(*args, **kwargs)
print(l)
self.name
print(df)
engine.block()
f = plt.figure()
y = (x + n // x) // 2
json_data = json.dumps(model_to_dict(user_obj))
WSGIScriptAlias / sauron / home / galdosd / finalsauronweb / django - root / apache / django.wsgi
temp = []
cipher = AES.new(self.key, AES.MODE_CBC, iv)
smtp_conn.starttls()
all(sympy.Eq(sympy.diff(expr, *t), 0) for t in combs)
lst = [0] * (r + b)
active_window = screen.get_active_window()
index = dict((tuple([n]), i) for i, n in enumerate(leaves))
Testing(8 / 8)
df.describe()
f = tar.extractfile(member)
lines = []
s.quit()
print(s)
it = iter(list(range(4)))
array = np.empty(shape=(2, len(result)), dtype=float)
self.bind(b=self.set_c)
B = Y.imag
f(arg_b=0)
X, Y = np.meshgrid(xs, ys)
kwargs[field_name] = getattr(model_instance, field_name)
print(list_bars[int(i) - 1])
self.comboBox = QtGui.QComboBox(self)
lines = iter(lines)
next(infile)
t.amount += 1
type(os.urandom(10))
bSizer.Add(button4, 0, wx.ALL, 5)
self.projectiles = []
roundup(100)
cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)
x = np.arange(0, 1000)
self.old_headers = self.br.addheaders
dic = {}
string[n]
args = inspect.getargspec(f)
np.set_printoptions(1, threshold=100, suppress=True)
self
trav(listD)
ax.set_ylim(-1, 9)
self.data = self.request.recv(1024)
p.search(s)
False
result = np.cumsum(some_array)
print(self.some_param)
fig = plt.figure(figsize=(11, 11))
q = Queue()
len(word) > 5
repeatlist(B, len(A))
data = []
greater.append(x)
foo.bars.add(bar2)
self.items.extend(other.items)
df1.join(df2)
self.linkHovered.emit(anchor)
seen.add(n)
dom = parseString(data)
conn.endheaders()
form = SQLFORM(db.foo)
plot(time, y2)
length = int(s)
outfile.write(out)
name = models.CharField(max_length=64)
buf = f.read(8192)
self.turnnow,
app = QtGui.QApplication(sys.argv)
self._host = host
func(a=2, b=6, c=8)
X = iris.data[(iris.target == 0) | (iris.target == 1)]
app = Flask(__name__)
handler = logging.StreamHandler()
canvas.print_png(png_output)
plt.loglog(x, y, basex=np.e, basey=np.e)
df = pandas.DataFrame(data=numpy.random.random((m, n)))
print(df)
self.value = value
print(a + 2)
tk.Frame.__init__(self, master)
output[0].lower() + output[1:]
c1 = csv.reader(f1)
print((a,))
d = defaultdict(bool)
conn.send(result)
df = pandas.DataFrame(a).groupby([0])
list({song.album for song in self.allSongs})
x = np.sort(x)
movie_dict[actor] = [key]
sample_size = 0
print(mkl_get_max_threads())
print(etc.__file__)
values = np.atleast_2d(func(points))
b = [(binsize * k) for k in range(imin, imax + 1)]
entries = [list(entry) for entry in entries]
(2009, 1, 1), datetime.date(2009, 1, 19), datetime.date(2009, 2, 16)
koch_fractal(yertle, 2, 100)
str(self.matrix)
pool.close()
df2[df2.mi.isin(df2.mi.value_counts() > 2)]
arrays = np.split(x, np.where(x == -1)[0])
[10, 9, 8, 9, 10, 11, 10, 9],
result.append(self.visit(z))
data = yaml.load(txt, yaml.SafeLoader)
r = f.read()
y.remove(i)
self.children.count()
l1[0:1] = l2
item[0], int(item[1][1:] or 0)
conn.login(account)
list(dic1.keys()) | dic2
df5.head(10)
s.a.b.c.d
sys.stderr = _LogWriter()
self.remove_unpickleable_attributes()
mahotas.polygon.fill_polygon(pts, canvas)
str(self.__dict__)
id = models.AutoField(primary_key=True)
self.memo[str] = self.fn(*args, **kwds)
ylim([-4.5, 4.5])
method
1 < {}
ax = fig.add_subplot(111)
l2_copy.remove(i)
y = np.sin(x) + np.random.random(N) * 0.2
cert = ssl.PEM_cert_to_DER_cert(cert)
print(template.format(*map(str, l)))
s.prompt()
self.remove_fields_from_representation(representation, remove_fields)
signal.signal(signal.SIGALRM, alarmHandler)
{{login_form}}
parser = HTMLParser(recover=True)
new_save
cursor.execute(stmt)
name = models.CharField(max_length=255)
Decimal(0.1)
self.weights = []
dict(list(kwargs.items()) + zip(spec, args))
starts = np.hstack(([0], nonoverlapping + 1))
process = subprocess.Popen(command.split())
app.exec_()
loop = asyncio.get_event_loop()
result = {t: [p for p in prefixes if t.startswith(p)] for t in targets}
globs = frame.f_globals
fig = pylab.figure()
colors = cmap(np.linspace(0, 1.0, len(kinds)))
x, y, z
x = np.linspace(0, 1, 1000)
width = int(cap.get(cv2.cv.CV_CAP_PROP_FRAME_WIDTH))
colb[n] = 0
result = map(_fuc1, samplez)
(b.A == 2) & (b.B == 2) & (b.C == 2)
self.wealth = 1.0
df.index.freq
sorted((c for c in nx.simple_cycles(DG) if node in c), key=len)[0]
result.append(self.indent(s))
tf.reduce_sum(tf.mul(tensor, identity_matrix(n)), [0])
aaaa
self.stream.parse(data)
BEGIN
print(match)
sportDict[ransport].append(name)
person.items.update(other.items)
transaction.enter_transaction_management(using=self.db)
yaml.add_representer(np.ndarray, opencv_matrix_representer)
self.serialc.quit()
print(df)
y = np.mean(X, 0)
binary_insert(r, Node(5))
l[i]
print(os.name)
self.cursor.execute(sql, args)
repo.remotes.origin.pull()
df6 = df.ix[:, 60:72]
main()
x = np.linspace(1, 5, 10000)
test_func()
records.append(record2)
stdout = sys.stdout
map(chr, list(range(65, 91)))
d[k] = int(v)
scene.camera.location.y = ty
q = q.filter(or_(*conditions))
sys.setrecursionlimit(maxint)
print(new_dict)
sps_acc = sps_acc + sps.coo_matrix((d, (r, c)), shape=(rows, cols))
b = 2
df = tempDF
print(d1 + td(days=i))
myarray[(myarray >= 2) & (myarray < 5)] = 100
os.getcwd()
show()
print(guess_seq_len(list_a))
c = count_events(e)
[self.combine(x) for x in X]
main()
[server - symlinks]
indices = np.vstack(np.unravel_index(np.arange(x * y), (y, x))).T
self.a = a
temp = [item for sublist in listD for item in sublist]
print(t)
moreVerbs.extend(getVerbsFromConjunctions(moreVerbs))
ax.plot(x, y)
self_dict[attr]
resid.flatten()
ftp_handle.cwd(original_cwd)
platform.uname()
output.put((pos, rand_str))
c.append(itemgetter(i)(a))
getsizeof(dict((n, 0) for n in range(5461))) / 5461.0
(np.convolve(np.convolve(A, K) >= WSZ, K)[L:-L] > 0).astype(int)
a = X()
length = ctypes.c_ulong(0)
ndb.put_multi(users)
process(line)
page = paginator.page(1)
serializer_class = UserSerializer
filters.append(Q(is_default=False))
InteractiveConsole.__init__(self)
y = sum(x > i for i in x)
self.limit = 10
list(seen_twice)
arr = sparse.coo_matrix((data_f, (rows_f, cols_f)), df.shape, dtype=np.float64)
print(sys.getrefcount(X))
html = Template(fp.read())
writer.writerow(row + [to_append])
yertle.begin_poly()
t.show()
diag = np.ones(n - 1)
t.start()
x, y
b = datetime.now()
reader.Close()
wb = Workbook()
asc.append(i)
dt - timedelta(seconds=time_tuple[-1])
TYPES[type_name].from_dict(value)
dis.dis(my_fun)
print(filename, lineno, strrepr)
os.setgroups([])
print(df.star_name)
df_list = []
instance = reservation.instances[0]
form = DjForm(data=data)
document.exitFullscreen()
a = f()[0]
bar.close()
idx = np.ravel_multi_index(arr, arr.max(1) + 1)
False
type(d)
session = sessionmaker(bind=engine)()
cap0.set(4, 120)
ax = fig.add_subplot(111)
print(sum(2, 4))
candidates = [base for base in bases]
print ()
print(a)
f.write(content)
st = time.time()
serial.flushOutput()
True
marshal.dumps(code)
HTML(style + df_html)
a[0]
crontab - e
self.q.put((True, msg.errorCode, msg.errorMsg))
result.append(dictionary[last_match])
setattr(targetCls, name, wrap(name, func))
t = d.unique()
_install_lib.run(self)
self[key] = kwargs[key]
print(T(data[0], 0.29, 4.5))
fr.close()
type = models.CharField(max_length=255)
timezone.make_aware(d, timezone.utc)
tocopy_wb.Sheets(1).Cells.Copy()
MyArray([(k, self.data[k]) for k in key])
length = np.random.random(10)
type(foo1)
self.module = importlib.import_module(module_name)
print ()
self.data[self.size] = x
self.data[idx] = item
y = time.time()
sub_compunds.extend(generate_sub_compound(tok))
data = file.read(1024)
input = request.json
newlist = [temp[0]] + [([0] + i) for i in temp[1:]]
s.close()
f()
serverEndpoint.listen(factory)
[str.upper() for str in args]
print(metrics.confusion_matrix(y_test, y_predicted))
Base = declarative_base()
comment.replace_with(tag)
self.master.wait_window(self.w.top)
f(d, name)
list_of_lists = []
b = np.arange(0, 5)
g += b
print(sorted(values.items()), expr.subs(values))
foo.bar
instance
sum(max(die().roll_until(6) for i in range(6)) for i in range(n)) / float(n)
self.cs = LockableCursor(self.connection.cursor())
block_list.append(y)
out.stop()
self.filter(owner=owner)
head(d, 10)
mylist = mymethod()
ax.hold(True)
B = np.vectorize(inds.get)(A)
self[:1] = []
a[np.arange(a.shape[1])[:] > a[:, (0), (np.newaxis)]] = 0
getattr(p, s)
x_a = points[..., :-1][..., (mask)]
a.shape
name = models.CharField(max_length=50, null=False, blank=False)
replacements[mo.group()]
m.show()
data = os.read(STDIN, 1024)
profile = pform.save(commit=False)
np.random.seed(0)
older_books.append(books.title)
x = np.linspace(0, 20, 500)
f.__dict__
dis.dis(lambda : Foo.bar.add(1, 2))
indexes.append(int(index))
data = s.readframes(nf)
print(args_dict)
partial(operator.mod, b=i)
np.conj(x, x)
fig, ax = plt.subplots()
urlparse.urljoin(response.url, extractedLink.strip())
next(it2)
ax.stem(x, y)
result
locale.getdefaultlocale()
self.close_button.pack()
turtle.pendown()
result = dict(curs.fetchall())
df = df.swaplevel(0, 1, axis=1)
map(eq, a, b).index(False)
self.parent.vLayout.insertWidget(1, self)
self.layout.addWidget(self.btn_run)
cursor.close()
wx.Panel.__init__(self, *args, **kwargs)
self.sock.sendall(data)
Kiwi
run.py
res
layout = QHBoxLayout(self)
df + 2
compose1(f1, f2)
res.fill(np.nan)
start = datetime.datetime.combine(today, start)
pdf.closed
u = User.query.get(id)
article = get_objects_or_404(Article, pk=id)
l[:n] + [0] * (n - len(l))
series.fillna(0)
translation.deactivate_all()
a = np.arange(20).reshape((4, 5))
my_data = np.random.random((210, 8))
print(string1[match.a:match.a + match.size])
angles = np.linspace(0, 2 * math.pi, n_angles, endpoint=False)
x, w = leggauss(deg)
plt.legend()
print(enclosing_class())
texter.show()
df = pd.read_csv(fo)
sieve()
fun = self.weak_fun()
bins_labels(bins, fontsize=20)
self._picked_indices.append(index)
getattr(value, arg)
result = list(queryset_1) + list(queryset_2)
c = get_redis_connection()
s.add_dependency(tasks[p[0]], tasks[p[1]])
ba = bytearray(c)
handler = logging.StreamHandler()
groups = []
list_of_files.push(file)
file.close()
print(x, y)
n1 += 1
response
self.resize(600, 400)
price_series.pct_change()
self.filename = tkFileDialog.askopenfilename()
results if len(results) != 1 else results[0]
f2.print_world()
img.save(js.framebuffer)
url_queue.put(1)
y = NP.row_stack((fnx(), fnx(), fnx()))
y = y[indices]
model.add(e)
unique_a.view(a.dtype).reshape((unique_a.shape[0], a.shape[1]))
globals()[func_name] = getattr(m, func_name)
fig = pyplot.figure()
hist = np.histogram(A, bins=bin_count)
results = service.files().list(maxResults=10).execute()
print(a, b, c)
tt.Index(1).Set(eb)
result
axis = PlotAxis(tick_generator=tick_gen)
v = np.arange(100).reshape(10, 10)
self.d[k] = v
logger.info(result.get())
result.append(dictionary[match_parts[i]])
np.frombuffer(mp_arr.get_obj())
plt.xlim(50, 70)
big_df = df.copy()
self.cdfunc = cdfunc
pl, u = lu(a, permute_l=True)
s = len(l)
result = np.array([np.sum(corr_time1(t, JM1, JM2)) for t in t_output])
cls
print(intdate2date(20160618))
DD, EE, FF
f1.close()
xs = ys = np.arange(0, 1.01, 0.01)
len(l)
G = nx.complete_graph(20)
b.close()
zipdata.write(get_zip_data())
2, 2, 5
combs += combinations(remove(e, elems), m - 1)
n += 1
print(dis.dis(f))
ch = screen.getch()
print(name)
pst_dt.strftime(fmt)
a = 20
value = value.strip()
getattr(self._queue, name)
result
axs[1].xaxis.set_minor_locator(x_minor_lct)
y = np.empty(s.size, dtype=np.int64)
[queue.get() for queue in queues]
self.name = zipinfo.filename
value = datetime.date(1, 1, 1)
F = list(S1)
pyperclip.paste()
new_d[key.upper()] += val
field = self.fields[field_name]
_build_ext.finalize_options(self)
df
lines.append(line)
ipx
myList = []
print(e.inserted_primary_key)
max_value = value
1 / 1024.0
random.choice(list(self.__cache.values()))
all_keys.add(k)
headers.customContextMenuRequested.connect(self.header_popup)
self.val += 1
liPos = [(a, b + 1) for a, b in liPos]
x = 2
self.x, self.y = x, y
ax.plot(1 / u * cos(phi), 1 / u * sin(phi))
Include / etc / apache2 / conf.d / phppgadmin
res = OrderedDict()
n = -1
merge_dict(v1, v2)
response
width
self.button = QtGui.QPushButton(self)
divs[j][1] += divs[i][0]
c = db.cursor()
fields = []
print(test[0])
im2 = Image.fromarray(data)
retval += chr(node[1][0][1])
list(range(item.start, item.stop))
frame = inspect.currentframe()
args = parser.parse_args()
rows = cur.fetchall()
df = areas.apply(multiply_by_demand).unstack(0)
value = mc.get(key)
print(tests.test_002)
button.click()
hist, _ = np.histogram(values, bins=[1, 4, 7, 10], weights=freqs)
print(x)
y = np.array([1, 2])
body = []
d = defaultdict(list)
decoder.process_raw(buf, False, False)
B = np.zeros_like(A)
urllib.request.HTTPSHandler.__init__(self)
df
df
df
result
File.Delete(FilePath)
type([]) is list
df_new
df.iloc[-6:-1, (2)].values
self.button.bind(on_release=self.button_click)
help(scipy.special.erf)
loop.run_until_complete(low_level())
execute_sql(s)
np.diff(np.hstack((0, run_ends, nums.size))).max()
a[0, 0, 1] = [0, 0, 5]
top = min(len(a1) - 1, len(a2) - 1)
cosine(pink, car)
a.bar
comma_ending_prettyprint(row, stream=outfile)
s.get_available_ranges()
df = pd.read_csv(filename)
do_something(val)
imshow(resultScaled.astype(uint8))
index_type()
queryset = User.objects.all()
driver = webdriver.Chrome(chromedriver)
l = list(range(100))
sys.stdout.write(session.recv(4096))
print((count, p))
app().mainloop()
power(lambda x: x * 2, 2)(9)
clf.fit(iris.data, iris.target)
pd.Series(factors, df.index).apply(np.binary_repr, width=width)
cur_set.append(A[index])
start = time.time()
lft = [([0] * i) for i in range(n_rows)]
map(word_tokenize, texts)
Point(self.x - point.x, self.y - point.y)
ts = np.concatenate(ts)
d[k] = v
p.is_running()
x, y, w, h = cv2.boundingRect(cnt)
oAccess.Quit()
gg.plot()
L = [0] * 10
os.mkfifo(logfilepipe)
orders = models.ManyToManyField(Order)
print(nonsub)
self.environment.handle_exception(exc_info, True)
value[0] += 1
merge(value, node)
dis.dis(lis[1])
len2 = math.hypot(x2, y2)
person = models.ForeignKey(Person)
r.append(-1)
{(8): 8, (6): 6, (7): 7}
stdout, stderr = proc.communicate()
ax1 = fig1.add_subplot(221)
numloss += 1
a
slice(0, 0, step)
popd
self._classes[cls.__module__, cls.__name__] = cls
y = [0] * n
salt = bcrypt.gensalt()
t = datetime.now()
soup = BeautifulSoup(text)
count += 1
self._fig = Figure()
print(regex.findall(test))
x = 0
repr(0.01)
sns.distplot(x, ax=ax, rug=True, hist=False)
edges = zip(rows.tolist(), cols.tolist())
asdas
shom_im(cir)
res_list.append(res)
isitIn(char, aStr)
root = tk.Tk()
count += countnodes(ele.left, 0)
BEHI
CFHJ
AC
thread.start()
output = [(first, second) for first, (second, count) in list(d_max.items())]
f.close()
print(repr(x), ucd.category(x), ucd.name(x))
lists = list(filter(len, lists))
idx = np.floor(input).astype(np.int)
duplicates = [keys for key_str, keys in reverse_d.items() if len(keys) > 1]
x[-44]
decorator
category = models.ForeignKey(Category)
a.insert_node(a.root, 2)
bar = Bar()
QtGui.QDirModel.flags(self, index) | QtCore.Qt.ItemIsUserCheckable
dat = gauss(x, amp, cen, sig) + np.random.normal(size=len(x), scale=0.1)
w.grid()
print(parser.prog)
self.im.putpalettealpha(i, a)
counts = Counter(seq)
np.random.seed(0)
ip = get_ipython()
loop = asyncio.get_event_loop()
res = []
suite.addTest(unittest.defaultTestLoader.loadTestsFromName(t))
HTH += HTHflips
info = json.loads(details)
print(log.text)
repr(self.tokens[0])
indices[indices >= arr.shape] = clipping_value
do_staging_stuff()
serializer_class = MyModelSerializer
()(())
self.__dict__.update(kwargs)
config = ruamel.yaml.load(open(file_name), ruamel.yaml.RoundTripLoader)
inner
self.waiters.append(new_lock)
MooBase.metadata.create_all(engine)
[5, 17, 8, 7]
pylab.show()
value = json.loads(jsonValue)
app = wx.PySimpleApp()
c = x = x + 1
total = sum(g[1] for g in group)
net.sortModules()
n = [(1.1, 5), (2.4, 7), (5.4, 6), (9.8, 14), (10, 4)]
pix = pixl.get_pixbuf()
groups = result.groups()
print(f())
y = numpy.zeros(x.shape)
arr = shm.zeros(N, dtype=np.uint8)
user_input.append(entered_text)
deferred.addBoth(callback)
print(mydata)
ok = True
print(soup)
B = A[::-1, :]
self.addCleanup(patcher.stop)
l.insert(0, y_axis[i])
f(x[:, (t - 1)], params, x[:, (t)])
alist.append(1)
print(insp.get_table_names())
plt.show()
readRequest += chr(self.transactionID / 256)
sys.stdout.write(c)
self.line = line
image_db.close()
Color(*[r, g, b])
B.shape
json.dumps(f(*a, **k))
fig = plt.figure()
data = numpy.fromiter(points, float)
dowrap
bar()
two = np.empty(three.shape, dtype=object)
elem.clear()
df = pd.read_csv(fo)
z = {}
indices = np.array(list(range(len(a))))[inter]
print(qr.data)
a.dtype = newtype
main()
key = bucket.new_key(filename)
print(repr(binary_split_array[0]))
out_put.append(participation_details)
idx = np.unique(idx)
r[:, (0)]
self.obj.my_attr == other.obj.my_attr
(0)(1, 40020)
ax
print(dumps(bob))
body = s.to_dict()
data.shape
ax2 = ax.twinx()
smtp = smtplib.SMTP()
output = cmd.communicate()[0]
logger = logging.getLogger(__name__)
words = f.readlines()
connections.append(connection)
out = np.zeros((a.shape[0], a.shape[0]))
main()
cursor = conn.cursor()
queue = Queue.Queue()
total = 0
x0, y0, z0, w0 = np.split(quaternion0, 4, axis=-1)
subprocess.Popen(args0)
i += 1
G, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0
sub(a)[:] = np.ones((2, 2))
sentencecount = 0
self.sum
find(resolved)
conn.close()
path = Column(ARRAY(Integer))
response
m = [([0] * n_classes) for i in range(n_classes)]
pprint(d)
self.update(*args, **kwargs)
obj.my_custom_method()
print(totals[totals.argsort()])
map(double, list_[1::2])
fetch(r)
list2 = [x for x in list1 if x]
source = ColumnDataSource(data=dict(x=[0, 1], y=[0, 1]))
ax1.imshow(bw, cmap=plt.cm.gray)
ibm_db.execute(query_stmt)
MyIterator(list, random.sample(list(range(n)), k))
lens = np.array([len(item) for item in v])
next(self)
canvas.Canvas.showPage(self)
self.assertEqual(result, (self.v.version, self.v.prerelease))
b[c]
ax = fig.gca()
field
y = pow(x, p - 2, p)
(True != False) != False
indices.append(index)
saver = tf.train.Saver()
print(self.server.conn)
Date(date.year, date.month, date.day)
autostart = true
_mydecor if clams else _myclassdecor
hm.start()
a, b = [float(s) for s in line.split()]
foo_on_scalars(x)
num = 0
HTMLParser.feed(self, data)
x.isupper()
print(contents)
arr = np.sum(np.exp(-4 * abs(val - val.reshape(len(df.index), -1))), axis=0)
counts, sums = Fenwick(len(a)), Fenwick(len(a))
myseries_two.loc[0]
g(arr, numbers, i + 1)
cls
numsum = sum(list(numbers))
box = ax.get_position()
model = QFileSystemModel()
new_func.__code__ = code
result = tuple(islice(it, n))
mask[np.triu_indices(len(df))] = False
print(nextfetch)
foo.bar - foo.baz
data = np.random.random((1000, 10))
s = list(iterable)
a = [(lambda y: lambda x: y * x)(i) for i in (1, 2)]
c = Counter(words_to_count)
root.remove(element)
False
print(optimize.fixed_point(func, 0))
datam = np.zeros_like(data)
dump(outdata, 5, 6)
time.sleep(0.01)
print(s)
self._foo = val
dt = aware_utc_dt.astimezone(tz)
y = x.__add__(x)
le.transform([1, 1, 2, 6])
answer.append((L1[tuple(row)], i))
result = comment.upper()
func2()
hamming_sets[0].add(l[0] + l[1])
image.data = f.read()
doSomething()
True
globals().update(load_dictionary(fpath)[0])
o4 = int(ipnum) % 256
x + x
df
randint(range_start, range_end)
np.vstack((np.zeros(shape), data))
{4, 5, 6},
list(map(set, out))
show(p)
y = foo()
d[key_list[-1]] = params[key]
self._locked
draw = ImageDraw.Draw(img2)
fin.seek(start_index)
b = [6, 7, 8, 9, 0]
list(islice((x for itr in (l, repeat(0)) for x in itr), n))
bar.set_hatch(hatch)
a = numpy.array([0.0, 0.25, 0.75, 1.0])
queryset.get(slug=self.slug)
[MyObject(), MyObject()]
x, y = data.T
print(int_array)
df.C
diff_as_html = ghdiff.diff(markdown1, markdown2)
print(dict_mul(dict1, dict2))
handle_results(proc.stdout)
current_string_split[-1] += s[j]
weights = numpy.array([0.5, -1])
np.array([inner(row, *args, **kwargs) for row in vec])
prevnode.left == node.right
s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
first.append(ele)
list(foo() for x in range(10))
L.append(x * k)
primes = [p for p in table if p][1:]
pymysql.install_as_MySQLdb()
found = True
data = json.loads(ninja_json)
q.join()
Y += 0.1 * np.random.random(N)
k = int(round(n * (float(percent) / 100) / 2))
a[something]
x[(0), 48:52]
j = json.loads(data)
form
app.MainLoop()
a = 1
socket.send(args.bar)
config.write(fp)
self.q.task_done()
show_error()
set(chain.from_iterable(periodic_gs[key].nodes() for key in periodic_gs))
rest = list(it)
Y.append(y)
type(sys.maxsize + 1)
exitonclick()
response = requests.post(searchUrl, files=multipart, allow_redirects=False)
NULL
y.sort()
serializer_class = UserSerializer
a = [5, 8, 9]
d = OrderedDict()
type(d)
form.category_select.choices = [(key, categories[key]) for key in categories]
args = []
A = matrix([[0, 0, 0, 1], [0, 0, 1, 0], [0, 1, 0, 0], [0, 0, 0, 0]])
t.print_exc()
result.add(word)
result.add(item)
print(df.dtypes)
result.append(next(g))
thread.join()
serializer_class = UserSerializer
self._current_message = qmessage
self.children = []
ax.plot(arange(10), rand(10))
print(x)
sum(val * self.weights[i] for i, val in enumerate(inputs))
result = cache.get(key)
logging.basicConfig(format=FORMAT)
159575276
m = alen(t)
m = MyModel(**data_dict)
entity.after_delete()
extractedData = data[:, (idx_IN_columns)]
root.after(0, download_chunk, readsofar + len(data), chunksize)
print(data)
self.SetTopWindow(frame)
(0, 10) == 0, 10
result = pool.apply_async(f, [10])
row = rows[0]
as_list = list(eval(args))
offset = lst.index(element, offset + 1)
mypad.scrollok(True)
__import__(modname)
result[last].append(obj)
print(one, two, three)
result |= Counter(d)
int(hex(200 - (1 << 16))[-4:-2], 16)
print(f(1.0, a=-1.0, b=1.0, n=4))
recall_accumulator.append(recall_score(y_true, y_pred, **kwargs))
reactor.connectTCP(host, PORT, BlastFactory())
hover.perform()
x1, y1, x2, y2 = lines[i][0]
raise AttributeError
hfile.seek(-bsize, os.SEEK_CUR)
X = np.asmatrix(np.arange(N * N).reshape(N, N))
self.delegate = delegate
print(a)
self.run_console_command(line)
f.close()
count = 0
plt.scatter(x, y, c=color, s=90, alpha=alpha)
Lv.append(last)
i += n + 1
print(z.namelist())
self.name = name
asyncio.set_event_loop(eventloop)
f.add_done_callback(set_if_success)
_repr(o)
print(np.shape(c))
result = func(*args, **kwargs)
a.update(b)
self.loadFinished.connect(self._result_available)
isinstance(inst, self._decorated)
iter(x)
arr[i:size + i]
0
is_active = models.BooleanField(default=False)
shutil.rmtree(self.__str__(), onerror=delete_dir_handler)
reader.close()
my_global_fun(data)
start = time.time()
C = np.empty(N, dtype=int)
funcList.append(factory(m))
0
heapq._siftdown_max(heap, 0, len(heap) - 1)
datalines_str.info()
pool.map(func, input_sequence)
~array
counter = Counter(line.split()[0] for line in fp)
k, v = next(iterator)
serializer = self.get_serializer(queryset, many=True)
self.__dict__[key] = item
df.date1 = pd.to_datetime(df.date1)
x
loop = asyncio.get_event_loop()
IOLoop.instance().add_timeout(time.time() + 5, self._process)
self.height = self.winfo_reqheight()
theta = np.deg2rad(angle)
z.close()
match = pattern.search(lines)
print(client.wsdl)
df
visited.append(i)
list2.insert(i, x)
time.sleep(0.45)
ipython - -matplotlib
no_background.append(orig[:, (i)] - np.median(orig, 1))
data = [tuple([d[0], dict(size=int(d[1]))]) for d in data]
print((a, args[a]))
self.panel = wx.Panel(self)
it = iter(numbers)
Blob.__init__(self, width, height, color, emphasis, highlight)
z.close()
l2 = []
self.grid(sticky=W + E + N + S)
deleten_lst[-1]
response
df = DF[DF.isin([eq]).any(1)].reset_index(drop=True)
plt.xlim(xmax=2)
func(*args, **kwargs)
newobj
sts = os.waitpid(p.pid, 0)
a[0]
siftDown(A, start, len(A) - 1)
cur = conn.cursor()
print(dt)
d.func1(name)
count[w] += 1
i += 1
dot_product = np.dot(normal, unit_ray)
np.random.seed(0)
extractor.runInParallel(numProcesses=2, numThreads=4)
self.cntrlPanel.Show()
file.seek(sequence_start, 0)
print(norm.ppf(y))
sum(opt(value) for opt, value in zip(ops, lst))
permutations[tuple(sorteditems.index(item) for item in items)] += 1
a, b = tee(iterable)
print(group)
value
A = np.random.rand(N, N, N)
min(scores)
self.__c
active_required(my_view)
days[index:] + days[:index]
d = {}
lst = [5, 20, 15]
df_bad_idea.sum()
fd, filename = tempfile.mkstemp()
x = np.linspace(0, 10, 20)
all_data = all_data.append(df, ignore_index=True)
z.write(os.path.join(absdir, f), os.path.join(zip_dir, f))
result = []
self._value + n
self.assertEqual(200, res.code)
sio.seek(0)
g.head(2)
PorterStemmer().stem_word(word)
vecData.columns = vec.get_feature_names()
list(range(5))
self.notifyObservers(old, self.value)
f = tempfile.TemporaryFile()
data = urlfile.read(chunk)
response = service_request.execute()
d = {printer(i): printer(j) for i, j in t}
Add()
self.ses.post(url_auth, data=my_dict)
res = {}
d = {}
out[-1].append(ele)
out = StringIO.StringIO()
self.name
self.my_float_layout.add_widget(self.button)
a = []
p1 = figure(plot_width=900, plot_height=500, y_range=[8, 10.5], tools=TOOLS)
self.timeout.reset(_timeout)
file.close()
d = {(1): 2}
self.int2base(self.current - 1, self.base)
display.start()
a, b, c
datadex[x] + 1
val = np.fromiter(list(d.values()), int)
op = s.pop()
foo = MyClass()
f_set = f[(f.year >= 2002) & (f.year < 2010)]
(2 < arr) ^ (arr < 6)
funct(*args, **kwargs)
cat.save()
ax.hold(True)
timer.timeout.connect(tick)
settings.py
plot(t, s2)
obj = C()
self.closefd = closefd
1
issubclass(bool, int)
x
request = HttpRequest()
args = parser.parse_args()
dothis(item)
print(form)
ch.setLevel(logging.INFO)
a + b + c
val = [len(list(g)) for _, g in groupby(l)][-1]
a, c
tokens = astr.split()
setup(**configuration)
check_thread.start()
ax.scatter(xs, ys, zs)
b = Swallow()
[]
result = remove_rows(df)
cax = fig.add_axes([0.27, 0.8, 0.5, 0.05])
os.kill(pid, SIGTERM)
csvdata.set_index(mergecols, inplace=True, drop=False)
cPickle.dumps(d, -1)
complements.append(2 ** (depth + 2) + 1)
fhd.close()
edgePoint.y += self.bounds.size.height / 2.0 - self.center.y
file_name = part.get_filename()
c = get_config()
x, y = [], []
parser.print_help()
c = [comb for i in range(n) for comb in combinations(x, i + 1)]
searchbox.clear()
a = np.arange(N)
points.append((1, 0))
self.k = min(k, len(train_data))
hour, minute = divmod(int(hhmm), 100)
seen = set()
GLX.glXMakeContextCurrent(d, w, w, context)
scnt += 1
fig = figure()
print(datetime.datetime.now() - now)
then = time.time()
arr2 = np.zeros((arr.shape[0], arr.shape[1] + column_pad))
obj = {}
fig = plt.gcf()
print(format % tuple(row))
print(sum(l, ()))
domain = splitting[1]
pen = QtGui.QPen(QtCore.Qt.red)
new_solution.append(data.pop())
c = pycurl.Curl()
virt - install
browser = webdriver.Firefox(profile)
df.loc[1]
reverse_d[key_str].append(key)
dotted_notation.setParseAction(name_notation_type)
print(b.build_lib)
im = im.crop((left, upper, right, lower))
rcode = response.rcode()
result = datetime.strptime(date, format)
db.connect()
dol[k].append(d)
subset = table[np.in1d(table.IDs, id_list)]
antigravity
int.__init__(self, *arg, **kwarg)
t[n - 1]
test_module_1.py
instance
process(path)
print(richard)
assert_frame_equal(df1.sort(axis=1), df2.sort(axis=1), check_names=True)
c = C(0, 1, 2)
[x[1] for x in links if x[0] == node]
ax.plot([-1, 0, 1, 2], list(range(4)))
(s.index[0] - s.name).total_seconds()
COMMIT
tf.write(sf.read())
False
[ChildClass(stream) for i in range(stream.read_ui16())]
GuiMixin_FunctionalityB.__init__(self)
a = a.__get__(C)
pacific_now.utcoffset().total_seconds() / 60 / 60
np.lib.stride_tricks.as_strided(arr, new_shape, new_strides)
d = dict()
print(answer)
data.append(val)
driver.init()
combined = defaultdict(list)
idict[sub_name] = new_dict
Potato(**validated_data)
GL.glShadeModel(GL.GL_FLAT)
source.close()
a = numpy.array([(n + datetime.timedelta(minutes=i)) for i in m])
[FreeTDS]
reimport(module)
A[:, (~drops)], drops
m.hexdigest()
ActionChains(context.browser).send_keys(Keys.ARROW_UP).perform()
params
self.factory.broadcastMessage(message)
y = pattern.match(x).groups()
pool._processes
True
print(sorted(list(func(n))))
h = ax.plot(x, rv.pdf(x), lw=2)
m_to_N[:, (0)] = -nrange[1:].reshape((n - 1, 1))
df.index = df.index.map(str)
f.write(libtorrent.bencode(torfile.generate()))
links[word].push_back(word.c_str())
n, [n]
datetime.datetime(2012, 10, 4, 1, 0, 51, 759000)
[1, 2] == [2, 1]
soup = BeatifulSoup.BeautifulSoup(data)
is_ok[idx] = np.logical_or(is_ok[idx], val)
BaseObject.initialized, ObjectOne.initialized, ObjectOne.x, ObjectTwo.initialized, ObjectTwo.x
a += 1
self.obj = obj
deleteself.mapping[key]
tmr.start()
n = len(points)
nodes.append(key)
(tuple(seq[pos:pos + size]) for pos in range(0, len(seq), size))
smtp = smtplib.SMTP()
end_time = Column(Integer)
print(l)
df.corr()
total
self.total += 1
print(a.shape)
plt.bar(X[:-1], Y, color=C, width=X[1] - X[0])
m.p
A = sps.coo_matrix((v, (i, j)))
print(list(missing_elements(L, 0, len(L) - 1)))
r = int(max(0, 255 * (ratio - 1)))
print(first_fifty_results[0].media_url)
name = Column(String)
username = NullColumn(db.String(80))
self.electric_conductivity = electric_conductivity
y_sorted
self._queue = Queue(maxsize=1)
blocks.append(f.read(BLOCK_SIZE))
a = np.array([9, 9, 9, 9, 9, 9, 9, 9, 9, 9])
ax_axis.offsetText.set_visible(False)
word = word.rstrip()
b = c = a[10:40:4]
__builtin__.__import__ = newimp
pcolor(data, cmap=new_map)
len1 = len(s)
f = np.vectorize(f)
print(s)
runrec(srcname)
current_list.append((header_id, header.string))
u_x.append(len(s) - 1)
options.parse_command_line()
code = marshal.load(f)
print(results.get())
ar[0:0]
u_y.append(s[-1])
do_other_stuff_to_header(line)
data = get_image_data(infile)
s[-amount:]
y[:] = np.where(mask, np.nan, r * np.sin(t))
self.__parser.add_section(attr)
formatfunc(thing)
r2 = (x - cx) * (x - cx) + (y - cy) * (y - cy)
r = re.search(pat, txt)
mysum += (a - b) ** 2
app.route(*args, **kwargs)(view_func)
df2
diag = [-1] * n + [1] * 2
dict.__delitem__(self, key)
self.m[r][c]
total = 0.0
print(i)
math.factorial(6)
cls(name=name, email=email)
array = np.empty(len(args), dtype=np.object)
print(user_input)
df[cat_columns] = df[cat_columns].apply(lambda x: x.cat.codes)
pil_im
(-9, -5)[-9, -8, -7, -6]
ax = s.cumprod().plot()
result2.add(k + 1)
hash - r
a.append(a_t)
print(i)
self.loop = asyncio.new_event_loop()
post_install()
ufmt_str.format(*args)
b = a[s]
q |= Q(name__icontains=merchant)
children = list(_get_ordered_child_nodes(node))
metadata = MetaData()
value = models.IntegerField()
number = m.group(1)
x = abs(x)
df = psql.frame_query(sql, cnxn)
sys.float_info.max
print(sess.run(y))
d[v] += 1
location = forms.ModelChoiceField(queryset=Location.objects.all())
getattr(self._original, key, value)
r, c = np.triu_indices(tot_vec, 1)
t[0]
q.put(2)
self.some_method = self.some_method
a[0:1] = [4]
next(g)
parsed = ET.parse(url_link)
my_list
handler = urllib.request.HTTPHandler()
join(idx, n)
print(uploaded_files)
self.testdata = open(TESTDATA_FILENAME).read()
y[s] = np.arange(s.size)
random.randint(0, 10000)
labels = [0, 1, 1, 2]
y[nans] = np.interp(x(nans), x(~nans), y[~nans])
app = Flask()
seconds = float(milliseconds) / 1000
x = np.empty(5)
f = Foo()
console = logging.StreamHandler()
newSingle.getHeader().setField(transacttime)
do_something(chunk)
today = datetime.datetime.today()
children.add(v)
myobject.__acl__ = load_acls(myobject)
data = json.loads(document)
print(last_array[211147, 9])
l.sort(key=alphanum_key)
clf.estimators_[0]
self.initfunc()
difference_in_years = date_as_float(end_time) - date_as_float(start_time)
self.dot.set_offsets((x, y))
delattr(cls, name)
np.array([100 - x, x + y, 100 - y])
enddef
channel.settimeout(2)
sftp = s.open_sftp()
Base = declarative_base()
yedges = np.linspace(0, N, nbin)
person = Person.query.get_or_404(id)
my_instance.a()
pairs = list(itertools.product(l1, l2))
destination.save()
output = sys.argv[2]
string, stream[pos + 1 + length:]
len(block)
d[x] += 1
d = datetime.date(2012, 2, 7)
print(x)
sorted(coursesList, key=len)
image.write(chunk)
[node.aspython() for node in nodelist]
Architecture
Management
{word for word, times in list(anagrams.items()) if times > 1}
C[A.nonzero()] = A[A.nonzero()]
rows, cols = matrix.shape[0], matrix.shape[1]
data[n] = line.rstrip()
setattr(self, unit, value)
False
show()
a = float(x)
dis.dis(foo)
test = sum(tests)
x = np.arange(Norig * Norig).reshape((Norig, Norig))
plt.setp(patches, linewidth=0)
self.scene.addPolygon(QtGui.QPolygonF(self.click_positions), pen)
threads.remove(thread)
all(value in x for x in self.sets)
self.value = value
Foo.bar.__self__ is Foo
parser.print_help()
cur.connection.autocommit(True)
self.val -= 1
thequickbrownfoxjumpsoverthelazydog
self.send_response(200)
b.compute(date, date)
os.remove(temp_file_name)
ws.write(row, 1, row)
do_totally_different_thing()
db.foo.remove({})
self._s.sendto(str(data), self._server)
weights[k] = 0.0
file_A.do_A_stuff
self.mc = wx.media.MediaCtrl(self, szBackend=wx.media.MEDIABACKEND_WMP10)
session.modified = True
col_sums[:, (j)] = col_sums[:, (j - 1)] + row_sums[:, (j)]
ar[np.bitwise_or.accumulate(~ar[::-1])[::-1]]
ipdb > X[k, k].shape
b = pandas.get_dummies(a)
p = Process(target=worker)
mod
attachment = MIMEText(fp.read(), _subtype=subtype)
self[i - 1][j - 1] == 1
peasant.knock_over()
self._s.sendto(str(data), self._addr)
keyfunc
QtCore.QTimer.singleShot(5000, self.showChildWindow)
id(df._data)
plt.subplot(2, 2, 2)
j = np.random.randint(0, ncols - 1, numdense)
arr = np.random.random((1000, 1500))
self.est = est
sent = np.zeros((len(vocab), len(text_idx)))
len(self._data.values)
pp.close()
print(obj.__class__)
twitter = Twython(APP_KEY, APP_SECRET, OAUTH_TOKEN, OAUTH_TOKEN_SECRET)
diff.sort()
a.dtype
mask = np.where((array >= x) & (array <= y), True, False)
fig = plt.figure()
combinedRDD = combinedRDD.map(convert)
boto.storage_uri()
a_list
sum((a - b) ** 2 for a, b in zip(u, v))
doSomethingWith({{user.username | tojson | safe}})
df
value
singlet_list = [2]
udf(lambda c: label_maker_topic(c, topic_words))
do_whatever()
self.assertEqual(captcha_count, 0)
self.openfile()
x % 2 == 0
ans = np.take(myarray, sorted(set(ind) - set(rm)))
a - a
t = threading.Thread(target=test)
f.close()
msg_decorator
tmp_file.flush()
found = False
GL.glClear(GL.GL_COLOR_BUFFER_BIT)
-math.log(theta * beta)
time.sleep(max(requiredDuration - connectionDuration, self._latency))
current.append(label2index[label])
cur = con.cursor()
words.update(test.split())
last_result
print(x)
print(value)
print(args.c)
print(qs)
wset.add(narrow)
A[0] = previous_A[1]
_multigen
print(pat.search(content).group())
get_page_labels(pdf)
a = Vector(1, 2)
number = 0
np.multiply(arr1[i], arr2, out=out[i].reshape((1, arr2.size)))
a.copyApply(A.foo)
logging.INFO
toimage(data).show()
d[nan2]
set([x for x in list(storage.values()) if list(storage.values()).count(x) > 1])
foo()
f.close()
print((w, follows(w)))
print(next(self.fibo))
fid.close()
print(max_number(1000))
self.x, self.y
id(b)
lambda func=self.test: func()
login(self.request, form.user)
filters.pop()
web.setPage(downloader.page)
content = db.Column(db.String(255))
print(content)
abc = myFunction
True
output = PdfFileWriter()
map(lambda x: x.extend([0] * (inner_max_len - len(x))), lst)
p.show()
r = urllib.request.urlopen(datasrc)
ax = fig.add_subplot(2, 1, 1)
self.file.flush()
indexes = np.zeros_like(data, dtype=int)
u[s] = np.arange(n)
HttpResponseRedirect(self.get_success_url())
[]
print(a[(idx == 0), :])
Z = np.zeros((2, 2))
sts = os.waitpid(p.pid, 0)
index.append(start)
url = sys.argv[1]
res1[:, (k)] = U[:, :, (k)].dot(V[:, (k)])
r = []
print(line)
random.randrange(start * f, stop * f, step * f) / f
expatparser.Parse(xml)
title = db.StringProperty()
pid = os.fork()
cv.Rectangle(image, pt1, pt2, cv.RGB(255, 0, 0), 5, 8, 0)
number // 2
print(x)
count(5)
link = soup.link.nextSibling
t.push(s.pop())
ttaken = time.time()
repo.remotes.origin.push()
qs = Room.objects.filter(name=self.name)
response = urllib.request.urlopen(sampleRequest)
w, h = im.size
app = QtGui.QApplication(sys.argv)
url += urllib.parse.urlencode(self.params)
main()
data = f.read()
print(query)
t1.start()
print(ast.literal_eval(assignments_removed))
self.sendHello()
df
model = treeview.get_model()
bitstring.BitString(uint=i, length=(i.bit_length() + 7) / 8 * 8).bytes
newshuffle(l)
print(chunk.values)
{{companyForm.locations()}}
-a.py
worker_process.start()
app.exit(1)
window = Gtk.Window()
print(ndimage.map_coordinates(data, [zi, yi, xi]))
print(self.server.arg1)
int(number + 0.5)
data = json.dumps([r for r in csv_reader])
nonRepetitive_x.insert(0, x[0] - 1)
key = min(iter(self.keys()), key=lambda x: abs(x - key))
Chainable(self.data, method)
nx.path.bidirectional_dijkstra(G, 1, 2)
cols = []
scroll = gtk.ScrolledWindow()
self._task = asyncio.ensure_future(self._run())
generations[-1]
result = [(i > maximum / 2) for i in diffs]
Audio(url=sound_file, autoplay=True)
app.logger.setLevel(debug)
self.factory = RequestFactory()
curl.setopt(pycurl.FOLLOWLOCATION, 1)
x[[0, 2], [1, 4]] = np.nan
print(a, b, file2freq[a, b])
self._cache.append(next(self._g))
h.Send()
grouped = s.groupby(level=0)
pool.join()
file = matplotlib.font_manager.findfont(font)
plot(s[:, (0)], s[:, (1)], color=dark2[c])
frame.worker.join()
xi, yi = np.meshgrid(new_row, new_row)
daemon.start()
y_series.append(int(z))
HttpResponseRedirect(url)
x = numpy.arange(0.0, 8, 0.1)
form = ArticleForm(instance=article)
print(arreq_in_list(myarr0, mylistarr))
s1 = set((0, 1))
print(dest_path + filename)
blosum.update(((b, a), val) for (a, b), val in list(blosum.items()))
sys.argv = [str(num)]
np.put(a, np.where(a > 1.0)[0], 1.0)
t.join()
self.webSocket.broadcastMessage(request.content.read())
wr = csv.writer(your_csv_file, quoting=csv.QUOTE_ALL)
timeit[Model.objects.filter(date_created__startswith=today)]
X.mean()
here_using_my_module.py
print(s2)
dict_df
tempset.update(x)
client = requests.Session()
sum(matrix[(row), :])
deleteself.data[index]
self.attr2 = attr2
[item[i] for i in self.columns]
print(img.getpixel((0, 0)))
score = pickle.load(file)
socketIO.wait_for_callbacks(seconds=1)
do_stuff(chunk)
bool(set(array1) & set(array2))
g()
sys.exit(not result.wasSuccessful())
self.tables.append(self.rows)
datetime.utcfromtimestamp(ts)
result = Test.objects.filter(actions__contains=kwargs)
fig.patch.set_alpha(0.0)
x.f2()(1)
bar_id = Column(Integer, ForeignKey(Bar.id))
end = datetime.strptime(end_date, date_format)
self[attr] = value
server.serve_forever()
layout.addWidget(self.list_widget)
len(s)
value
print(np.all(Z.A == np.maximum(X.A, Y.A)))
size = icon.availableSizes()[0]
add(10, 5)
fig1.colorbar(im, ax=ax1)
b = [9, 8, 7, 6, 5]
p = QPixmap.grabWidget(widget)
fullpath = os.path.join(root, f)
self.log.Show()
hello(a, b)
form = _get_link_form(request.POST)
print(myFunct())
df2
length = len(encoded)
node.left = Node()
print(fn.match.groups())
axes[1].append(string2.index(i))
t = np.linspace(0, T, N)
unsearched.task_done()
0
print(serv_resp_body)
Animal.objects.all()
mycode.my_func()
deleteself.dict[item]
print(id(string[-10:-5]))
ax1.set_xlim(-4, 15)
request = urllib.request.Request(sys.argv[1])
df.to_csv(tmp, index=False)
length = len(l1) + len(l2)
cond = np.array([[False, True, True], [True, False, True]])
self.loop.call_soon_threadsafe(self.loop.stop)
s = StringIO.StringIO()
increment_deal_count(dbconn, userID)
df.groupby(idx2.astype(object)).sum()
text = tk.StringVar()
self.save()
logger.addHandler(console)
lst1[0:1] + interleaveHelper(lst2, lst1[1:])
order = list(range(len(some_list)))
print(type(b))
tf = tempfile.NamedTemporaryFile()
data = self.data[:self.size]
isinstance(x, number.Number)
logger = get_task_logger(__name__)
e = Element(qualifiedName, namespaceURI, prefix)
b = np.sin(theta)
parser.set_defaults(type=do_stdout)
z = tf.matmul(x, y)
d = defaultdict(int)
not len(non_unique_list) == len(set(non_unique_list))
output.append(x)
img2 = np.uint8(np.random.randint(0, 255, (480, 640)))
index_li.append(idx)
{{email}}
zip_longest(fillvalue=fillvalue, *args)
l = []
print(row.text)
-1
sys.modules.update(old_modules)
type(_)
self.process()
parent.remove(r)
print(commaSeparatedList.parseString(s).asList())
self.after(100 * i, change_name)
model = PandasModel(your_pandas_data)
isinstance(t, str)
print(reversed(conn.execute(query).fetchall()))
{}
rmdir(root)
headers = {}
math.degrees(math.atan(1))
message = inbox.Messages.GetFirst()
print(emp.name, emp.title)
self.root.addHandler(self.qh)
b.__doc__
rainbow_fill(X, Y)
self.start_time = time.time()
[tuple for tuple in tuples if term in tuple]
self.__getitem__(k)
fh.setLevel(logging.INFO)
user.save()
df
digits = escapesequence[2:]
foo.close()
z[list(np.indices(z.shape[:-1])) + [a]] = 1
data = []
myapp / somelibfile.py
self.char_y += 10
points = [random() for _ in range(1000 * 2)]
monkey.patch_all()
x = np.linspace(0, 10)
p = Process(target=f)
diff(nges_uneval, n[5])
self.cookies = MyCookieJar()
os.killpg(0, signal.SIGKILL)
allocate(tmp(gridsize, gridsize, gridsize), work(gridsize))
print(strc)
list(d.keys())
unpack.append(item)
result
new_list = []
soup = BeautifulSoup(content)
print(find_skew(list(range(256))))
session.close()
Package - 1 / namespace / module1 / __init__.py
print(True)
parser = MyArgumentParser()
compressor.write(chunk)
is_admin = os.getuid() == 0
True
req.setUrl(url)
fig = plt.figure()
print(n)
callable(elt.text)
PyLong_AsByteArray(lnum, a, a.size, 0, 1)
p = MyPickler(f)
ps.image(box, im, dpi)
np.random.shuffle(idx)
email_message
y[i][j] = x[i][j]
print(today - BDay(4))
key_result[name_key] = groups[0][name_key]
the_list = numpy.array(list(range(0, 101, 10)))
print(line1.buffer(EPS).intersects(LineString([pt, pr])))
s = StringIO()
y = T.dmatrix()
birth_years = {nm: year[idx] for idx, nm in enumerate(name)}
print(Animal.__bases__)
f.__defaults__ = f,
ax = fig.add_subplot(1, 2, 1)
d = np.diff(x)
fout.write(line)
app = Flask(__name__)
self.globals[key]
cap = cv2.VideoCapture(0)
mlab.surf(subtract.outer(sin(xx), cos(xx)))
d[6] = 1
excel.Visible = False
u = np.hstack([[0], u])
path
[lower_keys(v) for v in x]
self.directory = os.listdir(*args)
a, b = b, a + b
b = Base()
canvas.setPageSize((lHeight, lWidth))
sphinx - apidoc - o / my / docs / live / here / my / source / lives / here
a, b = tee(iterable)
print(sortSparseMatrix(m))
result = defaultdict(dict)
c = b[:2]
b[a == k] = v
HTTPRedirectHandler(), urllib.request.HTTPHandler(debuglevel=0)
neighbors = G.neighbors(root)
form = CategoryForm
inputs.remove(s)
self.assertEqual(t[0], str(NumberedVersion(*t)))
list(lower[lower.index(strs[0]):lower.index(strs[-1]) + 1])
limit += 1
print(randomList)
print(find_parent(D, class_set))
np.PyArray_ITER_NEXT(itf)
self.assertEqual(some_method(), False)
fig.set_size_inches([8.0, 12.0])
doit()
a = Field()
extra_compile_args.append(arg)
parent_map[el].remove(el)
p1.daemon = True
self.fp.seek(offset, *args)
a_set = set(a)
dirname = os.path.dirname
shp = L[0].shape
print(grids[0].dtype, grids[0].nbytes)
f.close()
a.ravel()[5] = 99
raise StopIteration
plt.show()
B.__init__(self, a, b)
app = params.get(cls._APP_PARAM)
fig = plt.gcf()
a = int(round(time.time() * 1000))
self.checkBoxList.append(checkBox)
content = models.TextField(max_length=250)
b = np.array(b)
pprint.pprint(obj)
df.col1 = pd.to_datetime(df.col1)
cache[args]
rs = r1[(np.lexsort(r1.T)), :]
statement = query.statement
plt.ylabel(ax2_label)
pc.append(Path.CLOSEPOLY)
stuff.py
cam.release()
self.v = v
count[c] += 1
self.get_queryset().in_group(group)
mask = np.cumsum(mask, out=mask, axis=1)
self.index - 1
df
name, val = s.split()
x = len(self.right) // 2
len(dir(anIntOBJECT))
self.fingerprints.add(fp)
list(df[df > df.quantile(0.8)].dropna().index)
1 / 0
url = request.build_absolute_uri(request.get_full_path())
utf8[:i]
out.seek(0)
s = np.array([20, 10000, 10000])
shutil.rmtree(dir_name)
Hvalue = someoperation(Hnodes)
lenIter(s[1:])
print(len(object_keys))
result = dict(defaults)
b = np.random.rand(N, 1)
result = []
newlist.append(word)
a = np.random.rand(100 * 100).reshape((100, 100))
print(stream.get(cv.CV_CAP_PROP_FRAME_COUNT))
print(nums.std(axis=1))
Py_DECREF(pyth_val)
fmap[fid] += 1
w = wcs.WCS(naxis=2)
_NestedClassGetter(), (WidgetType, self.__class__.__name__)
a.somefield = somevalue
console_handler.setFormatter(log_formatter)
gevent.joinall(jobs)
child.setText(0, str(value))
[-2, -1, 0, 1, 2],
pymysql.install_as_MySQLdb()
df
curl.setopt(pycurl.SSL_VERIFYHOST, 2)
layout.set_font_description(font)
line_number = random.randint(0, total_num_lines)
app = flask.Flask(__name__)
ch.setLevel(logging.DEBUG)
self.axes.plot(self.data[(0), :], self.data[(1), :], self.data[(2), :])
plt.xticks(rotation=25)
PassengerID, Survived, Pclass, Name, Sex
df = pd.DataFrame(index=missing)
c = wmi.WMI()
show(p1)
html = page.read()
a = numpy.array([])
print(df)
someDict[num].append(line)
a + b
output = 4 * np.sum(integrand(a + h * np.arange(1, num, 2)), axis=1)
loop = asyncio.new_event_loop()
conn.close()
widget = InlineButtonWidget()
myA[np.where(myA > val)[0][:n]] = 0
plt.xlim([-1, 10])
servicemanager.Initialize()
Foo.bar == foo
stream.write(input_array)
msg = MIMEMultipart()
ls[1] = ls[1] - (ls[1] - ls[0]) / 2
a = calc_a(d1, d2)
x = np.array([[10, 0, 10, 0], [1, 1, 0, 0], [9, 9, 9, 0], [0, 10, 1, 0]])
a1 + csr_matrix((x - a1[ind], ([0] * x.size, ind)), (1, a1.size)).toarray()
next(generator())
print(resultMD5)
a = a.reshape((-1, 1))
os.close(self.pipe[0])
logging.setLoggerClass(CustomLogger)
rollback()
count -= 1
s.append(ALPHABET[r])
title = models.CharField(max_length=100)
True
m = mmap.mmap(f.fileno(), 0, prot=mmap.PROT_READ)
deleteobj.__dict__[self._name]
table = d.add_table(numrows, numcols)
PyObject_Print(item, stdout, 0)
print(etree.tostring(html))
data = urllib.parse.urlencode(values)
sleep(randint(10, 100))
sublime.set_timeout(test_progress_bar, 100)
df
print(s)
self.__class__.PARAM
x1 = min(x_normalised) - 1
client = self.get_current_client()
daynum += 1
start = get_start_input()
zip(ii, y[ii])
win.setCoords(0, 0, 10, 10)
a % 10 + digit_sum(a / 10)
url = urlparse.urljoin(url, match.groups()[0].strip())
deletetime.sleep
a = {}
output = [((k,) + v) for k, v in list(output.items())]
out, err = process.communicate()
files = list(x for x in filePath.iterdir() if x.is_file())
c(1)
pairLambs[2]()
Queue.put(self, (datetime.now(), item), False)
tf.file.close()
blocks[0][0]
ax2 = fig.add_subplot(gs[1], sharey=ax1)
True * 2
color_bar.set_alpha(1)
a = numpy.random.normal(size=10000)
os.makedirs(dest_dir)
seconds = tdelta.total_seconds()
count = 0 if count == N else N + 1
self.events.append(item)
f = sympy.exp(x + y) - sympy.sqrt(z)
A = numpy.array([[5.0, 5.0, 5.0], [8.0, 9.0, 9.0]])
X = numpy.random.normal(size=(100, 10))
print(clean_text)
Session = sessionmaker()
np.int(x)
request = urllib.request.Request(BASE_URL, headers=HEADERS)
codepoint = ord(c)
async_list.append(action_item)
len(done) == len(container)
res = res * scaling_factor
args = parser.parse_args()
l = list(range(10))
b[elem - 1].append(indx)
stack.extend(item)
vec = [random.randint(minval, maxval) for i in indices]
(comp.string.encode(enc) % params).decode(enc)
text += e.strip()
self._reject(request, REASON_BAD_TOKEN)
print(parsed_values)
args = command.strip().split()
print(sum(score_pairwise(seq1, seq2, blosum, -5, -1)))
plt.plot(dates, values)
end_date = datetime.datetime.today()
http_server.listen(8888)
c, addr = s.accept()
deleteself._x
l.append(number % base)
p.pretty(key)
result.append(copy(path))
fn(**arglist)
root = tk.Tk()
queue.append(start)
description = models.TextField(max_length=200)
math.factorial(temp)
app.debug = True
lines.append(str(self.problem_mark))
df.assign(z=df.x * df.y)
pylab.grid()
num += 1
os.umask(oldmask)
y = all_lists(negate(x))
raise KeyError(key, val)
event.widget.quit()
F.X[:, (0)]
unittest.main()
plt.grid(True)
print(df)
mydict = pickle.load(output)
out += str(serial.read(1))
array[slices]
y[::2]
tmp = np.bincount(idx, w)
p.close()
cax.set_array(colorv)
ns.c
True
keystone.roles.list()
now = datetime.datetime.now()
print(convert(52))
type(d.day)
print(value)
t = field.field.widget.__class__.__name__
elem.tag = elem.tag[i + 1:]
self.ui.gridLayout.addWidget(self.ui.dragDataEdit, 0, 0, 1, 1)
i = np.arange(M)[:, (np.newaxis), (np.newaxis)]
list(s.cookies.keys())
draw = ImageDraw.Draw(img1)
codecs.decode(s, originalencoding, errors), len(s)
CM[bmask] = data[bmask]
z = zipfile.ZipFile(StringIO.StringIO(r.content))
a = t
seen.add(field.data)
receiver.interrupt()
b = np.array([4, 5, 6])
X, Y = numpy.meshgrid(x, y)
x = uniq(0, [[[0]] * 5] * 5)
buffer[loc] = line.strip()
cls(len(a), a.ctypes.data_as(c_double_p))
Story.append(p)
event_box.show()
ch = logging.StreamHandler()
arr = df.a.values
X = np.random.randint(0, 99, (6, 5))
t = socket.htons(int(port))
(okays if success_condition(r) else errors).append(r)
fig.add_axes(ax)
alters[0]
p = c_char_p(s)
foo = decorator(dec_args)(foo)
row = cur.fetchall()
main_loop = tornado.ioloop.IOLoop.instance()
indices = np.arange(data.shape[0])
new_queryset = new_queryset | obj.get_ancestors()
self._x = value
p = Process(target=f)
ax.contourf(xi, yi, zi, 5, cmap=plt.cm.Oranges)
nested[outkey][inkey] = val
sys._argv = sys.argv[:]
db.session.add(stuff)
y = map(str, x)
a + step == b
EmailMessage(subject, message, to=to, from_email=from_email).send()
parsed = urlparse.urlsplit(url)
elementwiseApply(add, [4, 0], 4)
time.sleep(0.05)
binvalues.read(file, num_lon * num_lat)
d_sum[topkey][key] = dic1[topkey][key]
self.button.move(250, 50)
y = np.arange(10)
array2 = np.array(zip(*list2))
self._x
self.val *= 2
starts = np.where(xadf == 1)[0]
self.lframe.pack(side=tk.TOP)
helper(stack[:], [])
num_words += len(words)
a, b, c, d = [t(s) for t, s in zip((int, float, bool, str), input.split())]
print(process_backspaces(process_shifts(test_string)))
socket = context.socket(zmq.REP)
self.axes.zz_dataLim.intervalx
{{field.errors}}
s.enterabs(t0 + 10 + i, 0, f, (t0,))
a = np.random.rand(100000, 2)
y = tf.constant([[1.0, 1.0], [0.0, 1.0]])
b = [True] * len(a)
print((one, four, ten))
fp = webdriver.FirefoxProfile()
zip(a, a)
pos += len(char)
add.addtwo(4, 5)
self.cool_dict[attr]
f = interpolate.interp1d(theoryX, theoryY)
doc.build(elements)
it.chain.from_iterable(it.repeat(i, i) for i in range(1, n + 1))
a = [1, 2]
A = np.random.sample((n, n))
freqs[char] += 1
res = []
im = pl.contourf(data[(i), :, :])
EARTH_RADIUS_KM * c
textbox.pack()
A = 10 * np.eye(10) + np.random.rand(100).reshape(10, 10)
print(c.shape)
is_sub_with_gap(b, a)
D[i, j] = abs(x[i] - x[j])
sort(less) + equal + sort(greater)
tree = objectify.fromstring(your_xml)
df
c.perform()
True
f(x=5)
review.save()
print(x)
df[date_col_name] = pd.DatetimeIndex(df.index)
w, h = P.wrap(doc.width, doc.bottomMargin)
bisect.insort_left(l, 8)
autoCov += (Xi[i + k] - Xs) * (Xi[i] - Xs)
result += numbers[i:j]
y = eval(x)
tuples = itertools.zip_longest(*A)
evens.append(i)
filename = sys.argv[1]
random.randint(1, 100)
r = coo_matrix((data, (row, col)), shape=(M, N))
pylab.ylim([0, 100000])
ports_strs.append(str(port))
elapsed = timeit.default_timer() - start_time
[(k, v) for k, v in list(aliases.items()) if q in k or q in v]
x, y = width // 2, height // 2
task2.join()
Thread(target=reader, args=[process.stderr, q]).start()
result = []
f(2, covered_list)
square[np.logical_not(has_neighbor)] = 0
False
print(B.shape)
second_axis.set_yticks([0.2, 0.4])
DummyRequest.__init__(self, postpath, session)
vals[idx]
next(testcsv)
print(a[0])
some_module.hello_world()
fig, ax = plt.subplots()
SimpleHTTPServer.SimpleHTTPRequestHandler.do_GET(self)
self.lower() == other.lower()
points = []
1
mofile
a, b, c, d = argv
result[0]
reversel.append(orig.pop())
self.K = self.P.dot(spsolve2(S.T, C).T)
offset = datetime.fromtimestamp(epoch) - datetime.utcfromtimestamp(epoch)
results.append(right[0])
arr = np.array(your_list, dtype=np.int16)
result = []
cache[key]
self._index = dict()
lst = df.A.values.tolist()
print(paragraphsep)
dir.append(d)
p = lambda x: sum(phi(x) for phi in phis)
sdl2.SDL_RenderDrawPoint(renderer, offset.x + x, offset.y - y)
plt.pcolor(X, Y, v, cmap=cm)
blogpost.tags = new_tags
condition.notify()
y = np.zeros(2 * len(bins), np.float)
a()
self.imgdir = fcb.get_filename()
result = f.read()
a.sort()
value
dict.__getitem__(self, key)
a = np.random.random((16, 16))
context
chr(97)
loop = asyncio.get_event_loop()
i, j = np.ogrid[0:n, 0:m]
self.__dict__
diff_unique = [v1 for v1 in diff_list if v1 not in set(source_list)]
manager = multiprocessing.Manager()
x = op.inputs[0]
os.dup2(desired_output_file.fileno(), sys.stdout)
form = AnimalForm(request.POST, instance=animal)
memset(a.data.as_voidptr, 0, len(a) * sizeof(int))
handler.setLevel(level)
it.starmap(func, it.repeat(args))
ax = plt.subplot(111)
traceback.print_exc()
free(my_array)
l.append(val)
col.set_sort_column_id(0)
result = Queue.Queue()
bloc122[[0, 1, 2], [0, 1, 0], [0, 2, 2]] = 0
te = time.time()
x1, x2, y1, y2 = im.get_extent()
root = lxml.html.fromstring(n)
f.add_subplot(2, 1, n)
a.append(1)
a = [0] * (imax - imin + 1)
print(data.dtypes)
c.__doc__
bananas(dingo)
self.pid = pid
fig = plt.figure()
x = [[4], [6, 4, 9], [4, 6], [0], []]
self.message = message
self.allowed = self.funcB
x, x + 1, x + 2
print ()
print([x.classId for x in uniqList])
d.setdefault(i, []).append(j)
setattr(namespace, k, v)
print(strong_tag.text, strong_tag.next_sibling)
self.crawler.engine.pause()
result = self.send(soapenv)
tree = etree.fromstring(xml).getroottree()
plt.subplot(212)
value = int(field)
event = wait_for_event()
lis.append(lambda : 0)
print(selectiveEscape)
np.rad2deg(lat), np.rad2deg(lon)
self.mapping[key]
1, 4, False
out = np.concatenate((pic, separator_str), axis=1).tostring()
s = codeErr.getvalue()
link.cwd(path)
messages = list([_f for _f in messages if _f])
l = [True, True, False, True]
deletedict[k]
sf.flush()
{getattr(self, k): v for k, v in kwargs.items()}
print(my_tz.normalize(my_tz.localize(dt) + delta))
crypts
p2 = np.array([[1, 1]])
ax.set_ylim(min(y) - offset, max(y) + offset)
a = np.array([True, True, True, False, False])
saver.restore(sess, dir_path + ckpt_file)
a = 5
x = np.asarray(x)
signal.signal(signal.SIGWINCH, update_terminal_width)
Py_DECREF(v)
x = []
HSV_tuples = [(x * 1.0 / N, 0.5, 0.5) for x in range(N)]
df = DataFrame(table)
data = data.decode(encoding, data).encode(new_coding)
False
body = Column(UnicodeText, nullable=False)
logutils.set_up_only_once()
out.append([ele])
x = np.random.rand(1000)
cur = con.cursor()
print(err.args)
data = f.read(length)
int(newSave)
app = wx.App(False)
draw = ImageDraw.Draw(mask)
clf = clf.fit(X[:50, :], y[:50])
doStuffStart()
start = datetime(2015, 1, 1)
current.append(x)
time.clock()
result = [SQLRow(cursor, r) for r in cursor.fetchall()]
r1, r2 = spline.roots()
self.timer.timeout.connect(self.reply)
d = collections.defaultdict(list)
p1, _ = optimize.curve_fit(f, x, y, (0, 0, 0, 0, 0), sigma=sigma)
r.content
len(c)
reduced.pop(key, 0)
print(i)
Py_DECREF(it)
window = gtk.Window()
dz = [5, 4, 7]
js[key] = eval(value)
x0, y0, z0 = 10, 10, 10
match = max(d.get_matching_blocks(), key=lambda x: x[2])
t.join(timeout)
today = pd.datetime.today()
x[1]
True
plt.axes([0.45, 0.45, 0.45, 0.45])
save_cookies_lwp(r.cookies, filename)
x, y = np.meshgrid(np.linspace(-1, 1, 100), np.linspace(-1, 1, 100))
my_dict[key] = new_value
process_data(datum)
coord = tf.train.Coordinator()
prime_form(9, 1, 5)
thread_.start()
print(f(v, 0, sum))
exit()
m.indices = (indices + 1) % m.shape[1]
pl.set_line(line, [p1x, p2x], [p1y, p2y])
app = QApplication([])
screen = pygame.display.set_mode(SIZE, pygame.RESIZABLE)
output.write(output_compressor.compress(chunk))
out = []
tmpfile.write(oldline)
self.STDOUT_FILENO = sys.stdout.fileno()
feed = feedparser.parse(content)
Z = random.random((50, 50))
df = drop_col_n(df, 2)
m = adate.month - 1
c = np.arange(24).reshape((4, 6))
s[:p], s[p + 1:]
idx0 = np.concatenate(I)
img.save(path)
fig, axes = plt.subplots(nrows=4, ncols=4, sharex=True, sharey=True)
fig, ax = plt.subplots()
map(word_to_action, w)
sidebar_data_views.append(fn.__name__)
df = pd.DataFrame.from_records(foo).T
float.fromhex(new_hex_equiv)
a = np.arange(15)
print(o.x)
groups = []
next(it)
Any()
self.im.seek(j)
a = np.arange(5, dtype=np.double)
output = re.sub(regex, subst, output)
dx = np.diff(np.sort(x))
years, months = int(years), int(remainder // avgmonth)
A = numpy.array(A)
df
df
users = [User.load(db, uid) for uid in db]
print(enc.encode(obj))
CM = ax2.contourf(XC, YC, YC, levels=levls, norm=LogNorm())
avg = avg - datetime.timedelta(microseconds=avg.microseconds)
app = QtGui.QApplication(sys.argv)
ctx.text_path(text)
window = Gtk.Window()
self.obj[frozenset(idx)]
urlretrieve(urlparse.urlunparse(parsed), outpath)
Map(*maps)
d = {}
self.__missing__(key)
column_align.show()
a = Foo()
x = list(range(1, 10))
ret.time = self.time.__getitem__(item)
temp = np.dot(datam[i:], datam[i].T)
cmyk = []
bins = np.linspace(0, 1, nbins + 1)
ax = plt.gca()
self
printMetric()
[5, 6]
data = client.recv(size)
ax.cla()
fo.seek(0)
print(key)
pool.close()
G.remove_node(bad_minor[0])
no_integers = list(filter(is_integer, mylist))
float_str
instance = reservation.instances[0]
df
s[-1]
head.read()
z.dtype.names
files = [stack.enter_context(open(fname)) for fname in filenames]
f()
l.count(True) == 1
A.__init__(self)
clf1.fit(X, y)
arr[x] = row
reactor.listenTCP(8080, site)
print(msg.CC)
[s]
result.append(word_map.get(w, 0))
chain.from_iterable(islice(iterable, *i) for i in args)
age = forms.IntegerField()
worksheet = workbook.add_worksheet()
pool.apply_async(mytask, (runlist[sendcounter], q))
A[:] = [A[i] for i in new_order]
self.serv = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
self.buf = cStringIO.StringIO()
f.write(xmlstr)
y = np.linspace(1.0, 2.0, 101)
print(s.recv(65000))
c = numpy.zeros((4, 2, 2))
(x for _, x in nlargest(k, ((random.random(), x) for x in it)))
groups = [list(g) for k, g in groupby(seq, lambda x: x != -1) if k]
print(e, q)
bins[i] += 1
process(i for i, v in zip(generator(), counter))
frame[~(b1 | b2)] = 0
a is a + tuple()
logging.config.dictConfig(LOGGING)
cv2.floodFill(result2, maskborder, seed_pt, (0, 255, 0))
t = pd.DataFrame(dict(val1=[1, 2, 0, 0], val2=[0, 0, 2, 1]), df1.columns)
cookie = Cookie.SimpleCookie()
idx = a.cumsum()
copy_list = org_list[:]
app = Flask(__name__)
frame = pd.DataFrame(data)
PyObject_Del(self)
print(response.read())
f = open(fn)
list(menu_links.items())
item, = [1, 2]
f.seek(0, os.SEEK_END)
round(a, 4)
d = Image._getdecoder(self.mode, d, a, self.decoderconfig)
print(d[..., (2)])
i = bisect.bisect_left(float_list, 2.5)
connection.close()
0
print(combine(a, b))
item
do_all_the_processing()
frame.values.squeeze()
test[5] = 6
img = Image.open(BytesIO(img))
round(x * 4) / 4.0
current_group.extend(group)
p = Popen(cmd.split(), stdout=PIPE, stdin=PIPE, stderr=STDOUT, bufsize=1)
outer_sum += inner_sum * dk
self.flush()
self._y = self.y = y
serializer_class = ExperimentSerializer
test.test_func()
ax.patch.set_alpha(0.0)
textobj.set_text(wrapped_text)
self.cursor = self.conn.cursor()
b, c = zip(*matches)
enable()
len(listing), total
a = C()
res2 = slice_array(arr, 4)
u = np.cumsum(dist)
[1, 1, 1, 1, 0],
loop()
obj
now = datetime.now(local_tz)
Foo.lock = threading.Lock()
test1.put()
p.waitFor()
[i for text in myList for i in textwrap.wrap(text, 10)]
painter = QPainter()
fh = logging.FileHandler(filename)
answer2 = result2.get(timeout=10)
df = pd.DataFrame(dict(A=np.arange(len(tidx))), tidx).sort_index()
out = np.zeros_like(x)
print(link)
instance = ModClass()
loop = asyncio.get_event_loop()
output = ImageOps.fit(im, mask.size, centering=(0.5, 0.5))
s1[:i]
bound_method(*args)
stream.stop_stream()
temp_handle.write(command)
type(0)
df.Time = pd.to_timedelta(df.Time)
web.Response(self.format_data(data))
Orange.feature.Continuous(str(d.name), number_of_decimals=0)
self.HTMLDATA.append(data)
t.start()
grandFather.appendChild(tag)
im = cv2.imread(sys.argv[1])
print(args_name)
help(WebKit.WebView)
topic.users.get(pk=1)
print(e)
last = value[1]
left = randint(0, len(L))
print(self.b)
self.file.readline()
bounds = [len(lst) for lst in lists]
A[:] = D[slc]
instances = [i for r in reservations for i in r.instances]
word_list.append(k)
ploty, plotz = np.mgrid[-4:4:100j, -4:4:100j]
row = xy[1]
called.append(True)
soup4.div
particle.append()
names = pd.DataFrame()
obj = json.loads(chunk.group(2))
json_data = json.loads(urlobj)
len(data)
self.fig = ax.figure
Grid.columnconfigure(grid, x, weight=1)
show()
print(df1[mask])
Clothing | Menswear | Pants | Shorts
print(Xfit_mono_ind)
header += file_handle.readline()
p[np.triu_indices(p.shape[0], 1)] = pf
f
self.close()
count_primes(10 ** 9)
chained.extend(li.pop(0))
b = np.average(a, axis=2)
g = g.add_legend()
pprint.pprint(list(gen))
print(t)
app = QtGui.QApplication([])
self.count > 0
list(run(5, 5))
np.transpose(np.matrix(data))
a = np.arange(4).reshape(2, 2)
form.show()
{{page.title}}
func_name = method.__func__.__name__
x = x + b
q.get(False)
exec(sys.arg_set)
files = os.listdir(dir)
r.real = a.real * b.real - a.imag * b.imag
print(ps.maybe_random_prime_from_range(4000, 4200))
print(sorted_dict.iloc[2])
self.parent.id
_pix_write_implied_format(filename, self, quality, progessive)
ipcounter += 1
writer = csv.writer(new_a_buf)
max_range = np.asarray(max_range, dtype=int)
parsed_url = urlparse(url)
pwd.len() < minlen
MyClass.does_something()
xfmt = ticker.FuncFormatter(xformatter)
session = Session()
dict(posts_page=_posts_page)
self.method = method
values = df.Prices * df.Amount
url = urllib.parse.urlsplit(url)
l1.append(i)
value = get_value(value)
ax = plt.axes(projection=ccrs.PlateCarree())
fileobj = requests.get(url, stream=True)
current_dict = current_dict.setdefault(letter, {})
admin.site.register(MyGroup, MyGroupAdmin)
a = np.arange(1, n + 1)[(np.newaxis), :]
print(content)
gc.is_tracked(d)
show()
xs.append(expr)
self.finished.emit()
cursor = conn.cursor()
s.dt.components.hours
df = pd.DataFrame(data_points)
column_names = [d[0] for d in cur.description]
parent = element.getparent()
ints = list(filter(str.isdigit, line.split()))
4, 5, 6, 7
g = f.__globals__
list = []
self.token.join([str(s) for s in value])
sys.exit(1)
c.A7
count_dict[base] += 1
array[array < 0] = 0
skyscrapers[building_number] = BUILDING
fig, ax = plt.subplots()
meta.reflect(bind=someengine)
table.setdefault((w1, w2), []).append(word)
type(lst)
raise StopIteration()
allelts.add(u)
self.swallow = swallow
y = np.sin(x * 2) + np.sin(x + 1)
C.__init__(self, a, c)
print(results)
print(row)
print(name)
print(draw.get_font_metrics(img, artext))
glClearColor(0.5, 0.5, 0.5, 1.0)
(0 * pq.degC).rescale(pq.degF)
func
self._array = array
df
d = {s: 1}
tbsCertificate.decode(cert[0])
thread.join()
val + 1
MyApplication()
self.popup.show()
print(name)
menu = wx.Menu()
hanoi(pegs, aux, target, n - 1)
writer = csv.writer(f)
print(line)
print(req.text)
print(filename)
df
self._end = end
i = s.find(t)
coords = np.column_stack(np.nonzero(img))
Fin
auth.redeem_refresh_token(service_info.service_resource_id)
story.append(image)
resp_dict = json.loads(resp_str)
p.showPage()
q = q_key.get()
not any(chain.from_iterable(x))
B = np.asmatrix(np.arange(N)).T
y = extrapolator(dayswanted)
sys.exit(1)
print(root.nodes.node[0].PCDATA)
ts = pd.Series(np.random.randn(len(rng)), index=rng)
tf.add_to_collection(collection, clip_weights)
res = []
root = tk.Tk()
self(*args, **kwargs) + other(*args, **kwargs)
stream.close()
date = sheet.row_values(rownum)[0]
p.print_help()
dx, dy, dz = 1, 1, 2
G.number_of_edges()
cls(data)
counter += 1
img.write(artwork)
pprint.pprint(A)
image = numpy.array(image)
pool = multiprocessing.Pool(initializer=init, initargs=(l,))
print(set1 == set2)
print(foo()[0])
math.atan2(0.0, 0.0)
dfr = dfr.fillna(dfr.max().fillna(0) + dfr.isnull().cumsum(axis=0))
obj = Child()
a1[i] ^= a2[i]
print(type(my_time))
team = team_xpath(row)[0]
console = logging.StreamHandler()
keys = list(i.keys())
set_qt_bindings(sys.argv[-1])
fig = plt.figure()
a = [12, 4, 15, 11]
print(i)
self.list = TestListCtrl(self.panel, style=wx.LC_REPORT)
d1 = pickle.load(fp)
d[value].append(index)
self.im = im
result = itertools.chain(qs1, qs2)
print(newurl)
self.assertEqual(some_method(), True)
print(colornames[color])
result = []
[0.0, 1.0, 0.0],
pprint(lod)
df
data = list(input_file)
theta = random.uniform(0.0, 2.0 * math.pi)
bins = np.linspace(0, 1, nbins + 1)
sol = r[(r.imag == 0) & (r.real > 0)].real
lst.append(1)
atexit.register(readline.write_history_file, histfile)
f.write(json.dumps(settings))
count += 1
self.visit(node.value)
new_lst.append(int_i)
os.close(0)
a_list = [(randint(0, 100), randint(0, 100)) for _ in range(N_ITEMS)]
reps
parser.close()
Matrix(M)
localFile.write(packet)
angles = [90, 95, 75, 100]
print(line)
print(matplotlib.__version__)
next(cr)
application.listen(9999)
print(value.i)
selflink.allow_tags = True
l = [1, 2]
print(lines)
matches = [m for m in pattern.finditer(target)]
print(d)
d = dict()
numbers = remove_indices(numbers, indices)
no_digits.append(i)
print(x)
print(custom.vformat(templatestring, [], valuedict))
fd.read()
lines, _ = ax.get_legend_handles_labels()
l.append(x + 1)
xx = np.random.randint(0, 5, 1000000)
arr.shape
fig = plt.figure()
self.high = range_list[-1]
res.append(dic)
insert(d, keyList2, value2)
z = np.diff(np.append(-1, i))
numbers = {int(line) for line in integers}
EMAIL_USE_TLS = False
mylist[i] = item ** 2
db.session.add(user2_from_factory)
cursor.append(dict(zip(fieldnames, values)))
m = ma.masked_where([True, False] * 5, arange(10))
main(args)
outer_sum
[1]
self.load()
nArray[nArray == 10] = 9999
a = (zfront + zback) / (zfront - zback)
rows, cols = a.shape
patches.append(self.fill(x, y, closed=False, edgecolor=c, fill=False))
event = Event.objects.get(content_type__pk=ctype.id, object_id=self.id)
a = np.linspace(-1, 1, 4) ** 2
li.sort()
first_name = CharField()
print(countOccurencesAtTheEndOfTheList([1, 2, 1, 1, 1]))
keys = bucket.get_all_keys(prefix=key_prefix)
scrapy / linkextractors / lxmlhtml.py
2 + value
popen = subprocess.Popen(args, stdout=subprocess.PIPE)
sched.start()
print(instance.public_dns_name)
self.hline.set_ydata((y, y))
1558 < [1]
fig = pylab.figure()
logging.basicConfig()
size = len(f.read())
app.py
self.text = text
print(arr[:])
kclass
result
arr1[k] = 2
result = model.objects.get(**kwargs)
s[end + 1 - best:end + 1]
c.setopt(pycurl.WRITEFUNCTION, txtcurl.write)
Index = list(set(list(df1.index) + list(df2.index)))
print(node.toxml())
page = urllib.request.urlopen(url)
s1.values.append(2)
a = A()
cls(name, bases, dct)
app = wx.PySimpleApp()
shutil.rmtree(tmpdir)
output.paste(0, mask=mask)
result = func(x, y)
subsequences.append([data[-1]])
list.append(Food(4))
opener = urllib.request.build_opener(handler)
g.__call__
dir(Bar)
min_x, max_x, min_y, max_y = minmaxes(alist)
m = p.match(line)
func(context, *args, **kwargs)
x ** 2 + y ** 2 + z ** 2 <= 1
soup
frame = pylab.gca()
self.server = make_server(self.host, self.port, handler, **self.options)
num_rejects = 0
set_trace()
x < -1000
matrix = []
print(sys.prefix)
print(colnum_string(28))
zipped.close()
__builtin__.object
b = a - numpy.fix(a)
False
s = Session()
L.extend([4] * 10)
sourcelines = inspect.getsourcelines(func)[0]
self.v = v
sfile.close()
4805
tempCS1 = plt.imshow(frame, cmap=plt.cm.gray)
n, d = int(n_d[0]), int(n_d[1])
ts.tm_hour
ignore[np.ma.minimum(x11, x12) > np.ma.maximum(x21, x22)] = True
key = get_cache_key(request, key_prefix=key_prefix)
x.Foo()
bins = numpy.linspace(-10, 10, 100)
rv = func(*args, **kwargs)
0
doctest.testmod()
miny, maxy = -miny, -maxy
regexp - assemble
count = 0
xml = ET.tostring(root)
ax.set(axisbelow=True, xticklabels=[])
i = [0] + numpy.cumsum([len(i) for i in contribs]).tolist()[:-1]
V[..., (0)] + V[..., (1)]
data = np.random.random_sample((20, 10, 10))
df
df = pd.DataFrame(data)
mat.numCols()
curses.mousemask(curses.ALL_MOUSE_EVENTS)
replacement if c[0] == n else match.group(0)
children = set()
bytes = fcntl.ioctl(fd, _KDGETLED, bytes)
cell.eventson
dc.annotation.remove()
print(num)
dst.close()
Fun.name
len(m)
xx = np.lib.stride_tricks.as_strided(xx, shape, strides)
type(bytes)
d = HashableDict(a=1, b=2)
new_pos += 1
a = map(str, a)
self._y = self.y
print(df)
self.__class__(self.func.__get__(obj, type))
self.tvcolumn0.pack_start(self.text, True)
m.show()
ws.Columns.AutoFit()
file_in_memory.seek(0)
show()
attr_name_to_attr[attr_name].get()
request.PUT = QueryDict(request.body).dict()
utc_time = utc_time.replace(tzinfo=pytz.UTC)
newR = np.array(newR)
start + nones + end
apply_vectorized(funcs, a)
buf = f.read(4096)
result = sum(map(mult, pairs))
cond.wait(timeout - current_time + start_time)
server.serve_forever()
time_a_method(m, s)
print(result)
shifts = [1] * (len(pattern) + 1)
year_start + datetime.timedelta(days=iso_day - 1, weeks=iso_week - 1)
f
instance = TestClass()
print(df)
plt.sca(current_ax)
len(final_subnets)
i = len(words) - 1
599999900, 600000000
x[1:] += x[:-1]
d
p = argparse.ArgumentParser()
y = [(k, v) for k, v in x if max(d[v]) == k]
o.write(p)
idx = np.unique(index).tolist()
np.clip(dat, 0, 1, out=dat)
image = pyexiv2.Image(sys.argv[1])
some_lib.do_something_with(SomeMockObject)
math.sin(x)
content = gzip.GzipFile(fileobj=some_file).read()
print(root.attrib)
self.arr[key]
x = np.linspace(0, 4, 50)
signals.post_save.connect(Revision.send_email, sender=Revision)
ord(a), ord(b)
g()
response = Response(resp.content, resp.status_code, headers)
raise KeyError
c = vs.mean(axis=0)
data = numpy.arange(0.0, 16.0).reshape((4, 4))
date = models.DateTimeField()
a = list(range(5))
panel.draw()
n = 1
resp.sendRedirect(userService.createLoginURL(req.getRequestURI()))
b.append(6)
char = msvcrt.getch()
[15, 8, 9, 6],
print(ms.group(1).strip())
s = set()
ids = avgDists.argsort()[::-1][:n]
print(do_add(s, 4))
print(link.string)
self.start = start
socket.inet_ntoa(unpacked)
record = self.browse([NewId()])
fp = os.path.join(root, f)
main()
que.put(a * b)
app.setWindowIcon(app_icon)
decorator
n = len(data)
max(freqs)
newlist = list(oldlist | addlist)
spiral_ccw(np.arange(nrow * ncol).reshape(nrow, ncol))[::-1]
print(f(4, 2))
fp.write(part.get_payload(decode=True))
a
movie_dict[actor].append(key)
t = app.jinja_env.get_template(template_name)
loop.stop()
a = []
self.wait_for_prompt()
df2
(ds1 + ds2).to_netcdf(new_file)
sp = parser.add_subparsers()
df
x = random.random()
functools.update_wrapper(wrapper, fn)
np.random.seed(1)
grp1.append(s)
buff.append(line)
p = bk.figure()
out.write(chunk)
max(map(len, values))
counts = list(enumerate(uniq_count(words), 1))
self.assertEqual(captcha_count, 1)
width, height = im.size
(arr - amin) * 255 / rng
f = sys.exc_info()[2].tb_frame
key = cv2.waitKey(20)
queryset
print(item)
subVal[key]
pos = (j - i for i, j in enumerate(lst))
print(word)
b.instance_a.save()
a = a.reshape(a.shape[2:])
self.parent._fsb_controllers.append(self)
context = ogl.CGLGetCurrentContext()
__old__getattr__(self, name)
closedir(dir_p)
counts = Counter()
x = np.fromstring(np.random.bytes(n), np.uint8, n)
c = np.dot(X.T, Y)
next(r)
factor = inversemodp(A[i, i], q)
HTMLParser.reset(self)
print(bar)
interleave(s, t, res + t[j], i, j + 1, lis)
series = models.CharField(max_length=50)
gevent.spawn(read_stream, p2.stderr)
OneOrMore(blockOfText).parseString(bigHonkingString)
Base.metadata.create_all(engine, tables=[SaneTestModel.__table__])
sys.getrefcount(empty)
model = MyModel
opts, args = parser.parse_args()
df_c = df_a.reindex(df_a.index | df_b.index)
plt.ylim(ymin=-1.1, ymax=1.1)
time.time.__name__
bodylist.remove(x)
df = pd.DataFrame([1, 2, np.inf, -np.inf])
mytask.apply_async(args, kwargs, connection=conn)
blob_info = upload_files[0]
stdscr.clear()
permutes.append(list(permutations(values, subset)))
print(res._size())
op(A, B)
status, result
mask = x * x + y * y <= r * r
self.update_prop(legline, orig_handle, legend)
fig, axes = plt.subplots(ncols=2)
N - (fmin + 1) * f2
pygame.display.flip()
hash(1)
itertools.chain(self.vals, self._gen_iter())
self.systemTrayIcon = QtGui.QSystemTrayIcon(self)
tokenizer.transform(sentenceDataFrame).show()
cls
iren.Initialize()
np.import_array()
pickle.loads(pickle.dumps(e))
x.pos[int(x.n)]
pos = networkx.spring_layout(G)
arr = np.ndarray((10, 4), dtype=object)
2 * f
start_urls = []
floodfill(painted_map, POINT_STATE[k], 255 - color)
f.close()
self[key] = other[key]
df = pd.lreshape(df, d)
ff.seek(0)
A.__init__(self, name)
zf.write(fpath, zip_path)
np.uint8(np.abs(np.int16(img1) - img2))
x = np.random.normal(size=1000)
y = negate(x)
start = numpy.array([1, 5, 7], numpy.int16)
b = make_chess_board()
node = jinja2.Markup(html)
food_ctx.add((alice, dislikes, pizza))
modules_to_reload.add(name)
reader = csv.reader(afile, dialect=snift)
value
reactor.listenTCP(1025, factory)
False
e.args
m(1)
a = a[~np.isnan(a)].astype(int)
rconsole
stat_queue.task_done()
fields[key]()
fn
s.add(4)
table.show()
production.py
p.feed(s)
cv2.imshow(win, vis)
n = len(matrix)
t.join()
weights = faces[2]
data = f.read()
foo = Foo(1, 2)
valid_strings[start] = tuple(seq[start:start + length])
myList, myTuple = list(range(10)), tuple(range(10))
OrderForm(tickets=available_tickets)
[testenv]
self.__dict__
self
it = iter(it)
cb = plt.colorbar(im)
e = etree.fromstring(s)
threading.Thread.__init__(self)
r.withdraw()
self.name = name
resource.setrlimit(resource.RLIMIT_STACK, (2 ** 29, -1))
getline(cin, input_line)
a.__add__(b)
count1 += 1
fig.show()
l[:2]
setattr(TestCase, name, login_testuser(obj))
obj = getattr(obj, attr)
imgdata = urllib.request.urlopen(href)
buf.bind()
ax = pylab.subplot(111)
register = template.Library()
print(countOccurencesAtTheEndOfTheList([1, 1, 2, 2, 2, 2]))
mask = np.ones([len(x_2) - 1], dtype=bool)
help(foo.bar)
print(result)
self.density_water = 0.001
bounds = [(low, high) for low, high in zip(xmin, xmax)]
result = getattr(im, method)
test.paths()
print(string_list)
__main()
convert(f, 2)
a = [1, 2]
env = Environment()
print(test.param1)
self._db_recycles += 1
[node for node, length in path_lengths.items() if length == n]
ns = {}
pool.map(process_all, pathfile, 1)
str(self())
self.tree = [0] * (n + 1)
self.name = name
self.members = set()
g = coo_matrix((ares, (col, row)), shape=(2, 2))
event_date = models.DateField()
device = TextConverter(rsrcmgr, retstr, codec=codec, laparams=laparams)
print(line)
s.add(x)
temp = dict()
i = a.tolist().index(2)
an_image.point_data.scalars.from_array(colors)
exit(1)
isinstance([], collections.Sequence)
ax.add_patch(rect)
widget.init(data_from_django)
result.result()
x, y = pts.T
data = urllib.parse.urlencode(values)
dt = tz.localize(datetime.datetime(2011, 6, 20, 0, 0, 0, 0))
self.selenium[browser].quit()
print((a, b))
print(conn.list())
sequence[0]
self.__class__.PARAM
floor(2 * (N - i - 1), 1 + 4 * i)
y = x * f(x)
s = list(s)
ims.append([im])
f.read(6)
handler2.addFilter(MyFilter(logging.ERROR))
querylist.union(wordlists[wordno])
sum(1 for v in seq if pred(v))
[seq[i:i + length] for i in range(0, len(seq), length)]
b1 = tf.Variable(tf.zeros([256]))
keepers[key] = i, row[2]
Tprime.sum(-1).sum(-1).sum(-1).sum(-1)
X_test = X[test_indices]
list(dic1.keys()) - dic2
result = []
image_samples.append(im.crop(box))
opts
authenticate(bytearray(creds))
coursesList.sort()
blob_info = upload_files[0]
merge(list1, 0, 2)
x = np.zeros(n)
response = urllib.request.urlopen(url)
combis.append(guess)
fig = p.figure()
result
print(total)
True
ret, frame = cap.read()
print(a.add(1, 2))
lfilter(num, den, a, axis=0)
foo = Foo()
results[parent(u, mapping)].add(u)
myTurtle.right(50)
description = models.TextField()
response
718.7747248407644,
logger.addHandler(log_handler)
df[ops[op](df[col], val)]
S1 += len(set(ids))
soup = BeautifulSoup(browser.page_source)
server.daemon = True
top = tkinter.Tk()
p.start()
parser = argparse.ArgumentParser()
b = np.copy(identity)
entity = json.loads(data)
print(blah2)
p = Process(target=crawler, args=(domain,))
result = dict((key, len(list(group))) for key, group in groupby(sorted(words)))
now = datetime.datetime.now()
print(date)
username = db.Column(db.String(20))
p = argparse.ArgumentParser()
t = time.time()
parser = optparse.OptionParser()
lines.append(self.note)
s
bmp.CreateCompatibleBitmap(srcdc, width, height)
encoding_pipeline.fit_transform(fruit_data)
bits = bin(ord(c))[2:]
repr(self.data)
gc.set_debug(gc.DEBUG_SAVEALL)
l[0]
b = np.random.rand(100 * 100).reshape((100, 100))
node_data
self.form = Mock()
period += 1
mydict = {}
w, h = im.size
type(t[:1])
table[i][W - 1] = knapsack(i - 1, W)
ff.read()
ax2 = ax1.twinx()
font = cv2.FONT_HERSHEY_SIMPLEX
db.create_all()
root = Tk()
form = Product(request.form, category=2)
res = c.spelling
c = df.columns.values
basename = os.path.basename(name)
ret, gray = cv2.threshold(roi_gray, 250, 255, 0)
ClergySerializer(instance=instance).data
mkl.set_num_threads(2)
PyList_SET_ITEM(p, i, item)
d[k] = v
subparsers = parser.add_subparsers()
word = line.strip().lower()
d1 = date(2001, 5, 1)
p = subprocess.Popen(cmd, stderr=outputfile, stdout=outputfile)
msg = server.recv()
folder = client.GetResources(q=q).entry[0]
parse(matches.group(0))
arr.size()
optionmenu.grid(column=column, row=row)
newlist = []
end = len(ranges) - 1
Z = np.sqrt(X ** 2 + Y ** 2) + np.cos(Y)
count += 1
points = np.random.rand(1000, 2)
logits = tf.matmul(hidden, W_logits) + b_logits
print(counter[input_char])
print(bybuf())
print(byline())
print(a, b, c)
my_list = my_list.insert(0, my_string)
A().f2()
QuerySet._filter_or_exclude = _filter_or_exclude
print(df)
replchars.sub(replchars_to_hex, inputtext)
type(b)
bin((1 << 8 | 2) << 8)
date.month
result.join()
ax.scatter(args, color=next(palette))
new_pdf = PdfFileReader(packet)
od = defaultdict(list)
print(sum(df_subset.C * df_subset.E))
syncdb.Command().execute(noinput=True)
bool(set(fruits).intersection(fruit_dict2))
ranges = np.concatenate([np.arange(count) for count in counts])
print_set(email.get())
signal.signal(signal.SIGALRM, handler)
_recursivePop(tree, nodes)
tmpfile.close()
True == 1
img.close()
c = img.layers[0]
type(x)
print(row.name, np.mean(df2))
df
as_strided(b, (n - 1, n + 1), (b.itemsize * (n + 1), b.itemsize))
a = sorted(a, reverse=True)
controllers
helpers
queryset = Bloop.objects.all()
main()
method(self, *args, **kwargs)
a = np.array(a)
M = NP.empty(shape=(10, 5), dtype=float)
changed = [(k, v) for k, v in list(self.byEmail.items()) if id(person) == id(v)]
print(df2[mask])
R = array.shape[0]
self.items.append(item)
db.put(entities)
msg = clientsocket.recv(1024)
entries = re.split(regex, allLines)
arr[:, (0)] = int(10)
print(difft(time(20, 40, 0), time(22, 41, 0)))
map(numpy.random.shuffle, array)
print(foo.getI())
object_list = object_list.filter(user__in=request.user.patients.all())
result = cursor.fetchone()
self.__refs__[self.__class__].append(weakref.ref(self))
True
df
admin.site.unregister(Group)
DBSession = scoped_session(sessionmaker(extension=ZopeTransactionExtension))
entity = models.ForeignKey(CancellationEntity)
sqldf(q, globals())
test.open()
dispatcher.connect(reactor.stop, signals.spider_closed)
b = numpy.array([(n + datetime.timedelta(minutes=i)) for i in m])
info = response.info()
doc.remove(tag)
diam = np.zeros(len(seed))
glViewport(0, 0, self.width, self.height)
result = urllib.request.urlretrieve(self.url)
l[0] = 0
x = df.ix[(0), 5:]
something_useful()
http = credentials.authorize(http)
n_values = np.max(X, axis=0) + 1
y, x = np.mgrid[:nrows, :ncols]
print(cl.run())
res += YIELD
print(f(11))
ipdb.set_trace()
self.users = self.session.query(User).all()
-1
r = np.array([random.randrange(1, 1000) for _ in range(0, 1000)])
Model.objects.count()
x, y = event.x, event.y
b = 2
ws = book.worksheets[0]
__metaclass__ = ModelBase
m[j - 1, i - 1] = 1
new_tuples
estimator.fit(X_digits, y_digits)
cmd.Cmd.default(self, line)
seq = difflib.SequenceMatcher(a=a.lower(), b=b.lower())
links = sorted(links, key=lambda x: x.popularity, reverse=True)
d[get_key(f)].append(f)
print(df)
b = []
counts = {}
self.print_stats(stats)
reactor.stop()
list(proxy.keys())
app.MainLoop()
y.diff(x)
app = wx.App(False)
con.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)
params.sort(key=lambda k_v: len(str(k_v[0])), reverse=True)
self.frame.Raise()
self.user = user
myMap[n] = 1
profile_link.allow_tags = True
filename = part.get_filename()
False
psutil.swap_memory()
register.filter(hash)
A = np.vstack((x, np.ones(n))).T
layout.addWidget(self.datetime)
name = os.path.splitext(os.path.basename(sys.argv[0]))[0]
values = np.array((0, 0, 0, 0, 0))
p = [4, 10, 5]
b = form.save(commit=False)
print(s)
l += t + t2
print(xi, yi, value, color)
c = a[:]
test > 1
i1, i2 = p1[0], p2[0]
root.children.append(t(1))
print(df2)
a = np.linspace(0, 2 * np.pi, 500)
client.do_handshake()
xmax = logdata.max()
scipy.version.short_version
v = df.stack().unique()
f(phases)
s = f.read()
patch.stopall()
f.__setitem__(0, 1)
stats.strip_dirs()
data = np.random.randint(1, 10, N)
d[k] = myfun(v)
item = items.popleft()
df
bad_os()
two = Decimal(2)
protest, 1
thirdpartymodule_a.SomeClass.__init__ = new_init
slices.append(slice(r, r + np.random.randint(1000)))
print(-np.sort(-a))
print(MySubClass().a_property)
df
l = sc.recv(1024)
GenPasswd2(8, string.digits) + GenPasswd2(15, string.ascii_letters)
print(schema)
p = np.arange(256, dtype=int)
data2.to_csv(filename)
pool.join()
s = ctypes.cast(s, ctypes.c_char_p)
xlim(0, 5.5)
module = inspect.getmodule(inspect.currentframe().f_back)
x = np.linspace(0, 2 * np.pi, 100)
pympler.asizeof.asizeof(abr)
self.min_set[self.store[key]].remove(key)
[0.68800002, 0.62400001]
matplotlib.rcsetup.all_backends
v = np.array([1, 2])
self.orig_method = getattr(self.obj, self.method)
help(so27.myfunc)
R = np.empty(N, dtype=int)
func = cls.__dict__[func_name]
socket.fromshare(share)
mydict = {a: 1}
logger
self._check_setup()
print(root.Document.Placemark.Point.coordinates)
groups = [funA, funB, funC]
result_list
message = MessageForm(request.POST)
result[1, 0, 0, 0, 0]
array = np.array(array)
ax.grid(False)
print(sqc)
n = sum(1 for line in open(filename))
pool.spawn(time.sleep, 1)
self._expensive_operation
str(self._data.values[index.row()][index.column()])
myseries_three.loc[0]
print(data_value.text)
[pep8]
p.memory_percent()
a[:]
MSWord.Documents.Open(filename)
fcntl.lockf(file_handle, fcntl.LOCK_EX | fcntl.LOCK_NB)
lines = f_in.readlines()
i = 0
xy_pixels = ax.transData.transform(np.vstack([x, y]).T)
self.loadFinished.connect(self._result_available)
ax2.set_xticks([])
cam = AVTCamera()
fig.colorbar(surf, shrink=0.5, aspect=5)
spark.createDataFrame([row]).dtypes
print(a.a)
img = images.Image(blob_key=str(profile.avatar.key()))
id = np.where(fdata[1] == fdata[1].min())[0][0]
response = gss_client.session.get(full_feed_url)
G.remove_edge(keys[1], b[keys[1]])
print(m.groups())
logsum += log(p)
p.start()
numpy.finfo(numpy.float64).max
list1 = map(itemgetter(0), origlist)
sys.exit(make_main(sys.argv))
print(groups.mean().b)
offset += size1 * byte_size
print(df)
a += [i]
cr = func(*args, **kwargs)
q.put(url)
c.my_stuff
RFPDupeFilter.__init__(self, path)
python - Qnew
X = dataset[:, :60].astype(float)
all = list(range(1, 7))
self.file = zipextfile
print(get_file_names_from_file_number(fds))
File(file_obj, name=name)
a * np.cos(2.0 * np.pi * f * t + p)
iso8601.parse_date(mydate)
print(sdk)
numpy.logaddexp(0, logB - logA) + logA
int(str)
d = defaultdict(int)
fflush(stdout)
curses.init_pair(i, i, -1)
response.status_code
s.update(list2)
height, width, channels = scipy.ndimage.imread(filepath).shape
process(cl)
NULL
plt.show()
self.events.append(datetime.now())
self.__class__.instances.append(weakref.proxy(self))
l = max(l, max(longest(elem) for elem in list1))
app = Flask(__name__)
hash(tuple(sorted(self.items())))
x
self.fields[key].required = False
input = np.array([1.0, 1.0])
my_instance.b()
a.b_list.append(B())
output = mp.Queue()
exit()
setattr(self, attr, getattr(other, attr))
session.flush()
x = np.linspace(0, 2 * np.pi, 400)
http_server2.listen(8081)
self.timestamp = time.time()
raw = f.read(4)
recvall(sock, msglen)
g.user = current_user.get_id()
result = _SHGetFolderPath(0, CSIDL_COMMON_APPDATA, 0, 0, path_buf)
controller.authenticate()
filtered = scipy.signal.lfilter(b, a, data)
l2 = [TrackedObject(x, index) for index, x in enumerate(l1)]
v.discard(k)
set(t[0])
lightened25 = lerp(my_color, white, 0.25)
pred = sess.run([prediction], feed_dict=feed_dict)
data = np.ones(y.size, dtype=dtype)
print(bytes)
tri[np.triu_indices(67, 1)] = dm
bad_lines.append(j)
d = {}
self.arg1 = arg1
out[k:k + cnt] = np.arange(cnt)
t = Timer(20 * 60, timeout)
x509.parse(s)
print(f.name)
value
stokes_list[i] = stokes_line
labels = cls.fit_predict(X_hat)
print(df)
opener = urllib.request.build_opener(cookie)
args[i] = args[i] * args[i]
content_type = models.ForeignKey(ContentType)
filename = args.output.name
serialized.save()
post_save.connect(signals.do_some_stuff_with_mymodel, sender=MyModel)
print(model_admin.search_fields)
main()
b = pd.Series([49, 54, 62, 74], index=[2, 6, 4, 0])
soup = BeautifulStoneSoup(xml_str)
wf.setnchannels(CHANNELS)
hash(key)
f.write(c)
print(dt)
self.label.width(), self.label.height()
locations = np.arange(0, 50, 1)
b = int(max(0, 255 * (1 - ratio)))
yajl.load(f)
ujson.load(f)
req = urllib.request.Request(url)
self._namescallback[channel][0].append(d)
self[k] = v
self.z + x
print(line)
s = s.execute()
[float(row_list[0]), int(row_list[1])]
j = jinja2.Jinja2(app)
print(dir(etc))
doStuff()
formset = BuyerInlineFormSet
app = Flask(__name__)
result = [x for x in A if x in B]
g.get_group(0)
long_string
client = suds.client.Client(my_wsdl, transport=WellBehavedHttpTransport())
print(nx.pagerank(D))
jobs = []
s.translate(translate_table)
query = celery.events.state.tasks_by_type(your_task_name)
head.append(i)
response = requests.get(url)
print(x, x is y)
dosomething(alist)
win = curses.initscr()
scipy.maximum.accumulate(x)
dec
settings = propfaid.get_cache()
wallet
main()
self.response.write(w)
ax2 = ax.twinx()
signal.setitimer(signal.ITIMER_REAL, seconds)
Py_Initialize()
im = ax1.pcolormesh(t, r, c.T)
id(1) == id(1)
ans = np.array([map(float, mat.next().split()) for i in range(length)])
repeated = np.broadcast_to(arr, (1000, arr.size))
dt_aware = timezone.make_aware(dt_unaware, timezone.get_current_timezone())
res[j] = numbers[f:b]
cursor = conn.cursor()
y_train = Y[train_indices]
main()
col = pd.MultiIndex.from_product([df.columns, [0, 1]])
A().update()
df
print(a, b)
database = myDB
app = Flask(__name__)
x = x.replace(k, v)
inblock = 0
scipy.stats.poisson.interval(0.95, data)
mtime = os.stat(full_path).st_mtime
writer.writerow([t, u, v, w, targets[t][u][v][w]])
self.path = path
obj.ds.append(d)
deletelang_name[k]
do_something_else_1()
x, y
vec = [(i - 1) for i in dim]
list(s)
fp.close()
sys.exit(1)
self.code_map[code] = {}
axs.add_patch(rect)
lst1 + [x for x in lst2 if x not in lst1]
x + y + z
ax = plt.gcf().gca()
s = set(range(10))
a = np.int64(np.random.random_integers(0, _BLOCK_MAX, blocks_per_flush))
start, end, step = 0, len(out), 1
args = parser.parse_args()
python
c.execute(schema)
x = np.cos(u) * np.sin(v)
s.close()
eq_map.append((coeff, power))
ranges = sum((list(t) for t in zip(nums, nums[1:]) if t[0] + 1 != t[1]), [])
self
client_socket = socket.socket()
len1
l = arr.shape[1] / m
test()
x ** 2
cv.CvtColor(frame, frame, cv.CV_BGR2RGB)
foo = choice(elements)
v = self.cache[key] = f(*args, **kwargs), time.time()
form = AuthorForm(request.POST)
U = (np.arange(M * N) / (M * N)).reshape(M, N)
lst.remove(choice)
int(maybeLst)
iqr = qhigh - qlow
sys.exit(app.exec_())
print(X_train.shape)
[0, 0]
b.sum()
file2.close()
print([co for co in c if not any(st.issubset(co) for st in sts)])
self.params = dict(params or [])
nil
self.connection.shutdown(1)
factorial(*[5, 6, 7])
print(item)
glColorPointer(2, gl.GL_FLOAT, 0, vertices_gl)
table.rename(index=str)
print(model_tunning.best_score_)
self.obj = obj
lines = [line.strip() for line in handle]
grid.addWidget(text_edit)
B = np.repeat(A[(np.newaxis), ...], 4, 0)
bins = np.linspace(X.min(), X.max(), total_bins)
fly.rect.left = hit.rect.right
iter(obj)
self.Bind(wx.EVT_LIST_COL_CLICK, self.OnColumn)
lis[index[6] + 1]
True
int(x)
a[:, (1)] = x
self.client_address[0]
result = [example[i:j] for i, j in pairs]
d = dict(COUNTRIES)
print(a)
add.delay(4, 4)
text = f.read()
loop.run_until_complete(task)
W.shape
bool(st.st_mode & stat.S_IRGRP)
r = requests.get(zip_file_url)
cmap = mpl.cm.Blues
r.findall(strs)[:-1]
right = randint(left + 1, len(L))
ax.add_patch(PolygonPatch(j, alpha=0.5))
a.x = 1
numbers = map(int, list(filter(str.isdigit, input_string)))
print(list(reversed(numbers)))
lol = [list(range(i)) for i in range(5)]
print(latest_file)
VARIABLE5
VARIABLE6
VARIABLE7
VARIABLE8
VARIABLE9
VARIABLE10
VARIABLE11
VARIABLE12
VARIABLE4
print(matches.groupdict())
fg.canvas.draw()
setattr(self, attr, self.get_column(pyQueryRow, i))
im = ax.contourf(xi, yi, zi)
numbers[0]
app.yaml
print(str(s))
df
temp_rdd_dense.toDF().show()
res = []
dictionary[section][option] = config.get(section, option)
i = cv2.imdecode(np.fromstring(jpg, dtype=np.uint8), cv2.CV_LOAD_IMAGE_COLOR)
block = infile.read(BLOCKSIZE)
True
length = len(items)
a.nbytes
print(f.vals[0])
out = np.empty(sum(cnts))
print(a, b, err)
c.pop()
new_bigmat
keys = [0.5, 1]
angle *= 180 / math.pi
dotime(func, int(argv[1]))
self.view = QtWebKit.QWebView(self)
db = SQLAlchemy(app)
row_sums[(i), :] = row_sums[(i - 1), :] + img[(i), :]
ind = np.arange(N)
+yak.update(locals())
ax = axes[i, j]
ys = np.arange(512)
s = pickle.dumps(sys)
x, y = [], []
y + 5 * x
df = pd.DataFrame(a)
t0 = time.time()
r
time = json.loads(json.dumps(time))
screen.force_update()
self.pre_app(environ, start_response)
s * 5
[x for x in a]
g.append([])
1 / 0
sys.stdout.flush()
circles = np.uint16(np.around(circles))
df.gdp = df.gdp.shift(-1)
target = sys.stdin.readline().strip()
layout = QHBoxLayout(self)
days = dict(zip(day_list, list(range(len(day_list)))))
result
result = []
next(myIterator)
use(line)
group = models.ForeignKey(Event)
print(a - b)
l2[4][1:]
A = coo_matrix((data, (row, col)), shape=(4, 4))
server.test(1, 2)
(0)(a, b)
print(next(a))
q = lambda x: tuple(range(x, x + 4))
p2 = os.path.join(relname, p)
doSomethingElseWith(pos.x, pos.y, pos.z)
self.q = queue.Queue()
fig = plt.figure()
c = 2 * atan2(sqrt(a), sqrt(1 - a))
divider = make_axes_locatable(ax)
key
plt.plot(xdata, ydata)
True
parsed = urlparse.urlparse(url)
pts.append(temp)
parser = argparse.ArgumentParser()
settings.INSTALLED_APPS.append(app)
manager = mp.Manager()
f = plt.figure(figsize=(10, 10))
self.keyToId = {}
print(y.x.i)
total.update(sample)
result = dict(source_dict)
self.pred(obj) and predicate(obj)
fq[n].append(v)
aa = np.load(f)
X(X, b)
zip(a, b)
out[x] = multidict(*args[1:])
count = 0
UglyGen(x + 1, y, z), UglyGen(x, y + 1, z), UglyGen(x, y, z + 1)
self.destroyed.fire(self)
r = tf.reshape(r, [-1, 1])
print(s)
metadata = MetaData()
chunk = min(bufsize, length)
print(key)
paths()
sender._meta._field_name_cache.append(self)
getattr(obj, self.private_name)
z = [1, 2, 4, 5, 6]
n += 1
thread.start()
z = chain(x, y)
asdf.owner = request.user
handle.write(arg.data)
tmp = np.empty((4, sy, sz))
gc.collect()
b = complex(-1, 0)
params = libtorrent.parse_magnet_uri(magnet_uri)
event = screen.getch()
[]
n = len(ls)
sys.exit(1)
self.request = request
table = table.fillna(0)
map(lambda *z: list(z), *a)
A(obj.get_num())
s
fig = plt.figure()
d.extend(x)
shutil.copyfileobj(r.raw, f)
pandas.__version__
__library.terminate()
list(map(attrgetter(*fields), listobj))
(wrapper_unpickler, (factory, ParentClass, r[0]) + r[1][1:]) + r[2:]
answer = []
lines = [row.split() for row in lines]
a + b * x[0] + c * x[1] + d * x[0] * x[1]
encodings.insert(0, enc)
k.append(mydict[item])
_write_record_to_csv(row[1:])
self.wfile.write(value)
str(self.recipe)
key.send_file(f)
dirname = sys.argv[2]
stream.close()
print(x, y, z)
tup = fin.readlines()
alias.save()
print(cmp(test1, test2))
getname(woohoo)
traceback.print_exc(file=sys.stdout)
new_row = row[:-1]
hamming_sets[0].add(l[1] + l[2])
p2, _ = optimize.curve_fit(f, x, y, (0, 0, 0, 0, 0))
now = datetime.now()
method = getattr(builtins, name)
k = min(n, k)
print(convert_consolodate(ranges))
y = [z.element for z in x if x.frobnizzle == 5]
pprint(finalData)
action()
response = HttpResponse()
client_socket.send(size)
plt.grid(False)
win.clear()
Testing(6 / 6)
res
s.ehlo()
obj_set.remove(obj)
print(val)
out = abs(z.T - z)
b2 = [True, False, True, False]
b = np.ascontiguousarray(my_array).view(dt)
process_item_method(self, item, spider)
b = dict(enumerate(a))
[uwsgi]
results = []
print(list(r))
max = self.trell[i][1][k][0]
input.read(128)
s = re.search(search, fullstring)
Command2
-codeclimate - test - reporter - -file.coverage
MSWord.Documents.Open(filename)
body = self.rfile.read(content_length)
K.set_value(opt.lr, 0.01)
D[n, s, x] = sum(P(n - i * x, s - i, x - 1) for i in range(s))
n = len(data)
df_out
x, y, z
s = Sound()
print(np.array(foos))
stderr_lines.append(eline)
in_memory_blocks = a.view(np.uint64)
-1
count += 1
xs.min()
plt.title(title)
pixbuf = pixbuf.get_from_drawable(rw, rw.get_colormap(), x, y, 0, 0, 1, 1)
y = np.linspace(1, 10, 20)
args[0], fun(*args[1])
list_display.append(str(x))
setattr(args, self.dest, values)
req = urllib.request.Request(url, data)
root = Tkinter.Tk()
sha.hexdigest()
l = len(list1)
a * x ** n + b * x - c
Color(r, g, b)
Installed / home / prologic / tmp / hello - py - c
cur[list[0]] = {}
foo = Foo()
match = regex.search(content)
y1 = np.random.normal(0, 7, 100000) / 10.0
x.start()
data2 = np.ma.masked_equal(data2, 0)
self
self.assertEqual(BRConfig.WEBROOT, sel.get_location())
file_contents = the_file.read()
row_sums[(i), :] = img[(i), :]
im = ax.imshow(np.arange(100).reshape((10, 10)))
otherfile.txt
dist = np.hypot(np.diff(x - x.min()), np.diff(y - y.min())).cumsum()
jpal += 1
[0, 2, 1, 1, 4]
print(getname(f.bar))
packet = sock.recv(n - len(data))
imshow(red)
f.destroyedObjectListener(self)
title = db.Column(db.String(64))
fig = plt.figure()
l[n] = f(i)
thread = threading.Thread(target=worker, args=(chunk,))
a = np.arange(16).reshape(4, 4)
salt
fd.write(chunk)
lst.sort(key=str.lower)
foo(d)
Base = declarative_base()
S[a] = m
db_field.formfield(**kwargs)
json_obj
sum(map(sum_nested, astruct))
module = make_module_from_file(module_name, program_filename)
print(list(Example))
count = 0
False
groups = GroupSerializer(many=True)
x[index] = 1.0
file
id_arr = np.ones(idx.sum(), dtype=int)
post_syncdb.connect(add_user_permissions, sender=auth_models)
f = sp.sin(x) * sp.cos(y) * sp.sin(z)
label_text_font_size, label_text_font_style, label_width
[a for a in list2 if a not in set1]
obj = A.__new__(args)
c = np.cumsum(a)
stdout, stderr = pipe.communicate()
c.drawAlignedString(x, y, testo)
a = tonumpyarray(data, size)
x, y = event.pos
seen = []
df.value = df.value.astype(int)
S.mean()
cblas_matrixproduct(typenum, ap1, ap2, out)
x.close()
stream.stop_stream()
[Service]
d.A > d.C
ax1.set_ylim(10.0 * np.ceil(y.max() / 10.0), y.min())
arr = np.ascontiguousarray(arr)
foobar2
self.x & other.x
r.append(a)
data = digits.images.reshape((len(digits.images), -1))
print((test_item.p1, test_item.p2))
trip_id, arrival_time, departure_time, stop_id, stop_sequence, stop_headsign, pickup_type, drop_off_type, shape_dist_traveled
pdb.runcall(test.foo, 1, 2)
c = PublicC()
self.my_init()
print(i)
d.quantize(Decimal(10) ** -places, rounding=ROUND_DOWN)
scale = mode * x
print(UserCreateForm())
{}
Grid.rowconfigure(root, 0, weight=1)
serializer_class = UserSerializer
parser = OptionParser()
data
fig = plt.figure()
pet_list.append(pet)
a.append(2)
deletepacket.chksum
sel.start(True)
old_label_image.destroy()
i, j = self.maxI - 1, self.maxJ - 1
print(id(c2))
plt.ion()
body.extend(rv)
rpath
print(decoded)
self.ranges[k] += 1
fig = plt.figure()
result.setdefault(k, {})[property_str] = v
start_server()
print([(item, tri_tokens.count(item)) for item in sorted(set(tri_tokens))])
t.start()
y = data[:, (1)]
session.remove()
deleterenWin, iren
arr = numpy.array(im)
pairs += s[0], s[-1]
rows = np.random.choice(df.index.values, 10)
np.random.seed(42)
data = []
img.setPixel(0, 0, 5)
value = vinterp(xcenter + r * np.sin(angle), ycenter + r * np.cos(angle))
soup = BeautifulSoup(source)
args = parser.parse_args()
getattr(external, name)
parameters = urllib.parse.urlencode(parameters)
ax = fig.add_subplot(111)
print(is_new_style(new_style))
x if x > 100 and y < 50 else y
x = random.gauss(100, 50)
ranked = sx.expanding().agg(lambda x: rankdata(x)[-1] / len(x))
ordered.append(heappop(heap))
K.sort()
args = parser.parse_args()
print(sorted(d))
88888888, 55555
poly = np.polynomial.Polynomial(params)
myapp.db.drop_all()
m.login(user, pwd)
len(self.datatable.index)
count += 1
errorcodes.lookup(e.pgcode)
main()
autolabel(rects1)
True
porter.stem(greater)
response = urlopen(url)
t1 = time.time()
y = numpy.roll(x, 1)
soup.body.append(wrapper)
libc.fopen.restype = c_void_p
ser.setDTR(level=0)
1.0 / sigma * (y - func(x, *p))
db.expire_all()
b = np.ones((2, 2))
self.assertEqual(1 + 1, 2)
reversed_dict = collections.defaultdict(list)
print(len(clf.feature_importances_))
syncdict = manager.syncdict()
arr = np.fromiter(iter(im.getdata()), np.uint8)
DataFrame1.plot(legend=False)
gs = gridspec.GridSpec(rows, cols)
False
1244489871.0
hamming_sets[0].add(l[0] + l[2])
collections.defaultdict(Tree)
g.append(el)
values.append(int(x))
_HTTPConnection.connect(self)
results[obj].append(size)
n, seconds = divmod(t, 60)
push((nextbasesquared, nextbase, 2))
result = SomeResult()
M = arange(10).reshape(2, 5)
results.plot()
self.signal.disconnect(self.receiver)
1, 2
f = urllib.request.urlopen(url)
t = np.arange(0.01, 10.0, 0.01)
root = etree.fromstring(xml)
print(d.shape, len(k))
data = Data()
[self.x - 1, self.y - 1], [self.x + 1, self.y - 1]
data = {}
q, r = divmod(a, b)
doc = html.fromstring(s)
book = xlrd.open_workbook(sys.argv[1], formatting_info=1)
file.open()
G.add_edge(5, 17)
l = line.split()
print(next(generator))
a = [random.randint(0, 1000000) for _ in range(100000)]
xlim = ax.get_xlim()
[sum_vectors(v, w) for w in ws]
tuple(sorted(widget.items())) in widget_set
zip(cycle(tup[0:1]), tup[1:])
split = len(l) / 2
instance_method_ref()
x = i + 1
z = r * cos(theta)
i1 = [1, 2]
print(z)
print(find_gt(R, x))
print(heapq.nlargest(10, numbers))
l = [0, 1]
my_dict[get_group_from_angle(a)].append(l)
set(dir()) - set(dir(__builtins__))
repos.git.add(submodule.path)
l2 = [4, 5, 7]
self._items = dict(*args, **kwargs)
sqlplus.communicate()
input.sort(key=cmp_to_key(cmp_items))
print((item, item * 2))
out = [next(it)]
win.clear()
print(normalized(A, 0))
imp.load_module(name, fh, abs_path, description)
field1 = forms.IntegerField(required=False)
y, x = np.ogrid[-a:nx - a, -b:ny - b]
print(width, height)
out = []
x = data[:, (0)]
ips.append(i)
self.type = ContentType.objects.get_for_model(self.__class__)
A = np.random.random(10)
b * a(a, b - 1)
regex = re.sub(define, lambda m: defines[m.group(1)], regex)
cap = cv.CaptureFromFile(path)
row.update(nominations)
decorator
self = tuple.__new__(cls, arc)
k = item[:-1]
self.device.send_command(CMD_BLINK, 100)
ret.append((s, e))
profile = webdriver.FirefoxProfile()
b = np.arange(n + 1)[:, (np.newaxis)]
req = urllib.request.Request(authurl)
[1, 5, 21],
a, b, c = 0, 1, 1
feed.read()
this_row.append(val)
root.left = self.insert_node(root.left, element)
os.stat(arg)
y /= sum(y)
len(self.__storage) == 0
token, _ = Token.objects.get_or_create(user=original_request.user)
results = expr.parseString(s)
queryset = User.objects.all()
points = np.asarray(points)
print(df)
plt.xticks(list(range(width)), alphabet[:width])
instance = cls()
print(resp.info())
self.execute()
times = []
list(out)
B = A[idx]
df
transform = ET.XSLT(xslt)
new_cols.columns = list(string.ascii_uppercase)[:len(new_cols.columns)]
t0 = time.time()
print(link)
turtle.exitonclick()
dir(p)
BaseServer.__init__(self, server_address, HandlerClass)
n = self._sock.send(data)
df = df[(df.StartTime <= df.Timestamp) & (df.EndTime >= df.Timestamp)]
l = list(a)
title = StringField()
a, b = tee(iterable)
base._subclasses.add(cls)
listB = [(20 * random.random()) for i in range(20000)]
page.setLayout(vbox1)
draw.text((0, 100), txt2)
set |= Set(form2.objects.filter(keyskills=i))
parser = argparse.ArgumentParser()
epoch_in.append(x)
False
a = np.random.random((10,))
pid = os.fork()
q.put(x)
object2 = ClassB(object1)
sshcon.connect(hostname, username=myuser, key_filename=mySSHK)
d1 * Bo
reactor.stop()
name = models.CharField(max_length=128)
renderer = fig.canvas.get_renderer()
window = QWidget()
simulations_to_run.put({})
Ainv = np.matrix(identitymatrix(n), dtype=int)
z = numpy.polyfit(x, y, 1)
wn.wup_similarity(dog, cat)
f = (x - d) / _diff[:, (index)]
n = (alen - flen) / struct.calcsize(before_char) + 1
deletemetadata[k]
list(islice(c, i))
keep.append(item)
vals[i] += abs(np.dot(u, m[j]))
data
sieve = [False] * (limit + 1)
x = np.arange(10)
8, 1, 1, 8
self.appendleft(value)
print(dataframe)
sys.exit(0)
self.response.out.write(template.render(path, template_values))
print([(coin / 100.0) for coin in coins])
isnan(a)
feature_names = np.array(iris.feature_names)
method_to_decorate(self, *args, **kwargs)
a = [random.choice(list(range(1, 7)))]
show()
i = quaternion(0, 1, 0, 0)
values = []
get_thread.start()
out = dict(map(get_key_value, columns))
x = np.empty(len(a))
output = (lambda x=data[2]: x + x)()
expr = Forward()
self.lookup_tables[field][value].append(index)
result = {}
plt.show(open_plot=True)
print(caller.f_locals)
type.__new__(mcs, name, bases, dct)
self._x = 0
pygame.display.update()
